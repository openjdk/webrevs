{"files":[{"patch":"@@ -3360,1 +3360,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -3377,1 +3377,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -3397,1 +3397,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -3418,1 +3418,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -3438,1 +3438,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -3454,1 +3454,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n@@ -4582,1 +4582,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -4595,1 +4595,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -4610,0 +4610,1 @@\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -4611,1 +4612,0 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n@@ -4619,0 +4619,1 @@\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -4620,1 +4621,0 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n@@ -4644,1 +4644,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -4671,1 +4671,1 @@\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(VM_Version::supports_avx512bw(), \"\");\n@@ -7701,1 +7701,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7708,1 +7709,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7718,1 +7720,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7725,1 +7728,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7735,1 +7739,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7742,1 +7747,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7753,1 +7759,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7760,1 +7767,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7771,1 +7779,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7778,1 +7787,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7788,1 +7798,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7795,1 +7806,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7805,1 +7817,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7812,1 +7825,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -7822,1 +7836,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds, src)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -7829,1 +7844,2 @@\n-  assert(UseAVX > 0 && ((vector_len < Assembler::AVX_512bit && !needs_evex(dst, nds)) || VM_Version::supports_avx512bw()), \"\");\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -8312,0 +8328,1 @@\n+  assert(VM_Version::supports_evex(), \"\");\n@@ -8340,0 +8357,1 @@\n+  assert(VM_Version::supports_evex(), \"\");\n@@ -8355,0 +8373,2 @@\n+  assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+        (vector_len == AVX_256bit ? VM_Version::supports_avx2() : VM_Version::supports_avx512bw()), \"\");\n@@ -8356,1 +8376,0 @@\n-  assert(!needs_evex(dst, nds, src) || VM_Version::supports_avx512bw(), \"\");\n@@ -8363,0 +8382,2 @@\n+  assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+        (vector_len == AVX_256bit ? VM_Version::supports_avx2() : VM_Version::supports_avx512bw()), \"\");\n@@ -8364,1 +8385,0 @@\n-  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -8403,0 +8423,1 @@\n+  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n@@ -8409,0 +8430,2 @@\n+  assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+        (vector_len == AVX_256bit ? VM_Version::supports_avx2() : VM_Version::supports_avx512bw()), \"\");\n@@ -8410,1 +8433,0 @@\n-  assert(!needs_evex(dst, nds) || VM_Version::supports_avx512bw(), \"\");\n@@ -8449,0 +8471,1 @@\n+  assert((vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds, src) || VM_Version::supports_avx512vl())), \"\");\n@@ -8455,1 +8478,3 @@\n-  assert(UseAVX > 0 && (vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n+  assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+        (vector_len == AVX_256bit ? VM_Version::supports_avx2() : VM_Version::supports_avx512bw()), \"\");\n+  assert((vector_len == Assembler::AVX_512bit || (!needs_evex(dst, nds) || VM_Version::supports_avx512vl())), \"\");\n@@ -8478,0 +8503,1 @@\n+  assert(VM_Version::supports_evex(), \"\");\n@@ -8506,0 +8532,1 @@\n+  assert(VM_Version::supports_evex(), \"\");\n@@ -10229,1 +10256,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10256,1 +10283,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10283,1 +10310,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10310,1 +10337,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10337,1 +10364,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10364,1 +10391,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10391,1 +10418,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n@@ -10419,1 +10446,1 @@\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":67,"deletions":40,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -929,0 +929,19 @@\n+void C2_MacroAssembler::vpuminmaxq(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister xtmp1, XMMRegister xtmp2, int vlen_enc) {\n+ \/\/ T1 = -1\n+ vpcmpeqq(xtmp1, xtmp1, xtmp1, vlen_enc);\n+ \/\/ T1 = -1 << 63\n+ vpsllq(xtmp1, xtmp1, 63, vlen_enc);\n+ \/\/ Convert SRC2 to signed value i.e. T2 = T1 + SRC2\n+ vpaddq(xtmp2, xtmp1, src2, vlen_enc);\n+ \/\/ Convert SRC1 to signed value i.e. T1 = T1 + SRC1\n+ vpaddq(xtmp1, xtmp1, src1, vlen_enc);\n+ \/\/ Mask = T2 > T1\n+ vpcmpgtq(xtmp1, xtmp2, xtmp1, vlen_enc);\n+ \/\/ Res = Mask ? Src2 : Src1\n+ if (opcode == Op_UMaxV) {\n+   vpblendvb(dst, src1, src2, xtmp1, vlen_enc);\n+ } else {\n+   vpblendvb(dst, src2, src1, xtmp1, vlen_enc);\n+ }\n+}\n+\n@@ -6671,1 +6690,0 @@\n-  vpsub(etype, dst, src1, src2, vlen_enc);\n@@ -6673,1 +6691,1 @@\n-  evmovdqu(etype, ktmp, dst, dst, false, vlen_enc);\n+  evmasked_op(etype == T_INT ? Op_SubVI : Op_SubVL, etype, ktmp, dst, src1, src2, false, vlen_enc, false);\n@@ -6697,1 +6715,1 @@\n-  \/\/ overflow = ((UMAX - MAX(SRC1 & SRC2)) <u MIN(SRC1, SRC2)) >>> 31 == 1\n+  \/\/ overflow_mask = (SRC1 + SRC2) <u (SRC1 | SRC2)\n@@ -6700,2 +6718,2 @@\n-  \/\/ Max_Input = Unsigned MAX INP1, INP2\n-  evpmaxu(etype, xtmp1, k0, src1, src2, true, vlen_enc);\n+  \/\/ T1 = SRC1 | SRC2\n+  vpor(xtmp1, src1, src2, vlen_enc);\n@@ -6704,6 +6722,2 @@\n-  \/\/ X = Max_Unsigned - Max_Input\n-  vpsub(etype, xtmp1, xtmp3, xtmp1, vlen_enc);\n-  \/\/ Min_Input = Unsigned MIN INP1, INP2\n-  evpminu(etype, xtmp2, k0, src1, src2, true, vlen_enc);\n-  \/\/ Unsigned compare:  Mask = X <u Min_Unsigned\n-  evpcmpu(etype, ktmp, xtmp2, xtmp1, Assembler::nlt, vlen_enc);\n+  \/\/ Unsigned compare:  Mask = Res <u T1\n+  evpcmpu(etype, ktmp, dst, xtmp1, Assembler::lt, vlen_enc);\n@@ -6715,2 +6729,6 @@\n-\/\/ Adaptation of unsigned addition overflow detection from hacker's delight\n-\/\/ section 2-13 : overflow = ((a & b) | ((a | b) & ~(s))) >>> 31 == 1\n+\/\/ Section 2-13 Hacker Delight list following overflow detection check for saturating\n+\/\/ unsigned addition operation.\n+\/\/    overflow_mask = ((a & b) | ((a | b) & ~( a + b))) >>> 31 == 1\n+\/\/\n+\/\/ We empirically determined its semantic equivalence to following reduced expression\n+\/\/    overflow_mask =  (a + b) <u (a | b)\n@@ -6718,4 +6736,2 @@\n-\/\/ Apply Logic optimization on above overflow detection expression by substituting 'a'\n-\/\/ with boolean values:-\n-\/\/   V1 : a = 0  =>  b & ~s\n-\/\/   V2 : a = 1  =>  b | ~s\n+\/\/ and also verified it though Alive2 solver.\n+\/\/ (https:\/\/alive2.llvm.org\/ce\/z\/XDQ7dY)\n@@ -6723,12 +6739,1 @@\n-\/\/        V1  V2\n-\/\/         |0  |1\n-\/\/      ___|___|___\n-\/\/       \\       \/____ a\n-\/\/        \\_____\/            a + b UMAX\n-\/\/           |                 |0   |1\n-\/\/        overflow          ___|____|___\n-\/\/           |_______________\\        \/\n-\/\/                            \\______\/\n-\/\/                                |\n-\/\/                                |\n-\/\/                               Res\n+\n@@ -6736,2 +6741,1 @@\n-                                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n-                                                       XMMRegister xtmp4, int vlen_enc) {\n+                                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, int vlen_enc) {\n@@ -6740,15 +6744,16 @@\n-  \/\/ T1 = SRC2 & ~Res\n-  vpandn(xtmp1, dst, src2, vlen_enc);\n-  \/\/ Compute Max_Unsigned (T2) = -1\n-  vpcmpeqd(xtmp3, xtmp3, xtmp3, vlen_enc);\n-  \/\/ T2 = ~Res\n-  vpxor(xtmp2, xtmp3, dst, vlen_enc);\n-  \/\/ T3 = SRC2 | ~Res\n-  vpor(xtmp2, xtmp2, src2, vlen_enc);\n-  \/\/ Compute mask for muxing T1 with T3 using SRC1.\n-  vpsign_extend_dq(etype, xtmp4, src1, vlen_enc);\n-  \/\/ Blend T1 and T3 using above mask.\n-  vpblendvb(xtmp4, xtmp1, xtmp2, xtmp4, vlen_enc);\n-  \/\/ Compute mask for blending result with saturated upper bound.\n-  vpsign_extend_dq(etype, xtmp4, xtmp4, vlen_enc);\n-  vpblendvb(dst, dst, xtmp3, xtmp4, vlen_enc);\n+  \/\/ Compute T1 = INP1 | INP2\n+  vpor(xtmp3, src1, src2, vlen_enc);\n+  \/\/ T1 = Minimum signed value.\n+  vpgenmin_value(etype, xtmp2, xtmp1, vlen_enc, true);\n+  \/\/ Convert T1 to signed value, T1 = T1 + MIN_VALUE\n+  vpadd(etype, xtmp3, xtmp3, xtmp2, vlen_enc);\n+  \/\/ Convert Res to signed value, Res<s> = Res + MIN_VALUE\n+  vpadd(etype, xtmp2, xtmp2, dst, vlen_enc);\n+  \/\/ Compute overflow detection mask = Res<1> <s T1\n+  if (etype == T_INT) {\n+    vpcmpgtd(xtmp3, xtmp3, xtmp2, vlen_enc);\n+  } else {\n+    assert(etype == T_LONG, \"\");\n+    vpcmpgtq(xtmp3, xtmp3, xtmp2, vlen_enc);\n+  }\n+  vpblendvb(dst, dst, xtmp1, xtmp3, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":51,"deletions":46,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -71,0 +71,3 @@\n+\n+  void vpuminmaxq(int opcode, XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister xtmp1, XMMRegister xtmp2, int vlen_enc);\n+\n@@ -538,2 +541,1 @@\n-                                      XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n-                                      XMMRegister xtmp4, int vlen_enc);\n+                                      XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, int vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1773,3 +1773,0 @@\n-      if (bt == T_LONG && !VM_Version::supports_avx512vl()) {\n-        return false;\n-      }\n@@ -6518,0 +6515,1 @@\n+  predicate(VM_Version::supports_avx512vl() || Matcher::vector_element_basic_type(n) != T_LONG);\n@@ -6532,0 +6530,1 @@\n+  predicate(VM_Version::supports_avx512vl() || Matcher::vector_element_basic_type(n) != T_LONG);\n@@ -6545,0 +6544,14 @@\n+instruct uminmaxq_reg(vec dst, vec a, vec b, vec xtmp1, vec xtmp2) %{\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (UMinV a b));\n+  match(Set dst (UMaxV a b));\n+  effect(TEMP xtmp1, TEMP xtmp2);\n+  format %{ \"vector_uminmaxq_reg  $dst,$a,$b\\t! using xtmp1 and xtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vpuminmaxq(opcode, $dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -10635,1 +10648,1 @@\n-instruct saturating_unsigned_add_reg_avx(vec dst, vec src1, vec src2, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4)\n+instruct saturating_unsigned_add_reg_avx(vec dst, vec src1, vec src2, vec xtmp1, vec xtmp2, vec xtmp3)\n@@ -10640,2 +10653,2 @@\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4);\n-  format %{ \"saturating_vector_op $dst, $src1, $src2 \\t! using $xtmp1, $xtmp2, $xtmp3 and $xtmp4 as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3);\n+  format %{ \"saturating_vector_op $dst, $src1, $src2 \\t! using $xtmp1, $xtmp2 and $xtmp3 as TEMP\" %}\n@@ -10646,1 +10659,1 @@\n-                                      $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister, vlen_enc);\n+                                      $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":20,"deletions":7,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -150,1 +150,1 @@\n-  bool _is_unsigned;\n+  const bool _is_unsigned;\n@@ -172,1 +172,1 @@\n-  SaturatingAddVBNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1,in2,vt,is_unsigned) {}\n+  SaturatingAddVBNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1, in2, vt, is_unsigned) {}\n@@ -186,1 +186,1 @@\n-  SaturatingAddVSNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1,in2,vt,is_unsigned) {}\n+  SaturatingAddVSNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1, in2, vt, is_unsigned) {}\n@@ -201,1 +201,1 @@\n-  SaturatingAddVINode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1,in2,vt,is_unsigned) {}\n+  SaturatingAddVINode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1, in2, vt, is_unsigned) {}\n@@ -215,1 +215,1 @@\n-  SaturatingAddVLNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1,in2,vt,is_unsigned) {}\n+  SaturatingAddVLNode(Node* in1, Node* in2, const TypeVect* vt, bool is_unsigned) : SaturatingVectorNode(in1, in2, vt, is_unsigned) {}\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -78,10 +78,0 @@\n-    \/**\n-     * A constant holding polarity(sign) mask used by saturating operations.\n-     *\/\n-    public static final byte POLARITY_MASK_BYTE = (byte)(1 << 7);\n-\n-    \/**\n-     * A constant holding maximum unsigned value used by saturating unsigned operations.\n-     *\/\n-    public static final byte UNSIGNED_MAX = (byte)0xFF;\n-\n@@ -647,7 +637,5 @@\n-        byte res = (byte)(a - b);\n-        \/\/ Saturation occurs when result of computation over opposite polarity inputs exceeds the byte\n-        \/\/ value range, in this case, for a non-commutative operation like subtraction, result polarity does not\n-        \/\/ comply with first argument polarity.\n-        boolean opposite_polarity_inputs = ((a ^ b) & POLARITY_MASK_BYTE) == POLARITY_MASK_BYTE;\n-        if (opposite_polarity_inputs && ((res & POLARITY_MASK_BYTE) != (a & POLARITY_MASK_BYTE))) {\n-            return res < 0 ? Byte.MAX_VALUE : Byte.MIN_VALUE;\n+        int res = a - b;\n+        if (res > Byte.MAX_VALUE) {\n+            return Byte.MAX_VALUE;\n+        } else if (res < Byte.MIN_VALUE) {\n+            return Byte.MIN_VALUE;\n@@ -655,1 +643,1 @@\n-            return res;\n+            return (byte)res;\n@@ -661,1 +649,1 @@\n-     * which returns a {@code Byte.UNSIGNED_MAX} in overflowing scenario.\n+     * which returns an maximum unsigned byte value (0xFF) in overflowing scenario.\n@@ -665,1 +653,1 @@\n-     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting {@code Byte.UNSIGNED_MAX} value.\n+     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting maximum unsigned byte value.\n@@ -673,1 +661,1 @@\n-           return Byte.UNSIGNED_MAX;\n+           return (byte)(-1);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Byte.java","additions":9,"deletions":21,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -90,10 +90,0 @@\n-    \/**\n-     * A constant holding polarity(sign) mask used by saturating operations.\n-     *\/\n-    public static final int POLARITY_MASK_INT  = 1 << 31;\n-\n-    \/**\n-     * A constant holding maximum unsigned value used by saturating unsigned operations.\n-     *\/\n-    public static final int UNSIGNED_MAX = 0xFFFFFFFF;\n-\n@@ -2058,7 +2048,5 @@\n-        int res = a - b;\n-        boolean opposite_polarity_inputs = ((a ^ b) & POLARITY_MASK_INT) == POLARITY_MASK_INT;\n-        \/\/ Saturation occurs when result of computation over opposite polarity inputs exceeds the int\n-        \/\/ value range, in this case, for a non-commutative operation like subtraction, result polarity does not\n-        \/\/ comply with first argument polarity.\n-        if (opposite_polarity_inputs && ((res & POLARITY_MASK_INT) != (a & POLARITY_MASK_INT))) {\n-            return res < 0 ? Integer.MAX_VALUE : Integer.MIN_VALUE;\n+        long res = (long)a - (long)b;\n+        if (res > Integer.MAX_VALUE) {\n+            return Integer.MAX_VALUE;\n+        } else if (res < Integer.MIN_VALUE) {\n+            return Integer.MIN_VALUE;\n@@ -2066,1 +2054,1 @@\n-            return res;\n+            return (int)res;\n@@ -2072,1 +2060,1 @@\n-     * which returns a {@code Integer.UNSIGNED_MAX} in overflowing scenario.\n+     * which returns maximum unsigned int value in overflowing scenario.\n@@ -2076,1 +2064,1 @@\n-     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting {@code Integer.UNSIGNED_MAX} value.\n+     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting maximum unsigned int value.\n@@ -2084,1 +2072,1 @@\n-           return Integer.UNSIGNED_MAX;\n+           return -1;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Integer.java","additions":9,"deletions":21,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -1987,3 +1987,2 @@\n-        \/\/ Saturation occurs when result of computation over same polarity inputs exceeds the {@code long} value range.\n-        boolean same_polarity_inputs = ((a ^ b) & POLARITY_MASK_LONG) == 0;\n-        if (same_polarity_inputs && ((res & POLARITY_MASK_LONG) != (a & POLARITY_MASK_LONG))) {\n+        \/\/ HD 2-12 Overflow iff both arguments have the opposite sign of the result\n+        if (((a ^ res) & (b ^ res)) < 0) {\n@@ -2008,1 +2007,0 @@\n-        boolean opposite_polarity_inputs = ((a ^ b) & POLARITY_MASK_LONG) == POLARITY_MASK_LONG;\n@@ -2010,4 +2008,3 @@\n-        \/\/ Saturation occurs when result of computation over opposite polarity inputs exceeds the long\n-        \/\/ value range, in this case, for a non-commutative operation like subtraction, result polarity does not\n-        \/\/ comply with first argument polarity.\n-        if (opposite_polarity_inputs && ((res & POLARITY_MASK_LONG) != (a & POLARITY_MASK_LONG))) {\n+        \/\/ HD 2-12 Overflow iff the arguments have different signs and\n+        \/\/ the sign of the result is different from the sign of x\n+        if (((a ^ res) & (b ^ res)) < 0) {\n@@ -2022,1 +2019,1 @@\n-     * which returns a {@code Long.UNSIGNED_MAX} in overflowing scenario.\n+     * which returns maximum unsigned long value in overflowing scenario.\n@@ -2026,1 +2023,1 @@\n-     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting {@code Long.UNSIGNED_MAX} value.\n+     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting maximum unsigned long value.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Long.java","additions":7,"deletions":10,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -77,10 +77,0 @@\n-    \/**\n-     * A constant holding polarity(sign) mask used by saturating operations.\n-     *\/\n-    public static final short POLARITY_MASK_SHORT = (short)(1 << 15);\n-\n-    \/**\n-     * A constant holding maximum unsigned value used by saturating unsigned operations.\n-     *\/\n-    public static final short UNSIGNED_MAX = (short)0xFFFF;\n-\n@@ -666,1 +656,1 @@\n-           return (short)res;\n+            return (short)res;\n@@ -682,7 +672,5 @@\n-        short res = (short)(a - b);\n-        \/\/ Saturation occurs when result of computation over opposite polarity inputs exceeds the short\n-        \/\/ value range, in this case, for a non-commutative operation like subtraction, result polarity does not\n-        \/\/ comply with first argument polarity.\n-        boolean opposite_polarity_inputs = ((a ^ b) & POLARITY_MASK_SHORT) == POLARITY_MASK_SHORT;\n-        if (opposite_polarity_inputs && ((res & POLARITY_MASK_SHORT) != (a & POLARITY_MASK_SHORT))) {\n-            return res < 0 ? Short.MAX_VALUE : Short.MIN_VALUE;\n+        int res = a - b;\n+        if (res > Short.MAX_VALUE) {\n+            return Short.MAX_VALUE;\n+        } else if (res < Short.MIN_VALUE) {\n+            return Short.MIN_VALUE;\n@@ -690,1 +678,1 @@\n-            return res;\n+            return (short)res;\n@@ -696,1 +684,1 @@\n-     * which returns a {@code Short.UNSIGNED_MAX} in overflowing scenario.\n+     * which returns maximum unsigned short value in overflowing scenario.\n@@ -700,1 +688,1 @@\n-     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting {@code Short.UNSIGNED_MAX} value.\n+     * @return the unsigned sum of {@code a} and {@code b} iff within unsigned value range else delimiting maximum unsigned short value.\n@@ -708,1 +696,1 @@\n-           return Short.UNSIGNED_MAX;\n+           return (short)(-1);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Short.java","additions":10,"deletions":22,"binary":false,"changes":32,"status":"modified"}]}