{"files":[{"patch":"@@ -2793,0 +2793,2 @@\n+  enum DataOrder { Unknown, Forward, Reverse};\n+  DataOrder  _value_order;\n@@ -2798,1 +2800,1 @@\n-    _phase(phase), _store(store)\n+    _phase(phase), _store(store), _value_order(DataOrder::Unknown)\n@@ -2806,3 +2808,3 @@\n-  bool is_adjacent_pair(const StoreNode* use_store, const StoreNode* def_store) const;\n-  bool is_adjacent_input_pair(const Node* n1, const Node* n2, const int memory_size) const;\n-  static bool is_con_RShift(const Node* n, Node const*& base_out, jint& shift_out);\n+  bool is_adjacent_pair(const StoreNode* use_store, const StoreNode* def_store);\n+  bool is_adjacent_input_pair(const Node* n1, const Node* n2, const int memory_size);\n+  static bool is_con_RShift(const Node* n, Node const*& base_out, jint& shift_out, PhaseGVN* phase);\n@@ -2844,2 +2846,2 @@\n-  Status find_adjacent_use_store(const StoreNode* def_store) const;\n-  Status find_adjacent_def_store(const StoreNode* use_store) const;\n+  Status find_adjacent_use_store(const StoreNode* def_store);\n+  Status find_adjacent_def_store(const StoreNode* use_store);\n@@ -2851,1 +2853,1 @@\n-  void collect_merge_list(Node_List& merge_list) const;\n+  void collect_merge_list(Node_List& merge_list);\n@@ -2936,1 +2938,1 @@\n-bool MergePrimitiveStores::is_adjacent_pair(const StoreNode* use_store, const StoreNode* def_store) const {\n+bool MergePrimitiveStores::is_adjacent_pair(const StoreNode* use_store, const StoreNode* def_store) {\n@@ -2954,1 +2956,1 @@\n-bool MergePrimitiveStores::is_adjacent_input_pair(const Node* n1, const Node* n2, const int memory_size) const {\n+bool MergePrimitiveStores::is_adjacent_input_pair(const Node* n1, const Node* n2, const int memory_size) {\n@@ -2968,1 +2970,1 @@\n-  if (!is_con_RShift(n2, base_n2, shift_n2)) {\n+  if (!is_con_RShift(n2, base_n2, shift_n2, _phase)) {\n@@ -2981,1 +2983,1 @@\n-  } else if (!is_con_RShift(n1, base_n1, shift_n1)) {\n+  } else if (!is_con_RShift(n1, base_n1, shift_n1, _phase)) {\n@@ -2986,1 +2988,1 @@\n-      shift_n1 + bits_per_store != shift_n2 ||\n+      abs(shift_n1 - shift_n2) != bits_per_store ||\n@@ -2991,0 +2993,21 @@\n+  \/\/ initialize value_order once\n+  if (_value_order == DataOrder::Unknown) {\n+    if (shift_n1 < shift_n2) {\n+      _value_order = DataOrder::Forward;\n+#ifdef VM_LITTLE_ENDIAN\n+    } else if (memory_size == 1 &&\n+               Matcher::match_rule_supported(Op_ReverseBytesI) &&\n+               Matcher::match_rule_supported(Op_ReverseBytesL)) {\n+      _value_order = DataOrder::Reverse;  \/\/ only support reverse bytes\n+#endif\n+    } else {\n+      return false;\n+    }\n+  }\n+\n+  if ((_value_order == DataOrder::Forward && shift_n1 > shift_n2) ||\n+      (_value_order == DataOrder::Reverse && shift_n1 < shift_n2)) {\n+    \/\/ wrong order\n+    return false;\n+  }\n+\n@@ -2996,1 +3019,1 @@\n-bool MergePrimitiveStores::is_con_RShift(const Node* n, Node const*& base_out, jint& shift_out) {\n+bool MergePrimitiveStores::is_con_RShift(const Node* n, Node const*& base_out, jint& shift_out, PhaseGVN* phase) {\n@@ -3015,0 +3038,7 @@\n+\n+  if (phase->type(n)->isa_int()  != nullptr ||\n+      phase->type(n)->isa_long() != nullptr) {\n+    base_out = n;\n+    shift_out = 0;\n+    return true;\n+  }\n@@ -3064,1 +3094,1 @@\n-MergePrimitiveStores::Status MergePrimitiveStores::find_adjacent_use_store(const StoreNode* def_store) const {\n+MergePrimitiveStores::Status MergePrimitiveStores::find_adjacent_use_store(const StoreNode* def_store) {\n@@ -3073,1 +3103,1 @@\n-MergePrimitiveStores::Status MergePrimitiveStores::find_adjacent_def_store(const StoreNode* use_store) const {\n+MergePrimitiveStores::Status MergePrimitiveStores::find_adjacent_def_store(const StoreNode* use_store) {\n@@ -3138,1 +3168,1 @@\n-void MergePrimitiveStores::collect_merge_list(Node_List& merge_list) const {\n+void MergePrimitiveStores::collect_merge_list(Node_List& merge_list) {\n@@ -3201,0 +3231,1 @@\n+    assert(_value_order != DataOrder::Unknown, \"sanity\");\n@@ -3207,0 +3238,3 @@\n+    if (_value_order == DataOrder::Reverse) {\n+      swap(hi, lo);\n+    }\n@@ -3210,1 +3244,1 @@\n-    bool is_true = is_con_RShift(hi, hi_base, hi_shift);\n+    bool is_true = is_con_RShift(hi, hi_base, hi_shift, _phase);\n@@ -3236,0 +3270,9 @@\n+  if (_value_order == DataOrder::Reverse) {\n+    if (new_memory_size == 8) {\n+      merged_input_value = _phase->transform(new ReverseBytesLNode(nullptr, merged_input_value));\n+    } else if (new_memory_size == 4) {\n+      merged_input_value = _phase->transform(new ReverseBytesINode(nullptr, merged_input_value));\n+    } else {\n+      return nullptr;\n+    }\n+  }\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":60,"deletions":17,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -804,1 +804,5 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"false\", \"aarch64\", \"false\"})\n+    @IR(counts = { IRNode.STORE_L_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\",\n+                   IRNode.REVERSE_BYTES_L, \"1\"},\n+        applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n@@ -835,1 +839,5 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"false\", \"aarch64\", \"false\"})\n+    @IR(counts = { IRNode.STORE_L_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\",\n+                   IRNode.REVERSE_BYTES_L, \"1\"},\n+        applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n@@ -914,1 +922,5 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"false\", \"aarch64\", \"false\"})\n+    @IR(counts = {IRNode.STORE_I_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"2\",\n+                  IRNode.REVERSE_BYTES_I, \"1\"},\n+        applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n@@ -1013,0 +1025,7 @@\n+         applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+         applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"true\", \"aarch64\", \"true\"})\n+    @IR(counts = {IRNode.STORE_B_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"8\",\n+                  IRNode.STORE_C_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\",  \/\/ Stores of constants can be merged\n+                  IRNode.STORE_I_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"2\",\n+                  IRNode.STORE_L_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"0\",\n+                  IRNode.REVERSE_BYTES_I, \"1\"},\n@@ -1014,1 +1033,1 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n@@ -1904,1 +1923,8 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"false\", \"aarch64\", \"false\"})\n+    @IR(counts = {IRNode.STORE_B_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\", \/\/ for RangeCheck trap\n+                  IRNode.STORE_C_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"0\",\n+                  IRNode.STORE_I_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"0\",\n+                  IRNode.STORE_L_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\", \/\/ expect merged\n+                  IRNode.REVERSE_BYTES_L, \"1\"},\n+        applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n@@ -2175,1 +2201,8 @@\n-        applyIfPlatform = {\"little-endian\", \"true\"})\n+        applyIfPlatformAnd = {\"little-endian\", \"true\", \"x64\", \"false\", \"aarch64\", \"false\"})\n+    @IR(counts = {IRNode.STORE_B_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"2\",\n+                  IRNode.STORE_C_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"0\",\n+                  IRNode.STORE_I_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"1\",\n+                  IRNode.STORE_L_OF_CLASS, \"byte\\\\\\\\[int:>=0] \\\\\\\\(java\/lang\/Cloneable,java\/io\/Serializable\\\\\\\\)\", \"0\",\n+                  IRNode.REVERSE_BYTES_I, \"1\"},\n+        applyIf = {\"UseUnalignedAccesses\", \"true\"},\n+        applyIfPlatformOr = {\"x64\", \"true\", \"aarch64\", \"true\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/TestMergeStores.java","additions":39,"deletions":6,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -1458,0 +1458,10 @@\n+    public static final String REVERSE_BYTES_I = PREFIX + \"REVERSE_BYTES_I\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(REVERSE_BYTES_I, \"ReverseBytesI\");\n+    }\n+\n+    public static final String REVERSE_BYTES_L = PREFIX + \"REVERSE_BYTES_L\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(REVERSE_BYTES_L, \"ReverseBytesL\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"}]}