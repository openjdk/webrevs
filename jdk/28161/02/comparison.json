{"files":[{"patch":"@@ -67,0 +67,1 @@\n+  HOTSPOT_JTREG_EXECUTABLES_JDK_LIBS_exegc_z_TestLinuxVirtualAddressSpace := java.base:libjvm\n@@ -68,0 +69,1 @@\n+  HOTSPOT_JTREG_EXECUTABLES_LIBS_exegc_z_TestLinuxVirtualAddressSpace := -ldl\n@@ -74,1 +76,2 @@\n-      exeinvoke.c exestack-gap.c exestack-tls.c libAsyncGetCallTraceTest.cpp\n+      exeinvoke.c exestack-gap.c exestack-tls.c libAsyncGetCallTraceTest.cpp \\\n+      exegc_z_TestLinuxVirtualAddressSpace.c\n","filename":"make\/test\/JtregNativeHotspot.gmk","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -24,82 +24,2 @@\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/shared\/gcLogPrecious.hpp\"\n-#include \"gc\/z\/zAddress.hpp\"\n-#include \"gc\/z\/zBarrierSetAssembler.hpp\"\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"runtime\/globals.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/powerOfTwo.hpp\"\n-\n-#ifdef LINUX\n-#include <sys\/mman.h>\n-#endif \/\/ LINUX\n-\n-\/\/ Default value if probing is not implemented for a certain platform\n-\/\/ Max address bit is restricted by implicit assumptions in the code, for instance\n-\/\/ the bit layout of ZForwardingEntry or Partial array entry (see ZMarkStackEntry) in mark stack\n-static const size_t DEFAULT_MAX_ADDRESS_BIT = 46;\n-\/\/ Minimum value returned, if probing fail\n-static const size_t MINIMUM_MAX_ADDRESS_BIT = 36;\n-\n-static size_t probe_valid_max_address_bit() {\n-#ifdef LINUX\n-  size_t max_address_bit = 0;\n-  const size_t page_size = os::vm_page_size();\n-  for (size_t i = DEFAULT_MAX_ADDRESS_BIT; i > MINIMUM_MAX_ADDRESS_BIT; --i) {\n-    const uintptr_t base_addr = ((uintptr_t) 1U) << i;\n-    if (msync((void*)base_addr, page_size, MS_ASYNC) == 0) {\n-      \/\/ msync suceeded, the address is valid, and maybe even already mapped.\n-      max_address_bit = i;\n-      break;\n-    }\n-    if (errno != ENOMEM) {\n-      \/\/ Some error occured. This should never happen, but msync\n-      \/\/ has some undefined behavior, hence ignore this bit.\n-#ifdef ASSERT\n-      fatal(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#else \/\/ ASSERT\n-      log_warning_p(gc)(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#endif \/\/ ASSERT\n-      continue;\n-    }\n-    \/\/ Since msync failed with ENOMEM, the page might not be mapped.\n-    \/\/ Try to map it, to see if the address is valid.\n-    void* const result_addr = mmap((void*) base_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      munmap(result_addr, page_size);\n-    }\n-    if ((uintptr_t) result_addr == base_addr) {\n-      \/\/ address is valid\n-      max_address_bit = i;\n-      break;\n-    }\n-  }\n-  if (max_address_bit == 0) {\n-    \/\/ probing failed, allocate a very high page and take that bit as the maximum\n-    const uintptr_t high_addr = ((uintptr_t) 1U) << DEFAULT_MAX_ADDRESS_BIT;\n-    void* const result_addr = mmap((void*) high_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      max_address_bit = BitsPerSize_t - count_leading_zeros((size_t) result_addr) - 1;\n-      munmap(result_addr, page_size);\n-    }\n-  }\n-  log_info_p(gc, init)(\"Probing address space for the highest valid bit: %zu\", max_address_bit);\n-  return MAX2(max_address_bit, MINIMUM_MAX_ADDRESS_BIT);\n-#else \/\/ LINUX\n-  return DEFAULT_MAX_ADDRESS_BIT;\n-#endif \/\/ LINUX\n-}\n-\n-size_t ZPlatformAddressOffsetBits() {\n-  static const size_t valid_max_address_offset_bits = probe_valid_max_address_bit() + 1;\n-  const size_t max_address_offset_bits = valid_max_address_offset_bits - 3;\n-  const size_t min_address_offset_bits = max_address_offset_bits - 2;\n-  const size_t address_offset = ZGlobalsPointers::min_address_offset_request();\n-  const size_t address_offset_bits = log2i_exact(address_offset);\n-  return clamp(address_offset_bits, min_address_offset_bits, max_address_offset_bits);\n-}\n-\n-size_t ZPlatformAddressHeapBaseShift() {\n-  return ZPlatformAddressOffsetBits();\n-}\n+ #include \"gc\/z\/zAddress.hpp\"\n+ #include \"gc\/z\/zBarrierSetAssembler.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zAddress_aarch64.cpp","additions":2,"deletions":82,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -31,3 +31,0 @@\n-size_t ZPlatformAddressOffsetBits();\n-size_t ZPlatformAddressHeapBaseShift();\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zAddress_aarch64.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -24,86 +24,1 @@\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/shared\/gcLogPrecious.hpp\"\n-#include \"gc\/z\/zAddress.inline.hpp\"\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"runtime\/globals.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/powerOfTwo.hpp\"\n-\n-#ifdef LINUX\n-#include <sys\/mman.h>\n-#endif \/\/ LINUX\n-\n-\/\/ Default value if probing is not implemented for a certain platform\n-\/\/ Max address bit is restricted by implicit assumptions in the code, for instance\n-\/\/ the bit layout of ZForwardingEntry or Partial array entry (see ZMarkStackEntry) in mark stack\n-static const size_t DEFAULT_MAX_ADDRESS_BIT = 46;\n-\/\/ Minimum value returned, if probing fail\n-static const size_t MINIMUM_MAX_ADDRESS_BIT = 36;\n-\n-static size_t probe_valid_max_address_bit() {\n-#ifdef LINUX\n-  size_t max_address_bit = 0;\n-  const size_t page_size = os::vm_page_size();\n-  for (size_t i = DEFAULT_MAX_ADDRESS_BIT; i > MINIMUM_MAX_ADDRESS_BIT; --i) {\n-    const uintptr_t base_addr = ((uintptr_t) 1U) << i;\n-    if (msync((void*)base_addr, page_size, MS_ASYNC) == 0) {\n-      \/\/ msync suceeded, the address is valid, and maybe even already mapped.\n-      max_address_bit = i;\n-      break;\n-    }\n-    if (errno != ENOMEM) {\n-      \/\/ Some error occured. This should never happen, but msync\n-      \/\/ has some undefined behavior, hence ignore this bit.\n-#ifdef ASSERT\n-      fatal(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#else \/\/ ASSERT\n-      log_warning_p(gc)(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#endif \/\/ ASSERT\n-      continue;\n-    }\n-    \/\/ Since msync failed with ENOMEM, the page might not be mapped.\n-    \/\/ Try to map it, to see if the address is valid.\n-    void* const result_addr = mmap((void*) base_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      munmap(result_addr, page_size);\n-    }\n-    if ((uintptr_t) result_addr == base_addr) {\n-      \/\/ address is valid\n-      max_address_bit = i;\n-      break;\n-    }\n-  }\n-  if (max_address_bit == 0) {\n-    \/\/ probing failed, allocate a very high page and take that bit as the maximum\n-    const uintptr_t high_addr = ((uintptr_t) 1U) << DEFAULT_MAX_ADDRESS_BIT;\n-    void* const result_addr = mmap((void*) high_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      max_address_bit = BitsPerSize_t - count_leading_zeros((size_t) result_addr) - 1;\n-      munmap(result_addr, page_size);\n-    }\n-  }\n-  log_info_p(gc, init)(\"Probing address space for the highest valid bit: %zu\", max_address_bit);\n-  return MAX2(max_address_bit, MINIMUM_MAX_ADDRESS_BIT);\n-#else \/\/ LINUX\n-  return DEFAULT_MAX_ADDRESS_BIT;\n-#endif \/\/ LINUX\n-}\n-\n-size_t ZPlatformAddressOffsetBits() {\n-  static const size_t valid_max_address_offset_bits = probe_valid_max_address_bit() + 1;\n-  const size_t max_address_offset_bits = valid_max_address_offset_bits - 3;\n-#ifdef ADDRESS_SANITIZER\n-  \/\/ The max supported value is 44 because of other internal data structures.\n-  return MIN2(valid_max_address_offset_bits, (size_t)44);\n-#else\n-  const size_t min_address_offset_bits = max_address_offset_bits - 2;\n-  const size_t address_offset = ZGlobalsPointers::min_address_offset_request();\n-  const size_t address_offset_bits = log2i_exact(address_offset);\n-  return clamp(address_offset_bits, min_address_offset_bits, max_address_offset_bits);\n-#endif\n-}\n-\n-size_t ZPlatformAddressHeapBaseShift() {\n-  return ZPlatformAddressOffsetBits();\n-}\n+#include \"gc\/z\/zAddress.hpp\"\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/zAddress_ppc.cpp","additions":1,"deletions":86,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -31,3 +31,0 @@\n-size_t ZPlatformAddressOffsetBits();\n-size_t ZPlatformAddressHeapBaseShift();\n-\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/zAddress_ppc.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -25,2 +25,0 @@\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/shared\/gcLogPrecious.hpp\"\n@@ -29,78 +27,0 @@\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"runtime\/globals.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/powerOfTwo.hpp\"\n-\n-#ifdef LINUX\n-#include <sys\/mman.h>\n-#endif \/\/ LINUX\n-\n-\/\/ Default value if probing is not implemented for a certain platform\n-\/\/ Max address bit is restricted by implicit assumptions in the code, for instance\n-\/\/ the bit layout of ZForwardingEntry or Partial array entry (see ZMarkStackEntry) in mark stack\n-static const size_t DEFAULT_MAX_ADDRESS_BIT = 46;\n-\/\/ Minimum value returned, if probing fail\n-static const size_t MINIMUM_MAX_ADDRESS_BIT = 36;\n-\n-static size_t probe_valid_max_address_bit() {\n-#ifdef LINUX\n-  size_t max_address_bit = 0;\n-  const size_t page_size = os::vm_page_size();\n-  for (size_t i = DEFAULT_MAX_ADDRESS_BIT; i > MINIMUM_MAX_ADDRESS_BIT; --i) {\n-    const uintptr_t base_addr = ((uintptr_t) 1U) << i;\n-    if (msync((void*)base_addr, page_size, MS_ASYNC) == 0) {\n-      \/\/ msync suceeded, the address is valid, and maybe even already mapped.\n-      max_address_bit = i;\n-      break;\n-    }\n-    if (errno != ENOMEM) {\n-      \/\/ Some error occured. This should never happen, but msync\n-      \/\/ has some undefined behavior, hence ignore this bit.\n-#ifdef ASSERT\n-      fatal(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#else \/\/ ASSERT\n-      log_warning_p(gc)(\"Received '%s' while probing the address space for the highest valid bit\", os::errno_name(errno));\n-#endif \/\/ ASSERT\n-      continue;\n-    }\n-    \/\/ Since msync failed with ENOMEM, the page might not be mapped.\n-    \/\/ Try to map it, to see if the address is valid.\n-    void* const result_addr = mmap((void*) base_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      munmap(result_addr, page_size);\n-    }\n-    if ((uintptr_t) result_addr == base_addr) {\n-      \/\/ address is valid\n-      max_address_bit = i;\n-      break;\n-    }\n-  }\n-  if (max_address_bit == 0) {\n-    \/\/ probing failed, allocate a very high page and take that bit as the maximum\n-    const uintptr_t high_addr = ((uintptr_t) 1U) << DEFAULT_MAX_ADDRESS_BIT;\n-    void* const result_addr = mmap((void*) high_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n-    if (result_addr != MAP_FAILED) {\n-      max_address_bit = BitsPerSize_t - count_leading_zeros((size_t) result_addr) - 1;\n-      munmap(result_addr, page_size);\n-    }\n-  }\n-  log_info_p(gc, init)(\"Probing address space for the highest valid bit: %zu\", max_address_bit);\n-  return MAX2(max_address_bit, MINIMUM_MAX_ADDRESS_BIT);\n-#else \/\/ LINUX\n-  return DEFAULT_MAX_ADDRESS_BIT;\n-#endif \/\/ LINUX\n-}\n-\n-size_t ZPlatformAddressOffsetBits() {\n-  static const  size_t valid_max_address_offset_bits = probe_valid_max_address_bit() + 1;\n-  const size_t max_address_offset_bits = valid_max_address_offset_bits - 3;\n-  const size_t min_address_offset_bits = max_address_offset_bits - 2;\n-  const size_t address_offset = ZGlobalsPointers::min_address_offset_request();\n-  const size_t address_offset_bits = log2i_exact(address_offset);\n-  return clamp(address_offset_bits, min_address_offset_bits, max_address_offset_bits);\n-}\n-\n-size_t ZPlatformAddressHeapBaseShift() {\n-  return ZPlatformAddressOffsetBits();\n-}\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/zAddress_riscv.cpp","additions":0,"deletions":80,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -31,3 +31,0 @@\n-size_t ZPlatformAddressOffsetBits();\n-size_t ZPlatformAddressHeapBaseShift();\n-\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/zAddress_riscv.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -24,1 +24,0 @@\n-#include \"gc\/shared\/gc_globals.hpp\"\n@@ -26,3 +25,0 @@\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/powerOfTwo.hpp\"\n@@ -32,16 +28,0 @@\n-size_t ZPlatformAddressOffsetBits() {\n-#ifdef ADDRESS_SANITIZER\n-  return 44;\n-#else\n-  const size_t min_address_offset_bits = 42; \/\/ 4TB\n-  const size_t max_address_offset_bits = 44; \/\/ 16TB\n-  const size_t address_offset = ZGlobalsPointers::min_address_offset_request();\n-  const size_t address_offset_bits = log2i_exact(address_offset);\n-  return clamp(address_offset_bits, min_address_offset_bits, max_address_offset_bits);\n-#endif\n-}\n-\n-size_t ZPlatformAddressHeapBaseShift() {\n-  return ZPlatformAddressOffsetBits();\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zAddress_x86.cpp","additions":0,"deletions":20,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -31,3 +31,0 @@\n-size_t ZPlatformAddressOffsetBits();\n-size_t ZPlatformAddressHeapBaseShift();\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zAddress_x86.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,41 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+#ifdef __APPLE__\n+#include <mach\/vm_param.h>\n+#endif\n+\n+#if defined (__APPLE__) && defined(MACH_VM_MAX_ADDRESS)\n+\/\/ Use the system define if available\n+#define Z_PLATFORM_MAX_HEAP_ADDRESS ((size_t)(MACH_VM_MAX_ADDRESS))\n+#else\n+\/\/ Try using up to 46 bits for the address\n+#define Z_PLATFORM_MAX_HEAP_ADDRESS (size_t(1) << 45)\n+#endif\n+\n+size_t ZPlatformHeapBaseMaxShift() {\n+  return clamp((size_t)log2i(Z_PLATFORM_MAX_HEAP_ADDRESS), ZAddressHeapBaseMinShift,ZAddressHeapBaseMaxShift);\n+}\n","filename":"src\/hotspot\/os\/bsd\/gc\/z\/zAddress_bsd.cpp","additions":41,"deletions":0,"binary":false,"changes":41,"status":"added"},{"patch":"@@ -0,0 +1,31 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef OS_BSD_GC_Z_ZADDRESS_BSD_HPP\n+#define OS_BSD_GC_Z_ZADDRESS_BSD_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+size_t ZPlatformHeapBaseMaxShift();\n+\n+#endif \/\/ OS_BSD_GC_Z_ZADDRESS_BSD_HPP\n","filename":"src\/hotspot\/os\/bsd\/gc\/z\/zAddress_bsd.hpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"added"},{"patch":"@@ -0,0 +1,91 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/shared\/gcLogPrecious.hpp\"\n+#include \"gc\/z\/zAddress.hpp\"\n+#include \"gc\/z\/zErrno.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+\n+#include <sys\/mman.h>\n+\n+\/\/ Maximum value where probing starts\n+static constexpr size_t MAXIMUM_MAX_HEAP_BASE_SHIFT = MIN2(ZAddressHeapBaseMaxShift, size_t(47));\n+\/\/ Minimum value returned, if probing fail\n+static constexpr size_t MINIMUM_MAX_HEAP_BASE_SHIFT = ZAddressHeapBaseMinShift;\n+\n+static size_t probe_heap_base_max_shift() {\n+  const size_t page_size = os::vm_page_size();\n+  size_t max_heap_base_shift = 0;\n+\n+  for (size_t i = MAXIMUM_MAX_HEAP_BASE_SHIFT; i > MINIMUM_MAX_HEAP_BASE_SHIFT; --i) {\n+    const uintptr_t base_addr = ((uintptr_t) 1U) << i;\n+    if (msync((void*)base_addr, page_size, MS_ASYNC) == 0) {\n+      \/\/ msync succeeded, the address is valid, and maybe even already mapped.\n+      max_heap_base_shift = i;\n+      break;\n+    }\n+\n+    if (errno != ENOMEM) {\n+      ZErrno err;\n+      \/\/ Some error occurred. This should never happen, but msync\n+      \/\/ has some undefined behavior, hence ignore this shift.\n+      DEBUG_ONLY(fatal(\"Received '%s' while probing the address space for the highest valid shift\", err.to_string());)\n+      log_warning_p(gc)(\"Received '%s' while probing the address space for the highest valid shift\", err.to_string());\n+      continue;\n+    }\n+\n+    \/\/ Since msync failed with ENOMEM, the page might not be mapped.\n+    \/\/ Try to map it, to see if the address is valid.\n+    void* const result_addr = mmap((void*) base_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n+    if (result_addr != MAP_FAILED) {\n+      munmap(result_addr, page_size);\n+    }\n+\n+    if ((uintptr_t) result_addr == base_addr) {\n+      \/\/ Address is valid\n+      max_heap_base_shift = i;\n+      break;\n+    }\n+  }\n+\n+  if (max_heap_base_shift == 0) {\n+    \/\/ Probing failed, allocate a very high page and take that shift as the maximum\n+    const uintptr_t high_addr = ((uintptr_t) 1U) << MAXIMUM_MAX_HEAP_BASE_SHIFT;\n+    void* const result_addr = mmap((void*) high_addr, page_size, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0);\n+\n+    if (result_addr != MAP_FAILED) {\n+      max_heap_base_shift = (size_t)log2i((uintptr_t)result_addr);\n+      munmap(result_addr, page_size);\n+    }\n+  }\n+\n+  log_debug_p(gc, init)(\"Probing address space for the highest valid shift: %zu\", max_heap_base_shift);\n+\n+  return MAX2(max_heap_base_shift, MINIMUM_MAX_HEAP_BASE_SHIFT);\n+}\n+\n+size_t ZPlatformHeapBaseMaxShift() {\n+  return probe_heap_base_max_shift();\n+}\n","filename":"src\/hotspot\/os\/linux\/gc\/z\/zAddress_linux.cpp","additions":91,"deletions":0,"binary":false,"changes":91,"status":"added"},{"patch":"@@ -0,0 +1,31 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef OS_LINUX_GC_Z_ZADDRESS_LINUX_HPP\n+#define OS_LINUX_GC_Z_ZADDRESS_LINUX_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+size_t ZPlatformHeapBaseMaxShift();\n+\n+#endif \/\/ OS_LINUX_GC_Z_ZADDRESS_LINUX_HPP\n","filename":"src\/hotspot\/os\/linux\/gc\/z\/zAddress_linux.hpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"added"},{"patch":"@@ -33,1 +33,1 @@\n-void ZVirtualMemoryReserver::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n+void ZVirtualMemoryReservation::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n@@ -37,1 +37,1 @@\n-bool ZVirtualMemoryReserver::pd_reserve(zaddress_unsafe addr, size_t size) {\n+bool ZVirtualMemoryReserver::pd_reserve(uintptr_t addr, size_t size) {\n@@ -40,1 +40,1 @@\n-  void* const res = mmap((void*)untype(addr), size, PROT_NONE, flags, -1, 0);\n+  void* const res = mmap((void*)addr, size, PROT_NONE, flags, -1, 0);\n@@ -46,1 +46,1 @@\n-  if (res != (void*)untype(addr)) {\n+  if (res != (void*)addr) {\n@@ -56,2 +56,6 @@\n-void ZVirtualMemoryReserver::pd_unreserve(zaddress_unsafe addr, size_t size) {\n-  const int res = munmap((void*)untype(addr), size);\n+void ZVirtualMemoryReserver::pd_split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  \/\/ Does nothing\n+}\n+\n+void ZVirtualMemoryReserver::pd_unreserve(uintptr_t addr, size_t size) {\n+  const int res = munmap((void*)addr, size);\n","filename":"src\/hotspot\/os\/posix\/gc\/z\/zVirtualMemoryManager_posix.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -0,0 +1,33 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+size_t ZPlatformHeapBaseMaxShift() {\n+  \/\/ A 64-bit process on 64-bit Windows has a virtual address space within the\n+  \/\/ 128-terabyte range 0x000'00000000 through 0x7FFF'FFFFFFFF. So the heap base\n+  \/\/ can occupy the 47th bit, resulting in a shift of 46.\n+  return clamp(size_t(46), ZAddressHeapBaseMinShift, ZAddressHeapBaseMaxShift);\n+}\n+\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zAddress_windows.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"added"},{"patch":"@@ -0,0 +1,31 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef OS_WINDOWS_GC_Z_ZADDRESS_WINDOWS_HPP\n+#define OS_WINDOWS_GC_Z_ZADDRESS_WINDOWS_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+size_t ZPlatformHeapBaseMaxShift();\n+\n+#endif \/\/ OS_WINDOWS_GC_Z_ZADDRESS_WINDOWS_HPP\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zAddress_windows.hpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"added"},{"patch":"@@ -62,1 +62,1 @@\n-zaddress_unsafe ZMapper::reserve(zaddress_unsafe addr, size_t size) {\n+uintptr_t ZMapper::reserve(uintptr_t addr, size_t size) {\n@@ -65,1 +65,1 @@\n-    (void*)untype(addr),                   \/\/ BaseAddress\n+    (void*)addr,                           \/\/ BaseAddress\n@@ -74,1 +74,1 @@\n-  return to_zaddress_unsafe((uintptr_t)res);\n+  return (uintptr_t)res;\n@@ -77,1 +77,1 @@\n-void ZMapper::unreserve(zaddress_unsafe addr, size_t size) {\n+void ZMapper::unreserve(uintptr_t addr, size_t size) {\n@@ -80,1 +80,1 @@\n-    (void*)untype(addr), \/\/ lpAddress\n+    (void*)addr,         \/\/ lpAddress\n@@ -86,1 +86,1 @@\n-    fatal_error(\"Failed to unreserve memory\", untype(addr), size);\n+    fatal_error(\"Failed to unreserve memory\", addr, size);\n@@ -226,1 +226,1 @@\n-zaddress_unsafe ZMapper::reserve_for_shared_awe(HANDLE awe_section, zaddress_unsafe addr, size_t size) {\n+uintptr_t ZMapper::reserve_for_shared_awe(HANDLE awe_section, uintptr_t addr, size_t size) {\n@@ -233,1 +233,1 @@\n-    (void*)untype(addr),        \/\/ BaseAddress\n+    (void*)addr,                \/\/ BaseAddress\n@@ -242,1 +242,1 @@\n-  return to_zaddress_unsafe((uintptr_t)res);\n+  return (uintptr_t)res;\n@@ -245,1 +245,1 @@\n-void ZMapper::unreserve_for_shared_awe(zaddress_unsafe addr, size_t size) {\n+void ZMapper::unreserve_for_shared_awe(uintptr_t addr, size_t size) {\n@@ -247,3 +247,3 @@\n-    (void*)untype(addr), \/\/ lpAddress\n-    0,                   \/\/ dwSize\n-    MEM_RELEASE          \/\/ dwFreeType\n+    (void*)addr, \/\/ lpAddress\n+    0,           \/\/ dwSize\n+    MEM_RELEASE  \/\/ dwFreeType\n@@ -254,1 +254,1 @@\n-          untype(addr), size \/ M, GetLastError());\n+          addr, size \/ M, GetLastError());\n@@ -259,0 +259,4 @@\n+  split_placeholder_untyped(untype(addr), size);\n+}\n+\n+void ZMapper::split_placeholder_untyped(uintptr_t addr, size_t size) {\n@@ -260,1 +264,1 @@\n-    (void*)untype(addr),                   \/\/ lpAddress\n+    (void*)addr,                           \/\/ lpAddress\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zMapper_windows.cpp","additions":19,"deletions":15,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-  static zaddress_unsafe reserve(zaddress_unsafe addr, size_t size);\n+  static uintptr_t reserve(uintptr_t addr, size_t size);\n@@ -55,1 +55,1 @@\n-  static void unreserve(zaddress_unsafe addr, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n@@ -67,1 +67,1 @@\n-  static zaddress_unsafe reserve_for_shared_awe(HANDLE awe_section, zaddress_unsafe addr, size_t size);\n+  static uintptr_t reserve_for_shared_awe(HANDLE awe_section, uintptr_t addr, size_t size);\n@@ -70,1 +70,1 @@\n-  static void unreserve_for_shared_awe(zaddress_unsafe addr, size_t size);\n+  static void unreserve_for_shared_awe(uintptr_t addr, size_t size);\n@@ -79,0 +79,1 @@\n+  static void split_placeholder_untyped(uintptr_t addr, size_t size);\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zMapper_windows.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -38,2 +38,3 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) = 0;\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) = 0;\n+  virtual bool reserve(uintptr_t addr, size_t size) = 0;\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t size) = 0;\n+  virtual void unreserve(uintptr_t addr, size_t size) = 0;\n@@ -172,2 +173,2 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) {\n-    const zaddress_unsafe res = ZMapper::reserve(addr, size);\n+  virtual bool reserve(uintptr_t addr, size_t size) {\n+    const uintptr_t res = ZMapper::reserve(addr, size);\n@@ -175,1 +176,1 @@\n-    assert(res == addr || untype(res) == 0, \"Should not reserve other memory than requested\");\n+    assert(res == addr || res == 0, \"Should not reserve other memory than requested\");\n@@ -179,1 +180,5 @@\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) {\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t \/* size - unused *\/) {\n+    ZMapper::split_placeholder_untyped(addr, split_size);\n+  }\n+\n+  virtual void unreserve(uintptr_t addr, size_t size) {\n@@ -191,2 +196,2 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) {\n-    const zaddress_unsafe res = ZMapper::reserve_for_shared_awe(ZAWESection, addr, size);\n+  virtual bool reserve(uintptr_t addr, size_t size) {\n+    const uintptr_t res = ZMapper::reserve_for_shared_awe(ZAWESection, addr, size);\n@@ -194,1 +199,1 @@\n-    assert(res == addr || untype(res) == 0, \"Should not reserve other memory than requested\");\n+    assert(res == addr || res == 0, \"Should not reserve other memory than requested\");\n@@ -198,1 +203,5 @@\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) {\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+    \/\/ Does nothing\n+  }\n+\n+  virtual void unreserve(uintptr_t addr, size_t size) {\n@@ -220,1 +229,1 @@\n-void ZVirtualMemoryReserver::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n+void ZVirtualMemoryReservation::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n@@ -224,1 +233,1 @@\n-bool ZVirtualMemoryReserver::pd_reserve(zaddress_unsafe addr, size_t size) {\n+bool ZVirtualMemoryReserver::pd_reserve(uintptr_t addr, size_t size) {\n@@ -228,1 +237,5 @@\n-void ZVirtualMemoryReserver::pd_unreserve(zaddress_unsafe addr, size_t size) {\n+void ZVirtualMemoryReserver::pd_split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  return _impl->split_reserved(addr, split_size, size);\n+}\n+\n+void ZVirtualMemoryReserver::pd_unreserve(uintptr_t addr, size_t size) {\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zVirtualMemoryManager_windows.cpp","additions":26,"deletions":13,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -133,1 +133,2 @@\n-  declare_constant(ZAddressOffsetMax)\n+  declare_constant(ZAddressOffsetMax)                                                                \\\n+  declare_constant(ZAddressOffsetUpperLimit)\n","filename":"src\/hotspot\/share\/gc\/z\/vmStructs_z.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/z\/zGlobals.hpp\"\n@@ -28,0 +29,1 @@\n+#include \"gc\/z\/zOnError.hpp\"\n@@ -29,0 +31,1 @@\n+#include \"logging\/log.hpp\"\n@@ -31,0 +34,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -32,0 +36,1 @@\n+#include \"utilities\/powerOfTwo.hpp\"\n@@ -33,0 +38,1 @@\n+uintptr_t  ZAddressHeapBase;\n@@ -34,1 +40,2 @@\n-size_t     ZAddressHeapBase;\n+\n+size_t     ZAddressPlatformMaxAddressSpace;\n@@ -39,0 +46,1 @@\n+size_t     ZAddressOffsetUpperLimit;\n@@ -105,2 +113,14 @@\n-void ZGlobalsPointers::initialize() {\n-  ZAddressOffsetBits = ZPlatformAddressOffsetBits();\n+void ZGlobalsPointers::set_heap_limits(uintptr_t heap_base, uintptr_t heap_upper_limit) {\n+  log_trace(gc, init)(\"Set Heap Base: \" PTR_FORMAT, heap_base);\n+\n+  \/\/ Setup the heap base\n+  ZAddressHeapBase = heap_base;\n+  ZAddressHeapBaseShift = (size_t)log2i_exact(heap_base);\n+\n+  z_on_error_capture_64_5(ZAddressHeapBaseShift, ZAddressHeapBaseMaxShift, ZAddressPlatformHeapBaseMaxShift,\n+                          ZAddressHeapBaseMinShift, ZAddressMaxHeapRequiredHeapBaseShift);\n+\n+  validate_heap_base_shift(ZAddressHeapBaseShift);\n+\n+  \/\/ Setup the offset\n+  ZAddressOffsetBits = ZAddressHeapBaseShift;\n@@ -109,0 +129,23 @@\n+  ZAddressOffsetUpperLimit = heap_upper_limit - heap_base;\n+\n+  {\n+    z_on_error_capture_64_3(ZAddressHeapBase, ZAddressOffsetMax, ZAddressOffsetUpperLimit);\n+\n+    assert(ZAddressOffsetUpperLimit <= ZAddressOffsetMax,\n+        \"Unexpected ZAddressOffsetUpperLimit: \" PTR_FORMAT \" ZAddressOffsetMax: \" PTR_FORMAT,\n+        ZAddressOffsetUpperLimit, ZAddressOffsetMax);\n+  }\n+}\n+\n+size_t ZGlobalsPointers::ZAddressPlatformHeapBaseMaxShift;\n+size_t ZGlobalsPointers::ZAddressMaxHeapRequiredHeapBaseShift;\n+size_t ZGlobalsPointers::ZAddressMaxHeapRecommendedHeapBaseShift;\n+size_t ZGlobalsPointers::ZAddressInitialHeapBaseShift;\n+\n+void ZGlobalsPointers::initialize() {\n+  ZAddressPlatformHeapBaseMaxShift = ZPlatformHeapBaseMaxShift();\n+  ZAddressPlatformMaxAddressSpace = size_t(1) << ZAddressPlatformHeapBaseMaxShift;\n+  const size_t max_supported_heap = MIN2(ZAddressMaxCapacityLimit, ZAddressPlatformMaxAddressSpace);\n+\n+  guarantee(ZAddressPlatformHeapBaseMaxShift <= ZAddressHeapBaseMaxShift, \"Platform max shift must not be more than allowed max shift\");\n+  guarantee(ZAddressPlatformHeapBaseMaxShift >= ZAddressHeapBaseMinShift, \"Platform max shift must not be less than allowed min shift\");\n@@ -111,1 +154,1 @@\n-  if (MaxHeapSize > ZAddressOffsetMax) {\n+  if (MaxHeapSize > max_supported_heap) {\n@@ -114,1 +157,1 @@\n-                ZAddressOffsetMax \/ G));\n+                max_supported_heap \/ G));\n@@ -117,2 +160,7 @@\n-  ZAddressHeapBaseShift = ZPlatformAddressHeapBaseShift();\n-  ZAddressHeapBase = (uintptr_t)1 << ZAddressHeapBaseShift;\n+  \/\/ Set inital heap base\n+  ZAddressMaxHeapRequiredHeapBaseShift = (size_t)log2i_ceil(MaxHeapSize);\n+  const size_t desired_heap_base_shift = ZAddressMaxHeapRequiredHeapBaseShift + (size_t)log2i_exact(ZVirtualToPhysicalRatio);\n+  ZAddressMaxHeapRecommendedHeapBaseShift = MIN2(desired_heap_base_shift, ZAddressPlatformHeapBaseMaxShift);\n+  ZAddressInitialHeapBaseShift = ZForceHighestHeapBase\n+      ? ZAddressPlatformHeapBaseMaxShift\n+      : MAX2(MIN2(ZAddressHeapBaseRecommendInitalMinShift, ZAddressPlatformHeapBaseMaxShift), ZAddressMaxHeapRecommendedHeapBaseShift);\n@@ -132,0 +180,25 @@\n+void ZGlobalsPointers::validate_heap_base_shift(size_t heap_base_shift) {\n+  assert(heap_base_shift <= ZAddressHeapBaseMaxShift, \"Heap base shift to large\");\n+  assert(heap_base_shift <= ZAddressPlatformHeapBaseMaxShift, \"Heap base shift to large\");\n+  assert(heap_base_shift >= ZAddressHeapBaseMinShift, \"Heap base shift to small\");\n+  assert(heap_base_shift >= ZAddressMaxHeapRequiredHeapBaseShift, \"Heap base shift to small\");\n+}\n+\n+size_t ZGlobalsPointers::initial_heap_base_shift() {\n+  return ZAddressInitialHeapBaseShift;\n+}\n+\n+size_t ZGlobalsPointers::next_heap_base_shift(size_t heap_base_shift) {\n+  validate_heap_base_shift(heap_base_shift);\n+\n+  const size_t min_heap_base_shift = MAX2(ZAddressMaxHeapRequiredHeapBaseShift, ZAddressHeapBaseMinShift);\n+\n+  const size_t next_heap_base_shift = heap_base_shift == min_heap_base_shift\n+      ? ZAddressPlatformHeapBaseMaxShift\n+      : heap_base_shift - 1;\n+\n+  validate_heap_base_shift(next_heap_base_shift);\n+\n+  return next_heap_base_shift;\n+}\n+\n@@ -153,7 +226,0 @@\n-\n-size_t ZGlobalsPointers::min_address_offset_request() {\n-  \/\/ See ZVirtualMemoryReserver for logic around setting up the heap for NUMA\n-  const size_t desired_for_heap = MaxHeapSize * ZVirtualToPhysicalRatio;\n-  const size_t desired_for_numa_multiplier = ZNUMA::count() > 1 ? 2 : 1;\n-  return round_up_power_of_2(desired_for_heap * desired_for_numa_multiplier);\n-}\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.cpp","additions":80,"deletions":14,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include OS_HEADER(gc\/z\/zAddress)\n@@ -33,4 +34,16 @@\n-extern uintptr_t  ZAddressHeapBase;\n-extern uintptr_t  ZAddressHeapBaseShift;\n-\n-\/\/ Describes the maximal offset inside the heap.\n+extern uintptr_t ZAddressHeapBase;\n+extern size_t    ZAddressHeapBaseShift;\n+\n+\/\/ The min and max shift allowed for the heap base. The max is\n+\/\/ the limit that our ZForwardingEntry encoding can handle.\n+\/\/ The recommended initial min shift is the largest shift which\n+\/\/ allows the smallest ZMarkPartialArrayMinSize.\n+const size_t     ZAddressHeapBaseMaxShift = 44; \/\/ 16TB\n+const size_t     ZAddressHeapBaseRecommendInitalMinShift = 42; \/\/ 4TB\n+const size_t     ZAddressHeapBaseMinShift = 34; \/\/ 16GB\n+\n+\/\/ Max size limits for MaxHeapSize and the platforms available address space.\n+const size_t     ZAddressMaxCapacityLimit = size_t(1) << 44; \/\/ 16TB\n+extern size_t    ZAddressPlatformMaxAddressSpace;\n+\n+\/\/ Describes the offset inside the heap.\n@@ -40,0 +53,2 @@\n+\n+\/\/ Describes the computational max offset inside the heap.\n@@ -42,0 +57,3 @@\n+\/\/ Describes the reserved upper limit for offset inside the heap.\n+extern size_t    ZAddressOffsetUpperLimit;\n+\n@@ -313,0 +331,5 @@\n+  static size_t ZAddressPlatformHeapBaseMaxShift;\n+  static size_t ZAddressMaxHeapRequiredHeapBaseShift;\n+  static size_t ZAddressMaxHeapRecommendedHeapBaseShift;\n+  static size_t ZAddressInitialHeapBaseShift;\n+\n@@ -319,0 +342,6 @@\n+  static void set_heap_limits(uintptr_t heap_base, uintptr_t heap_upper_limit);\n+\n+  static size_t initial_heap_base_shift();\n+  static size_t next_heap_base_shift(size_t heap_base_shift);\n+  static void validate_heap_base_shift(size_t heap_base_shift);\n+\n@@ -323,2 +352,0 @@\n-\n-  static size_t min_address_offset_request();\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.hpp","additions":33,"deletions":6,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -151,1 +151,1 @@\n-  assert(value < ZAddressOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZAddressOffsetUpperLimit, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -157,1 +157,1 @@\n-  assert(value <= ZAddressOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -162,1 +162,1 @@\n-  assert(value < ZAddressOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZAddressOffsetUpperLimit, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -173,1 +173,1 @@\n-  if (value <= ZAddressOffsetMax) {\n+  if (value <= ZAddressOffsetUpperLimit) {\n@@ -182,2 +182,2 @@\n-  assert(value <= ZAddressOffsetMax, \"Overflow start: \" PTR_FORMAT \" size: \" PTR_FORMAT \" value: \" PTR_FORMAT,\n-                                     untype(start), size, value);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Overflow start: \" PTR_FORMAT \" size: \" PTR_FORMAT \" value: \" PTR_FORMAT,\n+                                            untype(start), size, value);\n@@ -188,1 +188,1 @@\n-  assert(value <= ZAddressOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -202,1 +202,1 @@\n-  assert(value < ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -208,1 +208,1 @@\n-  assert(value <= ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -213,1 +213,1 @@\n-  assert(value < ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -230,1 +230,1 @@\n-  assert(value <= ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -456,1 +456,1 @@\n-  if (value >= (ZAddressHeapBase + ZAddressOffsetMax)) {\n+  if (value >= (ZAddressHeapBase + ZAddressOffsetUpperLimit)) {\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.inline.hpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"gc\/z\/zAddress.hpp\"\n@@ -28,1 +29,0 @@\n-#include \"runtime\/globals.hpp\"\n@@ -31,1 +31,0 @@\n-#include \"utilities\/ostream.hpp\"\n@@ -36,1 +35,1 @@\n-  return align_up(limit, ZGranuleSize);\n+  return MIN2(align_up(limit, ZGranuleSize), ZAddressPlatformMaxAddressSpace);\n","filename":"src\/hotspot\/share\/gc\/z\/zAddressSpaceLimit.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -171,7 +171,8 @@\n-    printf \"     Young Phase:       %u\\n\", ZHeap::_heap->_young->_phase\n-    printf \"     Old Phase:         %u\\n\", ZHeap::_heap->_old->_phase\n-    printf \"     Young SeqNum:      %u\\n\", ZHeap::_heap->_young->_seqnum\n-    printf \"     Old SeqNum:        %u\\n\", ZHeap::_heap->_old->_seqnum\n-    printf \"     Offset Max:        %-15llu (0x%llx)\\n\", ZAddressOffsetMax, ZAddressOffsetMax\n-    printf \"     Page Size Small:   %-15llu (0x%llx)\\n\", ZPageSizeSmall, ZPageSizeSmall\n-    printf \"     Page Size Medium:  %-15llu (0x%llx)\\n\", ZPageSizeMedium, ZPageSizeMedium\n+    printf \"     Young Phase:        %u\\n\", ZHeap::_heap->_young->_phase\n+    printf \"     Old Phase:          %u\\n\", ZHeap::_heap->_old->_phase\n+    printf \"     Young SeqNum:       %u\\n\", ZHeap::_heap->_young->_seqnum\n+    printf \"     Old SeqNum:         %u\\n\", ZHeap::_heap->_old->_seqnum\n+    printf \"     Offset Max:         %-15llu (0x%llx)\\n\", ZAddressOffsetMax, ZAddressOffsetMax\n+    printf \"     Offset Upper Limit: %-15llu (0x%llx)\\n\", ZAddressOffsetUpperLimit, ZAddressOffsetUpperLimit\n+    printf \"     Page Size Small:    %-15llu (0x%llx)\\n\", ZPageSizeSmall, ZPageSizeSmall\n+    printf \"     Page Size Medium:   %-15llu (0x%llx)\\n\", ZPageSizeMedium, ZPageSizeMedium\n@@ -179,5 +180,5 @@\n-    printf \"     Good:              0x%016llx\\n\", ZPointerStoreGoodMask\n-    printf \"     Bad:               0x%016llx\\n\", ZPointerStoreBadMask\n-    printf \"     MarkedYoung:       0x%016llx\\n\", ZPointerMarkedYoung\n-    printf \"     MarkedOld:         0x%016llx\\n\", ZPointerMarkedOld\n-    printf \"     Remapped:          0x%016llx\\n\", ZPointerRemapped\n+    printf \"     Good:               0x%016llx\\n\", ZPointerStoreGoodMask\n+    printf \"     Bad:                0x%016llx\\n\", ZPointerStoreBadMask\n+    printf \"     MarkedYoung:        0x%016llx\\n\", ZPointerMarkedYoung\n+    printf \"     MarkedOld:          0x%016llx\\n\", ZPointerMarkedOld\n+    printf \"     Remapped:           0x%016llx\\n\", ZPointerRemapped\n","filename":"src\/hotspot\/share\/gc\/z\/zDebug.gdb","additions":13,"deletions":12,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-  : _map(ZAddressOffsetMax) {}\n+  : _map(ZAddressOffsetUpperLimit) {}\n","filename":"src\/hotspot\/share\/gc\/z\/zForwardingTable.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -383,0 +383,1 @@\n+  st->print_cr(\" Offset Upper Limit: \" EXACTFMT \" (\" PTR_FORMAT \")\", EXACTFMTARGS(ZAddressOffsetUpperLimit), ZAddressOffsetUpperLimit);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -259,1 +259,1 @@\n-    _bitmaps(ZAddressOffsetMax),\n+    _bitmaps(ZAddressOffsetUpperLimit),\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,2 +38,2 @@\n-void ZNMT::reserve(zaddress_unsafe start, size_t size) {\n-  MemTracker::record_virtual_memory_reserve((address)untype(start), size, CALLER_PC, mtJavaHeap);\n+void ZNMT::reserve(uintptr_t addr, size_t size) {\n+  MemTracker::record_virtual_memory_reserve((address)addr, size, CALLER_PC, mtJavaHeap);\n@@ -42,2 +42,2 @@\n-void ZNMT::unreserve(zaddress_unsafe start, size_t size) {\n-  precond(is_aligned(untype(start), ZGranuleSize));\n+void ZNMT::unreserve(uintptr_t addr, size_t size) {\n+  precond(is_aligned(addr, ZGranuleSize));\n@@ -57,1 +57,1 @@\n-      MemTracker::record_virtual_memory_release((address)untype(start + i), ZGranuleSize);\n+      MemTracker::record_virtual_memory_release((address)(addr + i), ZGranuleSize);\n","filename":"src\/hotspot\/share\/gc\/z\/zNMT.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -41,2 +41,2 @@\n-  static void reserve(zaddress_unsafe start, size_t size);\n-  static void unreserve(zaddress_unsafe start, size_t size);\n+  static void reserve(uintptr_t addr, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n","filename":"src\/hotspot\/share\/gc\/z\/zNMT.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,71 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef SHARE_GC_Z_ZONERROR_HPP\n+#define SHARE_GC_Z_ZONERROR_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/vmError.hpp\"\n+\n+#define z_expand_64_1(first)      uint64_t(first)\n+#define z_expand_64_2(first, ...) z_expand_64_1(first), z_expand_64_1(__VA_ARGS__)\n+#define z_expand_64_3(first, ...) z_expand_64_1(first), z_expand_64_2(__VA_ARGS__)\n+#define z_expand_64_4(first, ...) z_expand_64_1(first), z_expand_64_3(__VA_ARGS__)\n+#define z_expand_64_5(first, ...) z_expand_64_1(first), z_expand_64_4(__VA_ARGS__)\n+#define z_expand_64_6(first, ...) z_expand_64_1(first), z_expand_64_5(__VA_ARGS__)\n+\n+#define z_expand_format_64_1(first)      #first \": \" UINT64_FORMAT_X \" \"\n+#define z_expand_format_64_2(first, ...) z_expand_format_64_1(first) z_expand_format_64_1(__VA_ARGS__)\n+#define z_expand_format_64_3(first, ...) z_expand_format_64_1(first) z_expand_format_64_2(__VA_ARGS__)\n+#define z_expand_format_64_4(first, ...) z_expand_format_64_1(first) z_expand_format_64_3(__VA_ARGS__)\n+#define z_expand_format_64_5(first, ...) z_expand_format_64_1(first) z_expand_format_64_4(__VA_ARGS__)\n+#define z_expand_format_64_6(first, ...) z_expand_format_64_1(first) z_expand_format_64_5(__VA_ARGS__)\n+\n+#define z_on_error_capture_64(N, ...)                  \\\n+  OnVMError on_error([&](outputStream* st) {           \\\n+    st->print(\"Captured: \"                             \\\n+              z_expand_format_64_##N(__VA_ARGS__),     \\\n+              z_expand_64_##N(__VA_ARGS__));           \\\n+  })\n+\n+#define z_on_error_capture_64_1(...) z_on_error_capture_64(1, __VA_ARGS__)\n+#define z_on_error_capture_64_2(...) z_on_error_capture_64(2, __VA_ARGS__)\n+#define z_on_error_capture_64_3(...) z_on_error_capture_64(3, __VA_ARGS__)\n+#define z_on_error_capture_64_4(...) z_on_error_capture_64(4, __VA_ARGS__)\n+#define z_on_error_capture_64_5(...) z_on_error_capture_64(5, __VA_ARGS__)\n+#define z_on_error_capture_64_6(...) z_on_error_capture_64(6, __VA_ARGS__)\n+\n+#ifdef ASSERT\n+#define z_assert_capture_64(N, ...) z_on_error_capture_64(N, __VA_ARGS__)\n+#else\n+#define z_assert_capture_64(N, ...)\n+#endif\n+\n+#define z_assert_capture_64_1(...) z_assert_capture_64(1, __VA_ARGS__)\n+#define z_assert_capture_64_2(...) z_assert_capture_64(2, __VA_ARGS__)\n+#define z_assert_capture_64_3(...) z_assert_capture_64(3, __VA_ARGS__)\n+#define z_assert_capture_64_4(...) z_assert_capture_64(4, __VA_ARGS__)\n+#define z_assert_capture_64_5(...) z_assert_capture_64(5, __VA_ARGS__)\n+#define z_assert_capture_64_6(...) z_assert_capture_64(6, __VA_ARGS__)\n+\n+#endif \/\/ SHARE_GC_Z_ZONERROR_HPP\n","filename":"src\/hotspot\/share\/gc\/z\/zOnError.hpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"added"},{"patch":"@@ -32,3 +32,3 @@\n-static size_t get_max_offset_for_map() {\n-  \/\/ The page table has (ZAddressOffsetMax >> ZGranuleSizeShift) slots\n-  const size_t max_count = ZAddressOffsetMax >> ZGranuleSizeShift;\n+static size_t get_offset_upper_limit_for_map() {\n+  \/\/ The page table has (ZAddressOffsetUpperLimit >> ZGranuleSizeShift) slots\n+  const size_t max_count = ZAddressOffsetUpperLimit >> ZGranuleSizeShift;\n@@ -41,1 +41,1 @@\n-  : _map(get_max_offset_for_map()) {}\n+  : _map(get_offset_upper_limit_for_map()) {}\n","filename":"src\/hotspot\/share\/gc\/z\/zPageTable.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-    _physical_mappings(ZAddressOffsetMax) {\n+    _physical_mappings(ZAddressOffsetUpperLimit) {\n","filename":"src\/hotspot\/share\/gc\/z\/zPhysicalMemoryManager.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -112,0 +112,3 @@\n+\n+  template <typename Function>\n+  void visit_all(Function function) const;\n","filename":"src\/hotspot\/share\/gc\/z\/zRangeRegistry.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -470,0 +470,11 @@\n+template <typename Range>\n+template <typename Function>\n+void ZRangeRegistry<Range>::visit_all(Function function) const {\n+  ZLocker<ZLock> locker(&_lock);\n+\n+  ZListIterator<Node> iter(&_list);\n+  for (Node* node; iter.next(&node);) {\n+    function(node->range());\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zRangeRegistry.inline.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -351,2 +351,2 @@\n-  : _allocated_bitmap_0{ZAddressOffsetMax >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n-    _allocated_bitmap_1{ZAddressOffsetMax >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n+  : _allocated_bitmap_0{ZAddressOffsetUpperLimit >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n+    _allocated_bitmap_1{ZAddressOffsetUpperLimit >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n","filename":"src\/hotspot\/share\/gc\/z\/zRemembered.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -40,0 +40,5 @@\n+struct ZVirtualMemoryUntyped {\n+  uintptr_t _start;\n+  size_t    _size;\n+};\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemory.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/z\/zOnError.hpp\"\n@@ -38,0 +39,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -39,3 +41,2 @@\n-ZVirtualMemoryReserver::ZVirtualMemoryReserver(size_t size)\n-  : _registry(),\n-    _reserved(reserve(size)) {}\n+bool ZVirtualMemoryReserver::reserve(uintptr_t addr, size_t size) {\n+  log_debug(gc, init)(\"ZGC reserve:   [\" PTR_FORMAT \" - \" PTR_FORMAT \")\", addr, addr + size);\n@@ -43,2 +44,4 @@\n-void ZVirtualMemoryReserver::initialize_partition_registry(ZVirtualMemoryRegistry* partition_registry, size_t size) {\n-  assert(partition_registry->is_empty(), \"Should be empty when initializing\");\n+  \/\/ Reserve address space\n+  if (!pd_reserve(addr, size)) {\n+    return false;\n+  }\n@@ -46,2 +49,2 @@\n-  \/\/ Registers the Windows callbacks\n-  pd_register_callbacks(partition_registry);\n+  \/\/ Register address views with native memory tracker\n+  ZNMT::reserve(addr, size);\n@@ -49,1 +52,2 @@\n-  _registry.transfer_from_low(partition_registry, size);\n+  return true;\n+}\n@@ -51,2 +55,2 @@\n-  \/\/ Set the limits according to the virtual memory given to this partition\n-  partition_registry->anchor_limits();\n+void ZVirtualMemoryReserver::split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  pd_split_reserved(addr, split_size, size);\n@@ -55,2 +59,2 @@\n-void ZVirtualMemoryReserver::unreserve(const ZVirtualMemory& vmem) {\n-  const zaddress_unsafe addr = ZOffset::address_unsafe(vmem.start());\n+void ZVirtualMemoryReserver::unreserve(uintptr_t addr, size_t size) {\n+  log_debug(gc, init)(\"ZGC unreserve: [\" PTR_FORMAT \" - \" PTR_FORMAT \")\", addr, addr + size);\n@@ -59,1 +63,1 @@\n-  ZNMT::unreserve(addr, vmem.size());\n+  ZNMT::unreserve(addr, size);\n@@ -62,1 +66,1 @@\n-  pd_unreserve(addr, vmem.size());\n+  pd_unreserve(addr, size);\n@@ -65,4 +69,6 @@\n-void ZVirtualMemoryReserver::unreserve_all() {\n-  for (ZVirtualMemory vmem; _registry.unregister_first(&vmem);) {\n-    unreserve(vmem);\n-  }\n+ZVirtualMemoryWithHeapBaseReserver::ZVirtualMemoryWithHeapBaseReserver(size_t heap_base)\n+  : _heap_base(heap_base),\n+    _reserved_ranges() {}\n+\n+ZVirtualMemoryWithHeapBaseReserver::~ZVirtualMemoryWithHeapBaseReserver() {\n+  unreserve_all();\n@@ -71,2 +77,2 @@\n-bool ZVirtualMemoryReserver::is_empty() const {\n-  return _registry.is_empty();\n+uintptr_t ZVirtualMemoryWithHeapBaseReserver::heap_base() const {\n+  return _heap_base;\n@@ -75,2 +81,25 @@\n-bool ZVirtualMemoryReserver::is_contiguous() const {\n-  return _registry.is_contiguous();\n+size_t ZVirtualMemoryWithHeapBaseReserver::offset_max() const {\n+  \/\/ We currently have a restriction that the offsets don't overflow the heap base bit,\n+  \/\/ this limits the offset bits to be equal to the heap base.\n+  return (size_t)_heap_base;\n+}\n+\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve(size_t size) {\n+  if (offset_max() < size) {\n+    \/\/ Only attempt to reserve if the current heap base can accommodate the desired size\n+    return 0;\n+  }\n+\n+#ifdef ASSERT\n+  if (ZForceDiscontiguousHeapReservations > 0) {\n+    return force_reserve_discontiguous(size);\n+  }\n+#endif\n+\n+  \/\/ Prefer a contiguous address space\n+  if (reserve_contiguous(size)) {\n+    return size;\n+  }\n+\n+  \/\/ Fall back to a discontiguous address space\n+  return reserve_discontiguous(size);\n@@ -79,2 +108,4 @@\n-size_t ZVirtualMemoryReserver::reserved() const {\n-  return _reserved;\n+\n+void ZVirtualMemoryWithHeapBaseReserver::transfer_reserved_ranges_to(ZArray<ZVirtualMemoryUntyped>* to) {\n+  to->appendAll(&_reserved_ranges);\n+  _reserved_ranges.clear();\n@@ -83,2 +114,11 @@\n-zoffset_end ZVirtualMemoryReserver::highest_available_address_end() const {\n-  return _registry.peak_high_address_end();\n+size_t ZVirtualMemoryWithHeapBaseReserver::unreserve_all() {\n+  size_t unreserved = 0;\n+\n+  for (ZVirtualMemoryUntyped range : _reserved_ranges) {\n+    ZVirtualMemoryReserver::unreserve(range._start, range._size);\n+    unreserved += range._size;\n+  }\n+\n+  _reserved_ranges.clear();\n+\n+  return unreserved;\n@@ -88,1 +128,1 @@\n-size_t ZVirtualMemoryReserver::force_reserve_discontiguous(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::force_reserve_discontiguous(size_t size) {\n@@ -95,1 +135,1 @@\n-  uintptr_t end = ZAddressOffsetMax;\n+  size_t end = offset_max();\n@@ -99,1 +139,2 @@\n-    const uintptr_t reserve_start = end - reserve_size;\n+    const size_t reserve_start = end - reserve_size;\n+    const uintptr_t addr = _heap_base + reserve_start;\n@@ -101,1 +142,1 @@\n-    if (reserve_contiguous(to_zoffset(reserve_start), reserve_size)) {\n+    if (reserve_contiguous(addr, reserve_size)) {\n@@ -111,3 +152,4 @@\n-  while (reserved < size && start < ZAddressOffsetMax) {\n-    const size_t remaining = MIN2(size - reserved, ZAddressOffsetMax - start);\n-    reserved += reserve_discontiguous(to_zoffset(start), remaining, min_range);\n+  while (reserved < size && start < offset_max()) {\n+    const size_t remaining = MIN2(size - reserved, offset_max() - start);\n+    const uintptr_t addr = _heap_base + start;\n+    reserved += reserve_discontiguous(addr, remaining, min_range);\n@@ -121,1 +163,1 @@\n-size_t ZVirtualMemoryReserver::reserve_discontiguous(zoffset start, size_t size, size_t min_range) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve_discontiguous(uintptr_t addr, size_t size, size_t min_range) {\n@@ -129,1 +171,1 @@\n-  if (reserve_contiguous(start, size)) {\n+  if (reserve_contiguous(addr, size)) {\n@@ -142,2 +184,2 @@\n-  const size_t first_size = reserve_discontiguous(start, first_part, min_range);\n-  const size_t second_size = reserve_discontiguous(start + first_part, second_part, min_range);\n+  const size_t first_size = reserve_discontiguous(addr, first_part, min_range);\n+  const size_t second_size = reserve_discontiguous(addr + first_part, second_part, min_range);\n@@ -147,1 +189,1 @@\n-size_t ZVirtualMemoryReserver::calculate_min_range(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::calculate_min_range(size_t size) {\n@@ -154,1 +196,1 @@\n-size_t ZVirtualMemoryReserver::reserve_discontiguous(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve_discontiguous(size_t size) {\n@@ -159,4 +201,5 @@\n-  \/\/ Reserve size somewhere between [0, ZAddressOffsetMax)\n-  while (reserved < size && start < ZAddressOffsetMax) {\n-    const size_t remaining = MIN2(size - reserved, ZAddressOffsetMax - start);\n-    reserved += reserve_discontiguous(to_zoffset(start), remaining, min_range);\n+  \/\/ Reserve size somewhere between [0, offset_max())\n+  while (reserved < size && start < offset_max()) {\n+    const size_t remaining = MIN2(size - reserved, offset_max() - start);\n+    const uintptr_t addr = _heap_base + start;\n+    reserved += reserve_discontiguous(addr, remaining, min_range);\n@@ -169,1 +212,1 @@\n-bool ZVirtualMemoryReserver::reserve_contiguous(zoffset start, size_t size) {\n+bool ZVirtualMemoryWithHeapBaseReserver::reserve_contiguous(uintptr_t addr, size_t size) {\n@@ -171,0 +214,3 @@\n+  assert(addr >= _heap_base && addr < _heap_base + offset_max(),\n+         PTR_FORMAT \" not within [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n+         addr, _heap_base, _heap_base + offset_max());\n@@ -172,5 +218,1 @@\n-  \/\/ Reserve address views\n-  const zaddress_unsafe addr = ZOffset::address_unsafe(start);\n-\n-  \/\/ Reserve address space\n-  if (!pd_reserve(addr, size)) {\n+  if (!ZVirtualMemoryReserver::reserve(addr, size)) {\n@@ -180,3 +222,0 @@\n-  \/\/ Register address views with native memory tracker\n-  ZNMT::reserve(addr, size);\n-\n@@ -184,1 +223,1 @@\n-  _registry.register_range({start, size});\n+  _reserved_ranges.append({addr, size});\n@@ -189,3 +228,3 @@\n-bool ZVirtualMemoryReserver::reserve_contiguous(size_t size) {\n-  \/\/ Allow at most 8192 attempts spread evenly across [0, ZAddressOffsetMax)\n-  const size_t unused = ZAddressOffsetMax - size;\n+bool ZVirtualMemoryWithHeapBaseReserver::reserve_contiguous(size_t size) {\n+  \/\/ Allow at most 8192 attempts spread evenly across [0, offset_max)\n+  const size_t unused = offset_max() - size;\n@@ -194,2 +233,3 @@\n-  for (uintptr_t start = 0; start + size <= ZAddressOffsetMax; start += increment) {\n-    if (reserve_contiguous(to_zoffset(start), size)) {\n+  for (uintptr_t start = 0; start + size <= offset_max(); start += increment) {\n+    const uintptr_t addr = _heap_base + start;\n+    if (reserve_contiguous(addr, size)) {\n@@ -205,1 +245,251 @@\n-size_t ZVirtualMemoryReserver::reserve(size_t size) {\n+class ZHeapBaseIterator {\n+private:\n+  const size_t _initial;\n+  size_t       _current;\n+\n+public:\n+  ZHeapBaseIterator(size_t initial_heap_base_shift = ZGlobalsPointers::initial_heap_base_shift())\n+    : _initial(initial_heap_base_shift),\n+      _current(initial_heap_base_shift) {}\n+\n+  bool next(uintptr_t* out_heap_base) {\n+    size_t next = ZGlobalsPointers::next_heap_base_shift(_current);\n+    if (next == _initial) {\n+      \/\/ Iterator has completed\n+      return false;\n+    }\n+\n+    _current = next;\n+\n+    const uintptr_t heap_base = uintptr_t(1) << _current;\n+\n+    log_trace(gc, init)(\"Attempting Heap Base: \" PTR_FORMAT, heap_base);\n+\n+    *out_heap_base = heap_base;\n+\n+    return true;\n+  }\n+};\n+\n+ZVirtualMemoryAdaptiveReserver::ZVirtualMemoryAdaptiveReserver()\n+  : _heap_base(),\n+    _reserved_ranges() {}\n+\n+static int compare_ZVirtualMemoryUntyped(ZVirtualMemoryUntyped* vmem0, ZVirtualMemoryUntyped* vmem1) {\n+  if (vmem0->_start == vmem1->_start) {\n+    return 0;\n+  } else if (vmem0->_start < vmem1->_start) {\n+    return -1;\n+  } else {\n+    return 1;\n+  }\n+};\n+\n+void ZVirtualMemoryAdaptiveReserver::accept(ZVirtualMemoryWithHeapBaseReserver* reserver) {\n+  _heap_base = reserver->heap_base();\n+  reserver->transfer_reserved_ranges_to(&_reserved_ranges);\n+  _reserved_ranges.sort(&compare_ZVirtualMemoryUntyped);\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::reserve(size_t required_size, size_t desired_size) {\n+  assert(required_size <= desired_size, \"0x%zx <= 0x%zx\", required_size, desired_size);\n+\n+  size_t heap_base;\n+\n+  \/\/ First attempt to get the desired size\n+  for (ZHeapBaseIterator iter{}; iter.next(&heap_base);) {\n+    ZVirtualMemoryWithHeapBaseReserver reserver(heap_base);\n+\n+    const size_t reserved = reserver.reserve(desired_size);\n+\n+    if (reserved >= desired_size) {\n+      \/\/ Succeeded\n+      accept(&reserver);\n+      return reserved;\n+    }\n+  }\n+\n+  \/\/ Second attempt to get at least the required size\n+  for (ZHeapBaseIterator iter{}; iter.next(&heap_base);) {\n+    ZVirtualMemoryWithHeapBaseReserver reserver(heap_base);\n+\n+    const size_t max_reserve_size = reserver.offset_max();\n+    assert(max_reserve_size >= required_size, \"Should not have attempted this heap base: \"\n+          PTR_FORMAT \" for required size: 0x%zx\", heap_base, required_size);\n+\n+    \/\/ Still attempt to get up to desired_size\n+    const size_t to_reserve = MIN2<size_t>(max_reserve_size, desired_size);\n+\n+    const size_t reserved = reserver.reserve(to_reserve);\n+\n+    if (reserved >= required_size) {\n+      \/\/ Succeeded\n+      accept(&reserver);\n+      return reserved;\n+    }\n+  }\n+\n+  \/\/ Failed to reserve\n+  return 0;\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::unreserve_after(size_t keep_size) {\n+  precond(keep_size > 0);\n+  precond(keep_size <= reserved());\n+\n+  const size_t before = reserved();\n+\n+  struct UnreservePoint {\n+    int    _index;\n+    size_t _offset;\n+  };\n+\n+  auto find_unreserve_point = [&]() -> UnreservePoint {\n+    size_t accumulated = 0;\n+\n+    for (int i = 0; i < _reserved_ranges.length(); i++) {\n+      ZVirtualMemoryUntyped vmem = _reserved_ranges.at(i);\n+\n+      accumulated += vmem._size;\n+\n+      if (accumulated < keep_size) {\n+        \/\/ Keep on accumulating\n+        continue;\n+      }\n+\n+      \/\/ We have found the unreserve point\n+\n+      if (accumulated > keep_size) {\n+        \/\/ The unreserve point splits a vmem\n+        size_t vmem_over_size = (accumulated - keep_size);\n+        size_t vmem_split_size = vmem._size - vmem_over_size;\n+\n+        return {i, vmem_split_size};\n+      }\n+\n+      \/\/ The unreserve point doesn't split a vmem\n+      return {i + 1, 0};\n+    }\n+\n+    \/\/ Nothing to split\n+    return {_reserved_ranges.length(), 0};\n+  };\n+\n+  \/\/ Search for the point where we should unreserve from\n+  const UnreservePoint split = find_unreserve_point();\n+\n+  int index = split._index;\n+  const size_t offset = split._offset;\n+\n+  size_t unreserved = 0;\n+\n+  auto do_unreserve = [&](uintptr_t addr, size_t size) {\n+    ZVirtualMemoryReserver::unreserve(addr, size);\n+    unreserved += size;\n+  };\n+\n+  \/\/ Split a vmem if the unreserve point falls inside a vmem\n+  if (offset > 0) {\n+    const ZVirtualMemoryUntyped& vmem = _reserved_ranges.at(index);\n+\n+    \/\/ Mainly a call to Windows that the memory reservation is split\n+    ZVirtualMemoryReserver::split_reserved(vmem._start, offset, vmem._size);\n+\n+    \/\/ Unreserve the surplus\n+    do_unreserve(vmem._start + offset, vmem._size - offset);\n+\n+    \/\/ Re-register the area that was shrunk\n+    _reserved_ranges.at(index) = ZVirtualMemoryUntyped{vmem._start, offset};\n+\n+    \/\/ Unreserve the rest\n+    index++;\n+  }\n+\n+  \/\/ Unreserve the reset of the vmems\n+  for (int i = index; i < _reserved_ranges.length(); i++) {\n+    const ZVirtualMemoryUntyped& vmem = _reserved_ranges.at(i);\n+\n+    do_unreserve(vmem._start, vmem._size);\n+  }\n+\n+  _reserved_ranges.trunc_to(index);\n+\n+  z_on_error_capture_64_6(keep_size, unreserved, before, index, offset, _reserved_ranges.length());\n+\n+  postcond(keep_size + unreserved == before);\n+  postcond(reserved() == keep_size);\n+\n+  return unreserved;\n+}\n+\n+void ZVirtualMemoryAdaptiveReserver::unreserve_all() {\n+  for (ZVirtualMemoryUntyped vmem : _reserved_ranges) {\n+    ZVirtualMemoryReserver::unreserve(vmem._start, vmem._size);\n+  }\n+\n+  _reserved_ranges.clear();\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::heap_base() const {\n+  return _heap_base;\n+}\n+\n+ZArray<ZVirtualMemoryUntyped>* ZVirtualMemoryAdaptiveReserver::reserved_ranges() {\n+  return &_reserved_ranges;\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::bottom() const {\n+  uintptr_t min_start = SIZE_MAX;\n+\n+  for (auto range : _reserved_ranges) {\n+    const uintptr_t start = range._start;\n+\n+    if (start < min_start) {\n+      min_start = start;\n+    }\n+\n+  }\n+\n+  postcond(min_start != SIZE_MAX);\n+\n+  return min_start;\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::end() const {\n+  uintptr_t max_end = 0;\n+\n+  OnVMError on_error([&](outputStream* st) {\n+    for (auto vmem : _reserved_ranges) {\n+      st->print_cr(\" \" PTR_FORMAT \" \" PTR_FORMAT \" %zuM\", vmem._start, vmem._start + vmem._size, vmem._size \/ M);\n+    }\n+  });\n+\n+  for (auto range : _reserved_ranges) {\n+    const uintptr_t end = range._start + range._size;\n+\n+    assert(end > max_end,\n+           \"Unordered reserved memory end: \" PTR_FORMAT \" max_end: \" PTR_FORMAT,\n+           end, max_end);\n+\n+    if (end > max_end) {\n+      max_end = end;\n+    }\n+\n+  }\n+\n+  return max_end;\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::reserved() const {\n+  size_t reserved = 0;\n+\n+  for (auto range : _reserved_ranges) {\n+    reserved += range._size;\n+  }\n+\n+  return reserved;\n+}\n+\n+ZVirtualMemoryReservation::ZVirtualMemoryReservation(ZArray<ZVirtualMemoryUntyped>* reserved_ranges)\n+  : _registry() {\n+\n@@ -209,1 +499,3 @@\n-  \/\/ Reserve address space\n+  \/\/ Register the reserved regions with the registry\n+  transfer_reserved_ranges(reserved_ranges);\n+}\n@@ -211,3 +503,8 @@\n-#ifdef ASSERT\n-  if (ZForceDiscontiguousHeapReservations > 0) {\n-    return force_reserve_discontiguous(size);\n+void ZVirtualMemoryReservation::transfer_reserved_ranges(ZArray<ZVirtualMemoryUntyped>* reserved_ranges) {\n+  for (ZVirtualMemoryUntyped range : *reserved_ranges) {\n+    const zaddress_unsafe addr = to_zaddress_unsafe(range._start);\n+    const zoffset start = ZAddress::offset(addr);\n+    const size_t size = range._size;\n+\n+    \/\/ Register the memory reservation\n+    _registry.register_range({start, size});\n@@ -215,1 +512,0 @@\n-#endif\n@@ -217,3 +513,28 @@\n-  \/\/ Prefer a contiguous address space\n-  if (reserve_contiguous(size)) {\n-    return size;\n+  \/\/ Clear the accepted input array\n+  reserved_ranges->clear();\n+}\n+\n+void ZVirtualMemoryReservation::initialize_partition_registry(ZVirtualMemoryRegistry* partition_registry, size_t size) {\n+  assert(partition_registry->is_empty(), \"Should be empty when initializing\");\n+\n+  \/\/ Registers the Windows callbacks\n+  pd_register_callbacks(partition_registry);\n+\n+  _registry.transfer_from_low(partition_registry, size);\n+\n+  \/\/ Set the limits according to the virtual memory given to this partition\n+  partition_registry->anchor_limits();\n+}\n+\n+void ZVirtualMemoryReservation::unreserve(const ZVirtualMemory& vmem) {\n+  const zaddress_unsafe addr = ZOffset::address_unsafe(vmem.start());\n+\n+  ZVirtualMemoryReserver::unreserve(untype(addr), vmem.size());\n+}\n+\n+size_t ZVirtualMemoryReservation::unreserve_all() {\n+  size_t unreserved = 0;\n+\n+  for (ZVirtualMemory vmem; _registry.unregister_first(&vmem);) {\n+    unreserve(vmem);\n+    unreserved += vmem.size();\n@@ -222,2 +543,23 @@\n-  \/\/ Fall back to a discontiguous address space\n-  return reserve_discontiguous(size);\n+  return unreserved;\n+}\n+\n+bool ZVirtualMemoryReservation::is_empty() const {\n+  return _registry.is_empty();\n+}\n+\n+bool ZVirtualMemoryReservation::is_contiguous() const {\n+  return _registry.is_contiguous();\n+}\n+\n+size_t ZVirtualMemoryReservation::reserved() const {\n+  size_t reserved = 0;\n+\n+  _registry.visit_all([&](const ZVirtualMemory* vmem) {\n+    reserved += vmem->size();\n+  });\n+\n+  return reserved;\n+}\n+\n+zoffset_end ZVirtualMemoryReservation::highest_available_address_end() const {\n+  return _registry.peak_high_address_end();\n@@ -232,2 +574,0 @@\n-  assert(max_capacity <= ZAddressOffsetMax, \"Too large max_capacity\");\n-\n@@ -236,1 +576,7 @@\n-  const size_t limit = MIN2(ZAddressOffsetMax, ZAddressSpaceLimit::heap());\n+  const size_t limit = ZAddressSpaceLimit::heap();\n+\n+  if (max_capacity > limit) {\n+    \/\/ Cannot fit the heap within the limit\n+    ZInitialize::error_d(\"Java heap exceeds address space limits (\" EXACTFMT \")\", EXACTFMTARGS(limit));\n+    return;\n+  }\n@@ -245,0 +591,1 @@\n+  const size_t required = max_capacity;\n@@ -246,2 +593,2 @@\n-  \/\/ Reserve virtual memory for the heap\n-  ZVirtualMemoryReserver reserver(requested);\n+  log_debug_p(gc, init)(\"Reserved Space: limit \" EXACTFMT \", required \" EXACTFMT \", desired \" EXACTFMT \", requested \" EXACTFMT,\n+                        EXACTFMTARGS(limit), EXACTFMTARGS(required), EXACTFMTARGS(desired), EXACTFMTARGS(requested));\n@@ -249,2 +596,1 @@\n-  const size_t reserved = reserver.reserved();\n-  const bool is_contiguous = reserver.is_contiguous();\n+  ZVirtualMemoryAdaptiveReserver reserver;\n@@ -252,2 +598,2 @@\n-  log_debug_p(gc, init)(\"Reserved Space: limit \" EXACTFMT \", desired \" EXACTFMT \", requested \" EXACTFMT,\n-                        EXACTFMTARGS(limit), EXACTFMTARGS(desired), EXACTFMTARGS(requested));\n+  \/\/ Reserve virtual memory for the heap\n+  const size_t reserved = reserver.reserve(required, requested);\n@@ -260,3 +606,0 @@\n-  \/\/ Set ZAddressOffsetMax to the highest address end available after reservation\n-  ZAddressOffsetMax = untype(reserver.highest_available_address_end());\n-\n@@ -265,4 +608,1 @@\n-  \/\/ Divide size_for_partitions virtual memory over the NUMA nodes\n-  initialize_partitions(&reserver, size_for_partitions);\n-\n-  \/\/ Set up multi-partition or unreserve the surplus memory\n+  size_t unreserved;\n@@ -270,2 +610,1 @@\n-    \/\/ Enough left to setup the multi-partition memory reservation\n-    reserver.initialize_partition_registry(&_multi_partition_registry, desired_for_multi_partition);\n+    \/\/ Can have multi-partitions\n@@ -273,0 +612,1 @@\n+    unreserved = 0;\n@@ -275,1 +615,1 @@\n-    reserver.unreserve_all();\n+    unreserved = reserver.unreserve_after(size_for_partitions);\n@@ -278,1 +618,20 @@\n-  assert(reserver.is_empty(), \"Must have handled all reserved memory\");\n+  \/\/ Now lock down the heap limits to the reserved spaces selected by the reserver\n+  ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n+\n+  \/\/ Transfer the reserved ranges to the type-safe system\n+  ZVirtualMemoryReservation reservation(reserver.reserved_ranges());\n+\n+  \/\/ Divide size_for_partitions virtual memory over the NUMA nodes\n+  initialize_partitions(&reservation, size_for_partitions);\n+\n+  \/\/ Set up multi-partition\n+  if (_is_multi_partition_enabled) {\n+    \/\/ Enough left to setup the multi-partition memory reservation\n+    reservation.initialize_partition_registry(&_multi_partition_registry, desired_for_multi_partition);\n+  }\n+\n+  assert(reservation.is_empty(), \"Must have handled all reserved memory\");\n+\n+  const double heap_ratio = static_cast<double>(reserved) \/ static_cast<double>(max_capacity);\n+  const uintptr_t lowest_offset = untype(lowest_available_address(0));\n+  const bool is_contiguous = reservation.is_contiguous();\n@@ -284,1 +643,3 @@\n-  log_info_p(gc, init)(\"Reserved Space Size: \" EXACTFMT, EXACTFMTARGS(reserved));\n+  log_info_p(gc, init)(\"Reserved Space Size: \" EXACTFMT \" (x%.2f Heap Ratio)\", EXACTFMTARGS(reserved - unreserved), heap_ratio);\n+  log_debug_p(gc, init)(\"Reserved Space Span: \" RANGE2EXACTFMT, ZAddressHeapBase + lowest_offset, ZAddressHeapBase + ZAddressOffsetUpperLimit,\n+                        EXACTFMTARGS(ZAddressOffsetUpperLimit - lowest_offset));\n@@ -290,1 +651,1 @@\n-void ZVirtualMemoryManager::initialize_partitions(ZVirtualMemoryReserver* reserver, size_t size_for_partitions) {\n+void ZVirtualMemoryManager::initialize_partitions(ZVirtualMemoryReservation* reservation, size_t size_for_partitions) {\n@@ -311,1 +672,1 @@\n-    reserver->initialize_partition_registry(registry, reserved_for_partition);\n+    reservation->initialize_partition_registry(registry, reserved_for_partition);\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemoryManager.cpp","additions":453,"deletions":92,"binary":false,"changes":545,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/z\/zRange.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -33,1 +35,43 @@\n-using ZVirtualMemoryRegistry = ZRangeRegistry<ZVirtualMemory>;\n+class ZVirtualMemoryReserver : AllStatic {\n+private:\n+  \/\/ Platform specific implementation\n+  static bool pd_reserve(uintptr_t addr, size_t size);\n+  static void pd_split_reserved(uintptr_t addr, size_t split_size, size_t size);\n+  static void pd_unreserve(uintptr_t addr, size_t size);\n+\n+public:\n+  static bool reserve(uintptr_t addr, size_t size);\n+  static void split_reserved(uintptr_t addr, size_t split_size, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n+};\n+\n+class ZVirtualMemoryWithHeapBaseReserver {\n+  friend class ZVirtualMemoryReservationTest;\n+\n+private:\n+  \/\/ The heap base to reserve against\n+  const uintptr_t               _heap_base;\n+  ZArray<ZVirtualMemoryUntyped> _reserved_ranges;\n+\n+  static size_t calculate_min_range(size_t size);\n+\n+  bool reserve_contiguous(uintptr_t addr, size_t size);\n+  bool reserve_contiguous(size_t size);\n+  size_t reserve_discontiguous(uintptr_t start, size_t size, size_t min_range);\n+  size_t reserve_discontiguous(size_t size);\n+\n+  DEBUG_ONLY(size_t force_reserve_discontiguous(size_t size);)\n+\n+  size_t unreserve_all();\n+\n+public:\n+  ZVirtualMemoryWithHeapBaseReserver(size_t heap_base);\n+  ~ZVirtualMemoryWithHeapBaseReserver();\n+\n+  uintptr_t heap_base() const;\n+  size_t offset_max() const;\n+\n+  size_t reserve(size_t size);\n+\n+  void transfer_reserved_ranges_to(ZArray<ZVirtualMemoryUntyped>* to);\n+};\n@@ -35,1 +79,1 @@\n-class ZVirtualMemoryReserver {\n+class ZVirtualMemoryAdaptiveReserver {\n@@ -38,1 +82,2 @@\n-  friend class ZVirtualMemoryManagerTest;\n+  friend class ZVirtualMemoryRegistryTest;\n+  friend class ZVirtualMemoryReservationTest;\n@@ -41,0 +86,4 @@\n+  \/\/ Accepted heap base\n+  uintptr_t                     _heap_base;\n+  \/\/ Accepted reserved ranges\n+  ZArray<ZVirtualMemoryUntyped> _reserved_ranges;\n@@ -42,2 +91,1 @@\n-  ZVirtualMemoryRegistry _registry;\n-  const size_t           _reserved;\n+  void accept(ZVirtualMemoryWithHeapBaseReserver* reserver);\n@@ -45,1 +93,24 @@\n-  static size_t calculate_min_range(size_t size);\n+public:\n+  ZVirtualMemoryAdaptiveReserver();\n+\n+  size_t reserve(size_t required_size, size_t desired_size);\n+  size_t unreserve_after(size_t keep_size);\n+  void unreserve_all();\n+\n+  uintptr_t heap_base() const;\n+  ZArray<ZVirtualMemoryUntyped>* reserved_ranges();\n+\n+  uintptr_t bottom() const;\n+  uintptr_t end() const;\n+  size_t reserved() const;\n+};\n+\n+using ZVirtualMemoryRegistry = ZRangeRegistry<ZVirtualMemory>;\n+\n+class ZVirtualMemoryReservation {\n+  friend class ZMapperTest;\n+  friend class ZTestAddressReserver;\n+  friend class ZVirtualMemoryReservationTest;\n+\n+private:\n+  ZVirtualMemoryRegistry _registry;\n@@ -49,2 +120,0 @@\n-  bool pd_reserve(zaddress_unsafe addr, size_t size);\n-  void pd_unreserve(zaddress_unsafe addr, size_t size);\n@@ -52,6 +121,0 @@\n-  bool reserve_contiguous(zoffset start, size_t size);\n-  bool reserve_contiguous(size_t size);\n-  size_t reserve_discontiguous(zoffset start, size_t size, size_t min_range);\n-  size_t reserve_discontiguous(size_t size);\n-\n-  size_t reserve(size_t size);\n@@ -60,1 +123,1 @@\n-  DEBUG_ONLY(size_t force_reserve_discontiguous(size_t size);)\n+  void transfer_reserved_ranges(ZArray<ZVirtualMemoryUntyped>* reserved_ranges);\n@@ -63,1 +126,1 @@\n-  ZVirtualMemoryReserver(size_t size);\n+  ZVirtualMemoryReservation(ZArray<ZVirtualMemoryUntyped>* reserved_ranges);\n@@ -67,1 +130,1 @@\n-  void unreserve_all();\n+  size_t unreserve_all();\n@@ -90,1 +153,1 @@\n-  void initialize_partitions(ZVirtualMemoryReserver* reserver, size_t size_for_partitions);\n+  void initialize_partitions(ZVirtualMemoryReservation* reservation, size_t size_for_partitions);\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemoryManager.hpp","additions":81,"deletions":18,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -131,0 +131,3 @@\n+  develop(bool, ZForceHighestHeapBase, false,                               \\\n+          \"Forces the heap base to occupied the highest supported bit\")     \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/z\/z_globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -394,0 +394,4 @@\n+\/\/ Printing a range (with exact size format), with start and end given\n+#define RANGE2EXACTFMT             \"[\" PTR_FORMAT \" - \" PTR_FORMAT \"), (\" EXACTFMT \")\"\n+#define RANGE2EXACTFMTARGS(p1, p2) p2i(p1), p2i(p2), EXACTFMTARGS(p2u(p2) - p2u(p2))\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -47,5 +47,5 @@\n-  ZHeap*            _old_heap;\n-  ZGenerationOld*   _old_old;\n-  ZGenerationYoung* _old_young;\n-  ZAddressReserver  _zaddress_reserver;\n-  zoffset           _page_offset;\n+  ZHeap*                _old_heap;\n+  ZGenerationOld*       _old_old;\n+  ZGenerationYoung*     _old_young;\n+  ZTestAddressReserver  _zaddress_reserver;\n+  zoffset               _page_offset;\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zForwarding.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -39,3 +39,3 @@\n-  ZAddressReserver        _zaddress_reserver;\n-  ZVirtualMemoryReserver* _reserver;\n-  ZVirtualMemoryRegistry* _registry;\n+  ZTestAddressReserver       _zaddress_reserver;\n+  ZVirtualMemoryReservation* _reservation;\n+  ZVirtualMemoryRegistry*    _registry;\n@@ -46,1 +46,1 @@\n-    _reserver = _zaddress_reserver.reserver();\n+    _reservation = _zaddress_reserver.reservation();\n@@ -49,1 +49,1 @@\n-    if (_reserver->reserved() < ReservationSize || !_registry->is_contiguous()) {\n+    if (_reservation->reserved() < ReservationSize || !_registry->is_contiguous()) {\n@@ -51,1 +51,1 @@\n-          << (_reserver->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n+          << (_reservation->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n@@ -58,1 +58,1 @@\n-    _reserver = nullptr;\n+    _reservation = nullptr;\n@@ -72,1 +72,1 @@\n-    _reserver->unreserve(middle);\n+    _reservation->unreserve(middle);\n@@ -75,2 +75,2 @@\n-    _reserver->unreserve(bottom);\n-    _reserver->unreserve(top);\n+    _reservation->unreserve(bottom);\n+    _reservation->unreserve(top);\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zMapper_windows.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -36,1 +36,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -58,1 +58,1 @@\n-    ZVirtualMemory mem(zoffset(0), ZAddressOffsetMax);\n+    ZVirtualMemory mem(zoffset(0), ZAddressOffsetUpperLimit);\n@@ -61,3 +61,3 @@\n-    EXPECT_EQ(mem.end(), zoffset_end(ZAddressOffsetMax));\n-    EXPECT_EQ(mem.size(), ZAddressOffsetMax);\n-    EXPECT_EQ(mem.granule_count(), (int)(ZAddressOffsetMax >> ZGranuleSizeShift));\n+    EXPECT_EQ(mem.end(), zoffset_end(ZAddressOffsetUpperLimit));\n+    EXPECT_EQ(mem.size(), ZAddressOffsetUpperLimit);\n+    EXPECT_EQ(mem.granule_count(), (int)(ZAddressOffsetUpperLimit >> ZGranuleSizeShift));\n@@ -68,1 +68,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -98,1 +98,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -119,1 +119,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -133,1 +133,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemory.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1,272 +0,0 @@\n-\/*\n- * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"gc\/z\/zAddress.inline.hpp\"\n-#include \"gc\/z\/zArguments.hpp\"\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"gc\/z\/zInitialize.hpp\"\n-#include \"gc\/z\/zList.inline.hpp\"\n-#include \"gc\/z\/zNUMA.inline.hpp\"\n-#include \"gc\/z\/zValue.inline.hpp\"\n-#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"zunittest.hpp\"\n-\n-using namespace testing;\n-\n-#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n-\n-class ZCallbacksResetter {\n-private:\n-  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n-  ZVirtualMemoryRegistry::Callbacks  _saved;\n-\n-public:\n-  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n-    : _callbacks(callbacks),\n-      _saved(*callbacks) {\n-    *_callbacks = {};\n-  }\n-  ~ZCallbacksResetter() {\n-    *_callbacks = _saved;\n-  }\n-};\n-\n-class ZVirtualMemoryManagerTest : public ZTest {\n-private:\n-  static constexpr size_t ReservationSize = 32 * M;\n-\n-  ZAddressReserver        _zaddress_reserver;\n-  ZVirtualMemoryReserver* _reserver;\n-  ZVirtualMemoryRegistry* _registry;\n-\n-public:\n-  virtual void SetUp() {\n-    _zaddress_reserver.SetUp(ReservationSize);\n-    _reserver = _zaddress_reserver.reserver();\n-    _registry = _zaddress_reserver.registry();\n-\n-    if (_reserver->reserved() < ReservationSize || !_registry->is_contiguous()) {\n-      GTEST_SKIP() << \"Fixture failed to reserve adequate memory, reserved \"\n-          << (_reserver->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n-    }\n-  }\n-\n-  virtual void TearDown() {\n-    _registry = nullptr;\n-    _reserver = nullptr;\n-    _zaddress_reserver.TearDown();\n-  }\n-\n-  void test_reserve_discontiguous_and_coalesce() {\n-    \/\/ Start by ensuring that we have 3 unreserved granules, and then let the\n-    \/\/ fourth granule be pre-reserved and therefore blocking subsequent requests\n-    \/\/ to reserve memory.\n-    \/\/\n-    \/\/ +----+----+----+----+\n-    \/\/                -----  pre-reserved - to block contiguous reservation\n-    \/\/ ---------------       unreserved   - to allow reservation of 3 granules\n-    \/\/\n-    \/\/ If we then asks for 4 granules starting at the first granule above,\n-    \/\/ then we won't be able to reserve 4 consecutive granules and the code\n-    \/\/ reverts into the discontiguous mode. This mode uses interval halving\n-    \/\/ to find the limits of memory areas that have already been reserved.\n-    \/\/ This will lead to the first 2 granules being reserved, then the third\n-    \/\/ granule will be reserved.\n-    \/\/\n-    \/\/ The problem we had with this is that this would yield two separate\n-    \/\/ placeholder reservations, even though they are adjacent. The callbacks\n-    \/\/ are supposed to fix that by coalescing the placeholders, *but* the\n-    \/\/ callbacks used to be only turned on *after* the reservation call. So,\n-    \/\/ we end up with one 3 granule large memory area in the manager, which\n-    \/\/ unexpectedly was covered by two placeholders (instead of the expected\n-    \/\/ one placeholder).\n-    \/\/\n-    \/\/ Later when the callbacks had been installed and we tried to fetch memory\n-    \/\/ from the manager, the callbacks would try to split off the placeholder\n-    \/\/ to separate the fetched memory from the memory left in the manager. This\n-    \/\/ used to fail because the memory was already split into two placeholders.\n-\n-    \/\/ Start at the offset we reserved.\n-    const zoffset base_offset = _registry->peek_low_address();\n-\n-    \/\/ Empty the reserved memory in preparation for the rest of the test.\n-    _reserver->unreserve_all();\n-\n-    const zaddress_unsafe base = ZOffset::address_unsafe(base_offset);\n-    const zaddress_unsafe blocked = base + 3 * ZGranuleSize;\n-\n-    \/\/ Reserve the memory that is acting as a blocking reservation.\n-    {\n-      char* const result = os::attempt_reserve_memory_at((char*)untype(blocked), ZGranuleSize, mtTest);\n-      if (uintptr_t(result) != untype(blocked)) {\n-        GTEST_SKIP() << \"Failed to reserve requested memory at \" << untype(blocked);\n-      }\n-    }\n-\n-    {\n-      \/\/ This ends up reserving 2 granules and then 1 granule adjacent to the\n-      \/\/ first. In previous implementations this resulted in two separate\n-      \/\/ placeholders (4MB and 2MB). This was a bug, because the manager is\n-      \/\/ designed to have one placeholder per memory area. This in turn would\n-      \/\/ lead to a subsequent failure when _vmr->remove* tried to split off the\n-      \/\/ 4MB that is already covered by its own placeholder. You can't place\n-      \/\/ a placeholder over an already existing placeholder.\n-\n-      \/\/ To reproduce this, the test needed to mimic the initializing memory\n-      \/\/ reservation code which had the placeholders turned off. This was done\n-      \/\/ with this helper:\n-      \/\/\n-      \/\/ ZCallbacksResetter resetter(&_va->_callbacks);\n-      \/\/\n-      \/\/ After the fix, we always have the callbacks turned on, so we don't\n-      \/\/ need this to mimic the initializing memory reservation.\n-\n-      const size_t reserved = _reserver->reserve_discontiguous(base_offset, 4 * ZGranuleSize, ZGranuleSize);\n-      ASSERT_LE(reserved, 3 * ZGranuleSize);\n-      if (reserved < 3 * ZGranuleSize) {\n-        GTEST_SKIP() << \"Failed reserve_discontiguous\"\n-            \", expected 3 * ZGranuleSize, got \" << (reserved >> ZGranuleSizeShift)\n-            << \" * ZGranuleSize\";\n-      }\n-    }\n-\n-    {\n-      \/\/ The test used to crash here because the 3 granule memory area was\n-      \/\/ inadvertently covered by two place holders (2 granules + 1 granule).\n-      const ZVirtualMemory vmem = _registry->remove_from_low(2 * ZGranuleSize);\n-      ASSERT_EQ(vmem, ZVirtualMemory(base_offset, 2 * ZGranuleSize));\n-\n-      \/\/ Cleanup - Must happen in granule-sizes because of how Windows hands\n-      \/\/ out memory in granule-sized placeholder reservations.\n-      _reserver->unreserve(vmem.first_part(ZGranuleSize));\n-      _reserver->unreserve(vmem.last_part(ZGranuleSize));\n-    }\n-\n-    \/\/ Final cleanup\n-    const ZVirtualMemory vmem = _registry->remove_from_low(ZGranuleSize);\n-    ASSERT_EQ(vmem, ZVirtualMemory(base_offset + 2 * ZGranuleSize, ZGranuleSize));\n-    _reserver->unreserve(vmem);\n-\n-    const bool released = os::release_memory((char*)untype(blocked), ZGranuleSize);\n-    ASSERT_TRUE(released);\n-  }\n-\n-  void test_remove_from_low() {\n-    {\n-      \/\/ Verify that we get a placeholder for the first granule\n-      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n-\n-      _registry->insert(removed);\n-    }\n-\n-    {\n-      \/\/ Remove something larger than a granule and then insert it\n-      const ZVirtualMemory removed = _registry->remove_from_low(3 * ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, 3 * ZGranuleSize);\n-\n-      _registry->insert(removed);\n-    }\n-\n-    {\n-      \/\/ Insert with more memory removed\n-      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n-\n-      ZVirtualMemory next = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(next, ZGranuleSize);\n-\n-      _registry->insert(removed);\n-      _registry->insert(next);\n-    }\n-  }\n-\n-  void test_remove_from_high() {\n-    {\n-      \/\/ Verify that we get a placeholder for the last granule\n-      const ZVirtualMemory high = _registry->remove_from_high(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(high, ZGranuleSize);\n-\n-      const ZVirtualMemory prev = _registry->remove_from_high(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(prev, ZGranuleSize);\n-\n-      _registry->insert(high);\n-      _registry->insert(prev);\n-    }\n-\n-    {\n-      \/\/ Remove something larger than a granule and return it\n-      const ZVirtualMemory high = _registry->remove_from_high(2 * ZGranuleSize);\n-      ASSERT_REMOVAL_OK(high, 2 * ZGranuleSize);\n-\n-      _registry->insert(high);\n-    }\n-  }\n-\n-  void test_remove_whole() {\n-    \/\/ Need a local variable to appease gtest\n-    const size_t reservation_size = ReservationSize;\n-\n-    \/\/ Remove the whole reservation\n-    const ZVirtualMemory reserved = _registry->remove_from_low(reservation_size);\n-    ASSERT_REMOVAL_OK(reserved, reservation_size);\n-\n-    const ZVirtualMemory first(reserved.start(), 4 * ZGranuleSize);\n-    const ZVirtualMemory second(reserved.start() + 6 * ZGranuleSize, 6 * ZGranuleSize);\n-\n-    \/\/ Insert two chunks and then remove them again\n-    _registry->insert(first);\n-    _registry->insert(second);\n-\n-    const ZVirtualMemory removed_first = _registry->remove_from_low(first.size());\n-    ASSERT_EQ(removed_first, first);\n-\n-    const ZVirtualMemory removed_second = _registry->remove_from_low(second.size());\n-    ASSERT_EQ(removed_second, second);\n-\n-    \/\/ Now insert it all, and verify it can be re-removed\n-    _registry->insert(reserved);\n-\n-    const ZVirtualMemory removed_reserved = _registry->remove_from_low(reservation_size);\n-    ASSERT_EQ(removed_reserved, reserved);\n-\n-    _registry->insert(reserved);\n-  }\n-};\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_reserve_discontiguous_and_coalesce) {\n-  test_reserve_discontiguous_and_coalesce();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_from_low) {\n-  test_remove_from_low();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_from_high) {\n-  test_remove_from_high();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_whole) {\n-  test_remove_whole();\n-}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryManager.cpp","additions":0,"deletions":272,"binary":false,"changes":272,"status":"deleted"},{"patch":"@@ -0,0 +1,184 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.inline.hpp\"\n+#include \"gc\/z\/zArguments.hpp\"\n+#include \"gc\/z\/zGlobals.hpp\"\n+#include \"gc\/z\/zInitialize.hpp\"\n+#include \"gc\/z\/zList.inline.hpp\"\n+#include \"gc\/z\/zNUMA.inline.hpp\"\n+#include \"gc\/z\/zValue.inline.hpp\"\n+#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"zunittest.hpp\"\n+\n+using namespace testing;\n+\n+#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n+\n+class ZCallbacksResetter {\n+private:\n+  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n+  ZVirtualMemoryRegistry::Callbacks  _saved;\n+\n+public:\n+  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n+    : _callbacks(callbacks),\n+      _saved(*callbacks) {\n+    *_callbacks = {};\n+  }\n+  ~ZCallbacksResetter() {\n+    *_callbacks = _saved;\n+  }\n+};\n+\n+class ZVirtualMemoryRegistryTest : public ZTest {\n+private:\n+  static constexpr size_t ReservationSize = 32 * M;\n+\n+  ZTestAddressReserver       _zaddress_reserver;\n+  ZVirtualMemoryReservation* _reservation;\n+  ZVirtualMemoryRegistry*    _registry;\n+\n+public:\n+  virtual void SetUp() {\n+    \/\/ Only run test on supported Windows versions\n+    if (!is_os_supported()) {\n+      GTEST_SKIP() << \"OS not supported\";\n+    }\n+\n+    _zaddress_reserver.SetUp(ReservationSize);\n+    _reservation = _zaddress_reserver.reservation();\n+    _registry = _zaddress_reserver.registry();\n+\n+    if (_reservation->reserved() < ReservationSize || !_registry->is_contiguous()) {\n+      GTEST_SKIP() << \"Fixture failed to reserve adequate memory, reserved \"\n+          << (_reservation->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n+    }\n+  }\n+\n+  virtual void TearDown() {\n+    if (!is_os_supported()) {\n+      \/\/ Test skipped, nothing to cleanup\n+      return;\n+    }\n+\n+    _registry = nullptr;\n+    _reservation = nullptr;\n+    _zaddress_reserver.TearDown();\n+  }\n+\n+  void test_remove_from_low() {\n+    {\n+      \/\/ Verify that we get a placeholder for the first granule\n+      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n+\n+      _registry->insert(removed);\n+    }\n+\n+    {\n+      \/\/ Remove something larger than a granule and then insert it\n+      const ZVirtualMemory removed = _registry->remove_from_low(3 * ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, 3 * ZGranuleSize);\n+\n+      _registry->insert(removed);\n+    }\n+\n+    {\n+      \/\/ Insert with more memory removed\n+      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n+\n+      ZVirtualMemory next = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(next, ZGranuleSize);\n+\n+      _registry->insert(removed);\n+      _registry->insert(next);\n+    }\n+  }\n+\n+  void test_remove_from_high() {\n+    {\n+      \/\/ Verify that we get a placeholder for the last granule\n+      const ZVirtualMemory high = _registry->remove_from_high(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(high, ZGranuleSize);\n+\n+      const ZVirtualMemory prev = _registry->remove_from_high(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(prev, ZGranuleSize);\n+\n+      _registry->insert(high);\n+      _registry->insert(prev);\n+    }\n+\n+    {\n+      \/\/ Remove something larger than a granule and return it\n+      const ZVirtualMemory high = _registry->remove_from_high(2 * ZGranuleSize);\n+      ASSERT_REMOVAL_OK(high, 2 * ZGranuleSize);\n+\n+      _registry->insert(high);\n+    }\n+  }\n+\n+  void test_remove_whole() {\n+    \/\/ Need a local variable to appease gtest\n+    const size_t reservation_size = ReservationSize;\n+\n+    \/\/ Remove the whole reservation\n+    const ZVirtualMemory reserved = _registry->remove_from_low(reservation_size);\n+    ASSERT_REMOVAL_OK(reserved, reservation_size);\n+\n+    const ZVirtualMemory first(reserved.start(), 4 * ZGranuleSize);\n+    const ZVirtualMemory second(reserved.start() + 6 * ZGranuleSize, 6 * ZGranuleSize);\n+\n+    \/\/ Insert two chunks and then remove them again\n+    _registry->insert(first);\n+    _registry->insert(second);\n+\n+    const ZVirtualMemory removed_first = _registry->remove_from_low(first.size());\n+    ASSERT_EQ(removed_first, first);\n+\n+    const ZVirtualMemory removed_second = _registry->remove_from_low(second.size());\n+    ASSERT_EQ(removed_second, second);\n+\n+    \/\/ Now insert it all, and verify it can be re-removed\n+    _registry->insert(reserved);\n+\n+    const ZVirtualMemory removed_reserved = _registry->remove_from_low(reservation_size);\n+    ASSERT_EQ(removed_reserved, reserved);\n+\n+    _registry->insert(reserved);\n+  }\n+};\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_from_low) {\n+  test_remove_from_low();\n+}\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_from_high) {\n+  test_remove_from_high();\n+}\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_whole) {\n+  test_remove_whole();\n+}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryRegistry.cpp","additions":184,"deletions":0,"binary":false,"changes":184,"status":"added"},{"patch":"@@ -0,0 +1,186 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.inline.hpp\"\n+#include \"gc\/z\/zArguments.hpp\"\n+#include \"gc\/z\/zGlobals.hpp\"\n+#include \"gc\/z\/zInitialize.hpp\"\n+#include \"gc\/z\/zList.inline.hpp\"\n+#include \"gc\/z\/zNUMA.inline.hpp\"\n+#include \"gc\/z\/zValue.inline.hpp\"\n+#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"zunittest.hpp\"\n+\n+using namespace testing;\n+\n+#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n+\n+class ZCallbacksResetter {\n+private:\n+  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n+  ZVirtualMemoryRegistry::Callbacks  _saved;\n+\n+public:\n+  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n+    : _callbacks(callbacks),\n+      _saved(*callbacks) {\n+    *_callbacks = {};\n+  }\n+  ~ZCallbacksResetter() {\n+    *_callbacks = _saved;\n+  }\n+};\n+\n+class ZVirtualMemoryReservationTest : public ZTest {\n+private:\n+  static constexpr size_t ReservationSize = 32 * M;\n+\n+public:\n+  virtual void SetUp() {\n+    \/\/ Only run test on supported Windows versions\n+    if (!is_os_supported()) {\n+      GTEST_SKIP() << \"OS not supported\";\n+    }\n+  }\n+\n+  virtual void TearDown() {\n+    \/\/ Nothing to cleanup\n+  }\n+\n+  void test_reserve_discontiguous_and_coalesce() {\n+    ZVirtualMemoryAdaptiveReserver reserver;\n+\n+    reserver.reserve(4 * ZGranuleSize, 4 * ZGranuleSize);\n+\n+    if (reserver.reserved() != 4 * ZGranuleSize) {\n+      GTEST_SKIP() << \"Failed to reserve requested memory\";\n+    }\n+\n+    if (reserver._reserved_ranges.length() != 1) {\n+      GTEST_SKIP() << \"Failed to reserve single reserved area\";\n+    }\n+\n+    ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n+\n+    \/\/ Start by ensuring that we have 3 unreserved granules, and then let the\n+    \/\/ fourth granule be pre-reserved and therefore blocking subsequent requests\n+    \/\/ to reserve memory.\n+    \/\/\n+    \/\/ +----+----+----+----+\n+    \/\/                -----  pre-reserved - to block contiguous reservation\n+    \/\/ ---------------       unreserved   - to allow reservation of 3 granules\n+    \/\/\n+    \/\/ If we then asks for 4 granules starting at the first granule above,\n+    \/\/ then we won't be able to reserve 4 consecutive granules and the code\n+    \/\/ reverts into the discontiguous mode. This mode uses interval halving\n+    \/\/ to find the limits of memory areas that have already been reserved.\n+    \/\/ This will lead to the first 2 granules being reserved, then the third\n+    \/\/ granule will be reserved.\n+    \/\/\n+    \/\/ The problem we had with this is that this would yield two separate\n+    \/\/ placeholder reservations, even though they are adjacent. The callbacks\n+    \/\/ are supposed to fix that by coalescing the placeholders, *but* the\n+    \/\/ callbacks used to be only turned on *after* the reservation call. So,\n+    \/\/ we end up with one 3 granule large memory area in the manager, which\n+    \/\/ unexpectedly was covered by two placeholders (instead of the expected\n+    \/\/ one placeholder).\n+    \/\/\n+    \/\/ Later when the callbacks had been installed and we tried to fetch memory\n+    \/\/ from the manager, the callbacks would try to split off the placeholder\n+    \/\/ to separate the fetched memory from the memory left in the manager. This\n+    \/\/ used to fail because the memory was already split into two placeholders.\n+\n+    \/\/ Start at the offset we reserved.\n+    const uintptr_t bottom = reserver.bottom();\n+\n+    \/\/ Empty the reserved memory in preparation for the rest of the test.\n+    reserver.unreserve_all();\n+\n+    const uintptr_t blocked = bottom + 3 * ZGranuleSize;\n+\n+    \/\/ Reserve the memory that is acting as a blocking reservation.\n+    {\n+      char* const result = os::attempt_reserve_memory_at((char*)blocked, ZGranuleSize, mtTest);\n+      if (uintptr_t(result) != blocked) {\n+        GTEST_SKIP() << \"Failed to reserve requested memory at \" << blocked;\n+      }\n+    }\n+\n+    \/\/ This ends up reserving 2 granules and then 1 granule adjacent to the\n+    \/\/ first. In previous implementations this resulted in two separate\n+    \/\/ placeholders (4MB and 2MB). This was a bug, because the manager is\n+    \/\/ designed to have one placeholder per memory area. This in turn would\n+    \/\/ lead to a subsequent failure when _vmr->remove* tried to split off the\n+    \/\/ 4MB that is already covered by its own placeholder. You can't place\n+    \/\/ a placeholder over an already existing placeholder.\n+\n+    \/\/ To reproduce this, the test needed to mimic the initializing memory\n+    \/\/ reservation code which had the placeholders turned off. This was done\n+    \/\/ with this helper:\n+    \/\/\n+    \/\/ ZCallbacksResetter resetter(&_va->_callbacks);\n+    \/\/\n+    \/\/ After the fix, we always have the callbacks turned on, so we don't\n+    \/\/ need this to mimic the initializing memory reservation.\n+\n+    ZVirtualMemoryWithHeapBaseReserver reserver2(reserver.heap_base());\n+\n+    const size_t reserved = reserver2.reserve_discontiguous(bottom, 4 * ZGranuleSize, ZGranuleSize);\n+    ASSERT_LE(reserved, 3 * ZGranuleSize);\n+    if (reserved < 3 * ZGranuleSize) {\n+      GTEST_SKIP() << \"Failed reserve_discontiguous\"\n+          \", expected 3 * ZGranuleSize, got \" << (reserved >> ZGranuleSizeShift)\n+          << \" * ZGranuleSize\";\n+    }\n+\n+    \/\/ Transfer over to the reservation instance\n+    ZVirtualMemoryReservation reservation(&reserver2._reserved_ranges);\n+\n+    const zoffset bottom_offset = ZAddress::offset(to_zaddress(bottom));\n+\n+    {\n+      \/\/ The test used to crash here because the 3 granule memory area was\n+      \/\/ inadvertently covered by two place holders (2 granules + 1 granule).\n+      const ZVirtualMemory vmem = reservation._registry.remove_from_low(2 * ZGranuleSize);\n+      ASSERT_EQ(vmem, ZVirtualMemory(bottom_offset, 2 * ZGranuleSize));\n+\n+      \/\/ Cleanup - Must happen in granule-sizes because of how Windows hands\n+      \/\/ out memory in granule-sized placeholder reservations.\n+      reservation.unreserve(vmem.first_part(ZGranuleSize));\n+      reservation.unreserve(vmem.last_part(ZGranuleSize));\n+    }\n+\n+    \/\/ Final cleanup\n+    const ZVirtualMemory vmem = reservation._registry.remove_from_low(ZGranuleSize);\n+    ASSERT_EQ(vmem, ZVirtualMemory(bottom_offset + 2 * ZGranuleSize, ZGranuleSize));\n+    reservation.unreserve(vmem);\n+\n+    const bool released = os::release_memory((char*)blocked, ZGranuleSize);\n+    ASSERT_TRUE(released);\n+  }\n+};\n+\n+TEST_VM_F(ZVirtualMemoryReservationTest, test_reserve_discontiguous_and_coalesce) {\n+  test_reserve_discontiguous_and_coalesce();\n+}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryReservation.cpp","additions":186,"deletions":0,"binary":false,"changes":186,"status":"added"},{"patch":"@@ -43,1 +43,1 @@\n-class ZAddressOffsetMaxSetter {\n+class ZAddressOffsetLimitsSetter {\n@@ -49,0 +49,1 @@\n+  size_t _old_upper_limit;\n@@ -51,1 +52,1 @@\n-  ZAddressOffsetMaxSetter(size_t zaddress_offset_max)\n+  ZAddressOffsetLimitsSetter(size_t zaddress_offset_max, size_t zaddress_offset_limit)\n@@ -53,1 +54,2 @@\n-      _old_mask(ZAddressOffsetMask) {\n+      _old_mask(ZAddressOffsetMask),\n+      _old_upper_limit(ZAddressOffsetUpperLimit) {\n@@ -56,0 +58,2 @@\n+\n+    ZAddressOffsetUpperLimit = zaddress_offset_max;\n@@ -57,1 +61,4 @@\n-  ~ZAddressOffsetMaxSetter() {\n+  ZAddressOffsetLimitsSetter(size_t zaddress_offset_max)\n+    : ZAddressOffsetLimitsSetter(zaddress_offset_max, zaddress_offset_max) {}\n+\n+  ~ZAddressOffsetLimitsSetter() {\n@@ -60,0 +67,1 @@\n+    ZAddressOffsetUpperLimit = _old_upper_limit;\n@@ -64,43 +72,0 @@\n-public:\n-  class ZAddressReserver {\n-    ZVirtualMemoryReserver* _reserver;\n-    bool _active;\n-\n-    public:\n-      ZAddressReserver()\n-        : _reserver(nullptr),\n-          _active(false) {}\n-\n-      ~ZAddressReserver() {\n-        GTEST_EXPECT_FALSE(_active) << \"ZAddressReserver deconstructed without calling TearDown\";\n-      }\n-\n-      void SetUp(size_t reservation_size) {\n-        GTEST_EXPECT_FALSE(_active) << \"SetUp called twice without a TearDown\";\n-        _active = true;\n-\n-        _reserver = (ZVirtualMemoryReserver*)os::malloc(sizeof(ZVirtualMemoryManager), mtTest);\n-        _reserver = ::new (_reserver) ZVirtualMemoryReserver(reservation_size);\n-      }\n-\n-      void TearDown() {\n-        GTEST_EXPECT_TRUE(_active) << \"TearDown called without a preceding SetUp\";\n-        _active = false;\n-\n-        \/\/ Best-effort cleanup\n-        _reserver->unreserve_all();\n-        _reserver->~ZVirtualMemoryReserver();\n-        os::free(_reserver);\n-      }\n-\n-      ZVirtualMemoryReserver* reserver() {\n-        GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n-        return _reserver;\n-      }\n-\n-      ZVirtualMemoryRegistry* registry() {\n-        GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n-        return &_reserver->_registry;\n-      }\n-  };\n-\n@@ -108,1 +73,1 @@\n-  ZAddressOffsetMaxSetter _zaddress_offset_max_setter;\n+  ZAddressOffsetLimitsSetter _zaddress_offset_max_setter;\n@@ -135,2 +100,20 @@\n-      \/\/ ZGlobalsPointers::initialize() sets ZAddressOffsetMax, make sure the\n-      \/\/ first test fixture invocation has a correct ZAddressOffsetMaxSetter.\n+      auto initialize_heap_settings = [&]() {\n+        assert(MaxHeapSize > 0, \"Expecting heap size to be initialized\");\n+        for (size_t heap_base_shift = ZAddressHeapBaseMinShift;\n+            heap_base_shift <= ZAddressHeapBaseMaxShift;\n+            heap_base_shift++) {\n+          const size_t heap_base = uintptr_t(1) << heap_base_shift;\n+          const size_t max_offset = (size_t)heap_base;\n+          if (MaxHeapSize <= max_offset) {\n+            ZGlobalsPointers::set_heap_limits(heap_base, heap_base + size_t(heap_base));\n+            return true;\n+          }\n+        }\n+\n+        return false;\n+      };\n+\n+      GTEST_EXPECT_TRUE(initialize_heap_settings()) << \"Failed to setup test fixture\";\n+\n+      \/\/ ZGlobalsPointers::set_heap_limits() sets ZAddressOffsetMax and ZAddressOffsetUpperLimit,\n+      \/\/ make sure the first test fixture invocation has a correct ZAddressOffsetLimitsSetter.\n@@ -139,0 +122,1 @@\n+      _zaddress_offset_max_setter._old_upper_limit = ZAddressOffsetMax;\n@@ -149,1 +133,2 @@\n-  bool is_os_supported() {\n+public:\n+  static bool is_os_supported() {\n@@ -154,0 +139,51 @@\n+class ZTestAddressReserver {\n+  ZVirtualMemoryReservation*      _reservation;\n+  bool                            _active;\n+\n+public:\n+  ZTestAddressReserver()\n+  : _reservation(nullptr),\n+    _active(false) {}\n+\n+  ~ZTestAddressReserver() {\n+    GTEST_EXPECT_FALSE(_active) << \"ZTestAddressReserver deconstructed without calling TearDown\";\n+  }\n+\n+  void SetUp(size_t reservation_size) {\n+    GTEST_EXPECT_TRUE(ZTest::is_os_supported()) << \"Should not use SetUp on unsupported systems\";\n+    GTEST_EXPECT_FALSE(_active) << \"SetUp called twice without a TearDown\";\n+    _active = true;\n+\n+    ZVirtualMemoryAdaptiveReserver reserver;\n+\n+    const size_t reserved = reserver.reserve(reservation_size, reservation_size);\n+\n+    GTEST_EXPECT_TRUE(reserved == reservation_size);\n+\n+    ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n+\n+    _reservation = (ZVirtualMemoryReservation*)os::malloc(sizeof(ZVirtualMemoryReservation), mtTest);\n+    _reservation = ::new (_reservation) ZVirtualMemoryReservation(reserver.reserved_ranges());\n+  }\n+\n+  void TearDown() {\n+    GTEST_EXPECT_TRUE(_active) << \"TearDown called without a preceding SetUp\";\n+    _active = false;\n+\n+    \/\/ Best-effort cleanup\n+    _reservation->unreserve_all();\n+    _reservation->~ZVirtualMemoryReservation();\n+    os::free(_reservation);\n+  }\n+\n+  ZVirtualMemoryReservation* reservation() {\n+    GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n+    return _reservation;\n+  }\n+\n+  ZVirtualMemoryRegistry* registry() {\n+    GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n+    return &_reservation->_registry;\n+  }\n+};\n+\n","filename":"test\/hotspot\/gtest\/gc\/z\/zunittest.hpp","additions":87,"deletions":51,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -0,0 +1,208 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package gc.z;\n+\n+\/*\n+ * @test id=BlockUpper\n+ * @summary Tests linux virtual address space and ZGC heap reservation interactions\n+ * @library \/test\/lib\n+ * @requires vm.flagless & vm.gc.Z & os.family == \"linux\"\n+ * @run driver gc.z.TestLinuxVirtualAddressSpace ScenarioBlockUpper\n+ *\/\n+\n+\/*\n+ * @test id=BlockLower\n+ * @summary Tests linux virtual address space and ZGC heap reservation interactions\n+ * @library \/test\/lib\n+ * @requires vm.flagless & vm.gc.Z & os.family == \"linux\"\n+ * @run driver gc.z.TestLinuxVirtualAddressSpace ScenarioBlockLower\n+ *\/\n+\n+\/*\n+ * @test id=ScenarioBlockPreferred\n+ * @summary Tests linux virtual address space and ZGC heap reservation interactions\n+ * @library \/test\/lib\n+ * @requires vm.flagless & vm.gc.Z & os.family == \"linux\"\n+ * @run driver gc.z.TestLinuxVirtualAddressSpace ScenarioBlockPreferred\n+ *\/\n+\n+\n+import jdk.test.lib.Utils;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.lib.process.OutputAnalyzer;\n+\n+import jtreg.SkippedException;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Stream;\n+\n+public class TestLinuxVirtualAddressSpace {\n+    private static record Range (long start, long end) {\n+        List<String> asArgs() {\n+            if (start >= end) { throw new RuntimeException(\"Bad Range\"); }\n+            return List.of(\"\" + start, \"\" + end);\n+        }\n+    }\n+\n+    private static final long K = 1024;\n+    private static final long M = 1024 * K;\n+    private static final long G = 1024 * M;\n+    private static final long T = 1024 * G;\n+\n+    private static final int SIGKILL = 127;\n+\n+    private static String toXmxFlag(long xmx) {\n+        if (xmx % T == 0) { return \"-Xmx\" + (xmx \/ T) + \"T\"; }\n+        if (xmx % G == 0) { return \"-Xmx\" + (xmx \/ G) + \"G\"; }\n+        if (xmx % M == 0) { return \"-Xmx\" + (xmx \/ M) + \"M\"; }\n+        if (xmx % K == 0) { return \"-Xmx\" + (xmx \/ K) + \"K\"; }\n+        return \"-Xmx\" + xmx;\n+    }\n+\n+    private static abstract class ScenarioBase {\n+        List<Range> ranges;\n+        Optional<Long> xmx;\n+\n+        ScenarioBase(List<Range> ranges) {\n+            this.ranges = ranges;\n+            this.xmx = Optional.empty();\n+        }\n+\n+        ScenarioBase(List<Range> ranges, long xmx) {\n+            this.ranges = ranges;\n+            this.xmx = Optional.of(xmx);\n+        }\n+\n+        private String[] args() {\n+            return Stream.concat(\n+                xmx.stream().map(TestLinuxVirtualAddressSpace::toXmxFlag),\n+                ranges.stream().map(Range::asArgs).flatMap(Collection::stream)\n+            ).toArray(String[]::new);\n+        }\n+\n+        public void run() throws Exception {\n+            var pb = ProcessTools.createNativeTestProcessBuilder(\"gc_z_TestLinuxVirtualAddressSpace\", args());\n+            var oa = new OutputAnalyzer(pb.start());\n+\n+            \/\/ Check for SkippedException conditions\n+            if (oa.getExitValue() == SIGKILL) {\n+                \/\/ OS killed the test process\n+                throw new SkippedException(\"Received a SIGKILL\");\n+            }\n+\n+            if (oa.stdoutContains(\"MAP_FIXED_NOREPLACE unsupported\")) {\n+                \/\/ Old linux kernel\n+                throw new SkippedException(\"MAP_FIXED_NOREPLACE unsupported\");\n+            }\n+\n+            if (oa.stdoutContains(\"ENOMEM restriction encountered\")) {\n+                \/\/ Hit some resource limit\n+                throw new SkippedException(\"ENOMEM restriction encountered\");\n+            }\n+\n+            oa.shouldHaveExitValue(0);\n+\n+            oa.reportDiagnosticSummary();\n+\n+            analyze(oa);\n+        }\n+\n+        void error(String errorMessage) {\n+            throw new RuntimeException(errorMessage);\n+        }\n+\n+        Range parseReservedSpaceSpan(OutputAnalyzer oa) {\n+            String stdout = oa.getStdout();\n+            var pattern = Pattern.compile(\"Reserved Space Span: \\\\[(0x\\\\w+) - (0x\\\\w+)\\\\)\");\n+            var matcher = pattern.matcher(stdout);\n+            if (!matcher.find()) {\n+                error(\"Reserved Space Span string missing from output\");\n+            }\n+            return new Range(Long.decode(matcher.group(1)), Long.decode(matcher.group(2)));\n+        }\n+\n+        abstract void analyze(OutputAnalyzer oa);\n+    }\n+\n+    public static class ScenarioBlockUpper extends ScenarioBase {\n+        static final long top = 1L << 48;\n+        static final long bottom = 1L << 40;\n+\n+        public ScenarioBlockUpper() {\n+            super(List.of(new Range(bottom, top)));\n+        }\n+\n+        void analyze(OutputAnalyzer oa) {\n+            var range = parseReservedSpaceSpan(oa);\n+            if (range.end >= bottom) {\n+                error(\"Reserved Space Span above reserved range.\");\n+            }\n+        }\n+    }\n+\n+    public static class ScenarioBlockLower extends ScenarioBase {\n+        static final long top = 1L << 42;\n+        static final long bottom = 1L << 34;\n+\n+        public ScenarioBlockLower() {\n+            super(List.of(new Range(bottom, top)));\n+        }\n+\n+        void analyze(OutputAnalyzer oa) {\n+            var range = parseReservedSpaceSpan(oa);\n+            if (range.start < top) {\n+                error(\"Reserved Space Span below reserved range.\");\n+            }\n+        }\n+    }\n+\n+    public static class ScenarioBlockPreferred extends ScenarioBase {\n+        static final long xmx = 1L << 40; \/\/ 1 TB\n+        static final long top = 1L << 48;\n+        static final long bottom = 1L << 42;\n+\n+        public ScenarioBlockPreferred() {\n+            super(List.of(new Range(bottom, top)), xmx);\n+        }\n+\n+        void analyze(OutputAnalyzer oa) {\n+            var range = parseReservedSpaceSpan(oa);\n+            if (range.end >= bottom) {\n+                error(\"Reserved Space Span above reserved range.\");\n+            }\n+            oa.shouldMatch(\"Reserved Space Type: \\\\w+\/\\\\w+\/Degraded\");\n+        }\n+    }\n+\n+    public static void main(String args[]) throws Exception {\n+        var scenarioClass = Class.forName(TestLinuxVirtualAddressSpace.class.getCanonicalName() + \"$\" + args[0]);\n+        var scenario = (ScenarioBase)scenarioClass.getConstructor().newInstance();\n+        scenario.run();\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/z\/TestLinuxVirtualAddressSpace.java","additions":208,"deletions":0,"binary":false,"changes":208,"status":"added"},{"patch":"@@ -0,0 +1,291 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include <dlfcn.h>\n+#include <errno.h>\n+#include <inttypes.h>\n+#include <jni.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+#include <sys\/mman.h>\n+\n+#ifndef MAP_FIXED_NOREPLACE\n+#define MAP_FIXED_NOREPLACE 0x100000\n+#endif\n+\n+#define RESERVE_ALIGNMENT (2 * 1024 * 1024)\n+\n+#define ASSERT_JNI_OK(value)                                                   \\\n+do {                                                                           \\\n+  jint res = (value);                                                          \\\n+  if (res != JNI_OK) {                                                         \\\n+    fprintf(stderr, \"Test Error: \" #value \" failed: %d\\n\", res);               \\\n+    exit(1);                                                                   \\\n+  }                                                                            \\\n+} while (0)\n+#define ASSERT_NOT_NULL(value)                                                 \\\n+do {                                                                           \\\n+  if ((value) == NULL) {                                                       \\\n+    fprintf(stderr, \"Test Error: \" #value \" is NULL\\n\");                       \\\n+    exit(1);                                                                   \\\n+  }                                                                            \\\n+} while (0)\n+#define ASSERT_TRUE(value)                                                     \\\n+do {                                                                           \\\n+  if (!(value)) {                                                              \\\n+    fprintf(stderr, \"Test Error: \" #value \" not TRUE\\n\");                      \\\n+    exit(1);                                                                   \\\n+  }                                                                            \\\n+} while (0)\n+#define ASSERT_ALIGNED(value, alignment)                                       \\\n+do {                                                                           \\\n+  if ((value) % (alignment) != 0) {                                            \\\n+    fprintf(stderr, \"Test Error: \" #value \"[0x%zx] \"                           \\\n+                    \"not aligned to \" #alignment \"[0x%zx]\\n\",                  \\\n+                    (size_t)(value), (size_t)(alignment));                     \\\n+    exit(1);                                                                   \\\n+  }                                                                            \\\n+} while (0)\n+#define ASSERT_POWEROF2(value)                                                 \\\n+do {                                                                           \\\n+  if (((value) & ((value) - 1)) != 0) {                                        \\\n+    fprintf(stderr, \"Test Error: \" #value \"[0x%zx] is not a power of two\\n\",   \\\n+                    (size_t)(value));                                          \\\n+    exit(1);                                                                   \\\n+  }                                                                            \\\n+} while (0)\n+\n+#define OPTION(option) { (char*)option, NULL }\n+#define ARRAY_SIZE(a) sizeof(a)\/sizeof(a[0])\n+\n+#define FALSE 0\n+#define TRUE 1\n+\n+JNIEnv* create_vm(JavaVM **jvm, const char* xmx) {\n+  JNIEnv* env;\n+  JavaVMInitArgs args;\n+  JavaVMOption options[] = {\n+    OPTION(\"-XX:+UseZGC\"),\n+    OPTION(\"-Xlog:gc\"),\n+    OPTION(\"-Xlog:gc+init=trace\"),\n+    OPTION(\"-Xms32m\"),\n+    OPTION(xmx),\n+  };\n+  args.version = JNI_VERSION_1_8;\n+  args.nOptions = ARRAY_SIZE(options);\n+  args.options = options;\n+  args.ignoreUnrecognized = 0;\n+\n+  printf(\"Creating VM\\n\");\n+  fflush(stdout);\n+  ASSERT_JNI_OK(JNI_CreateJavaVM(jvm, (void**)&env, &args));\n+\n+  return env;\n+}\n+\n+\/\/ Simulates java --version\n+void run_jvm(const char* xmx) {\n+  \/\/ Create the vm\n+  JavaVM* jvm;\n+  jclass T_class;\n+  jmethodID test_method;\n+  JNIEnv* env = create_vm(&jvm, xmx);\n+  ASSERT_NOT_NULL(env);\n+\n+  \/\/ Simulate java --version via upcall to java.lang.VersionProps.print(false);\n+\n+  printf(\"Loader lookup\\n\");\n+  fflush(stdout);\n+  \/\/ Find the boot class loader\n+  typedef jclass (JNICALL FindClassFromBootLoader_t(JNIEnv *env, const char *name));\n+  FindClassFromBootLoader_t* find_class_from_boot_loader = (FindClassFromBootLoader_t*)dlsym(RTLD_DEFAULT, \"JVM_FindClassFromBootLoader\");\n+  ASSERT_NOT_NULL(find_class_from_boot_loader);\n+\n+  printf(\"Class lookup\\n\");\n+  fflush(stdout);\n+  \/\/ Lookup the java.lang.VersionProps class\n+  jclass ver = find_class_from_boot_loader(env, \"java\/lang\/VersionProps\");\n+  ASSERT_NOT_NULL(ver);\n+\n+  printf(\"Method lookup\\n\");\n+  fflush(stdout);\n+  \/\/ Lookup the java.lang.VersionProps.print(boolean) method\n+  jmethodID print = (*env)->GetStaticMethodID(env, ver, \"print\", \"(Z)V\");\n+  ASSERT_NOT_NULL(print);\n+\n+  printf(\"Method call\\n\");\n+  fflush(stdout);\n+  \/\/ Call java.lang.VersionProps.print(false);\n+  (*env)->CallStaticVoidMethod(env, ver, print, JNI_FALSE);\n+\n+  printf(\"Destroy VM\\n\");\n+  fflush(stdout);\n+  \/\/ Destroy the VM\n+  ASSERT_JNI_OK((*jvm)->DestroyJavaVM(jvm));\n+}\n+\n+uintptr_t str_to_uintptr_t(const char* str) {\n+  char* _;\n+  errno = 0;\n+  uintptr_t ret = strtoumax(str, &_, 10);\n+  if (errno) {\n+    perror(\"Failed to parse uintptr_t\");\n+    exit(1);\n+  }\n+  return ret;\n+}\n+\n+int try_reservation(void* addr, size_t len) {\n+  fflush(stdout);\n+  errno = 0;\n+\n+  \/\/ We reserve with MAP_FIXED_NOREPLACE in case we run on a kernel where the\n+  \/\/ address hint is not even attempted if it is next to a pre-existsing mapping.\n+  const int flags = MAP_ANONYMOUS | MAP_PRIVATE | MAP_NORESERVE | MAP_FIXED_NOREPLACE;\n+  void* const res = mmap(addr, len, PROT_NONE, flags, -1, 0);\n+\n+  if (res == MAP_FAILED) {\n+    return FALSE;\n+  }\n+\n+  if (res != addr) {\n+    \/\/ We did not get our fixed address, MAP_FIXED_NOREPLACE was ignored\n+    printf(\"MAP_FIXED_NOREPLACE unsupported\\n\");\n+    exit(0);\n+  }\n+\n+   return TRUE;\n+}\n+\n+size_t align_down(size_t value, size_t alignment) {\n+  ASSERT_POWEROF2(alignment);\n+\n+  const size_t alignment_mask = alignment - 1;\n+  const size_t aligned_value = value & ~alignment_mask;\n+\n+  ASSERT_ALIGNED(aligned_value, alignment);\n+  return aligned_value;\n+}\n+\n+size_t align_up(size_t value, size_t alignment) {\n+  return align_down(value + alignment - 1, alignment);\n+}\n+\n+void reserve_address_space_range(uintptr_t start, uintptr_t end) {\n+  ASSERT_TRUE(start < end);\n+\n+  const size_t min_len = RESERVE_ALIGNMENT;\n+\n+  ASSERT_ALIGNED(start, RESERVE_ALIGNMENT);\n+  ASSERT_ALIGNED(end, RESERVE_ALIGNMENT);\n+\n+  void* const addr = (void*)start;\n+  const size_t len = end - start;\n+\n+  if (try_reservation(addr, len)) {\n+    \/\/ Success\n+    printf(\"Reserved range [0x%zx - 0x%zx]\\n\", start, end);\n+  } else if (errno == EEXIST || errno == EINVAL) {\n+    \/\/ We check for alignment and size, assume EINVAL is either a strange\n+    \/\/ os page size or a too extreme address, treat it as if part of the range\n+    \/\/ is unmappable\n+    if (len > min_len) {\n+      \/\/ Divide and conquer\n+      const size_t half_len = align_up(len \/ 2, RESERVE_ALIGNMENT);\n+      const uintptr_t middle = start + half_len;\n+      if (middle != end) {\n+        reserve_address_space_range(start, middle);\n+        reserve_address_space_range(middle, end);\n+      }\n+    }\n+  } else if (errno == ENOMEM) {\n+    printf(\"ENOMEM restriction encountered\\n\");\n+    exit(0);\n+  } else {\n+    perror(\"Unexpected try_reservation error\");\n+    exit(1);\n+  }\n+}\n+\n+void reserve_address_space(int argc, const char** argv) {\n+  \/\/ We need to be careful to not reserve to close to the thread stack, as the\n+  \/\/ JVM will page fault in the stack space. If we have reserved that space as\n+  \/\/ prot none the kernel will not expand the stack but rather send a SIGSEGV.\n+  const size_t stack_headroom = 2 * RESERVE_ALIGNMENT;\n+  uintptr_t stack_top;\n+  stack_top = align_up((uintptr_t)&stack_top, RESERVE_ALIGNMENT);\n+  const uintptr_t stack_bottom = stack_top - stack_headroom;\n+\n+  for (int i = 2; i < argc; i += 2) {\n+    printf(\"Got range [%s - %s]\\n\", argv[i-1], argv[i]);\n+\n+    const uintptr_t start = str_to_uintptr_t(argv[i-1]);\n+    const uintptr_t end = str_to_uintptr_t(argv[i]);\n+\n+    ASSERT_TRUE(start < end);\n+\n+    if (start >= stack_top || end <= stack_bottom) {\n+      \/\/ No interference with thread stack\n+      reserve_address_space_range(start, end);\n+      continue;\n+    }\n+\n+    printf(\"Interference with stack [0x%zx - 0x%zx]\\n\", stack_bottom, stack_top);\n+\n+    if (start < stack_bottom) {\n+      \/\/ Reservation range below the stack\n+      reserve_address_space_range(start, stack_bottom);\n+    }\n+\n+    if (end > stack_top) {\n+      \/\/ Reservation range above the stack\n+      reserve_address_space_range(stack_top, end);\n+    }\n+  }\n+}\n+\n+int main(int argc, const char** argv) {\n+  printf(\"Started\\n\");\n+\n+  \/\/ Parse potential -Xmx option\n+  const char* xmx = \"-Xmx128m\";\n+  if (argc > 1 && strncmp(argv[1], \"-Xmx\", 4) == 0) {\n+    xmx = argv[1];\n+    argc--;\n+    argv++;\n+  }\n+  printf(\"Size flag: %s\\n\", xmx);\n+\n+  \/\/ Pre-reserve address space\n+  printf(\"Reserving\\n\");\n+  reserve_address_space(argc, argv);\n+\n+  \/\/ Invoke a new JVM\n+  printf(\"Running\\n\");\n+  fflush(stdout);\n+  run_jvm(xmx);\n+\n+  return 0;\n+}\n","filename":"test\/hotspot\/jtreg\/gc\/z\/exegc_z_TestLinuxVirtualAddressSpace.c","additions":291,"deletions":0,"binary":false,"changes":291,"status":"added"}]}