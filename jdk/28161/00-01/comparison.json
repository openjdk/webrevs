{"files":[{"patch":"@@ -33,1 +33,1 @@\n-void ZVirtualMemoryReserver::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n+void ZVirtualMemoryReservation::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n@@ -37,1 +37,1 @@\n-bool ZVirtualMemoryReserver::pd_reserve(zaddress_unsafe addr, size_t size) {\n+bool ZVirtualMemoryReserver::pd_reserve(uintptr_t addr, size_t size) {\n@@ -40,1 +40,1 @@\n-  void* const res = mmap((void*)untype(addr), size, PROT_NONE, flags, -1, 0);\n+  void* const res = mmap((void*)addr, size, PROT_NONE, flags, -1, 0);\n@@ -46,1 +46,1 @@\n-  if (res != (void*)untype(addr)) {\n+  if (res != (void*)addr) {\n@@ -56,2 +56,6 @@\n-void ZVirtualMemoryReserver::pd_unreserve(zaddress_unsafe addr, size_t size) {\n-  const int res = munmap((void*)untype(addr), size);\n+void ZVirtualMemoryReserver::pd_split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  \/\/ Does nothing\n+}\n+\n+void ZVirtualMemoryReserver::pd_unreserve(uintptr_t addr, size_t size) {\n+  const int res = munmap((void*)addr, size);\n","filename":"src\/hotspot\/os\/posix\/gc\/z\/zVirtualMemoryManager_posix.cpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-zaddress_unsafe ZMapper::reserve(zaddress_unsafe addr, size_t size) {\n+uintptr_t ZMapper::reserve(uintptr_t addr, size_t size) {\n@@ -65,1 +65,1 @@\n-    (void*)untype(addr),                   \/\/ BaseAddress\n+    (void*)addr,                           \/\/ BaseAddress\n@@ -74,1 +74,1 @@\n-  return to_zaddress_unsafe((uintptr_t)res);\n+  return (uintptr_t)res;\n@@ -77,1 +77,1 @@\n-void ZMapper::unreserve(zaddress_unsafe addr, size_t size) {\n+void ZMapper::unreserve(uintptr_t addr, size_t size) {\n@@ -80,1 +80,1 @@\n-    (void*)untype(addr), \/\/ lpAddress\n+    (void*)addr,         \/\/ lpAddress\n@@ -86,1 +86,1 @@\n-    fatal_error(\"Failed to unreserve memory\", untype(addr), size);\n+    fatal_error(\"Failed to unreserve memory\", addr, size);\n@@ -226,1 +226,1 @@\n-zaddress_unsafe ZMapper::reserve_for_shared_awe(HANDLE awe_section, zaddress_unsafe addr, size_t size) {\n+uintptr_t ZMapper::reserve_for_shared_awe(HANDLE awe_section, uintptr_t addr, size_t size) {\n@@ -233,1 +233,1 @@\n-    (void*)untype(addr),        \/\/ BaseAddress\n+    (void*)addr,                \/\/ BaseAddress\n@@ -242,1 +242,1 @@\n-  return to_zaddress_unsafe((uintptr_t)res);\n+  return (uintptr_t)res;\n@@ -245,1 +245,1 @@\n-void ZMapper::unreserve_for_shared_awe(zaddress_unsafe addr, size_t size) {\n+void ZMapper::unreserve_for_shared_awe(uintptr_t addr, size_t size) {\n@@ -247,3 +247,3 @@\n-    (void*)untype(addr), \/\/ lpAddress\n-    0,                   \/\/ dwSize\n-    MEM_RELEASE          \/\/ dwFreeType\n+    (void*)addr, \/\/ lpAddress\n+    0,           \/\/ dwSize\n+    MEM_RELEASE  \/\/ dwFreeType\n@@ -254,1 +254,1 @@\n-          untype(addr), size \/ M, GetLastError());\n+          addr, size \/ M, GetLastError());\n@@ -259,0 +259,4 @@\n+  split_placeholder_untyped(untype(addr), size);\n+}\n+\n+void ZMapper::split_placeholder_untyped(uintptr_t addr, size_t size) {\n@@ -260,1 +264,1 @@\n-    (void*)untype(addr),                   \/\/ lpAddress\n+    (void*)addr,                           \/\/ lpAddress\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zMapper_windows.cpp","additions":19,"deletions":15,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-  static zaddress_unsafe reserve(zaddress_unsafe addr, size_t size);\n+  static uintptr_t reserve(uintptr_t addr, size_t size);\n@@ -55,1 +55,1 @@\n-  static void unreserve(zaddress_unsafe addr, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n@@ -67,1 +67,1 @@\n-  static zaddress_unsafe reserve_for_shared_awe(HANDLE awe_section, zaddress_unsafe addr, size_t size);\n+  static uintptr_t reserve_for_shared_awe(HANDLE awe_section, uintptr_t addr, size_t size);\n@@ -70,1 +70,1 @@\n-  static void unreserve_for_shared_awe(zaddress_unsafe addr, size_t size);\n+  static void unreserve_for_shared_awe(uintptr_t addr, size_t size);\n@@ -79,0 +79,1 @@\n+  static void split_placeholder_untyped(uintptr_t addr, size_t size);\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zMapper_windows.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -38,2 +38,3 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) = 0;\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) = 0;\n+  virtual bool reserve(uintptr_t addr, size_t size) = 0;\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t size) = 0;\n+  virtual void unreserve(uintptr_t addr, size_t size) = 0;\n@@ -172,2 +173,2 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) {\n-    const zaddress_unsafe res = ZMapper::reserve(addr, size);\n+  virtual bool reserve(uintptr_t addr, size_t size) {\n+    const uintptr_t res = ZMapper::reserve(addr, size);\n@@ -175,1 +176,1 @@\n-    assert(res == addr || untype(res) == 0, \"Should not reserve other memory than requested\");\n+    assert(res == addr || res == 0, \"Should not reserve other memory than requested\");\n@@ -179,1 +180,5 @@\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) {\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t \/* size - unused *\/) {\n+    ZMapper::split_placeholder_untyped(addr, split_size);\n+  }\n+\n+  virtual void unreserve(uintptr_t addr, size_t size) {\n@@ -191,2 +196,2 @@\n-  virtual bool reserve(zaddress_unsafe addr, size_t size) {\n-    const zaddress_unsafe res = ZMapper::reserve_for_shared_awe(ZAWESection, addr, size);\n+  virtual bool reserve(uintptr_t addr, size_t size) {\n+    const uintptr_t res = ZMapper::reserve_for_shared_awe(ZAWESection, addr, size);\n@@ -194,1 +199,1 @@\n-    assert(res == addr || untype(res) == 0, \"Should not reserve other memory than requested\");\n+    assert(res == addr || res == 0, \"Should not reserve other memory than requested\");\n@@ -198,1 +203,5 @@\n-  virtual void unreserve(zaddress_unsafe addr, size_t size) {\n+  virtual void split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+    \/\/ Does nothing\n+  }\n+\n+  virtual void unreserve(uintptr_t addr, size_t size) {\n@@ -220,1 +229,1 @@\n-void ZVirtualMemoryReserver::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n+void ZVirtualMemoryReservation::pd_register_callbacks(ZVirtualMemoryRegistry* registry) {\n@@ -224,1 +233,1 @@\n-bool ZVirtualMemoryReserver::pd_reserve(zaddress_unsafe addr, size_t size) {\n+bool ZVirtualMemoryReserver::pd_reserve(uintptr_t addr, size_t size) {\n@@ -228,1 +237,5 @@\n-void ZVirtualMemoryReserver::pd_unreserve(zaddress_unsafe addr, size_t size) {\n+void ZVirtualMemoryReserver::pd_split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  return _impl->split_reserved(addr, split_size, size);\n+}\n+\n+void ZVirtualMemoryReserver::pd_unreserve(uintptr_t addr, size_t size) {\n","filename":"src\/hotspot\/os\/windows\/gc\/z\/zVirtualMemoryManager_windows.cpp","additions":26,"deletions":13,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -133,1 +133,2 @@\n-  declare_constant(ZAddressOffsetMax)\n+  declare_constant(ZAddressOffsetMax)                                                                \\\n+  declare_constant(ZAddressOffsetUpperLimit)\n","filename":"src\/hotspot\/share\/gc\/z\/vmStructs_z.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/z\/zOnError.hpp\"\n@@ -45,0 +46,1 @@\n+size_t     ZAddressOffsetUpperLimit;\n@@ -111,5 +113,2 @@\n-void ZGlobalsPointers::set_heap_base(size_t heap_base_shift) {\n-  assert(heap_base_shift <= ZAddressHeapBaseMaxShift, \"Heap base shift to large\");\n-  assert(heap_base_shift <= ZAddressPlatformHeapBaseMaxShift, \"Heap base shift to large\");\n-  assert(heap_base_shift >= ZAddressHeapBaseMinShift, \"Heap base shift to small\");\n-  assert(heap_base_shift >= ZAddressMaxHeapRequiredHeapBaseShift, \"Heap base shift to small\");\n+void ZGlobalsPointers::set_heap_limits(uintptr_t heap_base, uintptr_t heap_upper_limit) {\n+  log_trace(gc, init)(\"Set Heap Base: \" PTR_FORMAT, heap_base);\n@@ -118,2 +117,5 @@\n-  ZAddressHeapBaseShift = heap_base_shift;\n-  ZAddressHeapBase = (uintptr_t)1 << ZAddressHeapBaseShift;\n+  ZAddressHeapBase = heap_base;\n+  ZAddressHeapBaseShift = (size_t)log2i_exact(heap_base);\n+\n+  z_on_error_capture_64_5(ZAddressHeapBaseShift, ZAddressHeapBaseMaxShift, ZAddressPlatformHeapBaseMaxShift,\n+                          ZAddressHeapBaseMinShift, ZAddressMaxHeapRequiredHeapBaseShift);\n@@ -121,1 +123,1 @@\n-  log_trace(gc, init)(\"Set Heap Base: \" PTR_FORMAT, ZAddressHeapBase);\n+  validate_heap_base_shift(ZAddressHeapBaseShift);\n@@ -127,0 +129,9 @@\n+  ZAddressOffsetUpperLimit = heap_upper_limit - heap_base;\n+\n+  {\n+    z_on_error_capture_64_3(ZAddressHeapBase, ZAddressOffsetMax, ZAddressOffsetUpperLimit);\n+\n+    assert(ZAddressOffsetUpperLimit <= ZAddressOffsetMax,\n+        \"Unexpected ZAddressOffsetUpperLimit: \" PTR_FORMAT \" ZAddressOffsetMax: \" PTR_FORMAT,\n+        ZAddressOffsetUpperLimit, ZAddressOffsetMax);\n+  }\n@@ -156,1 +167,0 @@\n-  set_heap_base(ZAddressInitialHeapBaseShift);\n@@ -170,1 +180,14 @@\n-bool ZGlobalsPointers::set_next_heap_base() {\n+void ZGlobalsPointers::validate_heap_base_shift(size_t heap_base_shift) {\n+  assert(heap_base_shift <= ZAddressHeapBaseMaxShift, \"Heap base shift to large\");\n+  assert(heap_base_shift <= ZAddressPlatformHeapBaseMaxShift, \"Heap base shift to large\");\n+  assert(heap_base_shift >= ZAddressHeapBaseMinShift, \"Heap base shift to small\");\n+  assert(heap_base_shift >= ZAddressMaxHeapRequiredHeapBaseShift, \"Heap base shift to small\");\n+}\n+\n+size_t ZGlobalsPointers::initial_heap_base_shift() {\n+  return ZAddressInitialHeapBaseShift;\n+}\n+\n+size_t ZGlobalsPointers::next_heap_base_shift(size_t heap_base_shift) {\n+  validate_heap_base_shift(heap_base_shift);\n+\n@@ -173,1 +196,1 @@\n-  const size_t next_heap_base_shift = ZAddressHeapBaseShift == min_heap_base_shift\n+  const size_t next_heap_base_shift = heap_base_shift == min_heap_base_shift\n@@ -175,1 +198,1 @@\n-      : ZAddressHeapBaseShift - 1;\n+      : heap_base_shift - 1;\n@@ -177,2 +200,1 @@\n-  \/\/ Set next heap base\n-  set_heap_base(next_heap_base_shift);\n+  validate_heap_base_shift(next_heap_base_shift);\n@@ -180,2 +202,1 @@\n-  \/\/ Signal if we have reached the inital heap base\n-  return next_heap_base_shift != ZAddressInitialHeapBaseShift;\n+  return next_heap_base_shift;\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.cpp","additions":37,"deletions":16,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-\/\/ Describes the maximal offset inside the heap.\n+\/\/ Describes the offset inside the heap.\n@@ -53,0 +53,2 @@\n+\n+\/\/ Describes the computational max offset inside the heap.\n@@ -55,0 +57,3 @@\n+\/\/ Describes the reserved upper limit for offset inside the heap.\n+extern size_t    ZAddressOffsetUpperLimit;\n+\n@@ -333,1 +338,0 @@\n-  static void set_heap_base(size_t heap_base_shift);\n@@ -337,1 +341,6 @@\n-  static bool set_next_heap_base();\n+\n+  static void set_heap_limits(uintptr_t heap_base, uintptr_t heap_upper_limit);\n+\n+  static size_t initial_heap_base_shift();\n+  static size_t next_heap_base_shift(size_t heap_base_shift);\n+  static void validate_heap_base_shift(size_t heap_base_shift);\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.hpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -151,1 +151,1 @@\n-  assert(value < ZAddressOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZAddressOffsetUpperLimit, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -157,1 +157,1 @@\n-  assert(value <= ZAddressOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -162,1 +162,1 @@\n-  assert(value < ZAddressOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZAddressOffsetUpperLimit, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -173,1 +173,1 @@\n-  if (value <= ZAddressOffsetMax) {\n+  if (value <= ZAddressOffsetUpperLimit) {\n@@ -182,2 +182,2 @@\n-  assert(value <= ZAddressOffsetMax, \"Overflow start: \" PTR_FORMAT \" size: \" PTR_FORMAT \" value: \" PTR_FORMAT,\n-                                     untype(start), size, value);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Overflow start: \" PTR_FORMAT \" size: \" PTR_FORMAT \" value: \" PTR_FORMAT,\n+                                            untype(start), size, value);\n@@ -188,1 +188,1 @@\n-  assert(value <= ZAddressOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZAddressOffsetUpperLimit, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetUpperLimit);\n@@ -202,1 +202,1 @@\n-  assert(value < ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -208,1 +208,1 @@\n-  assert(value <= ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZBackingOffsetMax, \"Offset out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -213,1 +213,1 @@\n-  assert(value < ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value < ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" < \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -230,1 +230,1 @@\n-  assert(value <= ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZAddressOffsetMax);\n+  assert(value <= ZBackingOffsetMax, \"Value out of bounds (\" PTR_FORMAT \" <= \" PTR_FORMAT \")\", value, ZBackingOffsetMax);\n@@ -456,1 +456,1 @@\n-  if (value >= (ZAddressHeapBase + ZAddressOffsetMax)) {\n+  if (value >= (ZAddressHeapBase + ZAddressOffsetUpperLimit)) {\n","filename":"src\/hotspot\/share\/gc\/z\/zAddress.inline.hpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -171,7 +171,8 @@\n-    printf \"     Young Phase:       %u\\n\", ZHeap::_heap->_young->_phase\n-    printf \"     Old Phase:         %u\\n\", ZHeap::_heap->_old->_phase\n-    printf \"     Young SeqNum:      %u\\n\", ZHeap::_heap->_young->_seqnum\n-    printf \"     Old SeqNum:        %u\\n\", ZHeap::_heap->_old->_seqnum\n-    printf \"     Offset Max:        %-15llu (0x%llx)\\n\", ZAddressOffsetMax, ZAddressOffsetMax\n-    printf \"     Page Size Small:   %-15llu (0x%llx)\\n\", ZPageSizeSmall, ZPageSizeSmall\n-    printf \"     Page Size Medium:  %-15llu (0x%llx)\\n\", ZPageSizeMedium, ZPageSizeMedium\n+    printf \"     Young Phase:        %u\\n\", ZHeap::_heap->_young->_phase\n+    printf \"     Old Phase:          %u\\n\", ZHeap::_heap->_old->_phase\n+    printf \"     Young SeqNum:       %u\\n\", ZHeap::_heap->_young->_seqnum\n+    printf \"     Old SeqNum:         %u\\n\", ZHeap::_heap->_old->_seqnum\n+    printf \"     Offset Max:         %-15llu (0x%llx)\\n\", ZAddressOffsetMax, ZAddressOffsetMax\n+    printf \"     Offset Upper Limit: %-15llu (0x%llx)\\n\", ZAddressOffsetUpperLimit, ZAddressOffsetUpperLimit\n+    printf \"     Page Size Small:    %-15llu (0x%llx)\\n\", ZPageSizeSmall, ZPageSizeSmall\n+    printf \"     Page Size Medium:   %-15llu (0x%llx)\\n\", ZPageSizeMedium, ZPageSizeMedium\n@@ -179,5 +180,5 @@\n-    printf \"     Good:              0x%016llx\\n\", ZPointerStoreGoodMask\n-    printf \"     Bad:               0x%016llx\\n\", ZPointerStoreBadMask\n-    printf \"     MarkedYoung:       0x%016llx\\n\", ZPointerMarkedYoung\n-    printf \"     MarkedOld:         0x%016llx\\n\", ZPointerMarkedOld\n-    printf \"     Remapped:          0x%016llx\\n\", ZPointerRemapped\n+    printf \"     Good:               0x%016llx\\n\", ZPointerStoreGoodMask\n+    printf \"     Bad:                0x%016llx\\n\", ZPointerStoreBadMask\n+    printf \"     MarkedYoung:        0x%016llx\\n\", ZPointerMarkedYoung\n+    printf \"     MarkedOld:          0x%016llx\\n\", ZPointerMarkedOld\n+    printf \"     Remapped:           0x%016llx\\n\", ZPointerRemapped\n","filename":"src\/hotspot\/share\/gc\/z\/zDebug.gdb","additions":13,"deletions":12,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-  : _map(ZAddressOffsetMax) {}\n+  : _map(ZAddressOffsetUpperLimit) {}\n","filename":"src\/hotspot\/share\/gc\/z\/zForwardingTable.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -383,0 +383,1 @@\n+  st->print_cr(\" Offset Upper Limit: \" EXACTFMT \" (\" PTR_FORMAT \")\", EXACTFMTARGS(ZAddressOffsetUpperLimit), ZAddressOffsetUpperLimit);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -259,1 +259,1 @@\n-    _bitmaps(ZAddressOffsetMax),\n+    _bitmaps(ZAddressOffsetUpperLimit),\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,2 +38,2 @@\n-void ZNMT::reserve(zaddress_unsafe start, size_t size) {\n-  MemTracker::record_virtual_memory_reserve((address)untype(start), size, CALLER_PC, mtJavaHeap);\n+void ZNMT::reserve(uintptr_t addr, size_t size) {\n+  MemTracker::record_virtual_memory_reserve((address)addr, size, CALLER_PC, mtJavaHeap);\n@@ -42,2 +42,2 @@\n-void ZNMT::unreserve(zaddress_unsafe start, size_t size) {\n-  precond(is_aligned(untype(start), ZGranuleSize));\n+void ZNMT::unreserve(uintptr_t addr, size_t size) {\n+  precond(is_aligned(addr, ZGranuleSize));\n@@ -57,1 +57,1 @@\n-      MemTracker::record_virtual_memory_release((address)untype(start + i), ZGranuleSize);\n+      MemTracker::record_virtual_memory_release((address)(addr + i), ZGranuleSize);\n","filename":"src\/hotspot\/share\/gc\/z\/zNMT.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -41,2 +41,2 @@\n-  static void reserve(zaddress_unsafe start, size_t size);\n-  static void unreserve(zaddress_unsafe start, size_t size);\n+  static void reserve(uintptr_t addr, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n","filename":"src\/hotspot\/share\/gc\/z\/zNMT.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,71 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef SHARE_GC_Z_ZONERROR_HPP\n+#define SHARE_GC_Z_ZONERROR_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/vmError.hpp\"\n+\n+#define z_expand_64_1(first)      uint64_t(first)\n+#define z_expand_64_2(first, ...) z_expand_64_1(first), z_expand_64_1(__VA_ARGS__)\n+#define z_expand_64_3(first, ...) z_expand_64_1(first), z_expand_64_2(__VA_ARGS__)\n+#define z_expand_64_4(first, ...) z_expand_64_1(first), z_expand_64_3(__VA_ARGS__)\n+#define z_expand_64_5(first, ...) z_expand_64_1(first), z_expand_64_4(__VA_ARGS__)\n+#define z_expand_64_6(first, ...) z_expand_64_1(first), z_expand_64_5(__VA_ARGS__)\n+\n+#define z_expand_format_64_1(first)      #first \": \" UINT64_FORMAT_X \" \"\n+#define z_expand_format_64_2(first, ...) z_expand_format_64_1(first) z_expand_format_64_1(__VA_ARGS__)\n+#define z_expand_format_64_3(first, ...) z_expand_format_64_1(first) z_expand_format_64_2(__VA_ARGS__)\n+#define z_expand_format_64_4(first, ...) z_expand_format_64_1(first) z_expand_format_64_3(__VA_ARGS__)\n+#define z_expand_format_64_5(first, ...) z_expand_format_64_1(first) z_expand_format_64_4(__VA_ARGS__)\n+#define z_expand_format_64_6(first, ...) z_expand_format_64_1(first) z_expand_format_64_5(__VA_ARGS__)\n+\n+#define z_on_error_capture_64(N, ...)                  \\\n+  OnVMError on_error([&](outputStream* st) {           \\\n+    st->print(\"Captured: \"                             \\\n+              z_expand_format_64_##N(__VA_ARGS__),     \\\n+              z_expand_64_##N(__VA_ARGS__));           \\\n+  })\n+\n+#define z_on_error_capture_64_1(...) z_on_error_capture_64(1, __VA_ARGS__)\n+#define z_on_error_capture_64_2(...) z_on_error_capture_64(2, __VA_ARGS__)\n+#define z_on_error_capture_64_3(...) z_on_error_capture_64(3, __VA_ARGS__)\n+#define z_on_error_capture_64_4(...) z_on_error_capture_64(4, __VA_ARGS__)\n+#define z_on_error_capture_64_5(...) z_on_error_capture_64(5, __VA_ARGS__)\n+#define z_on_error_capture_64_6(...) z_on_error_capture_64(6, __VA_ARGS__)\n+\n+#ifdef ASSERT\n+#define z_assert_capture_64(N, ...) z_on_error_capture_64(N, __VA_ARGS__)\n+#else\n+#define z_assert_capture_64(N, ...)\n+#endif\n+\n+#define z_assert_capture_64_1(...) z_assert_capture_64(1, __VA_ARGS__)\n+#define z_assert_capture_64_2(...) z_assert_capture_64(2, __VA_ARGS__)\n+#define z_assert_capture_64_3(...) z_assert_capture_64(3, __VA_ARGS__)\n+#define z_assert_capture_64_4(...) z_assert_capture_64(4, __VA_ARGS__)\n+#define z_assert_capture_64_5(...) z_assert_capture_64(5, __VA_ARGS__)\n+#define z_assert_capture_64_6(...) z_assert_capture_64(6, __VA_ARGS__)\n+\n+#endif \/\/ SHARE_GC_Z_ZONERROR_HPP\n","filename":"src\/hotspot\/share\/gc\/z\/zOnError.hpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"added"},{"patch":"@@ -32,3 +32,3 @@\n-static size_t get_max_offset_for_map() {\n-  \/\/ The page table has (ZAddressOffsetMax >> ZGranuleSizeShift) slots\n-  const size_t max_count = ZAddressOffsetMax >> ZGranuleSizeShift;\n+static size_t get_offset_upper_limit_for_map() {\n+  \/\/ The page table has (ZAddressOffsetUpperLimit >> ZGranuleSizeShift) slots\n+  const size_t max_count = ZAddressOffsetUpperLimit >> ZGranuleSizeShift;\n@@ -41,1 +41,1 @@\n-  : _map(get_max_offset_for_map()) {}\n+  : _map(get_offset_upper_limit_for_map()) {}\n","filename":"src\/hotspot\/share\/gc\/z\/zPageTable.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-    _physical_mappings(ZAddressOffsetMax) {\n+    _physical_mappings(ZAddressOffsetUpperLimit) {\n","filename":"src\/hotspot\/share\/gc\/z\/zPhysicalMemoryManager.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -112,0 +112,3 @@\n+\n+  template <typename Function>\n+  void visit_all(Function function) const;\n","filename":"src\/hotspot\/share\/gc\/z\/zRangeRegistry.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -470,0 +470,11 @@\n+template <typename Range>\n+template <typename Function>\n+void ZRangeRegistry<Range>::visit_all(Function function) const {\n+  ZLocker<ZLock> locker(&_lock);\n+\n+  ZListIterator<Node> iter(&_list);\n+  for (Node* node; iter.next(&node);) {\n+    function(node->range());\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zRangeRegistry.inline.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -351,2 +351,2 @@\n-  : _allocated_bitmap_0{ZAddressOffsetMax >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n-    _allocated_bitmap_1{ZAddressOffsetMax >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n+  : _allocated_bitmap_0{ZAddressOffsetUpperLimit >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n+    _allocated_bitmap_1{ZAddressOffsetUpperLimit >> ZGranuleSizeShift, mtGC, true \/* clear *\/},\n","filename":"src\/hotspot\/share\/gc\/z\/zRemembered.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -40,0 +40,5 @@\n+struct ZVirtualMemoryUntyped {\n+  uintptr_t _start;\n+  size_t    _size;\n+};\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemory.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/z\/zOnError.hpp\"\n@@ -40,1 +41,2 @@\n-#include <cstdint>\n+bool ZVirtualMemoryReserver::reserve(uintptr_t addr, size_t size) {\n+  log_debug(gc, init)(\"ZGC reserve:   [\" PTR_FORMAT \" - \" PTR_FORMAT \")\", addr, addr + size);\n@@ -42,9 +44,4 @@\n-ZVirtualMemoryReserver::ZVirtualMemoryReserver(size_t size)\n-  : ZVirtualMemoryReserver(size, size) {}\n-\n-ZVirtualMemoryReserver::ZVirtualMemoryReserver(size_t required_size, size_t desired_size)\n-  : _registry(),\n-    _reserved(reserve(required_size, desired_size)) {}\n-\n-void ZVirtualMemoryReserver::initialize_partition_registry(ZVirtualMemoryRegistry* partition_registry, size_t size) {\n-  assert(partition_registry->is_empty(), \"Should be empty when initializing\");\n+  \/\/ Reserve address space\n+  if (!pd_reserve(addr, size)) {\n+    return false;\n+  }\n@@ -52,2 +49,2 @@\n-  \/\/ Registers the Windows callbacks\n-  pd_register_callbacks(partition_registry);\n+  \/\/ Register address views with native memory tracker\n+  ZNMT::reserve(addr, size);\n@@ -55,1 +52,2 @@\n-  _registry.transfer_from_low(partition_registry, size);\n+  return true;\n+}\n@@ -57,2 +55,2 @@\n-  \/\/ Set the limits according to the virtual memory given to this partition\n-  partition_registry->anchor_limits();\n+void ZVirtualMemoryReserver::split_reserved(uintptr_t addr, size_t split_size, size_t size) {\n+  pd_split_reserved(addr, split_size, size);\n@@ -61,2 +59,2 @@\n-void ZVirtualMemoryReserver::unreserve(const ZVirtualMemory& vmem) {\n-  const zaddress_unsafe addr = ZOffset::address_unsafe(vmem.start());\n+void ZVirtualMemoryReserver::unreserve(uintptr_t addr, size_t size) {\n+  log_debug(gc, init)(\"ZGC unreserve: [\" PTR_FORMAT \" - \" PTR_FORMAT \")\", addr, addr + size);\n@@ -65,1 +63,1 @@\n-  ZNMT::unreserve(addr, vmem.size());\n+  ZNMT::unreserve(addr, size);\n@@ -68,1 +66,1 @@\n-  pd_unreserve(addr, vmem.size());\n+  pd_unreserve(addr, size);\n@@ -71,7 +69,6 @@\n-size_t ZVirtualMemoryReserver::unreserve_all() {\n-  size_t unreserved = 0;\n-  for (ZVirtualMemory vmem; _registry.unregister_first(&vmem);) {\n-    unreserve(vmem);\n-    unreserved += vmem.size();\n-  }\n-  return unreserved;\n+ZVirtualMemoryWithHeapBaseReserver::ZVirtualMemoryWithHeapBaseReserver(size_t heap_base)\n+  : _heap_base(heap_base),\n+    _reserved_ranges() {}\n+\n+ZVirtualMemoryWithHeapBaseReserver::~ZVirtualMemoryWithHeapBaseReserver() {\n+  unreserve_all();\n@@ -80,2 +77,2 @@\n-bool ZVirtualMemoryReserver::is_empty() const {\n-  return _registry.is_empty();\n+uintptr_t ZVirtualMemoryWithHeapBaseReserver::heap_base() const {\n+  return _heap_base;\n@@ -84,2 +81,4 @@\n-bool ZVirtualMemoryReserver::is_contiguous() const {\n-  return _registry.is_contiguous();\n+size_t ZVirtualMemoryWithHeapBaseReserver::offset_max() const {\n+  \/\/ We currently have a restriction that the offsets don't overflow the heap base bit,\n+  \/\/ this limits the offset bits to be equal to the heap base.\n+  return (size_t)_heap_base;\n@@ -88,2 +87,19 @@\n-size_t ZVirtualMemoryReserver::reserved() const {\n-  return _reserved;\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve(size_t size) {\n+  if (offset_max() < size) {\n+    \/\/ Only attempt to reserve if the current heap base can accommodate the desired size\n+    return 0;\n+  }\n+\n+#ifdef ASSERT\n+  if (ZForceDiscontiguousHeapReservations > 0) {\n+    return force_reserve_discontiguous(size);\n+  }\n+#endif\n+\n+  \/\/ Prefer a contiguous address space\n+  if (reserve_contiguous(size)) {\n+    return size;\n+  }\n+\n+  \/\/ Fall back to a discontiguous address space\n+  return reserve_discontiguous(size);\n@@ -92,2 +108,17 @@\n-zoffset_end ZVirtualMemoryReserver::highest_available_address_end() const {\n-  return _registry.peak_high_address_end();\n+\n+void ZVirtualMemoryWithHeapBaseReserver::transfer_reserved_ranges_to(ZArray<ZVirtualMemoryUntyped>* to) {\n+  to->appendAll(&_reserved_ranges);\n+  _reserved_ranges.clear();\n+}\n+\n+size_t ZVirtualMemoryWithHeapBaseReserver::unreserve_all() {\n+  size_t unreserved = 0;\n+\n+  for (ZVirtualMemoryUntyped range : _reserved_ranges) {\n+    ZVirtualMemoryReserver::unreserve(range._start, range._size);\n+    unreserved += range._size;\n+  }\n+\n+  _reserved_ranges.clear();\n+\n+  return unreserved;\n@@ -97,1 +128,1 @@\n-size_t ZVirtualMemoryReserver::force_reserve_discontiguous(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::force_reserve_discontiguous(size_t size) {\n@@ -104,1 +135,1 @@\n-  uintptr_t end = ZAddressOffsetMax;\n+  size_t end = offset_max();\n@@ -108,1 +139,2 @@\n-    const uintptr_t reserve_start = end - reserve_size;\n+    const size_t reserve_start = end - reserve_size;\n+    const uintptr_t addr = _heap_base + reserve_start;\n@@ -110,1 +142,1 @@\n-    if (reserve_contiguous(to_zoffset(reserve_start), reserve_size)) {\n+    if (reserve_contiguous(addr, reserve_size)) {\n@@ -120,3 +152,4 @@\n-  while (reserved < size && start < ZAddressOffsetMax) {\n-    const size_t remaining = MIN2(size - reserved, ZAddressOffsetMax - start);\n-    reserved += reserve_discontiguous(to_zoffset(start), remaining, min_range);\n+  while (reserved < size && start < offset_max()) {\n+    const size_t remaining = MIN2(size - reserved, offset_max() - start);\n+    const uintptr_t addr = _heap_base + start;\n+    reserved += reserve_discontiguous(addr, remaining, min_range);\n@@ -130,1 +163,1 @@\n-size_t ZVirtualMemoryReserver::reserve_discontiguous(zoffset start, size_t size, size_t min_range) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve_discontiguous(uintptr_t addr, size_t size, size_t min_range) {\n@@ -138,1 +171,1 @@\n-  if (reserve_contiguous(start, size)) {\n+  if (reserve_contiguous(addr, size)) {\n@@ -151,2 +184,2 @@\n-  const size_t first_size = reserve_discontiguous(start, first_part, min_range);\n-  const size_t second_size = reserve_discontiguous(start + first_part, second_part, min_range);\n+  const size_t first_size = reserve_discontiguous(addr, first_part, min_range);\n+  const size_t second_size = reserve_discontiguous(addr + first_part, second_part, min_range);\n@@ -156,1 +189,1 @@\n-size_t ZVirtualMemoryReserver::calculate_min_range(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::calculate_min_range(size_t size) {\n@@ -163,1 +196,1 @@\n-size_t ZVirtualMemoryReserver::reserve_discontiguous(size_t size) {\n+size_t ZVirtualMemoryWithHeapBaseReserver::reserve_discontiguous(size_t size) {\n@@ -168,4 +201,5 @@\n-  \/\/ Reserve size somewhere between [0, ZAddressOffsetMax)\n-  while (reserved < size && start < ZAddressOffsetMax) {\n-    const size_t remaining = MIN2(size - reserved, ZAddressOffsetMax - start);\n-    reserved += reserve_discontiguous(to_zoffset(start), remaining, min_range);\n+  \/\/ Reserve size somewhere between [0, offset_max())\n+  while (reserved < size && start < offset_max()) {\n+    const size_t remaining = MIN2(size - reserved, offset_max() - start);\n+    const uintptr_t addr = _heap_base + start;\n+    reserved += reserve_discontiguous(addr, remaining, min_range);\n@@ -178,1 +212,1 @@\n-bool ZVirtualMemoryReserver::reserve_contiguous(zoffset start, size_t size) {\n+bool ZVirtualMemoryWithHeapBaseReserver::reserve_contiguous(uintptr_t addr, size_t size) {\n@@ -180,0 +214,3 @@\n+  assert(addr >= _heap_base && addr < _heap_base + offset_max(),\n+         PTR_FORMAT \" not within [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n+         addr, _heap_base, _heap_base + offset_max());\n@@ -181,5 +218,1 @@\n-  \/\/ Reserve address views\n-  const zaddress_unsafe addr = ZOffset::address_unsafe(start);\n-\n-  \/\/ Reserve address space\n-  if (!pd_reserve(addr, size)) {\n+  if (!ZVirtualMemoryReserver::reserve(addr, size)) {\n@@ -189,3 +222,0 @@\n-  \/\/ Register address views with native memory tracker\n-  ZNMT::reserve(addr, size);\n-\n@@ -193,1 +223,1 @@\n-  _registry.register_range({start, size});\n+  _reserved_ranges.append({addr, size});\n@@ -198,3 +228,3 @@\n-bool ZVirtualMemoryReserver::reserve_contiguous(size_t size) {\n-  \/\/ Allow at most 8192 attempts spread evenly across [0, ZAddressOffsetMax)\n-  const size_t unused = ZAddressOffsetMax - size;\n+bool ZVirtualMemoryWithHeapBaseReserver::reserve_contiguous(size_t size) {\n+  \/\/ Allow at most 8192 attempts spread evenly across [0, offset_max)\n+  const size_t unused = offset_max() - size;\n@@ -203,2 +233,3 @@\n-  for (uintptr_t start = 0; start + size <= ZAddressOffsetMax; start += increment) {\n-    if (reserve_contiguous(to_zoffset(start), size)) {\n+  for (uintptr_t start = 0; start + size <= offset_max(); start += increment) {\n+    const uintptr_t addr = _heap_base + start;\n+    if (reserve_contiguous(addr, size)) {\n@@ -214,1 +245,50 @@\n-size_t ZVirtualMemoryReserver::reserve(size_t required_size, size_t desired_size) {\n+class ZHeapBaseIterator {\n+private:\n+  const size_t _initial;\n+  size_t       _current;\n+\n+public:\n+  ZHeapBaseIterator(size_t initial_heap_base_shift = ZGlobalsPointers::initial_heap_base_shift())\n+    : _initial(initial_heap_base_shift),\n+      _current(initial_heap_base_shift) {}\n+\n+  bool next(uintptr_t* out_heap_base) {\n+    size_t next = ZGlobalsPointers::next_heap_base_shift(_current);\n+    if (next == _initial) {\n+      \/\/ Iterator has completed\n+      return false;\n+    }\n+\n+    _current = next;\n+\n+    const uintptr_t heap_base = uintptr_t(1) << _current;\n+\n+    log_trace(gc, init)(\"Attempting Heap Base: \" PTR_FORMAT, heap_base);\n+\n+    *out_heap_base = heap_base;\n+\n+    return true;\n+  }\n+};\n+\n+ZVirtualMemoryAdaptiveReserver::ZVirtualMemoryAdaptiveReserver()\n+  : _heap_base(),\n+    _reserved_ranges() {}\n+\n+static int compare_ZVirtualMemoryUntyped(ZVirtualMemoryUntyped* vmem0, ZVirtualMemoryUntyped* vmem1) {\n+  if (vmem0->_start == vmem1->_start) {\n+    return 0;\n+  } else if (vmem0->_start < vmem1->_start) {\n+    return -1;\n+  } else {\n+    return 1;\n+  }\n+};\n+\n+void ZVirtualMemoryAdaptiveReserver::accept(ZVirtualMemoryWithHeapBaseReserver* reserver) {\n+  _heap_base = reserver->heap_base();\n+  reserver->transfer_reserved_ranges_to(&_reserved_ranges);\n+  _reserved_ranges.sort(&compare_ZVirtualMemoryUntyped);\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::reserve(size_t required_size, size_t desired_size) {\n@@ -217,2 +297,1 @@\n-  \/\/ Register Windows callbacks\n-  pd_register_callbacks(&_registry);\n+  size_t heap_base;\n@@ -220,5 +299,10 @@\n-  \/\/ Reserve address space\n-  const auto do_reserve = [&](size_t size) {\n-#ifdef ASSERT\n-    if (ZForceDiscontiguousHeapReservations > 0) {\n-      return force_reserve_discontiguous(size);\n+  \/\/ First attempt to get the desired size\n+  for (ZHeapBaseIterator iter{}; iter.next(&heap_base);) {\n+    ZVirtualMemoryWithHeapBaseReserver reserver(heap_base);\n+\n+    const size_t reserved = reserver.reserve(desired_size);\n+\n+    if (reserved >= desired_size) {\n+      \/\/ Succeeded\n+      accept(&reserver);\n+      return reserved;\n@@ -226,1 +310,14 @@\n-#endif\n+  }\n+\n+  \/\/ Second attempt to get at least the required size\n+  for (ZHeapBaseIterator iter{}; iter.next(&heap_base);) {\n+    ZVirtualMemoryWithHeapBaseReserver reserver(heap_base);\n+\n+    const size_t max_reserve_size = reserver.offset_max();\n+    assert(max_reserve_size >= required_size, \"Should not have attempted this heap base: \"\n+          PTR_FORMAT \" for required size: 0x%zx\", heap_base, required_size);\n+\n+    \/\/ Still attempt to get up to desired_size\n+    const size_t to_reserve = MIN2<size_t>(max_reserve_size, desired_size);\n+\n+    const size_t reserved = reserver.reserve(to_reserve);\n@@ -228,3 +325,4 @@\n-    \/\/ Prefer a contiguous address space\n-    if (reserve_contiguous(size)) {\n-      return size;\n+    if (reserved >= required_size) {\n+      \/\/ Succeeded\n+      accept(&reserver);\n+      return reserved;\n@@ -232,0 +330,9 @@\n+  }\n+\n+  \/\/ Failed to reserve\n+  return 0;\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::unreserve_after(size_t keep_size) {\n+  precond(keep_size > 0);\n+  precond(keep_size <= reserved());\n@@ -233,2 +340,5 @@\n-    \/\/ Fall back to a discontiguous address space\n-    return reserve_discontiguous(size);\n+  const size_t before = reserved();\n+\n+  struct UnreservePoint {\n+    int    _index;\n+    size_t _offset;\n@@ -237,5 +347,29 @@\n-  size_t reserved = 0;\n-  const auto unreserve_all = [&]() {\n-    this->unreserve_all();\n-    reserved = 0;\n-    return true;\n+  auto find_unreserve_point = [&]() -> UnreservePoint {\n+    size_t accumulated = 0;\n+\n+    for (int i = 0; i < _reserved_ranges.length(); i++) {\n+      ZVirtualMemoryUntyped vmem = _reserved_ranges.at(i);\n+\n+      accumulated += vmem._size;\n+\n+      if (accumulated < keep_size) {\n+        \/\/ Keep on accumulating\n+        continue;\n+      }\n+\n+      \/\/ We have found the unreserve point\n+\n+      if (accumulated > keep_size) {\n+        \/\/ The unreserve point splits a vmem\n+        size_t vmem_over_size = (accumulated - keep_size);\n+        size_t vmem_split_size = vmem._size - vmem_over_size;\n+\n+        return {i, vmem_split_size};\n+      }\n+\n+      \/\/ The unreserve point doesn't split a vmem\n+      return {i + 1, 0};\n+    }\n+\n+    \/\/ Nothing to split\n+    return {_reserved_ranges.length(), 0};\n@@ -244,5 +378,86 @@\n-  \/\/ First attempt to get the desired size\n-  do {\n-    if (ZAddressHeapBase >= desired_size) {\n-      \/\/ Only attempt to reserve if the current heap base can accommodate the desired size\n-      reserved = do_reserve(desired_size);\n+  \/\/ Search for the point where we should unreserve from\n+  const UnreservePoint split = find_unreserve_point();\n+\n+  int index = split._index;\n+  const size_t offset = split._offset;\n+\n+  size_t unreserved = 0;\n+\n+  auto do_unreserve = [&](uintptr_t addr, size_t size) {\n+    ZVirtualMemoryReserver::unreserve(addr, size);\n+    unreserved += size;\n+  };\n+\n+  \/\/ Split a vmem if the unreserve point falls inside a vmem\n+  if (offset > 0) {\n+    const ZVirtualMemoryUntyped& vmem = _reserved_ranges.at(index);\n+\n+    \/\/ Mainly a call to Windows that the memory reservation is split\n+    ZVirtualMemoryReserver::split_reserved(vmem._start, offset, vmem._size);\n+\n+    \/\/ Unreserve the surplus\n+    do_unreserve(vmem._start + offset, vmem._size - offset);\n+\n+    \/\/ Re-register the area that was shrunk\n+    _reserved_ranges.at(index) = ZVirtualMemoryUntyped{vmem._start, offset};\n+\n+    \/\/ Unreserve the rest\n+    index++;\n+  }\n+\n+  \/\/ Unreserve the reset of the vmems\n+  for (int i = index; i < _reserved_ranges.length(); i++) {\n+    const ZVirtualMemoryUntyped& vmem = _reserved_ranges.at(i);\n+\n+    do_unreserve(vmem._start, vmem._size);\n+  }\n+\n+  _reserved_ranges.trunc_to(index);\n+\n+  z_on_error_capture_64_6(keep_size, unreserved, before, index, offset, _reserved_ranges.length());\n+\n+  postcond(keep_size + unreserved == before);\n+  postcond(reserved() == keep_size);\n+\n+  return unreserved;\n+}\n+\n+void ZVirtualMemoryAdaptiveReserver::unreserve_all() {\n+  for (ZVirtualMemoryUntyped vmem : _reserved_ranges) {\n+    ZVirtualMemoryReserver::unreserve(vmem._start, vmem._size);\n+  }\n+\n+  _reserved_ranges.clear();\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::heap_base() const {\n+  return _heap_base;\n+}\n+\n+ZArray<ZVirtualMemoryUntyped>* ZVirtualMemoryAdaptiveReserver::reserved_ranges() {\n+  return &_reserved_ranges;\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::bottom() const {\n+  uintptr_t min_start = SIZE_MAX;\n+\n+  for (auto range : _reserved_ranges) {\n+    const uintptr_t start = range._start;\n+\n+    if (start < min_start) {\n+      min_start = start;\n+    }\n+\n+  }\n+\n+  postcond(min_start != SIZE_MAX);\n+\n+  return min_start;\n+}\n+\n+uintptr_t ZVirtualMemoryAdaptiveReserver::end() const {\n+  uintptr_t max_end = 0;\n+\n+  OnVMError on_error([&](outputStream* st) {\n+    for (auto vmem : _reserved_ranges) {\n+      st->print_cr(\" \" PTR_FORMAT \" \" PTR_FORMAT \" %zuM\", vmem._start, vmem._start + vmem._size, vmem._size \/ M);\n@@ -250,1 +465,1 @@\n-  } while (reserved < desired_size && unreserve_all() && ZGlobalsPointers::set_next_heap_base());\n+  });\n@@ -252,1 +467,10 @@\n-  assert(reserved <= desired_size, \"Should not reserve more than desired\");\n+  for (auto range : _reserved_ranges) {\n+    const uintptr_t end = range._start + range._size;\n+\n+    assert(end > max_end,\n+           \"Unordered reserved memory end: \" PTR_FORMAT \" max_end: \" PTR_FORMAT,\n+           end, max_end);\n+\n+    if (end > max_end) {\n+      max_end = end;\n+    }\n@@ -254,3 +478,0 @@\n-  if (reserved == desired_size) {\n-    \/\/ The desired size reservation was successful\n-    return reserved;\n@@ -259,7 +480,80 @@\n-  \/\/ Second attempt to get at least the required size\n-  do {\n-    assert(ZAddressHeapBase >= required_size, \"Should not have attempted this heap base: \"\n-          PTR_FORMAT \" >= \" PTR_FORMAT, ZAddressHeapBase, (intptr_t)required_size);\n-    size_t to_reserve = MIN2<size_t>(ZAddressHeapBase, desired_size);\n-    reserved = do_reserve(to_reserve);\n-  } while (reserved < required_size && unreserve_all() && ZGlobalsPointers::set_next_heap_base());\n+  return max_end;\n+}\n+\n+size_t ZVirtualMemoryAdaptiveReserver::reserved() const {\n+  size_t reserved = 0;\n+\n+  for (auto range : _reserved_ranges) {\n+    reserved += range._size;\n+  }\n+\n+  return reserved;\n+}\n+\n+ZVirtualMemoryReservation::ZVirtualMemoryReservation(ZArray<ZVirtualMemoryUntyped>* reserved_ranges)\n+  : _registry() {\n+\n+  \/\/ Register Windows callbacks\n+  pd_register_callbacks(&_registry);\n+\n+  \/\/ Register the reserved regions with the registry\n+  transfer_reserved_ranges(reserved_ranges);\n+}\n+\n+void ZVirtualMemoryReservation::transfer_reserved_ranges(ZArray<ZVirtualMemoryUntyped>* reserved_ranges) {\n+  for (ZVirtualMemoryUntyped range : *reserved_ranges) {\n+    const zaddress_unsafe addr = to_zaddress_unsafe(range._start);\n+    const zoffset start = ZAddress::offset(addr);\n+    const size_t size = range._size;\n+\n+    \/\/ Register the memory reservation\n+    _registry.register_range({start, size});\n+  }\n+\n+  \/\/ Clear the accepted input array\n+  reserved_ranges->clear();\n+}\n+\n+void ZVirtualMemoryReservation::initialize_partition_registry(ZVirtualMemoryRegistry* partition_registry, size_t size) {\n+  assert(partition_registry->is_empty(), \"Should be empty when initializing\");\n+\n+  \/\/ Registers the Windows callbacks\n+  pd_register_callbacks(partition_registry);\n+\n+  _registry.transfer_from_low(partition_registry, size);\n+\n+  \/\/ Set the limits according to the virtual memory given to this partition\n+  partition_registry->anchor_limits();\n+}\n+\n+void ZVirtualMemoryReservation::unreserve(const ZVirtualMemory& vmem) {\n+  const zaddress_unsafe addr = ZOffset::address_unsafe(vmem.start());\n+\n+  ZVirtualMemoryReserver::unreserve(untype(addr), vmem.size());\n+}\n+\n+size_t ZVirtualMemoryReservation::unreserve_all() {\n+  size_t unreserved = 0;\n+\n+  for (ZVirtualMemory vmem; _registry.unregister_first(&vmem);) {\n+    unreserve(vmem);\n+    unreserved += vmem.size();\n+  }\n+\n+  return unreserved;\n+}\n+\n+bool ZVirtualMemoryReservation::is_empty() const {\n+  return _registry.is_empty();\n+}\n+\n+bool ZVirtualMemoryReservation::is_contiguous() const {\n+  return _registry.is_contiguous();\n+}\n+\n+size_t ZVirtualMemoryReservation::reserved() const {\n+  size_t reserved = 0;\n+\n+  _registry.visit_all([&](const ZVirtualMemory* vmem) {\n+    reserved += vmem->size();\n+  });\n@@ -270,0 +564,4 @@\n+zoffset_end ZVirtualMemoryReservation::highest_available_address_end() const {\n+  return _registry.peak_high_address_end();\n+}\n+\n@@ -295,6 +593,0 @@\n-  \/\/ Reserve virtual memory for the heap\n-  ZVirtualMemoryReserver reserver(required, requested);\n-\n-  const size_t reserved = reserver.reserved();\n-  const bool is_contiguous = reserver.is_contiguous();\n-\n@@ -304,0 +596,5 @@\n+  ZVirtualMemoryAdaptiveReserver reserver;\n+\n+  \/\/ Reserve virtual memory for the heap\n+  const size_t reserved = reserver.reserve(required, requested);\n+\n@@ -309,3 +606,0 @@\n-  \/\/ Set ZAddressOffsetMax to the highest address end available after reservation\n-  ZAddressOffsetMax = untype(reserver.highest_available_address_end());\n-\n@@ -314,5 +608,1 @@\n-  \/\/ Divide size_for_partitions virtual memory over the NUMA nodes\n-  const zoffset_end max_offset = initialize_partitions(&reserver, size_for_partitions);\n-  size_t unreserved = 0;\n-\n-  \/\/ Set up multi-partition or unreserve the surplus memory\n+  size_t unreserved;\n@@ -320,2 +610,1 @@\n-    \/\/ Enough left to setup the multi-partition memory reservation\n-    reserver.initialize_partition_registry(&_multi_partition_registry, desired_for_multi_partition);\n+    \/\/ Can have multi-partitions\n@@ -323,0 +612,1 @@\n+    unreserved = 0;\n@@ -325,1 +615,5 @@\n-    unreserved = reserver.unreserve_all();\n+    unreserved = reserver.unreserve_after(size_for_partitions);\n+  }\n+\n+  \/\/ Now lock down the heap limits to the reserved spaces selected by the reserver\n+  ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n@@ -327,2 +621,10 @@\n-    \/\/ Set ZAddressOffsetMax to the highest address end used by initialize_partitions\n-    ZAddressOffsetMax = untype(max_offset);\n+  \/\/ Transfer the reserved ranges to the type-safe system\n+  ZVirtualMemoryReservation reservation(reserver.reserved_ranges());\n+\n+  \/\/ Divide size_for_partitions virtual memory over the NUMA nodes\n+  initialize_partitions(&reservation, size_for_partitions);\n+\n+  \/\/ Set up multi-partition\n+  if (_is_multi_partition_enabled) {\n+    \/\/ Enough left to setup the multi-partition memory reservation\n+    reservation.initialize_partition_registry(&_multi_partition_registry, desired_for_multi_partition);\n@@ -331,1 +633,1 @@\n-  assert(reserver.is_empty(), \"Must have handled all reserved memory\");\n+  assert(reservation.is_empty(), \"Must have handled all reserved memory\");\n@@ -335,0 +637,1 @@\n+  const bool is_contiguous = reservation.is_contiguous();\n@@ -341,2 +644,2 @@\n-  log_debug_p(gc, init)(\"Reserved Space Span: \" RANGE2EXACTFMT, ZAddressHeapBase + lowest_offset, ZAddressHeapBase + ZAddressOffsetMax,\n-                        EXACTFMTARGS(ZAddressOffsetMax - lowest_offset));\n+  log_debug_p(gc, init)(\"Reserved Space Span: \" RANGE2EXACTFMT, ZAddressHeapBase + lowest_offset, ZAddressHeapBase + ZAddressOffsetUpperLimit,\n+                        EXACTFMTARGS(ZAddressOffsetUpperLimit - lowest_offset));\n@@ -348,1 +651,1 @@\n-zoffset_end ZVirtualMemoryManager::initialize_partitions(ZVirtualMemoryReserver* reserver, size_t size_for_partitions) {\n+void ZVirtualMemoryManager::initialize_partitions(ZVirtualMemoryReservation* reservation, size_t size_for_partitions) {\n@@ -358,1 +661,0 @@\n-  zoffset_end max_zoffset_end;\n@@ -370,4 +672,1 @@\n-    reserver->initialize_partition_registry(registry, reserved_for_partition);\n-\n-    \/\/ Keep track of the largest offset used for the partitions\n-    max_zoffset_end = registry->peak_high_address_end();\n+    reservation->initialize_partition_registry(registry, reserved_for_partition);\n@@ -375,2 +674,0 @@\n-\n-  return max_zoffset_end;\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemoryManager.cpp","additions":429,"deletions":132,"binary":false,"changes":561,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/z\/zRange.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -33,1 +35,12 @@\n-using ZVirtualMemoryRegistry = ZRangeRegistry<ZVirtualMemory>;\n+class ZVirtualMemoryReserver : AllStatic {\n+private:\n+  \/\/ Platform specific implementation\n+  static bool pd_reserve(uintptr_t addr, size_t size);\n+  static void pd_split_reserved(uintptr_t addr, size_t split_size, size_t size);\n+  static void pd_unreserve(uintptr_t addr, size_t size);\n+\n+public:\n+  static bool reserve(uintptr_t addr, size_t size);\n+  static void split_reserved(uintptr_t addr, size_t split_size, size_t size);\n+  static void unreserve(uintptr_t addr, size_t size);\n+};\n@@ -35,1 +48,32 @@\n-class ZVirtualMemoryReserver {\n+class ZVirtualMemoryWithHeapBaseReserver {\n+  friend class ZVirtualMemoryReservationTest;\n+\n+private:\n+  \/\/ The heap base to reserve against\n+  const uintptr_t               _heap_base;\n+  ZArray<ZVirtualMemoryUntyped> _reserved_ranges;\n+\n+  static size_t calculate_min_range(size_t size);\n+\n+  bool reserve_contiguous(uintptr_t addr, size_t size);\n+  bool reserve_contiguous(size_t size);\n+  size_t reserve_discontiguous(uintptr_t start, size_t size, size_t min_range);\n+  size_t reserve_discontiguous(size_t size);\n+\n+  DEBUG_ONLY(size_t force_reserve_discontiguous(size_t size);)\n+\n+  size_t unreserve_all();\n+\n+public:\n+  ZVirtualMemoryWithHeapBaseReserver(size_t heap_base);\n+  ~ZVirtualMemoryWithHeapBaseReserver();\n+\n+  uintptr_t heap_base() const;\n+  size_t offset_max() const;\n+\n+  size_t reserve(size_t size);\n+\n+  void transfer_reserved_ranges_to(ZArray<ZVirtualMemoryUntyped>* to);\n+};\n+\n+class ZVirtualMemoryAdaptiveReserver {\n@@ -38,1 +82,2 @@\n-  friend class ZVirtualMemoryManagerTest;\n+  friend class ZVirtualMemoryRegistryTest;\n+  friend class ZVirtualMemoryReservationTest;\n@@ -41,0 +86,4 @@\n+  \/\/ Accepted heap base\n+  uintptr_t                     _heap_base;\n+  \/\/ Accepted reserved ranges\n+  ZArray<ZVirtualMemoryUntyped> _reserved_ranges;\n@@ -42,2 +91,1 @@\n-  ZVirtualMemoryRegistry _registry;\n-  const size_t           _reserved;\n+  void accept(ZVirtualMemoryWithHeapBaseReserver* reserver);\n@@ -45,1 +93,24 @@\n-  static size_t calculate_min_range(size_t size);\n+public:\n+  ZVirtualMemoryAdaptiveReserver();\n+\n+  size_t reserve(size_t required_size, size_t desired_size);\n+  size_t unreserve_after(size_t keep_size);\n+  void unreserve_all();\n+\n+  uintptr_t heap_base() const;\n+  ZArray<ZVirtualMemoryUntyped>* reserved_ranges();\n+\n+  uintptr_t bottom() const;\n+  uintptr_t end() const;\n+  size_t reserved() const;\n+};\n+\n+using ZVirtualMemoryRegistry = ZRangeRegistry<ZVirtualMemory>;\n+\n+class ZVirtualMemoryReservation {\n+  friend class ZMapperTest;\n+  friend class ZTestAddressReserver;\n+  friend class ZVirtualMemoryReservationTest;\n+\n+private:\n+  ZVirtualMemoryRegistry _registry;\n@@ -49,2 +120,0 @@\n-  bool pd_reserve(zaddress_unsafe addr, size_t size);\n-  void pd_unreserve(zaddress_unsafe addr, size_t size);\n@@ -52,6 +121,0 @@\n-  bool reserve_contiguous(zoffset start, size_t size);\n-  bool reserve_contiguous(size_t size);\n-  size_t reserve_discontiguous(zoffset start, size_t size, size_t min_range);\n-  size_t reserve_discontiguous(size_t size);\n-\n-  size_t reserve(size_t required_size, size_t desired_size);\n@@ -60,1 +123,1 @@\n-  DEBUG_ONLY(size_t force_reserve_discontiguous(size_t size);)\n+  void transfer_reserved_ranges(ZArray<ZVirtualMemoryUntyped>* reserved_ranges);\n@@ -63,2 +126,1 @@\n-  ZVirtualMemoryReserver(size_t size);\n-  ZVirtualMemoryReserver(size_t required_size, size_t desired_size);\n+  ZVirtualMemoryReservation(ZArray<ZVirtualMemoryUntyped>* reserved_ranges);\n@@ -91,1 +153,1 @@\n-  zoffset_end initialize_partitions(ZVirtualMemoryReserver* reserver, size_t size_for_partitions);\n+  void initialize_partitions(ZVirtualMemoryReservation* reservation, size_t size_for_partitions);\n","filename":"src\/hotspot\/share\/gc\/z\/zVirtualMemoryManager.hpp","additions":80,"deletions":18,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -47,5 +47,5 @@\n-  ZHeap*            _old_heap;\n-  ZGenerationOld*   _old_old;\n-  ZGenerationYoung* _old_young;\n-  ZAddressReserver  _zaddress_reserver;\n-  zoffset           _page_offset;\n+  ZHeap*                _old_heap;\n+  ZGenerationOld*       _old_old;\n+  ZGenerationYoung*     _old_young;\n+  ZTestAddressReserver  _zaddress_reserver;\n+  zoffset               _page_offset;\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zForwarding.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -39,3 +39,3 @@\n-  ZAddressReserver        _zaddress_reserver;\n-  ZVirtualMemoryReserver* _reserver;\n-  ZVirtualMemoryRegistry* _registry;\n+  ZTestAddressReserver       _zaddress_reserver;\n+  ZVirtualMemoryReservation* _reservation;\n+  ZVirtualMemoryRegistry*    _registry;\n@@ -46,1 +46,1 @@\n-    _reserver = _zaddress_reserver.reserver();\n+    _reservation = _zaddress_reserver.reservation();\n@@ -49,1 +49,1 @@\n-    if (_reserver->reserved() < ReservationSize || !_registry->is_contiguous()) {\n+    if (_reservation->reserved() < ReservationSize || !_registry->is_contiguous()) {\n@@ -51,1 +51,1 @@\n-          << (_reserver->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n+          << (_reservation->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n@@ -58,1 +58,1 @@\n-    _reserver = nullptr;\n+    _reservation = nullptr;\n@@ -72,1 +72,1 @@\n-    _reserver->unreserve(middle);\n+    _reservation->unreserve(middle);\n@@ -75,2 +75,2 @@\n-    _reserver->unreserve(bottom);\n-    _reserver->unreserve(top);\n+    _reservation->unreserve(bottom);\n+    _reservation->unreserve(top);\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zMapper_windows.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -36,1 +36,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -58,1 +58,1 @@\n-    ZVirtualMemory mem(zoffset(0), ZAddressOffsetMax);\n+    ZVirtualMemory mem(zoffset(0), ZAddressOffsetUpperLimit);\n@@ -61,3 +61,3 @@\n-    EXPECT_EQ(mem.end(), zoffset_end(ZAddressOffsetMax));\n-    EXPECT_EQ(mem.size(), ZAddressOffsetMax);\n-    EXPECT_EQ(mem.granule_count(), (int)(ZAddressOffsetMax >> ZGranuleSizeShift));\n+    EXPECT_EQ(mem.end(), zoffset_end(ZAddressOffsetUpperLimit));\n+    EXPECT_EQ(mem.size(), ZAddressOffsetUpperLimit);\n+    EXPECT_EQ(mem.granule_count(), (int)(ZAddressOffsetUpperLimit >> ZGranuleSizeShift));\n@@ -68,1 +68,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -98,1 +98,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -119,1 +119,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n@@ -133,1 +133,1 @@\n-  ZAddressOffsetMaxSetter setter(size_t(16) * G * 1024);\n+  ZAddressOffsetLimitsSetter setter(size_t(16) * G * 1024);\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemory.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1,272 +0,0 @@\n-\/*\n- * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"gc\/z\/zAddress.inline.hpp\"\n-#include \"gc\/z\/zArguments.hpp\"\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"gc\/z\/zInitialize.hpp\"\n-#include \"gc\/z\/zList.inline.hpp\"\n-#include \"gc\/z\/zNUMA.inline.hpp\"\n-#include \"gc\/z\/zValue.inline.hpp\"\n-#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"zunittest.hpp\"\n-\n-using namespace testing;\n-\n-#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n-\n-class ZCallbacksResetter {\n-private:\n-  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n-  ZVirtualMemoryRegistry::Callbacks  _saved;\n-\n-public:\n-  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n-    : _callbacks(callbacks),\n-      _saved(*callbacks) {\n-    *_callbacks = {};\n-  }\n-  ~ZCallbacksResetter() {\n-    *_callbacks = _saved;\n-  }\n-};\n-\n-class ZVirtualMemoryManagerTest : public ZTest {\n-private:\n-  static constexpr size_t ReservationSize = 32 * M;\n-\n-  ZAddressReserver        _zaddress_reserver;\n-  ZVirtualMemoryReserver* _reserver;\n-  ZVirtualMemoryRegistry* _registry;\n-\n-public:\n-  virtual void SetUp() {\n-    _zaddress_reserver.SetUp(ReservationSize);\n-    _reserver = _zaddress_reserver.reserver();\n-    _registry = _zaddress_reserver.registry();\n-\n-    if (_reserver->reserved() < ReservationSize || !_registry->is_contiguous()) {\n-      GTEST_SKIP() << \"Fixture failed to reserve adequate memory, reserved \"\n-          << (_reserver->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n-    }\n-  }\n-\n-  virtual void TearDown() {\n-    _registry = nullptr;\n-    _reserver = nullptr;\n-    _zaddress_reserver.TearDown();\n-  }\n-\n-  void test_reserve_discontiguous_and_coalesce() {\n-    \/\/ Start by ensuring that we have 3 unreserved granules, and then let the\n-    \/\/ fourth granule be pre-reserved and therefore blocking subsequent requests\n-    \/\/ to reserve memory.\n-    \/\/\n-    \/\/ +----+----+----+----+\n-    \/\/                -----  pre-reserved - to block contiguous reservation\n-    \/\/ ---------------       unreserved   - to allow reservation of 3 granules\n-    \/\/\n-    \/\/ If we then asks for 4 granules starting at the first granule above,\n-    \/\/ then we won't be able to reserve 4 consecutive granules and the code\n-    \/\/ reverts into the discontiguous mode. This mode uses interval halving\n-    \/\/ to find the limits of memory areas that have already been reserved.\n-    \/\/ This will lead to the first 2 granules being reserved, then the third\n-    \/\/ granule will be reserved.\n-    \/\/\n-    \/\/ The problem we had with this is that this would yield two separate\n-    \/\/ placeholder reservations, even though they are adjacent. The callbacks\n-    \/\/ are supposed to fix that by coalescing the placeholders, *but* the\n-    \/\/ callbacks used to be only turned on *after* the reservation call. So,\n-    \/\/ we end up with one 3 granule large memory area in the manager, which\n-    \/\/ unexpectedly was covered by two placeholders (instead of the expected\n-    \/\/ one placeholder).\n-    \/\/\n-    \/\/ Later when the callbacks had been installed and we tried to fetch memory\n-    \/\/ from the manager, the callbacks would try to split off the placeholder\n-    \/\/ to separate the fetched memory from the memory left in the manager. This\n-    \/\/ used to fail because the memory was already split into two placeholders.\n-\n-    \/\/ Start at the offset we reserved.\n-    const zoffset base_offset = _registry->peek_low_address();\n-\n-    \/\/ Empty the reserved memory in preparation for the rest of the test.\n-    _reserver->unreserve_all();\n-\n-    const zaddress_unsafe base = ZOffset::address_unsafe(base_offset);\n-    const zaddress_unsafe blocked = base + 3 * ZGranuleSize;\n-\n-    \/\/ Reserve the memory that is acting as a blocking reservation.\n-    {\n-      char* const result = os::attempt_reserve_memory_at((char*)untype(blocked), ZGranuleSize, mtTest);\n-      if (uintptr_t(result) != untype(blocked)) {\n-        GTEST_SKIP() << \"Failed to reserve requested memory at \" << untype(blocked);\n-      }\n-    }\n-\n-    {\n-      \/\/ This ends up reserving 2 granules and then 1 granule adjacent to the\n-      \/\/ first. In previous implementations this resulted in two separate\n-      \/\/ placeholders (4MB and 2MB). This was a bug, because the manager is\n-      \/\/ designed to have one placeholder per memory area. This in turn would\n-      \/\/ lead to a subsequent failure when _vmr->remove* tried to split off the\n-      \/\/ 4MB that is already covered by its own placeholder. You can't place\n-      \/\/ a placeholder over an already existing placeholder.\n-\n-      \/\/ To reproduce this, the test needed to mimic the initializing memory\n-      \/\/ reservation code which had the placeholders turned off. This was done\n-      \/\/ with this helper:\n-      \/\/\n-      \/\/ ZCallbacksResetter resetter(&_va->_callbacks);\n-      \/\/\n-      \/\/ After the fix, we always have the callbacks turned on, so we don't\n-      \/\/ need this to mimic the initializing memory reservation.\n-\n-      const size_t reserved = _reserver->reserve_discontiguous(base_offset, 4 * ZGranuleSize, ZGranuleSize);\n-      ASSERT_LE(reserved, 3 * ZGranuleSize);\n-      if (reserved < 3 * ZGranuleSize) {\n-        GTEST_SKIP() << \"Failed reserve_discontiguous\"\n-            \", expected 3 * ZGranuleSize, got \" << (reserved >> ZGranuleSizeShift)\n-            << \" * ZGranuleSize\";\n-      }\n-    }\n-\n-    {\n-      \/\/ The test used to crash here because the 3 granule memory area was\n-      \/\/ inadvertently covered by two place holders (2 granules + 1 granule).\n-      const ZVirtualMemory vmem = _registry->remove_from_low(2 * ZGranuleSize);\n-      ASSERT_EQ(vmem, ZVirtualMemory(base_offset, 2 * ZGranuleSize));\n-\n-      \/\/ Cleanup - Must happen in granule-sizes because of how Windows hands\n-      \/\/ out memory in granule-sized placeholder reservations.\n-      _reserver->unreserve(vmem.first_part(ZGranuleSize));\n-      _reserver->unreserve(vmem.last_part(ZGranuleSize));\n-    }\n-\n-    \/\/ Final cleanup\n-    const ZVirtualMemory vmem = _registry->remove_from_low(ZGranuleSize);\n-    ASSERT_EQ(vmem, ZVirtualMemory(base_offset + 2 * ZGranuleSize, ZGranuleSize));\n-    _reserver->unreserve(vmem);\n-\n-    const bool released = os::release_memory((char*)untype(blocked), ZGranuleSize);\n-    ASSERT_TRUE(released);\n-  }\n-\n-  void test_remove_from_low() {\n-    {\n-      \/\/ Verify that we get a placeholder for the first granule\n-      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n-\n-      _registry->insert(removed);\n-    }\n-\n-    {\n-      \/\/ Remove something larger than a granule and then insert it\n-      const ZVirtualMemory removed = _registry->remove_from_low(3 * ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, 3 * ZGranuleSize);\n-\n-      _registry->insert(removed);\n-    }\n-\n-    {\n-      \/\/ Insert with more memory removed\n-      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n-\n-      ZVirtualMemory next = _registry->remove_from_low(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(next, ZGranuleSize);\n-\n-      _registry->insert(removed);\n-      _registry->insert(next);\n-    }\n-  }\n-\n-  void test_remove_from_high() {\n-    {\n-      \/\/ Verify that we get a placeholder for the last granule\n-      const ZVirtualMemory high = _registry->remove_from_high(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(high, ZGranuleSize);\n-\n-      const ZVirtualMemory prev = _registry->remove_from_high(ZGranuleSize);\n-      ASSERT_REMOVAL_OK(prev, ZGranuleSize);\n-\n-      _registry->insert(high);\n-      _registry->insert(prev);\n-    }\n-\n-    {\n-      \/\/ Remove something larger than a granule and return it\n-      const ZVirtualMemory high = _registry->remove_from_high(2 * ZGranuleSize);\n-      ASSERT_REMOVAL_OK(high, 2 * ZGranuleSize);\n-\n-      _registry->insert(high);\n-    }\n-  }\n-\n-  void test_remove_whole() {\n-    \/\/ Need a local variable to appease gtest\n-    const size_t reservation_size = ReservationSize;\n-\n-    \/\/ Remove the whole reservation\n-    const ZVirtualMemory reserved = _registry->remove_from_low(reservation_size);\n-    ASSERT_REMOVAL_OK(reserved, reservation_size);\n-\n-    const ZVirtualMemory first(reserved.start(), 4 * ZGranuleSize);\n-    const ZVirtualMemory second(reserved.start() + 6 * ZGranuleSize, 6 * ZGranuleSize);\n-\n-    \/\/ Insert two chunks and then remove them again\n-    _registry->insert(first);\n-    _registry->insert(second);\n-\n-    const ZVirtualMemory removed_first = _registry->remove_from_low(first.size());\n-    ASSERT_EQ(removed_first, first);\n-\n-    const ZVirtualMemory removed_second = _registry->remove_from_low(second.size());\n-    ASSERT_EQ(removed_second, second);\n-\n-    \/\/ Now insert it all, and verify it can be re-removed\n-    _registry->insert(reserved);\n-\n-    const ZVirtualMemory removed_reserved = _registry->remove_from_low(reservation_size);\n-    ASSERT_EQ(removed_reserved, reserved);\n-\n-    _registry->insert(reserved);\n-  }\n-};\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_reserve_discontiguous_and_coalesce) {\n-  test_reserve_discontiguous_and_coalesce();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_from_low) {\n-  test_remove_from_low();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_from_high) {\n-  test_remove_from_high();\n-}\n-\n-TEST_VM_F(ZVirtualMemoryManagerTest, test_remove_whole) {\n-  test_remove_whole();\n-}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryManager.cpp","additions":0,"deletions":272,"binary":false,"changes":272,"status":"deleted"},{"patch":"@@ -0,0 +1,184 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.inline.hpp\"\n+#include \"gc\/z\/zArguments.hpp\"\n+#include \"gc\/z\/zGlobals.hpp\"\n+#include \"gc\/z\/zInitialize.hpp\"\n+#include \"gc\/z\/zList.inline.hpp\"\n+#include \"gc\/z\/zNUMA.inline.hpp\"\n+#include \"gc\/z\/zValue.inline.hpp\"\n+#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"zunittest.hpp\"\n+\n+using namespace testing;\n+\n+#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n+\n+class ZCallbacksResetter {\n+private:\n+  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n+  ZVirtualMemoryRegistry::Callbacks  _saved;\n+\n+public:\n+  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n+    : _callbacks(callbacks),\n+      _saved(*callbacks) {\n+    *_callbacks = {};\n+  }\n+  ~ZCallbacksResetter() {\n+    *_callbacks = _saved;\n+  }\n+};\n+\n+class ZVirtualMemoryRegistryTest : public ZTest {\n+private:\n+  static constexpr size_t ReservationSize = 32 * M;\n+\n+  ZTestAddressReserver       _zaddress_reserver;\n+  ZVirtualMemoryReservation* _reservation;\n+  ZVirtualMemoryRegistry*    _registry;\n+\n+public:\n+  virtual void SetUp() {\n+    \/\/ Only run test on supported Windows versions\n+    if (!is_os_supported()) {\n+      GTEST_SKIP() << \"OS not supported\";\n+    }\n+\n+    _zaddress_reserver.SetUp(ReservationSize);\n+    _reservation = _zaddress_reserver.reservation();\n+    _registry = _zaddress_reserver.registry();\n+\n+    if (_reservation->reserved() < ReservationSize || !_registry->is_contiguous()) {\n+      GTEST_SKIP() << \"Fixture failed to reserve adequate memory, reserved \"\n+          << (_reservation->reserved() >> ZGranuleSizeShift) << \" * ZGranuleSize\";\n+    }\n+  }\n+\n+  virtual void TearDown() {\n+    if (!is_os_supported()) {\n+      \/\/ Test skipped, nothing to cleanup\n+      return;\n+    }\n+\n+    _registry = nullptr;\n+    _reservation = nullptr;\n+    _zaddress_reserver.TearDown();\n+  }\n+\n+  void test_remove_from_low() {\n+    {\n+      \/\/ Verify that we get a placeholder for the first granule\n+      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n+\n+      _registry->insert(removed);\n+    }\n+\n+    {\n+      \/\/ Remove something larger than a granule and then insert it\n+      const ZVirtualMemory removed = _registry->remove_from_low(3 * ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, 3 * ZGranuleSize);\n+\n+      _registry->insert(removed);\n+    }\n+\n+    {\n+      \/\/ Insert with more memory removed\n+      const ZVirtualMemory removed = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(removed, ZGranuleSize);\n+\n+      ZVirtualMemory next = _registry->remove_from_low(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(next, ZGranuleSize);\n+\n+      _registry->insert(removed);\n+      _registry->insert(next);\n+    }\n+  }\n+\n+  void test_remove_from_high() {\n+    {\n+      \/\/ Verify that we get a placeholder for the last granule\n+      const ZVirtualMemory high = _registry->remove_from_high(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(high, ZGranuleSize);\n+\n+      const ZVirtualMemory prev = _registry->remove_from_high(ZGranuleSize);\n+      ASSERT_REMOVAL_OK(prev, ZGranuleSize);\n+\n+      _registry->insert(high);\n+      _registry->insert(prev);\n+    }\n+\n+    {\n+      \/\/ Remove something larger than a granule and return it\n+      const ZVirtualMemory high = _registry->remove_from_high(2 * ZGranuleSize);\n+      ASSERT_REMOVAL_OK(high, 2 * ZGranuleSize);\n+\n+      _registry->insert(high);\n+    }\n+  }\n+\n+  void test_remove_whole() {\n+    \/\/ Need a local variable to appease gtest\n+    const size_t reservation_size = ReservationSize;\n+\n+    \/\/ Remove the whole reservation\n+    const ZVirtualMemory reserved = _registry->remove_from_low(reservation_size);\n+    ASSERT_REMOVAL_OK(reserved, reservation_size);\n+\n+    const ZVirtualMemory first(reserved.start(), 4 * ZGranuleSize);\n+    const ZVirtualMemory second(reserved.start() + 6 * ZGranuleSize, 6 * ZGranuleSize);\n+\n+    \/\/ Insert two chunks and then remove them again\n+    _registry->insert(first);\n+    _registry->insert(second);\n+\n+    const ZVirtualMemory removed_first = _registry->remove_from_low(first.size());\n+    ASSERT_EQ(removed_first, first);\n+\n+    const ZVirtualMemory removed_second = _registry->remove_from_low(second.size());\n+    ASSERT_EQ(removed_second, second);\n+\n+    \/\/ Now insert it all, and verify it can be re-removed\n+    _registry->insert(reserved);\n+\n+    const ZVirtualMemory removed_reserved = _registry->remove_from_low(reservation_size);\n+    ASSERT_EQ(removed_reserved, reserved);\n+\n+    _registry->insert(reserved);\n+  }\n+};\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_from_low) {\n+  test_remove_from_low();\n+}\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_from_high) {\n+  test_remove_from_high();\n+}\n+\n+TEST_VM_F(ZVirtualMemoryRegistryTest, test_remove_whole) {\n+  test_remove_whole();\n+}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryRegistry.cpp","additions":184,"deletions":0,"binary":false,"changes":184,"status":"added"},{"patch":"@@ -0,0 +1,186 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zAddress.inline.hpp\"\n+#include \"gc\/z\/zArguments.hpp\"\n+#include \"gc\/z\/zGlobals.hpp\"\n+#include \"gc\/z\/zInitialize.hpp\"\n+#include \"gc\/z\/zList.inline.hpp\"\n+#include \"gc\/z\/zNUMA.inline.hpp\"\n+#include \"gc\/z\/zValue.inline.hpp\"\n+#include \"gc\/z\/zVirtualMemoryManager.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"zunittest.hpp\"\n+\n+using namespace testing;\n+\n+#define ASSERT_REMOVAL_OK(range, sz) ASSERT_FALSE(range.is_null()); ASSERT_EQ(range.size(), (sz))\n+\n+class ZCallbacksResetter {\n+private:\n+  ZVirtualMemoryRegistry::Callbacks* _callbacks;\n+  ZVirtualMemoryRegistry::Callbacks  _saved;\n+\n+public:\n+  ZCallbacksResetter(ZVirtualMemoryRegistry::Callbacks* callbacks)\n+    : _callbacks(callbacks),\n+      _saved(*callbacks) {\n+    *_callbacks = {};\n+  }\n+  ~ZCallbacksResetter() {\n+    *_callbacks = _saved;\n+  }\n+};\n+\n+class ZVirtualMemoryReservationTest : public ZTest {\n+private:\n+  static constexpr size_t ReservationSize = 32 * M;\n+\n+public:\n+  virtual void SetUp() {\n+    \/\/ Only run test on supported Windows versions\n+    if (!is_os_supported()) {\n+      GTEST_SKIP() << \"OS not supported\";\n+    }\n+  }\n+\n+  virtual void TearDown() {\n+    \/\/ Nothing to cleanup\n+  }\n+\n+  void test_reserve_discontiguous_and_coalesce() {\n+    ZVirtualMemoryAdaptiveReserver reserver;\n+\n+    reserver.reserve(4 * ZGranuleSize, 4 * ZGranuleSize);\n+\n+    if (reserver.reserved() != 4 * ZGranuleSize) {\n+      GTEST_SKIP() << \"Failed to reserve requested memory\";\n+    }\n+\n+    if (reserver._reserved_ranges.length() != 1) {\n+      GTEST_SKIP() << \"Failed to reserve single reserved area\";\n+    }\n+\n+    ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n+\n+    \/\/ Start by ensuring that we have 3 unreserved granules, and then let the\n+    \/\/ fourth granule be pre-reserved and therefore blocking subsequent requests\n+    \/\/ to reserve memory.\n+    \/\/\n+    \/\/ +----+----+----+----+\n+    \/\/                -----  pre-reserved - to block contiguous reservation\n+    \/\/ ---------------       unreserved   - to allow reservation of 3 granules\n+    \/\/\n+    \/\/ If we then asks for 4 granules starting at the first granule above,\n+    \/\/ then we won't be able to reserve 4 consecutive granules and the code\n+    \/\/ reverts into the discontiguous mode. This mode uses interval halving\n+    \/\/ to find the limits of memory areas that have already been reserved.\n+    \/\/ This will lead to the first 2 granules being reserved, then the third\n+    \/\/ granule will be reserved.\n+    \/\/\n+    \/\/ The problem we had with this is that this would yield two separate\n+    \/\/ placeholder reservations, even though they are adjacent. The callbacks\n+    \/\/ are supposed to fix that by coalescing the placeholders, *but* the\n+    \/\/ callbacks used to be only turned on *after* the reservation call. So,\n+    \/\/ we end up with one 3 granule large memory area in the manager, which\n+    \/\/ unexpectedly was covered by two placeholders (instead of the expected\n+    \/\/ one placeholder).\n+    \/\/\n+    \/\/ Later when the callbacks had been installed and we tried to fetch memory\n+    \/\/ from the manager, the callbacks would try to split off the placeholder\n+    \/\/ to separate the fetched memory from the memory left in the manager. This\n+    \/\/ used to fail because the memory was already split into two placeholders.\n+\n+    \/\/ Start at the offset we reserved.\n+    const uintptr_t bottom = reserver.bottom();\n+\n+    \/\/ Empty the reserved memory in preparation for the rest of the test.\n+    reserver.unreserve_all();\n+\n+    const uintptr_t blocked = bottom + 3 * ZGranuleSize;\n+\n+    \/\/ Reserve the memory that is acting as a blocking reservation.\n+    {\n+      char* const result = os::attempt_reserve_memory_at((char*)blocked, ZGranuleSize, mtTest);\n+      if (uintptr_t(result) != blocked) {\n+        GTEST_SKIP() << \"Failed to reserve requested memory at \" << blocked;\n+      }\n+    }\n+\n+    \/\/ This ends up reserving 2 granules and then 1 granule adjacent to the\n+    \/\/ first. In previous implementations this resulted in two separate\n+    \/\/ placeholders (4MB and 2MB). This was a bug, because the manager is\n+    \/\/ designed to have one placeholder per memory area. This in turn would\n+    \/\/ lead to a subsequent failure when _vmr->remove* tried to split off the\n+    \/\/ 4MB that is already covered by its own placeholder. You can't place\n+    \/\/ a placeholder over an already existing placeholder.\n+\n+    \/\/ To reproduce this, the test needed to mimic the initializing memory\n+    \/\/ reservation code which had the placeholders turned off. This was done\n+    \/\/ with this helper:\n+    \/\/\n+    \/\/ ZCallbacksResetter resetter(&_va->_callbacks);\n+    \/\/\n+    \/\/ After the fix, we always have the callbacks turned on, so we don't\n+    \/\/ need this to mimic the initializing memory reservation.\n+\n+    ZVirtualMemoryWithHeapBaseReserver reserver2(reserver.heap_base());\n+\n+    const size_t reserved = reserver2.reserve_discontiguous(bottom, 4 * ZGranuleSize, ZGranuleSize);\n+    ASSERT_LE(reserved, 3 * ZGranuleSize);\n+    if (reserved < 3 * ZGranuleSize) {\n+      GTEST_SKIP() << \"Failed reserve_discontiguous\"\n+          \", expected 3 * ZGranuleSize, got \" << (reserved >> ZGranuleSizeShift)\n+          << \" * ZGranuleSize\";\n+    }\n+\n+    \/\/ Transfer over to the reservation instance\n+    ZVirtualMemoryReservation reservation(&reserver2._reserved_ranges);\n+\n+    const zoffset bottom_offset = ZAddress::offset(to_zaddress(bottom));\n+\n+    {\n+      \/\/ The test used to crash here because the 3 granule memory area was\n+      \/\/ inadvertently covered by two place holders (2 granules + 1 granule).\n+      const ZVirtualMemory vmem = reservation._registry.remove_from_low(2 * ZGranuleSize);\n+      ASSERT_EQ(vmem, ZVirtualMemory(bottom_offset, 2 * ZGranuleSize));\n+\n+      \/\/ Cleanup - Must happen in granule-sizes because of how Windows hands\n+      \/\/ out memory in granule-sized placeholder reservations.\n+      reservation.unreserve(vmem.first_part(ZGranuleSize));\n+      reservation.unreserve(vmem.last_part(ZGranuleSize));\n+    }\n+\n+    \/\/ Final cleanup\n+    const ZVirtualMemory vmem = reservation._registry.remove_from_low(ZGranuleSize);\n+    ASSERT_EQ(vmem, ZVirtualMemory(bottom_offset + 2 * ZGranuleSize, ZGranuleSize));\n+    reservation.unreserve(vmem);\n+\n+    const bool released = os::release_memory((char*)blocked, ZGranuleSize);\n+    ASSERT_TRUE(released);\n+  }\n+};\n+\n+TEST_VM_F(ZVirtualMemoryReservationTest, test_reserve_discontiguous_and_coalesce) {\n+  test_reserve_discontiguous_and_coalesce();\n+}\n","filename":"test\/hotspot\/gtest\/gc\/z\/test_zVirtualMemoryReservation.cpp","additions":186,"deletions":0,"binary":false,"changes":186,"status":"added"},{"patch":"@@ -43,1 +43,1 @@\n-class ZAddressOffsetMaxSetter {\n+class ZAddressOffsetLimitsSetter {\n@@ -49,0 +49,1 @@\n+  size_t _old_upper_limit;\n@@ -51,1 +52,1 @@\n-  ZAddressOffsetMaxSetter(size_t zaddress_offset_max)\n+  ZAddressOffsetLimitsSetter(size_t zaddress_offset_max, size_t zaddress_offset_limit)\n@@ -53,1 +54,2 @@\n-      _old_mask(ZAddressOffsetMask) {\n+      _old_mask(ZAddressOffsetMask),\n+      _old_upper_limit(ZAddressOffsetUpperLimit) {\n@@ -56,0 +58,2 @@\n+\n+    ZAddressOffsetUpperLimit = zaddress_offset_max;\n@@ -57,1 +61,4 @@\n-  ~ZAddressOffsetMaxSetter() {\n+  ZAddressOffsetLimitsSetter(size_t zaddress_offset_max)\n+    : ZAddressOffsetLimitsSetter(zaddress_offset_max, zaddress_offset_max) {}\n+\n+  ~ZAddressOffsetLimitsSetter() {\n@@ -60,0 +67,1 @@\n+    ZAddressOffsetUpperLimit = _old_upper_limit;\n@@ -64,43 +72,0 @@\n-public:\n-  class ZAddressReserver {\n-    ZVirtualMemoryReserver* _reserver;\n-    bool _active;\n-\n-    public:\n-      ZAddressReserver()\n-        : _reserver(nullptr),\n-          _active(false) {}\n-\n-      ~ZAddressReserver() {\n-        GTEST_EXPECT_FALSE(_active) << \"ZAddressReserver deconstructed without calling TearDown\";\n-      }\n-\n-      void SetUp(size_t reservation_size) {\n-        GTEST_EXPECT_FALSE(_active) << \"SetUp called twice without a TearDown\";\n-        _active = true;\n-\n-        _reserver = (ZVirtualMemoryReserver*)os::malloc(sizeof(ZVirtualMemoryManager), mtTest);\n-        _reserver = ::new (_reserver) ZVirtualMemoryReserver(reservation_size);\n-      }\n-\n-      void TearDown() {\n-        GTEST_EXPECT_TRUE(_active) << \"TearDown called without a preceding SetUp\";\n-        _active = false;\n-\n-        \/\/ Best-effort cleanup\n-        _reserver->unreserve_all();\n-        _reserver->~ZVirtualMemoryReserver();\n-        os::free(_reserver);\n-      }\n-\n-      ZVirtualMemoryReserver* reserver() {\n-        GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n-        return _reserver;\n-      }\n-\n-      ZVirtualMemoryRegistry* registry() {\n-        GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n-        return &_reserver->_registry;\n-      }\n-  };\n-\n@@ -108,1 +73,1 @@\n-  ZAddressOffsetMaxSetter _zaddress_offset_max_setter;\n+  ZAddressOffsetLimitsSetter _zaddress_offset_max_setter;\n@@ -135,2 +100,20 @@\n-      \/\/ ZGlobalsPointers::initialize() sets ZAddressOffsetMax, make sure the\n-      \/\/ first test fixture invocation has a correct ZAddressOffsetMaxSetter.\n+      auto initialize_heap_settings = [&]() {\n+        assert(MaxHeapSize > 0, \"Expecting heap size to be initialized\");\n+        for (size_t heap_base_shift = ZAddressHeapBaseMinShift;\n+            heap_base_shift <= ZAddressHeapBaseMaxShift;\n+            heap_base_shift++) {\n+          const size_t heap_base = uintptr_t(1) << heap_base_shift;\n+          const size_t max_offset = (size_t)heap_base;\n+          if (MaxHeapSize <= max_offset) {\n+            ZGlobalsPointers::set_heap_limits(heap_base, heap_base + size_t(heap_base));\n+            return true;\n+          }\n+        }\n+\n+        return false;\n+      };\n+\n+      GTEST_EXPECT_TRUE(initialize_heap_settings()) << \"Failed to setup test fixture\";\n+\n+      \/\/ ZGlobalsPointers::set_heap_limits() sets ZAddressOffsetMax and ZAddressOffsetUpperLimit,\n+      \/\/ make sure the first test fixture invocation has a correct ZAddressOffsetLimitsSetter.\n@@ -139,0 +122,1 @@\n+      _zaddress_offset_max_setter._old_upper_limit = ZAddressOffsetMax;\n@@ -149,1 +133,2 @@\n-  bool is_os_supported() {\n+public:\n+  static bool is_os_supported() {\n@@ -154,0 +139,51 @@\n+class ZTestAddressReserver {\n+  ZVirtualMemoryReservation*      _reservation;\n+  bool                            _active;\n+\n+public:\n+  ZTestAddressReserver()\n+  : _reservation(nullptr),\n+    _active(false) {}\n+\n+  ~ZTestAddressReserver() {\n+    GTEST_EXPECT_FALSE(_active) << \"ZTestAddressReserver deconstructed without calling TearDown\";\n+  }\n+\n+  void SetUp(size_t reservation_size) {\n+    GTEST_EXPECT_TRUE(ZTest::is_os_supported()) << \"Should not use SetUp on unsupported systems\";\n+    GTEST_EXPECT_FALSE(_active) << \"SetUp called twice without a TearDown\";\n+    _active = true;\n+\n+    ZVirtualMemoryAdaptiveReserver reserver;\n+\n+    const size_t reserved = reserver.reserve(reservation_size, reservation_size);\n+\n+    GTEST_EXPECT_TRUE(reserved == reservation_size);\n+\n+    ZGlobalsPointers::set_heap_limits(reserver.heap_base(), reserver.end());\n+\n+    _reservation = (ZVirtualMemoryReservation*)os::malloc(sizeof(ZVirtualMemoryReservation), mtTest);\n+    _reservation = ::new (_reservation) ZVirtualMemoryReservation(reserver.reserved_ranges());\n+  }\n+\n+  void TearDown() {\n+    GTEST_EXPECT_TRUE(_active) << \"TearDown called without a preceding SetUp\";\n+    _active = false;\n+\n+    \/\/ Best-effort cleanup\n+    _reservation->unreserve_all();\n+    _reservation->~ZVirtualMemoryReservation();\n+    os::free(_reservation);\n+  }\n+\n+  ZVirtualMemoryReservation* reservation() {\n+    GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n+    return _reservation;\n+  }\n+\n+  ZVirtualMemoryRegistry* registry() {\n+    GTEST_EXPECT_TRUE(_active) << \"Should only use HeapReserver while active\";\n+    return &_reservation->_registry;\n+  }\n+};\n+\n","filename":"test\/hotspot\/gtest\/gc\/z\/zunittest.hpp","additions":87,"deletions":51,"binary":false,"changes":138,"status":"modified"}]}