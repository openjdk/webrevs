{"files":[{"patch":"@@ -1225,0 +1225,1 @@\n+  constexpr size_t batch_size = 128;\n@@ -1228,6 +1229,10 @@\n-  for (size_t bucket_it = 0; bucket_it < table->_size; bucket_it++) {\n-    ScopedCS cs(thread, this);\n-    size_t count = 0;\n-    Bucket* bucket = table->get_bucket(bucket_it);\n-    if (bucket->have_redirect() || bucket->is_locked()) {\n-      continue;\n+  size_t num_batches = table->_size \/ batch_size;\n+  for (size_t current_batch = 0; current_batch <= num_batches; current_batch++) {\n+    size_t batch_start = current_batch * batch_size;\n+    size_t batch_end;\n+    if (current_batch == num_batches) {\n+      \/\/ Last batch; walk over the remaining part of the table\n+      batch_end = batch_start + table->_size % batch_size;\n+    } else {\n+      \/\/ Not last batch; walk over the current batch\n+      batch_end = batch_start + batch_size;\n@@ -1235,5 +1240,16 @@\n-    Node* current_node = bucket->first();\n-    while (current_node != nullptr) {\n-      ++count;\n-      literal_bytes += vs_f(current_node->value());\n-      current_node = current_node->next();\n+    ScopedCS cs(thread, this);\n+    for (size_t bucket_it = batch_start;\n+         bucket_it < batch_end;\n+         bucket_it++) {\n+      size_t count = 0;\n+      Bucket* bucket = table->get_bucket(bucket_it);\n+      if (bucket->have_redirect() || bucket->is_locked()) {\n+        continue;\n+      }\n+      Node* current_node = bucket->first();\n+      while (current_node != nullptr) {\n+        ++count;\n+        literal_bytes += vs_f(current_node->value());\n+        current_node = current_node->next();\n+      }\n+      summary.add((double)count);\n@@ -1241,1 +1257,0 @@\n-    summary.add((double)count);\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.inline.hpp","additions":27,"deletions":12,"binary":false,"changes":39,"status":"modified"}]}