{"files":[{"patch":"@@ -0,0 +1,313 @@\n+\/*\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package jdk.internal.net.http.quic;\n+\n+import jdk.internal.net.http.common.Deadline;\n+import jdk.internal.net.http.common.Log;\n+import jdk.internal.net.http.common.TimeLine;\n+import jdk.internal.net.http.common.TimeSource;\n+import jdk.internal.net.http.common.Utils;\n+import jdk.internal.net.http.quic.frames.AckFrame;\n+import jdk.internal.net.http.quic.packets.QuicPacket;\n+\n+import java.util.Collection;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+\/**\n+ * Implementation of the common parts of a QUIC congestion controller based on RFC 9002.\n+ *\n+ * This class implements the common parts of a congestion controller:\n+ * - slow start\n+ * - loss recovery\n+ * - cooperation with pacer\n+ *\n+ * Subclasses implement congestion window growth in congestion avoidance phase.\n+ *\n+ * @spec https:\/\/www.rfc-editor.org\/info\/rfc9002\n+ *      RFC 9002: QUIC Loss Detection and Congestion Control\n+ *\/\n+abstract class QuicBaseCongestionController implements QuicCongestionController {\n+    \/\/ higher of 14720 and 2*maxDatagramSize; we use fixed maxDatagramSize\n+    private static final int INITIAL_WINDOW = Math.max(14720, 2 * QuicConnectionImpl.DEFAULT_DATAGRAM_SIZE);\n+    private static final int MAX_BYTES_IN_FLIGHT = Math.clamp(\n+            Utils.getLongProperty(\"jdk.httpclient.quic.maxBytesInFlight\", 1 << 24),\n+            1 << 14, 1 << 24);\n+    protected final TimeLine timeSource;\n+    protected final String dbgTag;\n+    protected final Lock lock = new ReentrantLock();\n+    protected long congestionWindow = INITIAL_WINDOW;\n+    protected int maxDatagramSize = QuicConnectionImpl.DEFAULT_DATAGRAM_SIZE;\n+    protected int minimumWindow = 2 * maxDatagramSize;\n+    protected long bytesInFlight;\n+    \/\/ maximum bytes in flight seen since the last congestion event\n+    protected long maxBytesInFlight;\n+    protected Deadline congestionRecoveryStartTime;\n+    protected long ssThresh = Long.MAX_VALUE;\n+\n+    private final QuicPacer pacer;\n+\n+    protected QuicBaseCongestionController(String dbgTag, QuicRttEstimator rttEstimator) {\n+        this.dbgTag = dbgTag;\n+        this.timeSource = TimeSource.source();\n+        this.pacer = new QuicPacer(rttEstimator, this);\n+    }\n+\n+    \/\/ for testing\n+    protected QuicBaseCongestionController(TimeLine source, QuicRttEstimator rttEstimator) {\n+        this.dbgTag = \"TEST\";\n+        this.timeSource = source;\n+        this.pacer = new QuicPacer(rttEstimator, this);\n+    }\n+\n+    protected boolean inCongestionRecovery(Deadline sentTime) {\n+        return (congestionRecoveryStartTime != null &&\n+                !sentTime.isAfter(congestionRecoveryStartTime));\n+    }\n+\n+    protected abstract void onCongestionEvent(Deadline sentTime);\n+\n+    private static boolean inFlight(QuicPacket packet) {\n+        \/\/ packet is in flight if it contains anything other than a single ACK frame\n+        \/\/ specifically, a packet containing padding is considered to be in flight.\n+        return packet.frames().size() != 1 ||\n+                !(packet.frames().get(0) instanceof AckFrame);\n+    }\n+\n+    @Override\n+    public boolean canSendPacket() {\n+        lock.lock();\n+        try {\n+            if (bytesInFlight >= MAX_BYTES_IN_FLIGHT) {\n+                return false;\n+            }\n+            if (isCwndLimited() || isPacerLimited()) {\n+                return false;\n+            }\n+            return true;\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void updateMaxDatagramSize(int newSize) {\n+        lock.lock();\n+        try {\n+            if (minimumWindow != newSize * 2) {\n+                minimumWindow = newSize * 2;\n+                maxDatagramSize = newSize;\n+                congestionWindow = Math.max(congestionWindow, minimumWindow);\n+            }\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void packetSent(int packetBytes) {\n+        lock.lock();\n+        try {\n+            bytesInFlight += packetBytes;\n+            if (bytesInFlight > maxBytesInFlight) {\n+                maxBytesInFlight = bytesInFlight;\n+            }\n+            pacer.packetSent(packetBytes);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void packetAcked(int packetBytes, Deadline sentTime) {\n+        lock.lock();\n+        try {\n+            bytesInFlight -= packetBytes;\n+            \/\/ RFC 9002 says we should not increase cwnd when application limited.\n+            \/\/ The concept itself is poorly defined.\n+            \/\/ Here we limit cwnd growth based on the maximum bytes in flight\n+            \/\/ observed since the last congestion event\n+            if (inCongestionRecovery(sentTime)) {\n+                if (Log.quicCC() && Log.trace()) {\n+                    Log.logQuic(dbgTag + \" Acked, in recovery: bytes: \" + packetBytes +\n+                            \", in flight: \" + bytesInFlight);\n+                }\n+                return;\n+            }\n+            boolean isAppLimited;\n+            if (congestionWindow < ssThresh) {\n+                isAppLimited = congestionWindow >= 2 * maxBytesInFlight;\n+                if (!isAppLimited) {\n+                    congestionWindow += packetBytes;\n+                }\n+            } else {\n+                isAppLimited = congestionAvoidanceAcked(packetBytes, sentTime);\n+            }\n+            if (Log.quicCC() && Log.trace()) {\n+                if (isAppLimited) {\n+                    Log.logQuic(dbgTag + \" Acked, not blocked: bytes: \" + packetBytes +\n+                            \", in flight: \" + bytesInFlight);\n+                } else {\n+                    Log.logQuic(dbgTag + \" Acked, increased: bytes: \" + packetBytes +\n+                            \", in flight: \" + bytesInFlight +\n+                            \", new cwnd:\" + congestionWindow);\n+                }\n+            }\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    protected abstract boolean congestionAvoidanceAcked(int packetBytes, Deadline sentTime);\n+\n+    @Override\n+    public void packetLost(Collection<QuicPacket> lostPackets, Deadline sentTime, boolean persistent) {\n+        lock.lock();\n+        try {\n+            for (QuicPacket packet : lostPackets) {\n+                if (inFlight(packet)) {\n+                    bytesInFlight -= packet.size();\n+                }\n+            }\n+            onCongestionEvent(sentTime);\n+            if (persistent) {\n+                congestionWindow = minimumWindow;\n+                congestionRecoveryStartTime = null;\n+                if (Log.quicCC()) {\n+                    Log.logQuic(dbgTag + \" Persistent congestion: ssThresh: \" + ssThresh +\n+                            \", in flight: \" + bytesInFlight +\n+                            \", cwnd:\" + congestionWindow);\n+                }\n+            }\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void packetDiscarded(Collection<QuicPacket> discardedPackets) {\n+        lock.lock();\n+        try {\n+            for (QuicPacket packet : discardedPackets) {\n+                if (inFlight(packet)) {\n+                    bytesInFlight -= packet.size();\n+                }\n+            }\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public long congestionWindow() {\n+        lock.lock();\n+        try {\n+            return congestionWindow;\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public long initialWindow() {\n+        lock.lock();\n+        try {\n+            return Math.max(14720, 2 * maxDatagramSize);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public long maxDatagramSize() {\n+        lock.lock();\n+        try {\n+            return maxDatagramSize;\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public boolean isSlowStart() {\n+        lock.lock();\n+        try {\n+            return congestionWindow < ssThresh;\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void updatePacer(Deadline now) {\n+        lock.lock();\n+        try {\n+            pacer.updateQuota(now);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public boolean isPacerLimited() {\n+        lock.lock();\n+        try {\n+            return !pacer.canSend();\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public boolean isCwndLimited() {\n+        lock.lock();\n+        try {\n+            return congestionWindow - bytesInFlight < maxDatagramSize;\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public Deadline pacerDeadline() {\n+        lock.lock();\n+        try {\n+            return pacer.twoPacketDeadline();\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    @Override\n+    public void appLimited() {\n+        lock.lock();\n+        try {\n+            pacer.appLimited();\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+}\n","filename":"src\/java.net.http\/share\/classes\/jdk\/internal\/net\/http\/quic\/QuicBaseCongestionController.java","additions":313,"deletions":0,"binary":false,"changes":313,"status":"added"},{"patch":"@@ -337,1 +337,1 @@\n-        this.congestionController = new QuicRenoCongestionController(dbgTag, rttEstimator);\n+        this.congestionController = createCongestionController(dbgTag, rttEstimator);\n@@ -369,0 +369,10 @@\n+    private static QuicCongestionController createCongestionController\n+            (String dbgTag, QuicRttEstimator rttEstimator) {\n+        String algo = System.getProperty(\"jdk.httpclient.quic.congestionController\", \"cubic\");\n+        if (algo.equalsIgnoreCase(\"reno\")) {\n+            return new QuicRenoCongestionController(dbgTag, rttEstimator);\n+        } else {\n+            return new QuicCubicCongestionController(dbgTag, rttEstimator);\n+        }\n+    }\n+\n","filename":"src\/java.net.http\/share\/classes\/jdk\/internal\/net\/http\/quic\/QuicConnectionImpl.java","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,168 @@\n+\/*\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package jdk.internal.net.http.quic;\n+\n+import jdk.internal.net.http.common.Deadline;\n+import jdk.internal.net.http.common.Log;\n+import jdk.internal.net.http.common.TimeLine;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+\/**\n+ * Implementation of the CUBIC congestion controller\n+ * based on RFC 9438.\n+ *\n+ * @spec https:\/\/www.rfc-editor.org\/rfc\/rfc9438.html\n+ *       RFC 9438: CUBIC for Fast and Long-Distance Networks\n+ *\/\n+public class QuicCubicCongestionController extends QuicBaseCongestionController {\n+\n+    public static final double BETA = 0.7;\n+    public static final double ALPHA = 3 * (1 - BETA) \/ (1 + BETA);\n+    private static final double C = 0.4;\n+    private final QuicRttEstimator rttEstimator;\n+    \/\/ Cubic curve inflection point, in bytes\n+    private long wMaxBytes;\n+    \/\/ cwnd before the most recent congestion event\n+    private long cwndPriorBytes;\n+    \/\/ \"t\" from RFC 9438\n+    private long timeNanos;\n+    \/\/ \"K\" from RFC 9438\n+    private long kNanos;\n+    \/\/ estimate for the Reno-friendly congestion window\n+    private long wEstBytes;\n+    \/\/ the most recent time when the congestion window was filled\n+    private Deadline lastFullWindow;\n+\n+    public QuicCubicCongestionController(String dbgTag, QuicRttEstimator rttEstimator) {\n+        super(dbgTag, rttEstimator);\n+        this.rttEstimator = rttEstimator;\n+    }\n+\n+    \/\/ for testing\n+    public QuicCubicCongestionController(TimeLine source, QuicRttEstimator rttEstimator) {\n+        super(source, rttEstimator);\n+        this.rttEstimator = rttEstimator;\n+    }\n+\n+    @Override\n+    public void packetSent(int packetBytes) {\n+        lock.lock();\n+        try {\n+            super.packetSent(packetBytes);\n+            if (isCwndLimited()) {\n+                Deadline now = timeSource.instant();\n+                if (lastFullWindow == null) {\n+                    lastFullWindow = now;\n+                } else {\n+                    long timePassedNanos = Deadline.between(lastFullWindow, now).toNanos();\n+                    if (timePassedNanos > 0) {\n+                        \/* \"The elapsed time MUST NOT include periods during which cwnd\n+                           has not been updated due to application-limited behavior\"\n+                           \"A flow is application limited if it is currently sending less\n+                            than what is allowed by the congestion window.\"\n+\n+                           We are sending asynchronously; one thread is sending data,\n+                           a separate thread is processing the acknowledgements.\n+                           We can't rely on cwnd being fully utilized when we process an ack, because\n+                           most of the time it won't be.\n+\n+                           Instead, we assume that if we filled the cwnd, we were not application-limited\n+                           in the last RTT (which is a pretty good approximation because of pacing),\n+                           and acknowledgements for all packets sent prior to filling the cwnd\n+                           count towards cwnd increase.\n+                         *\/\n+                        long rttNanos = TimeUnit.MICROSECONDS.toNanos(rttEstimator.state().smoothedRttMicros());\n+                        timeNanos += Math.min(timePassedNanos, rttNanos);\n+                        lastFullWindow = now;\n+                    }\n+                }\n+            }\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+\n+    protected boolean congestionAvoidanceAcked(int packetBytes, Deadline sentTime) {\n+        boolean isAppLimited;\n+        isAppLimited = sentTime.isAfter(lastFullWindow);\n+        if (!isAppLimited) {\n+            if (wEstBytes < cwndPriorBytes) {\n+                wEstBytes += Math.max((long) (ALPHA * maxDatagramSize * packetBytes \/ congestionWindow), 1);\n+            } else {\n+                wEstBytes += Math.max((long)maxDatagramSize * packetBytes \/ congestionWindow, 1);\n+            }\n+            \/\/ Wcubic(t) = C * (t-K [seconds])^3 + Wmax (segments)\n+            \/\/ target = Wcubic(t)\n+            \/\/ this is less aggressive than RFC 9438, which uses target=Wcubic(t+RTT),\n+            \/\/ but seems to work well enough\n+            double dblTargetBytes = (C * maxDatagramSize * Math.pow((timeNanos - kNanos) \/ 1e9, 3)) + wMaxBytes;\n+            long targetBytes;\n+            \/\/ not sure if dblTarget can overflow a long, but 1.5 congestionWindow can not.\n+            if (dblTargetBytes > 1.5 * congestionWindow) {\n+                targetBytes = (long) (1.5 * congestionWindow);\n+            } else {\n+                targetBytes = (long)dblTargetBytes;\n+            }\n+            if (targetBytes > congestionWindow) {\n+                congestionWindow += Math.max((targetBytes - congestionWindow) * packetBytes \/ congestionWindow, 1L);\n+            }\n+            if (wEstBytes > congestionWindow) {\n+                congestionWindow = wEstBytes;\n+            }\n+        }\n+        return isAppLimited;\n+    }\n+\n+    protected void onCongestionEvent(Deadline sentTime) {\n+        if (inCongestionRecovery(sentTime)) {\n+            return;\n+        }\n+        if (congestionWindow < wMaxBytes) {\n+            \/\/ fast convergence\n+            wMaxBytes = (long) ((1 + BETA) * congestionWindow \/ 2);\n+        } else {\n+            wMaxBytes = congestionWindow;\n+        }\n+        cwndPriorBytes = congestionWindow;\n+        congestionRecoveryStartTime = timeSource.instant();\n+        ssThresh = (long)(congestionWindow * BETA);\n+        wEstBytes = congestionWindow = Math.max(minimumWindow, ssThresh);\n+        maxBytesInFlight = 0;\n+        timeNanos = 0;\n+        \/\/ set lastFullWindow to prevent rapid timeNanos growth\n+        lastFullWindow = congestionRecoveryStartTime;\n+        \/\/ ((wmax_segments - cwnd_segments) \/ C) ^ (1\/3) seconds\n+        kNanos = (long)(Math.cbrt((wMaxBytes - congestionWindow) \/ C \/ maxDatagramSize) * 1_000_000_000);\n+        if (Log.quicCC()) {\n+            Log.logQuic(dbgTag + \" Congestion: ssThresh: \" + ssThresh +\n+                    \", in flight: \" + bytesInFlight +\n+                    \", cwnd:\" + congestionWindow +\n+                    \", K: \" + TimeUnit.NANOSECONDS.toMillis(kNanos) + \" ms\");\n+        }\n+    }\n+}\n","filename":"src\/java.net.http\/share\/classes\/jdk\/internal\/net\/http\/quic\/QuicCubicCongestionController.java","additions":168,"deletions":0,"binary":false,"changes":168,"status":"added"},{"patch":"@@ -30,9 +30,0 @@\n-import jdk.internal.net.http.common.TimeLine;\n-import jdk.internal.net.http.common.TimeSource;\n-import jdk.internal.net.http.common.Utils;\n-import jdk.internal.net.http.quic.frames.AckFrame;\n-import jdk.internal.net.http.quic.packets.QuicPacket;\n-\n-import java.util.Collection;\n-import java.util.concurrent.locks.Lock;\n-import java.util.concurrent.locks.ReentrantLock;\n@@ -49,20 +40,1 @@\n-class QuicRenoCongestionController implements QuicCongestionController {\n-    \/\/ higher of 14720 and 2*maxDatagramSize; we use fixed maxDatagramSize\n-    private static final int INITIAL_WINDOW = Math.max(14720, 2 * QuicConnectionImpl.DEFAULT_DATAGRAM_SIZE);\n-    private static final int MAX_BYTES_IN_FLIGHT = Math.clamp(\n-            Utils.getLongProperty(\"jdk.httpclient.quic.maxBytesInFlight\", 1 << 24),\n-            1 << 14, 1 << 24);\n-    private final TimeLine timeSource;\n-    private final String dbgTag;\n-    private final Lock lock = new ReentrantLock();\n-    private long congestionWindow = INITIAL_WINDOW;\n-    private int maxDatagramSize = QuicConnectionImpl.DEFAULT_DATAGRAM_SIZE;\n-    private int minimumWindow = 2 * maxDatagramSize;\n-    private long bytesInFlight;\n-    \/\/ maximum bytes in flight seen since the last congestion event\n-    private long maxBytesInFlight;\n-    private Deadline congestionRecoveryStartTime;\n-    private long ssThresh = Long.MAX_VALUE;\n-\n-    private final QuicPacer pacer;\n-\n+class QuicRenoCongestionController extends QuicBaseCongestionController {\n@@ -70,3 +42,1 @@\n-        this.dbgTag = dbgTag;\n-        this.timeSource = TimeSource.source();\n-        this.pacer = new QuicPacer(rttEstimator, this);\n+        super(dbgTag, rttEstimator);\n@@ -75,3 +45,7 @@\n-    private boolean inCongestionRecovery(Deadline sentTime) {\n-        return (congestionRecoveryStartTime != null &&\n-                !sentTime.isAfter(congestionRecoveryStartTime));\n+    protected boolean congestionAvoidanceAcked(int packetBytes, Deadline sentTime) {\n+        boolean isAppLimited;\n+        isAppLimited = congestionWindow > maxBytesInFlight + 2L * maxDatagramSize;\n+        if (!isAppLimited) {\n+            congestionWindow += Math.max((long) maxDatagramSize * packetBytes \/ congestionWindow, 1L);\n+        }\n+        return isAppLimited;\n@@ -80,1 +54,1 @@\n-    private void onCongestionEvent(Deadline sentTime) {\n+    protected void onCongestionEvent(Deadline sentTime) {\n@@ -94,222 +68,0 @@\n-\n-    private static boolean inFlight(QuicPacket packet) {\n-        \/\/ packet is in flight if it contains anything other than a single ACK frame\n-        \/\/ specifically, a packet containing padding is considered to be in flight.\n-        return packet.frames().size() != 1 ||\n-                !(packet.frames().get(0) instanceof AckFrame);\n-    }\n-\n-    @Override\n-    public boolean canSendPacket() {\n-        lock.lock();\n-        try {\n-            if (bytesInFlight >= MAX_BYTES_IN_FLIGHT) {\n-                return false;\n-            }\n-            if (isCwndLimited() || isPacerLimited()) {\n-                return false;\n-            }\n-            return true;\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void updateMaxDatagramSize(int newSize) {\n-        lock.lock();\n-        try {\n-            if (minimumWindow != newSize * 2) {\n-                minimumWindow = newSize * 2;\n-                maxDatagramSize = newSize;\n-                congestionWindow = Math.max(congestionWindow, minimumWindow);\n-            }\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void packetSent(int packetBytes) {\n-        lock.lock();\n-        try {\n-            bytesInFlight += packetBytes;\n-            if (bytesInFlight > maxBytesInFlight) {\n-                maxBytesInFlight = bytesInFlight;\n-            }\n-            pacer.packetSent(packetBytes);\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void packetAcked(int packetBytes, Deadline sentTime) {\n-        lock.lock();\n-        try {\n-            bytesInFlight -= packetBytes;\n-            \/\/ RFC 9002 says we should not increase cwnd when application limited.\n-            \/\/ The concept itself is poorly defined.\n-            \/\/ Here we limit cwnd growth based on the maximum bytes in flight\n-            \/\/ observed since the last congestion event\n-            if (inCongestionRecovery(sentTime)) {\n-                if (Log.quicCC() && Log.trace()) {\n-                    Log.logQuic(dbgTag + \" Acked, in recovery: bytes: \" + packetBytes +\n-                            \", in flight: \" + bytesInFlight);\n-                }\n-                return;\n-            }\n-            boolean isAppLimited;\n-            if (congestionWindow < ssThresh) {\n-                isAppLimited = congestionWindow >= 2 * maxBytesInFlight;\n-                if (!isAppLimited) {\n-                    congestionWindow += packetBytes;\n-                }\n-            } else {\n-                isAppLimited = congestionWindow > maxBytesInFlight + 2L * maxDatagramSize;\n-                if (!isAppLimited) {\n-                    congestionWindow += Math.max((long) maxDatagramSize * packetBytes \/ congestionWindow, 1L);\n-                }\n-            }\n-            if (Log.quicCC() && Log.trace()) {\n-                if (isAppLimited) {\n-                    Log.logQuic(dbgTag + \" Acked, not blocked: bytes: \" + packetBytes +\n-                            \", in flight: \" + bytesInFlight);\n-                } else {\n-                    Log.logQuic(dbgTag + \" Acked, increased: bytes: \" + packetBytes +\n-                            \", in flight: \" + bytesInFlight +\n-                            \", new cwnd:\" + congestionWindow);\n-                }\n-            }\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void packetLost(Collection<QuicPacket> lostPackets, Deadline sentTime, boolean persistent) {\n-        lock.lock();\n-        try {\n-            for (QuicPacket packet : lostPackets) {\n-                if (inFlight(packet)) {\n-                    bytesInFlight -= packet.size();\n-                }\n-            }\n-            onCongestionEvent(sentTime);\n-            if (persistent) {\n-                congestionWindow = minimumWindow;\n-                congestionRecoveryStartTime = null;\n-                if (Log.quicCC()) {\n-                    Log.logQuic(dbgTag + \" Persistent congestion: ssThresh: \" + ssThresh +\n-                            \", in flight: \" + bytesInFlight +\n-                            \", cwnd:\" + congestionWindow);\n-                }\n-            }\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void packetDiscarded(Collection<QuicPacket> discardedPackets) {\n-        lock.lock();\n-        try {\n-            for (QuicPacket packet : discardedPackets) {\n-                if (inFlight(packet)) {\n-                    bytesInFlight -= packet.size();\n-                }\n-            }\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public long congestionWindow() {\n-        lock.lock();\n-        try {\n-            return congestionWindow;\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public long initialWindow() {\n-        lock.lock();\n-        try {\n-            return Math.max(14720, 2 * maxDatagramSize);\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public long maxDatagramSize() {\n-        lock.lock();\n-        try {\n-            return maxDatagramSize;\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public boolean isSlowStart() {\n-        lock.lock();\n-        try {\n-            return congestionWindow < ssThresh;\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void updatePacer(Deadline now) {\n-        lock.lock();\n-        try {\n-            pacer.updateQuota(now);\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public boolean isPacerLimited() {\n-        lock.lock();\n-        try {\n-            return !pacer.canSend();\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public boolean isCwndLimited() {\n-        lock.lock();\n-        try {\n-            return congestionWindow - bytesInFlight < maxDatagramSize;\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public Deadline pacerDeadline() {\n-        lock.lock();\n-        try {\n-            return pacer.twoPacketDeadline();\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n-\n-    @Override\n-    public void appLimited() {\n-        lock.lock();\n-        try {\n-            pacer.appLimited();\n-        } finally {\n-            lock.unlock();\n-        }\n-    }\n","filename":"src\/java.net.http\/share\/classes\/jdk\/internal\/net\/http\/quic\/QuicRenoCongestionController.java","additions":10,"deletions":258,"binary":false,"changes":268,"status":"modified"},{"patch":"@@ -0,0 +1,220 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+import jdk.internal.net.http.common.Deadline;\n+import jdk.internal.net.http.common.TimeLine;\n+import jdk.internal.net.http.quic.*;\n+import jdk.internal.net.http.quic.frames.PaddingFrame;\n+import jdk.internal.net.http.quic.frames.QuicFrame;\n+import jdk.internal.net.http.quic.packets.QuicPacket;\n+import org.testng.annotations.Test;\n+\n+import java.time.temporal.ChronoUnit;\n+import java.time.temporal.TemporalUnit;\n+import java.util.List;\n+\n+import static jdk.internal.net.http.quic.QuicCubicCongestionController.ALPHA;\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+\/*\n+ * @test\n+ * @run testng\/othervm -Djdk.httpclient.HttpClient.log=trace,quic:cc CubicTest\n+ *\/\n+public class CubicTest {\n+    static class TimeSource implements TimeLine {\n+        final Deadline first = jdk.internal.net.http.common.TimeSource.now();\n+        volatile Deadline current = first;\n+        public synchronized Deadline advance(long duration, TemporalUnit unit) {\n+            return current = current.plus(duration, unit);\n+        }\n+        public Deadline advanceMillis(long millis) {\n+            return advance(millis, ChronoUnit.MILLIS);\n+        }\n+        @Override\n+        public Deadline instant() {\n+            return current;\n+        }\n+    }\n+\n+    private final TimeSource timeSource = new TimeSource();\n+\n+    private class TestQuicPacket implements QuicPacket {\n+        private final int size;\n+\n+        public TestQuicPacket(int size) {\n+            this.size = size;\n+        }\n+\n+        @Override\n+        public List<QuicFrame> frames() {\n+            \/\/ fool congestion controller that this packet is in flight\n+            return List.of(new PaddingFrame(1));\n+        }\n+\n+        @Override\n+        public QuicConnectionId destinationId() {\n+            throw new AssertionError(\"Should not come here\");\n+        }\n+\n+        @Override\n+        public PacketNumberSpace numberSpace() {\n+            throw new AssertionError(\"Should not come here\");\n+        }\n+\n+        @Override\n+        public int size() {\n+            return size;\n+        }\n+\n+        @Override\n+        public HeadersType headersType() {\n+            throw new AssertionError(\"Should not come here\");\n+        }\n+\n+        @Override\n+        public PacketType packetType() {\n+            throw new AssertionError(\"Should not come here\");\n+        }\n+    }\n+\n+    @Test\n+    public void testReduction() {\n+        System.err.println(\"***** testReduction *****\");\n+        QuicRttEstimator rtt = new QuicRttEstimator();\n+        rtt.consumeRttSample(1, 0, Deadline.MIN);\n+        QuicCongestionController cc = new QuicCubicCongestionController(timeSource, rtt);\n+        int packetSize = (int) cc.maxDatagramSize();\n+        assertEquals(cc.congestionWindow(), cc.initialWindow(), \"Unexpected starting congestion window\");\n+        do {\n+            cc.packetSent(packetSize);\n+            \/\/ reduce to 70% of the last value, but not below 2*SMSS\n+            long newCongestionWindow = Math.max((long) (QuicCubicCongestionController.BETA * cc.congestionWindow()), 2 * packetSize);\n+            cc.packetLost(List.of(new TestQuicPacket(packetSize)), Deadline.MAX, false);\n+            assertEquals(cc.congestionWindow(), newCongestionWindow, \"Unexpected reduced congestion window\");\n+        } while (cc.congestionWindow() > 2 * packetSize);\n+    }\n+\n+    @Test\n+    public void testAppLimited() {\n+        System.err.println(\"***** testAppLimited *****\");\n+        QuicRttEstimator rtt = new QuicRttEstimator();\n+        rtt.consumeRttSample(1, 0, Deadline.MIN);\n+        QuicCongestionController cc = new QuicCubicCongestionController(timeSource, rtt);\n+        int packetSize = (int) cc.maxDatagramSize();\n+        assertEquals(cc.congestionWindow(), cc.initialWindow(), \"Unexpected starting congestion window\");\n+        cc.packetSent(packetSize);\n+        long newCongestionWindow = (long) (QuicCubicCongestionController.BETA * cc.congestionWindow());\n+        \/\/ lose packet to exit slow start\n+        cc.packetLost(List.of(new TestQuicPacket(packetSize)), Deadline.MAX, false);\n+        assertEquals(cc.congestionWindow(), newCongestionWindow, \"Unexpected reduced congestion window\");\n+        Deadline sentTime = timeSource.instant().plus(1, ChronoUnit.NANOS);\n+        \/\/ congestion window should not increase when sender is app-limited\n+        cc.packetSent(packetSize);\n+        cc.packetAcked(packetSize, sentTime);\n+        assertEquals(cc.congestionWindow(), newCongestionWindow, \"Unexpected congestion window change\");\n+    }\n+\n+    @Test\n+    public void testRenoFriendly() {\n+        System.err.println(\"***** testRenoFriendly *****\");\n+        QuicRttEstimator rtt = new QuicRttEstimator();\n+        rtt.consumeRttSample(1, 0, Deadline.MIN);\n+        QuicCongestionController cc = new QuicCubicCongestionController(timeSource, rtt);\n+        int packetSize = (int) cc.maxDatagramSize();\n+        assertEquals(cc.congestionWindow(), cc.initialWindow(), \"Unexpected starting congestion window\");\n+        int startingWindow = (int) cc.congestionWindow();\n+        \/\/ lose packet to exit slow start\n+        cc.packetSent(packetSize);\n+        long newCongestionWindow = (long) (QuicCubicCongestionController.BETA * cc.congestionWindow());\n+        cc.packetLost(List.of(new TestQuicPacket(packetSize)), timeSource.instant(), false);\n+        assertEquals(cc.congestionWindow(), newCongestionWindow, \"Unexpected reduced congestion window\");\n+        \/\/ exit loss recovery to start increasing cwnd\n+        Deadline sentTime = timeSource.advanceMillis(1);\n+        do {\n+            \/\/ test that the window increases roughly by ALPHA * maxDatagramSize every RTT\n+            int startingCwnd = (int) cc.congestionWindow();\n+            cc.packetSent(startingCwnd);\n+            \/\/ we ack the entire window in one call; in practice the increase will be slower\n+            \/\/ because cwnd increases (and increase rate reduces) after every call to packetAcked\n+            cc.packetAcked(startingCwnd, sentTime);\n+            long expectedCwnd = (long) (startingCwnd + ALPHA * packetSize);\n+            long actualCwnd = cc.congestionWindow();\n+            assertTrue(actualCwnd >= expectedCwnd - 1 && actualCwnd <= expectedCwnd + 1,\n+                    \"actual cwnd %s not within the expected range (%s, %s)\".formatted(\n+                            actualCwnd, expectedCwnd - 1, expectedCwnd + 1\n+                    ));\n+        } while (cc.congestionWindow() < startingWindow);\n+        \/\/ test that the window increases roughly by maxDatagramSize every RTT after passing cwndPrior\n+        int startingCwnd = (int) cc.congestionWindow();\n+        cc.packetSent(startingCwnd);\n+        cc.packetAcked(startingCwnd, sentTime);\n+        int expectedCwnd = startingCwnd + packetSize;\n+        long actualCwnd = cc.congestionWindow();\n+        assertTrue(actualCwnd >= expectedCwnd - 1 && actualCwnd <= expectedCwnd + 1,\n+                \"actual cwnd %s not within the expected range (%s, %s)\".formatted(\n+                        actualCwnd, expectedCwnd - 1, expectedCwnd + 1\n+                ));\n+    }\n+\n+    @Test\n+    public void testCubic() {\n+        \/*\n+         Manually created test vector:\n+         - ramp up the congestion window to 36 packets\n+         - trigger congestion; window will be reduced to 25.2 packets, K=3 seconds\n+         - to make things easier, set RTT = 3+ seconds, advance \"t\" to 3 seconds,\n+           send and acknowledge a whole cwnd of data\n+         - cwnd should be back to 36 packets, give or take a few bytes.\n+         *\/\n+        System.err.println(\"***** testCubic *****\");\n+        QuicRttEstimator rtt = new QuicRttEstimator();\n+        rtt.consumeRttSample(4_000_000, 0, Deadline.MIN);\n+        QuicCongestionController cc = new QuicCubicCongestionController(timeSource, rtt);\n+        int packetSize = (int) cc.maxDatagramSize();\n+        long cwnd = cc.congestionWindow();\n+        \/\/ ramp up the congestion window to 36 packets\n+        int tmp = (int) (36 * packetSize - cwnd);\n+        cc.packetSent(tmp + packetSize);\n+        cc.packetAcked(tmp, timeSource.instant());\n+        assertEquals(cc.congestionWindow(), 36*packetSize, \"Unexpected congestion window\");\n+        long newCongestionWindow = (long) (QuicCubicCongestionController.BETA * cc.congestionWindow());\n+        \/\/ trigger congestion; window will be reduced to 25.2 packets, K=3 seconds\n+        cc.packetLost(List.of(new TestQuicPacket(packetSize)), timeSource.instant(), false);\n+        assertEquals(cc.congestionWindow(), newCongestionWindow, \"Unexpected reduced congestion window\");\n+        \/\/ advance \"t\" to 3 seconds,\n+        Deadline sentTime = timeSource.advanceMillis(3000);\n+        \/\/ send and acknowledge a whole cwnd of data\n+        tmp = (int) cc.congestionWindow();\n+        cc.packetSent(tmp);\n+        \/\/ we ack the entire window in one call; in practice the increase will be slower\n+        \/\/ because cwnd increases (and increase rate reduces) after every call to packetAcked\n+        cc.packetAcked(tmp, sentTime);\n+        long expectedCwnd = 36 * packetSize;\n+        long actualCwnd = cc.congestionWindow();\n+        assertTrue(actualCwnd >= expectedCwnd - 1 && actualCwnd <= expectedCwnd + 1,\n+                \"actual cwnd %s not within the expected range (%s, %s)\".formatted(\n+                        actualCwnd, expectedCwnd - 1, expectedCwnd + 1\n+                ));\n+    }\n+}\n","filename":"test\/jdk\/java\/net\/httpclient\/quic\/CubicTest.java","additions":220,"deletions":0,"binary":false,"changes":220,"status":"added"}]}