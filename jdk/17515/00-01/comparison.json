{"files":[{"patch":"@@ -1848,0 +1848,6 @@\n+void Assembler::cmpb(Register dst, int imm8) {\n+  assert(dst->has_byte_register(), \"must have byte register\");\n+  prefix(dst);\n+  emit_arith_b(0x80, 0xF8, dst, imm8);\n+}\n+\n@@ -8976,1 +8982,1 @@\n-void Assembler::vinserti64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8) {\n+void Assembler::vinserti64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8, int vector_len) {\n@@ -8978,1 +8984,2 @@\n-   InstructionAttr attributes(AVX_512bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+   assert(vector_len == AVX_256bit || VM_Version::supports_avx512vl(), \"\");\n+   InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n@@ -11050,0 +11057,1 @@\n+  assert(vector_len == AVX_256bit || VM_Version::supports_avx512vl(), \"\");\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1196,0 +1196,1 @@\n+  void cmpb(Register reg, int imm8);\n@@ -2821,1 +2822,1 @@\n-  void vinserti64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8);\n+  void vinserti64x2(XMMRegister dst, XMMRegister nds, XMMRegister src, uint8_t imm8, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -380,3 +380,4 @@\n-                                         Register CTR_CHECK, Register NROUNDS, Register key, bool hk_broadcast,\n-                                         bool is_hash_start, bool do_hash_reduction, bool do_hash_hxor, bool no_ghash_in,\n-                                         int ghashin_offset, int aesout_offset, int hashkey_offset);\n+                                         Register CTR_CHECK, Register NROUNDS, Register key, XMMRegister CTR, XMMRegister GHASH,\n+                                         XMMRegister ADDBE_4x4, XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHUF_MASK,\n+                                         bool hk_broadcast, bool is_hash_start, bool do_hash_reduction, bool do_hash_hxor,\n+                                         bool no_ghash_in, int ghashin_offset, int aesout_offset, int hashkey_offset);\n@@ -386,3 +387,3 @@\n-                                XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHUF_MASK, int stack_offset, bool no_ghash);\n-  void gcm_enc_dec_last_avx512(Register len, Register in, Register pos, XMMRegister HASH, Register subkeyHtbl, int ghashin_offset,\n-                               int hashkey_offset, bool start_ghash, bool do_reduction);\n+                                XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHUF_MASK, int stack_offset);\n+  void gcm_enc_dec_last_avx512(Register len, Register in, Register pos, XMMRegister HASH, XMMRegister SHUFM, Register subkeyHtbl,\n+                               int ghashin_offset, int hashkey_offset, bool start_ghash, bool do_reduction);\n@@ -390,1 +391,1 @@\n-                      Register in, Register pos, Register subkeyHtbl, XMMRegister HASH, int in_offset,\n+                      Register in, Register pos, Register subkeyHtbl, XMMRegister HASH, XMMRegister SHUFM, int in_offset,\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -177,4 +177,4 @@\n-    0x0000000000000000UL, 0x0400000000000000UL,\n-    0x0000000000000000UL, 0x0400000000000000UL,\n-    0x0000000000000000UL, 0x0400000000000000UL,\n-    0x0000000000000000UL, 0x0400000000000000UL,\n+    0x0000000000000000ULL, 0x0400000000000000ULL,\n+    0x0000000000000000ULL, 0x0400000000000000ULL,\n+    0x0000000000000000ULL, 0x0400000000000000ULL,\n+    0x0000000000000000ULL, 0x0400000000000000ULL,\n@@ -188,4 +188,4 @@\n-    0x0000000000000000UL, 0x0100000000000000UL,\n-    0x0000000000000000UL, 0x0200000000000000UL,\n-    0x0000000000000000UL, 0x0300000000000000UL,\n-    0x0000000000000000UL, 0x0400000000000000UL,\n+    0x0000000000000000ULL, 0x0100000000000000ULL,\n+    0x0000000000000000ULL, 0x0200000000000000ULL,\n+    0x0000000000000000ULL, 0x0300000000000000ULL,\n+    0x0000000000000000ULL, 0x0400000000000000ULL,\n@@ -199,4 +199,4 @@\n-    0x0000000000000001UL, 0x0000000000000000UL,\n-    0x0000000000000002UL, 0x0000000000000000UL,\n-    0x0000000000000003UL, 0x0000000000000000UL,\n-    0x0000000000000004UL, 0x0000000000000000UL,\n+    0x0000000000000001ULL, 0x0000000000000000ULL,\n+    0x0000000000000002ULL, 0x0000000000000000ULL,\n+    0x0000000000000003ULL, 0x0000000000000000ULL,\n+    0x0000000000000004ULL, 0x0000000000000000ULL,\n@@ -298,1 +298,1 @@\n-  __ subptr(rsp, 200 * longSize); \/\/ Create space on the stack for htbl entries\n+  __ subptr(rsp, 200 * longSize); \/\/ Create space on the stack for 64 htbl entries and 4 zmm AES entries\n@@ -2749,1 +2749,1 @@\n-  const XMMRegister T5 = xmm4;\n+  const XMMRegister ZT10 = xmm10, ZT11 = xmm11, ZT12 = xmm12;\n@@ -2752,4 +2752,4 @@\n-  __ movdqu(xmm10, ExternalAddress(ghash_long_swap_mask_addr()), r15);\n-  __ vpshufb(HK, HK, xmm10, Assembler::AVX_128bit);\n-  __ movdqu(xmm11, ExternalAddress(ghash_polynomial_addr()), r15);\n-  __ movdqu(xmm12, ExternalAddress(ghash_polynomial_two_one_addr()), r15);\n+  __ movdqu(ZT10, ExternalAddress(ghash_long_swap_mask_addr()), r15);\n+  __ vpshufb(HK, HK, ZT10, Assembler::AVX_128bit);\n+  __ movdqu(ZT11, ExternalAddress(ghash_polynomial_addr()), r15);\n+  __ movdqu(ZT12, ExternalAddress(ghash_polynomial_two_one_addr()), r15);\n@@ -2757,15 +2757,15 @@\n-  __ movdqu(xmm2, xmm6);\n-  __ vpsllq(xmm6, xmm6, 1, Assembler::AVX_128bit);\n-  __ vpsrlq(xmm2, xmm2, 63, Assembler::AVX_128bit);\n-  __ movdqu(xmm1, xmm2);\n-  __ vpslldq(xmm2, xmm2, 8, Assembler::AVX_128bit);\n-  __ vpsrldq(xmm1, xmm1, 8, Assembler::AVX_128bit);\n-  __ vpor(xmm6, xmm6, xmm2, Assembler::AVX_128bit);\n-  __ vpshufd(xmm2, xmm1, 0x24, Assembler::AVX_128bit);\n-  __ vpcmpeqd(xmm2, xmm2, xmm12, Assembler::AVX_128bit);\n-  __ vpand(xmm2, xmm2, xmm11, Assembler::AVX_128bit);\n-  __ vpxor(xmm6, xmm6, xmm2, Assembler::AVX_128bit);\n-  __ movdqu(Address(avx512_htbl, 16 * 31), xmm6); \/\/ H ^ 2\n-\n-  __ movdqu(T5, HK);\n-  __ vinserti64x2(ZT7, ZT7, HK, 3);\n+  __ movdqu(ZT3, HK);\n+  __ vpsllq(HK, HK, 1, Assembler::AVX_128bit);\n+  __ vpsrlq(ZT3, ZT3, 63, Assembler::AVX_128bit);\n+  __ movdqu(ZT2, ZT3);\n+  __ vpslldq(ZT3, ZT3, 8, Assembler::AVX_128bit);\n+  __ vpsrldq(ZT2, ZT2, 8, Assembler::AVX_128bit);\n+  __ vpor(HK, HK, ZT3, Assembler::AVX_128bit);\n+  __ vpshufd(ZT3, ZT2, 0x24, Assembler::AVX_128bit);\n+  __ vpcmpeqd(ZT3, ZT3, ZT12, Assembler::AVX_128bit);\n+  __ vpand(ZT3, ZT3, ZT11, Assembler::AVX_128bit);\n+  __ vpxor(HK, HK, ZT3, Assembler::AVX_128bit);\n+  __ movdqu(Address(avx512_htbl, 16 * 31), HK); \/\/ H ^ 2\n+\n+  __ movdqu(ZT5, HK);\n+  __ vinserti64x2(ZT7, ZT7, HK, 3, Assembler::AVX_512bit);\n@@ -2774,3 +2774,3 @@\n-  gfmul_avx512(T5, HK);\n-  __ movdqu(Address(avx512_htbl, 16 * 30), T5);\n-  __ vinserti64x2(ZT7, ZT7, T5, 2);\n+  gfmul_avx512(ZT5, HK);\n+  __ movdqu(Address(avx512_htbl, 16 * 30), ZT5);\n+  __ vinserti64x2(ZT7, ZT7, ZT5, 2, Assembler::AVX_512bit);\n@@ -2779,3 +2779,3 @@\n-  gfmul_avx512(T5, HK);\n-  __ movdqu(Address(avx512_htbl, 16 * 29), T5);\n-  __ vinserti64x2(ZT7, ZT7, T5, 1);\n+  gfmul_avx512(ZT5, HK);\n+  __ movdqu(Address(avx512_htbl, 16 * 29), ZT5);\n+  __ vinserti64x2(ZT7, ZT7, ZT5, 1, Assembler::AVX_512bit);\n@@ -2784,3 +2784,3 @@\n-  gfmul_avx512(T5, HK);\n-  __ movdqu(Address(avx512_htbl, 16 * 28), T5);\n-  __ vinserti64x2(ZT7, ZT7, T5, 0);\n+  gfmul_avx512(ZT5, HK);\n+  __ movdqu(Address(avx512_htbl, 16 * 28), ZT5);\n+  __ vinserti64x2(ZT7, ZT7, ZT5, 0, Assembler::AVX_512bit);\n@@ -2813,59 +2813,24 @@\n-  \/\/calculate HashKey ^ 9 << 1 mod poly, HashKey ^ 10 << 1 mod poly, ... HashKey ^ 32 << 1 mod poly\n-  \/\/use HashKey ^ 8 as multiplier against ZT8 and ZT7 - this allows deeper ooo execution\n-  \/\/compute HashKey ^ (4 + n), HashKey ^ (3 + n), ... HashKey ^ (1 + n)\n-  gfmul_avx512(ZT8, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 20), ZT8, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT8, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT8, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 52), ZT1, Assembler::AVX_512bit);\n-\n-  \/\/compute HashKey ^ (8 + n), HashKey ^ (7 + n), ... HashKey ^ (5 + n)\n-  gfmul_avx512(ZT7, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 16), ZT7, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT7, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT7, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 48), ZT1, Assembler::AVX_512bit);\n-\n-  gfmul_avx512(ZT8, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 12), ZT8, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT8, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT8, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 44), ZT1, Assembler::AVX_512bit);\n-\n-  \/\/compute HashKey ^ (8 + n), HashKey ^ (7 + n), ... HashKey ^ (5 + n)\n-  gfmul_avx512(ZT7, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 8), ZT7, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT7, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT7, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 40), ZT1, Assembler::AVX_512bit);\n-\n-  gfmul_avx512(ZT8, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 4), ZT8, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT8, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT8, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 36), ZT1, Assembler::AVX_512bit);\n-\n-  \/\/compute HashKey ^ (8 + n), HashKey ^ (7 + n), ... HashKey ^ (5 + n)\n-  gfmul_avx512(ZT7, ZT5);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 0), ZT7, Assembler::AVX_512bit);\n-\n-  \/\/calculate HashKeyK = HashKey x POLY\n-  __ evpclmulqdq(ZT1, ZT7, xmm11, 0x10, Assembler::AVX_512bit);\n-  __ vpshufd(ZT2, ZT7, 78, Assembler::AVX_512bit);\n-  __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n-  __ evmovdquq(Address(avx512_htbl, 16 * 32), ZT1, Assembler::AVX_512bit);\n+  for (int i = 20, j = 52; i >= 0;) {\n+    gfmul_avx512(ZT8, ZT5);\n+    __ evmovdquq(Address(avx512_htbl, 16 * i), ZT8, Assembler::AVX_512bit);\n+    \/\/calculate HashKeyK = HashKey x POLY\n+    __ evpclmulqdq(ZT1, ZT8, xmm11, 0x10, Assembler::AVX_512bit);\n+    __ vpshufd(ZT2, ZT8, 78, Assembler::AVX_512bit);\n+    __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n+    __ evmovdquq(Address(avx512_htbl, 16 * j), ZT1, Assembler::AVX_512bit);\n+\n+    i -= 4;\n+    j -= 4;\n+    \/\/compute HashKey ^ (8 + n), HashKey ^ (7 + n), ... HashKey ^ (5 + n)\n+    gfmul_avx512(ZT7, ZT5);\n+    __ evmovdquq(Address(avx512_htbl, 16 * i), ZT7, Assembler::AVX_512bit);\n+\n+    \/\/calculate HashKeyK = HashKey x POLY\n+    __ evpclmulqdq(ZT1, ZT7, xmm11, 0x10, Assembler::AVX_512bit);\n+    __ vpshufd(ZT2, ZT7, 78, Assembler::AVX_512bit);\n+    __ evpxorq(ZT1, ZT1, ZT2, Assembler::AVX_512bit);\n+    __ evmovdquq(Address(avx512_htbl, 16 * j), ZT1, Assembler::AVX_512bit);\n+\n+    i -= 4;\n+    j -= 4;\n+  }\n@@ -2931,1 +2896,1 @@\n-                                   Register in, Register pos, Register subkeyHtbl, XMMRegister HASH, int in_offset,\n+                                   Register in, Register pos, Register subkeyHtbl, XMMRegister HASH, XMMRegister SHUFM, int in_offset,\n@@ -2944,1 +2909,1 @@\n-  const XMMRegister SHUFM = xmm29;\n+  const XMMRegister ZTMPB = xmm23;\n@@ -3037,2 +3002,2 @@\n-    __ evmovdquq(xmm23, ExternalAddress(ghash_polynomial_addr()), Assembler::AVX_512bit, rbx \/*rscratch*\/);\n-    __ evpclmulqdq(HASH, GL, xmm23, 0x10, Assembler::AVX_512bit);\n+    __ evmovdquq(ZTMPB, ExternalAddress(ghash_polynomial_addr()), Assembler::AVX_512bit, rbx \/*rscratch*\/);\n+    __ evpclmulqdq(HASH, GL, ZTMPB, 0x10, Assembler::AVX_512bit);\n@@ -3047,3 +3012,2 @@\n-\/\/Stitched GHASH of 16 blocks(with reduction) with encryption of N blocks\n-\/\/followed with GHASH of the N blocks.\n-void StubGenerator::gcm_enc_dec_last_avx512(Register len, Register in, Register pos, XMMRegister HASH, Register subkeyHtbl,\n+\/\/Stitched GHASH of 16 blocks(with reduction) with encryption of 0 blocks\n+void StubGenerator::gcm_enc_dec_last_avx512(Register len, Register in, Register pos, XMMRegister HASH, XMMRegister SHUFM, Register subkeyHtbl,\n@@ -3052,2 +3016,1 @@\n-  ghash16_avx512(start_ghash, do_reduction, false, false, true, in, pos, subkeyHtbl, HASH, ghashin_offset, 0, 0, hashkey_offset);\n-  \/\/**ZT01 may include sensitive data\n+  ghash16_avx512(start_ghash, do_reduction, false, false, true, in, pos, subkeyHtbl, HASH, SHUFM, ghashin_offset, 0, 0, hashkey_offset);\n@@ -3060,3 +3023,4 @@\n-                                                      Register CTR_CHECK, Register NROUNDS, Register key, bool hk_broadcast,\n-                                                      bool is_hash_start, bool do_hash_reduction, bool do_hash_hxor, bool no_ghash_in,\n-                                                      int ghashin_offset, int aesout_offset, int hashkey_offset) {\n+                                                      Register CTR_CHECK, Register NROUNDS, Register key, XMMRegister CTR_BE, XMMRegister GHASH_IN,\n+                                                      XMMRegister ADDBE_4x4, XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHFMSK,\n+                                                      bool hk_broadcast, bool is_hash_start, bool do_hash_reduction, bool do_hash_hxor,\n+                                                      bool no_ghash_in, int ghashin_offset, int aesout_offset, int hashkey_offset) {\n@@ -3064,1 +3028,0 @@\n-  const XMMRegister CTR_BE = xmm2;\n@@ -3068,1 +3031,0 @@\n-  const XMMRegister SHFMSK = xmm29;\n@@ -3077,2 +3039,1 @@\n-  const XMMRegister ADDBE_4x4 = xmm27, ADDBE_1234 = xmm28;\n-  const XMMRegister GHASH_IN = xmm14, TO_REDUCE_L = xmm25, TO_REDUCE_H = xmm24;\n+  const XMMRegister ZT = xmm23, TO_REDUCE_L = xmm25, TO_REDUCE_H = xmm24;\n@@ -3083,2 +3044,2 @@\n-  __ cmpl(CTR_CHECK, (256 - 16));\n-  __ jcc(Assembler::greaterEqual, blocks_overflow);\n+  __ cmpb(CTR_CHECK, (256 - 16));\n+  __ jcc(Assembler::aboveEqual, blocks_overflow);\n@@ -3093,1 +3054,1 @@\n-  __ vpaddd(B00_03, CTR_BE, ExternalAddress(counter_mask_add_1234_addr()), Assembler::AVX_512bit, rbx \/*rscratch*\/);\n+  __ vpaddd(B00_03, CTR_BE, ADD_1234, Assembler::AVX_512bit);\n@@ -3120,1 +3081,1 @@\n-  __ addl(CTR_CHECK, 16);\n+  __ addb(CTR_CHECK, 16);\n@@ -3221,2 +3182,2 @@\n-    __ evmovdquq(xmm23, ExternalAddress(ghash_polynomial_reduction_addr()), Assembler::AVX_512bit, rbx \/*rscratch*\/);\n-    __ evpclmulqdq(THH1, TO_REDUCE_L, xmm23, 0x10, Assembler::AVX_512bit);\n+    __ evmovdquq(ZT, ExternalAddress(ghash_polynomial_reduction_addr()), Assembler::AVX_512bit, rbx \/*rscratch*\/);\n+    __ evpclmulqdq(THH1, TO_REDUCE_L, ZT, 0x10, Assembler::AVX_512bit);\n@@ -3288,1 +3249,1 @@\n-                                             XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHUF_MASK, int stack_offset, bool no_ghash) {\n+                                             XMMRegister ADDBE_1234, XMMRegister ADD_1234, XMMRegister SHUF_MASK, int stack_offset) {\n@@ -3298,0 +3259,1 @@\n+  const XMMRegister T5 = xmm30;\n@@ -3301,1 +3263,1 @@\n-  __ cmpl(CTR_CHECK, (256 - 16));\n+  __ cmpb(CTR_CHECK, (256 - 16));\n@@ -3324,2 +3286,2 @@\n-  __ movdqu(xmm30, ExternalAddress(key_shuffle_mask_addr()), rbx \/*rscratch*\/);\n-  ev_load_key(T4, key, 0, xmm30);\n+  __ movdqu(T5, ExternalAddress(key_shuffle_mask_addr()), rbx \/*rscratch*\/);\n+  ev_load_key(T4, key, 0, T5);\n@@ -3332,1 +3294,1 @@\n-    ev_load_key(T4, key, i * 16, xmm30);\n+    ev_load_key(T4, key, i * 16, T5);\n@@ -3336,1 +3298,1 @@\n-  ev_load_key(T4, key, 10 * 16, xmm30);\n+  ev_load_key(T4, key, 10 * 16, T5);\n@@ -3341,1 +3303,1 @@\n-  ev_load_key(T4, key, 16 * 11, xmm30);\n+  ev_load_key(T4, key, 16 * 11, T5);\n@@ -3343,1 +3305,1 @@\n-  ev_load_key(T4, key, 16 * 12, xmm30);\n+  ev_load_key(T4, key, 16 * 12, T5);\n@@ -3348,1 +3310,1 @@\n-  ev_load_key(T4, key, 16 * 13, xmm30);\n+  ev_load_key(T4, key, 16 * 13, T5);\n@@ -3350,1 +3312,1 @@\n-  ev_load_key(T4, key, 16 * 14, xmm30);\n+  ev_load_key(T4, key, 16 * 14, T5);\n@@ -3371,5 +3333,0 @@\n-  if (no_ghash) {\n-    \/\/xor cipher block 0 with GHASH for the next GHASH round\n-    __ evpxorq(B00_03, B00_03, GHASH, Assembler::AVX_512bit);\n-  }\n-\n@@ -3417,1 +3374,1 @@\n-  const XMMRegister ADD_1234 = xmm13;\n+  const XMMRegister ADD_1234 = xmm9;\n@@ -3454,1 +3411,1 @@\n-  \/\/Shuffle counter, Broadcast counter value to 512 bit register and subtract 1 from the pre-incremented counter value\n+  \/\/Shuffle counter, subtract 1 from the pre-incremented counter value and broadcast counter value to 512 bit register\n@@ -3465,1 +3422,1 @@\n-  initial_blocks_16_avx512(in, out, ct, pos, key, avx512_subkeyHtbl, CTR_CHECK, rounds, CTR_BLOCKx, AAD_HASHx,  ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK, stack_offset, false);\n+  initial_blocks_16_avx512(in, out, ct, pos, key, avx512_subkeyHtbl, CTR_CHECK, rounds, CTR_BLOCKx, AAD_HASHx,  ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK, stack_offset);\n@@ -3470,1 +3427,1 @@\n-  initial_blocks_16_avx512(in, out, ct, pos, key, avx512_subkeyHtbl, CTR_CHECK, rounds, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK, stack_offset + 16, false);\n+  initial_blocks_16_avx512(in, out, ct, pos, key, avx512_subkeyHtbl, CTR_CHECK, rounds, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK, stack_offset + 16);\n@@ -3480,1 +3437,2 @@\n-  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, true, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n+  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK,\n+                                    true, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n@@ -3483,1 +3441,2 @@\n-  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, true, false, true, false, true, ghashin_offset + 16, aesout_offset + 16, HashKey_16);\n+  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK,\n+                                    true, false, true, false, true, ghashin_offset + 16, aesout_offset + 16, HashKey_16);\n@@ -3490,1 +3449,2 @@\n-  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, false, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n+  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK,\n+                                    false, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n@@ -3492,1 +3452,2 @@\n-  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, false, false, true, true, true, ghashin_offset + 16, aesout_offset + 16, HashKey_16);\n+  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK,\n+                                    false, false, true, true, true, ghashin_offset + 16, aesout_offset + 16, HashKey_16);\n@@ -3503,2 +3464,2 @@\n-  ghash16_avx512(true, false, false, false, true, in, pos, avx512_subkeyHtbl, AAD_HASHx, stack_offset, 0, 0, HashKey_32);\n-  gcm_enc_dec_last_avx512(len, in, pos, AAD_HASHx, avx512_subkeyHtbl, ghashin_offset + 16, HashKey_16, false, true);\n+  ghash16_avx512(true, false, false, false, true, in, pos, avx512_subkeyHtbl, AAD_HASHx, SHUF_MASK, stack_offset, 0, 0, HashKey_32);\n+  gcm_enc_dec_last_avx512(len, in, pos, AAD_HASHx, SHUF_MASK, avx512_subkeyHtbl, ghashin_offset + 16, HashKey_16, false, true);\n@@ -3508,1 +3469,2 @@\n-  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, false, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n+  ghash16_encrypt_parallel16_avx512(in, out, ct, pos, avx512_subkeyHtbl, CTR_CHECK, rounds, key, CTR_BLOCKx, AAD_HASHx, ADDBE_4x4, ADDBE_1234, ADD_1234, SHUF_MASK,\n+                                    false, true, false, false, false, ghashin_offset, aesout_offset, HashKey_32);\n@@ -3510,1 +3472,1 @@\n-  ghash16_avx512(false, true, false, false, true, in, pos, avx512_subkeyHtbl, AAD_HASHx, stack_offset, 16 * 16, 0, HashKey_16);\n+  ghash16_avx512(false, true, false, false, true, in, pos, avx512_subkeyHtbl, AAD_HASHx, SHUF_MASK, stack_offset, 16 * 16, 0, HashKey_16);\n@@ -3515,1 +3477,1 @@\n-  gcm_enc_dec_last_avx512(len, in, pos, AAD_HASHx, avx512_subkeyHtbl, ghashin_offset, HashKey_16, true, true);\n+  gcm_enc_dec_last_avx512(len, in, pos, AAD_HASHx, SHUF_MASK, avx512_subkeyHtbl, ghashin_offset, HashKey_16, true, true);\n@@ -3520,1 +3482,1 @@\n-  __ vpaddd(CTR_BLOCKx, CTR_BLOCKx, ExternalAddress(counter_mask_add_1234_addr()), Assembler::AVX_128bit, rbx);\n+  __ vpaddd(CTR_BLOCKx, CTR_BLOCKx, ADD_1234, Assembler::AVX_128bit);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_aes.cpp","additions":114,"deletions":152,"binary":false,"changes":266,"status":"modified"},{"patch":"@@ -60,4 +60,4 @@\n-    0x0000000000000001UL, 0xC200000000000000UL,\n-    0x0000000000000001UL, 0xC200000000000000UL,\n-    0x0000000000000001UL, 0xC200000000000000UL,\n-    0x0000000000000001UL, 0xC200000000000000UL\n+    0x0000000000000001ULL, 0xC200000000000000ULL,\n+    0x0000000000000001ULL, 0xC200000000000000ULL,\n+    0x0000000000000001ULL, 0xC200000000000000ULL,\n+    0x0000000000000001ULL, 0xC200000000000000ULL\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_ghash.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}