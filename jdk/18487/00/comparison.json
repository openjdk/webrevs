{"files":[{"patch":"@@ -16742,0 +16742,18 @@\n+instruct arrays_hashcode(iRegP_R1 ary, iRegI_R2 cnt, iRegI_R0 result, immI basic_type,\n+                         iRegLNoSp tmp1, vRegD_V0 vtmp0, vRegD_V1 vtmp1, vRegD_V2 vtmp2,\n+                         rFlagsReg cr)\n+%{\n+  match(Set result (VectorizedHashCode (Binary ary cnt) (Binary result basic_type)));\n+  effect(TEMP tmp1, TEMP vtmp0, TEMP vtmp1, TEMP vtmp2, USE_KILL ary,\n+         USE_KILL cnt, USE basic_type, KILL cr);\n+  size(256);\n+\n+  format %{ \"Array HashCode array[] $ary,$cnt,$result,$basic_type -> $result   \/\/ KILL all\" %}\n+  ins_encode %{\n+    __ arrays_hashcode($ary$$Register, $cnt$$Register, $result$$Register, $tmp1$$Register,\n+                       $vtmp0$$FloatRegister, $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,\n+                       (BasicType)$basic_type$$constant);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -49,0 +49,232 @@\n+\/\/ jdk.internal.util.ArraysSupport.vectorizedHashCode\n+void C2_MacroAssembler::arrays_hashcode(Register ary, Register cnt, Register result, Register tmp1,\n+                                        FloatRegister vtmp1, FloatRegister vtmp2,\n+                                        FloatRegister vtmp3, BasicType eltype) {\n+  assert_different_registers(ary, cnt, result, tmp1, rscratch1, rscratch2);\n+  assert_different_registers(vtmp1, vtmp2, vtmp3);\n+\n+  Register      tmp2 = rscratch1, pow4 = rscratch2;\n+  FloatRegister vpow0to3 = vtmp3;\n+\n+  Label ENTRY, TAIL, RELATIVE, PREHEADER, LOOP, DONE;\n+\n+  const size_t unroll_factor = 7;\n+  const size_t loop_factor = eltype == T_BOOLEAN || eltype == T_BYTE                    ? 8\n+                             : eltype == T_CHAR || eltype == T_SHORT || eltype == T_INT ? 4\n+                                                                                        : 0;\n+  guarantee(loop_factor, \"unsopported eltype\");\n+\n+  switch (eltype) {\n+    case T_BOOLEAN: BLOCK_COMMENT(\"arrays_hashcode(unsigned byte) {\"); break;\n+    case T_CHAR: BLOCK_COMMENT(\"arrays_hashcode(char) {\"); break;\n+    case T_BYTE: BLOCK_COMMENT(\"arrays_hashcode(byte) {\"); break;\n+    case T_SHORT: BLOCK_COMMENT(\"arrays_hashcode(short) {\"); break;\n+    case T_INT: BLOCK_COMMENT(\"arrays_hashcode(int) {\"); break;\n+    default: ShouldNotReachHere();\n+  }\n+\n+  \/**\n+   * Emit entry block that either jumps to the Neon loop or falls through to the tail (see below).\n+   *\n+   * Pseudocode:\n+   *\n+   *  input_cnt = cnt;\n+   *  cnt -= loop_factor;\n+   *  if (input_cnt > unroll_factor)\n+   *    goto .PREHEADER;\n+   *\/\n+  bind(ENTRY);\n+\n+  if (unroll_factor + 1 != loop_factor) {\n+    cmpw(cnt, unroll_factor + 1);\n+    subw(cnt, cnt, loop_factor);\n+  } else {\n+    subsw(cnt, cnt, loop_factor);\n+  }\n+\n+  br(Assembler::HS, PREHEADER);\n+\n+  \/**\n+   * Emit unrolled scalar tail loop. No SIMD instructions in this block.\n+   *\n+   * Pseudocode:\n+   *\n+   *  cnt -= unroll_facotor + 1 - loop_factor;\n+   *  switch (cnt) {\n+   *  case -1:\n+   *    ret = ret * 31 + *ary;\n+   *    ary++;\n+   *  case -2:\n+   *    ret = ret * 31 + *ary;\n+   *    ary++;\n+   *  ...\n+   *  case -unroll_factor:\n+   *    ret = ret * 31 + *ary;\n+   *    ary++;\n+   *  case -(unroll_factor + 1):\n+   *    break;\n+   *  }\n+   *  goto .DONE\n+   *\/\n+  bind(TAIL);\n+\n+  size_t compensate = unroll_factor + 1 - loop_factor;\n+  if (compensate) {\n+    subw(cnt, cnt, compensate);\n+  }\n+\n+  adr(tmp1, RELATIVE);\n+  subs(tmp1, tmp1, cnt, ext::sxtw, 3);\n+\n+  bind(RELATIVE);\n+  movw(tmp2, 0x1f);\n+  br(tmp1);\n+\n+  for (size_t i = 0; i < unroll_factor; ++i) {\n+    arrays_hashcode_elload(tmp1, Address(post(ary, arrays_hashcode_elsize(eltype))), eltype);\n+    maddw(result, result, tmp2, tmp1);\n+  }\n+\n+  b(DONE);\n+\n+  \/**\n+   * Put 0-4'th powers of 31 into registers. The 0-3'th go to a single SIMD register together.\n+   *\n+   * Pseudocode:\n+   *\n+   *  vpow0to3 = {1, 31, 31^2, 31^3};\n+   *  pow4 = 31^4;\n+   *\/\n+  bind(PREHEADER);\n+\n+  if (eltype == T_INT) {\n+    movw(tmp1, 0x745f);\n+    movw(tmp2, 0x3c1);\n+    mov(vpow0to3, Assembler::S, 0, tmp1);\n+    mov(vpow0to3, Assembler::S, 1, tmp2);\n+    movw(tmp1, 0x1f);\n+    movw(tmp2, 0x1);\n+    mov(vpow0to3, Assembler::S, 2, tmp1);\n+    mov(vpow0to3, Assembler::S, 3, tmp2);\n+  } else {\n+    movw(tmp1, 0x1f);\n+    movkw(tmp1, 0x1, 16);\n+    movw(tmp2, 0x745f);\n+    movkw(tmp2, 0x3c1, 16);\n+    mov(vpow0to3, Assembler::S, 0, tmp2);\n+    mov(vpow0to3, Assembler::S, 1, tmp1);\n+  }\n+  mov(pow4, 0x1781);\n+  movk(pow4, 0xe, 16);\n+\n+  \/**\n+   * Neon loop. Loads 4 or 8 elements per iteration.\n+   *\n+   * Pseudocode:\n+   *\n+   *  for (; cnt >= 0; cnt -= loop_factor)\n+   *    for (int i = 0; i += 4; i < loop_factor) {\n+   *      \/\/ This is executed twice for T_BOOLEAN and T_BYTE types and just once for all other types.\n+   *      \/\/ But even for T_BOOLEAN and T_BYTE this is a single 8B load.\n+   *      data = <eltype[4]> *ary * vpow0to3;\n+   *      ary += 4;\n+   *      addend = sum(data);\n+   *      result = result * pow4 + addend;\n+   *    }\n+   *\/\n+  bind(LOOP);\n+\n+  Register addend = tmp1;\n+\n+  FloatRegister vdata = vtmp1;\n+  FloatRegister vmultiplication = vtmp2;\n+\n+  size_t                      bytes_per_iteration = loop_factor * arrays_hashcode_elsize(eltype);\n+  Assembler::SIMD_Arrangement load_arrangement =\n+      eltype == T_BOOLEAN || eltype == T_BYTE ? Assembler::T8B\n+      : eltype == T_CHAR || eltype == T_SHORT ? Assembler::T4H\n+      : eltype == T_INT                       ? Assembler::T4S\n+                                              : Assembler::INVALID_ARRANGEMENT;\n+  guarantee(load_arrangement != Assembler::INVALID_ARRANGEMENT, \"invalid arrangement\");\n+\n+  ld1(vdata, load_arrangement, Address(post(ary, bytes_per_iteration)));\n+\n+  if (eltype == T_BOOLEAN || eltype == T_BYTE) {\n+    \/\/ Extend 8B to 8H to be able to use vector multiply instructions\n+    assert(load_arrangement == Assembler::T8B, \"expected to extend 8B to 8H\");\n+    if (is_signed_subword_type(eltype)) {\n+      sxtl(vdata, Assembler::T8H, vdata, load_arrangement);\n+    } else {\n+      uxtl(vdata, Assembler::T8H, vdata, load_arrangement);\n+    }\n+  }\n+\n+  \/\/ Process the lower half of a vector\n+  if (load_arrangement == Assembler::T4S) {\n+    mulv(vmultiplication, load_arrangement, vdata, vpow0to3);\n+  } else if (load_arrangement == Assembler::T4H || load_arrangement == Assembler::T8B) {\n+    assert(is_subword_type(eltype), \"subword type expected\");\n+    if (is_signed_subword_type(eltype)) {\n+      smullv(vmultiplication, Assembler::T4H, vdata, vpow0to3);\n+    } else {\n+      umullv(vmultiplication, Assembler::T4H, vdata, vpow0to3);\n+    }\n+  } else {\n+    should_not_reach_here();\n+  }\n+\n+  addv(vmultiplication, Assembler::T4S, vmultiplication);\n+  umov(addend, vmultiplication, Assembler::S, 0); \/\/ Sign-extension isn't necessary\n+  maddw(result, result, pow4, addend);\n+\n+  \/\/ Process the upper half of a vector\n+  if (load_arrangement == Assembler::T8B) {\n+    ext(vdata, Assembler::T16B, vdata, vdata, 8);\n+\n+    if (is_signed_subword_type(eltype)) {\n+      smullv(vmultiplication, Assembler::T4H, vdata, vpow0to3);\n+    } else {\n+      umullv(vmultiplication, Assembler::T4H, vdata, vpow0to3);\n+    }\n+\n+    addv(vmultiplication, Assembler::T4S, vmultiplication);\n+    umov(addend, vmultiplication, Assembler::S, 0); \/\/ Sign-extension isn't necessary\n+    maddw(result, result, pow4, addend);\n+  }\n+\n+  subsw(cnt, cnt, loop_factor);\n+  br(Assembler::HS, LOOP);\n+\n+  b(TAIL);\n+\n+  bind(DONE);\n+\n+  BLOCK_COMMENT(\"} \/\/ arrays_hashcode\");\n+}\n+\n+void C2_MacroAssembler::arrays_hashcode_elload(Register dst, Address src, BasicType eltype) {\n+  switch (eltype) {\n+  \/\/ T_BOOLEAN used as surrogate for unsigned byte\n+  case T_BOOLEAN: ldrb(dst, src);  break;\n+  case T_BYTE:    ldrsb(dst, src); break;\n+  case T_SHORT:   ldrsh(dst, src); break;\n+  case T_CHAR:    ldrh(dst, src);  break;\n+  case T_INT:     ldrw(dst, src);  break;\n+  default:\n+    ShouldNotReachHere();\n+  }\n+}\n+\n+int C2_MacroAssembler::arrays_hashcode_elsize(BasicType eltype) {\n+  switch (eltype) {\n+  case T_BOOLEAN: return sizeof(jboolean);\n+  case T_BYTE:    return sizeof(jbyte);\n+  case T_SHORT:   return sizeof(jshort);\n+  case T_CHAR:    return sizeof(jchar);\n+  case T_INT:     return sizeof(jint);\n+  default:\n+    ShouldNotReachHere();\n+    return -1;\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":232,"deletions":0,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -37,0 +37,4 @@\n+  \/\/ Helper functions for arrays_hashcode.\n+  void arrays_hashcode_elload(Register dst, Address src, BasicType eltype);\n+  int  arrays_hashcode_elsize(BasicType eltype);\n+\n@@ -38,0 +42,5 @@\n+  \/\/ jdk.internal.util.ArraysSupport.vectorizedHashCode\n+  void arrays_hashcode(Register ary, Register cnt, Register result, Register tmp1,\n+                       FloatRegister vtmp1, FloatRegister vtmp2, FloatRegister vtmp3,\n+                       BasicType eltype);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -565,0 +565,4 @@\n+\n+  if (FLAG_IS_DEFAULT(UseVectorizedHashCodeIntrinsic)) {\n+    FLAG_SET_DEFAULT(UseVectorizedHashCodeIntrinsic, true);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"}]}