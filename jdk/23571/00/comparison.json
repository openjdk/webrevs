{"files":[{"patch":"@@ -42,6 +42,0 @@\n-size_t ZAddressSpaceLimit::mark_stack() {\n-  \/\/ Allow mark stacks to occupy 10% of the address space\n-  const size_t limit = address_space_limit() \/ 10;\n-  return align_up(limit, ZMarkStackSpaceExpandSize);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zAddressSpaceLimit.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-  static size_t mark_stack();\n","filename":"src\/hotspot\/share\/gc\/z\/zAddressSpaceLimit.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -123,9 +123,0 @@\n-  \/\/ Check mark stack size\n-  const size_t mark_stack_space_limit = ZAddressSpaceLimit::mark_stack();\n-  if (ZMarkStackSpaceLimit > mark_stack_space_limit) {\n-    if (!FLAG_IS_DEFAULT(ZMarkStackSpaceLimit)) {\n-      vm_exit_during_initialization(\"ZMarkStackSpaceLimit too large for limited address space\");\n-    }\n-    FLAG_SET_DEFAULT(ZMarkStackSpaceLimit, mark_stack_space_limit);\n-  }\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zArguments.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n-  ZHeap::heap()->mark_flush_and_free(thread);\n+  ZHeap::heap()->mark_flush(thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -134,4 +134,0 @@\n-bool ZGeneration::is_initialized() const {\n-  return _mark.is_initialized();\n-}\n-\n@@ -154,2 +150,2 @@\n-void ZGeneration::mark_flush_and_free(Thread* thread) {\n-  _mark.flush_and_free(thread);\n+void ZGeneration::mark_flush(Thread* thread) {\n+  _mark.flush(thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zGeneration.cpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -102,2 +102,0 @@\n-  bool is_initialized() const;\n-\n@@ -164,1 +162,1 @@\n-  void mark_flush_and_free(Thread* thread);\n+  void mark_flush(Thread* thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zGeneration.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,11 +70,0 @@\n-\/\/ Mark stack space\n-const size_t      ZMarkStackSpaceExpandSize     = (size_t)1 << 25; \/\/ 32M\n-\n-\/\/ Mark stack and magazine sizes\n-const size_t      ZMarkStackSizeShift           = 11; \/\/ 2K\n-const size_t      ZMarkStackSize                = (size_t)1 << ZMarkStackSizeShift;\n-const size_t      ZMarkStackHeaderSize          = (size_t)1 << 4; \/\/ 16B\n-const size_t      ZMarkStackSlots               = (ZMarkStackSize - ZMarkStackHeaderSize) \/ sizeof(uintptr_t);\n-const size_t      ZMarkStackMagazineSize        = (size_t)1 << 15; \/\/ 32K\n-const size_t      ZMarkStackMagazineSlots       = (ZMarkStackMagazineSize \/ ZMarkStackSize) - 1;\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zGlobals.hpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-  if (!_page_allocator.is_initialized() || !_young.is_initialized() || !_old.is_initialized()) {\n+  if (!_page_allocator.is_initialized()) {\n@@ -274,3 +274,3 @@\n-void ZHeap::mark_flush_and_free(Thread* thread) {\n-  _young.mark_flush_and_free(thread);\n-  _old.mark_flush_and_free(thread);\n+void ZHeap::mark_flush(Thread* thread) {\n+  _young.mark_flush(thread);\n+  _old.mark_flush(thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -102,1 +102,1 @@\n-  void mark_flush_and_free(Thread* thread);\n+  void mark_flush(Thread* thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-#include \"gc\/z\/zMarkStackAllocator.hpp\"\n","filename":"src\/hotspot\/share\/gc\/z\/zInitialize.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -84,2 +84,2 @@\n-    _allocator(),\n-    _stripes(_allocator.start()),\n+    _marking_smr(),\n+    _stripes(),\n@@ -95,4 +95,0 @@\n-bool ZMark::is_initialized() const {\n-  return _allocator.is_initialized();\n-}\n-\n@@ -199,1 +195,1 @@\n-  stacks->push(&_allocator, &_stripes, stripe, &_terminate, entry, false \/* publish *\/);\n+  stacks->push(&_stripes, stripe, &_terminate, entry, false \/* publish *\/);\n@@ -474,0 +470,1 @@\n+    \/\/ The number of stripes has changed; reflect that change locally\n@@ -475,4 +472,8 @@\n-  } else if (nstripes < calculate_nstripes(_nworkers) && _allocator.clear_and_get_expanded_recently()) {\n-    const size_t new_nstripes = nstripes << 1;\n-    _stripes.set_nstripes(new_nstripes);\n-    context->set_nstripes(new_nstripes);\n+  } else if (nstripes < calculate_nstripes(_nworkers) && _stripes.is_crowded()) {\n+    \/\/ We are running on a reduced number of threads to minimize the amount of work\n+    \/\/ hidden in local stacks when the stripes are less well balanced. When this situation\n+    \/\/ starts getting crowded, we bump the number of stripes again.\n+    size_t new_nstripes = nstripes << 1;\n+    if (_stripes.try_set_nstripes(nstripes, new_nstripes)) {\n+      context->set_nstripes(new_nstripes);\n+    }\n@@ -485,1 +486,1 @@\n-    flush_and_free();\n+    flush(Thread::current());\n@@ -488,1 +489,1 @@\n-    flush_and_free();\n+    flush(Thread::current());\n@@ -505,1 +506,1 @@\n-  while (stacks->pop(&_allocator, &_stripes, context->stripe(), entry)) {\n+  while (stacks->pop(&_marking_smr, &_stripes, context->stripe(), &entry)) {\n@@ -544,1 +545,1 @@\n-    ZMarkStack* const stack = victim_stripe->steal_stack();\n+    ZMarkStack* const stack = victim_stripe->steal_stack(&_marking_smr);\n@@ -560,1 +561,1 @@\n-class ZMarkFlushAndFreeStacksClosure : public HandshakeClosure {\n+class ZMarkFlushStacksClosure : public HandshakeClosure {\n@@ -566,2 +567,2 @@\n-  ZMarkFlushAndFreeStacksClosure(ZMark* mark)\n-    : HandshakeClosure(\"ZMarkFlushAndFreeStacks\"),\n+  ZMarkFlushStacksClosure(ZMark* mark)\n+    : HandshakeClosure(\"ZMarkFlushStacks\"),\n@@ -572,1 +573,1 @@\n-    if (_mark->flush_and_free(thread)) {\n+    if (_mark->flush(thread)) {\n@@ -609,1 +610,1 @@\n-  ZMarkFlushAndFreeStacksClosure cl(this);\n+  ZMarkFlushStacksClosure cl(this);\n@@ -626,2 +627,1 @@\n-  return flush() ||\n-         _terminate.resurrected();\n+  return flush() || _terminate.resurrected();\n@@ -853,1 +853,1 @@\n-    ZHeap::heap()->mark_flush_and_free(Thread::current());\n+    ZHeap::heap()->mark_flush(Thread::current());\n@@ -911,1 +911,1 @@\n-    ZHeap::heap()->mark_flush_and_free(Thread::current());\n+    ZHeap::heap()->mark_flush(Thread::current());\n@@ -937,1 +937,1 @@\n-    ZHeap::heap()->mark_flush_and_free(Thread::current());\n+    ZHeap::heap()->mark_flush(Thread::current());\n@@ -981,1 +981,1 @@\n-  ZMarkFlushAndFreeStacksClosure cl(this);\n+  ZMarkFlushStacksClosure cl(this);\n@@ -1015,9 +1015,1 @@\n-  _allocator.free();\n-\n-  \/\/ Update statistics\n-  _generation->stat_mark()->at_mark_free(_allocator.size());\n-}\n-\n-void ZMark::flush_and_free() {\n-  Thread* const thread = Thread::current();\n-  flush_and_free(thread);\n+  _marking_smr.free();\n@@ -1026,1 +1018,1 @@\n-bool ZMark::flush_and_free(Thread* thread) {\n+bool ZMark::flush(Thread* thread) {\n@@ -1031,3 +1023,1 @@\n-  const bool flushed = stacks->flush(&_allocator, &_stripes, &_terminate);\n-  stacks->free(&_allocator);\n-  return flushed;\n+  return stacks->flush(&_stripes, &_terminate);\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.cpp","additions":29,"deletions":39,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/z\/zMarkingSMR.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"gc\/z\/zMarkStackAllocator.hpp\"\n@@ -58,12 +58,12 @@\n-  ZGeneration* const  _generation;\n-  ZPageTable* const   _page_table;\n-  ZMarkStackAllocator _allocator;\n-  ZMarkStripeSet      _stripes;\n-  ZMarkTerminate      _terminate;\n-  volatile size_t     _work_nproactiveflush;\n-  volatile size_t     _work_nterminateflush;\n-  size_t              _nproactiveflush;\n-  size_t              _nterminateflush;\n-  size_t              _ntrycomplete;\n-  size_t              _ncontinue;\n-  uint                _nworkers;\n+  ZGeneration* const _generation;\n+  ZPageTable* const  _page_table;\n+  ZMarkingSMR        _marking_smr;\n+  ZMarkStripeSet     _stripes;\n+  ZMarkTerminate     _terminate;\n+  volatile size_t    _work_nproactiveflush;\n+  volatile size_t    _work_nterminateflush;\n+  size_t             _nproactiveflush;\n+  size_t             _nterminateflush;\n+  size_t             _ntrycomplete;\n+  size_t             _ncontinue;\n+  uint               _nworkers;\n@@ -104,2 +104,0 @@\n-  bool is_initialized() const;\n-\n@@ -116,2 +114,1 @@\n-  void flush_and_free();\n-  bool flush_and_free(Thread* thread);\n+  bool flush(Thread* thread);\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.hpp","additions":14,"deletions":17,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-  stacks->push(&_allocator, &_stripes, stripe, &_terminate, entry, publish);\n+  stacks->push(&_stripes, stripe, &_terminate, entry, publish);\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -24,0 +24,1 @@\n+#include \"gc\/z\/zMarkingSMR.hpp\"\n@@ -25,1 +26,0 @@\n-#include \"gc\/z\/zMarkStackAllocator.hpp\"\n@@ -29,0 +29,1 @@\n+#include \"runtime\/orderAccess.hpp\"\n@@ -32,3 +33,12 @@\n-ZMarkStripe::ZMarkStripe(uintptr_t base)\n-  : _published(base),\n-    _overflowed(base) {}\n+ZMarkStack* ZMarkStack::create(bool first_stack) {\n+  \/\/ When allocating the first stack on a stripe, we try to use a\n+  \/\/ smaller mark stack to promote sharing of stacks with other\n+  \/\/ threads instead. Once more than one stack is needed, we revert\n+  \/\/ to a larger stack size instead, which reduces synchronization\n+  \/\/ overhead of churning around stacks on a stripe.\n+  size_t capacity = first_stack ? 128 : 512;\n+\n+  size_t size = sizeof(ZMarkStack) + capacity * sizeof(ZMarkStackEntry);\n+  char* memory = NEW_C_HEAP_ARRAY(char, size, mtGC);\n+  return new (memory) ZMarkStack(capacity);\n+}\n@@ -36,3 +46,126 @@\n-ZMarkStripeSet::ZMarkStripeSet(uintptr_t base)\n-  : _nstripes_mask(0),\n-    _stripes() {\n+void ZMarkStack::destroy(ZMarkStack* stack) {\n+  char* memory = (char*)stack;\n+  FREE_C_HEAP_ARRAY(char, memory);\n+}\n+\n+ZMarkStack::ZMarkStack(size_t capacity)\n+  : _top(0),\n+    _capacity(capacity) {}\n+\n+ZMarkStackListNode::ZMarkStackListNode(ZMarkStack* stack)\n+  : _stack(stack),\n+    _next() {}\n+\n+ZMarkStack* ZMarkStackListNode::stack() const {\n+  return _stack;\n+}\n+\n+ZMarkStackListNode* ZMarkStackListNode::next() const {\n+  return _next;\n+}\n+\n+void ZMarkStackListNode::set_next(ZMarkStackListNode* next) {\n+  _next = next;\n+}\n+\n+ZMarkStackList::ZMarkStackList()\n+  : _head(),\n+    _length() {}\n+\n+bool ZMarkStackList::is_empty() const {\n+  return Atomic::load(&_head) == nullptr;\n+}\n+\n+void ZMarkStackList::push(ZMarkStack* stack) {\n+  ZMarkStackListNode* node = new ZMarkStackListNode(stack);\n+  ZMarkStackListNode* head = Atomic::load(&_head);\n+  for (;;) {\n+    node->set_next(head);\n+    \/\/ Between reading the head and the linearizing CAS that pushes\n+    \/\/ the node onto the list, there could be an ABA problem. Except,\n+    \/\/ on the pushing sidee, that is benign. The node is never\n+    \/\/ dereferenced while pushing and if we were to detect the ABA\n+    \/\/ situation and run this loop one more time, we would end up\n+    \/\/ having the same side effects: set the next pointer to the same\n+    \/\/ head again, and CAS the head link.\n+    ZMarkStackListNode* prev = Atomic::cmpxchg(&_head, head, node, memory_order_release);\n+\n+    if (prev == head) {\n+      \/\/ Success\n+\n+      \/\/ Bookkeep the population count\n+      Atomic::inc(&_length, memory_order_relaxed);\n+      return;\n+    }\n+\n+    \/\/ Retry\n+    head = prev;\n+  }\n+}\n+\n+ZMarkStack* ZMarkStackList::pop(ZMarkingSMR* marking_smr) {\n+  ZMarkStackListNode* volatile* hazard_ptr = marking_smr->hazard_ptr();\n+\n+  ZMarkStackListNode* head = Atomic::load(&_head);\n+  for (;;) {\n+    if (head == nullptr) {\n+      \/\/ Stack is empty\n+      return nullptr;\n+    }\n+\n+    \/\/ Establish what the head is and publish a hazard pointer denoting\n+    \/\/ that the head is not safe to concurrently free while we are in the\n+    \/\/ middle of popping it and finding out that we lost the race.\n+    Atomic::store(hazard_ptr, head);\n+\n+    \/\/ A full fence is needed to ensure the store and subsequent load do\n+    \/\/ not reorder. If they did reorder, the second head load could happen\n+    \/\/ before other threads scanning hazard poitners can observe it, meaning\n+    \/\/ it could get concurrently freed.\n+    OrderAccess::fence();\n+\n+    \/\/ The acquire fence when loading the head is necessary to make sure\n+    \/\/ the next pointer load below observes the next pointer published\n+    \/\/ with the releasing CAS for the push operation that published the\n+    \/\/ marking stack.\n+    ZMarkStackListNode* const head_after_publish = Atomic::load_acquire(&_head);\n+    if (head_after_publish != head) {\n+      \/\/ Race during hazard pointer publishing\n+      head = head_after_publish;\n+      continue;\n+    }\n+\n+    \/\/ With the hazard pointer published, we can read the next pointer,\n+    \/\/ knowing that it is indeed the next pointer of the intended logical\n+    \/\/ head node that we established above.\n+    ZMarkStackListNode* const next = head->next();\n+\n+    \/\/ Popping entries from the list does not require any particular memory\n+    \/\/ ordering.\n+    ZMarkStackListNode* const prev = Atomic::cmpxchg(&_head, head, next, memory_order_relaxed);\n+\n+    if (prev == head) {\n+      \/\/ Success\n+\n+      \/\/ The ABA hazard is gone after the CAS. We use release_store to ensure\n+      \/\/ that the relinquishing of the hazard pointer becomes observable after\n+      \/\/ the unlinking CAS.\n+      Atomic::release_store(hazard_ptr, (ZMarkStackListNode*)nullptr);\n+\n+      \/\/ Perform bookkeeping of the population count.\n+      Atomic::dec(&_length, memory_order_relaxed);\n+\n+      ZMarkStack* result = head->stack();\n+\n+      marking_smr->free_node(head);\n+\n+      return result;\n+    }\n+\n+    \/\/ Retry\n+    head = prev;\n+  }\n+}\n+\n+size_t ZMarkStackList::length() const {\n+  ssize_t result = Atomic::load(&_length);\n@@ -40,3 +173,2 @@\n-  \/\/ Re-construct array elements with the correct base\n-  for (size_t i = 0; i < ARRAY_SIZE(_stripes); i++) {\n-    _stripes[i] = ZMarkStripe(base);\n+  if (result < 0) {\n+    return 0;\n@@ -44,0 +176,20 @@\n+\n+  return (size_t)result;\n+}\n+\n+ZMarkStripe::ZMarkStripe()\n+  : _published(),\n+    _overflowed() {}\n+\n+ZMarkStack* ZMarkStripe::steal_stack(ZMarkingSMR* marking_smr) {\n+  \/\/ Steal overflowed stacks first, then published stacks\n+  ZMarkStack* const stack = _overflowed.pop(marking_smr);\n+  if (stack != nullptr) {\n+    return stack;\n+  }\n+\n+  return _published.pop(marking_smr);\n+}\n+\n+size_t ZMarkStripe::population() const {\n+  return _overflowed.length() + _published.length();\n@@ -46,0 +198,4 @@\n+ZMarkStripeSet::ZMarkStripeSet()\n+  : _nstripes_mask(0),\n+    _stripes() {}\n+\n@@ -52,0 +208,15 @@\n+  size_t new_nstripes_mask = nstripes - 1;\n+  _nstripes_mask = new_nstripes_mask;\n+\n+  log_debug(gc, marking)(\"Using %zu mark stripes\", nstripes);\n+}\n+\n+bool ZMarkStripeSet::try_set_nstripes(size_t old_nstripes, size_t new_nstripes) {\n+  assert(is_power_of_2(new_nstripes), \"Must be a power of two\");\n+  assert(is_power_of_2(ZMarkStripesMax), \"Must be a power of two\");\n+  assert(new_nstripes >= 1, \"Invalid number of stripes\");\n+  assert(new_nstripes <= ZMarkStripesMax, \"Invalid number of stripes\");\n+\n+  size_t old_nstripes_mask = old_nstripes - 1;\n+  size_t new_nstripes_mask = new_nstripes - 1;\n+\n@@ -54,1 +225,4 @@\n-  Atomic::store(&_nstripes_mask, nstripes - 1);\n+  if (Atomic::cmpxchg(&_nstripes_mask, old_nstripes_mask, new_nstripes_mask) == old_nstripes_mask) {\n+    log_debug(gc, marking)(\"Using %zu mark stripes\", new_nstripes);\n+    return true;\n+  }\n@@ -56,1 +230,1 @@\n-  log_debug(gc, marking)(\"Using %zu mark stripes\", nstripes);\n+  return false;\n@@ -73,0 +247,14 @@\n+bool ZMarkStripeSet::is_crowded() const {\n+  size_t population = 0;\n+  const size_t crowded_threshold = nstripes() << 4;\n+\n+  for (size_t i = 0; i < ZMarkStripesMax; i++) {\n+    population += _stripes[i].population();\n+    if (population > crowded_threshold) {\n+      return true;\n+    }\n+  }\n+\n+  return false;\n+}\n+\n@@ -95,2 +283,1 @@\n-ZMarkThreadLocalStacks::ZMarkThreadLocalStacks()\n-  : _magazine(nullptr) {\n+ZMarkThreadLocalStacks::ZMarkThreadLocalStacks() {\n@@ -113,98 +300,2 @@\n-ZMarkStack* ZMarkThreadLocalStacks::allocate_stack(ZMarkStackAllocator* allocator) {\n-  if (_magazine == nullptr) {\n-    \/\/ Allocate new magazine\n-    _magazine = allocator->alloc_magazine();\n-    if (_magazine == nullptr) {\n-      return nullptr;\n-    }\n-  }\n-\n-  ZMarkStack* stack = nullptr;\n-\n-  if (!_magazine->pop(stack)) {\n-    \/\/ Magazine is empty, convert magazine into a new stack\n-    _magazine->~ZMarkStackMagazine();\n-    stack = new ((void*)_magazine) ZMarkStack();\n-    _magazine = nullptr;\n-  }\n-\n-  return stack;\n-}\n-\n-void ZMarkThreadLocalStacks::free_stack(ZMarkStackAllocator* allocator, ZMarkStack* stack) {\n-  for (;;) {\n-    if (_magazine == nullptr) {\n-      \/\/ Convert stack into a new magazine\n-      stack->~ZMarkStack();\n-      _magazine = new ((void*)stack) ZMarkStackMagazine();\n-      return;\n-    }\n-\n-    if (_magazine->push(stack)) {\n-      \/\/ Success\n-      return;\n-    }\n-\n-    \/\/ Free and uninstall full magazine\n-    allocator->free_magazine(_magazine);\n-    _magazine = nullptr;\n-  }\n-}\n-\n-bool ZMarkThreadLocalStacks::push_slow(ZMarkStackAllocator* allocator,\n-                                       ZMarkStripe* stripe,\n-                                       ZMarkStack** stackp,\n-                                       ZMarkTerminate* terminate,\n-                                       ZMarkStackEntry entry,\n-                                       bool publish) {\n-  ZMarkStack* stack = *stackp;\n-\n-  for (;;) {\n-    if (stack == nullptr) {\n-      \/\/ Allocate and install new stack\n-      *stackp = stack = allocate_stack(allocator);\n-      if (stack == nullptr) {\n-        \/\/ Out of mark stack memory\n-        return false;\n-      }\n-    }\n-\n-    if (stack->push(entry)) {\n-      \/\/ Success\n-      return true;\n-    }\n-\n-    \/\/ Publish\/Overflow and uninstall stack\n-    stripe->publish_stack(stack, terminate, publish);\n-    *stackp = stack = nullptr;\n-  }\n-}\n-\n-bool ZMarkThreadLocalStacks::pop_slow(ZMarkStackAllocator* allocator,\n-                                      ZMarkStripe* stripe,\n-                                      ZMarkStack** stackp,\n-                                      ZMarkStackEntry& entry) {\n-  ZMarkStack* stack = *stackp;\n-\n-  for (;;) {\n-    if (stack == nullptr) {\n-      \/\/ Try steal and install stack\n-      *stackp = stack = stripe->steal_stack();\n-      if (stack == nullptr) {\n-        \/\/ Nothing to steal\n-        return false;\n-      }\n-    }\n-\n-    if (stack->pop(entry)) {\n-      \/\/ Success\n-      return true;\n-    }\n-\n-    \/\/ Free and uninstall stack\n-    free_stack(allocator, stack);\n-    *stackp = stack = nullptr;\n-  }\n-}\n-\n-bool ZMarkThreadLocalStacks::flush(ZMarkStackAllocator* allocator, ZMarkStripeSet* stripes, ZMarkTerminate* terminate) {\n+bool ZMarkThreadLocalStacks::flush(ZMarkStripeSet* stripes,\n+                                   ZMarkTerminate* terminate) {\n@@ -223,6 +314,2 @@\n-    if (stack->is_empty()) {\n-      free_stack(allocator, stack);\n-    } else {\n-      stripe->publish_stack(stack, terminate, true \/* publish *\/);\n-      flushed = true;\n-    }\n+    stripe->publish_stack(stack, terminate, true \/* publish *\/);\n+    flushed = true;\n@@ -234,8 +321,0 @@\n-\n-void ZMarkThreadLocalStacks::free(ZMarkStackAllocator* allocator) {\n-  \/\/ Free and uninstall magazine\n-  if (_magazine != nullptr) {\n-    allocator->free_magazine(_magazine);\n-    _magazine = nullptr;\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStack.cpp","additions":205,"deletions":126,"binary":false,"changes":331,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,0 +29,1 @@\n+#include \"memory\/allocation.hpp\"\n@@ -31,0 +32,2 @@\n+class ZMarkingSMR;\n+class ZMarkStripe;\n@@ -33,2 +36,1 @@\n-template <typename T, size_t S>\n-class ZStack {\n+class ZMarkStack {\n@@ -36,3 +38,2 @@\n-  size_t        _top;\n-  ZStack<T, S>* _next;\n-  T             _slots[S];\n+  size_t           _top;\n+  size_t           _capacity;\n@@ -40,1 +41,3 @@\n-  bool is_full() const;\n+  ZMarkStackEntry* slots();\n+\n+  ZMarkStack(size_t capacity);\n@@ -43,1 +46,2 @@\n-  ZStack();\n+  static ZMarkStack* create(bool first_stack);\n+  static void destroy(ZMarkStack* stack);\n@@ -46,0 +50,1 @@\n+  bool is_full() const;\n@@ -47,5 +52,2 @@\n-  bool push(T value);\n-  bool pop(T& value);\n-\n-  ZStack<T, S>* next() const;\n-  ZStack<T, S>** next_addr();\n+  void push(ZMarkStackEntry value);\n+  ZMarkStackEntry pop();\n@@ -54,2 +56,1 @@\n-template <typename T>\n-class ZCACHE_ALIGNED ZStackList {\n+class ZMarkStackListNode : public CHeapObj<mtGC> {\n@@ -57,2 +58,2 @@\n-  uintptr_t   _base;\n-  T* volatile _head;\n+  ZMarkStack* const   _stack;\n+  ZMarkStackListNode* _next;\n@@ -60,2 +61,13 @@\n-  T* encode_versioned_pointer(const T* stack, uint32_t version) const;\n-  void decode_versioned_pointer(const T* vstack, T** stack, uint32_t* version) const;\n+public:\n+  ZMarkStackListNode(ZMarkStack* stack);\n+\n+  ZMarkStack* stack() const;\n+\n+  ZMarkStackListNode* next() const;\n+  void set_next(ZMarkStackListNode* next);\n+};\n+\n+class ZCACHE_ALIGNED ZMarkStackList {\n+private:\n+  ZMarkStackListNode* volatile _head;\n+  ssize_t volatile             _length;\n@@ -64,1 +76,1 @@\n-  explicit ZStackList(uintptr_t base);\n+  ZMarkStackList();\n@@ -68,2 +80,1 @@\n-  void push(T* stack);\n-  T* pop();\n+  size_t length() const;\n@@ -71,1 +82,2 @@\n-  void clear();\n+  void push(ZMarkStack* stack);\n+  ZMarkStack* pop(ZMarkingSMR* marking_smr);\n@@ -74,8 +86,0 @@\n-using ZMarkStack = ZStack<ZMarkStackEntry, ZMarkStackSlots>;\n-using ZMarkStackList = ZStackList<ZMarkStack>;\n-using ZMarkStackMagazine = ZStack<ZMarkStack*, ZMarkStackMagazineSlots>;\n-using ZMarkStackMagazineList = ZStackList<ZMarkStackMagazine>;\n-\n-static_assert(sizeof(ZMarkStack) == ZMarkStackSize, \"ZMarkStack size mismatch\");\n-static_assert(sizeof(ZMarkStackMagazine) <= ZMarkStackSize, \"ZMarkStackMagazine size too large\");\n-\n@@ -88,1 +92,1 @@\n-  explicit ZMarkStripe(uintptr_t base = 0);\n+  explicit ZMarkStripe();\n@@ -91,0 +95,1 @@\n+  size_t population() const;\n@@ -93,1 +98,1 @@\n-  ZMarkStack* steal_stack();\n+  ZMarkStack* steal_stack(ZMarkingSMR* marking_smr);\n@@ -102,1 +107,1 @@\n-  explicit ZMarkStripeSet(uintptr_t base);\n+  explicit ZMarkStripeSet();\n@@ -105,0 +110,1 @@\n+  bool try_set_nstripes(size_t old_nstripes, size_t new_nstripes);\n@@ -108,0 +114,1 @@\n+  bool is_crowded() const;\n@@ -116,2 +123,0 @@\n-class ZMarkStackAllocator;\n-\n@@ -120,17 +125,1 @@\n-  ZMarkStackMagazine* _magazine;\n-  ZMarkStack*         _stacks[ZMarkStripesMax];\n-\n-  ZMarkStack* allocate_stack(ZMarkStackAllocator* allocator);\n-  void free_stack(ZMarkStackAllocator* allocator, ZMarkStack* stack);\n-\n-  bool push_slow(ZMarkStackAllocator* allocator,\n-                 ZMarkStripe* stripe,\n-                 ZMarkStack** stackp,\n-                 ZMarkTerminate* terminate,\n-                 ZMarkStackEntry entry,\n-                 bool publish);\n-\n-  bool pop_slow(ZMarkStackAllocator* allocator,\n-                ZMarkStripe* stripe,\n-                ZMarkStack** stackp,\n-                ZMarkStackEntry& entry);\n+  ZMarkStack* _stacks[ZMarkStripesMax];\n@@ -150,2 +139,1 @@\n-  bool push(ZMarkStackAllocator* allocator,\n-            ZMarkStripeSet* stripes,\n+  void push(ZMarkStripeSet* stripes,\n@@ -157,1 +145,1 @@\n-  bool pop(ZMarkStackAllocator* allocator,\n+  bool pop(ZMarkingSMR* marking_smr,\n@@ -160,1 +148,1 @@\n-           ZMarkStackEntry& entry);\n+           ZMarkStackEntry* entry);\n@@ -162,2 +150,1 @@\n-  bool flush(ZMarkStackAllocator* allocator,\n-             ZMarkStripeSet* stripes,\n+  bool flush(ZMarkStripeSet* stripes,\n@@ -165,2 +152,0 @@\n-\n-  void free(ZMarkStackAllocator* allocator);\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStack.hpp","additions":46,"deletions":61,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"runtime\/atomic.hpp\"\n@@ -33,7 +32,1 @@\n-template <typename T, size_t S>\n-inline ZStack<T, S>::ZStack()\n-  : _top(0),\n-    _next(nullptr) {}\n-\n-template <typename T, size_t S>\n-inline bool ZStack<T, S>::is_empty() const {\n+inline bool ZMarkStack::is_empty() const {\n@@ -43,3 +36,2 @@\n-template <typename T, size_t S>\n-inline bool ZStack<T, S>::is_full() const {\n-  return _top == S;\n+inline bool ZMarkStack::is_full() const {\n+  return _top == _capacity;\n@@ -48,88 +40,4 @@\n-template <typename T, size_t S>\n-inline bool ZStack<T, S>::push(T value) {\n-  if (is_full()) {\n-    return false;\n-  }\n-\n-  _slots[_top++] = value;\n-  return true;\n-}\n-\n-template <typename T, size_t S>\n-inline bool ZStack<T, S>::pop(T& value) {\n-  if (is_empty()) {\n-    return false;\n-  }\n-\n-  value = _slots[--_top];\n-  return true;\n-}\n-\n-template <typename T, size_t S>\n-inline ZStack<T, S>* ZStack<T, S>::next() const {\n-  return _next;\n-}\n-\n-template <typename T, size_t S>\n-inline ZStack<T, S>** ZStack<T, S>::next_addr() {\n-  return &_next;\n-}\n-\n-template <typename T>\n-inline ZStackList<T>::ZStackList(uintptr_t base)\n-  : _base(base),\n-    _head(encode_versioned_pointer(nullptr, 0)) {}\n-\n-template <typename T>\n-inline T* ZStackList<T>::encode_versioned_pointer(const T* stack, uint32_t version) const {\n-  uint64_t addr;\n-\n-  if (stack == nullptr) {\n-    addr = (uint32_t)-1;\n-  } else {\n-    addr = ((uint64_t)stack - _base) >> ZMarkStackSizeShift;\n-  }\n-\n-  return (T*)((addr << 32) | (uint64_t)version);\n-}\n-\n-template <typename T>\n-inline void ZStackList<T>::decode_versioned_pointer(const T* vstack, T** stack, uint32_t* version) const {\n-  const uint64_t addr = (uint64_t)vstack >> 32;\n-\n-  if (addr == (uint32_t)-1) {\n-    *stack = nullptr;\n-  } else {\n-    *stack = (T*)((addr << ZMarkStackSizeShift) + _base);\n-  }\n-\n-  *version = (uint32_t)(uint64_t)vstack;\n-}\n-\n-template <typename T>\n-inline bool ZStackList<T>::is_empty() const {\n-  const T* vstack = _head;\n-  T* stack = nullptr;\n-  uint32_t version = 0;\n-\n-  decode_versioned_pointer(vstack, &stack, &version);\n-  return stack == nullptr;\n-}\n-\n-template <typename T>\n-inline void ZStackList<T>::push(T* stack) {\n-  T* vstack = _head;\n-  uint32_t version = 0;\n-\n-  for (;;) {\n-    decode_versioned_pointer(vstack, stack->next_addr(), &version);\n-    T* const new_vstack = encode_versioned_pointer(stack, version + 1);\n-    T* const prev_vstack = Atomic::cmpxchg(&_head, vstack, new_vstack);\n-    if (prev_vstack == vstack) {\n-      \/\/ Success\n-      break;\n-    }\n-\n-    \/\/ Retry\n-    vstack = prev_vstack;\n-  }\n+inline ZMarkStackEntry* ZMarkStack::slots() {\n+  uintptr_t start = (uintptr_t)this;\n+  uintptr_t result = start + sizeof(ZMarkStack);\n+  return (ZMarkStackEntry*)result;\n@@ -138,22 +46,3 @@\n-template <typename T>\n-inline T* ZStackList<T>::pop() {\n-  T* vstack = _head;\n-  T* stack = nullptr;\n-  uint32_t version = 0;\n-\n-  for (;;) {\n-    decode_versioned_pointer(vstack, &stack, &version);\n-    if (stack == nullptr) {\n-      return nullptr;\n-    }\n-\n-    T* const new_vstack = encode_versioned_pointer(stack->next(), version + 1);\n-    T* const prev_vstack = Atomic::cmpxchg(&_head, vstack, new_vstack);\n-    if (prev_vstack == vstack) {\n-      \/\/ Success\n-      return stack;\n-    }\n-\n-    \/\/ Retry\n-    vstack = prev_vstack;\n-  }\n+inline void ZMarkStack::push(ZMarkStackEntry value) {\n+  assert(!is_full(), \"can't push to full stack\");\n+  slots()[_top++] = value;\n@@ -162,3 +51,3 @@\n-template <typename T>\n-inline void ZStackList<T>::clear() {\n-  _head = encode_versioned_pointer(nullptr, 0);\n+inline ZMarkStackEntry ZMarkStack::pop() {\n+  assert(!is_empty(), \"can't pop from empty stack\");\n+  return slots()[--_top];\n@@ -178,0 +67,2 @@\n+  assert(!stack->is_empty(), \"we never publish empty stacks\");\n+\n@@ -187,10 +78,0 @@\n-inline ZMarkStack* ZMarkStripe::steal_stack() {\n-  \/\/ Steal overflowed stacks first, then published stacks\n-  ZMarkStack* const stack = _overflowed.pop();\n-  if (stack != nullptr) {\n-    return stack;\n-  }\n-\n-  return _published.pop();\n-}\n-\n@@ -239,2 +120,1 @@\n-inline bool ZMarkThreadLocalStacks::push(ZMarkStackAllocator* allocator,\n-                                         ZMarkStripeSet* stripes,\n+inline void ZMarkThreadLocalStacks::push(ZMarkStripeSet* stripes,\n@@ -245,4 +125,14 @@\n-  ZMarkStack** const stackp = &_stacks[stripes->stripe_id(stripe)];\n-  ZMarkStack* const stack = *stackp;\n-  if (stack != nullptr && stack->push(entry)) {\n-    return true;\n+  const size_t stripe_id = stripes->stripe_id(stripe);\n+  ZMarkStack** const stackp = &_stacks[stripe_id];\n+  ZMarkStack* const prev_stack = *stackp;\n+\n+  if (prev_stack != nullptr) {\n+    if (!prev_stack->is_full()) {\n+      \/\/ There's a stack and it isn't full: just push\n+      prev_stack->push(entry);\n+      return;\n+    }\n+\n+    \/\/ Publish full stacks\n+    stripe->publish_stack(prev_stack, terminate, publish);\n+    *stackp = nullptr;\n@@ -251,1 +141,6 @@\n-  return push_slow(allocator, stripe, stackp, terminate, entry, publish);\n+  \/\/ If no stack was available, allocate one and push to it\n+  const bool first_stack = prev_stack == nullptr;\n+  ZMarkStack* const new_stack = ZMarkStack::create(first_stack);\n+  *stackp = new_stack;\n+\n+  new_stack->push(entry);\n@@ -254,1 +149,1 @@\n-inline bool ZMarkThreadLocalStacks::pop(ZMarkStackAllocator* allocator,\n+inline bool ZMarkThreadLocalStacks::pop(ZMarkingSMR* marking_smr,\n@@ -257,1 +152,1 @@\n-                                        ZMarkStackEntry& entry) {\n+                                        ZMarkStackEntry* entry) {\n@@ -259,3 +154,20 @@\n-  ZMarkStack* const stack = *stackp;\n-  if (stack != nullptr && stack->pop(entry)) {\n-    return true;\n+  ZMarkStack* stack = *stackp;\n+\n+  \/\/ First make sure there is a stack to pop from\n+  if (stack == nullptr) {\n+    \/\/ If we have no stack, try to steal one\n+    stack = stripe->steal_stack(marking_smr);\n+    *stackp = stack;\n+\n+    if (stack == nullptr) {\n+      \/\/ Out of stacks to pop from\n+      return false;\n+    }\n+  }\n+\n+  *entry = stack->pop();\n+\n+  if (stack->is_empty()) {\n+    \/\/ Eagerly free empty stacks while on a worker thread\n+    ZMarkStack::destroy(stack);\n+    *stackp = nullptr;\n@@ -264,1 +176,1 @@\n-  return pop_slow(allocator, stripe, stackp, entry);\n+  return true;\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStack.inline.hpp","additions":60,"deletions":148,"binary":false,"changes":208,"status":"modified"},{"patch":"@@ -1,236 +0,0 @@\n-\/*\n- * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/z\/zInitialize.hpp\"\n-#include \"gc\/z\/zLock.inline.hpp\"\n-#include \"gc\/z\/zMarkStack.inline.hpp\"\n-#include \"gc\/z\/zMarkStackAllocator.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/debug.hpp\"\n-\n-ZMarkStackSpace::ZMarkStackSpace()\n-  : _expand_lock(),\n-    _start(0),\n-    _top(0),\n-    _end(0) {\n-  assert(ZMarkStackSpaceLimit >= ZMarkStackSpaceExpandSize, \"ZMarkStackSpaceLimit too small\");\n-\n-  \/\/ Reserve address space\n-  const size_t size = ZMarkStackSpaceLimit;\n-  const uintptr_t addr = (uintptr_t)os::reserve_memory(size, !ExecMem, mtGC);\n-  if (addr == 0) {\n-    ZInitialize::error_d(\"Failed to reserve address space for mark stacks\");\n-    return;\n-  }\n-\n-  \/\/ Successfully initialized\n-  _start = _top = _end = addr;\n-\n-  \/\/ Prime space\n-  _end += expand_space();\n-}\n-\n-bool ZMarkStackSpace::is_initialized() const {\n-  return _start != 0;\n-}\n-\n-uintptr_t ZMarkStackSpace::start() const {\n-  return _start;\n-}\n-\n-size_t ZMarkStackSpace::size() const {\n-  return _end - _start;\n-}\n-\n-size_t ZMarkStackSpace::used() const {\n-  return _top - _start;\n-}\n-\n-size_t ZMarkStackSpace::expand_space() {\n-  const size_t expand_size = ZMarkStackSpaceExpandSize;\n-  const size_t old_size = size();\n-  const size_t new_size = old_size + expand_size;\n-\n-  if (new_size > ZMarkStackSpaceLimit) {\n-    \/\/ Expansion limit reached. This is a fatal error since we\n-    \/\/ currently can't recover from running out of mark stack space.\n-    fatal(\"Mark stack space exhausted. Use -XX:ZMarkStackSpaceLimit=<size> to increase the \"\n-          \"maximum number of bytes allocated for mark stacks. Current limit is %zuM.\",\n-          ZMarkStackSpaceLimit \/ M);\n-  }\n-\n-  log_debug(gc, marking)(\"Expanding mark stack space: %zuM->%zuM\",\n-                         old_size \/ M, new_size \/ M);\n-\n-  \/\/ Expand\n-  os::commit_memory_or_exit((char*)_end, expand_size, false \/* executable *\/, \"Mark stack space\");\n-\n-  return expand_size;\n-}\n-\n-size_t ZMarkStackSpace::shrink_space() {\n-  \/\/ Shrink to what is currently used\n-  const size_t old_size = size();\n-  const size_t new_size = align_up(used(), ZMarkStackSpaceExpandSize);\n-  const size_t shrink_size = old_size - new_size;\n-\n-  if (shrink_size > 0) {\n-    \/\/ Shrink\n-    log_debug(gc, marking)(\"Shrinking mark stack space: %zuM->%zuM\",\n-                           old_size \/ M, new_size \/ M);\n-\n-    const uintptr_t shrink_start = _end - shrink_size;\n-    os::uncommit_memory((char*)shrink_start, shrink_size, false \/* executable *\/);\n-  }\n-\n-  return shrink_size;\n-}\n-\n-uintptr_t ZMarkStackSpace::alloc_space(size_t size) {\n-  uintptr_t top = Atomic::load(&_top);\n-\n-  for (;;) {\n-    const uintptr_t end = Atomic::load(&_end);\n-    const uintptr_t new_top = top + size;\n-    if (new_top > end) {\n-      \/\/ Not enough space left\n-      return 0;\n-    }\n-\n-    const uintptr_t prev_top = Atomic::cmpxchg(&_top, top, new_top);\n-    if (prev_top == top) {\n-      \/\/ Success\n-      return top;\n-    }\n-\n-    \/\/ Retry\n-    top = prev_top;\n-  }\n-}\n-\n-uintptr_t ZMarkStackSpace::expand_and_alloc_space(size_t size) {\n-  ZLocker<ZLock> locker(&_expand_lock);\n-\n-  \/\/ Retry allocation before expanding\n-  uintptr_t addr = alloc_space(size);\n-  if (addr != 0) {\n-    return addr;\n-  }\n-\n-  \/\/ Expand\n-  const size_t expand_size = expand_space();\n-\n-  \/\/ Increment top before end to make sure another\n-  \/\/ thread can't steal out newly expanded space.\n-  addr = Atomic::fetch_then_add(&_top, size);\n-  Atomic::add(&_end, expand_size);\n-\n-  return addr;\n-}\n-\n-uintptr_t ZMarkStackSpace::alloc(size_t size) {\n-  assert(size <= ZMarkStackSpaceExpandSize, \"Invalid size\");\n-\n-  const uintptr_t addr = alloc_space(size);\n-  if (addr != 0) {\n-    return addr;\n-  }\n-\n-  return expand_and_alloc_space(size);\n-}\n-\n-void ZMarkStackSpace::free() {\n-  _end -= shrink_space();\n-  _top = _start;\n-}\n-\n-ZMarkStackAllocator::ZMarkStackAllocator()\n-  : _space(),\n-    _freelist(_space.start()),\n-    _expanded_recently(false) {}\n-\n-bool ZMarkStackAllocator::is_initialized() const {\n-  return _space.is_initialized();\n-}\n-\n-uintptr_t ZMarkStackAllocator::start() const {\n-  return _space.start();\n-}\n-\n-size_t ZMarkStackAllocator::size() const {\n-  return _space.size();\n-}\n-\n-ZMarkStackMagazine* ZMarkStackAllocator::create_magazine_from_space(uintptr_t addr, size_t size) {\n-  assert(is_aligned(size, ZMarkStackSize), \"Invalid size\");\n-\n-  \/\/ Use first stack as magazine\n-  ZMarkStackMagazine* const magazine = new ((void*)addr) ZMarkStackMagazine();\n-  for (size_t i = ZMarkStackSize; i < size; i += ZMarkStackSize) {\n-    ZMarkStack* const stack = new ((void*)(addr + i)) ZMarkStack();\n-    const bool success = magazine->push(stack);\n-    assert(success, \"Magazine should never get full\");\n-  }\n-\n-  return magazine;\n-}\n-\n-ZMarkStackMagazine* ZMarkStackAllocator::alloc_magazine() {\n-  \/\/ Try allocating from the free list first\n-  ZMarkStackMagazine* const magazine = _freelist.pop();\n-  if (magazine != nullptr) {\n-    return magazine;\n-  }\n-\n-  if (!Atomic::load(&_expanded_recently)) {\n-    Atomic::cmpxchg(&_expanded_recently, false, true);\n-  }\n-\n-  \/\/ Allocate new magazine\n-  const uintptr_t addr = _space.alloc(ZMarkStackMagazineSize);\n-  if (addr == 0) {\n-    return nullptr;\n-  }\n-\n-  return create_magazine_from_space(addr, ZMarkStackMagazineSize);\n-}\n-\n-bool ZMarkStackAllocator::clear_and_get_expanded_recently() {\n-  if (!Atomic::load(&_expanded_recently)) {\n-    return false;\n-  }\n-\n-  return Atomic::cmpxchg(&_expanded_recently, true, false);\n-}\n-\n-void ZMarkStackAllocator::free_magazine(ZMarkStackMagazine* magazine) {\n-  _freelist.push(magazine);\n-}\n-\n-void ZMarkStackAllocator::free() {\n-  _freelist.clear();\n-  _space.free();\n-}\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStackAllocator.cpp","additions":0,"deletions":236,"binary":false,"changes":236,"status":"deleted"},{"patch":"@@ -1,84 +0,0 @@\n-\/*\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifndef SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n-#define SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n-\n-#include \"gc\/z\/zGlobals.hpp\"\n-#include \"gc\/z\/zLock.hpp\"\n-#include \"gc\/z\/zMarkStack.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-class ZMarkStackSpace {\n-private:\n-  ZLock              _expand_lock;\n-  uintptr_t          _start;\n-  volatile uintptr_t _top;\n-  volatile uintptr_t _end;\n-  volatile bool      _recently_expanded;\n-\n-  size_t used() const;\n-\n-  size_t expand_space();\n-  size_t shrink_space();\n-\n-  uintptr_t alloc_space(size_t size);\n-  uintptr_t expand_and_alloc_space(size_t size);\n-\n-public:\n-  ZMarkStackSpace();\n-\n-  bool is_initialized() const;\n-\n-  uintptr_t start() const;\n-  size_t size() const;\n-\n-  uintptr_t alloc(size_t size);\n-  void free();\n-};\n-\n-class ZMarkStackAllocator : public CHeapObj<mtGC> {\n-private:\n-  ZCACHE_ALIGNED ZMarkStackSpace        _space;\n-  ZCACHE_ALIGNED ZMarkStackMagazineList _freelist;\n-  ZCACHE_ALIGNED volatile bool          _expanded_recently;\n-\n-  ZMarkStackMagazine* create_magazine_from_space(uintptr_t addr, size_t size);\n-\n-public:\n-  ZMarkStackAllocator();\n-\n-  bool is_initialized() const;\n-\n-  uintptr_t start() const;\n-  size_t size() const;\n-\n-  bool clear_and_get_expanded_recently();\n-\n-  ZMarkStackMagazine* alloc_magazine();\n-  void free_magazine(ZMarkStackMagazine* magazine);\n-\n-  void free();\n-};\n-\n-#endif \/\/ SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStackAllocator.hpp","additions":0,"deletions":84,"binary":false,"changes":84,"status":"deleted"},{"patch":"@@ -63,2 +63,1 @@\n-    nstripes >>= 1;\n-    stripes->set_nstripes(nstripes);\n+    stripes->try_set_nstripes(nstripes, nstripes >> 1);\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkTerminate.inline.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,112 @@\n+\/*\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"gc\/z\/zMarkingSMR.hpp\"\n+#include \"gc\/z\/zMarkStack.inline.hpp\"\n+#include \"gc\/z\/zValue.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+\n+ZMarkingSMR::ZMarkingSMR()\n+  : _worker_states(),\n+    _expanded_recently() {\n+}\n+\n+void ZMarkingSMR::free_node(ZMarkStackListNode* node) {\n+  \/\/ We use hazard pointers as an safe memory reclamation (SMR) technique,\n+  \/\/ for marking stacks. Each stripe has a lock-free stack of mark stacks.\n+  \/\/ When a GC thread (1) pops a mark stack from this lock-free stack,\n+  \/\/ there is a small window of time when the head has been read and we\n+  \/\/ are about to read its next pointer. It is then of great importance\n+  \/\/ that the node is not concurrently freed by another concurrent GC\n+  \/\/ thread (2), popping the same entry. In such an event, the memory\n+  \/\/ of the freed node could, for example become part of a separate\n+  \/\/ node, and potentially pushed onto a separate stripe, with a\n+  \/\/ different next pointer referring to a node of the other stripe.\n+  \/\/ When GC thread (1) then reads the next pointer of what it believed\n+  \/\/ to be the current head node of the first stripe, it actually read\n+  \/\/ a next pointer of a logically different node, pointing into the\n+  \/\/ other stripe. GC thread (2) could then pop the node from the second\n+  \/\/ mark stripe and re-insert it as the head of the first stripe.\n+  \/\/ Disaster eventually hits when GC thread (1) succeeds with its\n+  \/\/ CAS (ABA problem), switching the loaded head to the loaded next\n+  \/\/ pointer of the head. Due to the next pointer belonging to a logically\n+  \/\/ different node than the logical head, we can accidentally corrupt the\n+  \/\/ stack integrity. Using hazarad pointers involves publishing what head\n+  \/\/ was observed by GC thread (1), so that GC thread (2) knows not to\n+  \/\/ free the node when popping it in this race. This prevents the racy\n+  \/\/ interactions from causing any such use-after-free problems.\n+\n+  assert(Thread::current()->is_Worker_thread(), \"must be a worker\");\n+\n+  ZWorkerState* local_state = _worker_states.addr();\n+  ZArray<ZMarkStackListNode*>* freeing = &local_state->_freeing;\n+  freeing->append(node);\n+\n+  if (freeing->length() < (int)ZPerWorkerStorage::count() * 8) {\n+    return;\n+  }\n+\n+  ZPerWorkerIterator<ZWorkerState> iter(&_worker_states);\n+  ZArray<ZMarkStackListNode*>* scanned_hazards = &local_state->_scanned_hazards;\n+\n+  for (ZWorkerState* remote_state; iter.next(&remote_state);) {\n+    ZMarkStackListNode* hazard = Atomic::load(&remote_state->_hazard_ptr);\n+\n+    if (hazard != nullptr) {\n+      scanned_hazards->append(hazard);\n+    }\n+  }\n+\n+  int kept = 0;\n+  for (int i = 0; i < freeing->length(); ++i) {\n+    ZMarkStackListNode* node = freeing->at(i);\n+    freeing->at_put(i, nullptr);\n+\n+    if (scanned_hazards->contains(node)) {\n+      \/\/ Keep\n+      freeing->at_put(kept++, node);\n+    } else {\n+      \/\/ Delete\n+      delete node;\n+    }\n+  }\n+\n+  scanned_hazards->clear();\n+  freeing->trunc_to(kept);\n+}\n+\n+void ZMarkingSMR::free() {\n+  \/\/ Here it is free by definition to free mark stacks.\n+  ZPerWorkerIterator<ZWorkerState> iter(&_worker_states);\n+  for (ZWorkerState* worker_state; iter.next(&worker_state);) {\n+    ZArray<ZMarkStackListNode*>* freeing = &worker_state->_freeing;\n+    for (ZMarkStackListNode* node: *freeing) {\n+      delete node;\n+    }\n+    freeing->clear();\n+  }\n+}\n+\n+ZMarkStackListNode* volatile* ZMarkingSMR::hazard_ptr() {\n+  return &_worker_states.addr()->_hazard_ptr;\n+}\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkingSMR.cpp","additions":112,"deletions":0,"binary":false,"changes":112,"status":"added"},{"patch":"@@ -0,0 +1,53 @@\n+\/*\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n+#define SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n+\n+#include \"gc\/z\/zArray.hpp\"\n+#include \"gc\/z\/zValue.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"memory\/allocation.hpp\"\n+\n+class ZMarkStackListNode;\n+\n+class ZMarkingSMR: public CHeapObj<mtGC> {\n+private:\n+  struct ZWorkerState {\n+    ZMarkStackListNode* volatile _hazard_ptr;\n+    ZArray<ZMarkStackListNode*>  _scanned_hazards;\n+    ZArray<ZMarkStackListNode*>  _freeing;\n+  };\n+\n+  ZPerWorker<ZWorkerState> _worker_states;\n+  volatile bool            _expanded_recently;\n+\n+public:\n+  ZMarkingSMR();\n+  void free();\n+  ZMarkStackListNode* allocate_stack();\n+  void free_node(ZMarkStackListNode* stack);\n+  ZMarkStackListNode* volatile* hazard_ptr();\n+};\n+\n+#endif \/\/ SHARE_GC_Z_ZMARKSTACKALLOCATOR_HPP\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkingSMR.hpp","additions":53,"deletions":0,"binary":false,"changes":53,"status":"added"},{"patch":"@@ -553,1 +553,1 @@\n-    ZHeap::heap()->mark_flush_and_free(Thread::current());\n+    ZHeap::heap()->mark_flush(Thread::current());\n","filename":"src\/hotspot\/share\/gc\/z\/zRemembered.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1427,2 +1427,1 @@\n-    _ncontinue(),\n-    _mark_stack_usage() {}\n+    _ncontinue() {}\n@@ -1444,4 +1443,0 @@\n-void ZStatMark::at_mark_free(size_t mark_stack_usage) {\n-  _mark_stack_usage = mark_stack_usage;\n-}\n-\n@@ -1460,2 +1455,0 @@\n-\n-  log_info(gc, marking)(\"Mark Stack Usage: %zuM\", _mark_stack_usage \/ M);\n","filename":"src\/hotspot\/share\/gc\/z\/zStat.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -509,1 +509,0 @@\n-  void at_mark_free(size_t mark_stack_usage);\n","filename":"src\/hotspot\/share\/gc\/z\/zStat.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -44,4 +44,0 @@\n-  product(size_t, ZMarkStackSpaceLimit, 8*G,                                \\\n-          \"Maximum number of bytes allocated for mark stacks\")              \\\n-          range(32*M, 1024*G)                                               \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/z\/z_globals.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -537,0 +537,1 @@\n+  { \"ZMarkStackSpaceLimit\",         JDK_Version::undefined(), JDK_Version::jdk(25), JDK_Version::undefined() },\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}