{"files":[{"patch":"@@ -1768,4 +1768,0 @@\n-  \/\/ insert a nop at the start of the prolog so we can patch in a\n-  \/\/ branch if we need to invalidate the method later\n-  __ nop();\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -215,5 +215,0 @@\n-\n-void NativeJump::check_verified_entry_alignment(address entry, address verified_entry) {\n-}\n-\n-\n@@ -348,4 +343,0 @@\n-bool NativeInstruction::is_sigill_not_entrant() {\n-  return uint_at(0) == 0xd4bbd5a1; \/\/ dcps1 #0xdead\n-}\n-\n@@ -362,25 +353,0 @@\n-\/\/ MT-safe inserting of a jump over a jump or a nop (used by\n-\/\/ nmethod::make_not_entrant)\n-\n-void NativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"expected fixed destination of patch\");\n-  assert(nativeInstruction_at(verified_entry)->is_jump_or_nop()\n-         || nativeInstruction_at(verified_entry)->is_sigill_not_entrant(),\n-         \"Aarch64 cannot replace non-jump with jump\");\n-\n-  \/\/ Patch this nmethod atomically.\n-  if (Assembler::reachable_from_branch_at(verified_entry, dest)) {\n-    ptrdiff_t disp = dest - verified_entry;\n-    guarantee(disp < 1 << 27 && disp > - (1 << 27), \"branch overflow\");\n-\n-    unsigned int insn = (0b000101 << 26) | ((disp >> 2) & 0x3ffffff);\n-    *(unsigned int*)verified_entry = insn;\n-  } else {\n-    \/\/ We use an illegal instruction for marking a method as not_entrant.\n-    NativeIllegalInstruction::insert(verified_entry);\n-  }\n-\n-  ICache::invalidate_range(verified_entry, instruction_size);\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/nativeInst_aarch64.cpp","additions":0,"deletions":34,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -86,1 +86,0 @@\n-  bool is_sigill_not_entrant();\n@@ -363,3 +362,0 @@\n-  \/\/ MT-safe insertion of native jump at verified method entry\n-  static void check_verified_entry_alignment(address entry, address verified_entry);\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n","filename":"src\/hotspot\/cpu\/aarch64\/nativeInst_aarch64.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -285,10 +285,0 @@\n-void RawNativeJump::check_verified_entry_alignment(address entry, address verified_entry) {\n-}\n-\n-void RawNativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"should be\");\n-  int *a = (int *)verified_entry;\n-  a[0] = not_entrant_illegal_instruction; \/\/ always illegal\n-  ICache::invalidate_range((address)&a[0], sizeof a[0]);\n-}\n-\n","filename":"src\/hotspot\/cpu\/arm\/nativeInst_arm_32.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,4 +64,0 @@\n-  \/\/ illegal instruction used by NativeJump::patch_verified_entry\n-  \/\/ permanently undefined (UDF): 0xe << 28 | 0b1111111 << 20 | 0b1111 << 4\n-  static const int not_entrant_illegal_instruction = 0xe7f000f0;\n-\n@@ -277,4 +273,0 @@\n-  static void check_verified_entry_alignment(address entry, address verified_entry);\n-\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n-\n","filename":"src\/hotspot\/cpu\/arm\/nativeInst_arm_32.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -49,1 +49,0 @@\n-  \/\/ Avoid stack bang as first instruction. It may get overwritten by patch_verified_entry.\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,12 +42,0 @@\n-\/\/ We use an illtrap for marking a method as not_entrant\n-\/\/ Work around a C++ compiler bug which changes 'this'\n-bool NativeInstruction::is_sigill_not_entrant_at(address addr) {\n-  if (!Assembler::is_illtrap(addr)) return false;\n-  CodeBlob* cb = CodeCache::find_blob(addr);\n-  if (cb == nullptr || !cb->is_nmethod()) return false;\n-  nmethod *nm = (nmethod *)cb;\n-  \/\/ This method is not_entrant iff the illtrap instruction is\n-  \/\/ located at the verified entry point.\n-  return nm->verified_entry_point() == addr;\n-}\n-\n@@ -334,19 +322,0 @@\n-void NativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-  ResourceMark rm;\n-  int code_size = 1 * BytesPerInstWord;\n-  CodeBuffer cb(verified_entry, code_size + 1);\n-  MacroAssembler* a = new MacroAssembler(&cb);\n-#ifdef COMPILER2\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"expected fixed destination of patch\");\n-#endif\n-  \/\/ Patch this nmethod atomically. Always use illtrap\/trap in debug build.\n-  if (DEBUG_ONLY(false &&) a->is_within_range_of_b(dest, a->pc())) {\n-    a->b(dest);\n-  } else {\n-    \/\/ The signal handler will continue at dest=OptoRuntime::handle_wrong_method_stub().\n-    \/\/ We use an illtrap for marking a method as not_entrant.\n-    a->illtrap();\n-  }\n-  ICache::ppc64_flush_icache_bytes(verified_entry, code_size);\n-}\n-\n@@ -465,3 +434,1 @@\n-  nmethod *nm = (nmethod *)cb;\n-  \/\/ see NativeInstruction::is_sigill_not_entrant_at()\n-  return nm->verified_entry_point() != code_pos;\n+  return true;\n","filename":"src\/hotspot\/cpu\/ppc\/nativeInst_ppc.cpp","additions":1,"deletions":34,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -72,7 +72,0 @@\n-  \/\/ We use an illtrap for marking a method as not_entrant.\n-  bool is_sigill_not_entrant() {\n-    \/\/ Work around a C++ compiler bug which changes 'this'.\n-    return NativeInstruction::is_sigill_not_entrant_at(addr_at(0));\n-  }\n-  static bool is_sigill_not_entrant_at(address addr);\n-\n@@ -331,3 +324,0 @@\n-  \/\/ MT-safe insertion of native jump at verified method entry\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n-\n@@ -335,5 +325,0 @@\n-\n-  static void check_verified_entry_alignment(address entry, address verified_entry) {\n-    \/\/ We just patch one instruction on ppc64, so the jump doesn't have to\n-    \/\/ be aligned. Nothing to do here.\n-  }\n","filename":"src\/hotspot\/cpu\/ppc\/nativeInst_ppc.hpp","additions":1,"deletions":16,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1689,6 +1689,1 @@\n-  if (method_is_frameless) {\n-    \/\/ Add nop at beginning of all frameless methods to prevent any\n-    \/\/ oop instructions from getting overwritten by make_not_entrant\n-    \/\/ (patching attempt would fail).\n-    __ nop();\n-  } else {\n+  if (!method_is_frameless) {\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -359,12 +359,0 @@\n-\n-void NativeJump::check_verified_entry_alignment(address entry, address verified_entry) {\n-  \/\/ Patching to not_entrant can happen while activations of the method are\n-  \/\/ in use. The patching in that instance must happen only when certain\n-  \/\/ alignment restrictions are true. These guarantees check those\n-  \/\/ conditions.\n-\n-  \/\/ Must be 4 bytes aligned\n-  MacroAssembler::assert_alignment(verified_entry);\n-}\n-\n-\n@@ -423,6 +411,0 @@\n-\/\/ A 16-bit instruction with all bits ones is permanently reserved as an illegal instruction.\n-bool NativeInstruction::is_sigill_not_entrant() {\n-  \/\/ jvmci\n-  return uint_at(0) == 0xffffffff;\n-}\n-\n@@ -439,39 +421,0 @@\n-\n-\/\/ MT-safe inserting of a jump over a jump or a nop (used by\n-\/\/ nmethod::make_not_entrant)\n-\n-void NativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"expected fixed destination of patch\");\n-\n-  assert(nativeInstruction_at(verified_entry)->is_jump_or_nop() ||\n-         nativeInstruction_at(verified_entry)->is_sigill_not_entrant(),\n-         \"riscv cannot replace non-jump with jump\");\n-\n-  check_verified_entry_alignment(entry, verified_entry);\n-\n-  \/\/ Patch this nmethod atomically.\n-  if (Assembler::reachable_from_branch_at(verified_entry, dest)) {\n-    ptrdiff_t offset = dest - verified_entry;\n-    guarantee(Assembler::is_simm21(offset) && ((offset % 2) == 0),\n-              \"offset is too large to be patched in one jal instruction.\"); \/\/ 1M\n-\n-    uint32_t insn = 0;\n-    address pInsn = (address)&insn;\n-    Assembler::patch(pInsn, 31, 31, (offset >> 20) & 0x1);\n-    Assembler::patch(pInsn, 30, 21, (offset >> 1) & 0x3ff);\n-    Assembler::patch(pInsn, 20, 20, (offset >> 11) & 0x1);\n-    Assembler::patch(pInsn, 19, 12, (offset >> 12) & 0xff);\n-    Assembler::patch(pInsn, 11, 7, 0); \/\/ zero, no link jump\n-    Assembler::patch(pInsn, 6, 0, 0b1101111); \/\/ j, (jal x0 offset)\n-    Assembler::sd_instr(verified_entry, insn);\n-  } else {\n-    \/\/ We use an illegal instruction for marking a method as\n-    \/\/ not_entrant.\n-    NativeIllegalInstruction::insert(verified_entry);\n-  }\n-\n-  ICache::invalidate_range(verified_entry, instruction_size);\n-}\n-\n-\/\/-------------------------------------------------------------------\n","filename":"src\/hotspot\/cpu\/riscv\/nativeInst_riscv.cpp","additions":0,"deletions":57,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -77,1 +77,0 @@\n-  bool is_sigill_not_entrant();\n@@ -277,3 +276,0 @@\n-  \/\/ MT-safe insertion of native jump at verified method entry\n-  static void check_verified_entry_alignment(address entry, address verified_entry);\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n","filename":"src\/hotspot\/cpu\/riscv\/nativeInst_riscv.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1371,8 +1371,0 @@\n-  \/\/ insert a nop at the start of the prolog so we can patch in a\n-  \/\/ branch if we need to invalidate the method later\n-  {\n-    Assembler::IncompressibleScope scope(masm); \/\/ keep the nop as 4 bytes for patching.\n-    MacroAssembler::assert_alignment(__ pc());\n-    __ nop();  \/\/ 4 bytes\n-  }\n-\n@@ -1807,1 +1799,0 @@\n-  \/\/ Verified entry point must be properly 4 bytes aligned for patching by NativeJump::patch_verified_entry().\n@@ -8202,1 +8193,1 @@\n-  \n+ \n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -170,21 +170,0 @@\n-\/\/ We use an illtrap for marking a method as not_entrant.\n-bool NativeInstruction::is_sigill_not_entrant() {\n-  if (!is_illegal()) return false; \/\/ Just a quick path.\n-\n-  \/\/ One-sided error of is_illegal tolerable here\n-  \/\/ (see implementation of is_illegal() for details).\n-\n-  CodeBlob* cb = CodeCache::find_blob(addr_at(0));\n-  if (cb == nullptr || !cb->is_nmethod()) {\n-    return false;\n-  }\n-\n-  nmethod *nm = (nmethod *)cb;\n-  \/\/ This method is not_entrant if the illtrap instruction\n-  \/\/ is located at the verified entry point.\n-  \/\/ BE AWARE: the current pc (this) points to the instruction after the\n-  \/\/ \"illtrap\" location.\n-  address sig_addr = ((address) this) - 2;\n-  return nm->verified_entry_point() == sig_addr;\n-}\n-\n@@ -623,13 +602,0 @@\n-\/\/ Patch atomically with an illtrap.\n-void NativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-  ResourceMark rm;\n-  int code_size = 2;\n-  CodeBuffer cb(verified_entry, code_size + 1);\n-  MacroAssembler* a = new MacroAssembler(&cb);\n-#ifdef COMPILER2\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"expected fixed destination of patch\");\n-#endif\n-  a->z_illtrap();\n-  ICache::invalidate_range(verified_entry, code_size);\n-}\n-\n","filename":"src\/hotspot\/cpu\/s390\/nativeInst_s390.cpp","additions":0,"deletions":34,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -88,3 +88,0 @@\n-  \/\/ We use an illtrap for marking a method as not_entrant.\n-  bool is_sigill_not_entrant();\n-\n@@ -612,5 +609,0 @@\n-\n-  \/\/ MT-safe insertion of native jump at verified method entry.\n-  static void check_verified_entry_alignment(address entry, address verified_entry) { }\n-\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n","filename":"src\/hotspot\/cpu\/s390\/nativeInst_s390.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -328,10 +328,0 @@\n-  if (breakAtEntry) {\n-    \/\/ Verified Entry first instruction should be 5 bytes long for correct\n-    \/\/ patching by patch_verified_entry().\n-    \/\/\n-    \/\/ Breakpoint has one byte first instruction.\n-    \/\/ Also first instruction will be one byte \"push(rbp)\" if stack banging\n-    \/\/ code is not generated (see build_frame() above).\n-    \/\/ For all these cases generate long instruction first.\n-    fat_nop();\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -53,7 +53,0 @@\n-\n-  \/\/ WARNING: Initial instruction MUST be 5 bytes or longer so that\n-  \/\/ NativeJump::patch_verified_entry will be able to patch out the entry\n-  \/\/ code safely. The push to verify stack depth is ok at 5 bytes,\n-  \/\/ the frame allocation can be either 3 or 6 bytes. So if we don't do\n-  \/\/ stack bang then we must use the 6 byte frame allocation even if\n-  \/\/ we have no frame. :-(\n@@ -90,2 +83,1 @@\n-    \/\/ Create frame (force generation of a 4 byte immediate value)\n-    subptr_imm32(rsp, framesize);\n+    subptr(rsp, framesize);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1624,13 +1624,0 @@\n-\/\/ A 5 byte nop that is safe for patching (see patch_verified_entry)\n-void MacroAssembler::fat_nop() {\n-  if (UseAddressNop) {\n-    addr_nop_5();\n-  } else {\n-    emit_int8((uint8_t)0x26); \/\/ es:\n-    emit_int8((uint8_t)0x2e); \/\/ cs:\n-    emit_int8((uint8_t)0x64); \/\/ fs:\n-    emit_int8((uint8_t)0x65); \/\/ gs:\n-    emit_int8((uint8_t)0x90);\n-  }\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -212,2 +212,0 @@\n-  \/\/ A 5 byte nop that is safe for patching (see patch_verified_entry)\n-  void fat_nop();\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -339,49 +339,0 @@\n-void NativeJump::check_verified_entry_alignment(address entry, address verified_entry) {\n-  \/\/ Patching to not_entrant can happen while activations of the method are\n-  \/\/ in use. The patching in that instance must happen only when certain\n-  \/\/ alignment restrictions are true. These guarantees check those\n-  \/\/ conditions.\n-  const int linesize = 64;\n-\n-  \/\/ Must be wordSize aligned\n-  guarantee(((uintptr_t) verified_entry & (wordSize -1)) == 0,\n-            \"illegal address for code patching 2\");\n-  \/\/ First 5 bytes must be within the same cache line - 4827828\n-  guarantee((uintptr_t) verified_entry \/ linesize ==\n-            ((uintptr_t) verified_entry + 4) \/ linesize,\n-            \"illegal address for code patching 3\");\n-}\n-\n-\n-\/\/ MT safe inserting of a jump over an unknown instruction sequence (used by nmethod::make_not_entrant)\n-\/\/ The problem: jmp <dest> is a 5-byte instruction. Atomic write can be only with 4 bytes.\n-\/\/ First patches the first word atomically to be a jump to itself.\n-\/\/ Then patches the last byte  and then atomically patches the first word (4-bytes),\n-\/\/ thus inserting the desired jump\n-\/\/ This code is mt-safe with the following conditions: entry point is 4 byte aligned,\n-\/\/ entry point is in same cache line as unverified entry point, and the instruction being\n-\/\/ patched is >= 5 byte (size of patch).\n-\/\/\n-\/\/ In C2 the 5+ byte sized instruction is enforced by code in MachPrologNode::emit.\n-\/\/ In C1 the restriction is enforced by CodeEmitter::method_entry\n-\/\/ In JVMCI, the restriction is enforced by HotSpotFrameContext.enter(...)\n-\/\/\n-void NativeJump::patch_verified_entry(address entry, address verified_entry, address dest) {\n-  \/\/ complete jump instruction (to be inserted) is in code_buffer;\n-  union {\n-    jlong cb_long;\n-    unsigned char code_buffer[8];\n-  } u;\n-\n-  u.cb_long = *(jlong *)verified_entry;\n-\n-  intptr_t disp = (intptr_t)dest - ((intptr_t)verified_entry + 1 + 4);\n-  guarantee(disp == (intptr_t)(int32_t)disp, \"must be 32-bit offset\");\n-\n-  u.code_buffer[0] = instruction_code;\n-  *(int32_t*)(u.code_buffer + 1) = (int32_t)disp;\n-\n-  Atomic::store((jlong *) verified_entry, u.cb_long);\n-  ICache::invalidate_range(verified_entry, 8);\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/nativeInst_x86.cpp","additions":0,"deletions":49,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -448,3 +448,0 @@\n-  \/\/ MT-safe insertion of native jump at verified method entry\n-  static void check_verified_entry_alignment(address entry, address verified_entry);\n-  static void patch_verified_entry(address entry, address verified_entry, address dest);\n","filename":"src\/hotspot\/cpu\/x86\/nativeInst_x86.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1,44 +0,0 @@\n-\/*\n- * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright 2008 Red Hat, Inc.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"entry_zero.hpp\"\n-#include \"interpreter\/zero\/zeroInterpreter.hpp\"\n-#include \"nativeInst_zero.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-\n-\/\/ This method is called by nmethod::make_not_entrant to\n-\/\/ insert a jump to SharedRuntime::get_handle_wrong_method_stub()\n-\/\/ (dest) at the start of a compiled method (verified_entry) to avoid\n-\/\/ a race where a method is invoked while being made non-entrant.\n-\n-void NativeJump::patch_verified_entry(address entry,\n-                                      address verified_entry,\n-                                      address dest) {\n-  assert(dest == SharedRuntime::get_handle_wrong_method_stub(), \"should be\");\n-\n-  ((ZeroEntry*) verified_entry)->set_entry_point(\n-    (address) ZeroInterpreter::normal_entry);\n-}\n","filename":"src\/hotspot\/cpu\/zero\/nativeInst_zero.cpp","additions":0,"deletions":44,"binary":false,"changes":44,"status":"deleted"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -180,8 +180,0 @@\n-\n-  static void check_verified_entry_alignment(address entry,\n-                                             address verified_entry) {\n-  }\n-\n-  static void patch_verified_entry(address entry,\n-                                   address verified_entry,\n-                                   address dest);\n","filename":"src\/hotspot\/cpu\/zero\/nativeInst_zero.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2755,13 +2755,0 @@\n-#ifdef _M_ARM64\n-    if (in_java &&\n-        (exception_code == EXCEPTION_ILLEGAL_INSTRUCTION ||\n-          exception_code == EXCEPTION_ILLEGAL_INSTRUCTION_2)) {\n-      if (nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant\");\n-        }\n-        return Handle_Exception(exceptionInfo, SharedRuntime::get_handle_wrong_method_stub());\n-      }\n-    }\n-#endif\n-\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -232,10 +232,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if (sig == SIGILL && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-        goto run_stub;\n-      }\n-\n-      else if ((sig == (USE_POLL_BIT_ONLY ? SIGTRAP : SIGSEGV)) &&\n+      if ((sig == (USE_POLL_BIT_ONLY ? SIGTRAP : SIGSEGV)) &&\n","filename":"src\/hotspot\/os_cpu\/aix_ppc\/os_aix_ppc.cpp","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -274,8 +274,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if ((sig == SIGILL)\n-          && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-      } else if ((sig == SIGSEGV || sig == SIGBUS) && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n+      if ((sig == SIGSEGV || sig == SIGBUS) && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/os_bsd_aarch64.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -235,8 +235,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if ((sig == SIGILL || sig == SIGTRAP)\n-          && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant (%s)\", (sig == SIGTRAP) ? \"SIGTRAP\" : \"SIGILL\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-      } else if (sig == SIGSEGV && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n+      if (sig == SIGSEGV && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/os_linux_aarch64.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -362,5 +362,0 @@\n-      } else if (sig == SIGILL &&\n-                 *(int*)pc ==\n-                     NativeInstruction::not_entrant_illegal_instruction) {\n-        \/\/ Not entrant\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n","filename":"src\/hotspot\/os_cpu\/linux_arm\/os_linux_arm.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -261,9 +261,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if (sig == SIGILL && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-      }\n-\n-      else if ((sig == (USE_POLL_BIT_ONLY ? SIGTRAP : SIGSEGV)) &&\n+      if ((sig == (USE_POLL_BIT_ONLY ? SIGTRAP : SIGSEGV)) &&\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/os_linux_ppc.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -226,8 +226,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if ((sig == SIGILL || sig == SIGTRAP)\n-          && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant (%s)\", (sig == SIGTRAP) ? \"SIGTRAP\" : \"SIGILL\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-      } else if (sig == SIGSEGV && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n+      if (sig == SIGSEGV && SafepointMechanism::is_poll_address((address)info->si_addr)) {\n","filename":"src\/hotspot\/os_cpu\/linux_riscv\/os_linux_riscv.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -260,9 +260,1 @@\n-      \/\/ Handle signal from NativeJump::patch_verified_entry().\n-      if (sig == SIGILL && nativeInstruction_at(pc)->is_sigill_not_entrant()) {\n-        if (TraceTraps) {\n-          tty->print_cr(\"trap: not_entrant (SIGILL)\");\n-        }\n-        stub = SharedRuntime::get_handle_wrong_method_stub();\n-      }\n-\n-      else if (sig == SIGSEGV &&\n+      if (sig == SIGSEGV &&\n","filename":"src\/hotspot\/os_cpu\/linux_s390\/os_linux_s390.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"code\/relocInfo.hpp\"\n@@ -695,7 +694,0 @@\n-  if (!is_in_use()) {\n-    low_boundary += NativeJump::instruction_size;\n-    \/\/ %%% Note:  On SPARC we patch only a 4-byte trap, not a full NativeJump.\n-    \/\/ This means that the low_boundary is going to be a little too high.\n-    \/\/ This shouldn't matter, since oops of non-entrant methods are never used.\n-    \/\/ In fact, why are we bothering to look at oops in a non-entrant method??\n-  }\n@@ -1656,4 +1648,0 @@\n-  \/\/ Enter a critical section to prevent a race with deopts that patch code and updates the relocation info.\n-  \/\/ Unfortunately, we have to lock the NMethodState_lock before the tty lock due to the deadlock rules and\n-  \/\/ cannot lock in a more finely grained manner.\n-  ConditionalMutexLocker ml(NMethodState_lock, !NMethodState_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n@@ -2043,13 +2031,1 @@\n-      NativeJump::patch_verified_entry(entry_point(), verified_entry_point(),\n-                                       SharedRuntime::get_handle_wrong_method_stub());\n-\n-      \/\/ Update the relocation info for the patched entry.\n-      \/\/ First, get the old relocation info...\n-      RelocIterator iter(this, verified_entry_point(), verified_entry_point() + 8);\n-      if (iter.next() && iter.addr() == verified_entry_point()) {\n-        Relocation* old_reloc = iter.reloc();\n-        \/\/ ...then reset the iterator to update it.\n-        RelocIterator iter(this, verified_entry_point(), verified_entry_point() + 8);\n-        relocInfo::change_reloc_info_for_address(&iter, verified_entry_point(), old_reloc->type(),\n-                                                 relocInfo::relocType::runtime_call_type);\n-      }\n+      BarrierSet::barrier_set()->barrier_set_nmethod()->make_not_entrant(this);\n@@ -2945,3 +2921,0 @@\n-  \/\/ Make sure all the entry points are correctly aligned for patching.\n-  NativeJump::check_verified_entry_alignment(entry_point(), verified_entry_point());\n-\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":1,"deletions":28,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -75,1 +75,15 @@\n-  set_guard_value(nm, disarmed_guard_value());\n+  arm_with(nm, disarmed_guard_value());\n+}\n+\n+void BarrierSetNMethod::arm_with(nmethod* nm, int value) {\n+  assert((value & not_entrant) == 0, \"not_entrant bit is reserved\");\n+  \/\/ Enter critical section.  Does not block for safepoint.\n+  ConditionalMutexLocker ml(NMethodEntryBarrier_lock, !NMethodEntryBarrier_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n+  \/\/ Do not undo sticky bit\n+  if (is_not_entrant(nm)) {\n+    value |= not_entrant;\n+  }\n+  if (guard_value(nm) != value) {\n+    \/\/ Patch the code only if needed.\n+    set_guard_value(nm, value);\n+  }\n@@ -79,1 +93,1 @@\n-  return guard_value(nm) != disarmed_guard_value();\n+  return (guard_value(nm) & ~not_entrant) != disarmed_guard_value();\n@@ -155,1 +169,1 @@\n-    _current_phase = 1;\n+    _current_phase = initial;\n@@ -181,1 +195,1 @@\n-  bool may_enter = bs_nm->nmethod_entry_barrier(nm);\n+  bool may_enter = !bs_nm->is_not_entrant(nm) && bs_nm->nmethod_entry_barrier(nm);\n@@ -184,14 +198,16 @@\n-  \/\/ In case a concurrent thread disarmed the nmethod, we need to ensure the new instructions\n-  \/\/ are made visible, by using a cross modify fence. Note that this is synchronous cross modifying\n-  \/\/ code, where the existence of new instructions is communicated via data (the guard value).\n-  \/\/ This cross modify fence is only needed when the nmethod entry barrier modifies the\n-  \/\/ instructions. Not all platforms currently do that, so if this check becomes expensive,\n-  \/\/ it can be made conditional on the nmethod_patching_type.\n-  OrderAccess::cross_modify_fence();\n-\n-  \/\/ Diagnostic option to force deoptimization 1 in 10 times. It is otherwise\n-  \/\/ a very rare event.\n-  if (DeoptimizeNMethodBarriersALot && !nm->is_osr_method()) {\n-    static volatile uint32_t counter=0;\n-    if (Atomic::add(&counter, 1u) % 10 == 0) {\n-      may_enter = false;\n+  if (may_enter) {\n+    \/\/ In case a concurrent thread disarmed the nmethod, we need to ensure the new instructions\n+    \/\/ are made visible, by using a cross modify fence. Note that this is synchronous cross modifying\n+    \/\/ code, where the existence of new instructions is communicated via data (the guard value).\n+    \/\/ This cross modify fence is only needed when the nmethod entry barrier modifies the\n+    \/\/ instructions. Not all platforms currently do that, so if this check becomes expensive,\n+    \/\/ it can be made conditional on the nmethod_patching_type.\n+    OrderAccess::cross_modify_fence();\n+\n+    \/\/ Diagnostic option to force deoptimization 1 in 10 times. It is otherwise\n+    \/\/ a very rare event.\n+    if (DeoptimizeNMethodBarriersALot && !nm->is_osr_method()) {\n+      static volatile uint32_t counter=0;\n+      if (Atomic::add(&counter, 1u) % 10 == 0) {\n+        may_enter = false;\n+      }\n@@ -223,0 +239,19 @@\n+\n+\/\/ Make the nmethod permanently not-entrant, so that nmethod_stub_entry_barrier() will call\n+\/\/ deoptimize() to redirect the caller to SharedRuntime::get_handle_wrong_method_stub().\n+\/\/ A sticky armed bit is set and other bits are preserved.  As a result, a call to\n+\/\/ nmethod_stub_entry_barrier() may appear to be spurious, because is_armed() still returns\n+\/\/ false and nmethod_entry_barrier() is not called.\n+void BarrierSetNMethod::make_not_entrant(nmethod* nm) {\n+  \/\/ Enter critical section.  Does not block for safepoint.\n+  ConditionalMutexLocker ml(NMethodEntryBarrier_lock, !NMethodEntryBarrier_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n+  int value = guard_value(nm) | not_entrant;\n+  if (guard_value(nm) != value) {\n+    \/\/ Patch the code only if needed.\n+    set_guard_value(nm, value);\n+  }\n+}\n+\n+bool BarrierSetNMethod::is_not_entrant(nmethod* nm) {\n+  return (guard_value(nm) & not_entrant) != 0;\n+}\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.cpp","additions":53,"deletions":18,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -39,0 +39,6 @@\n+  enum {\n+    not_entrant = 1 << 31, \/\/ armed sticky bit, see make_not_entrant\n+    armed = 0,\n+    initial = 1,\n+  };\n+\n@@ -41,0 +47,4 @@\n+protected:\n+  virtual int guard_value(nmethod* nm);\n+  void set_guard_value(nmethod* nm, int value);\n+\n@@ -42,1 +52,1 @@\n-  BarrierSetNMethod() : _current_phase(1) {}\n+  BarrierSetNMethod() : _current_phase(initial) {}\n@@ -53,1 +63,2 @@\n-  bool is_armed(nmethod* nm);\n+  virtual bool is_armed(nmethod* nm);\n+  void arm(nmethod* nm) { arm_with(nm, armed); }\n@@ -55,0 +66,2 @@\n+  virtual void make_not_entrant(nmethod* nm);\n+  virtual bool is_not_entrant(nmethod* nm);\n@@ -56,2 +69,1 @@\n-  int guard_value(nmethod* nm);\n-  void set_guard_value(nmethod* nm, int value);\n+  virtual void arm_with(nmethod* nm, int value);\n@@ -59,1 +71,1 @@\n-  void arm_all_nmethods();\n+  virtual void arm_all_nmethods();\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.hpp","additions":17,"deletions":5,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -153,1 +153,1 @@\n-        _bs->set_guard_value(nm, 0);\n+        _bs->arm(nm);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahCodeRoots.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -108,0 +108,33 @@\n+\n+void ZBarrierSetNMethod::arm_with(nmethod* nm, int value) {\n+  assert((value & not_entrant) == 0, \"not_entrant bit is reserved\");\n+  ZLocker<ZReentrantLock> locker(ZNMethod::lock_for_nmethod(nm));\n+  \/\/ Preserve the sticky bit\n+  if (is_not_entrant(nm)) {\n+    value |= not_entrant;\n+  }\n+  if (guard_value(nm) != value) {\n+    \/\/ Patch the code only if needed.\n+    set_guard_value(nm, value);\n+  }\n+}\n+\n+bool ZBarrierSetNMethod::is_armed(nmethod* nm) {\n+  int value = guard_value(nm) & ~not_entrant;\n+  return value != disarmed_guard_value();\n+}\n+\n+void ZBarrierSetNMethod::make_not_entrant(nmethod* nm) {\n+  ZLocker<ZReentrantLock> locker(ZNMethod::lock_for_nmethod(nm));\n+  int value = guard_value(nm) | not_entrant; \/\/ permanent sticky value\n+  set_guard_value(nm, value);\n+}\n+\n+bool ZBarrierSetNMethod::is_not_entrant(nmethod* nm) {\n+  return (guard_value(nm) & not_entrant) != 0;\n+}\n+\n+uintptr_t ZBarrierSetNMethod::color(nmethod* nm) {\n+  \/\/ color is stored at low order bits of int; conversion to uintptr_t is fine\n+  return uintptr_t(guard_value(nm) & ~not_entrant);\n+}\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSetNMethod.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -33,0 +33,4 @@\n+  enum : int {\n+    not_entrant = 1 << 31, \/\/ armed sticky bit, see make_not_entrant\n+  };\n+\n@@ -37,0 +41,2 @@\n+  uintptr_t color(nmethod* nm);\n+\n@@ -42,0 +48,6 @@\n+\n+  virtual void make_not_entrant(nmethod* nm);\n+  virtual bool is_not_entrant(nmethod* nm);\n+  virtual void arm_with(nmethod* nm, int value);\n+  virtual bool is_armed(nmethod* nm);\n+  virtual void arm_all_nmethods() { ShouldNotCallThis(); }\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSetNMethod.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -772,1 +772,1 @@\n-      _bs_nm->set_guard_value(nm, (int)untype(new_disarm_value_ptr));\n+      _bs_nm->arm_with(nm, (int)untype(new_disarm_value_ptr));\n","filename":"src\/hotspot\/share\/gc\/z\/zMark.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -244,1 +244,1 @@\n-  bs->set_guard_value(nm, value);\n+  bs->arm_with(nm, value);\n@@ -303,3 +303,2 @@\n-  BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()->barrier_set_nmethod();\n-  \/\/ color is stored at low order bits of int; conversion to uintptr_t is fine\n-  return (uintptr_t)bs_nm->guard_value(nm);\n+  ZBarrierSetNMethod* bs_nm = static_cast<ZBarrierSetNMethod*>(BarrierSet::barrier_set()->barrier_set_nmethod());\n+  return bs_nm->color(nm);\n","filename":"src\/hotspot\/share\/gc\/z\/zNMethod.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+Mutex*   NMethodEntryBarrier_lock     = nullptr;\n@@ -208,0 +209,2 @@\n+  MUTEX_DEFN(NMethodEntryBarrier_lock        , PaddedMutex  , service-1);\n+\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+extern Mutex*   NMethodEntryBarrier_lock;        \/\/ protects nmethod entry barrier\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}