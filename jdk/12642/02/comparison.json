{"files":[{"patch":"@@ -83,1 +83,1 @@\n-  NMTPreInit::pre_to_post();\n+  NMTPreInit::pre_to_post(level == NMT_off);\n","filename":"src\/hotspot\/share\/services\/memTracker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2022, 2023 SAP SE. All rights reserved.\n@@ -40,4 +40,0 @@\n-\/\/ We must ensure that the start of the payload area of the nmt lookup table nodes is malloc-aligned\n-static const size_t malloc_alignment = 2 * sizeof(void*); \/\/ could we use max_align_t?\n-STATIC_ASSERT(is_aligned(sizeof(NMTPreInitAllocation), malloc_alignment));\n-\n@@ -47,5 +43,0 @@\n-static void fail_oom(size_t size) {\n-  vm_exit_out_of_memory(size, OOM_MALLOC_ERROR, \"VM early initialization phase\");\n-}\n-\n-\/\/ --------- NMTPreInitAllocation --------------\n@@ -53,4 +44,2 @@\n-NMTPreInitAllocation* NMTPreInitAllocation::do_alloc(size_t payload_size) {\n-  const size_t outer_size = sizeof(NMTPreInitAllocation) + payload_size;\n-  guarantee(outer_size > payload_size, \"Overflow\");\n-  void* p = raw_malloc(outer_size);\n+static void* raw_checked_malloc(size_t s) {\n+  void* p = raw_malloc(s);\n@@ -58,1 +47,1 @@\n-    fail_oom(outer_size);\n+    vm_exit_out_of_memory(s, OOM_MALLOC_ERROR, \"VM early initialization phase\");\n@@ -60,2 +49,1 @@\n-  NMTPreInitAllocation* a = new(p) NMTPreInitAllocation(payload_size);\n-  return a;\n+  return p;\n@@ -64,6 +52,2 @@\n-NMTPreInitAllocation* NMTPreInitAllocation::do_reallocate(NMTPreInitAllocation* old, size_t new_payload_size) {\n-  assert(old->next == nullptr, \"unhang from map first\");\n-  \/\/ We just reallocate the old block, header and all.\n-  const size_t new_outer_size = sizeof(NMTPreInitAllocation) + new_payload_size;\n-  guarantee(new_outer_size > new_payload_size, \"Overflow\");\n-  void* p = raw_realloc(old, new_outer_size);\n+static void* raw_checked_realloc(void* old, size_t s) {\n+  void* p = raw_realloc(old, s);\n@@ -71,1 +55,1 @@\n-    fail_oom(new_outer_size);\n+    vm_exit_out_of_memory(s, OOM_MALLOC_ERROR, \"VM early initialization phase\");\n@@ -73,3 +57,1 @@\n-  \/\/ re-stamp header with new size\n-  NMTPreInitAllocation* a = new(p) NMTPreInitAllocation(new_payload_size);\n-  return a;\n+  return p;\n@@ -78,2 +60,7 @@\n-void NMTPreInitAllocation::do_free(NMTPreInitAllocation* p) {\n-  assert(p->next == nullptr, \"unhang from map first\");\n+\/\/ --------- NMTPreInitAllocation --------------\n+\n+void* NMTPreInitAllocation::operator new(size_t count) {\n+  return raw_checked_malloc(count);\n+}\n+\n+void NMTPreInitAllocation::operator delete(void* p) {\n@@ -83,0 +70,20 @@\n+NMTPreInitAllocation* NMTPreInitAllocation::do_alloc(size_t payload_size) {\n+  void* payload = raw_checked_malloc(payload_size);\n+  NMTPreInitAllocation* a = new NMTPreInitAllocation(payload_size, payload);\n+  return a;\n+}\n+\n+NMTPreInitAllocation* NMTPreInitAllocation::do_reallocate(NMTPreInitAllocation* a, size_t new_payload_size) {\n+  assert(a->next == nullptr, \"unhang from map first\");\n+  void* new_payload = raw_checked_realloc(a->payload, new_payload_size);\n+  NMTPreInitAllocation* a2 = new NMTPreInitAllocation(new_payload_size, new_payload);\n+  delete a;\n+  return a2;\n+}\n+\n+void NMTPreInitAllocation::do_free(NMTPreInitAllocation* a) {\n+  assert(a->next == nullptr, \"unhang from map first\");\n+  raw_free(a->payload);\n+  delete a;\n+}\n+\n@@ -85,0 +92,8 @@\n+void* NMTPreInitAllocationTable::operator new(size_t count) {\n+  return raw_checked_malloc(count);\n+}\n+\n+void NMTPreInitAllocationTable::operator delete(void* p) {\n+  return raw_free(p);\n+}\n+\n@@ -89,0 +104,12 @@\n+NMTPreInitAllocationTable::~NMTPreInitAllocationTable() {\n+  \/\/ clear LU entries, but let payloads live!\n+  for (int i = 0; i < table_size; i++) {\n+    NMTPreInitAllocation* a = _entries[i];\n+    while (a != nullptr) {\n+      NMTPreInitAllocation* a2 = a->next;\n+      delete a;\n+      a = a2;\n+    }\n+  }\n+}\n+\n@@ -119,1 +146,1 @@\n-      st->print( PTR_FORMAT \"(\" SIZE_FORMAT \") \", p2i(a->payload()), a->size);\n+      st->print( PTR_FORMAT \"(\" SIZE_FORMAT \") \", p2i(a->payload), a->size);\n@@ -135,1 +162,1 @@\n-      index_t i2 = index_for_key(a->payload());\n+      index_t i2 = index_for_key(a->payload);\n@@ -170,2 +197,1 @@\n-  void* p = raw_malloc(sizeof(NMTPreInitAllocationTable));\n-  _table = new(p) NMTPreInitAllocationTable();\n+  _table = new NMTPreInitAllocationTable;\n@@ -181,1 +207,2 @@\n-void NMTPreInit::pre_to_post() {\n+void NMTPreInit::pre_to_post(bool nmt_off) {\n+\n@@ -184,0 +211,13 @@\n+  if (nmt_off) {\n+    \/\/ NMT is disabled.\n+    \/\/ Since neither pre- nor post-init-allocations use headers, from now on any pre-init allocation\n+    \/\/ can be handled directly by os::realloc or os::free.\n+    \/\/ We also can get rid of the lookup table.\n+    \/\/ Note that we deliberately leak the headers (NMTPreInitAllocation) in order to speed up startup.\n+    \/\/ That may leak about 12KB of memory for ~500 surviving pre-init allocations, which is a typical\n+    \/\/ number. This is a compromise to keep the coding simple and startup time short. It could very\n+    \/\/ easily improved by keeping a header pool, similar to metaspace ChunkHeaderPool. But since NMTPreInit\n+    \/\/ had been critizised as \"too complicated\", I try to keep things short and simple.\n+    delete _table;\n+    _table = nullptr;\n+  }\n","filename":"src\/hotspot\/share\/services\/nmtPreInit.cpp","additions":74,"deletions":34,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2022, 2023 SAP SE. All rights reserved.\n@@ -124,1 +124,1 @@\n-  \/\/ <-- USER ALLOCATION (PAYLOAD) STARTS HERE -->\n+  void* const payload;\n@@ -126,5 +126,1 @@\n-  NMTPreInitAllocation(size_t size) : next(nullptr), size(size) {};\n-\n-  \/\/ Returns start of the user data area\n-  void* payload()             { return this + 1; }\n-  const void* payload() const { return this + 1; }\n+  NMTPreInitAllocation(size_t s, void* p) : next(nullptr), size(s), payload(p) {}\n@@ -135,2 +131,5 @@\n-  static NMTPreInitAllocation* do_reallocate(NMTPreInitAllocation* old, size_t new_payload_size);\n-  static void do_free(NMTPreInitAllocation* p);\n+  static NMTPreInitAllocation* do_reallocate(NMTPreInitAllocation* a, size_t new_payload_size);\n+  static void do_free(NMTPreInitAllocation* a);\n+\n+  void* operator new(size_t l);\n+  void  operator delete(void* p);\n@@ -173,1 +172,1 @@\n-    while ((*aa) != nullptr && (*aa)->payload() != p) {\n+    while ((*aa) != nullptr && (*aa)->payload != p) {\n@@ -176,1 +175,1 @@\n-    assert((*aa) == nullptr || p == (*aa)->payload(),\n+    assert((*aa) == nullptr || p == (*aa)->payload,\n@@ -178,1 +177,1 @@\n-           p2i(p), p2i((*aa)->payload()));\n+           p2i(p), p2i((*aa)->payload));\n@@ -185,0 +184,1 @@\n+  ~NMTPreInitAllocationTable();\n@@ -188,1 +188,1 @@\n-    void* payload = a->payload();\n+    void* payload = a->payload;\n@@ -215,0 +215,3 @@\n+\n+  void* operator new(size_t l);\n+  void  operator delete(void* p);\n@@ -228,0 +231,1 @@\n+  static void delete_table();\n@@ -257,1 +261,1 @@\n-  static void pre_to_post();\n+  static void pre_to_post(bool nmt_off);\n@@ -269,1 +273,1 @@\n-      (*rc) = a->payload();\n+      (*rc) = a->payload;\n@@ -284,27 +288,10 @@\n-    if (!MemTracker::is_initialized()) {\n-      \/\/ pre-NMT-init:\n-      \/\/ - the address must already be in the lookup table\n-      \/\/ - find the old entry, remove from table, reallocate, add to table\n-      NMTPreInitAllocation* a = find_and_remove_in_map(old_p);\n-      a = NMTPreInitAllocation::do_reallocate(a, new_size);\n-      add_to_map(a);\n-      (*rc) = a->payload();\n-      _num_reallocs_pre++;\n-      return true;\n-    } else {\n-      \/\/ post-NMT-init:\n-      \/\/ If the old block was allocated during pre-NMT-init, we must relocate it: the\n-      \/\/  new block must be allocated with \"normal\" os::malloc.\n-      \/\/ We do this by:\n-      \/\/ - look up (but not remove! lu table is read-only here.) the old entry\n-      \/\/ - allocate new memory via os::malloc()\n-      \/\/ - manually copy the old content over\n-      \/\/ - return the new memory\n-      \/\/ - The lu table is readonly so we keep the old address in the table. And we leave\n-      \/\/   the old block allocated too, to prevent the libc from returning the same address\n-      \/\/   and confusing us.\n-      const NMTPreInitAllocation* a = find_in_map(old_p);\n-      if (a != nullptr) { \/\/ this was originally a pre-init allocation\n-        void* p_new = do_os_malloc(new_size, memflags);\n-        ::memcpy(p_new, a->payload(), MIN2(a->size, new_size));\n-        (*rc) = p_new;\n+    switch (MemTracker::tracking_level()) {\n+      case NMT_unknown: {\n+        \/\/ pre-NMT-init:\n+        \/\/ - the address must already be in the lookup table\n+        \/\/ - find the old entry, remove from table, reallocate, add to table\n+        NMTPreInitAllocation* a = find_and_remove_in_map(old_p);\n+        a = NMTPreInitAllocation::do_reallocate(a, new_size);\n+        add_to_map(a);\n+        (*rc) = a->payload;\n+        _num_reallocs_pre++;\n@@ -313,0 +300,28 @@\n+      break;\n+      case NMT_off: {\n+        \/\/ post-NMT-init, NMT *disabled*:\n+        \/\/ Neither pre- nor post-init-allocation use malloc headers, therefore we can just\n+        \/\/ relegate the realloc to os::realloc.\n+        return false;\n+      }\n+      break;\n+      default: {\n+        \/\/ post-NMT-init, NMT *enabled*:\n+        \/\/ Pre-init allocation does not use malloc header, but from here on we need malloc headers.\n+        \/\/ Therefore, the new block must be allocated with os::malloc.\n+        \/\/ We do this by:\n+        \/\/ - look up (but don't remove! lu table is read-only here.) the old entry\n+        \/\/ - allocate new memory via os::malloc()\n+        \/\/ - manually copy the old content over\n+        \/\/ - return the new memory\n+        \/\/ - The lu table is readonly, so we keep the old address in the table. And we leave\n+        \/\/   the old block allocated too, to prevent the libc from returning the same address\n+        \/\/   and confusing us.\n+        const NMTPreInitAllocation* a = find_in_map(old_p);\n+        if (a != nullptr) { \/\/ this was originally a pre-init allocation\n+          void* p_new = do_os_malloc(new_size, memflags);\n+          ::memcpy(p_new, a->payload, MIN2(a->size, new_size));\n+          (*rc) = p_new;\n+          return true;\n+        }\n+      }\n@@ -323,17 +338,9 @@\n-    if (!MemTracker::is_initialized()) {\n-      \/\/ pre-NMT-init:\n-      \/\/ - the allocation must be in the hash map, since all allocations went through\n-      \/\/   NMTPreInit::handle_malloc()\n-      \/\/ - find the old entry, unhang from map, free it\n-      NMTPreInitAllocation* a = find_and_remove_in_map(p);\n-      NMTPreInitAllocation::do_free(a);\n-      _num_frees_pre++;\n-      return true;\n-    } else {\n-      \/\/ post-NMT-init:\n-      \/\/ - look up (but not remove! lu table is read-only here.) the entry\n-      \/\/ - if found, we do nothing: the lu table is readonly, so we keep the old address\n-      \/\/   in the table. We leave the block allocated to prevent the libc from returning\n-      \/\/   the same address and confusing us.\n-      \/\/ - if not found, we let regular os::free() handle this pointer\n-      if (find_in_map(p) != nullptr) {\n+    switch (MemTracker::tracking_level()) {\n+      case NMT_unknown: {\n+        \/\/ pre-NMT-init:\n+        \/\/ - the allocation must be in the hash map, since all allocations went through\n+        \/\/   NMTPreInit::handle_malloc()\n+        \/\/ - find the old entry, unhang from map, free it\n+        NMTPreInitAllocation* a = find_and_remove_in_map(p);\n+        NMTPreInitAllocation::do_free(a);\n+        _num_frees_pre++;\n@@ -342,0 +349,19 @@\n+      break;\n+      case NMT_off: {\n+        \/\/ post-NMT-init, NMT *disabled*:\n+        \/\/ Neither pre- nor post-init-allocation use malloc headers, therefore we can just\n+        \/\/ relegate the realloc to os::realloc.\n+        return false;\n+      }\n+      break;\n+      default: {\n+        \/\/ post-NMT-init, NMT *enabled*:\n+        \/\/ - look up (but don't remove! lu table is read-only here.) the entry\n+        \/\/ - if found, we do nothing: the lu table is readonly, so we keep the old address\n+        \/\/   in the table. We leave the block allocated to prevent the libc from returning\n+        \/\/   the same address and confusing us.\n+        \/\/ - if not found, we let regular os::free() handle this pointer\n+        if (find_in_map(p) != nullptr) {\n+          return true;\n+        }\n+      }\n","filename":"src\/hotspot\/share\/services\/nmtPreInit.hpp","additions":85,"deletions":59,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -81,1 +81,1 @@\n-    const NMTPreInitAllocation* a = table.find(allocations[i]->payload());\n+    const NMTPreInitAllocation* a = table.find(allocations[i]->payload);\n@@ -89,1 +89,1 @@\n-    NMTPreInitAllocation* a2 = table.find_and_remove(a1->payload());\n+    NMTPreInitAllocation* a2 = table.find_and_remove(a1->payload);\n@@ -100,1 +100,1 @@\n-    const NMTPreInitAllocation* a = table.find(allocations[i]->payload());\n+    const NMTPreInitAllocation* a = table.find(allocations[i]->payload);\n@@ -106,1 +106,1 @@\n-    NMTPreInitAllocation* a = table.find_and_remove(allocations[i]->payload());\n+    NMTPreInitAllocation* a = table.find_and_remove(allocations[i]->payload);\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmtpreinitmap.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -176,40 +176,40 @@\n-        String regex = \".*entries: (\\\\d+).*sum bytes: (\\\\d+).*longest chain length: (\\\\d+).*\";\n-        output.shouldMatch(regex);\n-        String line = output.firstMatch(regex, 0);\n-        if (line == null) {\n-            throw new RuntimeException(\"expected: \" + regex);\n-        }\n-        System.out.println(line);\n-        Pattern p = Pattern.compile(regex);\n-        Matcher mat = p.matcher(line);\n-        mat.matches();\n-        int entries = Integer.parseInt(mat.group(1));\n-        int sum_bytes = Integer.parseInt(mat.group(2));\n-        int longest_chain = Integer.parseInt(mat.group(3));\n-        System.out.println(\"found: \" + entries + \" - \" + sum_bytes + longest_chain + \".\");\n-\n-        \/\/ Now we test the state of the internal lookup table, and through our assumptions about\n-        \/\/   early pre-NMT-init allocations:\n-        \/\/ The normal allocation count of surviving pre-init allocations is around 300-500, with the sum of allocated\n-        \/\/   bytes of a few dozen KB. We check these boundaries (with a very generous overhead) to see if the numbers are\n-        \/\/   way off. If they are, we may either have a leak or just a lot more allocations than we thought before\n-        \/\/   NMT initialization. Both cases should be investigated. Even if the allocations are valid, too many of them\n-        \/\/   stretches the limits of the lookup map, and therefore may cause slower lookup. We should then either change\n-        \/\/   the coding, reducing the number of allocations. Or enlarge the lookup table.\n-\n-        \/\/ Apply some sensible assumptions\n-        if (entries > testMode.num_command_line_args + 2000) { \/\/ Note: normal baseline is 400-500\n-            throw new RuntimeException(\"Suspiciously high number of pre-init allocations.\");\n-        }\n-        if (sum_bytes > 128 * 1024 * 1024) { \/\/ Note: normal baseline is ~30-40KB\n-            throw new RuntimeException(\"Suspiciously high pre-init memory usage.\");\n-        }\n-        if (longest_chain > testMode.expected_max_chain_len) {\n-            \/\/ Under normal circumstances, load factor of the map should be about 0.1. With a good hash distribution, we\n-            \/\/ should rarely see even a chain > 1. Warn if we see exceedingly long bucket chains, since this indicates\n-            \/\/ either that the hash algorithm is inefficient or we have a bug somewhere.\n-            throw new RuntimeException(\"Suspiciously long bucket chains in lookup table.\");\n-        }\n-\n-        \/\/ Finally, check that we see our final NMT report:\n-        if (nmtMode != NMTMode.off) {\n+        if (nmtMode != NMTMode.off) { \/\/ in OFF mode LU table is deleted after VM initialization, nothing to see there\n+            String regex = \".*entries: (\\\\d+).*sum bytes: (\\\\d+).*longest chain length: (\\\\d+).*\";\n+            output.shouldMatch(regex);\n+            String line = output.firstMatch(regex, 0);\n+            if (line == null) {\n+                throw new RuntimeException(\"expected: \" + regex);\n+            }\n+            System.out.println(line);\n+            Pattern p = Pattern.compile(regex);\n+            Matcher mat = p.matcher(line);\n+            mat.matches();\n+            int entries = Integer.parseInt(mat.group(1));\n+            int sum_bytes = Integer.parseInt(mat.group(2));\n+            int longest_chain = Integer.parseInt(mat.group(3));\n+            System.out.println(\"found: \" + entries + \" - \" + sum_bytes + longest_chain + \".\");\n+\n+            \/\/ Now we test the state of the internal lookup table, and through our assumptions about\n+            \/\/   early pre-NMT-init allocations:\n+            \/\/ The normal allocation count of surviving pre-init allocations is around 300-500, with the sum of allocated\n+            \/\/   bytes of a few dozen KB. We check these boundaries (with a very generous overhead) to see if the numbers are\n+            \/\/   way off. If they are, we may either have a leak or just a lot more allocations than we thought before\n+            \/\/   NMT initialization. Both cases should be investigated. Even if the allocations are valid, too many of them\n+            \/\/   stretches the limits of the lookup map, and therefore may cause slower lookup. We should then either change\n+            \/\/   the coding, reducing the number of allocations. Or enlarge the lookup table.\n+\n+            \/\/ Apply some sensible assumptions\n+            if (entries > testMode.num_command_line_args + 2000) { \/\/ Note: normal baseline is 400-500\n+                throw new RuntimeException(\"Suspiciously high number of pre-init allocations.\");\n+            }\n+            if (sum_bytes > 128 * 1024 * 1024) { \/\/ Note: normal baseline is ~30-40KB\n+                throw new RuntimeException(\"Suspiciously high pre-init memory usage.\");\n+            }\n+            if (longest_chain > testMode.expected_max_chain_len) {\n+                \/\/ Under normal circumstances, load factor of the map should be about 0.1. With a good hash distribution, we\n+                \/\/ should rarely see even a chain > 1. Warn if we see exceedingly long bucket chains, since this indicates\n+                \/\/ either that the hash algorithm is inefficient or we have a bug somewhere.\n+                throw new RuntimeException(\"Suspiciously long bucket chains in lookup table.\");\n+            }\n+\n+            \/\/ Finally, check that we see our final NMT report:\n","filename":"test\/hotspot\/jtreg\/runtime\/NMT\/NMTInitializationTest.java","additions":40,"deletions":40,"binary":false,"changes":80,"status":"modified"}]}