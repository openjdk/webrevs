{"files":[{"patch":"@@ -16443,0 +16443,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -16446,2 +16447,0 @@\n-  \/\/ TODO\n-  \/\/ identify correct cost\n@@ -16449,1 +16448,1 @@\n-  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2\" %}\n+  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2,$tmp3\" %}\n@@ -16460,0 +16459,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -16473,0 +16473,31 @@\n+instruct cmpFastLockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP tmp2);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2\" %}\n+\n+  ins_encode %{\n+    __ fast_lock_lightweight($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n+\n+instruct cmpFastUnlockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, TEMP tmp2);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastunlock $object,$box\\t! kills $tmp, $tmp2\" %}\n+\n+  ins_encode %{\n+    __ fast_unlock_lightweight($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":34,"deletions":3,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -81,0 +81,3 @@\n+  } else if (LockingMode == LM_LIGHTWEIGHT) {\n+    \/\/ null check obj. load_klass performs load if DiagnoseSyncOnValueBasedClasses != 0.\n+    ldr(hdr, Address(obj));\n@@ -83,2 +86,0 @@\n-  \/\/ Load object header\n-  ldr(hdr, Address(obj, hdr_offset));\n@@ -89,0 +90,2 @@\n+    \/\/ Load object header\n+    ldr(hdr, Address(obj, hdr_offset));\n@@ -147,5 +150,0 @@\n-    ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-    \/\/ We cannot use tbnz here, the target might be too far away and cannot\n-    \/\/ be encoded.\n-    tst(hdr, markWord::monitor_value);\n-    br(Assembler::NE, slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -58,0 +59,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"uses fast_lock_lightweight\");\n@@ -76,1 +78,2 @@\n-  } else if (LockingMode == LM_LEGACY) {\n+  } else {\n+    assert(LockingMode == LM_LEGACY, \"must be\");\n@@ -105,4 +108,0 @@\n-  } else {\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n-    lightweight_lock(oop, disp_hdr, tmp, tmp3Reg, no_count);\n-    b(count);\n@@ -122,8 +121,7 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n-    mov(tmp, (address)markWord::unused_mark().value());\n-    str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-  }\n+  \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+  \/\/ lock. The fast-path monitor unlock code checks for\n+  \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+  \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n+  mov(tmp, (address)markWord::unused_mark().value());\n+  str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n@@ -160,0 +158,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"uses fast_unlock_lightweight\");\n@@ -178,1 +177,2 @@\n-  } else if (LockingMode == LM_LEGACY) {\n+  } else {\n+    assert(LockingMode == LM_LEGACY, \"must be\");\n@@ -186,4 +186,0 @@\n-  } else {\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n-    lightweight_unlock(oop, tmp, box, disp_hdr, no_count);\n-    b(count);\n@@ -199,13 +195,0 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ If the owner is anonymous, we need to fix it -- in an outline stub.\n-    Register tmp2 = disp_hdr;\n-    ldr(tmp2, Address(tmp, ObjectMonitor::owner_offset()));\n-    \/\/ We cannot use tbnz here, the target might be too far away and cannot\n-    \/\/ be encoded.\n-    tst(tmp2, (uint64_t)ObjectMonitor::ANONYMOUS_OWNER);\n-    C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmp, tmp2);\n-    Compile::current()->output()->add_stub(stub);\n-    br(Assembler::NE, stub->entry());\n-    bind(stub->continuation());\n-  }\n-\n@@ -244,0 +227,258 @@\n+void C2_MacroAssembler::fast_lock_lightweight(Register obj, Register t1,\n+                                              Register t2, Register t3) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert_different_registers(obj, t1, t2, t3);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated;\n+  \/\/ Finish fast lock successfully. MUST reach to with flag == EQ\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. MUST branch to with flag == NE\n+  Label slow_path;\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(t1, obj);\n+    ldrw(t1, Address(t1, Klass::access_flags_offset()));\n+    tstw(t1, JVM_ACC_IS_VALUE_BASED_CLASS);\n+    br(Assembler::NE, slow_path);\n+  }\n+\n+  const Register mark = t1;\n+\n+  { \/\/ Lightweight locking\n+\n+    \/\/ Push lock to the lock stack and finish successfully. MUST reach to with flag == EQ\n+    Label push;\n+\n+    const Register top = t2;\n+    const Register t = t3;\n+\n+    \/\/ Check if lock-stack is full.\n+    ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    cmpw(top, (unsigned)LockStack::end_offset() - 1);\n+    br(Assembler::GT, slow_path);\n+\n+    \/\/ Check if recursive.\n+    subw(t, top, oopSize);\n+    ldr(t, Address(rthread, t));\n+    cmp(obj, t);\n+    br(Assembler::EQ, push);\n+\n+    \/\/ Relaxed normal load to check for monitor. Optimization for monitor case.\n+    ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+\n+    \/\/ Not inflated\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid a lea\");\n+\n+    \/\/ Try to lock. Transition lock-bits 0b01 => 0b00\n+    orr(mark, mark, markWord::unlocked_value);\n+    eor(t, mark, markWord::unlocked_value);\n+    \/\/ Acquire to satisfy the JMM.\n+    cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::xword,\n+            \/*acquire*\/ true, \/*release*\/ false, \/*weak*\/ false, noreg);\n+    br(Assembler::NE, slow_path);\n+\n+    bind(push);\n+    \/\/ After successful lock, push object on lock-stack.\n+    str(obj, Address(rthread, top));\n+    addw(top, top, oopSize);\n+    strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    b(locked);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated);\n+\n+    \/\/ mark contains the tagged ObjectMonitor*.\n+    const Register tagged_monitor = mark;\n+    const uintptr_t monitor_tag = markWord::monitor_value;\n+    const Register owner_addr = t2;\n+    const Register owner = t3;\n+\n+    \/\/ Compute owner address.\n+    lea(owner_addr, Address(tagged_monitor, (in_bytes(ObjectMonitor::owner_offset()) - monitor_tag)));\n+\n+    \/\/ CAS owner (null => current thread).\n+    cmpxchg(owner_addr, zr, rthread, Assembler::xword, \/*acquire*\/ true,\n+            \/*release*\/ false, \/*weak*\/ false, owner);\n+    br(Assembler::EQ, locked);\n+\n+    \/\/ Check if recursive.\n+    cmp(owner, rthread);\n+    br(Assembler::NE, slow_path);\n+\n+    \/\/ Recursive.\n+    increment(Address(tagged_monitor, in_bytes(ObjectMonitor::recursions_offset()) - monitor_tag), 1);\n+  }\n+\n+  bind(locked);\n+  increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n+\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with Flags == EQ.\n+  Label flag_correct;\n+  br(Assembler::EQ, flag_correct);\n+  stop(\"Fast Lock Flag != EQ\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with Flags == NE.\n+  br(Assembler::NE, flag_correct);\n+  stop(\"Fast Lock Flag != NE\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of Flags (NE vs EQ) to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_unlock_lightweight(Register obj, Register t1, Register t2,\n+                                                Register t3) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert_different_registers(obj, t1, t2, t3);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated, inflated_load_monitor;\n+  \/\/ Finish fast unlock successfully. MUST reach to with flag == EQ\n+  Label unlocked;\n+  \/\/ Finish fast unlock unsuccessfully. MUST branch to with flag == NE\n+  Label slow_path;\n+\n+  const Register mark = t1;\n+  const Register top = t2;\n+  const Register t = t3;\n+\n+  { \/\/ Lightweight unlock\n+\n+    \/\/ Check if obj is top of lock-stack.\n+    ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    subw(top, top, oopSize);\n+    ldr(t, Address(rthread, top));\n+    cmp(obj, t);\n+    \/\/ Top of lock stack was not obj. Must be monitor.\n+    br(Assembler::NE, inflated_load_monitor);\n+\n+    \/\/ Pop lock-stack.\n+    DEBUG_ONLY(str(zr, Address(rthread, top));)\n+    strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check if recursive.\n+    subw(t, top, oopSize);\n+    ldr(t, Address(rthread, t));\n+    cmp(obj, t);\n+    br(Assembler::EQ, unlocked);\n+\n+    \/\/ Not recursive.\n+    \/\/ Load Mark.\n+    ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Check header for monitor (0b10).\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+\n+    \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+    orr(t, mark, markWord::unlocked_value);\n+    \/\/ Release to satisfy the JMM.\n+    cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::xword,\n+            \/*acquire*\/ false, \/*release*\/ true, \/*weak*\/ false, noreg);\n+    br(Assembler::EQ, unlocked);\n+\n+    \/\/ Load link store conditional exclusive failed.\n+    \/\/ Restore lock-stack and handle the unlock in runtime.\n+    DEBUG_ONLY(str(obj, Address(rthread, top));)\n+    addw(top, top, oopSize);\n+    str(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    b(slow_path);\n+  }\n+\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated_load_monitor);\n+    ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+#ifdef ASSERT\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+    stop(\"Fast Unlock not monitor\");\n+#endif\n+\n+    bind(inflated);\n+\n+#ifdef ASSERT\n+    Label check_done;\n+    subw(top, top, oopSize);\n+    cmpw(top, in_bytes(JavaThread::lock_stack_base_offset()));\n+    br(Assembler::LT, check_done);\n+    ldr(t, Address(rthread, top));\n+    cmp(obj, t);\n+    br(Assembler::NE, inflated);\n+    stop(\"Fast Unlock lock on stack\");\n+    bind(check_done);\n+#endif\n+\n+    \/\/ mark contains the tagged ObjectMonitor*.\n+    const Register monitor = mark;\n+    const uintptr_t monitor_tag = markWord::monitor_value;\n+\n+    \/\/ Untag the monitor.\n+    sub(monitor, mark, monitor_tag);\n+\n+    const Register recursions = t2;\n+    Label not_recursive;\n+\n+    \/\/ Check if recursive.\n+    ldr(recursions, Address(monitor, ObjectMonitor::recursions_offset()));\n+    cbz(recursions, not_recursive);\n+\n+    \/\/ Recursive unlock.\n+    sub(recursions, recursions, 1u);\n+    str(recursions, Address(monitor, ObjectMonitor::recursions_offset()));\n+    \/\/ Set flag == EQ\n+    cmp(recursions, recursions);\n+    b(unlocked);\n+\n+    bind(not_recursive);\n+\n+    Label release;\n+    const Register owner_addr = t2;\n+\n+    \/\/ Compute owner address.\n+    lea(owner_addr, Address(monitor, ObjectMonitor::owner_offset()));\n+\n+    \/\/ Check if the entry lists are empty.\n+    ldr(rscratch1, Address(monitor, ObjectMonitor::EntryList_offset()));\n+    ldr(t, Address(monitor, ObjectMonitor::cxq_offset()));\n+    orr(rscratch1, rscratch1, t);\n+    cmp(rscratch1, zr);\n+    br(Assembler::EQ, release);\n+\n+    \/\/ The owner may be anonymous and we removed the last obj entry in\n+    \/\/ the lock-stack. This loses the information about the owner.\n+    \/\/ Write the thread to the owner field so the runtime knows the owner.\n+    str(rthread, Address(owner_addr));\n+    b(slow_path);\n+\n+    bind(release);\n+    \/\/ Set owner to null.\n+    \/\/ Release to satisfy the JMM\n+    stlr(zr, owner_addr);\n+  }\n+\n+  bind(unlocked);\n+  decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with Flags == EQ.\n+  Label flag_correct;\n+  br(Assembler::EQ, flag_correct);\n+  stop(\"Fast Unlock Flag != EQ\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with Flags == NE.\n+  br(Assembler::NE, flag_correct);\n+  stop(\"Fast Unlock Flag != NE\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of Flags (NE vs EQ) to determine the continuation.\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":272,"deletions":31,"binary":false,"changes":303,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-  \/\/ See full description in macroAssembler_aarch64.cpp.\n@@ -42,0 +41,3 @@\n+  \/\/ Code used by cmpFastLockLightweight and cmpFastUnlockLightweight mach instructions in .ad file.\n+  void fast_lock_lightweight(Register object, Register t1, Register t2, Register t3);\n+  void fast_unlock_lightweight(Register object, Register t1, Register t2, Register t3);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -704,1 +704,0 @@\n-      ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -821,16 +820,0 @@\n-\n-      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n-      \/\/ must handle it.\n-      Register tmp = rscratch1;\n-      \/\/ First check for lock-stack underflow.\n-      ldrw(tmp, Address(rthread, JavaThread::lock_stack_top_offset()));\n-      cmpw(tmp, (unsigned)LockStack::start_offset());\n-      br(Assembler::LE, slow_case);\n-      \/\/ Then check if the top of the lock-stack matches the unlocked object.\n-      subw(tmp, tmp, oopSize);\n-      ldr(tmp, Address(rthread, tmp));\n-      cmpoop(tmp, obj_reg);\n-      br(Assembler::NE, slow_case);\n-\n-      ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      tbnz(header_reg, exact_log2(markWord::monitor_value), slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":0,"deletions":17,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -26,2 +26,0 @@\n-#include <sys\/types.h>\n-\n@@ -58,0 +56,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -69,0 +68,2 @@\n+#include <sys\/types.h>\n+\n@@ -6331,2 +6332,0 @@\n-\/\/ Branches to slow upon failure to lock the object, with ZF cleared.\n-\/\/ Falls through upon success with ZF set.\n@@ -6335,3 +6334,2 @@\n-\/\/  - hdr: the header, already loaded from obj, will be destroyed\n-\/\/  - t1, t2: temporary registers, will be destroyed\n-void MacroAssembler::lightweight_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+\/\/  - t1, t2, t3: temporary registers, will be destroyed\n+void MacroAssembler::lightweight_lock(Register obj, Register t1, Register t2, Register t3, Label& slow) {\n@@ -6339,15 +6337,21 @@\n-  assert_different_registers(obj, hdr, t1, t2, rscratch1);\n-\n-  \/\/ Check if we would have space on lock-stack for the object.\n-  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n-  cmpw(t1, (unsigned)LockStack::end_offset() - 1);\n-  br(Assembler::GT, slow);\n-\n-  \/\/ Load (object->mark() | 1) into hdr\n-  orr(hdr, hdr, markWord::unlocked_value);\n-  \/\/ Clear lock-bits, into t2\n-  eor(t2, hdr, markWord::unlocked_value);\n-  \/\/ Try to swing header from unlocked to locked\n-  \/\/ Clobbers rscratch1 when UseLSE is false\n-  cmpxchg(\/*addr*\/ obj, \/*expected*\/ hdr, \/*new*\/ t2, Assembler::xword,\n-          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t1);\n+  assert_different_registers(obj, t1, t2, t3, rscratch1);\n+\n+  Label push;\n+  const Register top = t1;\n+  const Register mark = t2;\n+  const Register t = t3;\n+\n+  \/\/ Check if the lock-stack is full.\n+  ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  cmpw(top, (unsigned)LockStack::end_offset());\n+  br(Assembler::GE, slow);\n+\n+  \/\/ Check for recursion.\n+  subw(t, top, oopSize);\n+  ldr(t, Address(rthread, t));\n+  cmp(obj, t);\n+  br(Assembler::EQ, push);\n+\n+  \/\/ Check header for monitor (0b10).\n+  ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  tst(mark, markWord::monitor_value);\n@@ -6356,5 +6360,13 @@\n-  \/\/ After successful lock, push object on lock-stack\n-  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n-  str(obj, Address(rthread, t1));\n-  addw(t1, t1, oopSize);\n-  strw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  \/\/ Try to lock. Transition lock bits 0b01 => 0b00\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+  orr(mark, mark, markWord::unlocked_value);\n+  eor(t, mark, markWord::unlocked_value);\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ false, \/*weak*\/ false, noreg);\n+  br(Assembler::NE, slow);\n+\n+  bind(push);\n+  \/\/ After successful lock, push object on lock-stack.\n+  str(obj, Address(rthread, top));\n+  addw(top, top, oopSize);\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n@@ -6364,2 +6376,0 @@\n-\/\/ Branches to slow upon failure, with ZF cleared.\n-\/\/ Falls through upon success, with ZF set.\n@@ -6368,3 +6378,2 @@\n-\/\/ - hdr: the (pre-loaded) header of the object\n-\/\/ - t1, t2: temporary registers\n-void MacroAssembler::lightweight_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+\/\/ - t1, t2, t3: temporary registers\n+void MacroAssembler::lightweight_unlock(Register obj, Register t1, Register t2, Register t3, Label& slow) {\n@@ -6372,1 +6381,1 @@\n-  assert_different_registers(obj, hdr, t1, t2, rscratch1);\n+  assert_different_registers(obj, t1, t2, t3, rscratch1);\n@@ -6376,4 +6385,0 @@\n-    \/\/ The following checks rely on the fact that LockStack is only ever modified by\n-    \/\/ its owning thread, even if the lock got inflated concurrently; removal of LockStack\n-    \/\/ entries after inflation will happen delayed in that case.\n-\n@@ -6384,1 +6389,1 @@\n-    br(Assembler::GT, stack_ok);\n+    br(Assembler::GE, stack_ok);\n@@ -6388,18 +6393,0 @@\n-  {\n-    \/\/ Check if the top of the lock-stack matches the unlocked object.\n-    Label tos_ok;\n-    subw(t1, t1, oopSize);\n-    ldr(t1, Address(rthread, t1));\n-    cmpoop(t1, obj);\n-    br(Assembler::EQ, tos_ok);\n-    STOP(\"Top of lock-stack does not match the unlocked object\");\n-    bind(tos_ok);\n-  }\n-  {\n-    \/\/ Check that hdr is fast-locked.\n-    Label hdr_ok;\n-    tst(hdr, markWord::lock_mask_in_place);\n-    br(Assembler::EQ, hdr_ok);\n-    STOP(\"Header is not fast-locked\");\n-    bind(hdr_ok);\n-  }\n@@ -6408,2 +6395,4 @@\n-  \/\/ Load the new header (unlocked) into t1\n-  orr(t1, hdr, markWord::unlocked_value);\n+  Label unlocked, push_and_slow;\n+  const Register top = t1;\n+  const Register mark = t2;\n+  const Register t = t3;\n@@ -6411,4 +6400,5 @@\n-  \/\/ Try to swing header from locked to unlocked\n-  \/\/ Clobbers rscratch1 when UseLSE is false\n-  cmpxchg(obj, hdr, t1, Assembler::xword,\n-          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t2);\n+  \/\/ Check if obj is top of lock-stack.\n+  ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  subw(top, top, oopSize);\n+  ldr(t, Address(rthread, top));\n+  cmp(obj, t);\n@@ -6417,3 +6407,14 @@\n-  \/\/ After successful unlock, pop object from lock-stack\n-  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n-  subw(t1, t1, oopSize);\n+  \/\/ Pop lock-stack.\n+  DEBUG_ONLY(str(zr, Address(rthread, top));)\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Check if recursive.\n+  subw(t, top, oopSize);\n+  ldr(t, Address(rthread, t));\n+  cmp(obj, t);\n+  br(Assembler::EQ, unlocked);\n+\n+  \/\/ Not recursive. Check header for monitor (0b10).\n+  ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  tbnz(mark, log2i_exact(markWord::monitor_value), push_and_slow);\n+\n@@ -6421,1 +6422,5 @@\n-  str(zr, Address(rthread, t1));\n+  \/\/ Check header not unlocked (0b01).\n+  Label not_unlocked;\n+  tbz(mark, log2i_exact(markWord::unlocked_value), not_unlocked);\n+  stop(\"lightweight_unlock already unlocked\");\n+  bind(not_unlocked);\n@@ -6423,1 +6428,16 @@\n-  strw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+  orr(t, mark, markWord::unlocked_value);\n+  cmpxchg(obj, mark, t, Assembler::xword,\n+          \/*acquire*\/ false, \/*release*\/ true, \/*weak*\/ false, noreg);\n+  br(Assembler::EQ, unlocked);\n+\n+  bind(push_and_slow);\n+  \/\/ Restore lock-stack and handle the unlock in runtime.\n+  DEBUG_ONLY(str(obj, Address(rthread, top));)\n+  addw(top, top, oopSize);\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  b(slow);\n+\n+  bind(unlocked);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":87,"deletions":67,"binary":false,"changes":154,"status":"modified"},{"patch":"@@ -1608,2 +1608,2 @@\n-  void lightweight_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n-  void lightweight_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n+  void lightweight_lock(Register obj, Register t1, Register t2, Register t3, Label& slow);\n+  void lightweight_unlock(Register obj, Register t1, Register t2, Register t3, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1817,1 +1817,0 @@\n-      __ ldr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -1960,2 +1959,0 @@\n-      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ tbnz(old_hdr, exact_log2(markWord::monitor_value), slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -171,0 +171,1 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}