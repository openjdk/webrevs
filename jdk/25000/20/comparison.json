{"files":[{"patch":"@@ -1,226 +0,0 @@\n-\/*\n- * Copyright (c) 2004, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"gc\/parallel\/gcAdaptivePolicyCounters.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-\n-\/\/ This class keeps statistical information and computes the\n-\/\/ size of the heap.\n-\n-GCAdaptivePolicyCounters::GCAdaptivePolicyCounters(const char* name,\n-                                        int collectors,\n-                                        int generations,\n-                                        AdaptiveSizePolicy* size_policy_arg)\n-        : GCPolicyCounters(name, collectors, generations),\n-          _size_policy(size_policy_arg) {\n-  if (UsePerfData) {\n-    EXCEPTION_MARK;\n-    ResourceMark rm;\n-\n-    const char* cname = PerfDataManager::counter_name(name_space(), \"edenSize\");\n-    _eden_size_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, _size_policy->calculated_eden_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"promoSize\");\n-    _promo_size_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, size_policy()->calculated_promo_size_in_bytes(),\n-      CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"youngCapacity\");\n-    size_t young_capacity_in_bytes =\n-      _size_policy->calculated_eden_size_in_bytes() +\n-      _size_policy->calculated_survivor_size_in_bytes();\n-    _young_capacity_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, young_capacity_in_bytes, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgSurvivedAvg\");\n-    _avg_survived_avg_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, size_policy()->calculated_survivor_size_in_bytes(),\n-        CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgSurvivedDev\");\n-    _avg_survived_dev_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) 0 , CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgSurvivedPaddedAvg\");\n-    _avg_survived_padded_avg_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Bytes,\n-        size_policy()->calculated_survivor_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgMinorPauseTime\");\n-    _avg_minor_pause_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Ticks, (jlong) _size_policy->_avg_minor_pause->average(),\n-      CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgMinorIntervalTime\");\n-    _avg_minor_interval_counter = PerfDataManager::create_variable(SUN_GC,\n-      cname,\n-      PerfData::U_Ticks,\n-      (jlong) _size_policy->_avg_minor_interval->average(),\n-      CHECK);\n-\n-#ifdef NOT_PRODUCT\n-      \/\/ This is a counter for the most recent minor pause time\n-      \/\/ (the last sample, not the average).  It is useful for\n-      \/\/ verifying the average pause time but not worth putting\n-      \/\/ into the product.\n-      cname = PerfDataManager::counter_name(name_space(), \"minorPauseTime\");\n-      _minor_pause_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Ticks, (jlong) _size_policy->_avg_minor_pause->last_sample(),\n-      CHECK);\n-#endif\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"minorGcCost\");\n-    _minor_gc_cost_counter = PerfDataManager::create_variable(SUN_GC,\n-      cname,\n-      PerfData::U_Ticks,\n-      (jlong) _size_policy->minor_gc_cost(),\n-      CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"mutatorCost\");\n-    _mutator_cost_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Ticks, (jlong) _size_policy->mutator_cost(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"survived\");\n-    _survived_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"promoted\");\n-    _promoted_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgYoungLive\");\n-    _avg_young_live_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) size_policy()->avg_young_live()->average(),\n-      CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgOldLive\");\n-    _avg_old_live_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) size_policy()->avg_old_live()->average(),\n-      CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"survivorOverflowed\");\n-    _survivor_overflowed_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Events, (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"decrementTenuringThresholdForGcCost\");\n-    _decrement_tenuring_threshold_for_gc_cost_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"incrementTenuringThresholdForGcCost\");\n-    _increment_tenuring_threshold_for_gc_cost_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"decrementTenuringThresholdForSurvivorLimit\");\n-    _decrement_tenuring_threshold_for_survivor_limit_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"changeYoungGenForMinPauses\");\n-    _change_young_gen_for_min_pauses_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"changeOldGenForMajPauses\");\n-    _change_old_gen_for_maj_pauses_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"increaseOldGenForThroughput\");\n-    _change_old_gen_for_throughput_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"increaseYoungGenForThroughput\");\n-    _change_young_gen_for_throughput_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"decreaseForFootprint\");\n-    _decrease_for_footprint_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Events, (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"decideAtFullGc\");\n-    _decide_at_full_gc_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"minorPauseYoungSlope\");\n-    _minor_pause_young_slope_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"majorCollectionSlope\");\n-    _major_collection_slope_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"minorCollectionSlope\");\n-    _minor_collection_slope_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-  }\n-}\n-\n-void GCAdaptivePolicyCounters::update_counters_from_policy() {\n-  if (UsePerfData && (size_policy() != nullptr)) {\n-    update_avg_minor_pause_counter();\n-    update_avg_minor_interval_counter();\n-#ifdef NOT_PRODUCT\n-    update_minor_pause_counter();\n-#endif\n-    update_minor_gc_cost_counter();\n-    update_avg_young_live_counter();\n-\n-    update_survivor_size_counters();\n-    update_avg_survived_avg_counters();\n-    update_avg_survived_dev_counters();\n-    update_avg_survived_padded_avg_counters();\n-\n-    update_change_old_gen_for_throughput();\n-    update_change_young_gen_for_throughput();\n-    update_decrease_for_footprint();\n-    update_change_young_gen_for_min_pauses();\n-    update_change_old_gen_for_maj_pauses();\n-\n-    update_minor_pause_young_slope_counter();\n-    update_minor_collection_slope_counter();\n-    update_major_collection_slope_counter();\n-  }\n-}\n-\n-void GCAdaptivePolicyCounters::update_counters() {\n-  if (UsePerfData) {\n-    update_counters_from_policy();\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/parallel\/gcAdaptivePolicyCounters.cpp","additions":0,"deletions":226,"binary":false,"changes":226,"status":"deleted"},{"patch":"@@ -1,228 +0,0 @@\n-\/*\n- * Copyright (c) 2004, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_PARALLEL_GCADAPTIVEPOLICYCOUNTERS_HPP\n-#define SHARE_GC_PARALLEL_GCADAPTIVEPOLICYCOUNTERS_HPP\n-\n-#include \"gc\/shared\/adaptiveSizePolicy.hpp\"\n-#include \"gc\/shared\/gcPolicyCounters.hpp\"\n-#include \"utilities\/macros.hpp\"\n-\n-\/\/ This class keeps statistical information and computes the\n-\/\/ size of the heap.\n-\n-class GCAdaptivePolicyCounters : public GCPolicyCounters {\n- protected:\n-  PerfVariable*         _eden_size_counter;\n-  PerfVariable*         _promo_size_counter;\n-\n-  PerfVariable*         _young_capacity_counter;\n-\n-  PerfVariable*         _minor_gc_cost_counter;\n-  PerfVariable*         _major_gc_cost_counter;\n-  PerfVariable*         _mutator_cost_counter;\n-\n-  PerfVariable*         _avg_young_live_counter;\n-  PerfVariable*         _avg_old_live_counter;\n-\n-  PerfVariable*         _avg_minor_pause_counter;\n-  PerfVariable*         _avg_minor_interval_counter;\n-\n-#ifdef NOT_PRODUCT\n-  PerfVariable*         _minor_pause_counter;\n-#endif\n-\n-  PerfVariable*         _change_young_gen_for_min_pauses_counter;\n-  PerfVariable*         _change_young_gen_for_throughput_counter;\n-  PerfVariable*         _change_old_gen_for_maj_pauses_counter;\n-  PerfVariable*         _change_old_gen_for_throughput_counter;\n-  PerfVariable*         _decrease_for_footprint_counter;\n-\n-  PerfVariable*         _minor_pause_young_slope_counter;\n-\n-  PerfVariable*         _decide_at_full_gc_counter;\n-\n-  PerfVariable*         _survived_counter;\n-  PerfVariable*         _promoted_counter;\n-\n-  PerfVariable*         _avg_survived_avg_counter;\n-  PerfVariable*         _avg_survived_dev_counter;\n-  PerfVariable*         _avg_survived_padded_avg_counter;\n-\n-  PerfVariable*         _survivor_overflowed_counter;\n-  PerfVariable*         _increment_tenuring_threshold_for_gc_cost_counter;\n-  PerfVariable*         _decrement_tenuring_threshold_for_gc_cost_counter;\n-  PerfVariable*        _decrement_tenuring_threshold_for_survivor_limit_counter;\n-\n-  PerfVariable*         _minor_collection_slope_counter;\n-  PerfVariable*         _major_collection_slope_counter;\n-\n-  AdaptiveSizePolicy* _size_policy;\n-\n-  inline void update_eden_size() {\n-    size_t eden_size_in_bytes = size_policy()->calculated_eden_size_in_bytes();\n-    _eden_size_counter->set_value(eden_size_in_bytes);\n-  }\n-\n-  inline void update_promo_size() {\n-    _promo_size_counter->set_value(\n-      size_policy()->calculated_promo_size_in_bytes());\n-  }\n-\n-  inline void update_avg_minor_pause_counter() {\n-    _avg_minor_pause_counter->set_value((jlong)\n-      (size_policy()->avg_minor_pause()->average() * 1000.0));\n-  }\n-  inline void update_avg_minor_interval_counter() {\n-    _avg_minor_interval_counter->set_value((jlong)\n-      (size_policy()->avg_minor_interval()->average() * 1000.0));\n-  }\n-\n-#ifdef NOT_PRODUCT\n-  inline void update_minor_pause_counter() {\n-    _minor_pause_counter->set_value((jlong)\n-      (size_policy()->avg_minor_pause()->last_sample() * 1000.0));\n-  }\n-#endif\n-  inline void update_minor_gc_cost_counter() {\n-    _minor_gc_cost_counter->set_value((jlong)\n-      (size_policy()->minor_gc_cost() * 100.0));\n-  }\n-\n-  inline void update_avg_young_live_counter() {\n-    _avg_young_live_counter->set_value(\n-      (jlong)(size_policy()->avg_young_live()->average())\n-    );\n-  }\n-\n-  inline void update_avg_survived_avg_counters() {\n-    _avg_survived_avg_counter->set_value(\n-      (jlong)(size_policy()->_avg_survived->average())\n-    );\n-  }\n-  inline void update_avg_survived_dev_counters() {\n-    _avg_survived_dev_counter->set_value(\n-      (jlong)(size_policy()->_avg_survived->deviation())\n-    );\n-  }\n-  inline void update_avg_survived_padded_avg_counters() {\n-    _avg_survived_padded_avg_counter->set_value(\n-      (jlong)(size_policy()->_avg_survived->padded_average())\n-    );\n-  }\n-\n-  inline void update_change_old_gen_for_throughput() {\n-    _change_old_gen_for_throughput_counter->set_value(\n-      size_policy()->change_old_gen_for_throughput());\n-  }\n-  inline void update_change_young_gen_for_throughput() {\n-    _change_young_gen_for_throughput_counter->set_value(\n-      size_policy()->change_young_gen_for_throughput());\n-  }\n-  inline void update_decrease_for_footprint() {\n-    _decrease_for_footprint_counter->set_value(\n-      size_policy()->decrease_for_footprint());\n-  }\n-\n-  inline void update_decide_at_full_gc_counter() {\n-    _decide_at_full_gc_counter->set_value(\n-      size_policy()->decide_at_full_gc());\n-  }\n-\n-  inline void update_minor_pause_young_slope_counter() {\n-    _minor_pause_young_slope_counter->set_value(\n-      (jlong)(size_policy()->minor_pause_young_slope() * 1000)\n-    );\n-  }\n-\n-  virtual void update_counters_from_policy();\n-\n- protected:\n-  virtual AdaptiveSizePolicy* size_policy() { return _size_policy; }\n-\n- public:\n-  GCAdaptivePolicyCounters(const char* name,\n-                           int collectors,\n-                           int generations,\n-                           AdaptiveSizePolicy* size_policy);\n-\n-  inline void update_survived(size_t survived) {\n-    _survived_counter->set_value(survived);\n-  }\n-  inline void update_promoted(size_t promoted) {\n-    _promoted_counter->set_value(promoted);\n-  }\n-  inline void update_young_capacity(size_t size_in_bytes) {\n-    _young_capacity_counter->set_value(size_in_bytes);\n-  }\n-\n-  virtual void update_counters();\n-\n-  inline void update_survivor_size_counters() {\n-    desired_survivor_size()->set_value(\n-      size_policy()->calculated_survivor_size_in_bytes());\n-  }\n-  inline void update_survivor_overflowed(bool survivor_overflowed) {\n-    _survivor_overflowed_counter->set_value(survivor_overflowed);\n-  }\n-  inline void update_tenuring_threshold(uint threshold) {\n-    tenuring_threshold()->set_value(threshold);\n-  }\n-  inline void update_increment_tenuring_threshold_for_gc_cost() {\n-    _increment_tenuring_threshold_for_gc_cost_counter->set_value(\n-      size_policy()->increment_tenuring_threshold_for_gc_cost());\n-  }\n-  inline void update_decrement_tenuring_threshold_for_gc_cost() {\n-    _decrement_tenuring_threshold_for_gc_cost_counter->set_value(\n-      size_policy()->decrement_tenuring_threshold_for_gc_cost());\n-  }\n-  inline void update_decrement_tenuring_threshold_for_survivor_limit() {\n-    _decrement_tenuring_threshold_for_survivor_limit_counter->set_value(\n-      size_policy()->decrement_tenuring_threshold_for_survivor_limit());\n-  }\n-  inline void update_change_young_gen_for_min_pauses() {\n-    _change_young_gen_for_min_pauses_counter->set_value(\n-      size_policy()->change_young_gen_for_min_pauses());\n-  }\n-  inline void update_change_old_gen_for_maj_pauses() {\n-    _change_old_gen_for_maj_pauses_counter->set_value(\n-      size_policy()->change_old_gen_for_maj_pauses());\n-  }\n-\n-  inline void update_minor_collection_slope_counter() {\n-    _minor_collection_slope_counter->set_value(\n-      (jlong)(size_policy()->minor_collection_slope() * 1000)\n-    );\n-  }\n-\n-  inline void update_major_collection_slope_counter() {\n-    _major_collection_slope_counter->set_value(\n-      (jlong)(size_policy()->major_collection_slope() * 1000)\n-    );\n-  }\n-\n-  void set_size_policy(AdaptiveSizePolicy* v) { _size_policy = v; }\n-};\n-\n-#endif \/\/ SHARE_GC_PARALLEL_GCADAPTIVEPOLICYCOUNTERS_HPP\n","filename":"src\/hotspot\/share\/gc\/parallel\/gcAdaptivePolicyCounters.hpp","additions":0,"deletions":228,"binary":false,"changes":228,"status":"deleted"},{"patch":"@@ -69,0 +69,5 @@\n+  \/\/ True in product build, since tests using debug build often stress GC\n+  if (FLAG_IS_DEFAULT(UseGCOverheadLimit)) {\n+    FLAG_SET_DEFAULT(UseGCOverheadLimit, trueInProduct);\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelArguments.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -61,1 +62,1 @@\n-PSGCAdaptivePolicyCounters* ParallelScavengeHeap::_gc_policy_counters = nullptr;\n+GCPolicyCounters* ParallelScavengeHeap::_gc_policy_counters = nullptr;\n@@ -103,11 +104,3 @@\n-  const size_t eden_capacity = _young_gen->eden_space()->capacity_in_bytes();\n-  const size_t old_capacity = _old_gen->capacity_in_bytes();\n-  const size_t initial_promo_size = MIN2(eden_capacity, old_capacity);\n-  _size_policy =\n-    new PSAdaptiveSizePolicy(eden_capacity,\n-                             initial_promo_size,\n-                             young_gen()->to_space()->capacity_in_bytes(),\n-                             SpaceAlignment,\n-                             max_gc_pause_sec,\n-                             GCTimeRatio\n-                             );\n+  _size_policy = new PSAdaptiveSizePolicy(SpaceAlignment,\n+                                          max_gc_pause_sec,\n+                                          GCTimeRatio);\n@@ -119,2 +112,1 @@\n-  _gc_policy_counters =\n-    new PSGCAdaptivePolicyCounters(\"ParScav:MSC\", 2, 2, _size_policy);\n+  _gc_policy_counters = new GCPolicyCounters(\"ParScav:MSC\", 2, 2);\n@@ -193,0 +185,15 @@\n+void ParallelScavengeHeap::gc_epilogue(bool full) {\n+  if (_is_heap_almost_full) {\n+    \/\/ Reset emergency state if eden is empty after a young\/full gc\n+    if (_young_gen->eden_space()->is_empty()) {\n+      log_debug(gc)(\"Leaving memory constrained state; back to normal\");\n+      _is_heap_almost_full = false;\n+    }\n+  } else {\n+    if (full && !_young_gen->eden_space()->is_empty()) {\n+      log_debug(gc)(\"Non-empty young-gen after full-gc; in memory constrained state\");\n+      _is_heap_almost_full = true;\n+    }\n+  }\n+}\n+\n@@ -275,7 +282,6 @@\n-\n-  \/\/ In general gc_overhead_limit_was_exceeded should be false so\n-  \/\/ set it so here and reset it to true only if the gc time\n-  \/\/ limit is being exceeded as checked below.\n-  *gc_overhead_limit_was_exceeded = false;\n-\n-  HeapWord* result = young_gen()->allocate(size);\n+  {\n+    HeapWord* result = young_gen()->allocate(size);\n+    if (result != nullptr) {\n+      return result;\n+    }\n+  }\n@@ -286,1 +292,1 @@\n-  while (result == nullptr) {\n+  while (true) {\n@@ -302,1 +308,1 @@\n-      result = young_gen()->allocate(size);\n+      HeapWord* result = young_gen()->allocate(size);\n@@ -308,2 +314,2 @@\n-      if (!is_tlab) {\n-        result = mem_allocate_old_gen(size);\n+      if (!is_tlab && !should_alloc_in_eden(size)) {\n+        result = old_gen()->cas_allocate_noexpand(size);\n@@ -316,1 +322,0 @@\n-    assert(result == nullptr, \"inv\");\n@@ -327,24 +332,0 @@\n-        \/\/ Exit the loop if the gc time limit has been exceeded.\n-        \/\/ The allocation must have failed above (\"result\" guarding\n-        \/\/ this path is null) and the most recent collection has exceeded the\n-        \/\/ gc overhead limit (although enough may have been collected to\n-        \/\/ satisfy the allocation).  Exit the loop so that an out-of-memory\n-        \/\/ will be thrown (return a null ignoring the contents of\n-        \/\/ op.result()),\n-        \/\/ but clear gc_overhead_limit_exceeded so that the next collection\n-        \/\/ starts with a clean slate (i.e., forgets about previous overhead\n-        \/\/ excesses).  Fill op.result() with a filler object so that the\n-        \/\/ heap remains parsable.\n-        const bool limit_exceeded = size_policy()->gc_overhead_limit_exceeded();\n-        const bool softrefs_clear = soft_ref_policy()->all_soft_refs_clear();\n-\n-        if (limit_exceeded && softrefs_clear) {\n-          *gc_overhead_limit_was_exceeded = true;\n-          size_policy()->set_gc_overhead_limit_exceeded(false);\n-          log_trace(gc)(\"ParallelScavengeHeap::mem_allocate: return null because gc_overhead_limit_exceeded is set\");\n-          if (op.result() != nullptr) {\n-            CollectedHeap::fill_with_object(op.result(), size);\n-          }\n-          return nullptr;\n-        }\n-\n@@ -353,0 +334,4 @@\n+      \/\/ Was the gc-overhead reached inside the safepoint? If so, this mutator should return null as well for global consistency.\n+      if (_gc_overhead_counter >= GCOverheadLimitThreshold) {\n+        return nullptr;\n+      }\n@@ -355,2 +340,0 @@\n-    \/\/ The policy object will prevent us from looping forever. If the\n-    \/\/ time spent in gc crosses a threshold, we will bail out.\n@@ -358,1 +341,1 @@\n-    if ((result == nullptr) && (QueuedAllocationWarningCount > 0) &&\n+    if ((QueuedAllocationWarningCount > 0) &&\n@@ -364,2 +347,0 @@\n-\n-  return result;\n@@ -368,7 +349,2 @@\n-HeapWord* ParallelScavengeHeap::allocate_old_gen_and_record(size_t size) {\n-  assert_locked_or_safepoint(Heap_lock);\n-  HeapWord* res = old_gen()->allocate(size);\n-  if (res != nullptr) {\n-    _size_policy->tenured_allocation(size * HeapWordSize);\n-  }\n-  return res;\n+void ParallelScavengeHeap::do_full_collection(bool clear_all_soft_refs) {\n+  PSParallelCompact::invoke(clear_all_soft_refs);\n@@ -377,7 +353,2 @@\n-HeapWord* ParallelScavengeHeap::mem_allocate_old_gen(size_t size) {\n-  if (!should_alloc_in_eden(size)) {\n-    \/\/ Size is too big for eden.\n-    return allocate_old_gen_and_record(size);\n-  }\n-\n-  return nullptr;\n+static bool check_gc_heap_free_limit(size_t free_bytes, size_t capacity_bytes) {\n+  return (free_bytes * 100 \/ capacity_bytes) < GCHeapFreeLimit;\n@@ -386,2 +357,19 @@\n-void ParallelScavengeHeap::do_full_collection(bool clear_all_soft_refs) {\n-  PSParallelCompact::invoke(clear_all_soft_refs);\n+bool ParallelScavengeHeap::check_gc_overhead_limit() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+\n+  if (UseGCOverheadLimit) {\n+    \/\/ The goal here is to return null prematurely so that apps can exit\n+    \/\/ gracefully when GC takes the most time.\n+    bool little_mutator_time = _size_policy->mutator_time_percent() * 100 < (100 - GCTimeLimit);\n+    bool little_free_space = check_gc_heap_free_limit(_young_gen->free_in_bytes(), _young_gen->capacity_in_bytes())\n+                          && check_gc_heap_free_limit(  _old_gen->free_in_bytes(),   _old_gen->capacity_in_bytes());\n+    if (little_mutator_time && little_free_space) {\n+      _gc_overhead_counter++;\n+      if (_gc_overhead_counter >= GCOverheadLimitThreshold) {\n+        return true;\n+      }\n+    } else {\n+      _gc_overhead_counter = 0;\n+    }\n+  }\n+  return false;\n@@ -391,1 +379,3 @@\n-  HeapWord* result = nullptr;\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+  \/\/ We just finished a young\/full gc, try everything to satisfy this allocation request.\n+  HeapWord* result = young_gen()->expand_and_allocate(size);\n@@ -393,1 +383,0 @@\n-  result = young_gen()->allocate(size);\n@@ -397,0 +386,1 @@\n+\n@@ -405,3 +395,3 @@\n-  \/\/ If young-gen can handle this allocation, attempt young-gc firstly.\n-  bool should_run_young_gc = is_tlab || should_alloc_in_eden(size);\n-  collect_at_safepoint(!should_run_young_gc);\n+  if (!_is_heap_almost_full) {\n+    \/\/ If young-gen can handle this allocation, attempt young-gc firstly, as young-gc is usually cheaper.\n+    bool should_run_young_gc = is_tlab || should_alloc_in_eden(size);\n@@ -409,3 +399,9 @@\n-  result = expand_heap_and_allocate(size, is_tlab);\n-  if (result != nullptr) {\n-    return result;\n+    collect_at_safepoint(!should_run_young_gc);\n+\n+    \/\/ If gc-overhead is reached, we will skip allocation.\n+    if (!check_gc_overhead_limit()) {\n+      result = expand_heap_and_allocate(size, is_tlab);\n+      if (result != nullptr) {\n+        return result;\n+      }\n+    }\n@@ -431,3 +427,3 @@\n-  result = expand_heap_and_allocate(size, is_tlab);\n-  if (result != nullptr) {\n-    return result;\n+  if (check_gc_overhead_limit()) {\n+    log_info(gc)(\"GCOverheadLimitThreshold %zu reached.\", GCOverheadLimitThreshold);\n+    return nullptr;\n@@ -436,6 +432,1 @@\n-  \/\/ What else?  We might try synchronous finalization later.  If the total\n-  \/\/ space available is large enough for the allocation, then a more\n-  \/\/ complete compaction phase than we've tried so far might be\n-  \/\/ appropriate.\n-  return nullptr;\n-}\n+  result = expand_heap_and_allocate(size, is_tlab);\n@@ -443,0 +434,2 @@\n+  return result;\n+}\n@@ -669,1 +662,0 @@\n-  AdaptiveSizePolicyOutput::print();\n@@ -766,4 +758,80 @@\n-void ParallelScavengeHeap::resize_young_gen(size_t eden_size,\n-                                            size_t survivor_size) {\n-  \/\/ Delegate the resize to the generation.\n-  _young_gen->resize(eden_size, survivor_size);\n+static size_t calculate_free_from_free_ratio_flag(size_t live, uintx free_percent) {\n+  assert(free_percent != 100, \"precondition\");\n+  \/\/ We want to calculate how much free memory there can be based on the\n+  \/\/ live size.\n+  \/\/   percent * (free + live) = free\n+  \/\/ =>\n+  \/\/   free = (live * percent) \/ (1 - percent)\n+\n+  const double percent = free_percent \/ 100.0;\n+  return live * percent \/ (1.0 - percent);\n+}\n+\n+size_t ParallelScavengeHeap::calculate_desired_old_gen_capacity(size_t old_gen_live_size) {\n+  \/\/ If min free percent is 100%, the old-gen should always be in its max capacity\n+  if (MinHeapFreeRatio == 100) {\n+    return _old_gen->max_gen_size();\n+  }\n+\n+  \/\/ Using recorded data to calculate the new capacity of old-gen to avoid\n+  \/\/ excessive expansion but also keep footprint low\n+\n+  size_t promoted_estimate = _size_policy->padded_average_promoted_in_bytes();\n+  \/\/ Should have at least this free room for the next young-gc promotion.\n+  size_t free_size = promoted_estimate;\n+\n+  size_t largest_live_size = MAX2((size_t)_size_policy->peak_old_gen_used_estimate(), old_gen_live_size);\n+  free_size += largest_live_size - old_gen_live_size;\n+\n+  \/\/ Respect free percent\n+  if (MinHeapFreeRatio != 0) {\n+    size_t min_free = calculate_free_from_free_ratio_flag(old_gen_live_size, MinHeapFreeRatio);\n+    free_size = MAX2(free_size, min_free);\n+  }\n+\n+  if (MaxHeapFreeRatio != 100) {\n+    size_t max_free = calculate_free_from_free_ratio_flag(old_gen_live_size, MaxHeapFreeRatio);\n+    free_size = MIN2(max_free, free_size);\n+  }\n+\n+  return old_gen_live_size + free_size;\n+}\n+\n+void ParallelScavengeHeap::resize_old_gen_after_full_gc() {\n+  size_t current_capacity = _old_gen->capacity_in_bytes();\n+  size_t desired_capacity = calculate_desired_old_gen_capacity(old_gen()->used_in_bytes());\n+\n+  \/\/ If MinHeapFreeRatio is at its default value; shrink cautiously. Otherwise, users expect prompt shrinking.\n+  if (FLAG_IS_DEFAULT(MinHeapFreeRatio)) {\n+    if (desired_capacity < current_capacity) {\n+      \/\/ Shrinking\n+      if (total_full_collections() < AdaptiveSizePolicyReadyThreshold) {\n+        \/\/ No enough data for shrinking\n+        return;\n+      }\n+    }\n+  }\n+\n+  _old_gen->resize(desired_capacity);\n+}\n+\n+void ParallelScavengeHeap::resize_after_young_gc(bool is_survivor_overflowing) {\n+  _young_gen->resize_after_young_gc(is_survivor_overflowing);\n+\n+  \/\/ Consider if should shrink old-gen\n+  if (!is_survivor_overflowing) {\n+    \/\/ Upper bound for a single step shrink\n+    size_t max_shrink_bytes = SpaceAlignment;\n+    size_t shrink_bytes = _size_policy->compute_old_gen_shrink_bytes(old_gen()->free_in_bytes(), max_shrink_bytes);\n+    if (shrink_bytes != 0) {\n+      if (MinHeapFreeRatio != 0) {\n+        size_t new_capacity = old_gen()->capacity_in_bytes() - shrink_bytes;\n+        size_t new_free_size = old_gen()->free_in_bytes() - shrink_bytes;\n+        if ((double)new_free_size \/ new_capacity * 100 < MinHeapFreeRatio) {\n+          \/\/ Would violate MinHeapFreeRatio\n+          return;\n+        }\n+      }\n+      old_gen()->shrink(shrink_bytes);\n+    }\n+  }\n@@ -772,3 +840,8 @@\n-void ParallelScavengeHeap::resize_old_gen(size_t desired_free_space) {\n-  \/\/ Delegate the resize to the generation.\n-  _old_gen->resize(desired_free_space);\n+void ParallelScavengeHeap::resize_after_full_gc() {\n+  resize_old_gen_after_full_gc();\n+  \/\/ We don't resize young-gen after full-gc because:\n+  \/\/ 1. eden-size directly affects young-gc frequency (GCTimeRatio), and we\n+  \/\/ don't have enough info to determine its desired size.\n+  \/\/ 2. eden can contain live objs after a full-gc, which is unsafe for\n+  \/\/ resizing. We will perform expansion on allocation if needed, in\n+  \/\/ satisfy_failed_allocation().\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":169,"deletions":96,"binary":false,"changes":265,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"gc\/parallel\/psGCAdaptivePolicyCounters.hpp\"\n+#include \"gc\/parallel\/psAdaptiveSizePolicy.hpp\"\n@@ -63,5 +63,5 @@\n-\/\/ +---------------+--------+-----------------+--------+--------+--------+\n-\/\/ |      old      |        |       eden      |  from  |   to   |        |\n-\/\/ |               |        |                 |  (to)  | (from) |        |\n-\/\/ +---------------+--------+-----------------+--------+--------+--------+\n-\/\/ |<- committed ->|        |<-          committed            ->|\n+\/\/ +---------------+--------+--------+--------+------------------+-------+\n+\/\/ |      old      |        |  from  |   to   |        eden      |       |\n+\/\/ |               |        |  (to)  | (from) |                  |       |\n+\/\/ +---------------+--------+--------+--------+------------------+-------+\n+\/\/ |<- committed ->|        |<-          committed             ->|\n@@ -77,1 +77,1 @@\n-  static PSGCAdaptivePolicyCounters* _gc_policy_counters;\n+  static GCPolicyCounters*           _gc_policy_counters;\n@@ -88,0 +88,4 @@\n+  uint _gc_overhead_counter;\n+\n+  bool _is_heap_almost_full;\n+\n@@ -93,3 +97,0 @@\n-  \/\/ Allocate in oldgen and record the allocation with the size_policy.\n-  HeapWord* allocate_old_gen_and_record(size_t word_size);\n-\n@@ -104,2 +105,0 @@\n-  HeapWord* mem_allocate_old_gen(size_t size);\n-\n@@ -114,0 +113,6 @@\n+  bool check_gc_overhead_limit();\n+\n+  size_t calculate_desired_old_gen_capacity(size_t old_gen_live_size);\n+\n+  void resize_old_gen_after_full_gc();\n+\n@@ -122,1 +127,3 @@\n-    _workers(\"GC Thread\", ParallelGCThreads) { }\n+    _workers(\"GC Thread\", ParallelGCThreads),\n+    _gc_overhead_counter(0),\n+    _is_heap_almost_full(false) {}\n@@ -132,0 +139,3 @@\n+  \/\/ Invoked at gc-pause-end\n+  void gc_epilogue(bool full);\n+\n@@ -140,1 +150,1 @@\n-  static PSGCAdaptivePolicyCounters* gc_policy_counters() { return _gc_policy_counters; }\n+  static GCPolicyCounters* gc_policy_counters() { return _gc_policy_counters; }\n@@ -229,7 +239,2 @@\n-  \/\/ Resize the young generation.  The reserved space for the\n-  \/\/ generation may be expanded in preparation for the resize.\n-  void resize_young_gen(size_t eden_size, size_t survivor_size);\n-\n-  \/\/ Resize the old generation.  The reserved space for the\n-  \/\/ generation may be expanded in preparation for the resize.\n-  void resize_old_gen(size_t desired_free_space);\n+  void resize_after_young_gc(bool is_survivor_overflowing);\n+  void resize_after_full_gc();\n@@ -253,29 +258,0 @@\n-\/\/ Class that can be used to print information about the\n-\/\/ adaptive size policy at intervals specified by\n-\/\/ AdaptiveSizePolicyOutputInterval.  Only print information\n-\/\/ if an adaptive size policy is in use.\n-class AdaptiveSizePolicyOutput : AllStatic {\n-  static bool enabled() {\n-    return UseParallelGC &&\n-           UseAdaptiveSizePolicy &&\n-           log_is_enabled(Debug, gc, ergo);\n-  }\n- public:\n-  static void print() {\n-    if (enabled()) {\n-      ParallelScavengeHeap::heap()->size_policy()->print();\n-    }\n-  }\n-\n-  static void print(AdaptiveSizePolicy* size_policy, uint count) {\n-    bool do_print =\n-        enabled() &&\n-        (AdaptiveSizePolicyOutputInterval > 0) &&\n-        (count % AdaptiveSizePolicyOutputInterval) == 0;\n-\n-    if (do_print) {\n-      size_policy->print();\n-    }\n-  }\n-};\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.hpp","additions":26,"deletions":50,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"gc\/parallel\/psGCAdaptivePolicyCounters.hpp\"\n@@ -29,0 +28,1 @@\n+#include \"gc\/shared\/gcArguments.hpp\"\n@@ -38,4 +38,1 @@\n-PSAdaptiveSizePolicy::PSAdaptiveSizePolicy(size_t init_eden_size,\n-                                           size_t init_promo_size,\n-                                           size_t init_survivor_size,\n-                                           size_t space_alignment,\n+PSAdaptiveSizePolicy::PSAdaptiveSizePolicy(size_t space_alignment,\n@@ -44,4 +41,1 @@\n-     AdaptiveSizePolicy(init_eden_size,\n-                        init_promo_size,\n-                        init_survivor_size,\n-                        gc_pause_goal_sec,\n+     AdaptiveSizePolicy(gc_pause_goal_sec,\n@@ -49,2 +43,0 @@\n-     _avg_major_pause(new AdaptivePaddedAverage(AdaptiveTimeWeight, PausePadding)),\n-     _avg_base_footprint(new AdaptiveWeightedAverage(AdaptiveSizePolicyWeight)),\n@@ -52,3 +44,0 @@\n-     _major_pause_old_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-     _major_pause_young_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-     _latest_major_mutator_interval_seconds(0),\n@@ -56,41 +45,1 @@\n-     _live_at_last_full_gc(init_promo_size),\n-     _change_old_gen_for_min_pauses(0),\n-     _change_young_gen_for_maj_pauses(0),\n-     _young_gen_size_increment_supplement(YoungGenerationSizeSupplement),\n-     _old_gen_size_increment_supplement(TenuredGenerationSizeSupplement)\n-{\n-  \/\/ Start the timers\n-  _major_timer.start();\n-}\n-\n-size_t PSAdaptiveSizePolicy::calculate_free_based_on_live(size_t live, uintx ratio_as_percentage) {\n-  \/\/ We want to calculate how much free memory there can be based on the\n-  \/\/ amount of live data currently in the old gen. Using the formula:\n-  \/\/ ratio * (free + live) = free\n-  \/\/ Some equation solving later we get:\n-  \/\/ free = (live * ratio) \/ (1 - ratio)\n-\n-  const double ratio = ratio_as_percentage \/ 100.0;\n-  const double ratio_inverse = 1.0 - ratio;\n-  const double tmp = live * ratio;\n-  size_t free = (size_t)(tmp \/ ratio_inverse);\n-\n-  return free;\n-}\n-\n-size_t PSAdaptiveSizePolicy::calculated_old_free_size_in_bytes() const {\n-  size_t free_size = (size_t)(_promo_size + avg_promoted()->padded_average());\n-  size_t live = ParallelScavengeHeap::heap()->old_gen()->used_in_bytes();\n-\n-  if (MinHeapFreeRatio != 0) {\n-    size_t min_free = calculate_free_based_on_live(live, MinHeapFreeRatio);\n-    free_size = MAX2(free_size, min_free);\n-  }\n-\n-  if (MaxHeapFreeRatio != 100) {\n-    size_t max_free = calculate_free_based_on_live(live, MaxHeapFreeRatio);\n-    free_size = MIN2(max_free, free_size);\n-  }\n-\n-  return free_size;\n-}\n+     _young_gen_size_increment_supplement(YoungGenerationSizeSupplement) {}\n@@ -99,4 +48,0 @@\n-  \/\/ Update the interval time\n-  _major_timer.stop();\n-  \/\/ Save most recent collection time\n-  _latest_major_mutator_interval_seconds = _major_timer.seconds();\n@@ -105,0 +50,1 @@\n+  record_gc_pause_start_instant();\n@@ -107,9 +53,1 @@\n-void PSAdaptiveSizePolicy::update_minor_pause_old_estimator(\n-    double minor_pause_in_ms) {\n-  double promo_size_in_mbytes = ((double)_promo_size)\/((double)M);\n-  _minor_pause_old_estimator->update(promo_size_in_mbytes,\n-    minor_pause_in_ms);\n-}\n-\n-void PSAdaptiveSizePolicy::major_collection_end(size_t amount_live,\n-  GCCause::Cause gc_cause) {\n+void PSAdaptiveSizePolicy::major_collection_end() {\n@@ -119,42 +57,1 @@\n-  if (should_update_promo_stats(gc_cause)) {\n-    double major_pause_in_seconds = _major_timer.seconds();\n-    double major_pause_in_ms = major_pause_in_seconds * MILLIUNITS;\n-\n-    \/\/ Sample for performance counter\n-    _avg_major_pause->sample(major_pause_in_seconds);\n-\n-    \/\/ Cost of collection (unit-less)\n-    double collection_cost = 0.0;\n-    if ((_latest_major_mutator_interval_seconds > 0.0) &&\n-        (major_pause_in_seconds > 0.0)) {\n-      double interval_in_seconds =\n-        _latest_major_mutator_interval_seconds + major_pause_in_seconds;\n-      collection_cost =\n-        major_pause_in_seconds \/ interval_in_seconds;\n-      avg_major_gc_cost()->sample(collection_cost);\n-\n-      \/\/ Sample for performance counter\n-      _avg_major_interval->sample(interval_in_seconds);\n-    }\n-\n-    \/\/ Calculate variables used to estimate pause time vs. gen sizes\n-    double eden_size_in_mbytes = ((double)_eden_size)\/((double)M);\n-    double promo_size_in_mbytes = ((double)_promo_size)\/((double)M);\n-    _major_pause_old_estimator->update(promo_size_in_mbytes,\n-      major_pause_in_ms);\n-    _major_pause_young_estimator->update(eden_size_in_mbytes,\n-      major_pause_in_ms);\n-\n-    log_trace(gc, ergo)(\"psAdaptiveSizePolicy::major_collection_end: major gc cost: %f  average: %f\",\n-                        collection_cost,avg_major_gc_cost()->average());\n-    log_trace(gc, ergo)(\"  major pause: %f major period %f\",\n-                        major_pause_in_ms, _latest_major_mutator_interval_seconds * MILLIUNITS);\n-\n-    \/\/ Calculate variable used to estimate collection cost vs. gen sizes\n-    assert(collection_cost >= 0.0, \"Expected to be non-negative\");\n-    _major_collection_estimator->update(promo_size_in_mbytes,\n-        collection_cost);\n-  }\n-\n-  \/\/ Update the amount live at the end of a full GC\n-  _live_at_last_full_gc = amount_live;\n+  double major_pause_in_seconds = _major_timer.seconds();\n@@ -162,4 +59,2 @@\n-  \/\/ Interval times use this timer to measure the interval that\n-  \/\/ the mutator runs.  Reset after the GC pause has been measured.\n-  _major_timer.reset();\n-  _major_timer.start();\n+  record_gc_duration(major_pause_in_seconds);\n+  _trimmed_major_gc_time_seconds.add(major_pause_in_seconds);\n@@ -168,29 +63,10 @@\n-void PSAdaptiveSizePolicy::clear_generation_free_space_flags() {\n-\n-  AdaptiveSizePolicy::clear_generation_free_space_flags();\n-\n-  set_change_old_gen_for_min_pauses(0);\n-\n-  set_change_young_gen_for_maj_pauses(0);\n-}\n-\n-\/\/ If this is not a full GC, only test and modify the young generation.\n-\n-void PSAdaptiveSizePolicy::compute_generations_free_space(\n-                                           size_t young_live,\n-                                           size_t eden_live,\n-                                           size_t old_live,\n-                                           size_t cur_eden,\n-                                           size_t max_old_gen_size,\n-                                           size_t max_eden_size,\n-                                           bool   is_full_gc) {\n-  compute_eden_space_size(young_live,\n-                          eden_live,\n-                          cur_eden,\n-                          max_eden_size,\n-                          is_full_gc);\n-\n-  compute_old_gen_free_space(old_live,\n-                             cur_eden,\n-                             max_old_gen_size,\n-                             is_full_gc);\n+void PSAdaptiveSizePolicy::print_stats(bool is_survivor_overflowing) {\n+  log_debug(gc, ergo)(\"Adaptive: throughput: %.3f, pause: %.1f ms, \"\n+                      \"gc-distance: %.3f (%.3f) s, \"\n+                      \"promoted: %.1f %s (%.1f %s), promotion-rate: %.1f M\/s (%.1f M\/s), overflowing: %s\",\n+    mutator_time_percent(),\n+    minor_gc_time_estimate() * 1000.0,\n+    _gc_distance_seconds_seq.davg(), _gc_distance_seconds_seq.last(),\n+    PROPERFMTARGS(promoted_bytes_estimate()), PROPERFMTARGS(_promoted_bytes.last()),\n+    _promotion_rate_bytes_per_sec.davg()\/M, _promotion_rate_bytes_per_sec.last()\/M,\n+    is_survivor_overflowing ? \"true\" : \"false\");\n@@ -199,110 +75,15 @@\n-void PSAdaptiveSizePolicy::compute_eden_space_size(\n-                                           size_t young_live,\n-                                           size_t eden_live,\n-                                           size_t cur_eden,\n-                                           size_t max_eden_size,\n-                                           bool   is_full_gc) {\n-\n-  \/\/ Update statistics\n-  avg_young_live()->sample(young_live);\n-  avg_eden_live()->sample(eden_live);\n-\n-  \/\/ This code used to return if the policy was not ready , i.e.,\n-  \/\/ policy_is_ready() returning false.  The intent was that\n-  \/\/ decisions below needed major collection times and so could\n-  \/\/ not be made before two major collections.  A consequence was\n-  \/\/ adjustments to the young generation were not done until after\n-  \/\/ two major collections even if the minor collections times\n-  \/\/ exceeded the requested goals.  Now let the young generation\n-  \/\/ adjust for the minor collection times.  Major collection times\n-  \/\/ will be zero for the first collection and will naturally be\n-  \/\/ ignored.  Tenured generation adjustments are only made at the\n-  \/\/ full collections so until the second major collection has\n-  \/\/ been reached, no tenured generation adjustments will be made.\n-\n-  \/\/ Until we know better, desired promotion size uses the last calculation\n-  size_t desired_promo_size = _promo_size;\n-\n-  \/\/ Start eden at the current value.  The desired value that is stored\n-  \/\/ in _eden_size is not bounded by constraints of the heap and can\n-  \/\/ run away.\n-  \/\/\n-  \/\/ As expected setting desired_eden_size to the current\n-  \/\/ value of desired_eden_size as a starting point\n-  \/\/ caused desired_eden_size to grow way too large and caused\n-  \/\/ an overflow down stream.  It may have improved performance in\n-  \/\/ some case but is dangerous.\n-  size_t desired_eden_size = cur_eden;\n-\n-  \/\/ Cache some values. There's a bit of work getting these, so\n-  \/\/ we might save a little time.\n-  const double major_cost = major_gc_cost();\n-  const double minor_cost = minor_gc_cost();\n-\n-  \/\/ This method sets the desired eden size.  That plus the\n-  \/\/ desired survivor space sizes sets the desired young generation\n-  \/\/ size.  This methods does not know what the desired survivor\n-  \/\/ size is but expects that other policy will attempt to make\n-  \/\/ the survivor sizes compatible with the live data in the\n-  \/\/ young generation.  This limit is an estimate of the space left\n-  \/\/ in the young generation after the survivor spaces have been\n-  \/\/ subtracted out.\n-  size_t eden_limit = max_eden_size;\n-\n-  const double gc_cost_limit = GCTimeLimit \/ 100.0;\n-\n-  \/\/ Which way should we go?\n-  \/\/ if pause requirement is not met\n-  \/\/   adjust size of any generation with average paus exceeding\n-  \/\/   the pause limit.  Adjust one pause at a time (the larger)\n-  \/\/   and only make adjustments for the major pause at full collections.\n-  \/\/ else if throughput requirement not met\n-  \/\/   adjust the size of the generation with larger gc time.  Only\n-  \/\/   adjust one generation at a time.\n-  \/\/ else\n-  \/\/   adjust down the total heap size.  Adjust down the larger of the\n-  \/\/   generations.\n-\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the necessary alignment is probably not worth\n-  \/\/ attempting.\n-\n-\n-  if ((_avg_minor_pause->padded_average() > gc_pause_goal_sec()) ||\n-      (_avg_major_pause->padded_average() > gc_pause_goal_sec())) {\n-    \/\/\n-    \/\/ Check pauses\n-    \/\/\n-    \/\/ Make changes only to affect one of the pauses (the larger)\n-    \/\/ at a time.\n-    adjust_eden_for_pause_time(&desired_eden_size);\n-\n-  } else if (_avg_minor_pause->padded_average() > gc_pause_goal_sec()) {\n-    \/\/ Adjust only for the minor pause time goal\n-    adjust_eden_for_minor_pause_time(&desired_eden_size);\n-\n-  } else if(adjusted_mutator_cost() < _throughput_goal) {\n-    \/\/ This branch used to require that (mutator_cost() > 0.0 in 1.4.2.\n-    \/\/ This sometimes resulted in skipping to the minimize footprint\n-    \/\/ code.  Change this to try and reduce GC time if mutator time is\n-    \/\/ negative for whatever reason.  Or for future consideration,\n-    \/\/ bail out of the code if mutator time is negative.\n-    \/\/\n-    \/\/ Throughput\n-    \/\/\n-    assert(major_cost >= 0.0, \"major cost is < 0.0\");\n-    assert(minor_cost >= 0.0, \"minor cost is < 0.0\");\n-    \/\/ Try to reduce the GC times.\n-    adjust_eden_for_throughput(is_full_gc, &desired_eden_size);\n-\n-  } else {\n-\n-    \/\/ Be conservative about reducing the footprint.\n-    \/\/   Do a minimum number of major collections first.\n-    \/\/   Have reasonable averages for major and minor collections costs.\n-    if (UseAdaptiveSizePolicyFootprintGoal &&\n-        young_gen_policy_is_ready() &&\n-        avg_major_gc_cost()->average() >= 0.0 &&\n-        avg_minor_gc_cost()->average() >= 0.0) {\n-      size_t desired_sum = desired_eden_size + desired_promo_size;\n-      desired_eden_size = adjust_eden_for_footprint(desired_eden_size, desired_sum);\n+size_t PSAdaptiveSizePolicy::compute_desired_eden_size(bool is_survivor_overflowing, size_t cur_eden) {\n+  \/\/ Guard against divide-by-zero; 0.001ms\n+  double gc_distance = MAX2(_gc_distance_seconds_seq.last(), 0.000001);\n+  double min_gc_distance = MinGCDistanceSecond;\n+\n+  if (mutator_time_percent() < _throughput_goal) {\n+    size_t new_eden;\n+    const double expected_gc_distance = _trimmed_minor_gc_time_seconds.last() * GCTimeRatio;\n+    if (gc_distance >= expected_gc_distance) {\n+      \/\/ The lastest sample already satisfies throughput goal; keep the current size\n+      new_eden = cur_eden;\n+    } else {\n+      \/\/ Using the latest sample to limit the growth in order to avoid overshoot\n+      new_eden = MIN2((expected_gc_distance \/ gc_distance) * cur_eden,\n+                      (double)increase_eden(cur_eden));\n@@ -310,0 +91,3 @@\n+    log_debug(gc, ergo)(\"Adaptive: throughput (actual vs goal): %.3f vs %.3f ; eden delta: + %zu K\",\n+      mutator_time_percent(), _throughput_goal, (new_eden - cur_eden)\/K);\n+    return new_eden;\n@@ -312,20 +96,4 @@\n-  \/\/ Note we make the same tests as in the code block below;  the code\n-  \/\/ seems a little easier to read with the printing in another block.\n-  if (desired_eden_size > eden_limit) {\n-    log_debug(gc, ergo)(\n-          \"PSAdaptiveSizePolicy::compute_eden_space_size limits:\"\n-          \" desired_eden_size: %zu\"\n-          \" old_eden_size: %zu\"\n-          \" eden_limit: %zu\"\n-          \" cur_eden: %zu\"\n-          \" max_eden_size: %zu\"\n-          \" avg_young_live: %zu\",\n-          desired_eden_size, _eden_size, eden_limit, cur_eden,\n-          max_eden_size, (size_t)avg_young_live()->average());\n-  }\n-  if (gc_cost() > gc_cost_limit) {\n-    log_debug(gc, ergo)(\n-          \"PSAdaptiveSizePolicy::compute_eden_space_size: gc time limit\"\n-          \" gc_cost: %f \"\n-          \" GCTimeLimit: %u\",\n-          gc_cost(), GCTimeLimit);\n+  if (minor_gc_time_estimate() > gc_pause_goal_sec()) {\n+    log_debug(gc, ergo)(\"Adaptive: pause (ms) (actual vs goal): %.1f vs %.1f\",\n+      minor_gc_time_estimate() * 1000.0, gc_pause_goal_sec() * 1000.0);\n+    return decrease_eden_for_minor_pause_time(cur_eden);\n@@ -334,14 +102,6 @@\n-  \/\/ Align everything and make a final limit check\n-  desired_eden_size  = align_up(desired_eden_size, _space_alignment);\n-  desired_eden_size  = MAX2(desired_eden_size, _space_alignment);\n-\n-  eden_limit  = align_down(eden_limit, _space_alignment);\n-\n-  \/\/ And one last limit check, now that we've aligned things.\n-  if (desired_eden_size > eden_limit) {\n-    \/\/ If the policy says to get a larger eden but\n-    \/\/ is hitting the limit, don't decrease eden.\n-    \/\/ This can lead to a general drifting down of the\n-    \/\/ eden size.  Let the tenuring calculation push more\n-    \/\/ into the old gen.\n-    desired_eden_size = MAX2(eden_limit, cur_eden);\n+  if (gc_distance < min_gc_distance) {\n+    size_t new_eden = MIN2((min_gc_distance \/ gc_distance) * cur_eden,\n+                           (double)increase_eden(cur_eden));\n+    log_debug(gc, ergo)(\"Adaptive: gc-distance (predicted vs goal): %.3f vs %.3f\",\n+      gc_distance, min_gc_distance);\n+    return new_eden;\n@@ -350,119 +110,19 @@\n-  log_debug(gc, ergo)(\"PSAdaptiveSizePolicy::compute_eden_space_size: costs minor_time: %f major_cost: %f mutator_cost: %f throughput_goal: %f\",\n-             minor_gc_cost(), major_gc_cost(), mutator_cost(), _throughput_goal);\n-\n-  log_trace(gc, ergo)(\"Minor_pause: %f major_pause: %f minor_interval: %f major_interval: %fpause_goal: %f\",\n-                      _avg_minor_pause->padded_average(),\n-                      _avg_major_pause->padded_average(),\n-                      _avg_minor_interval->average(),\n-                      _avg_major_interval->average(),\n-                      gc_pause_goal_sec());\n-\n-  log_debug(gc, ergo)(\"Live_space: %zu free_space: %zu\",\n-                      live_space(), free_space());\n-\n-  log_trace(gc, ergo)(\"avg_young_live: %zu avg_old_live: %zu\",\n-                      (size_t)avg_young_live()->average(),\n-                      (size_t)avg_old_live()->average());\n-\n-  log_debug(gc, ergo)(\"Old eden_size: %zu desired_eden_size: %zu\",\n-                      _eden_size, desired_eden_size);\n-\n-  set_eden_size(desired_eden_size);\n-}\n-\n-void PSAdaptiveSizePolicy::compute_old_gen_free_space(\n-                                           size_t old_live,\n-                                           size_t cur_eden,\n-                                           size_t max_old_gen_size,\n-                                           bool   is_full_gc) {\n-\n-  \/\/ Update statistics\n-  \/\/ Time statistics are updated as we go, update footprint stats here\n-  if (is_full_gc) {\n-    \/\/ old_live is only accurate after a full gc\n-    avg_old_live()->sample(old_live);\n-  }\n-\n-  \/\/ This code used to return if the policy was not ready , i.e.,\n-  \/\/ policy_is_ready() returning false.  The intent was that\n-  \/\/ decisions below needed major collection times and so could\n-  \/\/ not be made before two major collections.  A consequence was\n-  \/\/ adjustments to the young generation were not done until after\n-  \/\/ two major collections even if the minor collections times\n-  \/\/ exceeded the requested goals.  Now let the young generation\n-  \/\/ adjust for the minor collection times.  Major collection times\n-  \/\/ will be zero for the first collection and will naturally be\n-  \/\/ ignored.  Tenured generation adjustments are only made at the\n-  \/\/ full collections so until the second major collection has\n-  \/\/ been reached, no tenured generation adjustments will be made.\n-\n-  \/\/ Until we know better, desired promotion size uses the last calculation\n-  size_t desired_promo_size = _promo_size;\n-\n-  \/\/ Start eden at the current value.  The desired value that is stored\n-  \/\/ in _eden_size is not bounded by constraints of the heap and can\n-  \/\/ run away.\n-  \/\/\n-  \/\/ As expected setting desired_eden_size to the current\n-  \/\/ value of desired_eden_size as a starting point\n-  \/\/ caused desired_eden_size to grow way too large and caused\n-  \/\/ an overflow down stream.  It may have improved performance in\n-  \/\/ some case but is dangerous.\n-  size_t desired_eden_size = cur_eden;\n-\n-  \/\/ Cache some values. There's a bit of work getting these, so\n-  \/\/ we might save a little time.\n-  const double major_cost = major_gc_cost();\n-  const double minor_cost = minor_gc_cost();\n-\n-  \/\/ Limits on our growth\n-  size_t promo_limit = (size_t)(max_old_gen_size - avg_old_live()->average());\n-\n-  \/\/ But don't force a promo size below the current promo size. Otherwise,\n-  \/\/ the promo size will shrink for no good reason.\n-  promo_limit = MAX2(promo_limit, _promo_size);\n-\n-  const double gc_cost_limit = GCTimeLimit\/100.0;\n-\n-  \/\/ Which way should we go?\n-  \/\/ if pause requirement is not met\n-  \/\/   adjust size of any generation with average paus exceeding\n-  \/\/   the pause limit.  Adjust one pause at a time (the larger)\n-  \/\/   and only make adjustments for the major pause at full collections.\n-  \/\/ else if throughput requirement not met\n-  \/\/   adjust the size of the generation with larger gc time.  Only\n-  \/\/   adjust one generation at a time.\n-  \/\/ else\n-  \/\/   adjust down the total heap size.  Adjust down the larger of the\n-  \/\/   generations.\n-\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the necessary alignment is probably not worth\n-  \/\/ attempting.\n-\n-  if ((_avg_minor_pause->padded_average() > gc_pause_goal_sec()) ||\n-      (_avg_major_pause->padded_average() > gc_pause_goal_sec())) {\n-    \/\/\n-    \/\/ Check pauses\n-    \/\/\n-    \/\/ Make changes only to affect one of the pauses (the larger)\n-    \/\/ at a time.\n-    if (is_full_gc) {\n-      set_decide_at_full_gc(decide_at_full_gc_true);\n-      adjust_promo_for_pause_time(&desired_promo_size);\n-    }\n-  } else if (adjusted_mutator_cost() < _throughput_goal) {\n-    \/\/ This branch used to require that (mutator_cost() > 0.0 in 1.4.2.\n-    \/\/ This sometimes resulted in skipping to the minimize footprint\n-    \/\/ code.  Change this to try and reduce GC time if mutator time is\n-    \/\/ negative for whatever reason.  Or for future consideration,\n-    \/\/ bail out of the code if mutator time is negative.\n-    \/\/\n-    \/\/ Throughput\n-    \/\/\n-    assert(major_cost >= 0.0, \"major cost is < 0.0\");\n-    assert(minor_cost >= 0.0, \"minor cost is < 0.0\");\n-    \/\/ Try to reduce the GC times.\n-    if (is_full_gc) {\n-      set_decide_at_full_gc(decide_at_full_gc_true);\n-      adjust_promo_for_throughput(is_full_gc, &desired_promo_size);\n+  \/\/ If no overflowing and promotion is small\n+  if (!is_survivor_overflowing && promoted_bytes_estimate() < 1*K) {\n+    size_t delta = MIN2(eden_increment(cur_eden) \/ AdaptiveSizeDecrementScaleFactor, cur_eden \/ 2);\n+    double delta_factor = (double) delta \/ cur_eden;\n+\n+    const double gc_time_lower_estimate = _trimmed_minor_gc_time_seconds.davg() - _trimmed_minor_gc_time_seconds.dsd();\n+    \/\/ Limit gc-frequency so that promoted rate is < 1M\/s\n+    \/\/ promoted_bytes_estimate() \/ (gc_distance + gc_time_lower_estimate) < 1M\/s\n+    \/\/ ==> promoted_bytes_estimate() \/ M - gc_time_lower_estimate < gc_distance\n+\n+    const double gc_distance_target = MAX3(minor_gc_time_conservative_estimate() * GCTimeRatio,\n+                                           promoted_bytes_estimate() \/ M - gc_time_lower_estimate,\n+                                           min_gc_distance);\n+    double predicted_gc_distance = gc_distance * (1 - delta_factor) - _gc_distance_seconds_seq.dsd();\n+\n+    if (predicted_gc_distance > gc_distance_target) {\n+      log_debug(gc, ergo)(\"Adaptive: shrinking gc-distance (predicted vs threshold): %.3f vs %.3f\",\n+        predicted_gc_distance, gc_distance_target);\n+      return cur_eden - delta;\n@@ -470,31 +130,0 @@\n-  } else {\n-\n-    \/\/ Be conservative about reducing the footprint.\n-    \/\/   Do a minimum number of major collections first.\n-    \/\/   Have reasonable averages for major and minor collections costs.\n-    if (UseAdaptiveSizePolicyFootprintGoal &&\n-        young_gen_policy_is_ready() &&\n-        avg_major_gc_cost()->average() >= 0.0 &&\n-        avg_minor_gc_cost()->average() >= 0.0) {\n-      if (is_full_gc) {\n-        set_decide_at_full_gc(decide_at_full_gc_true);\n-        size_t desired_sum = desired_eden_size + desired_promo_size;\n-        desired_promo_size = adjust_promo_for_footprint(desired_promo_size, desired_sum);\n-      }\n-    }\n-  }\n-\n-  \/\/ Note we make the same tests as in the code block below;  the code\n-  \/\/ seems a little easier to read with the printing in another block.\n-  if (desired_promo_size > promo_limit)  {\n-    \/\/ \"free_in_old_gen\" was the original value for used for promo_limit\n-    size_t free_in_old_gen = (size_t)(max_old_gen_size - avg_old_live()->average());\n-    log_debug(gc, ergo)(\n-          \"PSAdaptiveSizePolicy::compute_old_gen_free_space limits:\"\n-          \" desired_promo_size: %zu\"\n-          \" promo_limit: %zu\"\n-          \" free_in_old_gen: %zu\"\n-          \" max_old_gen_size: %zu\"\n-          \" avg_old_live: %zu\",\n-          desired_promo_size, promo_limit, free_in_old_gen,\n-          max_old_gen_size, (size_t) avg_old_live()->average());\n@@ -502,13 +131,0 @@\n-  if (gc_cost() > gc_cost_limit) {\n-    log_debug(gc, ergo)(\n-          \"PSAdaptiveSizePolicy::compute_old_gen_free_space: gc time limit\"\n-          \" gc_cost: %f \"\n-          \" GCTimeLimit: %u\",\n-          gc_cost(), GCTimeLimit);\n-  }\n-\n-  \/\/ Align everything and make a final limit check\n-  desired_promo_size = align_up(desired_promo_size, _space_alignment);\n-  desired_promo_size = MAX2(desired_promo_size, _space_alignment);\n-\n-  promo_limit = align_down(promo_limit, _space_alignment);\n@@ -516,26 +132,2 @@\n-  \/\/ And one last limit check, now that we've aligned things.\n-  desired_promo_size = MIN2(desired_promo_size, promo_limit);\n-\n-  \/\/ Timing stats\n-  log_debug(gc, ergo)(\"PSAdaptiveSizePolicy::compute_old_gen_free_space: costs minor_time: %f major_cost: %f  mutator_cost: %f throughput_goal: %f\",\n-             minor_gc_cost(), major_gc_cost(), mutator_cost(), _throughput_goal);\n-\n-  log_trace(gc, ergo)(\"Minor_pause: %f major_pause: %f minor_interval: %f major_interval: %f pause_goal: %f\",\n-                      _avg_minor_pause->padded_average(),\n-                      _avg_major_pause->padded_average(),\n-                      _avg_minor_interval->average(),\n-                      _avg_major_interval->average(),\n-                      gc_pause_goal_sec());\n-\n-  \/\/ Footprint stats\n-  log_debug(gc, ergo)(\"Live_space: %zu free_space: %zu\",\n-                      live_space(), free_space());\n-\n-  log_trace(gc, ergo)(\"avg_young_live: %zu avg_old_live: %zu\",\n-                      (size_t)avg_young_live()->average(),\n-                      (size_t)avg_old_live()->average());\n-\n-  log_debug(gc, ergo)(\"Old promo_size: %zu desired_promo_size: %zu\",\n-                      _promo_size, desired_promo_size);\n-\n-  set_promo_size(desired_promo_size);\n+  log_debug(gc, ergo)(\"Adaptive: eden unchanged\");\n+  return cur_eden;\n@@ -544,21 +136,4 @@\n-void PSAdaptiveSizePolicy::decay_supplemental_growth(bool is_full_gc) {\n-  \/\/ Decay the supplemental increment?  Decay the supplement growth\n-  \/\/ factor even if it is not used.  It is only meant to give a boost\n-  \/\/ to the initial growth and if it is not used, then it was not\n-  \/\/ needed.\n-  if (is_full_gc) {\n-    \/\/ Don't wait for the threshold value for the major collections.  If\n-    \/\/ here, the supplemental growth term was used and should decay.\n-    if ((_avg_major_pause->count() % TenuredGenerationSizeSupplementDecay)\n-        == 0) {\n-      _old_gen_size_increment_supplement =\n-        _old_gen_size_increment_supplement >> 1;\n-    }\n-  } else {\n-    if ((_avg_minor_pause->count() >= AdaptiveSizePolicyReadyThreshold) &&\n-        (_avg_minor_pause->count() % YoungGenerationSizeSupplementDecay) == 0) {\n-      _young_gen_size_increment_supplement =\n-        _young_gen_size_increment_supplement >> 1;\n-    }\n-  }\n-}\n+size_t PSAdaptiveSizePolicy::compute_desired_survivor_size(\n+  size_t current_survivor_size,\n+  size_t max_gen_size) {\n+  size_t desired_survivor_size = survived_bytes_estimate();\n@@ -566,13 +141,3 @@\n-void PSAdaptiveSizePolicy::adjust_eden_for_minor_pause_time(size_t* desired_eden_size_ptr) {\n-  \/\/ Adjust the young generation size to reduce pause time of\n-  \/\/ of collections.\n-  \/\/\n-  \/\/ The AdaptiveSizePolicyInitializingSteps test is not used\n-  \/\/ here.  It has not seemed to be needed but perhaps should\n-  \/\/ be added for consistency.\n-  if (minor_pause_young_estimator()->decrement_will_decrease()) {\n-        \/\/ reduce eden size\n-    set_change_young_gen_for_min_pauses(\n-          decrease_young_gen_for_min_pauses_true);\n-    *desired_eden_size_ptr = *desired_eden_size_ptr -\n-      eden_decrement_aligned_down(*desired_eden_size_ptr);\n+  if (desired_survivor_size >= current_survivor_size) {\n+    \/\/ Increasing survivor\n+    return MIN2(desired_survivor_size, max_survivor_size(max_gen_size));\n@@ -580,12 +145,0 @@\n-}\n-\n-void PSAdaptiveSizePolicy::adjust_promo_for_pause_time(size_t* desired_promo_size_ptr) {\n-\n-  size_t promo_heap_delta = 0;\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the required alignment is probably not worth\n-  \/\/ attempting.\n-\n-  if (_avg_minor_pause->padded_average() <= _avg_major_pause->padded_average()) {\n-    \/\/ Adjust for the major pause time only at full gc's because the\n-    \/\/ affects of a change can only be seen at full gc's.\n@@ -593,15 +146,2 @@\n-    \/\/ Reduce old generation size to reduce pause?\n-    if (major_pause_old_estimator()->decrement_will_decrease()) {\n-      \/\/ reduce old generation size\n-      set_change_old_gen_for_maj_pauses(decrease_old_gen_for_maj_pauses_true);\n-      promo_heap_delta = promo_decrement_aligned_down(*desired_promo_size_ptr);\n-      *desired_promo_size_ptr = _promo_size - promo_heap_delta;\n-    }\n-  }\n-\n-  log_trace(gc, ergo)(\n-    \"PSAdaptiveSizePolicy::adjust_promo_for_pause_time \"\n-    \"adjusting gen sizes for major pause (avg %f goal %f). \"\n-    \"desired_promo_size %zu promo delta %zu\",\n-    _avg_major_pause->average(), gc_pause_goal_sec(),\n-    *desired_promo_size_ptr, promo_heap_delta);\n+  size_t delta = current_survivor_size - desired_survivor_size;\n+  return current_survivor_size - delta \/ AdaptiveSizeDecrementScaleFactor;\n@@ -610,1 +150,3 @@\n-void PSAdaptiveSizePolicy::adjust_eden_for_pause_time(size_t* desired_eden_size_ptr) {\n+size_t PSAdaptiveSizePolicy::compute_old_gen_shrink_bytes(size_t old_gen_free_bytes, size_t max_shrink_bytes) {\n+  \/\/ 10min\n+  static constexpr double lookahead_sec = 10 * 60;\n@@ -612,14 +154,1 @@\n-  size_t eden_heap_delta = 0;\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the required alignment is probably not worth\n-  \/\/ attempting.\n-  if (_avg_minor_pause->padded_average() > _avg_major_pause->padded_average()) {\n-    adjust_eden_for_minor_pause_time(desired_eden_size_ptr);\n-  }\n-  log_trace(gc, ergo)(\n-    \"PSAdaptiveSizePolicy::adjust_eden_for_pause_time \"\n-    \"adjusting gen sizes for major pause (avg %f goal %f). \"\n-    \"desired_eden_size %zu eden delta %zu\",\n-    _avg_major_pause->average(), gc_pause_goal_sec(),\n-    *desired_eden_size_ptr, eden_heap_delta);\n-}\n+  double free_bytes = old_gen_free_bytes;\n@@ -627,2 +156,1 @@\n-void PSAdaptiveSizePolicy::adjust_promo_for_throughput(bool is_full_gc,\n-                                             size_t* desired_promo_size_ptr) {\n+  double promotion_rate = promotion_rate_bytes_per_sec_estimate();\n@@ -630,3 +158,3 @@\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the required alignment is probably not worth\n-  \/\/ attempting.\n+  double min_free_bytes = MAX2((double)padded_average_promoted_in_bytes(),\n+                               promotion_rate * lookahead_sec);\n+  size_t shrink_bytes = 0;\n@@ -634,2 +162,3 @@\n-  if ((gc_cost() + mutator_cost()) == 0.0) {\n-    return;\n+  if (free_bytes > min_free_bytes) {\n+    shrink_bytes = (free_bytes - min_free_bytes) \/ 2;\n+    shrink_bytes = MIN2(shrink_bytes, max_shrink_bytes);\n@@ -638,29 +167,2 @@\n-  log_trace(gc, ergo)(\"PSAdaptiveSizePolicy::adjust_promo_for_throughput(is_full: %d, promo: %zu): mutator_cost %f  major_gc_cost %f minor_gc_cost %f\",\n-                      is_full_gc, *desired_promo_size_ptr, mutator_cost(), major_gc_cost(), minor_gc_cost());\n-\n-  \/\/ Tenured generation\n-  if (is_full_gc) {\n-    \/\/ Calculate the change to use for the tenured gen.\n-    size_t scaled_promo_heap_delta = 0;\n-    \/\/ Can the increment to the generation be scaled?\n-    if (gc_cost() >= 0.0 && major_gc_cost() >= 0.0) {\n-      size_t promo_heap_delta =\n-        promo_increment_with_supplement_aligned_up(*desired_promo_size_ptr);\n-      double scale_by_ratio = major_gc_cost() \/ gc_cost();\n-      scaled_promo_heap_delta =\n-        (size_t) (scale_by_ratio * (double) promo_heap_delta);\n-      log_trace(gc, ergo)(\"Scaled tenured increment: %zu by %f down to %zu\",\n-                          promo_heap_delta, scale_by_ratio, scaled_promo_heap_delta);\n-    } else if (major_gc_cost() >= 0.0) {\n-      \/\/ Scaling is not going to work.  If the major gc time is the\n-      \/\/ larger, give it a full increment.\n-      if (major_gc_cost() >= minor_gc_cost()) {\n-        scaled_promo_heap_delta =\n-          promo_increment_with_supplement_aligned_up(*desired_promo_size_ptr);\n-      }\n-    } else {\n-      \/\/ Don't expect to get here but it's ok if it does\n-      \/\/ in the product build since the delta will be 0\n-      \/\/ and nothing will change.\n-      assert(false, \"Unexpected value for gc costs\");\n-    }\n+  log_debug(gc, ergo)(\"Adaptive: old-gen free bytes: %.0f M, min-free-bytes: %.1f M, shrink-bytes: %zu K\",\n+    free_bytes\/M, min_free_bytes\/M, shrink_bytes\/K);\n@@ -668,36 +170,1 @@\n-    switch (AdaptiveSizeThroughPutPolicy) {\n-      case 1:\n-        \/\/ Early in the run the statistics might not be good.  Until\n-        \/\/ a specific number of collections have been, use the heuristic\n-        \/\/ that a larger generation size means lower collection costs.\n-        if (major_collection_estimator()->increment_will_decrease() ||\n-           (_old_gen_change_for_major_throughput\n-            <= AdaptiveSizePolicyInitializingSteps)) {\n-          \/\/ Increase tenured generation size to reduce major collection cost\n-          if ((*desired_promo_size_ptr + scaled_promo_heap_delta) >\n-              *desired_promo_size_ptr) {\n-            *desired_promo_size_ptr = _promo_size + scaled_promo_heap_delta;\n-          }\n-          set_change_old_gen_for_throughput(\n-              increase_old_gen_for_throughput_true);\n-              _old_gen_change_for_major_throughput++;\n-        }\n-\n-        break;\n-      default:\n-        \/\/ Simplest strategy\n-        if ((*desired_promo_size_ptr + scaled_promo_heap_delta) >\n-            *desired_promo_size_ptr) {\n-          *desired_promo_size_ptr = *desired_promo_size_ptr +\n-            scaled_promo_heap_delta;\n-        }\n-        set_change_old_gen_for_throughput(\n-          increase_old_gen_for_throughput_true);\n-        _old_gen_change_for_major_throughput++;\n-    }\n-\n-    log_trace(gc, ergo)(\"Adjusting tenured gen for throughput (avg %f goal %f). desired_promo_size %zu promo_delta %zu\",\n-                        mutator_cost(),\n-                        _throughput_goal,\n-                        *desired_promo_size_ptr, scaled_promo_heap_delta);\n-  }\n+  return shrink_bytes;\n@@ -706,68 +173,5 @@\n-void PSAdaptiveSizePolicy::adjust_eden_for_throughput(bool is_full_gc,\n-                                             size_t* desired_eden_size_ptr) {\n-\n-  \/\/ Add some checks for a threshold for a change.  For example,\n-  \/\/ a change less than the required alignment is probably not worth\n-  \/\/ attempting.\n-\n-  if ((gc_cost() + mutator_cost()) == 0.0) {\n-    return;\n-  }\n-\n-  log_trace(gc, ergo)(\"PSAdaptiveSizePolicy::adjust_eden_for_throughput(is_full: %d, cur_eden: %zu): mutator_cost %f  major_gc_cost %f minor_gc_cost %f\",\n-                      is_full_gc, *desired_eden_size_ptr, mutator_cost(), major_gc_cost(), minor_gc_cost());\n-\n-  \/\/ Young generation\n-  size_t scaled_eden_heap_delta = 0;\n-  \/\/ Can the increment to the generation be scaled?\n-  if (gc_cost() >= 0.0 && minor_gc_cost() >= 0.0) {\n-    size_t eden_heap_delta =\n-      eden_increment_with_supplement_aligned_up(*desired_eden_size_ptr);\n-    double scale_by_ratio = minor_gc_cost() \/ gc_cost();\n-    assert(scale_by_ratio <= 1.0 && scale_by_ratio >= 0.0, \"Scaling is wrong\");\n-    scaled_eden_heap_delta =\n-      (size_t) (scale_by_ratio * (double) eden_heap_delta);\n-    log_trace(gc, ergo)(\"Scaled eden increment: %zu by %f down to %zu\",\n-                        eden_heap_delta, scale_by_ratio, scaled_eden_heap_delta);\n-  } else if (minor_gc_cost() >= 0.0) {\n-    \/\/ Scaling is not going to work.  If the minor gc time is the\n-    \/\/ larger, give it a full increment.\n-    if (minor_gc_cost() > major_gc_cost()) {\n-      scaled_eden_heap_delta =\n-        eden_increment_with_supplement_aligned_up(*desired_eden_size_ptr);\n-    }\n-  } else {\n-    \/\/ Don't expect to get here but it's ok if it does\n-    \/\/ in the product build since the delta will be 0\n-    \/\/ and nothing will change.\n-    assert(false, \"Unexpected value for gc costs\");\n-  }\n-\n-  \/\/ Use a heuristic for some number of collections to give\n-  \/\/ the averages time to settle down.\n-  switch (AdaptiveSizeThroughPutPolicy) {\n-    case 1:\n-      if (minor_collection_estimator()->increment_will_decrease() ||\n-        (_young_gen_change_for_minor_throughput\n-          <= AdaptiveSizePolicyInitializingSteps)) {\n-        \/\/ Expand young generation size to reduce frequency of\n-        \/\/ of collections.\n-        if ((*desired_eden_size_ptr + scaled_eden_heap_delta) >\n-            *desired_eden_size_ptr) {\n-          *desired_eden_size_ptr =\n-            *desired_eden_size_ptr + scaled_eden_heap_delta;\n-        }\n-        set_change_young_gen_for_throughput(\n-          increase_young_gen_for_througput_true);\n-        _young_gen_change_for_minor_throughput++;\n-      }\n-          break;\n-    default:\n-      if ((*desired_eden_size_ptr + scaled_eden_heap_delta) >\n-          *desired_eden_size_ptr) {\n-        *desired_eden_size_ptr =\n-          *desired_eden_size_ptr + scaled_eden_heap_delta;\n-      }\n-      set_change_young_gen_for_throughput(\n-        increase_young_gen_for_througput_true);\n-      _young_gen_change_for_minor_throughput++;\n+void PSAdaptiveSizePolicy::decay_supplemental_growth(uint num_minor_gcs) {\n+  if ((num_minor_gcs >= AdaptiveSizePolicyReadyThreshold) &&\n+      (num_minor_gcs % YoungGenerationSizeSupplementDecay) == 0) {\n+    _young_gen_size_increment_supplement =\n+      _young_gen_size_increment_supplement >> 1;\n@@ -775,3 +179,0 @@\n-\n-    log_trace(gc, ergo)(\"Adjusting eden for throughput (avg %f goal %f). desired_eden_size %zu eden delta %zu\",\n-                        mutator_cost(), _throughput_goal, *desired_eden_size_ptr, scaled_eden_heap_delta);\n@@ -780,9 +181,4 @@\n-size_t PSAdaptiveSizePolicy::adjust_promo_for_footprint(\n-    size_t desired_promo_size, size_t desired_sum) {\n-  assert(desired_promo_size <= desired_sum, \"Inconsistent parameters\");\n-  set_decrease_for_footprint(decrease_old_gen_for_footprint_true);\n-\n-  size_t change = promo_decrement(desired_promo_size);\n-  change = scale_down(change, desired_promo_size, desired_sum);\n-\n-  size_t reduced_size = desired_promo_size - change;\n+size_t PSAdaptiveSizePolicy::decrease_eden_for_minor_pause_time(size_t current_eden_size) {\n+  size_t desired_eden_size = minor_pause_young_estimator()->decrement_will_decrease()\n+                           ? current_eden_size - eden_decrement_aligned_down(current_eden_size)\n+                           : current_eden_size;\n@@ -790,7 +186,1 @@\n-  log_trace(gc, ergo)(\n-    \"AdaptiveSizePolicy::adjust_promo_for_footprint \"\n-    \"adjusting tenured gen for footprint. \"\n-    \"starting promo size %zu\"\n-    \" reduced promo size %zu\"\n-    \" promo delta %zu\",\n-    desired_promo_size, reduced_size, change );\n+  assert(desired_eden_size <= current_eden_size, \"postcondition\");\n@@ -798,2 +188,1 @@\n-  assert(reduced_size <= desired_promo_size, \"Inconsistent result\");\n-  return reduced_size;\n+  return desired_eden_size;\n@@ -802,4 +191,2 @@\n-size_t PSAdaptiveSizePolicy::adjust_eden_for_footprint(\n-  size_t desired_eden_size, size_t desired_sum) {\n-  assert(desired_eden_size <= desired_sum, \"Inconsistent parameters\");\n-  set_decrease_for_footprint(decrease_young_gen_for_footprint_true);\n+size_t PSAdaptiveSizePolicy::increase_eden(size_t current_eden_size) {\n+  size_t delta = eden_increment_with_supplement_aligned_up(current_eden_size);\n@@ -807,2 +194,1 @@\n-  size_t change = eden_decrement(desired_eden_size);\n-  change = scale_down(change, desired_eden_size, desired_sum);\n+  size_t desired_eden_size = current_eden_size + delta;\n@@ -810,1 +196,1 @@\n-  size_t reduced_size = desired_eden_size - change;\n+  assert(desired_eden_size >= current_eden_size, \"postcondition\");\n@@ -812,27 +198,1 @@\n-  log_trace(gc, ergo)(\n-    \"AdaptiveSizePolicy::adjust_eden_for_footprint \"\n-    \"adjusting eden for footprint. \"\n-    \" starting eden size %zu\"\n-    \" reduced eden size %zu\"\n-    \" eden delta %zu\",\n-    desired_eden_size, reduced_size, change);\n-\n-  assert(reduced_size <= desired_eden_size, \"Inconsistent result\");\n-  return reduced_size;\n-}\n-\n-\/\/ Scale down \"change\" by the factor\n-\/\/      part \/ total\n-\/\/ Don't align the results.\n-\n-size_t PSAdaptiveSizePolicy::scale_down(size_t change,\n-                                        double part,\n-                                        double total) {\n-  assert(part <= total, \"Inconsistent input\");\n-  size_t reduced_change = change;\n-  if (total > 0) {\n-    double fraction =  part \/ total;\n-    reduced_change = (size_t) (fraction * (double) change);\n-  }\n-  assert(reduced_change <= change, \"Inconsistent result\");\n-  return reduced_change;\n+  return desired_eden_size;\n@@ -841,2 +201,1 @@\n-size_t PSAdaptiveSizePolicy::eden_increment_with_supplement_aligned_up(\n-  size_t cur_eden) {\n+size_t PSAdaptiveSizePolicy::eden_increment_with_supplement_aligned_up(size_t cur_eden) {\n@@ -849,1 +208,1 @@\n-  size_t eden_heap_delta = eden_decrement(cur_eden);\n+  size_t eden_heap_delta = eden_increment(cur_eden) \/ AdaptiveSizeDecrementScaleFactor;\n@@ -853,11 +212,5 @@\n-size_t PSAdaptiveSizePolicy::promo_increment_with_supplement_aligned_up(\n-  size_t cur_promo) {\n-  size_t result =  promo_increment(cur_promo,\n-    TenuredGenerationSizeIncrement + _old_gen_size_increment_supplement);\n-  return align_up(result, _space_alignment);\n-}\n-\n-size_t PSAdaptiveSizePolicy::promo_decrement_aligned_down(size_t cur_promo) {\n-  size_t promo_heap_delta = promo_decrement(cur_promo);\n-  return align_down(promo_heap_delta, _space_alignment);\n-}\n+uint PSAdaptiveSizePolicy::compute_tenuring_threshold(bool is_survivor_overflowing,\n+                                                      uint tenuring_threshold) {\n+  if (!young_gen_policy_is_ready()) {\n+    return tenuring_threshold;\n+  }\n@@ -865,13 +218,1 @@\n-uint PSAdaptiveSizePolicy::compute_survivor_space_size_and_threshold(\n-                                             bool is_survivor_overflow,\n-                                             uint tenuring_threshold,\n-                                             size_t survivor_limit) {\n-  assert(survivor_limit >= _space_alignment,\n-         \"survivor_limit too small\");\n-  assert(is_aligned(survivor_limit, _space_alignment),\n-         \"survivor_limit not aligned\");\n-\n-  \/\/ This method is called even if the tenuring threshold and survivor\n-  \/\/ spaces are not adjusted so that the averages are sampled above.\n-  if (!UsePSAdaptiveSurvivorSizePolicy ||\n-      !young_gen_policy_is_ready()) {\n+  if (is_survivor_overflowing) {\n@@ -881,4 +222,0 @@\n-  \/\/ We'll decide whether to increase or decrease the tenuring\n-  \/\/ threshold based partly on the newly computed survivor size\n-  \/\/ (if we hit the maximum limit allowed, we'll always choose to\n-  \/\/ decrement the threshold).\n@@ -886,1 +223,0 @@\n-  bool decr_tenuring_threshold = false;\n@@ -888,3 +224,2 @@\n-  set_decrement_tenuring_threshold_for_gc_cost(false);\n-  set_increment_tenuring_threshold_for_gc_cost(false);\n-  set_decrement_tenuring_threshold_for_survivor_limit(false);\n+  const double major_cost = major_gc_time_sum();\n+  const double minor_cost = minor_gc_time_sum();\n@@ -892,52 +227,5 @@\n-  if (!is_survivor_overflow) {\n-    \/\/ Keep running averages on how much survived\n-\n-    \/\/ We use the tenuring threshold to equalize the cost of major\n-    \/\/ and minor collections.\n-    \/\/ ThresholdTolerance is used to indicate how sensitive the\n-    \/\/ tenuring threshold is to differences in cost between the\n-    \/\/ collection types.\n-\n-    \/\/ Get the times of interest. This involves a little work, so\n-    \/\/ we cache the values here.\n-    const double major_cost = major_gc_cost();\n-    const double minor_cost = minor_gc_cost();\n-\n-    if (minor_cost > major_cost * _threshold_tolerance_percent) {\n-      \/\/ Minor times are getting too long;  lower the threshold so\n-      \/\/ less survives and more is promoted.\n-      decr_tenuring_threshold = true;\n-      set_decrement_tenuring_threshold_for_gc_cost(true);\n-    } else if (major_cost > minor_cost * _threshold_tolerance_percent) {\n-      \/\/ Major times are too long, so we want less promotion.\n-      incr_tenuring_threshold = true;\n-      set_increment_tenuring_threshold_for_gc_cost(true);\n-    }\n-\n-  } else {\n-    \/\/ Survivor space overflow occurred, so promoted and survived are\n-    \/\/ not accurate. We'll make our best guess by combining survived\n-    \/\/ and promoted and count them as survivors.\n-    \/\/\n-    \/\/ We'll lower the tenuring threshold to see if we can correct\n-    \/\/ things. Also, set the survivor size conservatively. We're\n-    \/\/ trying to avoid many overflows from occurring if defnew size\n-    \/\/ is just too small.\n-\n-    decr_tenuring_threshold = true;\n-  }\n-\n-  \/\/ The padded average also maintains a deviation from the average;\n-  \/\/ we use this to see how good of an estimate we have of what survived.\n-  \/\/ We're trying to pad the survivor size as little as possible without\n-  \/\/ overflowing the survivor spaces.\n-  size_t target_size = align_up((size_t)_avg_survived->padded_average(),\n-                                     _space_alignment);\n-  target_size = MAX2(target_size, _space_alignment);\n-\n-  if (target_size > survivor_limit) {\n-    \/\/ Target size is bigger than we can handle. Let's also reduce\n-    \/\/ the tenuring threshold.\n-    target_size = survivor_limit;\n-    decr_tenuring_threshold = true;\n-    set_decrement_tenuring_threshold_for_survivor_limit(true);\n+  if (minor_cost > major_cost * _threshold_tolerance_percent) {\n+    \/\/ nothing; we prefer young-gc over full-gc\n+  } else if (major_cost > minor_cost * _threshold_tolerance_percent) {\n+    \/\/ Major times are too long, so we want less promotion.\n+    incr_tenuring_threshold = true;\n@@ -950,3 +238,1 @@\n-    if (decr_tenuring_threshold && tenuring_threshold > 1) {\n-      tenuring_threshold--;\n-    } else if (incr_tenuring_threshold && tenuring_threshold < MaxTenuringThreshold) {\n+    if (incr_tenuring_threshold && tenuring_threshold < MaxTenuringThreshold) {\n@@ -957,16 +243,0 @@\n-  \/\/ We keep a running average of the amount promoted which is used\n-  \/\/ to decide when we should collect the old generation (when\n-  \/\/ the amount of old gen free space is less than what we expect to\n-  \/\/ promote).\n-\n-  log_trace(gc, ergo)(\"avg_survived: %f  avg_deviation: %f\", _avg_survived->average(), _avg_survived->deviation());\n-  log_debug(gc, ergo)(\"avg_survived_padded_avg: %f\", _avg_survived->padded_average());\n-\n-  log_trace(gc, ergo)(\"avg_promoted_avg: %f  avg_promoted_dev: %f\", avg_promoted()->average(), avg_promoted()->deviation());\n-  log_debug(gc, ergo)(\"avg_promoted_padded_avg: %f  avg_pretenured_padded_avg: %f  tenuring_thresh: %d  target_size: %zu\",\n-                      avg_promoted()->padded_average(),\n-                      _avg_pretenured->padded_average(),\n-                      tenuring_threshold, target_size);\n-\n-  set_survivor_size(target_size);\n-\n@@ -979,1 +249,0 @@\n-  \/\/ Update averages\n@@ -981,2 +250,1 @@\n-    \/\/ Keep running averages on how much survived\n-    _avg_survived->sample(survived);\n+    _survived_bytes.add(survived);\n@@ -984,13 +252,2 @@\n-    size_t survived_guess = survived + promoted;\n-    _avg_survived->sample(survived_guess);\n-  }\n-  avg_promoted()->sample(promoted);\n-\n-  log_trace(gc, ergo)(\"AdaptiveSizePolicy::update_averages:  survived: %zu  promoted: %zu  overflow: %s\",\n-                      survived, promoted, is_survivor_overflow ? \"true\" : \"false\");\n-}\n-\n-bool PSAdaptiveSizePolicy::print() const {\n-\n-  if (!UseAdaptiveSizePolicy) {\n-    return false;\n+    \/\/ survived is an underestimate\n+    _survived_bytes.add(survived + promoted);\n@@ -999,4 +256,2 @@\n-  if (AdaptiveSizePolicy::print()) {\n-    AdaptiveSizePolicy::print_tenuring_threshold(PSScavenge::tenuring_threshold());\n-    return true;\n-  }\n+  avg_promoted()->sample(promoted);\n+  _promoted_bytes.add(promoted);\n@@ -1004,2 +259,3 @@\n-  return false;\n-}\n+  double promotion_rate = promoted \/ (_gc_distance_seconds_seq.last() + _trimmed_minor_gc_time_seconds.last());\n+  _promotion_rate_bytes_per_sec.add(promotion_rate);\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/parallel\/psAdaptiveSizePolicy.cpp","additions":131,"deletions":875,"binary":false,"changes":1006,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"gc\/shared\/gcCause.hpp\"\n@@ -37,19 +36,0 @@\n-\/\/\n-\/\/ It also computes an optimal tenuring threshold between the young\n-\/\/ and old generations, so as to equalize the cost of collections\n-\/\/ of those generations, as well as optimal survivor space sizes\n-\/\/ for the young generation.\n-\/\/\n-\/\/ While this class is specifically intended for a generational system\n-\/\/ consisting of a young gen (containing an Eden and two semi-spaces)\n-\/\/ and a tenured gen, as well as a perm gen for reflective data, it\n-\/\/ makes NO references to specific generations.\n-\/\/\n-\/\/ 05\/02\/2003 Update\n-\/\/ The 1.5 policy makes use of data gathered for the costs of GC on\n-\/\/ specific generations.  That data does reference specific\n-\/\/ generation.  Also diagnostics specific to generations have\n-\/\/ been added.\n-\n-\/\/ Forward decls\n-class elapsedTimer;\n@@ -58,16 +38,0 @@\n- friend class PSGCAdaptivePolicyCounters;\n- private:\n-  \/\/ These values are used to record decisions made during the\n-  \/\/ policy.  For example, if the young generation was decreased\n-  \/\/ to decrease the GC cost of minor collections the value\n-  \/\/ decrease_young_gen_for_throughput_true is used.\n-\n-  \/\/ Last calculated sizes, in bytes, and aligned\n-  \/\/ NEEDS_CLEANUP should use sizes.hpp,  but it works in ints, not size_t's\n-\n-  \/\/ Time statistics\n-  AdaptivePaddedAverage* _avg_major_pause;\n-\n-  \/\/ Footprint statistics\n-  AdaptiveWeightedAverage* _avg_base_footprint;\n-\n@@ -77,14 +41,0 @@\n-  \/\/ Variable for estimating the major and minor pause times.\n-  \/\/ These variables represent linear least-squares fits of\n-  \/\/ the data.\n-  \/\/   major pause time vs. old gen size\n-  LinearLeastSquareFit* _major_pause_old_estimator;\n-  \/\/   major pause time vs. young gen size\n-  LinearLeastSquareFit* _major_pause_young_estimator;\n-\n-\n-  \/\/ These record the most recent collection times.  They\n-  \/\/ are available as an alternative to using the averages\n-  \/\/ for making ergonomic decisions.\n-  double _latest_major_mutator_interval_seconds;\n-\n@@ -93,11 +43,0 @@\n-  \/\/ The amount of live data in the heap at the last full GC, used\n-  \/\/ as a baseline to help us determine when we need to perform the\n-  \/\/ next full GC.\n-  size_t _live_at_last_full_gc;\n-\n-  \/\/ decrease\/increase the old generation for minor pause time\n-  int _change_old_gen_for_min_pauses;\n-\n-  \/\/ increase\/decrease the young generation for major pause time\n-  int _change_young_gen_for_maj_pauses;\n-\n@@ -109,1 +48,0 @@\n-  uint _old_gen_size_increment_supplement;\n@@ -111,1 +49,1 @@\n- private:\n+  size_t decrease_eden_for_minor_pause_time(size_t current_eden_size);\n@@ -113,17 +51,1 @@\n-  void adjust_eden_for_minor_pause_time(size_t* desired_eden_size_ptr);\n-  \/\/ Change the generation sizes to achieve a GC pause time goal\n-  \/\/ Returned sizes are not necessarily aligned.\n-  void adjust_promo_for_pause_time(size_t* desired_promo_size_ptr);\n-  void adjust_eden_for_pause_time(size_t* desired_eden_size_ptr);\n-  \/\/ Change the generation sizes to achieve an application throughput goal\n-  \/\/ Returned sizes are not necessarily aligned.\n-  void adjust_promo_for_throughput(bool is_full_gc,\n-                             size_t* desired_promo_size_ptr);\n-  void adjust_eden_for_throughput(bool is_full_gc,\n-                             size_t* desired_eden_size_ptr);\n-  \/\/ Change the generation sizes to achieve minimum footprint\n-  \/\/ Returned sizes are not aligned.\n-  size_t adjust_promo_for_footprint(size_t desired_promo_size,\n-                                    size_t desired_total);\n-  size_t adjust_eden_for_footprint(size_t desired_promo_size,\n-                                   size_t desired_total);\n+  size_t increase_eden(size_t current_eden_size);\n@@ -135,31 +57,0 @@\n-  \/\/ Size in bytes for an increment or decrement of the promotion area\n-  size_t promo_decrement_aligned_down(size_t cur_promo);\n-  size_t promo_increment_with_supplement_aligned_up(size_t cur_promo);\n-\n-  \/\/ Returns a change that has been scaled down.  Result\n-  \/\/ is not aligned.  (If useful, move to some shared\n-  \/\/ location.)\n-  size_t scale_down(size_t change, double part, double total);\n-\n- protected:\n-\n-  \/\/ Footprint accessors\n-  size_t live_space() const {\n-    return (size_t)(avg_young_live()->average() +\n-                    avg_old_live()->average());\n-  }\n-  size_t free_space() const {\n-    return _eden_size + _promo_size;\n-  }\n-\n-  void set_promo_size(size_t new_size) {\n-    _promo_size = new_size;\n-  }\n-\n-  \/\/ Update estimators\n-  void update_minor_pause_old_estimator(double minor_pause_in_ms);\n-\n-  virtual GCPolicyKind kind() const { return _gc_ps_adaptive_size_policy; }\n-\n- public:\n-  \/\/ Accessors for use by performance counters\n@@ -169,3 +60,1 @@\n-  AdaptiveWeightedAverage* avg_base_footprint() const {\n-    return _avg_base_footprint;\n-  }\n+ public:\n@@ -173,4 +62,0 @@\n-  \/\/ Input arguments are initial free space sizes for young and old\n-  \/\/ generations, the initial survivor space size, the\n-  \/\/ alignment values and the pause & throughput goals.\n-  \/\/\n@@ -178,4 +63,1 @@\n-  PSAdaptiveSizePolicy(size_t init_eden_size,\n-                       size_t init_promo_size,\n-                       size_t init_survivor_size,\n-                       size_t space_alignment,\n+  PSAdaptiveSizePolicy(size_t space_alignment,\n@@ -189,1 +71,1 @@\n-  void major_collection_end(size_t amount_live, GCCause::Cause gc_cause);\n+  void major_collection_end();\n@@ -191,3 +73,1 @@\n-  void tenured_allocation(size_t size) {\n-    _avg_pretenured->sample(size);\n-  }\n+  void print_stats(bool is_survivor_overflowing);\n@@ -196,5 +76,0 @@\n-  \/\/ NEEDS_CLEANUP   should use sizes.hpp\n-\n-  static size_t calculate_free_based_on_live(size_t live, uintx ratio_as_percentage);\n-\n-  size_t calculated_old_free_size_in_bytes() const;\n@@ -210,6 +85,1 @@\n-  int change_young_gen_for_maj_pauses() {\n-    return _change_young_gen_for_maj_pauses;\n-  }\n-  void set_change_young_gen_for_maj_pauses(int v) {\n-    _change_young_gen_for_maj_pauses = v;\n-  }\n+  size_t compute_desired_eden_size(bool is_survivor_overflowing, size_t cur_eden);\n@@ -217,6 +87,1 @@\n-  int change_old_gen_for_min_pauses() {\n-    return _change_old_gen_for_min_pauses;\n-  }\n-  void set_change_old_gen_for_min_pauses(int v) {\n-    _change_old_gen_for_min_pauses = v;\n-  }\n+  size_t compute_desired_survivor_size(size_t current_survivor_size, size_t max_gen_size);\n@@ -224,2 +89,1 @@\n-  \/\/ Accessors for estimators.  The slope of the linear fit is\n-  \/\/ currently all that is used for making decisions.\n+  size_t compute_old_gen_shrink_bytes(size_t old_gen_free_bytes, size_t max_shrink_bytes);\n@@ -227,40 +91,2 @@\n-  LinearLeastSquareFit* major_pause_old_estimator() {\n-    return _major_pause_old_estimator;\n-  }\n-\n-  virtual void clear_generation_free_space_flags();\n-\n-  double major_pause_old_slope() { return _major_pause_old_estimator->slope(); }\n-  double major_pause_young_slope() {\n-    return _major_pause_young_estimator->slope();\n-  }\n-\n-  \/\/ Calculates optimal (free) space sizes for both the young and old\n-  \/\/ generations.  Stores results in _eden_size and _promo_size.\n-  \/\/ Takes current used space in all generations as input, as well\n-  \/\/ as an indication if a full gc has just been performed, for use\n-  \/\/ in deciding if an OOM error should be thrown.\n-  void compute_generations_free_space(size_t young_live,\n-                                      size_t eden_live,\n-                                      size_t old_live,\n-                                      size_t cur_eden,  \/\/ current eden in bytes\n-                                      size_t max_old_gen_size,\n-                                      size_t max_eden_size,\n-                                      bool   is_full_gc);\n-\n-  void compute_eden_space_size(size_t young_live,\n-                               size_t eden_live,\n-                               size_t cur_eden,  \/\/ current eden in bytes\n-                               size_t max_eden_size,\n-                               bool   is_full_gc);\n-\n-  void compute_old_gen_free_space(size_t old_live,\n-                                             size_t cur_eden,  \/\/ current eden in bytes\n-                                             size_t max_old_gen_size,\n-                                             bool   is_full_gc);\n-\n-  \/\/ Calculates new survivor space size;  returns a new tenuring threshold\n-  \/\/ value. Stores new survivor size in _survivor_size.\n-  uint compute_survivor_space_size_and_threshold(bool   is_survivor_overflow,\n-                                                 uint    tenuring_threshold,\n-                                                 size_t survivor_limit);\n+  uint compute_tenuring_threshold(bool is_survivor_overflowing,\n+                                  uint tenuring_threshold);\n@@ -282,4 +108,0 @@\n-  size_t live_at_last_full_gc() {\n-    return _live_at_last_full_gc;\n-  }\n-\n@@ -292,3 +114,0 @@\n-  \/\/ Printing support\n-  virtual bool print() const;\n-\n@@ -296,1 +115,1 @@\n-  void decay_supplemental_growth(bool is_full_gc);\n+  void decay_supplemental_growth(uint num_minor_gcs);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psAdaptiveSizePolicy.hpp","additions":12,"deletions":193,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -1,179 +0,0 @@\n-\/*\n- * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"gc\/parallel\/psGCAdaptivePolicyCounters.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-\n-PSGCAdaptivePolicyCounters::PSGCAdaptivePolicyCounters(const char* name_arg,\n-                                      int collectors,\n-                                      int generations,\n-                                      PSAdaptiveSizePolicy* size_policy_arg)\n-        : GCAdaptivePolicyCounters(name_arg,\n-                                   collectors,\n-                                   generations,\n-                                   size_policy_arg) {\n-  if (UsePerfData) {\n-    EXCEPTION_MARK;\n-    ResourceMark rm;\n-\n-    const char* cname;\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"oldPromoSize\");\n-    _old_promo_size = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, ps_size_policy()->calculated_promo_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"oldEdenSize\");\n-    _old_eden_size = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, ps_size_policy()->calculated_eden_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"oldCapacity\");\n-    _old_capacity = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) InitialHeapSize, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgPromotedAvg\");\n-    _avg_promoted_avg_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Bytes,\n-        ps_size_policy()->calculated_promo_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgPromotedDev\");\n-    _avg_promoted_dev_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Bytes,\n-        (jlong) 0 , CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgPromotedPaddedAvg\");\n-    _avg_promoted_padded_avg_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Bytes,\n-        ps_size_policy()->calculated_promo_size_in_bytes(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"avgPretenuredPaddedAvg\");\n-    _avg_pretenured_padded_avg =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Bytes,\n-        (jlong) 0, CHECK);\n-\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"changeYoungGenForMajPauses\");\n-    _change_young_gen_for_maj_pauses_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(),\n-      \"changeOldGenForMinPauses\");\n-    _change_old_gen_for_min_pauses =\n-      PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-        (jlong)0, CHECK);\n-\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgMajorPauseTime\");\n-    _avg_major_pause = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Ticks, (jlong) ps_size_policy()->_avg_major_pause->average(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"avgMajorIntervalTime\");\n-    _avg_major_interval = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Ticks, (jlong) ps_size_policy()->_avg_major_interval->average(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"majorGcCost\");\n-    _major_gc_cost_counter = PerfDataManager::create_variable(SUN_GC, cname,\n-       PerfData::U_Ticks, (jlong) ps_size_policy()->major_gc_cost(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"liveSpace\");\n-    _live_space = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, ps_size_policy()->live_space(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"freeSpace\");\n-    _free_space = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, ps_size_policy()->free_space(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"liveAtLastFullGc\");\n-    _live_at_last_full_gc_counter =\n-      PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, ps_size_policy()->live_at_last_full_gc(), CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"majorPauseOldSlope\");\n-    _major_pause_old_slope = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"minorPauseOldSlope\");\n-    _minor_pause_old_slope = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"majorPauseYoungSlope\");\n-    _major_pause_young_slope = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_None, (jlong) 0, CHECK);\n-\n-    _counter_time_stamp.update();\n-  }\n-\n-  assert(size_policy()->is_gc_ps_adaptive_size_policy(),\n-    \"Wrong type of size policy\");\n-}\n-\n-void PSGCAdaptivePolicyCounters::update_counters_from_policy() {\n-  if (UsePerfData) {\n-    GCAdaptivePolicyCounters::update_counters_from_policy();\n-    update_eden_size();\n-    update_promo_size();\n-    update_avg_old_live();\n-    update_survivor_size_counters();\n-    update_avg_promoted_avg();\n-    update_avg_promoted_dev();\n-    update_avg_promoted_padded_avg();\n-    update_avg_pretenured_padded_avg();\n-\n-    update_avg_major_pause();\n-    update_avg_major_interval();\n-    update_minor_gc_cost_counter();\n-    update_major_gc_cost_counter();\n-    update_mutator_cost_counter();\n-    update_decrement_tenuring_threshold_for_gc_cost();\n-    update_increment_tenuring_threshold_for_gc_cost();\n-    update_decrement_tenuring_threshold_for_survivor_limit();\n-    update_live_space();\n-    update_free_space();\n-\n-    update_change_old_gen_for_maj_pauses();\n-    update_change_young_gen_for_maj_pauses();\n-    update_change_old_gen_for_min_pauses();\n-\n-    update_change_old_gen_for_throughput();\n-    update_change_young_gen_for_throughput();\n-\n-    update_decrease_for_footprint();\n-    update_decide_at_full_gc_counter();\n-\n-    update_major_pause_old_slope();\n-    update_minor_pause_old_slope();\n-    update_major_pause_young_slope();\n-    update_minor_collection_slope_counter();\n-    update_gc_overhead_limit_exceeded_counter();\n-    update_live_at_last_full_gc_counter();\n-  }\n-}\n-\n-void PSGCAdaptivePolicyCounters::update_counters() {\n-  if (UsePerfData) {\n-    update_counters_from_policy();\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/parallel\/psGCAdaptivePolicyCounters.cpp","additions":0,"deletions":179,"binary":false,"changes":179,"status":"deleted"},{"patch":"@@ -1,185 +0,0 @@\n-\/*\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_PARALLEL_PSGCADAPTIVEPOLICYCOUNTERS_HPP\n-#define SHARE_GC_PARALLEL_PSGCADAPTIVEPOLICYCOUNTERS_HPP\n-\n-#include \"gc\/parallel\/gcAdaptivePolicyCounters.hpp\"\n-#include \"gc\/parallel\/psAdaptiveSizePolicy.hpp\"\n-#include \"gc\/shared\/gcPolicyCounters.hpp\"\n-\n-\/\/ PSGCAdaptivePolicyCounters is a holder class for performance counters\n-\/\/ that track the data and decisions for the ergonomics policy for the\n-\/\/ parallel scavenge collector.\n-\n-class PSGCAdaptivePolicyCounters : public GCAdaptivePolicyCounters {\n-  friend class VMStructs;\n-\n- private:\n-  \/\/ survivor space vs. tenuring threshold\n-  PerfVariable* _old_promo_size;\n-  PerfVariable* _old_eden_size;\n-  PerfVariable* _avg_promoted_avg_counter;\n-  PerfVariable* _avg_promoted_dev_counter;\n-  PerfVariable* _avg_promoted_padded_avg_counter;\n-  PerfVariable* _avg_pretenured_padded_avg;\n-\n-  \/\/ young gen vs. old gen sizing\n-  PerfVariable* _avg_major_pause;\n-  PerfVariable* _avg_major_interval;\n-  PerfVariable* _live_space;\n-  PerfVariable* _free_space;\n-  PerfVariable* _live_at_last_full_gc_counter;\n-  PerfVariable* _old_capacity;\n-\n-  PerfVariable* _change_old_gen_for_min_pauses;\n-  PerfVariable* _change_young_gen_for_maj_pauses_counter;\n-\n-  PerfVariable* _major_pause_old_slope;\n-  PerfVariable* _minor_pause_old_slope;\n-  PerfVariable* _major_pause_young_slope;\n-\n-  \/\/ Use this time stamp if the gc time stamp is not available.\n-  TimeStamp     _counter_time_stamp;\n-\n- protected:\n-  PSAdaptiveSizePolicy* ps_size_policy() {\n-    return (PSAdaptiveSizePolicy*)_size_policy;\n-  }\n-\n- public:\n-  PSGCAdaptivePolicyCounters(const char* name, int collectors, int generations,\n-                             PSAdaptiveSizePolicy* size_policy);\n-  inline void update_old_capacity(size_t size_in_bytes) {\n-    _old_capacity->set_value(size_in_bytes);\n-  }\n-  inline void update_old_eden_size(size_t old_size) {\n-    _old_eden_size->set_value(old_size);\n-  }\n-  inline void update_old_promo_size(size_t old_size) {\n-    _old_promo_size->set_value(old_size);\n-  }\n-  inline void update_avg_promoted_avg() {\n-    _avg_promoted_avg_counter->set_value(\n-      (jlong)(ps_size_policy()->avg_promoted()->average())\n-    );\n-  }\n-  inline void update_avg_promoted_dev() {\n-    _avg_promoted_dev_counter->set_value(\n-      (jlong)(ps_size_policy()->avg_promoted()->deviation())\n-    );\n-  }\n-  inline void update_avg_promoted_padded_avg() {\n-    _avg_promoted_padded_avg_counter->set_value(\n-      (jlong)(ps_size_policy()->avg_promoted()->padded_average())\n-    );\n-  }\n-\n-  inline void update_avg_pretenured_padded_avg() {\n-    _avg_pretenured_padded_avg->set_value(\n-      (jlong)(ps_size_policy()->_avg_pretenured->padded_average())\n-    );\n-  }\n-  inline void update_change_young_gen_for_maj_pauses() {\n-    _change_young_gen_for_maj_pauses_counter->set_value(\n-      ps_size_policy()->change_young_gen_for_maj_pauses());\n-  }\n-  inline void update_change_old_gen_for_min_pauses() {\n-    _change_old_gen_for_min_pauses->set_value(\n-      ps_size_policy()->change_old_gen_for_min_pauses());\n-  }\n-\n-  \/\/ compute_generations_free_space() statistics\n-\n-  inline void update_avg_major_pause() {\n-    _avg_major_pause->set_value(\n-      (jlong)(ps_size_policy()->_avg_major_pause->average() * 1000.0)\n-    );\n-  }\n-  inline void update_avg_major_interval() {\n-    _avg_major_interval->set_value(\n-      (jlong)(ps_size_policy()->_avg_major_interval->average() * 1000.0)\n-    );\n-  }\n-\n-  inline void update_major_gc_cost_counter() {\n-    _major_gc_cost_counter->set_value(\n-      (jlong)(ps_size_policy()->major_gc_cost() * 100.0)\n-    );\n-  }\n-  inline void update_mutator_cost_counter() {\n-    _mutator_cost_counter->set_value(\n-      (jlong)(ps_size_policy()->mutator_cost() * 100.0)\n-    );\n-  }\n-\n-  inline void update_live_space() {\n-    _live_space->set_value(ps_size_policy()->live_space());\n-  }\n-  inline void update_free_space() {\n-    _free_space->set_value(ps_size_policy()->free_space());\n-  }\n-\n-  inline void update_avg_old_live() {\n-    _avg_old_live_counter->set_value(\n-      (jlong)(ps_size_policy()->avg_old_live()->average())\n-    );\n-  }\n-  \/\/ Scale up all the slopes\n-  inline void update_major_pause_old_slope() {\n-    _major_pause_old_slope->set_value(\n-      (jlong)(ps_size_policy()->major_pause_old_slope() * 1000)\n-    );\n-  }\n-  inline void update_minor_pause_old_slope() {\n-    _minor_pause_old_slope->set_value(\n-      (jlong)(ps_size_policy()->minor_pause_old_slope() * 1000)\n-    );\n-  }\n-  inline void update_major_pause_young_slope() {\n-    _major_pause_young_slope->set_value(\n-      (jlong)(ps_size_policy()->major_pause_young_slope() * 1000)\n-    );\n-  }\n-  inline void update_gc_overhead_limit_exceeded_counter() {\n-    gc_overhead_limit_exceeded_counter()->set_value(\n-      (jlong) ps_size_policy()->gc_overhead_limit_exceeded());\n-  }\n-  inline void update_live_at_last_full_gc_counter() {\n-    _live_at_last_full_gc_counter->set_value(\n-      (jlong)(ps_size_policy()->live_at_last_full_gc()));\n-  }\n-\n-  \/\/ Update all the counters that can be updated from the size policy.\n-  \/\/ This should be called after all policy changes have been made\n-  \/\/ and reflected internally in the size policy.\n-  void update_counters_from_policy();\n-\n-  \/\/ Update counters that can be updated from fields internal to the\n-  \/\/ counter or from globals.  This is distinguished from counters\n-  \/\/ that are updated via input parameters.\n-  void update_counters();\n-};\n-\n-#endif \/\/ SHARE_GC_PARALLEL_PSGCADAPTIVEPOLICYCOUNTERS_HPP\n","filename":"src\/hotspot\/share\/gc\/parallel\/psGCAdaptivePolicyCounters.hpp","additions":0,"deletions":185,"binary":false,"changes":185,"status":"deleted"},{"patch":"@@ -181,0 +181,15 @@\n+void PSOldGen::try_expand_till_size(size_t target_capacity_bytes) {\n+  if (target_capacity_bytes <= capacity_in_bytes()) {\n+    \/\/ Current capacity is enough\n+    return;\n+  }\n+\n+  if (capacity_in_bytes() == max_gen_size()) {\n+    \/\/ Already at max size\n+    return;\n+  }\n+\n+  size_t to_expand_bytes = target_capacity_bytes - capacity_in_bytes();\n+  expand(to_expand_bytes);\n+}\n+\n@@ -287,1 +302,1 @@\n-void PSOldGen::resize(size_t desired_free_space) {\n+void PSOldGen::resize(size_t desired_capacity) {\n@@ -290,5 +305,1 @@\n-  size_t new_size = used_in_bytes() + desired_free_space;\n-  if (new_size < used_in_bytes()) {\n-    \/\/ Overflowed the addition.\n-    new_size = max_gen_size();\n-  }\n+  size_t new_size = desired_capacity;\n@@ -303,2 +314,2 @@\n-    \"desired free: %zu used: %zu\"\n-    \" new size: %zu current size %zu\"\n+    \"used: %zu\"\n+    \" capacity %zu -> %zu\"\n@@ -306,1 +317,1 @@\n-    desired_free_space, used_in_bytes(), new_size, current_size,\n+    used_in_bytes(), current_size, new_size,\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":20,"deletions":9,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -55,9 +55,0 @@\n-  HeapWord* cas_allocate_noexpand(size_t word_size) {\n-    assert_locked_or_safepoint(Heap_lock);\n-    HeapWord* res = object_space()->cas_allocate(word_size);\n-    if (res != nullptr) {\n-      _start_array->update_for_block(res, res + word_size);\n-    }\n-    return res;\n-  }\n-\n@@ -69,2 +60,0 @@\n-  void shrink(size_t bytes);\n-\n@@ -96,0 +85,2 @@\n+  void try_expand_till_size(size_t live_bytes);\n+\n@@ -111,0 +102,1 @@\n+  size_t free_in_bytes() const            { return object_space()->free_in_bytes(); }\n@@ -115,1 +107,3 @@\n-  void resize(size_t desired_free_space);\n+  void resize(size_t desired_capacity);\n+\n+  void shrink(size_t bytes);\n@@ -127,0 +121,10 @@\n+  \/\/ Invoked by mutators before attempting GC.\n+  HeapWord* cas_allocate_noexpand(size_t word_size) {\n+    assert_locked_or_safepoint(Heap_lock);\n+    HeapWord* res = object_space()->cas_allocate(word_size);\n+    if (res != nullptr) {\n+      _start_array->update_for_block(res, res + word_size);\n+    }\n+    return res;\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.hpp","additions":16,"deletions":12,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -662,1 +662,0 @@\n-  \/\/ Increment the invocation count\n@@ -847,2 +846,2 @@\n-  \/\/ Check if all live objs are larger than old-gen.\n-  const bool is_old_gen_overflowing = (total_live_words > old_space->capacity_in_words());\n+  \/\/ Check if all live objs are too much for old-gen.\n+  const bool is_old_gen_too_full = (total_live_words >= old_space->capacity_in_words());\n@@ -860,1 +859,1 @@\n-  if (is_max_on_system_gc || is_old_gen_overflowing || is_interval_ended || is_region_full) {\n+  if (is_max_on_system_gc || is_old_gen_too_full || is_interval_ended || is_region_full) {\n@@ -894,0 +893,8 @@\n+    {\n+      GCTraceTime(Info, gc, phases) tm(\"Summary Phase: expand\", &_gc_timer);\n+      \/\/ Try to expand old-gen in order to fit all live objs and waste.\n+      size_t target_capacity_bytes = total_live_words * HeapWordSize\n+                                   + old_space->capacity_in_bytes() * (MarkSweepDeadRatio \/ 100);\n+      ParallelScavengeHeap::heap()->old_gen()->try_expand_till_size(target_capacity_bytes);\n+    }\n+\n@@ -1004,1 +1011,0 @@\n-  PSYoungGen* young_gen = heap->young_gen();\n@@ -1074,2 +1080,1 @@\n-    \/\/ Let the size policy know we're done\n-    size_policy->major_collection_end(old_gen->used_in_bytes(), gc_cause);\n+    size_policy->major_collection_end();\n@@ -1077,60 +1082,1 @@\n-    if (UseAdaptiveSizePolicy) {\n-      log_debug(gc, ergo)(\"AdaptiveSizeStart: collection: %d \", heap->total_collections());\n-      log_trace(gc, ergo)(\"old_gen_capacity: %zu young_gen_capacity: %zu\",\n-                          old_gen->capacity_in_bytes(), young_gen->capacity_in_bytes());\n-\n-      \/\/ Don't check if the size_policy is ready here.  Let\n-      \/\/ the size_policy check that internally.\n-      if (UseAdaptiveGenerationSizePolicyAtMajorCollection &&\n-          AdaptiveSizePolicy::should_update_promo_stats(gc_cause)) {\n-        \/\/ Swap the survivor spaces if from_space is empty. The\n-        \/\/ resize_young_gen() called below is normally used after\n-        \/\/ a successful young GC and swapping of survivor spaces;\n-        \/\/ otherwise, it will fail to resize the young gen with\n-        \/\/ the current implementation.\n-        if (young_gen->from_space()->is_empty()) {\n-          young_gen->from_space()->clear(SpaceDecorator::Mangle);\n-          young_gen->swap_spaces();\n-        }\n-\n-        \/\/ Calculate optimal free space amounts\n-        assert(young_gen->max_gen_size() >\n-          young_gen->from_space()->capacity_in_bytes() +\n-          young_gen->to_space()->capacity_in_bytes(),\n-          \"Sizes of space in young gen are out-of-bounds\");\n-\n-        size_t young_live = young_gen->used_in_bytes();\n-        size_t eden_live = young_gen->eden_space()->used_in_bytes();\n-        size_t old_live = old_gen->used_in_bytes();\n-        size_t cur_eden = young_gen->eden_space()->capacity_in_bytes();\n-        size_t max_old_gen_size = old_gen->max_gen_size();\n-        size_t max_eden_size = young_gen->max_gen_size() -\n-          young_gen->from_space()->capacity_in_bytes() -\n-          young_gen->to_space()->capacity_in_bytes();\n-\n-        \/\/ Used for diagnostics\n-        size_policy->clear_generation_free_space_flags();\n-\n-        size_policy->compute_generations_free_space(young_live,\n-                                                    eden_live,\n-                                                    old_live,\n-                                                    cur_eden,\n-                                                    max_old_gen_size,\n-                                                    max_eden_size,\n-                                                    true \/* full gc*\/);\n-\n-        size_policy->check_gc_overhead_limit(eden_live,\n-                                             max_old_gen_size,\n-                                             max_eden_size,\n-                                             true \/* full gc*\/,\n-                                             gc_cause,\n-                                             heap->soft_ref_policy());\n-\n-        size_policy->decay_supplemental_growth(true \/* full gc*\/);\n-\n-        heap->resize_old_gen(\n-          size_policy->calculated_old_free_size_in_bytes());\n-\n-        heap->resize_young_gen(size_policy->calculated_eden_size_in_bytes(),\n-                               size_policy->calculated_survivor_size_in_bytes());\n-      }\n+    size_policy->sample_old_gen_used_bytes(MAX2(pre_gc_values.old_gen_used(), old_gen->used_in_bytes()));\n@@ -1138,8 +1084,2 @@\n-      log_debug(gc, ergo)(\"AdaptiveSizeStop: collection: %d \", heap->total_collections());\n-    }\n-\n-    if (UsePerfData) {\n-      PSGCAdaptivePolicyCounters* const counters = heap->gc_policy_counters();\n-      counters->update_counters();\n-      counters->update_old_capacity(old_gen->capacity_in_bytes());\n-      counters->update_young_capacity(young_gen->capacity_in_bytes());\n+    if (UseAdaptiveSizePolicy) {\n+      heap->resize_after_full_gc();\n@@ -1164,0 +1104,2 @@\n+\n+    size_policy->record_gc_pause_end_instant();\n@@ -1166,0 +1108,2 @@\n+  heap->gc_epilogue(true);\n+\n@@ -1173,2 +1117,0 @@\n-  AdaptiveSizePolicyOutput::print(size_policy, heap->total_collections());\n-\n@@ -1589,0 +1531,1 @@\n+          \/\/ Empty space\n@@ -1593,1 +1536,0 @@\n-\n@@ -1637,1 +1579,1 @@\n-  HeapWord* old_dense_prefix_addr = dense_prefix(SpaceId(old_space_id));\n+  HeapWord* const old_dense_prefix_addr = dense_prefix(SpaceId(old_space_id));\n@@ -1730,1 +1672,1 @@\n-  for (unsigned int id = to_space_id; id + 1 > old_space_id; --id) {\n+  for (unsigned int id = last_space_id - 1; id + 1 > old_space_id; --id) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":22,"deletions":80,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -686,0 +686,1 @@\n+  \/\/ By the end of full-gc, all live objs are compacted into the first three spaces, old, eden, and from.\n@@ -687,2 +688,5 @@\n-    old_space_id, eden_space_id,\n-    from_space_id, to_space_id, last_space_id\n+    old_space_id,\n+    eden_space_id,\n+    from_space_id,\n+    to_space_id,\n+    last_space_id\n@@ -691,1 +695,0 @@\n-public:\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -196,0 +196,1 @@\n+  _young_gen_has_alloc_failure = false;\n@@ -254,1 +255,1 @@\n-  if (_young_gen_is_full) {\n+  if (_young_gen_is_full || _young_gen_has_alloc_failure) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+  bool                                _young_gen_has_alloc_failure;\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -210,0 +210,3 @@\n+        if (new_obj == nullptr && !_young_gen_is_full && !_young_gen_has_alloc_failure) {\n+          _young_gen_has_alloc_failure = true;\n+        }\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.inline.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -325,0 +325,1 @@\n+    log_info(gc, ergo)(\"Young-gc might fail so skipping\");\n@@ -350,4 +351,2 @@\n-  if (AdaptiveSizePolicy::should_update_eden_stats(gc_cause)) {\n-    \/\/ Gather the feedback data for eden occupancy.\n-    young_gen->eden_space()->accumulate_statistics();\n-  }\n+  \/\/ Gather the feedback data for eden occupancy.\n+  young_gen->eden_space()->accumulate_statistics();\n@@ -426,1 +425,1 @@\n-      WeakProcessor::weak_oops_do(&ParallelScavengeHeap::heap()->workers(), &_is_alive_closure, &root_closure, 1);\n+      WeakProcessor::weak_oops_do(&heap->workers(), &_is_alive_closure, &root_closure, 1);\n@@ -438,4 +437,3 @@\n-    \/\/ Let the size policy know we're done.  Note that we count promotion\n-    \/\/ failure cleanup time as part of the collection (otherwise, we're\n-    \/\/ implicitly saying it's mutator time).\n-    size_policy->minor_collection_end(gc_cause);\n+    \/\/ This is an underestimate, since it excludes time on auto-resizing. The\n+    \/\/ most expensive part in auto-resizing is commit\/uncommit OS API calls.\n+    size_policy->minor_collection_end(young_gen->eden_space()->capacity_in_bytes());\n@@ -450,0 +448,1 @@\n+      assert(old_gen->used_in_bytes() >= pre_gc_values.old_gen_used(), \"inv\");\n@@ -452,0 +451,1 @@\n+      size_policy->sample_old_gen_used_bytes(old_gen->used_in_bytes());\n@@ -453,3 +453,0 @@\n-      \/\/ A successful scavenge should restart the GC time limit count which is\n-      \/\/ for full GC's.\n-      size_policy->reset_gc_overhead_limit_count();\n@@ -457,1 +454,2 @@\n-        \/\/ Calculate the new survivor size and tenuring threshold\n+        _tenuring_threshold = size_policy->compute_tenuring_threshold(_survivor_overflow,\n+                                                                      _tenuring_threshold);\n@@ -459,3 +457,1 @@\n-        log_debug(gc, ergo)(\"AdaptiveSizeStart:  collection: %d \", heap->total_collections());\n-        log_trace(gc, ergo)(\"old_gen_capacity: %zu young_gen_capacity: %zu\",\n-                            old_gen->capacity_in_bytes(), young_gen->capacity_in_bytes());\n+        log_debug(gc, age)(\"New threshold %u (max threshold %u)\", _tenuring_threshold, MaxTenuringThreshold);\n@@ -463,11 +459,3 @@\n-        if (UsePerfData) {\n-          PSGCAdaptivePolicyCounters* counters = heap->gc_policy_counters();\n-          counters->update_old_eden_size(\n-            size_policy->calculated_eden_size_in_bytes());\n-          counters->update_old_promo_size(\n-            size_policy->calculated_promo_size_in_bytes());\n-          counters->update_old_capacity(old_gen->capacity_in_bytes());\n-          counters->update_young_capacity(young_gen->capacity_in_bytes());\n-          counters->update_survived(survived);\n-          counters->update_promoted(promoted);\n-          counters->update_survivor_overflowed(_survivor_overflow);\n+        if (young_gen->is_from_to_layout()) {\n+          size_policy->print_stats(_survivor_overflow);\n+          heap->resize_after_young_gc(_survivor_overflow);\n@@ -476,23 +464,0 @@\n-        size_t max_young_size = young_gen->max_gen_size();\n-\n-        \/\/ Deciding a free ratio in the young generation is tricky, so if\n-        \/\/ MinHeapFreeRatio or MaxHeapFreeRatio are in use (implicating\n-        \/\/ that the old generation size may have been limited because of them) we\n-        \/\/ should then limit our young generation size using NewRatio to have it\n-        \/\/ follow the old generation size.\n-        if (MinHeapFreeRatio != 0 || MaxHeapFreeRatio != 100) {\n-          max_young_size = MIN2(old_gen->capacity_in_bytes() \/ NewRatio,\n-                                young_gen->max_gen_size());\n-        }\n-\n-        size_t survivor_limit =\n-          size_policy->max_survivor_size(max_young_size);\n-        _tenuring_threshold =\n-          size_policy->compute_survivor_space_size_and_threshold(_survivor_overflow,\n-                                                                 _tenuring_threshold,\n-                                                                 survivor_limit);\n-\n-        log_debug(gc, age)(\"Desired survivor size %zu bytes, new threshold %u (max threshold %u)\",\n-                           size_policy->calculated_survivor_size_in_bytes(),\n-                           _tenuring_threshold, MaxTenuringThreshold);\n-\n@@ -500,3 +465,3 @@\n-          PSGCAdaptivePolicyCounters* counters = heap->gc_policy_counters();\n-          counters->update_tenuring_threshold(_tenuring_threshold);\n-          counters->update_survivor_size_counters();\n+          GCPolicyCounters* counters = ParallelScavengeHeap::gc_policy_counters();\n+          counters->tenuring_threshold()->set_value(_tenuring_threshold);\n+          counters->desired_survivor_size()->set_value(young_gen->from_space()->capacity_in_bytes());\n@@ -505,36 +470,6 @@\n-        \/\/ Do call at minor collections?\n-        \/\/ Don't check if the size_policy is ready at this\n-        \/\/ level.  Let the size_policy check that internally.\n-        if (UseAdaptiveGenerationSizePolicyAtMinorCollection &&\n-            AdaptiveSizePolicy::should_update_eden_stats(gc_cause)) {\n-          \/\/ Calculate optimal free space amounts\n-          assert(young_gen->max_gen_size() >\n-                 young_gen->from_space()->capacity_in_bytes() +\n-                 young_gen->to_space()->capacity_in_bytes(),\n-                 \"Sizes of space in young gen are out-of-bounds\");\n-\n-          size_t young_live = young_gen->used_in_bytes();\n-          size_t eden_live = young_gen->eden_space()->used_in_bytes();\n-          size_t cur_eden = young_gen->eden_space()->capacity_in_bytes();\n-          size_t max_old_gen_size = old_gen->max_gen_size();\n-          size_t max_eden_size = max_young_size -\n-                                 young_gen->from_space()->capacity_in_bytes() -\n-                                 young_gen->to_space()->capacity_in_bytes();\n-\n-          \/\/ Used for diagnostics\n-          size_policy->clear_generation_free_space_flags();\n-\n-          size_policy->compute_eden_space_size(young_live,\n-                                               eden_live,\n-                                               cur_eden,\n-                                               max_eden_size,\n-                                               false \/* not full gc*\/);\n-\n-          size_policy->check_gc_overhead_limit(eden_live,\n-                                               max_old_gen_size,\n-                                               max_eden_size,\n-                                               false \/* not full gc*\/,\n-                                               gc_cause,\n-                                               heap->soft_ref_policy());\n-\n-          size_policy->decay_supplemental_growth(false \/* not full gc*\/);\n+        {\n+          \/\/ In case the counter overflows\n+          uint num_minor_gcs = heap->total_collections() > heap->total_full_collections()\n+                                 ? heap->total_collections() - heap->total_full_collections()\n+                                 : 1;\n+          size_policy->decay_supplemental_growth(num_minor_gcs);\n@@ -542,13 +477,0 @@\n-        \/\/ Resize the young generation at every collection\n-        \/\/ even if new sizes have not been calculated.  This is\n-        \/\/ to allow resizes that may have been inhibited by the\n-        \/\/ relative location of the \"to\" and \"from\" spaces.\n-\n-        \/\/ Resizing the old gen at young collections can cause increases\n-        \/\/ that don't feed back to the generation sizing policy until\n-        \/\/ a full collection.  Don't resize the old gen here.\n-\n-        heap->resize_young_gen(size_policy->calculated_eden_size_in_bytes(),\n-                               size_policy->calculated_survivor_size_in_bytes());\n-\n-        log_debug(gc, ergo)(\"AdaptiveSizeStop: collection: %d \", heap->total_collections());\n@@ -563,2 +485,0 @@\n-      heap->gc_policy_counters()->update_counters();\n-\n@@ -568,0 +488,2 @@\n+\n+      heap->gc_epilogue(false);\n@@ -574,0 +496,2 @@\n+    size_policy->record_gc_pause_end_instant();\n+\n@@ -592,2 +516,0 @@\n-  AdaptiveSizePolicyOutput::print(size_policy, heap->total_collections());\n-\n@@ -615,1 +537,1 @@\n-    \/\/ To-space is not empty; should run full-gc instead.\n+    log_debug(gc, ergo)(\"To-space is not empty; should run full-gc instead.\");\n@@ -628,1 +550,1 @@\n-  log_trace(ergo)(\"%s scavenge: average_promoted %zu padded_average_promoted %zu free in old gen %zu\",\n+  log_trace(gc, ergo)(\"%s scavenge: average_promoted %zu padded_average_promoted %zu free in old gen %zu\",\n@@ -662,1 +584,1 @@\n-  assert(old_gen->reserved().end() <= young_gen->eden_space()->bottom(),\n+  assert(old_gen->reserved().end() == young_gen->reserved().start(),\n@@ -664,1 +586,1 @@\n-  set_young_generation_boundary(young_gen->eden_space()->bottom());\n+  set_young_generation_boundary(young_gen->reserved().start());\n","filename":"src\/hotspot\/share\/gc\/parallel\/psScavenge.cpp","additions":32,"deletions":110,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"logging\/log.hpp\"\n@@ -64,0 +65,2 @@\n+  } else {\n+    log_warning(gc)(\"PSVirtualSpace::expand_by: to commit %zu bytes failed\", bytes);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psVirtualspace.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -174,6 +174,4 @@\n-  \/\/ Initial layout is Eden, to, from. After swapping survivor spaces,\n-  \/\/ that leaves us with Eden, from, to, which is step one in our two\n-  \/\/ step resize-with-live-data procedure.\n-  char *eden_start = virtual_space()->low();\n-  char *to_start   = eden_start + eden_size;\n-  char *from_start = to_start   + survivor_size;\n+  \/\/ Layout: to, from, eden\n+  char *to_start   = virtual_space()->low();\n+  char *to_end     = to_start + survivor_size;\n+  char *from_start = to_end;\n@@ -181,0 +179,4 @@\n+  char *eden_start = from_end;\n+  char *eden_end   = eden_start + eden_size;\n+\n+  assert(eden_end == virtual_space()->high(), \"just checking\");\n@@ -182,1 +184,0 @@\n-  assert(from_end == virtual_space()->high(), \"just checking\");\n@@ -187,2 +188,2 @@\n-  MemRegion eden_mr((HeapWord*)eden_start, (HeapWord*)to_start);\n-  MemRegion to_mr  ((HeapWord*)to_start, (HeapWord*)from_start);\n+  MemRegion eden_mr((HeapWord*)eden_start, (HeapWord*)eden_end);\n+  MemRegion to_mr  ((HeapWord*)to_start, (HeapWord*)to_end);\n@@ -199,1 +200,0 @@\n-  \/\/ Currently, our eden size cannot shrink to zero\n@@ -202,1 +202,13 @@\n-  guarantee(to_space()->capacity_in_bytes() >= SpaceAlignment, \"to too small\");\n+  assert(from_space()->capacity_in_bytes() == to_space()->capacity_in_bytes(), \"inv\");\n+\n+  HeapWord* eden_bottom = eden_space()->bottom();\n+  HeapWord* eden_end    = eden_space()->end();\n+  HeapWord* eden_top    = eden_space()->top();\n+\n+  HeapWord* from_bottom = from_space()->bottom();\n+  HeapWord* from_end    = from_space()->end();\n+  HeapWord* from_top    = from_space()->top();\n+\n+  HeapWord* to_bottom   = to_space()->bottom();\n+  HeapWord* to_end      = to_space()->end();\n+  HeapWord* to_top      = to_space()->top();\n@@ -204,7 +216,3 @@\n-  \/\/ Relationship of spaces to each other\n-  char* eden_start = (char*)eden_space()->bottom();\n-  char* eden_end   = (char*)eden_space()->end();\n-  char* from_start = (char*)from_space()->bottom();\n-  char* from_end   = (char*)from_space()->end();\n-  char* to_start   = (char*)to_space()->bottom();\n-  char* to_end     = (char*)to_space()->end();\n+  assert(eden_bottom <= eden_top && eden_top <= eden_end, \"inv\");\n+  assert(from_bottom <= from_top && from_top <= from_end, \"inv\");\n+  assert(to_bottom <= to_top && to_top <= to_end, \"inv\");\n@@ -212,4 +220,6 @@\n-  guarantee(eden_start >= virtual_space()->low(), \"eden bottom\");\n-  guarantee(eden_start < eden_end, \"eden space consistency\");\n-  guarantee(from_start < from_end, \"from space consistency\");\n-  guarantee(to_start < to_end, \"to space consistency\");\n+  \/\/ Relationship of spaces to each other; from\/to, eden\n+  guarantee((char*)MIN2(from_bottom, to_bottom) == virtual_space()->low(), \"inv\");\n+\n+  guarantee(is_aligned(eden_bottom, SpaceAlignment), \"inv\");\n+  guarantee(is_aligned(from_bottom, SpaceAlignment), \"inv\");\n+  guarantee(is_aligned(  to_bottom, SpaceAlignment), \"inv\");\n@@ -218,5 +228,4 @@\n-  if (from_start < to_start) {\n-    \/\/ Eden, from, to\n-    guarantee(eden_end <= from_start, \"eden\/from boundary\");\n-    guarantee(from_end <= to_start,   \"from\/to boundary\");\n-    guarantee(to_end <= virtual_space()->high(), \"to end\");\n+  if (from_bottom < to_bottom) {\n+    \/\/ from, to\n+    guarantee(from_end == to_bottom, \"inv\");\n+    guarantee(to_end == eden_bottom, \"inv\");\n@@ -224,4 +233,3 @@\n-    \/\/ Eden, to, from\n-    guarantee(eden_end <= to_start, \"eden\/to boundary\");\n-    guarantee(to_end <= from_start, \"to\/from boundary\");\n-    guarantee(from_end <= virtual_space()->high(), \"from end\");\n+    \/\/ to, from\n+    guarantee(to_end == from_bottom, \"inv\");\n+    guarantee(from_end == eden_bottom, \"inv\");\n@@ -229,0 +237,2 @@\n+  guarantee((char*)eden_end <= virtual_space()->high(), \"inv\");\n+  guarantee(is_aligned(eden_end, SpaceAlignment), \"inv\");\n@@ -232,3 +242,1 @@\n-    (eden_space()->capacity_in_bytes() +\n-     to_space()->capacity_in_bytes() +\n-     from_space()->capacity_in_bytes()), \"Committed size is inconsistent\");\n+    (eden_space()->capacity_in_bytes() + 2 * from_space()->capacity_in_bytes()), \"Committed size is inconsistent\");\n@@ -237,6 +245,0 @@\n-  char* eden_top = (char*)eden_space()->top();\n-  char* from_top = (char*)from_space()->top();\n-  char* to_top = (char*)to_space()->top();\n-  assert(eden_top <= virtual_space()->high(), \"eden top\");\n-  assert(from_top <= virtual_space()->high(), \"from top\");\n-  assert(to_top <= virtual_space()->high(), \"to top\");\n@@ -248,6 +250,143 @@\n-void PSYoungGen::resize(size_t eden_size, size_t survivor_size) {\n-  \/\/ Resize the generation if needed. If the generation resize\n-  \/\/ reports false, do not attempt to resize the spaces.\n-  if (resize_generation(eden_size, survivor_size)) {\n-    \/\/ Then we lay out the spaces inside the generation\n-    resize_spaces(eden_size, survivor_size);\n+bool PSYoungGen::try_expand_to_hold(size_t word_size) {\n+  assert(eden_space()->free_in_words() < word_size, \"precondition\");\n+\n+  \/\/ For logging purpose\n+  size_t original_committed_size = virtual_space()->committed_size();\n+\n+  assert(is_aligned(virtual_space()->committed_high_addr(), SpaceAlignment), \"inv\");\n+  if (pointer_delta(virtual_space()->committed_high_addr(), eden_space()->top(), sizeof(HeapWord)) >= word_size) {\n+    \/\/ eden needs expansion but no OS committing\n+    assert(virtual_space()->committed_high_addr() > (char*)eden_space()->end(), \"inv\");\n+  } else {\n+    \/\/ eden needs OS committing and expansion\n+    assert(virtual_space()->reserved_high_addr() > virtual_space()->committed_high_addr(), \"inv\");\n+\n+    const size_t existing_free_in_eden = eden_space()->free_in_words();\n+    assert(existing_free_in_eden < word_size, \"inv\");\n+\n+    size_t delta_words = word_size - existing_free_in_eden;\n+    size_t delta_bytes = delta_words * HeapWordSize;\n+    delta_bytes = align_up(delta_bytes, virtual_space()->alignment());\n+    if (!virtual_space()->expand_by(delta_bytes)) {\n+      \/\/ Expansion fails at OS level.\n+      return false;\n+    }\n+\n+    assert(is_aligned(virtual_space()->committed_high_addr(), SpaceAlignment), \"inv\");\n+  }\n+\n+  HeapWord* new_eden_end = (HeapWord*) virtual_space()->committed_high_addr();\n+  assert(new_eden_end > eden_space()->end(), \"inv\");\n+  MemRegion edenMR = MemRegion(eden_space()->bottom(), new_eden_end);\n+\n+  eden_space()->initialize(edenMR,\n+                           eden_space()->is_empty(),\n+                           SpaceDecorator::DontMangle,\n+                           MutableSpace::SetupPages,\n+                           &ParallelScavengeHeap::heap()->workers());\n+\n+  if (ZapUnusedHeapArea) {\n+    eden_space()->mangle_unused_area();\n+  }\n+  post_resize();\n+  log_debug(gc, ergo)(\"PSYoung size changed (eden expansion): %zuK->%zuK\",\n+                      original_committed_size \/ K, virtual_space()->committed_size() \/ K);\n+  return true;\n+}\n+\n+HeapWord* PSYoungGen::expand_and_allocate(size_t word_size) {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+  assert(Thread::current()->is_VM_thread(), \"precondition\");\n+\n+  {\n+    size_t available_word_size = pointer_delta(virtual_space()->reserved_high_addr(),\n+                                               eden_space()->top(),\n+                                               sizeof(HeapWord));\n+    if (word_size > available_word_size) {\n+      return nullptr;\n+    }\n+  }\n+\n+  if (eden_space()->free_in_words() < word_size) {\n+    if (!try_expand_to_hold(word_size)) {\n+      return nullptr;\n+    }\n+  }\n+\n+  HeapWord* result = eden_space()->cas_allocate(word_size);\n+  assert(result, \"inv\");\n+  return result;\n+}\n+\n+void PSYoungGen::compute_desired_sizes(bool is_survivor_overflowing,\n+                                       size_t& eden_size,\n+                                       size_t& survivor_size) {\n+  assert(eden_space()->is_empty() && to_space()->is_empty(), \"precondition\");\n+  assert(is_from_to_layout(), \"precondition\");\n+\n+  \/\/ Current sizes for all three spaces\n+  const size_t current_eden_size = eden_space()->capacity_in_bytes();\n+  assert(from_space()->capacity_in_bytes() == to_space()->capacity_in_bytes(), \"inv\");\n+  const size_t current_survivor_size = from_space()->capacity_in_bytes();\n+  assert(current_eden_size + 2 * current_survivor_size <= max_gen_size(), \"inv\");\n+\n+  PSAdaptiveSizePolicy* size_policy = ParallelScavengeHeap::heap()->size_policy();\n+\n+  \/\/ eden-space\n+  eden_size = size_policy->compute_desired_eden_size(is_survivor_overflowing, current_eden_size);\n+  eden_size = align_up(eden_size, SpaceAlignment);\n+  assert(eden_size >= SpaceAlignment, \"inv\");\n+\n+  survivor_size = size_policy->compute_desired_survivor_size(current_survivor_size, max_gen_size());\n+  survivor_size = MAX3(survivor_size,\n+                       from_space()->used_in_bytes(),\n+                       SpaceAlignment);\n+  survivor_size = align_up(survivor_size, SpaceAlignment);\n+\n+  log_debug(gc, ergo)(\"Desired size eden: %zu K, survivor: %zu K\", eden_size\/K, survivor_size\/K);\n+\n+  const size_t new_gen_size = eden_size + 2 * survivor_size;\n+  if (new_gen_size < min_gen_size()) {\n+    \/\/ Keep survivor and adjust eden to meet min-gen-size\n+    eden_size = min_gen_size() - 2 * survivor_size;\n+  } else if (max_gen_size() < new_gen_size) {\n+    log_info(gc, ergo)(\"Requested sizes exceeds MaxNewSize (K): %zu vs %zu)\", new_gen_size\/K, max_gen_size()\/K);\n+    \/\/ New capacity would exceed max; need to revise these desired sizes.\n+    \/\/ Favor survivor over eden in order to reduce promotion (overflow).\n+    if (2 * survivor_size >= max_gen_size()) {\n+      \/\/ If requested survivor size is too large\n+      survivor_size = align_down((max_gen_size() - SpaceAlignment) \/ 2, SpaceAlignment);\n+      eden_size = max_gen_size() - 2 * survivor_size;\n+    } else {\n+      \/\/ Respect survivor size and reduce eden\n+      eden_size = max_gen_size() - 2 * survivor_size;\n+    }\n+  }\n+\n+  assert(eden_size >= SpaceAlignment, \"inv\");\n+  assert(survivor_size >= SpaceAlignment, \"inv\");\n+\n+  assert(is_aligned(eden_size, SpaceAlignment), \"inv\");\n+  assert(is_aligned(survivor_size, SpaceAlignment), \"inv\");\n+}\n+\n+void PSYoungGen::resize_inner(size_t desired_eden_size,\n+                              size_t desired_survivor_size) {\n+  assert(desired_eden_size != 0, \"precondition\");\n+  assert(desired_survivor_size != 0, \"precondition\");\n+\n+  size_t desired_young_gen_size = desired_eden_size + 2 * desired_survivor_size;\n+\n+  assert(desired_young_gen_size >= min_gen_size(), \"precondition\");\n+  assert(desired_young_gen_size <= max_gen_size(), \"precondition\");\n+\n+  if (eden_space()->capacity_in_bytes() == desired_eden_size\n+      && from_space()->capacity_in_bytes() == desired_survivor_size) {\n+    \/\/ no change\n+    return;\n+  }\n+\n+  bool resize_success = resize_generation(desired_young_gen_size);\n+\n+  if (resize_success) {\n+    resize_spaces(desired_eden_size, desired_survivor_size);\n@@ -261,1 +400,1 @@\n-                        eden_size, survivor_size, used_in_bytes(), capacity_in_bytes(),\n+                        desired_eden_size, desired_survivor_size, used_in_bytes(), capacity_in_bytes(),\n@@ -266,0 +405,13 @@\n+void PSYoungGen::resize_after_young_gc(bool is_survivor_overflowing) {\n+  assert(eden_space()->is_empty(), \"precondition\");\n+  assert(to_space()->is_empty(), \"precondition\");\n+\n+  size_t desired_eden_size = 0;\n+  size_t desired_survivor_size = 0;\n+\n+  compute_desired_sizes(is_survivor_overflowing,\n+                        desired_eden_size,\n+                        desired_survivor_size);\n+\n+  resize_inner(desired_eden_size, desired_survivor_size);\n+}\n@@ -267,1 +419,1 @@\n-bool PSYoungGen::resize_generation(size_t eden_size, size_t survivor_size) {\n+bool PSYoungGen::resize_generation(size_t desired_young_gen_size) {\n@@ -272,6 +424,0 @@\n-  \/\/ There used to be this guarantee there.\n-  \/\/ guarantee ((eden_size + 2*survivor_size)  <= max_gen_size(), \"incorrect input arguments\");\n-  \/\/ Code below forces this requirement.  In addition the desired eden\n-  \/\/ size and desired survivor sizes are desired goals and may\n-  \/\/ exceed the total generation size.\n-\n@@ -280,5 +426,3 @@\n-  \/\/ Adjust new generation size\n-  const size_t eden_plus_survivors =\n-          align_up(eden_size + 2 * survivor_size, alignment);\n-  size_t desired_size = clamp(eden_plus_survivors, min_gen_size(), max_gen_size());\n-  assert(desired_size <= max_gen_size(), \"just checking\");\n+  size_t desired_size = clamp(align_up(desired_young_gen_size, alignment),\n+                              min_gen_size(),\n+                              max_gen_size());\n@@ -306,9 +450,2 @@\n-\n-    desired_change = limit_gen_shrink(desired_change);\n-\n-    if (desired_change > 0) {\n-      virtual_space()->shrink_by(desired_change);\n-      reset_survivors_after_shrink();\n-\n-      size_changed = true;\n-    }\n+    virtual_space()->shrink_by(desired_change);\n+    size_changed = true;\n@@ -329,1 +466,1 @@\n-  guarantee(eden_plus_survivors <= virtual_space()->committed_size() ||\n+  guarantee(desired_young_gen_size <= virtual_space()->committed_size() ||\n@@ -335,76 +472,0 @@\n-#ifndef PRODUCT\n-\/\/ In the numa case eden is not mangled so a survivor space\n-\/\/ moving into a region previously occupied by a survivor\n-\/\/ may find an unmangled region.  Also in the PS case eden\n-\/\/ to-space and from-space may not touch (i.e., there may be\n-\/\/ gaps between them due to movement while resizing the\n-\/\/ spaces).  Those gaps must be mangled.\n-void PSYoungGen::mangle_survivors(MutableSpace* s1,\n-                                  MemRegion s1MR,\n-                                  MutableSpace* s2,\n-                                  MemRegion s2MR) {\n-  \/\/ Check eden and gap between eden and from-space, in deciding\n-  \/\/ what to mangle in from-space.  Check the gap between from-space\n-  \/\/ and to-space when deciding what to mangle.\n-  \/\/\n-  \/\/      +--------+   +----+    +---+\n-  \/\/      | eden   |   |s1  |    |s2 |\n-  \/\/      +--------+   +----+    +---+\n-  \/\/                 +-------+ +-----+\n-  \/\/                 |s1MR   | |s2MR |\n-  \/\/                 +-------+ +-----+\n-  \/\/ All of survivor-space is properly mangled so find the\n-  \/\/ upper bound on the mangling for any portion above current s1.\n-  HeapWord* delta_end = MIN2(s1->bottom(), s1MR.end());\n-  MemRegion delta1_left;\n-  if (s1MR.start() < delta_end) {\n-    delta1_left = MemRegion(s1MR.start(), delta_end);\n-    s1->mangle_region(delta1_left);\n-  }\n-  \/\/ Find any portion to the right of the current s1.\n-  HeapWord* delta_start = MAX2(s1->end(), s1MR.start());\n-  MemRegion delta1_right;\n-  if (delta_start < s1MR.end()) {\n-    delta1_right = MemRegion(delta_start, s1MR.end());\n-    s1->mangle_region(delta1_right);\n-  }\n-\n-  \/\/ Similarly for the second survivor space except that\n-  \/\/ any of the new region that overlaps with the current\n-  \/\/ region of the first survivor space has already been\n-  \/\/ mangled.\n-  delta_end = MIN2(s2->bottom(), s2MR.end());\n-  delta_start = MAX2(s2MR.start(), s1->end());\n-  MemRegion delta2_left;\n-  if (s2MR.start() < delta_end) {\n-    delta2_left = MemRegion(s2MR.start(), delta_end);\n-    s2->mangle_region(delta2_left);\n-  }\n-  delta_start = MAX2(s2->end(), s2MR.start());\n-  MemRegion delta2_right;\n-  if (delta_start < s2MR.end()) {\n-    s2->mangle_region(delta2_right);\n-  }\n-\n-  \/\/ s1\n-  log_develop_trace(gc)(\"Current region: [\" PTR_FORMAT \", \" PTR_FORMAT \") \"\n-    \"New region: [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-    p2i(s1->bottom()), p2i(s1->end()),\n-    p2i(s1MR.start()), p2i(s1MR.end()));\n-  log_develop_trace(gc)(\"    Mangle before: [\" PTR_FORMAT \", \"\n-    PTR_FORMAT \")  Mangle after: [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-    p2i(delta1_left.start()), p2i(delta1_left.end()),\n-    p2i(delta1_right.start()), p2i(delta1_right.end()));\n-\n-  \/\/ s2\n-  log_develop_trace(gc)(\"Current region: [\" PTR_FORMAT \", \" PTR_FORMAT \") \"\n-    \"New region: [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-    p2i(s2->bottom()), p2i(s2->end()),\n-    p2i(s2MR.start()), p2i(s2MR.end()));\n-  log_develop_trace(gc)(\"    Mangle before: [\" PTR_FORMAT \", \"\n-    PTR_FORMAT \")  Mangle after: [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-    p2i(delta2_left.start()), p2i(delta2_left.end()),\n-    p2i(delta2_right.start()), p2i(delta2_right.end()));\n-}\n-#endif \/\/ NOT PRODUCT\n-\n@@ -413,186 +474,15 @@\n-  assert(UseAdaptiveSizePolicy, \"sanity check\");\n-  assert(requested_eden_size > 0  && requested_survivor_size > 0,\n-         \"just checking\");\n-\n-  \/\/ We require eden and to space to be empty\n-  if ((!eden_space()->is_empty()) || (!to_space()->is_empty())) {\n-    return;\n-  }\n-\n-  log_trace(gc, ergo)(\"PSYoungGen::resize_spaces(requested_eden_size: %zu, requested_survivor_size: %zu)\",\n-                      requested_eden_size, requested_survivor_size);\n-  log_trace(gc, ergo)(\"    eden: [\" PTR_FORMAT \"..\" PTR_FORMAT \") %zu\",\n-                      p2i(eden_space()->bottom()),\n-                      p2i(eden_space()->end()),\n-                      pointer_delta(eden_space()->end(),\n-                                    eden_space()->bottom(),\n-                                    sizeof(char)));\n-  log_trace(gc, ergo)(\"    from: [\" PTR_FORMAT \"..\" PTR_FORMAT \") %zu\",\n-                      p2i(from_space()->bottom()),\n-                      p2i(from_space()->end()),\n-                      pointer_delta(from_space()->end(),\n-                                    from_space()->bottom(),\n-                                    sizeof(char)));\n-  log_trace(gc, ergo)(\"      to: [\" PTR_FORMAT \"..\" PTR_FORMAT \") %zu\",\n-                      p2i(to_space()->bottom()),\n-                      p2i(to_space()->end()),\n-                      pointer_delta(  to_space()->end(),\n-                                      to_space()->bottom(),\n-                                      sizeof(char)));\n-\n-  \/\/ There's nothing to do if the new sizes are the same as the current\n-  if (requested_survivor_size == to_space()->capacity_in_bytes() &&\n-      requested_survivor_size == from_space()->capacity_in_bytes() &&\n-      requested_eden_size == eden_space()->capacity_in_bytes()) {\n-    log_trace(gc, ergo)(\"    capacities are the right sizes, returning\");\n-    return;\n-  }\n-\n-  char* eden_start = (char*)eden_space()->bottom();\n-  char* eden_end   = (char*)eden_space()->end();\n-  char* from_start = (char*)from_space()->bottom();\n-  char* from_end   = (char*)from_space()->end();\n-  char* to_start   = (char*)to_space()->bottom();\n-  char* to_end     = (char*)to_space()->end();\n-\n-  const bool maintain_minimum =\n-    (requested_eden_size + 2 * requested_survivor_size) <= min_gen_size();\n-\n-  bool eden_from_to_order = from_start < to_start;\n-  \/\/ Check whether from space is below to space\n-  if (eden_from_to_order) {\n-    \/\/ Eden, from, to\n-    eden_from_to_order = true;\n-    log_trace(gc, ergo)(\"  Eden, from, to:\");\n-\n-    \/\/ Set eden\n-    \/\/ \"requested_eden_size\" is a goal for the size of eden\n-    \/\/ and may not be attainable.  \"eden_size\" below is\n-    \/\/ calculated based on the location of from-space and\n-    \/\/ the goal for the size of eden.  from-space is\n-    \/\/ fixed in place because it contains live data.\n-    \/\/ The calculation is done this way to avoid 32bit\n-    \/\/ overflow (i.e., eden_start + requested_eden_size\n-    \/\/ may too large for representation in 32bits).\n-    size_t eden_size;\n-    if (maintain_minimum) {\n-      \/\/ Only make eden larger than the requested size if\n-      \/\/ the minimum size of the generation has to be maintained.\n-      \/\/ This could be done in general but policy at a higher\n-      \/\/ level is determining a requested size for eden and that\n-      \/\/ should be honored unless there is a fundamental reason.\n-      eden_size = pointer_delta(from_start,\n-                                eden_start,\n-                                sizeof(char));\n-    } else {\n-      eden_size = MIN2(requested_eden_size,\n-                       pointer_delta(from_start, eden_start, sizeof(char)));\n-    }\n-\n-    eden_end = eden_start + eden_size;\n-    assert(eden_end >= eden_start, \"addition overflowed\");\n-\n-    \/\/ To may resize into from space as long as it is clear of live data.\n-    \/\/ From space must remain page aligned, though, so we need to do some\n-    \/\/ extra calculations.\n-\n-    \/\/ First calculate an optimal to-space\n-    to_end   = (char*)virtual_space()->high();\n-    to_start = (char*)pointer_delta(to_end, (char*)requested_survivor_size,\n-                                    sizeof(char));\n-\n-    \/\/ Does the optimal to-space overlap from-space?\n-    if (to_start < (char*)from_space()->end()) {\n-      \/\/ Calculate the minimum offset possible for from_end\n-      size_t from_size = pointer_delta(from_space()->top(), from_start, sizeof(char));\n-\n-      \/\/ Should we be in this method if from_space is empty? Why not the set_space method? FIX ME!\n-      if (from_size == 0) {\n-        from_size = SpaceAlignment;\n-      } else {\n-        from_size = align_up(from_size, SpaceAlignment);\n-      }\n-\n-      from_end = from_start + from_size;\n-      assert(from_end > from_start, \"addition overflow or from_size problem\");\n-\n-      guarantee(from_end <= (char*)from_space()->end(), \"from_end moved to the right\");\n-\n-      \/\/ Now update to_start with the new from_end\n-      to_start = MAX2(from_end, to_start);\n-    }\n-\n-    guarantee(to_start != to_end, \"to space is zero sized\");\n-\n-    log_trace(gc, ergo)(\"    [eden_start .. eden_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(eden_start),\n-                        p2i(eden_end),\n-                        pointer_delta(eden_end, eden_start, sizeof(char)));\n-    log_trace(gc, ergo)(\"    [from_start .. from_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(from_start),\n-                        p2i(from_end),\n-                        pointer_delta(from_end, from_start, sizeof(char)));\n-    log_trace(gc, ergo)(\"    [  to_start ..   to_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(to_start),\n-                        p2i(to_end),\n-                        pointer_delta(  to_end,   to_start, sizeof(char)));\n-  } else {\n-    \/\/ Eden, to, from\n-    log_trace(gc, ergo)(\"  Eden, to, from:\");\n-\n-    \/\/ To space gets priority over eden resizing. Note that we position\n-    \/\/ to space as if we were able to resize from space, even though from\n-    \/\/ space is not modified.\n-    \/\/ Giving eden priority was tried and gave poorer performance.\n-    to_end   = (char*)pointer_delta(virtual_space()->high(),\n-                                    (char*)requested_survivor_size,\n-                                    sizeof(char));\n-    to_end   = MIN2(to_end, from_start);\n-    to_start = (char*)pointer_delta(to_end, (char*)requested_survivor_size,\n-                                    sizeof(char));\n-    \/\/ if the space sizes are to be increased by several times then\n-    \/\/ 'to_start' will point beyond the young generation. In this case\n-    \/\/ 'to_start' should be adjusted.\n-    to_start = MAX2(to_start, eden_start + SpaceAlignment);\n-\n-    \/\/ Compute how big eden can be, then adjust end.\n-    \/\/ See  comments above on calculating eden_end.\n-    size_t eden_size;\n-    if (maintain_minimum) {\n-      eden_size = pointer_delta(to_start, eden_start, sizeof(char));\n-    } else {\n-      eden_size = MIN2(requested_eden_size,\n-                       pointer_delta(to_start, eden_start, sizeof(char)));\n-    }\n-    eden_end = eden_start + eden_size;\n-    assert(eden_end >= eden_start, \"addition overflowed\");\n-\n-    \/\/ Could choose to not let eden shrink\n-    \/\/ to_start = MAX2(to_start, eden_end);\n-\n-    \/\/ Don't let eden shrink down to 0 or less.\n-    eden_end = MAX2(eden_end, eden_start + SpaceAlignment);\n-    to_start = MAX2(to_start, eden_end);\n-\n-    log_trace(gc, ergo)(\"    [eden_start .. eden_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(eden_start),\n-                        p2i(eden_end),\n-                        pointer_delta(eden_end, eden_start, sizeof(char)));\n-    log_trace(gc, ergo)(\"    [  to_start ..   to_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(to_start),\n-                        p2i(to_end),\n-                        pointer_delta(  to_end,   to_start, sizeof(char)));\n-    log_trace(gc, ergo)(\"    [from_start .. from_end): [\" PTR_FORMAT \" .. \" PTR_FORMAT \") %zu\",\n-                        p2i(from_start),\n-                        p2i(from_end),\n-                        pointer_delta(from_end, from_start, sizeof(char)));\n-  }\n-\n-\n-  guarantee((HeapWord*)from_start <= from_space()->bottom(),\n-            \"from start moved to the right\");\n-  guarantee((HeapWord*)from_end >= from_space()->top(),\n-            \"from end moved into live data\");\n-  assert(is_object_aligned(eden_start), \"checking alignment\");\n-  assert(is_object_aligned(from_start), \"checking alignment\");\n-  assert(is_object_aligned(to_start), \"checking alignment\");\n+  assert(requested_eden_size > 0 && requested_survivor_size > 0,\n+         \"precondition\");\n+  assert(is_aligned(requested_eden_size, SpaceAlignment), \"precondition\");\n+  assert(is_aligned(requested_survivor_size, SpaceAlignment), \"precondition\");\n+  assert(from_space()->bottom() < to_space()->bottom(), \"precondition\");\n+\n+  \/\/ layout: from, to, eden\n+  char* from_start = virtual_space()->low();\n+  char* from_end = from_start + requested_survivor_size;\n+  char* to_start = from_end;\n+  char* to_end = to_start + requested_survivor_size;\n+  char* eden_start = to_end;\n+  char* eden_end = eden_start + requested_eden_size;\n+\n+  assert(eden_end <= virtual_space()->high(), \"inv\");\n@@ -601,1 +491,0 @@\n-  MemRegion toMR  ((HeapWord*)to_start,   (HeapWord*)to_end);\n@@ -603,0 +492,1 @@\n+  MemRegion toMR  ((HeapWord*)to_start,   (HeapWord*)to_end);\n@@ -604,20 +494,4 @@\n-  \/\/ Let's make sure the call to initialize doesn't reset \"top\"!\n-  HeapWord* old_from_top = from_space()->top();\n-\n-  \/\/ For logging block  below\n-  size_t old_from = from_space()->capacity_in_bytes();\n-  size_t old_to   = to_space()->capacity_in_bytes();\n-\n-  if (ZapUnusedHeapArea) {\n-    \/\/ NUMA is a special case because a numa space is not mangled\n-    \/\/ in order to not prematurely bind its address to memory to\n-    \/\/ the wrong memory (i.e., don't want the GC thread to first\n-    \/\/ touch the memory).  The survivor spaces are not numa\n-    \/\/ spaces and are mangled.\n-    if (UseNUMA) {\n-      if (eden_from_to_order) {\n-        mangle_survivors(from_space(), fromMR, to_space(), toMR);\n-      } else {\n-        mangle_survivors(to_space(), toMR, from_space(), fromMR);\n-      }\n-    }\n+#ifdef ASSERT\n+  if (!from_space()->is_empty()) {\n+    assert(fromMR.start() == from_space()->bottom(), \"inv\");\n+    assert(fromMR.contains(from_space()->used_region()), \"inv\");\n@@ -625,0 +499,4 @@\n+#endif\n+  \/\/ For logging below\n+  size_t old_from_capacity = from_space()->capacity_in_bytes();\n+  size_t old_to_capacity   = to_space()->capacity_in_bytes();\n@@ -628,2 +506,0 @@\n-  \/\/ When an existing space is being initialized, it is not\n-  \/\/ mangled because the space has been previously mangled.\n@@ -641,1 +517,1 @@\n-                           SpaceDecorator::DontClear,\n+                           from_space()->is_empty(),\n@@ -646,1 +522,7 @@\n-  assert(from_space()->top() == old_from_top, \"from top changed!\");\n+  if (ZapUnusedHeapArea) {\n+    if (!UseNUMA) {\n+      eden_space()->mangle_unused_area();\n+    }\n+    to_space()->mangle_unused_area();\n+    from_space()->mangle_unused_area();\n+  }\n@@ -648,3 +530,2 @@\n-  log_trace(gc, ergo)(\"AdaptiveSizePolicy::survivor space sizes: collection: %d (%zu, %zu) -> (%zu, %zu) \",\n-                      ParallelScavengeHeap::heap()->total_collections(),\n-                      old_from, old_to,\n+  log_trace(gc, ergo)(\"AdaptiveSizePolicy::survivor sizes: (%zu, %zu) -> (%zu, %zu) \",\n+                      old_from_capacity, old_to_capacity,\n@@ -713,81 +594,0 @@\n-size_t PSYoungGen::available_to_min_gen() {\n-  assert(virtual_space()->committed_size() >= min_gen_size(), \"Invariant\");\n-  return virtual_space()->committed_size() - min_gen_size();\n-}\n-\n-\/\/ This method assumes that from-space has live data and that\n-\/\/ any shrinkage of the young gen is limited by location of\n-\/\/ from-space.\n-size_t PSYoungGen::available_to_live() {\n-  size_t delta_in_survivor = 0;\n-  MutableSpace* space_shrinking = nullptr;\n-  if (from_space()->end() > to_space()->end()) {\n-    space_shrinking = from_space();\n-  } else {\n-    space_shrinking = to_space();\n-  }\n-\n-  \/\/ Include any space that is committed but not included in\n-  \/\/ the survivor spaces.\n-  assert(((HeapWord*)virtual_space()->high()) >= space_shrinking->end(),\n-    \"Survivor space beyond high end\");\n-  size_t unused_committed = pointer_delta(virtual_space()->high(),\n-    space_shrinking->end(), sizeof(char));\n-\n-  if (space_shrinking->is_empty()) {\n-    \/\/ Don't let the space shrink to 0\n-    assert(space_shrinking->capacity_in_bytes() >= SpaceAlignment,\n-      \"Space is too small\");\n-    delta_in_survivor = space_shrinking->capacity_in_bytes() - SpaceAlignment;\n-  } else {\n-    delta_in_survivor = pointer_delta(space_shrinking->end(),\n-                                      space_shrinking->top(),\n-                                      sizeof(char));\n-  }\n-\n-  size_t delta_in_bytes = unused_committed + delta_in_survivor;\n-  delta_in_bytes = align_down(delta_in_bytes, SpaceAlignment);\n-  return delta_in_bytes;\n-}\n-\n-\/\/ Return the number of bytes available for resizing down the young\n-\/\/ generation.  This is the minimum of\n-\/\/      input \"bytes\"\n-\/\/      bytes to the minimum young gen size\n-\/\/      bytes to the size currently being used + some small extra\n-size_t PSYoungGen::limit_gen_shrink(size_t bytes) {\n-  \/\/ Allow shrinkage into the current eden but keep eden large enough\n-  \/\/ to maintain the minimum young gen size\n-  bytes = MIN3(bytes, available_to_min_gen(), available_to_live());\n-  return align_down(bytes, virtual_space()->alignment());\n-}\n-\n-void PSYoungGen::reset_survivors_after_shrink() {\n-  _reserved = MemRegion((HeapWord*)virtual_space()->low_boundary(),\n-                        (HeapWord*)virtual_space()->high_boundary());\n-  PSScavenge::set_subject_to_discovery_span(_reserved);\n-\n-  MutableSpace* space_shrinking = nullptr;\n-  if (from_space()->end() > to_space()->end()) {\n-    space_shrinking = from_space();\n-  } else {\n-    space_shrinking = to_space();\n-  }\n-\n-  HeapWord* new_end = (HeapWord*)virtual_space()->high();\n-  assert(new_end >= space_shrinking->bottom(), \"Shrink was too large\");\n-  \/\/ Was there a shrink of the survivor space?\n-  if (new_end < space_shrinking->end()) {\n-    MemRegion mr(space_shrinking->bottom(), new_end);\n-\n-    space_shrinking->initialize(mr,\n-                                SpaceDecorator::DontClear,\n-                                SpaceDecorator::Mangle,\n-                                MutableSpace::SetupPages,\n-                                &ParallelScavengeHeap::heap()->workers());\n-  }\n-}\n-\n-\/\/ This method currently does not expect to expand into eden (i.e.,\n-\/\/ the virtual space boundaries is expected to be consistent\n-\/\/ with the eden boundaries..\n@@ -796,3 +596,0 @@\n-  assert((eden_space()->bottom() < to_space()->bottom()) &&\n-         (eden_space()->bottom() < from_space()->bottom()),\n-         \"Eden is assumed to be below the survivor spaces\");\n@@ -803,1 +600,0 @@\n-  space_invariants();\n@@ -806,2 +602,0 @@\n-\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psYoungGen.cpp","additions":240,"deletions":446,"binary":false,"changes":686,"status":"modified"},{"patch":"@@ -64,2 +64,7 @@\n-  bool resize_generation(size_t eden_size, size_t survivor_size);\n-  void resize_spaces(size_t eden_size, size_t survivor_size);\n+  bool resize_generation(size_t desired_young_gen_size);\n+  void resize_spaces(size_t requested_eden_size,\n+                     size_t requested_survivor_size);\n+\n+  \/\/ Try to expand eden to hold at least word_size.\n+  \/\/ Return true iff the expansion is successful.\n+  bool try_expand_to_hold(size_t word_size);\n@@ -70,10 +75,0 @@\n-  \/\/ Given a desired shrinkage in the size of the young generation,\n-  \/\/ return the actual size available for shrinkage.\n-  size_t limit_gen_shrink(size_t desired_change);\n-  \/\/ returns the number of bytes available from the current size\n-  \/\/ down to the minimum generation size.\n-  size_t available_to_min_gen();\n-  \/\/ Return the number of bytes available for shrinkage considering\n-  \/\/ the location the live data in the generation.\n-  size_t available_to_live();\n-\n@@ -84,0 +79,7 @@\n+  void compute_desired_sizes(bool is_survivor_overflowing,\n+                             size_t& eden_size,\n+                             size_t& survivor_size);\n+\n+  void resize_inner(size_t desired_eden_size,\n+                    size_t desired_survivor_size);\n+\n@@ -109,5 +111,5 @@\n-  \/\/ Resize generation using suggested free space size and survivor size\n-  \/\/ NOTE:  \"eden_size\" and \"survivor_size\" are suggestions only. Current\n-  \/\/        heap layout (particularly, live objects in from space) might\n-  \/\/        not allow us to use these values.\n-  void resize(size_t eden_size, size_t survivor_size);\n+  bool is_from_to_layout() const {\n+    return from_space()->bottom() < to_space()->bottom();\n+  }\n+\n+  void resize_after_young_gc(bool is_survivor_overflowing);\n@@ -133,0 +135,2 @@\n+  HeapWord* expand_and_allocate(size_t word_size);\n+\n@@ -136,2 +140,0 @@\n-  void reset_survivors_after_shrink();\n-\n@@ -150,6 +152,0 @@\n-\n-  \/\/ Helper for mangling survivor spaces.\n-  void mangle_survivors(MutableSpace* s1,\n-                        MemRegion s1MR,\n-                        MutableSpace* s2,\n-                        MemRegion s2MR) PRODUCT_RETURN;\n","filename":"src\/hotspot\/share\/gc\/parallel\/psYoungGen.hpp","additions":21,"deletions":25,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -41,4 +41,1 @@\n-AdaptiveSizePolicy::AdaptiveSizePolicy(size_t init_eden_size,\n-                                       size_t init_promo_size,\n-                                       size_t init_survivor_size,\n-                                       double gc_pause_goal_sec,\n+AdaptiveSizePolicy::AdaptiveSizePolicy(double gc_pause_goal_sec,\n@@ -46,43 +43,14 @@\n-    _throughput_goal(1.0 - double(1.0 \/ (1.0 + (double) gc_cost_ratio))),\n-    _eden_size(init_eden_size),\n-    _promo_size(init_promo_size),\n-    _survivor_size(init_survivor_size),\n-    _avg_minor_pause(new AdaptivePaddedAverage(AdaptiveTimeWeight, PausePadding)),\n-    _avg_minor_interval(new AdaptiveWeightedAverage(AdaptiveTimeWeight)),\n-    _avg_minor_gc_cost(new AdaptiveWeightedAverage(AdaptiveTimeWeight)),\n-    _avg_major_interval(new AdaptiveWeightedAverage(AdaptiveTimeWeight)),\n-    _avg_major_gc_cost(new AdaptiveWeightedAverage(AdaptiveTimeWeight)),\n-    _avg_young_live(new AdaptiveWeightedAverage(AdaptiveSizePolicyWeight)),\n-    _avg_eden_live(new AdaptiveWeightedAverage(AdaptiveSizePolicyWeight)),\n-    _avg_old_live(new AdaptiveWeightedAverage(AdaptiveSizePolicyWeight)),\n-    _avg_survived(new AdaptivePaddedAverage(AdaptiveSizePolicyWeight, SurvivorPadding)),\n-    _avg_pretenured(new AdaptivePaddedNoZeroDevAverage(AdaptiveSizePolicyWeight, SurvivorPadding)),\n-    _minor_pause_old_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-    _minor_pause_young_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-    _minor_collection_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-    _major_collection_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n-    _latest_minor_mutator_interval_seconds(0),\n-    _threshold_tolerance_percent(1.0 + ThresholdTolerance\/100.0),\n-    _gc_pause_goal_sec(gc_pause_goal_sec),\n-    _young_gen_policy_is_ready(false),\n-    _change_young_gen_for_min_pauses(0),\n-    _change_old_gen_for_maj_pauses(0),\n-    _change_old_gen_for_throughput(0),\n-    _change_young_gen_for_throughput(0),\n-    _increment_tenuring_threshold_for_gc_cost(false),\n-    _decrement_tenuring_threshold_for_gc_cost(false),\n-    _decrement_tenuring_threshold_for_survivor_limit(false),\n-    _decrease_for_footprint(0),\n-    _decide_at_full_gc(0),\n-    _young_gen_change_for_minor_throughput(0),\n-    _old_gen_change_for_major_throughput(0) {\n-\n-  \/\/ Start the timers\n-  _minor_timer.start();\n-}\n-\n-bool AdaptiveSizePolicy::tenuring_threshold_change() const {\n-  return decrement_tenuring_threshold_for_gc_cost() ||\n-         increment_tenuring_threshold_for_gc_cost() ||\n-         decrement_tenuring_threshold_for_survivor_limit();\n-}\n+  _throughput_goal(1.0 - double(1.0 \/ (1.0 + (double) gc_cost_ratio))),\n+  _gc_distance_timer(),\n+  _gc_distance_seconds_seq(seq_default_alpha_value),\n+  _trimmed_minor_gc_time_seconds(NumOfGCSample, seq_default_alpha_value),\n+  _trimmed_major_gc_time_seconds(NumOfGCSample, seq_default_alpha_value),\n+  _gc_samples(),\n+  _promoted_bytes(seq_default_alpha_value),\n+  _survived_bytes(seq_default_alpha_value),\n+  _promotion_rate_bytes_per_sec(seq_default_alpha_value),\n+  _peak_old_used_bytes_seq(seq_default_alpha_value),\n+  _minor_pause_young_estimator(new LinearLeastSquareFit(AdaptiveSizePolicyWeight)),\n+  _threshold_tolerance_percent(1.0 + ThresholdTolerance\/100.0),\n+  _gc_pause_goal_sec(gc_pause_goal_sec),\n+  _young_gen_policy_is_ready(false) {}\n@@ -91,4 +59,0 @@\n-  \/\/ Update the interval time\n-  _minor_timer.stop();\n-  \/\/ Save most recent collection time\n-  _latest_minor_mutator_interval_seconds = _minor_timer.seconds();\n@@ -97,0 +61,1 @@\n+  record_gc_pause_start_instant();\n@@ -99,9 +64,1 @@\n-void AdaptiveSizePolicy::update_minor_pause_young_estimator(\n-    double minor_pause_in_ms) {\n-  double eden_size_in_mbytes = ((double)_eden_size)\/((double)M);\n-  _minor_pause_young_estimator->update(eden_size_in_mbytes,\n-    minor_pause_in_ms);\n-}\n-\n-void AdaptiveSizePolicy::minor_collection_end(GCCause::Cause gc_cause) {\n-  \/\/ Update the pause time.\n+void AdaptiveSizePolicy::minor_collection_end(size_t eden_capacity_in_bytes) {\n@@ -110,4 +67,2 @@\n-  if (!GCCause::is_user_requested_gc(gc_cause) ||\n-      UseAdaptiveSizePolicyWithSystemGC) {\n-    double minor_pause_in_seconds = _minor_timer.seconds();\n-    double minor_pause_in_ms = minor_pause_in_seconds * MILLIUNITS;\n+  double minor_pause_in_seconds = _minor_timer.seconds();\n+  double minor_pause_in_ms = minor_pause_in_seconds * MILLIUNITS;\n@@ -115,15 +70,2 @@\n-    \/\/ Sample for performance counter\n-    _avg_minor_pause->sample(minor_pause_in_seconds);\n-\n-    \/\/ Cost of collection (unit-less)\n-    double collection_cost = 0.0;\n-    if ((_latest_minor_mutator_interval_seconds > 0.0) &&\n-        (minor_pause_in_seconds > 0.0)) {\n-      double interval_in_seconds =\n-        _latest_minor_mutator_interval_seconds + minor_pause_in_seconds;\n-      collection_cost =\n-        minor_pause_in_seconds \/ interval_in_seconds;\n-      _avg_minor_gc_cost->sample(collection_cost);\n-      \/\/ Sample for performance counter\n-      _avg_minor_interval->sample(interval_in_seconds);\n-    }\n+  record_gc_duration(minor_pause_in_seconds);\n+  _trimmed_minor_gc_time_seconds.add(minor_pause_in_seconds);\n@@ -131,0 +73,1 @@\n+  if (!_young_gen_policy_is_ready) {\n@@ -133,16 +76,1 @@\n-    _young_gen_policy_is_ready =\n-      (_avg_minor_gc_cost->count() >= AdaptiveSizePolicyReadyThreshold);\n-\n-    \/\/ Calculate variables used to estimate pause time vs. gen sizes\n-    double eden_size_in_mbytes = ((double)_eden_size) \/ ((double)M);\n-    update_minor_pause_young_estimator(minor_pause_in_ms);\n-    update_minor_pause_old_estimator(minor_pause_in_ms);\n-\n-    log_trace(gc, ergo)(\"AdaptiveSizePolicy::minor_collection_end: minor gc cost: %f  average: %f\",\n-                        collection_cost, _avg_minor_gc_cost->average());\n-    log_trace(gc, ergo)(\"  minor pause: %f minor period %f\",\n-                        minor_pause_in_ms, _latest_minor_mutator_interval_seconds * MILLIUNITS);\n-\n-    \/\/ Calculate variable used to estimate collection cost vs. gen sizes\n-    assert(collection_cost >= 0.0, \"Expected to be non-negative\");\n-    _minor_collection_estimator->update(eden_size_in_mbytes, collection_cost);\n+    _young_gen_policy_is_ready = GCId::current() >= AdaptiveSizePolicyReadyThreshold;\n@@ -151,4 +79,4 @@\n-  \/\/ Interval times use this timer to measure the mutator time.\n-  \/\/ Reset the timer after the GC pause.\n-  _minor_timer.reset();\n-  _minor_timer.start();\n+  {\n+    double eden_size_in_mbytes = ((double)eden_capacity_in_bytes)\/((double)M);\n+    _minor_pause_young_estimator->update(eden_size_in_mbytes, minor_pause_in_ms);\n+  }\n@@ -158,2 +86,1 @@\n-  size_t eden_heap_delta;\n-  eden_heap_delta = cur_eden \/ 100 * percent_change;\n+  size_t eden_heap_delta = cur_eden * percent_change \/ 100;\n@@ -165,305 +92,1 @@\n-}\n-\n-size_t AdaptiveSizePolicy::eden_decrement(size_t cur_eden) {\n-  size_t eden_heap_delta = eden_increment(cur_eden) \/\n-    AdaptiveSizeDecrementScaleFactor;\n-  return eden_heap_delta;\n-}\n-\n-size_t AdaptiveSizePolicy::promo_increment(size_t cur_promo, uint percent_change) {\n-  size_t promo_heap_delta;\n-  promo_heap_delta = cur_promo \/ 100 * percent_change;\n-  return promo_heap_delta;\n-}\n-\n-size_t AdaptiveSizePolicy::promo_increment(size_t cur_promo) {\n-  return promo_increment(cur_promo, TenuredGenerationSizeIncrement);\n-}\n-\n-size_t AdaptiveSizePolicy::promo_decrement(size_t cur_promo) {\n-  size_t promo_heap_delta = promo_increment(cur_promo);\n-  promo_heap_delta = promo_heap_delta \/ AdaptiveSizeDecrementScaleFactor;\n-  return promo_heap_delta;\n-}\n-\n-double AdaptiveSizePolicy::time_since_major_gc() const {\n-  _major_timer.stop();\n-  double result = _major_timer.seconds();\n-  _major_timer.start();\n-  return result;\n-}\n-\n-\/\/ Linear decay of major gc cost\n-double AdaptiveSizePolicy::decaying_major_gc_cost() const {\n-  double major_interval = major_gc_interval_average_for_decay();\n-  double major_gc_cost_average = major_gc_cost();\n-  double decayed_major_gc_cost = major_gc_cost_average;\n-  if(time_since_major_gc() > 0.0) {\n-    decayed_major_gc_cost = major_gc_cost() *\n-      (((double) AdaptiveSizeMajorGCDecayTimeScale) * major_interval)\n-      \/ time_since_major_gc();\n-  }\n-\n-  \/\/ The decayed cost should always be smaller than the\n-  \/\/ average cost but the vagaries of finite arithmetic could\n-  \/\/ produce a larger value in decayed_major_gc_cost so protect\n-  \/\/ against that.\n-  return MIN2(major_gc_cost_average, decayed_major_gc_cost);\n-}\n-\n-\/\/ Use a value of the major gc cost that has been decayed\n-\/\/ by the factor\n-\/\/\n-\/\/      average-interval-between-major-gc * AdaptiveSizeMajorGCDecayTimeScale \/\n-\/\/        time-since-last-major-gc\n-\/\/\n-\/\/ if the average-interval-between-major-gc * AdaptiveSizeMajorGCDecayTimeScale\n-\/\/ is less than time-since-last-major-gc.\n-\/\/\n-\/\/ In cases where there are initial major gc's that\n-\/\/ are of a relatively high cost but no later major\n-\/\/ gc's, the total gc cost can remain high because\n-\/\/ the major gc cost remains unchanged (since there are no major\n-\/\/ gc's).  In such a situation the value of the unchanging\n-\/\/ major gc cost can keep the mutator throughput below\n-\/\/ the goal when in fact the major gc cost is becoming diminishingly\n-\/\/ small.  Use the decaying gc cost only to decide whether to\n-\/\/ adjust for throughput.  Using it also to determine the adjustment\n-\/\/ to be made for throughput also seems reasonable but there is\n-\/\/ no test case to use to decide if it is the right thing to do\n-\/\/ don't do it yet.\n-\n-double AdaptiveSizePolicy::decaying_gc_cost() const {\n-  double decayed_major_gc_cost = major_gc_cost();\n-  double avg_major_interval = major_gc_interval_average_for_decay();\n-  if (UseAdaptiveSizeDecayMajorGCCost &&\n-      (AdaptiveSizeMajorGCDecayTimeScale > 0) &&\n-      (avg_major_interval > 0.00)) {\n-    double time_since_last_major_gc = time_since_major_gc();\n-\n-    \/\/ Decay the major gc cost?\n-    if (time_since_last_major_gc >\n-        ((double) AdaptiveSizeMajorGCDecayTimeScale) * avg_major_interval) {\n-\n-      \/\/ Decay using the time-since-last-major-gc\n-      decayed_major_gc_cost = decaying_major_gc_cost();\n-      log_trace(gc, ergo)(\"decaying_gc_cost: major interval average: %f  time since last major gc: %f\",\n-                    avg_major_interval, time_since_last_major_gc);\n-      log_trace(gc, ergo)(\"  major gc cost: %f  decayed major gc cost: %f\",\n-                    major_gc_cost(), decayed_major_gc_cost);\n-    }\n-  }\n-  double result = MIN2(1.0, decayed_major_gc_cost + minor_gc_cost());\n-  return result;\n-}\n-\n-\n-void AdaptiveSizePolicy::clear_generation_free_space_flags() {\n-  set_change_young_gen_for_min_pauses(0);\n-  set_change_old_gen_for_maj_pauses(0);\n-\n-  set_change_old_gen_for_throughput(0);\n-  set_change_young_gen_for_throughput(0);\n-  set_decrease_for_footprint(0);\n-  set_decide_at_full_gc(0);\n-}\n-\n-class AdaptiveSizePolicyTimeOverheadTester: public GCOverheadTester {\n-  double _gc_cost;\n-\n- public:\n-  AdaptiveSizePolicyTimeOverheadTester(double gc_cost) : _gc_cost(gc_cost) {}\n-\n-  bool is_exceeded() {\n-    return _gc_cost > (GCTimeLimit \/ 100.0);\n-  }\n-};\n-\n-class AdaptiveSizePolicySpaceOverheadTester: public GCOverheadTester {\n-  size_t _eden_live;\n-  size_t _max_old_gen_size;\n-  size_t _max_eden_size;\n-  size_t _promo_size;\n-  double _avg_eden_live;\n-  double _avg_old_live;\n-\n- public:\n-  AdaptiveSizePolicySpaceOverheadTester(size_t eden_live,\n-                                        size_t max_old_gen_size,\n-                                        size_t max_eden_size,\n-                                        size_t promo_size,\n-                                        double avg_eden_live,\n-                                        double avg_old_live) :\n-    _eden_live(eden_live),\n-    _max_old_gen_size(max_old_gen_size),\n-    _max_eden_size(max_eden_size),\n-    _promo_size(promo_size),\n-    _avg_eden_live(avg_eden_live),\n-    _avg_old_live(avg_old_live) {}\n-\n-  bool is_exceeded() {\n-    \/\/ _max_eden_size is the upper limit on the size of eden based on\n-    \/\/ the maximum size of the young generation and the sizes\n-    \/\/ of the survivor space.\n-    \/\/ The question being asked is whether the space being recovered by\n-    \/\/ a collection is low.\n-    \/\/ free_in_eden is the free space in eden after a collection and\n-    \/\/ free_in_old_gen is the free space in the old generation after\n-    \/\/ a collection.\n-    \/\/\n-    \/\/ Use the minimum of the current value of the live in eden\n-    \/\/ or the average of the live in eden.\n-    \/\/ If the current value drops quickly, that should be taken\n-    \/\/ into account (i.e., don't trigger if the amount of free\n-    \/\/ space has suddenly jumped up).  If the current is much\n-    \/\/ higher than the average, use the average since it represents\n-    \/\/ the longer term behavior.\n-    const size_t live_in_eden =\n-      MIN2(_eden_live, (size_t)_avg_eden_live);\n-    const size_t free_in_eden = _max_eden_size > live_in_eden ?\n-      _max_eden_size - live_in_eden : 0;\n-    const size_t free_in_old_gen = (size_t)(_max_old_gen_size - _avg_old_live);\n-    const size_t total_free_limit = free_in_old_gen + free_in_eden;\n-    const size_t total_mem = _max_old_gen_size + _max_eden_size;\n-    const double free_limit_ratio = GCHeapFreeLimit \/ 100.0;\n-    const double mem_free_limit = total_mem * free_limit_ratio;\n-    const double mem_free_old_limit = _max_old_gen_size * free_limit_ratio;\n-    const double mem_free_eden_limit = _max_eden_size * free_limit_ratio;\n-    size_t promo_limit = (size_t)(_max_old_gen_size - _avg_old_live);\n-    \/\/ But don't force a promo size below the current promo size. Otherwise,\n-    \/\/ the promo size will shrink for no good reason.\n-    promo_limit = MAX2(promo_limit, _promo_size);\n-\n-    log_trace(gc, ergo)(\n-          \"AdaptiveSizePolicySpaceOverheadTester::is_exceeded:\"\n-          \" promo_limit: %zu\"\n-          \" total_free_limit: %zu\"\n-          \" max_old_gen_size: %zu\"\n-          \" max_eden_size: %zu\"\n-          \" mem_free_limit: %zu\",\n-          promo_limit, total_free_limit,\n-          _max_old_gen_size, _max_eden_size,\n-          (size_t)mem_free_limit);\n-\n-    return free_in_old_gen < (size_t)mem_free_old_limit &&\n-           free_in_eden < (size_t)mem_free_eden_limit;\n-  }\n-};\n-\n-void AdaptiveSizePolicy::check_gc_overhead_limit(\n-                                          size_t eden_live,\n-                                          size_t max_old_gen_size,\n-                                          size_t max_eden_size,\n-                                          bool   is_full_gc,\n-                                          GCCause::Cause gc_cause,\n-                                          SoftRefPolicy* soft_ref_policy) {\n-\n-  AdaptiveSizePolicyTimeOverheadTester time_overhead(gc_cost());\n-  AdaptiveSizePolicySpaceOverheadTester space_overhead(eden_live,\n-                                                       max_old_gen_size,\n-                                                       max_eden_size,\n-                                                       _promo_size,\n-                                                       avg_eden_live()->average(),\n-                                                       avg_old_live()->average());\n-  _overhead_checker.check_gc_overhead_limit(&time_overhead,\n-                                            &space_overhead,\n-                                            is_full_gc,\n-                                            gc_cause,\n-                                            soft_ref_policy);\n-}\n-\/\/ Printing\n-\n-bool AdaptiveSizePolicy::print() const {\n-  assert(UseAdaptiveSizePolicy, \"UseAdaptiveSizePolicy need to be enabled.\");\n-\n-  if (!log_is_enabled(Debug, gc, ergo)) {\n-    return false;\n-  }\n-\n-  \/\/ Print goal for which action is needed.\n-  char* action = nullptr;\n-  bool change_for_pause = false;\n-  if ((change_old_gen_for_maj_pauses() ==\n-         decrease_old_gen_for_maj_pauses_true) ||\n-      (change_young_gen_for_min_pauses() ==\n-         decrease_young_gen_for_min_pauses_true)) {\n-    action = (char*) \" *** pause time goal ***\";\n-    change_for_pause = true;\n-  } else if ((change_old_gen_for_throughput() ==\n-               increase_old_gen_for_throughput_true) ||\n-            (change_young_gen_for_throughput() ==\n-               increase_young_gen_for_througput_true)) {\n-    action = (char*) \" *** throughput goal ***\";\n-  } else if (decrease_for_footprint()) {\n-    action = (char*) \" *** reduced footprint ***\";\n-  } else {\n-    \/\/ No actions were taken.  This can legitimately be the\n-    \/\/ situation if not enough data has been gathered to make\n-    \/\/ decisions.\n-    return false;\n-  }\n-\n-  \/\/ Pauses\n-  \/\/ Currently the size of the old gen is only adjusted to\n-  \/\/ change the major pause times.\n-  char* young_gen_action = nullptr;\n-  char* tenured_gen_action = nullptr;\n-\n-  char* shrink_msg = (char*) \"(attempted to shrink)\";\n-  char* grow_msg = (char*) \"(attempted to grow)\";\n-  char* no_change_msg = (char*) \"(no change)\";\n-  if (change_young_gen_for_min_pauses() ==\n-      decrease_young_gen_for_min_pauses_true) {\n-    young_gen_action = shrink_msg;\n-  } else if (change_for_pause) {\n-    young_gen_action = no_change_msg;\n-  }\n-\n-  if (change_old_gen_for_maj_pauses() == decrease_old_gen_for_maj_pauses_true) {\n-    tenured_gen_action = shrink_msg;\n-  } else if (change_for_pause) {\n-    tenured_gen_action = no_change_msg;\n-  }\n-\n-  \/\/ Throughput\n-  if (change_old_gen_for_throughput() == increase_old_gen_for_throughput_true) {\n-    assert(change_young_gen_for_throughput() ==\n-           increase_young_gen_for_througput_true,\n-           \"Both generations should be growing\");\n-    young_gen_action = grow_msg;\n-    tenured_gen_action = grow_msg;\n-  } else if (change_young_gen_for_throughput() ==\n-             increase_young_gen_for_througput_true) {\n-    \/\/ Only the young generation may grow at start up (before\n-    \/\/ enough full collections have been done to grow the old generation).\n-    young_gen_action = grow_msg;\n-    tenured_gen_action = no_change_msg;\n-  }\n-\n-  \/\/ Minimum footprint\n-  if (decrease_for_footprint() != 0) {\n-    young_gen_action = shrink_msg;\n-    tenured_gen_action = shrink_msg;\n-  }\n-\n-  log_debug(gc, ergo)(\"UseAdaptiveSizePolicy actions to meet %s\", action);\n-  log_debug(gc, ergo)(\"                       GC overhead (%%)\");\n-  log_debug(gc, ergo)(\"    Young generation:     %7.2f\\t  %s\",\n-                      100.0 * avg_minor_gc_cost()->average(), young_gen_action);\n-  log_debug(gc, ergo)(\"    Tenured generation:   %7.2f\\t  %s\",\n-                      100.0 * avg_major_gc_cost()->average(), tenured_gen_action);\n-  return true;\n-}\n-\n-void AdaptiveSizePolicy::print_tenuring_threshold( uint new_tenuring_threshold_arg) const {\n-  \/\/ Tenuring threshold\n-  if (decrement_tenuring_threshold_for_survivor_limit()) {\n-    log_debug(gc, ergo)(\"Tenuring threshold: (attempted to decrease to avoid survivor space overflow) = %u\", new_tenuring_threshold_arg);\n-  } else if (decrement_tenuring_threshold_for_gc_cost()) {\n-    log_debug(gc, ergo)(\"Tenuring threshold: (attempted to decrease to balance GC costs) = %u\", new_tenuring_threshold_arg);\n-  } else if (increment_tenuring_threshold_for_gc_cost()) {\n-    log_debug(gc, ergo)(\"Tenuring threshold: (attempted to increase to balance GC costs) = %u\", new_tenuring_threshold_arg);\n-  } else {\n-    assert(!tenuring_threshold_change(), \"(no change was attempted)\");\n-  }\n-}\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/shared\/adaptiveSizePolicy.cpp","additions":29,"deletions":406,"binary":false,"changes":435,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"gc\/shared\/gcOverheadChecker.hpp\"\n@@ -32,0 +32,2 @@\n+#include \"runtime\/os.hpp\"\n+#include \"utilities\/numberSeq.hpp\"\n@@ -36,3 +38,0 @@\n-\/\/ Forward decls\n-class elapsedTimer;\n-\n@@ -40,2 +39,0 @@\n- friend class GCAdaptivePolicyCounters;\n- friend class PSGCAdaptivePolicyCounters;\n@@ -43,0 +40,2 @@\n+  \/\/ [0, 1]; closer to 1 means assigning more weight to most recent samples.\n+  constexpr static double seq_default_alpha_value = 0.75;\n@@ -44,17 +43,6 @@\n-  enum GCPolicyKind {\n-    _gc_adaptive_size_policy,\n-    _gc_ps_adaptive_size_policy\n-  };\n-  virtual GCPolicyKind kind() const { return _gc_adaptive_size_policy; }\n-\n-  enum SizePolicyTrueValues {\n-    decrease_young_gen_for_min_pauses_true = 1,\n-    decrease_old_gen_for_maj_pauses_true = 2,\n-\n-    increase_old_gen_for_throughput_true = 4,\n-    increase_young_gen_for_througput_true = 5,\n-\n-    decrease_young_gen_for_footprint_true = 6,\n-    decrease_old_gen_for_footprint_true = 7,\n-    decide_at_full_gc_true = 8\n-  };\n+  \/\/ Minimal distance between two consecutive GC pauses; shorter distance (more\n+  \/\/ frequent gc) can hinder app throughput. Additionally, too frequent gc\n+  \/\/ means objs haven't got time to die yet, so #promoted objs will be high.\n+  \/\/ Default: 100ms.\n+  static constexpr double MinGCDistanceSecond = 0.100;\n+  static_assert(MinGCDistanceSecond >= 0.001, \"inv\");\n@@ -66,10 +54,0 @@\n-  \/\/ Last calculated sizes, in bytes, and aligned\n-  size_t _eden_size;        \/\/ calculated eden free space in bytes\n-  size_t _promo_size;       \/\/ calculated promoted free space in bytes\n-\n-  size_t _survivor_size;    \/\/ calculated survivor size in bytes\n-\n-  \/\/ Support for UseGCOverheadLimit\n-  GCOverheadChecker _overhead_checker;\n-\n-  \/\/ Minor collection timers used to determine both\n@@ -83,4 +61,52 @@\n-  \/\/ Time statistics\n-  AdaptivePaddedAverage*   _avg_minor_pause;\n-  AdaptiveWeightedAverage* _avg_minor_interval;\n-  AdaptiveWeightedAverage* _avg_minor_gc_cost;\n+  \/\/ To measure wall-clock time between two GCs, i.e. mutator running time, and record them.\n+  elapsedTimer _gc_distance_timer;\n+  NumberSeq _gc_distance_seconds_seq;\n+\n+  static constexpr uint NumOfGCSample = 32;\n+  \/\/ Recording the last NumOfGCSample number of minor\/major gc durations\n+  TruncatedSeq _trimmed_minor_gc_time_seconds;\n+  TruncatedSeq _trimmed_major_gc_time_seconds;\n+\n+  \/\/ A ring buffer with fixed size (NumOfGCSample) to record the most recent\n+  \/\/ samples of gc-duration (minor and major) so that we can calculate\n+  \/\/ mutator-wall-clock-time percentage for the given window.\n+  class GCSampleRingBuffer {\n+    double _start_instants[NumOfGCSample];\n+    double _durations[NumOfGCSample];\n+    double _duration_sum;\n+    uint _sample_index;\n+    uint _num_of_samples;\n+\n+  public:\n+    GCSampleRingBuffer()\n+      : _duration_sum(0.0), _sample_index(0), _num_of_samples(0) {}\n+\n+    double duration_sum() const { return _duration_sum; }\n+\n+    void record_sample(double gc_duration) {\n+      if (_num_of_samples < NumOfGCSample) {\n+        _num_of_samples++;\n+      } else {\n+        assert(_num_of_samples == NumOfGCSample, \"inv\");\n+        _duration_sum -= _durations[_sample_index];\n+      }\n+\n+      double gc_start_instant = os::elapsedTime() - gc_duration;\n+      _start_instants[_sample_index] = gc_start_instant;\n+      _durations[_sample_index] = gc_duration;\n+      _duration_sum += gc_duration;\n+\n+      _sample_index = (_sample_index + 1) % NumOfGCSample;\n+    }\n+\n+    double trimmed_window_duration() const {\n+      double current_time = os::elapsedTime();\n+      double oldest_gc_start_instant;\n+      if (_num_of_samples < NumOfGCSample) {\n+        oldest_gc_start_instant = _start_instants[0];\n+      } else {\n+        oldest_gc_start_instant = _start_instants[_sample_index];\n+      }\n+      return current_time - oldest_gc_start_instant;\n+    }\n+  };\n@@ -88,2 +114,1 @@\n-  AdaptiveWeightedAverage* _avg_major_interval;\n-  AdaptiveWeightedAverage* _avg_major_gc_cost;\n+  GCSampleRingBuffer _gc_samples;\n@@ -91,4 +116,2 @@\n-  \/\/ Footprint statistics\n-  AdaptiveWeightedAverage* _avg_young_live;\n-  AdaptiveWeightedAverage* _avg_eden_live;\n-  AdaptiveWeightedAverage* _avg_old_live;\n+  \/\/ The number of bytes promoted to old-gen after a young-gc\n+  NumberSeq _promoted_bytes;\n@@ -96,2 +119,2 @@\n-  \/\/ Statistics for survivor space calculation for young generation\n-  AdaptivePaddedAverage*   _avg_survived;\n+  \/\/ The number of bytes in to-space after a young-gc\n+  NumberSeq _survived_bytes;\n@@ -99,2 +122,5 @@\n-  \/\/ Objects that have been directly allocated in the old generation\n-  AdaptivePaddedNoZeroDevAverage*   _avg_pretenured;\n+  \/\/ The rate of promotion to old-gen\n+  NumberSeq _promotion_rate_bytes_per_sec;\n+\n+  \/\/ The peak of used bytes in old-gen before\/after young\/full-gc\n+  NumberSeq _peak_old_used_bytes_seq;\n@@ -105,2 +131,0 @@\n-  \/\/   minor pause time vs. old gen size\n-  LinearLeastSquareFit* _minor_pause_old_estimator;\n@@ -110,11 +134,0 @@\n-  \/\/ Variables for estimating the major and minor collection costs\n-  \/\/   minor collection time vs. young gen size\n-  LinearLeastSquareFit* _minor_collection_estimator;\n-  \/\/   major collection time vs. old gen size\n-  LinearLeastSquareFit* _major_collection_estimator;\n-\n-  \/\/ These record the most recent collection times.  They\n-  \/\/ are available as an alternative to using the averages\n-  \/\/ for making ergonomic decisions.\n-  double _latest_minor_mutator_interval_seconds;\n-\n@@ -130,36 +143,0 @@\n-  \/\/ Decrease\/increase the young generation for minor pause time\n-  int _change_young_gen_for_min_pauses;\n-\n-  \/\/ Decrease\/increase the old generation for major pause time\n-  int _change_old_gen_for_maj_pauses;\n-\n-  \/\/   change old generation for throughput\n-  int _change_old_gen_for_throughput;\n-\n-  \/\/   change young generation for throughput\n-  int _change_young_gen_for_throughput;\n-\n-  \/\/ Flag indicating that the policy would\n-  \/\/   increase the tenuring threshold because of the total major GC cost\n-  \/\/   is greater than the total minor GC cost\n-  bool _increment_tenuring_threshold_for_gc_cost;\n-  \/\/   decrease the tenuring threshold because of the total minor GC\n-  \/\/   cost is greater than the total major GC cost\n-  bool _decrement_tenuring_threshold_for_gc_cost;\n-  \/\/   decrease due to survivor size limit\n-  bool _decrement_tenuring_threshold_for_survivor_limit;\n-\n-  \/\/   decrease generation sizes for footprint\n-  int _decrease_for_footprint;\n-\n-  \/\/ Set if the ergonomic decisions were made at a full GC.\n-  int _decide_at_full_gc;\n-\n-  \/\/ Changing the generation sizing depends on the data that is\n-  \/\/ gathered about the effects of changes on the pause times and\n-  \/\/ throughput.  These variable count the number of data points\n-  \/\/ gathered.  The policy may use these counters as a threshold\n-  \/\/ for reliable data.\n-  julong _young_gen_change_for_minor_throughput;\n-  julong _old_gen_change_for_major_throughput;\n-\n@@ -167,1 +144,0 @@\n-\n@@ -169,13 +145,0 @@\n-  \/\/ The value returned is unitless:  it's the proportion of time\n-  \/\/ spent in a particular collection type.\n-  \/\/ An interval time will be 0.0 if a collection type hasn't occurred yet.\n-  \/\/ The 1.4.2 implementation put a floor on the values of major_gc_cost\n-  \/\/ and minor_gc_cost.  This was useful because of the way major_gc_cost\n-  \/\/ and minor_gc_cost was used in calculating the sizes of the generations.\n-  \/\/ Do not use a floor in this implementation because any finite value\n-  \/\/ will put a limit on the throughput that can be achieved and any\n-  \/\/ throughput goal above that limit will drive the generations sizes\n-  \/\/ to extremes.\n-  double major_gc_cost() const {\n-    return MAX2(0.0F, _avg_major_gc_cost->average());\n-  }\n@@ -183,13 +146,2 @@\n-  \/\/ The value returned is unitless:  it's the proportion of time\n-  \/\/ spent in a particular collection type.\n-  \/\/ An interval time will be 0.0 if a collection type hasn't occurred yet.\n-  \/\/ The 1.4.2 implementation put a floor on the values of major_gc_cost\n-  \/\/ and minor_gc_cost.  This was useful because of the way major_gc_cost\n-  \/\/ and minor_gc_cost was used in calculating the sizes of the generations.\n-  \/\/ Do not use a floor in this implementation because any finite value\n-  \/\/ will put a limit on the throughput that can be achieved and any\n-  \/\/ throughput goal above that limit will drive the generations sizes\n-  \/\/ to extremes.\n-\n-  double minor_gc_cost() const {\n-    return MAX2(0.0F, _avg_minor_gc_cost->average());\n+  double minor_gc_time_sum() const {\n+    return _trimmed_minor_gc_time_seconds.sum();\n@@ -197,27 +149,2 @@\n-\n-  \/\/ Because we're dealing with averages, gc_cost() can be\n-  \/\/ larger than 1.0 if just the sum of the minor cost the\n-  \/\/ the major cost is used.  Worse than that is the\n-  \/\/ fact that the minor cost and the major cost each\n-  \/\/ tend toward 1.0 in the extreme of high GC costs.\n-  \/\/ Limit the value of gc_cost to 1.0 so that the mutator\n-  \/\/ cost stays non-negative.\n-  virtual double gc_cost() const {\n-    double result = MIN2(1.0, minor_gc_cost() + major_gc_cost());\n-    assert(result >= 0.0, \"Both minor and major costs are non-negative\");\n-    return result;\n-  }\n-\n-  \/\/ Elapsed time since the last major collection.\n-  virtual double time_since_major_gc() const;\n-\n-  \/\/ Average interval between major collections to be used\n-  \/\/ in calculating the decaying major GC cost.  An overestimate\n-  \/\/ of this time would be a conservative estimate because\n-  \/\/ this time is used to decide if the major GC cost\n-  \/\/ should be decayed (i.e., if the time since the last\n-  \/\/ major GC is long compared to the time returned here,\n-  \/\/ then the major GC cost will be decayed).  See the\n-  \/\/ implementations for the specifics.\n-  virtual double major_gc_interval_average_for_decay() const {\n-    return _avg_major_interval->average();\n+  double major_gc_time_sum() const {\n+    return _trimmed_major_gc_time_seconds.sum();\n@@ -226,17 +153,2 @@\n-  \/\/ Return the cost of the GC where the major GC cost\n-  \/\/ has been decayed based on the time since the last\n-  \/\/ major collection.\n-  double decaying_gc_cost() const;\n-\n-  \/\/ Decay the major GC cost.  Use this only for decisions on\n-  \/\/ whether to adjust, not to determine by how much to adjust.\n-  \/\/ This approximation is crude and may not be good enough for the\n-  \/\/ latter.\n-  double decaying_major_gc_cost() const;\n-\n-  \/\/ Return the mutator cost using the decayed\n-  \/\/ GC cost.\n-  double adjusted_mutator_cost() const {\n-    double result = 1.0 - decaying_gc_cost();\n-    assert(result >= 0.0, \"adjusted mutator cost calculation is incorrect\");\n-    return result;\n+  void record_gc_duration(double gc_duration) {\n+    _gc_samples.record_sample(gc_duration);\n@@ -245,4 +157,8 @@\n-  virtual double mutator_cost() const {\n-    double result = 1.0 - gc_cost();\n-    assert(result >= 0.0, \"mutator cost calculation is incorrect\");\n-    return result;\n+  \/\/ Percent of GC wall-clock time.\n+  double gc_time_percent() const {\n+    double total_time = _gc_samples.trimmed_window_duration();\n+    double gc_time = _gc_samples.duration_sum();\n+    double gc_percent = gc_time \/ total_time;\n+    assert(gc_percent <= 1.0, \"inv\");\n+    assert(gc_percent >= 0, \"inv\");\n+    return gc_percent;\n@@ -251,1 +167,0 @@\n-\n@@ -254,6 +169,0 @@\n-  void update_minor_pause_young_estimator(double minor_pause_in_ms);\n-  virtual void update_minor_pause_old_estimator(double minor_pause_in_ms) {\n-    \/\/ This is not meaningful for all policies but needs to be present\n-    \/\/ to use minor_collection_end() in its current form.\n-  }\n-\n@@ -262,6 +171,0 @@\n-  size_t eden_decrement(size_t cur_eden);\n-  size_t promo_increment(size_t cur_eden);\n-  size_t promo_increment(size_t cur_eden, uint percent_change);\n-  size_t promo_decrement(size_t cur_eden);\n-\n-  virtual void clear_generation_free_space_flags();\n@@ -269,46 +172,2 @@\n-  int change_old_gen_for_throughput() const {\n-    return _change_old_gen_for_throughput;\n-  }\n-  void set_change_old_gen_for_throughput(int v) {\n-    _change_old_gen_for_throughput = v;\n-  }\n-  int change_young_gen_for_throughput() const {\n-    return _change_young_gen_for_throughput;\n-  }\n-  void set_change_young_gen_for_throughput(int v) {\n-    _change_young_gen_for_throughput = v;\n-  }\n-\n-  int change_old_gen_for_maj_pauses() const {\n-    return _change_old_gen_for_maj_pauses;\n-  }\n-  void set_change_old_gen_for_maj_pauses(int v) {\n-    _change_old_gen_for_maj_pauses = v;\n-  }\n-\n-  bool decrement_tenuring_threshold_for_gc_cost() const {\n-    return _decrement_tenuring_threshold_for_gc_cost;\n-  }\n-  void set_decrement_tenuring_threshold_for_gc_cost(bool v) {\n-    _decrement_tenuring_threshold_for_gc_cost = v;\n-  }\n-  bool increment_tenuring_threshold_for_gc_cost() const {\n-    return _increment_tenuring_threshold_for_gc_cost;\n-  }\n-  void set_increment_tenuring_threshold_for_gc_cost(bool v) {\n-    _increment_tenuring_threshold_for_gc_cost = v;\n-  }\n-  bool decrement_tenuring_threshold_for_survivor_limit() const {\n-    return _decrement_tenuring_threshold_for_survivor_limit;\n-  }\n-  void set_decrement_tenuring_threshold_for_survivor_limit(bool v) {\n-    _decrement_tenuring_threshold_for_survivor_limit = v;\n-  }\n-  \/\/ Return true if the policy suggested a change.\n-  bool tenuring_threshold_change() const;\n-\n- public:\n-  AdaptiveSizePolicy(size_t init_eden_size,\n-                     size_t init_promo_size,\n-                     size_t init_survivor_size,\n-                     double gc_pause_goal_sec,\n+public:\n+  AdaptiveSizePolicy(double gc_pause_goal_sec,\n@@ -317,7 +176,3 @@\n-  bool is_gc_ps_adaptive_size_policy() {\n-    return kind() == _gc_ps_adaptive_size_policy;\n-  }\n-\n-  AdaptivePaddedAverage*   avg_minor_pause() const { return _avg_minor_pause; }\n-  AdaptiveWeightedAverage* avg_minor_interval() const {\n-    return _avg_minor_interval;\n+  void record_gc_pause_end_instant() {\n+    _gc_distance_timer.reset();\n+    _gc_distance_timer.start();\n@@ -325,17 +180,0 @@\n-  AdaptiveWeightedAverage* avg_minor_gc_cost() const {\n-    return _avg_minor_gc_cost;\n-  }\n-\n-  AdaptiveWeightedAverage* avg_major_gc_cost() const {\n-    return _avg_major_gc_cost;\n-  }\n-\n-  AdaptiveWeightedAverage* avg_young_live() const { return _avg_young_live; }\n-  AdaptiveWeightedAverage* avg_eden_live() const { return _avg_eden_live; }\n-  AdaptiveWeightedAverage* avg_old_live() const { return _avg_old_live; }\n-\n-  \/\/ Methods indicating events of interest to the adaptive size policy,\n-  \/\/ called by GC algorithms. It is the responsibility of users of this\n-  \/\/ policy to call these methods at the correct times!\n-  virtual void minor_collection_begin();\n-  virtual void minor_collection_end(GCCause::Cause gc_cause);\n@@ -343,5 +181,3 @@\n-  LinearLeastSquareFit* minor_pause_young_estimator() {\n-    return _minor_pause_young_estimator;\n-  }\n-  LinearLeastSquareFit* minor_collection_estimator() {\n-    return _minor_collection_estimator;\n+  void record_gc_pause_start_instant() {\n+    _gc_distance_timer.stop();\n+    _gc_distance_seconds_seq.add(_gc_distance_timer.seconds());\n@@ -350,2 +186,3 @@\n-  LinearLeastSquareFit* major_collection_estimator() {\n-    return _major_collection_estimator;\n+  double minor_gc_time_estimate() const {\n+    return _trimmed_minor_gc_time_seconds.davg()\n+         + _trimmed_minor_gc_time_seconds.dsd();\n@@ -354,2 +191,6 @@\n-  double minor_pause_young_slope() {\n-    return _minor_pause_young_estimator->slope();\n+  double minor_gc_time_conservative_estimate() const {\n+    double davg_plus_dsd = _trimmed_minor_gc_time_seconds.davg()\n+                         + _trimmed_minor_gc_time_seconds.dsd();\n+    double avg_plus_sd =  _trimmed_minor_gc_time_seconds.avg()\n+                         + _trimmed_minor_gc_time_seconds.sd();\n+    return MAX2(davg_plus_dsd, avg_plus_sd);\n@@ -358,5 +199,3 @@\n-  double minor_collection_slope() { return _minor_collection_estimator->slope();}\n-  double major_collection_slope() { return _major_collection_estimator->slope();}\n-\n-  double minor_pause_old_slope() {\n-    return _minor_pause_old_estimator->slope();\n+  double major_gc_time_estimate() const {\n+    return _trimmed_major_gc_time_seconds.davg()\n+         + _trimmed_major_gc_time_seconds.dsd();\n@@ -365,5 +204,2 @@\n-  void set_eden_size(size_t new_size) {\n-    _eden_size = new_size;\n-  }\n-  void set_survivor_size(size_t new_size) {\n-    _survivor_size = new_size;\n+  void sample_old_gen_used_bytes(size_t used_bytes) {\n+    _peak_old_used_bytes_seq.add(used_bytes);\n@@ -372,2 +208,3 @@\n-  size_t calculated_eden_size_in_bytes() const {\n-    return _eden_size;\n+  double peak_old_gen_used_estimate() const {\n+    return _peak_old_used_bytes_seq.davg()\n+         + _peak_old_used_bytes_seq.dsd();\n@@ -376,2 +213,3 @@\n-  size_t calculated_promo_size_in_bytes() const {\n-    return _promo_size;\n+  double promoted_bytes_estimate() const {\n+    return _promoted_bytes.davg()\n+         + _promoted_bytes.dsd();\n@@ -380,2 +218,3 @@\n-  size_t calculated_survivor_size_in_bytes() const {\n-    return _survivor_size;\n+  double promotion_rate_bytes_per_sec_estimate() const {\n+    return _promotion_rate_bytes_per_sec.davg()\n+         + _promotion_rate_bytes_per_sec.dsd();\n@@ -384,5 +223,7 @@\n-  bool gc_overhead_limit_exceeded() {\n-    return _overhead_checker.gc_overhead_limit_exceeded();\n-  }\n-  void set_gc_overhead_limit_exceeded(bool v) {\n-    _overhead_checker.set_gc_overhead_limit_exceeded(v);\n+  double survived_bytes_estimate() const {\n+    \/\/ Conservative estimate to minimize promotion to old-gen\n+    double avg_plus_sd = _survived_bytes.avg()\n+                       + _survived_bytes.sd();\n+    double davg_plus_dsd = _survived_bytes.davg()\n+                         + _survived_bytes.dsd();\n+    return MAX2(avg_plus_sd, davg_plus_dsd);\n@@ -391,2 +232,4 @@\n-  void reset_gc_overhead_limit_count() {\n-    _overhead_checker.reset_gc_overhead_limit_count();\n+  \/\/ Percent of mutator wall-clock time.\n+  double mutator_time_percent() const {\n+    double result = 1.0 - gc_time_percent();\n+    return result;\n@@ -394,2 +237,0 @@\n-  \/\/ accessors for flags recording the decisions to resize the\n-  \/\/ generations to meet the pause goal.\n@@ -397,25 +238,5 @@\n-  int change_young_gen_for_min_pauses() const {\n-    return _change_young_gen_for_min_pauses;\n-  }\n-  void set_change_young_gen_for_min_pauses(int v) {\n-    _change_young_gen_for_min_pauses = v;\n-  }\n-  void set_decrease_for_footprint(int v) { _decrease_for_footprint = v; }\n-  int decrease_for_footprint() const { return _decrease_for_footprint; }\n-  int decide_at_full_gc() { return _decide_at_full_gc; }\n-  void set_decide_at_full_gc(int v) { _decide_at_full_gc = v; }\n-\n-  \/\/ Check the conditions for an out-of-memory due to excessive GC time.\n-  \/\/ Set _gc_overhead_limit_exceeded if all the conditions have been met.\n-  void check_gc_overhead_limit(size_t eden_live,\n-                               size_t max_old_gen_size,\n-                               size_t max_eden_size,\n-                               bool   is_full_gc,\n-                               GCCause::Cause gc_cause,\n-                               SoftRefPolicy* soft_ref_policy);\n-\n-  static bool should_update_promo_stats(GCCause::Cause cause) {\n-    return ((GCCause::is_user_requested_gc(cause)  &&\n-               UseAdaptiveSizePolicyWithSystemGC) ||\n-            GCCause::is_tenured_allocation_failure_gc(cause));\n-  }\n+  \/\/ Methods indicating events of interest to the adaptive size policy,\n+  \/\/ called by GC algorithms. It is the responsibility of users of this\n+  \/\/ policy to call these methods at the correct times!\n+  void minor_collection_begin();\n+  void minor_collection_end(size_t eden_capacity_in_bytes);\n@@ -423,4 +244,2 @@\n-  static bool should_update_eden_stats(GCCause::Cause cause) {\n-    return ((GCCause::is_user_requested_gc(cause)  &&\n-               UseAdaptiveSizePolicyWithSystemGC) ||\n-            GCCause::is_allocation_failure_gc(cause));\n+  LinearLeastSquareFit* minor_pause_young_estimator() {\n+    return _minor_pause_young_estimator;\n@@ -428,4 +247,0 @@\n-\n-  \/\/ Printing support\n-  virtual bool print() const;\n-  void print_tenuring_threshold(uint new_tenuring_threshold) const;\n","filename":"src\/hotspot\/share\/gc\/shared\/adaptiveSizePolicy.hpp","additions":136,"deletions":321,"binary":false,"changes":457,"status":"modified"},{"patch":"@@ -1,104 +0,0 @@\n-\/*\n- * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2019, Google and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"gc\/shared\/gcOverheadChecker.hpp\"\n-#include \"gc\/shared\/softRefPolicy.hpp\"\n-#include \"logging\/log.hpp\"\n-\n-GCOverheadChecker::GCOverheadChecker() :\n-  _gc_overhead_limit_exceeded(false),\n-  _gc_overhead_limit_count(0) {\n-  assert(GCOverheadLimitThreshold > 0,\n-    \"No opportunity to clear SoftReferences before GC overhead limit\");\n-}\n-\n-void GCOverheadChecker::check_gc_overhead_limit(GCOverheadTester* time_overhead,\n-                                                GCOverheadTester* space_overhead,\n-                                                bool is_full_gc,\n-                                                GCCause::Cause gc_cause,\n-                                                SoftRefPolicy* soft_ref_policy) {\n-  if (is_full_gc) {\n-    \/\/ Explicit Full GC would do the clearing of soft-refs as well\n-    \/\/ So reset in the beginning\n-    soft_ref_policy->set_should_clear_all_soft_refs(false);\n-  }\n-  \/\/ Ignore explicit GC's.  Exiting here does not set the flag and\n-  \/\/ does not reset the count.\n-  if (GCCause::is_user_requested_gc(gc_cause) ||\n-      GCCause::is_serviceability_requested_gc(gc_cause)) {\n-    return;\n-  }\n-\n-  bool print_gc_overhead_limit_would_be_exceeded = false;\n-  if (is_full_gc) {\n-    if (time_overhead->is_exceeded() && space_overhead->is_exceeded()) {\n-      \/\/ Collections, on average, are taking too much time, and\n-      \/\/ we have too little space available after a full gc.\n-      \/\/ At this point the GC overhead limit is being exceeded.\n-      _gc_overhead_limit_count++;\n-      if (UseGCOverheadLimit) {\n-        if (_gc_overhead_limit_count >= GCOverheadLimitThreshold){\n-          \/\/ All conditions have been met for throwing an out-of-memory\n-          set_gc_overhead_limit_exceeded(true);\n-          \/\/ Avoid consecutive OOM due to the gc time limit by resetting\n-          \/\/ the counter.\n-          reset_gc_overhead_limit_count();\n-        } else {\n-          \/\/ The required consecutive collections which exceed the\n-          \/\/ GC time limit may or may not have been reached. We\n-          \/\/ are approaching that condition and so as not to\n-          \/\/ throw an out-of-memory before all SoftRef's have been\n-          \/\/ cleared, set _should_clear_all_soft_refs in SoftRefPolicy.\n-          \/\/ The clearing will be done on the next GC.\n-          bool near_limit = gc_overhead_limit_near();\n-          if (near_limit) {\n-            soft_ref_policy->set_should_clear_all_soft_refs(true);\n-            log_trace(gc, ergo)(\"Nearing GC overhead limit, will be clearing all SoftReference\");\n-          }\n-        }\n-      }\n-      \/\/ Set this even when the overhead limit will not\n-      \/\/ cause an out-of-memory.  Diagnostic message indicating\n-      \/\/ that the overhead limit is being exceeded is sometimes\n-      \/\/ printed.\n-      print_gc_overhead_limit_would_be_exceeded = true;\n-\n-    } else {\n-      \/\/ Did not exceed overhead limits\n-      reset_gc_overhead_limit_count();\n-    }\n-  }\n-\n-  if (UseGCOverheadLimit) {\n-    if (gc_overhead_limit_exceeded()) {\n-      log_trace(gc, ergo)(\"GC is exceeding overhead limit of %u%%\", GCTimeLimit);\n-      reset_gc_overhead_limit_count();\n-    } else if (print_gc_overhead_limit_would_be_exceeded) {\n-      assert(_gc_overhead_limit_count > 0, \"Should not be printing\");\n-      log_trace(gc, ergo)(\"GC would exceed overhead limit of %u%% %d consecutive time(s)\",\n-                          GCTimeLimit, _gc_overhead_limit_count);\n-    }\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/shared\/gcOverheadChecker.cpp","additions":0,"deletions":104,"binary":false,"changes":104,"status":"deleted"},{"patch":"@@ -1,84 +0,0 @@\n-\/*\n- * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2019, Google and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHARED_GCOVERHEADCHECKER_HPP\n-#define SHARE_GC_SHARED_GCOVERHEADCHECKER_HPP\n-\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/shared\/gcCause.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"runtime\/globals.hpp\"\n-\n-class SoftRefPolicy;\n-\n-class GCOverheadTester: public StackObj {\n-public:\n-  virtual bool is_exceeded() = 0;\n-};\n-\n-class GCOverheadChecker: public CHeapObj<mtGC> {\n-  \/\/ This is a hint for the heap:  we've detected that GC times\n-  \/\/ are taking longer than GCTimeLimit allows.\n-  bool _gc_overhead_limit_exceeded;\n-  \/\/ Count of consecutive GC that have exceeded the\n-  \/\/ GC time limit criterion\n-  uint _gc_overhead_limit_count;\n-  \/\/ This flag signals that GCTimeLimit is being exceeded\n-  \/\/ but may not have done so for the required number of consecutive\n-  \/\/ collections\n-\n-public:\n-  GCOverheadChecker();\n-\n-  \/\/ This is a hint for the heap:  we've detected that gc times\n-  \/\/ are taking longer than GCTimeLimit allows.\n-  \/\/ Most heaps will choose to throw an OutOfMemoryError when\n-  \/\/ this occurs but it is up to the heap to request this information\n-  \/\/ of the policy\n-  bool gc_overhead_limit_exceeded() {\n-    return _gc_overhead_limit_exceeded;\n-  }\n-  void set_gc_overhead_limit_exceeded(bool v) {\n-    _gc_overhead_limit_exceeded = v;\n-  }\n-\n-  \/\/ Tests conditions indicate the GC overhead limit is being approached.\n-  bool gc_overhead_limit_near() {\n-    return _gc_overhead_limit_count >= (GCOverheadLimitThreshold - 1);\n-  }\n-  void reset_gc_overhead_limit_count() {\n-    _gc_overhead_limit_count = 0;\n-  }\n-\n-  \/\/ Check the conditions for an out-of-memory due to excessive GC time.\n-  \/\/ Set _gc_overhead_limit_exceeded if all the conditions have been met.\n-  void check_gc_overhead_limit(GCOverheadTester* time_overhead,\n-                               GCOverheadTester* space_overhead,\n-                               bool is_full_gc,\n-                               GCCause::Cause gc_cause,\n-                               SoftRefPolicy* soft_ref_policy);\n-};\n-\n-#endif \/\/ SHARE_GC_SHARED_GCOVERHEADCHECKER_HPP\n","filename":"src\/hotspot\/share\/gc\/shared\/gcOverheadChecker.hpp","additions":0,"deletions":84,"binary":false,"changes":84,"status":"deleted"},{"patch":"@@ -62,5 +62,0 @@\n-\n-    cname = PerfDataManager::counter_name(_name_space, \"gcTimeLimitExceeded\");\n-    _gc_overhead_limit_exceeded_counter =\n-        PerfDataManager::create_variable(SUN_GC, cname, PerfData::U_Events,\n-                                         CHECK);\n","filename":"src\/hotspot\/share\/gc\/shared\/gcPolicyCounters.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -44,1 +44,0 @@\n-  PerfVariable* _gc_overhead_limit_exceeded_counter;\n@@ -59,4 +58,0 @@\n-  inline PerfVariable* gc_overhead_limit_exceeded_counter() const {\n-    return _gc_overhead_limit_exceeded_counter;\n-  }\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/gcPolicyCounters.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -307,20 +307,0 @@\n-  product(bool, UsePSAdaptiveSurvivorSizePolicy, true,                      \\\n-          \"Use adaptive survivor sizing policies\")                          \\\n-                                                                            \\\n-  product(bool, UseAdaptiveGenerationSizePolicyAtMinorCollection, true,     \\\n-          \"Use adaptive young-old sizing policies at minor collections\")    \\\n-                                                                            \\\n-  product(bool, UseAdaptiveGenerationSizePolicyAtMajorCollection, true,     \\\n-          \"Use adaptive young-old sizing policies at major collections\")    \\\n-                                                                            \\\n-  product(bool, UseAdaptiveSizePolicyWithSystemGC, false,                   \\\n-          \"Include statistics from System.gc() for adaptive size policy\")   \\\n-                                                                            \\\n-  product(uint, AdaptiveSizeThroughPutPolicy, 0,                            \\\n-          \"Policy for changing generation size for throughput goals\")       \\\n-          range(0, 1)                                                       \\\n-                                                                            \\\n-  product(uintx, AdaptiveSizePolicyInitializingSteps, 20,                   \\\n-          \"Number of steps where heuristics is used before data is used\")   \\\n-          range(0, max_uintx)                                               \\\n-                                                                            \\\n@@ -330,7 +310,0 @@\n-  product(uintx, AdaptiveSizePolicyOutputInterval, 0,                       \\\n-          \"Collection interval for printing information; zero means never\") \\\n-          range(0, max_uintx)                                               \\\n-                                                                            \\\n-  product(bool, UseAdaptiveSizePolicyFootprintGoal, true,                   \\\n-          \"Use adaptive minimum footprint as a goal\")                       \\\n-                                                                            \\\n@@ -341,8 +314,0 @@\n-  product(uint, AdaptiveTimeWeight,       25,                               \\\n-          \"Weight given to time in adaptive policy, between 0 and 100\")     \\\n-          range(0, 100)                                                     \\\n-                                                                            \\\n-  product(uint, PausePadding, 1,                                            \\\n-          \"How much buffer to keep for pause time\")                         \\\n-          range(0, UINT_MAX)                                                \\\n-                                                                            \\\n@@ -353,4 +318,0 @@\n-  product(uint, SurvivorPadding, 3,                                         \\\n-          \"How much buffer to keep for survivor overflow\")                  \\\n-          range(0, UINT_MAX)                                                \\\n-                                                                            \\\n@@ -373,12 +334,0 @@\n-  product(uint, TenuredGenerationSizeIncrement, 20,                         \\\n-          \"Adaptive size percentage change in tenured generation\")          \\\n-          range(0, 100)                                                     \\\n-                                                                            \\\n-  product(uint, TenuredGenerationSizeSupplement, 80,                        \\\n-          \"Supplement to TenuredGenerationSizeIncrement used at startup\")   \\\n-          range(0, 100)                                                     \\\n-                                                                            \\\n-  product(uintx, TenuredGenerationSizeSupplementDecay, 2,                   \\\n-          \"Decay factor to TenuredGenerationSizeIncrement\")                 \\\n-          range(1, max_uintx)                                               \\\n-                                                                            \\\n@@ -403,7 +352,0 @@\n-  product(bool, UseAdaptiveSizeDecayMajorGCCost, true,                      \\\n-          \"Adaptive size decays the major cost for long major intervals\")   \\\n-                                                                            \\\n-  product(uintx, AdaptiveSizeMajorGCDecayTimeScale, 10,                     \\\n-          \"Time scale over which major costs decay\")                        \\\n-          range(0, max_uintx)                                               \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":0,"deletions":58,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -553,0 +553,17 @@\n+  { \"AdaptiveSizeMajorGCDecayTimeScale\",                JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"AdaptiveSizePolicyInitializingSteps\",              JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"AdaptiveSizePolicyOutputInterval\",                 JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"AdaptiveSizeThroughPutPolicy\",                     JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"AdaptiveTimeWeight\",                               JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"PausePadding\",                                     JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"SurvivorPadding\",                                  JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"TenuredGenerationSizeIncrement\",                   JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"TenuredGenerationSizeSupplement\",                  JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"TenuredGenerationSizeSupplementDecay\",             JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UseAdaptiveGenerationSizePolicyAtMajorCollection\", JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UseAdaptiveGenerationSizePolicyAtMinorCollection\", JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UseAdaptiveSizeDecayMajorGCCost\",                  JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UseAdaptiveSizePolicyFootprintGoal\",               JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UseAdaptiveSizePolicyWithSystemGC\",                JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+  { \"UsePSAdaptiveSurvivorSizePolicy\",                  JDK_Version::undefined(), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -407,36 +407,0 @@\n-alias sun.gc.policy.avgMajorIntervalTime          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_major_interval      \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgMajorPauseTime             \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_major_pause         \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgMinorIntervalTime          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_minor_interval      \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgMinorPauseTime             \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_minor_pause         \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgOldLive                    \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_old_live            \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgPretenuredPaddedAvg          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_pretenured_padded_avg \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgPromotedAvg                \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_promoted_avg        \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgPromotedDev                \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_promoted_dev        \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgPromotedPaddedAvg          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_promoted_padded_avg \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgSurvivedAvg                \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_survived_avg        \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgSurvivedDev                \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_survived_dev        \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgSurvivedPaddedAvg          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_survived_padded_avg \/\/ 1.5.0 b21\n-alias sun.gc.policy.avgYoungLive                  \/\/ 1.5.0 b39\n-\thotspot.gc.policy.avg_young_live          \/\/ 1.5.0 b21\n-alias sun.gc.policy.boundaryMoved                 \/\/ 1.5.0 b39\n-\thotspot.gc.policy.boundary_moved          \/\/ 1.5.0 b21\n-alias sun.gc.policy.changeOldGenForMajPauses               \/\/ 1.5.0 b39\n-\thotspot.gc.policy.change_old_gen_for_maj_pauses    \/\/ 1.5.0 b21\n-alias sun.gc.policy.changeOldGenForMinPauses               \/\/ 1.5.0 b39\n-\thotspot.gc.policy.change_old_gen_for_min_pauses    \/\/ 1.5.0 b21\n-alias sun.gc.policy.changeYoungGenForMajPauses               \/\/ 1.5.0 b39\n-\thotspot.gc.policy.change_young_gen_for_maj_pauses    \/\/ 1.5.0 b21\n-alias sun.gc.policy.changeYoungGenForMinPauses               \/\/ 1.5.0 b39\n-\thotspot.gc.policy.change_young_gen_for_min_pauses    \/\/ 1.5.0 b21\n@@ -445,8 +409,0 @@\n-alias sun.gc.policy.decideAtFullGc                \/\/ 1.5.0 b39\n-\thotspot.gc.policy.decide_at_full_gc       \/\/ 1.5.0 b21\n-alias sun.gc.policy.decreaseForFootprint          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.decrease_for_footprint  \/\/ 1.5.0 b21\n-alias sun.gc.policy.decrementTenuringThresholdForGcCost             \/\/ 1.5.0 b39\n-\thotspot.gc.policy.decrement_tenuring_threshold_for_gc_cost  \/\/ 1.5.0 b21\n-alias sun.gc.policy.decrementTenuringThresholdForSurvivorLimit             \/\/ 1.5.0 b39\n-\thotspot.gc.policy.decrement_tenuring_threshold_for_survivor_limit  \/\/ 1.5.0 b21\n@@ -456,4 +412,0 @@\n-alias sun.gc.policy.edenSize                      \/\/ 1.5.0 b39\n-\thotspot.gc.policy.eden_size               \/\/ 1.5.0 b21\n-alias sun.gc.policy.freeSpace                     \/\/ 1.5.0 b39\n-\thotspot.gc.policy.free_space              \/\/ 1.5.0 b21\n@@ -464,18 +416,0 @@\n-alias sun.gc.policy.increaseOldGenForThroughput           \/\/ 1.5.0 b39\n-\thotspot.gc.policy.increase_old_gen_for_throughput \/\/ 1.5.0 b21\n-alias sun.gc.policy.increaseYoungGenForThroughput           \/\/ 1.5.0 b39\n-\thotspot.gc.policy.increase_young_gen_for_throughput \/\/ 1.5.0 b21\n-alias sun.gc.policy.incrementTenuringThresholdForGcCost            \/\/ 1.5.0 b39\n-\thotspot.gc.policy.increment_tenuring_threshold_for_gc_cost \/\/ 1.5.0 b21\n-alias sun.gc.policy.liveAtLastFullGc              \/\/ 1.5.0 b39\n-\thotspot.gc.policy.live_at_last_full_gc    \/\/ 1.5.0 b21\n-alias sun.gc.policy.liveSpace                     \/\/ 1.5.0 b39\n-\thotspot.gc.policy.live_space              \/\/ 1.5.0 b21\n-alias sun.gc.policy.majorCollectionSlope          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.major_collection_slope  \/\/ 1.5.0 b21\n-alias sun.gc.policy.majorGcCost                   \/\/ 1.5.0 b39\n-\thotspot.gc.policy.major_gc_cost           \/\/ 1.5.0 b21\n-alias sun.gc.policy.majorPauseOldSlope            \/\/ 1.5.0 b39\n-\thotspot.gc.policy.major_pause_old_slope   \/\/ 1.5.0 b21\n-alias sun.gc.policy.majorPauseYoungSlope          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.major_pause_young_slope \/\/ 1.5.0 b21\n@@ -485,10 +419,0 @@\n-alias sun.gc.policy.minorCollectionSlope          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.minor_collection_slope  \/\/ 1.5.0 b21\n-alias sun.gc.policy.minorGcCost                   \/\/ 1.5.0 b39\n-\thotspot.gc.policy.minor_gc_cost           \/\/ 1.5.0 b21\n-alias sun.gc.policy.minorPauseOldSlope            \/\/ 1.5.0 b39\n-\thotspot.gc.policy.minor_pause_old_slope   \/\/ 1.5.0 b21\n-alias sun.gc.policy.minorPauseYoungSlope          \/\/ 1.5.0 b39\n-\thotspot.gc.policy.minor_pause_young_slope \/\/ 1.5.0 b21\n-alias sun.gc.policy.mutatorCost                   \/\/ 1.5.0 b39\n-\thotspot.gc.policy.mutator_cost            \/\/ 1.5.0 b21\n@@ -497,14 +421,0 @@\n-alias sun.gc.policy.oldCapacity                   \/\/ 1.5.0 b39\n-\thotspot.gc.policy.old_capacity            \/\/ 1.5.0 b21\n-alias sun.gc.policy.oldEdenSize                   \/\/ 1.5.0 b39\n-\thotspot.gc.policy.old_eden_size           \/\/ 1.5.0 b21\n-alias sun.gc.policy.oldPromoSize                  \/\/ 1.5.0 b39\n-\thotspot.gc.policy.old_promo_size          \/\/ 1.5.0 b21\n-alias sun.gc.policy.promoSize                     \/\/ 1.5.0 b39\n-\thotspot.gc.policy.promo_size              \/\/ 1.5.0 b21\n-alias sun.gc.policy.promoted                      \/\/ 1.5.0 b39\n-\thotspot.gc.policy.promoted                \/\/ 1.5.0 b21\n-alias sun.gc.policy.survived                      \/\/ 1.5.0 b39\n-\thotspot.gc.policy.survived                \/\/ 1.5.0 b21\n-alias sun.gc.policy.survivorOverflowed            \/\/ 1.5.0 b39\n-\thotspot.gc.policy.survivor_overflowed     \/\/ 1.5.0 b21\n@@ -513,3 +423,0 @@\n-\thotspot.gc.agetable.tt                    \/\/ 1.4.1\n-alias sun.gc.policy.youngCapacity                 \/\/ 1.5.0 b39\n-\thotspot.gc.policy.young_capacity          \/\/ 1.5.0 b21\n","filename":"src\/jdk.internal.jvmstat\/share\/classes\/sun\/jvmstat\/perfdata\/resources\/aliasmap","additions":0,"deletions":93,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -1,60 +0,0 @@\n-\/*\n- * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"gc\/parallel\/psAdaptiveSizePolicy.hpp\"\n-#include \"utilities\/macros.hpp\"\n-#include \"unittest.hpp\"\n-\n-#if INCLUDE_PARALLELGC\n-\n-  TEST_VM(gc, oldFreeSpaceCalculation) {\n-\n-    struct TestCase {\n-        size_t live;\n-        uintx ratio;\n-        size_t expectedResult;\n-    };\n-\n-    TestCase test_cases[] = {\n-                                {100, 20, 25},\n-                                {100, 50, 100},\n-                                {100, 60, 150},\n-                                {100, 75, 300},\n-                                {400, 20, 100},\n-                                {400, 50, 400},\n-                                {400, 60, 600},\n-                                {400, 75, 1200},\n-                            };\n-\n-    size_t array_len = sizeof(test_cases) \/ sizeof(TestCase);\n-    for (size_t i = 0; i < array_len; ++i) {\n-      ASSERT_EQ(PSAdaptiveSizePolicy::calculate_free_based_on_live(\n-          test_cases[i].live, test_cases[i].ratio),\n-          test_cases[i].expectedResult)\n-          << \" Calculation of free memory failed\"\n-          << \" - Test case \" << i << \": live = \" << test_cases[i].live\n-          << \"; ratio = \" << test_cases[i].ratio;\n-    }\n-  }\n-#endif\n","filename":"test\/hotspot\/gtest\/gc\/parallel\/test_psAdaptiveSizePolicy.cpp","additions":0,"deletions":60,"binary":false,"changes":60,"status":"deleted"},{"patch":"@@ -34,1 +34,1 @@\n- * @run main\/othervm -XX:+UseAdaptiveSizePolicyWithSystemGC -XX:+UseParallelGC -XX:MinHeapFreeRatio=0 -XX:MaxHeapFreeRatio=100 -Xmx1g -verbose:gc gc.parallel.TestDynShrinkHeap\n+ * @run main\/othervm -XX:+UseParallelGC -XX:MinHeapFreeRatio=0 -XX:MaxHeapFreeRatio=100 -Xmx1g -verbose:gc gc.parallel.TestDynShrinkHeap\n","filename":"test\/hotspot\/jtreg\/gc\/parallel\/TestDynShrinkHeap.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}