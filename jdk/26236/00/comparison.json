{"files":[{"patch":"@@ -2703,6 +2703,7 @@\n-  \/\/ Loads and stores with indirect memory input (e.g., volatile loads and\n-  \/\/ stores) do not subsume the input into complex addressing expressions. If\n-  \/\/ the addressing expression is input to at least one such load or store, do\n-  \/\/ not clone the addressing expression. Query needs_acquiring_load and\n-  \/\/ needs_releasing_store as a proxy for indirect memory input, as it is not\n-  \/\/ possible to directly query for indirect memory input at this stage.\n+  \/\/ Loads and stores with indirect memory input (e.g., volatile loads\/stores,\n+  \/\/ and vector gather_loads\/scatter_stores) do not subsume the input into\n+  \/\/ complex addressing expressions. If the addressing expression is input\n+  \/\/ to at least one such load or store, do not clone the addressing expression.\n+  \/\/ Query needs_acquiring_load and needs_releasing_store as a proxy for\n+  \/\/ indirect memory input, as it is not possible to directly query for indirect\n+  \/\/ memory input at this stage.\n@@ -2717,0 +2718,7 @@\n+\n+    if (n->is_LoadVectorGather() ||\n+        n->is_StoreVectorScatter() ||\n+        n->is_LoadVectorGatherMasked() ||\n+        n->is_StoreVectorScatterMasked()) {\n+      return false;\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":14,"deletions":6,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -171,0 +171,2 @@\n+      case Op_LoadVectorGather:\n+      case Op_LoadVectorGatherMasked:\n@@ -177,0 +179,3 @@\n+      \/\/ Temporarily disable vector mask widen support for NEON,\n+      \/\/ because we do not have the use case now.\n+      case Op_VectorMaskWiden:\n@@ -181,6 +186,0 @@\n-      case Op_LoadVectorGather:\n-      case Op_LoadVectorGatherMasked:\n-        if (UseSVE == 0 || is_subword_type(bt)) {\n-          return false;\n-        }\n-        break;\n@@ -5326,0 +5325,18 @@\n+\/\/ ------------------------- VectorConcatenateAndNarrow ------------------------\n+instruct vconcatenate(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (VectorConcatenateAndNarrow src1 src2));\n+  format %{ \"vconcatenate $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ uzp1($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_uzp1($dst$$FloatRegister, get_reg_variant(this),\n+                  $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5989,0 +6006,26 @@\n+\/\/ Vector mask widen to twice size\n+\/\/\n+\/\/ Unpack elements from the lower or upper half of the source\n+\/\/ predicate and place in elements of twice their size within\n+\/\/ the destination predicate.\n+\n+instruct vmaskwiden_lo_sve(pReg dst, pReg src) %{\n+  predicate(UseSVE > 0 && !n->as_VectorMaskWiden()->is_hi());\n+  match(Set dst (VectorMaskWiden src));\n+  format %{ \"vmaskwiden_lo_sve $dst, $src\" %}\n+  ins_encode %{\n+    __ sve_punpklo($dst$$PRegister, $src$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskwiden_hi_sve(pReg dst, pReg src) %{\n+  predicate(UseSVE > 0 && n->as_VectorMaskWiden()->is_hi());\n+  match(Set dst (VectorMaskWiden src));\n+  format %{ \"vmaskwiden_hi_sve $dst, $src\" %}\n+  ins_encode %{\n+    __ sve_punpkhi($dst$$PRegister, $src$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -6720,0 +6763,28 @@\n+instruct gather_loadB(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == 1);\n+  match(Set dst (LoadVectorGather mem idx));\n+  format %{ \"gather_loadB $dst, $mem, $idx\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_ld1b_gather($dst$$FloatRegister, ptrue,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadH(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == 2);\n+  match(Set dst (LoadVectorGather mem idx));\n+  format %{ \"gather_loadH $dst, $mem, $idx\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_ld1h_gather($dst$$FloatRegister, ptrue,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -6722,1 +6793,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == 4);\n@@ -6730,1 +6801,1 @@\n- %}\n+  %}\n@@ -6736,1 +6807,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == 8);\n@@ -6750,0 +6821,26 @@\n+\/\/ ------------------------------ Vector Load Gather Masked ---------------------------\n+\n+instruct gather_loadB_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == 1);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  format %{ \"gather_loadB_masked $dst, $pg, $mem, $idx\" %}\n+  ins_encode %{\n+    __ sve_ld1b_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadH_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == 2);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  format %{ \"gather_loadH_masked $dst, $pg, $mem, $idx\" %}\n+  ins_encode %{\n+    __ sve_ld1h_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -6752,1 +6849,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == 4);\n@@ -6764,1 +6861,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == 8);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":108,"deletions":11,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -161,0 +161,2 @@\n+      case Op_LoadVectorGather:\n+      case Op_LoadVectorGatherMasked:\n@@ -167,0 +169,3 @@\n+      \/\/ Temporarily disable vector mask widen support for NEON,\n+      \/\/ because we do not have the use case now.\n+      case Op_VectorMaskWiden:\n@@ -171,6 +176,0 @@\n-      case Op_LoadVectorGather:\n-      case Op_LoadVectorGatherMasked:\n-        if (UseSVE == 0 || is_subword_type(bt)) {\n-          return false;\n-        }\n-        break;\n@@ -3471,0 +3470,18 @@\n+\/\/ ------------------------- VectorConcatenateAndNarrow ------------------------\n+instruct vconcatenate(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (VectorConcatenateAndNarrow src1 src2));\n+  format %{ \"vconcatenate $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ uzp1($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_uzp1($dst$$FloatRegister, get_reg_variant(this),\n+                  $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -4042,0 +4059,22 @@\n+dnl\n+dnl VECTOR_MASK_WIDEN($1)\n+dnl VECTOR_MASK_WIDEN(part)\n+define(`VECTOR_MASK_WIDEN', `\n+instruct vmaskwiden_$1_sve(pReg dst, pReg src) %{\n+  predicate(UseSVE > 0 && ifelse(lo, $1, !, `')n->as_VectorMaskWiden()->is_hi());\n+  match(Set dst (VectorMaskWiden src));\n+  format %{ \"vmaskwiden_$1_sve $dst, $src\" %}\n+  ins_encode %{\n+    __ sve_punpk$1($dst$$PRegister, $src$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\n+\/\/ Vector mask widen to twice size\n+\/\/\n+\/\/ Unpack elements from the lower or upper half of the source\n+\/\/ predicate and place in elements of twice their size within\n+\/\/ the destination predicate.\n+VECTOR_MASK_WIDEN(lo)\n+VECTOR_MASK_WIDEN(hi)\n@@ -4727,4 +4766,5 @@\n-\n-\/\/ ------------------------------ Vector Load Gather ---------------------------\n-\n-instruct gather_loadS(vReg dst, indirect mem, vReg idx) %{\n+dnl\n+dnl VECTOR_GATHER_LOAD_BHS($1,   $2,   $3  )\n+dnl VECTOR_GATHER_LOAD_BHS(type, size, inst)\n+define(`VECTOR_GATHER_LOAD_BHS', `\n+instruct gather_load$1(vReg dst, indirect mem, vReg idx) %{\n@@ -4732,1 +4772,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == $2);\n@@ -4734,1 +4774,1 @@\n-  format %{ \"gather_loadS $dst, $mem, $idx\\t# vector (sve)\" %}\n+  format %{ \"gather_load$1 $dst, $mem, $idx\\t# vector (sve)\" %}\n@@ -4738,1 +4778,1 @@\n-    __ sve_ld1w_gather($dst$$FloatRegister, ptrue,\n+    __ sve_$3_gather($dst$$FloatRegister, ptrue,\n@@ -4740,1 +4780,1 @@\n- %}\n+  %}\n@@ -4742,1 +4782,23 @@\n-%}\n+%}')dnl\n+dnl\n+dnl\n+dnl VECTOR_GATHER_LOAD_PREDICATE_BHS($1,   $2,   $3  )\n+dnl VECTOR_GATHER_LOAD_PREDICATE_BHS(type, size, inst)\n+define(`VECTOR_GATHER_LOAD_PREDICATE_BHS', `\n+instruct gather_load$1_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == $2);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  format %{ \"gather_load$1_masked $dst, $pg, $mem, $idx\" %}\n+  ins_encode %{\n+    __ sve_$3_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------\n+VECTOR_GATHER_LOAD_BHS(B, 1, ld1b)\n+VECTOR_GATHER_LOAD_BHS(H, 2, ld1h)\n+VECTOR_GATHER_LOAD_BHS(S, 4, ld1w)\n@@ -4746,1 +4808,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+            type2aelembytes(n->as_LoadVectorGather()->mem_bt()) == 8);\n@@ -4760,11 +4822,4 @@\n-instruct gather_loadS_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n-  predicate(UseSVE > 0 &&\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n-  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n-  format %{ \"gather_loadS_masked $dst, $pg, $mem, $idx\" %}\n-  ins_encode %{\n-    __ sve_ld1w_gather($dst$$FloatRegister, $pg$$PRegister,\n-                       as_Register($mem$$base), $idx$$FloatRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n+\/\/ ------------------------------ Vector Load Gather Masked ---------------------------\n+VECTOR_GATHER_LOAD_PREDICATE_BHS(B, 1, ld1b)\n+VECTOR_GATHER_LOAD_PREDICATE_BHS(H, 2, ld1h)\n+VECTOR_GATHER_LOAD_PREDICATE_BHS(S, 4, ld1w)\n@@ -4774,1 +4829,1 @@\n-            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+            type2aelembytes(n->as_LoadVectorGatherMasked()->mem_bt()) == 8);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":83,"deletions":28,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -3664,0 +3664,4 @@\n+  \/\/ SVE 8-bit gather load bytes (scalar plus 32-bit unscaled offsets)\n+  INSN(sve_ld1b_gather,  0b1000010, 0b00, 0b00, 0b010);\n+  \/\/ SVE 16-bit gather load halfwords (scalar plus 32-bit scaled offsets)\n+  INSN(sve_ld1h_gather,  0b1000010, 0b01, 0b01, 0b010);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -167,0 +167,10 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  \/\/\n+  \/\/ SVE requires vector indices for gather-load\/scatter-store operations on all\n+  \/\/ data types.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/matcher_aarch64.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -160,0 +160,7 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/arm\/matcher_arm.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -170,0 +170,7 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/ppc\/matcher_ppc.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -166,0 +166,7 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/matcher_riscv.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -163,0 +163,7 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/s390\/matcher_s390.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -158,0 +158,9 @@\n+  \/\/ Return true if this CPU requires the index input saved in an array address\n+  \/\/ for vector gather-load\/scatter-store operations. Otherwise, return false if\n+  \/\/ the index input should be saved in a vector register.\n+  \/\/\n+  \/\/ Subword gather operations require the index input saved in an array address.\n+  static bool gather_scatter_requires_index_in_address(BasicType bt) {\n+    return is_subword_type(bt);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -4363,1 +4363,1 @@\n-    \"VectorRearrange\", \"VectorLoadShuffle\", \"VectorLoadConst\",\n+    \"VectorRearrange\", \"VectorLoadShuffle\", \"VectorLoadConst\", \"VectorConcatenateAndNarrow\",\n@@ -4371,1 +4371,1 @@\n-    \"MaskAll\", \"AndVMask\", \"OrVMask\", \"XorVMask\", \"VectorMaskCast\",\n+    \"MaskAll\", \"AndVMask\", \"OrVMask\", \"XorVMask\", \"VectorMaskCast\", \"VectorMaskWiden\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -518,0 +518,1 @@\n+macro(VectorMaskWiden)\n@@ -538,0 +539,1 @@\n+macro(VectorConcatenateAndNarrow)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -421,0 +421,2 @@\n+  Node* gen_vector_gather_load(Node* addr, Node* indexes, Node* indexes1, Node* indexes2, Node* indexes3, Node* mask, const TypeVect* vt);\n+  Node* gen_mask_for_subword_gather(Node* mask, const TypeVect* vt, uint part);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -196,0 +196,1 @@\n+class VectorMaskWidenNode;\n@@ -753,0 +754,1 @@\n+        DEFINE_CLASS_ID(VectorMaskWiden, Vector, 11)\n@@ -1015,0 +1017,1 @@\n+  DEFINE_CLASS_QUERY(VectorMaskWiden)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1185,0 +1185,136 @@\n+\/\/ Widen the input mask \"in\" from \"byte|short\" to \"int\" for use in vector gather loads.\n+\/\/ The \"part\" parameter selects which segment of the original mask to extend.\n+Node* LibraryCallKit::gen_mask_for_subword_gather(Node* in, const TypeVect* vt, uint part) {\n+  assert(vt->element_basic_type() == T_INT, \"must be\");\n+  const TypeVect* in_vt = in->bottom_type()->is_vect();\n+  BasicType in_bt = in_vt->element_basic_type();\n+\n+  if (in_bt == T_BYTE) {\n+    assert(part < 4, \"must be\");\n+    const TypeVect* temp_vt = TypeVect::makemask(T_SHORT, vt->length() * 2);\n+    \/\/ If part == 0, extend elements from the lowest 1\/4 of the input.\n+    \/\/ If part == 1, extend elements from the second 1\/4 of the input.\n+    \/\/ If part == 2, extend elements from the third 1\/4 of the input.\n+    \/\/ If part == 3, extend elements from the highest 1\/4 of the input.\n+    Node* mask = gvn().transform(new VectorMaskWidenNode(in, temp_vt, \/* is_hi *\/ (part & 2) != 0));\n+    return gvn().transform(new VectorMaskWidenNode(mask, vt, \/* is_hi *\/ (part & 1) != 0));\n+  }\n+\n+  assert(in_bt == T_SHORT, \"must be a subword type\");\n+  assert(part == 0 || part == 1, \"must be\");\n+  \/\/ If part == 0, extend elements from the lower half of the input.\n+  \/\/ If part == 1, extend elements from the upper half of the input.\n+  return gvn().transform(new VectorMaskWidenNode(in, vt, \/* is_hi *\/ part == 1));\n+}\n+\n+Node* LibraryCallKit::gen_vector_gather_load(Node* addr, Node* indexes0, Node* indexes1, Node* indexes2,\n+                                             Node* indexes3, Node* mask, const TypeVect* vt) {\n+  BasicType elem_bt = vt->element_basic_type();\n+  const TypeVect* index_vt = indexes0->bottom_type()->isa_vect();\n+  const TypePtr* addr_type = gvn().type(addr)->isa_ptr();\n+  Node* addr_mem = memory(addr);\n+\n+  \/\/ A single gather-load IR is generated with mask and the vector type unchanged. This happens\n+  \/\/ for the following cases:\n+  \/\/ 1. It's not loading a subword type vector (e.g. int\/long\/float\/double).\n+  \/\/ 2. It's loading a subword type vector on platforms (e.g. X86_64) that the gather IR does\n+  \/\/    not accept a vector index.\n+  if (!is_subword_type(elem_bt) || index_vt == nullptr) {\n+    if (mask != nullptr) {\n+      return gvn().transform(new LoadVectorGatherMaskedNode(control(), addr_mem, addr, addr_type,\n+                                                            vt, indexes0, mask));\n+    }\n+    return gvn().transform(new LoadVectorGatherNode(control(), addr_mem, addr, addr_type, vt, indexes0));\n+  }\n+\n+  \/\/ Otherwise, because the vector gather-load oepration works on the same type of the vector\n+  \/\/ indice, the vector type of each gather-load IR will be defined as the indice type.\n+  \/\/\n+  \/\/ For masked operation, the given mask may need to be split and used by multiple masked vector\n+  \/\/ gather-loads respectively. Additionally, each part of the mask needs to be converted to int\n+  \/\/ type.\n+  \/\/\n+  \/\/ For example, if it is gather loading a short vector and it needs two times of gather-load,\n+  \/\/ the lower half of the given mask is used by the first gather-load, and the upper half of the\n+  \/\/ given mask is used by the second gather-load. It will be more complicated for byte vector,\n+  \/\/ that the mask maybe split into 4 parts. Here is an example for byte vector:\n+  \/\/\n+  \/\/  mask = [1010 0101 1111 1100]\n+  \/\/          ---- ---- ---- ----\n+  \/\/            |    |    |    |------ gather_mask0\n+  \/\/            |    |    |----------- gather_mask1\n+  \/\/            |    |---------------- gather_mask2\n+  \/\/            |--------------------- gather_mask3\n+\n+  \/\/ Define the type of the gather mask as the same as the vector indice.\n+  const TypeVect* mask_vt = mask != nullptr ? TypeVect::makemask(T_INT, index_vt->length()) : nullptr;\n+\n+  \/\/ The first vector gather-load.\n+  Node* gather_mask = nullptr;\n+  Node* vgather = nullptr;\n+  if (mask != nullptr) {\n+    gather_mask = gen_mask_for_subword_gather(mask, mask_vt, 0);\n+    vgather = gvn().transform(new LoadVectorGatherMaskedNode(control(), addr_mem, addr, addr_type,\n+                                                             index_vt, indexes0, gather_mask, elem_bt));\n+  } else {\n+    vgather = gvn().transform(new LoadVectorGatherNode(control(), addr_mem, addr, addr_type,\n+                                                       index_vt, indexes0, elem_bt));\n+  }\n+\n+  \/\/ If one gather-load is enough, cast the gather result to the target subword vector type.\n+  if (indexes1 == nullptr) {\n+    assert(indexes2 == nullptr && indexes3 == nullptr, \"must be\");\n+    return gvn().transform(new VectorCastI2XNode(vgather, vt));\n+  }\n+\n+  \/\/ It needs more than 2 times of gather-load. Here begins the second vector gather-load.\n+  assert(Type::equals(indexes1->bottom_type(), index_vt), \"index vector type mismatch\");\n+  Node* vgather1 = nullptr;\n+  if (mask != nullptr) {\n+    gather_mask = gen_mask_for_subword_gather(mask, mask_vt, 1);\n+    vgather1 = gvn().transform(new LoadVectorGatherMaskedNode(control(), addr_mem, addr, addr_type,\n+                                                              index_vt, indexes1, gather_mask, elem_bt));\n+  } else {\n+    vgather1 = gvn().transform(new LoadVectorGatherNode(control(), addr_mem, addr, addr_type,\n+                                                        index_vt, indexes1, elem_bt));\n+  }\n+  \/\/ Merge the second gather result with the first one.\n+  const TypeVect* merge_vt = TypeVect::make(T_SHORT, index_vt->length() * 2);\n+  Node* merge1 = gvn().transform(new VectorConcatenateAndNarrowNode(vgather, vgather1, merge_vt));\n+\n+  \/\/ If two gather-loads are enough, return the merged result.\n+  if (indexes2 == nullptr) {\n+    assert(indexes3 == nullptr, \"must be\");\n+    if (elem_bt == T_BYTE) {\n+      merge1 = gvn().transform(new VectorCastS2XNode(merge1, vt));\n+    }\n+    return merge1;\n+  }\n+\n+  \/\/ It needs 4 times of gather-load. This should just happen for byte vector.\n+  \/\/ Here begins the third and fourth vector gather-load.\n+  assert(elem_bt == T_BYTE, \"must be\");\n+  assert(indexes3 != nullptr, \"must be\");\n+  assert(Type::equals(indexes2->bottom_type(), index_vt), \"index vector type mismatch\");\n+  assert(Type::equals(indexes3->bottom_type(), index_vt), \"index vector type mismatch\");\n+  Node* vgather2 = nullptr;\n+  Node* vgather3 = nullptr;\n+  if (mask != nullptr) {\n+    gather_mask = gen_mask_for_subword_gather(mask, mask_vt, 2);\n+    vgather2 = gvn().transform(new LoadVectorGatherMaskedNode(control(), addr_mem, addr, addr_type,\n+                                                              index_vt, indexes2, gather_mask, elem_bt));\n+    gather_mask = gen_mask_for_subword_gather(mask, mask_vt, 3);\n+    vgather3 = gvn().transform(new LoadVectorGatherMaskedNode(control(), addr_mem, addr, addr_type,\n+                                                              index_vt, indexes3, gather_mask, elem_bt));\n+  } else {\n+    vgather2 = gvn().transform(new LoadVectorGatherNode(control(), addr_mem, addr, addr_type,\n+                                                        index_vt, indexes2, elem_bt));\n+    vgather3 = gvn().transform(new LoadVectorGatherNode(control(), addr_mem, addr, addr_type,\n+                                                        index_vt, indexes3, elem_bt));\n+  }\n+  \/\/ Merge the third and fourth gather results.\n+  Node* merge2 = gvn().transform(new VectorConcatenateAndNarrowNode(vgather2, vgather3, merge_vt));\n+  \/\/ Merge the two merged results.\n+  return gvn().transform(new VectorConcatenateAndNarrowNode(merge1, merge2, vt));\n+}\n+\n@@ -1285,7 +1421,25 @@\n-  \/\/ Check that the vector holding indices is supported by architecture\n-  \/\/ For sub-word gathers expander receive index array.\n-  if (!is_subword_type(elem_bt) && !arch_supports_vector(Op_LoadVector, idx_num_elem, T_INT, VecMaskNotUsed)) {\n-    log_if_needed(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int is_masked_op=%d\",\n-                  is_scatter, is_scatter ? \"scatter\" : \"gather\",\n-                  idx_num_elem, is_masked_op ? 1 : 0);\n-    return false; \/\/ not supported\n+  bool needs_index_address = Matcher::gather_scatter_requires_index_in_address(elem_bt);\n+  if (!needs_index_address) {\n+    \/\/ Check that the vector holding indices is supported by architecture\n+    if (!arch_supports_vector(Op_LoadVector, idx_num_elem, T_INT, VecMaskNotUsed)) {\n+      log_if_needed(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int is_masked_op=%d\",\n+                    is_scatter, is_scatter ? \"scatter\" : \"gather\",\n+                    idx_num_elem, is_masked_op ? 1 : 0);\n+      return false; \/\/ not supported\n+    }\n+\n+    \/\/ Check more ops that are necessary to finish the whole subword gather with vector indexes.\n+    if (!is_scatter && gvn().type(argument(10)) != TypePtr::NULL_PTR) {\n+      assert(is_subword_type(elem_bt), \"Only subword gather operation accepts multiple indexes\");\n+      if (!arch_supports_vector(Op_VectorConcatenateAndNarrow, idx_num_elem, T_INT, VecMaskNotUsed)) {\n+        log_if_needed(\"  ** not supported: op=gather\/merge vlen=%d etype=%s is_masked_op=%d\",\n+                      num_elem, type2name(elem_bt), is_masked_op ? 1 : 0);\n+        return false; \/\/ not supported\n+      }\n+\n+      if (is_masked_op && !arch_supports_vector(Op_VectorMaskWiden, idx_num_elem, T_INT, VecMaskNotUsed)) {\n+        log_if_needed(\"  ** not supported: op=gather\/maskwiden vlen=%d etype=%s is_masked_op=1\",\n+                      idx_num_elem, type2name(elem_bt));\n+        return false; \/\/ not supported\n+      }\n+    }\n@@ -1301,1 +1455,1 @@\n-  if (!is_subword_type(elem_bt)) {\n+  if (!needs_index_address) {\n@@ -1304,0 +1458,1 @@\n+    assert(is_subword_type(elem_bt), \"Only subword gather operation supports non-vector indexes\");\n@@ -1333,1 +1488,1 @@\n-  if (is_subword_type(elem_bt)) {\n+  if (needs_index_address) {\n@@ -1345,0 +1500,31 @@\n+  \/\/ Get other index vectors if they are not nullptr for subword gather operation.\n+  Node* indexes1 = nullptr;\n+  Node* indexes2 = nullptr;\n+  Node* indexes3 = nullptr;\n+  if (!is_scatter && !needs_index_address) {\n+    \/\/ Get the second index vector if it is not nullptr.\n+    Node* idx1 = argument(10);\n+    if (gvn().type(idx1) != TypePtr::NULL_PTR) {\n+      indexes1 = unbox_vector(idx1, vbox_idx_type, T_INT, idx_num_elem);\n+      if (indexes1 == nullptr) {\n+        return false;\n+      }\n+    }\n+\n+    \/\/ Get the third and fourth index vectors if they are not nullptr.\n+    Node* idx2 = argument(11);\n+    Node* idx3 = argument(12);\n+    if (gvn().type(idx2) != TypePtr::NULL_PTR) {\n+      assert(elem_bt == T_BYTE, \"Only byte gather needs more than 2 index vectors\");\n+      if (gvn().type(idx3) == TypePtr::NULL_PTR) {\n+        return false;\n+      }\n+\n+      indexes2 = unbox_vector(idx2, vbox_idx_type, T_INT, idx_num_elem);\n+      indexes3 = unbox_vector(idx3, vbox_idx_type, T_INT, idx_num_elem);\n+      if (indexes2 == nullptr || indexes3 == nullptr) {\n+        return false;\n+      }\n+    }\n+  }\n+\n@@ -1373,6 +1559,1 @@\n-    Node* vload = nullptr;\n-    if (mask != nullptr) {\n-      vload = gvn().transform(new LoadVectorGatherMaskedNode(control(), memory(addr), addr, addr_type, vector_type, indexes, mask));\n-    } else {\n-      vload = gvn().transform(new LoadVectorGatherNode(control(), memory(addr), addr, addr_type, vector_type, indexes));\n-    }\n+    Node* vload = gen_vector_gather_load(addr, indexes, indexes1, indexes2, indexes3, mask, vector_type);\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":196,"deletions":15,"binary":false,"changes":211,"status":"modified"},{"patch":"@@ -970,1 +970,2 @@\n-                                          node->in(3), mask);\n+                                          node->in(3), mask,\n+                                          node->as_LoadVectorGather()->mem_bt());\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1120,1 +1120,4 @@\n-\/\/ Load Vector from memory via index map\n+\/\/ Load Vector from memory via index map. The index map is usually a vector of indices\n+\/\/ that has the same vector type as the node's bottom type. For non-subword types, it must\n+\/\/ be. However, for subword types, the basic type of index is int. Hence, the index map\n+\/\/ can be either a vector with int elements or an address which saves the int indices.\n@@ -1122,0 +1125,9 @@\n+ private:\n+  \/\/ The basic type of memory, which might be different with the vector element type\n+  \/\/ when it is a subword type loading.\n+  \/\/\n+  \/\/ For example, when it is a byte type loading, the memory basic type is T_BYTE while\n+  \/\/ the vector element type of this node is T_INT, if the indices input has a vector\n+  \/\/ type.\n+  BasicType _mem_bt;\n+\n@@ -1123,1 +1135,1 @@\n-  LoadVectorGatherNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, Node* indices)\n+  LoadVectorGatherNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, Node* indices, BasicType mem_bt = T_ILLEGAL)\n@@ -1130,0 +1142,1 @@\n+    _mem_bt = mem_bt != T_ILLEGAL ? mem_bt : vt->element_basic_type();\n@@ -1140,0 +1153,2 @@\n+  virtual uint size_of() const { return sizeof(*this); }\n+  BasicType mem_bt() const { return _mem_bt; }\n@@ -1185,2 +1200,2 @@\n-\/\/ Store Vector into memory via index map\n-\n+\/\/ Store Vector into memory via index map. The index map is usually a vector of indices\n+\/\/ that has the same vector type as the node's bottom type.\n@@ -1251,0 +1266,4 @@\n+\/\/ The index map is usually a vector of indices that has the same vector type as the node's\n+\/\/ bottom type. For non-subword types, it must be. However, for subword types, the basic type\n+\/\/ of index is int. Hence, the index map can be either a vector with int elements or an address\n+\/\/ which saves the int indices.\n@@ -1252,0 +1271,8 @@\n+ private:\n+  \/\/ The basic type of memory, which might be different with the vector element type when it\n+  \/\/ is a subword type loading.\n+  \/\/\n+  \/\/ For example, when it is a byte type loading, the memory basic type is T_BYTE while\n+  \/\/ the vector element type of this node is T_INT, if the indices input has a vector type.\n+  BasicType _mem_bt;\n+\n@@ -1253,1 +1280,2 @@\n-  LoadVectorGatherMaskedNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, Node* indices, Node* mask)\n+  LoadVectorGatherMaskedNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt,\n+                             Node* indices, Node* mask, BasicType mem_bt = T_ILLEGAL)\n@@ -1260,0 +1288,1 @@\n+    _mem_bt = mem_bt != T_ILLEGAL ? mem_bt : vt->element_basic_type();\n@@ -1270,0 +1299,2 @@\n+  virtual uint size_of() const { return sizeof(*this); }\n+  BasicType mem_bt() const { return _mem_bt; }\n@@ -1748,0 +1779,20 @@\n+\/\/ Concatenate elements from two source vectors by narrowing the elements to half size. Put\n+\/\/ the narrowed elements from the first source vector to the lower half of the destination\n+\/\/ vector, and the narrowed elements from the second source vector to the upper half.\n+\/\/\n+\/\/ e.g. vec1 = [0d 0c 0b 0a], vec2 = [0h 0g 0f 0e]\n+\/\/      dst = [h g f e d c b a]\n+\/\/\n+class VectorConcatenateAndNarrowNode : public VectorNode {\n+ public:\n+  VectorConcatenateAndNarrowNode(Node* vec1, Node* vec2, const TypeVect* vt)\n+    : VectorNode(vec1, vec2, vt) {\n+    assert(Type::equals(vec1->bottom_type(), vec2->bottom_type()), \"must be same vector type\");\n+    assert(vec1->bottom_type()->is_vect()->length_in_bytes() ==\n+           vt->length_in_bytes(), \"vector length mismatch\");\n+    assert(type2aelembytes(vec1->bottom_type()->is_vect()->element_basic_type()) ==\n+           type2aelembytes(vt->element_basic_type()) * 2, \"must be half size\");\n+  }\n+\n+  virtual int Opcode() const;\n+};\n@@ -1809,0 +1860,30 @@\n+\/\/ Unpack the elements to twice size.\n+class VectorMaskWidenNode : public VectorNode {\n+ private:\n+  \/\/ \"_is_hi\" is used to denote whether the upper or lower half of the elements\n+  \/\/ are widened. Widen the upper half part if it is true, otherwise widen the\n+  \/\/ lower half part.\n+  \/\/\n+  \/\/ E.g. src = [1111 0101]\n+  \/\/      _is_hi = false, dst = [0001 0001]\n+  \/\/      _is_hi = true, dst = [0101 0101]\n+  bool _is_hi;\n+\n+ public:\n+  VectorMaskWidenNode(Node* in, const TypeVect* vt, bool is_hi)\n+    : VectorNode(in, vt), _is_hi(is_hi) {\n+    init_class_id(Class_VectorMaskWiden);\n+    const TypeVect* in_vt = in->bottom_type()->is_vect();\n+    assert(type2aelembytes(in_vt->element_basic_type()) ==\n+           type2aelembytes(vt->element_basic_type()) \/ 2, \"must be half size\");\n+  }\n+\n+  bool is_hi() const { return _is_hi; }\n+  virtual int Opcode() const;\n+  virtual uint size_of() const { return sizeof(*this); }\n+  virtual uint hash() const { return Node::hash() + _is_hi; }\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _is_hi == ((VectorMaskWidenNode&)n).is_hi();\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":86,"deletions":5,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -2096,0 +2096,2 @@\n+                        [\"ld1b\",     \"__ sve_ld1b_gather(z15, p0, r5, z16);\",              \"ld1b\\t{z15.s}, p0\/z, [x5, z16.s, uxtw]\"],\n+                        [\"ld1h\",     \"__ sve_ld1h_gather(z15, p0, r5, z16);\",              \"ld1h\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #1]\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1109,0 +1109,2 @@\n+    __ sve_ld1b_gather(z15, p0, r5, z16);              \/\/       ld1b    {z15.s}, p0\/z, [x5, z16.s, uxtw]\n+    __ sve_ld1h_gather(z15, p0, r5, z16);              \/\/       ld1h    {z15.s}, p0\/z, [x5, z16.s, uxtw #1]\n@@ -1452,7 +1454,7 @@\n-    0x14000000,     0x17ffffd7,     0x140004bb,     0x94000000,\n-    0x97ffffd4,     0x940004b8,     0x3400000a,     0x34fffa2a,\n-    0x340096aa,     0x35000008,     0x35fff9c8,     0x35009648,\n-    0xb400000b,     0xb4fff96b,     0xb40095eb,     0xb500001d,\n-    0xb5fff91d,     0xb500959d,     0x10000013,     0x10fff8b3,\n-    0x10009533,     0x90000013,     0x36300016,     0x3637f836,\n-    0x363094b6,     0x3758000c,     0x375ff7cc,     0x3758944c,\n+    0x14000000,     0x17ffffd7,     0x140004bd,     0x94000000,\n+    0x97ffffd4,     0x940004ba,     0x3400000a,     0x34fffa2a,\n+    0x340096ea,     0x35000008,     0x35fff9c8,     0x35009688,\n+    0xb400000b,     0xb4fff96b,     0xb400962b,     0xb500001d,\n+    0xb5fff91d,     0xb50095dd,     0x10000013,     0x10fff8b3,\n+    0x10009573,     0x90000013,     0x36300016,     0x3637f836,\n+    0x363094f6,     0x3758000c,     0x375ff7cc,     0x3758948c,\n@@ -1463,13 +1465,13 @@\n-    0x54009220,     0x54000001,     0x54fff541,     0x540091c1,\n-    0x54000002,     0x54fff4e2,     0x54009162,     0x54000002,\n-    0x54fff482,     0x54009102,     0x54000003,     0x54fff423,\n-    0x540090a3,     0x54000003,     0x54fff3c3,     0x54009043,\n-    0x54000004,     0x54fff364,     0x54008fe4,     0x54000005,\n-    0x54fff305,     0x54008f85,     0x54000006,     0x54fff2a6,\n-    0x54008f26,     0x54000007,     0x54fff247,     0x54008ec7,\n-    0x54000008,     0x54fff1e8,     0x54008e68,     0x54000009,\n-    0x54fff189,     0x54008e09,     0x5400000a,     0x54fff12a,\n-    0x54008daa,     0x5400000b,     0x54fff0cb,     0x54008d4b,\n-    0x5400000c,     0x54fff06c,     0x54008cec,     0x5400000d,\n-    0x54fff00d,     0x54008c8d,     0x5400000e,     0x54ffefae,\n-    0x54008c2e,     0x5400000f,     0x54ffef4f,     0x54008bcf,\n+    0x54009260,     0x54000001,     0x54fff541,     0x54009201,\n+    0x54000002,     0x54fff4e2,     0x540091a2,     0x54000002,\n+    0x54fff482,     0x54009142,     0x54000003,     0x54fff423,\n+    0x540090e3,     0x54000003,     0x54fff3c3,     0x54009083,\n+    0x54000004,     0x54fff364,     0x54009024,     0x54000005,\n+    0x54fff305,     0x54008fc5,     0x54000006,     0x54fff2a6,\n+    0x54008f66,     0x54000007,     0x54fff247,     0x54008f07,\n+    0x54000008,     0x54fff1e8,     0x54008ea8,     0x54000009,\n+    0x54fff189,     0x54008e49,     0x5400000a,     0x54fff12a,\n+    0x54008dea,     0x5400000b,     0x54fff0cb,     0x54008d8b,\n+    0x5400000c,     0x54fff06c,     0x54008d2c,     0x5400000d,\n+    0x54fff00d,     0x54008ccd,     0x5400000e,     0x54ffefae,\n+    0x54008c6e,     0x5400000f,     0x54ffef4f,     0x54008c0f,\n@@ -1684,72 +1686,72 @@\n-    0x853040af,     0xc5b040af,     0xe57080af,     0xe5b080af,\n-    0x25034440,     0x254054c4,     0x25034640,     0x25415a05,\n-    0x25834440,     0x25c54489,     0x250b5d3a,     0x2550dc20,\n-    0x2518e3e1,     0x2518e021,     0x2518e0a1,     0x2518e121,\n-    0x2518e1a1,     0x2558e3e2,     0x2558e042,     0x2558e0c2,\n-    0x2558e142,     0x2598e3e3,     0x2598e063,     0x2598e0e3,\n-    0x2598e163,     0x25d8e3e4,     0x25d8e084,     0x25d8e104,\n-    0x25d8e184,     0x2518e407,     0x05214800,     0x05614800,\n-    0x05a14800,     0x05e14800,     0x05214c00,     0x05614c00,\n-    0x05a14c00,     0x05e14c00,     0x05304001,     0x05314001,\n-    0x05a18610,     0x05e18610,     0x0420bc31,     0x05271e11,\n-    0x6545e891,     0x6585e891,     0x65c5e891,     0x6545c891,\n-    0x6585c891,     0x65c5c891,     0x052c8020,     0x056c8020,\n-    0x05ac8020,     0x05ec8020,     0x45b0c210,     0x45f1c231,\n-    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,\n-    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,\n-    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,\n-    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,\n-    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,\n-    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,\n-    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,\n-    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,\n-    0xf8268267,     0xf82d023c,     0xf8301046,     0xf83d2083,\n-    0xf8263290,     0xf82d528c,     0xf8284299,     0xf8337160,\n-    0xf8386286,     0xf8bf820e,     0xf8a600e0,     0xf8af1353,\n-    0xf8a922ea,     0xf8b53396,     0xf8a251e3,     0xf8b340f4,\n-    0xf8a470fd,     0xf8a06209,     0xf8f48097,     0xf8f002ea,\n-    0xf8eb10d9,     0xf8ff21b0,     0xf8f7302c,     0xf8ee52a9,\n-    0xf8f041fa,     0xf8e471e4,     0xf8e863c6,     0xf864823d,\n-    0xf87d013a,     0xf86f1162,     0xf87d20e3,     0xf86132bb,\n-    0xf870510e,     0xf8704336,     0xf86572b4,     0xf8706217,\n-    0xb83e8294,     0xb8200264,     0xb8381284,     0xb8242358,\n-    0xb8333102,     0xb828530e,     0xb83042df,     0xb824703f,\n-    0xb82a6194,     0xb8a080e9,     0xb8b80090,     0xb8bb1146,\n-    0xb8bb21b8,     0xb8b032df,     0xb8b653f4,     0xb8bd41c9,\n-    0xb8b47287,     0xb8bc6169,     0xb8ee828c,     0xb8e10138,\n-    0xb8f3126d,     0xb8f020b0,     0xb8e03183,     0xb8e851ef,\n-    0xb8f041e4,     0xb8fe7005,     0xb8ea6376,     0xb8638120,\n-    0xb873015d,     0xb8781284,     0xb86723b8,     0xb86e3175,\n-    0xb87b51ed,     0xb87f41d1,     0xb863721e,     0xb87660f4,\n-    0xce216874,     0xce104533,     0xce648c15,     0xce8e3302,\n-    0xce6e82ab,     0xce6c87d1,     0xcec08063,     0xce638937,\n-    0x25e0c358,     0x25a1c7d3,     0x0580785a,     0x05426328,\n-    0x05009892,     0x25a0cc29,     0x2561cec8,     0x058044b3,\n-    0x05401c99,     0x05006b49,     0x25e0d6f7,     0x2561c528,\n-    0x0583c8bc,     0x0542522f,     0x05001ec0,     0x25e0de65,\n-    0x25a1c113,     0x05803cad,     0x0540f3c0,     0x0500ab15,\n-    0x2560c28c,     0x2561d7c0,     0x05801ed7,     0x0542633b,\n-    0x05003696,     0x2560d4b4,     0x25e1c918,     0x058021ff,\n-    0x05400e15,     0x0500f3de,     0x0473025a,     0x04bd05ab,\n-    0x658e0025,     0x658a08e2,     0x659a0493,     0x043e1062,\n-    0x04f418b4,     0x046d15bd,     0x04611fce,     0x04d6a07c,\n-    0x04001929,     0x041a09da,     0x04d098f4,     0x04db10d4,\n-    0x0459a3ad,     0x041aa029,     0x041919fb,     0x04d39e24,\n-    0x04118302,     0x04101dba,     0x04d7ae16,     0x04dea571,\n-    0x04180210,     0x05e786fc,     0x05e4915c,     0x04881cf1,\n-    0x044a0f04,     0x04090969,     0x048b16c4,     0x044101e4,\n-    0x04dcbf44,     0x65809745,     0x658d833f,     0x65c68468,\n-    0x65c79b07,     0x65829e38,     0x049dafca,     0x6582bba8,\n-    0x65c0b7ff,     0x65c1b4e0,     0x658dbadd,     0x65819a9d,\n-    0x65ed9246,     0x65b30815,     0x65e6263c,     0x65eebb94,\n-    0x65bad14e,     0x65efe178,     0x65fc5697,     0x65e07f14,\n-    0x040c55a6,     0x04977f4d,     0x043d3046,     0x04b733a0,\n-    0x046830a4,     0x04ed322d,     0x05686948,     0x05bd6c13,\n-    0x65c88ef0,     0x450db3d7,     0x4540b6d9,     0x043e3979,\n-    0x445896ce,     0x445a9005,     0x44d98069,     0x445b87ae,\n-    0x04da348e,     0x04982edb,     0x0499397f,     0x0408338c,\n-    0x04ca309c,     0x65c721e6,     0x65c63641,     0x65982882,\n-    0x04812b8b,     0x0e251083,     0x4e3712d5,     0x0e61101f,\n-    0x4e6d118b,     0x0eba1338,     0x4eb712d5,     0x2e31120f,\n-    0x6e2e11ac,     0x2e6810e6,     0x6e6f11cd,     0x2eaa1128,\n-    0x6eb1120f,\n+    0x841040af,     0x84b040af,     0x853040af,     0xc5b040af,\n+    0xe57080af,     0xe5b080af,     0x25034440,     0x254054c4,\n+    0x25034640,     0x25415a05,     0x25834440,     0x25c54489,\n+    0x250b5d3a,     0x2550dc20,     0x2518e3e1,     0x2518e021,\n+    0x2518e0a1,     0x2518e121,     0x2518e1a1,     0x2558e3e2,\n+    0x2558e042,     0x2558e0c2,     0x2558e142,     0x2598e3e3,\n+    0x2598e063,     0x2598e0e3,     0x2598e163,     0x25d8e3e4,\n+    0x25d8e084,     0x25d8e104,     0x25d8e184,     0x2518e407,\n+    0x05214800,     0x05614800,     0x05a14800,     0x05e14800,\n+    0x05214c00,     0x05614c00,     0x05a14c00,     0x05e14c00,\n+    0x05304001,     0x05314001,     0x05a18610,     0x05e18610,\n+    0x0420bc31,     0x05271e11,     0x6545e891,     0x6585e891,\n+    0x65c5e891,     0x6545c891,     0x6585c891,     0x65c5c891,\n+    0x052c8020,     0x056c8020,     0x05ac8020,     0x05ec8020,\n+    0x45b0c210,     0x45f1c231,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf8268267,     0xf82d023c,\n+    0xf8301046,     0xf83d2083,     0xf8263290,     0xf82d528c,\n+    0xf8284299,     0xf8337160,     0xf8386286,     0xf8bf820e,\n+    0xf8a600e0,     0xf8af1353,     0xf8a922ea,     0xf8b53396,\n+    0xf8a251e3,     0xf8b340f4,     0xf8a470fd,     0xf8a06209,\n+    0xf8f48097,     0xf8f002ea,     0xf8eb10d9,     0xf8ff21b0,\n+    0xf8f7302c,     0xf8ee52a9,     0xf8f041fa,     0xf8e471e4,\n+    0xf8e863c6,     0xf864823d,     0xf87d013a,     0xf86f1162,\n+    0xf87d20e3,     0xf86132bb,     0xf870510e,     0xf8704336,\n+    0xf86572b4,     0xf8706217,     0xb83e8294,     0xb8200264,\n+    0xb8381284,     0xb8242358,     0xb8333102,     0xb828530e,\n+    0xb83042df,     0xb824703f,     0xb82a6194,     0xb8a080e9,\n+    0xb8b80090,     0xb8bb1146,     0xb8bb21b8,     0xb8b032df,\n+    0xb8b653f4,     0xb8bd41c9,     0xb8b47287,     0xb8bc6169,\n+    0xb8ee828c,     0xb8e10138,     0xb8f3126d,     0xb8f020b0,\n+    0xb8e03183,     0xb8e851ef,     0xb8f041e4,     0xb8fe7005,\n+    0xb8ea6376,     0xb8638120,     0xb873015d,     0xb8781284,\n+    0xb86723b8,     0xb86e3175,     0xb87b51ed,     0xb87f41d1,\n+    0xb863721e,     0xb87660f4,     0xce216874,     0xce104533,\n+    0xce648c15,     0xce8e3302,     0xce6e82ab,     0xce6c87d1,\n+    0xcec08063,     0xce638937,     0x25e0c358,     0x25a1c7d3,\n+    0x0580785a,     0x05426328,     0x05009892,     0x25a0cc29,\n+    0x2561cec8,     0x058044b3,     0x05401c99,     0x05006b49,\n+    0x25e0d6f7,     0x2561c528,     0x0583c8bc,     0x0542522f,\n+    0x05001ec0,     0x25e0de65,     0x25a1c113,     0x05803cad,\n+    0x0540f3c0,     0x0500ab15,     0x2560c28c,     0x2561d7c0,\n+    0x05801ed7,     0x0542633b,     0x05003696,     0x2560d4b4,\n+    0x25e1c918,     0x058021ff,     0x05400e15,     0x0500f3de,\n+    0x0473025a,     0x04bd05ab,     0x658e0025,     0x658a08e2,\n+    0x659a0493,     0x043e1062,     0x04f418b4,     0x046d15bd,\n+    0x04611fce,     0x04d6a07c,     0x04001929,     0x041a09da,\n+    0x04d098f4,     0x04db10d4,     0x0459a3ad,     0x041aa029,\n+    0x041919fb,     0x04d39e24,     0x04118302,     0x04101dba,\n+    0x04d7ae16,     0x04dea571,     0x04180210,     0x05e786fc,\n+    0x05e4915c,     0x04881cf1,     0x044a0f04,     0x04090969,\n+    0x048b16c4,     0x044101e4,     0x04dcbf44,     0x65809745,\n+    0x658d833f,     0x65c68468,     0x65c79b07,     0x65829e38,\n+    0x049dafca,     0x6582bba8,     0x65c0b7ff,     0x65c1b4e0,\n+    0x658dbadd,     0x65819a9d,     0x65ed9246,     0x65b30815,\n+    0x65e6263c,     0x65eebb94,     0x65bad14e,     0x65efe178,\n+    0x65fc5697,     0x65e07f14,     0x040c55a6,     0x04977f4d,\n+    0x043d3046,     0x04b733a0,     0x046830a4,     0x04ed322d,\n+    0x05686948,     0x05bd6c13,     0x65c88ef0,     0x450db3d7,\n+    0x4540b6d9,     0x043e3979,     0x445896ce,     0x445a9005,\n+    0x44d98069,     0x445b87ae,     0x04da348e,     0x04982edb,\n+    0x0499397f,     0x0408338c,     0x04ca309c,     0x65c721e6,\n+    0x65c63641,     0x65982882,     0x04812b8b,     0x0e251083,\n+    0x4e3712d5,     0x0e61101f,     0x4e6d118b,     0x0eba1338,\n+    0x4eb712d5,     0x2e31120f,     0x6e2e11ac,     0x2e6810e6,\n+    0x6e6f11cd,     0x2eaa1128,     0x6eb1120f,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":94,"deletions":92,"binary":false,"changes":186,"status":"modified"},{"patch":"@@ -0,0 +1,398 @@\n+\/*\n+ * Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.vectorapi;\n+\n+import compiler.lib.generators.*;\n+import compiler.lib.ir_framework.*;\n+import jdk.incubator.vector.*;\n+import jdk.test.lib.Asserts;\n+\n+\/**\n+ * @test\n+ * @bug 8351623\n+ * @summary VectorAPI: Add SVE implementation for subword gather load operation\n+ * @key randomness\n+ * @library \/test\/lib \/\n+ * @modules jdk.incubator.vector\n+ *\n+ * @run driver compiler.vectorapi.VectorGatherSubwordTest MaxVectorSize_16\n+ * @run driver compiler.vectorapi.VectorGatherSubwordTest MaxVectorSize_32\n+ * @run driver compiler.vectorapi.VectorGatherSubwordTest MaxVectorSize_64\n+ * @run driver compiler.vectorapi.VectorGatherSubwordTest\n+ *\/\n+public class VectorGatherSubwordTest {\n+    private static final VectorSpecies<Byte> BSPEC_64 = ByteVector.SPECIES_64;\n+    private static final VectorSpecies<Byte> BSPEC_128 = ByteVector.SPECIES_128;\n+    private static final VectorSpecies<Byte> BSPEC_256 = ByteVector.SPECIES_256;\n+    private static final VectorSpecies<Byte> BSPEC_512 = ByteVector.SPECIES_512;\n+    private static final VectorSpecies<Short> SSPEC_64 = ShortVector.SPECIES_64;\n+    private static final VectorSpecies<Short> SSPEC_128 = ShortVector.SPECIES_128;\n+    private static final VectorSpecies<Short> SSPEC_256 = ShortVector.SPECIES_256;\n+    private static final VectorSpecies<Short> SSPEC_512 = ShortVector.SPECIES_512;\n+\n+    private static int LENGTH = 128;\n+    private static final Generators random = Generators.G;\n+\n+    private static byte[] ba;\n+    private static byte[] br;\n+    private static short[] sa;\n+    private static short[] sr;\n+    private static boolean[] m;\n+    private static int[][] indexes;\n+\n+    static {\n+        ba = new byte[LENGTH];\n+        br = new byte[LENGTH];\n+        sa = new short[LENGTH];\n+        sr = new short[LENGTH];\n+        m = new boolean[LENGTH];\n+        indexes = new int[5][];\n+\n+        Generator<Integer> byteGen = random.uniformInts(Byte.MIN_VALUE, Byte.MAX_VALUE);\n+        Generator<Integer> shortGen = random.uniformInts(Short.MIN_VALUE, Short.MAX_VALUE);\n+        for (int i = 0; i < LENGTH; i++) {\n+            ba[i] = byteGen.next().byteValue();\n+            sa[i] = shortGen.next().shortValue();\n+            m[i] = i % 2 == 0;\n+        }\n+\n+        int[] nums = {4, 8, 16, 32, 64};\n+        for (int i = 0; i < 5; i++) {\n+            indexes[i] = new int[nums[i]];\n+            random.fill(random.uniformInts(0, nums[i] - 1), indexes[i]);\n+        }\n+    }\n+\n+    \/\/ Tests for gather load of byte vector with different vector species.\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherByte64() {\n+        ByteVector.fromArray(BSPEC_64, ba, 0, indexes[1], 0)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherByte64\")\n+    public void verifyLoadGatherByte64() {\n+        for (int i = 0; i < BSPEC_64.length(); i++) {\n+            Asserts.assertEquals(ba[indexes[1][i]], br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherByte128() {\n+        ByteVector.fromArray(BSPEC_128, ba, 0, indexes[2], 0)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherByte128\")\n+    public void verifyLoadGatherByte128() {\n+        for (int i = 0; i < BSPEC_128.length(); i++) {\n+            Asserts.assertEquals(ba[indexes[2][i]], br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherByte256() {\n+        ByteVector.fromArray(BSPEC_256, ba, 0, indexes[3], 0)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherByte256\")\n+    public void verifyLoadGatherByte256() {\n+        for (int i = 0; i < BSPEC_256.length(); i++) {\n+            Asserts.assertEquals(ba[indexes[3][i]], br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherByte512() {\n+        ByteVector.fromArray(BSPEC_512, ba, 0, indexes[4], 0)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherByte512\")\n+    public void verifyLoadGatherByte512() {\n+        for (int i = 0; i < BSPEC_512.length(); i++) {\n+            Asserts.assertEquals(ba[indexes[4][i]], br[i]);\n+        }\n+    }\n+\n+    \/\/ Tests for gather load of short vector with different vector species.\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \">= 32\"})\n+    public void testLoadGatherShort64() {\n+        ShortVector.fromArray(SSPEC_64, sa, 0, indexes[0], 0)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherShort64\")\n+    public void verifyLoadGatherShort64() {\n+        for (int i = 0; i < SSPEC_64.length(); i++) {\n+            Asserts.assertEquals(sa[indexes[0][i]], sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherShort128() {\n+        ShortVector.fromArray(SSPEC_128, sa, 0, indexes[1], 0)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherShort128\")\n+    public void verifyLoadGatherShort128() {\n+        for (int i = 0; i < SSPEC_128.length(); i++) {\n+            Asserts.assertEquals(sa[indexes[1][i]], sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherShort256() {\n+        ShortVector.fromArray(SSPEC_256, sa, 0, indexes[2], 0)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherShort256\")\n+    public void verifyLoadGatherShort256() {\n+        for (int i = 0; i < SSPEC_256.length(); i++) {\n+            Asserts.assertEquals(sa[indexes[2][i]], sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherShort512() {\n+        ShortVector.fromArray(SSPEC_512, sa, 0, indexes[3], 0)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherShort512\")\n+    public void verifyLoadGatherShort512() {\n+        for (int i = 0; i < SSPEC_512.length(); i++) {\n+            Asserts.assertEquals(sa[indexes[3][i]], sr[i]);\n+        }\n+    }\n+\n+    \/\/ Tests for masked gather load of byte vector with different vector species.\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \">= 32\"})\n+    public void testLoadGatherMaskedByte64() {\n+        VectorMask<Byte> mask = VectorMask.fromArray(BSPEC_64, m, 0);\n+        ByteVector.fromArray(BSPEC_64, ba, 0, indexes[1], 0, mask)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedByte64\")\n+    public void verifyLoadGatherMaskedByte64() {\n+        for (int i = 0; i < BSPEC_64.length(); i++) {\n+            Asserts.assertEquals(m[i] ? ba[indexes[1][i]] : 0, br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherMaskedByte128() {\n+        VectorMask<Byte> mask = VectorMask.fromArray(BSPEC_128, m, 0);\n+        ByteVector.fromArray(BSPEC_128, ba, 0, indexes[2], 0, mask)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedByte128\")\n+    public void verifyLoadGatherMaskedByte128() {\n+        for (int i = 0; i < BSPEC_128.length(); i++) {\n+            Asserts.assertEquals(m[i] ? ba[indexes[2][i]] : 0, br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherMaskedByte256() {\n+        VectorMask<Byte> mask = VectorMask.fromArray(BSPEC_256, m, 0);\n+        ByteVector.fromArray(BSPEC_256, ba, 0, indexes[3], 0, mask)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedByte256\")\n+    public void verifyLoadGatherMaskedByte256() {\n+        for (int i = 0; i < BSPEC_256.length(); i++) {\n+            Asserts.assertEquals(m[i] ? ba[indexes[3][i]] : 0, br[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"4\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherMaskedByte512() {\n+        VectorMask<Byte> mask = VectorMask.fromArray(BSPEC_512, m, 0);\n+        ByteVector.fromArray(BSPEC_512, ba, 0, indexes[4], 0, mask)\n+                  .intoArray(br, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedByte512\")\n+    public void verifyLoadGatherMaskedByte512() {\n+        for (int i = 0; i < BSPEC_512.length(); i++) {\n+            Asserts.assertEquals(m[i] ? ba[indexes[4][i]] : 0, br[i]);\n+        }\n+    }\n+\n+    \/\/ Tests for masked gather load of short vector with different vector species.\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \">= 16\"})\n+    public void testLoadGatherMaskedShort64() {\n+        VectorMask<Short> mask = VectorMask.fromArray(SSPEC_64, m, 0);\n+        ShortVector.fromArray(SSPEC_64, sa, 0, indexes[0], 0, mask)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedShort64\")\n+    public void verifyLoadGatherMaskedShort64() {\n+        for (int i = 0; i < SSPEC_64.length(); i++) {\n+            Asserts.assertEquals(m[i] ? sa[indexes[0][i]] : 0, sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"16\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \">= 32\"})\n+    public void testLoadGatherMaskedShort128() {\n+        VectorMask<Short> mask = VectorMask.fromArray(SSPEC_128, m, 0);\n+        ShortVector.fromArray(SSPEC_128, sa, 0, indexes[1], 0, mask)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedShort128\")\n+    public void verifyLoadGatherMaskedShort128() {\n+        for (int i = 0; i < SSPEC_128.length(); i++) {\n+            Asserts.assertEquals(m[i] ? sa[indexes[1][i]] : 0, sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"32\"})\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"1\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherMaskedShort256() {\n+        VectorMask<Short> mask = VectorMask.fromArray(SSPEC_256, m, 0);\n+        ShortVector.fromArray(SSPEC_256, sa, 0, indexes[2], 0, mask)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedShort256\")\n+    public void verifyLoadGatherMaskedShort256() {\n+        for (int i = 0; i < SSPEC_256.length(); i++) {\n+            Asserts.assertEquals(m[i] ? sa[indexes[2][i]] : 0, sr[i]);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_GATHER_MASKED, \"2\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"}, applyIf = {\"MaxVectorSize\", \"64\"})\n+    public void testLoadGatherMaskedShort512() {\n+        VectorMask<Short> mask = VectorMask.fromArray(SSPEC_512, m, 0);\n+        ShortVector.fromArray(SSPEC_512, sa, 0, indexes[3], 0, mask)\n+                   .intoArray(sr, 0);\n+    }\n+\n+    @Check(test = \"testLoadGatherMaskedShort512\")\n+    public void verifyLoadGatherMaskedShort512() {\n+        for (int i = 0; i < SSPEC_512.length(); i++) {\n+            Asserts.assertEquals(m[i] ? sa[indexes[3][i]] : 0, sr[i]);\n+        }\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFramework testFramework = new TestFramework();\n+        testFramework.setDefaultWarmup(5000)\n+                     .addFlags(\"--add-modules=jdk.incubator.vector\",\n+                               \"-XX:-TieredCompilation\");\n+        \/\/ Set MaxVectorSize for tests.\n+        if (args != null && args.length > 0) {\n+            String vmFlags = \"\";\n+            switch (args[0]) {\n+                case \"MaxVectorSize_16\":\n+                    vmFlags = \"-XX:MaxVectorSize=16\";\n+                    break;\n+                case \"MaxVectorSize_32\":\n+                    vmFlags = \"-XX:MaxVectorSize=32\";\n+                    break;\n+                case \"MaxVectorSize_64\":\n+                    vmFlags = \"-XX:MaxVectorSize=64\";\n+                    break;\n+                default:\n+                    throw new RuntimeException(\"Unexpected args\");\n+            }\n+            testFramework.addFlags(vmFlags);\n+        }\n+        testFramework.start();\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/VectorGatherSubwordTest.java","additions":398,"deletions":0,"binary":false,"changes":398,"status":"added"}]}