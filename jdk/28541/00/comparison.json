{"files":[{"patch":"@@ -151,0 +151,3 @@\n+\/\/ State for randomized profile counters. Used by C1.\n+extern Register r_profile_rng;\n+\n@@ -3230,5 +3233,5 @@\n-#define INSN(NAME, c, sf, sz)                                             \\\n-  void NAME(Register Rd, Register Rn, Register Rm) {                      \\\n-    starti;                                                               \\\n-    f(sf, 31), f(0b0011010110, 30, 21), f(0b010, 15, 13), f(c, 12);       \\\n-    f(sz, 11, 10), rf(Rm, 16), rf(Rn, 5), rf(Rd, 0);                      \\\n+#define INSN(NAME, c, sf, sz)                                           \\\n+  void NAME(Register Rd, Register Rn, Register Rm) {                    \\\n+    starti;                                                             \\\n+    f(sf, 31), f(0b0011010110, 30, 21), f(0b010, 15, 13), f(c, 12);     \\\n+    f(sz, 11, 10), zrf(Rm, 16), rf(Rn, 5), rf(Rd, 0);                   \\\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -194,1 +194,0 @@\n-  map_register(i, r26); r26_opr = LIR_OprFact::single_cpu(i); i++;\n@@ -196,5 +195,19 @@\n-  \/\/ r27 is allocated conditionally. With compressed oops it holds\n-  \/\/ the heapbase value and is not visible to the allocator.\n-  bool preserve_rheapbase = i >= nof_caller_save_cpu_regs();\n-  if (!preserve_rheapbase) {\n-    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n+  auto remaining = RegSet::of(r26, r27);\n+\n+  if (UseCompressedOops && (CompressedOops::base() != nullptr)) {\n+    \/\/ r27 is allocated conditionally. With compressed oops it holds\n+    \/\/ the heapbase value and is not visible to the allocator.\n+    remaining -= r27;\n+  }\n+\n+  if (ProfileCaptureRatio > 1) {\n+    \/\/ Use the highest remaining register for r_profile_rng.\n+    r_profile_rng = *remaining.rbegin();\n+    remaining -= r_profile_rng;\n+  }\n+\n+  if (remaining.contains(r26)) {\n+    map_register(i, r26); r26_opr = LIR_OprFact::single_cpu(i); i++;\n+  }\n+  if (remaining.contains(r27)) {\n+    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++;\n@@ -208,4 +221,0 @@\n-\n-  if (preserve_rheapbase) {\n-    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n-  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.cpp","additions":19,"deletions":10,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -150,0 +150,5 @@\n+    \/\/ Use r26 for randomized profile captures.\n+    if (ProfileCaptureRatio > 1) {\n+      range -= 1;\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1233,1 +1233,1 @@\n-              DataLayout::counter_increment);\n+              DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1245,1 +1245,1 @@\n-    __ mov(rscratch1, DataLayout::counter_increment);\n+    __ mov(rscratch1, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1262,0 +1262,5 @@\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n@@ -1311,6 +1316,25 @@\n-    Label update_done;\n-    Register recv = k_RInfo;\n-    __ load_klass(recv, obj);\n-    type_profile_helper(mdo, md, data, recv, &update_done);\n-    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    ProfileStub *stub\n+      = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+    auto lambda = [stub, md, mdo, data, k_RInfo, obj] (LIR_Assembler* ce, LIR_Op* base_op) {\n+\n+#undef __\n+#define __ masm->\n+\n+      auto masm = ce->masm();\n+      if (stub != nullptr)  __ bind(*stub->entry());\n+\n+      Label update_done;\n+      Register recv = k_RInfo;\n+      __ load_klass(recv, obj);\n+      ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+      Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+      __ bind(update_done);\n+\n+      if (stub != nullptr)  __ b(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+    };\n@@ -1318,1 +1342,12 @@\n-    __ bind(update_done);\n+    if (stub != nullptr) {\n+      __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+      __ cbz(rscratch1, *stub->entry());\n+      __ bind(*stub->continuation());\n+      __ step_random(r_profile_rng, rscratch2);\n+\n+      stub->set_action(lambda, op);\n+      stub->set_name(\"Typecheck stub\");\n+      append_code_stub(stub);\n+    } else {\n+      lambda(this, op);\n+    }\n@@ -1411,13 +1446,34 @@\n-      Label not_null;\n-      Register mdo  = klass_RInfo;\n-      __ mov_metadata(mdo, md->constant_encoding());\n-      __ cbnz(value, not_null);\n-      \/\/ Object is null; update MDO and exit\n-      Address data_addr\n-        = __ form_address(rscratch2, mdo,\n-                          md->byte_offset_of_slot(data, DataLayout::flags_offset()), 0);\n-      __ ldrb(rscratch1, data_addr);\n-      __ orr(rscratch1, rscratch1, BitData::null_seen_byte_constant());\n-      __ strb(rscratch1, data_addr);\n-      __ b(done);\n-      __ bind(not_null);\n+      int profile_capture_ratio = ProfileCaptureRatio;\n+      int ratio_shift = exact_log2(profile_capture_ratio);\n+      auto threshold = (1ull << 32) >> ratio_shift;\n+      assert(threshold > 0, \"must be\");\n+\n+      ProfileStub *profile_stub\n+        = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+      auto lambda = [profile_stub, md, data, value,\n+                     k_RInfo, klass_RInfo, success_target] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+        auto masm = ce->masm();\n+\n+        if (profile_stub != nullptr)  __ bind(*profile_stub->entry());\n+\n+        Label not_null;\n+        Register mdo  = klass_RInfo;\n+        __ mov_metadata(mdo, md->constant_encoding());\n+        __ cbnz(value, not_null);\n+        \/\/ Object is null; update MDO and exit\n+        Address data_addr\n+          = __ form_address(rscratch2, mdo,\n+                            md->byte_offset_of_slot(data, DataLayout::flags_offset()), 0);\n+        __ ldrb(rscratch1, data_addr);\n+        __ orr(rscratch1, rscratch1, BitData::null_seen_byte_constant());\n+        __ strb(rscratch1, data_addr);\n+        if (profile_stub != nullptr) {\n+          __ b(*profile_stub->continuation());\n+        } else {\n+          __ b(*success_target);\n+        }\n+        __ bind(not_null);\n@@ -1425,7 +1481,27 @@\n-      Label update_done;\n-      Register recv = k_RInfo;\n-      __ load_klass(recv, value);\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n-      __ bind(update_done);\n+        Label update_done;\n+        Register recv = k_RInfo;\n+        __ load_klass(recv, value);\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+        __ bind(update_done);\n+\n+        if (profile_stub != nullptr)  __ b(*profile_stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+      };\n+\n+      if (profile_stub != nullptr) {\n+        __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+        __ cbz(rscratch1, *profile_stub->entry());\n+        __ bind(*profile_stub->continuation());\n+        __ step_random(r_profile_rng, rscratch2);\n+        __ cbz(value, done);\n+\n+        profile_stub->set_action(lambda, op);\n+        profile_stub->set_name(\"Typecheck profile stub\");\n+        append_code_stub(profile_stub);\n+      } else {\n+        lambda(this, op);\n+      }\n@@ -1982,2 +2058,3 @@\n-void LIR_Assembler::align_call(LIR_Code code) {  }\n-\n+void LIR_Assembler::align_call(LIR_Code code) {\n+  __ save_profile_rng();\n+}\n@@ -1993,0 +2070,1 @@\n+  __ restore_profile_rng();\n@@ -2004,0 +2082,1 @@\n+  __ restore_profile_rng();\n@@ -2510,0 +2589,126 @@\n+void LIR_Assembler::increment_profile_ctr(LIR_Opr step, LIR_Opr counter_addr, LIR_Opr dest, LIR_Opr temp_op,\n+                                          LIR_Opr freq_op,\n+                                          CodeStub* overflow_stub) {\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"increment_event_counter {\");\n+  }\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  unsigned long threshold = (UCONST64(1) << 32) >> ratio_shift;\n+\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *counter_stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  Register temp = temp_op->is_register() ? temp_op->as_register() : noreg;\n+  Address raw_dest_adr = as_Address(counter_addr->as_address_ptr());\n+\n+  auto lambda = [counter_stub, overflow_stub, freq_op, ratio_shift, step,\n+                 temp, dest, raw_dest_adr] (LIR_Assembler* ce, LIR_Op* op) {\n+\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+\n+    if (counter_stub != nullptr)  __ bind(*counter_stub->entry());\n+\n+    if (step->is_register()) {\n+      Address dest_adr = __ legitimize_address(raw_dest_adr, sizeof (jint), rscratch2);\n+      Register inc = step->as_register();\n+      __ ldrw(temp, dest_adr);\n+      if (ProfileCaptureRatio > 1) {\n+        __ lsl(inc, inc, ratio_shift);\n+      }\n+      __ addw(temp, temp, inc);\n+      __ strw(temp, dest_adr);\n+      if (dest->is_register())  __ mov(dest->as_register(), temp);\n+      if (ProfileCaptureRatio > 1) {\n+        __ lsr(inc, inc, ratio_shift);\n+      }\n+      if (dest->is_register())  __ mov(dest->as_register(), temp);\n+    } else {\n+      jint inc = step->as_constant_ptr()->as_jint_bits();\n+      switch (dest->type()) {\n+        case T_INT: {\n+          Address dest_adr = __ legitimize_address(raw_dest_adr, sizeof (jint), rscratch2);\n+          inc *= ProfileCaptureRatio;\n+          __ incrementw(dest_adr, inc, temp);\n+          if (dest->is_register())  __ movw(dest->as_register(), temp);\n+\n+          break;\n+        }\n+        case T_LONG: {\n+          Address dest_adr = __ legitimize_address(raw_dest_adr, sizeof (jlong), rscratch2);\n+          inc *= ProfileCaptureRatio;\n+          __ increment(dest_adr, inc, temp);\n+          if (dest->is_register())  __ mov(dest->as_register_lo(), temp);\n+\n+          break;\n+        }\n+        default:\n+          ShouldNotReachHere();\n+      }\n+\n+      if (step->is_valid() && overflow_stub) {\n+        if (!freq_op->is_valid()) {\n+          if (!step->is_constant()) {\n+            __ cbz(step->as_register(), *overflow_stub->entry());\n+          } else {\n+            __ b(*overflow_stub->entry());\n+            return;\n+          }\n+        } else {\n+          Register result =\n+            dest->type() == T_INT ? dest->as_register() :\n+            dest->type() == T_LONG ? dest->as_register_lo() :\n+            noreg;\n+          if (!step->is_constant()) {\n+            \/\/ If step is 0, make sure the stub check below always fails\n+            __ cmp(step->as_register(), (u1)0);\n+            __ mov(temp, InvocationCounter::count_increment * ProfileCaptureRatio);\n+            __ csel(result, result, temp, __ NE);\n+          }\n+          juint mask = freq_op->as_jint();\n+          __ andw(rscratch1, result,  mask);\n+          __ cbzw(rscratch1, *overflow_stub->entry());\n+        }\n+      }\n+    }\n+\n+    if (counter_stub != nullptr) {\n+      __ b(*counter_stub->continuation());\n+    }\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (counter_stub != nullptr) {\n+    __ ubfx(rscratch1, r_profile_rng, 32 - ratio_shift, ratio_shift);\n+    __ cbz(rscratch1, *counter_stub->entry());\n+    __ bind(*counter_stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    counter_stub->set_action(lambda, nullptr);\n+    counter_stub->set_name(\"IncrementEventCounter\");\n+    append_code_stub(counter_stub);\n+  } else {\n+    lambda(this, nullptr);\n+  }\n+\n+  if (overflow_stub != nullptr) {\n+    __ bind(*overflow_stub->continuation());\n+  }\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} increment_event_counter\");\n+  }\n+#endif\n+}\n+\n@@ -2515,32 +2720,59 @@\n-  \/\/ Update counter for all call types\n-  ciMethodData* md = method->method_data_or_null();\n-  assert(md != nullptr, \"Sanity\");\n-  ciProfileData* data = md->bci_to_data(bci);\n-  assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n-  assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n-  Register mdo  = op->mdo()->as_register();\n-  __ mov_metadata(mdo, md->constant_encoding());\n-  Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-  \/\/ Perform additional virtual call profiling for invokevirtual and\n-  \/\/ invokeinterface bytecodes\n-  if (op->should_profile_receiver_type()) {\n-    assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n-    Register recv = op->recv()->as_register();\n-    assert_different_registers(mdo, recv);\n-    assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n-    ciKlass* known_klass = op->known_holder();\n-    if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n-      \/\/ We know the type that will be seen at this call site; we can\n-      \/\/ statically update the MethodData* rather than needing to do\n-      \/\/ dynamic tests on the receiver type\n-\n-      \/\/ NOTE: we should probably put a lock around this search to\n-      \/\/ avoid collisions by concurrent compilations\n-      ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n-      uint i;\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (known_klass->equals(receiver)) {\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+\n+  Register temp = op->tmp1()->as_register_lo();\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [op, stub] (LIR_Assembler* ce, LIR_Op* base_op) {\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    LIR_OpProfileCall* op = base_op->as_OpProfileCall();\n+    ciMethod* method = op->profiled_method();\n+    int bci          = op->profiled_bci();\n+    ciMethod* callee = op->profiled_callee();\n+    Register tmp_load_klass = rscratch1;\n+\n+    Register temp = op->tmp1()->as_register_lo();\n+\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n+    \/\/ Update counter for all call types\n+    ciMethodData* md = method->method_data_or_null();\n+    assert(md != nullptr, \"Sanity\");\n+    ciProfileData* data = md->bci_to_data(bci);\n+    assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n+    assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n+    Register mdo  = op->mdo()->as_register();\n+    __ mov_metadata(mdo, md->constant_encoding());\n+    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+    \/\/ Perform additional virtual call profiling for invokevirtual and\n+    \/\/ invokeinterface bytecodes\n+    if (op->should_profile_receiver_type()) {\n+      assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n+      Register recv = op->recv()->as_register();\n+      assert_different_registers(mdo, recv);\n+      assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n+      ciKlass* known_klass = op->known_holder();\n+      if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n+        \/\/ We know the type that will be seen at this call site; we can\n+        \/\/ statically update the MethodData* rather than needing to do\n+        \/\/ dynamic tests on the receiver type\n+\n+        \/\/ NOTE: we should probably put a lock around this search to\n+        \/\/ avoid collisions by concurrent compilations\n+        ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n+        uint i;\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (known_klass->equals(receiver)) {\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n@@ -2548,1 +2780,0 @@\n-      }\n@@ -2550,17 +2781,18 @@\n-      \/\/ Receiver type not found in profile data; select an empty slot\n-\n-      \/\/ Note that this is less efficient than it should be because it\n-      \/\/ always does a write to the receiver part of the\n-      \/\/ VirtualCallData rather than just the first time\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (receiver == nullptr) {\n-          __ mov_metadata(rscratch1, known_klass->constant_encoding());\n-          Address recv_addr =\n-            __ form_address(rscratch2, mdo,\n-                            md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)),\n-                            LogBytesPerWord);\n-          __ str(rscratch1, recv_addr);\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+        \/\/ Receiver type not found in profile data; select an empty slot\n+\n+        \/\/ Note that this is less efficient than it should be because it\n+        \/\/ always does a write to the receiver part of the\n+        \/\/ VirtualCallData rather than just the first time\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (receiver == nullptr) {\n+            __ mov_metadata(rscratch1, known_klass->constant_encoding());\n+            Address recv_addr =\n+              __ form_address(rscratch2, mdo,\n+                              md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)),\n+                              LogBytesPerWord);\n+            __ str(rscratch1, recv_addr);\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n@@ -2568,0 +2800,9 @@\n+      } else {\n+        __ load_klass(recv, recv);\n+        Label update_done;\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n+        \/\/ Increment total counter to indicate polymorphic case.\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+        __ bind(update_done);\n@@ -2569,0 +2810,1 @@\n+    exit: {}\n@@ -2570,8 +2812,2 @@\n-      __ load_klass(recv, recv);\n-      Label update_done;\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n-      \/\/ Increment total counter to indicate polymorphic case.\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n-\n-      __ bind(update_done);\n+      \/\/ Static call\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -2579,0 +2815,16 @@\n+\n+    if (stub != nullptr)  __ b(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+    __ cbz(rscratch1, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileCallStub\");\n+    append_code_stub(stub);\n@@ -2580,2 +2832,1 @@\n-    \/\/ Static call\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    lambda(this, op);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":342,"deletions":91,"binary":false,"changes":433,"status":"modified"},{"patch":"@@ -1382,0 +1382,4 @@\n+  \/\/ If we're subsampling counter updates, then profiling code kills flags\n+  if (ProfileCaptureRatio != 1) {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+Register r_profile_rng;\n+\n@@ -250,0 +252,1 @@\n+  restore_profile_rng();\n@@ -258,0 +261,1 @@\n+  save_profile_rng();\n@@ -279,0 +283,29 @@\n+\/\/ Randomized profile capture.\n+\n+void C1_MacroAssembler::step_random(Register state, Register temp, Register data) {\n+  if (VM_Version::supports_crc32()) {\n+    \/* CRC used as a psuedo-random-number generator *\/\n+    \/\/ In effect, the CRC instruction is being used here for its\n+    \/\/ linear feedback shift register. It's unbeatably fast, and\n+    \/\/ plenty good enough for what we need.\n+    crc32h(state, state, data);\n+  } else {\n+    \/* LCG from glibc. *\/\n+    mov(temp, 1103515245);\n+    mulw(state, state, temp);\n+    addw(state, state, 12345);\n+  }\n+}\n+\n+void C1_MacroAssembler::save_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    strw(r_profile_rng, Address(rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n+void C1_MacroAssembler::restore_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    ldrw(r_profile_rng, Address(rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -116,0 +116,5 @@\n+  \/\/ Randomized profile capture\n+  void step_random(Register state, Register temp, Register data = rthread);\n+  void save_profile_rng();\n+  void restore_profile_rng();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2750,1 +2750,1 @@\n-void MacroAssembler::incrementw(Address dst, int value)\n+void MacroAssembler::incrementw(Address dst, int value, Register result)\n@@ -2752,1 +2752,3 @@\n-  assert(!dst.uses(rscratch1), \"invalid dst for address increment\");\n+  assert(!dst.uses(result), \"invalid dst for address increment\");\n+  assert(result->is_valid(), \"must be\");\n+  assert_different_registers(result, rscratch2);\n@@ -2758,3 +2760,3 @@\n-  ldrw(rscratch1, dst);\n-  incrementw(rscratch1, value);\n-  strw(rscratch1, dst);\n+  ldrw(result, dst);\n+  incrementw(result, value);\n+  strw(result, dst);\n@@ -2763,1 +2765,1 @@\n-void MacroAssembler::increment(Address dst, int value)\n+void MacroAssembler::increment(Address dst, int value, Register result)\n@@ -2765,1 +2767,3 @@\n-  assert(!dst.uses(rscratch1), \"invalid dst for address increment\");\n+  assert(!dst.uses(result), \"invalid dst for address increment\");\n+  assert(result->is_valid(), \"must be\");\n+  assert_different_registers(result, rscratch2);\n@@ -2771,3 +2775,3 @@\n-  ldr(rscratch1, dst);\n-  increment(rscratch1, value);\n-  str(rscratch1, dst);\n+  ldr(result, dst);\n+  increment(result, value);\n+  str(result, dst);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":14,"deletions":10,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -483,0 +483,19 @@\n+  using Assembler::andw, Assembler::andr;\n+  void andw(Register Rd, Register Rn, uint64_t imm) {\n+    if (operand_valid_for_logical_immediate(\/*is32*\/true, imm)) {\n+      Assembler::andw(Rd, Rn, imm);\n+    } else {\n+      assert(Rd != Rn, \"must be\");\n+      movw(Rd, imm);\n+      andw(Rd, Rn, Rd);\n+    }\n+  }\n+  void andr(Register Rd, Register Rn, uint64_t imm) {\n+    if (operand_valid_for_logical_immediate(\/*is32*\/false, imm)) {\n+      Assembler::andr(Rd, Rn, imm);\n+    } else {\n+      assert(Rd != Rn, \"must be\");\n+      mov(Rd, imm);\n+      andr(Rd, Rn, Rd);\n+    }\n+  }\n@@ -755,1 +774,1 @@\n-  void incrementw(Address dst, int value = 1);\n+  void incrementw(Address dst, int value = 1, Register result = rscratch1);\n@@ -759,1 +778,1 @@\n-  void increment(Address dst, int value = 1);\n+  void increment(Address dst, int value = 1, Register result = rscratch1);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":21,"deletions":2,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -402,0 +402,7 @@\n+template <>\n+inline Register AbstractRegSet<Register>::last() {\n+  if (_bitset == 0) { return noreg; }\n+  int last = max_size() - 1 - count_leading_zeros(_bitset);\n+  return as_Register(last);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -139,0 +139,3 @@\n+\/\/ State for randomized profile counters. Used by C1.\n+extern Register r_profile_rng;\n+\n@@ -463,0 +466,1 @@\n+  friend class CodeStub; \/\/ as_Address()\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -170,0 +170,6 @@\n+  \/\/ r_profile_rng is allocated conditionally. It is used to hold the random\n+  \/\/ generator for profile counters.\n+  r_profile_rng\n+    = (UseCompressedOops && ProfileCaptureRatio > 1) ? r14\n+    : (ProfileCaptureRatio > 1) ? r12\n+    : noreg;\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -130,2 +130,4 @@\n-    \/\/ Reduce the number of available regs (to free r12) in case of compressed oops\n-    if (UseCompressedOops) return range - 1;\n+    \/\/ Reduce the number of available regs (to free r12 or r14) in\n+    \/\/ case of compressed oops and randomized profile captures.\n+    if (UseCompressedOops && ProfileCaptureRatio > 1) return range - 2;\n+    if (UseCompressedOops || ProfileCaptureRatio > 1) return range - 1;\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1263,1 +1263,1 @@\n-    __ addptr(data_addr, DataLayout::counter_increment);\n+    __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1275,1 +1275,1 @@\n-    __ movptr(Address(mdo, md->byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);\n+    __ movptr(Address(mdo, md->byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1325,0 +1325,5 @@\n+    int profile_capture_ratio = ProfileCaptureRatio;\n+    int ratio_shift = exact_log2(profile_capture_ratio);\n+    auto threshold = (1ull << 32) >> ratio_shift;\n+    assert(threshold > 0, \"must be\");\n+\n@@ -1336,0 +1341,11 @@\n+    ProfileStub *stub\n+      = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+    auto lambda = [stub, md, mdo, data, k_RInfo, obj, tmp_load_klass] (LIR_Assembler* ce, LIR_Op* base_op) {\n+\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n@@ -1337,0 +1353,1 @@\n+\n@@ -1339,1 +1356,1 @@\n-    type_profile_helper(mdo, md, data, recv, &update_done);\n+    ce->type_profile_helper(mdo, md, data, recv, &update_done);\n@@ -1342,1 +1359,1 @@\n-    __ addptr(nonprofiled_receiver_count_addr, DataLayout::counter_increment);\n+    __ addptr(nonprofiled_receiver_count_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1345,0 +1362,19 @@\n+\n+    if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, rscratch1);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"Typecheck stub\");\n+    append_code_stub(stub);\n+  } else {\n+    lambda(this, op);\n+  }\n@@ -1443,1 +1479,0 @@\n-    __ testptr(value, value);\n@@ -1445,0 +1480,19 @@\n+      int profile_capture_ratio = ProfileCaptureRatio;\n+      int ratio_shift = exact_log2(profile_capture_ratio);\n+      auto threshold = (1ull << 32) >> ratio_shift;\n+      assert(threshold > 0, \"must be\");\n+\n+      ProfileStub *profile_stub\n+        = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+      auto lambda = [profile_stub, md, data, value,\n+                     k_RInfo, klass_RInfo, tmp_load_klass, success_target] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+      auto masm = ce->masm();\n+\n+      if (profile_stub != nullptr)  __ bind(*profile_stub->entry());\n+\n+      __ testptr(value, value);\n+\n@@ -1449,0 +1503,1 @@\n+\n@@ -1453,1 +1508,5 @@\n-      __ jmp(done);\n+      if (profile_stub != nullptr) {\n+        __ jmp(*profile_stub->continuation());\n+      } else {\n+        __ jmp(*success_target);\n+      }\n@@ -1459,1 +1518,1 @@\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n+      ce->type_profile_helper(mdo, md, data, recv, &update_done);\n@@ -1464,0 +1523,22 @@\n+\n+      if (profile_stub != nullptr)  __ jmp(*profile_stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+      };\n+\n+      if (profile_stub != nullptr) {\n+        __ cmpl(r_profile_rng, threshold);\n+        __ jcc(Assembler::below, *profile_stub->entry());\n+        __ bind(*profile_stub->continuation());\n+        __ step_random(r_profile_rng, rscratch1);\n+        __ testptr(value, value);\n+        __ jcc(Assembler::equal, done);\n+\n+        profile_stub->set_action(lambda, op);\n+        profile_stub->set_name(\"Typecheck profile stub\");\n+        append_code_stub(profile_stub);\n+      } else {\n+        lambda(this, op);\n+      }\n+\n@@ -1465,0 +1546,1 @@\n+      __ testptr(value, value);\n@@ -2150,0 +2232,2 @@\n+  \/\/ We do this here in order not to affect call site alignment.\n+  __ save_profile_rng();\n@@ -2173,0 +2257,2 @@\n+\n+  __ restore_profile_rng();\n@@ -2182,0 +2268,1 @@\n+  __ restore_profile_rng();\n@@ -2760,5 +2847,22 @@\n-void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {\n-  ciMethod* method = op->profiled_method();\n-  int bci          = op->profiled_bci();\n-  ciMethod* callee = op->profiled_callee();\n-  Register tmp_load_klass = rscratch1;\n+void LIR_Assembler::increment_profile_ctr(LIR_Opr incr, LIR_Opr addr, LIR_Opr dest, LIR_Opr temp_op,\n+                                          LIR_Opr freq_op, CodeStub* overflow_stub) {\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"increment_profile_ctr\" \" {\");\n+  }\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (UCONST64(1) << 32) >> ratio_shift;\n+\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *counter_stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  Register temp = temp_op->is_register() ? temp_op->as_register() : noreg;\n+  Address dest_adr = as_Address(addr->as_address_ptr());\n+\n+  auto lambda = [counter_stub, overflow_stub, freq_op, ratio_shift, incr,\n+                 temp, dest, dest_adr] (LIR_Assembler* ce, LIR_Op* op) {\n@@ -2766,32 +2870,32 @@\n-  \/\/ Update counter for all call types\n-  ciMethodData* md = method->method_data_or_null();\n-  assert(md != nullptr, \"Sanity\");\n-  ciProfileData* data = md->bci_to_data(bci);\n-  assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n-  assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n-  Register mdo  = op->mdo()->as_register();\n-  __ mov_metadata(mdo, md->constant_encoding());\n-  Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-  \/\/ Perform additional virtual call profiling for invokevirtual and\n-  \/\/ invokeinterface bytecodes\n-  if (op->should_profile_receiver_type()) {\n-    assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n-    Register recv = op->recv()->as_register();\n-    assert_different_registers(mdo, recv);\n-    assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n-    ciKlass* known_klass = op->known_holder();\n-    if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n-      \/\/ We know the type that will be seen at this call site; we can\n-      \/\/ statically update the MethodData* rather than needing to do\n-      \/\/ dynamic tests on the receiver type\n-\n-      \/\/ NOTE: we should probably put a lock around this search to\n-      \/\/ avoid collisions by concurrent compilations\n-      ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n-      uint i;\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (known_klass->equals(receiver)) {\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+\n+    if (counter_stub != nullptr)  __ bind(*counter_stub->entry());\n+\n+    if (incr->is_register()) {\n+      Register inc = incr->as_register();\n+      __ movl(temp, dest_adr);\n+      if (ProfileCaptureRatio > 1) {\n+        __ shll(inc, ratio_shift);\n+      }\n+      __ lea(temp, Address(temp, inc, Address::times_1));\n+      __ movl(dest_adr, temp);\n+      __ movl(dest->as_register(), temp);\n+      if (ProfileCaptureRatio > 1) {\n+        __ shrl(inc, ratio_shift);\n+      }\n+    } else {\n+      jint inc = incr->as_constant_ptr()->as_jint_bits();\n+      switch (dest->type()) {\n+        case T_INT: {\n+          inc *= ProfileCaptureRatio;\n+          __ movl(temp, dest_adr);\n+          \/\/ Use lea instead of add to avoid destroying condition codes on x86\n+          __ lea(temp, Address(temp, inc, Address::times_1));\n+          __ movl(dest_adr, temp);\n+          if (dest->is_register()) {\n+            __ movl(dest->as_register(), temp);\n+          }\n+          break;\n@@ -2799,0 +2903,14 @@\n+        case T_LONG: {\n+          inc *= ProfileCaptureRatio;\n+          __ movq(temp, dest_adr);\n+          \/\/ Use lea instead of add to avoid destroying condition codes on x86\n+          __ lea(temp, Address(temp, inc, Address::times_1));\n+          __ movq(dest_adr, temp);\n+          if (dest->is_register()) {\n+            __ movq(dest->as_register_lo(), temp);\n+          }\n+\n+          break;\n+        }\n+        default:\n+          ShouldNotReachHere();\n@@ -2801,13 +2919,22 @@\n-      \/\/ Receiver type not found in profile data; select an empty slot\n-\n-      \/\/ Note that this is less efficient than it should be because it\n-      \/\/ always does a write to the receiver part of the\n-      \/\/ VirtualCallData rather than just the first time\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (receiver == nullptr) {\n-          Address recv_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));\n-          __ mov_metadata(recv_addr, known_klass->constant_encoding(), rscratch1);\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+      if (incr->is_valid() && overflow_stub) {\n+        if (!freq_op->is_valid()) {\n+          if (!incr->is_constant()) {\n+            __ cmpl(incr->as_register(), 0);\n+            __ jcc(Assembler::equal, *overflow_stub->entry());\n+          } else {\n+            __ jmp(*overflow_stub->entry());\n+            goto exit;\n+          }\n+        } else {\n+          Register result =\n+            dest->type() == T_INT ? dest->as_register() :\n+            dest->type() == T_LONG ? dest->as_register_lo() :\n+            noreg;\n+          if (!incr->is_constant()) {\n+            \/\/ If step is 0, make sure the stub check below always fails\n+            __ cmpl(incr->as_register(), 0);\n+            __ movl(temp, InvocationCounter::count_increment * ProfileCaptureRatio);\n+            __ cmovl(Assembler::notEqual, result, temp);\n+          }\n+          __ andl(result, freq_op->as_jint());\n+          __ jcc(Assembler::equal, *overflow_stub->entry());\n@@ -2816,7 +2943,1 @@\n-    } else {\n-      __ load_klass(recv, recv, tmp_load_klass);\n-      Label update_done;\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n-      \/\/ Increment total counter to indicate polymorphic case.\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n+    }\n@@ -2824,1 +2945,2 @@\n-      __ bind(update_done);\n+    if (counter_stub != nullptr) {\n+      __ jmp(*counter_stub->continuation());\n@@ -2826,0 +2948,139 @@\n+\n+  exit: { }\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (counter_stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *counter_stub->entry());\n+    __ bind(*counter_stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    counter_stub->set_action(lambda, nullptr);\n+    counter_stub->set_name(\"IncrementProfileCtr\");\n+    append_code_stub(counter_stub);\n+  } else {\n+    lambda(this, nullptr);\n+  }\n+\n+  if (overflow_stub != nullptr) {\n+    __ bind(*overflow_stub->continuation());\n+  }\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} increment_profile_ctr\");\n+  }\n+#endif\n+}\n+\n+void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {\n+\n+  Register temp = op->tmp1()->as_register_lo();\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [op, stub] (LIR_Assembler* ce, LIR_Op* base_op) {\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    LIR_OpProfileCall* op = base_op->as_OpProfileCall();\n+    ciMethod* method = op->profiled_method();\n+    int bci          = op->profiled_bci();\n+    ciMethod* callee = op->profiled_callee();\n+    Register tmp_load_klass = rscratch1;\n+\n+    Register temp = op->tmp1()->as_register_lo();\n+\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n+    \/\/ Update counter for all call types\n+    ciMethodData* md = method->method_data_or_null();\n+    assert(md != nullptr, \"Sanity\");\n+    ciProfileData* data = md->bci_to_data(bci);\n+    assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n+    assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n+    Register mdo  = op->mdo()->as_register();\n+    __ mov_metadata(mdo, md->constant_encoding());\n+    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+    \/\/ Perform additional virtual call profiling for invokevirtual and\n+    \/\/ invokeinterface bytecodes\n+    if (op->should_profile_receiver_type()) {\n+      assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n+      Register recv = op->recv()->as_register();\n+      assert_different_registers(mdo, recv);\n+      assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n+      ciKlass* known_klass = op->known_holder();\n+      if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n+        \/\/ We know the type that will be seen at this call site; we can\n+        \/\/ statically update the MethodData* rather than needing to do\n+        \/\/ dynamic tests on the receiver type\n+\n+        \/\/ NOTE: we should probably put a lock around this search to\n+        \/\/ avoid collisions by concurrent compilations\n+        ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n+        uint i;\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (known_klass->equals(receiver)) {\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment);\n+            goto exit;\n+          }\n+        }\n+\n+        \/\/ Receiver type not found in profile data; select an empty slot\n+\n+        \/\/ Note that this is less efficient than it should be because it\n+        \/\/ always does a write to the receiver part of the\n+        \/\/ VirtualCallData rather than just the first time\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (receiver == nullptr) {\n+            Address recv_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));\n+            __ mov_metadata(recv_addr, known_klass->constant_encoding(), rscratch1);\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n+        }\n+      } else {\n+        __ load_klass(recv, recv, tmp_load_klass);\n+        Label update_done;\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n+        \/\/ Increment total counter to indicate polymorphic case.\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+        __ bind(update_done);\n+      }\n+    exit: {}\n+    } else {\n+      \/\/ Static call\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+    }\n+\n+    if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileCallStub\");\n+    append_code_stub(stub);\n@@ -2827,2 +3088,1 @@\n-    \/\/ Static call\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    lambda(this, op);\n@@ -2842,0 +3102,20 @@\n+  __ verify_oop(obj);\n+\n+#ifdef ASSERT\n+  assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [stub, mdo_addr, not_null, exact_klass, current_klass,\n+                 obj, tmp, tmp_load_klass, no_conflict] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+  auto masm = ce->masm();\n@@ -2851,0 +3131,1 @@\n+  if (stub != nullptr)  __ bind(*stub->entry());\n@@ -2854,5 +3135,1 @@\n-  if (obj == tmp) {\n-    assert_different_registers(obj, rscratch1, mdo_addr.base(), mdo_addr.index());\n-  } else {\n-    assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n-  }\n+  assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n@@ -2998,1 +3275,2 @@\n-  }\n+  } \/\/ do_update\n+\n@@ -3000,0 +3278,18 @@\n+  if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, tmp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileTypeStub\");\n+    append_code_stub(stub);\n+  } else {\n+    lambda(this, op);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":369,"deletions":73,"binary":false,"changes":442,"status":"modified"},{"patch":"@@ -1379,0 +1379,4 @@\n+  \/\/ If we're subsampling counter updates, then profiling code kills flags\n+  if (ProfileCaptureRatio != 1) {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+Register r_profile_rng;\n+\n@@ -240,0 +242,2 @@\n+  restore_profile_rng();\n+\n@@ -247,0 +251,1 @@\n+  save_profile_rng();\n@@ -267,0 +272,43 @@\n+\/\/ Randomized profile capture.\n+\n+void C1_MacroAssembler::step_random(Register state, Register temp) {\n+  \/\/ One of these will be the best for a particular CPU.\n+\n+  \/* Algorithm \"xor\" from p. 4 of Marsaglia, \"Xorshift RNGs\" *\/\n+  \/\/ movl(temp, state);\n+  \/\/ sall(temp, 13);\n+  \/\/ xorl(state, temp);\n+  \/\/ movl(temp, state);\n+  \/\/ shrl(temp, 7);\n+  \/\/ xorl(state, temp);\n+  \/\/ movl(temp, state);\n+  \/\/ sall(temp, 5);\n+  \/\/ xorl(state, temp);\n+\n+  if (VM_Version::supports_sse4_2()) {\n+    \/* CRC used as a psuedo-random-number generator *\/\n+    \/\/ In effect, the CRC instruction is being used here for its\n+    \/\/ linear feedback shift register. It's unbeatably fast, and\n+    \/\/ plenty good enough for what we need.\n+    movl(temp, 1);\n+    crc32(state, temp, \/*sizeInBytes*\/2);\n+  } else {\n+    \/* LCG from glibc. *\/\n+    movl(temp, 1103515245);\n+    imull(state, temp);\n+    addl(state, 12345);\n+  }\n+}\n+\n+void C1_MacroAssembler::save_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    movl(Address(r15_thread, JavaThread::profile_rng_offset()), r_profile_rng);\n+  }\n+}\n+\n+void C1_MacroAssembler::restore_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    movl(r_profile_rng, Address(r15_thread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -131,0 +131,5 @@\n+  \/\/ Randomized profile capture\n+  void step_random(Register state, Register temp);\n+  void save_profile_rng();\n+  void restore_profile_rng();\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -64,0 +64,2 @@\n+  Address as_Address(LIR_Assembler* ce, LIR_Address* addr, Register tmp);\n+  Address as_Address(LIR_Assembler* ce, LIR_Address* addr);\n@@ -130,0 +132,39 @@\n+\n+class AbstractLambdaWrapper : public CompilationResourceObj {\n+public:\n+  virtual void operator() (LIR_Assembler* ce) = 0;\n+};\n+\n+template<typename T>\n+struct LambdaWrapper : public AbstractLambdaWrapper {\n+  T _lambda;\n+  LIR_Op* _op;\n+\n+  LambdaWrapper(T lambda, LIR_Op* op) : _lambda(lambda), _op(op) { }\n+  virtual void operator() (LIR_Assembler* ce) {\n+    _lambda(ce, _op);\n+  }\n+};\n+\n+class ProfileStub: public CodeStub {\n+private:\n+  AbstractLambdaWrapper *_action;\n+  const char* _name;\n+\n+public:\n+  ProfileStub() {\n+    _name = \"ProfileStub\";\n+  }\n+  template<typename U>\n+  void set_action(U action, LIR_Op *op) { _action = new LambdaWrapper(action, op); }\n+  void set_name(const char* name) { _name = name; }\n+  virtual void emit_code(LIR_Assembler* ce) {\n+    (*_action)(ce);\n+  }\n+#ifndef PRODUCT\n+  virtual void print_name(outputStream* out) const { out->print(\"%s\", _name); }\n+#endif \/\/ PRODUCT\n+  virtual void visit(LIR_OpVisitState* visitor) { }\n+};\n+\n+\n@@ -141,1 +182,0 @@\n-    NOT_IA32( ShouldNotReachHere(); ) \/\/ used only on x86-32\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":41,"deletions":1,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -297,1 +297,1 @@\n-  \/\/ generate code or slow cases\n+  \/\/ generate code for slow cases\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -893,1 +893,1 @@\n-      do_input(opProfileType->_obj);\n+      do_input(opProfileType->_obj); do_temp(opProfileType->_obj);\n@@ -897,1 +897,17 @@\n-  default:\n+\n+    case lir_increment_counter:\n+    {\n+      LIR_OpIncrementCounter* opr = op->as_OpIncrementCounter();\n+      assert(opr != nullptr, \"must be\");\n+\n+      if (opr->_info)                      do_info(opr->_info);\n+      do_input(opr->_counter_addr);        do_temp(opr->_counter_addr);\n+      do_input(opr->_step);                do_temp(opr->_step);\n+      if (opr->_dest->is_valid())          { do_output(opr->_dest); }\n+      if (opr->_temp_op->is_valid())       do_temp(opr->_temp_op);\n+      if (opr->overflow_stub() != nullptr) do_stub(opr->overflow_stub());\n+\n+      break;\n+    }\n+\n+    default:\n@@ -1062,0 +1078,8 @@\n+void LIR_OpIncrementCounter::emit_code(LIR_Assembler* masm) {\n+  masm->increment_profile_ctr\n+    (_step, _counter_addr, _dest, _temp_op, _freq_op, _overflow_stub);\n+  if (overflow_stub()) {\n+    masm->append_code_stub(overflow_stub());\n+  }\n+}\n+\n@@ -1267,0 +1291,13 @@\n+void LIR_List::increment_counter(LIR_Opr step, LIR_Address* addr, LIR_Opr dest, LIR_Opr tmp,\n+                                 LIR_Opr freq, CodeStub* overflow, CodeEmitInfo* info) {\n+    append(new LIR_OpIncrementCounter (\n+            step,\n+            LIR_OprFact::address(addr),\n+            dest,\n+            tmp,\n+            freq,\n+            overflow,\n+            info));\n+}\n+\n+\n@@ -1758,0 +1795,1 @@\n+     case lir_increment_counter:     s = \"increment_counter\"; break;\n@@ -2053,0 +2091,7 @@\n+void LIR_OpIncrementCounter::print_instr(outputStream* out) const {\n+  step()->print(out);          out->print(\" \");\n+  counter_addr()->print(out);  out->print(\" \");\n+  dest()->print(out);          out->print(\" \");\n+  temp_op()->print(out);       out->print(\" \");\n+  freq_op()->print(out);       out->print(\" \");\n+}\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":47,"deletions":2,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -896,0 +896,1 @@\n+class    LIR_OpIncrementCounter;\n@@ -1000,0 +1001,1 @@\n+    , lir_increment_counter\n@@ -1142,0 +1144,1 @@\n+  virtual LIR_OpIncrementCounter* as_OpIncrementCounter() { return nullptr; }\n@@ -1938,0 +1941,36 @@\n+\/\/ LIR_OpIncrementCounter\n+class LIR_OpIncrementCounter : public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr _step;\n+  LIR_Opr _counter_addr;\n+  LIR_Opr _dest;\n+  LIR_Opr _temp_op;\n+  LIR_Opr _freq_op;\n+  CodeStub* _overflow_stub;\n+\n+ public:\n+  \/\/ Destroys recv\n+  LIR_OpIncrementCounter(LIR_Opr step, LIR_Opr counter_addr, LIR_Opr dest, LIR_Opr temp_op,\n+                         LIR_Opr freq_op, CodeStub* overflow_stub, CodeEmitInfo *info)\n+    : LIR_Op(lir_increment_counter, LIR_OprFact::illegalOpr, info)\n+    , _step(step)\n+    , _counter_addr(counter_addr)\n+    , _dest(dest)\n+    , _temp_op(temp_op)\n+    , _freq_op(freq_op)\n+    , _overflow_stub(overflow_stub) { }\n+\n+  LIR_Opr   step()          const            { return _step;          }\n+  LIR_Opr   counter_addr()  const            { return _counter_addr;  }\n+  LIR_Opr   dest()          const            { return _dest;          }\n+  LIR_Opr   temp_op()       const            { return _temp_op;       }\n+  LIR_Opr   freq_op()       const            { return _freq_op;       }\n+  CodeStub* overflow_stub() const            { return _overflow_stub; };\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpIncrementCounter* as_OpIncrementCounter() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n@@ -2240,0 +2279,6 @@\n+  void increment_counter(LIR_Opr src, LIR_Address* addr, LIR_Opr res, LIR_Opr tmp, LIR_Opr freq, CodeStub* overflow, CodeEmitInfo* info);\n+  void increment_counter(LIR_Opr src, LIR_Address* addr, LIR_Opr res, LIR_Opr tmp, CodeStub* overflow = nullptr) {\n+    increment_counter(src, addr, res, tmp, LIR_OprFact::illegalOpr, overflow, nullptr);\n+  }\n+\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -238,0 +238,4 @@\n+  void increment_profile_ctr(LIR_Opr incr, LIR_Opr addr, LIR_Opr dest, LIR_Opr temp,\n+                             LIR_Opr freq_op,\n+                             CodeStub *overflow);\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -930,5 +930,3 @@\n-    __ move(data_addr, data_reg);\n-    \/\/ Use leal instead of add to avoid destroying condition codes on x86\n-    LIR_Address* fake_incr_value = new LIR_Address(data_reg, DataLayout::counter_increment, T_INT);\n-    __ leal(LIR_OprFact::address(fake_incr_value), data_reg);\n-    __ move(data_reg, data_addr);\n+    LIR_Opr tmp = new_register(T_INT);\n+    LIR_Opr step = LIR_OprFact::intConst(DataLayout::counter_increment);\n+    __ increment_counter(step, data_addr, LIR_OprFact::intConst(0), tmp, nullptr);\n@@ -2376,2 +2374,6 @@\n-    increment_counter(new LIR_Address(md_reg, offset,\n-                                      NOT_LP64(T_INT) LP64_ONLY(T_LONG)), DataLayout::counter_increment);\n+    LIR_Address *counter_addr = new LIR_Address(md_reg, offset,\n+                                           NOT_LP64(T_INT) LP64_ONLY(T_LONG));\n+    LIR_Opr tmp = new_register(T_INT);\n+    LIR_Opr dummy = LIR_OprFact::intConst(0);\n+    LIR_Opr inc = LIR_OprFact::intConst(DataLayout::counter_increment);\n+    __ increment_counter(inc, counter_addr, dummy, tmp, nullptr);\n@@ -3175,4 +3177,3 @@\n-  LIR_Opr result = new_register(T_INT);\n-  __ load(counter, result);\n-  __ add(result, step, result);\n-  __ store(result, counter);\n+  LIR_Opr result = notify ? new_register(T_INT) : LIR_OprFact::intConst(0);\n+  LIR_Opr tmp = new_register(T_INT);\n+\n@@ -3180,0 +3181,1 @@\n+    int ratio_shift = exact_log2(ProfileCaptureRatio);\n@@ -3182,21 +3184,11 @@\n-    CodeStub* overflow = new CounterOverflowStub(info, bci, meth);\n-    int freq = frequency << InvocationCounter::count_shift;\n-    if (freq == 0) {\n-      if (!step->is_constant()) {\n-        __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));\n-        __ branch(lir_cond_notEqual, overflow);\n-      } else {\n-        __ branch(lir_cond_always, overflow);\n-      }\n-    } else {\n-      LIR_Opr mask = load_immediate(freq, T_INT);\n-      if (!step->is_constant()) {\n-        \/\/ If step is 0, make sure the overflow check below always fails\n-        __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));\n-        __ cmove(lir_cond_notEqual, result, LIR_OprFact::intConst(InvocationCounter::count_increment), result, T_INT);\n-      }\n-      __ logical_and(result, mask, result);\n-      __ cmp(lir_cond_equal, result, LIR_OprFact::intConst(0));\n-      __ branch(lir_cond_equal, overflow);\n-    }\n-    __ branch_destination(overflow->continuation());\n+    CodeStub* overflow = new CounterOverflowStub (info, bci, meth);\n+    \/\/ Zero the low-order bits of the frequency, otherwise we'll miss\n+    \/\/ overflows when usind randomized profile counters.\n+    unsigned int freq = (unsigned int)frequency\n+                         >> ratio_shift << ratio_shift\n+                         << InvocationCounter::count_shift;\n+    __ increment_counter(step, counter, result, tmp,\n+                         LIR_OprFact::intConst(freq), overflow, info);\n+  } else {\n+    __ increment_counter(step, counter, result, tmp,\n+                             LIR_OprFact::illegalOpr, nullptr, info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":24,"deletions":32,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -398,0 +398,6 @@\n+  product(int, ProfileCaptureRatio, 64, EXPERIMENTAL,                        \\\n+          \"Reduce and randomize tiered-compilation profile captures \"       \\\n+          \"in order to reduce cache contention on shared method data. \"     \\\n+          \"Must be a power of 2.\")                                          \\\n+          range(1, 65536)\n+\n","filename":"src\/hotspot\/share\/compiler\/compiler_globals.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -520,1 +520,3 @@\n-  _om_cache(this) {\n+  _om_cache(this),\n+\n+  _profile_rng(-1) {\n@@ -537,0 +539,10 @@\n+  \/\/ Initial state of random-number generator used when profiling\n+  \/\/ C1-generated code.\n+  if (ProfileCaptureRatio > 1) {\n+    int state;\n+    do {\n+      state = os::random();\n+    } while (state == 0);\n+    _profile_rng = state;\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -885,0 +885,1 @@\n+  static ByteSize profile_rng_offset()        { return byte_offset_of(JavaThread, _profile_rng); }\n@@ -1246,0 +1247,3 @@\n+  \/\/ Random value for randomized profile counters.\n+  uint32_t _profile_rng;\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}