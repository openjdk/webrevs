{"files":[{"patch":"@@ -47,0 +47,3 @@\n+  else ifeq ($(call isTargetCpuArch, arm), true)\n+    CAPSTONE_ARCH := CS_ARCH_ARM\n+    CAPSTONE_MODE := CS_MODE_ARM\n","filename":"make\/Hsdis.gmk","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -151,0 +151,3 @@\n+\/\/ State for randomized profile counters. Used by C1.\n+extern Register r_profile_rng;\n+\n@@ -459,1 +462,1 @@\n-  Address(Register base, RegisterOrConstant index, extend ext = lsl()) {\n+  Address(Register base, RegisterOrConstant index, extend ext = lsl(0)) {\n@@ -3230,5 +3233,5 @@\n-#define INSN(NAME, c, sf, sz)                                             \\\n-  void NAME(Register Rd, Register Rn, Register Rm) {                      \\\n-    starti;                                                               \\\n-    f(sf, 31), f(0b0011010110, 30, 21), f(0b010, 15, 13), f(c, 12);       \\\n-    f(sz, 11, 10), rf(Rm, 16), rf(Rn, 5), rf(Rd, 0);                      \\\n+#define INSN(NAME, c, sf, sz)                                           \\\n+  void NAME(Register Rd, Register Rn, Register Rm) {                    \\\n+    starti;                                                             \\\n+    f(sf, 31), f(0b0011010110, 30, 21), f(0b010, 15, 13), f(c, 12);     \\\n+    f(sz, 11, 10), zrf(Rm, 16), rf(Rn, 5), rf(Rd, 0);                   \\\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":9,"deletions":6,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -194,1 +194,0 @@\n-  map_register(i, r26); r26_opr = LIR_OprFact::single_cpu(i); i++;\n@@ -196,5 +195,19 @@\n-  \/\/ r27 is allocated conditionally. With compressed oops it holds\n-  \/\/ the heapbase value and is not visible to the allocator.\n-  bool preserve_rheapbase = i >= nof_caller_save_cpu_regs();\n-  if (!preserve_rheapbase) {\n-    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n+  auto remaining = RegSet::of(r26, r27);\n+\n+  if (UseCompressedOops && (CompressedOops::base() != nullptr)) {\n+    \/\/ r27 is allocated conditionally. With compressed oops it holds\n+    \/\/ the heapbase value and is not visible to the allocator.\n+    remaining -= r27;\n+  }\n+\n+  if (ProfileCaptureRatio > 1) {\n+    \/\/ Use the highest remaining register for r_profile_rng.\n+    r_profile_rng = *remaining.rbegin();\n+    remaining -= r_profile_rng;\n+  }\n+\n+  if (remaining.contains(r26)) {\n+    map_register(i, r26); r26_opr = LIR_OprFact::single_cpu(i); i++;\n+  }\n+  if (remaining.contains(r27)) {\n+    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++;\n@@ -208,4 +221,0 @@\n-\n-  if (preserve_rheapbase) {\n-    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n-  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.cpp","additions":19,"deletions":10,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -150,0 +150,5 @@\n+    \/\/ Use r26 for randomized profile captures.\n+    if (ProfileCaptureRatio > 1) {\n+      range -= 1;\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1241,1 +1241,1 @@\n-              DataLayout::counter_increment);\n+              DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1253,1 +1253,1 @@\n-    __ mov(rscratch1, DataLayout::counter_increment);\n+    __ mov(rscratch1, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1270,0 +1270,5 @@\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n@@ -1319,6 +1324,21 @@\n-    Label update_done;\n-    Register recv = k_RInfo;\n-    __ load_klass(recv, obj);\n-    type_profile_helper(mdo, md, data, recv, &update_done);\n-    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    ProfileStub *stub\n+      = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+    auto lambda = [stub, md, mdo, data, k_RInfo, obj] (LIR_Assembler* ce, LIR_Op* base_op) {\n+\n+#undef __\n+#define __ masm->\n+\n+      auto masm = ce->masm();\n+      if (stub != nullptr)  __ bind(*stub->entry());\n+\n+      Label update_done;\n+      Register recv = k_RInfo;\n+      __ load_klass(recv, obj);\n+      ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+      Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+      __ bind(update_done);\n+\n+      if (stub != nullptr)  __ b(*stub->continuation());\n@@ -1326,1 +1346,16 @@\n-    __ bind(update_done);\n+#undef __\n+#define __ _masm->\n+    };\n+\n+    if (stub != nullptr) {\n+      __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+      __ cbz(rscratch1, *stub->entry());\n+      __ bind(*stub->continuation());\n+      __ step_random(r_profile_rng, rscratch2);\n+\n+      stub->set_action(lambda, op);\n+      stub->set_name(\"Typecheck stub\");\n+      append_code_stub(stub);\n+    } else {\n+      lambda(this, op);\n+    }\n@@ -1419,13 +1454,34 @@\n-      Label not_null;\n-      Register mdo  = klass_RInfo;\n-      __ mov_metadata(mdo, md->constant_encoding());\n-      __ cbnz(value, not_null);\n-      \/\/ Object is null; update MDO and exit\n-      Address data_addr\n-        = __ form_address(rscratch2, mdo,\n-                          md->byte_offset_of_slot(data, DataLayout::flags_offset()), 0);\n-      __ ldrb(rscratch1, data_addr);\n-      __ orr(rscratch1, rscratch1, BitData::null_seen_byte_constant());\n-      __ strb(rscratch1, data_addr);\n-      __ b(done);\n-      __ bind(not_null);\n+      int profile_capture_ratio = ProfileCaptureRatio;\n+      int ratio_shift = exact_log2(profile_capture_ratio);\n+      auto threshold = (1ull << 32) >> ratio_shift;\n+      assert(threshold > 0, \"must be\");\n+\n+      ProfileStub *profile_stub\n+        = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+      auto lambda = [profile_stub, md, data, value,\n+                     k_RInfo, klass_RInfo, success_target] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+        auto masm = ce->masm();\n+\n+        if (profile_stub != nullptr)  __ bind(*profile_stub->entry());\n+\n+        Label not_null;\n+        Register mdo  = klass_RInfo;\n+        __ mov_metadata(mdo, md->constant_encoding());\n+        __ cbnz(value, not_null);\n+        \/\/ Object is null; update MDO and exit\n+        Address data_addr\n+          = __ form_address(rscratch2, mdo,\n+                            md->byte_offset_of_slot(data, DataLayout::flags_offset()), 0);\n+        __ ldrb(rscratch1, data_addr);\n+        __ orr(rscratch1, rscratch1, BitData::null_seen_byte_constant());\n+        __ strb(rscratch1, data_addr);\n+        if (profile_stub != nullptr) {\n+          __ b(*profile_stub->continuation());\n+        } else {\n+          __ b(*success_target);\n+        }\n+        __ bind(not_null);\n@@ -1433,7 +1489,27 @@\n-      Label update_done;\n-      Register recv = k_RInfo;\n-      __ load_klass(recv, value);\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n-      __ bind(update_done);\n+        Label update_done;\n+        Register recv = k_RInfo;\n+        __ load_klass(recv, value);\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+        __ bind(update_done);\n+\n+        if (profile_stub != nullptr)  __ b(*profile_stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+      };\n+\n+      if (profile_stub != nullptr) {\n+        __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+        __ cbz(rscratch1, *profile_stub->entry());\n+        __ bind(*profile_stub->continuation());\n+        __ step_random(r_profile_rng, rscratch2);\n+        __ cbz(value, done);\n+\n+        profile_stub->set_action(lambda, op);\n+        profile_stub->set_name(\"Typecheck profile stub\");\n+        append_code_stub(profile_stub);\n+      } else {\n+        lambda(this, op);\n+      }\n@@ -1990,2 +2066,3 @@\n-void LIR_Assembler::align_call(LIR_Code code) {  }\n-\n+void LIR_Assembler::align_call(LIR_Code code) {\n+  __ save_profile_rng();\n+}\n@@ -2001,0 +2078,1 @@\n+  __ restore_profile_rng();\n@@ -2012,0 +2090,1 @@\n+  __ restore_profile_rng();\n@@ -2518,0 +2597,133 @@\n+void LIR_Assembler::increment_profile_ctr(LIR_Opr step, LIR_Opr dest_opr,\n+                                          LIR_Opr freq_opr,\n+                                          LIR_Opr md_reg, LIR_Opr md_opr, LIR_Opr md_offset_opr,\n+                                          CodeStub* overflow_stub) {\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"increment_event_counter {\");\n+  }\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  unsigned long threshold = (UCONST64(1) << 32) >> ratio_shift;\n+\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *counter_stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  Register dest = as_reg(dest_opr);\n+\n+  auto lambda = [counter_stub, overflow_stub, freq_opr, dest_opr, dest, ratio_shift, step,\n+                 md_reg, md_opr, md_offset_opr] (LIR_Assembler* ce, LIR_Op* op) {\n+\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    Address counter_address;\n+\n+    if (counter_stub != nullptr)  __ bind(*counter_stub->entry());\n+\n+    if (md_opr->is_valid()) {\n+      if (md_opr->type() == T_METADATA) {\n+        __ mov_metadata(md_reg->as_register(),\n+                          md_opr->as_constant_ptr()->as_metadata());\n+      } else {\n+        __ mov(md_reg->as_pointer_register(),\n+               md_opr->as_constant_ptr()->as_pointer());\n+      }\n+      RegisterOrConstant offset =\n+        md_offset_opr->is_constant()\n+        ? RegisterOrConstant(md_offset_opr->as_constant_ptr()->as_jint())\n+        : as_reg(md_offset_opr);\n+      counter_address = Address(md_reg->as_pointer_register(), offset);\n+    }\n+    if (step->is_register()) {\n+      Address dest_adr = __ legitimize_address(counter_address, sizeof (jint), rscratch2);\n+      Register inc = step->as_register();\n+      __ ldrw(dest, dest_adr);\n+      if (ProfileCaptureRatio > 1) {\n+        __ lsl(inc, inc, ratio_shift);\n+      }\n+      __ addw(dest, dest, inc);\n+      __ strw(dest, dest_adr);\n+      if (ProfileCaptureRatio > 1) {\n+        __ lsr(inc, inc, ratio_shift);\n+      }\n+    } else {\n+      jint inc = step->as_constant_ptr()->as_jint_bits();\n+      switch (dest_opr->type()) {\n+        case T_INT: {\n+          Address dest_adr = __ legitimize_address(counter_address, sizeof (jint), rscratch2);\n+          inc *= ProfileCaptureRatio;\n+          __ incrementw(dest_adr, inc, dest);\n+\n+          break;\n+        }\n+        case T_LONG: {\n+          Address dest_adr = __ legitimize_address(counter_address, sizeof (jlong), rscratch2);\n+          inc *= ProfileCaptureRatio;\n+          __ increment(dest_adr, inc, dest);\n+\n+          break;\n+        }\n+        default:\n+          ShouldNotReachHere();\n+      }\n+\n+      if (step->is_valid() && overflow_stub) {\n+        if (!freq_opr->is_valid()) {\n+          if (!step->is_constant()) {\n+            __ cbz(step->as_register(), *overflow_stub->entry());\n+          } else {\n+            __ b(*overflow_stub->entry());\n+            return;\n+          }\n+        } else {\n+          if (!step->is_constant()) {\n+            \/\/ If step is 0, make sure the stub check below always fails\n+            __ cmp(step->as_register(), (u1)0);\n+            __ mov(rscratch1, InvocationCounter::count_increment * ProfileCaptureRatio);\n+            __ csel(dest, dest, rscratch1, __ NE);\n+          }\n+          juint mask = freq_opr->as_jint();\n+          __ andw(rscratch1, dest,  mask);\n+          __ cbzw(rscratch1, *overflow_stub->entry());\n+        }\n+      }\n+    }\n+\n+    if (counter_stub != nullptr) {\n+      __ b(*counter_stub->continuation());\n+    }\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (counter_stub != nullptr) {\n+    __ ubfx(rscratch1, r_profile_rng, 32 - ratio_shift, ratio_shift);\n+    __ cbz(rscratch1, *counter_stub->entry());\n+    __ bind(*counter_stub->continuation());\n+    __ step_random(r_profile_rng, rscratch2);\n+\n+    counter_stub->set_action(lambda, nullptr);\n+    counter_stub->set_name(\"IncrementEventCounter\");\n+    append_code_stub(counter_stub);\n+  } else {\n+    lambda(this, nullptr);\n+  }\n+\n+  if (overflow_stub != nullptr) {\n+    __ bind(*overflow_stub->continuation());\n+  }\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} increment_event_counter\");\n+  }\n+#endif\n+}\n+\n@@ -2523,32 +2735,64 @@\n-  \/\/ Update counter for all call types\n-  ciMethodData* md = method->method_data_or_null();\n-  assert(md != nullptr, \"Sanity\");\n-  ciProfileData* data = md->bci_to_data(bci);\n-  assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n-  assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n-  Register mdo  = op->mdo()->as_register();\n-  __ mov_metadata(mdo, md->constant_encoding());\n-  Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-  \/\/ Perform additional virtual call profiling for invokevirtual and\n-  \/\/ invokeinterface bytecodes\n-  if (op->should_profile_receiver_type()) {\n-    assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n-    Register recv = op->recv()->as_register();\n-    assert_different_registers(mdo, recv);\n-    assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n-    ciKlass* known_klass = op->known_holder();\n-    if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n-      \/\/ We know the type that will be seen at this call site; we can\n-      \/\/ statically update the MethodData* rather than needing to do\n-      \/\/ dynamic tests on the receiver type\n-\n-      \/\/ NOTE: we should probably put a lock around this search to\n-      \/\/ avoid collisions by concurrent compilations\n-      ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n-      uint i;\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (known_klass->equals(receiver)) {\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"profile_call {\");\n+  }\n+#endif\n+\n+  Register temp = op->tmp1()->as_register_lo();\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [stub] (LIR_Assembler* ce, LIR_Op* base_op) {\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    LIR_OpProfileCall* op = base_op->as_OpProfileCall();\n+    ciMethod* method = op->profiled_method();\n+    int bci          = op->profiled_bci();\n+    ciMethod* callee = op->profiled_callee();\n+    Register tmp_load_klass = rscratch1;\n+\n+    Register temp = op->tmp1()->as_register_lo();\n+\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n+    \/\/ Update counter for all call types\n+    ciMethodData* md = method->method_data_or_null();\n+    assert(md != nullptr, \"Sanity\");\n+    ciProfileData* data = md->bci_to_data(bci);\n+    assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n+    assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n+    Register mdo  = op->mdo()->as_register();\n+    __ mov_metadata(mdo, md->constant_encoding());\n+    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+    \/\/ Perform additional virtual call profiling for invokevirtual and\n+    \/\/ invokeinterface bytecodes\n+    if (op->should_profile_receiver_type()) {\n+      assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n+      Register recv = op->recv()->as_register();\n+      assert_different_registers(mdo, recv);\n+      assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n+      ciKlass* known_klass = op->known_holder();\n+      if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n+        \/\/ We know the type that will be seen at this call site; we can\n+        \/\/ statically update the MethodData* rather than needing to do\n+        \/\/ dynamic tests on the receiver type\n+\n+        \/\/ NOTE: we should probably put a lock around this search to\n+        \/\/ avoid collisions by concurrent compilations\n+        ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n+        uint i;\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (known_klass->equals(receiver)) {\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n@@ -2556,1 +2800,0 @@\n-      }\n@@ -2558,17 +2801,18 @@\n-      \/\/ Receiver type not found in profile data; select an empty slot\n-\n-      \/\/ Note that this is less efficient than it should be because it\n-      \/\/ always does a write to the receiver part of the\n-      \/\/ VirtualCallData rather than just the first time\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (receiver == nullptr) {\n-          __ mov_metadata(rscratch1, known_klass->constant_encoding());\n-          Address recv_addr =\n-            __ form_address(rscratch2, mdo,\n-                            md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)),\n-                            LogBytesPerWord);\n-          __ str(rscratch1, recv_addr);\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+        \/\/ Receiver type not found in profile data; select an empty slot\n+\n+        \/\/ Note that this is less efficient than it should be because it\n+        \/\/ always does a write to the receiver part of the\n+        \/\/ VirtualCallData rather than just the first time\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (receiver == nullptr) {\n+            __ mov_metadata(rscratch1, known_klass->constant_encoding());\n+            Address recv_addr =\n+              __ form_address(rscratch2, mdo,\n+                              md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)),\n+                              LogBytesPerWord);\n+            __ str(rscratch1, recv_addr);\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n@@ -2576,0 +2820,9 @@\n+      } else {\n+        __ load_klass(recv, recv);\n+        Label update_done;\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n+        \/\/ Increment total counter to indicate polymorphic case.\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+        __ bind(update_done);\n@@ -2577,0 +2830,1 @@\n+    exit: {}\n@@ -2578,8 +2832,2 @@\n-      __ load_klass(recv, recv);\n-      Label update_done;\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n-      \/\/ Increment total counter to indicate polymorphic case.\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n-\n-      __ bind(update_done);\n+      \/\/ Static call\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -2587,0 +2835,16 @@\n+\n+    if (stub != nullptr)  __ b(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ ubfx(rscratch1, r_profile_rng, 32-ratio_shift, ratio_shift);\n+    __ cbz(rscratch1, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileCallStub\");\n+    append_code_stub(stub);\n@@ -2588,2 +2852,1 @@\n-    \/\/ Static call\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    lambda(this, op);\n@@ -2591,0 +2854,6 @@\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} profile_call\");\n+  }\n+#endif\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":360,"deletions":91,"binary":false,"changes":451,"status":"modified"},{"patch":"@@ -1382,0 +1382,4 @@\n+  \/\/ If we're subsampling counter updates, then profiling code kills flags\n+  if (ProfileCaptureRatio != 1) {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+Register r_profile_rng;\n+\n@@ -250,0 +252,1 @@\n+  restore_profile_rng();\n@@ -258,0 +261,1 @@\n+  save_profile_rng();\n@@ -279,0 +283,29 @@\n+\/\/ Randomized profile capture.\n+\n+void C1_MacroAssembler::step_random(Register state, Register temp, Register data) {\n+  if (VM_Version::supports_crc32()) {\n+    \/* CRC used as a psuedo-random-number generator *\/\n+    \/\/ In effect, the CRC instruction is being used here for its\n+    \/\/ linear feedback shift register. It's unbeatably fast, and\n+    \/\/ plenty good enough for what we need.\n+    crc32h(state, state, data);\n+  } else {\n+    \/* LCG from glibc. *\/\n+    mov(temp, 1103515245);\n+    mulw(state, state, temp);\n+    addw(state, state, 12345);\n+  }\n+}\n+\n+void C1_MacroAssembler::save_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    strw(r_profile_rng, Address(rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n+void C1_MacroAssembler::restore_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    ldrw(r_profile_rng, Address(rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -116,0 +116,5 @@\n+  \/\/ Randomized profile capture\n+  void step_random(Register state, Register temp, Register data = rthread);\n+  void save_profile_rng();\n+  void restore_profile_rng();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2742,1 +2742,1 @@\n-void MacroAssembler::incrementw(Address dst, int value)\n+void MacroAssembler::incrementw(Address dst, int value, Register result)\n@@ -2744,1 +2744,3 @@\n-  assert(!dst.uses(rscratch1), \"invalid dst for address increment\");\n+  assert(!dst.uses(result), \"invalid dst for address increment\");\n+  assert(result->is_valid(), \"must be\");\n+  assert_different_registers(result, rscratch2);\n@@ -2750,3 +2752,3 @@\n-  ldrw(rscratch1, dst);\n-  incrementw(rscratch1, value);\n-  strw(rscratch1, dst);\n+  ldrw(result, dst);\n+  incrementw(result, value);\n+  strw(result, dst);\n@@ -2755,1 +2757,1 @@\n-void MacroAssembler::increment(Address dst, int value)\n+void MacroAssembler::increment(Address dst, int value, Register result)\n@@ -2757,1 +2759,3 @@\n-  assert(!dst.uses(rscratch1), \"invalid dst for address increment\");\n+  assert(!dst.uses(result), \"invalid dst for address increment\");\n+  assert(result->is_valid(), \"must be\");\n+  assert_different_registers(result, rscratch2);\n@@ -2763,3 +2767,3 @@\n-  ldr(rscratch1, dst);\n-  increment(rscratch1, value);\n-  str(rscratch1, dst);\n+  ldr(result, dst);\n+  increment(result, value);\n+  str(result, dst);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":14,"deletions":10,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -484,0 +484,19 @@\n+  using Assembler::andw, Assembler::andr;\n+  void andw(Register Rd, Register Rn, uint64_t imm) {\n+    if (operand_valid_for_logical_immediate(\/*is32*\/true, imm)) {\n+      Assembler::andw(Rd, Rn, imm);\n+    } else {\n+      assert(Rd != Rn, \"must be\");\n+      movw(Rd, imm);\n+      andw(Rd, Rn, Rd);\n+    }\n+  }\n+  void andr(Register Rd, Register Rn, uint64_t imm) {\n+    if (operand_valid_for_logical_immediate(\/*is32*\/false, imm)) {\n+      Assembler::andr(Rd, Rn, imm);\n+    } else {\n+      assert(Rd != Rn, \"must be\");\n+      mov(Rd, imm);\n+      andr(Rd, Rn, Rd);\n+    }\n+  }\n@@ -756,1 +775,1 @@\n-  void incrementw(Address dst, int value = 1);\n+  void incrementw(Address dst, int value = 1, Register result = rscratch1);\n@@ -760,1 +779,1 @@\n-  void increment(Address dst, int value = 1);\n+  void increment(Address dst, int value = 1, Register result = rscratch1);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":21,"deletions":2,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -402,0 +402,7 @@\n+template <>\n+inline Register AbstractRegSet<Register>::last() {\n+  if (_bitset == 0) { return noreg; }\n+  int last = max_size() - 1 - count_leading_zeros(_bitset);\n+  return as_Register(last);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -98,1 +98,2 @@\n-    return range;\n+    int result = range - (ProfileCaptureRatio > 1);\n+    return align_down(result, 2);  \/\/ ouch\n","filename":"src\/hotspot\/cpu\/arm\/c1_FrameMap_arm.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2461,0 +2461,133 @@\n+void LIR_Assembler::increment_profile_ctr(LIR_Opr step, LIR_Opr dest_opr,\n+                                          LIR_Opr freq_opr,\n+                                          LIR_Opr md_reg, LIR_Opr md_opr, LIR_Opr md_offset_opr,\n+                                          CodeStub* overflow_stub) {\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"increment_event_counter {\");\n+  }\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  uint64_t threshold = (UCONST64(1) << 32) >> ratio_shift;\n+\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *counter_stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  Register dest = dest_opr->as_register();\n+\n+  auto lambda = [counter_stub, overflow_stub, freq_opr, dest_opr, dest, ratio_shift, step,\n+                 md_reg, md_opr, md_offset_opr] (LIR_Assembler* ce, LIR_Op* op) {\n+\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    Address counter_address;\n+\n+    if (counter_stub != nullptr)  __ bind(*counter_stub->entry());\n+\n+    if (md_opr->is_valid()) {\n+      if (md_opr->type() == T_METADATA) {\n+        __ mov_metadata(md_reg->as_register(),\n+                        md_opr->as_constant_ptr()->as_metadata());\n+      } else {\n+        __ lea(md_reg->as_pointer_register(),\n+               ExternalAddress(md_opr->as_constant_ptr()->as_pointer()));\n+      }\n+      RegisterOrConstant offset =\n+        md_offset_opr->is_constant()\n+        ? RegisterOrConstant(md_offset_opr->as_constant_ptr()->as_jint())\n+        : md_offset_opr->as_register();\n+      counter_address = Address(md_reg->as_pointer_register(), offset);\n+    }\n+    if (step->is_register()) {\n+      Address dest_adr = counter_address;\n+      Register inc = step->as_register();\n+      if (ProfileCaptureRatio > 1) {\n+        __ mov(inc, AsmOperand(inc, lsl, ratio_shift));\n+      }\n+      __ increment_mdp_data_at(dest_adr, dest, 1);\n+      if (ProfileCaptureRatio > 1) {\n+        __ mov(inc, AsmOperand(inc, lsr, ratio_shift));\n+      }\n+    } else {\n+      jint inc = step->as_constant_ptr()->as_jint_bits();\n+      switch (dest_opr->type()) {\n+        case T_INT: {\n+          Address dest_adr = counter_address;\n+          inc *= ProfileCaptureRatio;\n+          __ increment_mdp_data_at(dest_adr, dest, 1);\n+\n+          break;\n+        }\n+        \/\/ case T_LONG: {\n+        \/\/   Address dest_adr = counter_address;\n+        \/\/   inc *= ProfileCaptureRatio;\n+        \/\/   __ increment(dest_adr, inc, dest);\n+\n+        \/\/   break;\n+        \/\/ }\n+        default:\n+          ShouldNotReachHere();\n+      }\n+\n+      if (step->is_valid() && overflow_stub) {\n+        if (!freq_opr->is_valid()) {\n+          if (!step->is_constant()) {\n+            __ cbz(step->as_register(), *overflow_stub->entry());\n+          } else {\n+            __ b(*overflow_stub->entry());\n+            return;\n+          }\n+        } else {\n+          if (!step->is_constant()) {\n+            \/\/ If step is 0, make sure the stub check below always fails\n+            __ cmp(step->as_register(), (u1)0);\n+            __ mov(Rtemp, InvocationCounter::count_increment * ProfileCaptureRatio);\n+            __ mov(dest, Rtemp, eq);\n+          }\n+          juint mask = freq_opr->as_jint();\n+          __ mov_slow(Rtemp, mask);\n+          __ tst(dest, Rtemp);\n+          __ b(*overflow_stub->entry(), eq);\n+        }\n+      }\n+    }\n+\n+    if (counter_stub != nullptr) {\n+      __ b(*counter_stub->continuation());\n+    }\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (counter_stub != nullptr) {\n+    __ mov(Rtemp, AsmOperand(r_profile_rng, lsr, 32 - ratio_shift));\n+    __ cmp(Rtemp, 0);\n+    __ b(*counter_stub->entry(), eq);\n+    __ bind(*counter_stub->continuation());\n+    __ step_random(r_profile_rng, Rtemp);\n+\n+    counter_stub->set_action(lambda, nullptr);\n+    counter_stub->set_name(\"IncrementEventCounter\");\n+    append_code_stub(counter_stub);\n+  } else {\n+    lambda(this, nullptr);\n+  }\n+\n+  if (overflow_stub != nullptr) {\n+    __ bind(*overflow_stub->continuation());\n+  }\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} increment_event_counter\");\n+  }\n+#endif\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":133,"deletions":0,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -740,0 +740,24 @@\n+\n+void LIRGenerator::arm_cas_long(LIR_Opr addr, LIRItem& cmp_value, LIRItem& new_value, LIR_Opr &result) {\n+  address func = StubRoutines::Arm::atomic_compareAndSet_long_entry();\n+\n+  BasicTypeList signature;\n+  signature.append(T_LONG);\n+  signature.append(T_LONG);\n+  signature.append(T_ADDRESS);\n+\n+  CallingConvention* cc = frame_map()->c_calling_convention(&signature);\n+  cmp_value.load_item_force(cc->at(0));\n+  new_value.load_item_force(cc->at(1));\n+  __ move(addr->as_address_ptr()->base(), cc->at(2));\n+  assert(addr->as_address_ptr()->disp() == 0, \"must be\");\n+\n+  LIR_OprList *args = new LIR_OprList(3);\n+  args->append(cmp_value.result());\n+  args->append(new_value.result());\n+  args->append(cc->at(2));\n+\n+  __ call_runtime_leaf(func, LIR_OprFact::illegalOpr, FrameMap::Int_result_opr, args);\n+  __ move(FrameMap::Int_result_opr, result);\n+}\n+\n@@ -741,1 +765,0 @@\n-  LIR_Opr ill = LIR_OprFact::illegalOpr;  \/\/ for convenience\n@@ -752,2 +775,8 @@\n-    tmp1 = new_register(T_LONG);\n-    __ cas_long(addr->as_address_ptr()->base(), cmp_value.result(), new_value.result(), tmp1, tmp2, result);\n+    if (ProfileCaptureRatio > 1) {\n+      \/\/ Call out to runtime because we don't have enough registers to\n+      \/\/ expand compareAndSet(long) inline.\n+      arm_cas_long(addr, cmp_value, new_value, result);\n+    } else {\n+      tmp1 = new_register(T_LONG);\n+      __ cas_long(addr->as_address_ptr()->base(), cmp_value.result(), new_value.result(), tmp1, tmp2, result);\n+    }\n@@ -1278,0 +1307,5 @@\n+  \/\/ If we're subsampling counter updates, then profiling code kills flags\n+  \/\/ if (ProfileCaptureRatio != 1)\n+    {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRGenerator_arm.cpp","additions":37,"deletions":3,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+  void arm_cas_long(LIR_Opr addr, LIRItem& cmp_value, LIRItem& new_value, LIR_Opr &result);\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRGenerator_arm.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -225,0 +225,57 @@\n+\/\/ Increments mdp data. Sets bumped_count register to adjusted counter.\n+void C1_MacroAssembler::increment_mdp_data_at(Address data,\n+                                              Register bumped_count,\n+                                              int increment) {\n+  assert(ProfileInterpreter, \"must be profiling interpreter\");\n+  assert_different_registers(data.base(), Rtemp);\n+  assert(data.mode() == basic_offset, \"must be\");\n+\n+  int offset = data.disp();\n+  bool is_memoryI =  offset < 4096 && offset > -4096;\n+\n+  if (!is_memoryI) {\n+    block_comment(\"Move slow\");\n+    mov_slow(Rtemp, offset);\n+    data = Address(data.base(), Rtemp);\n+  }\n+  ldr(bumped_count, data);\n+  if (increment < 0) {\n+    sub(bumped_count, bumped_count, -increment);\n+  } else {\n+    add(bumped_count, bumped_count, increment);\n+  }\n+  str(bumped_count, data);\n+}\n+\n+\/\/ Randomized profile capture.\n+\n+void C1_MacroAssembler::step_random(Register state, Register temp, Register data) {\n+  \/\/ if (VM_Version::supports_crc32()) {\n+  \/\/   \/* CRC used as a psuedo-random-number generator *\/\n+  \/\/   \/\/ In effect, the CRC instruction is being used here for its\n+  \/\/   \/\/ linear feedback shift register. It's unbeatably fast, and\n+  \/\/   \/\/ plenty good enough for what we need.\n+  \/\/   crc32h(state, state, data);\n+  \/\/ } else\n+    {\n+    \/* LCG from glibc. *\/\n+    mov_slow(temp, 1103515245);\n+    mul(state, state, temp);\n+    \/\/ add(state, state, 12345);\n+    add(state, state, 251);\n+  }\n+}\n+\n+void C1_MacroAssembler::save_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    str(r_profile_rng, Address(Rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n+void C1_MacroAssembler::restore_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    ldr(r_profile_rng, Address(Rthread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":57,"deletions":0,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -66,0 +66,9 @@\n+  \/\/ Randomized profile capture\n+  void step_random(Register state, Register temp, Register data = Rtemp);\n+  void save_profile_rng();\n+  void restore_profile_rng();\n+\n+  void increment_mdp_data_at(Address data,\n+                             Register bumped_count,\n+                             int increment);\n+\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -727,1 +727,0 @@\n-#ifdef __SOFTFP__\n@@ -730,0 +729,1 @@\n+#ifdef __SOFTFP__\n@@ -782,1 +782,3 @@\n-const char *Runtime1::pd_name_for_address(address entry) {\n+if (entry == StubRoutines::Arm::atomic_compareAndSet_long_entry()) {\n+    return \"StubRoutines::atomic_compareAndSet_long\";\n+  }\n@@ -784,1 +786,0 @@\n-}\n@@ -786,0 +787,1 @@\n+}\n","filename":"src\/hotspot\/cpu\/arm\/c1_Runtime1_arm.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,3 @@\n+\/\/ State for randomized profile counters. Used by C1.\n+constexpr Register r_profile_rng = R9;\n+\n","filename":"src\/hotspot\/cpu\/arm\/macroAssembler_arm.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -66,0 +66,3 @@\n+  do_stub(compiler, atomic_compareAndSet_long)                          \\\n+  do_arch_entry(Arm, compiler, atomic_compareAndSet_long,               \\\n+                atomic_compareAndSet_long_entry, atomic_compareAndSet_long_entry)\n","filename":"src\/hotspot\/cpu\/arm\/stubDeclarations_arm.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -623,0 +623,1 @@\n+\n@@ -639,0 +640,54 @@\n+  \/\/ Support for jboolean jdk.internal.misc.Unsafe::compareAndSetLong\n+  \/\/ (jobject o, jlong offset, jlong compare_value, jlong exchange_value)\n+  \/\/ reordered before by a wrapper to\n+  \/\/ (jlong compare_value, jlong exchange_value, volatile jlong *dest)\n+  \/\/\n+  \/\/ Arguments :\n+  \/\/\n+  \/\/      compare_value:  R1 (High), R0 (Low)\n+  \/\/      exchange_value: R3 (High), R2 (Low)\n+  \/\/      dest:           SP+0\n+  \/\/\n+  \/\/ Results:\n+  \/\/\n+  \/\/      R0:     true if successful, otherwise false if the memory value\n+  \/\/              was not the same as the compare value.\n+  \/\/\n+  \/\/ Overwrites:\n+  \/\/\n+  address generate_atomic_compareAndSet_long() {\n+    address start;\n+\n+    StubId stub_id = StubId::stubgen_atomic_compareAndSet_long_id;\n+    StubCodeMark mark(this, stub_id);\n+    start = __ pc();\n+    Register cmp_lo      = R0;\n+    Register cmp_hi      = R1;\n+    Register newval_lo   = R2;\n+    Register newval_hi   = R3;\n+    Register addr        = Rtemp;  \/* After load from stack *\/\n+    Register temp_lo     = R4;\n+    Register temp_hi     = R5;\n+    Register temp_result = R8;\n+    assert_different_registers(cmp_lo, newval_lo, temp_lo, addr, temp_result, R7);\n+    assert_different_registers(cmp_hi, newval_hi, temp_hi, addr, temp_result, R7);\n+\n+    __ membar(MEMBAR_ATOMIC_OP_PRE, Rtemp); \/\/ Rtemp free (native ABI)\n+\n+    __ push(RegisterSet(temp_result) | RegisterSet(temp_lo, temp_hi));\n+    __ ldr(addr, Address(SP, 12));\n+\n+    \/\/ atomic_cas64 returns previous value in temp_lo, temp_hi\n+    \/\/ status in temp_result\n+    __ atomic_cas64(temp_lo, temp_hi, temp_result, cmp_lo, cmp_hi,\n+                    newval_lo, newval_hi, addr, 0);\n+    __ mov(R0, temp_result);\n+\n+    __ pop(RegisterSet(temp_result) | RegisterSet(temp_lo, temp_hi));\n+\n+    __ membar(MEMBAR_ATOMIC_OP_POST, Rtemp); \/\/ Rtemp free (native ABI)\n+    __ bx(LR);\n+\n+    return start;\n+  }\n+\n@@ -3195,0 +3250,1 @@\n+    StubRoutines::Arm::_atomic_compareAndSet_long_entry = generate_atomic_compareAndSet_long();\n@@ -3198,1 +3254,1 @@\n-    StubRoutines::Arm::_partial_subtype_check                = generate_partial_subtype_check();\n+    StubRoutines::Arm::_partial_subtype_check           = generate_partial_subtype_check();\n","filename":"src\/hotspot\/cpu\/arm\/stubGenerator_arm.cpp","additions":57,"deletions":1,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -139,0 +139,3 @@\n+\/\/ State for randomized profile counters. Used by C1.\n+extern Register r_profile_rng;\n+\n@@ -463,0 +466,1 @@\n+  friend class CodeStub; \/\/ as_Address()\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -170,0 +170,6 @@\n+  \/\/ r_profile_rng is allocated conditionally. It is used to hold the random\n+  \/\/ generator for profile counters.\n+  r_profile_rng\n+    = (UseCompressedOops && ProfileCaptureRatio > 1) ? r14\n+    : (ProfileCaptureRatio > 1) ? r12\n+    : noreg;\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -130,2 +130,4 @@\n-    \/\/ Reduce the number of available regs (to free r12) in case of compressed oops\n-    if (UseCompressedOops) return range - 1;\n+    \/\/ Reduce the number of available regs (to free r12 or r14) in\n+    \/\/ case of compressed oops and randomized profile captures.\n+    if (UseCompressedOops && ProfileCaptureRatio > 1) return range - 2;\n+    if (UseCompressedOops || ProfileCaptureRatio > 1) return range - 1;\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -204,0 +204,4 @@\n+static Register as_reg(LIR_Opr op) {\n+  return op->is_double_cpu() ? op->as_register_lo() : op->as_register();\n+}\n+\n@@ -1271,1 +1275,1 @@\n-    __ addptr(data_addr, DataLayout::counter_increment);\n+    __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1283,1 +1287,1 @@\n-    __ movptr(Address(mdo, md->byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment);\n+    __ movptr(Address(mdo, md->byte_offset_of_slot(data, ReceiverTypeData::receiver_count_offset(i))), DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1333,0 +1337,5 @@\n+    int profile_capture_ratio = ProfileCaptureRatio;\n+    int ratio_shift = exact_log2(profile_capture_ratio);\n+    auto threshold = (1ull << 32) >> ratio_shift;\n+    assert(threshold > 0, \"must be\");\n+\n@@ -1344,0 +1353,11 @@\n+    ProfileStub *stub\n+      = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+    auto lambda = [stub, md, mdo, data, k_RInfo, obj, tmp_load_klass] (LIR_Assembler* ce, LIR_Op* base_op) {\n+\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n@@ -1345,0 +1365,1 @@\n+\n@@ -1347,1 +1368,1 @@\n-    type_profile_helper(mdo, md, data, recv, &update_done);\n+    ce->type_profile_helper(mdo, md, data, recv, &update_done);\n@@ -1350,1 +1371,1 @@\n-    __ addptr(nonprofiled_receiver_count_addr, DataLayout::counter_increment);\n+    __ addptr(nonprofiled_receiver_count_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n@@ -1353,0 +1374,19 @@\n+\n+    if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, rscratch1);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"Typecheck stub\");\n+    append_code_stub(stub);\n+  } else {\n+    lambda(this, op);\n+  }\n@@ -1451,1 +1491,0 @@\n-    __ testptr(value, value);\n@@ -1453,0 +1492,19 @@\n+      int profile_capture_ratio = ProfileCaptureRatio;\n+      int ratio_shift = exact_log2(profile_capture_ratio);\n+      auto threshold = (1ull << 32) >> ratio_shift;\n+      assert(threshold > 0, \"must be\");\n+\n+      ProfileStub *profile_stub\n+        = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+      auto lambda = [profile_stub, md, data, value,\n+                     k_RInfo, klass_RInfo, tmp_load_klass, success_target] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+      auto masm = ce->masm();\n+\n+      if (profile_stub != nullptr)  __ bind(*profile_stub->entry());\n+\n+      __ testptr(value, value);\n+\n@@ -1457,0 +1515,1 @@\n+\n@@ -1461,1 +1520,5 @@\n-      __ jmp(done);\n+      if (profile_stub != nullptr) {\n+        __ jmp(*profile_stub->continuation());\n+      } else {\n+        __ jmp(*success_target);\n+      }\n@@ -1467,1 +1530,1 @@\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n+      ce->type_profile_helper(mdo, md, data, recv, &update_done);\n@@ -1472,0 +1535,22 @@\n+\n+      if (profile_stub != nullptr)  __ jmp(*profile_stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+      };\n+\n+      if (profile_stub != nullptr) {\n+        __ cmpl(r_profile_rng, threshold);\n+        __ jcc(Assembler::below, *profile_stub->entry());\n+        __ bind(*profile_stub->continuation());\n+        __ step_random(r_profile_rng, rscratch1);\n+        __ testptr(value, value);\n+        __ jcc(Assembler::equal, done);\n+\n+        profile_stub->set_action(lambda, op);\n+        profile_stub->set_name(\"Typecheck profile stub\");\n+        append_code_stub(profile_stub);\n+      } else {\n+        lambda(this, op);\n+      }\n+\n@@ -1473,0 +1558,1 @@\n+      __ testptr(value, value);\n@@ -2158,0 +2244,2 @@\n+  \/\/ We do this here in order not to affect call site alignment.\n+  __ save_profile_rng();\n@@ -2181,0 +2269,2 @@\n+\n+  __ restore_profile_rng();\n@@ -2190,0 +2280,1 @@\n+  __ restore_profile_rng();\n@@ -2768,5 +2859,24 @@\n-void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {\n-  ciMethod* method = op->profiled_method();\n-  int bci          = op->profiled_bci();\n-  ciMethod* callee = op->profiled_callee();\n-  Register tmp_load_klass = rscratch1;\n+void LIR_Assembler::increment_profile_ctr(LIR_Opr step_opr, LIR_Opr dest_opr,\n+                                          LIR_Opr freq_opr,\n+                                          LIR_Opr md_reg, LIR_Opr md_opr, LIR_Opr md_offset_opr,\n+                                          CodeStub* overflow_stub) {\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"increment_profile_ctr\" \" {\");\n+  }\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (UCONST64(1) << 32) >> ratio_shift;\n+\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *counter_stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  Register temp = temp_op->is_register() ? temp_op->as_register() : noreg;\n+  Address dest_adr = as_Address(addr->as_address_ptr());\n+\n+  auto lambda = [counter_stub, overflow_stub, freq_op, ratio_shift, incr,\n+                 temp, dest, dest_adr] (LIR_Assembler* ce, LIR_Op* op) {\n@@ -2774,32 +2884,45 @@\n-  \/\/ Update counter for all call types\n-  ciMethodData* md = method->method_data_or_null();\n-  assert(md != nullptr, \"Sanity\");\n-  ciProfileData* data = md->bci_to_data(bci);\n-  assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n-  assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n-  Register mdo  = op->mdo()->as_register();\n-  __ mov_metadata(mdo, md->constant_encoding());\n-  Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n-  \/\/ Perform additional virtual call profiling for invokevirtual and\n-  \/\/ invokeinterface bytecodes\n-  if (op->should_profile_receiver_type()) {\n-    assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n-    Register recv = op->recv()->as_register();\n-    assert_different_registers(mdo, recv);\n-    assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n-    ciKlass* known_klass = op->known_holder();\n-    if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n-      \/\/ We know the type that will be seen at this call site; we can\n-      \/\/ statically update the MethodData* rather than needing to do\n-      \/\/ dynamic tests on the receiver type\n-\n-      \/\/ NOTE: we should probably put a lock around this search to\n-      \/\/ avoid collisions by concurrent compilations\n-      ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n-      uint i;\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (known_klass->equals(receiver)) {\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+\n+    if (counter_stub != nullptr)  __ bind(*counter_stub->entry());\n+\n+    if (incr->is_register()) {\n+      Register inc = incr->as_register();\n+      __ movl(temp, dest_adr);\n+      if (md_opr->type() == T_METADATA) {\n+        __ mov_metadata(md_reg->as_register(),\n+                          md_opr->as_constant_ptr()->as_metadata());\n+      } else {\n+        __ lea(md_reg->as_pointer_register(),\n+                  ExternalAddress(md_opr->as_constant_ptr()->as_pointer()));\n+      }\n+      RegisterOrConstant offset =\n+        md_offset_opr->is_constant()\n+        ? RegisterOrConstant(md_offset_opr->as_constant_ptr()->as_jint())\n+        : as_reg(md_offset_opr);\n+      counter_address = Address(md_reg->as_pointer_register(), offset);\n+    }\n+\n+    if (step_opr->is_register()) {\n+      Register inc = step_opr->as_register();\n+      __ movl(dest, counter_address);\n+      if (ProfileCaptureRatio > 1) {\n+        __ shll(inc, ratio_shift);\n+      }\n+      __ lea(dest, Address(dest, inc, Address::times_1));\n+      __ movl(counter_address, dest);\n+      if (ProfileCaptureRatio > 1) {\n+        __ shrl(inc, ratio_shift);\n+      }\n+    } else {\n+      jint inc = step_opr->as_constant_ptr()->as_jint_bits();\n+      switch (dest_opr->type()) {\n+        case T_INT: {\n+          inc *= ProfileCaptureRatio;\n+          __ movl(dest, counter_address);\n+          \/\/ Use lea instead of add to avoid destroying condition codes on x86\n+          __ lea(dest, Address(dest, inc, Address::times_1));\n+          __ movl(counter_address, dest);\n+          break;\n@@ -2807,0 +2930,10 @@\n+        case T_LONG: {\n+          inc *= ProfileCaptureRatio;\n+          __ movq(dest, counter_address);\n+          \/\/ Use lea instead of add to avoid destroying condition codes on x86\n+          __ lea(dest, Address(dest, inc, Address::times_1));\n+          __ movq(counter_address, dest);\n+          break;\n+        }\n+        default:\n+          ShouldNotReachHere();\n@@ -2809,13 +2942,19 @@\n-      \/\/ Receiver type not found in profile data; select an empty slot\n-\n-      \/\/ Note that this is less efficient than it should be because it\n-      \/\/ always does a write to the receiver part of the\n-      \/\/ VirtualCallData rather than just the first time\n-      for (i = 0; i < VirtualCallData::row_limit(); i++) {\n-        ciKlass* receiver = vc_data->receiver(i);\n-        if (receiver == nullptr) {\n-          Address recv_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));\n-          __ mov_metadata(recv_addr, known_klass->constant_encoding(), rscratch1);\n-          Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n-          __ addptr(data_addr, DataLayout::counter_increment);\n-          return;\n+      if (step_opr->is_valid() && overflow_stub) {\n+        if (!freq_opr->is_valid()) {\n+          if (!step_opr->is_constant()) {\n+            __ cmpl(step_opr->as_register(), 0);\n+            __ jcc(Assembler::equal, *overflow_stub->entry());\n+          } else {\n+            __ jmp(*overflow_stub->entry());\n+            goto exit;\n+          }\n+        } else {\n+          if (!step_opr->is_constant()) {\n+            guarantee(dest != step_opr->as_register(), \"must be\");\n+            \/\/ If step_opr is 0, make sure the stub check below always fails\n+            __ cmpl(step_opr->as_register(), 0);\n+            __ movl(step_opr->as_register(), InvocationCounter::count_increment * ProfileCaptureRatio);\n+            __ cmovl(Assembler::notEqual, dest, step_opr->as_register());\n+          }\n+          __ andl(dest, freq_opr->as_jint());\n+          __ jcc(Assembler::equal, *overflow_stub->entry());\n@@ -2824,7 +2963,1 @@\n-    } else {\n-      __ load_klass(recv, recv, tmp_load_klass);\n-      Label update_done;\n-      type_profile_helper(mdo, md, data, recv, &update_done);\n-      \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n-      \/\/ Increment total counter to indicate polymorphic case.\n-      __ addptr(counter_addr, DataLayout::counter_increment);\n+    }\n@@ -2832,1 +2965,2 @@\n-      __ bind(update_done);\n+    if (counter_stub != nullptr) {\n+      __ jmp(*counter_stub->continuation());\n@@ -2834,0 +2968,16 @@\n+\n+  exit: { }\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (counter_stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *counter_stub->entry());\n+    __ bind(*counter_stub->continuation());\n+    __ step_random(r_profile_rng, dest);\n+\n+    counter_stub->set_action(lambda, nullptr);\n+    counter_stub->set_name(\"IncrementProfileCtr\");\n+    append_code_stub(counter_stub);\n@@ -2835,2 +2985,5 @@\n-    \/\/ Static call\n-    __ addptr(counter_addr, DataLayout::counter_increment);\n+    lambda(this, nullptr);\n+  }\n+\n+  if (overflow_stub != nullptr) {\n+    __ bind(*overflow_stub->continuation());\n@@ -2838,0 +2991,130 @@\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} increment_profile_ctr\");\n+  }\n+#endif\n+}\n+\n+void LIR_Assembler::emit_profile_call(LIR_OpProfileCall* op) {\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"profile_call {\");\n+  }\n+#endif\n+  Register temp = op->tmp1()->as_register_lo();\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [stub] (LIR_Assembler* ce, LIR_Op* base_op) {\n+#undef __\n+#define __ masm->\n+\n+    auto masm = ce->masm();\n+    LIR_OpProfileCall* op = base_op->as_OpProfileCall();\n+    ciMethod* method = op->profiled_method();\n+    int bci          = op->profiled_bci();\n+    ciMethod* callee = op->profiled_callee();\n+    Register tmp_load_klass = rscratch1;\n+\n+    Register temp = op->tmp1()->as_register_lo();\n+\n+    if (stub != nullptr)  __ bind(*stub->entry());\n+\n+    \/\/ Update counter for all call types\n+    ciMethodData* md = method->method_data_or_null();\n+    assert(md != nullptr, \"Sanity\");\n+    ciProfileData* data = md->bci_to_data(bci);\n+    assert(data != nullptr && data->is_CounterData(), \"need CounterData for calls\");\n+    assert(op->mdo()->is_single_cpu(),  \"mdo must be allocated\");\n+    Register mdo  = op->mdo()->as_register();\n+    __ mov_metadata(mdo, md->constant_encoding());\n+    Address counter_addr(mdo, md->byte_offset_of_slot(data, CounterData::count_offset()));\n+    \/\/ Perform additional virtual call profiling for invokevirtual and\n+    \/\/ invokeinterface bytecodes\n+    if (op->should_profile_receiver_type()) {\n+      assert(op->recv()->is_single_cpu(), \"recv must be allocated\");\n+      Register recv = op->recv()->as_register();\n+      assert_different_registers(mdo, recv);\n+      assert(data->is_VirtualCallData(), \"need VirtualCallData for virtual calls\");\n+      ciKlass* known_klass = op->known_holder();\n+      if (C1OptimizeVirtualCallProfiling && known_klass != nullptr) {\n+        \/\/ We know the type that will be seen at this call site; we can\n+        \/\/ statically update the MethodData* rather than needing to do\n+        \/\/ dynamic tests on the receiver type\n+\n+        \/\/ NOTE: we should probably put a lock around this search to\n+        \/\/ avoid collisions by concurrent compilations\n+        ciVirtualCallData* vc_data = (ciVirtualCallData*) data;\n+        uint i;\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (known_klass->equals(receiver)) {\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment);\n+            goto exit;\n+          }\n+        }\n+\n+        \/\/ Receiver type not found in profile data; select an empty slot\n+\n+        \/\/ Note that this is less efficient than it should be because it\n+        \/\/ always does a write to the receiver part of the\n+        \/\/ VirtualCallData rather than just the first time\n+        for (i = 0; i < VirtualCallData::row_limit(); i++) {\n+          ciKlass* receiver = vc_data->receiver(i);\n+          if (receiver == nullptr) {\n+            Address recv_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_offset(i)));\n+            __ mov_metadata(recv_addr, known_klass->constant_encoding(), rscratch1);\n+            Address data_addr(mdo, md->byte_offset_of_slot(data, VirtualCallData::receiver_count_offset(i)));\n+            __ addptr(data_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+            goto exit;\n+          }\n+        }\n+      } else {\n+        __ load_klass(recv, recv, tmp_load_klass);\n+        Label update_done;\n+        ce->type_profile_helper(mdo, md, data, recv, &update_done);\n+        \/\/ Receiver did not match any saved receiver and there is no empty row for it.\n+        \/\/ Increment total counter to indicate polymorphic case.\n+        __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+\n+        __ bind(update_done);\n+      }\n+    exit: {}\n+    } else {\n+      \/\/ Static call\n+      __ addptr(counter_addr, DataLayout::counter_increment * ProfileCaptureRatio);\n+    }\n+\n+    if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, temp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileCallStub\");\n+    append_code_stub(stub);\n+  } else {\n+    lambda(this, op);\n+  }\n+\n+#ifndef PRODUCT\n+  if (CommentedAssembly) {\n+    __ block_comment(\"} profile_call\");\n+  }\n+#endif\n@@ -2850,0 +3133,20 @@\n+  __ verify_oop(obj);\n+\n+#ifdef ASSERT\n+  assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n+#endif\n+\n+  int profile_capture_ratio = ProfileCaptureRatio;\n+  int ratio_shift = exact_log2(profile_capture_ratio);\n+  auto threshold = (1ull << 32) >> ratio_shift;\n+  assert(threshold > 0, \"must be\");\n+\n+  ProfileStub *stub\n+    = profile_capture_ratio > 1 ? new ProfileStub() : nullptr;\n+\n+  auto lambda = [stub, mdo_addr, not_null, exact_klass, current_klass,\n+                 obj, tmp, tmp_load_klass, no_conflict] (LIR_Assembler* ce, LIR_Op*) {\n+#undef __\n+#define __ masm->\n+\n+  auto masm = ce->masm();\n@@ -2859,0 +3162,1 @@\n+  if (stub != nullptr)  __ bind(*stub->entry());\n@@ -2862,5 +3166,1 @@\n-  if (obj == tmp) {\n-    assert_different_registers(obj, rscratch1, mdo_addr.base(), mdo_addr.index());\n-  } else {\n-    assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n-  }\n+  assert_different_registers(obj, tmp, rscratch1, mdo_addr.base(), mdo_addr.index());\n@@ -3006,1 +3306,2 @@\n-  }\n+  } \/\/ do_update\n+\n@@ -3008,0 +3309,18 @@\n+  if (stub != nullptr)  __ jmp(*stub->continuation());\n+\n+#undef __\n+#define __ _masm->\n+  };\n+\n+  if (stub != nullptr) {\n+    __ cmpl(r_profile_rng, threshold);\n+    __ jcc(Assembler::below, *stub->entry());\n+    __ bind(*stub->continuation());\n+    __ step_random(r_profile_rng, tmp);\n+\n+    stub->set_action(lambda, op);\n+    stub->set_name(\"ProfileTypeStub\");\n+    append_code_stub(stub);\n+  } else {\n+    lambda(this, op);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":392,"deletions":73,"binary":false,"changes":465,"status":"modified"},{"patch":"@@ -1379,0 +1379,4 @@\n+  \/\/ If we're subsampling counter updates, then profiling code kills flags\n+  if (ProfileCaptureRatio != 1) {\n+    __ cmp(lir_cond(cond), left, right);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+Register r_profile_rng;\n+\n@@ -240,0 +242,2 @@\n+  restore_profile_rng();\n+\n@@ -247,0 +251,1 @@\n+  save_profile_rng();\n@@ -267,0 +272,43 @@\n+\/\/ Randomized profile capture.\n+\n+void C1_MacroAssembler::step_random(Register state, Register temp) {\n+  \/\/ One of these will be the best for a particular CPU.\n+\n+  \/* Algorithm \"xor\" from p. 4 of Marsaglia, \"Xorshift RNGs\" *\/\n+  \/\/ movl(temp, state);\n+  \/\/ sall(temp, 13);\n+  \/\/ xorl(state, temp);\n+  \/\/ movl(temp, state);\n+  \/\/ shrl(temp, 7);\n+  \/\/ xorl(state, temp);\n+  \/\/ movl(temp, state);\n+  \/\/ sall(temp, 5);\n+  \/\/ xorl(state, temp);\n+\n+  if (VM_Version::supports_sse4_2()) {\n+    \/* CRC used as a psuedo-random-number generator *\/\n+    \/\/ In effect, the CRC instruction is being used here for its\n+    \/\/ linear feedback shift register. It's unbeatably fast, and\n+    \/\/ plenty good enough for what we need.\n+    movl(temp, 0);\n+    crc32(state, temp, \/*sizeInBytes*\/2);\n+  } else {\n+    \/* LCG from glibc. *\/\n+    movl(temp, 1103515245);\n+    imull(state, temp);\n+    addl(state, 12345);\n+  }\n+}\n+\n+void C1_MacroAssembler::save_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    movl(Address(r15_thread, JavaThread::profile_rng_offset()), r_profile_rng);\n+  }\n+}\n+\n+void C1_MacroAssembler::restore_profile_rng() {\n+  if (ProfileCaptureRatio != 1) {\n+    movl(r_profile_rng, Address(r15_thread, JavaThread::profile_rng_offset()));\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -131,0 +131,5 @@\n+  \/\/ Randomized profile capture\n+  void step_random(Register state, Register temp);\n+  void save_profile_rng();\n+  void restore_profile_rng();\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -64,0 +64,2 @@\n+  Address as_Address(LIR_Assembler* ce, LIR_Address* addr, Register tmp);\n+  Address as_Address(LIR_Assembler* ce, LIR_Address* addr);\n@@ -130,0 +132,68 @@\n+\n+class AbstractLambdaWrapper : public CompilationResourceObj {\n+public:\n+  virtual void operator() (LIR_Assembler* ce) = 0;\n+};\n+\n+template<typename T>\n+struct LambdaWrapper : public AbstractLambdaWrapper {\n+  T _lambda;\n+  LIR_Op* _op;\n+\n+  LambdaWrapper(T lambda, LIR_Op* op) : _lambda(lambda), _op(op) { }\n+  virtual void operator() (LIR_Assembler* ce) {\n+    _lambda(ce, _op);\n+  }\n+};\n+\n+class ProfileStub: public CodeStub {\n+private:\n+  AbstractLambdaWrapper *_action;\n+  const char* _name;\n+\n+public:\n+  ProfileStub() {\n+    _name = \"ProfileStub\";\n+  }\n+  template<typename U>\n+  void set_action(U action, LIR_Op *op) { _action = new LambdaWrapper(action, op); }\n+  void set_name(const char* name) { _name = name; }\n+  virtual void emit_code(LIR_Assembler* ce) {\n+    (*_action)(ce);\n+  }\n+#ifndef PRODUCT\n+  virtual void print_name(outputStream* out) const { out->print(\"%s\", _name); }\n+#endif \/\/ PRODUCT\n+  virtual void visit(LIR_OpVisitState* visitor) { }\n+};\n+\n+\n+class ConversionStub: public CodeStub {\n+ private:\n+  Bytecodes::Code _bytecode;\n+  LIR_Opr         _input;\n+  LIR_Opr         _result;\n+\n+  static float float_zero;\n+  static double double_zero;\n+ public:\n+  ConversionStub(Bytecodes::Code bytecode, LIR_Opr input, LIR_Opr result)\n+    : _bytecode(bytecode), _input(input), _result(result) {\n+  }\n+\n+  Bytecodes::Code bytecode() { return _bytecode; }\n+  LIR_Opr         input()    { return _input; }\n+  LIR_Opr         result()   { return _result; }\n+\n+  virtual void emit_code(LIR_Assembler* e);\n+  virtual void visit(LIR_OpVisitState* visitor) {\n+    visitor->do_slow_case();\n+    visitor->do_input(_input);\n+    visitor->do_output(_result);\n+  }\n+#ifndef PRODUCT\n+  virtual void print_name(outputStream* out) const { out->print(\"ConversionStub\"); }\n+#endif \/\/ PRODUCT\n+};\n+\n+\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":70,"deletions":0,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -297,1 +297,1 @@\n-  \/\/ generate code or slow cases\n+  \/\/ generate code for slow cases\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -892,1 +892,1 @@\n-      do_input(opProfileType->_obj);\n+      do_input(opProfileType->_obj); do_temp(opProfileType->_obj);\n@@ -896,1 +896,21 @@\n-  default:\n+\n+    case lir_increment_counter:\n+    {\n+      LIR_OpIncrementCounter* opr = op->as_OpIncrementCounter();\n+      assert(opr != nullptr, \"must be\");\n+\n+      if (opr->_info)                      do_info(opr->_info);\n+      do_input(opr->_step);                do_temp(opr->_step);\n+      if (opr->_result->is_valid()) {\n+        do_temp(opr->_result);             do_output(opr->_result);\n+      }\n+      if (opr->overflow_stub() != nullptr) do_stub(opr->overflow_stub());\n+      if (opr->_md_reg->is_valid())        do_temp(opr->_md_reg);\n+      if (opr->_md_op->is_valid())         { do_input(opr->_md_op); }\n+      if (opr->_md_offset_op->is_valid()) {\n+        do_input(opr->_md_offset_op);      do_temp(opr->_md_offset_op);\n+      }\n+      break;\n+    }\n+\n+    default:\n@@ -1058,0 +1078,9 @@\n+void LIR_OpIncrementCounter::emit_code(LIR_Assembler* masm) {\n+  masm->increment_profile_ctr\n+    (_step, _result, _freq_op,\n+     _md_reg, _md_op, _md_offset_op, _overflow_stub);\n+  if (overflow_stub()) {\n+    masm->append_code_stub(overflow_stub());\n+  }\n+}\n+\n@@ -1263,0 +1292,16 @@\n+void LIR_List::increment_counter(LIR_Opr step, LIR_Opr dest,\n+                                 LIR_Opr freq,\n+                                 LIR_Opr md_reg, LIR_Opr md_op, LIR_Opr md_offset_op,\n+                                 CodeStub* overflow, CodeEmitInfo* info) {\n+    append(new LIR_OpIncrementCounter (\n+            step,\n+            dest,\n+            freq,\n+            md_reg,\n+            md_op,\n+            md_offset_op,\n+            overflow,\n+            info));\n+}\n+\n+\n@@ -1754,0 +1799,1 @@\n+     case lir_increment_counter:     s = \"increment_counter\"; break;\n@@ -1805,1 +1851,1 @@\n-\n+  result_opr()->print(out); out->print(\" \");\n@@ -1846,0 +1892,9 @@\n+  int n = _arguments->length();\n+  for (int i = 0; i < n; i++) {\n+    _arguments->at(i)->print(out);\n+    out->print(\" \");\n+  }\n+  if (_result->is_valid()) {\n+    _result->print(out);\n+    out->print(\" \");\n+  }\n@@ -2049,0 +2104,10 @@\n+void LIR_OpIncrementCounter::print_instr(outputStream* out) const {\n+  step()->print(out);          out->print(\" \");\n+  dest()->print(out);          out->print(\" \");\n+  \/\/ temp_op()->print(out);       out->print(\" \");\n+  freq_op()->print(out);       out->print(\" \");\n+  md_reg()->print(out);        out->print(\" \");\n+  md_op()->print(out);         out->print(\" \");\n+  md_offset_op()->print(out);  out->print(\" \");\n+}\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":68,"deletions":3,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -449,1 +449,1 @@\n-  Register as_pointer_register() {\n+  Register as_pointer_register() const {\n@@ -896,0 +896,1 @@\n+class    LIR_OpIncrementCounter;\n@@ -1000,0 +1001,1 @@\n+    , lir_increment_counter\n@@ -1142,0 +1144,1 @@\n+  virtual LIR_OpIncrementCounter* as_OpIncrementCounter() { return nullptr; }\n@@ -1933,0 +1936,39 @@\n+\/\/ LIR_OpIncrementCounter\n+class LIR_OpIncrementCounter : public LIR_Op {\n+ friend class LIR_OpVisitState;\n+\n+ private:\n+  LIR_Opr _step;\n+  LIR_Opr _freq_op;\n+  LIR_Opr _md_reg;\n+  LIR_Opr _md_op;\n+  LIR_Opr _md_offset_op;\n+  CodeStub* _overflow_stub;\n+\n+ public:\n+  \/\/ Destroys recv\n+  LIR_OpIncrementCounter(LIR_Opr step, LIR_Opr dest,\n+                         LIR_Opr freq_op, LIR_Opr md_reg, LIR_Opr md_op, LIR_Opr md_offset_op,\n+                         CodeStub* overflow_stub, CodeEmitInfo *info)\n+    : LIR_Op(lir_increment_counter, dest, info)\n+    , _step(step)\n+    , _freq_op(freq_op)\n+    , _md_reg(md_reg)\n+    , _md_op(md_op)\n+    , _md_offset_op(md_offset_op)\n+    , _overflow_stub(overflow_stub) { }\n+\n+  LIR_Opr   step()          const            { return _step;          }\n+  LIR_Opr   dest()          const            { return result_opr();   }\n+  LIR_Opr   freq_op()       const            { return _freq_op;       }\n+  LIR_Opr   md_reg()        const            { return _md_reg;        }\n+  LIR_Opr   md_op()         const            { return _md_op;         }\n+  LIR_Opr   md_offset_op()  const            { return _md_offset_op;  }\n+\n+  CodeStub* overflow_stub() const            { return _overflow_stub; };\n+\n+  virtual void emit_code(LIR_Assembler* masm);\n+  virtual LIR_OpIncrementCounter* as_OpIncrementCounter() { return this; }\n+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;\n+};\n+\n@@ -2235,0 +2277,26 @@\n+  void increment_counter(LIR_Opr src, LIR_Opr res,\n+                         LIR_Opr freq, LIR_Opr md_reg, LIR_Opr md_op, LIR_Opr md_offset,\n+                         CodeStub* overflow, CodeEmitInfo* info);\n+\n+  void increment_counter(LIR_Opr step, LIR_Opr dummy,\n+                         LIR_Opr md_reg, Metadata* md, LIR_Opr offset) {\n+    increment_counter(step, dummy,\n+                      \/*freq*\/LIR_OprFact::illegalOpr,\n+                      md_reg, LIR_OprFact::metadataConst(md),\n+                      offset,\n+                      \/*overflow*\/nullptr, \/*info*\/nullptr);\n+  }\n+  void increment_counter(LIR_Opr step, LIR_Opr dummy,\n+                         LIR_Opr md_reg, Metadata* md, int offset) {\n+    increment_counter(step, dummy, md_reg, md,\n+                      LIR_OprFact::intConst(offset));\n+  }\n+  void increment_counter(LIR_Opr step, LIR_Opr result, LIR_Opr freq,\n+                         LIR_Opr md_reg, LIR_Opr md, int offset,\n+                         CodeStub* overflow, CodeEmitInfo* info) {\n+    increment_counter(step, result,\n+                      freq,\n+                      md_reg, md, LIR_OprFact::intConst(offset),\n+                      overflow, info);\n+  }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":69,"deletions":1,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -238,0 +238,5 @@\n+  void increment_profile_ctr(LIR_Opr incr, LIR_Opr dest,\n+                             LIR_Opr freq_op,\n+                             LIR_Opr md_reg, LIR_Opr md_op, LIR_Opr md_offset_op,\n+                             CodeStub *overflow);\n+\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -919,1 +919,0 @@\n-    __ metadata2reg(md->constant_encoding(), md_reg);\n@@ -929,6 +928,4 @@\n-    LIR_Address* data_addr = new LIR_Address(md_reg, data_offset_reg, data_reg->type());\n-    __ move(data_addr, data_reg);\n-    \/\/ Use leal instead of add to avoid destroying condition codes on x86\n-    LIR_Address* fake_incr_value = new LIR_Address(data_reg, DataLayout::counter_increment, T_INT);\n-    __ leal(LIR_OprFact::address(fake_incr_value), data_reg);\n-    __ move(data_reg, data_addr);\n+    LIR_Opr tmp = new_register(T_INT);\n+    LIR_Opr step = LIR_OprFact::intConst(DataLayout::counter_increment);\n+    LIR_Opr dummy = LIR_OprFact::intConst(0);\n+    __ increment_counter(step, tmp, md_reg, md->constant_encoding(), data_offset_reg);\n@@ -2374,4 +2371,4 @@\n-    __ metadata2reg(md->constant_encoding(), md_reg);\n-\n-    increment_counter(new LIR_Address(md_reg, offset,\n-                                      NOT_LP64(T_INT) LP64_ONLY(T_LONG)), DataLayout::counter_increment);\n+    LIR_Opr tmp = new_register(T_INT);\n+    LIR_Opr dummy = LIR_OprFact::intptrConst((intptr_t)0);\n+    LIR_Opr inc = LIR_OprFact::intConst(DataLayout::counter_increment);\n+    __ increment_counter(inc, tmp, md_reg, md->constant_encoding(), offset);\n@@ -3154,0 +3151,1 @@\n+  LIR_Opr counters_base;\n@@ -3161,1 +3159,0 @@\n-    __ move(LIR_OprFact::intptrConst(counters_adr), counter_holder);\n@@ -3164,0 +3161,1 @@\n+    counters_base = LIR_OprFact::intptrConst(counters_adr);\n@@ -3168,3 +3166,3 @@\n-    ciMethodData* md = method->method_data_or_null();\n-    assert(md != nullptr, \"Sanity\");\n-    __ metadata2reg(md->constant_encoding(), counter_holder);\n+    counters_base = LIR_OprFact::metadataConst\n+                     (method ->method_data_or_null()\n+                      ->constant_encoding());\n@@ -3174,5 +3172,3 @@\n-  LIR_Address* counter = new LIR_Address(counter_holder, offset, T_INT);\n-  LIR_Opr result = new_register(T_INT);\n-  __ load(counter, result);\n-  __ add(result, step, result);\n-  __ store(result, counter);\n+  LIR_Opr result = notify ? new_register(T_INT) : LIR_OprFact::intConst(0);\n+  LIR_Opr tmp = new_register(T_INT);\n+\n@@ -3180,0 +3176,1 @@\n+    int ratio_shift = exact_log2(ProfileCaptureRatio);\n@@ -3182,21 +3179,15 @@\n-    CodeStub* overflow = new CounterOverflowStub(info, bci, meth);\n-    int freq = frequency << InvocationCounter::count_shift;\n-    if (freq == 0) {\n-      if (!step->is_constant()) {\n-        __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));\n-        __ branch(lir_cond_notEqual, overflow);\n-      } else {\n-        __ branch(lir_cond_always, overflow);\n-      }\n-    } else {\n-      LIR_Opr mask = load_immediate(freq, T_INT);\n-      if (!step->is_constant()) {\n-        \/\/ If step is 0, make sure the overflow check below always fails\n-        __ cmp(lir_cond_notEqual, step, LIR_OprFact::intConst(0));\n-        __ cmove(lir_cond_notEqual, result, LIR_OprFact::intConst(InvocationCounter::count_increment), result, T_INT);\n-      }\n-      __ logical_and(result, mask, result);\n-      __ cmp(lir_cond_equal, result, LIR_OprFact::intConst(0));\n-      __ branch(lir_cond_equal, overflow);\n-    }\n-    __ branch_destination(overflow->continuation());\n+    CodeStub* overflow = new CounterOverflowStub (info, bci, meth);\n+    \/\/ Zero the low-order bits of the frequency, otherwise we'll miss\n+    \/\/ overflows when usind randomized profile counters.\n+    unsigned int freq = (unsigned int)frequency\n+                         >> ratio_shift << ratio_shift\n+                         << InvocationCounter::count_shift;\n+    __ increment_counter(step, result,\n+                         LIR_OprFact::intConst(freq),\n+                         counter_holder, counters_base, offset,\n+                         overflow, info);\n+  } else {\n+    __ increment_counter(step, result,\n+                         \/*freq*\/LIR_OprFact::illegalOpr,\n+                         counter_holder, counters_base, offset,\n+                         \/*overflow*\/nullptr, info);\n@@ -3352,1 +3343,0 @@\n-\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":32,"deletions":42,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -282,0 +282,2 @@\n+  LIR_Opr call_runtime(LIR_Opr arg1, LIR_Opr arg2, LIR_Opr arg3, LIR_Opr result,\n+                       address entry, ValueType* result_type, CodeEmitInfo* info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -391,0 +391,6 @@\n+  product(int, ProfileCaptureRatio, 1, EXPERIMENTAL,                        \\\n+          \"Reduce and randomize tiered-compilation profile captures \"       \\\n+          \"in order to reduce cache contention on shared method data. \"     \\\n+          \"Must be a power of 2.\")                                          \\\n+          range(1, 65536)\n+\n","filename":"src\/hotspot\/share\/compiler\/compiler_globals.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -525,1 +525,3 @@\n-  _om_cache(this) {\n+  _om_cache(this),\n+\n+  _profile_rng(-1) {\n@@ -542,0 +544,10 @@\n+  \/\/ Initial state of random-number generator used when profiling\n+  \/\/ C1-generated code.\n+  if (ProfileCaptureRatio > 1) {\n+    int state;\n+    do {\n+      state = os::random();\n+    } while (state == 0);\n+    _profile_rng = state;\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -933,0 +933,1 @@\n+  static ByteSize profile_rng_offset()        { return byte_offset_of(JavaThread, _profile_rng); }\n@@ -1294,0 +1295,3 @@\n+  \/\/ Random value for randomized profile counters.\n+  uint32_t _profile_rng;\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+#undef arm\n@@ -166,1 +167,1 @@\n-      (*event_callback)(event_stream, \"insn\", (void*) insn[j].address);\n+      (*event_callback)(event_stream, \"insn\", (void*)(uintptr_t) insn[j].address);\n@@ -168,1 +169,1 @@\n-      (*event_callback)(event_stream, \"\/insn\", (void*) (insn[j].address + insn[j].size));\n+      (*event_callback)(event_stream, \"\/insn\", (void*)(uintptr_t) (insn[j].address + insn[j].size));\n","filename":"src\/utils\/hsdis\/capstone\/hsdis-capstone.c","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}