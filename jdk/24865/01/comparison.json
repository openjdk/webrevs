{"files":[{"patch":"@@ -418,1 +418,1 @@\n-instruct vadd_immI(vReg dst, vReg src1, immI5 con) %{\n+instruct vaddI_vi(vReg dst, vReg src1, immI5 con) %{\n@@ -422,1 +422,1 @@\n-  format %{ \"vadd_immI $dst, $src1, $con\" %}\n+  format %{ \"vaddI_vi $dst, $src1, $con\" %}\n@@ -433,1 +433,1 @@\n-instruct vadd_immL(vReg dst, vReg src1, immL5 con) %{\n+instruct vaddL_vi(vReg dst, vReg src1, immL5 con) %{\n@@ -435,1 +435,1 @@\n-  format %{ \"vadd_immL $dst, $src1, $con\" %}\n+  format %{ \"vaddL_vi $dst, $src1, $con\" %}\n@@ -447,1 +447,1 @@\n-instruct vadd_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vaddI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -451,1 +451,1 @@\n-  format %{ \"vadd_regI $dst, $src1, $src2\" %}\n+  format %{ \"vaddI_vx $dst, $src1, $src2\" %}\n@@ -462,1 +462,1 @@\n-instruct vadd_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vaddL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -464,1 +464,1 @@\n-  format %{ \"vadd_regL $dst, $src1, $src2\" %}\n+  format %{ \"vaddL_vx $dst, $src1, $src2\" %}\n@@ -476,1 +476,1 @@\n-instruct vadd_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vaddI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -480,1 +480,1 @@\n-  format %{ \"vadd_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vaddI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -491,1 +491,1 @@\n-instruct vadd_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vaddL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -493,1 +493,1 @@\n-  format %{ \"vadd_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vaddL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -505,1 +505,1 @@\n-instruct vadd_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vaddI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -509,1 +509,1 @@\n-  format %{ \"vadd_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vaddI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -520,1 +520,1 @@\n-instruct vadd_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vaddL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -522,1 +522,1 @@\n-  format %{ \"vadd_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vaddL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -598,1 +598,1 @@\n-instruct vsub_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vsubI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -602,1 +602,1 @@\n-  format %{ \"vsub_regI $dst, $src1, $src2\" %}\n+  format %{ \"vsubI_vx $dst, $src1, $src2\" %}\n@@ -613,1 +613,1 @@\n-instruct vsub_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vsubL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -615,1 +615,1 @@\n-  format %{ \"vsub_regL $dst, $src1, $src2\" %}\n+  format %{ \"vsubL_vx $dst, $src1, $src2\" %}\n@@ -627,1 +627,1 @@\n-instruct vsub_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vsubI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -631,1 +631,1 @@\n-  format %{ \"vsub_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vsubI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -642,1 +642,1 @@\n-instruct vsub_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vsubL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -644,1 +644,1 @@\n-  format %{ \"vsub_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vsub_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -688,1 +688,1 @@\n-instruct vand_immI(vReg dst_src, immI5 con) %{\n+instruct vandI_vi(vReg dst_src, immI5 con) %{\n@@ -693,1 +693,1 @@\n-  format %{ \"vand_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandI_vi $dst_src, $dst_src, $con\" %}\n@@ -704,1 +704,1 @@\n-instruct vand_immL(vReg dst_src, immL5 con) %{\n+instruct vandL_vi(vReg dst_src, immL5 con) %{\n@@ -707,1 +707,1 @@\n-  format %{ \"vand_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandL_vi $dst_src, $dst_src, $con\" %}\n@@ -719,1 +719,1 @@\n-instruct vand_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vandI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -724,1 +724,1 @@\n-  format %{ \"vand_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandI_vx $dst_src, $dst_src, $src\" %}\n@@ -735,1 +735,1 @@\n-instruct vand_regL(vReg dst_src, iRegL src) %{\n+instruct vandL_vx(vReg dst_src, iRegL src) %{\n@@ -738,1 +738,1 @@\n-  format %{ \"vand_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandL_vx $dst_src, $dst_src, $src\" %}\n@@ -750,1 +750,1 @@\n-instruct vand_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vandI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -755,1 +755,1 @@\n-  format %{ \"vand_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -766,1 +766,1 @@\n-instruct vand_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vandL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -769,1 +769,1 @@\n-  format %{ \"vand_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -781,1 +781,1 @@\n-instruct vand_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vandI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -786,1 +786,1 @@\n-  format %{ \"vand_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -797,1 +797,1 @@\n-instruct vand_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vandL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -800,1 +800,1 @@\n-  format %{ \"vand_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -844,1 +844,1 @@\n-instruct vor_immI(vReg dst_src, immI5 con) %{\n+instruct vorI_vi(vReg dst_src, immI5 con) %{\n@@ -849,1 +849,1 @@\n-  format %{ \"vor_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorI_vi $dst_src, $dst_src, $con\" %}\n@@ -860,1 +860,1 @@\n-instruct vor_immL(vReg dst_src, immL5 con) %{\n+instruct vorL_vi(vReg dst_src, immL5 con) %{\n@@ -863,1 +863,1 @@\n-  format %{ \"vor_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorL_vi $dst_src, $dst_src, $con\" %}\n@@ -875,1 +875,1 @@\n-instruct vor_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vorI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -880,1 +880,1 @@\n-  format %{ \"vor_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorI_vx $dst_src, $dst_src, $src\" %}\n@@ -891,1 +891,1 @@\n-instruct vor_regL(vReg dst_src, iRegL src) %{\n+instruct vorL_vx(vReg dst_src, iRegL src) %{\n@@ -894,1 +894,1 @@\n-  format %{ \"vor_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorL_vx $dst_src, $dst_src, $src\" %}\n@@ -906,1 +906,1 @@\n-instruct vor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -911,1 +911,1 @@\n-  format %{ \"vor_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -922,1 +922,1 @@\n-instruct vor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -925,1 +925,1 @@\n-  format %{ \"vor_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -937,1 +937,1 @@\n-instruct vor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -942,1 +942,1 @@\n-  format %{ \"vor_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -953,1 +953,1 @@\n-instruct vor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -956,1 +956,1 @@\n-  format %{ \"vor_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1000,1 +1000,1 @@\n-instruct vxor_immI(vReg dst_src, immI5 con) %{\n+instruct vxorI_vi(vReg dst_src, immI5 con) %{\n@@ -1005,1 +1005,1 @@\n-  format %{ \"vxor_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorI_vi $dst_src, $dst_src, $con\" %}\n@@ -1016,1 +1016,1 @@\n-instruct vxor_immL(vReg dst_src, immL5 con) %{\n+instruct vxorL_vi(vReg dst_src, immL5 con) %{\n@@ -1019,1 +1019,1 @@\n-  format %{ \"vxor_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorL_vi $dst_src, $dst_src, $con\" %}\n@@ -1031,1 +1031,1 @@\n-instruct vxor_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vxorI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -1036,1 +1036,1 @@\n-  format %{ \"vxor_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorI_vx $dst_src, $dst_src, $src\" %}\n@@ -1047,1 +1047,1 @@\n-instruct vxor_regL(vReg dst_src, iRegL src) %{\n+instruct vxorL_vx(vReg dst_src, iRegL src) %{\n@@ -1050,1 +1050,1 @@\n-  format %{ \"vxor_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorL_vx $dst_src, $dst_src, $src\" %}\n@@ -1062,1 +1062,1 @@\n-instruct vxor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vxorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -1067,1 +1067,1 @@\n-  format %{ \"vxor_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -1078,1 +1078,1 @@\n-instruct vxor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vxorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -1081,1 +1081,1 @@\n-  format %{ \"vxor_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -1093,1 +1093,1 @@\n-instruct vxor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vxorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -1098,1 +1098,1 @@\n-  format %{ \"vxor_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1109,1 +1109,1 @@\n-instruct vxor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vxorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -1112,1 +1112,1 @@\n-  format %{ \"vxor_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1804,1 +1804,1 @@\n-instruct vmul_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vmulI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -1808,1 +1808,1 @@\n-  format %{ \"vmul_regI $dst, $src1, $src2\" %}\n+  format %{ \"vmulI_vx $dst, $src1, $src2\" %}\n@@ -1819,1 +1819,1 @@\n-instruct vmul_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vmulL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -1821,1 +1821,1 @@\n-  format %{ \"vmul_regL $dst, $src1, $src2\" %}\n+  format %{ \"vmulL_vx $dst, $src1, $src2\" %}\n@@ -1833,1 +1833,1 @@\n-instruct vmul_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vmulI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -1837,1 +1837,1 @@\n-  format %{ \"vmul_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vmulI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -1848,1 +1848,1 @@\n-instruct vmul_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vmulL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -1850,1 +1850,1 @@\n-  format %{ \"vmul_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vmulL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -3125,1 +3125,1 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3128,1 +3128,1 @@\n-  format %{ \"vasrB_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrB_vi $dst, $src, $shift\" %}\n@@ -3143,1 +3143,1 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3146,1 +3146,1 @@\n-  format %{ \"vasrS_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrS_vi $dst, $src, $shift\" %}\n@@ -3161,1 +3161,1 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3164,1 +3164,1 @@\n-  format %{ \"vasrI_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrI_vi $dst, $src, $shift\" %}\n@@ -3178,1 +3178,1 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3182,1 +3182,1 @@\n-  format %{ \"vasrL_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrL_vi $dst, $src, $shift\" %}\n@@ -3196,1 +3196,1 @@\n-instruct vasrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3199,1 +3199,1 @@\n-  format %{ \"vasrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3213,1 +3213,1 @@\n-instruct vasrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3216,1 +3216,1 @@\n-  format %{ \"vasrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3230,1 +3230,1 @@\n-instruct vasrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3233,1 +3233,1 @@\n-  format %{ \"vasrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3246,1 +3246,1 @@\n-instruct vasrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3250,1 +3250,1 @@\n-  format %{ \"vasrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3263,1 +3263,1 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3266,1 +3266,1 @@\n-  format %{ \"vlsrB_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrB_vi $dst, $src, $shift\" %}\n@@ -3285,1 +3285,1 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3288,1 +3288,1 @@\n-  format %{ \"vlsrS_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrS_vi $dst, $src, $shift\" %}\n@@ -3307,1 +3307,1 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3310,1 +3310,1 @@\n-  format %{ \"vlsrI_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrI_vi $dst, $src, $shift\" %}\n@@ -3324,1 +3324,1 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3328,1 +3328,1 @@\n-  format %{ \"vlsrL_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrL_vi $dst, $src, $shift\" %}\n@@ -3342,1 +3342,1 @@\n-instruct vlsrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3345,1 +3345,1 @@\n-  format %{ \"vlsrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3363,1 +3363,1 @@\n-instruct vlsrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3366,1 +3366,1 @@\n-  format %{ \"vlsrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3384,1 +3384,1 @@\n-instruct vlsrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3387,1 +3387,1 @@\n-  format %{ \"vlsrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3400,1 +3400,1 @@\n-instruct vlsrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3404,1 +3404,1 @@\n-  format %{ \"vlsrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3417,1 +3417,1 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3420,1 +3420,1 @@\n-  format %{ \"vlslB_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslB_vi $dst, $src, $shift\" %}\n@@ -3434,1 +3434,1 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3437,1 +3437,1 @@\n-  format %{ \"vlslS_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslS_vi $dst, $src, $shift\" %}\n@@ -3451,1 +3451,1 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3454,1 +3454,1 @@\n-  format %{ \"vlslI_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslI_vi $dst, $src, $shift\" %}\n@@ -3463,1 +3463,1 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3467,1 +3467,1 @@\n-  format %{ \"vlslL_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslL_vi $dst, $src, $shift\" %}\n@@ -3476,1 +3476,1 @@\n-instruct vlslB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3479,1 +3479,1 @@\n-  format %{ \"vlslB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3494,1 +3494,1 @@\n-instruct vlslS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3497,1 +3497,1 @@\n-  format %{ \"vlslS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3512,1 +3512,1 @@\n-instruct vlslI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3515,1 +3515,1 @@\n-  format %{ \"vlslI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3525,1 +3525,1 @@\n-instruct vlslL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3529,1 +3529,1 @@\n-  format %{ \"vlslL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3569,1 +3569,1 @@\n-instruct vrotate_right_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_right_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3571,1 +3571,1 @@\n-  format %{ \"vrotate_right_reg $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_vx $dst, $src, $shift\\t\" %}\n@@ -3581,1 +3581,1 @@\n-instruct vrotate_right_imm(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_right_vi(vReg dst, vReg src, immI shift) %{\n@@ -3583,1 +3583,1 @@\n-  format %{ \"vrotate_right_imm $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_vi $dst, $src, $shift\\t\" %}\n@@ -3601,1 +3601,1 @@\n-  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3612,1 +3612,1 @@\n-instruct vrotate_right_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3614,1 +3614,1 @@\n-  format %{ \"vrotate_right_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3624,1 +3624,1 @@\n-instruct vrotate_right_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3626,1 +3626,1 @@\n-  format %{ \"vrotate_right_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3656,1 +3656,1 @@\n-instruct vrotate_left_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_left_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3658,1 +3658,1 @@\n-  format %{ \"vrotate_left_reg $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_vx $dst, $src, $shift\\t\" %}\n@@ -3668,1 +3668,1 @@\n-instruct vrotate_left_imm(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_left_vi(vReg dst, vReg src, immI shift) %{\n@@ -3670,1 +3670,1 @@\n-  format %{ \"vrotate_left_imm $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_vi $dst, $src, $shift\\t\" %}\n@@ -3689,1 +3689,1 @@\n-  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3700,1 +3700,1 @@\n-instruct vrotate_left_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3702,1 +3702,1 @@\n-  format %{ \"vrotate_left_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3712,1 +3712,1 @@\n-instruct vrotate_left_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3714,1 +3714,1 @@\n-  format %{ \"vrotate_left_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":146,"deletions":146,"binary":false,"changes":292,"status":"modified"}]}