{"files":[{"patch":"@@ -418,1 +418,1 @@\n-instruct vadd_immI(vReg dst, vReg src1, immI5 con) %{\n+instruct vaddI_vi(vReg dst, vReg src1, immI5 con) %{\n@@ -422,1 +422,1 @@\n-  format %{ \"vadd_immI $dst, $src1, $con\" %}\n+  format %{ \"vaddI_vi $dst, $src1, $con\" %}\n@@ -433,1 +433,1 @@\n-instruct vadd_immL(vReg dst, vReg src1, immL5 con) %{\n+instruct vaddL_vi(vReg dst, vReg src1, immL5 con) %{\n@@ -435,1 +435,1 @@\n-  format %{ \"vadd_immL $dst, $src1, $con\" %}\n+  format %{ \"vaddL_vi $dst, $src1, $con\" %}\n@@ -447,1 +447,1 @@\n-instruct vadd_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vaddI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -451,1 +451,1 @@\n-  format %{ \"vadd_regI $dst, $src1, $src2\" %}\n+  format %{ \"vaddI_vx $dst, $src1, $src2\" %}\n@@ -462,1 +462,1 @@\n-instruct vadd_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vaddL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -464,1 +464,1 @@\n-  format %{ \"vadd_regL $dst, $src1, $src2\" %}\n+  format %{ \"vaddL_vx $dst, $src1, $src2\" %}\n@@ -476,1 +476,1 @@\n-instruct vadd_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vaddI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -480,1 +480,1 @@\n-  format %{ \"vadd_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vaddI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -491,1 +491,1 @@\n-instruct vadd_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vaddL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -493,1 +493,1 @@\n-  format %{ \"vadd_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vaddL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -505,1 +505,1 @@\n-instruct vadd_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vaddI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -509,1 +509,1 @@\n-  format %{ \"vadd_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vaddI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -520,1 +520,1 @@\n-instruct vadd_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vaddL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -522,1 +522,1 @@\n-  format %{ \"vadd_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vaddL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -598,1 +598,1 @@\n-instruct vsub_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vsubI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -602,1 +602,1 @@\n-  format %{ \"vsub_regI $dst, $src1, $src2\" %}\n+  format %{ \"vsubI_vx $dst, $src1, $src2\" %}\n@@ -613,1 +613,1 @@\n-instruct vsub_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vsubL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -615,1 +615,1 @@\n-  format %{ \"vsub_regL $dst, $src1, $src2\" %}\n+  format %{ \"vsubL_vx $dst, $src1, $src2\" %}\n@@ -627,1 +627,1 @@\n-instruct vsub_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vsubI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -631,1 +631,1 @@\n-  format %{ \"vsub_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vsubI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -642,1 +642,1 @@\n-instruct vsub_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vsubL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -644,1 +644,1 @@\n-  format %{ \"vsub_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vsub_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -688,1 +688,1 @@\n-instruct vand_immI(vReg dst_src, immI5 con) %{\n+instruct vandI_vi(vReg dst_src, immI5 con) %{\n@@ -693,1 +693,1 @@\n-  format %{ \"vand_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandI_vi $dst_src, $dst_src, $con\" %}\n@@ -704,1 +704,1 @@\n-instruct vand_immL(vReg dst_src, immL5 con) %{\n+instruct vandL_vi(vReg dst_src, immL5 con) %{\n@@ -707,1 +707,1 @@\n-  format %{ \"vand_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandL_vi $dst_src, $dst_src, $con\" %}\n@@ -719,1 +719,1 @@\n-instruct vand_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vandI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -724,1 +724,1 @@\n-  format %{ \"vand_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandI_vx $dst_src, $dst_src, $src\" %}\n@@ -735,1 +735,1 @@\n-instruct vand_regL(vReg dst_src, iRegL src) %{\n+instruct vandL_vx(vReg dst_src, iRegL src) %{\n@@ -738,1 +738,1 @@\n-  format %{ \"vand_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandL_vx $dst_src, $dst_src, $src\" %}\n@@ -750,1 +750,1 @@\n-instruct vand_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vandI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -755,1 +755,1 @@\n-  format %{ \"vand_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -766,1 +766,1 @@\n-instruct vand_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vandL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -769,1 +769,1 @@\n-  format %{ \"vand_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vandL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -781,1 +781,1 @@\n-instruct vand_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vandI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -786,1 +786,1 @@\n-  format %{ \"vand_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -797,1 +797,1 @@\n-instruct vand_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vandL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -800,1 +800,1 @@\n-  format %{ \"vand_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vandL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -844,1 +844,1 @@\n-instruct vor_immI(vReg dst_src, immI5 con) %{\n+instruct vorI_vi(vReg dst_src, immI5 con) %{\n@@ -849,1 +849,1 @@\n-  format %{ \"vor_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorI_vi $dst_src, $dst_src, $con\" %}\n@@ -860,1 +860,1 @@\n-instruct vor_immL(vReg dst_src, immL5 con) %{\n+instruct vorL_vi(vReg dst_src, immL5 con) %{\n@@ -863,1 +863,1 @@\n-  format %{ \"vor_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorL_vi $dst_src, $dst_src, $con\" %}\n@@ -875,1 +875,1 @@\n-instruct vor_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vorI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -880,1 +880,1 @@\n-  format %{ \"vor_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorI_vx $dst_src, $dst_src, $src\" %}\n@@ -891,1 +891,1 @@\n-instruct vor_regL(vReg dst_src, iRegL src) %{\n+instruct vorL_vx(vReg dst_src, iRegL src) %{\n@@ -894,1 +894,1 @@\n-  format %{ \"vor_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorL_vx $dst_src, $dst_src, $src\" %}\n@@ -906,1 +906,1 @@\n-instruct vor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -911,1 +911,1 @@\n-  format %{ \"vor_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -922,1 +922,1 @@\n-instruct vor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -925,1 +925,1 @@\n-  format %{ \"vor_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -937,1 +937,1 @@\n-instruct vor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -942,1 +942,1 @@\n-  format %{ \"vor_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -953,1 +953,1 @@\n-instruct vor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -956,1 +956,1 @@\n-  format %{ \"vor_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1000,1 +1000,1 @@\n-instruct vxor_immI(vReg dst_src, immI5 con) %{\n+instruct vxorI_vi(vReg dst_src, immI5 con) %{\n@@ -1005,1 +1005,1 @@\n-  format %{ \"vxor_immI $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorI_vi $dst_src, $dst_src, $con\" %}\n@@ -1016,1 +1016,1 @@\n-instruct vxor_immL(vReg dst_src, immL5 con) %{\n+instruct vxorL_vi(vReg dst_src, immL5 con) %{\n@@ -1019,1 +1019,1 @@\n-  format %{ \"vxor_immL $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorL_vi $dst_src, $dst_src, $con\" %}\n@@ -1031,1 +1031,1 @@\n-instruct vxor_regI(vReg dst_src, iRegIorL2I src) %{\n+instruct vxorI_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -1036,1 +1036,1 @@\n-  format %{ \"vxor_regI $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorI_vx $dst_src, $dst_src, $src\" %}\n@@ -1047,1 +1047,1 @@\n-instruct vxor_regL(vReg dst_src, iRegL src) %{\n+instruct vxorL_vx(vReg dst_src, iRegL src) %{\n@@ -1050,1 +1050,1 @@\n-  format %{ \"vxor_regL $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorL_vx $dst_src, $dst_src, $src\" %}\n@@ -1062,1 +1062,1 @@\n-instruct vxor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vxorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -1067,1 +1067,1 @@\n-  format %{ \"vxor_immI_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -1078,1 +1078,1 @@\n-instruct vxor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vxorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -1081,1 +1081,1 @@\n-  format %{ \"vxor_immL_masked $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -1093,1 +1093,1 @@\n-instruct vxor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vxorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -1098,1 +1098,1 @@\n-  format %{ \"vxor_regI_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1109,1 +1109,1 @@\n-instruct vxor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vxorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -1112,1 +1112,1 @@\n-  format %{ \"vxor_regL_masked $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1740,1 +1740,1 @@\n-instruct vmul_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vmulI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -1744,1 +1744,1 @@\n-  format %{ \"vmul_regI $dst, $src1, $src2\" %}\n+  format %{ \"vmulI_vx $dst, $src1, $src2\" %}\n@@ -1755,1 +1755,1 @@\n-instruct vmul_regL(vReg dst, vReg src1, iRegL src2) %{\n+instruct vmulL_vx(vReg dst, vReg src1, iRegL src2) %{\n@@ -1757,1 +1757,1 @@\n-  format %{ \"vmul_regL $dst, $src1, $src2\" %}\n+  format %{ \"vmulL_vx $dst, $src1, $src2\" %}\n@@ -1769,1 +1769,1 @@\n-instruct vmul_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vmulI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -1773,1 +1773,1 @@\n-  format %{ \"vmul_regI_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vmulI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -1784,1 +1784,1 @@\n-instruct vmul_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vmulL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -1786,1 +1786,1 @@\n-  format %{ \"vmul_regL_masked $dst_src, $dst_src, $src2\" %}\n+  format %{ \"vmulL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -3061,1 +3061,1 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3064,1 +3064,1 @@\n-  format %{ \"vasrB_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrB_vi $dst, $src, $shift\" %}\n@@ -3079,1 +3079,1 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3082,1 +3082,1 @@\n-  format %{ \"vasrS_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrS_vi $dst, $src, $shift\" %}\n@@ -3097,1 +3097,1 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3100,1 +3100,1 @@\n-  format %{ \"vasrI_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrI_vi $dst, $src, $shift\" %}\n@@ -3114,1 +3114,1 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3118,1 +3118,1 @@\n-  format %{ \"vasrL_imm $dst, $src, $shift\" %}\n+  format %{ \"vasrL_vi $dst, $src, $shift\" %}\n@@ -3132,1 +3132,1 @@\n-instruct vasrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3135,1 +3135,1 @@\n-  format %{ \"vasrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3149,1 +3149,1 @@\n-instruct vasrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3152,1 +3152,1 @@\n-  format %{ \"vasrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3166,1 +3166,1 @@\n-instruct vasrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3169,1 +3169,1 @@\n-  format %{ \"vasrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3182,1 +3182,1 @@\n-instruct vasrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3186,1 +3186,1 @@\n-  format %{ \"vasrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3199,1 +3199,1 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3202,1 +3202,1 @@\n-  format %{ \"vlsrB_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrB_vi $dst, $src, $shift\" %}\n@@ -3221,1 +3221,1 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3224,1 +3224,1 @@\n-  format %{ \"vlsrS_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrS_vi $dst, $src, $shift\" %}\n@@ -3243,1 +3243,1 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3246,1 +3246,1 @@\n-  format %{ \"vlsrI_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrI_vi $dst, $src, $shift\" %}\n@@ -3260,1 +3260,1 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlsrL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3264,1 +3264,1 @@\n-  format %{ \"vlsrL_imm $dst, $src, $shift\" %}\n+  format %{ \"vlsrL_vi $dst, $src, $shift\" %}\n@@ -3278,1 +3278,1 @@\n-instruct vlsrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3281,1 +3281,1 @@\n-  format %{ \"vlsrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3299,1 +3299,1 @@\n-instruct vlsrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3302,1 +3302,1 @@\n-  format %{ \"vlsrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3320,1 +3320,1 @@\n-instruct vlsrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3323,1 +3323,1 @@\n-  format %{ \"vlsrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3336,1 +3336,1 @@\n-instruct vlsrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3340,1 +3340,1 @@\n-  format %{ \"vlsrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3353,1 +3353,1 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslB_vi(vReg dst, vReg src, immI shift) %{\n@@ -3356,1 +3356,1 @@\n-  format %{ \"vlslB_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslB_vi $dst, $src, $shift\" %}\n@@ -3370,1 +3370,1 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslS_vi(vReg dst, vReg src, immI shift) %{\n@@ -3373,1 +3373,1 @@\n-  format %{ \"vlslS_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslS_vi $dst, $src, $shift\" %}\n@@ -3387,1 +3387,1 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslI_vi(vReg dst, vReg src, immI shift) %{\n@@ -3390,1 +3390,1 @@\n-  format %{ \"vlslI_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslI_vi $dst, $src, $shift\" %}\n@@ -3399,1 +3399,1 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vlslL_vi(vReg dst, vReg src, immI shift) %{\n@@ -3403,1 +3403,1 @@\n-  format %{ \"vlslL_imm $dst, $src, $shift\" %}\n+  format %{ \"vlslL_vi $dst, $src, $shift\" %}\n@@ -3412,1 +3412,1 @@\n-instruct vlslB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3415,1 +3415,1 @@\n-  format %{ \"vlslB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3430,1 +3430,1 @@\n-instruct vlslS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3433,1 +3433,1 @@\n-  format %{ \"vlslS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3448,1 +3448,1 @@\n-instruct vlslI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3451,1 +3451,1 @@\n-  format %{ \"vlslI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3461,1 +3461,1 @@\n-instruct vlslL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3465,1 +3465,1 @@\n-  format %{ \"vlslL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3505,1 +3505,1 @@\n-instruct vrotate_right_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_right_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3507,1 +3507,1 @@\n-  format %{ \"vrotate_right_reg $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_vx $dst, $src, $shift\\t\" %}\n@@ -3517,1 +3517,1 @@\n-instruct vrotate_right_imm(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_right_vi(vReg dst, vReg src, immI shift) %{\n@@ -3519,1 +3519,1 @@\n-  format %{ \"vrotate_right_imm $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_vi $dst, $src, $shift\\t\" %}\n@@ -3537,1 +3537,1 @@\n-  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3548,1 +3548,1 @@\n-instruct vrotate_right_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3550,1 +3550,1 @@\n-  format %{ \"vrotate_right_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3560,1 +3560,1 @@\n-instruct vrotate_right_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3562,1 +3562,1 @@\n-  format %{ \"vrotate_right_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_right_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3592,1 +3592,1 @@\n-instruct vrotate_left_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_left_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3594,1 +3594,1 @@\n-  format %{ \"vrotate_left_reg $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_vx $dst, $src, $shift\\t\" %}\n@@ -3604,1 +3604,1 @@\n-instruct vrotate_left_imm(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_left_vi(vReg dst, vReg src, immI shift) %{\n@@ -3606,1 +3606,1 @@\n-  format %{ \"vrotate_left_imm $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_vi $dst, $src, $shift\\t\" %}\n@@ -3625,1 +3625,1 @@\n-  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3636,1 +3636,1 @@\n-instruct vrotate_left_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3638,1 +3638,1 @@\n-  format %{ \"vrotate_left_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n@@ -3648,1 +3648,1 @@\n-instruct vrotate_left_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3650,1 +3650,1 @@\n-  format %{ \"vrotate_left_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n+  format %{ \"vrotate_left_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":146,"deletions":146,"binary":false,"changes":292,"status":"modified"}]}