[{"commit":{"message":"Merge branch 'master' into fg8283091\n\nChange-Id: I1dfb4a6092302267e3796e08d411d0241b23df83"},"files":[{"filename":"src\/hotspot\/share\/opto\/superword.cpp"},{"filename":"src\/hotspot\/share\/opto\/superword.hpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.cpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.hpp"}],"sha":"cd0755557aa562a3ab055ce1f742e63815cdb873"},{"commit":{"message":"Add micro-benchmark cases\n\nChange-Id: I3c741255804ce410c8b6dcbdec974fa2c9051fd8"},"files":[{"filename":"test\/micro\/org\/openjdk\/bench\/vm\/compiler\/TypeVectorOperations.java"}],"sha":"bf3fc418aaf601b619ae7de2aa0dc85d6397c21f"},{"commit":{"message":"Merge branch 'master' into fg8283091\n\nChange-Id: I674581135fd0844accc65520574fcef161eededa"},"files":[],"sha":"0ea285322d2f0ff3eccc9cd78160831383d58d3f"},{"commit":{"message":"8283091: Support type conversion between different data sizes in SLP\n\nAfter JDK-8275317, C2's SLP vectorizer has supported type conversion\nbetween the same data size. We can also support conversions between\ndifferent data sizes like:\nint <-> double\nfloat <-> long\nint <-> long\nfloat <-> double\n\nA typical test case:\n\nint[] a;\ndouble[] b;\nfor (int i = start; i < limit; i++) {\n    b[i] = (double) a[i];\n}\n\nOur expected OptoAssembly code for one iteration is like below:\n\nadd R12, R2, R11, LShiftL #2\nvector_load   V16,[R12, #16]\nvectorcast_i2d  V16, V16  # convert I to D vector\nadd R11, R1, R11, LShiftL #3\t# ptr\nadd R13, R11, #16\t# ptr\nvector_store [R13], V16\n\nTo enable the vectorization, the patch solves the following problems\nin the SLP.\n\nThere are three main operations in the case above, LoadI, ConvI2D and\nStoreD. Assuming that the vector length is 128 bits, how many scalar\nnodes should be packed together to a vector? If we decide it\nseparately for each operation node, like what we did before the patch\nin SuperWord::combine_packs(), a 128-bit vector will support 4 LoadI\nor 2 ConvI2D or 2 StoreD nodes. However, if we put these packed nodes\nin a vector node sequence, like loading 4 elements to a vector, then\ntypecasting 2 elements and lastly storing these 2 elements, they become\ninvalid. As a result, we should look through the whole def-use chain\nand then pick up the minimum of these element sizes, like function\nSuperWord::max_vector_size_in_ud_chain() do in the superword.cpp.\nIn this case, we pack 2 LoadI, 2 ConvI2D and 2 StoreD nodes, and then\ngenerate valid vector node sequence, like loading 2 elements,\nconverting the 2 elements to another type and storing the 2 elements\nwith new type.\n\nAfter this, LoadI nodes don't make full use of the whole vector and\nonly occupy part of it. So we adapt the code in\nSuperWord::get_vw_bytes_special() to the situation.\n\nIn SLP, we calculate a kind of alignment as position trace for each\nscalar node in the whole vector. In this case, the alignments for 2\nLoadI nodes are 0, 4 while the alignment for 2 ConvI2D nodes are 0, 8.\nSometimes, 4 for LoadI and 8 for ConvI2D work the same, both of which\nmark that this node is the second node in the whole vector, while the\ndifference between 4 and 8 are just because of their own data sizes. In\nthis situation, we should try to remove the impact caused by different\ndata size in SLP. For example, in the stage of\nSuperWord::extend_packlist(), while determining if it's potential to\npack a pair of def nodes in the function SuperWord::follow_use_defs(),\nwe remove the side effect of different data size by transforming the\ntarget alignment from the use node. Because we believe that, assuming\nthat the vector length is 512 bits, if the ConvI2D use nodes have\nalignments of 16-24 and their def nodes, LoadI, have alignments of 8-12,\nthese two LoadI nodes should be packed as a pair as well.\n\nSimilarly, when determining if the vectorization is profitable, type\nconversion between different data size takes a type of one size and\nproduces a type of another size, hence the special checks on alignment\nand size should be applied, like what we do in SuperWord::is_vector_use.\n\nAfter solving these problems, we successfully implemented the\nvectorization of type conversion between different data sizes.\n\nHere is the test data on NEON:\n\nBefore the patch:\nBenchmark              (length)  Mode  Cnt    Score   Error  Units\n  VectorLoop.convertD2F       523  avgt   15  216.431 ± 0.131  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  220.522 ± 0.311  ns\/op\n  VectorLoop.convertF2D       523  avgt   15  217.034 ± 0.292  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  231.634 ± 1.881  ns\/op\n  VectorLoop.convertI2D       523  avgt   15  229.538 ± 0.095  ns\/op\n  VectorLoop.convertI2L       523  avgt   15  214.822 ± 0.131  ns\/op\n  VectorLoop.convertL2F       523  avgt   15  230.188 ± 0.217  ns\/op\n  VectorLoop.convertL2I       523  avgt   15  162.234 ± 0.235  ns\/op\n\nAfter the patch:\nBenchmark              (length)  Mode  Cnt    Score    Error  Units\n  VectorLoop.convertD2F       523  avgt   15  124.352 ±  1.079  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  557.388 ±  8.166  ns\/op\n  VectorLoop.convertF2D       523  avgt   15  118.082 ±  4.026  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  225.810 ± 11.180  ns\/op\n  VectorLoop.convertI2D       523  avgt   15  166.247 ±  0.120  ns\/op\n  VectorLoop.convertI2L       523  avgt   15  119.699 ±  2.925  ns\/op\n  VectorLoop.convertL2F       523  avgt   15  220.847 ±  0.053  ns\/op\n  VectorLoop.convertL2I       523  avgt   15  122.339 ±  2.738  ns\/op\n\nperf data on X86:\nBefore the patch:\nBenchmark              (length)  Mode  Cnt    Score   Error  Units\n  VectorLoop.convertD2F       523  avgt   15  279.466 ± 0.069  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  551.009 ± 7.459  ns\/op\n  VectorLoop.convertF2D       523  avgt   15  276.066 ± 0.117  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  545.108 ± 5.697  ns\/op\n  VectorLoop.convertI2D       523  avgt   15  745.303 ± 0.185  ns\/op\n  VectorLoop.convertI2L       523  avgt   15  260.878 ± 0.044  ns\/op\n  VectorLoop.convertL2F       523  avgt   15  502.016 ± 0.172  ns\/op\n  VectorLoop.convertL2I       523  avgt   15  261.654 ± 3.326  ns\/op\n\nAfter the patch:\nBenchmark              (length)  Mode  Cnt    Score   Error  Units\n  VectorLoop.convertD2F       523  avgt   15  106.975 ± 0.045  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  546.866 ± 9.287  ns\/op\n  VectorLoop.convertF2D       523  avgt   15   82.414 ± 0.340  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  542.235 ± 2.785  ns\/op\n  VectorLoop.convertI2D       523  avgt   15   92.966 ± 1.400  ns\/op\n  VectorLoop.convertI2L       523  avgt   15   79.960 ± 0.528  ns\/op\n  VectorLoop.convertL2F       523  avgt   15  504.712 ± 4.794  ns\/op\n  VectorLoop.convertL2I       523  avgt   15  129.753 ± 0.094  ns\/op\n\nperf data on AVX512:\nBefore the patch:\nBenchmark              (length)  Mode  Cnt    Score   Error  Units\n  VectorLoop.convertD2F       523  avgt   15  282.984 ± 4.022  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  543.080 ± 3.873  ns\/op\n  VectorLoop.convertF2D       523  avgt   15  273.950 ± 0.131  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  539.568 ± 2.747  ns\/op\n  VectorLoop.convertI2D       523  avgt   15  745.238 ± 0.069  ns\/op\n  VectorLoop.convertI2L       523  avgt   15  260.935 ± 0.169  ns\/op\n  VectorLoop.convertL2F       523  avgt   15  501.870 ± 0.359  ns\/op\n  VectorLoop.convertL2I       523  avgt   15  257.508 ± 0.174  ns\/op\n\nAfter the patch:\nBenchmark              (length)  Mode  Cnt    Score   Error  Units\n  VectorLoop.convertD2F       523  avgt   15   76.687 ± 0.530  ns\/op\n  VectorLoop.convertD2I       523  avgt   15  545.408 ± 4.657  ns\/op\n  VectorLoop.convertF2D       523  avgt   15  273.935 ± 0.099  ns\/op\n  VectorLoop.convertF2L       523  avgt   15  540.534 ± 3.032  ns\/op\n  VectorLoop.convertI2D       523  avgt   15  745.234 ± 0.053  ns\/op\n  VectorLoop.convertI2L       523  avgt   15  260.865 ± 0.104  ns\/op\n  VectorLoop.convertL2F       523  avgt   15   63.834 ± 4.777  ns\/op\n  VectorLoop.convertL2I       523  avgt   15   48.183 ± 0.990  ns\/op\n\nChange-Id: I93e60fd956547dad9204ceec90220145c58a72ef"},"files":[{"filename":"src\/hotspot\/share\/opto\/superword.cpp"},{"filename":"src\/hotspot\/share\/opto\/superword.hpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.cpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.hpp"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestByteDoubleVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestByteFloatVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestByteLongVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestFloatDoubleVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestIntDoubleVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestIntLongVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestLongFloatVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestShortDoubleVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestShortFloatVect.java"},{"filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestShortLongVect.java"}],"sha":"c2c1373926a0bacaa5081e362119b949c1355ba9"}]