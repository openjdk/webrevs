{"files":[{"patch":"@@ -72,3 +72,0 @@\n-  \/\/ Load object header\n-  ld(hdr, Address(obj, hdr_offset));\n-\n@@ -79,0 +76,2 @@\n+    \/\/ Load object header\n+    ld(hdr, Address(obj, hdr_offset));\n@@ -137,3 +136,0 @@\n-    ld(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-    test_bit(temp, hdr, exact_log2(markWord::monitor_value));\n-    bnez(temp, slow_case, \/* is_far *\/ true);\n","filename":"src\/hotspot\/cpu\/riscv\/c1_MacroAssembler_riscv.cpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -54,1 +55,0 @@\n-  Label cont;\n@@ -56,1 +56,4 @@\n-  Label count, no_count;\n+  \/\/ Finish fast lock successfully. MUST branch to with flag == 0\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. slow_path MUST branch to with flag != 0\n+  Label slow_path;\n@@ -58,0 +61,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_lock_lightweight\");\n@@ -60,0 +64,2 @@\n+  mv(flag, 1);\n+\n@@ -64,4 +70,4 @@\n-    load_klass(flag, oop);\n-    lwu(flag, Address(flag, Klass::access_flags_offset()));\n-    test_bit(flag, flag, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n-    bnez(flag, cont, true \/* is_far *\/);\n+    load_klass(tmp, oop);\n+    lwu(tmp, Address(tmp, Klass::access_flags_offset()));\n+    test_bit(tmp, tmp, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+    bnez(tmp, slow_path);\n@@ -71,2 +77,2 @@\n-  test_bit(t0, disp_hdr, exact_log2(markWord::monitor_value));\n-  bnez(t0, object_has_monitor);\n+  test_bit(tmp, disp_hdr, exact_log2(markWord::monitor_value));\n+  bnez(tmp, object_has_monitor);\n@@ -75,3 +81,3 @@\n-    mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow-path\n-    j(cont);\n-  } else if (LockingMode == LM_LEGACY) {\n+    j(slow_path);\n+  } else {\n+    assert(LockingMode == LM_LEGACY, \"must be\");\n@@ -87,4 +93,3 @@\n-    cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64, Assembler::aq,\n-            Assembler::rl, \/*result*\/disp_hdr);\n-    mv(flag, zr);\n-    beq(disp_hdr, tmp, cont); \/\/ prepare zero flag and goto cont if we won the cas\n+    cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64,\n+            Assembler::aq, Assembler::rl, \/*result*\/disp_hdr);\n+    beq(disp_hdr, tmp, locked);\n@@ -95,1 +100,1 @@\n-    \/\/ object, will have now locked it will continue at label cont\n+    \/\/ object, will have now locked it will continue at label locked\n@@ -102,1 +107,1 @@\n-    \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto cont,\n+    \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto label locked,\n@@ -107,13 +112,2 @@\n-    mv(flag, tmp); \/\/ we can use the value of tmp as the result here\n-    j(cont);\n-  } else {\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n-    Label slow;\n-    lightweight_lock(oop, disp_hdr, tmp, tmp3Reg, slow);\n-\n-    \/\/ Indicate success on completion.\n-    mv(flag, zr);\n-    j(count);\n-    bind(slow);\n-    mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow-path\n-    j(no_count);\n+    beqz(tmp, locked);\n+    j(slow_path);\n@@ -129,11 +123,2 @@\n-  cmpxchg(\/*memory address*\/tmp, \/*expected value*\/zr, \/*new value*\/xthread, Assembler::int64, Assembler::aq,\n-          Assembler::rl, \/*result*\/flag); \/\/ cas succeeds if flag == zr(expected)\n-\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n-    mv(tmp, (address)markWord::unused_mark().value());\n-    sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-  }\n+  cmpxchg(\/*memory address*\/tmp, \/*expected value*\/zr, \/*new value*\/xthread, Assembler::int64,\n+          Assembler::aq, Assembler::rl, \/*result*\/tmp3Reg); \/\/ cas succeeds if tmp3Reg == zr(expected)\n@@ -141,1 +126,6 @@\n-  beqz(flag, cont); \/\/ CAS success means locking succeeded\n+  \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+  \/\/ lock. The fast-path monitor unlock code checks for\n+  \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+  \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n+  mv(tmp, (address)markWord::unused_mark().value());\n+  sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n@@ -143,1 +133,3 @@\n-  bne(flag, xthread, cont); \/\/ Check for recursive locking\n+  beqz(tmp3Reg, locked); \/\/ CAS success means locking succeeded\n+\n+  bne(tmp3Reg, xthread, slow_path); \/\/ Check for recursive locking\n@@ -146,2 +138,1 @@\n-  mv(flag, zr);\n-  increment(Address(disp_hdr, in_bytes(ObjectMonitor::recursions_offset()) - markWord::monitor_value), 1, t0, tmp);\n+  increment(Address(disp_hdr, in_bytes(ObjectMonitor::recursions_offset()) - markWord::monitor_value), 1, tmp2Reg, tmp3Reg);\n@@ -149,4 +140,3 @@\n-  bind(cont);\n-  \/\/ zero flag indicates success\n-  \/\/ non-zero flag indicates failure\n-  bnez(flag, no_count);\n+  bind(locked);\n+  mv(flag, zr);\n+  increment(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2Reg, tmp3Reg);\n@@ -154,2 +144,6 @@\n-  bind(count);\n-  increment(Address(xthread, JavaThread::held_monitor_count_offset()), 1, t0, tmp);\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with flag == 0.\n+  Label flag_correct;\n+  beqz(flag, flag_correct);\n+  stop(\"Fast Lock Flag != 0\");\n+#endif\n@@ -157,1 +151,8 @@\n-  bind(no_count);\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with flag != 0.\n+  bnez(flag, flag_correct);\n+  stop(\"Fast Lock Flag == 0\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n@@ -168,1 +169,0 @@\n-  Label cont;\n@@ -170,1 +170,4 @@\n-  Label count, no_count;\n+  \/\/ Finish fast lock successfully. MUST branch to with flag == 0\n+  Label unlocked;\n+  \/\/ Finish fast lock unsuccessfully. slow_path MUST branch to with flag != 0\n+  Label slow_path;\n@@ -172,0 +175,1 @@\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_unlock_lightweight\");\n@@ -174,0 +178,2 @@\n+  mv(flag, 1);\n+\n@@ -179,2 +185,1 @@\n-    mv(flag, disp_hdr);\n-    beqz(disp_hdr, cont);\n+    beqz(disp_hdr, unlocked);\n@@ -189,3 +194,3 @@\n-    mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow path\n-    j(cont);\n-  } else if (LockingMode == LM_LEGACY) {\n+    j(slow_path);\n+  } else {\n+    assert(LockingMode == LM_LEGACY, \"must be\");\n@@ -196,15 +201,4 @@\n-    cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64, Assembler::relaxed,\n-            Assembler::rl, \/*result*\/tmp);\n-    xorr(flag, box, tmp); \/\/ box == tmp if cas succeeds\n-    j(cont);\n-  } else {\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n-    Label slow;\n-    lightweight_unlock(oop, tmp, box, disp_hdr, slow);\n-\n-    \/\/ Indicate success on completion.\n-    mv(flag, zr);\n-    j(count);\n-    bind(slow);\n-    mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow path\n-    j(no_count);\n+    cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64,\n+            Assembler::relaxed, Assembler::rl, \/*result*\/tmp);\n+    beq(box, tmp, unlocked); \/\/ box == tmp if cas succeeds\n+    j(slow_path);\n@@ -220,11 +214,0 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ If the owner is anonymous, we need to fix it -- in an outline stub.\n-    Register tmp2 = disp_hdr;\n-    ld(tmp2, Address(tmp, ObjectMonitor::owner_offset()));\n-    test_bit(t0, tmp2, exact_log2(ObjectMonitor::ANONYMOUS_OWNER));\n-    C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmp, tmp2);\n-    Compile::current()->output()->add_stub(stub);\n-    bnez(t0, stub->entry(), \/* is_far *\/ true);\n-    bind(stub->continuation());\n-  }\n-\n@@ -239,2 +222,1 @@\n-  mv(flag, zr);\n-  j(cont);\n+  j(unlocked);\n@@ -243,1 +225,1 @@\n-  ld(flag, Address(tmp, ObjectMonitor::EntryList_offset()));\n+  ld(t0, Address(tmp, ObjectMonitor::EntryList_offset()));\n@@ -245,2 +227,3 @@\n-  orr(flag, flag, disp_hdr); \/\/ Will be 0 if both are 0.\n-  bnez(flag, cont);\n+  orr(t0, t0, disp_hdr); \/\/ Will be 0 if both are 0.\n+  bnez(t0, slow_path);\n+\n@@ -252,4 +235,3 @@\n-  bind(cont);\n-  \/\/ zero flag indicates success\n-  \/\/ non-zero flag indicates failure\n-  bnez(flag, no_count);\n+  bind(unlocked);\n+  mv(flag, zr);\n+  decrement(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp1Reg, tmp2Reg);\n@@ -257,2 +239,6 @@\n-  bind(count);\n-  decrement(Address(xthread, JavaThread::held_monitor_count_offset()), 1, t0, tmp);\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with flag == 0.\n+  Label flag_correct;\n+  beqz(flag, flag_correct);\n+  stop(\"Fast Lock Flag != 0\");\n+#endif\n@@ -260,1 +246,274 @@\n-  bind(no_count);\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with flag != 0.\n+  bnez(flag, flag_correct);\n+  stop(\"Fast Lock Flag == 0\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_lock_lightweight(Register obj, Register tmp1, Register tmp2, Register tmp3) {\n+  \/\/ Flag register, zero for success; non-zero for failure.\n+  Register flag = t1;\n+\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert_different_registers(obj, tmp1, tmp2, tmp3, flag, t0);\n+\n+  mv(flag, 1);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated;\n+  \/\/ Finish fast lock successfully. MUST branch to with flag == 0\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. slow_path MUST branch to with flag != 0\n+  Label slow_path;\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(tmp1, obj);\n+    lwu(tmp1, Address(tmp1, Klass::access_flags_offset()));\n+    test_bit(tmp1, tmp1, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n+    bnez(tmp1, slow_path);\n+  }\n+\n+  const Register tmp1_mark = tmp1;\n+\n+  { \/\/ Lightweight locking\n+\n+    \/\/ Push lock to the lock stack and finish successfully. MUST branch to with flag == 0\n+    Label push;\n+\n+    const Register tmp2_top = tmp2;\n+    const Register tmp3_t = tmp3;\n+\n+    \/\/ Check if lock-stack is full.\n+    lwu(tmp2_top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+    mv(tmp3_t, (unsigned)LockStack::end_offset());\n+    bge(tmp2_top, tmp3_t, slow_path);\n+\n+    \/\/ Check if recursive.\n+    add(tmp3_t, xthread, tmp2_top);\n+    ld(tmp3_t, Address(tmp3_t, -oopSize));\n+    beq(obj, tmp3_t, push);\n+\n+    \/\/ Relaxed normal load to check for monitor. Optimization for monitor case.\n+    ld(tmp1_mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    test_bit(tmp3_t, tmp1_mark, exact_log2(markWord::monitor_value));\n+    bnez(tmp3_t, inflated);\n+\n+    \/\/ Not inflated\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid a la\");\n+\n+    \/\/ Try to lock. Transition lock-bits 0b01 => 0b00\n+    ori(tmp1_mark, tmp1_mark, markWord::unlocked_value);\n+    xori(tmp3_t, tmp1_mark, markWord::unlocked_value);\n+    cmpxchg(\/*addr*\/ obj, \/*expected*\/ tmp1_mark, \/*new*\/ tmp3_t, Assembler::int64,\n+            \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::relaxed, \/*result*\/ tmp3_t);\n+    bne(tmp1_mark, tmp3_t, slow_path);\n+\n+    bind(push);\n+    \/\/ After successful lock, push object on lock-stack.\n+    add(tmp3_t, xthread, tmp2_top);\n+    sd(obj, Address(tmp3_t));\n+    addw(tmp2_top, tmp2_top, oopSize);\n+    sw(tmp2_top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+    j(locked);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated);\n+\n+    \/\/ mark contains the tagged ObjectMonitor*.\n+    const Register tmp1_tagged_monitor = tmp1_mark;\n+    const uintptr_t monitor_tag = markWord::monitor_value;\n+    const Register tmp2_owner_addr = tmp2;\n+    const Register tmp3_owner = tmp3;\n+\n+    \/\/ Compute owner address.\n+    la(tmp2_owner_addr, Address(tmp1_tagged_monitor, (in_bytes(ObjectMonitor::owner_offset()) - monitor_tag)));\n+\n+    \/\/ CAS owner (null => current thread).\n+    cmpxchg(\/*addr*\/ tmp2_owner_addr, \/*expected*\/ zr, \/*new*\/ xthread, Assembler::int64,\n+            \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::relaxed, \/*result*\/ tmp3_owner);\n+    beqz(tmp3_owner, locked);\n+\n+    \/\/ Check if recursive.\n+    bne(tmp3_owner, xthread, slow_path);\n+\n+    \/\/ Recursive.\n+    increment(Address(tmp1_tagged_monitor, in_bytes(ObjectMonitor::recursions_offset()) - monitor_tag), 1, tmp2, tmp3);\n+  }\n+\n+  bind(locked);\n+  mv(flag, zr);\n+  increment(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2, tmp3);\n+\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with flag == 0.\n+  Label flag_correct;\n+  beqz(flag, flag_correct);\n+  stop(\"Fast Lock Flag != 0\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with flag != 0.\n+  bnez(flag, flag_correct);\n+  stop(\"Fast Lock Flag == 0\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_unlock_lightweight(Register obj, Register tmp1, Register tmp2,\n+                                                Register tmp3) {\n+  \/\/ Flag register, zero for success; non-zero for failure.\n+  Register flag = t1;\n+\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+  assert_different_registers(obj, tmp1, tmp2, tmp3, flag, t0);\n+\n+  mv(flag, 1);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated, inflated_load_monitor;\n+  \/\/ Finish fast unlock successfully. unlocked MUST branch to with flag == 0\n+  Label unlocked;\n+  \/\/ Finish fast unlock unsuccessfully. MUST branch to with flag != 0\n+  Label slow_path;\n+\n+  const Register tmp1_mark = tmp1;\n+  const Register tmp2_top = tmp2;\n+  const Register tmp3_t = tmp3;\n+\n+  { \/\/ Lightweight unlock\n+\n+    \/\/ Check if obj is top of lock-stack.\n+    lwu(tmp2_top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+    subw(tmp2_top, tmp2_top, oopSize);\n+    add(tmp3_t, xthread, tmp2_top);\n+    ld(tmp3_t, Address(tmp3_t));\n+    \/\/ Top of lock stack was not obj. Must be monitor.\n+    bne(obj, tmp3_t, inflated_load_monitor);\n+\n+    \/\/ Pop lock-stack.\n+    DEBUG_ONLY(add(tmp3_t, xthread, tmp2_top);)\n+    DEBUG_ONLY(sd(zr, Address(tmp3_t));)\n+    sw(tmp2_top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check if recursive.\n+    add(tmp3_t, xthread, tmp2_top);\n+    ld(tmp3_t, Address(tmp3_t, -oopSize));\n+    beq(obj, tmp3_t, unlocked);\n+\n+    \/\/ Not recursive.\n+    \/\/ Load Mark.\n+    ld(tmp1_mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Check header for monitor (0b10).\n+    test_bit(tmp3_t, tmp1_mark, exact_log2(markWord::monitor_value));\n+    bnez(tmp3_t, inflated);\n+\n+    \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+    ori(tmp3_t, tmp1_mark, markWord::unlocked_value);\n+    cmpxchg(\/*addr*\/ obj, \/*expected*\/ tmp1_mark, \/*new*\/ tmp3_t, Assembler::int64,\n+            \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, \/*result*\/ tmp3_t);\n+    beq(tmp1_mark, tmp3_t, unlocked);\n+\n+    \/\/ Compare and exchange failed.\n+    \/\/ Restore lock-stack and handle the unlock in runtime.\n+    DEBUG_ONLY(add(tmp3_t, xthread, tmp2_top);)\n+    DEBUG_ONLY(sd(obj, Address(tmp3_t));)\n+    addw(tmp2_top, tmp2_top, oopSize);\n+    sd(tmp2_top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+    j(slow_path);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated_load_monitor);\n+    ld(tmp1_mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+#ifdef ASSERT\n+    test_bit(tmp3_t, tmp1_mark, exact_log2(markWord::monitor_value));\n+    bnez(tmp3_t, inflated);\n+    stop(\"Fast Unlock not monitor\");\n+#endif\n+\n+    bind(inflated);\n+\n+#ifdef ASSERT\n+    Label check_done;\n+    subw(tmp2_top, tmp2_top, oopSize);\n+    mv(tmp3_t, in_bytes(JavaThread::lock_stack_base_offset()));\n+    blt(tmp2_top, tmp3_t, check_done);\n+    add(tmp3_t, xthread, tmp2_top);\n+    ld(tmp3_t, Address(tmp3_t));\n+    bne(obj, tmp3_t, inflated);\n+    stop(\"Fast Unlock lock on stack\");\n+    bind(check_done);\n+#endif\n+\n+    \/\/ mark contains the tagged ObjectMonitor*.\n+    const Register tmp1_monitor = tmp1_mark;\n+    const uintptr_t monitor_tag = markWord::monitor_value;\n+\n+    \/\/ Untag the monitor.\n+    sub(tmp1_monitor, tmp1_mark, monitor_tag);\n+\n+    const Register tmp2_recursions = tmp2;\n+    Label not_recursive;\n+\n+    \/\/ Check if recursive.\n+    ld(tmp2_recursions, Address(tmp1_monitor, ObjectMonitor::recursions_offset()));\n+    beqz(tmp2_recursions, not_recursive);\n+\n+    \/\/ Recursive unlock.\n+    addi(tmp2_recursions, tmp2_recursions, -1);\n+    sd(tmp2_recursions, Address(tmp1_monitor, ObjectMonitor::recursions_offset()));\n+    j(unlocked);\n+\n+    bind(not_recursive);\n+\n+    Label release;\n+    const Register tmp2_owner_addr = tmp2;\n+\n+    \/\/ Compute owner address.\n+    la(tmp2_owner_addr, Address(tmp1_monitor, ObjectMonitor::owner_offset()));\n+\n+    \/\/ Check if the entry lists are empty.\n+    ld(t0, Address(tmp1_monitor, ObjectMonitor::EntryList_offset()));\n+    ld(tmp3_t, Address(tmp1_monitor, ObjectMonitor::cxq_offset()));\n+    orr(t0, t0, tmp3_t);\n+    beqz(t0, release);\n+\n+    \/\/ The owner may be anonymous and we removed the last obj entry in\n+    \/\/ the lock-stack. This loses the information about the owner.\n+    \/\/ Write the thread to the owner field so the runtime knows the owner.\n+    sd(xthread, Address(tmp2_owner_addr));\n+    j(slow_path);\n+\n+    bind(release);\n+    \/\/ Set owner to null.\n+    membar(MacroAssembler::LoadStore | MacroAssembler::StoreStore);\n+    sd(zr, Address(tmp2_owner_addr));\n+  }\n+\n+  bind(unlocked);\n+  mv(flag, zr);\n+  decrement(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2, tmp3);\n+\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with flag == 0.\n+  Label flag_correct;\n+  beqz(flag, flag_correct);\n+  stop(\"Fast Lock Flag != 0\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with flag != 0.\n+  bnez(flag, flag_correct);\n+  stop(\"Fast Lock Flag == 0\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":356,"deletions":97,"binary":false,"changes":453,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-  \/\/ See full description in macroAssembler_riscv.cpp.\n@@ -50,0 +49,3 @@\n+  \/\/ Code used by cmpFastLockLightweight and cmpFastUnlockLightweight mach instructions in .ad file.\n+  void fast_lock_lightweight(Register object, Register tmp1, Register tmp2, Register tmp3);\n+  void fast_unlock_lightweight(Register object, Register tmp1, Register tmp2, Register tmp3);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -766,1 +766,0 @@\n-      ld(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -863,18 +862,0 @@\n-\n-      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n-      \/\/ must handle it.\n-      Register tmp1 = t0;\n-      Register tmp2 = header_reg;\n-      \/\/ First check for lock-stack underflow.\n-      lwu(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n-      mv(tmp2, (unsigned)LockStack::start_offset());\n-      ble(tmp1, tmp2, slow_case);\n-      \/\/ Then check if the top of the lock-stack matches the unlocked object.\n-      subw(tmp1, tmp1, oopSize);\n-      add(tmp1, xthread, tmp1);\n-      ld(tmp1, Address(tmp1, 0));\n-      bne(tmp1, obj_reg, slow_case);\n-\n-      ld(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      test_bit(t0, header_reg, exact_log2(markWord::monitor_value));\n-      bnez(t0, slow_case);\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":0,"deletions":19,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -5045,2 +5046,0 @@\n-\/\/ Branches to slow upon failure to lock the object.\n-\/\/ Falls through upon success.\n@@ -5049,3 +5048,3 @@\n-\/\/  - hdr: the header, already loaded from obj, will be destroyed\n-\/\/  - tmp1, tmp2: temporary registers, will be destroyed\n-void MacroAssembler::lightweight_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow) {\n+\/\/  - tmp1, tmp2, tmp3: temporary registers, will be destroyed\n+\/\/  - slow: branched to if locking fails\n+void MacroAssembler::lightweight_lock(Register obj, Register tmp1, Register tmp2, Register tmp3, Label& slow) {\n@@ -5053,23 +5052,39 @@\n-  assert_different_registers(obj, hdr, tmp1, tmp2, t0);\n-\n-  \/\/ Check if we would have space on lock-stack for the object.\n-  lwu(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n-  mv(tmp2, (unsigned)LockStack::end_offset());\n-  bge(tmp1, tmp2, slow, \/* is_far *\/ true);\n-\n-  \/\/ Load (object->mark() | 1) into hdr\n-  ori(hdr, hdr, markWord::unlocked_value);\n-  \/\/ Clear lock-bits, into tmp2\n-  xori(tmp2, hdr, markWord::unlocked_value);\n-\n-  \/\/ Try to swing header from unlocked to locked\n-  Label success;\n-  cmpxchgptr(hdr, tmp2, obj, tmp1, success, &slow);\n-  bind(success);\n-\n-  \/\/ After successful lock, push object on lock-stack\n-  lwu(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n-  add(tmp2, xthread, tmp1);\n-  sd(obj, Address(tmp2, 0));\n-  addw(tmp1, tmp1, oopSize);\n-  sw(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n+  assert_different_registers(obj, tmp1, tmp2, tmp3, t0);\n+\n+  Label push;\n+  const Register top = tmp1;\n+  const Register mark = tmp2;\n+  const Register t = tmp3;\n+\n+  \/\/ Preload the markWord. It is important that this is the first\n+  \/\/ instruction emitted as it is part of C1's null check semantics.\n+  ld(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+  \/\/ Check if the lock-stack is full.\n+  lwu(top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+  mv(t, (unsigned)LockStack::end_offset());\n+  bge(top, t, slow, \/* is_far *\/ true);\n+\n+  \/\/ Check for recursion.\n+  add(t, xthread, top);\n+  ld(t, Address(t, -oopSize));\n+  beq(obj, t, push);\n+\n+  \/\/ Check header for monitor (0b10).\n+  test_bit(t, mark, exact_log2(markWord::monitor_value));\n+  bnez(t, slow, \/* is_far *\/ true);\n+\n+  \/\/ Try to lock. Transition lock-bits 0b01 => 0b00\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid a la\");\n+  ori(mark, mark, markWord::unlocked_value);\n+  xori(t, mark, markWord::unlocked_value);\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::int64,\n+          \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::relaxed, \/*result*\/ t);\n+  bne(mark, t, slow, \/* is_far *\/ true);\n+\n+  bind(push);\n+  \/\/ After successful lock, push object on lock-stack.\n+  add(t, xthread, top);\n+  sd(obj, Address(t));\n+  addw(top, top, oopSize);\n+  sw(top, Address(xthread, JavaThread::lock_stack_top_offset()));\n@@ -5079,2 +5094,0 @@\n-\/\/ Branches to slow upon failure.\n-\/\/ Falls through upon success.\n@@ -5083,3 +5096,3 @@\n-\/\/ - hdr: the (pre-loaded) header of the object\n-\/\/ - tmp1, tmp2: temporary registers\n-void MacroAssembler::lightweight_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow) {\n+\/\/ - tmp1, tmp2, tmp3: temporary registers\n+\/\/ - slow: branched to if unlocking fails\n+void MacroAssembler::lightweight_unlock(Register obj, Register tmp1, Register tmp2, Register tmp3, Label& slow) {\n@@ -5087,1 +5100,1 @@\n-  assert_different_registers(obj, hdr, tmp1, tmp2, t0);\n+  assert_different_registers(obj, tmp1, tmp2, tmp3, t0);\n@@ -5091,4 +5104,0 @@\n-    \/\/ The following checks rely on the fact that LockStack is only ever modified by\n-    \/\/ its owning thread, even if the lock got inflated concurrently; removal of LockStack\n-    \/\/ entries after inflation will happen delayed in that case.\n-\n@@ -5099,1 +5108,1 @@\n-    bgt(tmp1, tmp2, stack_ok);\n+    bge(tmp1, tmp2, stack_ok);\n@@ -5103,18 +5112,0 @@\n-  {\n-    \/\/ Check if the top of the lock-stack matches the unlocked object.\n-    Label tos_ok;\n-    subw(tmp1, tmp1, oopSize);\n-    add(tmp1, xthread, tmp1);\n-    ld(tmp1, Address(tmp1, 0));\n-    beq(tmp1, obj, tos_ok);\n-    STOP(\"Top of lock-stack does not match the unlocked object\");\n-    bind(tos_ok);\n-  }\n-  {\n-    \/\/ Check that hdr is fast-locked.\n-   Label hdr_ok;\n-    andi(tmp1, hdr, markWord::lock_mask_in_place);\n-    beqz(tmp1, hdr_ok);\n-    STOP(\"Header is not fast-locked\");\n-    bind(hdr_ok);\n-  }\n@@ -5123,2 +5114,26 @@\n-  \/\/ Load the new header (unlocked) into tmp1\n-  ori(tmp1, hdr, markWord::unlocked_value);\n+  Label unlocked, push_and_slow;\n+  const Register top = tmp1;\n+  const Register mark = tmp2;\n+  const Register t = tmp3;\n+\n+  \/\/ Check if obj is top of lock-stack.\n+  lwu(top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+  subw(top, top, oopSize);\n+  add(t, xthread, top);\n+  ld(t, Address(t));\n+  bne(obj, t, slow, \/* is_far *\/ true);\n+\n+  \/\/ Pop lock-stack.\n+  DEBUG_ONLY(add(t, xthread, top);)\n+  DEBUG_ONLY(sd(zr, Address(t));)\n+  sw(top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Check if recursive.\n+  add(t, xthread, top);\n+  ld(t, Address(t, -oopSize));\n+  beq(obj, t, unlocked);\n+\n+  \/\/ Not recursive. Check header for monitor (0b10).\n+  ld(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  test_bit(t, mark, exact_log2(markWord::monitor_value));\n+  bnez(t, push_and_slow);\n@@ -5126,8 +5141,0 @@\n-  \/\/ Try to swing header from locked to unlocked\n-  Label success;\n-  cmpxchgptr(hdr, tmp1, obj, tmp2, success, &slow);\n-  bind(success);\n-\n-  \/\/ After successful unlock, pop object from lock-stack\n-  lwu(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n-  subw(tmp1, tmp1, oopSize);\n@@ -5135,2 +5142,6 @@\n-  add(tmp2, xthread, tmp1);\n-  sd(zr, Address(tmp2, 0));\n+  \/\/ Check header not unlocked (0b01).\n+  Label not_unlocked;\n+  test_bit(t, mark, exact_log2(markWord::unlocked_value));\n+  beqz(t, not_unlocked);\n+  stop(\"lightweight_unlock already unlocked\");\n+  bind(not_unlocked);\n@@ -5138,1 +5149,17 @@\n-  sw(tmp1, Address(xthread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+  ori(t, mark, markWord::unlocked_value);\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::int64,\n+          \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, \/*result*\/ t);\n+  beq(mark, t, unlocked);\n+\n+  bind(push_and_slow);\n+  \/\/ Restore lock-stack and handle the unlock in runtime.\n+  DEBUG_ONLY(add(t, xthread, top);)\n+  DEBUG_ONLY(sd(obj, Address(t));)\n+  addw(top, top, oopSize);\n+  sw(top, Address(xthread, JavaThread::lock_stack_top_offset()));\n+  j(slow);\n+\n+  bind(unlocked);\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":97,"deletions":70,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -1522,2 +1522,2 @@\n-  void lightweight_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow);\n-  void lightweight_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow);\n+  void lightweight_lock(Register obj, Register tmp1, Register tmp2, Register tmp3, Label& slow);\n+  void lightweight_unlock(Register obj, Register tmp1, Register tmp2, Register tmp3, Label& slow);\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -10472,0 +10472,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -10475,1 +10476,1 @@\n-  ins_cost(LOAD_COST * 2 + STORE_COST * 3 + ALU_COST * 6 + BRANCH_COST * 3);\n+  ins_cost(10 * DEFAULT_COST);\n@@ -10488,0 +10489,1 @@\n+  predicate(LockingMode != LM_LIGHTWEIGHT);\n@@ -10491,1 +10493,1 @@\n-  ins_cost(LOAD_COST * 2 + STORE_COST + ALU_COST * 2 + BRANCH_COST * 4);\n+  ins_cost(10 * DEFAULT_COST);\n@@ -10501,0 +10503,32 @@\n+instruct cmpFastLockLightweight(rFlagsReg cr, iRegP object, iRegP_R10 box, iRegPNoSp tmp1, iRegPNoSp tmp2)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp1, TEMP tmp2, USE_KILL box);\n+\n+  ins_cost(10 * DEFAULT_COST);\n+  format %{ \"fastlock $object,$box\\t! kills $box,$tmp1,$tmp2 #@cmpFastLockLightweight\" %}\n+\n+  ins_encode %{\n+    __ fast_lock_lightweight($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n+\n+instruct cmpFastUnlockLightweight(rFlagsReg cr, iRegP object, iRegP_R10 box, iRegPNoSp tmp1, iRegPNoSp tmp2)\n+%{\n+  predicate(LockingMode == LM_LIGHTWEIGHT);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp1, TEMP tmp2, USE_KILL box);\n+\n+  ins_cost(10 * DEFAULT_COST);\n+  format %{ \"fastunlock $object,$box\\t! kills $box,$tmp1,$tmp2, #@cmpFastUnlockLightweight\" %}\n+\n+  ins_encode %{\n+    __ fast_unlock_lightweight($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":36,"deletions":2,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -1682,2 +1682,1 @@\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n-      __ ld(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n@@ -1809,3 +1808,0 @@\n-      __ ld(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ test_bit(t0, old_hdr, exact_log2(markWord::monitor_value));\n-      __ bnez(t0, slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -220,0 +220,2 @@\n+  constexpr static bool supports_recursive_lightweight_locking() { return true; }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"}]}