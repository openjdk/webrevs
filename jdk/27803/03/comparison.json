{"files":[{"patch":"@@ -132,2 +132,3 @@\n-      \/\/ NEON instructions support them. But the match rule support for them is profitable for\n-      \/\/ Vector API intrinsics.\n+      \/\/ NEON instructions support them. They use multiple instructions which is more\n+      \/\/ expensive in almost all cases where we would auto vectorize.\n+      \/\/ But the match rule support for them is profitable for Vector API intrinsics.\n@@ -138,0 +139,1 @@\n+          opcode == Op_MulVL ||\n@@ -141,0 +143,5 @@\n+          \/\/ Note: we could implement sequential reductions for these reduction operators, but\n+          \/\/       this will still almost never lead to speedups, because the sequential\n+          \/\/       reductions are latency limited along the reduction chain, and not\n+          \/\/       throughput limited. This is unlike unordered reductions (associative op)\n+          \/\/       and element-wise ops which are usually throughput limited.\n@@ -142,2 +149,1 @@\n-          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF ||\n-          opcode == Op_MulVL) {\n+          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -122,2 +122,3 @@\n-      \/\/ NEON instructions support them. But the match rule support for them is profitable for\n-      \/\/ Vector API intrinsics.\n+      \/\/ NEON instructions support them. They use multiple instructions which is more\n+      \/\/ expensive in almost all cases where we would auto vectorize.\n+      \/\/ But the match rule support for them is profitable for Vector API intrinsics.\n@@ -128,0 +129,1 @@\n+          opcode == Op_MulVL ||\n@@ -131,0 +133,5 @@\n+          \/\/ Note: we could implement sequential reductions for these reduction operators, but\n+          \/\/       this will still almost never lead to speedups, because the sequential\n+          \/\/       reductions are latency limited along the reduction chain, and not\n+          \/\/       throughput limited. This is unlike unordered reductions (associative op)\n+          \/\/       and element-wise ops which are usually throughput limited.\n@@ -132,2 +139,1 @@\n-          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF ||\n-          opcode == Op_MulVL) {\n+          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -45,3 +45,1 @@\n-  _do_vector_loop(phase()->C->do_vector_loop()),            \/\/ whether to do vectorization\/simd style\n-  _num_work_vecs(0),                                        \/\/ amount of vector work we have\n-  _num_reductions(0)                                        \/\/ amount of reduction work we have\n+  _do_vector_loop(phase()->C->do_vector_loop())             \/\/ whether to do vectorization\/simd style\n@@ -1570,12 +1568,0 @@\n-  \/\/ Count the number of reductions vs other vector ops, for the\n-  \/\/ reduction profitability heuristic.\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* pack = _packset.at(i);\n-    Node* n = pack->at(0);\n-    if (is_marked_reduction(n)) {\n-      _num_reductions++;\n-    } else {\n-      _num_work_vecs++;\n-    }\n-  }\n-\n@@ -1598,25 +1584,1 @@\n-      const Type *arith_type = p0->bottom_type();\n-      \/\/ This heuristic predicts that 2-element reductions for INT\/LONG are not\n-      \/\/ profitable. This heuristic was added in JDK-8078563. The argument\n-      \/\/ was that reductions are not just a single instruction, but multiple, and\n-      \/\/ hence it is not directly clear that they are profitable. If we only have\n-      \/\/ two elements per vector, then the performance gains from non-reduction\n-      \/\/ vectors are at most going from 2 scalar instructions to 1 vector instruction.\n-      \/\/ But a 2-element reduction vector goes from 2 scalar instructions to\n-      \/\/ 3 instructions (1 shuffle and two reduction ops).\n-      \/\/ However, this optimization assumes that these reductions stay in the loop\n-      \/\/ which may not be true any more in most cases after the introduction of:\n-      \/\/ See: VTransformReductionVectorNode::optimize_move_non_strict_order_reductions_out_of_loop\n-      \/\/ Hence, this heuristic has room for improvement.\n-      bool is_two_element_int_or_long_reduction = (size == 2) &&\n-                                                  (arith_type->basic_type() == T_INT ||\n-                                                   arith_type->basic_type() == T_LONG);\n-      if (is_two_element_int_or_long_reduction && AutoVectorizationOverrideProfitability != 2) {\n-#ifndef PRODUCT\n-        if (is_trace_superword_rejections()) {\n-          tty->print_cr(\"\\nPerformance heuristic: 2-element INT\/LONG reduction not profitable.\");\n-          tty->print_cr(\"  Can override with AutoVectorizationOverrideProfitability=2\");\n-        }\n-#endif\n-        return false;\n-      }\n+      const Type* arith_type = p0->bottom_type();\n@@ -1775,20 +1737,0 @@\n-    } else if (_num_work_vecs == _num_reductions && AutoVectorizationOverrideProfitability != 2) {\n-      \/\/ This heuristic predicts that the reduction is not profitable.\n-      \/\/ Reduction vectors can be expensive, because they require multiple\n-      \/\/ operations to fold all the lanes together. Hence, vectorizing the\n-      \/\/ reduction is not profitable on its own. Hence, we need a lot of\n-      \/\/ other \"work vectors\" that deliver performance improvements to\n-      \/\/ balance out the performance loss due to reductions.\n-      \/\/ This heuristic is a bit simplistic, and assumes that the reduction\n-      \/\/ vector stays in the loop. But in some cases, we can move the\n-      \/\/ reduction out of the loop, replacing it with a single vector op.\n-      \/\/ See: VTransformReductionVectorNode::optimize_move_non_strict_order_reductions_out_of_loop\n-      \/\/ Hence, this heuristic has room for improvement.\n-#ifndef PRODUCT\n-        if (is_trace_superword_rejections()) {\n-          tty->print_cr(\"\\nPerformance heuristic: not enough vectors in the loop to make\");\n-          tty->print_cr(\"  reduction profitable.\");\n-          tty->print_cr(\"  Can override with AutoVectorizationOverrideProfitability=2\");\n-        }\n-#endif\n-      return false;\n@@ -1953,1 +1895,11 @@\n-  if (vtransform.has_store_to_load_forwarding_failure()) { return false; }\n+\n+  if (!vtransform.is_profitable()) { return false; }\n+\n+  vtransform.apply();\n+  return true;\n+}\n+\n+\/\/ Check Cost-Model, and other heuristics.\n+\/\/ Can be overridden with AutoVectorizationOverrideProfitability.\n+bool VTransform::is_profitable() const {\n+  assert(_graph.is_scheduled(), \"must already be scheduled\");\n@@ -1957,1 +1909,1 @@\n-    if (is_trace_superword_any()) {\n+    if (_trace._info) {\n@@ -1964,2 +1916,26 @@\n-  vtransform.apply();\n-  return true;\n+  if (AutoVectorizationOverrideProfitability == 2) {\n+#ifndef PRODUCT\n+    if (_trace._info) {\n+      tty->print_cr(\"\\nForced vectorization, ignoring profitability (AutoVectorizationOverrideProfitability=2).\");\n+    }\n+#endif\n+    return true;\n+  }\n+\n+  \/\/ Note: currently we only do throughput-based cost-modeling. In the future, we could\n+  \/\/       also implement latency-based cost-modeling and take store-to-load-forwarding\n+  \/\/       failures into account as the latency between the load and store. This would\n+  \/\/       allow a more precise tradeoff between the forwarding failure penalty versus\n+  \/\/       the vectorization gains.\n+  if (has_store_to_load_forwarding_failure()) { return false; }\n+\n+  \/\/ Cost-model\n+  float scalar_cost = _vloop_analyzer.cost_for_scalar_loop();\n+  float vector_cost = cost_for_vector_loop();\n+#ifndef PRODUCT\n+  if (_trace._info) {\n+    tty->print_cr(\"\\nVTransform: scalar_cost = %.2f vs vector_cost = %.2f\",\n+                  scalar_cost, vector_cost);\n+  }\n+#endif\n+  return vector_cost < scalar_cost;\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":40,"deletions":64,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -552,2 +552,0 @@\n-  int            _num_work_vecs;   \/\/ Number of non memory vector operations\n-  int            _num_reductions;  \/\/ Number of reduction expressions applied\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-  flags(POINTERS,                   \"Trace VLoopPointers\") \\\n+  flags(POINTERS,                   \"Trace VLoopVPointers\") \\\n@@ -50,0 +50,2 @@\n+  flags(COST,                       \"Trace cost of VLoop (scalar) and VTransform (vector)\") \\\n+  flags(COST_VERBOSE,               \"Trace like COST, but more verbose\") \\\n","filename":"src\/hotspot\/share\/opto\/traceAutoVectorizationTag.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -290,1 +290,1 @@\n-    ::new (&_vpointers[pointers_idx]) VPointer(mem, _vloop);\n+    ::new (&_vpointers[pointers_idx]) VPointer(mem, _vloop, _pointer_expression_nodes);\n@@ -544,0 +544,102 @@\n+\/\/ Cost-model heuristic for nodes that do not contribute to computational\n+\/\/ cost inside the loop.\n+bool VLoopAnalyzer::has_zero_cost(Node* n) const {\n+  \/\/ Outside body?\n+  if (!_vloop.in_bb(n)) { return true; }\n+\n+  \/\/ Internal nodes of pointer expressions are most likely folded into\n+  \/\/ the load \/ store and have no additional cost.\n+  if (vpointers().is_in_pointer_expression(n)) { return true; }\n+\n+  \/\/ Not all AddP nodes can be detected in VPointer parsing, so\n+  \/\/ we filter them out here.\n+  \/\/ We don't want to explicitly model the cost of control flow,\n+  \/\/ since we have the same CFG structure before and after\n+  \/\/ vectorization: A loop head, a loop exit, with a backedge.\n+  if (n->is_AddP() || \/\/ Pointer expression\n+      n->is_CFG() ||  \/\/ CFG\n+      n->is_Phi() ||  \/\/ CFG\n+      n->is_Cmp() ||  \/\/ CFG\n+      n->is_Bool()) { \/\/ CFG\n+    return true;\n+  }\n+\n+  \/\/ All other nodes have a non-zero cost.\n+  return false;\n+}\n+\n+\/\/ Compute the cost over all operations in the (scalar) loop.\n+float VLoopAnalyzer::cost_for_scalar_loop() const {\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"\\nVLoopAnalyzer::cost_for_scalar_loop:\");\n+  }\n+#endif\n+\n+  float sum = 0;\n+  for (int j = 0; j < body().body().length(); j++) {\n+    Node* n = body().body().at(j);\n+    if (!has_zero_cost(n)) {\n+      float c = cost_for_scalar_node(n->Opcode());\n+      sum += c;\n+#ifndef PRODUCT\n+      if (_vloop.is_trace_cost_verbose()) {\n+        tty->print_cr(\"  -> cost = %.2f for %d %s\", c, n->_idx, n->Name());\n+      }\n+#endif\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"  total_cost = %.2f\", sum);\n+  }\n+#endif\n+  return sum;\n+}\n+\n+\/\/ For now, we use unit cost. We might refine that in the future.\n+\/\/ If needed, we could also use platform specific costs, if the\n+\/\/ default here is not accurate enough.\n+float VLoopAnalyzer::cost_for_scalar_node(int opcode) const {\n+  float c = 1;\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"  cost = %.2f opc=%s\", c, NodeClassNames[opcode]);\n+  }\n+#endif\n+  return c;\n+}\n+\n+\/\/ For now, we use unit cost. We might refine that in the future.\n+\/\/ If needed, we could also use platform specific costs, if the\n+\/\/ default here is not accurate enough.\n+float VLoopAnalyzer::cost_for_vector_node(int opcode, int vlen, BasicType bt) const {\n+  float c = 1;\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"  cost = %.2f opc=%s vlen=%d bt=%s\",\n+                  c, NodeClassNames[opcode], vlen, type2name(bt));\n+  }\n+#endif\n+  return c;\n+}\n+\n+\/\/ For now, we use unit cost, i.e. we count the number of backend instructions\n+\/\/ that the vtnode will use. We might refine that in the future.\n+\/\/ If needed, we could also use platform specific costs, if the\n+\/\/ default here is not accurate enough.\n+float VLoopAnalyzer::cost_for_vector_reduction_node(int opcode, int vlen, BasicType bt, bool requires_strict_order) const {\n+  \/\/ Each reduction is composed of multiple instructions, each estimated with a unit cost.\n+  \/\/                                Linear: shuffle and reduce    Recursive: shuffle and reduce\n+  float c = requires_strict_order ? 2 * vlen                    : 2 * exact_log2(vlen);\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"  cost = %.2f opc=%s vlen=%d bt=%s requires_strict_order=%s\",\n+                  c, NodeClassNames[opcode], vlen, type2name(bt),\n+                  requires_strict_order ? \"true\" : \"false\");\n+  }\n+#endif\n+  return c;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/vectorization.cpp","additions":103,"deletions":1,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -212,0 +212,8 @@\n+  bool is_trace_cost() const {\n+    return _vtrace.is_trace(TraceAutoVectorizationTag::COST);\n+  }\n+\n+  bool is_trace_cost_verbose() const {\n+    return _vtrace.is_trace(TraceAutoVectorizationTag::COST_VERBOSE);\n+  }\n+\n@@ -587,0 +595,26 @@\n+\/\/ Mark all nodes from the loop that are part of any VPointer expression.\n+class PointerExpressionNodes : public MemPointerParserCallback {\n+private:\n+  const VLoop&     _vloop;\n+  const VLoopBody& _body;\n+  VectorSet        _in_pointer_expression;\n+\n+public:\n+  PointerExpressionNodes(Arena* arena,\n+                         const VLoop& vloop,\n+                         const VLoopBody& body) :\n+    _vloop(vloop),\n+    _body(body),\n+    _in_pointer_expression(arena) {}\n+\n+  virtual void callback(Node* n) override {\n+    if (!_vloop.in_bb(n)) { return; }\n+    _in_pointer_expression.set(_body.bb_idx(n));\n+  }\n+\n+  bool contains(const Node* n) const {\n+    if (!_vloop.in_bb(n)) { return false; }\n+    return _in_pointer_expression.test(_body.bb_idx(n));\n+  }\n+};\n+\n@@ -602,0 +636,3 @@\n+  \/\/ Mark all nodes that are part of any pointers expression.\n+  PointerExpressionNodes _pointer_expression_nodes;\n+\n@@ -613,1 +650,2 @@\n-                        -1) {}\n+                        -1),\n+    _pointer_expression_nodes(arena, _vloop, _body) {}\n@@ -620,0 +658,4 @@\n+  bool is_in_pointer_expression(const Node* n) const {\n+    return _pointer_expression_nodes.contains(n);\n+  }\n+\n@@ -813,0 +855,9 @@\n+  \/\/ Compute the cost of the (scalar) body.\n+  float cost_for_scalar_loop() const;\n+  bool has_zero_cost(Node* n) const;\n+\n+  \/\/ Cost-modeling with tracing.\n+  float cost_for_scalar_node(int opcode) const;\n+  float cost_for_vector_node(int opcode, int vlen, BasicType bt) const;\n+  float cost_for_vector_reduction_node(int opcode, int vlen, BasicType bt, bool requires_strict_order) const;\n+\n","filename":"src\/hotspot\/share\/opto\/vectorization.hpp","additions":52,"deletions":1,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -189,0 +189,93 @@\n+\/\/ Find all nodes that in the loop, in a 2-phase process:\n+\/\/ - First, find all nodes that are not before the loop:\n+\/\/   - loop-phis\n+\/\/   - loads and stores that are in the loop\n+\/\/   - and all their transitive uses.\n+\/\/ - Second, we find all nodes that are not after the loop:\n+\/\/   - backedges\n+\/\/   - loads and stores that are in the loop\n+\/\/   - and all their transitive uses.\n+\/\/\n+\/\/ in_loop: vtn->_idx -> bool\n+void VTransformGraph::mark_vtnodes_in_loop(VectorSet& in_loop) const {\n+  assert(is_scheduled(), \"must already be scheduled\");\n+\n+  \/\/ Phase 1: find all nodes that are not before the loop.\n+  VectorSet is_not_before_loop;\n+  for (int i = 0; i < _schedule.length(); i++) {\n+    VTransformNode* vtn = _schedule.at(i);\n+    \/\/ Is vtn a loop-phi?\n+    if (vtn->isa_LoopPhi() != nullptr ||\n+        vtn->is_load_or_store_in_loop()) {\n+      is_not_before_loop.set(vtn->_idx);\n+      continue;\n+    }\n+    \/\/ Or one of its transitive uses?\n+    for (uint j = 0; j < vtn->req(); j++) {\n+      VTransformNode* def = vtn->in_req(j);\n+      if (def != nullptr && is_not_before_loop.test(def->_idx)) {\n+        is_not_before_loop.set(vtn->_idx);\n+        break;\n+      }\n+    }\n+  }\n+\n+  \/\/ Phase 2: find all nodes that are not after the loop.\n+  for (int i = _schedule.length()-1; i >= 0; i--) {\n+    VTransformNode* vtn = _schedule.at(i);\n+    if (!is_not_before_loop.test(vtn->_idx)) { continue; }\n+    \/\/ Is load or store?\n+    if (vtn->is_load_or_store_in_loop()) {\n+        in_loop.set(vtn->_idx);\n+        continue;\n+    }\n+    for (uint i = 0; i < vtn->out_strong_edges(); i++) {\n+      VTransformNode* use = vtn->out_strong_edge(i);\n+      \/\/ Or is vtn a backedge or one of its transitive defs?\n+      if (in_loop.test(use->_idx) ||\n+          use->isa_LoopPhi() != nullptr) {\n+        in_loop.set(vtn->_idx);\n+        break;\n+      }\n+    }\n+  }\n+}\n+\n+float VTransformGraph::cost_for_vector_loop() const {\n+  assert(is_scheduled(), \"must already be scheduled\");\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"\\nVTransformGraph::cost_for_vector_loop:\");\n+  }\n+#endif\n+\n+  \/\/ We only want to count the cost of nodes that are in the loop.\n+  \/\/ This is especially important for cases where we were able to move\n+  \/\/ some nodes outside the loop during VTransform::optimize, e.g.:\n+  \/\/ VTransformReductionVectorNode::optimize_move_non_strict_order_reductions_out_of_loop\n+  ResourceMark rm;\n+  VectorSet in_loop; \/\/ vtn->_idx -> bool\n+  mark_vtnodes_in_loop(in_loop);\n+\n+  float sum = 0;\n+  for (int i = 0; i < _schedule.length(); i++) {\n+    VTransformNode* vtn = _schedule.at(i);\n+    if (!in_loop.test(vtn->_idx)) { continue; }\n+    float c = vtn->cost(_vloop_analyzer);\n+    sum += c;\n+#ifndef PRODUCT\n+    if (c != 0 && _vloop.is_trace_cost_verbose()) {\n+      tty->print(\"  -> cost = %.2f for \", c);\n+      vtn->print();\n+    }\n+#endif\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_cost()) {\n+    tty->print_cr(\"  total_cost = %.2f\", sum);\n+  }\n+#endif\n+  return sum;\n+}\n+\n@@ -834,0 +927,6 @@\n+float VTransformMemopScalarNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  \/\/ This is an identity transform, but loads and stores must be counted.\n+  assert(!vloop_analyzer.has_zero_cost(_node), \"memop nodes must be counted\");\n+  return vloop_analyzer.cost_for_scalar_node(_node->Opcode());\n+}\n+\n@@ -846,0 +945,10 @@\n+float VTransformDataScalarNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  \/\/ Since this is an identity transform, we may have nodes that also\n+  \/\/ VLoopAnalyzer::cost does not count for the scalar loop.\n+  if (vloop_analyzer.has_zero_cost(_node)) {\n+    return 0;\n+  } else {\n+    return vloop_analyzer.cost_for_scalar_node(_node->Opcode());\n+  }\n+}\n+\n@@ -898,0 +1007,4 @@\n+float VTransformReplicateNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  return vloop_analyzer.cost_for_vector_node(Op_Replicate, _vlen, _element_type);\n+}\n+\n@@ -905,0 +1018,4 @@\n+float VTransformConvI2LNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  return vloop_analyzer.cost_for_scalar_node(Op_ConvI2L);\n+}\n+\n@@ -912,0 +1029,6 @@\n+float VTransformShiftCountNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  int shift_count_opc = VectorNode::shift_count_opcode(_shift_opcode);\n+  return vloop_analyzer.cost_for_scalar_node(Op_AndI) +\n+         vloop_analyzer.cost_for_vector_node(shift_count_opc, _vlen, _element_bt);\n+}\n+\n@@ -927,0 +1050,3 @@\n+float VTransformPopulateIndexNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  return vloop_analyzer.cost_for_vector_node(Op_PopulateIndex, _vlen, _element_bt);\n+}\n@@ -939,0 +1065,4 @@\n+float VTransformElementWiseVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  return vloop_analyzer.cost_for_vector_node(_vector_opcode, vector_length(), element_basic_type());\n+}\n+\n@@ -957,0 +1087,6 @@\n+float VTransformElementWiseLongOpWithCastToIntVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  int vopc = VectorNode::opcode(scalar_opcode(), element_basic_type());\n+  return vloop_analyzer.cost_for_vector_node(vopc, vector_length(), element_basic_type()) +\n+         vloop_analyzer.cost_for_vector_node(Op_VectorCastL2X, vector_length(), T_INT);\n+}\n+\n@@ -972,0 +1108,4 @@\n+float VTransformReinterpretVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  return vloop_analyzer.cost_for_vector_node(Op_VectorReinterpret, vector_length(), element_basic_type());\n+}\n+\n@@ -984,0 +1124,5 @@\n+float VTransformBoolVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  assert(scalar_opcode() == Op_Bool, \"\");\n+  return vloop_analyzer.cost_for_vector_node(Op_VectorMaskCmp, vector_length(), element_basic_type());\n+}\n+\n@@ -1104,4 +1249,4 @@\n-  if (!Matcher::match_rule_supported_vector(vopc, vlen, bt)) {\n-    DEBUG_ONLY( this->print(); )\n-    assert(false, \"do not have normal vector op for this reduction\");\n-    return false; \/\/ not implemented\n+  if (!Matcher::match_rule_supported_auto_vectorization(vopc, vlen, bt)) {\n+    \/\/ The element-wise vector operation needed for the vector accumulator\n+    \/\/ is not implemented \/ supported.\n+    return false;\n@@ -1239,0 +1384,8 @@\n+float VTransformReductionVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  uint vlen    = vector_length();\n+  BasicType bt = element_basic_type();\n+  int vopc = vector_reduction_opcode();\n+  bool requires_strict_order = ReductionNode::auto_vectorization_requires_strict_order(vopc);\n+  return vloop_analyzer.cost_for_vector_reduction_node(vopc, vlen, bt, requires_strict_order);\n+}\n+\n@@ -1248,0 +1401,6 @@\n+float VTransformLoadVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  uint vlen    = vector_length();\n+  BasicType bt = element_basic_type();\n+  return vloop_analyzer.cost_for_vector_node(Op_LoadVector, vlen, bt);\n+}\n+\n@@ -1277,0 +1436,6 @@\n+float VTransformStoreVectorNode::cost(const VLoopAnalyzer& vloop_analyzer) const {\n+  uint vlen    = vector_length();\n+  BasicType bt = element_basic_type();\n+  return vloop_analyzer.cost_for_vector_node(Op_StoreVector, vlen, bt);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/vtransform.cpp","additions":169,"deletions":4,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -54,0 +54,4 @@\n+\/\/ - Cost-Model:\n+\/\/   - We use a cost-model as a heuristic to determine if vectorization is profitable.\n+\/\/     Compute the cost of the loop with and without vectorization.\n+\/\/\n@@ -193,0 +197,1 @@\n+  float cost_for_vector_loop() const;\n@@ -203,0 +208,1 @@\n+  void mark_vtnodes_in_loop(VectorSet& in_loop) const;\n@@ -255,0 +261,2 @@\n+  bool is_profitable() const;\n+  float cost_for_vector_loop() const { return _graph.cost_for_vector_loop(); }\n@@ -552,0 +560,2 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const = 0;\n+\n@@ -582,0 +592,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -598,0 +609,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -615,0 +627,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override { return 0; }\n@@ -632,0 +645,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override { return 0; }\n@@ -658,0 +672,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override { ShouldNotReachHere(); }\n@@ -671,0 +686,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -680,0 +696,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -694,0 +711,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -707,0 +725,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -772,0 +791,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -784,0 +804,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -794,0 +815,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -814,0 +836,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override { return 0; }\n@@ -826,0 +849,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -838,0 +862,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -880,0 +905,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n@@ -891,0 +917,1 @@\n+  virtual float cost(const VLoopAnalyzer& vloop_analyzer) const override;\n","filename":"src\/hotspot\/share\/opto\/vtransform.hpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -413,3 +413,0 @@\n-    \/\/ Not vectorized: simple addition not profitable, see JDK-8307516. NOTE:\n-    \/\/ This check does not document the _desired_ behavior of the system but\n-    \/\/ the current behavior (no vectorization)\n@@ -417,2 +414,5 @@\n-    @IR(counts = { IRNode.LOAD_VECTOR_I, \"= 0\",\n-                   IRNode.STORE_VECTOR,  \"= 0\" })\n+    @IR(counts = { IRNode.LOAD_VECTOR_I,     \"> 0\",\n+                   IRNode.ADD_REDUCTION_VI,  \"> 0\",\n+                   IRNode.ADD_VI,            \"> 0\" })\n+    \/\/ The reduction is moved outside the loop, and we use a\n+    \/\/ element-wise accumulator inside the loop.\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/cr7200264\/TestIntVect.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -118,1 +118,1 @@\n-        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 2\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"},\n@@ -121,1 +121,1 @@\n-        applyIf = {\"AutoVectorizationOverrideProfitability\", \"< 2\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"},\n@@ -123,6 +123,7 @@\n-    \/\/ Current heuristics say that this simple int reduction is not profitable.\n-    \/\/ But it would actually be profitable, since we are able to move the\n-    \/\/ reduction out of the loop (we can reorder the reduction). When moving\n-    \/\/ the reduction out of the loop, we instead accumulate with a simple\n-    \/\/ ADD_VI inside the loop.\n-    \/\/ See: JDK-8307516 JDK-8345044\n+    \/\/ We are able to vectorize the reduction. But on its own, that would\n+    \/\/ not reduce the cost sufficiently in all cases, because vectorized\n+    \/\/ reduction nodes are expensive. But since integer addition is associative\n+    \/\/ we can move the reduction vector out of the loop. Instead, we accumulate\n+    \/\/ with a simple ADD_VI inside the loop, which is very cheap. After the\n+    \/\/ loop, we only need to use the vectorized reduction once, to collapse\n+    \/\/ the partial sums contained in the lanes.\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestAutoVectorizationOverrideProfitability.java","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -0,0 +1,2452 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=no-vectorization\n+ * @bug 8340093\n+ * @summary Test vectorization of reduction loops.\n+ * @library \/test\/lib \/\n+ * @run driver compiler.loopopts.superword.TestReductions P0\n+ *\/\n+\n+\/*\n+ * @test id=vanilla\n+ * @bug 8340093\n+ * @summary Test vectorization of reduction loops.\n+ * @library \/test\/lib \/\n+ * @run driver compiler.loopopts.superword.TestReductions P1\n+ *\/\n+\n+\/*\n+ * @test id=force-vectorization\n+ * @bug 8340093\n+ * @summary Test vectorization of reduction loops.\n+ * @library \/test\/lib \/\n+ * @run driver compiler.loopopts.superword.TestReductions P2\n+ *\/\n+\n+package compiler.loopopts.superword;\n+\n+import java.util.Map;\n+import java.util.HashMap;\n+\n+import compiler.lib.ir_framework.*;\n+import compiler.lib.verify.*;\n+import static compiler.lib.generators.Generators.G;\n+import compiler.lib.generators.Generator;\n+\n+\/**\n+ * Note: there is a corresponding JMH benchmark:\n+ * test\/micro\/org\/openjdk\/bench\/vm\/compiler\/VectorReduction2.java\n+ *\/\n+public class TestReductions {\n+    private static int SIZE = 1024*8;\n+    private static final Generator<Integer> GEN_I = G.ints();\n+    private static final Generator<Long>    GEN_L = G.longs();\n+    private static final Generator<Float>   GEN_F = G.floats();\n+    private static final Generator<Double>  GEN_D = G.doubles();\n+\n+    private static byte[] in1B   = fillRandom(new byte[SIZE]);\n+    private static byte[] in2B   = fillRandom(new byte[SIZE]);\n+    private static byte[] in3B   = fillRandom(new byte[SIZE]);\n+    private static char[] in1C   = fillRandom(new char[SIZE]);\n+    private static char[] in2C   = fillRandom(new char[SIZE]);\n+    private static char[] in3C   = fillRandom(new char[SIZE]);\n+    private static short[] in1S  = fillRandom(new short[SIZE]);\n+    private static short[] in2S  = fillRandom(new short[SIZE]);\n+    private static short[] in3S  = fillRandom(new short[SIZE]);\n+\n+    private static int[] in1I    = fillRandom(new int[SIZE]);\n+    private static int[] in2I    = fillRandom(new int[SIZE]);\n+    private static int[] in3I    = fillRandom(new int[SIZE]);\n+    private static long[] in1L   = fillRandom(new long[SIZE]);\n+    private static long[] in2L   = fillRandom(new long[SIZE]);\n+    private static long[] in3L   = fillRandom(new long[SIZE]);\n+\n+    private static float[] in1F  = fillRandom(new float[SIZE]);\n+    private static float[] in2F  = fillRandom(new float[SIZE]);\n+    private static float[] in3F  = fillRandom(new float[SIZE]);\n+    private static double[] in1D = fillRandom(new double[SIZE]);\n+    private static double[] in2D = fillRandom(new double[SIZE]);\n+    private static double[] in3D = fillRandom(new double[SIZE]);\n+\n+    interface TestFunction {\n+        Object run();\n+    }\n+\n+    \/\/ Map of test names to tests.\n+    Map<String,TestFunction> tests = new HashMap<String,TestFunction>();\n+\n+    \/\/ Map of gold, the results from the first run (before compilation), one per tests entry.\n+    Map<String,Object> golds = new HashMap<String,Object>();\n+\n+    public static void main(String[] args) {\n+        TestFramework framework = new TestFramework(TestReductions.class);\n+        switch (args[0]) {\n+            case \"P0\" -> { framework.addFlags(\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:AutoVectorizationOverrideProfitability=0\"); }\n+            case \"P1\" -> { framework.addFlags(\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:AutoVectorizationOverrideProfitability=1\"); }\n+            \/\/ Note: increasing the node count limit also helps in some cases.\n+            case \"P2\" -> { framework.addFlags(\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:AutoVectorizationOverrideProfitability=2\", \"-XX:LoopUnrollLimit=1000\"); }\n+            default -> { throw new RuntimeException(\"Test argument not recognized: \" + args[0]); }\n+        };\n+        framework.start();\n+    }\n+\n+    public TestReductions() {\n+        \/\/ Add all tests to list\n+        tests.put(\"byteAndSimple\",       TestReductions::byteAndSimple);\n+        tests.put(\"byteOrSimple\",        TestReductions::byteOrSimple);\n+        tests.put(\"byteXorSimple\",       TestReductions::byteXorSimple);\n+        tests.put(\"byteAddSimple\",       TestReductions::byteAddSimple);\n+        tests.put(\"byteMulSimple\",       TestReductions::byteMulSimple);\n+        tests.put(\"byteMinSimple\",       TestReductions::byteMinSimple);\n+        tests.put(\"byteMaxSimple\",       TestReductions::byteMaxSimple);\n+        tests.put(\"byteAndDotProduct\",   TestReductions::byteAndDotProduct);\n+        tests.put(\"byteOrDotProduct\",    TestReductions::byteOrDotProduct);\n+        tests.put(\"byteXorDotProduct\",   TestReductions::byteXorDotProduct);\n+        tests.put(\"byteAddDotProduct\",   TestReductions::byteAddDotProduct);\n+        tests.put(\"byteMulDotProduct\",   TestReductions::byteMulDotProduct);\n+        tests.put(\"byteMinDotProduct\",   TestReductions::byteMinDotProduct);\n+        tests.put(\"byteMaxDotProduct\",   TestReductions::byteMaxDotProduct);\n+        tests.put(\"byteAndBig\",          TestReductions::byteAndBig);\n+        tests.put(\"byteOrBig\",           TestReductions::byteOrBig);\n+        tests.put(\"byteXorBig\",          TestReductions::byteXorBig);\n+        tests.put(\"byteAddBig\",          TestReductions::byteAddBig);\n+        tests.put(\"byteMulBig\",          TestReductions::byteMulBig);\n+        tests.put(\"byteMinBig\",          TestReductions::byteMinBig);\n+        tests.put(\"byteMaxBig\",          TestReductions::byteMaxBig);\n+\n+        tests.put(\"charAndSimple\",       TestReductions::charAndSimple);\n+        tests.put(\"charOrSimple\",        TestReductions::charOrSimple);\n+        tests.put(\"charXorSimple\",       TestReductions::charXorSimple);\n+        tests.put(\"charAddSimple\",       TestReductions::charAddSimple);\n+        tests.put(\"charMulSimple\",       TestReductions::charMulSimple);\n+        tests.put(\"charMinSimple\",       TestReductions::charMinSimple);\n+        tests.put(\"charMaxSimple\",       TestReductions::charMaxSimple);\n+        tests.put(\"charAndDotProduct\",   TestReductions::charAndDotProduct);\n+        tests.put(\"charOrDotProduct\",    TestReductions::charOrDotProduct);\n+        tests.put(\"charXorDotProduct\",   TestReductions::charXorDotProduct);\n+        tests.put(\"charAddDotProduct\",   TestReductions::charAddDotProduct);\n+        tests.put(\"charMulDotProduct\",   TestReductions::charMulDotProduct);\n+        tests.put(\"charMinDotProduct\",   TestReductions::charMinDotProduct);\n+        tests.put(\"charMaxDotProduct\",   TestReductions::charMaxDotProduct);\n+        tests.put(\"charAndBig\",          TestReductions::charAndBig);\n+        tests.put(\"charOrBig\",           TestReductions::charOrBig);\n+        tests.put(\"charXorBig\",          TestReductions::charXorBig);\n+        tests.put(\"charAddBig\",          TestReductions::charAddBig);\n+        tests.put(\"charMulBig\",          TestReductions::charMulBig);\n+        tests.put(\"charMinBig\",          TestReductions::charMinBig);\n+        tests.put(\"charMaxBig\",          TestReductions::charMaxBig);\n+\n+        tests.put(\"shortAndSimple\",      TestReductions::shortAndSimple);\n+        tests.put(\"shortOrSimple\",       TestReductions::shortOrSimple);\n+        tests.put(\"shortXorSimple\",      TestReductions::shortXorSimple);\n+        tests.put(\"shortAddSimple\",      TestReductions::shortAddSimple);\n+        tests.put(\"shortMulSimple\",      TestReductions::shortMulSimple);\n+        tests.put(\"shortMinSimple\",      TestReductions::shortMinSimple);\n+        tests.put(\"shortMaxSimple\",      TestReductions::shortMaxSimple);\n+        tests.put(\"shortAndDotProduct\",  TestReductions::shortAndDotProduct);\n+        tests.put(\"shortOrDotProduct\",   TestReductions::shortOrDotProduct);\n+        tests.put(\"shortXorDotProduct\",  TestReductions::shortXorDotProduct);\n+        tests.put(\"shortAddDotProduct\",  TestReductions::shortAddDotProduct);\n+        tests.put(\"shortMulDotProduct\",  TestReductions::shortMulDotProduct);\n+        tests.put(\"shortMinDotProduct\",  TestReductions::shortMinDotProduct);\n+        tests.put(\"shortMaxDotProduct\",  TestReductions::shortMaxDotProduct);\n+        tests.put(\"shortAndBig\",         TestReductions::shortAndBig);\n+        tests.put(\"shortOrBig\",          TestReductions::shortOrBig);\n+        tests.put(\"shortXorBig\",         TestReductions::shortXorBig);\n+        tests.put(\"shortAddBig\",         TestReductions::shortAddBig);\n+        tests.put(\"shortMulBig\",         TestReductions::shortMulBig);\n+        tests.put(\"shortMinBig\",         TestReductions::shortMinBig);\n+        tests.put(\"shortMaxBig\",         TestReductions::shortMaxBig);\n+\n+        tests.put(\"intAndSimple\",        TestReductions::intAndSimple);\n+        tests.put(\"intOrSimple\",         TestReductions::intOrSimple);\n+        tests.put(\"intXorSimple\",        TestReductions::intXorSimple);\n+        tests.put(\"intAddSimple\",        TestReductions::intAddSimple);\n+        tests.put(\"intMulSimple\",        TestReductions::intMulSimple);\n+        tests.put(\"intMinSimple\",        TestReductions::intMinSimple);\n+        tests.put(\"intMaxSimple\",        TestReductions::intMaxSimple);\n+        tests.put(\"intAndDotProduct\",    TestReductions::intAndDotProduct);\n+        tests.put(\"intOrDotProduct\",     TestReductions::intOrDotProduct);\n+        tests.put(\"intXorDotProduct\",    TestReductions::intXorDotProduct);\n+        tests.put(\"intAddDotProduct\",    TestReductions::intAddDotProduct);\n+        tests.put(\"intMulDotProduct\",    TestReductions::intMulDotProduct);\n+        tests.put(\"intMinDotProduct\",    TestReductions::intMinDotProduct);\n+        tests.put(\"intMaxDotProduct\",    TestReductions::intMaxDotProduct);\n+        tests.put(\"intAndBig\",           TestReductions::intAndBig);\n+        tests.put(\"intOrBig\",            TestReductions::intOrBig);\n+        tests.put(\"intXorBig\",           TestReductions::intXorBig);\n+        tests.put(\"intAddBig\",           TestReductions::intAddBig);\n+        tests.put(\"intMulBig\",           TestReductions::intMulBig);\n+        tests.put(\"intMinBig\",           TestReductions::intMinBig);\n+        tests.put(\"intMaxBig\",           TestReductions::intMaxBig);\n+\n+        tests.put(\"longAndSimple\",       TestReductions::longAndSimple);\n+        tests.put(\"longOrSimple\",        TestReductions::longOrSimple);\n+        tests.put(\"longXorSimple\",       TestReductions::longXorSimple);\n+        tests.put(\"longAddSimple\",       TestReductions::longAddSimple);\n+        tests.put(\"longMulSimple\",       TestReductions::longMulSimple);\n+        tests.put(\"longMinSimple\",       TestReductions::longMinSimple);\n+        tests.put(\"longMaxSimple\",       TestReductions::longMaxSimple);\n+        tests.put(\"longAndDotProduct\",   TestReductions::longAndDotProduct);\n+        tests.put(\"longOrDotProduct\",    TestReductions::longOrDotProduct);\n+        tests.put(\"longXorDotProduct\",   TestReductions::longXorDotProduct);\n+        tests.put(\"longAddDotProduct\",   TestReductions::longAddDotProduct);\n+        tests.put(\"longMulDotProduct\",   TestReductions::longMulDotProduct);\n+        tests.put(\"longMinDotProduct\",   TestReductions::longMinDotProduct);\n+        tests.put(\"longMaxDotProduct\",   TestReductions::longMaxDotProduct);\n+        tests.put(\"longAndBig\",          TestReductions::longAndBig);\n+        tests.put(\"longOrBig\",           TestReductions::longOrBig);\n+        tests.put(\"longXorBig\",          TestReductions::longXorBig);\n+        tests.put(\"longAddBig\",          TestReductions::longAddBig);\n+        tests.put(\"longMulBig\",          TestReductions::longMulBig);\n+        tests.put(\"longMinBig\",          TestReductions::longMinBig);\n+        tests.put(\"longMaxBig\",          TestReductions::longMaxBig);\n+\n+        tests.put(\"floatAddSimple\",      TestReductions::floatAddSimple);\n+        tests.put(\"floatMulSimple\",      TestReductions::floatMulSimple);\n+        tests.put(\"floatMinSimple\",      TestReductions::floatMinSimple);\n+        tests.put(\"floatMaxSimple\",      TestReductions::floatMaxSimple);\n+        tests.put(\"floatAddDotProduct\",  TestReductions::floatAddDotProduct);\n+        tests.put(\"floatMulDotProduct\",  TestReductions::floatMulDotProduct);\n+        tests.put(\"floatMinDotProduct\",  TestReductions::floatMinDotProduct);\n+        tests.put(\"floatMaxDotProduct\",  TestReductions::floatMaxDotProduct);\n+        tests.put(\"floatAddBig\",         TestReductions::floatAddBig);\n+        tests.put(\"floatMulBig\",         TestReductions::floatMulBig);\n+        tests.put(\"floatMinBig\",         TestReductions::floatMinBig);\n+        tests.put(\"floatMaxBig\",         TestReductions::floatMaxBig);\n+\n+        tests.put(\"doubleAddSimple\",     TestReductions::doubleAddSimple);\n+        tests.put(\"doubleMulSimple\",     TestReductions::doubleMulSimple);\n+        tests.put(\"doubleMinSimple\",     TestReductions::doubleMinSimple);\n+        tests.put(\"doubleMaxSimple\",     TestReductions::doubleMaxSimple);\n+        tests.put(\"doubleAddDotProduct\", TestReductions::doubleAddDotProduct);\n+        tests.put(\"doubleMulDotProduct\", TestReductions::doubleMulDotProduct);\n+        tests.put(\"doubleMinDotProduct\", TestReductions::doubleMinDotProduct);\n+        tests.put(\"doubleMaxDotProduct\", TestReductions::doubleMaxDotProduct);\n+        tests.put(\"doubleAddBig\",        TestReductions::doubleAddBig);\n+        tests.put(\"doubleMulBig\",        TestReductions::doubleMulBig);\n+        tests.put(\"doubleMinBig\",        TestReductions::doubleMinBig);\n+        tests.put(\"doubleMaxBig\",        TestReductions::doubleMaxBig);\n+\n+        \/\/ Compute gold value for all test methods before compilation\n+        for (Map.Entry<String,TestFunction> entry : tests.entrySet()) {\n+            String name = entry.getKey();\n+            TestFunction test = entry.getValue();\n+            Object gold = test.run();\n+            golds.put(name, gold);\n+        }\n+    }\n+\n+    @Warmup(100)\n+    @Run(test = {\"byteAndSimple\",\n+                 \"byteOrSimple\",\n+                 \"byteXorSimple\",\n+                 \"byteAddSimple\",\n+                 \"byteMulSimple\",\n+                 \"byteMinSimple\",\n+                 \"byteMaxSimple\",\n+                 \"byteAndDotProduct\",\n+                 \"byteOrDotProduct\",\n+                 \"byteXorDotProduct\",\n+                 \"byteAddDotProduct\",\n+                 \"byteMulDotProduct\",\n+                 \"byteMinDotProduct\",\n+                 \"byteMaxDotProduct\",\n+                 \"byteAndBig\",\n+                 \"byteOrBig\",\n+                 \"byteXorBig\",\n+                 \"byteAddBig\",\n+                 \"byteMulBig\",\n+                 \"byteMinBig\",\n+                 \"byteMaxBig\",\n+\n+                 \"charAndSimple\",\n+                 \"charOrSimple\",\n+                 \"charXorSimple\",\n+                 \"charAddSimple\",\n+                 \"charMulSimple\",\n+                 \"charMinSimple\",\n+                 \"charMaxSimple\",\n+                 \"charAndDotProduct\",\n+                 \"charOrDotProduct\",\n+                 \"charXorDotProduct\",\n+                 \"charAddDotProduct\",\n+                 \"charMulDotProduct\",\n+                 \"charMinDotProduct\",\n+                 \"charMaxDotProduct\",\n+                 \"charAndBig\",\n+                 \"charOrBig\",\n+                 \"charXorBig\",\n+                 \"charAddBig\",\n+                 \"charMulBig\",\n+                 \"charMinBig\",\n+                 \"charMaxBig\",\n+\n+                 \"shortAndSimple\",\n+                 \"shortOrSimple\",\n+                 \"shortXorSimple\",\n+                 \"shortAddSimple\",\n+                 \"shortMulSimple\",\n+                 \"shortMinSimple\",\n+                 \"shortMaxSimple\",\n+                 \"shortAndDotProduct\",\n+                 \"shortOrDotProduct\",\n+                 \"shortXorDotProduct\",\n+                 \"shortAddDotProduct\",\n+                 \"shortMulDotProduct\",\n+                 \"shortMinDotProduct\",\n+                 \"shortMaxDotProduct\",\n+                 \"shortAndBig\",\n+                 \"shortOrBig\",\n+                 \"shortXorBig\",\n+                 \"shortAddBig\",\n+                 \"shortMulBig\",\n+                 \"shortMinBig\",\n+                 \"shortMaxBig\",\n+\n+                 \"intAndSimple\",\n+                 \"intOrSimple\",\n+                 \"intXorSimple\",\n+                 \"intAddSimple\",\n+                 \"intMulSimple\",\n+                 \"intMinSimple\",\n+                 \"intMaxSimple\",\n+                 \"intAndDotProduct\",\n+                 \"intOrDotProduct\",\n+                 \"intXorDotProduct\",\n+                 \"intAddDotProduct\",\n+                 \"intMulDotProduct\",\n+                 \"intMinDotProduct\",\n+                 \"intMaxDotProduct\",\n+                 \"intAndBig\",\n+                 \"intOrBig\",\n+                 \"intXorBig\",\n+                 \"intAddBig\",\n+                 \"intMulBig\",\n+                 \"intMinBig\",\n+                 \"intMaxBig\",\n+\n+                 \"longAndSimple\",\n+                 \"longOrSimple\",\n+                 \"longXorSimple\",\n+                 \"longAddSimple\",\n+                 \"longMulSimple\",\n+                 \"longMinSimple\",\n+                 \"longMaxSimple\",\n+                 \"longAndDotProduct\",\n+                 \"longOrDotProduct\",\n+                 \"longXorDotProduct\",\n+                 \"longAddDotProduct\",\n+                 \"longMulDotProduct\",\n+                 \"longMinDotProduct\",\n+                 \"longMaxDotProduct\",\n+                 \"longAndBig\",\n+                 \"longOrBig\",\n+                 \"longXorBig\",\n+                 \"longAddBig\",\n+                 \"longMulBig\",\n+                 \"longMinBig\",\n+                 \"longMaxBig\",\n+\n+                 \"floatAddSimple\",\n+                 \"floatMulSimple\",\n+                 \"floatMinSimple\",\n+                 \"floatMaxSimple\",\n+                 \"floatAddDotProduct\",\n+                 \"floatMulDotProduct\",\n+                 \"floatMinDotProduct\",\n+                 \"floatMaxDotProduct\",\n+                 \"floatAddBig\",\n+                 \"floatMulBig\",\n+                 \"floatMinBig\",\n+                 \"floatMaxBig\",\n+\n+                 \"doubleAddSimple\",\n+                 \"doubleMulSimple\",\n+                 \"doubleMinSimple\",\n+                 \"doubleMaxSimple\",\n+                 \"doubleAddDotProduct\",\n+                 \"doubleMulDotProduct\",\n+                 \"doubleMinDotProduct\",\n+                 \"doubleMaxDotProduct\",\n+                 \"doubleAddBig\",\n+                 \"doubleMulBig\",\n+                 \"doubleMinBig\",\n+                 \"doubleMaxBig\"})\n+    public void runTests() {\n+        for (Map.Entry<String,TestFunction> entry : tests.entrySet()) {\n+            String name = entry.getKey();\n+            TestFunction test = entry.getValue();\n+            \/\/ Recall gold value from before compilation\n+            Object gold = golds.get(name);\n+            \/\/ Compute new result\n+            Object result = test.run();\n+            \/\/ Compare gold and new result\n+            try {\n+                Verify.checkEQ(gold, result);\n+            } catch (VerifyException e) {\n+                throw new RuntimeException(\"Verify failed for \" + name, e);\n+            }\n+        }\n+    }\n+\n+    static byte[] fillRandom(byte[] a) {\n+        for (int i = 0; i < a.length; i++) {\n+            a[i] = (byte)(int)GEN_I.next();\n+        }\n+        return a;\n+    }\n+\n+    static char[] fillRandom(char[] a) {\n+        for (int i = 0; i < a.length; i++) {\n+            a[i] = (char)(int)GEN_I.next();\n+        }\n+        return a;\n+    }\n+\n+    static short[] fillRandom(short[] a) {\n+        for (int i = 0; i < a.length; i++) {\n+            a[i] = (short)(int)GEN_I.next();\n+        }\n+        return a;\n+    }\n+\n+    static int[] fillRandom(int[] a) {\n+        G.fill(GEN_I, a);\n+        return a;\n+    }\n+\n+    static long[] fillRandom(long[] a) {\n+        G.fill(GEN_L, a);\n+        return a;\n+    }\n+\n+    static float[] fillRandom(float[] a) {\n+        G.fill(GEN_F, a);\n+        return a;\n+    }\n+\n+    static double[] fillRandom(double[] a) {\n+        G.fill(GEN_D, a);\n+        return a;\n+    }\n+\n+    \/\/ ---------byte***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAndSimple() {\n+        byte acc = (byte)0xFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteOrSimple() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteXorSimple() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAddSimple() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMulSimple() {\n+        byte acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMinSimple() {\n+        byte acc = Byte.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc = (byte)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMaxSimple() {\n+        byte acc = Byte.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = in1B[i];\n+            acc = (byte)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------byte***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAndDotProduct() {\n+        byte acc = (byte)0xFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteOrDotProduct() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteXorDotProduct() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAddDotProduct() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMulDotProduct() {\n+        byte acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMinDotProduct() {\n+        byte acc = Byte.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc = (byte)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMaxDotProduct() {\n+        byte acc = Byte.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)(in1B[i] * in2B[i]);\n+            acc = (byte)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------byte***Big ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAndBig() {\n+        byte acc = (byte)0xFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteOrBig() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteXorBig() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteAddBig() {\n+        byte acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMulBig() {\n+        byte acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMinBig() {\n+        byte acc = Byte.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc = (byte)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_B) \/\/ does not vectorize for now, might in the future.\n+    private static byte byteMaxBig() {\n+        byte acc = Byte.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            byte val = (byte)((in1B[i] * in2B[i]) + (in1B[i] * in3B[i]) + (in2B[i] * in3B[i]));\n+            acc = (byte)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------char***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAndSimple() {\n+        char acc = (char)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charOrSimple() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charXorSimple() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAddSimple() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMulSimple() {\n+        char acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMinSimple() {\n+        char acc = Character.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc = (char)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMaxSimple() {\n+        char acc = Character.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = in1C[i];\n+            acc = (char)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------char***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAndDotProduct() {\n+        char acc = (char)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charOrDotProduct() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charXorDotProduct() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAddDotProduct() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMulDotProduct() {\n+        char acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMinDotProduct() {\n+        char acc = Character.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc = (char)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMaxDotProduct() {\n+        char acc = Character.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)(in1C[i] * in2C[i]);\n+            acc = (char)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------char***Big ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAndBig() {\n+        char acc = (char)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charOrBig() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charXorBig() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charAddBig() {\n+        char acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMulBig() {\n+        char acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMinBig() {\n+        char acc = Character.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc = (char)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_C) \/\/ does not vectorize for now, might in the future.\n+    private static char charMaxBig() {\n+        char acc = Character.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            char val = (char)((in1C[i] * in2C[i]) + (in1C[i] * in3C[i]) + (in2C[i] * in3C[i]));\n+            acc = (char)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------short***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAndSimple() {\n+        short acc = (short)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortOrSimple() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortXorSimple() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAddSimple() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMulSimple() {\n+        short acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMinSimple() {\n+        short acc = Short.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc = (short)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMaxSimple() {\n+        short acc = Short.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = in1S[i];\n+            acc = (short)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------short***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAndDotProduct() {\n+        short acc = (short)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortOrDotProduct() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortXorDotProduct() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAddDotProduct() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMulDotProduct() {\n+        short acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMinDotProduct() {\n+        short acc = Short.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc = (short)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMaxDotProduct() {\n+        short acc = Short.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)(in1S[i] * in2S[i]);\n+            acc = (short)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------short***Big ------------------------------------------------------------\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAndBig() {\n+        short acc = (short)0xFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortOrBig() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortXorBig() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortAddBig() {\n+        short acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMulBig() {\n+        short acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMinBig() {\n+        short acc = Short.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc = (short)Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.LOAD_VECTOR_S) \/\/ does not vectorize for now, might in the future.\n+    private static short shortMaxBig() {\n+        short acc = Short.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            short val = (short)((in1S[i] * in2S[i]) + (in1S[i] * in3S[i]) + (in2S[i] * in3S[i]));\n+            acc = (short)Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------int***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAndSimple() {\n+        int acc = 0xFFFFFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intOrSimple() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intXorSimple() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VI, \"> 0\",\n+                  IRNode.ADD_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAddSimple() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VI, \"> 0\",\n+                  IRNode.MUL_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMulSimple() {\n+        int acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMinSimple() {\n+        int acc = Integer.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMaxSimple() {\n+        int acc = Integer.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------int***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAndDotProduct() {\n+        int acc = 0xFFFFFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intOrDotProduct() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intXorDotProduct() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VI, \"> 0\",\n+                  IRNode.ADD_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAddDotProduct() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VI, \"> 0\",\n+                  IRNode.MUL_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMulDotProduct() {\n+        int acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMinDotProduct() {\n+        int acc = Integer.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMaxDotProduct() {\n+        int acc = Integer.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = in1I[i] * in2I[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------int***Big ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAndBig() {\n+        int acc = 0xFFFFFFFF; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intOrBig() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intXorBig() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VI, \"> 0\",\n+                  IRNode.ADD_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intAddBig() {\n+        int acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VI, \"> 0\",\n+                  IRNode.MUL_VI,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMulBig() {\n+        int acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMinBig() {\n+        int acc = Integer.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_I,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VI,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_I,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static int intMaxBig() {\n+        int acc = Integer.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            int val = (in1I[i] * in2I[i]) + (in1I[i] * in3I[i]) + (in2I[i] * in3I[i]);\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------long***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VL,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAndSimple() {\n+        long acc = 0xFFFFFFFFFFFFFFFFL; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VL,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longOrSimple() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VL,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longXorSimple() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VL, \"> 0\",\n+                  IRNode.ADD_VL,           \"> 0\"},\n+        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAddSimple() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VL, \"> 0\",\n+                  IRNode.MUL_VL,           \"> 0\"}, \/\/ vector accumulator\n+        applyIfCPUFeature = {\"avx512dq\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512dq\", \"false\", \"sse4.1\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370673\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VL, \"> 0\",\n+                  IRNode.MUL_VL,           \"= 0\"}, \/\/ Reduction NOT moved out of loop\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    \/\/ Note: NEON does not support MulVL for auto vectorization. There is\n+    \/\/       a scalarized implementation, but that is not profitable for\n+    \/\/       auto vectorization in almost all cases, and would not be\n+    \/\/       profitable here at any rate.\n+    \/\/       Hence, we have to keep the reduction inside the loop, and\n+    \/\/       cannot use the MulVL as the vector accumulator.\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMulSimple() {\n+        long acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VL,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx512\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMinSimple() {\n+        long acc = Long.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VL,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx512\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMaxSimple() {\n+        long acc = Long.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------long***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While AndReductionV is implemented in NEON (see longAndSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAndDotProduct() {\n+        long acc = 0xFFFFFFFFFFFFFFFFL; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While OrReductionV is implemented in NEON (see longOrSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longOrDotProduct() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longXorSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longXorDotProduct() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VL, \"> 0\",\n+                  IRNode.ADD_VL,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longAddSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAddDotProduct() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VL, \"> 0\",\n+                  IRNode.MUL_VL,           \"> 0\"},\n+        applyIfCPUFeature = {\"avx512dq\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512dq\", \"false\", \"sse4.1\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370673\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ MulVL is not implemented on NEON, so we also not have the reduction.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMulDotProduct() {\n+        long acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"avx512\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longMinSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMinDotProduct() {\n+        long acc = Long.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"avx512\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longMaxSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMaxDotProduct() {\n+        long acc = Long.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = in1L[i] * in2L[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------long***Big ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.AND_REDUCTION_V, \"> 0\",\n+                  IRNode.AND_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While AndReductionV is implemented in NEON (see longAndSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAndBig() {\n+        long acc = 0xFFFFFFFFFFFFFFFFL; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc &= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,  \"> 0\",\n+                  IRNode.OR_REDUCTION_V, \"> 0\",\n+                  IRNode.OR_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While OrReductionV is implemented in NEON (see longOrSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longOrBig() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc |= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.XOR_REDUCTION_V, \"> 0\",\n+                  IRNode.XOR_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longXorSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longXorBig() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc ^= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VL, \"> 0\",\n+                  IRNode.ADD_VL,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longAddSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longAddBig() {\n+        long acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VL, \"> 0\",\n+                  IRNode.MUL_VL,           \"> 0\"},\n+        applyIfCPUFeature = {\"avx512dq\", \"true\"},\n+        applyIfAnd = {\"AutoVectorizationOverrideProfitability\", \"> 0\",\n+                      \"LoopUnrollLimit\", \">= 1000\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeature = {\"avx512dq\", \"true\"},\n+        applyIfAnd = {\"AutoVectorizationOverrideProfitability\", \"> 0\",\n+                      \"LoopUnrollLimit\", \"< 1000\"})\n+    \/\/ Increasing the body limit seems to help. Filed for investigation: JDK-8370685\n+    \/\/ If you can eliminate this exception for LoopUnrollLimit, please remove\n+    \/\/ the flag completely from the test, also the \"addFlags\" at the top.\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ MulVL is not implemented on NEON, so we also not have the reduction.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMulBig() {\n+        long acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"avx512\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longMinSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMinBig() {\n+        long acc = Long.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_L,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VL,          \"> 0\"},\n+        applyIfCPUFeature = {\"avx512\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"avx512\", \"false\", \"avx2\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370671\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ While MaxReductionV is implemented in NEON (see longMaxSimple), MulVL is not.\n+    \/\/ Filed: JDK-8370686\n+    @IR(failOn = IRNode.LOAD_VECTOR_L,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static long longMaxBig() {\n+        long acc = Long.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            long val = (in1L[i] * in2L[i]) + (in1L[i] * in3L[i]) + (in2L[i] * in3L[i]);\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------float***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.ADD_REDUCTION_V, \"> 0\",\n+                  IRNode.ADD_VF,          \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 2\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"< 2\"})\n+    \/\/ Not considered profitable by cost model, but if forced we can vectorize.\n+    \/\/ Scalar: n loads + n adds\n+    \/\/ Vector: n loads + n adds + n extract (sequential order of reduction)\n+    private static float floatAddSimple() {\n+        float acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VF, \"> 0\",\n+                  IRNode.MUL_VF,           \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 2\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"< 2\"})\n+    \/\/ Not considered profitable by cost model, but if forced we can vectorize.\n+    \/\/ Scalar: n loads + n mul\n+    \/\/ Vector: n loads + n mul + n extract (sequential order of reduction)\n+    private static float floatMulSimple() {\n+        float acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMinSimple() {\n+        float acc = Float.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMaxSimple() {\n+        float acc = Float.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------float***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.ADD_REDUCTION_V, \"> 0\",\n+                  IRNode.ADD_VF,          \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatAddDotProduct() {\n+        float acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i] * in2F[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VF, \"> 0\",\n+                  IRNode.MUL_VF,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMulDotProduct() {\n+        float acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i] * in2F[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMinDotProduct() {\n+        float acc = Float.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i] * in2F[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMaxDotProduct() {\n+        float acc = Float.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = in1F[i] * in2F[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------float***Big ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.ADD_REDUCTION_V, \"> 0\",\n+                  IRNode.ADD_VF,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatAddBig() {\n+        float acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = (in1F[i] * in2F[i]) + (in1F[i] * in3F[i]) + (in2F[i] * in3F[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VF, \"> 0\",\n+                  IRNode.MUL_VF,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMulBig() {\n+        float acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = (in1F[i] * in2F[i]) + (in1F[i] * in3F[i]) + (in2F[i] * in3F[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMinBig() {\n+        float acc = Float.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = (in1F[i] * in2F[i]) + (in1F[i] * in3F[i]) + (in2F[i] * in3F[i]);\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_F,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VF,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_F,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static float floatMaxBig() {\n+        float acc = Float.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            float val = (in1F[i] * in2F[i]) + (in1F[i] * in3F[i]) + (in2F[i] * in3F[i]);\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------double***Simple ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,    \"> 0\",\n+                  IRNode.ADD_REDUCTION_VD, \"> 0\",\n+                  IRNode.ADD_VD,           \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 2\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"< 2\"})\n+    \/\/ Not considered profitable by cost model, but if forced we can vectorize.\n+    \/\/ Scalar: n loads + n adds\n+    \/\/ Vector: n loads + n adds + n extract (sequential order of reduction)\n+    private static double doubleAddSimple() {\n+        double acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VD, \"> 0\",\n+                  IRNode.MUL_VD,           \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 2\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"< 2\"})\n+    \/\/ Not considered profitable by cost model, but if forced we can vectorize.\n+    \/\/ Scalar: n loads + n mul\n+    \/\/ Vector: n loads + n mul + n extract (sequential order of reduction)\n+    private static double doubleMulSimple() {\n+        double acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMinSimple() {\n+        double acc = Double.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMaxSimple() {\n+        double acc = Double.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------double***DotProduct ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.ADD_REDUCTION_V, \"> 0\",\n+                  IRNode.ADD_VD,          \"= 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleAddDotProduct() {\n+        double acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i] * in2D[i];\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VD, \"> 0\",\n+                  IRNode.MUL_VD,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMulDotProduct() {\n+        double acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i] * in2D[i];\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMinDotProduct() {\n+        double acc = Double.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i] * in2D[i];\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMaxDotProduct() {\n+        double acc = Double.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = in1D[i] * in2D[i];\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    \/\/ ---------double***Big ------------------------------------------------------------\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.ADD_REDUCTION_V, \"> 0\",\n+                  IRNode.ADD_VD,          \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleAddBig() {\n+        double acc = 0; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = (in1D[i] * in2D[i]) + (in1D[i] * in3D[i]) + (in2D[i] * in3D[i]);\n+            acc += val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,    \"> 0\",\n+                  IRNode.MUL_REDUCTION_VD, \"> 0\",\n+                  IRNode.MUL_VD,           \"> 0\"},\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\"})\n+    \/\/ I think this could vectorize, but currently does not. Filed: JDK-8370677\n+    \/\/ But: it is not clear that it would be profitable, given the sequential reduction.\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMulBig() {\n+        double acc = 1; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = (in1D[i] * in2D[i]) + (in1D[i] * in3D[i]) + (in2D[i] * in3D[i]);\n+            acc *= val;\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MIN_REDUCTION_V, \"> 0\",\n+                  IRNode.MIN_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMinBig() {\n+        double acc = Double.MAX_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = (in1D[i] * in2D[i]) + (in1D[i] * in3D[i]) + (in2D[i] * in3D[i]);\n+            acc = Math.min(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LOAD_VECTOR_D,   \"> 0\",\n+                  IRNode.MAX_REDUCTION_V, \"> 0\",\n+                  IRNode.MAX_VD,          \"> 0\"},\n+        applyIfCPUFeatureOr = {\"avx\", \"true\", \"asimd\", \"true\"},\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"> 0\"})\n+    @IR(failOn = IRNode.LOAD_VECTOR_D,\n+        applyIf = {\"AutoVectorizationOverrideProfitability\", \"= 0\"})\n+    private static double doubleMaxBig() {\n+        double acc = Double.MIN_VALUE; \/\/ neutral element\n+        for (int i = 0; i < SIZE; i++) {\n+            double val = (in1D[i] * in2D[i]) + (in1D[i] * in3D[i]) + (in2D[i] * in3D[i]);\n+            acc = Math.max(acc, val);\n+        }\n+        return acc;\n+    }\n+\n+\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestReductions.java","additions":2452,"deletions":0,"binary":false,"changes":2452,"status":"added"},{"patch":"@@ -31,0 +31,4 @@\n+\/**\n+ * Note: there is a corresponding IR test:\n+ * test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestReductions.java\n+ *\/\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/compiler\/VectorReduction2.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}