{"files":[{"patch":"@@ -845,1 +845,1 @@\n-    if ((0xFF & *ip++) & REXBIT_W) {\n+    if ((0xFF & *ip++) & REX2BIT_W) {\n@@ -902,1 +902,1 @@\n-      if ((0xFF & *ip++) & REXBIT_W) {\n+      if ((0xFF & *ip++) & REX2BIT_W) {\n@@ -1679,0 +1679,1 @@\n+  assert((!needs_eevex(dst, src1) && !needs_eevex(src2.base(), src2.index())) || UseAPX, \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -5896,0 +5897,65 @@\n+#ifdef _LP64\n+void Assembler::push2(Register src1, Register src2, bool with_ppx) {\n+  assert(VM_Version::supports_apx_f(), \"requires APX\");\n+  InstructionAttr attributes(0, \/* rex_w *\/ with_ppx, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  \/* EVEX.BASE *\/\n+  int src_enc = src1->encoding();\n+  \/* EVEX.VVVV *\/\n+  int nds_enc = src2->encoding();\n+\n+  bool vex_b = (src_enc & 8) == 8;\n+  bool evex_v = (nds_enc >= 16);\n+  bool evex_b = (src_enc >= 16);\n+\n+  \/\/ EVEX.ND = 1;\n+  attributes.set_extended_context();\n+  attributes.set_is_evex_instruction();\n+  set_attributes(&attributes);\n+\n+  evex_prefix(0, vex_b, 0, 0, evex_b, evex_v, false \/*eevex_x*\/, nds_enc, VEX_SIMD_NONE, \/* map4 *\/ VEX_OPCODE_0F_3C);\n+  emit_int16(0xFF, (0xC0 | (0x6 << 3) | (src_enc & 7)));\n+}\n+\n+void Assembler::pop2(Register src1, Register src2, bool with_ppx) {\n+  assert(VM_Version::supports_apx_f(), \"requires APX\");\n+  InstructionAttr attributes(0, \/* rex_w *\/ with_ppx, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  \/* EVEX.BASE *\/\n+  int src_enc = src1->encoding();\n+  \/* EVEX.VVVV *\/\n+  int nds_enc = src2->encoding();\n+\n+  bool vex_b = (src_enc & 8) == 8;\n+  bool evex_v = (nds_enc >= 16);\n+  bool evex_b = (src_enc >= 16);\n+\n+  \/\/ EVEX.ND = 1;\n+  attributes.set_extended_context();\n+  attributes.set_is_evex_instruction();\n+  set_attributes(&attributes);\n+\n+  evex_prefix(0, vex_b, 0, 0, evex_b, evex_v, false \/*eevex_x*\/, nds_enc, VEX_SIMD_NONE, \/* map4 *\/ VEX_OPCODE_0F_3C);\n+  emit_int16(0x8F, (0xC0 | (src_enc & 7)));\n+}\n+\n+void Assembler::push2p(Register src1, Register src2) {\n+  push2(src1, src2, true);\n+}\n+\n+void Assembler::pop2p(Register src1, Register src2) {\n+  pop2(src1, src2, true);\n+}\n+\n+void Assembler::pushp(Register src) {\n+  assert(VM_Version::supports_apx_f(), \"requires APX\");\n+  int encode = prefixq_and_encode_rex2(src->encoding());\n+  emit_int8(0x50 | encode);\n+}\n+\n+void Assembler::popp(Register dst) {\n+  assert(VM_Version::supports_apx_f(), \"requires APX\");\n+  int encode = prefixq_and_encode_rex2(dst->encoding());\n+  emit_int8((unsigned char)0x58 | encode);\n+}\n+#endif \/\/_LP64\n+\n+\n@@ -11811,1 +11877,0 @@\n-\n@@ -12924,1 +12989,1 @@\n-  if (enc & 8) bits |= REXBIT_B;\n+  if (enc & 8) bits |= REX2BIT_B;\n@@ -12931,1 +12996,1 @@\n-  if (enc & 8) bits |= REXBIT_X;\n+  if (enc & 8) bits |= REX2BIT_X;\n@@ -12946,1 +13011,1 @@\n-  if (enc & 8) bits |= REXBIT_R;\n+  if (enc & 8) bits |= REX2BIT_R;\n@@ -13184,0 +13249,9 @@\n+int Assembler::get_prefixq_rex2(Address adr, bool is_map1) {\n+  assert(UseAPX, \"APX features not enabled\");\n+  int bits = REX2BIT_W;\n+  if (is_map1) bits |= REX2BIT_M0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  return WREX2 | bits;\n+}\n+\n@@ -13193,9 +13267,0 @@\n-int Assembler::get_prefixq_rex2(Address adr, bool is_map1) {\n-  assert(UseAPX, \"APX features not enabled\");\n-  int bits = REXBIT_W;\n-  if (is_map1) bits |= REX2BIT_M0;\n-  bits |= get_base_prefix_bits(adr.base());\n-  bits |= get_index_prefix_bits(adr.index());\n-  return WREX2 | bits;\n-}\n-\n@@ -13246,1 +13311,1 @@\n-  int bits = REXBIT_W;\n+  int bits = REX2BIT_W;\n@@ -13309,1 +13374,1 @@\n-  int bits = REXBIT_W;\n+  int bits = REX2BIT_W;\n@@ -13332,1 +13397,1 @@\n-  prefix16(WREX2 | REXBIT_W | (is_map1 ? REX2BIT_M0: 0) | get_base_prefix_bits(reg_enc));\n+  prefix16(WREX2 | REX2BIT_W | (is_map1 ? REX2BIT_M0: 0) | get_base_prefix_bits(reg_enc));\n@@ -13361,1 +13426,1 @@\n-  int init_bits = REXBIT_W | (is_map1 ? REX2BIT_M0 : 0);\n+  int init_bits = REX2BIT_W | (is_map1 ? REX2BIT_M0 : 0);\n@@ -14171,1 +14236,1 @@\n-  int size = 256;\n+  int size = UseAPX ? 512 : 256;\n@@ -14215,25 +14280,0 @@\n-void Assembler::popa() { \/\/ 64bit\n-  emit_copy(code_section(), popa_code, popa_len);\n-}\n-\n-void Assembler::popa_uncached() { \/\/ 64bit\n-  movq(r15, Address(rsp, 0));\n-  movq(r14, Address(rsp, wordSize));\n-  movq(r13, Address(rsp, 2 * wordSize));\n-  movq(r12, Address(rsp, 3 * wordSize));\n-  movq(r11, Address(rsp, 4 * wordSize));\n-  movq(r10, Address(rsp, 5 * wordSize));\n-  movq(r9,  Address(rsp, 6 * wordSize));\n-  movq(r8,  Address(rsp, 7 * wordSize));\n-  movq(rdi, Address(rsp, 8 * wordSize));\n-  movq(rsi, Address(rsp, 9 * wordSize));\n-  movq(rbp, Address(rsp, 10 * wordSize));\n-  \/\/ Skip rsp as it is restored automatically to the value\n-  \/\/ before the corresponding pusha when popa is done.\n-  movq(rbx, Address(rsp, 12 * wordSize));\n-  movq(rdx, Address(rsp, 13 * wordSize));\n-  movq(rcx, Address(rsp, 14 * wordSize));\n-  movq(rax, Address(rsp, 15 * wordSize));\n-\n-  addq(rsp, 16 * wordSize);\n-}\n@@ -14250,20 +14290,50 @@\n-  subq(rsp, 16 * wordSize);\n-\n-  movq(Address(rsp, 15 * wordSize), rax);\n-  movq(Address(rsp, 14 * wordSize), rcx);\n-  movq(Address(rsp, 13 * wordSize), rdx);\n-  movq(Address(rsp, 12 * wordSize), rbx);\n-  \/\/ Skip rsp as the value is normally not used. There are a few places where\n-  \/\/ the original value of rsp needs to be known but that can be computed\n-  \/\/ from the value of rsp immediately after pusha (rsp + 16 * wordSize).\n-  movq(Address(rsp, 10 * wordSize), rbp);\n-  movq(Address(rsp, 9 * wordSize), rsi);\n-  movq(Address(rsp, 8 * wordSize), rdi);\n-  movq(Address(rsp, 7 * wordSize), r8);\n-  movq(Address(rsp, 6 * wordSize), r9);\n-  movq(Address(rsp, 5 * wordSize), r10);\n-  movq(Address(rsp, 4 * wordSize), r11);\n-  movq(Address(rsp, 3 * wordSize), r12);\n-  movq(Address(rsp, 2 * wordSize), r13);\n-  movq(Address(rsp, wordSize), r14);\n-  movq(Address(rsp, 0), r15);\n+  if (UseAPX) {\n+    \/\/ Data being pushed by PUSH2 must be 16B-aligned on the stack, for this push rax upfront\n+    \/\/ and use it as a temporary register for stack alignment.\n+    pushp(rax);\n+    \/\/ Move original stack pointer to RAX and align stack pointer to 16B boundary.\n+    movq(rax, rsp);\n+    andq(rsp, -(StackAlignmentInBytes));\n+    \/\/ Push pair of original stack pointer along with remaining registers\n+    \/\/ at 16B aligned boundary.\n+    push2p(rax, r31);\n+    push2p(r30, r29);\n+    push2p(r28, r27);\n+    push2p(r26, r25);\n+    push2p(r24, r23);\n+    push2p(r22, r21);\n+    push2p(r20, r19);\n+    push2p(r18, r17);\n+    push2p(r16, r15);\n+    push2p(r14, r13);\n+    push2p(r12, r11);\n+    push2p(r10, r9);\n+    push2p(r8, rdi);\n+    push2p(rsi, rbp);\n+    push2p(rbx, rdx);\n+    \/\/ To maintain 16 byte alignment after rcx is pushed.\n+    subq(rsp, 8);\n+    pushp(rcx);\n+  } else {\n+    subq(rsp, 16 * wordSize);\n+    movq(Address(rsp, 15 * wordSize), rax);\n+    movq(Address(rsp, 14 * wordSize), rcx);\n+    movq(Address(rsp, 13 * wordSize), rdx);\n+    movq(Address(rsp, 12 * wordSize), rbx);\n+    \/\/ Skip rsp as the value is normally not used. There are a few places where\n+    \/\/ the original value of rsp needs to be known but that can be computed\n+    \/\/ from the value of rsp immediately after pusha (rsp + 16 * wordSize).\n+    \/\/ FIXME: For APX any such direct access should also consider EGPR size\n+    \/\/ during address compution.\n+    movq(Address(rsp, 10 * wordSize), rbp);\n+    movq(Address(rsp, 9 * wordSize), rsi);\n+    movq(Address(rsp, 8 * wordSize), rdi);\n+    movq(Address(rsp, 7 * wordSize), r8);\n+    movq(Address(rsp, 6 * wordSize), r9);\n+    movq(Address(rsp, 5 * wordSize), r10);\n+    movq(Address(rsp, 4 * wordSize), r11);\n+    movq(Address(rsp, 3 * wordSize), r12);\n+    movq(Address(rsp, 2 * wordSize), r13);\n+    movq(Address(rsp, wordSize), r14);\n+    movq(Address(rsp, 0), r15);\n+  }\n@@ -14272,0 +14342,50 @@\n+void Assembler::popa() { \/\/ 64bit\n+  emit_copy(code_section(), popa_code, popa_len);\n+}\n+\n+void Assembler::popa_uncached() { \/\/ 64bit\n+  if (UseAPX) {\n+    popp(rcx);\n+    addq(rsp, 8);\n+    \/\/ Data being popped by POP2 must be 16B-aligned on the stack.\n+    pop2p(rdx, rbx);\n+    pop2p(rbp, rsi);\n+    pop2p(rdi, r8);\n+    pop2p(r9, r10);\n+    pop2p(r11, r12);\n+    pop2p(r13, r14);\n+    pop2p(r15, r16);\n+    pop2p(r17, r18);\n+    pop2p(r19, r20);\n+    pop2p(r21, r22);\n+    pop2p(r23, r24);\n+    pop2p(r25, r26);\n+    pop2p(r27, r28);\n+    pop2p(r29, r30);\n+    \/\/ Popped value in RAX holds original unaligned stack pointer.\n+    pop2p(r31, rax);\n+    \/\/ Reinstantiate original stack pointer.\n+    movq(rsp, rax);\n+    popp(rax);\n+  } else {\n+    movq(r15, Address(rsp, 0));\n+    movq(r14, Address(rsp, wordSize));\n+    movq(r13, Address(rsp, 2 * wordSize));\n+    movq(r12, Address(rsp, 3 * wordSize));\n+    movq(r11, Address(rsp, 4 * wordSize));\n+    movq(r10, Address(rsp, 5 * wordSize));\n+    movq(r9,  Address(rsp, 6 * wordSize));\n+    movq(r8,  Address(rsp, 7 * wordSize));\n+    movq(rdi, Address(rsp, 8 * wordSize));\n+    movq(rsi, Address(rsp, 9 * wordSize));\n+    movq(rbp, Address(rsp, 10 * wordSize));\n+    \/\/ Skip rsp as it is restored automatically to the value\n+    \/\/ before the corresponding pusha when popa is done.\n+    movq(rbx, Address(rsp, 12 * wordSize));\n+    movq(rdx, Address(rsp, 13 * wordSize));\n+    movq(rcx, Address(rsp, 14 * wordSize));\n+    movq(rax, Address(rsp, 15 * wordSize));\n+\n+    addq(rsp, 16 * wordSize);\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":185,"deletions":65,"binary":false,"changes":250,"status":"modified"},{"patch":"@@ -533,4 +533,4 @@\n-    REXBIT_B  = 0x01,\n-    REXBIT_X  = 0x02,\n-    REXBIT_R  = 0x04,\n-    REXBIT_W  = 0x08,\n+    REX2BIT_B  = 0x01,\n+    REX2BIT_X  = 0x02,\n+    REX2BIT_R  = 0x04,\n+    REX2BIT_W  = 0x08,\n@@ -540,1 +540,3 @@\n-    REX2BIT_M0 = 0x80\n+    REX2BIT_M0 = 0x80,\n+    REX2BIT_WB = 0x09,\n+    REX2BIT_WB4 = 0x18,\n@@ -1020,0 +1022,9 @@\n+\n+  \/\/ APX ISA extensions for register save\/restore optimizations.\n+  void push2(Register src1, Register src2, bool with_ppx = false);\n+  void pop2(Register src1, Register src2, bool with_ppx = false);\n+  void push2p(Register src1, Register src2);\n+  void pop2p(Register src1, Register src2);\n+  void pushp(Register src);\n+  void popp(Register src);\n+\n@@ -3073,1 +3084,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":16,"deletions":6,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  pd_nof_cpu_regs_frame_map = Register::number_of_registers,       \/\/ number of registers used during code emission\n+  pd_nof_cpu_regs_frame_map = NOT_LP64(8) LP64_ONLY(16),           \/\/ number of registers used during code emission\n","filename":"src\/hotspot\/cpu\/x86\/c1_Defs_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2839,1 +2839,1 @@\n-    offset += NativeCall::displacement_offset + NativeMovConstReg::instruction_size;\n+    offset += NativeCall::displacement_offset + NativeMovConstReg::instruction_size_rex;\n@@ -2876,1 +2876,1 @@\n-  __ align(BytesPerWord, __ offset() + NativeMovConstReg::instruction_size + NativeCall::displacement_offset);\n+  __ align(BytesPerWord, __ offset() + NativeMovConstReg::instruction_size_rex + NativeCall::displacement_offset);\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -423,1 +423,24 @@\n-  __ pusha();         \/\/ integer registers\n+  \/\/ Push CPU state in multiple of 16 bytes\n+#ifdef _LP64\n+  __ subq(rsp, 16 * wordSize);\n+  __ movq(Address(rsp, 15 * wordSize), rax);\n+  __ movq(Address(rsp, 14 * wordSize), rcx);\n+  __ movq(Address(rsp, 13 * wordSize), rdx);\n+  __ movq(Address(rsp, 12 * wordSize), rbx);\n+  \/\/ Skip rsp as the value is normally not used. There are a few places where\n+  \/\/ the original value of rsp needs to be known but that can be computed\n+  \/\/ from the value of rsp immediately after pusha (rsp + 16 * wordSize).\n+  __ movq(Address(rsp, 10 * wordSize), rbp);\n+  __ movq(Address(rsp, 9 * wordSize), rsi);\n+  __ movq(Address(rsp, 8 * wordSize), rdi);\n+  __ movq(Address(rsp, 7 * wordSize), r8);\n+  __ movq(Address(rsp, 6 * wordSize), r9);\n+  __ movq(Address(rsp, 5 * wordSize), r10);\n+  __ movq(Address(rsp, 4 * wordSize), r11);\n+  __ movq(Address(rsp, 3 * wordSize), r12);\n+  __ movq(Address(rsp, 2 * wordSize), r13);\n+  __ movq(Address(rsp, wordSize), r14);\n+  __ movq(Address(rsp, 0), r15);\n+#else\n+  __ pusha();\n+#endif\n@@ -563,0 +586,20 @@\n+#ifdef _LP64\n+  __ movq(r15, Address(rsp, 0));\n+  __ movq(r14, Address(rsp, wordSize));\n+  __ movq(r13, Address(rsp, 2 * wordSize));\n+  __ movq(r12, Address(rsp, 3 * wordSize));\n+  __ movq(r11, Address(rsp, 4 * wordSize));\n+  __ movq(r10, Address(rsp, 5 * wordSize));\n+  __ movq(r9,  Address(rsp, 6 * wordSize));\n+  __ movq(r8,  Address(rsp, 7 * wordSize));\n+  __ movq(rdi, Address(rsp, 8 * wordSize));\n+  __ movq(rsi, Address(rsp, 9 * wordSize));\n+  __ movq(rbp, Address(rsp, 10 * wordSize));\n+  \/\/ Skip rsp as it is restored automatically to the value\n+  \/\/ before the corresponding pusha when popa is done.\n+  __ movq(rbx, Address(rsp, 12 * wordSize));\n+  __ movq(rdx, Address(rsp, 13 * wordSize));\n+  __ movq(rcx, Address(rsp, 14 * wordSize));\n+  __ movq(rax, Address(rsp, 15 * wordSize));\n+  __ addq(rsp, 16 * wordSize);\n+#else\n@@ -564,0 +607,2 @@\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":46,"deletions":1,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -586,0 +586,19 @@\n+  if (UseAPX) {\n+    caller_saved.Insert(OptoReg::as_OptoReg(r16->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r17->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r18->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r19->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r20->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r21->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r22->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r23->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r24->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r25->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r26->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r27->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r28->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r29->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r30->as_VMReg()));\n+    caller_saved.Insert(OptoReg::as_OptoReg(r31->as_VMReg()));\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -487,0 +487,19 @@\n+    if (UseAPX) {\n+      caller_saved.Insert(OptoReg::as_OptoReg(r16->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r17->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r18->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r19->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r20->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r21->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r22->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r23->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r24->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r25->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r26->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r27->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r28->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r29->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r30->as_VMReg()));\n+      caller_saved.Insert(OptoReg::as_OptoReg(r31->as_VMReg()));\n+    }\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/x\/xBarrierSetAssembler_x86.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -118,1 +118,0 @@\n-                                                                            \\\n@@ -195,1 +194,0 @@\n-                                                                            \\\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-    jint offset = pc_offset + NativeMovConstReg::instruction_size;\n+    jint offset = pc_offset + ((NativeMovConstReg*)inst)->instruction_size();\n@@ -55,0 +55,5 @@\n+    if (call[0] == Assembler::REX2) {\n+      offset += 2; \/* prefix byte for APX extended GPR register R16-R31 *\/\n+      call+=2;\n+    }\n+    \/\/ Register indirect call.\n","filename":"src\/hotspot\/cpu\/x86\/jvmciCodeInstaller_x86.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -4090,0 +4090,5 @@\n+#endif\n+#ifdef _LP64\n+  if (UseAPX) {\n+    regs += RegSet::range(r16, as_Register(Register::number_of_registers - 1));\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -539,1 +539,2 @@\n-      assert(Register::number_of_registers == 16, \"sanity\");\n+      int num_regs = UseAPX ? 32 : 16;\n+      assert(Register::available_gp_registers() == num_regs, \"sanity\");\n@@ -542,1 +543,1 @@\n-        ls.print(\"%3s=\" PTR_FORMAT, r->name(), (intptr_t)(&saved_regs[16]));\n+        ls.print(\"%3s=\" PTR_FORMAT, r->name(), (intptr_t)(&saved_regs[num_regs]));\n","filename":"src\/hotspot\/cpu\/x86\/methodHandles_x86.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -300,2 +300,7 @@\n-  if ((ubyte_at(0) != Assembler::REX_W && ubyte_at(0) != Assembler::REX_WB) ||\n-      (ubyte_at(1) & (0xff ^ register_mask)) != 0xB8) {\n+  bool valid_rex_prefix  = ubyte_at(0) == Assembler::REX_W || ubyte_at(0) == Assembler::REX_WB;\n+  bool valid_rex2_prefix = ubyte_at(0) == Assembler::REX2  &&\n+       (ubyte_at(1) == Assembler::REX2BIT_W  ||\n+        ubyte_at(1) == Assembler::REX2BIT_WB ||\n+        ubyte_at(1) == Assembler::REX2BIT_WB4);\n+  int opcode = has_rex2_prefix() ? ubyte_at(2) : ubyte_at(1);\n+  if ((!valid_rex_prefix || !valid_rex2_prefix) && (opcode & (0xff ^ register_mask)) != 0xB8) {\n@@ -348,0 +353,5 @@\n+  if (instr_0 == instruction_REX2_prefix) {\n+    off+=2;\n+    instr_0 = ubyte_at(off);\n+  }\n+\n@@ -366,0 +376,5 @@\n+  if (instr_0 == instruction_REX2_prefix) {\n+    off+=2;\n+    instr_0 = ubyte_at(off);\n+  }\n+\n@@ -372,1 +387,2 @@\n-\n+  \/\/ Extended prefixes can only follow REX prefixes,\n+  \/\/ REX2 is directly followed by main opcode.\n@@ -377,0 +393,1 @@\n+  \/\/ Offset of instruction opcode.\n@@ -380,0 +397,1 @@\n+\/\/ Format [REX\/REX2] [OPCODE] [ModRM] [SIB] [IMM\/DISP32]\n@@ -386,0 +404,1 @@\n+  \/\/ ModRM Byte Format = Mod[2] REG[3] RM[3]\n@@ -389,0 +408,1 @@\n+  \/\/ Displacement offset.\n@@ -434,6 +454,0 @@\n-#ifdef _LP64\n-  if ( (test_byte == instruction_prefix_wide ||\n-        test_byte == instruction_prefix_wide_extended) ) {\n-    test_byte = *(u_char*)(instruction_address() + 1);\n-  }\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/nativeInst_x86.cpp","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -95,0 +95,1 @@\n+  bool has_rex2_prefix() const { return ubyte_at(0) == Assembler::REX2; }\n@@ -107,0 +108,1 @@\n+\/\/ PLT(procedure linkage table) call with relative displacement.\n@@ -224,0 +226,5 @@\n+\/\/ Call with target address in a general purpose register(indirect absolute addressing).\n+\/\/ Encoding : FF \/2  CALL r\/m32\n+\/\/ Primary Opcode: FF\n+\/\/ Opcode Extension(part of ModRM.REG): \/2\n+\/\/ Operand ModRM.RM  = r\/m32\n@@ -230,1 +237,2 @@\n-    return_address_offset_rex   =    3\n+    return_address_offset_rex   =    3,\n+    return_address_offset_rex2  =    4\n@@ -236,0 +244,2 @@\n+    } else if (has_rex2_prefix()) {\n+      return return_address_offset_rex2;\n@@ -237,0 +247,1 @@\n+      assert((ubyte_at(0) & 0xF0) ==  Assembler::REX, \"\");\n@@ -244,0 +255,2 @@\n+\/\/ Instruction format for implied addressing mode immediate operand move to register instruction:\n+\/\/  [REX\/REX2] [OPCODE] [IMM32]\n@@ -246,2 +259,3 @@\n-  static const bool has_rex = true;\n-  static const int rex_size = 1;\n+  static const bool has_rex  = true;\n+  static const int rex_size  = 1;\n+  static const int rex2_size = 2;\n@@ -249,2 +263,3 @@\n-  static const bool has_rex = false;\n-  static const int rex_size = 0;\n+  static const bool has_rex  = false;\n+  static const int rex_size  = 0;\n+  static const int rex2_size = 0;\n@@ -254,6 +269,9 @@\n-    instruction_code            = 0xB8,\n-    instruction_size            =    1 + rex_size + wordSize,\n-    instruction_offset          =    0,\n-    data_offset                 =    1 + rex_size,\n-    next_instruction_offset     =    instruction_size,\n-    register_mask               = 0x07\n+    instruction_code             = 0xB8,\n+    instruction_offset           =    0,\n+    instruction_size_rex         =    1 + rex_size + wordSize,\n+    instruction_size_rex2        =    1 + rex2_size + wordSize,\n+    data_offset_rex              =    1 + rex_size,\n+    data_offset_rex2             =    1 + rex2_size,\n+    next_instruction_offset_rex  =    instruction_size_rex,\n+    next_instruction_offset_rex2 =    instruction_size_rex2,\n+    register_mask                = 0x07\n@@ -262,0 +280,3 @@\n+  int instruction_size() const              { return has_rex2_prefix() ? instruction_size_rex2 : instruction_size_rex; }\n+  int next_inst_offset() const              { return has_rex2_prefix() ? next_instruction_offset_rex2 : next_instruction_offset_rex; }\n+  int data_byte_offset() const              { return has_rex2_prefix() ? data_offset_rex2 : data_offset_rex;}\n@@ -263,3 +284,3 @@\n-  address next_instruction_address() const  { return addr_at(next_instruction_offset); }\n-  intptr_t data() const                     { return ptr_at(data_offset); }\n-  void  set_data(intptr_t x)                { set_ptr_at(data_offset, x); }\n+  address next_instruction_address() const  { return addr_at(next_inst_offset()); }\n+  intptr_t data() const                     { return ptr_at(data_byte_offset()); }\n+  void  set_data(intptr_t x)                { set_ptr_at(data_byte_offset(), x); }\n@@ -284,1 +305,4 @@\n-  NativeMovConstReg* test = (NativeMovConstReg*)(address - NativeMovConstReg::instruction_size - NativeMovConstReg::instruction_offset);\n+  int instruction_size = ((NativeInstruction*)(address))->has_rex2_prefix() ?\n+                                  NativeMovConstReg::instruction_size_rex2 :\n+                                  NativeMovConstReg::instruction_size_rex;\n+  NativeMovConstReg* test = (NativeMovConstReg*)(address - instruction_size - NativeMovConstReg::instruction_offset);\n@@ -317,1 +341,1 @@\n-\n+\/\/\n@@ -325,0 +349,2 @@\n+\n+    \/\/ Legacy encoding MAP1 instructions promotable to REX2 encoding.\n@@ -330,0 +356,1 @@\n+\n@@ -331,0 +358,2 @@\n+\n+    \/\/ Legacy encoding MAP0 instructions promotable to REX2 encoding.\n@@ -335,0 +364,2 @@\n+    instruction_code_lea                = 0x8d,\n+\n@@ -338,0 +369,2 @@\n+\n+    \/\/ VEX\/EVEX\/Legacy encodeded MAP1 instructions promotable to REX2 encoding.\n@@ -340,0 +373,1 @@\n+\n@@ -341,0 +375,3 @@\n+\n+    \/\/ Address operand load\/store\/ldp are promotable to REX2 to accomodate\n+    \/\/ extended SIB encoding.\n@@ -345,2 +382,0 @@\n-    instruction_code_lea                = 0x8d,\n-\n@@ -350,0 +385,1 @@\n+    instruction_REX2_prefix             = Assembler::REX2,\n@@ -353,1 +389,2 @@\n-    next_instruction_offset             = 4\n+    next_instruction_offset_rex         = 4,\n+    next_instruction_offset_rex2        = 5\n@@ -431,0 +468,1 @@\n+\/\/FIXME: Currently not being used in hotspot code base, extend it to support REX2 prefix.\n@@ -536,0 +574,1 @@\n+\/\/FIXME: Currently not being used in hotspot code base, extend it to support REX2 prefix.\n@@ -555,1 +594,2 @@\n-\/\/ Handles all kinds of jump on Intel. Long\/far, conditional\/unconditional\n+\/\/ Handles all kinds of jump on Intel. Long\/far, conditional\/unconditional with relative offsets\n+\/\/ barring register indirect jumps.\n@@ -588,0 +628,2 @@\n+\/\/FIXME: Register indirect jump interface, currently not being used in hotspot code base,\n+\/\/ extend it to support REX2 prefix if needed.\n@@ -628,0 +670,1 @@\n+\/\/FIXME: Currently not being used in hotspot code base, extend it to support REX2 prefix.\n@@ -711,1 +754,1 @@\n-  const int test_offset = has_rex_prefix ? 1 : 0;\n+  const int test_offset = has_rex2_prefix() ? 2 : (has_rex_prefix ? 1 : 0);\n@@ -722,2 +765,8 @@\n-  return ((ubyte_at(0) == Assembler::REX_W || ubyte_at(0) == Assembler::REX_WB) &&\n-          (ubyte_at(1) & (0xff ^ NativeMovConstReg::register_mask)) == 0xB8);\n+  bool valid_rex_prefix  = ubyte_at(0) == Assembler::REX_W || ubyte_at(0) == Assembler::REX_WB;\n+  bool valid_rex2_prefix = ubyte_at(0) == Assembler::REX2  &&\n+       (ubyte_at(1) == Assembler::REX2BIT_W  ||\n+        ubyte_at(1) == Assembler::REX2BIT_WB ||\n+        ubyte_at(1) == Assembler::REX2BIT_WB4);\n+\n+  int opcode = has_rex2_prefix() ? ubyte_at(2) : ubyte_at(1);\n+  return ((valid_rex_prefix || valid_rex2_prefix) &&  (opcode & (0xff ^ NativeMovConstReg::register_mask)) == 0xB8);\n","filename":"src\/hotspot\/cpu\/x86\/nativeInst_x86.hpp","additions":73,"deletions":24,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -38,1 +38,3 @@\n-    \"r8\",  \"r9\",  \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\"\n+    \"r8\",  \"r9\",  \"r10\", \"r11\", \"r12\", \"r13\", \"r14\", \"r15\",\n+    \"r16\", \"r17\", \"r18\", \"r19\", \"r20\", \"r21\", \"r22\", \"r23\",\n+    \"r24\", \"r25\", \"r26\", \"r27\", \"r28\", \"r29\", \"r30\", \"r31\"\n","filename":"src\/hotspot\/cpu\/x86\/register_x86.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -48,2 +48,2 @@\n-    number_of_registers      = LP64_ONLY( 16 ) NOT_LP64( 8 ),\n-    number_of_byte_registers = LP64_ONLY( 16 ) NOT_LP64( 4 ),\n+    number_of_registers      = LP64_ONLY( 32 ) NOT_LP64( 8 ),\n+    number_of_byte_registers = LP64_ONLY( 32 ) NOT_LP64( 4 ),\n@@ -79,0 +79,10 @@\n+\n+  \/\/ Actually available GP registers for use, depending on actual CPU capabilities and flags.\n+  static int available_gp_registers() {\n+#ifdef _LP64\n+    if (!UseAPX) {\n+      return number_of_registers \/ 2;\n+    }\n+#endif \/\/ _LP64\n+    return number_of_registers;\n+  }\n@@ -118,0 +128,16 @@\n+constexpr Register r16 = as_Register(16);\n+constexpr Register r17 = as_Register(17);\n+constexpr Register r18 = as_Register(18);\n+constexpr Register r19 = as_Register(19);\n+constexpr Register r20 = as_Register(20);\n+constexpr Register r21 = as_Register(21);\n+constexpr Register r22 = as_Register(22);\n+constexpr Register r23 = as_Register(23);\n+constexpr Register r24 = as_Register(24);\n+constexpr Register r25 = as_Register(25);\n+constexpr Register r26 = as_Register(26);\n+constexpr Register r27 = as_Register(27);\n+constexpr Register r28 = as_Register(28);\n+constexpr Register r29 = as_Register(29);\n+constexpr Register r30 = as_Register(30);\n+constexpr Register r31 = as_Register(31);\n","filename":"src\/hotspot\/cpu\/x86\/register_x86.hpp","additions":28,"deletions":2,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -98,0 +98,1 @@\n+#define XSAVE_AREA_EGPRS 960\n@@ -107,2 +108,2 @@\n-    fpu_state_off = frame::arg_reg_save_area_bytes\/BytesPerInt, \/\/ fxsave save area\n-    xmm_off       = fpu_state_off + XSAVE_AREA_BEGIN\/BytesPerInt,            \/\/ offset in fxsave save area\n+    fpu_state_off = frame::arg_reg_save_area_bytes\/BytesPerInt,    \/\/ fxsave save area\n+    xmm_off       = fpu_state_off + XSAVE_AREA_BEGIN\/BytesPerInt,  \/\/ offset in fxsave save area\n@@ -116,1 +117,18 @@\n-    opmask_off         = xmm_off + (XSAVE_AREA_OPMASK_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    r31_off = xmm_off + (XSAVE_AREA_EGPRS - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    r31H_off,\n+    r30_off, r30H_off,\n+    r29_off, r29H_off,\n+    r28_off, r28H_off,\n+    r27_off, r27H_off,\n+    r26_off, r26H_off,\n+    r25_off, r25H_off,\n+    r24_off, r24H_off,\n+    r23_off, r23H_off,\n+    r22_off, r22H_off,\n+    r21_off, r21H_off,\n+    r20_off, r20H_off,\n+    r19_off, r19H_off,\n+    r18_off, r18H_off,\n+    r17_off, r17H_off,\n+    r16_off, r16H_off,\n+    opmask_off   = xmm_off + (XSAVE_AREA_OPMASK_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n@@ -202,1 +220,26 @@\n-  __ push_CPU_state(); \/\/ Push a multiple of 16 bytes\n+  __ pushf();\n+  \/\/ Make sure rsp stays 16-byte aligned\n+  __ subq(rsp, 8);\n+  \/\/ Push CPU state in multiple of 16 bytes\n+  __ subq(rsp, 16 * wordSize);\n+\n+  __ movq(Address(rsp, 15 * wordSize), rax);\n+  __ movq(Address(rsp, 14 * wordSize), rcx);\n+  __ movq(Address(rsp, 13 * wordSize), rdx);\n+  __ movq(Address(rsp, 12 * wordSize), rbx);\n+  \/\/ Skip rsp as the value is normally not used. There are a few places where\n+  \/\/ the original value of rsp needs to be known but that can be computed\n+  \/\/ from the value of rsp immediately after pusha (rsp + 16 * wordSize).\n+  __ movq(Address(rsp, 10 * wordSize), rbp);\n+  __ movq(Address(rsp, 9 * wordSize), rsi);\n+  __ movq(Address(rsp, 8 * wordSize), rdi);\n+  __ movq(Address(rsp, 7 * wordSize), r8);\n+  __ movq(Address(rsp, 6 * wordSize), r9);\n+  __ movq(Address(rsp, 5 * wordSize), r10);\n+  __ movq(Address(rsp, 4 * wordSize), r11);\n+  __ movq(Address(rsp, 3 * wordSize), r12);\n+  __ movq(Address(rsp, 2 * wordSize), r13);\n+  __ movq(Address(rsp, wordSize), r14);\n+  __ movq(Address(rsp, 0), r15);\n+  __ push_FPU_state();\n+\n@@ -250,0 +293,11 @@\n+\n+#if COMPILER2_OR_JVMCI\n+  if (UseAPX) {\n+      int base_addr = XSAVE_AREA_EGPRS;\n+      off = 0;\n+      for(int n = 16; n < Register::number_of_registers; n++) {\n+        __ movq(Address(rsp, base_addr+(off++*8)), as_Register(n));\n+      }\n+  }\n+#endif\n+\n@@ -282,0 +336,19 @@\n+\n+  if (UseAPX) {\n+    map->set_callee_saved(STACK_OFFSET( r16_off ), r16->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r17_off ), r17->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r18_off ), r18->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r19_off ), r19->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r20_off ), r20->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r21_off ), r21->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r22_off ), r22->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r23_off ), r23->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r24_off ), r24->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r25_off ), r25->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r26_off ), r26->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r27_off ), r27->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r28_off ), r28->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r29_off ), r29->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r30_off ), r30->as_VMReg());\n+    map->set_callee_saved(STACK_OFFSET( r31_off ), r31->as_VMReg());\n+  }\n@@ -342,0 +415,18 @@\n+    if (UseAPX) {\n+      map->set_callee_saved(STACK_OFFSET( r16H_off ), r16->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r17H_off ), r17->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r18H_off ), r18->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r19H_off ), r19->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r20H_off ), r20->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r21H_off ), r21->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r22H_off ), r22->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r23H_off ), r23->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r24H_off ), r24->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r25H_off ), r25->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r26H_off ), r26->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r27H_off ), r27->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r28H_off ), r28->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r29H_off ), r29->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r30H_off ), r30->as_VMReg()->next());\n+      map->set_callee_saved(STACK_OFFSET( r31H_off ), r31->as_VMReg()->next());\n+    }\n@@ -431,0 +522,10 @@\n+#if COMPILER2_OR_JVMCI\n+  if (UseAPX) {\n+    int base_addr = XSAVE_AREA_EGPRS;\n+    int off = 0;\n+    for (int n = 16; n < Register::number_of_registers; n++) {\n+      __ movq(as_Register(n), Address(rsp, base_addr+(off++*8)));\n+    }\n+  }\n+#endif\n+\n@@ -432,1 +533,22 @@\n-  __ pop_CPU_state();\n+  __ pop_FPU_state();\n+\n+  __ movq(r15, Address(rsp, 0));\n+  __ movq(r14, Address(rsp, wordSize));\n+  __ movq(r13, Address(rsp, 2 * wordSize));\n+  __ movq(r12, Address(rsp, 3 * wordSize));\n+  __ movq(r11, Address(rsp, 4 * wordSize));\n+  __ movq(r10, Address(rsp, 5 * wordSize));\n+  __ movq(r9,  Address(rsp, 6 * wordSize));\n+  __ movq(r8,  Address(rsp, 7 * wordSize));\n+  __ movq(rdi, Address(rsp, 8 * wordSize));\n+  __ movq(rsi, Address(rsp, 9 * wordSize));\n+  __ movq(rbp, Address(rsp, 10 * wordSize));\n+  \/\/ Skip rsp as it is restored automatically to the value\n+  \/\/ before the corresponding pusha when popa is done.\n+  __ movq(rbx, Address(rsp, 12 * wordSize));\n+  __ movq(rdx, Address(rsp, 13 * wordSize));\n+  __ movq(rcx, Address(rsp, 14 * wordSize));\n+  __ movq(rax, Address(rsp, 15 * wordSize));\n+  __ addq(rsp, 16 * wordSize);\n+  __ addq(rsp, 8);\n+  __ popf();\n@@ -2546,0 +2668,3 @@\n+  if (UseAPX) {\n+    pad += 1024;\n+  }\n@@ -3094,1 +3219,1 @@\n-  CodeBuffer buffer(\"handler_blob\", 2048, 1024);\n+  CodeBuffer buffer(\"handler_blob\", 2348, 1024);\n@@ -3250,1 +3375,1 @@\n-  CodeBuffer buffer(name, 1200, 512);\n+  CodeBuffer buffer(name, 1752, 512);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":132,"deletions":7,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -43,1 +43,5 @@\n-  return reg->is_valid() && (UseAVX >= 3 || (reg->encoding() < 16)); \/\/ why is this not covered by is_valid()?\n+  return reg->is_valid() && (reg->encoding() < (UseAVX >= 3 ? 32 : 16)); \/\/ why is this not covered by is_valid()?\n+}\n+\n+static bool is_valid_gp(Register reg) {\n+  return reg->is_valid() && (reg->encoding() < (UseAPX ? 32 : 16));\n@@ -49,1 +53,1 @@\n-  for (Register reg = as_Register(0); reg->is_valid(); reg = reg->successor()) {\n+  for (Register reg = as_Register(0); is_valid_gp(reg); reg = reg->successor()) {\n@@ -87,1 +91,1 @@\n-  for (Register reg = as_Register(0); reg->is_valid(); reg = reg->successor()) {\n+  for (Register reg = as_Register(0); is_valid_gp(reg); reg = reg->successor()) {\n@@ -137,1 +141,1 @@\n-  for (Register reg = as_Register(0); reg->is_valid(); reg = reg->successor()) {\n+  for (Register reg = as_Register(0); is_valid_gp(reg); reg = reg->successor()) {\n","filename":"src\/hotspot\/cpu\/x86\/upcallLinker_x86_64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -118,1 +118,0 @@\n-    \/* FIXME Uncomment following code after OS enablement of\n@@ -127,1 +126,0 @@\n-    *\/\n@@ -440,1 +438,0 @@\n-    \/* FIXME: Uncomment while integrating JDK-8329032\n@@ -446,1 +443,0 @@\n-    *\/\n@@ -453,1 +449,0 @@\n-    \/* FIXME: Uncomment after integration of JDK-8329032\n@@ -459,1 +454,0 @@\n-    *\/\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -131,0 +131,47 @@\n+reg_def R16  (SOC, SOC, Op_RegI, 16, r16->as_VMReg());\n+reg_def R16_H(SOC, SOC, Op_RegI, 16, r16->as_VMReg()->next());\n+\n+reg_def R17  (SOC, SOC, Op_RegI, 17, r17->as_VMReg());\n+reg_def R17_H(SOC, SOC, Op_RegI, 17, r17->as_VMReg()->next());\n+\n+reg_def R18  (SOC, SOC, Op_RegI, 18, r18->as_VMReg());\n+reg_def R18_H(SOC, SOC, Op_RegI, 18, r18->as_VMReg()->next());\n+\n+reg_def R19  (SOC, SOC, Op_RegI, 19, r19->as_VMReg());\n+reg_def R19_H(SOC, SOC, Op_RegI, 19, r19->as_VMReg()->next());\n+\n+reg_def R20  (SOC, SOC, Op_RegI, 20, r20->as_VMReg());\n+reg_def R20_H(SOC, SOC, Op_RegI, 20, r20->as_VMReg()->next());\n+\n+reg_def R21  (SOC, SOC, Op_RegI, 21, r21->as_VMReg());\n+reg_def R21_H(SOC, SOC, Op_RegI, 21, r21->as_VMReg()->next());\n+\n+reg_def R22  (SOC, SOC, Op_RegI, 22, r22->as_VMReg());\n+reg_def R22_H(SOC, SOC, Op_RegI, 22, r22->as_VMReg()->next());\n+\n+reg_def R23  (SOC, SOC, Op_RegI, 23, r23->as_VMReg());\n+reg_def R23_H(SOC, SOC, Op_RegI, 23, r23->as_VMReg()->next());\n+\n+reg_def R24  (SOC, SOC, Op_RegI, 24, r24->as_VMReg());\n+reg_def R24_H(SOC, SOC, Op_RegI, 24, r24->as_VMReg()->next());\n+\n+reg_def R25  (SOC, SOC, Op_RegI, 25, r25->as_VMReg());\n+reg_def R25_H(SOC, SOC, Op_RegI, 25, r25->as_VMReg()->next());\n+\n+reg_def R26  (SOC, SOC, Op_RegI, 26, r26->as_VMReg());\n+reg_def R26_H(SOC, SOC, Op_RegI, 26, r26->as_VMReg()->next());\n+\n+reg_def R27  (SOC, SOC, Op_RegI, 27, r27->as_VMReg());\n+reg_def R27_H(SOC, SOC, Op_RegI, 27, r27->as_VMReg()->next());\n+\n+reg_def R28  (SOC, SOC, Op_RegI, 28, r28->as_VMReg());\n+reg_def R28_H(SOC, SOC, Op_RegI, 28, r28->as_VMReg()->next());\n+\n+reg_def R29  (SOC, SOC, Op_RegI, 29, r29->as_VMReg());\n+reg_def R29_H(SOC, SOC, Op_RegI, 29, r29->as_VMReg()->next());\n+\n+reg_def R30  (SOC, SOC, Op_RegI, 30, r30->as_VMReg());\n+reg_def R30_H(SOC, SOC, Op_RegI, 30, r30->as_VMReg()->next());\n+\n+reg_def R31  (SOC, SOC, Op_RegI, 31, r31->as_VMReg());\n+reg_def R31_H(SOC, SOC, Op_RegI, 31, r31->as_VMReg()->next());\n@@ -157,0 +204,16 @@\n+                   R16,         R16_H,\n+                   R17,         R17_H,\n+                   R18,         R18_H,\n+                   R19,         R19_H,\n+                   R20,         R20_H,\n+                   R21,         R21_H,\n+                   R22,         R22_H,\n+                   R23,         R23_H,\n+                   R24,         R24_H,\n+                   R25,         R25_H,\n+                   R26,         R26_H,\n+                   R27,         R27_H,\n+                   R28,         R28_H,\n+                   R29,         R29_H,\n+                   R30,         R30_H,\n+                   R31,         R31_H,\n@@ -170,1 +233,1 @@\n-\/\/ Class for all pointer\/long registers\n+\/\/ Class for all pointer\/long registers including APX extended GPRs.\n@@ -186,3 +249,19 @@\n-                  R15, R15_H);\n-\n-\/\/ Class for all int registers\n+                  R15, R15_H,\n+                  R16, R16_H,\n+                  R17, R17_H,\n+                  R18, R18_H,\n+                  R19, R19_H,\n+                  R20, R20_H,\n+                  R21, R21_H,\n+                  R22, R22_H,\n+                  R23, R23_H,\n+                  R24, R24_H,\n+                  R25, R25_H,\n+                  R26, R26_H,\n+                  R27, R27_H,\n+                  R28, R28_H,\n+                  R29, R29_H,\n+                  R30, R30_H,\n+                  R31, R31_H);\n+\n+\/\/ Class for all int registers including APX extended GPRs.\n@@ -202,1 +281,17 @@\n-                      R14);\n+                      R14,\n+                      R16,\n+                      R17,\n+                      R18,\n+                      R19,\n+                      R20,\n+                      R21,\n+                      R22,\n+                      R23,\n+                      R24,\n+                      R25,\n+                      R26,\n+                      R27,\n+                      R28,\n+                      R29,\n+                      R30,\n+                      R31);\n@@ -389,0 +484,2 @@\n+  constexpr Register egprs[] = {r16, r17, r18, r19, r20, r21, r22, r23, r24, r25, r26, r27, r28, r29, r30, r31};\n+\n@@ -407,0 +504,6 @@\n+  if (!UseAPX) {\n+    for (uint i = 0; i < sizeof(egprs)\/sizeof(Register); i++) {\n+      _PTR_REG_mask.Remove(OptoReg::as_OptoReg(egprs[i]->as_VMReg()));\n+      _PTR_REG_mask.Remove(OptoReg::as_OptoReg(egprs[i]->as_VMReg()->next()));\n+    }\n+  }\n@@ -423,0 +526,1 @@\n+\n@@ -444,0 +548,6 @@\n+  if (!UseAPX) {\n+    for (uint i = 0; i < sizeof(egprs)\/sizeof(Register); i++) {\n+      _INT_REG_mask.Remove(OptoReg::as_OptoReg(egprs[i]->as_VMReg()));\n+    }\n+  }\n+\n@@ -12323,1 +12433,0 @@\n-  size(4); \/* setting an explicit size will cause debug builds to assert if size is incorrect *\/\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":115,"deletions":6,"binary":false,"changes":121,"status":"modified"}]}