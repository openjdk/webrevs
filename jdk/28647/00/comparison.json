{"files":[{"patch":"@@ -178,1 +178,0 @@\n-  size_t region_size_bytes = ShenandoahHeapRegion::region_size_bytes();\n@@ -1608,1 +1607,0 @@\n-  size_t ac = alloc_capacity(r);\n@@ -1610,1 +1608,0 @@\n-  ShenandoahGeneration* request_generation = nullptr;\n@@ -1612,1 +1609,0 @@\n-    request_generation = _heap->mode()->is_generational()? _heap->young_generation(): _heap->global_generation();\n@@ -1615,1 +1611,0 @@\n-    request_generation = _heap->old_generation();\n@@ -1619,1 +1614,0 @@\n-    request_generation = _heap->mode()->is_generational()? _heap->young_generation(): _heap->global_generation();\n@@ -1691,1 +1685,0 @@\n-  ShenandoahGeneration* generation = _heap->generation_for(req.affiliation());\n@@ -1836,91 +1829,0 @@\n-private:\n-  static const ssize_t SentinelUsed = -1;\n-  static const ssize_t SentinelIndex = -1;\n-  static const size_t MaxSavedRegions = 128;\n-\n-  ShenandoahRegionPartitions* _partitions;\n-  volatile size_t _recycled_region_count;\n-  ssize_t _region_indices[MaxSavedRegions];\n-  ssize_t _region_used[MaxSavedRegions];\n-\n-  void get_lock_and_flush_buffer(size_t region_count, size_t overflow_region_used, size_t overflow_region_index) {\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahHeapLocker locker(heap->lock());\n-    size_t recycled_regions = AtomicAccess::load(&_recycled_region_count);\n-    size_t region_tallies[int(ShenandoahRegionPartitions::NumPartitions)];\n-    size_t used_byte_tallies[int(ShenandoahRegionPartitions::NumPartitions)];\n-    for (int p = 0; p < int(ShenandoahRegionPartitions::NumPartitions); p++) {\n-      region_tallies[p] = 0;\n-      used_byte_tallies[p] = 0;\n-    }\n-    ShenandoahFreeSetPartitionId p = _partitions->membership(overflow_region_index);\n-    used_byte_tallies[int(p)] += overflow_region_used;\n-    if (region_count <= recycled_regions) {\n-      \/\/ _recycled_region_count has not been decremented after I incremented it to obtain region_count, so I will\n-      \/\/ try to flush the buffer.\n-\n-      \/\/ Multiple worker threads may attempt to flush this buffer.  The first thread to acquire the lock does the work.\n-      \/\/ _recycled_region_count is only decreased while holding the heap lock.\n-      if (region_count > recycled_regions) {\n-        region_count = recycled_regions;\n-      }\n-      for (size_t i = 0; i < region_count; i++) {\n-        ssize_t used;\n-        \/\/ wait for other threads to finish updating their entries within the region buffer before processing entry\n-        do {\n-          used = _region_used[i];\n-        } while (used == SentinelUsed);\n-        ssize_t index;\n-        do {\n-          index = _region_indices[i];\n-        } while (index == SentinelIndex);\n-\n-        ShenandoahFreeSetPartitionId p = _partitions->membership(index);\n-        assert(p != ShenandoahFreeSetPartitionId::NotFree, \"Trashed regions should be in a free partition\");\n-        used_byte_tallies[int(p)] += used;\n-        region_tallies[int(p)]++;\n-      }\n-      if (region_count > 0) {\n-        for (size_t i = 0; i < MaxSavedRegions; i++) {\n-          _region_indices[i] = SentinelIndex;\n-          _region_used[i] = SentinelUsed;\n-        }\n-      }\n-\n-      \/\/ The almost last thing we do before releasing the lock is to set the _recycled_region_count to 0.  What happens next?\n-      \/\/\n-      \/\/  1. Any worker thread that attempted to buffer a new region while we were flushing the buffer will have seen\n-      \/\/     that _recycled_region_count > MaxSavedRegions. All such worker threads will first wait for the lock, then\n-      \/\/     discover that the _recycled_region_count is zero, then, while holding the lock, they will process the\n-      \/\/     region so it doesn't have to be placed into the buffer.  This handles the large majority of cases.\n-      \/\/\n-      \/\/  2. However, there's a race that can happen, which will result in someewhat different behavior.  Suppose\n-      \/\/     this thread resets _recycled_region_count to 0.  Then some other worker thread increments _recycled_region_count\n-      \/\/     in order to stores its region into the buffer and suppose this happens before all of the other worker threads\n-      \/\/     which are waiting to acquire the heap lock have finished their efforts to flush the buffer.  If this happens,\n-      \/\/     then the workers who are waiting to acquire the heap lock and flush the buffer will find that _recycled_region_count\n-      \/\/     has decreased from the value it held when they last tried to increment its value.  In this case, these worker\n-      \/\/     threads will process their overflow region while holding the lock, but they will not attempt to process regions\n-      \/\/     newly placed into the buffer.  Otherwise, confusion could result.\n-      \/\/\n-      \/\/ Assumption: all worker threads who are attempting to acquire lock and flush buffer will finish their efforts before\n-      \/\/             the buffer once again overflows.\n-      \/\/ How could we avoid depending on this assumption?\n-      \/\/   1. Let MaxSavedRegions be as large as number of regions, or at least as large as the collection set.\n-      \/\/   2. Keep a count of how many times the buffer has been flushed per instantation of the\n-      \/\/      ShenandoahRecycleTrashedRegionClosure object, and only consult\/update this value while holding the heap lock.\n-      \/\/      Need to think about how this helps resolve the race.\n-      _recycled_region_count = 0;\n-    } else {\n-      \/\/ Some other thread has already processed the buffer, resetting _recycled_region_count to zero. Its current value\n-      \/\/ may be greater than zero because other workers may have accumulated entries into the buffer. But it is \"extremely\"\n-      \/\/ unlikely that it will overflow again before all waiting workers have had a chance to clear their state. While I've\n-      \/\/ got the heap lock, I'll go ahead and update the global state for my overflow region. I'll let other heap regions\n-      \/\/ accumulate in the buffer to be processed when the buffer is once again full.\n-      region_count = 0;\n-    }\n-    for (size_t p = 0; p < int(ShenandoahRegionPartitions::NumPartitions); p++) {\n-      _partitions->decrease_used(ShenandoahFreeSetPartitionId(p), used_byte_tallies[p]);\n-    }\n-  }\n-\n@@ -1928,9 +1830,0 @@\n-  ShenandoahRecycleTrashedRegionClosure(ShenandoahRegionPartitions* p): ShenandoahHeapRegionClosure() {\n-    _partitions = p;\n-    _recycled_region_count = 0;\n-    for (size_t i = 0; i < MaxSavedRegions; i++) {\n-      _region_indices[i] = SentinelIndex;\n-      _region_used[i] = SentinelUsed;\n-    }\n-  }\n-\n@@ -1953,1 +1846,1 @@\n-  ShenandoahRecycleTrashedRegionClosure closure(&_partitions);\n+  ShenandoahRecycleTrashedRegionClosure closure;\n@@ -1959,2 +1852,0 @@\n-  ShenandoahYoungGeneration* young_gen = gen_heap->young_generation();\n-  ShenandoahOldGeneration* old_gen = gen_heap->old_generation();\n@@ -1988,1 +1879,0 @@\n-  ShenandoahGenerationalHeap* gen_heap = ShenandoahGenerationalHeap::heap();\n@@ -2136,1 +2026,0 @@\n-  bool is_generational = _heap->mode()->is_generational();\n@@ -2225,1 +2114,0 @@\n-        size_t ac = alloc_capacity(region);\n@@ -3123,1 +3011,0 @@\n-      size_t total_trashed_free = 0;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":1,"deletions":114,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -527,1 +527,0 @@\n-  ShenandoahYoungGeneration* young_gen = heap->young_generation();\n@@ -565,1 +564,0 @@\n-  size_t min_remnant_size = PLAB::min_size() * HeapWordSize;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -691,13 +691,0 @@\n-void ShenandoahGenerationalHeap::TransferResult::print_on(const char* when, outputStream* ss) const {\n-  auto heap = ShenandoahGenerationalHeap::heap();\n-  ShenandoahYoungGeneration* const young_gen = heap->young_generation();\n-  ShenandoahOldGeneration* const old_gen = heap->old_generation();\n-  const size_t young_available = young_gen->available();\n-  const size_t old_available = old_gen->available();\n-  ss->print_cr(\"After %s, %s %zu regions to %s to prepare for next gc, old available: \"\n-                     PROPERFMT \", young_available: \" PROPERFMT,\n-                     when,\n-                     success? \"successfully transferred\": \"failed to transfer\", region_count, region_destination,\n-                     PROPERFMTARGS(old_available), PROPERFMTARGS(young_available));\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -135,9 +135,0 @@\n-  \/\/ Used for logging the result of a region transfer outside the heap lock\n-  struct TransferResult {\n-    bool success;\n-    size_t region_count;\n-    const char* region_destination;\n-\n-    void print_on(const char* when, outputStream* ss) const;\n-  };\n-\n@@ -150,3 +141,0 @@\n-  \/\/ Transfers surplus old regions to young, or takes regions from young to satisfy old region deficit\n-  TransferResult balance_generations();\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.hpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -160,1 +160,1 @@\n-  size_t new_live_data = AtomicAccess::add(&_live_data, s, memory_order_relaxed);\n+  AtomicAccess::add(&_live_data, s, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -65,1 +65,0 @@\n-  bool resume_old_cycle();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRegulatorThread.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -236,2 +236,0 @@\n-  inline void mark_card_as_clean(size_t card_index);\n-  inline void mark_range_as_clean(size_t card_index, size_t num_cards);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahScanRemembered.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"}]}