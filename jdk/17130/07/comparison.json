{"files":[{"patch":"@@ -4812,0 +4812,346 @@\n+\n+  \/\/ ------------------------ SHA-1 intrinsic ------------------------\n+\n+  \/\/ K't =\n+  \/\/    5a827999, 0  <= t <= 19\n+  \/\/    6ed9eba1, 20 <= t <= 39\n+  \/\/    8f1bbcdc, 40 <= t <= 59\n+  \/\/    ca62c1d6, 60 <= t <= 79\n+  void sha1_prepare_k(int round, Register cur_k) {\n+    assert(round >= 0 && round < 80, \"must be\");\n+\n+    static const int64_t ks[] = {0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6};\n+    if ((round % 20) == 0) {\n+      __ mv(cur_k, ks[round\/20]);\n+    }\n+  }\n+\n+  \/\/ W't =\n+  \/\/    M't,                                      0 <=  t <= 15\n+  \/\/    ROTL'1(W't-3 ^ W't-8 ^ W't-14 ^ W't-16),  16 <= t <= 79\n+  void sha1_prepare_w(int round, Register cur_w, Register ws[], Register buf,\n+                      Register tmp1, Register tmp2, Register tmp3) {\n+    assert(round >= 0 && round < 80, \"must be\");\n+\n+    if (round < 16) {\n+      if ((round % 2) == 0) {\n+        __ ld(ws[round\/2], Address(buf, round * 4));\n+        \/\/ reverse bytes, as SHA-1 is defined in big-endian.\n+        __ revb(ws[round\/2], ws[round\/2]);\n+        __ srli(cur_w, ws[round\/2], 32);\n+      } else {\n+        __ mv(cur_w, ws[round\/2]);\n+      }\n+\n+      return;\n+    }\n+\n+    if (round == 16) {\n+      int64_t block_bytes = round * 4;\n+      __ addi(buf, buf, block_bytes);\n+    }\n+\n+    if ((round % 2) == 0) {\n+      int idx = 16;\n+      \/\/ W't = ROTL'1(W't-3 ^ W't-8 ^ W't-14 ^ W't-16),  16 <= t <= 79\n+      __ mv(tmp1, ws[(idx-3)\/2]);\n+      __ srli(tmp2, ws[(idx-8)\/2], 32);\n+      __ xorr(tmp1, tmp1, tmp2);\n+\n+      __ srli(tmp3, ws[(idx-14)\/2], 32);\n+      __ srli(cur_w, ws[(idx-16)\/2], 32);\n+      __ xorr(cur_w, cur_w, tmp3);\n+\n+      __ xorr(cur_w, cur_w, tmp1);\n+      __ rolw_imm(cur_w, cur_w, 1, tmp1);\n+\n+      \/\/ copy the cur_w value to ws[8].\n+      \/\/ now, valid w't values are at:\n+      \/\/  w0:       ws[0]'s lower 32 bits\n+      \/\/  w1 ~ w14: ws[1] ~ ws[7]\n+      \/\/  w15:      ws[8]'s higher 32 bits\n+      __ slli(ws[idx\/2], cur_w, 32);\n+\n+      return;\n+    }\n+\n+    int idx = 17;\n+    \/\/ W't = ROTL'1(W't-3 ^ W't-8 ^ W't-14 ^ W't-16),  16 <= t <= 79\n+    __ srli(tmp1, ws[(idx-3)\/2], 32);\n+    __ mv(tmp2, ws[(idx-8)\/2]);\n+    __ xorr(tmp1, tmp1, tmp2);\n+\n+    __ mv(tmp3, ws[(idx-14)\/2]);\n+    __ mv(cur_w, ws[(idx-16)\/2]);\n+    __ xorr(cur_w, cur_w, tmp3);\n+\n+    __ xorr(cur_w, cur_w, tmp1);\n+    __ rolw_imm(cur_w, cur_w, 1, tmp1);\n+\n+    \/\/ copy the cur_w value to ws[8]\n+    __ zero_extend(cur_w, cur_w, 32);\n+    __ orr(ws[idx\/2], ws[idx\/2], cur_w);\n+\n+    \/\/ shift the w't registers, so they start from ws[0] again.\n+    \/\/ now, valid w't values are at:\n+    \/\/  w0 ~ w15: ws[0] ~ ws[7]\n+    Register ws_0 = ws[0];\n+    for (int i = 0; i < 16\/2; i++) {\n+      ws[i] = ws[i+1];\n+    }\n+    ws[8] = ws_0;\n+  }\n+\n+  \/\/ f't(x, y, z) =\n+  \/\/    Ch(x, y, z)     = (x & y) ^ (~x & z)            , 0  <= t <= 19\n+  \/\/    Parity(x, y, z) = x ^ y ^ z                     , 20 <= t <= 39\n+  \/\/    Maj(x, y, z)    = (x & y) ^ (x & z) ^ (y & z)   , 40 <= t <= 59\n+  \/\/    Parity(x, y, z) = x ^ y ^ z                     , 60 <= t <= 79\n+  void sha1_f(int round, Register dst, Register x, Register y, Register z,\n+              Register tmp1, Register tmp2) {\n+    assert(round >= 0 && round < 80, \"must be\");\n+    assert_different_registers(dst, x, y, z, tmp1, tmp2);\n+\n+    if (round < 20) {\n+      \/\/ (x & y) ^ (~x & z)\n+      __ andr(tmp1, x, y);\n+      __ andn(dst, z, x);\n+      __ xorr(dst, dst, tmp1);\n+    } else if (round >= 40 && round < 60) {\n+      \/\/ (x & y) ^ (x & z) ^ (y & z)\n+      __ andr(tmp1, x, y);\n+      __ andr(tmp2, x, z);\n+      __ andr(dst, y, z);\n+      __ xorr(dst, dst, tmp1);\n+      __ xorr(dst, dst, tmp2);\n+    } else {\n+      \/\/ x ^ y ^ z\n+      __ xorr(dst, x, y);\n+      __ xorr(dst, dst, z);\n+    }\n+  }\n+\n+  \/\/ T = ROTL'5(a) + f't(b, c, d) + e + K't + W't\n+  \/\/ e = d\n+  \/\/ d = c\n+  \/\/ c = ROTL'30(b)\n+  \/\/ b = a\n+  \/\/ a = T\n+  void sha1_process_round(int round, Register a, Register b, Register c, Register d, Register e,\n+                          Register cur_k, Register cur_w,\n+                          Register tmp1, Register tmp2, Register tmp3) {\n+    assert(round >= 0 && round < 80, \"must be\");\n+    assert_different_registers(a, b, c, d, e, cur_w, cur_k, tmp1, tmp2, tmp3);\n+\n+    \/\/ T = ROTL'5(a) + f't(b, c, d) + e + K't + W't\n+    {\n+      \/\/ reuse e as a temporary register, as we will mv new value into it later\n+      Register t = e;\n+      \/\/ cur_w will be recalculated at the beginning of each round,\n+      \/\/ so, we can reuse it as a temp register here.\n+      __ add(cur_w, cur_k, cur_w);\n+      __ add(t, t, cur_w);\n+      __ rolw_imm(tmp1, a, 5, tmp2);\n+      \/\/ as pointed above, we can use cur_w as temporary register here.\n+      sha1_f(round, tmp3, b, c, d, cur_w, tmp2);\n+      __ add(tmp1, tmp1, tmp3);\n+      __ add(tmp1, tmp1, t);\n+    }\n+\n+    \/\/ e = d\n+    \/\/ d = c\n+    \/\/ c = ROTL'30(b)\n+    \/\/ b = a\n+    \/\/ a = T\n+    __ mv(e, d);\n+    __ mv(d, c);\n+    \/\/ as pointed above, we can use cur_w as temporary register here.\n+    __ rolw_imm(c, b, 30, cur_w);\n+    __ mv(b, a);\n+    __ mv(a, tmp1);\n+  }\n+\n+  \/\/ H(i)0 = a + H(i-1)0\n+  \/\/ H(i)1 = b + H(i-1)1\n+  \/\/ H(i)2 = c + H(i-1)2\n+  \/\/ H(i)3 = d + H(i-1)3\n+  \/\/ H(i)4 = e + H(i-1)4\n+  void sha1_calculate_im_hash(Register a, Register b, Register c, Register d, Register e,\n+                              Register prev_ab, Register prev_cd, Register prev_e) {\n+    assert_different_registers(a, b, c, d, e, prev_ab, prev_cd, prev_e);\n+\n+    __ add(a, a, prev_ab);\n+    __ srli(prev_ab, prev_ab, 32);\n+    __ add(b, b, prev_ab);\n+\n+    __ add(c, c, prev_cd);\n+    __ srli(prev_cd, prev_cd, 32);\n+    __ add(d, d, prev_cd);\n+\n+    __ add(e, e, prev_e);\n+  }\n+\n+  void sha1_preserve_prev_abcde(Register a, Register b, Register c, Register d, Register e,\n+                                Register prev_ab, Register prev_cd, Register prev_e,\n+                                Register tmp) {\n+    assert_different_registers(a, b, c, d, e, prev_ab, prev_cd, prev_e, tmp);\n+\n+    __ slli(tmp, b, 32);\n+    __ zero_extend(prev_ab, a, 32);\n+    __ orr(prev_ab, prev_ab, tmp);\n+\n+    __ slli(tmp, d, 32);\n+    __ zero_extend(prev_cd, c, 32);\n+    __ orr(prev_cd, prev_cd, tmp);\n+\n+    __ mv(prev_e, e);\n+  }\n+\n+  \/\/ Intrinsic for:\n+  \/\/   void sun.security.provider.SHA.implCompress0(byte[] buf, int ofs)\n+  \/\/   void sun.security.provider.DigestBase.implCompressMultiBlock0(byte[] b, int ofs, int limit)\n+  \/\/\n+  \/\/ Arguments:\n+  \/\/\n+  \/\/ Inputs:\n+  \/\/   c_rarg0: byte[]  src array + offset\n+  \/\/   c_rarg1: int[]   SHA.state\n+  \/\/   - - - - - - below are only for implCompressMultiBlock0 - - - - - -\n+  \/\/   c_rarg2: int     offset\n+  \/\/   c_rarg3: int     limit\n+  \/\/\n+  \/\/ Outpus:\n+  \/\/   - - - - - - below are only for implCompressMultiBlock0 - - - - - -\n+  \/\/   c_rarg0: int offset, when (multi_block == true)\n+  \/\/\n+  address generate_sha1_implCompress(bool multi_block, const char *name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+\n+    address start = __ pc();\n+    __ enter();\n+\n+    RegSet saved_regs = RegSet::range(x18, x27);\n+    if (multi_block) {\n+      \/\/ use x9 as src below.\n+      saved_regs += RegSet::of(x9);\n+    }\n+    __ push_reg(saved_regs, sp);\n+\n+    \/\/ c_rarg0 - c_rarg3: x10 - x13\n+    Register buf    = c_rarg0;\n+    Register state  = c_rarg1;\n+    Register offset = c_rarg2;\n+    Register limit  = c_rarg3;\n+    \/\/ use src to contain the original start point of the array.\n+    Register src    = x9;\n+\n+    if (multi_block) {\n+      __ sub(limit, limit, offset);\n+      __ add(limit, limit, buf);\n+      __ sub(src, buf, offset);\n+    }\n+\n+    \/\/ [args-reg]:  x14 - x17\n+    \/\/ [temp-reg]:  x28 - x31\n+    \/\/ [saved-reg]: x18 - x27\n+\n+    \/\/ h0\/1\/2\/3\/4\n+    const Register a = x14, b = x15, c = x16, d = x17, e = x28;\n+    \/\/ w0, w1, ... w15\n+    \/\/ put two adjecent w's in one register:\n+    \/\/    one at high word part, another at low word part\n+    \/\/ at different round (even or odd), w't value resdie in different items in ws[].\n+    \/\/ w0 ~ w15, either reside in\n+    \/\/    ws[0] ~ ws[7], where\n+    \/\/      w0 at higher 32 bits of ws[0],\n+    \/\/      w1 at lower 32 bits of ws[0],\n+    \/\/      ...\n+    \/\/      w14 at higher 32 bits of ws[7],\n+    \/\/      w15 at lower 32 bits of ws[7].\n+    \/\/ or, reside in\n+    \/\/    w0:       ws[0]'s lower 32 bits\n+    \/\/    w1 ~ w14: ws[1] ~ ws[7]\n+    \/\/    w15:      ws[8]'s higher 32 bits\n+    Register ws[9] = {x29, x30, x31, x18,\n+                      x19, x20, x21, x22,\n+                      x23}; \/\/ auxiliary register for calculating w's value\n+    \/\/ current k't's value\n+    const Register cur_k = x24;\n+    \/\/ current w't's value\n+    const Register cur_w = x25;\n+    \/\/ values of a, b, c, d, e in the previous round\n+    const Register prev_ab = x26, prev_cd = x27;\n+    const Register prev_e = offset; \/\/ reuse offset\/c_rarg2\n+\n+    \/\/ load 5 words state into a, b, c, d, e.\n+    \/\/\n+    \/\/ To minimize the number of memory operations, we apply following\n+    \/\/ optimization: read the states (a\/b\/c\/d) of 4-byte values in pairs,\n+    \/\/ with a single ld, and split them into 2 registers.\n+    \/\/\n+    \/\/ And, as the core algorithm of SHA-1 works on 32-bits words, so\n+    \/\/ in the following code, it does not care about the content of\n+    \/\/ higher 32-bits in a\/b\/c\/d\/e. Based on this observation,\n+    \/\/ we can apply further optimization, which is to just ignore the\n+    \/\/ higher 32-bits in a\/c\/e, rather than set the higher\n+    \/\/ 32-bits of a\/c\/e to zero explicitly with extra instructions.\n+    __ ld(a, Address(state, 0));\n+    __ srli(b, a, 32);\n+    __ ld(c, Address(state, 8));\n+    __ srli(d, c, 32);\n+    __ lw(e, Address(state, 16));\n+\n+    Label L_sha1_loop;\n+    if (multi_block) {\n+      __ BIND(L_sha1_loop);\n+    }\n+\n+    sha1_preserve_prev_abcde(a, b, c, d, e, prev_ab, prev_cd, prev_e, t0);\n+\n+    for (int round = 0; round < 80; round++) {\n+      \/\/ prepare K't value\n+      sha1_prepare_k(round, cur_k);\n+\n+      \/\/ prepare W't value\n+      sha1_prepare_w(round, cur_w, ws, buf, t0, t1, t2);\n+\n+      \/\/ one round process\n+      sha1_process_round(round, a, b, c, d, e, cur_k, cur_w, t0, t1, t2);\n+    }\n+\n+    \/\/ compute the intermediate hash value\n+    sha1_calculate_im_hash(a, b, c, d, e, prev_ab, prev_cd, prev_e);\n+\n+    if (multi_block) {\n+      __ bge(limit, buf, L_sha1_loop, true);\n+    }\n+\n+    const Register mask32 = t2;\n+    __ mv(mask32, 0xffffffff);\n+    \/\/ store back the state.\n+    __ andr(a, a, mask32);\n+    __ slli(b, b, 32);\n+    __ orr(a, a, b);\n+    __ sd(a, Address(state, 0));\n+    __ andr(c, c, mask32);\n+    __ slli(d, d, 32);\n+    __ orr(c, c, d);\n+    __ sd(c, Address(state, 8));\n+    __ sw(e, Address(state, 16));\n+\n+    \/\/ return offset\n+    if (multi_block) {\n+      __ sub(c_rarg0, buf, src);\n+    }\n+\n+    __ pop_reg(saved_regs, sp);\n+\n+    __ leave();\n+    __ ret();\n+\n+    return (address) start;\n+  }\n+\n+\n+\n@@ -5276,0 +5622,5 @@\n+    if (UseSHA1Intrinsics) {\n+      StubRoutines::_sha1_implCompress     = generate_sha1_implCompress(false, \"sha1_implCompress\");\n+      StubRoutines::_sha1_implCompressMB   = generate_sha1_implCompress(true, \"sha1_implCompressMB\");\n+    }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/stubGenerator_riscv.cpp","additions":351,"deletions":0,"binary":false,"changes":351,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  _compiler_stubs_code_size     = 15000 ZGC_ONLY(+5000),\n+  _compiler_stubs_code_size     = 25000 ZGC_ONLY(+5000),\n","filename":"src\/hotspot\/cpu\/riscv\/stubRoutines_riscv.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -152,10 +152,0 @@\n-  if (UseSHA1Intrinsics) {\n-    warning(\"Intrinsics for SHA-1 crypto hash functions not available on this CPU.\");\n-    FLAG_SET_DEFAULT(UseSHA1Intrinsics, false);\n-  }\n-\n-  if (UseSHA3Intrinsics) {\n-    warning(\"Intrinsics for SHA3-224, SHA3-256, SHA3-384 and SHA3-512 crypto hash functions not available on this CPU.\");\n-    FLAG_SET_DEFAULT(UseSHA3Intrinsics, false);\n-  }\n-\n@@ -263,4 +253,0 @@\n-  if (UseZvkn && !UseRVV) {\n-    FLAG_SET_DEFAULT(UseZvkn, false);\n-    warning(\"Cannot enable Zvkn on cpu without RVV support.\");\n-  }\n@@ -268,0 +254,1 @@\n+  \/\/ ChaCha20\n@@ -279,4 +266,2 @@\n-  if (!UseZvkn && UseSHA) {\n-    warning(\"SHA instructions are not available on this CPU\");\n-    FLAG_SET_DEFAULT(UseSHA, false);\n-  } else if (UseZvkn && FLAG_IS_DEFAULT(UseSHA)) {\n+  \/\/ SHA's\n+  if (FLAG_IS_DEFAULT(UseSHA)) {\n@@ -286,1 +271,35 @@\n-  if (!UseSHA) {\n+  \/\/ SHA-1, no RVV required though.\n+  if (UseSHA) {\n+    if (FLAG_IS_DEFAULT(UseSHA1Intrinsics)) {\n+      FLAG_SET_DEFAULT(UseSHA1Intrinsics, true);\n+    }\n+  } else if (UseSHA1Intrinsics) {\n+    warning(\"Intrinsics for SHA-1 crypto hash functions not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseSHA1Intrinsics, false);\n+  }\n+\n+  \/\/ UseZvkn (depends on RVV) and SHA-2.\n+  if (UseZvkn && !UseRVV) {\n+    FLAG_SET_DEFAULT(UseZvkn, false);\n+    warning(\"Cannot enable Zvkn on cpu without RVV support.\");\n+  }\n+  \/\/ SHA-2, depends on Zvkn.\n+  if (UseSHA) {\n+    if (UseZvkn) {\n+      if (FLAG_IS_DEFAULT(UseSHA256Intrinsics)) {\n+        FLAG_SET_DEFAULT(UseSHA256Intrinsics, true);\n+      }\n+      if (FLAG_IS_DEFAULT(UseSHA512Intrinsics)) {\n+        FLAG_SET_DEFAULT(UseSHA512Intrinsics, true);\n+      }\n+    } else {\n+      if (UseSHA256Intrinsics) {\n+        warning(\"Intrinsics for SHA-224 and SHA-256 crypto hash functions not available on this CPU, UseZvkn needed.\");\n+        FLAG_SET_DEFAULT(UseSHA256Intrinsics, false);\n+      }\n+      if (UseSHA512Intrinsics) {\n+        warning(\"Intrinsics for SHA-384 and SHA-512 crypto hash functions not available on this CPU, UseZvkn needed.\");\n+        FLAG_SET_DEFAULT(UseSHA512Intrinsics, false);\n+      }\n+    }\n+  } else {\n@@ -288,1 +307,1 @@\n-      warning(\"Intrinsics for SHA-224 and SHA-256 crypto hash functions not available on this CPU, UseZvkn needed.\");\n+      warning(\"Intrinsics for SHA-224 and SHA-256 crypto hash functions not available on this CPU, as UseSHA disabled.\");\n@@ -292,1 +311,1 @@\n-      warning(\"Intrinsics for SHA-384 and SHA-512 crypto hash functions not available on this CPU, UseZvkn needed.\");\n+      warning(\"Intrinsics for SHA-384 and SHA-512 crypto hash functions not available on this CPU, as UseSHA disabled.\");\n@@ -295,7 +314,11 @@\n-  } else {\n-    if (FLAG_IS_DEFAULT(UseSHA256Intrinsics)) {\n-       FLAG_SET_DEFAULT(UseSHA256Intrinsics, true);\n-    }\n-    if (FLAG_IS_DEFAULT(UseSHA512Intrinsics)) {\n-      FLAG_SET_DEFAULT(UseSHA512Intrinsics, true);\n-    }\n+  }\n+\n+  \/\/ SHA-3\n+  if (UseSHA3Intrinsics) {\n+    warning(\"Intrinsics for SHA3-224, SHA3-256, SHA3-384 and SHA3-512 crypto hash functions not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UseSHA3Intrinsics, false);\n+  }\n+\n+  \/\/ UseSHA\n+  if (!(UseSHA1Intrinsics || UseSHA256Intrinsics || UseSHA3Intrinsics || UseSHA512Intrinsics)) {\n+    FLAG_SET_DEFAULT(UseSHA, false);\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.cpp","additions":51,"deletions":28,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -72,1 +72,2 @@\n-              new OrPredicate(new CPUSpecificPredicate(\"riscv64.*\", new String[] { \"sha1\" }, null),\n+              \/\/ on riscv64, SHA-1 intrinsic is implemented with basic instructions\n+              new OrPredicate(new CPUSpecificPredicate(\"riscv64.*\", null, null),\n","filename":"test\/hotspot\/jtreg\/compiler\/testlibrary\/sha\/predicate\/IntrinsicPredicates.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"}]}