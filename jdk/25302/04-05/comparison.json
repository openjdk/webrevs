{"files":[{"patch":"@@ -35,1 +35,2 @@\n-  return jt->jfr_thread_local()->has_sample_request() || jt->jfr_thread_local()->has_cpu_time_jfr_requests();\n+  JfrThreadLocal* tl = jt->jfr_thread_local();\n+  return tl->has_sample_request() || tl->has_cpu_time_jfr_requests();\n","filename":"src\/hotspot\/share\/jfr\/jfr.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n@@ -29,0 +28,1 @@\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrJniMethod.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -972,1 +972,1 @@\n-    <Field type=\"boolean\" name=\"biased\" label=\"Biased\" description=\"The sample is biased towards the frame at safepoint\" \/>\n+    <Field type=\"boolean\" name=\"biased\" label=\"Biased\" description=\"The sample is safepoint-biased\" \/>\n@@ -975,1 +975,1 @@\n-  <Event name=\"CPUTimeSampleLoss\" category=\"Java Virtual Machine, Profiling\" label=\"CPU Time Method Profiling Lost Samples\" description=\"Records that the CPU time sampler lost samples because of internal throttling\"\n+  <Event name=\"CPUTimeSampleLoss\" category=\"Java Virtual Machine, Profiling\" label=\"CPU Time Method Profiling Lost Samples\" description=\"Records that the CPU time sampler lost samples\"\n@@ -1261,1 +1261,1 @@\n-  \n+\n","filename":"src\/hotspot\/share\/jfr\/metadata\/metadata.xml","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"gc\/shared\/barrierSet.hpp\"\n@@ -31,1 +30,0 @@\n-#include \"utilities\/utf8.hpp\"\n@@ -36,4 +34,0 @@\n-#include \"jfr\/recorder\/service\/jfrOptionSet.hpp\"\n-#include \"jfr\/recorder\/service\/jfrEvent.hpp\"\n-#include \"jfr\/utilities\/jfrThreadIterator.hpp\"\n-#include \"jfr\/utilities\/jfrTypes.hpp\"\n@@ -41,1 +35,0 @@\n-#include \"jfr\/recorder\/storage\/jfrBuffer.hpp\"\n@@ -43,0 +36,2 @@\n+#include \"jfr\/utilities\/jfrThreadIterator.hpp\"\n+#include \"jfr\/utilities\/jfrTypes.hpp\"\n@@ -49,2 +44,0 @@\n-#include \"runtime\/threadCrashProtection.hpp\"\n-#include \"runtime\/osThread.hpp\"\n@@ -145,2 +138,3 @@\n-  while (Atomic::cmpxchg(&_lost_samples, lost_samples, 0) != lost_samples) {\n-    lost_samples = Atomic::load_acquire(&_lost_samples);\n+  s4 new_lost_samples;\n+  while ((new_lost_samples = Atomic::cmpxchg(&_lost_samples, lost_samples, 0)) != lost_samples) {\n+    lost_samples = new_lost_samples;\n@@ -169,1 +163,6 @@\n-static int64_t compute_sampling_period(double rate);\n+static int64_t compute_sampling_period(double rate) {\n+  if (rate == 0) {\n+    return 0;\n+  }\n+  return os::active_processor_count() * 1000000000.0 \/ rate;\n+}\n@@ -178,1 +177,1 @@\n-  volatile int64_t _current_sampling_period_ns = -1;\n+  volatile int64_t _current_sampling_period_ns;\n@@ -180,3 +179,3 @@\n-  volatile bool _stop_signals = false;\n-  volatile int _active_signal_handlers = 0;\n-  volatile bool _is_out_of_safepoint_sampling_triggered = false;\n+  volatile bool _stop_signals;\n+  volatile int _active_signal_handlers;\n+  volatile bool _is_thread_in_native_stackwalking_triggered;\n@@ -185,1 +184,0 @@\n-  ~JfrCPUTimeThreadSampler();\n@@ -200,2 +198,2 @@\n-  \/\/ sample all marked threads out of safepoint\n-  void sample_out_of_safepoint();\n+  \/\/ sample all threads that are in native state (and requested to be sampled)\n+  void stackwalk_threads_in_native();\n@@ -203,1 +201,1 @@\n-  void sample_out_of_safepoint(JavaThread* thread);\n+  void stackwalk_thread_in_native(JavaThread* thread);\n@@ -219,1 +217,1 @@\n-  void trigger_out_of_safepoint_sampling();\n+  void trigger_is_thread_in_native_stackwalking();\n@@ -229,1 +227,4 @@\n-  _disenrolled(true) {\n+  _disenrolled(true),\n+  _stop_signals(false),\n+  _active_signal_handlers(0),\n+  _is_thread_in_native_stackwalking_triggered(false) {\n@@ -233,5 +234,2 @@\n-JfrCPUTimeThreadSampler::~JfrCPUTimeThreadSampler() {\n-}\n-\n-void JfrCPUTimeThreadSampler::trigger_out_of_safepoint_sampling() {\n-  Atomic::release_store(&_is_out_of_safepoint_sampling_triggered, true);\n+void JfrCPUTimeThreadSampler::trigger_is_thread_in_native_stackwalking() {\n+  Atomic::release_store(&_is_thread_in_native_stackwalking_triggered, true);\n@@ -315,3 +313,3 @@\n-    if (Atomic::load_acquire(&_is_out_of_safepoint_sampling_triggered)) {\n-      Atomic::release_store(&_is_out_of_safepoint_sampling_triggered, false);\n-      sample_out_of_safepoint();\n+    if (Atomic::load_acquire(&_is_thread_in_native_stackwalking_triggered)) {\n+      Atomic::release_store(&_is_thread_in_native_stackwalking_triggered, false);\n+      stackwalk_threads_in_native();\n@@ -323,1 +321,1 @@\n-void JfrCPUTimeThreadSampler::sample_out_of_safepoint() {\n+void JfrCPUTimeThreadSampler::stackwalk_threads_in_native() {\n@@ -330,1 +328,1 @@\n-    if (tl != nullptr && tl->wants_out_of_safepoint_sampling()) {\n+    if (tl != nullptr && tl->wants_is_thread_in_native_stackwalking()) {\n@@ -334,2 +332,2 @@\n-      tl->set_wants_out_of_safepoint_sampling(false);\n-      sample_out_of_safepoint(jt);\n+      tl->set_wants_is_thread_in_native_stackwalking(false);\n+      stackwalk_thread_in_native(jt);\n@@ -353,2 +351,1 @@\n-void JfrCPUTimeThreadSampler::sample_out_of_safepoint(JavaThread* thread) {\n-  assert(thread->jfr_thread_local() != nullptr, \"invariant\");\n+void JfrCPUTimeThreadSampler::stackwalk_thread_in_native(JavaThread* thread) {\n@@ -356,0 +353,1 @@\n+  assert(tl != nullptr, \"invariant\");\n@@ -528,1 +526,1 @@\n-void JfrCPUTimeThreadSampling::trigger_out_of_safepoint_sampling() {\n+void JfrCPUTimeThreadSampling::trigger_is_thread_in_native_stackwalking() {\n@@ -530,1 +528,1 @@\n-    _instance->_sampler->trigger_out_of_safepoint_sampling();\n+    _instance->_sampler->trigger_is_thread_in_native_stackwalking();\n@@ -561,1 +559,0 @@\n-    case _thread_in_vm:\n@@ -574,1 +571,0 @@\n-      jt->is_at_poll_safepoint() ||\n@@ -577,1 +573,1 @@\n-      tl->set_wants_out_of_safepoint_sampling(false);\n+      tl->set_wants_is_thread_in_native_stackwalking(false);\n@@ -585,1 +581,0 @@\n-  NoResourceMark rm;\n@@ -603,2 +598,2 @@\n-    tl->set_wants_out_of_safepoint_sampling(true);\n-    JfrCPUTimeThreadSampling::trigger_out_of_safepoint_sampling();\n+    tl->set_wants_is_thread_in_native_stackwalking(true);\n+    JfrCPUTimeThreadSampling::trigger_is_thread_in_native_stackwalking();\n@@ -606,1 +601,1 @@\n-    tl->set_wants_out_of_safepoint_sampling(false);\n+    tl->set_wants_is_thread_in_native_stackwalking(false);\n@@ -630,3 +625,0 @@\n-  if (thread->osthread() == nullptr || thread->osthread()->thread_id() == 0){\n-    return false;\n-  }\n@@ -695,1 +687,1 @@\n-      if (tl != nullptr && tl->has_cpu_timer()) {\n+      if (tl->has_cpu_timer()) {\n@@ -709,7 +701,0 @@\n-int64_t compute_sampling_period(double rate) {\n-  if (rate == 0) {\n-    return 0;\n-  }\n-  return os::active_processor_count() * 1000000000.0 \/ rate;\n-}\n-\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.cpp","additions":41,"deletions":56,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-  static const u4 CPU_TIME_QUEUE_CAPACITY = 1000;\n+  static const u4 CPU_TIME_QUEUE_CAPACITY = 500;\n@@ -130,1 +130,2 @@\n-  static void trigger_out_of_safepoint_sampling();\n+  \/\/ Trigger sampling while a thread is not in a safepoint, from a seperate thread\n+  static void trigger_is_thread_in_native_stackwalking();\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -168,2 +168,0 @@\n-  biased = false;\n-\n@@ -279,1 +277,1 @@\n-  bool biased;\n+  bool biased = false;\n@@ -362,1 +360,0 @@\n-    JfrTicks now = JfrTicks::now();\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampling.cpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n@@ -34,0 +33,1 @@\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n","filename":"src\/hotspot\/share\/jfr\/recorder\/jfrRecorder.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -548,0 +548,25 @@\n+void JfrThreadLocal::set_cpu_timer(timer_t timer) {\n+  _has_cpu_timer = true;\n+  _cpu_timer = timer;\n+}\n+\n+void JfrThreadLocal::unset_cpu_timer() {\n+  _has_cpu_timer = false;\n+}\n+\n+timer_t JfrThreadLocal::cpu_timer() const {\n+  return _cpu_timer;\n+}\n+\n+bool JfrThreadLocal::has_cpu_timer() const {\n+  return _has_cpu_timer;\n+}\n+\n+bool JfrThreadLocal::is_cpu_time_jfr_enqueue_locked() {\n+  return Atomic::load(&_cpu_time_jfr_locked) == ENQUEUE;\n+}\n+\n+bool JfrThreadLocal::is_cpu_time_jfr_dequeue_locked() {\n+  return Atomic::load(&_cpu_time_jfr_locked) == DEQUEUE;\n+}\n+\n@@ -564,2 +589,2 @@\n-void JfrThreadLocal::set_has_cpu_time_jfr_requests(bool has_events) {\n-  Atomic::release_store(&_has_cpu_time_jfr_requests, has_events);\n+void JfrThreadLocal::set_has_cpu_time_jfr_requests(bool has_requests) {\n+  Atomic::release_store(&_has_cpu_time_jfr_requests, has_requests);\n@@ -580,2 +605,2 @@\n-void JfrThreadLocal::set_wants_out_of_safepoint_sampling(bool wants) {\n-  Atomic::release_store(&_wants_out_of_safepoint_sampling, wants);\n+void JfrThreadLocal::set_wants_is_thread_in_native_stackwalking(bool wants) {\n+  Atomic::release_store(&_wants_is_thread_in_native_stackwalking, wants);\n@@ -584,2 +609,2 @@\n-bool JfrThreadLocal::wants_out_of_safepoint_sampling() {\n-  return Atomic::load(&_wants_out_of_safepoint_sampling);\n+bool JfrThreadLocal::wants_is_thread_in_native_stackwalking() {\n+  return Atomic::load(&_wants_is_thread_in_native_stackwalking);\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadLocal.cpp","additions":31,"deletions":6,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -98,1 +98,1 @@\n-    \/\/ locked for writing native event out of safepoint\n+    \/\/ locked for sampling a thread in native state\n@@ -104,1 +104,1 @@\n-  volatile bool _wants_out_of_safepoint_sampling = false;\n+  volatile bool _wants_is_thread_in_native_stackwalking = false;\n@@ -372,19 +372,15 @@\n-  void set_cpu_timer(timer_t timer) {\n-    _has_cpu_timer = true;\n-    _cpu_timer = timer;\n-  }\n-\n-  void unset_cpu_timer() {\n-    _has_cpu_timer = false;\n-  }\n-\n-  timer_t cpu_timer() const {\n-    return _cpu_timer;\n-  }\n-\n-  bool has_cpu_timer() const {\n-    return _has_cpu_timer;\n-  }\n-\n-  bool is_cpu_time_jfr_enqueue_locked() { return Atomic::load(&_cpu_time_jfr_locked) == ENQUEUE; }\n-  bool is_cpu_time_jfr_dequeue_locked() { return Atomic::load(&_cpu_time_jfr_locked) == DEQUEUE; }\n+  void set_cpu_timer(timer_t timer);\n+  void unset_cpu_timer();\n+  timer_t cpu_timer() const;\n+  bool has_cpu_timer() const;\n+\n+  \/\/ The CPU time JFR lock has four different states:\n+  \/\/ - ENQUEUE: lock for enqueuing CPU time requests\n+  \/\/ - DEQUEUE: lock for dequeuing CPU time requests\n+  \/\/ - NATIVE: lock for writing events for threads in native state\n+  \/\/ - UNLOCKED: no lock held\n+  \/\/ This ensures that we can safely enqueue and dequeue CPU time requests,\n+  \/\/ without interleaving\n+\n+  bool is_cpu_time_jfr_enqueue_locked();\n+  bool is_cpu_time_jfr_dequeue_locked();\n@@ -403,2 +399,2 @@\n-  void set_wants_out_of_safepoint_sampling(bool wants);\n-  bool wants_out_of_safepoint_sampling();\n+  void set_wants_is_thread_in_native_stackwalking(bool wants);\n+  bool wants_is_thread_in_native_stackwalking();\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadLocal.hpp","additions":19,"deletions":23,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -152,7 +152,0 @@\n-  #ifdef ASSERT\n-  Thread* t = Thread::current_or_null_safe();\n-  if (t != nullptr && t->resource_area() != nullptr) {\n-    \/\/ Just to make sure that we're allowed to allocate\n-    t->resource_area()->verify_no_NoResourceMark();\n-  }\n-  #endif\n","filename":"src\/hotspot\/share\/memory\/arena.cpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-    area->verify_no_NoResourceMark();\n@@ -48,1 +47,1 @@\n-  if ((_nesting <= 0 || _no_resource_mark_nesting > 0) && !VMError::is_error_reported()) {\n+  if (_nesting <= 0 && !VMError::is_error_reported()) {\n@@ -55,5 +54,1 @@\n-        if (_nesting <= 0) {\n-          fatal(\"memory leak: allocating without ResourceMark\");\n-        } else {\n-          fatal(\"memory leak: allocating with NoResourceMark\");\n-        }\n+        fatal(\"memory leak: allocating without ResourceMark\");\n@@ -85,17 +80,0 @@\n-\n-#ifdef ASSERT\n-\n-NoResourceMark::NoResourceMark() {\n-  ResourceArea* area = Thread::current()->resource_area();\n-  area->_no_resource_mark_nesting++;\n-  assert(area->_no_resource_mark_nesting > 0, \"must stack allocate NoResourceMark\" );\n-}\n-\n-\n-NoResourceMark::~NoResourceMark() {\n-  ResourceArea* area = Thread::current()->resource_area();\n-  assert(area->_no_resource_mark_nesting > 0, \"must stack allocate NoResourceMark\" );\n-  area->_no_resource_mark_nesting--;\n-}\n-\n-#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/memory\/resourceArea.cpp","additions":2,"deletions":24,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -47,2 +47,0 @@\n-  friend class NoResourceMark;\n-\n@@ -51,1 +49,0 @@\n-  int _no_resource_mark_nesting; \/\/ current # of nested NoResourceMarks\n@@ -57,1 +54,1 @@\n-    Arena(mem_tag, Arena::Tag::tag_ra) DEBUG_ONLY(COMMA _nesting(0) COMMA _no_resource_mark_nesting(0)) {}\n+    Arena(mem_tag, Arena::Tag::tag_ra) DEBUG_ONLY(COMMA _nesting(0)) {}\n@@ -60,1 +57,1 @@\n-    Arena(mem_tag, arena_tag, init_size) DEBUG_ONLY(COMMA _nesting(0) COMMA _no_resource_mark_nesting(0)) {\n+    Arena(mem_tag, arena_tag, init_size) DEBUG_ONLY(COMMA _nesting(0)) {\n@@ -64,1 +61,1 @@\n-    Arena(mem_tag, arena_tag) DEBUG_ONLY(COMMA _nesting(0) COMMA _no_resource_mark_nesting(0)) {\n+    Arena(mem_tag, arena_tag) DEBUG_ONLY(COMMA _nesting(0)) {\n@@ -69,1 +66,0 @@\n-  DEBUG_ONLY(void verify_no_NoResourceMark() const { assert(_no_resource_mark_nesting == 0, \"Allocating inside NoResourceMark\"); })\n@@ -195,1 +191,0 @@\n-\/\/ Voided by the NoResourceMark stack object\n@@ -233,15 +228,0 @@\n-\/\/------------------------------------------------------------------------------------------------------------------------\n-\/\/ A NoResourceMark stack object will verify that no resource areas or new chunks are allocated\n-\/\/ in its scope. Enabled in debug mode only.\n-\n-class NoResourceMark: public StackObj {\n- public:\n-#ifdef ASSERT\n-  NoResourceMark();\n-  ~NoResourceMark();\n-#else\n-  NoResourceMark()  {}\n-  ~NoResourceMark() {}\n-#endif\n-};\n-\n","filename":"src\/hotspot\/share\/memory\/resourceArea.hpp","additions":3,"deletions":23,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -588,2 +588,0 @@\n-  NoResourceMark rm;\n-\n","filename":"src\/hotspot\/share\/prims\/forte.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -626,1 +626,0 @@\n-  ThreadCrashProtection* _crash_protection = nullptr;\n@@ -628,1 +627,0 @@\n-\n@@ -630,4 +628,1 @@\n-  ThreadCrashProtection* crash_protection() const { return _crash_protection; }\n-  void set_crash_protection(ThreadCrashProtection* cp) { _crash_protection = cp; }\n-\n-  \/\/ in ASGCT or the signal handler of the JfrCPUTimeSampler\n+  \/\/ in ASGCT\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"}]}