{"files":[{"patch":"@@ -78,0 +78,4 @@\n+  if test \"x$OPENJDK_TARGET_CPU\" = xx86 && test \"x$with_jvm_variants\" != xzero; then\n+    AC_MSG_ERROR([32-bit x86 builds are not supported])\n+  fi\n+\n@@ -79,3 +83,0 @@\n-    if test \"x$OPENJDK_TARGET_CPU_BITS\" = \"x32\"; then\n-      AC_MSG_ERROR([32-bit Windows builds are not supported])\n-    fi\n","filename":"make\/autoconf\/basic.m4","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -669,11 +669,1 @@\n-  # Unfortunately, variants have not been parsed yet, so we have to check the configure option\n-  # directly. Allow only the directly specified Zero variant, treat any other mix as containing\n-  # something non-Zero.\n-  if test \"x$OPENJDK_TARGET_CPU\" = xx86 && test \"x$with_jvm_variants\" != xzero; then\n-    if test \"x$enable_deprecated_ports\" = \"xyes\"; then\n-      AC_MSG_WARN([The 32-bit x86 port is deprecated and may be removed in a future release.])\n-    else\n-      AC_MSG_ERROR(m4_normalize([The 32-bit x86 port is deprecated and may be removed in a future release.\n-        Use --enable-deprecated-ports=yes to suppress this error.]))\n-    fi\n-  fi\n+  # There are no deprecated ports. Implement the deprecation warnings here.\n","filename":"make\/autoconf\/platform.m4","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1,42 +0,0 @@\n-\/*\n- * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"prims\/downcallLinker.hpp\"\n-\n-RuntimeStub* DowncallLinker::make_downcall_stub(BasicType* signature,\n-                                                int num_args,\n-                                                BasicType ret_bt,\n-                                                const ABIDescriptor& abi,\n-                                                const GrowableArray<VMStorage>& input_registers,\n-                                                const GrowableArray<VMStorage>& output_registers,\n-                                                bool needs_return_buffer,\n-                                                int captured_state_mask,\n-                                                bool needs_transition) {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n-void DowncallLinker::StubGenerator::pd_add_offset_to_oop(VMStorage reg_oop, VMStorage reg_offset,\n-                                                         VMStorage tmp1, VMStorage tmp2) const {\n-  Unimplemented();\n-}\n","filename":"src\/hotspot\/cpu\/x86\/downcallLinker_x86_32.cpp","additions":0,"deletions":42,"binary":false,"changes":42,"status":"deleted"},{"patch":"@@ -1,54 +0,0 @@\n-\/*\n- * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"code\/vmreg.hpp\"\n-#include \"prims\/foreignGlobals.hpp\"\n-#include \"utilities\/debug.hpp\"\n-\n-class MacroAssembler;\n-\n-bool ForeignGlobals::is_foreign_linker_supported() {\n-  return false;\n-}\n-\n-const ABIDescriptor ForeignGlobals::parse_abi_descriptor(jobject jabi) {\n-  Unimplemented();\n-  return {};\n-}\n-\n-int RegSpiller::pd_reg_size(VMStorage reg) {\n-  Unimplemented();\n-  return -1;\n-}\n-\n-void RegSpiller::pd_store_reg(MacroAssembler* masm, int offset, VMStorage reg) {\n-  Unimplemented();\n-}\n-\n-void RegSpiller::pd_load_reg(MacroAssembler* masm, int offset, VMStorage reg) {\n-  Unimplemented();\n-}\n-\n-void ArgumentShuffle::pd_generate(MacroAssembler* masm, VMStorage tmp, int in_stk_bias, int out_stk_bias) const {\n-  Unimplemented();\n-}\n","filename":"src\/hotspot\/cpu\/x86\/foreignGlobals_x86_32.cpp","additions":0,"deletions":54,"binary":false,"changes":54,"status":"deleted"},{"patch":"@@ -1,71 +0,0 @@\n-\/\/\n-\/\/ Copyright (c) 2018, Red Hat, Inc. All rights reserved.\n-\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-\/\/\n-\/\/ This code is free software; you can redistribute it and\/or modify it\n-\/\/ under the terms of the GNU General Public License version 2 only, as\n-\/\/ published by the Free Software Foundation.\n-\/\/\n-\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n-\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-\/\/ version 2 for more details (a copy is included in the LICENSE file that\n-\/\/ accompanied this code).\n-\/\/\n-\/\/ You should have received a copy of the GNU General Public License version\n-\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n-\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-\/\/\n-\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-\/\/ or visit www.oracle.com if you need additional information or have any\n-\/\/ questions.\n-\/\/\n-\/\/\n-\n-source_hpp %{\n-#include \"gc\/shenandoah\/shenandoahBarrierSetAssembler.hpp\"\n-#include \"gc\/shenandoah\/c2\/shenandoahSupport.hpp\"\n-%}\n-\n-instruct compareAndSwapP_shenandoah(rRegI res,\n-                                    memory mem_ptr,\n-                                    eRegP tmp1, eRegP tmp2,\n-                                    eAXRegP oldval, eRegP newval,\n-                                    eFlagsReg cr)\n-%{\n-  match(Set res (ShenandoahCompareAndSwapP mem_ptr (Binary oldval newval)));\n-  match(Set res (ShenandoahWeakCompareAndSwapP mem_ptr (Binary oldval newval)));\n-  effect(TEMP tmp1, TEMP tmp2, KILL cr, KILL oldval);\n-\n-  format %{ \"shenandoah_cas_oop $mem_ptr,$newval\" %}\n-\n-  ins_encode %{\n-    ShenandoahBarrierSet::assembler()->cmpxchg_oop(masm,\n-                                                   $res$$Register, $mem_ptr$$Address, $oldval$$Register, $newval$$Register,\n-                                                   false, \/\/ swap\n-                                                   $tmp1$$Register, $tmp2$$Register\n-                                                   );\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeP_shenandoah(memory mem_ptr,\n-                                        eAXRegP oldval, eRegP newval,\n-                                        eRegP tmp1, eRegP tmp2,\n-                                        eFlagsReg cr)\n-%{\n-  match(Set oldval (ShenandoahCompareAndExchangeP mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, TEMP tmp1, TEMP tmp2);\n-  ins_cost(1000);\n-\n-  format %{ \"shenandoah_cas_oop $mem_ptr,$newval\" %}\n-\n-  ins_encode %{\n-    ShenandoahBarrierSet::assembler()->cmpxchg_oop(masm,\n-                                                   noreg, $mem_ptr$$Address, $oldval$$Register, $newval$$Register,\n-                                                   true,  \/\/ exchange\n-                                                   $tmp1$$Register, $tmp2$$Register\n-                                                   );\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoah_x86_32.ad","additions":0,"deletions":71,"binary":false,"changes":71,"status":"deleted"},{"patch":"@@ -1,145 +0,0 @@\n-\/*\n- * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"interpreter\/interp_masm.hpp\"\n-#include \"interpreter\/interpreter.hpp\"\n-#include \"interpreter\/interpreterRuntime.hpp\"\n-#include \"memory\/allocation.inline.hpp\"\n-#include \"oops\/method.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/handles.inline.hpp\"\n-#include \"runtime\/icache.hpp\"\n-#include \"runtime\/interfaceSupport.inline.hpp\"\n-#include \"runtime\/signature.hpp\"\n-\n-\n-#define __ _masm->\n-\n-\n-\/\/ Implementation of SignatureHandlerGenerator\n-InterpreterRuntime::SignatureHandlerGenerator::SignatureHandlerGenerator(const methodHandle& method, CodeBuffer* buffer) :\n-    NativeSignatureIterator(method) {\n-  _masm = new MacroAssembler(buffer);\n-}\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::pass_int() {\n-  move(offset(), jni_offset() + 1);\n-}\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::pass_float() {\n-  move(offset(), jni_offset() + 1);\n-}\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::pass_long() {\n-   move(offset(), jni_offset() + 2);\n-   move(offset() + 1, jni_offset() + 1);\n-}\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::pass_object() {\n-  box (offset(), jni_offset() + 1);\n-}\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::move(int from_offset, int to_offset) {\n-  __ movl(temp(), Address(from(), Interpreter::local_offset_in_bytes(from_offset)));\n-  __ movl(Address(to(), to_offset * wordSize), temp());\n-}\n-\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::box(int from_offset, int to_offset) {\n-  __ lea(temp(), Address(from(), Interpreter::local_offset_in_bytes(from_offset)));\n-  __ cmpptr(Address(from(), Interpreter::local_offset_in_bytes(from_offset)), NULL_WORD); \/\/ do not use temp() to avoid AGI\n-  Label L;\n-  __ jcc(Assembler::notZero, L);\n-  __ movptr(temp(), NULL_WORD);\n-  __ bind(L);\n-  __ movptr(Address(to(), to_offset * wordSize), temp());\n-}\n-\n-\n-void InterpreterRuntime::SignatureHandlerGenerator::generate( uint64_t fingerprint) {\n-  \/\/ generate code to handle arguments\n-  iterate(fingerprint);\n-  \/\/ return result handler\n-  __ lea(rax,\n-         ExternalAddress((address)Interpreter::result_handler(method()->result_type())));\n-  \/\/ return\n-  __ ret(0);\n-  __ flush();\n-}\n-\n-\n-Register InterpreterRuntime::SignatureHandlerGenerator::from()       { return rdi; }\n-Register InterpreterRuntime::SignatureHandlerGenerator::to()         { return rsp; }\n-Register InterpreterRuntime::SignatureHandlerGenerator::temp()       { return rcx; }\n-\n-\n-\/\/ Implementation of SignatureHandlerLibrary\n-\n-void SignatureHandlerLibrary::pd_set_handler(address handler) {}\n-\n-class SlowSignatureHandler: public NativeSignatureIterator {\n- private:\n-  address   _from;\n-  intptr_t* _to;\n-\n-  virtual void pass_int() {\n-    *_to++ = *(jint *)(_from+Interpreter::local_offset_in_bytes(0));\n-    _from -= Interpreter::stackElementSize;\n-  }\n-\n-  virtual void pass_float() {\n-    *_to++ = *(jint *)(_from+Interpreter::local_offset_in_bytes(0));\n-    _from -= Interpreter::stackElementSize;\n-  }\n-\n-  virtual void pass_long() {\n-    _to[0] = *(intptr_t*)(_from+Interpreter::local_offset_in_bytes(1));\n-    _to[1] = *(intptr_t*)(_from+Interpreter::local_offset_in_bytes(0));\n-    _to += 2;\n-    _from -= 2*Interpreter::stackElementSize;\n-  }\n-\n-  virtual void pass_object() {\n-    \/\/ pass address of from\n-    intptr_t from_addr = (intptr_t)(_from + Interpreter::local_offset_in_bytes(0));\n-    *_to++ = (*(intptr_t*)from_addr == 0) ? NULL_WORD : from_addr;\n-    _from -= Interpreter::stackElementSize;\n-   }\n-\n- public:\n-  SlowSignatureHandler(const methodHandle& method, address from, intptr_t* to) :\n-    NativeSignatureIterator(method) {\n-    _from = from;\n-    _to   = to + (is_static() ? 2 : 1);\n-  }\n-};\n-\n-JRT_ENTRY(address, InterpreterRuntime::slow_signature_handler(JavaThread* current, Method* method, intptr_t* from, intptr_t* to))\n-  methodHandle m(current, (Method*)method);\n-  assert(m->is_native(), \"sanity check\");\n-  \/\/ handle arguments\n-  SlowSignatureHandler(m, (address)from, to + 1).iterate((uint64_t)CONST64(-1));\n-  \/\/ return result handler\n-  return Interpreter::result_handler(m->result_type());\n-JRT_END\n","filename":"src\/hotspot\/cpu\/x86\/interpreterRT_x86_32.cpp","additions":0,"deletions":145,"binary":false,"changes":145,"status":"deleted"},{"patch":"@@ -1,323 +0,0 @@\n-\/*\n- * Copyright (c) 2004, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-#include \"prims\/jniFastGetField.hpp\"\n-#include \"prims\/jvm_misc.hpp\"\n-#include \"prims\/jvmtiExport.hpp\"\n-#include \"runtime\/os.inline.hpp\"\n-#include \"runtime\/safepoint.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-\n-#define __ masm->\n-\n-#define BUFFER_SIZE 30\n-\n-\/\/ Instead of issuing lfence for LoadLoad barrier, we create data dependency\n-\/\/ between loads, which is much more efficient than lfence.\n-\n-address JNI_FastGetField::generate_fast_get_int_field0(BasicType type) {\n-  const char *name = nullptr;\n-  switch (type) {\n-    case T_BOOLEAN: name = \"jni_fast_GetBooleanField\"; break;\n-    case T_BYTE:    name = \"jni_fast_GetByteField\";    break;\n-    case T_CHAR:    name = \"jni_fast_GetCharField\";    break;\n-    case T_SHORT:   name = \"jni_fast_GetShortField\";   break;\n-    case T_INT:     name = \"jni_fast_GetIntField\";     break;\n-    default:        ShouldNotReachHere();\n-  }\n-  ResourceMark rm;\n-  BufferBlob* blob = BufferBlob::create(name, BUFFER_SIZE*wordSize);\n-  CodeBuffer cbuf(blob);\n-  MacroAssembler* masm = new MacroAssembler(&cbuf);\n-  address fast_entry = __ pc();\n-\n-  Label slow;\n-\n-  \/\/ stack layout:    offset from rsp (in words):\n-  \/\/  return pc        0\n-  \/\/  jni env          1\n-  \/\/  obj              2\n-  \/\/  jfieldID         3\n-\n-  ExternalAddress counter(SafepointSynchronize::safepoint_counter_addr());\n-  __ mov32 (rcx, counter);\n-  __ testb (rcx, 1);\n-  __ jcc (Assembler::notZero, slow);\n-\n-  if (JvmtiExport::can_post_field_access()) {\n-    \/\/ Check to see if a field access watch has been set before we\n-    \/\/ take the fast path.\n-    __ cmp32(ExternalAddress((address) JvmtiExport::get_field_access_count_addr()), 0);\n-    __ jcc(Assembler::notZero, slow);\n-  }\n-\n-  __ mov(rax, rcx);\n-  __ andptr(rax, 1);                         \/\/ rax, must end up 0\n-  __ movptr(rdx, Address(rsp, rax, Address::times_1, 2*wordSize));\n-                                            \/\/ obj, notice rax, is 0.\n-                                            \/\/ rdx is data dependent on rcx.\n-  __ movptr(rax, Address(rsp, 3*wordSize));  \/\/ jfieldID\n-\n-  __ clear_jobject_tag(rdx);\n-\n-  __ movptr(rdx, Address(rdx, 0));           \/\/ *obj\n-  __ shrptr (rax, 2);                         \/\/ offset\n-\n-  assert(count < LIST_CAPACITY, \"LIST_CAPACITY too small\");\n-  speculative_load_pclist[count] = __ pc();\n-  switch (type) {\n-    case T_BOOLEAN: __ movzbl (rax, Address(rdx, rax, Address::times_1)); break;\n-    case T_BYTE:    __ movsbl (rax, Address(rdx, rax, Address::times_1)); break;\n-    case T_CHAR:    __ movzwl (rax, Address(rdx, rax, Address::times_1)); break;\n-    case T_SHORT:   __ movswl (rax, Address(rdx, rax, Address::times_1)); break;\n-    case T_INT:     __ movl   (rax, Address(rdx, rax, Address::times_1)); break;\n-    default:        ShouldNotReachHere();\n-  }\n-\n-  Address ca1;\n-  __ lea(rdx, counter);\n-  __ xorptr(rdx, rax);\n-  __ xorptr(rdx, rax);\n-  __ cmp32(rcx, Address(rdx, 0));\n-  \/\/ ca1 is the same as ca because\n-  \/\/ rax, ^ counter_addr ^ rax, = address\n-  \/\/ ca1 is data dependent on rax,.\n-  __ jcc (Assembler::notEqual, slow);\n-\n-  __ ret (0);\n-\n-  slowcase_entry_pclist[count++] = __ pc();\n-  __ bind (slow);\n-  address slow_case_addr = nullptr;\n-  switch (type) {\n-    case T_BOOLEAN: slow_case_addr = jni_GetBooleanField_addr(); break;\n-    case T_BYTE:    slow_case_addr = jni_GetByteField_addr();    break;\n-    case T_CHAR:    slow_case_addr = jni_GetCharField_addr();    break;\n-    case T_SHORT:   slow_case_addr = jni_GetShortField_addr();   break;\n-    case T_INT:     slow_case_addr = jni_GetIntField_addr();     break;\n-    default:        ShouldNotReachHere();\n-  }\n-  \/\/ tail call\n-  __ jump (RuntimeAddress(slow_case_addr));\n-\n-  __ flush ();\n-\n-  return fast_entry;\n-}\n-\n-address JNI_FastGetField::generate_fast_get_boolean_field() {\n-  return generate_fast_get_int_field0(T_BOOLEAN);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_byte_field() {\n-  return generate_fast_get_int_field0(T_BYTE);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_char_field() {\n-  return generate_fast_get_int_field0(T_CHAR);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_short_field() {\n-  return generate_fast_get_int_field0(T_SHORT);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_int_field() {\n-  return generate_fast_get_int_field0(T_INT);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_long_field() {\n-  const char *name = \"jni_fast_GetLongField\";\n-  ResourceMark rm;\n-  BufferBlob* blob = BufferBlob::create(name, BUFFER_SIZE*wordSize);\n-  CodeBuffer cbuf(blob);\n-  MacroAssembler* masm = new MacroAssembler(&cbuf);\n-  address fast_entry = __ pc();\n-\n-  Label slow;\n-\n-  \/\/ stack layout:    offset from rsp (in words):\n-  \/\/  old rsi          0\n-  \/\/  return pc        1\n-  \/\/  jni env          2\n-  \/\/  obj              3\n-  \/\/  jfieldID         4\n-\n-  ExternalAddress counter(SafepointSynchronize::safepoint_counter_addr());\n-\n-  __ push  (rsi);\n-  __ mov32 (rcx, counter);\n-  __ testb (rcx, 1);\n-  __ jcc (Assembler::notZero, slow);\n-\n-  if (JvmtiExport::can_post_field_access()) {\n-    \/\/ Check to see if a field access watch has been set before we\n-    \/\/ take the fast path.\n-    __ cmp32(ExternalAddress((address) JvmtiExport::get_field_access_count_addr()), 0);\n-    __ jcc(Assembler::notZero, slow);\n-  }\n-\n-  __ mov(rax, rcx);\n-  __ andptr(rax, 1);                         \/\/ rax, must end up 0\n-  __ movptr(rdx, Address(rsp, rax, Address::times_1, 3*wordSize));\n-                                            \/\/ obj, notice rax, is 0.\n-                                            \/\/ rdx is data dependent on rcx.\n-  __ movptr(rsi, Address(rsp, 4*wordSize));  \/\/ jfieldID\n-\n-  __ clear_jobject_tag(rdx);\n-\n-  __ movptr(rdx, Address(rdx, 0));           \/\/ *obj\n-  __ shrptr(rsi, 2);                         \/\/ offset\n-\n-  assert(count < LIST_CAPACITY-1, \"LIST_CAPACITY too small\");\n-  speculative_load_pclist[count++] = __ pc();\n-  __ movptr(rax, Address(rdx, rsi, Address::times_1));\n-  speculative_load_pclist[count] = __ pc();\n-  __ movl(rdx, Address(rdx, rsi, Address::times_1, 4));\n-\n-  __ lea(rsi, counter);\n-  __ xorptr(rsi, rdx);\n-  __ xorptr(rsi, rax);\n-  __ xorptr(rsi, rdx);\n-  __ xorptr(rsi, rax);\n-  __ cmp32(rcx, Address(rsi, 0));\n-  \/\/ ca1 is the same as ca because\n-  \/\/ rax, ^ rdx ^ counter_addr ^ rax, ^ rdx = address\n-  \/\/ ca1 is data dependent on both rax, and rdx.\n-  __ jcc (Assembler::notEqual, slow);\n-\n-  __ pop (rsi);\n-\n-  __ ret (0);\n-\n-  slowcase_entry_pclist[count-1] = __ pc();\n-  slowcase_entry_pclist[count++] = __ pc();\n-  __ bind (slow);\n-  __ pop  (rsi);\n-  address slow_case_addr = jni_GetLongField_addr();;\n-  \/\/ tail call\n-  __ jump (RuntimeAddress(slow_case_addr));\n-\n-  __ flush ();\n-\n-  return fast_entry;\n-}\n-\n-address JNI_FastGetField::generate_fast_get_float_field0(BasicType type) {\n-  const char *name = nullptr;\n-  switch (type) {\n-    case T_FLOAT:  name = \"jni_fast_GetFloatField\";  break;\n-    case T_DOUBLE: name = \"jni_fast_GetDoubleField\"; break;\n-    default:       ShouldNotReachHere();\n-  }\n-  ResourceMark rm;\n-  BufferBlob* blob = BufferBlob::create(name, BUFFER_SIZE*wordSize);\n-  CodeBuffer cbuf(blob);\n-  MacroAssembler* masm = new MacroAssembler(&cbuf);\n-  address fast_entry = __ pc();\n-\n-  Label slow_with_pop, slow;\n-\n-  \/\/ stack layout:    offset from rsp (in words):\n-  \/\/  return pc        0\n-  \/\/  jni env          1\n-  \/\/  obj              2\n-  \/\/  jfieldID         3\n-\n-  ExternalAddress counter(SafepointSynchronize::safepoint_counter_addr());\n-\n-  __ mov32 (rcx, counter);\n-  __ testb (rcx, 1);\n-  __ jcc (Assembler::notZero, slow);\n-\n-  if (JvmtiExport::can_post_field_access()) {\n-    \/\/ Check to see if a field access watch has been set before we\n-    \/\/ take the fast path.\n-    __ cmp32(ExternalAddress((address) JvmtiExport::get_field_access_count_addr()), 0);\n-    __ jcc(Assembler::notZero, slow);\n-  }\n-\n-  __ mov(rax, rcx);\n-  __ andptr(rax, 1);                         \/\/ rax, must end up 0\n-  __ movptr(rdx, Address(rsp, rax, Address::times_1, 2*wordSize));\n-                                            \/\/ obj, notice rax, is 0.\n-                                            \/\/ rdx is data dependent on rcx.\n-  __ movptr(rax, Address(rsp, 3*wordSize));  \/\/ jfieldID\n-\n-  __ clear_jobject_tag(rdx);\n-\n-  __ movptr(rdx, Address(rdx, 0));           \/\/ *obj\n-  __ shrptr(rax, 2);                         \/\/ offset\n-\n-  assert(count < LIST_CAPACITY, \"LIST_CAPACITY too small\");\n-  speculative_load_pclist[count] = __ pc();\n-  switch (type) {\n-    case T_FLOAT:  __ fld_s (Address(rdx, rax, Address::times_1)); break;\n-    case T_DOUBLE: __ fld_d (Address(rdx, rax, Address::times_1)); break;\n-    default:       ShouldNotReachHere();\n-  }\n-\n-  Address ca1;\n-  __ fst_s (Address(rsp, -4));\n-  __ lea(rdx, counter);\n-  __ movl (rax, Address(rsp, -4));\n-  \/\/ garbage hi-order bits on 64bit are harmless.\n-  __ xorptr(rdx, rax);\n-  __ xorptr(rdx, rax);\n-  __ cmp32(rcx, Address(rdx, 0));\n-  \/\/ rax, ^ counter_addr ^ rax, = address\n-  \/\/ ca1 is data dependent on the field\n-  \/\/ access.\n-  __ jcc (Assembler::notEqual, slow_with_pop);\n-\n-  __ ret (0);\n-\n-  __ bind (slow_with_pop);\n-  \/\/ invalid load. pop FPU stack.\n-  __ fstp_d (0);\n-\n-  slowcase_entry_pclist[count++] = __ pc();\n-  __ bind (slow);\n-  address slow_case_addr = nullptr;\n-  switch (type) {\n-    case T_FLOAT:  slow_case_addr = jni_GetFloatField_addr();  break;\n-    case T_DOUBLE: slow_case_addr = jni_GetDoubleField_addr(); break;\n-    default:       ShouldNotReachHere();\n-  }\n-  \/\/ tail call\n-  __ jump (RuntimeAddress(slow_case_addr));\n-\n-  __ flush ();\n-\n-  return fast_entry;\n-}\n-\n-address JNI_FastGetField::generate_fast_get_float_field() {\n-  return generate_fast_get_float_field0(T_FLOAT);\n-}\n-\n-address JNI_FastGetField::generate_fast_get_double_field() {\n-  return generate_fast_get_float_field0(T_DOUBLE);\n-}\n","filename":"src\/hotspot\/cpu\/x86\/jniFastGetField_x86_32.cpp","additions":0,"deletions":323,"binary":false,"changes":323,"status":"deleted"},{"patch":"@@ -1,52 +0,0 @@\n-\/*\n- * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"macroAssembler_x86.hpp\"\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _ONES[] = {\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xbff00000UL\n-};\n-address MacroAssembler::ONES = (address)_ONES;\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _PI4_INV[] = {\n-    0x6dc9c883UL, 0x3ff45f30UL\n-};\n-address MacroAssembler::PI4_INV = (address)_PI4_INV;\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _PI4X3[] = {\n-    0x54443000UL, 0xbfe921fbUL, 0x3b39a000UL, 0x3d373dcbUL, 0xe0e68948UL,\n-    0xba845c06UL\n-};\n-address MacroAssembler::PI4X3 = (address)_PI4X3;\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _PI4X4[] = {\n-    0x54400000UL, 0xbfe921fbUL, 0x1a600000UL, 0xbdc0b461UL, 0x2e000000UL,\n-    0xbb93198aUL, 0x252049c1UL, 0xb96b839aUL\n-};\n-address MacroAssembler::PI4X4 = (address)_PI4X4;\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _L_2IL0FLOATPACKET_0[] = {\n-    0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n-};\n-address MacroAssembler::L_2IL0FLOATPACKET_0 = (address)_L_2IL0FLOATPACKET_0;\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_constants.cpp","additions":0,"deletions":52,"binary":false,"changes":52,"status":"deleted"},{"patch":"@@ -1,427 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - COS()\n-\/\/                     ---------------------\n-\/\/\n-\/\/     1. RANGE REDUCTION\n-\/\/\n-\/\/     We perform an initial range reduction from X to r with\n-\/\/\n-\/\/          X =~= N * pi\/32 + r\n-\/\/\n-\/\/     so that |r| <= pi\/64 + epsilon. We restrict inputs to those\n-\/\/     where |N| <= 932560. Beyond this, the range reduction is\n-\/\/     insufficiently accurate. For extremely small inputs,\n-\/\/     denormalization can occur internally, impacting performance.\n-\/\/     This means that the main path is actually only taken for\n-\/\/     2^-252 <= |X| < 90112.\n-\/\/\n-\/\/     To avoid branches, we perform the range reduction to full\n-\/\/     accuracy each time.\n-\/\/\n-\/\/          X - N * (P_1 + P_2 + P_3)\n-\/\/\n-\/\/     where P_1 and P_2 are 32-bit numbers (so multiplication by N\n-\/\/     is exact) and P_3 is a 53-bit number. Together, these\n-\/\/     approximate pi well enough for all cases in the restricted\n-\/\/     range.\n-\/\/\n-\/\/     The main reduction sequence is:\n-\/\/\n-\/\/             y = 32\/pi * x\n-\/\/             N = integer(y)\n-\/\/     (computed by adding and subtracting off SHIFTER)\n-\/\/\n-\/\/             m_1 = N * P_1\n-\/\/             m_2 = N * P_2\n-\/\/             r_1 = x - m_1\n-\/\/             r = r_1 - m_2\n-\/\/     (this r can be used for most of the calculation)\n-\/\/\n-\/\/             c_1 = r_1 - r\n-\/\/             m_3 = N * P_3\n-\/\/             c_2 = c_1 - m_2\n-\/\/             c = c_2 - m_3\n-\/\/\n-\/\/     2. MAIN ALGORITHM\n-\/\/\n-\/\/     The algorithm uses a table lookup based on B = M * pi \/ 32\n-\/\/     where M = N mod 64. The stored values are:\n-\/\/       sigma             closest power of 2 to cos(B)\n-\/\/       C_hl              53-bit cos(B) - sigma\n-\/\/       S_hi + S_lo       2 * 53-bit sin(B)\n-\/\/\n-\/\/     The computation is organized as follows:\n-\/\/\n-\/\/          sin(B + r + c) = [sin(B) + sigma * r] +\n-\/\/                           r * (cos(B) - sigma) +\n-\/\/                           sin(B) * [cos(r + c) - 1] +\n-\/\/                           cos(B) * [sin(r + c) - r]\n-\/\/\n-\/\/     which is approximately:\n-\/\/\n-\/\/          [S_hi + sigma * r] +\n-\/\/          C_hl * r +\n-\/\/          S_lo + S_hi * [(cos(r) - 1) - r * c] +\n-\/\/          (C_hl + sigma) * [(sin(r) - r) + c]\n-\/\/\n-\/\/     and this is what is actually computed. We separate this sum\n-\/\/     into four parts:\n-\/\/\n-\/\/          hi + med + pols + corr\n-\/\/\n-\/\/     where\n-\/\/\n-\/\/          hi       = S_hi + sigma r\n-\/\/          med      = C_hl * r\n-\/\/          pols     = S_hi * (cos(r) - 1) + (C_hl + sigma) * (sin(r) - r)\n-\/\/          corr     = S_lo + c * ((C_hl + sigma) - S_hi * r)\n-\/\/\n-\/\/     3. POLYNOMIAL\n-\/\/\n-\/\/     The polynomial S_hi * (cos(r) - 1) + (C_hl + sigma) *\n-\/\/     (sin(r) - r) can be rearranged freely, since it is quite\n-\/\/     small, so we exploit parallelism to the fullest.\n-\/\/\n-\/\/          psc4       =   SC_4 * r_1\n-\/\/          msc4       =   psc4 * r\n-\/\/          r2         =   r * r\n-\/\/          msc2       =   SC_2 * r2\n-\/\/          r4         =   r2 * r2\n-\/\/          psc3       =   SC_3 + msc4\n-\/\/          psc1       =   SC_1 + msc2\n-\/\/          msc3       =   r4 * psc3\n-\/\/          sincospols =   psc1 + msc3\n-\/\/          pols       =   sincospols *\n-\/\/                         <S_hi * r^2 | (C_hl + sigma) * r^3>\n-\/\/\n-\/\/     4. CORRECTION TERM\n-\/\/\n-\/\/     This is where the \"c\" component of the range reduction is\n-\/\/     taken into account; recall that just \"r\" is used for most of\n-\/\/     the calculation.\n-\/\/\n-\/\/          -c   = m_3 - c_2\n-\/\/          -d   = S_hi * r - (C_hl + sigma)\n-\/\/          corr = -c * -d + S_lo\n-\/\/\n-\/\/     5. COMPENSATED SUMMATIONS\n-\/\/\n-\/\/     The two successive compensated summations add up the high\n-\/\/     and medium parts, leaving just the low parts to add up at\n-\/\/     the end.\n-\/\/\n-\/\/          rs        =  sigma * r\n-\/\/          res_int   =  S_hi + rs\n-\/\/          k_0       =  S_hi - res_int\n-\/\/          k_2       =  k_0 + rs\n-\/\/          med       =  C_hl * r\n-\/\/          res_hi    =  res_int + med\n-\/\/          k_1       =  res_int - res_hi\n-\/\/          k_3       =  k_1 + med\n-\/\/\n-\/\/     6. FINAL SUMMATION\n-\/\/\n-\/\/     We now add up all the small parts:\n-\/\/\n-\/\/          res_lo = pols(hi) + pols(lo) + corr + k_1 + k_3\n-\/\/\n-\/\/     Now the overall result is just:\n-\/\/\n-\/\/          res_hi + res_lo\n-\/\/\n-\/\/     7. SMALL ARGUMENTS\n-\/\/\n-\/\/     Inputs with |X| < 2^-252 are treated specially as\n-\/\/     1 - |x|.\n-\/\/\n-\/\/ Special cases:\n-\/\/  cos(NaN) = quiet NaN, and raise invalid exception\n-\/\/  cos(INF) = NaN and raise invalid exception\n-\/\/  cos(0) = 1\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_cos[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL, 0xbf73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL,\n-    0xc0000000UL, 0xbc626d19UL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL,\n-    0xbfa60beaUL, 0x2ed59f06UL, 0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL,\n-    0x00000000UL, 0x3ff00000UL, 0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL,\n-    0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL, 0x00000000UL, 0x3ff00000UL,\n-    0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL, 0x20000000UL,\n-    0x3c5e0d89UL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL, 0xbfc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0x3ff00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL,\n-    0x20000000UL, 0x3c68076aUL, 0x00000000UL, 0x3ff00000UL, 0x99fcef32UL,\n-    0x3fca8279UL, 0x667f3bcdUL, 0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL,\n-    0x00000000UL, 0x3fe00000UL, 0x94247758UL, 0x3fc133ccUL, 0x6b151741UL,\n-    0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL, 0x00000000UL, 0x3fe00000UL,\n-    0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL, 0xe0000000UL,\n-    0x3c39f630UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL, 0xbf9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0x3fe00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0x3fed906bUL,\n-    0x20000000UL, 0x3c7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x76acf82dUL,\n-    0x3fa4a031UL, 0x56c62ddaUL, 0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL,\n-    0x00000000UL, 0x3fd00000UL, 0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL,\n-    0x3fef6297UL, 0x20000000UL, 0x3c756217UL, 0x00000000UL, 0x3fd00000UL,\n-    0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL, 0x3fefd88dUL, 0x40000000UL,\n-    0xbc887df6UL, 0x00000000UL, 0x3fc00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0x3fefd88dUL,\n-    0x40000000UL, 0xbc887df6UL, 0x00000000UL, 0xbfc00000UL, 0x0e5967d5UL,\n-    0x3fac1d1fUL, 0xcff75cb0UL, 0x3fef6297UL, 0x20000000UL, 0x3c756217UL,\n-    0x00000000UL, 0xbfd00000UL, 0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL,\n-    0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL, 0x00000000UL, 0xbfd00000UL,\n-    0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL, 0x3fed906bUL, 0x20000000UL,\n-    0x3c7457e6UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL, 0x3f9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL,\n-    0xe0000000UL, 0x3c39f630UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL,\n-    0xbfc133ccUL, 0x6b151741UL, 0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL,\n-    0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL, 0x00000000UL, 0xbfe00000UL,\n-    0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL, 0x20000000UL,\n-    0x3c68076aUL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL, 0x3fc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL,\n-    0x20000000UL, 0x3c5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL,\n-    0x3fb37ca1UL, 0xa6aea963UL, 0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL,\n-    0x00000000UL, 0xbff00000UL, 0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL,\n-    0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL, 0x00000000UL, 0xbff00000UL,\n-    0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL, 0xc0000000UL,\n-    0xbc626d19UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL, 0x3f73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0xbff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL,\n-    0x3f73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0xbff00000UL, 0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL,\n-    0xbfc8f8b8UL, 0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0xbff00000UL,\n-    0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL,\n-    0x3c75d28dUL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL, 0x3fb37ca1UL,\n-    0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL, 0x3c672cedUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0xbfde2b5dUL,\n-    0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL,\n-    0x3fc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0xbff00000UL, 0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL,\n-    0xbfe44cf3UL, 0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0xbff00000UL,\n-    0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL,\n-    0x3c8bdd34UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL, 0xbfc133ccUL,\n-    0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL, 0x3c82c5e1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0xbfea9b66UL,\n-    0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL,\n-    0x3f9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL,\n-    0xbfed906bUL, 0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0xbfe00000UL,\n-    0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL,\n-    0xbc8760b1UL, 0x00000000UL, 0xbfd00000UL, 0x0e5967d5UL, 0x3fac1d1fUL,\n-    0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL, 0xbc756217UL, 0x00000000UL,\n-    0xbfd00000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0xbfefd88dUL,\n-    0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0xbfc00000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL,\n-    0xbfefd88dUL, 0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0x3fc00000UL,\n-    0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL,\n-    0xbc756217UL, 0x00000000UL, 0x3fd00000UL, 0x76acf82dUL, 0x3fa4a031UL,\n-    0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL, 0xbc8760b1UL, 0x00000000UL,\n-    0x3fd00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0xbfed906bUL,\n-    0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL,\n-    0xbf9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0x3fe00000UL, 0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL,\n-    0xbfea9b66UL, 0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0x3fe00000UL,\n-    0x94247758UL, 0x3fc133ccUL, 0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL,\n-    0x3c82c5e1UL, 0x00000000UL, 0x3fe00000UL, 0x99fcef32UL, 0x3fca8279UL,\n-    0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL, 0x3c8bdd34UL, 0x00000000UL,\n-    0x3fe00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0xbfe44cf3UL,\n-    0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL,\n-    0xbfc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0x3ff00000UL, 0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL,\n-    0xbfde2b5dUL, 0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0x3ff00000UL,\n-    0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL,\n-    0x3c672cedUL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL, 0xbfa60beaUL,\n-    0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL, 0x3c75d28dUL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0xbfc8f8b8UL,\n-    0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL,\n-    0xbf73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0x3ff00000UL, 0x55555555UL, 0xbfc55555UL, 0x00000000UL,\n-    0xbfe00000UL, 0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL,\n-    0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL, 0xa556c734UL,\n-    0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL, 0x1a600000UL, 0x3d90b461UL,\n-    0x1a600000UL, 0x3d90b461UL, 0x54400000UL, 0x3fb921fbUL, 0x00000000UL,\n-    0x00000000UL, 0x2e037073UL, 0x3b63198aUL, 0x00000000UL, 0x00000000UL,\n-    0x6dc9c883UL, 0x40245f30UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x43380000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x3ff00000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x80000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x80000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-};\n-\/\/registers,\n-\/\/ input: (rbp + 8)\n-\/\/ scratch: xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7\n-\/\/          eax, ecx, edx, ebx (tmp)\n-\n-\/\/ Code generated by Intel C compiler for LIBM library\n-\n-void MacroAssembler::fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                              Register eax, Register ecx, Register edx, Register tmp) {\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label start;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-\n-  address static_const_table_cos = (address)_static_const_table_cos;\n-\n-  bind(start);\n-  subl(rsp, 120);\n-  movl(Address(rsp, 56), tmp);\n-  lea(tmp, ExternalAddress(static_const_table_cos));\n-  movsd(xmm0, Address(rsp, 128));\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32767);\n-  subl(eax, 12336);\n-  cmpl(eax, 4293);\n-  jcc(Assembler::above, L_2TAG_PACKET_0_0_2);\n-  movsd(xmm1, Address(tmp, 2160));\n-  mulsd(xmm1, xmm0);\n-  movdqu(xmm5, Address(tmp, 2240));\n-  movsd(xmm4, Address(tmp, 2224));\n-  pand(xmm4, xmm0);\n-  por(xmm5, xmm4);\n-  movsd(xmm3, Address(tmp, 2128));\n-  movdqu(xmm2, Address(tmp, 2112));\n-  addpd(xmm1, xmm5);\n-  cvttsd2sil(edx, xmm1);\n-  cvtsi2sdl(xmm1, edx);\n-  mulsd(xmm3, xmm1);\n-  unpcklpd(xmm1, xmm1);\n-  addl(edx, 1865232);\n-  movdqu(xmm4, xmm0);\n-  andl(edx, 63);\n-  movdqu(xmm5, Address(tmp, 2096));\n-  lea(eax, Address(tmp, 0));\n-  shll(edx, 5);\n-  addl(eax, edx);\n-  mulpd(xmm2, xmm1);\n-  subsd(xmm0, xmm3);\n-  mulsd(xmm1, Address(tmp, 2144));\n-  subsd(xmm4, xmm3);\n-  movsd(xmm7, Address(eax, 8));\n-  unpcklpd(xmm0, xmm0);\n-  movapd(xmm3, xmm4);\n-  subsd(xmm4, xmm2);\n-  mulpd(xmm5, xmm0);\n-  subpd(xmm0, xmm2);\n-  movdqu(xmm6, Address(tmp, 2064));\n-  mulsd(xmm7, xmm4);\n-  subsd(xmm3, xmm4);\n-  mulpd(xmm5, xmm0);\n-  mulpd(xmm0, xmm0);\n-  subsd(xmm3, xmm2);\n-  movdqu(xmm2, Address(eax, 0));\n-  subsd(xmm1, xmm3);\n-  movsd(xmm3, Address(eax, 24));\n-  addsd(xmm2, xmm3);\n-  subsd(xmm7, xmm2);\n-  mulsd(xmm2, xmm4);\n-  mulpd(xmm6, xmm0);\n-  mulsd(xmm3, xmm4);\n-  mulpd(xmm2, xmm0);\n-  mulpd(xmm0, xmm0);\n-  addpd(xmm5, Address(tmp, 2080));\n-  mulsd(xmm4, Address(eax, 0));\n-  addpd(xmm6, Address(tmp, 2048));\n-  mulpd(xmm5, xmm0);\n-  movapd(xmm0, xmm3);\n-  addsd(xmm3, Address(eax, 8));\n-  mulpd(xmm1, xmm7);\n-  movapd(xmm7, xmm4);\n-  addsd(xmm4, xmm3);\n-  addpd(xmm6, xmm5);\n-  movsd(xmm5, Address(eax, 8));\n-  subsd(xmm5, xmm3);\n-  subsd(xmm3, xmm4);\n-  addsd(xmm1, Address(eax, 16));\n-  mulpd(xmm6, xmm2);\n-  addsd(xmm5, xmm0);\n-  addsd(xmm3, xmm7);\n-  addsd(xmm1, xmm5);\n-  addsd(xmm1, xmm3);\n-  addsd(xmm1, xmm6);\n-  unpckhpd(xmm6, xmm6);\n-  addsd(xmm1, xmm6);\n-  addsd(xmm4, xmm1);\n-  movsd(Address(rsp, 0), xmm4);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  jcc(Assembler::greater, L_2TAG_PACKET_2_0_2);\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32767);\n-  pinsrw(xmm0, eax, 3);\n-  movsd(xmm1, Address(tmp, 2192));\n-  subsd(xmm1, xmm0);\n-  movsd(Address(rsp, 0), xmm1);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movl(eax, Address(rsp, 132));\n-  andl(eax, 2146435072);\n-  cmpl(eax, 2146435072);\n-  jcc(Assembler::equal, L_2TAG_PACKET_3_0_2);\n-  subl(rsp, 32);\n-  movsd(Address(rsp, 0), xmm0);\n-  lea(eax, Address(rsp, 40));\n-  movl(Address(rsp, 8), eax);\n-  movl(eax, 1);\n-  movl(Address(rsp, 12), eax);\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlibm_sin_cos_huge())));\n-  addl(rsp, 32);\n-  fld_d(Address(rsp, 8));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  fld_d(Address(rsp, 128));\n-  fmul_d(Address(tmp, 2208));\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  movl(tmp, Address(rsp, 56));\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_cos.cpp","additions":0,"deletions":427,"binary":false,"changes":427,"status":"deleted"},{"patch":"@@ -1,329 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Copyright (C) 2021 THL A29 Limited, a Tencent company. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - EXP()\n-\/\/                     ---------------------\n-\/\/\n-\/\/ Description:\n-\/\/  Let K = 64 (table size).\n-\/\/        x    x\/log(2)     n\n-\/\/       e  = 2          = 2 * T[j] * (1 + P(y))\n-\/\/  where\n-\/\/       x = m*log(2)\/K + y,    y in [-log(2)\/K..log(2)\/K]\n-\/\/       m = n*K + j,           m,n,j - signed integer, j in [-K\/2..K\/2]\n-\/\/                  j\/K\n-\/\/       values of 2   are tabulated as T[j] = T_hi[j] ( 1 + T_lo[j]).\n-\/\/\n-\/\/       P(y) is a minimax polynomial approximation of exp(x)-1\n-\/\/       on small interval [-log(2)\/K..log(2)\/K] (were calculated by Maple V).\n-\/\/\n-\/\/  To avoid problems with arithmetic overflow and underflow,\n-\/\/            n                        n1  n2\n-\/\/  value of 2  is safely computed as 2 * 2 where n1 in [-BIAS\/2..BIAS\/2]\n-\/\/  where BIAS is a value of exponent bias.\n-\/\/\n-\/\/ Special cases:\n-\/\/  exp(NaN) = NaN\n-\/\/  exp(+INF) = +INF\n-\/\/  exp(-INF) = 0\n-\/\/  exp(x) = 1 for subnormals\n-\/\/  for finite argument, only exp(0)=1 is exact\n-\/\/  For IEEE double\n-\/\/    if x >  709.782712893383973096 then exp(x) overflow\n-\/\/    if x < -745.133219101941108420 then exp(x) underflow\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table[] =\n-{\n-    0x00000000UL, 0xfff00000UL, 0x00000000UL, 0xfff00000UL, 0xffffffc0UL,\n-    0x00000000UL, 0xffffffc0UL, 0x00000000UL, 0x0000ffc0UL, 0x00000000UL,\n-    0x0000ffc0UL, 0x00000000UL, 0x00000000UL, 0x43380000UL, 0x00000000UL,\n-    0x43380000UL, 0x652b82feUL, 0x40571547UL, 0x652b82feUL, 0x40571547UL,\n-    0xfefa0000UL, 0x3f862e42UL, 0xfefa0000UL, 0x3f862e42UL, 0xbc9e3b3aUL,\n-    0x3d1cf79aUL, 0xbc9e3b3aUL, 0x3d1cf79aUL, 0xfffffffeUL, 0x3fdfffffUL,\n-    0xfffffffeUL, 0x3fdfffffUL, 0xe3289860UL, 0x3f56c15cUL, 0x555b9e25UL,\n-    0x3fa55555UL, 0xc090cf0fUL, 0x3f811115UL, 0x55548ba1UL, 0x3fc55555UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x0e03754dUL,\n-    0x3cad7bbfUL, 0x3e778060UL, 0x00002c9aUL, 0x3567f613UL, 0x3c8cd252UL,\n-    0xd3158574UL, 0x000059b0UL, 0x61e6c861UL, 0x3c60f74eUL, 0x18759bc8UL,\n-    0x00008745UL, 0x5d837b6cUL, 0x3c979aa6UL, 0x6cf9890fUL, 0x0000b558UL,\n-    0x702f9cd1UL, 0x3c3ebe3dUL, 0x32d3d1a2UL, 0x0000e3ecUL, 0x1e63bcd8UL,\n-    0x3ca3516eUL, 0xd0125b50UL, 0x00011301UL, 0x26f0387bUL, 0x3ca4c554UL,\n-    0xaea92ddfUL, 0x0001429aUL, 0x62523fb6UL, 0x3ca95153UL, 0x3c7d517aUL,\n-    0x000172b8UL, 0x3f1353bfUL, 0x3c8b898cUL, 0xeb6fcb75UL, 0x0001a35bUL,\n-    0x3e3a2f5fUL, 0x3c9aecf7UL, 0x3168b9aaUL, 0x0001d487UL, 0x44a6c38dUL,\n-    0x3c8a6f41UL, 0x88628cd6UL, 0x0002063bUL, 0xe3a8a894UL, 0x3c968efdUL,\n-    0x6e756238UL, 0x0002387aUL, 0x981fe7f2UL, 0x3c80472bUL, 0x65e27cddUL,\n-    0x00026b45UL, 0x6d09ab31UL, 0x3c82f7e1UL, 0xf51fdee1UL, 0x00029e9dUL,\n-    0x720c0ab3UL, 0x3c8b3782UL, 0xa6e4030bUL, 0x0002d285UL, 0x4db0abb6UL,\n-    0x3c834d75UL, 0x0a31b715UL, 0x000306feUL, 0x5dd3f84aUL, 0x3c8fdd39UL,\n-    0xb26416ffUL, 0x00033c08UL, 0xcc187d29UL, 0x3ca12f8cUL, 0x373aa9caUL,\n-    0x000371a7UL, 0x738b5e8bUL, 0x3ca7d229UL, 0x34e59ff6UL, 0x0003a7dbUL,\n-    0xa72a4c6dUL, 0x3c859f48UL, 0x4c123422UL, 0x0003dea6UL, 0x259d9205UL,\n-    0x3ca8b846UL, 0x21f72e29UL, 0x0004160aUL, 0x60c2ac12UL, 0x3c4363edUL,\n-    0x6061892dUL, 0x00044e08UL, 0xdaa10379UL, 0x3c6ecce1UL, 0xb5c13cd0UL,\n-    0x000486a2UL, 0xbb7aafb0UL, 0x3c7690ceUL, 0xd5362a27UL, 0x0004bfdaUL,\n-    0x9b282a09UL, 0x3ca083ccUL, 0x769d2ca6UL, 0x0004f9b2UL, 0xc1aae707UL,\n-    0x3ca509b0UL, 0x569d4f81UL, 0x0005342bUL, 0x18fdd78eUL, 0x3c933505UL,\n-    0x36b527daUL, 0x00056f47UL, 0xe21c5409UL, 0x3c9063e1UL, 0xdd485429UL,\n-    0x0005ab07UL, 0x2b64c035UL, 0x3c9432e6UL, 0x15ad2148UL, 0x0005e76fUL,\n-    0x99f08c0aUL, 0x3ca01284UL, 0xb03a5584UL, 0x0006247eUL, 0x0073dc06UL,\n-    0x3c99f087UL, 0x82552224UL, 0x00066238UL, 0x0da05571UL, 0x3c998d4dUL,\n-    0x667f3bccUL, 0x0006a09eUL, 0x86ce4786UL, 0x3ca52bb9UL, 0x3c651a2eUL,\n-    0x0006dfb2UL, 0x206f0dabUL, 0x3ca32092UL, 0xe8ec5f73UL, 0x00071f75UL,\n-    0x8e17a7a6UL, 0x3ca06122UL, 0x564267c8UL, 0x00075febUL, 0x461e9f86UL,\n-    0x3ca244acUL, 0x73eb0186UL, 0x0007a114UL, 0xabd66c55UL, 0x3c65ebe1UL,\n-    0x36cf4e62UL, 0x0007e2f3UL, 0xbbff67d0UL, 0x3c96fe9fUL, 0x994cce12UL,\n-    0x00082589UL, 0x14c801dfUL, 0x3c951f14UL, 0x9b4492ecUL, 0x000868d9UL,\n-    0xc1f0eab4UL, 0x3c8db72fUL, 0x422aa0dbUL, 0x0008ace5UL, 0x59f35f44UL,\n-    0x3c7bf683UL, 0x99157736UL, 0x0008f1aeUL, 0x9c06283cUL, 0x3ca360baUL,\n-    0xb0cdc5e4UL, 0x00093737UL, 0x20f962aaUL, 0x3c95e8d1UL, 0x9fde4e4fUL,\n-    0x00097d82UL, 0x2b91ce27UL, 0x3c71affcUL, 0x82a3f090UL, 0x0009c491UL,\n-    0x589a2ebdUL, 0x3c9b6d34UL, 0x7b5de564UL, 0x000a0c66UL, 0x9ab89880UL,\n-    0x3c95277cUL, 0xb23e255cUL, 0x000a5503UL, 0x6e735ab3UL, 0x3c846984UL,\n-    0x5579fdbfUL, 0x000a9e6bUL, 0x92cb3387UL, 0x3c8c1a77UL, 0x995ad3adUL,\n-    0x000ae89fUL, 0xdc2d1d96UL, 0x3ca22466UL, 0xb84f15faUL, 0x000b33a2UL,\n-    0xb19505aeUL, 0x3ca1112eUL, 0xf2fb5e46UL, 0x000b7f76UL, 0x0a5fddcdUL,\n-    0x3c74ffd7UL, 0x904bc1d2UL, 0x000bcc1eUL, 0x30af0cb3UL, 0x3c736eaeUL,\n-    0xdd85529cUL, 0x000c199bUL, 0xd10959acUL, 0x3c84e08fUL, 0x2e57d14bUL,\n-    0x000c67f1UL, 0x6c921968UL, 0x3c676b2cUL, 0xdcef9069UL, 0x000cb720UL,\n-    0x36df99b3UL, 0x3c937009UL, 0x4a07897bUL, 0x000d072dUL, 0xa63d07a7UL,\n-    0x3c74a385UL, 0xdcfba487UL, 0x000d5818UL, 0xd5c192acUL, 0x3c8e5a50UL,\n-    0x03db3285UL, 0x000da9e6UL, 0x1c4a9792UL, 0x3c98bb73UL, 0x337b9b5eUL,\n-    0x000dfc97UL, 0x603a88d3UL, 0x3c74b604UL, 0xe78b3ff6UL, 0x000e502eUL,\n-    0x92094926UL, 0x3c916f27UL, 0xa2a490d9UL, 0x000ea4afUL, 0x41aa2008UL,\n-    0x3c8ec3bcUL, 0xee615a27UL, 0x000efa1bUL, 0x31d185eeUL, 0x3c8a64a9UL,\n-    0x5b6e4540UL, 0x000f5076UL, 0x4d91cd9dUL, 0x3c77893bUL, 0x819e90d8UL,\n-    0x000fa7c1UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x7ff00000UL,\n-    0x00000000UL, 0x00000000UL, 0xffffffffUL, 0x7fefffffUL, 0x00000000UL,\n-    0x00100000UL\n-};\n-\n-\/\/registers,\n-\/\/ input: (rbp + 8)\n-\/\/ scratch: xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7\n-\/\/          rax, rdx, rcx, rbx (tmp)\n-\n-\/\/ Code generated by Intel C compiler for LIBM library\n-\n-void MacroAssembler::fast_exp(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                              Register eax, Register ecx, Register edx, Register tmp) {\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2, L_2TAG_PACKET_5_0_2, L_2TAG_PACKET_6_0_2, L_2TAG_PACKET_7_0_2;\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, L_2TAG_PACKET_10_0_2, L_2TAG_PACKET_11_0_2;\n-  Label L_2TAG_PACKET_12_0_2;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-  address static_const_table = (address)_static_const_table;\n-\n-  subl(rsp, 120);\n-  movl(Address(rsp, 64), tmp);\n-  lea(tmp, ExternalAddress(static_const_table));\n-  movsd(xmm0, Address(rsp, 128));\n-  unpcklpd(xmm0, xmm0);\n-  movdqu(xmm1, Address(tmp, 64));          \/\/ 0x652b82feUL, 0x40571547UL, 0x652b82feUL, 0x40571547UL\n-  movdqu(xmm6, Address(tmp, 48));          \/\/ 0x00000000UL, 0x43380000UL, 0x00000000UL, 0x43380000UL\n-  movdqu(xmm2, Address(tmp, 80));          \/\/ 0xfefa0000UL, 0x3f862e42UL, 0xfefa0000UL, 0x3f862e42UL\n-  movdqu(xmm3, Address(tmp, 96));          \/\/ 0xbc9e3b3aUL, 0x3d1cf79aUL, 0xbc9e3b3aUL, 0x3d1cf79aUL\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32767);\n-  movl(edx, 16527);\n-  subl(edx, eax);\n-  subl(eax, 15504);\n-  orl(edx, eax);\n-  cmpl(edx, INT_MIN);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_0_0_2);\n-  mulpd(xmm1, xmm0);\n-  addpd(xmm1, xmm6);\n-  movapd(xmm7, xmm1);\n-  subpd(xmm1, xmm6);\n-  mulpd(xmm2, xmm1);\n-  movdqu(xmm4, Address(tmp, 128));         \/\/ 0xe3289860UL, 0x3f56c15cUL, 0x555b9e25UL, 0x3fa55555UL\n-  mulpd(xmm3, xmm1);\n-  movdqu(xmm5, Address(tmp, 144));         \/\/ 0xc090cf0fUL, 0x3f811115UL, 0x55548ba1UL, 0x3fc55555UL\n-  subpd(xmm0, xmm2);\n-  movdl(eax, xmm7);\n-  movl(ecx, eax);\n-  andl(ecx, 63);\n-  shll(ecx, 4);\n-  sarl(eax, 6);\n-  movl(edx, eax);\n-  movdqu(xmm6, Address(tmp, 16));          \/\/ 0xffffffc0UL, 0x00000000UL, 0xffffffc0UL, 0x00000000UL\n-  pand(xmm7, xmm6);\n-  movdqu(xmm6, Address(tmp, 32));          \/\/ 0x0000ffc0UL, 0x00000000UL, 0x0000ffc0UL, 0x00000000UL\n-  paddq(xmm7, xmm6);\n-  psllq(xmm7, 46);\n-  subpd(xmm0, xmm3);\n-  movdqu(xmm2, Address(tmp, ecx, Address::times_1, 160));\n-  mulpd(xmm4, xmm0);\n-  movapd(xmm6, xmm0);\n-  movapd(xmm1, xmm0);\n-  mulpd(xmm6, xmm6);\n-  mulpd(xmm0, xmm6);\n-  addpd(xmm5, xmm4);\n-  mulsd(xmm0, xmm6);\n-  mulpd(xmm6, Address(tmp, 112));          \/\/ 0xfffffffeUL, 0x3fdfffffUL, 0xfffffffeUL, 0x3fdfffffUL\n-  addsd(xmm1, xmm2);\n-  unpckhpd(xmm2, xmm2);\n-  mulpd(xmm0, xmm5);\n-  addsd(xmm1, xmm0);\n-  por(xmm2, xmm7);\n-  unpckhpd(xmm0, xmm0);\n-  addsd(xmm0, xmm1);\n-  addsd(xmm0, xmm6);\n-  addl(edx, 894);\n-  cmpl(edx, 1916);\n-  jcc(Assembler::above, L_2TAG_PACKET_1_0_2);\n-  mulsd(xmm0, xmm2);\n-  addsd(xmm0, xmm2);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  fnstcw(Address(rsp, 24));\n-  movzwl(edx, Address(rsp, 24));\n-  orl(edx, 768);\n-  movw(Address(rsp, 28), edx);\n-  fldcw(Address(rsp, 28));\n-  movl(edx, eax);\n-  sarl(eax, 1);\n-  subl(edx, eax);\n-  movdqu(xmm6, Address(tmp, 0));           \/\/ 0x00000000UL, 0xfff00000UL, 0x00000000UL, 0xfff00000UL\n-  pandn(xmm6, xmm2);\n-  addl(eax, 1023);\n-  movdl(xmm3, eax);\n-  psllq(xmm3, 52);\n-  por(xmm6, xmm3);\n-  addl(edx, 1023);\n-  movdl(xmm4, edx);\n-  psllq(xmm4, 52);\n-  movsd(Address(rsp, 8), xmm0);\n-  fld_d(Address(rsp, 8));\n-  movsd(Address(rsp, 16), xmm6);\n-  fld_d(Address(rsp, 16));\n-  fmula(1);\n-  faddp(1);\n-  movsd(Address(rsp, 8), xmm4);\n-  fld_d(Address(rsp, 8));\n-  fmulp(1);\n-  fstp_d(Address(rsp, 8));\n-  movsd(xmm0, Address(rsp, 8));\n-  fldcw(Address(rsp, 24));\n-  pextrw(ecx, xmm0, 3);\n-  andl(ecx, 32752);\n-  cmpl(ecx, 32752);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_3_0_2);\n-  cmpl(ecx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_4_0_2);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-  cmpl(ecx, INT_MIN);\n-  jcc(Assembler::below, L_2TAG_PACKET_3_0_2);\n-  cmpl(ecx, -1064950997);\n-  jcc(Assembler::below, L_2TAG_PACKET_2_0_2);\n-  jcc(Assembler::above, L_2TAG_PACKET_4_0_2);\n-  movl(edx, Address(rsp, 128));\n-  cmpl(edx, -17155601);\n-  jcc(Assembler::below, L_2TAG_PACKET_2_0_2);\n-  jmp(L_2TAG_PACKET_4_0_2);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  movl(edx, 14);\n-  jmp(L_2TAG_PACKET_5_0_2);\n-\n-  bind(L_2TAG_PACKET_4_0_2);\n-  movl(edx, 15);\n-\n-  bind(L_2TAG_PACKET_5_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  movsd(xmm0, Address(rsp, 128));\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_7_0_2);\n-  cmpl(eax, 2146435072);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_8_0_2);\n-  movl(eax, Address(rsp, 132));\n-  cmpl(eax, INT_MIN);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_9_0_2);\n-  movsd(xmm0, Address(tmp, 1208));         \/\/ 0xffffffffUL, 0x7fefffffUL\n-  mulsd(xmm0, xmm0);\n-  movl(edx, 14);\n-  jmp(L_2TAG_PACKET_5_0_2);\n-\n-  bind(L_2TAG_PACKET_9_0_2);\n-  movsd(xmm0, Address(tmp, 1216));\n-  mulsd(xmm0, xmm0);\n-  movl(edx, 15);\n-  jmp(L_2TAG_PACKET_5_0_2);\n-\n-  bind(L_2TAG_PACKET_8_0_2);\n-  movl(edx, Address(rsp, 128));\n-  cmpl(eax, 2146435072);\n-  jcc(Assembler::above, L_2TAG_PACKET_10_0_2);\n-  cmpl(edx, 0);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_10_0_2);\n-  movl(eax, Address(rsp, 132));\n-  cmpl(eax, 2146435072);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_11_0_2);\n-  movsd(xmm0, Address(tmp, 1192));         \/\/ 0x00000000UL, 0x7ff00000UL\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_11_0_2);\n-  movsd(xmm0, Address(tmp, 1200));         \/\/ 0x00000000UL, 0x00000000UL\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_10_0_2);\n-  movsd(xmm0, Address(rsp, 128));\n-  addsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  movl(eax, Address(rsp, 132));\n-  andl(eax, 2147483647);\n-  cmpl(eax, 1083179008);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_7_0_2);\n-  movsd(xmm0, Address(rsp, 128));\n-  addsd(xmm0, Address(tmp, 1184));         \/\/ 0x00000000UL, 0x3ff00000UL\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movsd(Address(rsp, 48), xmm0);\n-  fld_d(Address(rsp, 48));\n-\n-  bind(L_2TAG_PACKET_6_0_2);\n-  movl(tmp, Address(rsp, 64));\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_exp.cpp","additions":0,"deletions":329,"binary":false,"changes":329,"status":"deleted"},{"patch":"@@ -1,344 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Copyright (C) 2021 THL A29 Limited, a Tencent company. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - LOG()\n-\/\/                     ---------------------\n-\/\/\n-\/\/    x=2^k * mx, mx in [1,2)\n-\/\/\n-\/\/    Get B~1\/mx based on the output of rcpss instruction (B0)\n-\/\/    B = int((B0*2^7+0.5))\/2^7\n-\/\/\n-\/\/    Reduced argument: r=B*mx-1.0 (computed accurately in high and low parts)\n-\/\/\n-\/\/    Result:  k*log(2) - log(B) + p(r) if |x-1| >= small value (2^-6)  and\n-\/\/             p(r) is a degree 7 polynomial\n-\/\/             -log(B) read from data table (high, low parts)\n-\/\/             Result is formed from high and low parts\n-\/\/\n-\/\/ Special cases:\n-\/\/  log(NaN) = quiet NaN, and raise invalid exception\n-\/\/  log(+INF) = that INF\n-\/\/  log(0) = -INF with divide-by-zero exception raised\n-\/\/  log(1) = +0\n-\/\/  log(x) = NaN with invalid exception raised if x < -0, including -INF\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-\/\/\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_log[] =\n-{\n-    0xfefa3800UL, 0x3fe62e42UL, 0x93c76730UL, 0x3d2ef357UL, 0xaa241800UL,\n-    0x3fe5ee82UL, 0x0cda46beUL, 0x3d220238UL, 0x5c364800UL, 0x3fe5af40UL,\n-    0xac10c9fbUL, 0x3d2dfa63UL, 0x26bb8c00UL, 0x3fe5707aUL, 0xff3303ddUL,\n-    0x3d09980bUL, 0x26867800UL, 0x3fe5322eUL, 0x5d257531UL, 0x3d05ccc4UL,\n-    0x835a5000UL, 0x3fe4f45aUL, 0x6d93b8fbUL, 0xbd2e6c51UL, 0x6f970c00UL,\n-    0x3fe4b6fdUL, 0xed4c541cUL, 0x3cef7115UL, 0x27e8a400UL, 0x3fe47a15UL,\n-    0xf94d60aaUL, 0xbd22cb6aUL, 0xf2f92400UL, 0x3fe43d9fUL, 0x481051f7UL,\n-    0xbcfd984fUL, 0x2125cc00UL, 0x3fe4019cUL, 0x30f0c74cUL, 0xbd26ce79UL,\n-    0x0c36c000UL, 0x3fe3c608UL, 0x7cfe13c2UL, 0xbd02b736UL, 0x17197800UL,\n-    0x3fe38ae2UL, 0xbb5569a4UL, 0xbd218b7aUL, 0xad9d8c00UL, 0x3fe35028UL,\n-    0x9527e6acUL, 0x3d10b83fUL, 0x44340800UL, 0x3fe315daUL, 0xc5a0ed9cUL,\n-    0xbd274e93UL, 0x57b0e000UL, 0x3fe2dbf5UL, 0x07b9dc11UL, 0xbd17a6e5UL,\n-    0x6d0ec000UL, 0x3fe2a278UL, 0xe797882dUL, 0x3d206d2bUL, 0x1134dc00UL,\n-    0x3fe26962UL, 0x05226250UL, 0xbd0b61f1UL, 0xd8bebc00UL, 0x3fe230b0UL,\n-    0x6e48667bUL, 0x3d12fc06UL, 0x5fc61800UL, 0x3fe1f863UL, 0xc9fe81d3UL,\n-    0xbd2a7242UL, 0x49ae6000UL, 0x3fe1c078UL, 0xed70e667UL, 0x3cccacdeUL,\n-    0x40f23c00UL, 0x3fe188eeUL, 0xf8ab4650UL, 0x3d14cc4eUL, 0xf6f29800UL,\n-    0x3fe151c3UL, 0xa293ae49UL, 0xbd2edd97UL, 0x23c75c00UL, 0x3fe11af8UL,\n-    0xbb9ddcb2UL, 0xbd258647UL, 0x8611cc00UL, 0x3fe0e489UL, 0x07801742UL,\n-    0x3d1c2998UL, 0xe2d05400UL, 0x3fe0ae76UL, 0x887e7e27UL, 0x3d1f486bUL,\n-    0x0533c400UL, 0x3fe078bfUL, 0x41edf5fdUL, 0x3d268122UL, 0xbe760400UL,\n-    0x3fe04360UL, 0xe79539e0UL, 0xbd04c45fUL, 0xe5b20800UL, 0x3fe00e5aUL,\n-    0xb1727b1cUL, 0xbd053ba3UL, 0xaf7a4800UL, 0x3fdfb358UL, 0x3c164935UL,\n-    0x3d0085faUL, 0xee031800UL, 0x3fdf4aa7UL, 0x6f014a8bUL, 0x3d12cde5UL,\n-    0x56b41000UL, 0x3fdee2a1UL, 0x5a470251UL, 0x3d2f27f4UL, 0xc3ddb000UL,\n-    0x3fde7b42UL, 0x5372bd08UL, 0xbd246550UL, 0x1a272800UL, 0x3fde148aUL,\n-    0x07322938UL, 0xbd1326b2UL, 0x484c9800UL, 0x3fddae75UL, 0x60dc616aUL,\n-    0xbd1ea42dUL, 0x46def800UL, 0x3fdd4902UL, 0xe9a767a8UL, 0x3d235bafUL,\n-    0x18064800UL, 0x3fdce42fUL, 0x3ec7a6b0UL, 0xbd0797c3UL, 0xc7455800UL,\n-    0x3fdc7ff9UL, 0xc15249aeUL, 0xbd29b6ddUL, 0x693fa000UL, 0x3fdc1c60UL,\n-    0x7fe8e180UL, 0x3d2cec80UL, 0x1b80e000UL, 0x3fdbb961UL, 0xf40a666dUL,\n-    0x3d27d85bUL, 0x04462800UL, 0x3fdb56faUL, 0x2d841995UL, 0x3d109525UL,\n-    0x5248d000UL, 0x3fdaf529UL, 0x52774458UL, 0xbd217cc5UL, 0x3c8ad800UL,\n-    0x3fda93edUL, 0xbea77a5dUL, 0x3d1e36f2UL, 0x0224f800UL, 0x3fda3344UL,\n-    0x7f9d79f5UL, 0x3d23c645UL, 0xea15f000UL, 0x3fd9d32bUL, 0x10d0c0b0UL,\n-    0xbd26279eUL, 0x43135800UL, 0x3fd973a3UL, 0xa502d9f0UL, 0xbd152313UL,\n-    0x635bf800UL, 0x3fd914a8UL, 0x2ee6307dUL, 0xbd1766b5UL, 0xa88b3000UL,\n-    0x3fd8b639UL, 0xe5e70470UL, 0xbd205ae1UL, 0x776dc800UL, 0x3fd85855UL,\n-    0x3333778aUL, 0x3d2fd56fUL, 0x3bd81800UL, 0x3fd7fafaUL, 0xc812566aUL,\n-    0xbd272090UL, 0x687cf800UL, 0x3fd79e26UL, 0x2efd1778UL, 0x3d29ec7dUL,\n-    0x76c67800UL, 0x3fd741d8UL, 0x49dc60b3UL, 0x3d2d8b09UL, 0xe6af1800UL,\n-    0x3fd6e60eUL, 0x7c222d87UL, 0x3d172165UL, 0x3e9c6800UL, 0x3fd68ac8UL,\n-    0x2756eba0UL, 0x3d20a0d3UL, 0x0b3ab000UL, 0x3fd63003UL, 0xe731ae00UL,\n-    0xbd2db623UL, 0xdf596000UL, 0x3fd5d5bdUL, 0x08a465dcUL, 0xbd0a0b2aUL,\n-    0x53c8d000UL, 0x3fd57bf7UL, 0xee5d40efUL, 0x3d1fadedUL, 0x0738a000UL,\n-    0x3fd522aeUL, 0x8164c759UL, 0x3d2ebe70UL, 0x9e173000UL, 0x3fd4c9e0UL,\n-    0x1b0ad8a4UL, 0xbd2e2089UL, 0xc271c800UL, 0x3fd4718dUL, 0x0967d675UL,\n-    0xbd2f27ceUL, 0x23d5e800UL, 0x3fd419b4UL, 0xec90e09dUL, 0x3d08e436UL,\n-    0x77333000UL, 0x3fd3c252UL, 0xb606bd5cUL, 0x3d183b54UL, 0x76be1000UL,\n-    0x3fd36b67UL, 0xb0f177c8UL, 0x3d116ecdUL, 0xe1d36000UL, 0x3fd314f1UL,\n-    0xd3213cb8UL, 0xbd28e27aUL, 0x7cdc9000UL, 0x3fd2bef0UL, 0x4a5004f4UL,\n-    0x3d2a9cfaUL, 0x1134d800UL, 0x3fd26962UL, 0xdf5bb3b6UL, 0x3d2c93c1UL,\n-    0x6d0eb800UL, 0x3fd21445UL, 0xba46baeaUL, 0x3d0a87deUL, 0x635a6800UL,\n-    0x3fd1bf99UL, 0x5147bdb7UL, 0x3d2ca6edUL, 0xcbacf800UL, 0x3fd16b5cUL,\n-    0xf7a51681UL, 0x3d2b9acdUL, 0x8227e800UL, 0x3fd1178eUL, 0x63a5f01cUL,\n-    0xbd2c210eUL, 0x67616000UL, 0x3fd0c42dUL, 0x163ceae9UL, 0x3d27188bUL,\n-    0x604d5800UL, 0x3fd07138UL, 0x16ed4e91UL, 0x3cf89cdbUL, 0x5626c800UL,\n-    0x3fd01eaeUL, 0x1485e94aUL, 0xbd16f08cUL, 0x6cb3b000UL, 0x3fcf991cUL,\n-    0xca0cdf30UL, 0x3d1bcbecUL, 0xe4dd0000UL, 0x3fcef5adUL, 0x65bb8e11UL,\n-    0xbcca2115UL, 0xffe71000UL, 0x3fce530eUL, 0x6041f430UL, 0x3cc21227UL,\n-    0xb0d49000UL, 0x3fcdb13dUL, 0xf715b035UL, 0xbd2aff2aUL, 0xf2656000UL,\n-    0x3fcd1037UL, 0x75b6f6e4UL, 0xbd084a7eUL, 0xc6f01000UL, 0x3fcc6ffbUL,\n-    0xc5962bd2UL, 0xbcf1ec72UL, 0x383be000UL, 0x3fcbd087UL, 0x595412b6UL,\n-    0xbd2d4bc4UL, 0x575bd000UL, 0x3fcb31d8UL, 0x4eace1aaUL, 0xbd0c358dUL,\n-    0x3c8ae000UL, 0x3fca93edUL, 0x50562169UL, 0xbd287243UL, 0x07089000UL,\n-    0x3fc9f6c4UL, 0x6865817aUL, 0x3d29904dUL, 0xdcf70000UL, 0x3fc95a5aUL,\n-    0x58a0ff6fUL, 0x3d07f228UL, 0xeb390000UL, 0x3fc8beafUL, 0xaae92cd1UL,\n-    0xbd073d54UL, 0x6551a000UL, 0x3fc823c1UL, 0x9a631e83UL, 0x3d1e0ddbUL,\n-    0x85445000UL, 0x3fc7898dUL, 0x70914305UL, 0xbd1c6610UL, 0x8b757000UL,\n-    0x3fc6f012UL, 0xe59c21e1UL, 0xbd25118dUL, 0xbe8c1000UL, 0x3fc6574eUL,\n-    0x2c3c2e78UL, 0x3d19cf8bUL, 0x6b544000UL, 0x3fc5bf40UL, 0xeb68981cUL,\n-    0xbd127023UL, 0xe4a1b000UL, 0x3fc527e5UL, 0xe5697dc7UL, 0x3d2633e8UL,\n-    0x8333b000UL, 0x3fc4913dUL, 0x54fdb678UL, 0x3d258379UL, 0xa5993000UL,\n-    0x3fc3fb45UL, 0x7e6a354dUL, 0xbd2cd1d8UL, 0xb0159000UL, 0x3fc365fcUL,\n-    0x234b7289UL, 0x3cc62fa8UL, 0x0c868000UL, 0x3fc2d161UL, 0xcb81b4a1UL,\n-    0x3d039d6cUL, 0x2a49c000UL, 0x3fc23d71UL, 0x8fd3df5cUL, 0x3d100d23UL,\n-    0x7e23f000UL, 0x3fc1aa2bUL, 0x44389934UL, 0x3d2ca78eUL, 0x8227e000UL,\n-    0x3fc1178eUL, 0xce2d07f2UL, 0x3d21ef78UL, 0xb59e4000UL, 0x3fc08598UL,\n-    0x7009902cUL, 0xbd27e5ddUL, 0x39dbe000UL, 0x3fbfe891UL, 0x4fa10afdUL,\n-    0xbd2534d6UL, 0x830a2000UL, 0x3fbec739UL, 0xafe645e0UL, 0xbd2dc068UL,\n-    0x63844000UL, 0x3fbda727UL, 0x1fa71733UL, 0x3d1a8940UL, 0x01bc4000UL,\n-    0x3fbc8858UL, 0xc65aacd3UL, 0x3d2646d1UL, 0x8dad6000UL, 0x3fbb6ac8UL,\n-    0x2bf768e5UL, 0xbd139080UL, 0x40b1c000UL, 0x3fba4e76UL, 0xb94407c8UL,\n-    0xbd0e42b6UL, 0x5d594000UL, 0x3fb9335eUL, 0x3abd47daUL, 0x3d23115cUL,\n-    0x2f40e000UL, 0x3fb8197eUL, 0xf96ffdf7UL, 0x3d0f80dcUL, 0x0aeac000UL,\n-    0x3fb700d3UL, 0xa99ded32UL, 0x3cec1e8dUL, 0x4d97a000UL, 0x3fb5e95aUL,\n-    0x3c5d1d1eUL, 0xbd2c6906UL, 0x5d208000UL, 0x3fb4d311UL, 0x82f4e1efUL,\n-    0xbcf53a25UL, 0xa7d1e000UL, 0x3fb3bdf5UL, 0xa5db4ed7UL, 0x3d2cc85eUL,\n-    0xa4472000UL, 0x3fb2aa04UL, 0xae9c697dUL, 0xbd20b6e8UL, 0xd1466000UL,\n-    0x3fb1973bUL, 0x560d9e9bUL, 0xbd25325dUL, 0xb59e4000UL, 0x3fb08598UL,\n-    0x7009902cUL, 0xbd17e5ddUL, 0xc006c000UL, 0x3faeea31UL, 0x4fc93b7bUL,\n-    0xbd0e113eUL, 0xcdddc000UL, 0x3faccb73UL, 0x47d82807UL, 0xbd1a68f2UL,\n-    0xd0fb0000UL, 0x3faaaef2UL, 0x353bb42eUL, 0x3d20fc1aUL, 0x149fc000UL,\n-    0x3fa894aaUL, 0xd05a267dUL, 0xbd197995UL, 0xf2d4c000UL, 0x3fa67c94UL,\n-    0xec19afa2UL, 0xbd029efbUL, 0xd42e0000UL, 0x3fa466aeUL, 0x75bdfd28UL,\n-    0xbd2c1673UL, 0x2f8d0000UL, 0x3fa252f3UL, 0xe021b67bUL, 0x3d283e9aUL,\n-    0x89e74000UL, 0x3fa0415dUL, 0x5cf1d753UL, 0x3d0111c0UL, 0xec148000UL,\n-    0x3f9c63d2UL, 0x3f9eb2f3UL, 0x3d2578c6UL, 0x28c90000UL, 0x3f984925UL,\n-    0x325a0c34UL, 0xbd2aa0baUL, 0x25980000UL, 0x3f9432a9UL, 0x928637feUL,\n-    0x3d098139UL, 0x58938000UL, 0x3f902056UL, 0x06e2f7d2UL, 0xbd23dc5bUL,\n-    0xa3890000UL, 0x3f882448UL, 0xda74f640UL, 0xbd275577UL, 0x75890000UL,\n-    0x3f801015UL, 0x999d2be8UL, 0xbd10c76bUL, 0x59580000UL, 0x3f700805UL,\n-    0xcb31c67bUL, 0x3d2166afUL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x80000000UL, 0xfefa3800UL, 0x3fa62e42UL, 0x93c76730UL, 0x3ceef357UL,\n-    0x92492492UL, 0x3fc24924UL, 0x00000000UL, 0xbfd00000UL, 0x3d6fb175UL,\n-    0xbfc5555eUL, 0x55555555UL, 0x3fd55555UL, 0x9999999aUL, 0x3fc99999UL,\n-    0x00000000UL, 0xbfe00000UL, 0x00000000UL, 0xffffe000UL, 0x00000000UL,\n-    0xffffe000UL\n-};\n-\n-\/\/registers,\n-\/\/ input: xmm0\n-\/\/ scratch: xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7\n-\/\/          rax, rdx, rcx, rbx (tmp)\n-void MacroAssembler::fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                              Register eax, Register ecx, Register edx, Register tmp) {\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2, L_2TAG_PACKET_5_0_2, L_2TAG_PACKET_6_0_2, L_2TAG_PACKET_7_0_2;\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2;\n-  Label L_2TAG_PACKET_10_0_2;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-  address static_const_table = (address)_static_const_table_log;\n-\n-  subl(rsp, 104);\n-  movl(Address(rsp, 40), tmp);\n-  lea(tmp, ExternalAddress(static_const_table));\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  xorpd(xmm3, xmm3);\n-  movl(edx, 30704);\n-  pinsrw(xmm3, edx, 3);\n-  movsd(xmm0, Address(rsp, 112));\n-  movapd(xmm1, xmm0);\n-  movl(ecx, 32768);\n-  movdl(xmm4, ecx);\n-  movsd(xmm5, Address(tmp, 2128));         \/\/ 0x00000000UL, 0xffffe000UL\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  psllq(xmm0, 5);\n-  movl(ecx, 16352);\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm1, 12);\n-  pshufd(xmm6, xmm5, 228);\n-  psrlq(xmm1, 12);\n-  subl(eax, 16);\n-  cmpl(eax, 32736);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_0_0_2);\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  paddd(xmm0, xmm4);\n-  por(xmm1, xmm3);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  pand(xmm5, xmm1);\n-  pand(xmm0, xmm6);\n-  subsd(xmm1, xmm5);\n-  mulpd(xmm5, xmm0);\n-  andl(eax, 32752);\n-  subl(eax, ecx);\n-  cvtsi2sdl(xmm7, eax);\n-  mulsd(xmm1, xmm0);\n-  movsd(xmm6, Address(tmp, 2064));         \/\/ 0xfefa3800UL, 0x3fa62e42UL\n-  movdqu(xmm3, Address(tmp, 2080));        \/\/ 0x92492492UL, 0x3fc24924UL, 0x00000000UL, 0xbfd00000UL\n-  subsd(xmm5, xmm2);\n-  andl(edx, 16711680);\n-  shrl(edx, 12);\n-  movdqu(xmm0, Address(tmp, edx));\n-  movdqu(xmm4, Address(tmp, 2096));        \/\/ 0x3d6fb175UL, 0xbfc5555eUL, 0x55555555UL, 0x3fd55555UL\n-  addsd(xmm1, xmm5);\n-  movdqu(xmm2, Address(tmp, 2112));        \/\/ 0x9999999aUL, 0x3fc99999UL, 0x00000000UL, 0xbfe00000UL\n-  mulsd(xmm6, xmm7);\n-  pshufd(xmm5, xmm1, 68);\n-  mulsd(xmm7, Address(tmp, 2072));         \/\/ 0x93c76730UL, 0x3ceef357UL, 0x92492492UL, 0x3fc24924UL\n-  mulsd(xmm3, xmm1);\n-  addsd(xmm0, xmm6);\n-  mulpd(xmm4, xmm5);\n-  mulpd(xmm5, xmm5);\n-  pshufd(xmm6, xmm0, 228);\n-  addsd(xmm0, xmm1);\n-  addpd(xmm4, xmm2);\n-  mulpd(xmm3, xmm5);\n-  subsd(xmm6, xmm0);\n-  mulsd(xmm4, xmm1);\n-  pshufd(xmm2, xmm0, 238);\n-  addsd(xmm1, xmm6);\n-  mulsd(xmm5, xmm5);\n-  addsd(xmm7, xmm2);\n-  addpd(xmm4, xmm3);\n-  addsd(xmm1, xmm7);\n-  mulpd(xmm4, xmm5);\n-  addsd(xmm1, xmm4);\n-  pshufd(xmm5, xmm4, 238);\n-  addsd(xmm1, xmm5);\n-  addsd(xmm0, xmm1);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  movsd(xmm0, Address(rsp, 112));\n-  movdqu(xmm1, xmm0);\n-  addl(eax, 16);\n-  cmpl(eax, 32768);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_3_0_2);\n-  cmpl(eax, 16);\n-  jcc(Assembler::below, L_2TAG_PACKET_4_0_2);\n-\n-  bind(L_2TAG_PACKET_5_0_2);\n-  addsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_6_0_2);\n-  jcc(Assembler::above, L_2TAG_PACKET_5_0_2);\n-  cmpl(edx, 0);\n-  jcc(Assembler::above, L_2TAG_PACKET_5_0_2);\n-  jmp(L_2TAG_PACKET_7_0_2);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  movdl(edx, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(ecx, xmm1);\n-  addl(ecx, ecx);\n-  cmpl(ecx, -2097152);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_6_0_2);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_8_0_2);\n-\n-  bind(L_2TAG_PACKET_7_0_2);\n-  xorpd(xmm1, xmm1);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32752);\n-  pinsrw(xmm1, eax, 3);\n-  movl(edx, 3);\n-  mulsd(xmm0, xmm1);\n-\n-  bind(L_2TAG_PACKET_9_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  movsd(xmm0, Address(rsp, 112));\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_10_0_2);\n-\n-  bind(L_2TAG_PACKET_8_0_2);\n-  xorpd(xmm1, xmm1);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 49136);\n-  pinsrw(xmm0, eax, 3);\n-  divsd(xmm0, xmm1);\n-  movl(edx, 2);\n-  jmp(L_2TAG_PACKET_9_0_2);\n-\n-  bind(L_2TAG_PACKET_4_0_2);\n-  movdl(edx, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(ecx, xmm1);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_8_0_2);\n-  xorpd(xmm1, xmm1);\n-  movl(eax, 18416);\n-  pinsrw(xmm1, eax, 3);\n-  mulsd(xmm0, xmm1);\n-  movapd(xmm1, xmm0);\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  psllq(xmm0, 5);\n-  movl(ecx, 18416);\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm1, 12);\n-  pshufd(xmm6, xmm5, 228);\n-  psrlq(xmm1, 12);\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movsd(Address(rsp, 24), xmm0);\n-  fld_d(Address(rsp, 24));\n-\n-  bind(L_2TAG_PACKET_10_0_2);\n-  movl(tmp, Address(rsp, 40));\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_log.cpp","additions":0,"deletions":344,"binary":false,"changes":344,"status":"deleted"},{"patch":"@@ -1,357 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - LOG10()\n-\/\/                     ---------------------\n-\/\/\n-\/\/    Let x=2^k * mx, mx in [1,2)\n-\/\/\n-\/\/    Get B~1\/mx based on the output of rcpss instruction (B0)\n-\/\/    B = int((B0*LH*2^7+0.5))\/2^7\n-\/\/    LH is a short approximation for log10(e)\n-\/\/\n-\/\/    Reduced argument: r=B*mx-LH (computed accurately in high and low parts)\n-\/\/\n-\/\/    Result:  k*log10(2) - log(B) + p(r)\n-\/\/             p(r) is a degree 7 polynomial\n-\/\/             -log(B) read from data table (high, low parts)\n-\/\/             Result is formed from high and low parts\n-\/\/\n-\/\/ Special cases:\n-\/\/  log10(0) = -INF with divide-by-zero exception raised\n-\/\/  log10(1) = +0\n-\/\/  log10(x) = NaN with invalid exception raised if x < -0, including -INF\n-\/\/  log10(+INF) = +INF\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_log10[] =\n-{\n-    0x509f7800UL, 0x3fd34413UL, 0x1f12b358UL, 0x3d1fef31UL, 0x80333400UL,\n-    0x3fd32418UL, 0xc671d9d0UL, 0xbcf542bfUL, 0x51195000UL, 0x3fd30442UL,\n-    0x78a4b0c3UL, 0x3d18216aUL, 0x6fc79400UL, 0x3fd2e490UL, 0x80fa389dUL,\n-    0xbc902869UL, 0x89d04000UL, 0x3fd2c502UL, 0x75c2f564UL, 0x3d040754UL,\n-    0x4ddd1c00UL, 0x3fd2a598UL, 0xd219b2c3UL, 0xbcfa1d84UL, 0x6baa7c00UL,\n-    0x3fd28651UL, 0xfd9abec1UL, 0x3d1be6d3UL, 0x94028800UL, 0x3fd2672dUL,\n-    0xe289a455UL, 0xbd1ede5eUL, 0x78b86400UL, 0x3fd2482cUL, 0x6734d179UL,\n-    0x3d1fe79bUL, 0xcca3c800UL, 0x3fd2294dUL, 0x981a40b8UL, 0xbced34eaUL,\n-    0x439c5000UL, 0x3fd20a91UL, 0xcc392737UL, 0xbd1a9cc3UL, 0x92752c00UL,\n-    0x3fd1ebf6UL, 0x03c9afe7UL, 0x3d1e98f8UL, 0x6ef8dc00UL, 0x3fd1cd7dUL,\n-    0x71dae7f4UL, 0x3d08a86cUL, 0x8fe4dc00UL, 0x3fd1af25UL, 0xee9185a1UL,\n-    0xbcff3412UL, 0xace59400UL, 0x3fd190eeUL, 0xc2cab353UL, 0x3cf17ed9UL,\n-    0x7e925000UL, 0x3fd172d8UL, 0x6952c1b2UL, 0x3cf1521cUL, 0xbe694400UL,\n-    0x3fd154e2UL, 0xcacb79caUL, 0xbd0bdc78UL, 0x26cbac00UL, 0x3fd1370dUL,\n-    0xf71f4de1UL, 0xbd01f8beUL, 0x72fa0800UL, 0x3fd11957UL, 0x55bf910bUL,\n-    0x3c946e2bUL, 0x5f106000UL, 0x3fd0fbc1UL, 0x39e639c1UL, 0x3d14a84bUL,\n-    0xa802a800UL, 0x3fd0de4aUL, 0xd3f31d5dUL, 0xbd178385UL, 0x0b992000UL,\n-    0x3fd0c0f3UL, 0x3843106fUL, 0xbd1f602fUL, 0x486ce800UL, 0x3fd0a3baUL,\n-    0x8819497cUL, 0x3cef987aUL, 0x1de49400UL, 0x3fd086a0UL, 0x1caa0467UL,\n-    0x3d0faec7UL, 0x4c30cc00UL, 0x3fd069a4UL, 0xa4424372UL, 0xbd1618fcUL,\n-    0x94490000UL, 0x3fd04cc6UL, 0x946517d2UL, 0xbd18384bUL, 0xb7e84000UL,\n-    0x3fd03006UL, 0xe0109c37UL, 0xbd19a6acUL, 0x798a0c00UL, 0x3fd01364UL,\n-    0x5121e864UL, 0xbd164cf7UL, 0x38ce8000UL, 0x3fcfedbfUL, 0x46214d1aUL,\n-    0xbcbbc402UL, 0xc8e62000UL, 0x3fcfb4efUL, 0xdab93203UL, 0x3d1e0176UL,\n-    0x2cb02800UL, 0x3fcf7c5aUL, 0x2a2ea8e4UL, 0xbcfec86aUL, 0xeeeaa000UL,\n-    0x3fcf43fdUL, 0xc18e49a4UL, 0x3cf110a8UL, 0x9bb6e800UL, 0x3fcf0bdaUL,\n-    0x923cc9c0UL, 0xbd15ce99UL, 0xc093f000UL, 0x3fced3efUL, 0x4d4b51e9UL,\n-    0x3d1a04c7UL, 0xec58f800UL, 0x3fce9c3cUL, 0x163cad59UL, 0x3cac8260UL,\n-    0x9a907000UL, 0x3fce2d7dUL, 0x3fa93646UL, 0x3ce4a1c0UL, 0x37311000UL,\n-    0x3fcdbf99UL, 0x32abd1fdUL, 0x3d07ea9dUL, 0x6744b800UL, 0x3fcd528cUL,\n-    0x4dcbdfd4UL, 0xbd1b08e2UL, 0xe36de800UL, 0x3fcce653UL, 0x0b7b7f7fUL,\n-    0xbd1b8f03UL, 0x77506800UL, 0x3fcc7aecUL, 0xa821c9fbUL, 0x3d13c163UL,\n-    0x00ff8800UL, 0x3fcc1053UL, 0x536bca76UL, 0xbd074ee5UL, 0x70719800UL,\n-    0x3fcba684UL, 0xd7da9b6bUL, 0xbd1fbf16UL, 0xc6f8d800UL, 0x3fcb3d7dUL,\n-    0xe2220bb3UL, 0x3d1a295dUL, 0x16c15800UL, 0x3fcad53cUL, 0xe724911eUL,\n-    0xbcf55822UL, 0x82533800UL, 0x3fca6dbcUL, 0x6d982371UL, 0x3cac567cUL,\n-    0x3c19e800UL, 0x3fca06fcUL, 0x84d17d80UL, 0x3d1da204UL, 0x85ef8000UL,\n-    0x3fc9a0f8UL, 0x54466a6aUL, 0xbd002204UL, 0xb0ac2000UL, 0x3fc93baeUL,\n-    0xd601fd65UL, 0x3d18840cUL, 0x1bb9b000UL, 0x3fc8d71cUL, 0x7bf58766UL,\n-    0xbd14f897UL, 0x34aae800UL, 0x3fc8733eUL, 0x3af6ac24UL, 0xbd0f5c45UL,\n-    0x76d68000UL, 0x3fc81012UL, 0x4303e1a1UL, 0xbd1f9a80UL, 0x6af57800UL,\n-    0x3fc7ad96UL, 0x43fbcb46UL, 0x3cf4c33eUL, 0xa6c51000UL, 0x3fc74bc7UL,\n-    0x70f0eac5UL, 0xbd192e3bUL, 0xccab9800UL, 0x3fc6eaa3UL, 0xc0093dfeUL,\n-    0xbd0faf15UL, 0x8b60b800UL, 0x3fc68a28UL, 0xde78d5fdUL, 0xbc9ea4eeUL,\n-    0x9d987000UL, 0x3fc62a53UL, 0x962bea6eUL, 0xbd194084UL, 0xc9b0e800UL,\n-    0x3fc5cb22UL, 0x888dd999UL, 0x3d1fe201UL, 0xe1634800UL, 0x3fc56c93UL,\n-    0x16ada7adUL, 0x3d1b1188UL, 0xc176c000UL, 0x3fc50ea4UL, 0x4159b5b5UL,\n-    0xbcf09c08UL, 0x51766000UL, 0x3fc4b153UL, 0x84393d23UL, 0xbcf6a89cUL,\n-    0x83695000UL, 0x3fc4549dUL, 0x9f0b8bbbUL, 0x3d1c4b8cUL, 0x538d5800UL,\n-    0x3fc3f881UL, 0xf49df747UL, 0x3cf89b99UL, 0xc8138000UL, 0x3fc39cfcUL,\n-    0xd503b834UL, 0xbd13b99fUL, 0xf0df0800UL, 0x3fc3420dUL, 0xf011b386UL,\n-    0xbd05d8beUL, 0xe7466800UL, 0x3fc2e7b2UL, 0xf39c7bc2UL, 0xbd1bb94eUL,\n-    0xcdd62800UL, 0x3fc28de9UL, 0x05e6d69bUL, 0xbd10ed05UL, 0xd015d800UL,\n-    0x3fc234b0UL, 0xe29b6c9dUL, 0xbd1ff967UL, 0x224ea800UL, 0x3fc1dc06UL,\n-    0x727711fcUL, 0xbcffb30dUL, 0x01540000UL, 0x3fc183e8UL, 0x39786c5aUL,\n-    0x3cc23f57UL, 0xb24d9800UL, 0x3fc12c54UL, 0xc905a342UL, 0x3d003a1dUL,\n-    0x82835800UL, 0x3fc0d54aUL, 0x9b9920c0UL, 0x3d03b25aUL, 0xc72ac000UL,\n-    0x3fc07ec7UL, 0x46f26a24UL, 0x3cf0fa41UL, 0xdd35d800UL, 0x3fc028caUL,\n-    0x41d9d6dcUL, 0x3d034a65UL, 0x52474000UL, 0x3fbfa6a4UL, 0x44f66449UL,\n-    0x3d19cad3UL, 0x2da3d000UL, 0x3fbefcb8UL, 0x67832999UL, 0x3d18400fUL,\n-    0x32a10000UL, 0x3fbe53ceUL, 0x9c0e3b1aUL, 0xbcff62fdUL, 0x556b7000UL,\n-    0x3fbdabe3UL, 0x02976913UL, 0xbcf8243bUL, 0x97e88000UL, 0x3fbd04f4UL,\n-    0xec793797UL, 0x3d1c0578UL, 0x09647000UL, 0x3fbc5effUL, 0x05fc0565UL,\n-    0xbd1d799eUL, 0xc6426000UL, 0x3fbbb9ffUL, 0x4625f5edUL, 0x3d1f5723UL,\n-    0xf7afd000UL, 0x3fbb15f3UL, 0xdd5aae61UL, 0xbd1a7e1eUL, 0xd358b000UL,\n-    0x3fba72d8UL, 0x3314e4d3UL, 0x3d17bc91UL, 0x9b1f5000UL, 0x3fb9d0abUL,\n-    0x9a4d514bUL, 0x3cf18c9bUL, 0x9cd4e000UL, 0x3fb92f69UL, 0x7e4496abUL,\n-    0x3cf1f96dUL, 0x31f4f000UL, 0x3fb88f10UL, 0xf56479e7UL, 0x3d165818UL,\n-    0xbf628000UL, 0x3fb7ef9cUL, 0x26bf486dUL, 0xbd1113a6UL, 0xb526b000UL,\n-    0x3fb7510cUL, 0x1a1c3384UL, 0x3ca9898dUL, 0x8e31e000UL, 0x3fb6b35dUL,\n-    0xb3875361UL, 0xbd0661acUL, 0xd01de000UL, 0x3fb6168cUL, 0x2a7cacfaUL,\n-    0xbd1bdf10UL, 0x0af23000UL, 0x3fb57a98UL, 0xff868816UL, 0x3cf046d0UL,\n-    0xd8ea0000UL, 0x3fb4df7cUL, 0x1515fbe7UL, 0xbd1fd529UL, 0xde3b2000UL,\n-    0x3fb44538UL, 0x6e59a132UL, 0x3d1faeeeUL, 0xc8df9000UL, 0x3fb3abc9UL,\n-    0xf1322361UL, 0xbd198807UL, 0x505f1000UL, 0x3fb3132dUL, 0x0888e6abUL,\n-    0x3d1e5380UL, 0x359bd000UL, 0x3fb27b61UL, 0xdfbcbb22UL, 0xbcfe2724UL,\n-    0x429ee000UL, 0x3fb1e463UL, 0x6eb4c58cUL, 0xbcfe4dd6UL, 0x4a673000UL,\n-    0x3fb14e31UL, 0x4ce1ac9bUL, 0x3d1ba691UL, 0x28b96000UL, 0x3fb0b8c9UL,\n-    0x8c7813b8UL, 0xbd0b3872UL, 0xc1f08000UL, 0x3fb02428UL, 0xc2bc8c2cUL,\n-    0x3cb5ea6bUL, 0x05a1a000UL, 0x3faf209cUL, 0x72e8f18eUL, 0xbce8df84UL,\n-    0xc0b5e000UL, 0x3fadfa6dUL, 0x9fdef436UL, 0x3d087364UL, 0xaf416000UL,\n-    0x3facd5c2UL, 0x1068c3a9UL, 0x3d0827e7UL, 0xdb356000UL, 0x3fabb296UL,\n-    0x120a34d3UL, 0x3d101a9fUL, 0x5dfea000UL, 0x3faa90e6UL, 0xdaded264UL,\n-    0xbd14c392UL, 0x6034c000UL, 0x3fa970adUL, 0x1c9d06a9UL, 0xbd1b705eUL,\n-    0x194c6000UL, 0x3fa851e8UL, 0x83996ad9UL, 0xbd0117bcUL, 0xcf4ac000UL,\n-    0x3fa73492UL, 0xb1a94a62UL, 0xbca5ea42UL, 0xd67b4000UL, 0x3fa618a9UL,\n-    0x75aed8caUL, 0xbd07119bUL, 0x9126c000UL, 0x3fa4fe29UL, 0x5291d533UL,\n-    0x3d12658fUL, 0x6f4d4000UL, 0x3fa3e50eUL, 0xcd2c5cd9UL, 0x3d1d5c70UL,\n-    0xee608000UL, 0x3fa2cd54UL, 0xd1008489UL, 0x3d1a4802UL, 0x9900e000UL,\n-    0x3fa1b6f9UL, 0x54fb5598UL, 0xbd16593fUL, 0x06bb6000UL, 0x3fa0a1f9UL,\n-    0x64ef57b4UL, 0xbd17636bUL, 0xb7940000UL, 0x3f9f1c9fUL, 0xee6a4737UL,\n-    0x3cb5d479UL, 0x91aa0000UL, 0x3f9cf7f5UL, 0x3a16373cUL, 0x3d087114UL,\n-    0x156b8000UL, 0x3f9ad5edUL, 0x836c554aUL, 0x3c6900b0UL, 0xd4764000UL,\n-    0x3f98b67fUL, 0xed12f17bUL, 0xbcffc974UL, 0x77dec000UL, 0x3f9699a7UL,\n-    0x232ce7eaUL, 0x3d1e35bbUL, 0xbfbf4000UL, 0x3f947f5dUL, 0xd84ffa6eUL,\n-    0x3d0e0a49UL, 0x82c7c000UL, 0x3f92679cUL, 0x8d170e90UL, 0xbd14d9f2UL,\n-    0xadd20000UL, 0x3f90525dUL, 0x86d9f88eUL, 0x3cdeb986UL, 0x86f10000UL,\n-    0x3f8c7f36UL, 0xb9e0a517UL, 0x3ce29faaUL, 0xb75c8000UL, 0x3f885e9eUL,\n-    0x542568cbUL, 0xbd1f7bdbUL, 0x46b30000UL, 0x3f8442e8UL, 0xb954e7d9UL,\n-    0x3d1e5287UL, 0xb7e60000UL, 0x3f802c07UL, 0x22da0b17UL, 0xbd19fb27UL,\n-    0x6c8b0000UL, 0x3f7833e3UL, 0x821271efUL, 0xbd190f96UL, 0x29910000UL,\n-    0x3f701936UL, 0xbc3491a5UL, 0xbd1bcf45UL, 0x354a0000UL, 0x3f600fe3UL,\n-    0xc0ff520aUL, 0xbd19d71cUL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x509f7800UL, 0x3f934413UL, 0x1f12b358UL, 0x3cdfef31UL,\n-    0xc1a5f12eUL, 0x40358874UL, 0x64d4ef0dUL, 0xc0089309UL, 0x385593b1UL,\n-    0xc025c917UL, 0xdc963467UL, 0x3ffc6a02UL, 0x7f9d3aa1UL, 0x4016ab9fUL,\n-    0xdc77b115UL, 0xbff27af2UL, 0xf8000000UL, 0xffffffffUL, 0x00000000UL,\n-    0xffffe000UL, 0x00000000UL, 0x3fdbc000UL, 0xbf2e4108UL, 0x3f5a7a6cUL\n-};\n-\/\/registers,\n-\/\/ input: xmm0\n-\/\/ scratch: xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7\n-\/\/          rax, rdx, rcx, rbx (tmp)\n-\n-void MacroAssembler::fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                                Register eax, Register ecx, Register edx, Register tmp) {\n-\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2, L_2TAG_PACKET_5_0_2, L_2TAG_PACKET_6_0_2, L_2TAG_PACKET_7_0_2;\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, L_2TAG_PACKET_10_0_2;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-\n-  address static_const_table_log10 = (address)_static_const_table_log10;\n-\n-  subl(rsp, 104);\n-  movl(Address(rsp, 40), tmp);\n-  lea(tmp, ExternalAddress(static_const_table_log10));\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  movl(ecx, 1054736384);\n-  movdl(xmm7, ecx);\n-  xorpd(xmm3, xmm3);\n-  movl(edx, 30704);\n-  pinsrw(xmm3, edx, 3);\n-  movsd(xmm0, Address(rsp, 112));\n-  movdqu(xmm1, xmm0);\n-  movl(edx, 32768);\n-  movdl(xmm4, edx);\n-  movdqu(xmm5, Address(tmp, 2128));    \/\/0x3ffc6a02UL, 0x7f9d3aa1UL, 0x4016ab9fUL, 0xdc77b115UL\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  movl(ecx, 16352);\n-  psllq(xmm0, 5);\n-  movsd(xmm2, Address(tmp, 2144));    \/\/0xbff27af2UL, 0xf8000000UL, 0xffffffffUL, 0x00000000UL\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm1, 12);\n-  pshufd(xmm6, xmm5, 78);\n-  psrlq(xmm1, 12);\n-  subl(eax, 16);\n-  cmpl(eax, 32736);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_0_0_2);\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  mulss(xmm0, xmm7);\n-  por(xmm1, xmm3);\n-  andpd(xmm5, xmm1);\n-  paddd(xmm0, xmm4);\n-  subsd(xmm1, xmm5);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  andpd(xmm0, xmm6);\n-  andl(eax, 32752);\n-  subl(eax, ecx);\n-  cvtsi2sdl(xmm7, eax);\n-  mulpd(xmm5, xmm0);\n-  mulsd(xmm1, xmm0);\n-  movsd(xmm6, Address(tmp, 2064));    \/\/0xbd19d71cUL, 0x00000000UL, 0x00000000UL, 0x00000000UL\n-  movdqu(xmm3, Address(tmp, 2080));    \/\/0x00000000UL, 0x509f7800UL, 0x3f934413UL, 0x1f12b358UL\n-  subsd(xmm5, xmm2);\n-  andl(edx, 16711680);\n-  shrl(edx, 12);\n-  movdqu(xmm0, Address(tmp, edx, Address::times_1, -1504));\n-  movdqu(xmm4, Address(tmp, 2096));    \/\/0x3cdfef31UL, 0xc1a5f12eUL, 0x40358874UL, 0x64d4ef0dUL\n-  addsd(xmm1, xmm5);\n-  movdqu(xmm2, Address(tmp, 2112));    \/\/0xc0089309UL, 0x385593b1UL, 0xc025c917UL, 0xdc963467UL\n-  mulsd(xmm6, xmm7);\n-  pshufd(xmm5, xmm1, 68);\n-  mulsd(xmm7, Address(tmp, 2072));    \/\/0x00000000UL, 0x00000000UL, 0x00000000UL, 0x509f7800UL\n-  mulsd(xmm3, xmm1);\n-  addsd(xmm0, xmm6);\n-  mulpd(xmm4, xmm5);\n-  movsd(xmm6, Address(tmp, 2152));    \/\/0xffffffffUL, 0x00000000UL, 0xffffe000UL, 0x00000000UL\n-  mulpd(xmm5, xmm5);\n-  addpd(xmm4, xmm2);\n-  mulpd(xmm3, xmm5);\n-  pshufd(xmm2, xmm0, 228);\n-  addsd(xmm0, xmm1);\n-  mulsd(xmm4, xmm1);\n-  subsd(xmm2, xmm0);\n-  mulsd(xmm6, xmm1);\n-  addsd(xmm1, xmm2);\n-  pshufd(xmm2, xmm0, 238);\n-  mulsd(xmm5, xmm5);\n-  addsd(xmm7, xmm2);\n-  addsd(xmm1, xmm6);\n-  addpd(xmm4, xmm3);\n-  addsd(xmm1, xmm7);\n-  mulpd(xmm4, xmm5);\n-  addsd(xmm1, xmm4);\n-  pshufd(xmm5, xmm4, 238);\n-  addsd(xmm1, xmm5);\n-  addsd(xmm0, xmm1);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  movsd(xmm0, Address(rsp, 112));    \/\/0xbcfa1d84UL, 0x6baa7c00UL, 0x3fd28651UL, 0xfd9abec1UL\n-  movdqu(xmm1, xmm0);\n-  addl(eax, 16);\n-  cmpl(eax, 32768);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_3_0_2);\n-  cmpl(eax, 16);\n-  jcc(Assembler::below, L_2TAG_PACKET_4_0_2);\n-\n-  bind(L_2TAG_PACKET_5_0_2);\n-  addsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_2_0_2);\n-\n-  bind(L_2TAG_PACKET_6_0_2);\n-  jcc(Assembler::above, L_2TAG_PACKET_5_0_2);\n-  cmpl(edx, 0);\n-  jcc(Assembler::above, L_2TAG_PACKET_5_0_2);\n-  jmp(L_2TAG_PACKET_7_0_2);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  movdl(edx, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(ecx, xmm1);\n-  addl(ecx, ecx);\n-  cmpl(ecx, -2097152);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_6_0_2);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_8_0_2);\n-\n-  bind(L_2TAG_PACKET_7_0_2);\n-  xorpd(xmm1, xmm1);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32752);\n-  pinsrw(xmm1, eax, 3);\n-  movl(edx, 9);\n-  mulsd(xmm0, xmm1);\n-\n-  bind(L_2TAG_PACKET_9_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  movsd(xmm0, Address(rsp, 112));    \/\/0xbcfa1d84UL, 0x6baa7c00UL, 0x3fd28651UL, 0xfd9abec1UL\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_10_0_2);\n-\n-  bind(L_2TAG_PACKET_8_0_2);\n-  xorpd(xmm1, xmm1);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 49136);\n-  pinsrw(xmm0, eax, 3);\n-  divsd(xmm0, xmm1);\n-  movl(edx, 8);\n-  jmp(L_2TAG_PACKET_9_0_2);\n-\n-  bind(L_2TAG_PACKET_4_0_2);\n-  movdl(edx, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(ecx, xmm1);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_8_0_2);\n-  xorpd(xmm1, xmm1);\n-  movl(eax, 18416);\n-  pinsrw(xmm1, eax, 3);\n-  mulsd(xmm0, xmm1);\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  movdqu(xmm1, xmm0);\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  movl(ecx, 18416);\n-  psllq(xmm0, 5);\n-  movsd(xmm2, Address(tmp, 2144));    \/\/0xbff27af2UL, 0xf8000000UL, 0xffffffffUL, 0x00000000UL\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm1, 12);\n-  pshufd(xmm6, xmm5, 78);\n-  psrlq(xmm1, 12);\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movsd(Address(rsp, 24), xmm0);\n-  fld_d(Address(rsp, 24));\n-\n-  bind(L_2TAG_PACKET_10_0_2);\n-  movl(tmp, Address(rsp, 40));\n-\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_log10.cpp","additions":0,"deletions":357,"binary":false,"changes":357,"status":"deleted"},{"patch":"@@ -1,1855 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Copyright (C) 2021 THL A29 Limited, a Tencent company. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION  - POW()\n-\/\/                     ---------------------\n-\/\/\n-\/\/    Let x=2^k * mx, mx in [1,2)\n-\/\/\n-\/\/    log2(x) calculation:\n-\/\/\n-\/\/    Get B~1\/mx based on the output of rcpps instruction (B0)\n-\/\/    B = int((B0*LH*2^9+0.5))\/2^9\n-\/\/    LH is a short approximation for log2(e)\n-\/\/\n-\/\/    Reduced argument, scaled by LH:\n-\/\/                r=B*mx-LH (computed accurately in high and low parts)\n-\/\/\n-\/\/    log2(x) result:  k - log2(B) + p(r)\n-\/\/             p(r) is a degree 8 polynomial\n-\/\/             -log2(B) read from data table (high, low parts)\n-\/\/             log2(x) is formed from high and low parts\n-\/\/    For |x| in [1-1\/32, 1+1\/16), a slower but more accurate computation\n-\/\/    based om the same table design is performed.\n-\/\/\n-\/\/   Main path is taken if | floor(log2(|log2(|x|)|) + floor(log2|y|) | < 8,\n-\/\/   to filter out all potential OF\/UF cases.\n-\/\/   exp2(y*log2(x)) is computed using an 8-bit index table and a degree 5\n-\/\/   polynomial\n-\/\/\n-\/\/ Special cases:\n-\/\/  pow(-0,y) = -INF and raises the divide-by-zero exception for y an odd\n-\/\/  integer < 0.\n-\/\/  pow(-0,y) = +INF and raises the divide-by-zero exception for y < 0 and\n-\/\/  not an odd integer.\n-\/\/  pow(-0,y) = -0 for y an odd integer > 0.\n-\/\/  pow(-0,y) = +0 for y > 0 and not an odd integer.\n-\/\/  pow(-1,-INF) = NaN.\n-\/\/  pow(+1,y) = NaN for any y, even a NaN.\n-\/\/  pow(x,-0) = 1 for any x, even a NaN.\n-\/\/  pow(x,y) = a NaN and raises the invalid exception for finite x < 0 and\n-\/\/  finite non-integer y.\n-\/\/  pow(x,-INF) = +INF for |x|<1.\n-\/\/  pow(x,-INF) = +0 for |x|>1.\n-\/\/  pow(x,+INF) = +0 for |x|<1.\n-\/\/  pow(x,+INF) = +INF for |x|>1.\n-\/\/  pow(-INF,y) = -0 for y an odd integer < 0.\n-\/\/  pow(-INF,y) = +0 for y < 0 and not an odd integer.\n-\/\/  pow(-INF,y) = -INF for y an odd integer > 0.\n-\/\/  pow(-INF,y) = +INF for y > 0 and not an odd integer.\n-\/\/  pow(+INF,y) = +0 for y <0.\n-\/\/  pow(+INF,y) = +INF for y >0.\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_pow[] =\n-{\n-    0x00000000UL, 0xbfd61a00UL, 0x00000000UL, 0xbf5dabe1UL, 0xf8000000UL,\n-    0xffffffffUL, 0x00000000UL, 0xfffff800UL, 0x00000000UL, 0x3ff00000UL,\n-    0x00000000UL, 0x00000000UL, 0x20000000UL, 0x3feff00aUL, 0x96621f95UL,\n-    0x3e5b1856UL, 0xe0000000UL, 0x3fefe019UL, 0xe5916f9eUL, 0xbe325278UL,\n-    0x00000000UL, 0x3fefd02fUL, 0x859a1062UL, 0x3e595fb7UL, 0xc0000000UL,\n-    0x3fefc049UL, 0xb245f18fUL, 0xbe529c38UL, 0xe0000000UL, 0x3fefb069UL,\n-    0xad2880a7UL, 0xbe501230UL, 0x60000000UL, 0x3fefa08fUL, 0xc8e72420UL,\n-    0x3e597bd1UL, 0x80000000UL, 0x3fef90baUL, 0xc30c4500UL, 0xbe5d6c75UL,\n-    0xe0000000UL, 0x3fef80eaUL, 0x02c63f43UL, 0x3e2e1318UL, 0xc0000000UL,\n-    0x3fef7120UL, 0xb3d4ccccUL, 0xbe44c52aUL, 0x00000000UL, 0x3fef615cUL,\n-    0xdbd91397UL, 0xbe4e7d6cUL, 0xa0000000UL, 0x3fef519cUL, 0x65c5cd68UL,\n-    0xbe522dc8UL, 0xa0000000UL, 0x3fef41e2UL, 0x46d1306cUL, 0xbe5a840eUL,\n-    0xe0000000UL, 0x3fef322dUL, 0xd2980e94UL, 0x3e5071afUL, 0xa0000000UL,\n-    0x3fef227eUL, 0x773abadeUL, 0xbe5891e5UL, 0xa0000000UL, 0x3fef12d4UL,\n-    0xdc6bf46bUL, 0xbe5cccbeUL, 0xe0000000UL, 0x3fef032fUL, 0xbc7247faUL,\n-    0xbe2bab83UL, 0x80000000UL, 0x3feef390UL, 0xbcaa1e46UL, 0xbe53bb3bUL,\n-    0x60000000UL, 0x3feee3f6UL, 0x5f6c682dUL, 0xbe54c619UL, 0x80000000UL,\n-    0x3feed461UL, 0x5141e368UL, 0xbe4b6d86UL, 0xe0000000UL, 0x3feec4d1UL,\n-    0xec678f76UL, 0xbe369af6UL, 0x80000000UL, 0x3feeb547UL, 0x41301f55UL,\n-    0xbe2d4312UL, 0x60000000UL, 0x3feea5c2UL, 0x676da6bdUL, 0xbe4d8dd0UL,\n-    0x60000000UL, 0x3fee9642UL, 0x57a891c4UL, 0x3e51f991UL, 0xa0000000UL,\n-    0x3fee86c7UL, 0xe4eb491eUL, 0x3e579bf9UL, 0x20000000UL, 0x3fee7752UL,\n-    0xfddc4a2cUL, 0xbe3356e6UL, 0xc0000000UL, 0x3fee67e1UL, 0xd75b5bf1UL,\n-    0xbe449531UL, 0x80000000UL, 0x3fee5876UL, 0xbd423b8eUL, 0x3df54fe4UL,\n-    0x60000000UL, 0x3fee4910UL, 0x330e51b9UL, 0x3e54289cUL, 0x80000000UL,\n-    0x3fee39afUL, 0x8651a95fUL, 0xbe55aad6UL, 0xa0000000UL, 0x3fee2a53UL,\n-    0x5e98c708UL, 0xbe2fc4a9UL, 0xe0000000UL, 0x3fee1afcUL, 0x0989328dUL,\n-    0x3e23958cUL, 0x40000000UL, 0x3fee0babUL, 0xee642abdUL, 0xbe425dd8UL,\n-    0xa0000000UL, 0x3fedfc5eUL, 0xc394d236UL, 0x3e526362UL, 0x20000000UL,\n-    0x3feded17UL, 0xe104aa8eUL, 0x3e4ce247UL, 0xc0000000UL, 0x3fedddd4UL,\n-    0x265a9be4UL, 0xbe5bb77aUL, 0x40000000UL, 0x3fedce97UL, 0x0ecac52fUL,\n-    0x3e4a7cb1UL, 0xe0000000UL, 0x3fedbf5eUL, 0x124cb3b8UL, 0x3e257024UL,\n-    0x80000000UL, 0x3fedb02bUL, 0xe6d4febeUL, 0xbe2033eeUL, 0x20000000UL,\n-    0x3feda0fdUL, 0x39cca00eUL, 0xbe3ddabcUL, 0xc0000000UL, 0x3fed91d3UL,\n-    0xef8a552aUL, 0xbe543390UL, 0x40000000UL, 0x3fed82afUL, 0xb8e85204UL,\n-    0x3e513850UL, 0xe0000000UL, 0x3fed738fUL, 0x3d59fe08UL, 0xbe5db728UL,\n-    0x40000000UL, 0x3fed6475UL, 0x3aa7ead1UL, 0x3e58804bUL, 0xc0000000UL,\n-    0x3fed555fUL, 0xf8a35ba9UL, 0xbe5298b0UL, 0x00000000UL, 0x3fed464fUL,\n-    0x9a88dd15UL, 0x3e5a8cdbUL, 0x40000000UL, 0x3fed3743UL, 0xb0b0a190UL,\n-    0x3e598635UL, 0x80000000UL, 0x3fed283cUL, 0xe2113295UL, 0xbe5c1119UL,\n-    0x80000000UL, 0x3fed193aUL, 0xafbf1728UL, 0xbe492e9cUL, 0x60000000UL,\n-    0x3fed0a3dUL, 0xe4a4ccf3UL, 0x3e19b90eUL, 0x20000000UL, 0x3fecfb45UL,\n-    0xba3cbeb8UL, 0x3e406b50UL, 0xc0000000UL, 0x3fecec51UL, 0x110f7dddUL,\n-    0x3e0d6806UL, 0x40000000UL, 0x3fecdd63UL, 0x7dd7d508UL, 0xbe5a8943UL,\n-    0x80000000UL, 0x3fecce79UL, 0x9b60f271UL, 0xbe50676aUL, 0x80000000UL,\n-    0x3fecbf94UL, 0x0b9ad660UL, 0x3e59174fUL, 0x60000000UL, 0x3fecb0b4UL,\n-    0x00823d9cUL, 0x3e5bbf72UL, 0x20000000UL, 0x3feca1d9UL, 0x38a6ec89UL,\n-    0xbe4d38f9UL, 0x80000000UL, 0x3fec9302UL, 0x3a0b7d8eUL, 0x3e53dbfdUL,\n-    0xc0000000UL, 0x3fec8430UL, 0xc6826b34UL, 0xbe27c5c9UL, 0xc0000000UL,\n-    0x3fec7563UL, 0x0c706381UL, 0xbe593653UL, 0x60000000UL, 0x3fec669bUL,\n-    0x7df34ec7UL, 0x3e461ab5UL, 0xe0000000UL, 0x3fec57d7UL, 0x40e5e7e8UL,\n-    0xbe5c3daeUL, 0x00000000UL, 0x3fec4919UL, 0x5602770fUL, 0xbe55219dUL,\n-    0xc0000000UL, 0x3fec3a5eUL, 0xec7911ebUL, 0x3e5a5d25UL, 0x60000000UL,\n-    0x3fec2ba9UL, 0xb39ea225UL, 0xbe53c00bUL, 0x80000000UL, 0x3fec1cf8UL,\n-    0x967a212eUL, 0x3e5a8ddfUL, 0x60000000UL, 0x3fec0e4cUL, 0x580798bdUL,\n-    0x3e5f53abUL, 0x00000000UL, 0x3febffa5UL, 0xb8282df6UL, 0xbe46b874UL,\n-    0x20000000UL, 0x3febf102UL, 0xe33a6729UL, 0x3e54963fUL, 0x00000000UL,\n-    0x3febe264UL, 0x3b53e88aUL, 0xbe3adce1UL, 0x60000000UL, 0x3febd3caUL,\n-    0xc2585084UL, 0x3e5cde9fUL, 0x80000000UL, 0x3febc535UL, 0xa335c5eeUL,\n-    0xbe39fd9cUL, 0x20000000UL, 0x3febb6a5UL, 0x7325b04dUL, 0x3e42ba15UL,\n-    0x60000000UL, 0x3feba819UL, 0x1564540fUL, 0x3e3a9f35UL, 0x40000000UL,\n-    0x3feb9992UL, 0x83fff592UL, 0xbe5465ceUL, 0xa0000000UL, 0x3feb8b0fUL,\n-    0xb9da63d3UL, 0xbe4b1a0aUL, 0x80000000UL, 0x3feb7c91UL, 0x6d6f1ea4UL,\n-    0x3e557657UL, 0x00000000UL, 0x3feb6e18UL, 0x5e80a1bfUL, 0x3e4ddbb6UL,\n-    0x00000000UL, 0x3feb5fa3UL, 0x1c9eacb5UL, 0x3e592877UL, 0xa0000000UL,\n-    0x3feb5132UL, 0x6d40beb3UL, 0xbe51858cUL, 0xa0000000UL, 0x3feb42c6UL,\n-    0xd740c67bUL, 0x3e427ad2UL, 0x40000000UL, 0x3feb345fUL, 0xa3e0cceeUL,\n-    0xbe5c2fc4UL, 0x40000000UL, 0x3feb25fcUL, 0x8e752b50UL, 0xbe3da3c2UL,\n-    0xc0000000UL, 0x3feb179dUL, 0xa892e7deUL, 0x3e1fb481UL, 0xc0000000UL,\n-    0x3feb0943UL, 0x21ed71e9UL, 0xbe365206UL, 0x20000000UL, 0x3feafaeeUL,\n-    0x0e1380a3UL, 0x3e5c5b7bUL, 0x20000000UL, 0x3feaec9dUL, 0x3c3d640eUL,\n-    0xbe5dbbd0UL, 0x60000000UL, 0x3feade50UL, 0x8f97a715UL, 0x3e3a8ec5UL,\n-    0x20000000UL, 0x3fead008UL, 0x23ab2839UL, 0x3e2fe98aUL, 0x40000000UL,\n-    0x3feac1c4UL, 0xf4bbd50fUL, 0x3e54d8f6UL, 0xe0000000UL, 0x3feab384UL,\n-    0x14757c4dUL, 0xbe48774cUL, 0xc0000000UL, 0x3feaa549UL, 0x7c7b0eeaUL,\n-    0x3e5b51bbUL, 0x20000000UL, 0x3fea9713UL, 0xf56f7013UL, 0x3e386200UL,\n-    0xe0000000UL, 0x3fea88e0UL, 0xbe428ebeUL, 0xbe514af5UL, 0xe0000000UL,\n-    0x3fea7ab2UL, 0x8d0e4496UL, 0x3e4f9165UL, 0x60000000UL, 0x3fea6c89UL,\n-    0xdbacc5d5UL, 0xbe5c063bUL, 0x20000000UL, 0x3fea5e64UL, 0x3f19d970UL,\n-    0xbe5a0c8cUL, 0x20000000UL, 0x3fea5043UL, 0x09ea3e6bUL, 0x3e5065dcUL,\n-    0x80000000UL, 0x3fea4226UL, 0x78df246cUL, 0x3e5e05f6UL, 0x40000000UL,\n-    0x3fea340eUL, 0x4057d4a0UL, 0x3e431b2bUL, 0x40000000UL, 0x3fea25faUL,\n-    0x82867bb5UL, 0x3e4b76beUL, 0xa0000000UL, 0x3fea17eaUL, 0x9436f40aUL,\n-    0xbe5aad39UL, 0x20000000UL, 0x3fea09dfUL, 0x4b5253b3UL, 0x3e46380bUL,\n-    0x00000000UL, 0x3fe9fbd8UL, 0x8fc52466UL, 0xbe386f9bUL, 0x20000000UL,\n-    0x3fe9edd5UL, 0x22d3f344UL, 0xbe538347UL, 0x60000000UL, 0x3fe9dfd6UL,\n-    0x1ac33522UL, 0x3e5dbc53UL, 0x00000000UL, 0x3fe9d1dcUL, 0xeabdff1dUL,\n-    0x3e40fc0cUL, 0xe0000000UL, 0x3fe9c3e5UL, 0xafd30e73UL, 0xbe585e63UL,\n-    0xe0000000UL, 0x3fe9b5f3UL, 0xa52f226aUL, 0xbe43e8f9UL, 0x20000000UL,\n-    0x3fe9a806UL, 0xecb8698dUL, 0xbe515b36UL, 0x80000000UL, 0x3fe99a1cUL,\n-    0xf2b4e89dUL, 0x3e48b62bUL, 0x20000000UL, 0x3fe98c37UL, 0x7c9a88fbUL,\n-    0x3e44414cUL, 0x00000000UL, 0x3fe97e56UL, 0xda015741UL, 0xbe5d13baUL,\n-    0xe0000000UL, 0x3fe97078UL, 0x5fdace06UL, 0x3e51b947UL, 0x00000000UL,\n-    0x3fe962a0UL, 0x956ca094UL, 0x3e518785UL, 0x40000000UL, 0x3fe954cbUL,\n-    0x01164c1dUL, 0x3e5d5b57UL, 0xc0000000UL, 0x3fe946faUL, 0xe63b3767UL,\n-    0xbe4f84e7UL, 0x40000000UL, 0x3fe9392eUL, 0xe57cc2a9UL, 0x3e34eda3UL,\n-    0xe0000000UL, 0x3fe92b65UL, 0x8c75b544UL, 0x3e5766a0UL, 0xc0000000UL,\n-    0x3fe91da1UL, 0x37d1d087UL, 0xbe5e2ab1UL, 0x80000000UL, 0x3fe90fe1UL,\n-    0xa953dc20UL, 0x3e5fa1f3UL, 0x80000000UL, 0x3fe90225UL, 0xdbd3f369UL,\n-    0x3e47d6dbUL, 0xa0000000UL, 0x3fe8f46dUL, 0x1c9be989UL, 0xbe5e2b0aUL,\n-    0xa0000000UL, 0x3fe8e6b9UL, 0x3c93d76aUL, 0x3e5c8618UL, 0xe0000000UL,\n-    0x3fe8d909UL, 0x2182fc9aUL, 0xbe41aa9eUL, 0x20000000UL, 0x3fe8cb5eUL,\n-    0xe6b3539dUL, 0xbe530d19UL, 0x60000000UL, 0x3fe8bdb6UL, 0x49e58cc3UL,\n-    0xbe3bb374UL, 0xa0000000UL, 0x3fe8b012UL, 0xa7cfeb8fUL, 0x3e56c412UL,\n-    0x00000000UL, 0x3fe8a273UL, 0x8d52bc19UL, 0x3e1429b8UL, 0x60000000UL,\n-    0x3fe894d7UL, 0x4dc32c6cUL, 0xbe48604cUL, 0xc0000000UL, 0x3fe8873fUL,\n-    0x0c868e56UL, 0xbe564ee5UL, 0x00000000UL, 0x3fe879acUL, 0x56aee828UL,\n-    0x3e5e2fd8UL, 0x60000000UL, 0x3fe86c1cUL, 0x7ceab8ecUL, 0x3e493365UL,\n-    0xc0000000UL, 0x3fe85e90UL, 0x78d4dadcUL, 0xbe4f7f25UL, 0x00000000UL,\n-    0x3fe85109UL, 0x0ccd8280UL, 0x3e31e7a2UL, 0x40000000UL, 0x3fe84385UL,\n-    0x34ba4e15UL, 0x3e328077UL, 0x80000000UL, 0x3fe83605UL, 0xa670975aUL,\n-    0xbe53eee5UL, 0xa0000000UL, 0x3fe82889UL, 0xf61b77b2UL, 0xbe43a20aUL,\n-    0xa0000000UL, 0x3fe81b11UL, 0x13e6643bUL, 0x3e5e5fe5UL, 0xc0000000UL,\n-    0x3fe80d9dUL, 0x82cc94e8UL, 0xbe5ff1f9UL, 0xa0000000UL, 0x3fe8002dUL,\n-    0x8a0c9c5dUL, 0xbe42b0e7UL, 0x60000000UL, 0x3fe7f2c1UL, 0x22a16f01UL,\n-    0x3e5d9ea0UL, 0x20000000UL, 0x3fe7e559UL, 0xc38cd451UL, 0x3e506963UL,\n-    0xc0000000UL, 0x3fe7d7f4UL, 0x9902bc71UL, 0x3e4503d7UL, 0x40000000UL,\n-    0x3fe7ca94UL, 0xdef2a3c0UL, 0x3e3d98edUL, 0xa0000000UL, 0x3fe7bd37UL,\n-    0xed49abb0UL, 0x3e24c1ffUL, 0xe0000000UL, 0x3fe7afdeUL, 0xe3b0be70UL,\n-    0xbe40c467UL, 0x00000000UL, 0x3fe7a28aUL, 0xaf9f193cUL, 0xbe5dff6cUL,\n-    0xe0000000UL, 0x3fe79538UL, 0xb74cf6b6UL, 0xbe258ed0UL, 0xa0000000UL,\n-    0x3fe787ebUL, 0x1d9127c7UL, 0x3e345fb0UL, 0x40000000UL, 0x3fe77aa2UL,\n-    0x1028c21dUL, 0xbe4619bdUL, 0xa0000000UL, 0x3fe76d5cUL, 0x7cb0b5e4UL,\n-    0x3e40f1a2UL, 0xe0000000UL, 0x3fe7601aUL, 0x2b1bc4adUL, 0xbe32e8bbUL,\n-    0xe0000000UL, 0x3fe752dcUL, 0x6839f64eUL, 0x3e41f57bUL, 0xc0000000UL,\n-    0x3fe745a2UL, 0xc4121f7eUL, 0xbe52c40aUL, 0x60000000UL, 0x3fe7386cUL,\n-    0xd6852d72UL, 0xbe5c4e6bUL, 0xc0000000UL, 0x3fe72b39UL, 0x91d690f7UL,\n-    0xbe57f88fUL, 0xe0000000UL, 0x3fe71e0aUL, 0x627a2159UL, 0xbe4425d5UL,\n-    0xc0000000UL, 0x3fe710dfUL, 0x50a54033UL, 0x3e422b7eUL, 0x60000000UL,\n-    0x3fe703b8UL, 0x3b0b5f91UL, 0x3e5d3857UL, 0xe0000000UL, 0x3fe6f694UL,\n-    0x84d628a2UL, 0xbe51f090UL, 0x00000000UL, 0x3fe6e975UL, 0x306d8894UL,\n-    0xbe414d83UL, 0xe0000000UL, 0x3fe6dc58UL, 0x30bf24aaUL, 0xbe4650caUL,\n-    0x80000000UL, 0x3fe6cf40UL, 0xd4628d69UL, 0xbe5db007UL, 0xc0000000UL,\n-    0x3fe6c22bUL, 0xa2aae57bUL, 0xbe31d279UL, 0xc0000000UL, 0x3fe6b51aUL,\n-    0x860edf7eUL, 0xbe2d4c4aUL, 0x80000000UL, 0x3fe6a80dUL, 0xf3559341UL,\n-    0xbe5f7e98UL, 0xe0000000UL, 0x3fe69b03UL, 0xa885899eUL, 0xbe5c2011UL,\n-    0xe0000000UL, 0x3fe68dfdUL, 0x2bdc6d37UL, 0x3e224a82UL, 0xa0000000UL,\n-    0x3fe680fbUL, 0xc12ad1b9UL, 0xbe40cf56UL, 0x00000000UL, 0x3fe673fdUL,\n-    0x1bcdf659UL, 0xbdf52f2dUL, 0x00000000UL, 0x3fe66702UL, 0x5df10408UL,\n-    0x3e5663e0UL, 0xc0000000UL, 0x3fe65a0aUL, 0xa4070568UL, 0xbe40b12fUL,\n-    0x00000000UL, 0x3fe64d17UL, 0x71c54c47UL, 0x3e5f5e8bUL, 0x00000000UL,\n-    0x3fe64027UL, 0xbd4b7e83UL, 0x3e42ead6UL, 0xa0000000UL, 0x3fe6333aUL,\n-    0x61598bd2UL, 0xbe4c48d4UL, 0xc0000000UL, 0x3fe62651UL, 0x6f538d61UL,\n-    0x3e548401UL, 0xa0000000UL, 0x3fe6196cUL, 0x14344120UL, 0xbe529af6UL,\n-    0x00000000UL, 0x3fe60c8bUL, 0x5982c587UL, 0xbe3e1e4fUL, 0x00000000UL,\n-    0x3fe5ffadUL, 0xfe51d4eaUL, 0xbe4c897aUL, 0x80000000UL, 0x3fe5f2d2UL,\n-    0xfd46ebe1UL, 0x3e552e00UL, 0xa0000000UL, 0x3fe5e5fbUL, 0xa4695699UL,\n-    0x3e5ed471UL, 0x60000000UL, 0x3fe5d928UL, 0x80d118aeUL, 0x3e456b61UL,\n-    0xa0000000UL, 0x3fe5cc58UL, 0x304c330bUL, 0x3e54dc29UL, 0x80000000UL,\n-    0x3fe5bf8cUL, 0x0af2dedfUL, 0xbe3aa9bdUL, 0xe0000000UL, 0x3fe5b2c3UL,\n-    0x15fc9258UL, 0xbe479a37UL, 0xc0000000UL, 0x3fe5a5feUL, 0x9292c7eaUL,\n-    0x3e188650UL, 0x20000000UL, 0x3fe5993dUL, 0x33b4d380UL, 0x3e5d6d93UL,\n-    0x20000000UL, 0x3fe58c7fUL, 0x02fd16c7UL, 0x3e2fe961UL, 0xa0000000UL,\n-    0x3fe57fc4UL, 0x4a05edb6UL, 0xbe4d55b4UL, 0xa0000000UL, 0x3fe5730dUL,\n-    0x3d443abbUL, 0xbe5e6954UL, 0x00000000UL, 0x3fe5665aUL, 0x024acfeaUL,\n-    0x3e50e61bUL, 0x00000000UL, 0x3fe559aaUL, 0xcc9edd09UL, 0xbe325403UL,\n-    0x60000000UL, 0x3fe54cfdUL, 0x1fe26950UL, 0x3e5d500eUL, 0x60000000UL,\n-    0x3fe54054UL, 0x6c5ae164UL, 0xbe4a79b4UL, 0xc0000000UL, 0x3fe533aeUL,\n-    0x154b0287UL, 0xbe401571UL, 0xa0000000UL, 0x3fe5270cUL, 0x0673f401UL,\n-    0xbe56e56bUL, 0xe0000000UL, 0x3fe51a6dUL, 0x751b639cUL, 0x3e235269UL,\n-    0xa0000000UL, 0x3fe50dd2UL, 0x7c7b2bedUL, 0x3ddec887UL, 0xc0000000UL,\n-    0x3fe5013aUL, 0xafab4e17UL, 0x3e5e7575UL, 0x60000000UL, 0x3fe4f4a6UL,\n-    0x2e308668UL, 0x3e59aed6UL, 0x80000000UL, 0x3fe4e815UL, 0xf33e2a76UL,\n-    0xbe51f184UL, 0xe0000000UL, 0x3fe4db87UL, 0x839f3e3eUL, 0x3e57db01UL,\n-    0xc0000000UL, 0x3fe4cefdUL, 0xa9eda7bbUL, 0x3e535e0fUL, 0x00000000UL,\n-    0x3fe4c277UL, 0x2a8f66a5UL, 0x3e5ce451UL, 0xc0000000UL, 0x3fe4b5f3UL,\n-    0x05192456UL, 0xbe4e8518UL, 0xc0000000UL, 0x3fe4a973UL, 0x4aa7cd1dUL,\n-    0x3e46784aUL, 0x40000000UL, 0x3fe49cf7UL, 0x8e23025eUL, 0xbe5749f2UL,\n-    0x00000000UL, 0x3fe4907eUL, 0x18d30215UL, 0x3e360f39UL, 0x20000000UL,\n-    0x3fe48408UL, 0x63dcf2f3UL, 0x3e5e00feUL, 0xc0000000UL, 0x3fe47795UL,\n-    0x46182d09UL, 0xbe5173d9UL, 0xa0000000UL, 0x3fe46b26UL, 0x8f0e62aaUL,\n-    0xbe48f281UL, 0xe0000000UL, 0x3fe45ebaUL, 0x5775c40cUL, 0xbe56aad4UL,\n-    0x60000000UL, 0x3fe45252UL, 0x0fe25f69UL, 0x3e48bd71UL, 0x40000000UL,\n-    0x3fe445edUL, 0xe9989ec5UL, 0x3e590d97UL, 0x80000000UL, 0x3fe4398bUL,\n-    0xb3d9ffe3UL, 0x3e479dbcUL, 0x20000000UL, 0x3fe42d2dUL, 0x388e4d2eUL,\n-    0xbe5eed80UL, 0xe0000000UL, 0x3fe420d1UL, 0x6f797c18UL, 0x3e554b4cUL,\n-    0x20000000UL, 0x3fe4147aUL, 0x31048bb4UL, 0xbe5b1112UL, 0x80000000UL,\n-    0x3fe40825UL, 0x2efba4f9UL, 0x3e48ebc7UL, 0x40000000UL, 0x3fe3fbd4UL,\n-    0x50201119UL, 0x3e40b701UL, 0x40000000UL, 0x3fe3ef86UL, 0x0a4db32cUL,\n-    0x3e551de8UL, 0xa0000000UL, 0x3fe3e33bUL, 0x0c9c148bUL, 0xbe50c1f6UL,\n-    0x20000000UL, 0x3fe3d6f4UL, 0xc9129447UL, 0x3e533fa0UL, 0x00000000UL,\n-    0x3fe3cab0UL, 0xaae5b5a0UL, 0xbe22b68eUL, 0x20000000UL, 0x3fe3be6fUL,\n-    0x02305e8aUL, 0xbe54fc08UL, 0x60000000UL, 0x3fe3b231UL, 0x7f908258UL,\n-    0x3e57dc05UL, 0x00000000UL, 0x3fe3a5f7UL, 0x1a09af78UL, 0x3e08038bUL,\n-    0xe0000000UL, 0x3fe399bfUL, 0x490643c1UL, 0xbe5dbe42UL, 0xe0000000UL,\n-    0x3fe38d8bUL, 0x5e8ad724UL, 0xbe3c2b72UL, 0x20000000UL, 0x3fe3815bUL,\n-    0xc67196b6UL, 0x3e1713cfUL, 0xa0000000UL, 0x3fe3752dUL, 0x6182e429UL,\n-    0xbe3ec14cUL, 0x40000000UL, 0x3fe36903UL, 0xab6eb1aeUL, 0x3e5a2cc5UL,\n-    0x40000000UL, 0x3fe35cdcUL, 0xfe5dc064UL, 0xbe5c5878UL, 0x40000000UL,\n-    0x3fe350b8UL, 0x0ba6b9e4UL, 0x3e51619bUL, 0x80000000UL, 0x3fe34497UL,\n-    0x857761aaUL, 0x3e5fff53UL, 0x00000000UL, 0x3fe3387aUL, 0xf872d68cUL,\n-    0x3e484f4dUL, 0xa0000000UL, 0x3fe32c5fUL, 0x087e97c2UL, 0x3e52842eUL,\n-    0x80000000UL, 0x3fe32048UL, 0x73d6d0c0UL, 0xbe503edfUL, 0x80000000UL,\n-    0x3fe31434UL, 0x0c1456a1UL, 0xbe5f72adUL, 0xa0000000UL, 0x3fe30823UL,\n-    0x83a1a4d5UL, 0xbe5e65ccUL, 0xe0000000UL, 0x3fe2fc15UL, 0x855a7390UL,\n-    0xbe506438UL, 0x40000000UL, 0x3fe2f00bUL, 0xa2898287UL, 0x3e3d22a2UL,\n-    0xe0000000UL, 0x3fe2e403UL, 0x8b56f66fUL, 0xbe5aa5fdUL, 0x80000000UL,\n-    0x3fe2d7ffUL, 0x52db119aUL, 0x3e3a2e3dUL, 0x60000000UL, 0x3fe2cbfeUL,\n-    0xe2ddd4c0UL, 0xbe586469UL, 0x40000000UL, 0x3fe2c000UL, 0x6b01bf10UL,\n-    0x3e352b9dUL, 0x40000000UL, 0x3fe2b405UL, 0xb07a1cdfUL, 0x3e5c5cdaUL,\n-    0x80000000UL, 0x3fe2a80dUL, 0xc7b5f868UL, 0xbe5668b3UL, 0xc0000000UL,\n-    0x3fe29c18UL, 0x185edf62UL, 0xbe563d66UL, 0x00000000UL, 0x3fe29027UL,\n-    0xf729e1ccUL, 0x3e59a9a0UL, 0x80000000UL, 0x3fe28438UL, 0x6433c727UL,\n-    0xbe43cc89UL, 0x00000000UL, 0x3fe2784dUL, 0x41782631UL, 0xbe30750cUL,\n-    0xa0000000UL, 0x3fe26c64UL, 0x914911b7UL, 0xbe58290eUL, 0x40000000UL,\n-    0x3fe2607fUL, 0x3dcc73e1UL, 0xbe4269cdUL, 0x00000000UL, 0x3fe2549dUL,\n-    0x2751bf70UL, 0xbe5a6998UL, 0xc0000000UL, 0x3fe248bdUL, 0x4248b9fbUL,\n-    0xbe4ddb00UL, 0x80000000UL, 0x3fe23ce1UL, 0xf35cf82fUL, 0x3e561b71UL,\n-    0x60000000UL, 0x3fe23108UL, 0x8e481a2dUL, 0x3e518fb9UL, 0x60000000UL,\n-    0x3fe22532UL, 0x5ab96edcUL, 0xbe5fafc5UL, 0x40000000UL, 0x3fe2195fUL,\n-    0x80943911UL, 0xbe07f819UL, 0x40000000UL, 0x3fe20d8fUL, 0x386f2d6cUL,\n-    0xbe54ba8bUL, 0x40000000UL, 0x3fe201c2UL, 0xf29664acUL, 0xbe5eb815UL,\n-    0x20000000UL, 0x3fe1f5f8UL, 0x64f03390UL, 0x3e5e320cUL, 0x20000000UL,\n-    0x3fe1ea31UL, 0x747ff696UL, 0x3e5ef0a5UL, 0x40000000UL, 0x3fe1de6dUL,\n-    0x3e9ceb51UL, 0xbe5f8d27UL, 0x20000000UL, 0x3fe1d2acUL, 0x4ae0b55eUL,\n-    0x3e5faa21UL, 0x20000000UL, 0x3fe1c6eeUL, 0x28569a5eUL, 0x3e598a4fUL,\n-    0x20000000UL, 0x3fe1bb33UL, 0x54b33e07UL, 0x3e46130aUL, 0x20000000UL,\n-    0x3fe1af7bUL, 0x024f1078UL, 0xbe4dbf93UL, 0x00000000UL, 0x3fe1a3c6UL,\n-    0xb0783bfaUL, 0x3e419248UL, 0xe0000000UL, 0x3fe19813UL, 0x2f02b836UL,\n-    0x3e4e02b7UL, 0xc0000000UL, 0x3fe18c64UL, 0x28dec9d4UL, 0x3e09064fUL,\n-    0x80000000UL, 0x3fe180b8UL, 0x45cbf406UL, 0x3e5b1f46UL, 0x40000000UL,\n-    0x3fe1750fUL, 0x03d9964cUL, 0x3e5b0a79UL, 0x00000000UL, 0x3fe16969UL,\n-    0x8b5b882bUL, 0xbe238086UL, 0xa0000000UL, 0x3fe15dc5UL, 0x73bad6f8UL,\n-    0xbdf1fca4UL, 0x20000000UL, 0x3fe15225UL, 0x5385769cUL, 0x3e5e8d76UL,\n-    0xa0000000UL, 0x3fe14687UL, 0x1676dc6bUL, 0x3e571d08UL, 0x20000000UL,\n-    0x3fe13aedUL, 0xa8c41c7fUL, 0xbe598a25UL, 0x60000000UL, 0x3fe12f55UL,\n-    0xc4e1aaf0UL, 0x3e435277UL, 0xa0000000UL, 0x3fe123c0UL, 0x403638e1UL,\n-    0xbe21aa7cUL, 0xc0000000UL, 0x3fe1182eUL, 0x557a092bUL, 0xbdd0116bUL,\n-    0xc0000000UL, 0x3fe10c9fUL, 0x7d779f66UL, 0x3e4a61baUL, 0xc0000000UL,\n-    0x3fe10113UL, 0x2b09c645UL, 0xbe5d586eUL, 0x20000000UL, 0x3fe0ea04UL,\n-    0xea2cad46UL, 0x3e5aa97cUL, 0x20000000UL, 0x3fe0d300UL, 0x23190e54UL,\n-    0x3e50f1a7UL, 0xa0000000UL, 0x3fe0bc07UL, 0x1379a5a6UL, 0xbe51619dUL,\n-    0x60000000UL, 0x3fe0a51aUL, 0x926a3d4aUL, 0x3e5cf019UL, 0xa0000000UL,\n-    0x3fe08e38UL, 0xa8c24358UL, 0x3e35241eUL, 0x20000000UL, 0x3fe07762UL,\n-    0x24317e7aUL, 0x3e512cfaUL, 0x00000000UL, 0x3fe06097UL, 0xfd9cf274UL,\n-    0xbe55bef3UL, 0x00000000UL, 0x3fe049d7UL, 0x3689b49dUL, 0xbe36d26dUL,\n-    0x40000000UL, 0x3fe03322UL, 0xf72ef6c4UL, 0xbe54cd08UL, 0xa0000000UL,\n-    0x3fe01c78UL, 0x23702d2dUL, 0xbe5900bfUL, 0x00000000UL, 0x3fe005daUL,\n-    0x3f59c14cUL, 0x3e57d80bUL, 0x40000000UL, 0x3fdfde8dUL, 0xad67766dUL,\n-    0xbe57fad4UL, 0x40000000UL, 0x3fdfb17cUL, 0x644f4ae7UL, 0x3e1ee43bUL,\n-    0x40000000UL, 0x3fdf8481UL, 0x903234d2UL, 0x3e501a86UL, 0x40000000UL,\n-    0x3fdf579cUL, 0xafe9e509UL, 0xbe267c3eUL, 0x00000000UL, 0x3fdf2acdUL,\n-    0xb7dfda0bUL, 0xbe48149bUL, 0x40000000UL, 0x3fdefe13UL, 0x3b94305eUL,\n-    0x3e5f4ea7UL, 0x80000000UL, 0x3fded16fUL, 0x5d95da61UL, 0xbe55c198UL,\n-    0x00000000UL, 0x3fdea4e1UL, 0x406960c9UL, 0xbdd99a19UL, 0x00000000UL,\n-    0x3fde7868UL, 0xd22f3539UL, 0x3e470c78UL, 0x80000000UL, 0x3fde4c04UL,\n-    0x83eec535UL, 0xbe3e1232UL, 0x40000000UL, 0x3fde1fb6UL, 0x3dfbffcbUL,\n-    0xbe4b7d71UL, 0x40000000UL, 0x3fddf37dUL, 0x7e1be4e0UL, 0xbe5b8f8fUL,\n-    0x40000000UL, 0x3fddc759UL, 0x46dae887UL, 0xbe350458UL, 0x80000000UL,\n-    0x3fdd9b4aUL, 0xed6ecc49UL, 0xbe5f0045UL, 0x80000000UL, 0x3fdd6f50UL,\n-    0x2e9e883cUL, 0x3e2915daUL, 0x80000000UL, 0x3fdd436bUL, 0xf0bccb32UL,\n-    0x3e4a68c9UL, 0x80000000UL, 0x3fdd179bUL, 0x9bbfc779UL, 0xbe54a26aUL,\n-    0x00000000UL, 0x3fdcebe0UL, 0x7cea33abUL, 0x3e43c6b7UL, 0x40000000UL,\n-    0x3fdcc039UL, 0xe740fd06UL, 0x3e5526c2UL, 0x40000000UL, 0x3fdc94a7UL,\n-    0x9eadeb1aUL, 0xbe396d8dUL, 0xc0000000UL, 0x3fdc6929UL, 0xf0a8f95aUL,\n-    0xbe5c0ab2UL, 0x80000000UL, 0x3fdc3dc0UL, 0x6ee2693bUL, 0x3e0992e6UL,\n-    0xc0000000UL, 0x3fdc126bUL, 0x5ac6b581UL, 0xbe2834b6UL, 0x40000000UL,\n-    0x3fdbe72bUL, 0x8cc226ffUL, 0x3e3596a6UL, 0x00000000UL, 0x3fdbbbffUL,\n-    0xf92a74bbUL, 0x3e3c5813UL, 0x00000000UL, 0x3fdb90e7UL, 0x479664c0UL,\n-    0xbe50d644UL, 0x00000000UL, 0x3fdb65e3UL, 0x5004975bUL, 0xbe55258fUL,\n-    0x00000000UL, 0x3fdb3af3UL, 0xe4b23194UL, 0xbe588407UL, 0xc0000000UL,\n-    0x3fdb1016UL, 0xe65d4d0aUL, 0x3e527c26UL, 0x80000000UL, 0x3fdae54eUL,\n-    0x814fddd6UL, 0x3e5962a2UL, 0x40000000UL, 0x3fdaba9aUL, 0xe19d0913UL,\n-    0xbe562f4eUL, 0x80000000UL, 0x3fda8ff9UL, 0x43cfd006UL, 0xbe4cfdebUL,\n-    0x40000000UL, 0x3fda656cUL, 0x686f0a4eUL, 0x3e5e47a8UL, 0xc0000000UL,\n-    0x3fda3af2UL, 0x7200d410UL, 0x3e5e1199UL, 0xc0000000UL, 0x3fda108cUL,\n-    0xabd2266eUL, 0x3e5ee4d1UL, 0x40000000UL, 0x3fd9e63aUL, 0x396f8f2cUL,\n-    0x3e4dbffbUL, 0x00000000UL, 0x3fd9bbfbUL, 0xe32b25ddUL, 0x3e5c3a54UL,\n-    0x40000000UL, 0x3fd991cfUL, 0x431e4035UL, 0xbe457925UL, 0x80000000UL,\n-    0x3fd967b6UL, 0x7bed3dd3UL, 0x3e40c61dUL, 0x00000000UL, 0x3fd93db1UL,\n-    0xd7449365UL, 0x3e306419UL, 0x80000000UL, 0x3fd913beUL, 0x1746e791UL,\n-    0x3e56fcfcUL, 0x40000000UL, 0x3fd8e9dfUL, 0xf3a9028bUL, 0xbe5041b9UL,\n-    0xc0000000UL, 0x3fd8c012UL, 0x56840c50UL, 0xbe26e20aUL, 0x40000000UL,\n-    0x3fd89659UL, 0x19763102UL, 0xbe51f466UL, 0x80000000UL, 0x3fd86cb2UL,\n-    0x7032de7cUL, 0xbe4d298aUL, 0x80000000UL, 0x3fd8431eUL, 0xdeb39fabUL,\n-    0xbe4361ebUL, 0x40000000UL, 0x3fd8199dUL, 0x5d01cbe0UL, 0xbe5425b3UL,\n-    0x80000000UL, 0x3fd7f02eUL, 0x3ce99aa9UL, 0x3e146fa8UL, 0x80000000UL,\n-    0x3fd7c6d2UL, 0xd1a262b9UL, 0xbe5a1a69UL, 0xc0000000UL, 0x3fd79d88UL,\n-    0x8606c236UL, 0x3e423a08UL, 0x80000000UL, 0x3fd77451UL, 0x8fd1e1b7UL,\n-    0x3e5a6a63UL, 0xc0000000UL, 0x3fd74b2cUL, 0xe491456aUL, 0x3e42c1caUL,\n-    0x40000000UL, 0x3fd7221aUL, 0x4499a6d7UL, 0x3e36a69aUL, 0x00000000UL,\n-    0x3fd6f91aUL, 0x5237df94UL, 0xbe0f8f02UL, 0x00000000UL, 0x3fd6d02cUL,\n-    0xb6482c6eUL, 0xbe5abcf7UL, 0x00000000UL, 0x3fd6a750UL, 0x1919fd61UL,\n-    0xbe57ade2UL, 0x00000000UL, 0x3fd67e86UL, 0xaa7a994dUL, 0xbe3f3fbdUL,\n-    0x00000000UL, 0x3fd655ceUL, 0x67db014cUL, 0x3e33c550UL, 0x00000000UL,\n-    0x3fd62d28UL, 0xa82856b7UL, 0xbe1409d1UL, 0xc0000000UL, 0x3fd60493UL,\n-    0x1e6a300dUL, 0x3e55d899UL, 0x80000000UL, 0x3fd5dc11UL, 0x1222bd5cUL,\n-    0xbe35bfc0UL, 0xc0000000UL, 0x3fd5b3a0UL, 0x6e8dc2d3UL, 0x3e5d4d79UL,\n-    0x00000000UL, 0x3fd58b42UL, 0xe0e4ace6UL, 0xbe517303UL, 0x80000000UL,\n-    0x3fd562f4UL, 0xb306e0a8UL, 0x3e5edf0fUL, 0xc0000000UL, 0x3fd53ab8UL,\n-    0x6574bc54UL, 0x3e5ee859UL, 0x80000000UL, 0x3fd5128eUL, 0xea902207UL,\n-    0x3e5f6188UL, 0xc0000000UL, 0x3fd4ea75UL, 0x9f911d79UL, 0x3e511735UL,\n-    0x80000000UL, 0x3fd4c26eUL, 0xf9c77397UL, 0xbe5b1643UL, 0x40000000UL,\n-    0x3fd49a78UL, 0x15fc9258UL, 0x3e479a37UL, 0x80000000UL, 0x3fd47293UL,\n-    0xd5a04dd9UL, 0xbe426e56UL, 0xc0000000UL, 0x3fd44abfUL, 0xe04042f5UL,\n-    0x3e56f7c6UL, 0x40000000UL, 0x3fd422fdUL, 0x1d8bf2c8UL, 0x3e5d8810UL,\n-    0x00000000UL, 0x3fd3fb4cUL, 0x88a8ddeeUL, 0xbe311454UL, 0xc0000000UL,\n-    0x3fd3d3abUL, 0x3e3b5e47UL, 0xbe5d1b72UL, 0x40000000UL, 0x3fd3ac1cUL,\n-    0xc2ab5d59UL, 0x3e31b02bUL, 0xc0000000UL, 0x3fd3849dUL, 0xd4e34b9eUL,\n-    0x3e51cb2fUL, 0x40000000UL, 0x3fd35d30UL, 0x177204fbUL, 0xbe2b8cd7UL,\n-    0x80000000UL, 0x3fd335d3UL, 0xfcd38c82UL, 0xbe4356e1UL, 0x80000000UL,\n-    0x3fd30e87UL, 0x64f54accUL, 0xbe4e6224UL, 0x00000000UL, 0x3fd2e74cUL,\n-    0xaa7975d9UL, 0x3e5dc0feUL, 0x80000000UL, 0x3fd2c021UL, 0x516dab3fUL,\n-    0xbe50ffa3UL, 0x40000000UL, 0x3fd29907UL, 0x2bfb7313UL, 0x3e5674a2UL,\n-    0xc0000000UL, 0x3fd271fdUL, 0x0549fc99UL, 0x3e385d29UL, 0xc0000000UL,\n-    0x3fd24b04UL, 0x55b63073UL, 0xbe500c6dUL, 0x00000000UL, 0x3fd2241cUL,\n-    0x3f91953aUL, 0x3e389977UL, 0xc0000000UL, 0x3fd1fd43UL, 0xa1543f71UL,\n-    0xbe3487abUL, 0xc0000000UL, 0x3fd1d67bUL, 0x4ec8867cUL, 0x3df6a2dcUL,\n-    0x00000000UL, 0x3fd1afc4UL, 0x4328e3bbUL, 0x3e41d9c0UL, 0x80000000UL,\n-    0x3fd1891cUL, 0x2e1cda84UL, 0x3e3bdd87UL, 0x40000000UL, 0x3fd16285UL,\n-    0x4b5331aeUL, 0xbe53128eUL, 0x00000000UL, 0x3fd13bfeUL, 0xb9aec164UL,\n-    0xbe52ac98UL, 0xc0000000UL, 0x3fd11586UL, 0xd91e1316UL, 0xbe350630UL,\n-    0x80000000UL, 0x3fd0ef1fUL, 0x7cacc12cUL, 0x3e3f5219UL, 0x40000000UL,\n-    0x3fd0c8c8UL, 0xbce277b7UL, 0x3e3d30c0UL, 0x00000000UL, 0x3fd0a281UL,\n-    0x2a63447dUL, 0xbe541377UL, 0x80000000UL, 0x3fd07c49UL, 0xfac483b5UL,\n-    0xbe5772ecUL, 0xc0000000UL, 0x3fd05621UL, 0x36b8a570UL, 0xbe4fd4bdUL,\n-    0xc0000000UL, 0x3fd03009UL, 0xbae505f7UL, 0xbe450388UL, 0x80000000UL,\n-    0x3fd00a01UL, 0x3e35aeadUL, 0xbe5430fcUL, 0x80000000UL, 0x3fcfc811UL,\n-    0x707475acUL, 0x3e38806eUL, 0x80000000UL, 0x3fcf7c3fUL, 0xc91817fcUL,\n-    0xbe40cceaUL, 0x80000000UL, 0x3fcf308cUL, 0xae05d5e9UL, 0xbe4919b8UL,\n-    0x80000000UL, 0x3fcee4f8UL, 0xae6cc9e6UL, 0xbe530b94UL, 0x00000000UL,\n-    0x3fce9983UL, 0x1efe3e8eUL, 0x3e57747eUL, 0x00000000UL, 0x3fce4e2dUL,\n-    0xda78d9bfUL, 0xbe59a608UL, 0x00000000UL, 0x3fce02f5UL, 0x8abe2c2eUL,\n-    0x3e4a35adUL, 0x00000000UL, 0x3fcdb7dcUL, 0x1495450dUL, 0xbe0872ccUL,\n-    0x80000000UL, 0x3fcd6ce1UL, 0x86ee0ba0UL, 0xbe4f59a0UL, 0x00000000UL,\n-    0x3fcd2205UL, 0xe81ca888UL, 0x3e5402c3UL, 0x00000000UL, 0x3fccd747UL,\n-    0x3b4424b9UL, 0x3e5dfdc3UL, 0x80000000UL, 0x3fcc8ca7UL, 0xd305b56cUL,\n-    0x3e202da6UL, 0x00000000UL, 0x3fcc4226UL, 0x399a6910UL, 0xbe482a1cUL,\n-    0x80000000UL, 0x3fcbf7c2UL, 0x747f7938UL, 0xbe587372UL, 0x80000000UL,\n-    0x3fcbad7cUL, 0x6fc246a0UL, 0x3e50d83dUL, 0x00000000UL, 0x3fcb6355UL,\n-    0xee9e9be5UL, 0xbe5c35bdUL, 0x80000000UL, 0x3fcb194aUL, 0x8416c0bcUL,\n-    0x3e546d4fUL, 0x00000000UL, 0x3fcacf5eUL, 0x49f7f08fUL, 0x3e56da76UL,\n-    0x00000000UL, 0x3fca858fUL, 0x5dc30de2UL, 0x3e5f390cUL, 0x00000000UL,\n-    0x3fca3bdeUL, 0x950583b6UL, 0xbe5e4169UL, 0x80000000UL, 0x3fc9f249UL,\n-    0x33631553UL, 0x3e52aeb1UL, 0x00000000UL, 0x3fc9a8d3UL, 0xde8795a6UL,\n-    0xbe59a504UL, 0x00000000UL, 0x3fc95f79UL, 0x076bf41eUL, 0x3e5122feUL,\n-    0x80000000UL, 0x3fc9163cUL, 0x2914c8e7UL, 0x3e3dd064UL, 0x00000000UL,\n-    0x3fc8cd1dUL, 0x3a30eca3UL, 0xbe21b4aaUL, 0x80000000UL, 0x3fc8841aUL,\n-    0xb2a96650UL, 0xbe575444UL, 0x80000000UL, 0x3fc83b34UL, 0x2376c0cbUL,\n-    0xbe2a74c7UL, 0x80000000UL, 0x3fc7f26bUL, 0xd8a0b653UL, 0xbe5181b6UL,\n-    0x00000000UL, 0x3fc7a9bfUL, 0x32257882UL, 0xbe4a78b4UL, 0x00000000UL,\n-    0x3fc7612fUL, 0x1eee8bd9UL, 0xbe1bfe9dUL, 0x80000000UL, 0x3fc718bbUL,\n-    0x0c603cc4UL, 0x3e36fdc9UL, 0x80000000UL, 0x3fc6d064UL, 0x3728b8cfUL,\n-    0xbe1e542eUL, 0x80000000UL, 0x3fc68829UL, 0xc79a4067UL, 0x3e5c380fUL,\n-    0x00000000UL, 0x3fc6400bUL, 0xf69eac69UL, 0x3e550a84UL, 0x80000000UL,\n-    0x3fc5f808UL, 0xb7a780a4UL, 0x3e5d9224UL, 0x80000000UL, 0x3fc5b022UL,\n-    0xad9dfb1eUL, 0xbe55242fUL, 0x00000000UL, 0x3fc56858UL, 0x659b18beUL,\n-    0xbe4bfda3UL, 0x80000000UL, 0x3fc520a9UL, 0x66ee3631UL, 0xbe57d769UL,\n-    0x80000000UL, 0x3fc4d916UL, 0x1ec62819UL, 0x3e2427f7UL, 0x80000000UL,\n-    0x3fc4919fUL, 0xdec25369UL, 0xbe435431UL, 0x00000000UL, 0x3fc44a44UL,\n-    0xa8acfc4bUL, 0xbe3c62e8UL, 0x00000000UL, 0x3fc40304UL, 0xcf1d3eabUL,\n-    0xbdfba29fUL, 0x80000000UL, 0x3fc3bbdfUL, 0x79aba3eaUL, 0xbdf1b7c8UL,\n-    0x80000000UL, 0x3fc374d6UL, 0xb8d186daUL, 0xbe5130cfUL, 0x80000000UL,\n-    0x3fc32de8UL, 0x9d74f152UL, 0x3e2285b6UL, 0x00000000UL, 0x3fc2e716UL,\n-    0x50ae7ca9UL, 0xbe503920UL, 0x80000000UL, 0x3fc2a05eUL, 0x6caed92eUL,\n-    0xbe533924UL, 0x00000000UL, 0x3fc259c2UL, 0x9cb5034eUL, 0xbe510e31UL,\n-    0x80000000UL, 0x3fc21340UL, 0x12c4d378UL, 0xbe540b43UL, 0x80000000UL,\n-    0x3fc1ccd9UL, 0xcc418706UL, 0x3e59887aUL, 0x00000000UL, 0x3fc1868eUL,\n-    0x921f4106UL, 0xbe528e67UL, 0x80000000UL, 0x3fc1405cUL, 0x3969441eUL,\n-    0x3e5d8051UL, 0x00000000UL, 0x3fc0fa46UL, 0xd941ef5bUL, 0x3e5f9079UL,\n-    0x80000000UL, 0x3fc0b44aUL, 0x5a3e81b2UL, 0xbe567691UL, 0x00000000UL,\n-    0x3fc06e69UL, 0x9d66afe7UL, 0xbe4d43fbUL, 0x00000000UL, 0x3fc028a2UL,\n-    0x0a92a162UL, 0xbe52f394UL, 0x00000000UL, 0x3fbfc5eaUL, 0x209897e5UL,\n-    0x3e529e37UL, 0x00000000UL, 0x3fbf3ac5UL, 0x8458bd7bUL, 0x3e582831UL,\n-    0x00000000UL, 0x3fbeafd5UL, 0xb8d8b4b8UL, 0xbe486b4aUL, 0x00000000UL,\n-    0x3fbe2518UL, 0xe0a3b7b6UL, 0x3e5bafd2UL, 0x00000000UL, 0x3fbd9a90UL,\n-    0x2bf2710eUL, 0x3e383b2bUL, 0x00000000UL, 0x3fbd103cUL, 0x73eb6ab7UL,\n-    0xbe56d78dUL, 0x00000000UL, 0x3fbc861bUL, 0x32ceaff5UL, 0xbe32dc5aUL,\n-    0x00000000UL, 0x3fbbfc2eUL, 0xbee04cb7UL, 0xbe4a71a4UL, 0x00000000UL,\n-    0x3fbb7274UL, 0x35ae9577UL, 0x3e38142fUL, 0x00000000UL, 0x3fbae8eeUL,\n-    0xcbaddab4UL, 0xbe5490f0UL, 0x00000000UL, 0x3fba5f9aUL, 0x95ce1114UL,\n-    0x3e597c71UL, 0x00000000UL, 0x3fb9d67aUL, 0x6d7c0f78UL, 0x3e3abc2dUL,\n-    0x00000000UL, 0x3fb94d8dUL, 0x2841a782UL, 0xbe566cbcUL, 0x00000000UL,\n-    0x3fb8c4d2UL, 0x6ed429c6UL, 0xbe3cfff9UL, 0x00000000UL, 0x3fb83c4aUL,\n-    0xe4a49fbbUL, 0xbe552964UL, 0x00000000UL, 0x3fb7b3f4UL, 0x2193d81eUL,\n-    0xbe42fa72UL, 0x00000000UL, 0x3fb72bd0UL, 0xdd70c122UL, 0x3e527a8cUL,\n-    0x00000000UL, 0x3fb6a3dfUL, 0x03108a54UL, 0xbe450393UL, 0x00000000UL,\n-    0x3fb61c1fUL, 0x30ff7954UL, 0x3e565840UL, 0x00000000UL, 0x3fb59492UL,\n-    0xdedd460cUL, 0xbe5422b5UL, 0x00000000UL, 0x3fb50d36UL, 0x950f9f45UL,\n-    0xbe5313f6UL, 0x00000000UL, 0x3fb4860bUL, 0x582cdcb1UL, 0x3e506d39UL,\n-    0x00000000UL, 0x3fb3ff12UL, 0x7216d3a6UL, 0x3e4aa719UL, 0x00000000UL,\n-    0x3fb3784aUL, 0x57a423fdUL, 0x3e5a9b9fUL, 0x00000000UL, 0x3fb2f1b4UL,\n-    0x7a138b41UL, 0xbe50b418UL, 0x00000000UL, 0x3fb26b4eUL, 0x2fbfd7eaUL,\n-    0x3e23a53eUL, 0x00000000UL, 0x3fb1e519UL, 0x18913ccbUL, 0x3e465fc1UL,\n-    0x00000000UL, 0x3fb15f15UL, 0x7ea24e21UL, 0x3e042843UL, 0x00000000UL,\n-    0x3fb0d941UL, 0x7c6d9c77UL, 0x3e59f61eUL, 0x00000000UL, 0x3fb0539eUL,\n-    0x114efd44UL, 0x3e4ccab7UL, 0x00000000UL, 0x3faf9c56UL, 0x1777f657UL,\n-    0x3e552f65UL, 0x00000000UL, 0x3fae91d2UL, 0xc317b86aUL, 0xbe5a61e0UL,\n-    0x00000000UL, 0x3fad87acUL, 0xb7664efbUL, 0xbe41f64eUL, 0x00000000UL,\n-    0x3fac7de6UL, 0x5d3d03a9UL, 0x3e0807a0UL, 0x00000000UL, 0x3fab7480UL,\n-    0x743c38ebUL, 0xbe3726e1UL, 0x00000000UL, 0x3faa6b78UL, 0x06a253f1UL,\n-    0x3e5ad636UL, 0x00000000UL, 0x3fa962d0UL, 0xa35f541bUL, 0x3e5a187aUL,\n-    0x00000000UL, 0x3fa85a88UL, 0x4b86e446UL, 0xbe508150UL, 0x00000000UL,\n-    0x3fa7529cUL, 0x2589cacfUL, 0x3e52938aUL, 0x00000000UL, 0x3fa64b10UL,\n-    0xaf6b11f2UL, 0xbe3454cdUL, 0x00000000UL, 0x3fa543e2UL, 0x97506fefUL,\n-    0xbe5fdec5UL, 0x00000000UL, 0x3fa43d10UL, 0xe75f7dd9UL, 0xbe388dd3UL,\n-    0x00000000UL, 0x3fa3369cUL, 0xa4139632UL, 0xbdea5177UL, 0x00000000UL,\n-    0x3fa23086UL, 0x352d6f1eUL, 0xbe565ad6UL, 0x00000000UL, 0x3fa12accUL,\n-    0x77449eb7UL, 0xbe50d5c7UL, 0x00000000UL, 0x3fa0256eUL, 0x7478da78UL,\n-    0x3e404724UL, 0x00000000UL, 0x3f9e40dcUL, 0xf59cef7fUL, 0xbe539d0aUL,\n-    0x00000000UL, 0x3f9c3790UL, 0x1511d43cUL, 0x3e53c2c8UL, 0x00000000UL,\n-    0x3f9a2f00UL, 0x9b8bff3cUL, 0xbe43b3e1UL, 0x00000000UL, 0x3f982724UL,\n-    0xad1e22a5UL, 0x3e46f0bdUL, 0x00000000UL, 0x3f962000UL, 0x130d9356UL,\n-    0x3e475ba0UL, 0x00000000UL, 0x3f941994UL, 0x8f86f883UL, 0xbe513d0bUL,\n-    0x00000000UL, 0x3f9213dcUL, 0x914d0dc8UL, 0xbe534335UL, 0x00000000UL,\n-    0x3f900ed8UL, 0x2d73e5e7UL, 0xbe22ba75UL, 0x00000000UL, 0x3f8c1510UL,\n-    0xc5b7d70eUL, 0x3e599c5dUL, 0x00000000UL, 0x3f880de0UL, 0x8a27857eUL,\n-    0xbe3d28c8UL, 0x00000000UL, 0x3f840810UL, 0xda767328UL, 0x3e531b3dUL,\n-    0x00000000UL, 0x3f8003b0UL, 0x77bacaf3UL, 0xbe5f04e3UL, 0x00000000UL,\n-    0x3f780150UL, 0xdf4b0720UL, 0x3e5a8bffUL, 0x00000000UL, 0x3f6ffc40UL,\n-    0x34c48e71UL, 0xbe3fcd99UL, 0x00000000UL, 0x3f5ff6c0UL, 0x1ad218afUL,\n-    0xbe4c78a7UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x80000000UL,\n-    0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL, 0x00000000UL,\n-    0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL, 0x6dc96112UL, 0xbf836578UL,\n-    0xee241472UL, 0xbf9b0301UL, 0x9f95985aUL, 0xbfb528dbUL, 0xb3841d2aUL,\n-    0xbfd619b6UL, 0x518775e3UL, 0x3f9004f2UL, 0xac8349bbUL, 0x3fa76c9bUL,\n-    0x486ececcUL, 0x3fc4635eUL, 0x161bb241UL, 0xbf5dabe1UL, 0x9f95985aUL,\n-    0xbfb528dbUL, 0xf8b5787dUL, 0x3ef2531eUL, 0x486ececbUL, 0x3fc4635eUL,\n-    0x412055ccUL, 0xbdd61bb2UL, 0x00000000UL, 0xfffffff8UL, 0x00000000UL,\n-    0xffffffffUL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x3b700000UL,\n-    0xfa5abcbfUL, 0x3ff00b1aUL, 0xa7609f71UL, 0xbc84f6b2UL, 0xa9fb3335UL,\n-    0x3ff0163dUL, 0x9ab8cdb7UL, 0x3c9b6129UL, 0x143b0281UL, 0x3ff02168UL,\n-    0x0fc54eb6UL, 0xbc82bf31UL, 0x3e778061UL, 0x3ff02c9aUL, 0x535b085dUL,\n-    0xbc719083UL, 0x2e11bbccUL, 0x3ff037d4UL, 0xeeade11aUL, 0x3c656811UL,\n-    0xe86e7f85UL, 0x3ff04315UL, 0x1977c96eUL, 0xbc90a31cUL, 0x72f654b1UL,\n-    0x3ff04e5fUL, 0x3aa0d08cUL, 0x3c84c379UL, 0xd3158574UL, 0x3ff059b0UL,\n-    0xa475b465UL, 0x3c8d73e2UL, 0x0e3c1f89UL, 0x3ff0650aUL, 0x5799c397UL,\n-    0xbc95cb7bUL, 0x29ddf6deUL, 0x3ff0706bUL, 0xe2b13c27UL, 0xbc8c91dfUL,\n-    0x2b72a836UL, 0x3ff07bd4UL, 0x54458700UL, 0x3c832334UL, 0x18759bc8UL,\n-    0x3ff08745UL, 0x4bb284ffUL, 0x3c6186beUL, 0xf66607e0UL, 0x3ff092bdUL,\n-    0x800a3fd1UL, 0xbc968063UL, 0xcac6f383UL, 0x3ff09e3eUL, 0x18316136UL,\n-    0x3c914878UL, 0x9b1f3919UL, 0x3ff0a9c7UL, 0x873d1d38UL, 0x3c85d16cUL,\n-    0x6cf9890fUL, 0x3ff0b558UL, 0x4adc610bUL, 0x3c98a62eUL, 0x45e46c85UL,\n-    0x3ff0c0f1UL, 0x06d21cefUL, 0x3c94f989UL, 0x2b7247f7UL, 0x3ff0cc92UL,\n-    0x16e24f71UL, 0x3c901edcUL, 0x23395decUL, 0x3ff0d83bUL, 0xe43f316aUL,\n-    0xbc9bc14dUL, 0x32d3d1a2UL, 0x3ff0e3ecUL, 0x27c57b52UL, 0x3c403a17UL,\n-    0x5fdfa9c5UL, 0x3ff0efa5UL, 0xbc54021bUL, 0xbc949db9UL, 0xaffed31bUL,\n-    0x3ff0fb66UL, 0xc44ebd7bUL, 0xbc6b9bedUL, 0x28d7233eUL, 0x3ff10730UL,\n-    0x1692fdd5UL, 0x3c8d46ebUL, 0xd0125b51UL, 0x3ff11301UL, 0x39449b3aUL,\n-    0xbc96c510UL, 0xab5e2ab6UL, 0x3ff11edbUL, 0xf703fb72UL, 0xbc9ca454UL,\n-    0xc06c31ccUL, 0x3ff12abdUL, 0xb36ca5c7UL, 0xbc51b514UL, 0x14f204abUL,\n-    0x3ff136a8UL, 0xba48dcf0UL, 0xbc67108fUL, 0xaea92de0UL, 0x3ff1429aUL,\n-    0x9af1369eUL, 0xbc932fbfUL, 0x934f312eUL, 0x3ff14e95UL, 0x39bf44abUL,\n-    0xbc8b91e8UL, 0xc8a58e51UL, 0x3ff15a98UL, 0xb9eeab0aUL, 0x3c82406aUL,\n-    0x5471c3c2UL, 0x3ff166a4UL, 0x82ea1a32UL, 0x3c58f23bUL, 0x3c7d517bUL,\n-    0x3ff172b8UL, 0xb9d78a76UL, 0xbc819041UL, 0x8695bbc0UL, 0x3ff17ed4UL,\n-    0xe2ac5a64UL, 0x3c709e3fUL, 0x388c8deaUL, 0x3ff18af9UL, 0xd1970f6cUL,\n-    0xbc911023UL, 0x58375d2fUL, 0x3ff19726UL, 0x85f17e08UL, 0x3c94aaddUL,\n-    0xeb6fcb75UL, 0x3ff1a35bUL, 0x7b4968e4UL, 0x3c8e5b4cUL, 0xf8138a1cUL,\n-    0x3ff1af99UL, 0xa4b69280UL, 0x3c97bf85UL, 0x84045cd4UL, 0x3ff1bbe0UL,\n-    0x352ef607UL, 0xbc995386UL, 0x95281c6bUL, 0x3ff1c82fUL, 0x8010f8c9UL,\n-    0x3c900977UL, 0x3168b9aaUL, 0x3ff1d487UL, 0x00a2643cUL, 0x3c9e016eUL,\n-    0x5eb44027UL, 0x3ff1e0e7UL, 0x088cb6deUL, 0xbc96fdd8UL, 0x22fcd91dUL,\n-    0x3ff1ed50UL, 0x027bb78cUL, 0xbc91df98UL, 0x8438ce4dUL, 0x3ff1f9c1UL,\n-    0xa097af5cUL, 0xbc9bf524UL, 0x88628cd6UL, 0x3ff2063bUL, 0x814a8495UL,\n-    0x3c8dc775UL, 0x3578a819UL, 0x3ff212beUL, 0x2cfcaac9UL, 0x3c93592dUL,\n-    0x917ddc96UL, 0x3ff21f49UL, 0x9494a5eeUL, 0x3c82a97eUL, 0xa27912d1UL,\n-    0x3ff22bddUL, 0x5577d69fUL, 0x3c8d34fbUL, 0x6e756238UL, 0x3ff2387aUL,\n-    0xb6c70573UL, 0x3c99b07eUL, 0xfb82140aUL, 0x3ff2451fUL, 0x911ca996UL,\n-    0x3c8acfccUL, 0x4fb2a63fUL, 0x3ff251ceUL, 0xbef4f4a4UL, 0x3c8ac155UL,\n-    0x711ece75UL, 0x3ff25e85UL, 0x4ac31b2cUL, 0x3c93e1a2UL, 0x65e27cddUL,\n-    0x3ff26b45UL, 0x9940e9d9UL, 0x3c82bd33UL, 0x341ddf29UL, 0x3ff2780eUL,\n-    0x05f9e76cUL, 0x3c9e067cUL, 0xe1f56381UL, 0x3ff284dfUL, 0x8c3f0d7eUL,\n-    0xbc9a4c3aUL, 0x7591bb70UL, 0x3ff291baUL, 0x28401cbdUL, 0xbc82cc72UL,\n-    0xf51fdee1UL, 0x3ff29e9dUL, 0xafad1255UL, 0x3c8612e8UL, 0x66d10f13UL,\n-    0x3ff2ab8aUL, 0x191690a7UL, 0xbc995743UL, 0xd0dad990UL, 0x3ff2b87fUL,\n-    0xd6381aa4UL, 0xbc410adcUL, 0x39771b2fUL, 0x3ff2c57eUL, 0xa6eb5124UL,\n-    0xbc950145UL, 0xa6e4030bUL, 0x3ff2d285UL, 0x54db41d5UL, 0x3c900247UL,\n-    0x1f641589UL, 0x3ff2df96UL, 0xfbbce198UL, 0x3c9d16cfUL, 0xa93e2f56UL,\n-    0x3ff2ecafUL, 0x45d52383UL, 0x3c71ca0fUL, 0x4abd886bUL, 0x3ff2f9d2UL,\n-    0x532bda93UL, 0xbc653c55UL, 0x0a31b715UL, 0x3ff306feUL, 0xd23182e4UL,\n-    0x3c86f46aUL, 0xedeeb2fdUL, 0x3ff31432UL, 0xf3f3fcd1UL, 0x3c8959a3UL,\n-    0xfc4cd831UL, 0x3ff32170UL, 0x8e18047cUL, 0x3c8a9ce7UL, 0x3ba8ea32UL,\n-    0x3ff32eb8UL, 0x3cb4f318UL, 0xbc9c45e8UL, 0xb26416ffUL, 0x3ff33c08UL,\n-    0x843659a6UL, 0x3c932721UL, 0x66e3fa2dUL, 0x3ff34962UL, 0x930881a4UL,\n-    0xbc835a75UL, 0x5f929ff1UL, 0x3ff356c5UL, 0x5c4e4628UL, 0xbc8b5ceeUL,\n-    0xa2de883bUL, 0x3ff36431UL, 0xa06cb85eUL, 0xbc8c3144UL, 0x373aa9cbUL,\n-    0x3ff371a7UL, 0xbf42eae2UL, 0xbc963aeaUL, 0x231e754aUL, 0x3ff37f26UL,\n-    0x9eceb23cUL, 0xbc99f5caUL, 0x6d05d866UL, 0x3ff38caeUL, 0x3c9904bdUL,\n-    0xbc9e958dUL, 0x1b7140efUL, 0x3ff39a40UL, 0xfc8e2934UL, 0xbc99a9a5UL,\n-    0x34e59ff7UL, 0x3ff3a7dbUL, 0xd661f5e3UL, 0xbc75e436UL, 0xbfec6cf4UL,\n-    0x3ff3b57fUL, 0xe26fff18UL, 0x3c954c66UL, 0xc313a8e5UL, 0x3ff3c32dUL,\n-    0x375d29c3UL, 0xbc9efff8UL, 0x44ede173UL, 0x3ff3d0e5UL, 0x8c284c71UL,\n-    0x3c7fe8d0UL, 0x4c123422UL, 0x3ff3dea6UL, 0x11f09ebcUL, 0x3c8ada09UL,\n-    0xdf1c5175UL, 0x3ff3ec70UL, 0x7b8c9bcaUL, 0xbc8af663UL, 0x04ac801cUL,\n-    0x3ff3fa45UL, 0xf956f9f3UL, 0xbc97d023UL, 0xc367a024UL, 0x3ff40822UL,\n-    0xb6f4d048UL, 0x3c8bddf8UL, 0x21f72e2aUL, 0x3ff4160aUL, 0x1c309278UL,\n-    0xbc5ef369UL, 0x2709468aUL, 0x3ff423fbUL, 0xc0b314ddUL, 0xbc98462dUL,\n-    0xd950a897UL, 0x3ff431f5UL, 0xe35f7999UL, 0xbc81c7ddUL, 0x3f84b9d4UL,\n-    0x3ff43ffaUL, 0x9704c003UL, 0x3c8880beUL, 0x6061892dUL, 0x3ff44e08UL,\n-    0x04ef80d0UL, 0x3c489b7aUL, 0x42a7d232UL, 0x3ff45c20UL, 0x82fb1f8eUL,\n-    0xbc686419UL, 0xed1d0057UL, 0x3ff46a41UL, 0xd1648a76UL, 0x3c9c944bUL,\n-    0x668b3237UL, 0x3ff4786dUL, 0xed445733UL, 0xbc9c20f0UL, 0xb5c13cd0UL,\n-    0x3ff486a2UL, 0xb69062f0UL, 0x3c73c1a3UL, 0xe192aed2UL, 0x3ff494e1UL,\n-    0x5e499ea0UL, 0xbc83b289UL, 0xf0d7d3deUL, 0x3ff4a32aUL, 0xf3d1be56UL,\n-    0x3c99cb62UL, 0xea6db7d7UL, 0x3ff4b17dUL, 0x7f2897f0UL, 0xbc8125b8UL,\n-    0xd5362a27UL, 0x3ff4bfdaUL, 0xafec42e2UL, 0x3c7d4397UL, 0xb817c114UL,\n-    0x3ff4ce41UL, 0x690abd5dUL, 0x3c905e29UL, 0x99fddd0dUL, 0x3ff4dcb2UL,\n-    0xbc6a7833UL, 0x3c98ecdbUL, 0x81d8abffUL, 0x3ff4eb2dUL, 0x2e5d7a52UL,\n-    0xbc95257dUL, 0x769d2ca7UL, 0x3ff4f9b2UL, 0xd25957e3UL, 0xbc94b309UL,\n-    0x7f4531eeUL, 0x3ff50841UL, 0x49b7465fUL, 0x3c7a249bUL, 0xa2cf6642UL,\n-    0x3ff516daUL, 0x69bd93efUL, 0xbc8f7685UL, 0xe83f4eefUL, 0x3ff5257dUL,\n-    0x43efef71UL, 0xbc7c998dUL, 0x569d4f82UL, 0x3ff5342bUL, 0x1db13cadUL,\n-    0xbc807abeUL, 0xf4f6ad27UL, 0x3ff542e2UL, 0x192d5f7eUL, 0x3c87926dUL,\n-    0xca5d920fUL, 0x3ff551a4UL, 0xefede59bUL, 0xbc8d689cUL, 0xdde910d2UL,\n-    0x3ff56070UL, 0x168eebf0UL, 0xbc90fb6eUL, 0x36b527daUL, 0x3ff56f47UL,\n-    0x011d93adUL, 0x3c99bb2cUL, 0xdbe2c4cfUL, 0x3ff57e27UL, 0x8a57b9c4UL,\n-    0xbc90b98cUL, 0xd497c7fdUL, 0x3ff58d12UL, 0x5b9a1de8UL, 0x3c8295e1UL,\n-    0x27ff07ccUL, 0x3ff59c08UL, 0xe467e60fUL, 0xbc97e2ceUL, 0xdd485429UL,\n-    0x3ff5ab07UL, 0x054647adUL, 0x3c96324cUL, 0xfba87a03UL, 0x3ff5ba11UL,\n-    0x4c233e1aUL, 0xbc9b77a1UL, 0x8a5946b7UL, 0x3ff5c926UL, 0x816986a2UL,\n-    0x3c3c4b1bUL, 0x90998b93UL, 0x3ff5d845UL, 0xa8b45643UL, 0xbc9cd6a7UL,\n-    0x15ad2148UL, 0x3ff5e76fUL, 0x3080e65eUL, 0x3c9ba6f9UL, 0x20dceb71UL,\n-    0x3ff5f6a3UL, 0xe3cdcf92UL, 0xbc89eaddUL, 0xb976dc09UL, 0x3ff605e1UL,\n-    0x9b56de47UL, 0xbc93e242UL, 0xe6cdf6f4UL, 0x3ff6152aUL, 0x4ab84c27UL,\n-    0x3c9e4b3eUL, 0xb03a5585UL, 0x3ff6247eUL, 0x7e40b497UL, 0xbc9383c1UL,\n-    0x1d1929fdUL, 0x3ff633ddUL, 0xbeb964e5UL, 0x3c984710UL, 0x34ccc320UL,\n-    0x3ff64346UL, 0x759d8933UL, 0xbc8c483cUL, 0xfebc8fb7UL, 0x3ff652b9UL,\n-    0xc9a73e09UL, 0xbc9ae3d5UL, 0x82552225UL, 0x3ff66238UL, 0x87591c34UL,\n-    0xbc9bb609UL, 0xc70833f6UL, 0x3ff671c1UL, 0x586c6134UL, 0xbc8e8732UL,\n-    0xd44ca973UL, 0x3ff68155UL, 0x44f73e65UL, 0x3c6038aeUL, 0xb19e9538UL,\n-    0x3ff690f4UL, 0x9aeb445dUL, 0x3c8804bdUL, 0x667f3bcdUL, 0x3ff6a09eUL,\n-    0x13b26456UL, 0xbc9bdd34UL, 0xfa75173eUL, 0x3ff6b052UL, 0x2c9a9d0eUL,\n-    0x3c7a38f5UL, 0x750bdabfUL, 0x3ff6c012UL, 0x67ff0b0dUL, 0xbc728956UL,\n-    0xddd47645UL, 0x3ff6cfdcUL, 0xb6f17309UL, 0x3c9c7aa9UL, 0x3c651a2fUL,\n-    0x3ff6dfb2UL, 0x683c88abUL, 0xbc6bbe3aUL, 0x98593ae5UL, 0x3ff6ef92UL,\n-    0x9e1ac8b2UL, 0xbc90b974UL, 0xf9519484UL, 0x3ff6ff7dUL, 0x25860ef6UL,\n-    0xbc883c0fUL, 0x66f42e87UL, 0x3ff70f74UL, 0xd45aa65fUL, 0x3c59d644UL,\n-    0xe8ec5f74UL, 0x3ff71f75UL, 0x86887a99UL, 0xbc816e47UL, 0x86ead08aUL,\n-    0x3ff72f82UL, 0x2cd62c72UL, 0xbc920aa0UL, 0x48a58174UL, 0x3ff73f9aUL,\n-    0x6c65d53cUL, 0xbc90a8d9UL, 0x35d7cbfdUL, 0x3ff74fbdUL, 0x618a6e1cUL,\n-    0x3c9047fdUL, 0x564267c9UL, 0x3ff75febUL, 0x57316dd3UL, 0xbc902459UL,\n-    0xb1ab6e09UL, 0x3ff77024UL, 0x169147f8UL, 0x3c9b7877UL, 0x4fde5d3fUL,\n-    0x3ff78069UL, 0x0a02162dUL, 0x3c9866b8UL, 0x38ac1cf6UL, 0x3ff790b9UL,\n-    0x62aadd3eUL, 0x3c9349a8UL, 0x73eb0187UL, 0x3ff7a114UL, 0xee04992fUL,\n-    0xbc841577UL, 0x0976cfdbUL, 0x3ff7b17bUL, 0x8468dc88UL, 0xbc9bebb5UL,\n-    0x0130c132UL, 0x3ff7c1edUL, 0xd1164dd6UL, 0x3c9f124cUL, 0x62ff86f0UL,\n-    0x3ff7d26aUL, 0xfb72b8b4UL, 0x3c91bddbUL, 0x36cf4e62UL, 0x3ff7e2f3UL,\n-    0xba15797eUL, 0x3c705d02UL, 0x8491c491UL, 0x3ff7f387UL, 0xcf9311aeUL,\n-    0xbc807f11UL, 0x543e1a12UL, 0x3ff80427UL, 0x626d972bUL, 0xbc927c86UL,\n-    0xadd106d9UL, 0x3ff814d2UL, 0x0d151d4dUL, 0x3c946437UL, 0x994cce13UL,\n-    0x3ff82589UL, 0xd41532d8UL, 0xbc9d4c1dUL, 0x1eb941f7UL, 0x3ff8364cUL,\n-    0x31df2bd5UL, 0x3c999b9aUL, 0x4623c7adUL, 0x3ff8471aUL, 0xa341cdfbUL,\n-    0xbc88d684UL, 0x179f5b21UL, 0x3ff857f4UL, 0xf8b216d0UL, 0xbc5ba748UL,\n-    0x9b4492edUL, 0x3ff868d9UL, 0x9bd4f6baUL, 0xbc9fc6f8UL, 0xd931a436UL,\n-    0x3ff879caUL, 0xd2db47bdUL, 0x3c85d2d7UL, 0xd98a6699UL, 0x3ff88ac7UL,\n-    0xf37cb53aUL, 0x3c9994c2UL, 0xa478580fUL, 0x3ff89bd0UL, 0x4475202aUL,\n-    0x3c9d5395UL, 0x422aa0dbUL, 0x3ff8ace5UL, 0x56864b27UL, 0x3c96e9f1UL,\n-    0xbad61778UL, 0x3ff8be05UL, 0xfc43446eUL, 0x3c9ecb5eUL, 0x16b5448cUL,\n-    0x3ff8cf32UL, 0x32e9e3aaUL, 0xbc70d55eUL, 0x5e0866d9UL, 0x3ff8e06aUL,\n-    0x6fc9b2e6UL, 0xbc97114aUL, 0x99157736UL, 0x3ff8f1aeUL, 0xa2e3976cUL,\n-    0x3c85cc13UL, 0xd0282c8aUL, 0x3ff902feUL, 0x85fe3fd2UL, 0x3c9592caUL,\n-    0x0b91ffc6UL, 0x3ff9145bUL, 0x2e582524UL, 0xbc9dd679UL, 0x53aa2fe2UL,\n-    0x3ff925c3UL, 0xa639db7fUL, 0xbc83455fUL, 0xb0cdc5e5UL, 0x3ff93737UL,\n-    0x81b57ebcUL, 0xbc675fc7UL, 0x2b5f98e5UL, 0x3ff948b8UL, 0x797d2d99UL,\n-    0xbc8dc3d6UL, 0xcbc8520fUL, 0x3ff95a44UL, 0x96a5f039UL, 0xbc764b7cUL,\n-    0x9a7670b3UL, 0x3ff96bddUL, 0x7f19c896UL, 0xbc5ba596UL, 0x9fde4e50UL,\n-    0x3ff97d82UL, 0x7c1b85d1UL, 0xbc9d185bUL, 0xe47a22a2UL, 0x3ff98f33UL,\n-    0xa24c78ecUL, 0x3c7cabdaUL, 0x70ca07baUL, 0x3ff9a0f1UL, 0x91cee632UL,\n-    0xbc9173bdUL, 0x4d53fe0dUL, 0x3ff9b2bbUL, 0x4df6d518UL, 0xbc9dd84eUL,\n-    0x82a3f090UL, 0x3ff9c491UL, 0xb071f2beUL, 0x3c7c7c46UL, 0x194bb8d5UL,\n-    0x3ff9d674UL, 0xa3dd8233UL, 0xbc9516beUL, 0x19e32323UL, 0x3ff9e863UL,\n-    0x78e64c6eUL, 0x3c7824caUL, 0x8d07f29eUL, 0x3ff9fa5eUL, 0xaaf1faceUL,\n-    0xbc84a9ceUL, 0x7b5de565UL, 0x3ffa0c66UL, 0x5d1cd533UL, 0xbc935949UL,\n-    0xed8eb8bbUL, 0x3ffa1e7aUL, 0xee8be70eUL, 0x3c9c6618UL, 0xec4a2d33UL,\n-    0x3ffa309bUL, 0x7ddc36abUL, 0x3c96305cUL, 0x80460ad8UL, 0x3ffa42c9UL,\n-    0x589fb120UL, 0xbc9aa780UL, 0xb23e255dUL, 0x3ffa5503UL, 0xdb8d41e1UL,\n-    0xbc9d2f6eUL, 0x8af46052UL, 0x3ffa674aUL, 0x30670366UL, 0x3c650f56UL,\n-    0x1330b358UL, 0x3ffa799eUL, 0xcac563c7UL, 0x3c9bcb7eUL, 0x53c12e59UL,\n-    0x3ffa8bfeUL, 0xb2ba15a9UL, 0xbc94f867UL, 0x5579fdbfUL, 0x3ffa9e6bUL,\n-    0x0ef7fd31UL, 0x3c90fac9UL, 0x21356ebaUL, 0x3ffab0e5UL, 0xdae94545UL,\n-    0x3c889c31UL, 0xbfd3f37aUL, 0x3ffac36bUL, 0xcae76cd0UL, 0xbc8f9234UL,\n-    0x3a3c2774UL, 0x3ffad5ffUL, 0xb6b1b8e5UL, 0x3c97ef3bUL, 0x995ad3adUL,\n-    0x3ffae89fUL, 0x345dcc81UL, 0x3c97a1cdUL, 0xe622f2ffUL, 0x3ffafb4cUL,\n-    0x0f315ecdUL, 0xbc94b2fcUL, 0x298db666UL, 0x3ffb0e07UL, 0x4c80e425UL,\n-    0xbc9bdef5UL, 0x6c9a8952UL, 0x3ffb20ceUL, 0x4a0756ccUL, 0x3c94dd02UL,\n-    0xb84f15fbUL, 0x3ffb33a2UL, 0x3084d708UL, 0xbc62805eUL, 0x15b749b1UL,\n-    0x3ffb4684UL, 0xe9df7c90UL, 0xbc7f763dUL, 0x8de5593aUL, 0x3ffb5972UL,\n-    0xbbba6de3UL, 0xbc9c71dfUL, 0x29f1c52aUL, 0x3ffb6c6eUL, 0x52883f6eUL,\n-    0x3c92a8f3UL, 0xf2fb5e47UL, 0x3ffb7f76UL, 0x7e54ac3bUL, 0xbc75584fUL,\n-    0xf22749e4UL, 0x3ffb928cUL, 0x54cb65c6UL, 0xbc9b7216UL, 0x30a1064aUL,\n-    0x3ffba5b0UL, 0x0e54292eUL, 0xbc9efcd3UL, 0xb79a6f1fUL, 0x3ffbb8e0UL,\n-    0xc9696205UL, 0xbc3f52d1UL, 0x904bc1d2UL, 0x3ffbcc1eUL, 0x7a2d9e84UL,\n-    0x3c823dd0UL, 0xc3f3a207UL, 0x3ffbdf69UL, 0x60ea5b53UL, 0xbc3c2623UL,\n-    0x5bd71e09UL, 0x3ffbf2c2UL, 0x3f6b9c73UL, 0xbc9efdcaUL, 0x6141b33dUL,\n-    0x3ffc0628UL, 0xa1fbca34UL, 0xbc8d8a5aUL, 0xdd85529cUL, 0x3ffc199bUL,\n-    0x895048ddUL, 0x3c811065UL, 0xd9fa652cUL, 0x3ffc2d1cUL, 0x17c8a5d7UL,\n-    0xbc96e516UL, 0x5fffd07aUL, 0x3ffc40abUL, 0xe083c60aUL, 0x3c9b4537UL,\n-    0x78fafb22UL, 0x3ffc5447UL, 0x2493b5afUL, 0x3c912f07UL, 0x2e57d14bUL,\n-    0x3ffc67f1UL, 0xff483cadUL, 0x3c92884dUL, 0x8988c933UL, 0x3ffc7ba8UL,\n-    0xbe255559UL, 0xbc8e76bbUL, 0x9406e7b5UL, 0x3ffc8f6dUL, 0x48805c44UL,\n-    0x3c71acbcUL, 0x5751c4dbUL, 0x3ffca340UL, 0xd10d08f5UL, 0xbc87f2beUL,\n-    0xdcef9069UL, 0x3ffcb720UL, 0xd1e949dbUL, 0x3c7503cbUL, 0x2e6d1675UL,\n-    0x3ffccb0fUL, 0x86009092UL, 0xbc7d220fUL, 0x555dc3faUL, 0x3ffcdf0bUL,\n-    0x53829d72UL, 0xbc8dd83bUL, 0x5b5bab74UL, 0x3ffcf315UL, 0xb86dff57UL,\n-    0xbc9a08e9UL, 0x4a07897cUL, 0x3ffd072dUL, 0x43797a9cUL, 0xbc9cbc37UL,\n-    0x2b08c968UL, 0x3ffd1b53UL, 0x219a36eeUL, 0x3c955636UL, 0x080d89f2UL,\n-    0x3ffd2f87UL, 0x719d8578UL, 0xbc9d487bUL, 0xeacaa1d6UL, 0x3ffd43c8UL,\n-    0xbf5a1614UL, 0x3c93db53UL, 0xdcfba487UL, 0x3ffd5818UL, 0xd75b3707UL,\n-    0x3c82ed02UL, 0xe862e6d3UL, 0x3ffd6c76UL, 0x4a8165a0UL, 0x3c5fe87aUL,\n-    0x16c98398UL, 0x3ffd80e3UL, 0x8beddfe8UL, 0xbc911ec1UL, 0x71ff6075UL,\n-    0x3ffd955dUL, 0xbb9af6beUL, 0x3c9a052dUL, 0x03db3285UL, 0x3ffda9e6UL,\n-    0x696db532UL, 0x3c9c2300UL, 0xd63a8315UL, 0x3ffdbe7cUL, 0x926b8be4UL,\n-    0xbc9b76f1UL, 0xf301b460UL, 0x3ffdd321UL, 0x78f018c3UL, 0x3c92da57UL,\n-    0x641c0658UL, 0x3ffde7d5UL, 0x8e79ba8fUL, 0xbc9ca552UL, 0x337b9b5fUL,\n-    0x3ffdfc97UL, 0x4f184b5cUL, 0xbc91a5cdUL, 0x6b197d17UL, 0x3ffe1167UL,\n-    0xbd5c7f44UL, 0xbc72b529UL, 0x14f5a129UL, 0x3ffe2646UL, 0x817a1496UL,\n-    0xbc97b627UL, 0x3b16ee12UL, 0x3ffe3b33UL, 0x31fdc68bUL, 0xbc99f4a4UL,\n-    0xe78b3ff6UL, 0x3ffe502eUL, 0x80a9cc8fUL, 0x3c839e89UL, 0x24676d76UL,\n-    0x3ffe6539UL, 0x7522b735UL, 0xbc863ff8UL, 0xfbc74c83UL, 0x3ffe7a51UL,\n-    0xca0c8de2UL, 0x3c92d522UL, 0x77cdb740UL, 0x3ffe8f79UL, 0x80b054b1UL,\n-    0xbc910894UL, 0xa2a490daUL, 0x3ffea4afUL, 0x179c2893UL, 0xbc9e9c23UL,\n-    0x867cca6eUL, 0x3ffeb9f4UL, 0x2293e4f2UL, 0x3c94832fUL, 0x2d8e67f1UL,\n-    0x3ffecf48UL, 0xb411ad8cUL, 0xbc9c93f3UL, 0xa2188510UL, 0x3ffee4aaUL,\n-    0xa487568dUL, 0x3c91c68dUL, 0xee615a27UL, 0x3ffefa1bUL, 0x86a4b6b0UL,\n-    0x3c9dc7f4UL, 0x1cb6412aUL, 0x3fff0f9cUL, 0x65181d45UL, 0xbc932200UL,\n-    0x376bba97UL, 0x3fff252bUL, 0xbf0d8e43UL, 0x3c93a1a5UL, 0x48dd7274UL,\n-    0x3fff3ac9UL, 0x3ed837deUL, 0xbc795a5aUL, 0x5b6e4540UL, 0x3fff5076UL,\n-    0x2dd8a18bUL, 0x3c99d3e1UL, 0x798844f8UL, 0x3fff6632UL, 0x3539343eUL,\n-    0x3c9fa37bUL, 0xad9cbe14UL, 0x3fff7bfdUL, 0xd006350aUL, 0xbc9dbb12UL,\n-    0x02243c89UL, 0x3fff91d8UL, 0xa779f689UL, 0xbc612ea8UL, 0x819e90d8UL,\n-    0x3fffa7c1UL, 0xf3a5931eUL, 0x3c874853UL, 0x3692d514UL, 0x3fffbdbaUL,\n-    0x15098eb6UL, 0xbc796773UL, 0x2b8f71f1UL, 0x3fffd3c2UL, 0x966579e7UL,\n-    0x3c62eb74UL, 0x6b2a23d9UL, 0x3fffe9d9UL, 0x7442fde3UL, 0x3c74a603UL,\n-    0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL, 0x6fba4e77UL,\n-    0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL, 0xfefa39efUL, 0x3fe62e42UL,\n-    0x00000000UL, 0x00000000UL, 0xfefa39efUL, 0x3fe62e42UL, 0xfefa39efUL,\n-    0xbfe62e42UL, 0xf8000000UL, 0xffffffffUL, 0xf8000000UL, 0xffffffffUL,\n-    0x00000000UL, 0x80000000UL, 0x00000000UL, 0x00000000UL\n-\n-};\n-\n-ATTRIBUTE_ALIGNED(8) static const double _DOUBLE2 = 2.0;\n-ATTRIBUTE_ALIGNED(8) static const double _DOUBLE0 = 0.0;\n-ATTRIBUTE_ALIGNED(8) static const double _DOUBLE0DOT5 = 0.5;\n-\n-\/\/registers,\n-\/\/ input: xmm0, xmm1\n-\/\/ scratch: xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7\n-\/\/          eax, edx, ecx, ebx\n-\n-\/\/ Code generated by Intel C compiler for LIBM library\n-\n-void MacroAssembler::fast_pow(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2, L_2TAG_PACKET_5_0_2, L_2TAG_PACKET_6_0_2, L_2TAG_PACKET_7_0_2;\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, L_2TAG_PACKET_10_0_2, L_2TAG_PACKET_11_0_2;\n-  Label L_2TAG_PACKET_12_0_2, L_2TAG_PACKET_13_0_2, L_2TAG_PACKET_14_0_2, L_2TAG_PACKET_15_0_2;\n-  Label L_2TAG_PACKET_16_0_2, L_2TAG_PACKET_17_0_2, L_2TAG_PACKET_18_0_2, L_2TAG_PACKET_19_0_2;\n-  Label L_2TAG_PACKET_20_0_2, L_2TAG_PACKET_21_0_2, L_2TAG_PACKET_22_0_2, L_2TAG_PACKET_23_0_2;\n-  Label L_2TAG_PACKET_24_0_2, L_2TAG_PACKET_25_0_2, L_2TAG_PACKET_26_0_2, L_2TAG_PACKET_27_0_2;\n-  Label L_2TAG_PACKET_28_0_2, L_2TAG_PACKET_29_0_2, L_2TAG_PACKET_30_0_2, L_2TAG_PACKET_31_0_2;\n-  Label L_2TAG_PACKET_32_0_2, L_2TAG_PACKET_33_0_2, L_2TAG_PACKET_34_0_2, L_2TAG_PACKET_35_0_2;\n-  Label L_2TAG_PACKET_36_0_2, L_2TAG_PACKET_37_0_2, L_2TAG_PACKET_38_0_2, L_2TAG_PACKET_39_0_2;\n-  Label L_2TAG_PACKET_40_0_2, L_2TAG_PACKET_41_0_2, L_2TAG_PACKET_42_0_2, L_2TAG_PACKET_43_0_2;\n-  Label L_2TAG_PACKET_44_0_2, L_2TAG_PACKET_45_0_2, L_2TAG_PACKET_46_0_2, L_2TAG_PACKET_47_0_2;\n-  Label L_2TAG_PACKET_48_0_2, L_2TAG_PACKET_49_0_2, L_2TAG_PACKET_50_0_2, L_2TAG_PACKET_51_0_2;\n-  Label L_2TAG_PACKET_52_0_2, L_2TAG_PACKET_53_0_2, L_2TAG_PACKET_54_0_2, L_2TAG_PACKET_55_0_2;\n-  Label L_2TAG_PACKET_56_0_2, L_2TAG_PACKET_57_0_2, L_2TAG_PACKET_58_0_2, start;\n-  Label L_NOT_DOUBLE2, L_NOT_DOUBLE0DOT5;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-\n-  address static_const_table_pow = (address)_static_const_table_pow;\n-  address DOUBLE2 = (address) &_DOUBLE2;\n-  address DOUBLE0 = (address) &_DOUBLE0;\n-  address DOUBLE0DOT5 = (address) &_DOUBLE0DOT5;\n-\n-  subl(rsp, 120);\n-  movl(Address(rsp, 64), tmp);\n-  lea(tmp, ExternalAddress(static_const_table_pow));\n-  movsd(xmm0, Address(rsp, 128));\n-  movsd(xmm1, Address(rsp, 136));\n-\n-  \/\/ Special case: pow(x, 2.0) => x * x\n-  ucomisd(xmm1, ExternalAddress(DOUBLE2));\n-  jccb(Assembler::notEqual, L_NOT_DOUBLE2);\n-  jccb(Assembler::parity, L_NOT_DOUBLE2);\n-  mulsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_NOT_DOUBLE2);\n-  \/\/ Special case: pow(x, 0.5) => sqrt(x)\n-  ucomisd(xmm1, ExternalAddress(DOUBLE0DOT5)); \/\/ For pow(x, y), check whether y == 0.5\n-  jccb(Assembler::notEqual, L_NOT_DOUBLE0DOT5);\n-  jccb(Assembler::parity, L_NOT_DOUBLE0DOT5);\n-  ucomisd(xmm0, ExternalAddress(DOUBLE0));\n-  \/\/ According to the API specs, pow(-0.0, 0.5) = 0.0 and sqrt(-0.0) = -0.0.\n-  \/\/ So pow(-0.0, 0.5) shouldn't be replaced with sqrt(-0.0).\n-  \/\/ -0.0\/+0.0 are both excluded since floating-point comparison doesn't distinguish -0.0 from +0.0.\n-  jccb(Assembler::belowEqual, L_NOT_DOUBLE0DOT5); \/\/ pow(x, 0.5) => sqrt(x) only for x > 0.0\n-  sqrtsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_NOT_DOUBLE0DOT5);\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  movl(ecx, 1069088768);\n-  movdl(xmm7, ecx);\n-  movsd(Address(rsp, 16), xmm1);\n-  xorpd(xmm1, xmm1);\n-  movl(edx, 30704);\n-  pinsrw(xmm1, edx, 3);\n-  movsd(Address(rsp, 8), xmm0);\n-  movdqu(xmm3, xmm0);\n-  movl(edx, 8192);\n-  movdl(xmm4, edx);\n-  movdqu(xmm6, Address(tmp, 8240));\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  psllq(xmm0, 5);\n-  movsd(xmm2, Address(tmp, 8256));\n-  psrlq(xmm0, 34);\n-  movl(edx, eax);\n-  andl(edx, 32752);\n-  subl(edx, 16368);\n-  movl(ecx, edx);\n-  sarl(edx, 31);\n-  addl(ecx, edx);\n-  xorl(ecx, edx);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm3, 12);\n-  addl(ecx, 16);\n-  bsrl(ecx, ecx);\n-  psrlq(xmm3, 12);\n-  movl(Address(rsp, 24), rsi);\n-  subl(eax, 16);\n-  cmpl(eax, 32736);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_0_0_2);\n-  movl(rsi, 0);\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  mulss(xmm0, xmm7);\n-  movl(edx, -1);\n-  subl(ecx, 4);\n-  shll(edx);\n-  movdl(xmm5, edx);\n-  por(xmm3, xmm1);\n-  subl(eax, 16351);\n-  cmpl(eax, 1);\n-  jcc(Assembler::belowEqual, L_2TAG_PACKET_2_0_2);\n-  paddd(xmm0, xmm4);\n-  psllq(xmm5, 32);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  pand(xmm5, xmm3);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  pand(xmm0, xmm6);\n-  subsd(xmm3, xmm5);\n-  subl(eax, 1);\n-  sarl(eax, 4);\n-  cvtsi2sdl(xmm7, eax);\n-  mulpd(xmm5, xmm0);\n-\n-  bind(L_2TAG_PACKET_4_0_2);\n-  mulsd(xmm3, xmm0);\n-  movdqu(xmm1, Address(tmp, 8272));\n-  subsd(xmm5, xmm2);\n-  movdqu(xmm4, Address(tmp, 8288));\n-  movl(ecx, eax);\n-  sarl(eax, 31);\n-  addl(ecx, eax);\n-  xorl(eax, ecx);\n-  addl(eax, 1);\n-  bsrl(eax, eax);\n-  unpcklpd(xmm5, xmm3);\n-  movdqu(xmm6, Address(tmp, 8304));\n-  addsd(xmm3, xmm5);\n-  andl(edx, 16760832);\n-  shrl(edx, 10);\n-  addpd(xmm5, Address(tmp, edx, Address::times_1, -3616));\n-  movdqu(xmm0, Address(tmp, 8320));\n-  pshufd(xmm2, xmm3, 68);\n-  mulsd(xmm3, xmm3);\n-  mulpd(xmm1, xmm2);\n-  mulpd(xmm4, xmm2);\n-  addsd(xmm5, xmm7);\n-  mulsd(xmm2, xmm3);\n-  addpd(xmm6, xmm1);\n-  mulsd(xmm3, xmm3);\n-  addpd(xmm0, xmm4);\n-  movsd(xmm1, Address(rsp, 16));\n-  movzwl(ecx, Address(rsp, 22));\n-  pshufd(xmm7, xmm5, 238);\n-  movsd(xmm4, Address(tmp, 8368));\n-  mulpd(xmm6, xmm2);\n-  pshufd(xmm3, xmm3, 68);\n-  mulpd(xmm0, xmm2);\n-  shll(eax, 4);\n-  subl(eax, 15872);\n-  andl(ecx, 32752);\n-  addl(eax, ecx);\n-  mulpd(xmm3, xmm6);\n-  cmpl(eax, 624);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_5_0_2);\n-  xorpd(xmm6, xmm6);\n-  movl(edx, 17080);\n-  pinsrw(xmm6, edx, 3);\n-  movdqu(xmm2, xmm1);\n-  pand(xmm4, xmm1);\n-  subsd(xmm1, xmm4);\n-  mulsd(xmm4, xmm5);\n-  addsd(xmm0, xmm7);\n-  mulsd(xmm1, xmm5);\n-  movdqu(xmm7, xmm6);\n-  addsd(xmm6, xmm4);\n-  addpd(xmm3, xmm0);\n-  movdl(edx, xmm6);\n-  subsd(xmm6, xmm7);\n-  pshufd(xmm0, xmm3, 238);\n-  subsd(xmm4, xmm6);\n-  addsd(xmm0, xmm3);\n-  movl(ecx, edx);\n-  andl(edx, 255);\n-  addl(edx, edx);\n-  movdqu(xmm5, Address(tmp, edx, Address::times_8, 8384));\n-  addsd(xmm4, xmm1);\n-  mulsd(xmm2, xmm0);\n-  movdqu(xmm7, Address(tmp, 12480));\n-  movdqu(xmm3, Address(tmp, 12496));\n-  shll(ecx, 12);\n-  xorl(ecx, rsi);\n-  andl(ecx, -1048576);\n-  movdl(xmm6, ecx);\n-  addsd(xmm2, xmm4);\n-  movsd(xmm1, Address(tmp, 12512));\n-  pshufd(xmm0, xmm2, 68);\n-  pshufd(xmm4, xmm2, 68);\n-  mulpd(xmm0, xmm0);\n-  movl(rsi, Address(rsp, 24));\n-  mulpd(xmm7, xmm4);\n-  pshufd(xmm6, xmm6, 17);\n-  mulsd(xmm1, xmm2);\n-  mulsd(xmm0, xmm0);\n-  paddd(xmm5, xmm6);\n-  addpd(xmm3, xmm7);\n-  mulsd(xmm1, xmm5);\n-  pshufd(xmm6, xmm5, 238);\n-  mulpd(xmm0, xmm3);\n-  addsd(xmm1, xmm6);\n-  pshufd(xmm3, xmm0, 238);\n-  mulsd(xmm0, xmm5);\n-  mulsd(xmm3, xmm5);\n-  addsd(xmm0, xmm1);\n-  addsd(xmm0, xmm3);\n-  addsd(xmm0, xmm5);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_7_0_2);\n-  movsd(xmm0, Address(rsp, 128));\n-  movsd(xmm1, Address(rsp, 136));\n-  mulsd(xmm0, xmm1);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  addl(eax, 16);\n-  movl(edx, 32752);\n-  andl(edx, eax);\n-  cmpl(edx, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_8_0_2);\n-  testl(eax, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_9_0_2);\n-\n-  bind(L_2TAG_PACKET_10_0_2);\n-  movl(ecx, Address(rsp, 16));\n-  xorl(edx, edx);\n-  testl(ecx, ecx);\n-  movl(ecx, 1);\n-  cmovl(Assembler::notEqual, edx, ecx);\n-  orl(edx, Address(rsp, 20));\n-  cmpl(edx, 1072693248);\n-  jcc(Assembler::equal, L_2TAG_PACKET_7_0_2);\n-  movsd(xmm0, Address(rsp, 8));\n-  movsd(xmm3, Address(rsp, 8));\n-  movdl(edx, xmm3);\n-  psrlq(xmm3, 32);\n-  movdl(ecx, xmm3);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_11_0_2);\n-  xorpd(xmm3, xmm3);\n-  movl(eax, 18416);\n-  pinsrw(xmm3, eax, 3);\n-  mulsd(xmm0, xmm3);\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  movdqu(xmm3, xmm0);\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  movl(ecx, 18416);\n-  psllq(xmm0, 5);\n-  movsd(xmm2, Address(tmp, 8256));\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm3, 12);\n-  movdqu(xmm6, Address(tmp, 8240));\n-  psrlq(xmm3, 12);\n-  mulss(xmm0, xmm7);\n-  movl(edx, -1024);\n-  movdl(xmm5, edx);\n-  por(xmm3, xmm1);\n-  paddd(xmm0, xmm4);\n-  psllq(xmm5, 32);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  pand(xmm5, xmm3);\n-  movl(rsi, 0);\n-  pand(xmm0, xmm6);\n-  subsd(xmm3, xmm5);\n-  andl(eax, 32752);\n-  subl(eax, 18416);\n-  sarl(eax, 4);\n-  cvtsi2sdl(xmm7, eax);\n-  mulpd(xmm5, xmm0);\n-  jmp(L_2TAG_PACKET_4_0_2);\n-\n-  bind(L_2TAG_PACKET_12_0_2);\n-  movl(ecx, Address(rsp, 16));\n-  xorl(edx, edx);\n-  testl(ecx, ecx);\n-  movl(ecx, 1);\n-  cmovl(Assembler::notEqual, edx, ecx);\n-  orl(edx, Address(rsp, 20));\n-  cmpl(edx, 1072693248);\n-  jcc(Assembler::equal, L_2TAG_PACKET_7_0_2);\n-  movsd(xmm0, Address(rsp, 8));\n-  movsd(xmm3, Address(rsp, 8));\n-  movdl(edx, xmm3);\n-  psrlq(xmm3, 32);\n-  movdl(ecx, xmm3);\n-  orl(edx, ecx);\n-  cmpl(edx, 0);\n-  jcc(Assembler::equal, L_2TAG_PACKET_11_0_2);\n-  xorpd(xmm3, xmm3);\n-  movl(eax, 18416);\n-  pinsrw(xmm3, eax, 3);\n-  mulsd(xmm0, xmm3);\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 16368);\n-  pinsrw(xmm2, eax, 3);\n-  movdqu(xmm3, xmm0);\n-  pextrw(eax, xmm0, 3);\n-  por(xmm0, xmm2);\n-  movl(ecx, 18416);\n-  psllq(xmm0, 5);\n-  movsd(xmm2, Address(tmp, 8256));\n-  psrlq(xmm0, 34);\n-  rcpss(xmm0, xmm0);\n-  psllq(xmm3, 12);\n-  movdqu(xmm6, Address(tmp, 8240));\n-  psrlq(xmm3, 12);\n-  mulss(xmm0, xmm7);\n-  movl(edx, -1024);\n-  movdl(xmm5, edx);\n-  por(xmm3, xmm1);\n-  paddd(xmm0, xmm4);\n-  psllq(xmm5, 32);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  pand(xmm5, xmm3);\n-  movl(rsi, INT_MIN);\n-  pand(xmm0, xmm6);\n-  subsd(xmm3, xmm5);\n-  andl(eax, 32752);\n-  subl(eax, 18416);\n-  sarl(eax, 4);\n-  cvtsi2sdl(xmm7, eax);\n-  mulpd(xmm5, xmm0);\n-  jmp(L_2TAG_PACKET_4_0_2);\n-\n-  bind(L_2TAG_PACKET_5_0_2);\n-  cmpl(eax, 0);\n-  jcc(Assembler::less, L_2TAG_PACKET_13_0_2);\n-  cmpl(eax, 752);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_14_0_2);\n-\n-  bind(L_2TAG_PACKET_15_0_2);\n-  addsd(xmm0, xmm7);\n-  movsd(xmm2, Address(tmp, 12544));\n-  addpd(xmm3, xmm0);\n-  xorpd(xmm6, xmm6);\n-  movl(eax, 17080);\n-  pinsrw(xmm6, eax, 3);\n-  pshufd(xmm0, xmm3, 238);\n-  addsd(xmm0, xmm3);\n-  movdqu(xmm3, xmm5);\n-  addsd(xmm5, xmm0);\n-  movdqu(xmm4, xmm2);\n-  subsd(xmm3, xmm5);\n-  movdqu(xmm7, xmm5);\n-  pand(xmm5, xmm2);\n-  movdqu(xmm2, xmm1);\n-  pand(xmm4, xmm1);\n-  subsd(xmm7, xmm5);\n-  addsd(xmm0, xmm3);\n-  subsd(xmm1, xmm4);\n-  mulsd(xmm4, xmm5);\n-  addsd(xmm0, xmm7);\n-  mulsd(xmm2, xmm0);\n-  movdqu(xmm7, xmm6);\n-  mulsd(xmm1, xmm5);\n-  addsd(xmm6, xmm4);\n-  movdl(eax, xmm6);\n-  subsd(xmm6, xmm7);\n-  addsd(xmm2, xmm1);\n-  movdqu(xmm7, Address(tmp, 12480));\n-  movdqu(xmm3, Address(tmp, 12496));\n-  subsd(xmm4, xmm6);\n-  pextrw(edx, xmm6, 3);\n-  movl(ecx, eax);\n-  andl(eax, 255);\n-  addl(eax, eax);\n-  movdqu(xmm5, Address(tmp, eax, Address::times_8, 8384));\n-  addsd(xmm2, xmm4);\n-  sarl(ecx, 8);\n-  movl(eax, ecx);\n-  sarl(ecx, 1);\n-  subl(eax, ecx);\n-  shll(ecx, 20);\n-  xorl(ecx, rsi);\n-  movdl(xmm6, ecx);\n-  movsd(xmm1, Address(tmp, 12512));\n-  andl(edx, 32767);\n-  cmpl(edx, 16529);\n-  jcc(Assembler::above, L_2TAG_PACKET_14_0_2);\n-  pshufd(xmm0, xmm2, 68);\n-  pshufd(xmm4, xmm2, 68);\n-  mulpd(xmm0, xmm0);\n-  mulpd(xmm7, xmm4);\n-  pshufd(xmm6, xmm6, 17);\n-  mulsd(xmm1, xmm2);\n-  mulsd(xmm0, xmm0);\n-  paddd(xmm5, xmm6);\n-  addpd(xmm3, xmm7);\n-  mulsd(xmm1, xmm5);\n-  pshufd(xmm6, xmm5, 238);\n-  mulpd(xmm0, xmm3);\n-  addsd(xmm1, xmm6);\n-  pshufd(xmm3, xmm0, 238);\n-  mulsd(xmm0, xmm5);\n-  mulsd(xmm3, xmm5);\n-  shll(eax, 4);\n-  xorpd(xmm4, xmm4);\n-  addl(eax, 16368);\n-  pinsrw(xmm4, eax, 3);\n-  addsd(xmm0, xmm1);\n-  movl(rsi, Address(rsp, 24));\n-  addsd(xmm0, xmm3);\n-  movdqu(xmm1, xmm0);\n-  addsd(xmm0, xmm5);\n-  mulsd(xmm0, xmm4);\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_16_0_2);\n-  cmpl(eax, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_17_0_2);\n-\n-  bind(L_2TAG_PACKET_18_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_8_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movsd(xmm0, Address(rsp, 8));\n-  movdqu(xmm2, xmm0);\n-  movdl(eax, xmm2);\n-  psrlq(xmm2, 20);\n-  movdl(edx, xmm2);\n-  orl(eax, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_19_0_2);\n-  addsd(xmm0, xmm0);\n-  movdl(eax, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(edx, xmm1);\n-  movl(ecx, edx);\n-  addl(edx, edx);\n-  orl(eax, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_20_0_2);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_20_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  pinsrw(xmm0, eax, 3);\n-  movl(edx, 29);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_22_0_2);\n-  movsd(xmm0, Address(rsp, 16));\n-  addpd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_19_0_2);\n-  movdl(eax, xmm1);\n-  movdqu(xmm2, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(edx, xmm1);\n-  movl(ecx, edx);\n-  addl(edx, edx);\n-  orl(eax, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_23_0_2);\n-  pextrw(eax, xmm2, 3);\n-  andl(eax, 32752);\n-  cmpl(eax, 32752);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_24_0_2);\n-  movdl(eax, xmm2);\n-  psrlq(xmm2, 20);\n-  movdl(edx, xmm2);\n-  orl(eax, edx);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_22_0_2);\n-\n-  bind(L_2TAG_PACKET_24_0_2);\n-  pextrw(eax, xmm0, 3);\n-  testl(eax, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_25_0_2);\n-  testl(ecx, INT_MIN);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_26_0_2);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_27_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movdl(eax, xmm1);\n-  testl(eax, 1);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_28_0_2);\n-  testl(eax, 2);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_29_0_2);\n-  jmp(L_2TAG_PACKET_28_0_2);\n-\n-  bind(L_2TAG_PACKET_25_0_2);\n-  shrl(ecx, 20);\n-  andl(ecx, 2047);\n-  cmpl(ecx, 1075);\n-  jcc(Assembler::above, L_2TAG_PACKET_28_0_2);\n-  jcc(Assembler::equal, L_2TAG_PACKET_30_0_2);\n-  cmpl(ecx, 1074);\n-  jcc(Assembler::above, L_2TAG_PACKET_27_0_2);\n-  cmpl(ecx, 1023);\n-  jcc(Assembler::below, L_2TAG_PACKET_28_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movl(eax, 17208);\n-  xorpd(xmm3, xmm3);\n-  pinsrw(xmm3, eax, 3);\n-  movdqu(xmm4, xmm3);\n-  addsd(xmm3, xmm1);\n-  subsd(xmm4, xmm3);\n-  addsd(xmm1, xmm4);\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32752);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_28_0_2);\n-  movdl(eax, xmm3);\n-  andl(eax, 1);\n-  jcc(Assembler::equal, L_2TAG_PACKET_28_0_2);\n-\n-  bind(L_2TAG_PACKET_29_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32768);\n-  jcc(Assembler::equal, L_2TAG_PACKET_18_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32768);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_28_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_26_0_2);\n-\n-  bind(L_2TAG_PACKET_31_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32752);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_30_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movdl(eax, xmm1);\n-  andl(eax, 1);\n-  jcc(Assembler::equal, L_2TAG_PACKET_28_0_2);\n-  jmp(L_2TAG_PACKET_29_0_2);\n-\n-  bind(L_2TAG_PACKET_32_0_2);\n-  movdl(eax, xmm1);\n-  psrlq(xmm1, 20);\n-  movdl(edx, xmm1);\n-  orl(eax, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_33_0_2);\n-  movsd(xmm0, Address(rsp, 16));\n-  addsd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_33_0_2);\n-  movsd(xmm0, Address(rsp, 8));\n-  pextrw(eax, xmm0, 3);\n-  cmpl(eax, 49136);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_34_0_2);\n-  movdl(ecx, xmm0);\n-  psrlq(xmm0, 20);\n-  movdl(edx, xmm0);\n-  orl(ecx, edx);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_34_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32760);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_34_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  andl(eax, 32752);\n-  subl(eax, 16368);\n-  pextrw(edx, xmm1, 3);\n-  xorpd(xmm0, xmm0);\n-  xorl(eax, edx);\n-  andl(eax, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_18_0_2);\n-  movl(ecx, 32752);\n-  pinsrw(xmm0, ecx, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_35_0_2);\n-  movdl(eax, xmm1);\n-  cmpl(edx, 17184);\n-  jcc(Assembler::above, L_2TAG_PACKET_36_0_2);\n-  testl(eax, 1);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_37_0_2);\n-  testl(eax, 2);\n-  jcc(Assembler::equal, L_2TAG_PACKET_38_0_2);\n-  jmp(L_2TAG_PACKET_39_0_2);\n-\n-  bind(L_2TAG_PACKET_36_0_2);\n-  testl(eax, 1);\n-  jcc(Assembler::equal, L_2TAG_PACKET_38_0_2);\n-  jmp(L_2TAG_PACKET_39_0_2);\n-\n-  bind(L_2TAG_PACKET_9_0_2);\n-  movsd(xmm2, Address(rsp, 8));\n-  movdl(eax, xmm2);\n-  psrlq(xmm2, 31);\n-  movdl(ecx, xmm2);\n-  orl(eax, ecx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_11_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  pextrw(edx, xmm1, 3);\n-  movdl(eax, xmm1);\n-  movdqu(xmm2, xmm1);\n-  psrlq(xmm2, 32);\n-  movdl(ecx, xmm2);\n-  addl(ecx, ecx);\n-  orl(ecx, eax);\n-  jcc(Assembler::equal, L_2TAG_PACKET_40_0_2);\n-  andl(edx, 32752);\n-  cmpl(edx, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_32_0_2);\n-  cmpl(edx, 17200);\n-  jcc(Assembler::above, L_2TAG_PACKET_38_0_2);\n-  cmpl(edx, 17184);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_35_0_2);\n-  cmpl(edx, 16368);\n-  jcc(Assembler::below, L_2TAG_PACKET_37_0_2);\n-  movl(eax, 17208);\n-  xorpd(xmm2, xmm2);\n-  pinsrw(xmm2, eax, 3);\n-  movdqu(xmm4, xmm2);\n-  addsd(xmm2, xmm1);\n-  subsd(xmm4, xmm2);\n-  addsd(xmm1, xmm4);\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32767);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_37_0_2);\n-  movdl(eax, xmm2);\n-  andl(eax, 1);\n-  jcc(Assembler::equal, L_2TAG_PACKET_38_0_2);\n-\n-  bind(L_2TAG_PACKET_39_0_2);\n-  xorpd(xmm1, xmm1);\n-  movl(edx, 30704);\n-  pinsrw(xmm1, edx, 3);\n-  movsd(xmm2, Address(tmp, 8256));\n-  movsd(xmm4, Address(rsp, 8));\n-  pextrw(eax, xmm4, 3);\n-  movl(edx, 8192);\n-  movdl(xmm4, edx);\n-  andl(eax, 32767);\n-  subl(eax, 16);\n-  jcc(Assembler::less, L_2TAG_PACKET_12_0_2);\n-  movl(edx, eax);\n-  andl(edx, 32752);\n-  subl(edx, 16368);\n-  movl(ecx, edx);\n-  sarl(edx, 31);\n-  addl(ecx, edx);\n-  xorl(ecx, edx);\n-  addl(ecx, 16);\n-  bsrl(ecx, ecx);\n-  movl(rsi, INT_MIN);\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_37_0_2);\n-  xorpd(xmm1, xmm1);\n-  movl(eax, 32752);\n-  pinsrw(xmm1, eax, 3);\n-  xorpd(xmm0, xmm0);\n-  mulsd(xmm0, xmm1);\n-  movl(edx, 28);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_38_0_2);\n-  xorpd(xmm1, xmm1);\n-  movl(edx, 30704);\n-  pinsrw(xmm1, edx, 3);\n-  movsd(xmm2, Address(tmp, 8256));\n-  movsd(xmm4, Address(rsp, 8));\n-  pextrw(eax, xmm4, 3);\n-  movl(edx, 8192);\n-  movdl(xmm4, edx);\n-  andl(eax, 32767);\n-  subl(eax, 16);\n-  jcc(Assembler::less, L_2TAG_PACKET_10_0_2);\n-  movl(edx, eax);\n-  andl(edx, 32752);\n-  subl(edx, 16368);\n-  movl(ecx, edx);\n-  sarl(edx, 31);\n-  addl(ecx, edx);\n-  xorl(ecx, edx);\n-  addl(ecx, 16);\n-  bsrl(ecx, ecx);\n-  movl(rsi, 0);\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_23_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_26_0_2);\n-  xorpd(xmm0, xmm0);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_13_0_2);\n-  addl(eax, 384);\n-  cmpl(eax, 0);\n-  jcc(Assembler::less, L_2TAG_PACKET_41_0_2);\n-  mulsd(xmm5, xmm1);\n-  addsd(xmm0, xmm7);\n-  shrl(rsi, 31);\n-  addpd(xmm3, xmm0);\n-  pshufd(xmm0, xmm3, 238);\n-  addsd(xmm3, xmm0);\n-  movsd(xmm4, Address(tmp, rsi, Address::times_8, 12528));\n-  mulsd(xmm1, xmm3);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  shll(rsi, 15);\n-  orl(eax, rsi);\n-  pinsrw(xmm0, eax, 3);\n-  addsd(xmm5, xmm1);\n-  movl(rsi, Address(rsp, 24));\n-  mulsd(xmm5, xmm4);\n-  addsd(xmm0, xmm5);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_41_0_2);\n-  movl(rsi, Address(rsp, 24));\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_40_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_42_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 16368);\n-  pinsrw(xmm0, eax, 3);\n-  movl(edx, 26);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_11_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movdqu(xmm2, xmm1);\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32752);\n-  cmpl(eax, 32752);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_43_0_2);\n-  movdl(eax, xmm2);\n-  psrlq(xmm2, 20);\n-  movdl(edx, xmm2);\n-  orl(eax, edx);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_22_0_2);\n-\n-  bind(L_2TAG_PACKET_43_0_2);\n-  movdl(eax, xmm1);\n-  psrlq(xmm1, 32);\n-  movdl(edx, xmm1);\n-  movl(ecx, edx);\n-  addl(edx, edx);\n-  orl(eax, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_42_0_2);\n-  shrl(edx, 21);\n-  cmpl(edx, 1075);\n-  jcc(Assembler::above, L_2TAG_PACKET_44_0_2);\n-  jcc(Assembler::equal, L_2TAG_PACKET_45_0_2);\n-  cmpl(edx, 1023);\n-  jcc(Assembler::below, L_2TAG_PACKET_44_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movl(eax, 17208);\n-  xorpd(xmm3, xmm3);\n-  pinsrw(xmm3, eax, 3);\n-  movdqu(xmm4, xmm3);\n-  addsd(xmm3, xmm1);\n-  subsd(xmm4, xmm3);\n-  addsd(xmm1, xmm4);\n-  pextrw(eax, xmm1, 3);\n-  andl(eax, 32752);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_44_0_2);\n-  movdl(eax, xmm3);\n-  andl(eax, 1);\n-  jcc(Assembler::equal, L_2TAG_PACKET_44_0_2);\n-\n-  bind(L_2TAG_PACKET_46_0_2);\n-  movsd(xmm0, Address(rsp, 8));\n-  testl(ecx, INT_MIN);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_47_0_2);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_45_0_2);\n-  movsd(xmm1, Address(rsp, 16));\n-  movdl(eax, xmm1);\n-  testl(eax, 1);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_46_0_2);\n-\n-  bind(L_2TAG_PACKET_44_0_2);\n-  testl(ecx, INT_MIN);\n-  jcc(Assembler::equal, L_2TAG_PACKET_26_0_2);\n-  xorpd(xmm0, xmm0);\n-\n-  bind(L_2TAG_PACKET_47_0_2);\n-  movl(eax, 16368);\n-  xorpd(xmm1, xmm1);\n-  pinsrw(xmm1, eax, 3);\n-  divsd(xmm1, xmm0);\n-  movdqu(xmm0, xmm1);\n-  movl(edx, 27);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_14_0_2);\n-  movsd(xmm2, Address(rsp, 8));\n-  movsd(xmm6, Address(rsp, 16));\n-  pextrw(eax, xmm2, 3);\n-  pextrw(edx, xmm6, 3);\n-  movl(ecx, 32752);\n-  andl(ecx, edx);\n-  cmpl(ecx, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_48_0_2);\n-  andl(eax, 32752);\n-  subl(eax, 16368);\n-  xorl(edx, eax);\n-  testl(edx, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_49_0_2);\n-\n-  bind(L_2TAG_PACKET_50_0_2);\n-  movl(eax, 32736);\n-  pinsrw(xmm0, eax, 3);\n-  shrl(rsi, 16);\n-  orl(eax, rsi);\n-  pinsrw(xmm1, eax, 3);\n-  movl(rsi, Address(rsp, 24));\n-  mulsd(xmm0, xmm1);\n-\n-  bind(L_2TAG_PACKET_17_0_2);\n-  movl(edx, 24);\n-\n-  bind(L_2TAG_PACKET_21_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_49_0_2);\n-  movl(eax, 16);\n-  pinsrw(xmm0, eax, 3);\n-  mulsd(xmm0, xmm0);\n-  testl(rsi, INT_MIN);\n-  jcc(Assembler::equal, L_2TAG_PACKET_51_0_2);\n-  movsd(xmm2, Address(tmp, 12560));\n-  xorpd(xmm0, xmm2);\n-\n-  bind(L_2TAG_PACKET_51_0_2);\n-  movl(rsi, Address(rsp, 24));\n-  movl(edx, 25);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_16_0_2);\n-  pextrw(ecx, xmm5, 3);\n-  pextrw(edx, xmm4, 3);\n-  movl(eax, -1);\n-  andl(ecx, 32752);\n-  subl(ecx, 16368);\n-  andl(edx, 32752);\n-  addl(edx, ecx);\n-  movl(ecx, -31);\n-  sarl(edx, 4);\n-  subl(ecx, edx);\n-  jcc(Assembler::lessEqual, L_2TAG_PACKET_52_0_2);\n-  cmpl(ecx, 20);\n-  jcc(Assembler::above, L_2TAG_PACKET_53_0_2);\n-  shll(eax);\n-\n-  bind(L_2TAG_PACKET_52_0_2);\n-  movdl(xmm0, eax);\n-  psllq(xmm0, 32);\n-  pand(xmm0, xmm5);\n-  subsd(xmm5, xmm0);\n-  addsd(xmm5, xmm1);\n-  mulsd(xmm0, xmm4);\n-  mulsd(xmm5, xmm4);\n-  addsd(xmm0, xmm5);\n-\n-  bind(L_2TAG_PACKET_53_0_2);\n-  movl(edx, 25);\n-  jmp(L_2TAG_PACKET_21_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movzwl(ecx, Address(rsp, 22));\n-  movl(edx, INT_MIN);\n-  movdl(xmm1, edx);\n-  xorpd(xmm7, xmm7);\n-  paddd(xmm0, xmm4);\n-  psllq(xmm5, 32);\n-  movdl(edx, xmm0);\n-  psllq(xmm0, 29);\n-  paddq(xmm1, xmm3);\n-  pand(xmm5, xmm1);\n-  andl(ecx, 32752);\n-  cmpl(ecx, 16560);\n-  jcc(Assembler::below, L_2TAG_PACKET_3_0_2);\n-  pand(xmm0, xmm6);\n-  subsd(xmm3, xmm5);\n-  addl(eax, 16351);\n-  shrl(eax, 4);\n-  subl(eax, 1022);\n-  cvtsi2sdl(xmm7, eax);\n-  mulpd(xmm5, xmm0);\n-  movsd(xmm4, Address(tmp, 0));\n-  mulsd(xmm3, xmm0);\n-  movsd(xmm6, Address(tmp, 0));\n-  subsd(xmm5, xmm2);\n-  movsd(xmm1, Address(tmp, 8));\n-  pshufd(xmm2, xmm3, 68);\n-  unpcklpd(xmm5, xmm3);\n-  addsd(xmm3, xmm5);\n-  movsd(xmm0, Address(tmp, 8));\n-  andl(edx, 16760832);\n-  shrl(edx, 10);\n-  addpd(xmm7, Address(tmp, edx, Address::times_1, -3616));\n-  mulsd(xmm4, xmm5);\n-  mulsd(xmm0, xmm5);\n-  mulsd(xmm6, xmm2);\n-  mulsd(xmm1, xmm2);\n-  movdqu(xmm2, xmm5);\n-  mulsd(xmm4, xmm5);\n-  addsd(xmm5, xmm0);\n-  movdqu(xmm0, xmm7);\n-  addsd(xmm2, xmm3);\n-  addsd(xmm7, xmm5);\n-  mulsd(xmm6, xmm2);\n-  subsd(xmm0, xmm7);\n-  movdqu(xmm2, xmm7);\n-  addsd(xmm7, xmm4);\n-  addsd(xmm0, xmm5);\n-  subsd(xmm2, xmm7);\n-  addsd(xmm4, xmm2);\n-  pshufd(xmm2, xmm5, 238);\n-  movdqu(xmm5, xmm7);\n-  addsd(xmm7, xmm2);\n-  addsd(xmm4, xmm0);\n-  movdqu(xmm0, Address(tmp, 8272));\n-  subsd(xmm5, xmm7);\n-  addsd(xmm6, xmm4);\n-  movdqu(xmm4, xmm7);\n-  addsd(xmm5, xmm2);\n-  addsd(xmm7, xmm1);\n-  movdqu(xmm2, Address(tmp, 8336));\n-  subsd(xmm4, xmm7);\n-  addsd(xmm6, xmm5);\n-  addsd(xmm4, xmm1);\n-  pshufd(xmm5, xmm7, 238);\n-  movdqu(xmm1, xmm7);\n-  addsd(xmm7, xmm5);\n-  subsd(xmm1, xmm7);\n-  addsd(xmm1, xmm5);\n-  movdqu(xmm5, Address(tmp, 8352));\n-  pshufd(xmm3, xmm3, 68);\n-  addsd(xmm6, xmm4);\n-  addsd(xmm6, xmm1);\n-  movdqu(xmm1, Address(tmp, 8304));\n-  mulpd(xmm0, xmm3);\n-  mulpd(xmm2, xmm3);\n-  pshufd(xmm4, xmm3, 68);\n-  mulpd(xmm3, xmm3);\n-  addpd(xmm0, xmm1);\n-  addpd(xmm5, xmm2);\n-  mulsd(xmm4, xmm3);\n-  movsd(xmm2, Address(tmp, 16));\n-  mulpd(xmm3, xmm3);\n-  movsd(xmm1, Address(rsp, 16));\n-  movzwl(ecx, Address(rsp, 22));\n-  mulpd(xmm0, xmm4);\n-  pextrw(eax, xmm7, 3);\n-  mulpd(xmm5, xmm4);\n-  mulpd(xmm0, xmm3);\n-  movsd(xmm4, Address(tmp, 8376));\n-  pand(xmm2, xmm7);\n-  addsd(xmm5, xmm6);\n-  subsd(xmm7, xmm2);\n-  addpd(xmm5, xmm0);\n-  andl(eax, 32752);\n-  subl(eax, 16368);\n-  andl(ecx, 32752);\n-  cmpl(ecx, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_48_0_2);\n-  addl(ecx, eax);\n-  cmpl(ecx, 16576);\n-  jcc(Assembler::aboveEqual, L_2TAG_PACKET_54_0_2);\n-  pshufd(xmm0, xmm5, 238);\n-  pand(xmm4, xmm1);\n-  movdqu(xmm3, xmm1);\n-  addsd(xmm5, xmm0);\n-  subsd(xmm1, xmm4);\n-  xorpd(xmm6, xmm6);\n-  movl(edx, 17080);\n-  pinsrw(xmm6, edx, 3);\n-  addsd(xmm7, xmm5);\n-  mulsd(xmm4, xmm2);\n-  mulsd(xmm1, xmm2);\n-  movdqu(xmm5, xmm6);\n-  mulsd(xmm3, xmm7);\n-  addsd(xmm6, xmm4);\n-  addsd(xmm1, xmm3);\n-  movdqu(xmm7, Address(tmp, 12480));\n-  movdl(edx, xmm6);\n-  subsd(xmm6, xmm5);\n-  movdqu(xmm3, Address(tmp, 12496));\n-  movsd(xmm2, Address(tmp, 12512));\n-  subsd(xmm4, xmm6);\n-  movl(ecx, edx);\n-  andl(edx, 255);\n-  addl(edx, edx);\n-  movdqu(xmm5, Address(tmp, edx, Address::times_8, 8384));\n-  addsd(xmm4, xmm1);\n-  pextrw(edx, xmm6, 3);\n-  shrl(ecx, 8);\n-  movl(eax, ecx);\n-  shrl(ecx, 1);\n-  subl(eax, ecx);\n-  shll(ecx, 20);\n-  movdl(xmm6, ecx);\n-  pshufd(xmm0, xmm4, 68);\n-  pshufd(xmm1, xmm4, 68);\n-  mulpd(xmm0, xmm0);\n-  mulpd(xmm7, xmm1);\n-  pshufd(xmm6, xmm6, 17);\n-  mulsd(xmm2, xmm4);\n-  andl(edx, 32767);\n-  cmpl(edx, 16529);\n-  jcc(Assembler::above, L_2TAG_PACKET_14_0_2);\n-  mulsd(xmm0, xmm0);\n-  paddd(xmm5, xmm6);\n-  addpd(xmm3, xmm7);\n-  mulsd(xmm2, xmm5);\n-  pshufd(xmm6, xmm5, 238);\n-  mulpd(xmm0, xmm3);\n-  addsd(xmm2, xmm6);\n-  pshufd(xmm3, xmm0, 238);\n-  addl(eax, 1023);\n-  shll(eax, 20);\n-  orl(eax, rsi);\n-  movdl(xmm4, eax);\n-  mulsd(xmm0, xmm5);\n-  mulsd(xmm3, xmm5);\n-  addsd(xmm0, xmm2);\n-  psllq(xmm4, 32);\n-  addsd(xmm0, xmm3);\n-  movdqu(xmm1, xmm0);\n-  addsd(xmm0, xmm5);\n-  movl(rsi, Address(rsp, 24));\n-  mulsd(xmm0, xmm4);\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_16_0_2);\n-  cmpl(eax, 32752);\n-  jcc(Assembler::equal, L_2TAG_PACKET_17_0_2);\n-\n-  bind(L_2TAG_PACKET_55_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_6_0_2);\n-\n-  bind(L_2TAG_PACKET_48_0_2);\n-  movl(rsi, Address(rsp, 24));\n-\n-  bind(L_2TAG_PACKET_56_0_2);\n-  movsd(xmm0, Address(rsp, 8));\n-  movsd(xmm1, Address(rsp, 16));\n-  addsd(xmm1, xmm1);\n-  xorpd(xmm2, xmm2);\n-  movl(eax, 49136);\n-  pinsrw(xmm2, eax, 3);\n-  addsd(xmm2, xmm0);\n-  pextrw(eax, xmm2, 3);\n-  cmpl(eax, 0);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_57_0_2);\n-  xorpd(xmm0, xmm0);\n-  movl(eax, 32760);\n-  pinsrw(xmm0, eax, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_57_0_2);\n-  movdl(edx, xmm1);\n-  movdqu(xmm3, xmm1);\n-  psrlq(xmm3, 20);\n-  movdl(ecx, xmm3);\n-  orl(ecx, edx);\n-  jcc(Assembler::equal, L_2TAG_PACKET_58_0_2);\n-  addsd(xmm1, xmm1);\n-  movdqu(xmm0, xmm1);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_58_0_2);\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32752);\n-  pextrw(edx, xmm1, 3);\n-  xorpd(xmm0, xmm0);\n-  subl(eax, 16368);\n-  xorl(eax, edx);\n-  testl(eax, 32768);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_18_0_2);\n-  movl(edx, 32752);\n-  pinsrw(xmm0, edx, 3);\n-  jmp(L_2TAG_PACKET_18_0_2);\n-\n-  bind(L_2TAG_PACKET_54_0_2);\n-  pextrw(eax, xmm1, 3);\n-  pextrw(ecx, xmm2, 3);\n-  xorl(eax, ecx);\n-  testl(eax, 32768);\n-  jcc(Assembler::equal, L_2TAG_PACKET_50_0_2);\n-  jmp(L_2TAG_PACKET_49_0_2);\n-\n-  bind(L_2TAG_PACKET_6_0_2);\n-  movl(tmp, Address(rsp, 64));\n-\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_pow.cpp","additions":0,"deletions":1855,"binary":false,"changes":1855,"status":"deleted"},{"patch":"@@ -1,1742 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"stubRoutines_x86.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - SIN()\n-\/\/                     ---------------------\n-\/\/\n-\/\/     1. RANGE REDUCTION\n-\/\/\n-\/\/     We perform an initial range reduction from X to r with\n-\/\/\n-\/\/          X =~= N * pi\/32 + r\n-\/\/\n-\/\/     so that |r| <= pi\/64 + epsilon. We restrict inputs to those\n-\/\/     where |N| <= 932560. Beyond this, the range reduction is\n-\/\/     insufficiently accurate. For extremely small inputs,\n-\/\/     denormalization can occur internally, impacting performance.\n-\/\/     This means that the main path is actually only taken for\n-\/\/     2^-252 <= |X| < 90112.\n-\/\/\n-\/\/     To avoid branches, we perform the range reduction to full\n-\/\/     accuracy each time.\n-\/\/\n-\/\/          X - N * (P_1 + P_2 + P_3)\n-\/\/\n-\/\/     where P_1 and P_2 are 32-bit numbers (so multiplication by N\n-\/\/     is exact) and P_3 is a 53-bit number. Together, these\n-\/\/     approximate pi well enough for all cases in the restricted\n-\/\/     range.\n-\/\/\n-\/\/     The main reduction sequence is:\n-\/\/\n-\/\/             y = 32\/pi * x\n-\/\/             N = integer(y)\n-\/\/     (computed by adding and subtracting off SHIFTER)\n-\/\/\n-\/\/             m_1 = N * P_1\n-\/\/             m_2 = N * P_2\n-\/\/             r_1 = x - m_1\n-\/\/             r = r_1 - m_2\n-\/\/     (this r can be used for most of the calculation)\n-\/\/\n-\/\/             c_1 = r_1 - r\n-\/\/             m_3 = N * P_3\n-\/\/             c_2 = c_1 - m_2\n-\/\/             c = c_2 - m_3\n-\/\/\n-\/\/     2. MAIN ALGORITHM\n-\/\/\n-\/\/     The algorithm uses a table lookup based on B = M * pi \/ 32\n-\/\/     where M = N mod 64. The stored values are:\n-\/\/       sigma             closest power of 2 to cos(B)\n-\/\/       C_hl              53-bit cos(B) - sigma\n-\/\/       S_hi + S_lo       2 * 53-bit sin(B)\n-\/\/\n-\/\/     The computation is organized as follows:\n-\/\/\n-\/\/          sin(B + r + c) = [sin(B) + sigma * r] +\n-\/\/                           r * (cos(B) - sigma) +\n-\/\/                           sin(B) * [cos(r + c) - 1] +\n-\/\/                           cos(B) * [sin(r + c) - r]\n-\/\/\n-\/\/     which is approximately:\n-\/\/\n-\/\/          [S_hi + sigma * r] +\n-\/\/          C_hl * r +\n-\/\/          S_lo + S_hi * [(cos(r) - 1) - r * c] +\n-\/\/          (C_hl + sigma) * [(sin(r) - r) + c]\n-\/\/\n-\/\/     and this is what is actually computed. We separate this sum\n-\/\/     into four parts:\n-\/\/\n-\/\/          hi + med + pols + corr\n-\/\/\n-\/\/     where\n-\/\/\n-\/\/          hi       = S_hi + sigma r\n-\/\/          med      = C_hl * r\n-\/\/          pols     = S_hi * (cos(r) - 1) + (C_hl + sigma) * (sin(r) - r)\n-\/\/          corr     = S_lo + c * ((C_hl + sigma) - S_hi * r)\n-\/\/\n-\/\/     3. POLYNOMIAL\n-\/\/\n-\/\/     The polynomial S_hi * (cos(r) - 1) + (C_hl + sigma) *\n-\/\/     (sin(r) - r) can be rearranged freely, since it is quite\n-\/\/     small, so we exploit parallelism to the fullest.\n-\/\/\n-\/\/          psc4       =   SC_4 * r_1\n-\/\/          msc4       =   psc4 * r\n-\/\/          r2         =   r * r\n-\/\/          msc2       =   SC_2 * r2\n-\/\/          r4         =   r2 * r2\n-\/\/          psc3       =   SC_3 + msc4\n-\/\/          psc1       =   SC_1 + msc2\n-\/\/          msc3       =   r4 * psc3\n-\/\/          sincospols =   psc1 + msc3\n-\/\/          pols       =   sincospols *\n-\/\/                         <S_hi * r^2 | (C_hl + sigma) * r^3>\n-\/\/\n-\/\/     4. CORRECTION TERM\n-\/\/\n-\/\/     This is where the \"c\" component of the range reduction is\n-\/\/     taken into account; recall that just \"r\" is used for most of\n-\/\/     the calculation.\n-\/\/\n-\/\/          -c   = m_3 - c_2\n-\/\/          -d   = S_hi * r - (C_hl + sigma)\n-\/\/          corr = -c * -d + S_lo\n-\/\/\n-\/\/     5. COMPENSATED SUMMATIONS\n-\/\/\n-\/\/     The two successive compensated summations add up the high\n-\/\/     and medium parts, leaving just the low parts to add up at\n-\/\/     the end.\n-\/\/\n-\/\/          rs        =  sigma * r\n-\/\/          res_int   =  S_hi + rs\n-\/\/          k_0       =  S_hi - res_int\n-\/\/          k_2       =  k_0 + rs\n-\/\/          med       =  C_hl * r\n-\/\/          res_hi    =  res_int + med\n-\/\/          k_1       =  res_int - res_hi\n-\/\/          k_3       =  k_1 + med\n-\/\/\n-\/\/     6. FINAL SUMMATION\n-\/\/\n-\/\/     We now add up all the small parts:\n-\/\/\n-\/\/          res_lo = pols(hi) + pols(lo) + corr + k_1 + k_3\n-\/\/\n-\/\/     Now the overall result is just:\n-\/\/\n-\/\/          res_hi + res_lo\n-\/\/\n-\/\/     7. SMALL ARGUMENTS\n-\/\/\n-\/\/     If |x| < SNN (SNN meaning the smallest normal number), we\n-\/\/     simply perform 0.1111111 cdots 1111 * x. For SNN <= |x|, we\n-\/\/     do 2^-55 * (2^55 * x - x).\n-\/\/\n-\/\/ Special cases:\n-\/\/  sin(NaN) = quiet NaN, and raise invalid exception\n-\/\/  sin(INF) = NaN and raise invalid exception\n-\/\/  sin(+\/-0) = +\/-0\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-ATTRIBUTE_ALIGNED(8) static const juint _zero_none[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xbff00000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint __4onpi_d[] =\n-{\n-    0x6dc9c883UL, 0x3ff45f30UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _TWO_32H[] =\n-{\n-    0x00000000UL, 0x41f80000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _pi04_3d[] =\n-{\n-    0x54442d00UL, 0x3fe921fbUL, 0x98cc5180UL, 0x3ce84698UL, 0xcbb5bf6cUL,\n-    0xb9dfc8f8UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _pi04_5d[] =\n-{\n-    0x54400000UL, 0x3fe921fbUL, 0x1a600000UL, 0x3dc0b461UL, 0x2e000000UL,\n-    0x3b93198aUL, 0x25200000UL, 0x396b839aUL, 0x533e63a0UL, 0x37027044UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _SCALE[] =\n-{\n-    0x00000000UL, 0x32600000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _zeros[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x80000000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _pi04_2d[] =\n-{\n-    0x54400000UL, 0x3fe921fbUL, 0x1a626331UL, 0x3dc0b461UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) static const juint _TWO_12H[] =\n-{\n-    0x00000000UL, 0x40b80000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(2) static const jushort __4onpi_31l[] =\n-{\n-    0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x0000, 0x836e, 0xa2f9,\n-    0x40d8, 0x0000, 0x0000, 0x0000, 0x2a50, 0x9c88, 0x40b7, 0x0000, 0x0000, 0x0000,\n-    0xabe8, 0xfe13, 0x4099, 0x0000, 0x0000, 0x0000, 0x6ee0, 0xfa9a, 0x4079, 0x0000,\n-    0x0000, 0x0000, 0x9580, 0xdb62, 0x4058, 0x0000, 0x0000, 0x0000, 0x1c82, 0xc9e2,\n-    0x403d, 0x0000, 0x0000, 0x0000, 0xb1c0, 0xff28, 0x4019, 0x0000, 0x0000, 0x0000,\n-    0xef14, 0xaf7a, 0x3ffe, 0x0000, 0x0000, 0x0000, 0x48dc, 0xc36e, 0x3fdf, 0x0000,\n-    0x0000, 0x0000, 0x3740, 0xe909, 0x3fbe, 0x0000, 0x0000, 0x0000, 0x924a, 0xb801,\n-    0x3fa2, 0x0000, 0x0000, 0x0000, 0x3a32, 0xdd41, 0x3f83, 0x0000, 0x0000, 0x0000,\n-    0x8778, 0x873f, 0x3f62, 0x0000, 0x0000, 0x0000, 0x1298, 0xb1cb, 0x3f44, 0x0000,\n-    0x0000, 0x0000, 0xa208, 0x9cfb, 0x3f26, 0x0000, 0x0000, 0x0000, 0xbaec, 0xd7d4,\n-    0x3f06, 0x0000, 0x0000, 0x0000, 0xd338, 0x8909, 0x3ee7, 0x0000, 0x0000, 0x0000,\n-    0x68b8, 0xe04d, 0x3ec7, 0x0000, 0x0000, 0x0000, 0x4e64, 0xdf90, 0x3eaa, 0x0000,\n-    0x0000, 0x0000, 0xc1a8, 0xeb1c, 0x3e89, 0x0000, 0x0000, 0x0000, 0x2720, 0xce7d,\n-    0x3e6a, 0x0000, 0x0000, 0x0000, 0x77b8, 0x8bf1, 0x3e4b, 0x0000, 0x0000, 0x0000,\n-    0xec7e, 0xe4a0, 0x3e2e, 0x0000, 0x0000, 0x0000, 0xffbc, 0xf12f, 0x3e0f, 0x0000,\n-    0x0000, 0x0000, 0xfdc0, 0xb301, 0x3deb, 0x0000, 0x0000, 0x0000, 0xc5ac, 0x9788,\n-    0x3dd1, 0x0000, 0x0000, 0x0000, 0x47da, 0x829b, 0x3db2, 0x0000, 0x0000, 0x0000,\n-    0xd9e4, 0xa6cf, 0x3d93, 0x0000, 0x0000, 0x0000, 0x36e8, 0xf961, 0x3d73, 0x0000,\n-    0x0000, 0x0000, 0xf668, 0xf463, 0x3d54, 0x0000, 0x0000, 0x0000, 0x5168, 0xf2ff,\n-    0x3d35, 0x0000, 0x0000, 0x0000, 0x758e, 0xea4f, 0x3d17, 0x0000, 0x0000, 0x0000,\n-    0xf17a, 0xebe5, 0x3cf8, 0x0000, 0x0000, 0x0000, 0x9cfa, 0x9e83, 0x3cd9, 0x0000,\n-    0x0000, 0x0000, 0xa4ba, 0xe294, 0x3cba, 0x0000, 0x0000, 0x0000, 0xd7ec, 0x9afe,\n-    0x3c9a, 0x0000, 0x0000, 0x0000, 0xae80, 0x8fc6, 0x3c79, 0x0000, 0x0000, 0x0000,\n-    0x3304, 0x8560, 0x3c5c, 0x0000, 0x0000, 0x0000, 0x6d70, 0xdf8f, 0x3c3b, 0x0000,\n-    0x0000, 0x0000, 0x3ef0, 0xafc3, 0x3c1e, 0x0000, 0x0000, 0x0000, 0xd0d8, 0x826b,\n-    0x3bfe, 0x0000, 0x0000, 0x0000, 0x1c80, 0xed4f, 0x3bdd, 0x0000, 0x0000, 0x0000,\n-    0x730c, 0xb0af, 0x3bc1, 0x0000, 0x0000, 0x0000, 0x6660, 0xc219, 0x3ba2, 0x0000,\n-    0x0000, 0x0000, 0x940c, 0xabe2, 0x3b83, 0x0000, 0x0000, 0x0000, 0xdffc, 0x8408,\n-    0x3b64, 0x0000, 0x0000, 0x0000, 0x6b98, 0xc402, 0x3b45, 0x0000, 0x0000, 0x0000,\n-    0x1818, 0x9cc4, 0x3b26, 0x0000, 0x0000, 0x0000, 0x5390, 0xaab6, 0x3b05, 0x0000,\n-    0x0000, 0x0000, 0xb070, 0xd464, 0x3ae9, 0x0000, 0x0000, 0x0000, 0x231a, 0x9ef0,\n-    0x3aca, 0x0000, 0x0000, 0x0000, 0x0670, 0xd1f1, 0x3aaa, 0x0000, 0x0000, 0x0000,\n-    0x7738, 0xd9f3, 0x3a8a, 0x0000, 0x0000, 0x0000, 0xa834, 0x8092, 0x3a6c, 0x0000,\n-    0x0000, 0x0000, 0xb45c, 0xce23, 0x3a4d, 0x0000, 0x0000, 0x0000, 0x36e8, 0xb0e5,\n-    0x3a2d, 0x0000, 0x0000, 0x0000, 0xd156, 0xaf44, 0x3a10, 0x0000, 0x0000, 0x0000,\n-    0x9f52, 0x8c82, 0x39f1, 0x0000, 0x0000, 0x0000, 0x829c, 0xff83, 0x39d1, 0x0000,\n-    0x0000, 0x0000, 0x7d06, 0xefc6, 0x39b3, 0x0000, 0x0000, 0x0000, 0x93e0, 0xb0b7,\n-    0x3992, 0x0000, 0x0000, 0x0000, 0xedde, 0xc193, 0x3975, 0x0000, 0x0000, 0x0000,\n-    0xbbc0, 0xcf49, 0x3952, 0x0000, 0x0000, 0x0000, 0xbdf0, 0xd63c, 0x3937, 0x0000,\n-    0x0000, 0x0000, 0x1f34, 0x9f3a, 0x3918, 0x0000, 0x0000, 0x0000, 0x3f8e, 0xe579,\n-    0x38f9, 0x0000, 0x0000, 0x0000, 0x90c8, 0xc3f8, 0x38d9, 0x0000, 0x0000, 0x0000,\n-    0x48c0, 0xf8f8, 0x38b7, 0x0000, 0x0000, 0x0000, 0xed56, 0xafa6, 0x389c, 0x0000,\n-    0x0000, 0x0000, 0x8218, 0xb969, 0x387d, 0x0000, 0x0000, 0x0000, 0x1852, 0xec57,\n-    0x385e, 0x0000, 0x0000, 0x0000, 0x670c, 0xd674, 0x383e, 0x0000, 0x0000, 0x0000,\n-    0xad40, 0xc2c4, 0x3820, 0x0000, 0x0000, 0x0000, 0x2e80, 0xa696, 0x3801, 0x0000,\n-    0x0000, 0x0000, 0xd800, 0xc467, 0x37dc, 0x0000, 0x0000, 0x0000, 0x3c72, 0xc5ae,\n-    0x37c3, 0x0000, 0x0000, 0x0000, 0xb006, 0xac69, 0x37a4, 0x0000, 0x0000, 0x0000,\n-    0x34a0, 0x8cdf, 0x3782, 0x0000, 0x0000, 0x0000, 0x9ed2, 0xd25e, 0x3766, 0x0000,\n-    0x0000, 0x0000, 0x6fec, 0xaaaa, 0x3747, 0x0000, 0x0000, 0x0000, 0x6040, 0xfb5c,\n-    0x3726, 0x0000, 0x0000, 0x0000, 0x764c, 0xa3fc, 0x3708, 0x0000, 0x0000, 0x0000,\n-    0xb254, 0x954e, 0x36e9, 0x0000, 0x0000, 0x0000, 0x3e1c, 0xf5dc, 0x36ca, 0x0000,\n-    0x0000, 0x0000, 0x7b06, 0xc635, 0x36ac, 0x0000, 0x0000, 0x0000, 0xa8ba, 0xd738,\n-    0x368d, 0x0000, 0x0000, 0x0000, 0x06cc, 0xb24e, 0x366d, 0x0000, 0x0000, 0x0000,\n-    0x7108, 0xac76, 0x364f, 0x0000, 0x0000, 0x0000, 0x2324, 0xa7cb, 0x3630, 0x0000,\n-    0x0000, 0x0000, 0xac40, 0xef15, 0x360f, 0x0000, 0x0000, 0x0000, 0xae46, 0xd516,\n-    0x35f2, 0x0000, 0x0000, 0x0000, 0x615e, 0xe003, 0x35d3, 0x0000, 0x0000, 0x0000,\n-    0x0cf0, 0xefe7, 0x35b1, 0x0000, 0x0000, 0x0000, 0xfb50, 0xf98c, 0x3595, 0x0000,\n-    0x0000, 0x0000, 0x0abc, 0xf333, 0x3575, 0x0000, 0x0000, 0x0000, 0xdd60, 0xca3f,\n-    0x3555, 0x0000, 0x0000, 0x0000, 0x7eb6, 0xd87f, 0x3538, 0x0000, 0x0000, 0x0000,\n-    0x44f4, 0xb291, 0x3519, 0x0000, 0x0000, 0x0000, 0xff80, 0xc982, 0x34f6, 0x0000,\n-    0x0000, 0x0000, 0x9de0, 0xd9b8, 0x34db, 0x0000, 0x0000, 0x0000, 0xcd42, 0x9366,\n-    0x34bc, 0x0000, 0x0000, 0x0000, 0xbef0, 0xfaee, 0x349d, 0x0000, 0x0000, 0x0000,\n-    0xdac4, 0xb6f1, 0x347d, 0x0000, 0x0000, 0x0000, 0xf140, 0x94de, 0x345d, 0x0000,\n-    0x0000, 0x0000, 0xa218, 0x8b4b, 0x343e, 0x0000, 0x0000, 0x0000, 0x6380, 0xa135,\n-    0x341e, 0x0000, 0x0000, 0x0000, 0xb184, 0x8cb2, 0x3402, 0x0000, 0x0000, 0x0000,\n-    0x196e, 0xdc61, 0x33e3, 0x0000, 0x0000, 0x0000, 0x0c00, 0xde05, 0x33c4, 0x0000,\n-    0x0000, 0x0000, 0xef9a, 0xbd38, 0x33a5, 0x0000, 0x0000, 0x0000, 0xc1a0, 0xdf00,\n-    0x3385, 0x0000, 0x0000, 0x0000, 0x1090, 0x9973, 0x3365, 0x0000, 0x0000, 0x0000,\n-    0x4882, 0x8301, 0x3348, 0x0000, 0x0000, 0x0000, 0x7abe, 0xadc7, 0x3329, 0x0000,\n-    0x0000, 0x0000, 0x7cba, 0xec2b, 0x330a, 0x0000, 0x0000, 0x0000, 0xa520, 0x8f21,\n-    0x32e9, 0x0000, 0x0000, 0x0000, 0x710c, 0x8d36, 0x32cc, 0x0000, 0x0000, 0x0000,\n-    0x5212, 0xc6ed, 0x32ad, 0x0000, 0x0000, 0x0000, 0x7308, 0xfd76, 0x328d, 0x0000,\n-    0x0000, 0x0000, 0x5014, 0xd548, 0x326f, 0x0000, 0x0000, 0x0000, 0xd3f2, 0xb499,\n-    0x3250, 0x0000, 0x0000, 0x0000, 0x7f74, 0xa606, 0x3230, 0x0000, 0x0000, 0x0000,\n-    0xf0a8, 0xd720, 0x3212, 0x0000, 0x0000, 0x0000, 0x185c, 0xe20f, 0x31f2, 0x0000,\n-    0x0000, 0x0000, 0xa5a8, 0x8738, 0x31d4, 0x0000, 0x0000, 0x0000, 0xdd74, 0xcafb,\n-    0x31b4, 0x0000, 0x0000, 0x0000, 0x98b6, 0xbd8e, 0x3196, 0x0000, 0x0000, 0x0000,\n-    0xe9de, 0x977f, 0x3177, 0x0000, 0x0000, 0x0000, 0x67c0, 0x818d, 0x3158, 0x0000,\n-    0x0000, 0x0000, 0xe52a, 0x9322, 0x3139, 0x0000, 0x0000, 0x0000, 0xe568, 0x9b6c,\n-    0x3119, 0x0000, 0x0000, 0x0000, 0x2358, 0xaa0a, 0x30fa, 0x0000, 0x0000, 0x0000,\n-    0xe480, 0xe13b, 0x30d9, 0x0000, 0x0000, 0x0000, 0x3024, 0x90a1, 0x30bd, 0x0000,\n-    0x0000, 0x0000, 0x9620, 0xda30, 0x309d, 0x0000, 0x0000, 0x0000, 0x898a, 0xb388,\n-    0x307f, 0x0000, 0x0000, 0x0000, 0xb24c, 0xc891, 0x3060, 0x0000, 0x0000, 0x0000,\n-    0x8056, 0xf98b, 0x3041, 0x0000, 0x0000, 0x0000, 0x72a4, 0xa1ea, 0x3021, 0x0000,\n-    0x0000, 0x0000, 0x6af8, 0x9488, 0x3001, 0x0000, 0x0000, 0x0000, 0xe00c, 0xdfcb,\n-    0x2fe4, 0x0000, 0x0000, 0x0000, 0xeeec, 0xc941, 0x2fc4, 0x0000, 0x0000, 0x0000,\n-    0x53e0, 0xe70f, 0x2fa4, 0x0000, 0x0000, 0x0000, 0x8f60, 0x9c07, 0x2f85, 0x0000,\n-    0x0000, 0x0000, 0xb328, 0xc3e7, 0x2f68, 0x0000, 0x0000, 0x0000, 0x9404, 0xf8c7,\n-    0x2f48, 0x0000, 0x0000, 0x0000, 0x38e0, 0xc99f, 0x2f29, 0x0000, 0x0000, 0x0000,\n-    0x9778, 0xd984, 0x2f09, 0x0000, 0x0000, 0x0000, 0xe700, 0xd142, 0x2eea, 0x0000,\n-    0x0000, 0x0000, 0xd904, 0x9443, 0x2ecd, 0x0000, 0x0000, 0x0000, 0xd4ba, 0xae7e,\n-    0x2eae, 0x0000, 0x0000, 0x0000, 0x8e5e, 0x8524, 0x2e8f, 0x0000, 0x0000, 0x0000,\n-    0xb550, 0xc9ed, 0x2e6e, 0x0000, 0x0000, 0x0000, 0x53b8, 0x8648, 0x2e51, 0x0000,\n-    0x0000, 0x0000, 0xdae4, 0x87f9, 0x2e32, 0x0000, 0x0000, 0x0000, 0x2942, 0xd966,\n-    0x2e13, 0x0000, 0x0000, 0x0000, 0x4f28, 0xcf3c, 0x2df3, 0x0000, 0x0000, 0x0000,\n-    0xfa40, 0xc4ef, 0x2dd1, 0x0000, 0x0000, 0x0000, 0x4424, 0xbca7, 0x2db5, 0x0000,\n-    0x0000, 0x0000, 0x2e62, 0xcdc5, 0x2d97, 0x0000, 0x0000, 0x0000, 0xed88, 0x996b,\n-    0x2d78, 0x0000, 0x0000, 0x0000, 0x7c30, 0xd97d, 0x2d56, 0x0000, 0x0000, 0x0000,\n-    0xed26, 0xbf6e, 0x2d3a, 0x0000, 0x0000, 0x0000, 0x2918, 0x921b, 0x2d1a, 0x0000,\n-    0x0000, 0x0000, 0x4e24, 0xe84e, 0x2cfb, 0x0000, 0x0000, 0x0000, 0x6dc0, 0x92ec,\n-    0x2cdd, 0x0000, 0x0000, 0x0000, 0x4f2c, 0xacf8, 0x2cbd, 0x0000, 0x0000, 0x0000,\n-    0xc634, 0xf094, 0x2c9e, 0x0000, 0x0000, 0x0000, 0xdc70, 0xe5d3, 0x2c7e, 0x0000,\n-    0x0000, 0x0000, 0x2180, 0xa600, 0x2c5b, 0x0000, 0x0000, 0x0000, 0x8480, 0xd680,\n-    0x2c3c, 0x0000, 0x0000, 0x0000, 0x8b24, 0xd63b, 0x2c22, 0x0000, 0x0000, 0x0000,\n-    0x02e0, 0xaa47, 0x2c00, 0x0000, 0x0000, 0x0000, 0x9ad0, 0xee84, 0x2be3, 0x0000,\n-    0x0000, 0x0000, 0xf7dc, 0xf699, 0x2bc6, 0x0000, 0x0000, 0x0000, 0xddde, 0xe490,\n-    0x2ba7, 0x0000, 0x0000, 0x0000, 0x34a0, 0xb4fd, 0x2b85, 0x0000, 0x0000, 0x0000,\n-    0x91b4, 0x8ef6, 0x2b68, 0x0000, 0x0000, 0x0000, 0xa3e0, 0xa2a7, 0x2b47, 0x0000,\n-    0x0000, 0x0000, 0xcce4, 0x82b3, 0x2b2a, 0x0000, 0x0000, 0x0000, 0xe4be, 0x8207,\n-    0x2b0c, 0x0000, 0x0000, 0x0000, 0x1d92, 0xab43, 0x2aed, 0x0000, 0x0000, 0x0000,\n-    0xe818, 0xf9f6, 0x2acd, 0x0000, 0x0000, 0x0000, 0xff12, 0xba80, 0x2aaf, 0x0000,\n-    0x0000, 0x0000, 0x5254, 0x8529, 0x2a90, 0x0000, 0x0000, 0x0000, 0x1b88, 0xe032,\n-    0x2a71, 0x0000, 0x0000, 0x0000, 0x3248, 0xd86d, 0x2a50, 0x0000, 0x0000, 0x0000,\n-    0x3140, 0xc9d5, 0x2a2e, 0x0000, 0x0000, 0x0000, 0x14e6, 0xbd47, 0x2a14, 0x0000,\n-    0x0000, 0x0000, 0x5c10, 0xe544, 0x29f4, 0x0000, 0x0000, 0x0000, 0x9f50, 0x90b6,\n-    0x29d4, 0x0000, 0x0000, 0x0000, 0x9850, 0xab55, 0x29b6, 0x0000, 0x0000, 0x0000,\n-    0x2750, 0x9d07, 0x2998, 0x0000, 0x0000, 0x0000, 0x6700, 0x8bbb, 0x2973, 0x0000,\n-    0x0000, 0x0000, 0x5dba, 0xed31, 0x295a, 0x0000, 0x0000, 0x0000, 0x61dc, 0x85fe,\n-    0x293a, 0x0000, 0x0000, 0x0000, 0x9ba2, 0xd6b4, 0x291c, 0x0000, 0x0000, 0x0000,\n-    0x2d30, 0xe3a5, 0x28fb, 0x0000, 0x0000, 0x0000, 0x6630, 0xb566, 0x28dd, 0x0000,\n-    0x0000, 0x0000, 0x5ad4, 0xa829, 0x28bf, 0x0000, 0x0000, 0x0000, 0x89d8, 0xe290,\n-    0x28a0, 0x0000, 0x0000, 0x0000, 0x3916, 0xc428, 0x2881, 0x0000, 0x0000, 0x0000,\n-    0x0490, 0xbea4, 0x2860, 0x0000, 0x0000, 0x0000, 0xee06, 0x80ee, 0x2843, 0x0000,\n-    0x0000, 0x0000, 0xfc00, 0xf327, 0x2820, 0x0000, 0x0000, 0x0000, 0xea40, 0xa871,\n-    0x2800, 0x0000, 0x0000, 0x0000, 0x63d8, 0x9c26, 0x27e4, 0x0000, 0x0000, 0x0000,\n-    0x07ba, 0xc0c9, 0x27c7, 0x0000, 0x0000, 0x0000, 0x3fa2, 0x9797, 0x27a8, 0x0000,\n-    0x0000, 0x0000, 0x21c6, 0xfeca, 0x2789, 0x0000, 0x0000, 0x0000, 0xde40, 0x860d,\n-    0x2768, 0x0000, 0x0000, 0x0000, 0x9cc8, 0x98ce, 0x2749, 0x0000, 0x0000, 0x0000,\n-    0x3778, 0xa31c, 0x272a, 0x0000, 0x0000, 0x0000, 0xe778, 0xf6e2, 0x270b, 0x0000,\n-    0x0000, 0x0000, 0x59b8, 0xf841, 0x26ed, 0x0000, 0x0000, 0x0000, 0x02e0, 0xad04,\n-    0x26cd, 0x0000, 0x0000, 0x0000, 0x5a92, 0x9380, 0x26b0, 0x0000, 0x0000, 0x0000,\n-    0xc740, 0x8886, 0x268d, 0x0000, 0x0000, 0x0000, 0x0680, 0xfaf8, 0x266c, 0x0000,\n-    0x0000, 0x0000, 0xfb60, 0x897f, 0x2653, 0x0000, 0x0000, 0x0000, 0x8760, 0xf903,\n-    0x2634, 0x0000, 0x0000, 0x0000, 0xad2a, 0xc2c8, 0x2615, 0x0000, 0x0000, 0x0000,\n-    0x2d86, 0x8aef, 0x25f6, 0x0000, 0x0000, 0x0000, 0x1ef4, 0xe627, 0x25d6, 0x0000,\n-    0x0000, 0x0000, 0x09e4, 0x8020, 0x25b7, 0x0000, 0x0000, 0x0000, 0x7548, 0xd227,\n-    0x2598, 0x0000, 0x0000, 0x0000, 0x75dc, 0xfb5b, 0x2579, 0x0000, 0x0000, 0x0000,\n-    0xea84, 0xc8b6, 0x255a, 0x0000, 0x0000, 0x0000, 0xe4d0, 0x8145, 0x253b, 0x0000,\n-    0x0000, 0x0000, 0x3640, 0x9768, 0x251c, 0x0000, 0x0000, 0x0000, 0x246a, 0xccec,\n-    0x24fe, 0x0000, 0x0000, 0x0000, 0x51d0, 0xa075, 0x24dd, 0x0000, 0x0000, 0x0000,\n-    0x4638, 0xa385, 0x24bf, 0x0000, 0x0000, 0x0000, 0xd788, 0xd776, 0x24a1, 0x0000,\n-    0x0000, 0x0000, 0x1370, 0x8997, 0x2482, 0x0000, 0x0000, 0x0000, 0x1e88, 0x9b67,\n-    0x2462, 0x0000, 0x0000, 0x0000, 0x6c08, 0xd975, 0x2444, 0x0000, 0x0000, 0x0000,\n-    0xfdb0, 0xcfc0, 0x2422, 0x0000, 0x0000, 0x0000, 0x3100, 0xc026, 0x2406, 0x0000,\n-    0x0000, 0x0000, 0xc5b4, 0xae64, 0x23e6, 0x0000, 0x0000, 0x0000, 0x2280, 0xf687,\n-    0x23c3, 0x0000, 0x0000, 0x0000, 0x2de0, 0x9006, 0x23a9, 0x0000, 0x0000, 0x0000,\n-    0x24bc, 0xf631, 0x238a, 0x0000, 0x0000, 0x0000, 0xb8d4, 0xa975, 0x236b, 0x0000,\n-    0x0000, 0x0000, 0xd9a4, 0xb949, 0x234b, 0x0000, 0x0000, 0x0000, 0xb54e, 0xbd39,\n-    0x232d, 0x0000, 0x0000, 0x0000, 0x4aac, 0x9a52, 0x230e, 0x0000, 0x0000, 0x0000,\n-    0xbbbc, 0xd085, 0x22ef, 0x0000, 0x0000, 0x0000, 0xdf18, 0xc633, 0x22cf, 0x0000,\n-    0x0000, 0x0000, 0x16d0, 0xeca5, 0x22af, 0x0000, 0x0000, 0x0000, 0xf2a0, 0xdf6f,\n-    0x228e, 0x0000, 0x0000, 0x0000, 0x8c44, 0xe86b, 0x2272, 0x0000, 0x0000, 0x0000,\n-    0x35c0, 0xbbf4, 0x2253, 0x0000, 0x0000, 0x0000, 0x0c40, 0xdafb, 0x2230, 0x0000,\n-    0x0000, 0x0000, 0x92dc, 0x9935, 0x2216, 0x0000, 0x0000, 0x0000, 0x0ca0, 0xbda6,\n-    0x21f3, 0x0000, 0x0000, 0x0000, 0x5958, 0xa6fd, 0x21d6, 0x0000, 0x0000, 0x0000,\n-    0xa3dc, 0x9d7f, 0x21b9, 0x0000, 0x0000, 0x0000, 0x79dc, 0xfcb5, 0x2199, 0x0000,\n-    0x0000, 0x0000, 0xf264, 0xcebb, 0x217b, 0x0000, 0x0000, 0x0000, 0x0abe, 0x8308,\n-    0x215c, 0x0000, 0x0000, 0x0000, 0x30ae, 0xb463, 0x213d, 0x0000, 0x0000, 0x0000,\n-    0x6228, 0xb040, 0x211c, 0x0000, 0x0000, 0x0000, 0xc9b2, 0xf43b, 0x20ff, 0x0000,\n-    0x0000, 0x0000, 0x3d8e, 0xa4b3, 0x20e0, 0x0000, 0x0000, 0x0000, 0x84e6, 0x8dab,\n-    0x20c1, 0x0000, 0x0000, 0x0000, 0xa124, 0x9b74, 0x20a1, 0x0000, 0x0000, 0x0000,\n-    0xc276, 0xd497, 0x2083, 0x0000, 0x0000, 0x0000, 0x6354, 0xa466, 0x2063, 0x0000,\n-    0x0000, 0x0000, 0x8654, 0xaf0a, 0x2044, 0x0000, 0x0000, 0x0000, 0x1d20, 0xfa5c,\n-    0x2024, 0x0000, 0x0000, 0x0000, 0xbcd0, 0xf3f0, 0x2004, 0x0000, 0x0000, 0x0000,\n-    0xedf0, 0xf0b6, 0x1fe7, 0x0000, 0x0000, 0x0000, 0x45bc, 0x9182, 0x1fc9, 0x0000,\n-    0x0000, 0x0000, 0xe254, 0xdc85, 0x1faa, 0x0000, 0x0000, 0x0000, 0xb898, 0xe9b1,\n-    0x1f8a, 0x0000, 0x0000, 0x0000, 0x0ebe, 0xe6f0, 0x1f6c, 0x0000, 0x0000, 0x0000,\n-    0xa9b8, 0xf584, 0x1f4c, 0x0000, 0x0000, 0x0000, 0x12e8, 0xdf6b, 0x1f2e, 0x0000,\n-    0x0000, 0x0000, 0x9f9e, 0xcd55, 0x1f0f, 0x0000, 0x0000, 0x0000, 0x05a0, 0xec3a,\n-    0x1eef, 0x0000, 0x0000, 0x0000, 0xd8e0, 0x96f8, 0x1ed1, 0x0000, 0x0000, 0x0000,\n-    0x3bd4, 0xccc6, 0x1eb1, 0x0000, 0x0000, 0x0000, 0x4910, 0xb87b, 0x1e93, 0x0000,\n-    0x0000, 0x0000, 0xbefc, 0xd40b, 0x1e73, 0x0000, 0x0000, 0x0000, 0x317e, 0xa406,\n-    0x1e55, 0x0000, 0x0000, 0x0000, 0x6bb2, 0xc2b2, 0x1e36, 0x0000, 0x0000, 0x0000,\n-    0xb87e, 0xbb78, 0x1e17, 0x0000, 0x0000, 0x0000, 0xa03c, 0xdbbd, 0x1df7, 0x0000,\n-    0x0000, 0x0000, 0x5b6c, 0xe3c8, 0x1dd9, 0x0000, 0x0000, 0x0000, 0x8968, 0xca8e,\n-    0x1dba, 0x0000, 0x0000, 0x0000, 0xc024, 0xe6ab, 0x1d9a, 0x0000, 0x0000, 0x0000,\n-    0x4110, 0xd4eb, 0x1d7a, 0x0000, 0x0000, 0x0000, 0xa168, 0xbdb5, 0x1d5d, 0x0000,\n-    0x0000, 0x0000, 0x012e, 0xa5fa, 0x1d3e, 0x0000, 0x0000, 0x0000, 0x6838, 0x9c1f,\n-    0x1d1e, 0x0000, 0x0000, 0x0000, 0xa158, 0xaa76, 0x1d00, 0x0000, 0x0000, 0x0000,\n-    0x090a, 0xbd95, 0x1ce1, 0x0000, 0x0000, 0x0000, 0xf73e, 0x8b6d, 0x1cc2, 0x0000,\n-    0x0000, 0x0000, 0x5fda, 0xbcbf, 0x1ca3, 0x0000, 0x0000, 0x0000, 0xdbe8, 0xb89f,\n-    0x1c84, 0x0000, 0x0000, 0x0000, 0x6e4c, 0x96c7, 0x1c64, 0x0000, 0x0000, 0x0000,\n-    0x19c2, 0xf2a4, 0x1c46, 0x0000, 0x0000, 0x0000, 0xb800, 0xf855, 0x1c1e, 0x0000,\n-    0x0000, 0x0000, 0x87fc, 0x85ff, 0x1c08, 0x0000, 0x0000, 0x0000, 0x1418, 0x839f,\n-    0x1be9, 0x0000, 0x0000, 0x0000, 0x6186, 0xd9d8, 0x1bca, 0x0000, 0x0000, 0x0000,\n-    0xf500, 0xabaa, 0x1ba6, 0x0000, 0x0000, 0x0000, 0x7b36, 0xdafe, 0x1b8c, 0x0000,\n-    0x0000, 0x0000, 0xf394, 0xe6d8, 0x1b6c, 0x0000, 0x0000, 0x0000, 0x6efc, 0x9e55,\n-    0x1b4e, 0x0000, 0x0000, 0x0000, 0x5e10, 0xc523, 0x1b2e, 0x0000, 0x0000, 0x0000,\n-    0x8210, 0xb6f9, 0x1b0d, 0x0000, 0x0000, 0x0000, 0x9ab0, 0x96e3, 0x1af1, 0x0000,\n-    0x0000, 0x0000, 0x3864, 0x92e7, 0x1ad1, 0x0000, 0x0000, 0x0000, 0x9878, 0xdc65,\n-    0x1ab1, 0x0000, 0x0000, 0x0000, 0xfa20, 0xd6cb, 0x1a94, 0x0000, 0x0000, 0x0000,\n-    0x6c00, 0xa4e4, 0x1a70, 0x0000, 0x0000, 0x0000, 0xab40, 0xb41b, 0x1a53, 0x0000,\n-    0x0000, 0x0000, 0x43a4, 0x8ede, 0x1a37, 0x0000, 0x0000, 0x0000, 0x22e0, 0x9314,\n-    0x1a15, 0x0000, 0x0000, 0x0000, 0x6170, 0xb949, 0x19f8, 0x0000, 0x0000, 0x0000,\n-    0x6b00, 0xe056, 0x19d8, 0x0000, 0x0000, 0x0000, 0x9ba8, 0xa94c, 0x19b9, 0x0000,\n-    0x0000, 0x0000, 0xfaa0, 0xaa16, 0x199b, 0x0000, 0x0000, 0x0000, 0x899a, 0xf627,\n-    0x197d, 0x0000, 0x0000, 0x0000, 0x9f20, 0xfb70, 0x195d, 0x0000, 0x0000, 0x0000,\n-    0xa4b8, 0xc176, 0x193e, 0x0000, 0x0000, 0x0000, 0xb21c, 0x85c3, 0x1920, 0x0000,\n-    0x0000, 0x0000, 0x50d2, 0x9b19, 0x1901, 0x0000, 0x0000, 0x0000, 0xd4b0, 0xb708,\n-    0x18e0, 0x0000, 0x0000, 0x0000, 0xfb88, 0xf510, 0x18c1, 0x0000, 0x0000, 0x0000,\n-    0x31ec, 0xdc8d, 0x18a3, 0x0000, 0x0000, 0x0000, 0x3c00, 0xbff9, 0x1885, 0x0000,\n-    0x0000, 0x0000, 0x5020, 0xc30b, 0x1862, 0x0000, 0x0000, 0x0000, 0xd4f0, 0xda0c,\n-    0x1844, 0x0000, 0x0000, 0x0000, 0x20d2, 0x99a5, 0x1828, 0x0000, 0x0000, 0x0000,\n-    0x852e, 0xd159, 0x1809, 0x0000, 0x0000, 0x0000, 0x7cd8, 0x97a1, 0x17e9, 0x0000,\n-    0x0000, 0x0000, 0x423a, 0x997b, 0x17cb, 0x0000, 0x0000, 0x0000, 0xc1c0, 0xbe7d,\n-    0x17a8, 0x0000, 0x0000, 0x0000, 0xe8bc, 0xdcdd, 0x178d, 0x0000, 0x0000, 0x0000,\n-    0x8b28, 0xae06, 0x176e, 0x0000, 0x0000, 0x0000, 0x102e, 0xb8d4, 0x174f, 0x0000,\n-    0x0000, 0x0000, 0xaa00, 0xaa5c, 0x172f, 0x0000, 0x0000, 0x0000, 0x51f0, 0x9fc0,\n-    0x170e, 0x0000, 0x0000, 0x0000, 0xf858, 0xe181, 0x16f2, 0x0000, 0x0000, 0x0000,\n-    0x91a8, 0x8162, 0x16d3, 0x0000, 0x0000, 0x0000, 0x5f40, 0xcb6f, 0x16b1, 0x0000,\n-    0x0000, 0x0000, 0xbb50, 0xe55f, 0x1693, 0x0000, 0x0000, 0x0000, 0xacd2, 0xd895,\n-    0x1676, 0x0000, 0x0000, 0x0000, 0xef30, 0x97bf, 0x1654, 0x0000, 0x0000, 0x0000,\n-    0xf700, 0xb3d7, 0x1633, 0x0000, 0x0000, 0x0000, 0x3454, 0xa7b5, 0x1619, 0x0000,\n-    0x0000, 0x0000, 0x6b00, 0xa929, 0x15f6, 0x0000, 0x0000, 0x0000, 0x9f04, 0x89f7,\n-    0x15db, 0x0000, 0x0000, 0x0000, 0xad78, 0xd985, 0x15bc, 0x0000, 0x0000, 0x0000,\n-    0xa46a, 0xae3f, 0x159d, 0x0000, 0x0000, 0x0000, 0x63a0, 0xd0da, 0x157c, 0x0000,\n-    0x0000, 0x0000, 0x5e90, 0x817d, 0x155e, 0x0000, 0x0000, 0x0000, 0x1494, 0xb13f,\n-    0x1540, 0x0000, 0x0000, 0x0000, 0x0090, 0x9c40, 0x1521, 0x0000, 0x0000, 0x0000,\n-    0xdd70, 0xcc86, 0x1500, 0x0000, 0x0000, 0x0000, 0x64f8, 0xdb6f, 0x14e1, 0x0000,\n-    0x0000, 0x0000, 0xe22c, 0xac17, 0x14c3, 0x0000, 0x0000, 0x0000, 0x60e0, 0xa9ad,\n-    0x14a3, 0x0000, 0x0000, 0x0000, 0x4640, 0xd658, 0x1481, 0x0000, 0x0000, 0x0000,\n-    0x6490, 0xa181, 0x1467, 0x0000, 0x0000, 0x0000, 0x1df4, 0xaaa2, 0x1447, 0x0000,\n-    0x0000, 0x0000, 0xb94a, 0x8f61, 0x1429, 0x0000, 0x0000, 0x0000, 0x5198, 0x9d83,\n-    0x1409, 0x0000, 0x0000, 0x0000, 0x0f7a, 0xa818, 0x13eb, 0x0000, 0x0000, 0x0000,\n-    0xc45e, 0xc06c, 0x13cc, 0x0000, 0x0000, 0x0000, 0x4ec0, 0xfa29, 0x13a8, 0x0000,\n-    0x0000, 0x0000, 0x6418, 0x8cad, 0x138c, 0x0000, 0x0000, 0x0000, 0xbcc8, 0xe7d1,\n-    0x136f, 0x0000, 0x0000, 0x0000, 0xc934, 0xf9b0, 0x134f, 0x0000, 0x0000, 0x0000,\n-    0x6ce0, 0x98df, 0x1331, 0x0000, 0x0000, 0x0000, 0x3516, 0xe5e9, 0x1312, 0x0000,\n-    0x0000, 0x0000, 0xc6c0, 0xef8b, 0x12ef, 0x0000, 0x0000, 0x0000, 0xaf02, 0x913d,\n-    0x12d4, 0x0000, 0x0000, 0x0000, 0xd230, 0xe1d5, 0x12b5, 0x0000, 0x0000, 0x0000,\n-    0xfba8, 0xc232, 0x1295, 0x0000, 0x0000, 0x0000, 0x7ba4, 0xabeb, 0x1277, 0x0000,\n-    0x0000, 0x0000, 0x6e5c, 0xc692, 0x1258, 0x0000, 0x0000, 0x0000, 0x76a2, 0x9756,\n-    0x1239, 0x0000, 0x0000, 0x0000, 0xe180, 0xe423, 0x1214, 0x0000, 0x0000, 0x0000,\n-    0x8c3c, 0x90f8, 0x11fb, 0x0000, 0x0000, 0x0000, 0x9f3c, 0x9fd2, 0x11dc, 0x0000,\n-    0x0000, 0x0000, 0x53e0, 0xb73e, 0x11bd, 0x0000, 0x0000, 0x0000, 0x45be, 0x88d6,\n-    0x119e, 0x0000, 0x0000, 0x0000, 0x111a, 0x8bc0, 0x117f, 0x0000, 0x0000, 0x0000,\n-    0xe26a, 0xd7ff, 0x1160, 0x0000, 0x0000, 0x0000, 0xfb60, 0xdd8d, 0x113f, 0x0000,\n-    0x0000, 0x0000, 0x9370, 0xc108, 0x1120, 0x0000, 0x0000, 0x0000, 0x9654, 0x8baf,\n-    0x1103, 0x0000, 0x0000, 0x0000, 0xd6ec, 0xd6b9, 0x10e4, 0x0000, 0x0000, 0x0000,\n-    0x23e4, 0xd7b7, 0x10c4, 0x0000, 0x0000, 0x0000, 0x1aa6, 0xa847, 0x10a6, 0x0000,\n-    0x0000, 0x0000, 0xbee6, 0x9fef, 0x1087, 0x0000, 0x0000, 0x0000, 0x26d0, 0xa6eb,\n-    0x1066, 0x0000, 0x0000, 0x0000, 0x5b86, 0xa880, 0x1049, 0x0000, 0x0000, 0x0000,\n-    0x125c, 0xd971, 0x1029, 0x0000, 0x0000, 0x0000, 0x1f78, 0x9d18, 0x100a, 0x0000,\n-    0x0000, 0x0000, 0x0e84, 0xb15b, 0x0feb, 0x0000, 0x0000, 0x0000, 0xd0c0, 0xc150,\n-    0x0fcc, 0x0000, 0x0000, 0x0000, 0xa330, 0xc40c, 0x0fad, 0x0000, 0x0000, 0x0000,\n-    0x5202, 0xfc2c, 0x0f8f, 0x0000, 0x0000, 0x0000, 0x3f7c, 0xecf5, 0x0f6f, 0x0000,\n-    0x0000, 0x0000, 0xef44, 0xfdfd, 0x0f50, 0x0000, 0x0000, 0x0000, 0x3f6c, 0xab1b,\n-    0x0f31, 0x0000, 0x0000, 0x0000, 0xf658, 0x89ec, 0x0f11, 0x0000, 0x0000, 0x0000,\n-    0xbfc8, 0x9ba8, 0x0ef4, 0x0000, 0x0000, 0x0000, 0x3d40, 0xbe21, 0x0ed5, 0x0000,\n-    0x0000, 0x0000, 0xbbc4, 0xc70d, 0x0eb6, 0x0000, 0x0000, 0x0000, 0x5158, 0xdb16,\n-    0x0e96, 0x0000, 0x0000, 0x0000, 0xb5a8, 0xa8d8, 0x0e78, 0x0000, 0x0000, 0x0000,\n-    0xcccc, 0xb40e, 0x0e58, 0x0000, 0x0000, 0x0000, 0x448c, 0xcb62, 0x0e3a, 0x0000,\n-    0x0000, 0x0000, 0xf12a, 0x8aed, 0x0e1b, 0x0000, 0x0000, 0x0000, 0x79d0, 0xc59c,\n-    0x0dfb, 0x0000, 0x0000, 0x0000, 0x06b4, 0xcdc9, 0x0ddd, 0x0000, 0x0000, 0x0000,\n-    0xae70, 0xa979, 0x0dbe, 0x0000, 0x0000, 0x0000, 0x317c, 0xa8fb, 0x0d9e, 0x0000,\n-    0x0000, 0x0000, 0x5fe0, 0x8a50, 0x0d7d, 0x0000, 0x0000, 0x0000, 0x70b6, 0xfdfa,\n-    0x0d61, 0x0000, 0x0000, 0x0000, 0x1640, 0x9dc7, 0x0d41, 0x0000, 0x0000, 0x0000,\n-    0x9a9c, 0xdc50, 0x0d23, 0x0000, 0x0000, 0x0000, 0x4fcc, 0x9a9b, 0x0d04, 0x0000,\n-    0x0000, 0x0000, 0x7e48, 0x8f77, 0x0ce5, 0x0000, 0x0000, 0x0000, 0x84e4, 0xd4b9,\n-    0x0cc6, 0x0000, 0x0000, 0x0000, 0x84e0, 0xbd10, 0x0ca6, 0x0000, 0x0000, 0x0000,\n-    0x1b0a, 0xc8d9, 0x0c88, 0x0000, 0x0000, 0x0000, 0x6a48, 0xfc81, 0x0c68, 0x0000,\n-    0x0000, 0x0000, 0x070a, 0xbef6, 0x0c4a, 0x0000, 0x0000, 0x0000, 0x8a70, 0xf096,\n-    0x0c2b, 0x0000, 0x0000, 0x0000, 0xecc2, 0xc994, 0x0c0c, 0x0000, 0x0000, 0x0000,\n-    0x1540, 0x9537, 0x0bea, 0x0000, 0x0000, 0x0000, 0x1b02, 0xab5b, 0x0bce, 0x0000,\n-    0x0000, 0x0000, 0x5dc0, 0xb0c8, 0x0bad, 0x0000, 0x0000, 0x0000, 0xc928, 0xe034,\n-    0x0b8f, 0x0000, 0x0000, 0x0000, 0x2d12, 0xb4b0, 0x0b71, 0x0000, 0x0000, 0x0000,\n-    0x8fc2, 0xbb94, 0x0b52, 0x0000, 0x0000, 0x0000, 0xe236, 0xe22f, 0x0b33, 0x0000,\n-    0x0000, 0x0000, 0xb97c, 0xbe9e, 0x0b13, 0x0000, 0x0000, 0x0000, 0xe1a6, 0xe16d,\n-    0x0af5, 0x0000, 0x0000, 0x0000, 0xd330, 0xbaf0, 0x0ad6, 0x0000, 0x0000, 0x0000,\n-    0xc0bc, 0xbbd0, 0x0ab7, 0x0000, 0x0000, 0x0000, 0x8e66, 0xdd9b, 0x0a98, 0x0000,\n-    0x0000, 0x0000, 0xc95c, 0xf799, 0x0a79, 0x0000, 0x0000, 0x0000, 0xdac0, 0xbe4c,\n-    0x0a55, 0x0000, 0x0000, 0x0000, 0xafc0, 0xc378, 0x0a37, 0x0000, 0x0000, 0x0000,\n-    0xa880, 0xe341, 0x0a19, 0x0000, 0x0000, 0x0000, 0xc242, 0x81f6, 0x09fd, 0x0000,\n-    0x0000, 0x0000, 0x7470, 0xc777, 0x09de, 0x0000, 0x0000, 0x0000, 0x62bc, 0xb684,\n-    0x09be, 0x0000, 0x0000, 0x0000, 0x43ac, 0x8c58, 0x099f, 0x0000, 0x0000, 0x0000,\n-    0xcc3c, 0xf9ac, 0x0981, 0x0000, 0x0000, 0x0000, 0x1526, 0xb670, 0x0962, 0x0000,\n-    0x0000, 0x0000, 0xc9fe, 0xdf50, 0x0943, 0x0000, 0x0000, 0x0000, 0x6ae6, 0xc065,\n-    0x0924, 0x0000, 0x0000, 0x0000, 0xb114, 0xcf29, 0x0905, 0x0000, 0x0000, 0x0000,\n-    0xd388, 0x922a, 0x08e4, 0x0000, 0x0000, 0x0000, 0xcf54, 0xb926, 0x08c7, 0x0000,\n-    0x0000, 0x0000, 0x3826, 0xe855, 0x08a8, 0x0000, 0x0000, 0x0000, 0xe7c8, 0x829b,\n-    0x0888, 0x0000, 0x0000, 0x0000, 0x546c, 0xa903, 0x086a, 0x0000, 0x0000, 0x0000,\n-    0x8768, 0x99cc, 0x0849, 0x0000, 0x0000, 0x0000, 0x00ac, 0xf529, 0x082b, 0x0000,\n-    0x0000, 0x0000, 0x2658, 0x9f0b, 0x080c, 0x0000, 0x0000, 0x0000, 0xfe5c, 0x9e21,\n-    0x07ee, 0x0000, 0x0000, 0x0000, 0x6da2, 0x9910, 0x07cf, 0x0000, 0x0000, 0x0000,\n-    0x9220, 0xf9b3, 0x07b0, 0x0000, 0x0000, 0x0000, 0x3d90, 0xa541, 0x0791, 0x0000,\n-    0x0000, 0x0000, 0x6e4c, 0xe7cc, 0x0771, 0x0000, 0x0000, 0x0000, 0xa8fa, 0xe80a,\n-    0x0753, 0x0000, 0x0000, 0x0000, 0x4e14, 0xc3a7, 0x0734, 0x0000, 0x0000, 0x0000,\n-    0xf7e0, 0xbad9, 0x0712, 0x0000, 0x0000, 0x0000, 0xfea0, 0xeff2, 0x06f5, 0x0000,\n-    0x0000, 0x0000, 0xcef6, 0xbd48, 0x06d7, 0x0000, 0x0000, 0x0000, 0x7544, 0xf559,\n-    0x06b7, 0x0000, 0x0000, 0x0000, 0x2388, 0xf655, 0x0698, 0x0000, 0x0000, 0x0000,\n-    0xe900, 0xad56, 0x0676, 0x0000, 0x0000, 0x0000, 0x2cc0, 0x8437, 0x0659, 0x0000,\n-    0x0000, 0x0000, 0x3068, 0xc544, 0x063b, 0x0000, 0x0000, 0x0000, 0xdc70, 0xe73c,\n-    0x061b, 0x0000, 0x0000, 0x0000, 0xee50, 0x9d49, 0x05fc, 0x0000, 0x0000, 0x0000,\n-    0x93d2, 0x81f6, 0x05df, 0x0000, 0x0000, 0x0000, 0x941c, 0xadff, 0x05bf, 0x0000,\n-    0x0000, 0x0000, 0x2ce2, 0x8e45, 0x05a1, 0x0000, 0x0000, 0x0000, 0x4a60, 0x95fd,\n-    0x0581, 0x0000, 0x0000, 0x0000, 0x79f8, 0xb83a, 0x0563, 0x0000, 0x0000, 0x0000,\n-    0xcb58, 0xa1f5, 0x0543, 0x0000, 0x0000, 0x0000, 0x2a3a, 0xdc36, 0x0525, 0x0000,\n-    0x0000, 0x0000, 0x14ee, 0x890e, 0x0506, 0x0000, 0x0000, 0x0000, 0x8f20, 0xc432,\n-    0x04e3, 0x0000, 0x0000, 0x0000, 0x8440, 0xb21d, 0x04c6, 0x0000, 0x0000, 0x0000,\n-    0x5430, 0xf698, 0x04a7, 0x0000, 0x0000, 0x0000, 0x04ae, 0x8b20, 0x048a, 0x0000,\n-    0x0000, 0x0000, 0x04d0, 0xe872, 0x046b, 0x0000, 0x0000, 0x0000, 0xc78e, 0x8893,\n-    0x044c, 0x0000, 0x0000, 0x0000, 0x0f78, 0x9895, 0x042b, 0x0000, 0x0000, 0x0000,\n-    0x11d4, 0xdf2e, 0x040d, 0x0000, 0x0000, 0x0000, 0xe84c, 0x89d5, 0x03ef, 0x0000,\n-    0x0000, 0x0000, 0xf7be, 0x8a67, 0x03d0, 0x0000, 0x0000, 0x0000, 0x95d0, 0xc906,\n-    0x03b1, 0x0000, 0x0000, 0x0000, 0x64ce, 0xd96c, 0x0392, 0x0000, 0x0000, 0x0000,\n-    0x97ba, 0xa16f, 0x0373, 0x0000, 0x0000, 0x0000, 0x463c, 0xc51a, 0x0354, 0x0000,\n-    0x0000, 0x0000, 0xef0a, 0xe93e, 0x0335, 0x0000, 0x0000, 0x0000, 0x526a, 0xa466,\n-    0x0316, 0x0000, 0x0000, 0x0000, 0x4140, 0xa94d, 0x02f5, 0x0000, 0x0000, 0x0000,\n-    0xb4ec, 0xce68, 0x02d8, 0x0000, 0x0000, 0x0000, 0x4fa2, 0x8490, 0x02b9, 0x0000,\n-    0x0000, 0x0000, 0x4e60, 0xca98, 0x0298, 0x0000, 0x0000, 0x0000, 0x08dc, 0xe09c,\n-    0x027a, 0x0000, 0x0000, 0x0000, 0x2b90, 0xc7e3, 0x025c, 0x0000, 0x0000, 0x0000,\n-    0x5a7c, 0xf8ef, 0x023c, 0x0000, 0x0000, 0x0000, 0x5022, 0x9d58, 0x021e, 0x0000,\n-    0x0000, 0x0000, 0x553a, 0xe242, 0x01ff, 0x0000, 0x0000, 0x0000, 0x7e6e, 0xb54d,\n-    0x01e0, 0x0000, 0x0000, 0x0000, 0xd2d4, 0xa88c, 0x01c1, 0x0000, 0x0000, 0x0000,\n-    0x75b6, 0xfe6d, 0x01a2, 0x0000, 0x0000, 0x0000, 0x3bb2, 0xf04c, 0x0183, 0x0000,\n-    0x0000, 0x0000, 0xc2d0, 0xc046, 0x0163, 0x0000, 0x0000, 0x0000, 0x250c, 0xf9d6,\n-    0x0145, 0x0000, 0x0000, 0x0000, 0xb7b4, 0x8a0d, 0x0126, 0x0000, 0x0000, 0x0000,\n-    0x1a72, 0xe4f5, 0x0107, 0x0000, 0x0000, 0x0000, 0x825c, 0xa9b8, 0x00e8, 0x0000,\n-    0x0000, 0x0000, 0x6c90, 0xc9ad, 0x00c6, 0x0000, 0x0000, 0x0000, 0x4d00, 0xd1bb,\n-    0x00aa, 0x0000, 0x0000, 0x0000, 0xa4a0, 0xee01, 0x0087, 0x0000, 0x0000, 0x0000,\n-    0x89a8, 0xbe9f, 0x006b, 0x0000, 0x0000, 0x0000, 0x038e, 0xc80c, 0x004d, 0x0000,\n-    0x0000, 0x0000, 0xfe26, 0x8384, 0x002e, 0x0000, 0x0000, 0x0000, 0xcd90, 0xca57,\n-    0x000e, 0x0000\n-};\n-\n-void MacroAssembler::libm_reduce_pi04l(Register eax, Register ecx, Register edx, Register ebx, Register esi, Register edi, Register ebp, Register esp) {\n-  Label B1_1, B1_2, B1_3, B1_4, B1_5, B1_6, B1_7, B1_8, B1_9, B1_10, B1_11, B1_12;\n-  Label B1_13, B1_14, B1_15;\n-\n-  assert_different_registers(ebx, eax, ecx, edx, esi, edi, ebp, esp);\n-\n-  address zero_none  = (address)_zero_none;\n-  address _4onpi_d   = (address)__4onpi_d;\n-  address TWO_32H    = (address)_TWO_32H;\n-  address pi04_3d    = (address)_pi04_3d;\n-  address pi04_5d    = (address)_pi04_5d;\n-  address SCALE      = (address)_SCALE;\n-  address zeros      = (address)_zeros;\n-  address pi04_2d    = (address)_pi04_2d;\n-  address TWO_12H    = (address)_TWO_12H;\n-  address _4onpi_31l = (address)__4onpi_31l;\n-\n-  bind(B1_1);\n-  push(ebp);\n-  movl(ebp, esp);\n-  andl(esp, -16);\n-  push(esi);\n-  push(edi);\n-  push(ebx);\n-  subl(esp, 20);\n-  movzwl(ebx, Address(ebp, 16));\n-  andl(ebx, 32767);\n-  movl(eax, Address(ebp, 20));\n-  cmpl(ebx, 16413);\n-  movl(esi, Address(ebp, 24));\n-  movl(Address(esp, 4), eax);\n-  jcc(Assembler::greaterEqual, B1_8);\n-\n-  bind(B1_2);\n-  fld_x(Address(ebp, 8));\n-  fld_d(ExternalAddress(_4onpi_d));    \/\/0x6dc9c883UL, 0x3ff45f30UL\n-  fmul(1);\n-  fstp_x(Address(esp, 8));\n-  movzwl(ecx, Address(esp, 16));\n-  negl(ecx);\n-  addl(ecx, 30);\n-  movl(eax, Address(esp, 12));\n-  shrl(eax);\n-  cmpl(Address(esp, 4), 0);\n-  jcc(Assembler::notEqual, B1_4);\n-\n-  bind(B1_3);\n-  lea(ecx, Address(eax, 1));\n-  andl(ecx, -2);\n-  jmp(B1_5);\n-\n-  bind(B1_4);\n-  movl(ecx, eax);\n-  addl(eax, Address(esp, 4));\n-  movl(edx, eax);\n-  andl(edx, 1);\n-  addl(ecx, edx);\n-\n-  bind(B1_5);\n-  fld_d(ExternalAddress(TWO_32H));    \/\/0x00000000UL, 0x41f80000UL\n-  cmpl(ebx, 16400);\n-  movl(Address(esp, 0), ecx);\n-  fild_s(Address(esp, 0));\n-  jcc(Assembler::greaterEqual, B1_7);\n-\n-  bind(B1_6);\n-  fld_d(ExternalAddress(pi04_3d));    \/\/0x54442d00UL, 0x3fe921fbUL\n-  fmul(1);\n-  fsubp(3);\n-  fxch(1);\n-  fmul(2);\n-  fld_s(2);\n-  fadd(1);\n-  fsubrp(1);\n-  fld_s(0);\n-  fxch(1);\n-  fsuba(3);\n-  fld_d(ExternalAddress(8 + pi04_3d));    \/\/0x98cc5180UL, 0x3ce84698UL\n-  fmul(3);\n-  fsuba(2);\n-  fxch(1);\n-  fsub(2);\n-  fsubrp(1);\n-  faddp(3);\n-  fld_d(ExternalAddress(16 + pi04_3d));    \/\/0xcbb5bf6cUL, 0xb9dfc8f8UL\n-  fmulp(2);\n-  fld_s(1);\n-  fsubr(1);\n-  fsuba(1);\n-  fxch(2);\n-  fsubp(1);\n-  faddp(2);\n-  fxch(1);\n-  jmp(B1_15);\n-\n-  bind(B1_7);\n-  fld_d(ExternalAddress(pi04_5d));    \/\/0x54400000UL, 0x3fe921fbUL\n-  fmul(1);\n-  fsubp(3);\n-  fxch(1);\n-  fmul(2);\n-  fld_s(2);\n-  fadd(1);\n-  fsubrp(1);\n-  fld_s(0);\n-  fxch(1);\n-  fsuba(3);\n-  fld_d(ExternalAddress(8 + pi04_5d));    \/\/0x1a600000UL, 0x3dc0b461UL\n-  fmul(3);\n-  fsuba(2);\n-  fxch(1);\n-  fsub(2);\n-  fsubrp(1);\n-  faddp(3);\n-  fld_d(ExternalAddress(16 + pi04_5d));    \/\/0x2e000000UL, 0x3b93198aUL\n-  fmul(2);\n-  fld_s(0);\n-  fsubr(2);\n-  fsuba(2);\n-  fxch(1);\n-  fsubp(2);\n-  fxch(1);\n-  faddp(3);\n-  fld_d(ExternalAddress(24 + pi04_5d));    \/\/0x25200000UL, 0x396b839aUL\n-  fmul(2);\n-  fld_s(0);\n-  fsubr(2);\n-  fsuba(2);\n-  fxch(1);\n-  fsubp(2);\n-  fxch(1);\n-  faddp(3);\n-  fld_d(ExternalAddress(32 + pi04_5d));    \/\/0x533e63a0UL, 0x37027044UL\n-  fmulp(2);\n-  fld_s(1);\n-  fsubr(1);\n-  fsuba(1);\n-  fxch(2);\n-  fsubp(1);\n-  faddp(2);\n-  fxch(1);\n-  jmp(B1_15);\n-\n-  bind(B1_8);\n-  fld_x(Address(ebp, 8));\n-  addl(ebx, -16417);\n-  fmul_d(as_Address(ExternalAddress(SCALE)));    \/\/0x00000000UL, 0x32600000UL\n-  movl(eax, -2078209981);\n-  imull(ebx);\n-  addl(edx, ebx);\n-  movl(ecx, ebx);\n-  sarl(edx, 4);\n-  sarl(ecx, 31);\n-  subl(edx, ecx);\n-  movl(eax, edx);\n-  shll(eax, 5);\n-  fstp_x(Address(ebp, 8));\n-  fld_x(Address(ebp, 8));\n-  subl(eax, edx);\n-  movl(Address(ebp, 8), 0);\n-  subl(ebx, eax);\n-  fld_x(Address(ebp, 8));\n-  cmpl(ebx, 17);\n-  fsuba(1);\n-  jcc(Assembler::less, B1_10);\n-\n-  bind(B1_9);\n-  lea(eax, Address(noreg, edx, Address::times_8));\n-  lea(ecx, Address(eax, edx, Address::times_4));\n-  incl(edx);\n-  fld_x(Address(_4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmul(2);\n-  fld_x(Address(12 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmul(2);\n-  fld_s(0);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(1);\n-  faddp(2);\n-  fld_s(1);\n-  fadd(1);\n-  fstp_x(Address(esp, 8));\n-  andl(Address(esp, 8), -16777216);\n-  fld_x(Address(esp, 8));\n-  fsubp(1);\n-  jmp(B1_11);\n-\n-  bind(B1_10);\n-  fld_d(ExternalAddress(zeros));    \/\/0x00000000UL, 0x00000000UL\n-  fld_s(0);\n-\n-  bind(B1_11);\n-  fld_s(0);\n-  lea(eax, Address(noreg, edx, Address::times_8));\n-  fld_s(3);\n-  lea(edx, Address(eax, edx, Address::times_4));\n-  fld_x(Address(_4onpi_31l, RelocationHolder::none).plus_disp(edx, Address::times_1));\n-  fmul(6);\n-  movl(Address(esp, 0), edx);\n-  fadda(2);\n-  fxch(2);\n-  fsuba(3);\n-  fxch(2);\n-  faddp(3);\n-  fxch(2);\n-  faddp(3);\n-  fld_x(Address(12 + _4onpi_31l, RelocationHolder::none).plus_disp(edx, Address::times_1));\n-  fmula(2);\n-  fld_s(2);\n-  fadd(2);\n-  fld_s(0);\n-  fxch(1);\n-  fsubra(3);\n-  fxch(3);\n-  fchs();\n-  faddp(4);\n-  fxch(3);\n-  faddp(4);\n-  fxch(2);\n-  fadd(3);\n-  fxch(2);\n-  fmul(5);\n-  fadda(2);\n-  fld_s(4);\n-  fld_x(Address(24 + _4onpi_31l, RelocationHolder::none).plus_disp(edx, Address::times_1));\n-  fmula(1);\n-  fxch(1);\n-  fadda(4);\n-  fxch(4);\n-  fstp_x(Address(esp, 8));\n-  movzwl(ebx, Address(esp, 16));\n-  andl(ebx, 32767);\n-  cmpl(ebx, 16415);\n-  jcc(Assembler::greaterEqual, B1_13);\n-\n-  bind(B1_12);\n-  negl(ebx);\n-  addl(ebx, 30);\n-  movl(ecx, ebx);\n-  movl(eax, Address(esp, 12));\n-  shrl(eax);\n-  shll(eax);\n-  movl(Address(esp, 12), eax);\n-  movl(Address(esp, 8), 0);\n-  shrl(eax);\n-  jmp(B1_14);\n-\n-  bind(B1_13);\n-  negl(ebx);\n-  addl(ebx, 30);\n-  movl(ecx, ebx);\n-  movl(edx, Address(esp, 8));\n-  shrl(edx);\n-  shll(edx);\n-  negl(ecx);\n-  movl(eax, Address(esp, 12));\n-  shll(eax);\n-  movl(ecx, ebx);\n-  movl(Address(esp, 8), edx);\n-  shrl(edx);\n-  orl(eax, edx);\n-\n-  bind(B1_14);\n-  fld_x(Address(esp, 8));\n-  addl(eax, Address(esp, 4));\n-  fsubp(3);\n-  fmul(6);\n-  fld_s(4);\n-  movl(edx, eax);\n-  andl(edx, 1);\n-  fadd(3);\n-  movl(ecx, Address(esp, 0));\n-  fsuba(3);\n-  fxch(3);\n-  faddp(5);\n-  fld_s(1);\n-  fxch(3);\n-  fadd_d(Address(zero_none, RelocationHolder::none).plus_disp(edx, Address::times_8));\n-  fadda(3);\n-  fsub(3);\n-  faddp(2);\n-  fxch(1);\n-  faddp(4);\n-  fld_s(2);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(3);\n-  faddp(2);\n-  fxch(1);\n-  faddp(3);\n-  fld_s(0);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(1);\n-  faddp(2);\n-  fxch(1);\n-  faddp(2);\n-  fld_s(2);\n-  fld_x(Address(36 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmula(1);\n-  fld_s(1);\n-  fadd(3);\n-  fsuba(3);\n-  fxch(2);\n-  faddp(3);\n-  fxch(2);\n-  faddp(3);\n-  fxch(1);\n-  fmul(4);\n-  fld_s(0);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(1);\n-  faddp(2);\n-  fxch(1);\n-  faddp(2);\n-  fld_s(2);\n-  fld_x(Address(48 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmula(1);\n-  fld_s(1);\n-  fadd(3);\n-  fsuba(3);\n-  fxch(2);\n-  faddp(3);\n-  fxch(2);\n-  faddp(3);\n-  fld_s(3);\n-  fxch(2);\n-  fmul(5);\n-  fld_x(Address(60 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmula(3);\n-  fxch(3);\n-  faddp(1);\n-  fld_s(0);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(1);\n-  faddp(2);\n-  fxch(1);\n-  faddp(3);\n-  fld_s(3);\n-  fxch(2);\n-  fmul(5);\n-  fld_x(Address(72 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmula(3);\n-  fxch(3);\n-  faddp(1);\n-  fld_s(0);\n-  fadd(2);\n-  fsuba(2);\n-  fxch(1);\n-  faddp(2);\n-  fxch(1);\n-  faddp(3);\n-  fxch(1);\n-  fmulp(4);\n-  fld_x(Address(84 + _4onpi_31l, RelocationHolder::none).plus_disp(ecx, Address::times_1));\n-  fmulp(3);\n-  fxch(2);\n-  faddp(3);\n-  fld_s(2);\n-  fadd(2);\n-  fld_d(ExternalAddress(TWO_32H));    \/\/0x00000000UL, 0x41f80000UL\n-  fmul(1);\n-  fadda(1);\n-  fsubp(1);\n-  fsuba(2);\n-  fxch(3);\n-  faddp(2);\n-  faddp(1);\n-  fld_d(ExternalAddress(pi04_2d));    \/\/0x54400000UL, 0x3fe921fbUL\n-  fld_s(0);\n-  fmul(2);\n-  fxch(2);\n-  fadd(3);\n-  fxch(1);\n-  fmulp(3);\n-  fmul_d(as_Address(ExternalAddress(8 + pi04_2d)));    \/\/0x1a626331UL, 0x3dc0b461UL\n-  faddp(1);\n-\n-  bind(B1_15);\n-  fld_d(ExternalAddress(TWO_12H));    \/\/0x00000000UL, 0x40b80000UL\n-  fld_s(2);\n-  fadd(2);\n-  fmula(1);\n-  fstp_x(Address(esp, 8));\n-  fld_x(Address(esp, 8));\n-  fadd(1);\n-  fsubrp(1);\n-  fst_d(Address(esi, 0));\n-  fsubp(2);\n-  faddp(1);\n-  fstp_d(Address(esi, 8));\n-  addl(esp, 20);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-}\n-\n-\n-ATTRIBUTE_ALIGNED(16) static const jushort _SP[] =\n-{\n-    0xaaab, 0xaaaa, 0xaaaa, 0xaaaa, 0xbffc, 0x0000, 0x8887, 0x8888, 0x8888, 0x8888,\n-    0x3ff8, 0x0000, 0xc527, 0x0d00, 0x00d0, 0xd00d, 0xbff2, 0x0000, 0x45f6, 0xb616,\n-    0x1d2a, 0xb8ef, 0x3fec, 0x0000, 0x825b, 0x3997, 0x2b3f, 0xd732, 0xbfe5, 0x0000,\n-    0xbf33, 0x8bb4, 0x2fda, 0xb092, 0x3fde, 0x0000, 0x44a6, 0xed1a, 0x29ef, 0xd73e,\n-    0xbfd6, 0x0000, 0x8610, 0x307f, 0x62a1, 0xc921, 0x3fce, 0x0000\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const jushort _CP[] =\n-{\n-    0x0000, 0x0000, 0x0000, 0x8000, 0xbffe, 0x0000, 0xaaa5, 0xaaaa, 0xaaaa, 0xaaaa,\n-    0x3ffa, 0x0000, 0x9c2f, 0x0b60, 0x60b6, 0xb60b, 0xbff5, 0x0000, 0xf024, 0x0cac,\n-    0x00d0, 0xd00d, 0x3fef, 0x0000, 0x03fe, 0x3f65, 0x7dbb, 0x93f2, 0xbfe9, 0x0000,\n-    0xd84d, 0xadee, 0xc698, 0x8f76, 0x3fe2, 0x0000, 0xdaba, 0xfe79, 0xea36, 0xc9c9,\n-    0xbfda, 0x0000, 0x3ac6, 0x0ba0, 0x07ce, 0xd585, 0x3fd2, 0x0000\n-};\n-\n-void MacroAssembler::libm_sincos_huge(XMMRegister xmm0, XMMRegister xmm1, Register eax, Register ecx, Register edx, Register ebx, Register esi, Register edi, Register ebp, Register esp) {\n-  Label B1_1, B1_2, B1_3, B1_4, B1_5, B1_6, B1_7, B1_8, B1_9, B1_10, B1_11, B1_12;\n-  Label B1_13, B1_14, B1_15, B1_16, B1_17, B1_18, B1_19, B1_20, B1_21, B1_22, B1_23;\n-  Label B1_24, B1_25, B1_26, B1_27, B1_28, B1_29, B1_30, B1_31, B1_32, B1_33, B1_34;\n-  Label B1_35, B1_36, B1_37, B1_38, B1_39, B1_40, B1_41, B1_42, B1_43, B1_46;\n-\n-  assert_different_registers(ebx, eax, ecx, edx, esi, edi, ebp, esp);\n-\n-  address CP = (address)_CP;\n-  address SP = (address)_SP;\n-\n-  bind(B1_1);\n-  push(ebp);\n-  movl(ebp, esp);\n-  andl(esp, -64);\n-  push(esi);\n-  push(edi);\n-  push(ebx);\n-  subl(esp, 52);\n-  movl(eax, Address(ebp, 16));\n-  movl(edx, Address(ebp, 20));\n-  movl(Address(esp, 32), eax);\n-  movl(Address(esp, 36), edx);\n-\n-  bind(B1_2);\n-  fnstcw(Address(esp, 30));\n-\n-  bind(B1_3);\n-  movsd(xmm1, Address(ebp, 8));\n-  movl(esi, Address(ebp, 12));\n-  movl(eax, esi);\n-  andl(eax, 2147483647);\n-  andps(xmm1, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n-  shrl(esi, 31);\n-  movl(Address(esp, 40), eax);\n-  cmpl(eax, 1104150528);\n-  movsd(Address(ebp, 8), xmm1);\n-  jcc(Assembler::aboveEqual, B1_11);\n-\n-  bind(B1_4);\n-  movsd(xmm0, ExternalAddress(PI4_INV));    \/\/0x6dc9c883UL, 0x3ff45f30UL\n-  mulsd(xmm0, xmm1);\n-  movzwl(edx, Address(esp, 30));\n-  movl(eax, edx);\n-  andl(eax, 768);\n-  movsd(Address(esp, 0), xmm0);\n-  cmpl(eax, 768);\n-  jcc(Assembler::equal, B1_42);\n-\n-  bind(B1_5);\n-  orl(edx, -64768);\n-  movw(Address(esp, 28), edx);\n-\n-  bind(B1_6);\n-  fldcw(Address(esp, 28));\n-\n-  bind(B1_7);\n-  movsd(xmm1, Address(ebp, 8));\n-  movl(ebx, 1);\n-\n-  bind(B1_8);\n-  movl(Address(esp, 12), ebx);\n-  movl(ebx, Address(esp, 4));\n-  movl(eax, ebx);\n-  movl(Address(esp, 8), esi);\n-  movl(esi, ebx);\n-  shrl(esi, 20);\n-  andl(eax, 1048575);\n-  movl(ecx, esi);\n-  orl(eax, 1048576);\n-  negl(ecx);\n-  movl(edx, eax);\n-  addl(ecx, 19);\n-  addl(esi, 13);\n-  movl(Address(esp, 24), ecx);\n-  shrl(edx);\n-  movl(ecx, esi);\n-  shll(eax);\n-  movl(ecx, Address(esp, 24));\n-  movl(esi, Address(esp, 0));\n-  shrl(esi);\n-  orl(eax, esi);\n-  cmpl(ebx, 1094713344);\n-  movsd(Address(esp, 16), xmm1);\n-  fld_d(Address(esp, 16));\n-  cmov32(Assembler::below, eax, edx);\n-  movl(esi, Address(esp, 8));\n-  lea(edx, Address(eax, 1));\n-  movl(ebx, edx);\n-  andl(ebx, -2);\n-  movl(Address(esp, 16), ebx);\n-  fild_s(Address(esp, 16));\n-  movl(ebx, Address(esp, 12));\n-  cmpl(Address(esp, 40), 1094713344);\n-  jcc(Assembler::aboveEqual, B1_10);\n-\n-  bind(B1_9);\n-  fld_d(ExternalAddress(PI4X3));    \/\/0x54443000UL, 0xbfe921fbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X3 + 8));    \/\/0x3b39a000UL, 0x3d373dcbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X3 + 16));    \/\/0xe0e68948UL, 0xba845c06UL\n-  fmulp(1);\n-  faddp(1);\n-  jmp(B1_17);\n-\n-  bind(B1_10);\n-  fld_d(ExternalAddress(PI4X4));    \/\/0x54400000UL, 0xbfe921fbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 8));    \/\/0x1a600000UL, 0xbdc0b461UL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 16));    \/\/0x2e000000UL, 0xbb93198aUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 24));    \/\/0x252049c1UL, 0xb96b839aUL\n-  fmulp(1);\n-  faddp(1);\n-  jmp(B1_17);\n-\n-  bind(B1_11);\n-  movzwl(edx, Address(esp, 30));\n-  movl(eax, edx);\n-  andl(eax, 768);\n-  cmpl(eax, 768);\n-  jcc(Assembler::equal, B1_43);\n-  bind(B1_12);\n-  orl(edx, -64768);\n-  movw(Address(esp, 28), edx);\n-\n-  bind(B1_13);\n-  fldcw(Address(esp, 28));\n-\n-  bind(B1_14);\n-  movsd(xmm1, Address(ebp, 8));\n-  movl(ebx, 1);\n-\n-  bind(B1_15);\n-  movsd(Address(esp, 16), xmm1);\n-  fld_d(Address(esp, 16));\n-  addl(esp, -32);\n-  lea(eax, Address(esp, 32));\n-  fstp_x(Address(esp, 0));\n-  movl(Address(esp, 12), 0);\n-  movl(Address(esp, 16), eax);\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlibm_reduce_pi04l())));\n-\n-  bind(B1_46);\n-  addl(esp, 32);\n-\n-  bind(B1_16);\n-  fld_d(Address(esp, 0));\n-  lea(edx, Address(eax, 1));\n-  fld_d(Address(esp, 8));\n-  faddp(1);\n-\n-  bind(B1_17);\n-  movl(ecx, edx);\n-  addl(eax, 3);\n-  shrl(ecx, 2);\n-  andl(ecx, 1);\n-  shrl(eax, 2);\n-  xorl(esi, ecx);\n-  movl(ecx, Address(esp, 36));\n-  andl(eax, 1);\n-  andl(ecx, 3);\n-  cmpl(ecx, 3);\n-  jcc(Assembler::notEqual, B1_25);\n-\n-  bind(B1_18);\n-  fld_x(ExternalAddress(84 + SP));    \/\/0x8610, 0x307f, 0x62\n-  fld_s(1);\n-  fmul((2));\n-  testb(edx, 2);\n-  fmula((1));\n-  fld_x(ExternalAddress(72 + SP));    \/\/0x44a6, 0xed1a, 0x29\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(60 + SP));    \/\/0xbf33, 0x8bb4, 0x2f\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(48 + SP));    \/\/0x825b, 0x3997, 0x2b\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(36 + SP));    \/\/0x45f6, 0xb616, 0x1d\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(24 + SP));    \/\/0xc527, 0x0d00, 0x00\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(12 + SP));    \/\/0x8887, 0x8888, 0x88\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(SP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(2);\n-  fmula(1);\n-  fld_x(ExternalAddress(84 + CP));    \/\/0x3ac6, 0x0ba0, 0x07\n-  fmul(1);\n-  fld_x(ExternalAddress(72 + CP));    \/\/0xdaba, 0xfe79, 0xea\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(62 + CP));    \/\/0xd84d, 0xadee, 0xc6\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(48 + CP));    \/\/0x03fe, 0x3f65, 0x7d\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(36 + CP));    \/\/0xf024, 0x0cac, 0x00\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(24 + CP));    \/\/0x9c2f, 0x0b60, 0x60\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(12 + CP));    \/\/0xaaa5, 0xaaaa, 0xaa\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(CP));    \/\/0x0000, 0x0000, 0x00\n-  faddp(1);\n-  fmulp(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(esi, Address::times_8));\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  jcc(Assembler::equal, B1_22);\n-\n-  bind(B1_19);\n-  fmulp(4);\n-  testl(ebx, ebx);\n-  fxch(2);\n-  fmul(3);\n-  movl(eax, Address(esp, 2));\n-  faddp(3);\n-  fxch(2);\n-  fstp_d(Address(eax, 0));\n-  fmula(1);\n-  faddp(1);\n-  fstp_d(Address(eax, 8));\n-  jcc(Assembler::equal, B1_21);\n-\n-  bind(B1_20);\n-  fldcw(Address(esp, 30));\n-\n-  bind(B1_21);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_22);\n-  fxch(1);\n-  fmulp(4);\n-  testl(ebx, ebx);\n-  fxch(2);\n-  fmul(3);\n-  movl(eax, Address(esp, 32));\n-  faddp(3);\n-  fxch(2);\n-  fstp_d(Address(eax, 8));\n-  fmula(1);\n-  faddp(1);\n-  fstp_d(Address(eax, 0));\n-  jcc(Assembler::equal, B1_24);\n-\n-  bind(B1_23);\n-  fldcw(Address(esp, 30));\n-\n-  bind(B1_24);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_25);\n-  testb(Address(esp, 36), 2);\n-  jcc(Assembler::equal, B1_33);\n-\n-  bind(B1_26);\n-  fld_s(0);\n-  testb(edx, 2);\n-  fmul(1);\n-  fld_s(0);\n-  fmul(1);\n-  jcc(Assembler::equal, B1_30);\n-\n-  bind(B1_27);\n-  fstp_d(2);\n-  fld_x(ExternalAddress(84 + CP));    \/\/0x3ac6, 0x0ba0, 0x07\n-  testl(ebx, ebx);\n-  fmul(2);\n-  fld_x(ExternalAddress(72 + CP));    \/\/0xdaba, 0xfe79, 0xea\n-  fmul(3);\n-  fld_x(ExternalAddress(60 + CP));    \/\/0xd84d, 0xadee, 0xc6\n-  movl(eax, Address(rsp, 32));\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(48 + CP));    \/\/0x03fe, 0x3f65, 0x7d\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(36 + CP));    \/\/0xf024, 0x0cac, 0x00\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(24 + CP));    \/\/0x9c2f, 0x0b60, 0x60\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(12 + CP));    \/\/0xaaa5, 0xaaaa, 0xaa\n-  faddp(2);\n-  fxch(1);\n-  fmulp(3);\n-  fld_x(ExternalAddress(CP));    \/\/0x0000, 0x0000, 0x00\n-  faddp(1);\n-  fmulp(1);\n-  faddp(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n-  fmula(1);\n-  faddp(1);\n-  fstp_d(Address(eax, 8));\n-  jcc(Assembler::equal, B1_29);\n-\n-  bind(B1_28);\n-  fldcw(Address(esp, 30));\n-\n-  bind(B1_29);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_30);\n-  fld_x(ExternalAddress(84 + SP));    \/\/0x8610, 0x307f, 0x62\n-  testl(ebx, ebx);\n-  fmul(1);\n-  fld_x(ExternalAddress(72 + SP));    \/\/0x44a6, 0xed1a, 0x29\n-  fmul(2);\n-  fld_x(ExternalAddress(60 + SP));    \/\/0xbf33, 0x8bb4, 0x2f\n-  movl(eax, Address(rsp, 32));\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(48 + SP));    \/\/0x825b, 0x3997, 0x2b\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(36 + SP));    \/\/0x45f6, 0xb616, 0x1d\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + SP));    \/\/0xc527, 0x0d00, 0x00\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(12 + SP));    \/\/0x8887, 0x8888, 0x88\n-  faddp(2);\n-  fxch(1);\n-  fmulp(2);\n-  fld_x(ExternalAddress(SP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(1);\n-  fmulp(2);\n-  faddp(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n-  fmulp(2);\n-  fmul(1);\n-  faddp(1);\n-  fstp_d(Address(eax, 8));\n-  jcc(Assembler::equal, B1_32);\n-\n-  bind(B1_31);\n-  fldcw(Address(esp, 30));\n-\n-  bind(B1_32);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_33);\n-  testb(Address(esp, 36), 1);\n-  jcc(Assembler::equal, B1_41);\n-\n-  bind(B1_34);\n-  fld_s(0);\n-  testb(edx, 2);\n-  fmul(1);\n-  fld_s(0);\n-  fmul(1);\n-  jcc(Assembler::equal, B1_38);\n-\n-  bind(B1_35);\n-  fld_x(ExternalAddress(84 + SP));    \/\/0x8610, 0x307f, 0x62\n-  testl(ebx, ebx);\n-  fmul(1);\n-  fld_x(ExternalAddress(72 + SP));    \/\/0x44a6, 0xed1a, 0x29\n-  fmul(2);\n-  fld_x(ExternalAddress(60 + SP));    \/\/0xbf33, 0x8bb4, 0x2f\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(48 + SP));    \/\/0x825b, 0x3997, 0x2b\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(36 + SP));    \/\/0x45f6, 0xb616, 0x1d\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + SP));    \/\/0xc527, 0x0d00, 0x00\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(12 + SP));    \/\/0x8887, 0x8888, 0x88\n-  faddp(2);\n-  fxch(1);\n-  fmulp(2);\n-  fld_x(ExternalAddress(SP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(1);\n-  fmulp(2);\n-  faddp(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmulp(2);\n-  fmul(1);\n-  movl(eax, Address(esp, 32));\n-  faddp(1);\n-  fstp_d(Address(eax, 0));\n-  jcc(Assembler::equal, B1_37);\n-\n-  bind(B1_36);\n-  fldcw(Address(esp, 30));\n-\n-  bind(B1_37);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_38);\n-  fstp_d(2);\n-  fld_x(ExternalAddress(84 + CP));    \/\/0x3ac6, 0x0ba0, 0x07\n-  testl(ebx, ebx);\n-  fmul(2);\n-  fld_x(ExternalAddress(72 + CP));    \/\/0xdaba, 0xfe79, 0xea\n-  fmul(3);\n-  fld_x(ExternalAddress(60 + CP));    \/\/0xd84d, 0xadee, 0xc6\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(48 + CP));    \/\/0x03fe, 0x3f65, 0x7d\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(36 + CP));    \/\/0xf024, 0x0cac, 0x00\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(24 + CP));    \/\/0x9c2f, 0x0b60, 0x60\n-  faddp(2);\n-  fxch(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(12 + CP));    \/\/0xaaa5, 0xaaaa, 0xaa\n-  faddp(2);\n-  fxch(1);\n-  fmulp(3);\n-  fld_x(ExternalAddress(CP));    \/\/0x0000, 0x0000, 0x00\n-  faddp(1);\n-  fmulp(1);\n-  faddp(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(1);\n-  movl(eax, Address(esp, 32));\n-  faddp(1);\n-  fstp_d(Address(eax, 0));\n-  jcc(Assembler::equal, B1_40);\n-\n-  bind(B1_39);\n-  fldcw(Address(esp, 30));\n-  bind(B1_40);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-  bind(B1_41);\n-  fstp_d(0);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-  bind(B1_42);\n-  xorl(ebx, ebx);\n-  jmp(B1_8);\n-  bind(B1_43);\n-  xorl(ebx, ebx);\n-  jmp(B1_15);\n-}\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_sin[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL, 0xbf73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL,\n-    0xc0000000UL, 0xbc626d19UL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL,\n-    0xbfa60beaUL, 0x2ed59f06UL, 0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL,\n-    0x00000000UL, 0x3ff00000UL, 0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL,\n-    0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL, 0x00000000UL, 0x3ff00000UL,\n-    0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL, 0x20000000UL,\n-    0x3c5e0d89UL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL, 0xbfc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0x3ff00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL,\n-    0x20000000UL, 0x3c68076aUL, 0x00000000UL, 0x3ff00000UL, 0x99fcef32UL,\n-    0x3fca8279UL, 0x667f3bcdUL, 0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL,\n-    0x00000000UL, 0x3fe00000UL, 0x94247758UL, 0x3fc133ccUL, 0x6b151741UL,\n-    0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL, 0x00000000UL, 0x3fe00000UL,\n-    0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL, 0xe0000000UL,\n-    0x3c39f630UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL, 0xbf9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0x3fe00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0x3fed906bUL,\n-    0x20000000UL, 0x3c7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x76acf82dUL,\n-    0x3fa4a031UL, 0x56c62ddaUL, 0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL,\n-    0x00000000UL, 0x3fd00000UL, 0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL,\n-    0x3fef6297UL, 0x20000000UL, 0x3c756217UL, 0x00000000UL, 0x3fd00000UL,\n-    0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL, 0x3fefd88dUL, 0x40000000UL,\n-    0xbc887df6UL, 0x00000000UL, 0x3fc00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0x3fefd88dUL,\n-    0x40000000UL, 0xbc887df6UL, 0x00000000UL, 0xbfc00000UL, 0x0e5967d5UL,\n-    0x3fac1d1fUL, 0xcff75cb0UL, 0x3fef6297UL, 0x20000000UL, 0x3c756217UL,\n-    0x00000000UL, 0xbfd00000UL, 0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL,\n-    0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL, 0x00000000UL, 0xbfd00000UL,\n-    0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL, 0x3fed906bUL, 0x20000000UL,\n-    0x3c7457e6UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL, 0x3f9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL,\n-    0xe0000000UL, 0x3c39f630UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL,\n-    0xbfc133ccUL, 0x6b151741UL, 0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL,\n-    0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL, 0x00000000UL, 0xbfe00000UL,\n-    0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL, 0x20000000UL,\n-    0x3c68076aUL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL, 0x3fc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL,\n-    0x20000000UL, 0x3c5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL,\n-    0x3fb37ca1UL, 0xa6aea963UL, 0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL,\n-    0x00000000UL, 0xbff00000UL, 0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL,\n-    0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL, 0x00000000UL, 0xbff00000UL,\n-    0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL, 0xc0000000UL,\n-    0xbc626d19UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL, 0x3f73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0xbff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL,\n-    0x3f73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0xbff00000UL, 0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL,\n-    0xbfc8f8b8UL, 0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0xbff00000UL,\n-    0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL,\n-    0x3c75d28dUL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL, 0x3fb37ca1UL,\n-    0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL, 0x3c672cedUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0xbfde2b5dUL,\n-    0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL,\n-    0x3fc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0xbff00000UL, 0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL,\n-    0xbfe44cf3UL, 0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0xbff00000UL,\n-    0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL,\n-    0x3c8bdd34UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL, 0xbfc133ccUL,\n-    0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL, 0x3c82c5e1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0xbfea9b66UL,\n-    0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL,\n-    0x3f9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL,\n-    0xbfed906bUL, 0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0xbfe00000UL,\n-    0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL,\n-    0xbc8760b1UL, 0x00000000UL, 0xbfd00000UL, 0x0e5967d5UL, 0x3fac1d1fUL,\n-    0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL, 0xbc756217UL, 0x00000000UL,\n-    0xbfd00000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0xbfefd88dUL,\n-    0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0xbfc00000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL,\n-    0xbfefd88dUL, 0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0x3fc00000UL,\n-    0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL,\n-    0xbc756217UL, 0x00000000UL, 0x3fd00000UL, 0x76acf82dUL, 0x3fa4a031UL,\n-    0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL, 0xbc8760b1UL, 0x00000000UL,\n-    0x3fd00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0xbfed906bUL,\n-    0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL,\n-    0xbf9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0x3fe00000UL, 0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL,\n-    0xbfea9b66UL, 0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0x3fe00000UL,\n-    0x94247758UL, 0x3fc133ccUL, 0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL,\n-    0x3c82c5e1UL, 0x00000000UL, 0x3fe00000UL, 0x99fcef32UL, 0x3fca8279UL,\n-    0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL, 0x3c8bdd34UL, 0x00000000UL,\n-    0x3fe00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0xbfe44cf3UL,\n-    0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL,\n-    0xbfc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0x3ff00000UL, 0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL,\n-    0xbfde2b5dUL, 0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0x3ff00000UL,\n-    0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL,\n-    0x3c672cedUL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL, 0xbfa60beaUL,\n-    0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL, 0x3c75d28dUL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0xbfc8f8b8UL,\n-    0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL,\n-    0xbf73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0x3ff00000UL, 0x55555555UL, 0xbfc55555UL, 0x00000000UL,\n-    0xbfe00000UL, 0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL,\n-    0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL, 0xa556c734UL,\n-    0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL, 0x1a600000UL, 0x3d90b461UL,\n-    0x1a600000UL, 0x3d90b461UL, 0x54400000UL, 0x3fb921fbUL, 0x00000000UL,\n-    0x00000000UL, 0x2e037073UL, 0x3b63198aUL, 0x00000000UL, 0x00000000UL,\n-    0x6dc9c883UL, 0x40245f30UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x43380000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x43600000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x3c800000UL, 0x00000000UL,\n-    0x00000000UL, 0xffffffffUL, 0x3fefffffUL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x80000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x80000000UL, 0x00000000UL, 0x80000000UL, 0x00000000UL, 0x3fe00000UL,\n-    0x00000000UL, 0x3fe00000UL\n-};\n-\n-void MacroAssembler::fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                              Register eax, Register ebx, Register edx) {\n-\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2;\n-\n-  assert_different_registers(eax, ebx, edx);\n-\n-  address static_const_table_sin = (address)_static_const_table_sin;\n-\n-  subl(rsp, 120);\n-  movl(Address(rsp, 56), ebx);\n-  lea(ebx, ExternalAddress(static_const_table_sin));\n-  movsd(xmm0, Address(rsp, 128));\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32767);\n-  subl(eax, 12336);\n-  cmpl(eax, 4293);\n-  jcc(Assembler::above, L_2TAG_PACKET_0_0_2);\n-  movsd(xmm1, Address(ebx, 2160));\n-  mulsd(xmm1, xmm0);\n-  movsd(xmm5, Address(ebx, 2272));\n-  movdqu(xmm4, Address(ebx, 2256));\n-  pand(xmm4, xmm0);\n-  por(xmm5, xmm4);\n-  movsd(xmm3, Address(ebx, 2128));\n-  movdqu(xmm2, Address(ebx, 2112));\n-  addpd(xmm1, xmm5);\n-  cvttsd2sil(edx, xmm1);\n-  cvtsi2sdl(xmm1, edx);\n-  mulsd(xmm3, xmm1);\n-  unpcklpd(xmm1, xmm1);\n-  addl(edx, 1865216);\n-  movdqu(xmm4, xmm0);\n-  andl(edx, 63);\n-  movdqu(xmm5, Address(ebx, 2096));\n-  lea(eax, Address(ebx, 0));\n-  shll(edx, 5);\n-  addl(eax, edx);\n-  mulpd(xmm2, xmm1);\n-  subsd(xmm0, xmm3);\n-  mulsd(xmm1, Address(ebx, 2144));\n-  subsd(xmm4, xmm3);\n-  movsd(xmm7, Address(eax, 8));\n-  unpcklpd(xmm0, xmm0);\n-  movapd(xmm3, xmm4);\n-  subsd(xmm4, xmm2);\n-  mulpd(xmm5, xmm0);\n-  subpd(xmm0, xmm2);\n-  movdqu(xmm6, Address(ebx, 2064));\n-  mulsd(xmm7, xmm4);\n-  subsd(xmm3, xmm4);\n-  mulpd(xmm5, xmm0);\n-  mulpd(xmm0, xmm0);\n-  subsd(xmm3, xmm2);\n-  movdqu(xmm2, Address(eax, 0));\n-  subsd(xmm1, xmm3);\n-  movsd(xmm3, Address(eax, 24));\n-  addsd(xmm2, xmm3);\n-  subsd(xmm7, xmm2);\n-  mulsd(xmm2, xmm4);\n-  mulpd(xmm6, xmm0);\n-  mulsd(xmm3, xmm4);\n-  mulpd(xmm2, xmm0);\n-  mulpd(xmm0, xmm0);\n-  addpd(xmm5, Address(ebx, 2080));\n-  mulsd(xmm4, Address(eax, 0));\n-  addpd(xmm6, Address(ebx, 2048));\n-  mulpd(xmm5, xmm0);\n-  movapd(xmm0, xmm3);\n-  addsd(xmm3, Address(eax, 8));\n-  mulpd(xmm1, xmm7);\n-  movapd(xmm7, xmm4);\n-  addsd(xmm4, xmm3);\n-  addpd(xmm6, xmm5);\n-  movsd(xmm5, Address(eax, 8));\n-  subsd(xmm5, xmm3);\n-  subsd(xmm3, xmm4);\n-  addsd(xmm1, Address(eax, 16));\n-  mulpd(xmm6, xmm2);\n-  addsd(xmm5, xmm0);\n-  addsd(xmm3, xmm7);\n-  addsd(xmm1, xmm5);\n-  addsd(xmm1, xmm3);\n-  addsd(xmm1, xmm6);\n-  unpckhpd(xmm6, xmm6);\n-  addsd(xmm1, xmm6);\n-  addsd(xmm4, xmm1);\n-  movsd(Address(rsp, 0), xmm4);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  jcc(Assembler::greater, L_2TAG_PACKET_2_0_2);\n-  shrl(eax, 4);\n-  cmpl(eax, 268434685);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_3_0_2);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  movsd(xmm3, Address(ebx, 2192));\n-  mulsd(xmm3, xmm0);\n-  subsd(xmm3, xmm0);\n-  mulsd(xmm3, Address(ebx, 2208));\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movl(eax, Address(rsp, 132));\n-  andl(eax, 2146435072);\n-  cmpl(eax, 2146435072);\n-  jcc(Assembler::equal, L_2TAG_PACKET_4_0_2);\n-  subl(rsp, 32);\n-  movsd(Address(rsp, 0), xmm0);\n-  lea(eax, Address(rsp, 40));\n-  movl(Address(rsp, 8), eax);\n-  movl(eax, 2);\n-  movl(Address(rsp, 12), eax);\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlibm_sin_cos_huge())));\n-  addl(rsp, 32);\n-  fld_d(Address(rsp, 16));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-  bind(L_2TAG_PACKET_4_0_2);\n-  fld_d(Address(rsp, 128));\n-  fmul_d(Address(ebx, 2240));\n-  bind(L_2TAG_PACKET_1_0_2);\n-  movl(ebx, Address(rsp, 56));\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_sin.cpp","additions":0,"deletions":1742,"binary":false,"changes":1742,"status":"deleted"},{"patch":"@@ -1,1172 +0,0 @@\n-\/*\n-* Copyright (c) 2016, 2021, Intel Corporation. All rights reserved.\n-* Intel Math Library (LIBM) Source Code\n-*\n-* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-*\n-* This code is free software; you can redistribute it and\/or modify it\n-* under the terms of the GNU General Public License version 2 only, as\n-* published by the Free Software Foundation.\n-*\n-* This code is distributed in the hope that it will be useful, but WITHOUT\n-* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-* version 2 for more details (a copy is included in the LICENSE file that\n-* accompanied this code).\n-*\n-* You should have received a copy of the GNU General Public License version\n-* 2 along with this work; if not, write to the Free Software Foundation,\n-* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-*\n-* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-* or visit www.oracle.com if you need additional information or have any\n-* questions.\n-*\n-*\/\n-\n-#include \"asm\/assembler.hpp\"\n-#include \"asm\/assembler.inline.hpp\"\n-#include \"macroAssembler_x86.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-\/******************************************************************************\/\n-\/\/                     ALGORITHM DESCRIPTION - TAN()\n-\/\/                     ---------------------\n-\/\/\n-\/\/ Polynomials coefficients and other constants.\n-\/\/\n-\/\/ Note that in this algorithm, there is a different polynomial for\n-\/\/ each breakpoint, so there are 32 sets of polynomial coefficients\n-\/\/ as well as 32 instances of the other constants.\n-\/\/\n-\/\/ The polynomial coefficients and constants are offset from the start\n-\/\/ of the main block as follows:\n-\/\/\n-\/\/   0:  c8 | c0\n-\/\/  16:  c9 | c1\n-\/\/  32: c10 | c2\n-\/\/  48: c11 | c3\n-\/\/  64: c12 | c4\n-\/\/  80: c13 | c5\n-\/\/  96: c14 | c6\n-\/\/ 112: c15 | c7\n-\/\/ 128: T_hi\n-\/\/ 136: T_lo\n-\/\/ 144: Sigma\n-\/\/ 152: T_hl\n-\/\/ 160: Tau\n-\/\/ 168: Mask\n-\/\/ 176: (end of block)\n-\/\/\n-\/\/ The total table size is therefore 5632 bytes.\n-\/\/\n-\/\/ Note that c0 and c1 are always zero. We could try storing\n-\/\/ other constants here, and just loading the low part of the\n-\/\/ SIMD register in these cases, after ensuring the high part\n-\/\/ is zero.\n-\/\/\n-\/\/ The higher terms of the polynomial are computed in the *low*\n-\/\/ part of the SIMD register. This is so we can overlap the\n-\/\/ multiplication by r^8 and the unpacking of the other part.\n-\/\/\n-\/\/ The constants are:\n-\/\/ T_hi + T_lo = accurate constant term in power series\n-\/\/ Sigma + T_hl = accurate coefficient of r in power series (Sigma=1 bit)\n-\/\/ Tau = multiplier for the reciprocal, always -1 or 0\n-\/\/\n-\/\/ The basic reconstruction formula using these constants is:\n-\/\/\n-\/\/ High = tau * recip_hi + t_hi\n-\/\/ Med = (sgn * r + t_hl * r)_hi\n-\/\/ Low = (sgn * r + t_hl * r)_lo +\n-\/\/       tau * recip_lo + T_lo + (T_hl + sigma) * c + pol\n-\/\/\n-\/\/ where pol = c0 + c1 * r + c2 * r^2 + ... + c15 * r^15\n-\/\/\n-\/\/ (c0 = c1 = 0, but using them keeps SIMD regularity)\n-\/\/\n-\/\/ We then do a compensated sum High + Med, add the low parts together\n-\/\/ and then do the final sum.\n-\/\/\n-\/\/ Here recip_hi + recip_lo is an accurate reciprocal of the remainder\n-\/\/ modulo pi\/2\n-\/\/\n-\/\/ Special cases:\n-\/\/  tan(NaN) = quiet NaN, and raise invalid exception\n-\/\/  tan(INF) = NaN and raise invalid exception\n-\/\/  tan(+\/-0) = +\/-0\n-\/\/\n-\/******************************************************************************\/\n-\n-\/\/ The 32 bit code is at most SSE2 compliant\n-\n-ATTRIBUTE_ALIGNED(16) static const jushort _TP[] =\n-{\n-    0x4cd6, 0xaf6c, 0xc710, 0xc662, 0xbffd, 0x0000, 0x4b06, 0xb0ac, 0xd3b2, 0xcc2c,\n-    0x3ff9, 0x0000, 0x00e3, 0xc850, 0xaa28, 0x9533, 0xbff3, 0x0000, 0x2ff0, 0x466d,\n-    0x1a3b, 0xb266, 0x3fe5, 0x0000\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const jushort _TQ[] =\n-{\n-    0x399c, 0x8391, 0x154c, 0x94ca, 0xbfff, 0x0000, 0xb6a3, 0xc36a, 0x44e2, 0x8a2c,\n-    0x3ffe, 0x0000, 0xb70f, 0xd068, 0xa6ce, 0xe9dd, 0xbff9, 0x0000, 0x820f, 0x51ce,\n-    0x7d76, 0x9bff, 0x3ff3, 0x0000\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const jushort _GP[] =\n-{\n-    0xaaab, 0xaaaa, 0xaaaa, 0xaaaa, 0xbffd, 0x0000, 0xb62f, 0x0b60, 0x60b6, 0xb60b,\n-    0xbff9, 0x0000, 0xdfa7, 0x08aa, 0x55e0, 0x8ab3, 0xbff6, 0x0000, 0x85a0, 0xa819,\n-    0xbc99, 0xddeb, 0xbff2, 0x0000, 0x7065, 0x6a37, 0x795f, 0xb354, 0xbfef, 0x0000,\n-    0xa8f9, 0x83f1, 0x2ec8, 0x9140, 0xbfec, 0x0000, 0xf3ca, 0x8c96, 0x8e0b, 0xeb6d,\n-    0xbfe8, 0x0000, 0x355b, 0xd910, 0x67c9, 0xbed3, 0xbfe5, 0x0000, 0x286b, 0xb49e,\n-    0xb854, 0x9a98, 0xbfe2, 0x0000, 0x0871, 0x1a2f, 0x6477, 0xfcc4, 0xbfde, 0x0000,\n-    0xa559, 0x1da9, 0xaed2, 0xba76, 0xbfdb, 0x0000, 0x00a3, 0x7fea, 0x9bc3, 0xf205,\n-    0xbfd8, 0x0000\n-};\n-\n-void MacroAssembler::libm_tancot_huge(XMMRegister xmm0, XMMRegister xmm1, Register eax, Register ecx, Register edx, Register ebx, Register esi, Register edi, Register ebp, Register esp) {\n-  Label B1_1, B1_2, B1_3, B1_4, B1_5, B1_6, B1_7, B1_8, B1_9, B1_10, B1_11, B1_12;\n-  Label B1_13, B1_14, B1_15, B1_16, B1_17, B1_18, B1_19, B1_20, B1_21, B1_22, B1_23;\n-  Label B1_24, B1_25, B1_26, B1_27, B1_28, B1_29, B1_30, B1_31, B1_32, B1_33, B1_34;\n-  Label B1_35, B1_36, B1_37, B1_38, B1_39, B1_40, B1_43;\n-\n-  assert_different_registers(ebx, eax, ecx, edx, esi, edi, ebp, esp);\n-\n-  address TP = (address)_TP;\n-  address TQ = (address)_TQ;\n-  address GP = (address)_GP;\n-\n-  bind(B1_1);\n-  push(ebp);\n-  movl(ebp, esp);\n-  andl(esp, -64);\n-  push(esi);\n-  push(edi);\n-  push(ebx);\n-  subl(esp, 52);\n-  movl(eax, Address(ebp, 16));\n-  movl(ebx, Address(ebp, 20));\n-  movl(Address(esp, 40), eax);\n-\n-  bind(B1_2);\n-  fnstcw(Address(esp, 38));\n-\n-  bind(B1_3);\n-  movl(edx, Address(ebp, 12));\n-  movl(eax, edx);\n-  andl(eax, 2147483647);\n-  shrl(edx, 31);\n-  movl(Address(esp, 44), edx);\n-  cmpl(eax, 1104150528);\n-  jcc(Assembler::aboveEqual, B1_11);\n-\n-  bind(B1_4);\n-  movsd(xmm1, Address(ebp, 8));\n-  movzwl(ecx, Address(esp, 38));\n-  movl(edx, ecx);\n-  andl(edx, 768);\n-  andps(xmm1, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n-  cmpl(edx, 768);\n-  movsd(xmm0, ExternalAddress(PI4_INV));    \/\/\/\/0x6dc9c883UL, 0x3ff45f30UL\n-  mulsd(xmm0, xmm1);\n-  movsd(Address(ebp, 8), xmm1);\n-  movsd(Address(esp, 0), xmm0);\n-  jcc(Assembler::equal, B1_39);\n-\n-  bind(B1_5);\n-  orl(ecx, -64768);\n-  movw(Address(esp, 36), ecx);\n-\n-  bind(B1_6);\n-  fldcw(Address(esp, 36));\n-\n-  bind(B1_7);\n-  movsd(xmm1, Address(ebp, 8));\n-  movl(edi, 1);\n-\n-  bind(B1_8);\n-  movl(Address(esp, 12), esi);\n-  movl(esi, Address(esp, 4));\n-  movl(edx, esi);\n-  movl(Address(esp, 24), edi);\n-  movl(edi, esi);\n-  shrl(edi, 20);\n-  andl(edx, 1048575);\n-  movl(ecx, edi);\n-  orl(edx, 1048576);\n-  negl(ecx);\n-  addl(edi, 13);\n-  movl(Address(esp, 8), ebx);\n-  addl(ecx, 19);\n-  movl(ebx, edx);\n-  movl(Address(esp, 28), ecx);\n-  shrl(ebx);\n-  movl(ecx, edi);\n-  shll(edx);\n-  movl(ecx, Address(esp, 28));\n-  movl(edi, Address(esp, 0));\n-  shrl(edi);\n-  orl(edx, edi);\n-  cmpl(esi, 1094713344);\n-  movsd(Address(esp, 16), xmm1);\n-  fld_d(Address(esp, 16));\n-  cmov32(Assembler::below, edx, ebx);\n-  movl(edi, Address(esp, 24));\n-  movl(esi, Address(esp, 12));\n-  lea(ebx, Address(edx, 1));\n-  andl(ebx, -2);\n-  movl(Address(esp, 16), ebx);\n-  cmpl(eax, 1094713344);\n-  fild_s(Address(esp, 16));\n-  movl(ebx, Address(esp, 8));\n-  jcc(Assembler::aboveEqual, B1_10);\n-\n-  bind(B1_9);\n-  fld_d(ExternalAddress(PI4X3));    \/\/0x54443000UL, 0xbfe921fbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X3 + 8));    \/\/0x3b39a000UL, 0x3d373dcbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X3 + 16));    \/\/0xe0e68948UL, 0xba845c06UL\n-  fmulp(1);\n-  faddp(1);\n-  jmp(B1_17);\n-\n-  bind(B1_10);\n-  fld_d(ExternalAddress(PI4X4));    \/\/0x54400000UL, 0xbfe921fbUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 8));    \/\/0x1a600000UL, 0xbdc0b461UL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 16));    \/\/0x2e000000UL, 0xbb93198aUL\n-  fmul(1);\n-  faddp(2);\n-  fld_d(ExternalAddress(PI4X4 + 24));    \/\/0x252049c1UL, 0xb96b839aUL\n-  fmulp(1);\n-  faddp(1);\n-  jmp(B1_17);\n-\n-  bind(B1_11);\n-  movzwl(edx, Address(esp, 38));\n-  movl(eax, edx);\n-  andl(eax, 768);\n-  cmpl(eax, 768);\n-  jcc(Assembler::equal, B1_40);\n-\n-  bind(B1_12);\n-  orl(edx, -64768);\n-  movw(Address(esp, 36), edx);\n-\n-  bind(B1_13);\n-  fldcw(Address(esp, 36));\n-\n-  bind(B1_14);\n-  movl(edi, 1);\n-\n-  bind(B1_15);\n-  movsd(xmm0, Address(ebp, 8));\n-  addl(esp, -32);\n-  andps(xmm0, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n-  lea(eax, Address(esp, 32));\n-  movsd(Address(eax, 16), xmm0);\n-  fld_d(Address(eax, 16));\n-  fstp_x(Address(esp, 0));\n-  movl(Address(esp, 12), 0);\n-  movl(Address(esp, 16), eax);\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlibm_reduce_pi04l())));\n-\n-  bind(B1_43);\n-  movl(edx, eax);\n-  addl(esp, 32);\n-\n-  bind(B1_16);\n-  fld_d(Address(esp, 0));\n-  fld_d(Address(esp, 8));\n-  faddp(1);\n-\n-  bind(B1_17);\n-  movl(eax, ebx);\n-  andl(eax, 3);\n-  cmpl(eax, 3);\n-  jcc(Assembler::notEqual, B1_24);\n-\n-  bind(B1_18);\n-  fld_d(ExternalAddress(ONES));\n-  incl(edx);\n-  fdiv(1);\n-  testb(edx, 2);\n-  fstp_x(Address(esp, 24));\n-  fld_s(0);\n-  fmul(1);\n-  fld_s(0);\n-  fmul(1);\n-  fld_x(ExternalAddress(36 + TP));    \/\/0x2ff0, 0x466d, 0x1a\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + TP));    \/\/0x00e3, 0xc850, 0xaa\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(12 + TP));    \/\/0x4b06, 0xb0ac, 0xd3\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(36 + TQ));    \/\/0x820f, 0x51ce, 0x7d\n-  fmul(3);\n-  fld_x(ExternalAddress(24 + TQ));    \/\/0xb70f, 0xd068, 0xa6\n-  faddp(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(12 + TQ));    \/\/0xb6a3, 0xc36a, 0x44\n-  faddp(1);\n-  fmul(3);\n-  fld_x(ExternalAddress(TQ));    \/\/0x399c, 0x8391, 0x15\n-  faddp(1);\n-  fld_x(ExternalAddress(TP));    \/\/0x4cd6, 0xaf6c, 0xc7\n-  faddp(2);\n-  fld_x(ExternalAddress(132 + GP));    \/\/0x00a3, 0x7fea, 0x9b\n-  fmul(3);\n-  fld_x(ExternalAddress(120 + GP));    \/\/0xa559, 0x1da9, 0xae\n-  fmul(4);\n-  fld_x(ExternalAddress(108 + GP));    \/\/0x0871, 0x1a2f, 0x64\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(96 + GP));    \/\/0x286b, 0xb49e, 0xb8\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(84 + GP));    \/\/0x355b, 0xd910, 0x67\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(72 + GP));    \/\/0x8c96, 0x8e0b, 0xeb\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(60 + GP));    \/\/0xa8f9, 0x83f1, 0x2e\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(48 + GP));    \/\/0x7065, 0x6a37, 0x79\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(36 + GP));    \/\/0x85a0, 0xa819, 0xbc\n-  faddp(2);\n-  fxch(1);\n-  fmul(4);\n-  fld_x(ExternalAddress(24 + GP));    \/\/0xdfa7, 0x08aa, 0x55\n-  faddp(2);\n-  fxch(1);\n-  fmulp(4);\n-  fld_x(ExternalAddress(12 + GP));    \/\/0xb62f, 0x0b60, 0x60\n-  faddp(1);\n-  fmul(4);\n-  fmul(5);\n-  fld_x(ExternalAddress(GP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(4);\n-  fxch(3);\n-  fmul(5);\n-  faddp(3);\n-  jcc(Assembler::equal, B1_20);\n-\n-  bind(B1_19);\n-  fld_x(Address(esp, 24));\n-  fxch(1);\n-  fdivrp(2);\n-  fxch(1);\n-  fmulp(3);\n-  movl(eax, Address(esp, 44));\n-  xorl(eax, 1);\n-  fxch(2);\n-  fmul(3);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(2);\n-  fmula(3);\n-  fxch(3);\n-  faddp(2);\n-  fxch(1);\n-  fstp_d(Address(esp, 16));\n-  fmul(1);\n-  fxch(1);\n-  fmulp(2);\n-  movsd(xmm0, Address(esp, 16));\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm1, Address(esp, 16));\n-  jmp(B1_21);\n-\n-  bind(B1_20);\n-  fdivrp(1);\n-  fmulp(2);\n-  fxch(1);\n-  fmul(2);\n-  movl(eax, Address(esp, 44));\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(1);\n-  fmula(3);\n-  fxch(3);\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  fmul(1);\n-  fld_x(Address(esp, 24));\n-  fmulp(2);\n-  movsd(xmm0, Address(esp, 16));\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm1, Address(esp, 16));\n-\n-  bind(B1_21);\n-  testl(edi, edi);\n-  jcc(Assembler::equal, B1_23);\n-\n-  bind(B1_22);\n-  fldcw(Address(esp, 38));\n-\n-  bind(B1_23);\n-  movl(eax, Address(esp, 40));\n-  movsd(Address(eax, 0), xmm0);\n-  movsd(Address(eax, 8), xmm1);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_24);\n-  testb(ebx, 2);\n-  jcc(Assembler::equal, B1_31);\n-\n-  bind(B1_25);\n-  incl(edx);\n-  fld_s(0);\n-  fmul(1);\n-  testb(edx, 2);\n-  jcc(Assembler::equal, B1_27);\n-\n-  bind(B1_26);\n-  fld_d(ExternalAddress(ONES));\n-  fdiv(2);\n-  fld_s(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(132 + GP));    \/\/0x00a3, 0x7fea, 0x9b\n-  fmul(1);\n-  fld_x(ExternalAddress(120 + GP));    \/\/0xa559, 0x1da9, 0xae\n-  fmul(2);\n-  fld_x(ExternalAddress(108 + GP));    \/\/0x67c9, 0xbed3, 0xbf\n-  movl(eax, Address(esp, 44));\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  xorl(eax, 1);\n-  fld_x(ExternalAddress(96 + GP));    \/\/0x286b, 0xb49e, 0xb8\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(84 + GP));    \/\/0x355b, 0xd910, 0x67\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(72 + GP));    \/\/0xf3ca, 0x8c96, 0x8e\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(60 + GP));    \/\/0xa8f9, 0x83f1, 0x2e\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(48 + GP));    \/\/0x7065, 0x6a37, 0x79\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(36 + GP));    \/\/0x85a0, 0xa819, 0xbc\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + GP));    \/\/0xdfa7, 0x08aa, 0x55\n-  faddp(2);\n-  fxch(1);\n-  fmulp(2);\n-  fld_x(ExternalAddress(12 + GP));    \/\/0xb62f, 0x0b60, 0x60\n-  faddp(1);\n-  fmulp(3);\n-  fld_x(ExternalAddress(GP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(1);\n-  fmul(3);\n-  fxch(2);\n-  fmulp(3);\n-  fxch(1);\n-  faddp(2);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(2);\n-  fmulp(1);\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm0, Address(esp, 16));\n-  jmp(B1_28);\n-\n-  bind(B1_27);\n-  fld_x(ExternalAddress(36 + TP));    \/\/0x2ff0, 0x466d, 0x1a\n-  fmul(1);\n-  fld_x(ExternalAddress(24 + TP));    \/\/0x00e3, 0xc850, 0xaa\n-  movl(eax, Address(esp, 44));\n-  faddp(1);\n-  fmul(1);\n-  fld_x(ExternalAddress(36 + TQ));    \/\/0x820f, 0x51ce, 0x7d\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + TQ));    \/\/0xb70f, 0xd068, 0xa6\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(12 + TQ));    \/\/0xb6a3, 0xc36a, 0x44\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(TQ));    \/\/0x399c, 0x8391, 0x15\n-  faddp(1);\n-  fld_x(ExternalAddress(12 + TP));    \/\/0x4b06, 0xb0ac, 0xd3\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(TP));    \/\/0x4cd6, 0xaf6c, 0xc7\n-  faddp(1);\n-  fdivrp(1);\n-  fmulp(1);\n-  fmul(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(1);\n-  fmulp(2);\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm0, Address(esp, 16));\n-\n-  bind(B1_28);\n-  testl(edi, edi);\n-  jcc(Assembler::equal, B1_30);\n-\n-  bind(B1_29);\n-  fldcw(Address(esp, 38));\n-\n-  bind(B1_30);\n-  movl(eax, Address(esp, 40));\n-  movsd(Address(eax, 0), xmm0);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  movl(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_31);\n-  testb(ebx, 1);\n-  jcc(Assembler::equal, B1_38);\n-\n-  bind(B1_32);\n-  incl(edx);\n-  fld_s(0);\n-  fmul(1);\n-  testb(edx, 2);\n-  jcc(Assembler::equal, B1_34);\n-\n-  bind(B1_33);\n-  fld_x(ExternalAddress(36 + TP));    \/\/0x2ff0, 0x466d, 0x1a\n-  fmul(1);\n-  fld_x(ExternalAddress(24 + TP));    \/\/0x00e3, 0xc850, 0xaa\n-  movl(eax, Address(esp, 44));\n-  faddp(1);\n-  fmul(1);\n-  xorl(eax, 1);\n-  fld_x(ExternalAddress(36 + TQ));    \/\/0x820f, 0x51ce, 0x7d\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + TQ));    \/\/0xb70f, 0xd068, 0xa6\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(12 + TQ));    \/\/0xb6a3, 0xc36a, 0x44\n-  faddp(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(TQ));    \/\/0x399c, 0x8391, 0x15\n-  faddp(1);\n-  fld_x(ExternalAddress(12 + TP));    \/\/0x4b06, 0xb0ac, 0xd3\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(TP));    \/\/0x4cd6, 0xaf6c, 0xc7\n-  faddp(1);\n-  fdivrp(1);\n-  fmulp(1);\n-  fmul(1);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(1);\n-  fmulp(2);\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm0, Address(esp, 16));\n-  jmp(B1_35);\n-\n-  bind(B1_34);\n-  fld_d(ExternalAddress(ONES));\n-  fdiv(2);\n-  fld_s(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(132 + GP));    \/\/0x00a3, 0x7fea, 0x9b\n-  fmul(1);\n-  fld_x(ExternalAddress(120 + GP));    \/\/0xa559, 0x1da9, 0xae\n-  fmul(2);\n-  fld_x(ExternalAddress(108 + GP));    \/\/0x67c9, 0xbed3, 0xbf\n-  movl(eax, Address(esp, 44));\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(96 + GP));    \/\/0x286b, 0xb49e, 0xb8\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(84 + GP));    \/\/0x355b, 0xd910, 0x67\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(72 + GP));    \/\/0xf3ca, 0x8c96, 0x8e\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(60 + GP));    \/\/0xa8f9, 0x83f1, 0x2e\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(48 + GP));    \/\/0x7065, 0x6a37, 0x79\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(36 + GP));    \/\/0x85a0, 0xa819, 0xbc\n-  faddp(2);\n-  fxch(1);\n-  fmul(2);\n-  fld_x(ExternalAddress(24 + GP));    \/\/0xdfa7, 0x08aa, 0x55\n-  faddp(2);\n-  fxch(1);\n-  fmulp(2);\n-  fld_x(ExternalAddress(12 + GP));    \/\/0xb62f, 0x0b60, 0x60\n-  faddp(1);\n-  fmulp(3);\n-  fld_x(ExternalAddress(GP));    \/\/0xaaab, 0xaaaa, 0xaa\n-  faddp(1);\n-  fmul(3);\n-  fxch(2);\n-  fmulp(3);\n-  fxch(1);\n-  faddp(2);\n-  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n-  fmula(2);\n-  fmulp(1);\n-  faddp(1);\n-  fstp_d(Address(esp, 16));\n-  movsd(xmm0, Address(esp, 16));\n-\n-  bind(B1_35);\n-  testl(edi, edi);\n-  jcc(Assembler::equal, B1_37);\n-\n-  bind(B1_36);\n-  fldcw(Address(esp, 38));\n-\n-  bind(B1_37);\n-  movl(eax, Address(esp, 40));\n-  movsd(Address(eax, 8), xmm0);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  mov(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_38);\n-  fstp_d(0);\n-  addl(esp, 52);\n-  pop(ebx);\n-  pop(edi);\n-  pop(esi);\n-  mov(esp, ebp);\n-  pop(ebp);\n-  ret(0);\n-\n-  bind(B1_39);\n-  xorl(edi, edi);\n-  jmp(B1_8);\n-\n-  bind(B1_40);\n-  xorl(edi, edi);\n-  jmp(B1_15);\n-}\n-\n-ATTRIBUTE_ALIGNED(16) static const juint _static_const_table_tan[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x882c10faUL,\n-    0x3f9664f4UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x55e6c23dUL, 0x3f8226e3UL, 0x55555555UL,\n-    0x3fd55555UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x0e157de0UL, 0x3f6d6d3dUL, 0x11111111UL, 0x3fc11111UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x452b75e3UL, 0x3f57da36UL,\n-    0x1ba1ba1cUL, 0x3faba1baUL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x4e435f9bUL,\n-    0x3f953f83UL, 0x00000000UL, 0x00000000UL, 0x3c6e8e46UL, 0x3f9b74eaUL,\n-    0x00000000UL, 0x00000000UL, 0xda5b7511UL, 0x3f85ad63UL, 0xdc230b9bUL,\n-    0x3fb97558UL, 0x26cb3788UL, 0x3f881308UL, 0x76fc4985UL, 0x3fd62ac9UL,\n-    0x77bb08baUL, 0x3f757c85UL, 0xb6247521UL, 0x3fb1381eUL, 0x5922170cUL,\n-    0x3f754e95UL, 0x8746482dUL, 0x3fc27f83UL, 0x11055b30UL, 0x3f64e391UL,\n-    0x3e666320UL, 0x3fa3e609UL, 0x0de9dae3UL, 0x3f6301dfUL, 0x1f1dca06UL,\n-    0x3fafa8aeUL, 0x8c5b2da2UL, 0x3fb936bbUL, 0x4e88f7a5UL, 0x3c587d05UL,\n-    0x00000000UL, 0x3ff00000UL, 0xa8935dd9UL, 0x3f83dde2UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x5a279ea3UL, 0x3faa3407UL,\n-    0x00000000UL, 0x00000000UL, 0x432d65faUL, 0x3fa70153UL, 0x00000000UL,\n-    0x00000000UL, 0x891a4602UL, 0x3f9d03efUL, 0xd62ca5f8UL, 0x3fca77d9UL,\n-    0xb35f4628UL, 0x3f97a265UL, 0x433258faUL, 0x3fd8cf51UL, 0xb58fd909UL,\n-    0x3f8f88e3UL, 0x01771ceaUL, 0x3fc2b154UL, 0xf3562f8eUL, 0x3f888f57UL,\n-    0xc028a723UL, 0x3fc7370fUL, 0x20b7f9f0UL, 0x3f80f44cUL, 0x214368e9UL,\n-    0x3fb6dfaaUL, 0x28891863UL, 0x3f79b4b6UL, 0x172dbbf0UL, 0x3fb6cb8eUL,\n-    0xe0553158UL, 0x3fc975f5UL, 0x593fe814UL, 0x3c2ef5d3UL, 0x00000000UL,\n-    0x3ff00000UL, 0x03dec550UL, 0x3fa44203UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x9314533eUL, 0x3fbb8ec5UL, 0x00000000UL,\n-    0x00000000UL, 0x09aa36d0UL, 0x3fb6d3f4UL, 0x00000000UL, 0x00000000UL,\n-    0xdcb427fdUL, 0x3fb13950UL, 0xd87ab0bbUL, 0x3fd5335eUL, 0xce0ae8a5UL,\n-    0x3fabb382UL, 0x79143126UL, 0x3fddba41UL, 0x5f2b28d4UL, 0x3fa552f1UL,\n-    0x59f21a6dUL, 0x3fd015abUL, 0x22c27d95UL, 0x3fa0e984UL, 0xe19fc6aaUL,\n-    0x3fd0576cUL, 0x8f2c2950UL, 0x3f9a4898UL, 0xc0b3f22cUL, 0x3fc59462UL,\n-    0x1883a4b8UL, 0x3f94b61cUL, 0x3f838640UL, 0x3fc30eb8UL, 0x355c63dcUL,\n-    0x3fd36a08UL, 0x1dce993dUL, 0xbc6d704dUL, 0x00000000UL, 0x3ff00000UL,\n-    0x2b82ab63UL, 0x3fb78e92UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x56f37042UL, 0x3fccfc56UL, 0x00000000UL, 0x00000000UL,\n-    0xaa563951UL, 0x3fc90125UL, 0x00000000UL, 0x00000000UL, 0x3d0e7c5dUL,\n-    0x3fc50533UL, 0x9bed9b2eUL, 0x3fdf0ed9UL, 0x5fe7c47cUL, 0x3fc1f250UL,\n-    0x96c125e5UL, 0x3fe2edd9UL, 0x5a02bbd8UL, 0x3fbe5c71UL, 0x86362c20UL,\n-    0x3fda08b7UL, 0x4b4435edUL, 0x3fb9d342UL, 0x4b494091UL, 0x3fd911bdUL,\n-    0xb56658beUL, 0x3fb5e4c7UL, 0x93a2fd76UL, 0x3fd3c092UL, 0xda271794UL,\n-    0x3fb29910UL, 0x3303df2bUL, 0x3fd189beUL, 0x99fcef32UL, 0x3fda8279UL,\n-    0xb68c1467UL, 0x3c708b2fUL, 0x00000000UL, 0x3ff00000UL, 0x980c4337UL,\n-    0x3fc5f619UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0xcc03e501UL, 0x3fdff10fUL, 0x00000000UL, 0x00000000UL, 0x44a4e845UL,\n-    0x3fddb63bUL, 0x00000000UL, 0x00000000UL, 0x3768ad9fUL, 0x3fdb72a4UL,\n-    0x3dd01ccaUL, 0x3fe5fdb9UL, 0xa61d2811UL, 0x3fd972b2UL, 0x5645ad0bUL,\n-    0x3fe977f9UL, 0xd013b3abUL, 0x3fd78ca3UL, 0xbf0bf914UL, 0x3fe4f192UL,\n-    0x4d53e730UL, 0x3fd5d060UL, 0x3f8b9000UL, 0x3fe49933UL, 0xe2b82f08UL,\n-    0x3fd4322aUL, 0x5936a835UL, 0x3fe27ae1UL, 0xb1c61c9bUL, 0x3fd2b3fbUL,\n-    0xef478605UL, 0x3fe1659eUL, 0x190834ecUL, 0x3fe11ab7UL, 0xcdb625eaUL,\n-    0xbc8e564bUL, 0x00000000UL, 0x3ff00000UL, 0xb07217e3UL, 0x3fd248f1UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x2b2c49d0UL,\n-    0x3ff2de9cUL, 0x00000000UL, 0x00000000UL, 0x2655bc98UL, 0x3ff33e58UL,\n-    0x00000000UL, 0x00000000UL, 0xff691fa2UL, 0x3ff3972eUL, 0xe93463bdUL,\n-    0x3feeed87UL, 0x070e10a0UL, 0x3ff3f5b2UL, 0xf4d790a4UL, 0x3ff20c10UL,\n-    0xa04e8ea3UL, 0x3ff4541aUL, 0x386accd3UL, 0x3ff1369eUL, 0x222a66ddUL,\n-    0x3ff4b521UL, 0x22a9777eUL, 0x3ff20817UL, 0x52a04a6eUL, 0x3ff5178fUL,\n-    0xddaa0031UL, 0x3ff22137UL, 0x4447d47cUL, 0x3ff57c01UL, 0x1e9c7f1dUL,\n-    0x3ff29311UL, 0x2ab7f990UL, 0x3fe561b8UL, 0x209c7df1UL, 0x3c87a8c5UL,\n-    0x00000000UL, 0x3ff00000UL, 0x4170bcc6UL, 0x3fdc92d8UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xc7ab4d5aUL, 0x40085e24UL,\n-    0x00000000UL, 0x00000000UL, 0xe93ea75dUL, 0x400b963dUL, 0x00000000UL,\n-    0x00000000UL, 0x94a7f25aUL, 0x400f37e2UL, 0x4b6261cbUL, 0x3ff5f984UL,\n-    0x5a9dd812UL, 0x4011aab0UL, 0x74c30018UL, 0x3ffaf5a5UL, 0x7f2ce8e3UL,\n-    0x4013fe8bUL, 0xfe8e54faUL, 0x3ffd7334UL, 0x670d618dUL, 0x4016a10cUL,\n-    0x4db97058UL, 0x4000e012UL, 0x24df44ddUL, 0x40199c5fUL, 0x697d6eceUL,\n-    0x4003006eUL, 0x83298b82UL, 0x401cfc4dUL, 0x19d490d6UL, 0x40058c19UL,\n-    0x2ae42850UL, 0x3fea4300UL, 0x118e20e6UL, 0xbc7a6db8UL, 0x00000000UL,\n-    0x40000000UL, 0xe33345b8UL, 0xbfd4e526UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x65965966UL, 0x40219659UL, 0x00000000UL,\n-    0x00000000UL, 0x882c10faUL, 0x402664f4UL, 0x00000000UL, 0x00000000UL,\n-    0x83cd3723UL, 0x402c8342UL, 0x00000000UL, 0x40000000UL, 0x55e6c23dUL,\n-    0x403226e3UL, 0x55555555UL, 0x40055555UL, 0x34451939UL, 0x40371c96UL,\n-    0xaaaaaaabUL, 0x400aaaaaUL, 0x0e157de0UL, 0x403d6d3dUL, 0x11111111UL,\n-    0x40111111UL, 0xa738201fUL, 0x4042bbceUL, 0x05b05b06UL, 0x4015b05bUL,\n-    0x452b75e3UL, 0x4047da36UL, 0x1ba1ba1cUL, 0x401ba1baUL, 0x00000000UL,\n-    0x3ff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x40000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x4f48b8d3UL, 0xbf33eaf9UL, 0x00000000UL, 0x00000000UL,\n-    0x0cf7586fUL, 0x3f20b8eaUL, 0x00000000UL, 0x00000000UL, 0xd0258911UL,\n-    0xbf0abaf3UL, 0x23e49fe9UL, 0xbfab5a8cUL, 0x2d53222eUL, 0x3ef60d15UL,\n-    0x21169451UL, 0x3fa172b2UL, 0xbb254dbcUL, 0xbee1d3b5UL, 0xdbf93b8eUL,\n-    0xbf84c7dbUL, 0x05b4630bUL, 0x3ecd3364UL, 0xee9aada7UL, 0x3f743924UL,\n-    0x794a8297UL, 0xbeb7b7b9UL, 0xe015f797UL, 0xbf5d41f5UL, 0xe41a4a56UL,\n-    0x3ea35dfbUL, 0xe4c2a251UL, 0x3f49a2abUL, 0x5af9e000UL, 0xbfce49ceUL,\n-    0x8c743719UL, 0x3d1eb860UL, 0x00000000UL, 0x00000000UL, 0x1b4863cfUL,\n-    0x3fd78294UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL,\n-    0x535ad890UL, 0xbf2b9320UL, 0x00000000UL, 0x00000000UL, 0x018fdf1fUL,\n-    0x3f16d61dUL, 0x00000000UL, 0x00000000UL, 0x0359f1beUL, 0xbf0139e4UL,\n-    0xa4317c6dUL, 0xbfa67e17UL, 0x82672d0fUL, 0x3eebb405UL, 0x2f1b621eUL,\n-    0x3f9f455bUL, 0x51ccf238UL, 0xbed55317UL, 0xf437b9acUL, 0xbf804beeUL,\n-    0xc791a2b5UL, 0x3ec0e993UL, 0x919a1db2UL, 0x3f7080c2UL, 0x336a5b0eUL,\n-    0xbeaa48a2UL, 0x0a268358UL, 0xbf55a443UL, 0xdfd978e4UL, 0x3e94b61fUL,\n-    0xd7767a58UL, 0x3f431806UL, 0x2aea0000UL, 0xbfc9bbe8UL, 0x7723ea61UL,\n-    0xbd3a2369UL, 0x00000000UL, 0x00000000UL, 0xdf7796ffUL, 0x3fd6e642UL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0xb9ff07ceUL,\n-    0xbf231c78UL, 0x00000000UL, 0x00000000UL, 0xa5517182UL, 0x3f0ff0e0UL,\n-    0x00000000UL, 0x00000000UL, 0x790b4cbcUL, 0xbef66191UL, 0x848a46c6UL,\n-    0xbfa21ac0UL, 0xb16435faUL, 0x3ee1d3ecUL, 0x2a1aa832UL, 0x3f9c71eaUL,\n-    0xfdd299efUL, 0xbec9dd1aUL, 0x3f8dbaafUL, 0xbf793363UL, 0x309fc6eaUL,\n-    0x3eb415d6UL, 0xbee60471UL, 0x3f6b83baUL, 0x94a0a697UL, 0xbe9dae11UL,\n-    0x3e5c67b3UL, 0xbf4fd07bUL, 0x9a8f3e3eUL, 0x3e86bd75UL, 0xa4beb7a4UL,\n-    0x3f3d1eb1UL, 0x29cfc000UL, 0xbfc549ceUL, 0xbf159358UL, 0xbd397b33UL,\n-    0x00000000UL, 0x00000000UL, 0x871fee6cUL, 0x3fd666f0UL, 0x00000000UL,\n-    0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0x7d98a556UL, 0xbf1a3958UL,\n-    0x00000000UL, 0x00000000UL, 0x9d88dc01UL, 0x3f0704c2UL, 0x00000000UL,\n-    0x00000000UL, 0x73742a2bUL, 0xbeed054aUL, 0x58844587UL, 0xbf9c2a13UL,\n-    0x55688a79UL, 0x3ed7a326UL, 0xee33f1d6UL, 0x3f9a48f4UL, 0xa8dc9888UL,\n-    0xbebf8939UL, 0xaad4b5b8UL, 0xbf72f746UL, 0x9102efa1UL, 0x3ea88f82UL,\n-    0xdabc29cfUL, 0x3f678228UL, 0x9289afb8UL, 0xbe90f456UL, 0x741fb4edUL,\n-    0xbf46f3a3UL, 0xa97f6663UL, 0x3e79b4bfUL, 0xca89ff3fUL, 0x3f36db70UL,\n-    0xa8a2a000UL, 0xbfc0ee13UL, 0x3da24be1UL, 0xbd338b9fUL, 0x00000000UL,\n-    0x00000000UL, 0x11cd6c69UL, 0x3fd601fdUL, 0x00000000UL, 0x3ff00000UL,\n-    0x00000000UL, 0xfffffff8UL, 0x1a154b97UL, 0xbf116b01UL, 0x00000000UL,\n-    0x00000000UL, 0x2d427630UL, 0x3f0147bfUL, 0x00000000UL, 0x00000000UL,\n-    0xb93820c8UL, 0xbee264d4UL, 0xbb6cbb18UL, 0xbf94ab8cUL, 0x888d4d92UL,\n-    0x3ed0568bUL, 0x60730f7cUL, 0x3f98b19bUL, 0xe4b1fb11UL, 0xbeb2f950UL,\n-    0x22cf9f74UL, 0xbf6b21cdUL, 0x4a3ff0a6UL, 0x3e9f499eUL, 0xfd2b83ceUL,\n-    0x3f64aad7UL, 0x637b73afUL, 0xbe83487cUL, 0xe522591aUL, 0xbf3fc092UL,\n-    0xa158e8bcUL, 0x3e6e3aaeUL, 0xe5e82ffaUL, 0x3f329d2fUL, 0xd636a000UL,\n-    0xbfb9477fUL, 0xc2c2d2bcUL, 0xbd135ef9UL, 0x00000000UL, 0x00000000UL,\n-    0xf2fdb123UL, 0x3fd5b566UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL,\n-    0xfffffff8UL, 0xc41acb64UL, 0xbf05448dUL, 0x00000000UL, 0x00000000UL,\n-    0xdbb03d6fUL, 0x3efb7ad2UL, 0x00000000UL, 0x00000000UL, 0x9e42962dUL,\n-    0xbed5aea5UL, 0x2579f8efUL, 0xbf8b2398UL, 0x288a1ed9UL, 0x3ec81441UL,\n-    0xb0198dc5UL, 0x3f979a3aUL, 0x2fdfe253UL, 0xbea57cd3UL, 0x5766336fUL,\n-    0xbf617caaUL, 0x600944c3UL, 0x3e954ed6UL, 0xa4e0aaf8UL, 0x3f62c646UL,\n-    0x6b8fb29cUL, 0xbe74e3a3UL, 0xdc4c0409UL, 0xbf33f952UL, 0x9bffe365UL,\n-    0x3e6301ecUL, 0xb8869e44UL, 0x3f2fc566UL, 0xe1e04000UL, 0xbfb0cc62UL,\n-    0x016b907fUL, 0xbd119cbcUL, 0x00000000UL, 0x00000000UL, 0xe6b9d8faUL,\n-    0x3fd57fb3UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL,\n-    0x5daf22a6UL, 0xbef429d7UL, 0x00000000UL, 0x00000000UL, 0x06bca545UL,\n-    0x3ef7a27dUL, 0x00000000UL, 0x00000000UL, 0x7211c19aUL, 0xbec41c3eUL,\n-    0x956ed53eUL, 0xbf7ae3f4UL, 0xee750e72UL, 0x3ec3901bUL, 0x91d443f5UL,\n-    0x3f96f713UL, 0x36661e6cUL, 0xbe936e09UL, 0x506f9381UL, 0xbf5122e8UL,\n-    0xcb6dd43fUL, 0x3e9041b9UL, 0x6698b2ffUL, 0x3f61b0c7UL, 0x576bf12bUL,\n-    0xbe625a8aUL, 0xe5a0e9dcUL, 0xbf23499dUL, 0x110384ddUL, 0x3e5b1c2cUL,\n-    0x68d43db6UL, 0x3f2cb899UL, 0x6ecac000UL, 0xbfa0c414UL, 0xcd7dd58cUL,\n-    0x3d13500fUL, 0x00000000UL, 0x00000000UL, 0x85a2c8fbUL, 0x3fd55fe0UL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x2bf70ebeUL, 0x3ef66a8fUL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0xd644267fUL, 0x3ec22805UL, 0x16c16c17UL, 0x3f96c16cUL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0xc4e09162UL,\n-    0x3e8d6db2UL, 0xbc011567UL, 0x3f61566aUL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x1f79955cUL, 0x3e57da4eUL, 0x9334ef0bUL,\n-    0x3f2bbd77UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x55555555UL, 0x3fd55555UL, 0x00000000UL,\n-    0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0x5daf22a6UL, 0x3ef429d7UL,\n-    0x00000000UL, 0x00000000UL, 0x06bca545UL, 0x3ef7a27dUL, 0x00000000UL,\n-    0x00000000UL, 0x7211c19aUL, 0x3ec41c3eUL, 0x956ed53eUL, 0x3f7ae3f4UL,\n-    0xee750e72UL, 0x3ec3901bUL, 0x91d443f5UL, 0x3f96f713UL, 0x36661e6cUL,\n-    0x3e936e09UL, 0x506f9381UL, 0x3f5122e8UL, 0xcb6dd43fUL, 0x3e9041b9UL,\n-    0x6698b2ffUL, 0x3f61b0c7UL, 0x576bf12bUL, 0x3e625a8aUL, 0xe5a0e9dcUL,\n-    0x3f23499dUL, 0x110384ddUL, 0x3e5b1c2cUL, 0x68d43db6UL, 0x3f2cb899UL,\n-    0x6ecac000UL, 0x3fa0c414UL, 0xcd7dd58cUL, 0xbd13500fUL, 0x00000000UL,\n-    0x00000000UL, 0x85a2c8fbUL, 0x3fd55fe0UL, 0x00000000UL, 0x3ff00000UL,\n-    0x00000000UL, 0xfffffff8UL, 0xc41acb64UL, 0x3f05448dUL, 0x00000000UL,\n-    0x00000000UL, 0xdbb03d6fUL, 0x3efb7ad2UL, 0x00000000UL, 0x00000000UL,\n-    0x9e42962dUL, 0x3ed5aea5UL, 0x2579f8efUL, 0x3f8b2398UL, 0x288a1ed9UL,\n-    0x3ec81441UL, 0xb0198dc5UL, 0x3f979a3aUL, 0x2fdfe253UL, 0x3ea57cd3UL,\n-    0x5766336fUL, 0x3f617caaUL, 0x600944c3UL, 0x3e954ed6UL, 0xa4e0aaf8UL,\n-    0x3f62c646UL, 0x6b8fb29cUL, 0x3e74e3a3UL, 0xdc4c0409UL, 0x3f33f952UL,\n-    0x9bffe365UL, 0x3e6301ecUL, 0xb8869e44UL, 0x3f2fc566UL, 0xe1e04000UL,\n-    0x3fb0cc62UL, 0x016b907fUL, 0x3d119cbcUL, 0x00000000UL, 0x00000000UL,\n-    0xe6b9d8faUL, 0x3fd57fb3UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL,\n-    0xfffffff8UL, 0x1a154b97UL, 0x3f116b01UL, 0x00000000UL, 0x00000000UL,\n-    0x2d427630UL, 0x3f0147bfUL, 0x00000000UL, 0x00000000UL, 0xb93820c8UL,\n-    0x3ee264d4UL, 0xbb6cbb18UL, 0x3f94ab8cUL, 0x888d4d92UL, 0x3ed0568bUL,\n-    0x60730f7cUL, 0x3f98b19bUL, 0xe4b1fb11UL, 0x3eb2f950UL, 0x22cf9f74UL,\n-    0x3f6b21cdUL, 0x4a3ff0a6UL, 0x3e9f499eUL, 0xfd2b83ceUL, 0x3f64aad7UL,\n-    0x637b73afUL, 0x3e83487cUL, 0xe522591aUL, 0x3f3fc092UL, 0xa158e8bcUL,\n-    0x3e6e3aaeUL, 0xe5e82ffaUL, 0x3f329d2fUL, 0xd636a000UL, 0x3fb9477fUL,\n-    0xc2c2d2bcUL, 0x3d135ef9UL, 0x00000000UL, 0x00000000UL, 0xf2fdb123UL,\n-    0x3fd5b566UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL,\n-    0x7d98a556UL, 0x3f1a3958UL, 0x00000000UL, 0x00000000UL, 0x9d88dc01UL,\n-    0x3f0704c2UL, 0x00000000UL, 0x00000000UL, 0x73742a2bUL, 0x3eed054aUL,\n-    0x58844587UL, 0x3f9c2a13UL, 0x55688a79UL, 0x3ed7a326UL, 0xee33f1d6UL,\n-    0x3f9a48f4UL, 0xa8dc9888UL, 0x3ebf8939UL, 0xaad4b5b8UL, 0x3f72f746UL,\n-    0x9102efa1UL, 0x3ea88f82UL, 0xdabc29cfUL, 0x3f678228UL, 0x9289afb8UL,\n-    0x3e90f456UL, 0x741fb4edUL, 0x3f46f3a3UL, 0xa97f6663UL, 0x3e79b4bfUL,\n-    0xca89ff3fUL, 0x3f36db70UL, 0xa8a2a000UL, 0x3fc0ee13UL, 0x3da24be1UL,\n-    0x3d338b9fUL, 0x00000000UL, 0x00000000UL, 0x11cd6c69UL, 0x3fd601fdUL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0xb9ff07ceUL,\n-    0x3f231c78UL, 0x00000000UL, 0x00000000UL, 0xa5517182UL, 0x3f0ff0e0UL,\n-    0x00000000UL, 0x00000000UL, 0x790b4cbcUL, 0x3ef66191UL, 0x848a46c6UL,\n-    0x3fa21ac0UL, 0xb16435faUL, 0x3ee1d3ecUL, 0x2a1aa832UL, 0x3f9c71eaUL,\n-    0xfdd299efUL, 0x3ec9dd1aUL, 0x3f8dbaafUL, 0x3f793363UL, 0x309fc6eaUL,\n-    0x3eb415d6UL, 0xbee60471UL, 0x3f6b83baUL, 0x94a0a697UL, 0x3e9dae11UL,\n-    0x3e5c67b3UL, 0x3f4fd07bUL, 0x9a8f3e3eUL, 0x3e86bd75UL, 0xa4beb7a4UL,\n-    0x3f3d1eb1UL, 0x29cfc000UL, 0x3fc549ceUL, 0xbf159358UL, 0x3d397b33UL,\n-    0x00000000UL, 0x00000000UL, 0x871fee6cUL, 0x3fd666f0UL, 0x00000000UL,\n-    0x3ff00000UL, 0x00000000UL, 0xfffffff8UL, 0x535ad890UL, 0x3f2b9320UL,\n-    0x00000000UL, 0x00000000UL, 0x018fdf1fUL, 0x3f16d61dUL, 0x00000000UL,\n-    0x00000000UL, 0x0359f1beUL, 0x3f0139e4UL, 0xa4317c6dUL, 0x3fa67e17UL,\n-    0x82672d0fUL, 0x3eebb405UL, 0x2f1b621eUL, 0x3f9f455bUL, 0x51ccf238UL,\n-    0x3ed55317UL, 0xf437b9acUL, 0x3f804beeUL, 0xc791a2b5UL, 0x3ec0e993UL,\n-    0x919a1db2UL, 0x3f7080c2UL, 0x336a5b0eUL, 0x3eaa48a2UL, 0x0a268358UL,\n-    0x3f55a443UL, 0xdfd978e4UL, 0x3e94b61fUL, 0xd7767a58UL, 0x3f431806UL,\n-    0x2aea0000UL, 0x3fc9bbe8UL, 0x7723ea61UL, 0x3d3a2369UL, 0x00000000UL,\n-    0x00000000UL, 0xdf7796ffUL, 0x3fd6e642UL, 0x00000000UL, 0x3ff00000UL,\n-    0x00000000UL, 0xfffffff8UL, 0x4f48b8d3UL, 0x3f33eaf9UL, 0x00000000UL,\n-    0x00000000UL, 0x0cf7586fUL, 0x3f20b8eaUL, 0x00000000UL, 0x00000000UL,\n-    0xd0258911UL, 0x3f0abaf3UL, 0x23e49fe9UL, 0x3fab5a8cUL, 0x2d53222eUL,\n-    0x3ef60d15UL, 0x21169451UL, 0x3fa172b2UL, 0xbb254dbcUL, 0x3ee1d3b5UL,\n-    0xdbf93b8eUL, 0x3f84c7dbUL, 0x05b4630bUL, 0x3ecd3364UL, 0xee9aada7UL,\n-    0x3f743924UL, 0x794a8297UL, 0x3eb7b7b9UL, 0xe015f797UL, 0x3f5d41f5UL,\n-    0xe41a4a56UL, 0x3ea35dfbUL, 0xe4c2a251UL, 0x3f49a2abUL, 0x5af9e000UL,\n-    0x3fce49ceUL, 0x8c743719UL, 0xbd1eb860UL, 0x00000000UL, 0x00000000UL,\n-    0x1b4863cfUL, 0x3fd78294UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL,\n-    0xfffffff8UL, 0x65965966UL, 0xc0219659UL, 0x00000000UL, 0x00000000UL,\n-    0x882c10faUL, 0x402664f4UL, 0x00000000UL, 0x00000000UL, 0x83cd3723UL,\n-    0xc02c8342UL, 0x00000000UL, 0xc0000000UL, 0x55e6c23dUL, 0x403226e3UL,\n-    0x55555555UL, 0x40055555UL, 0x34451939UL, 0xc0371c96UL, 0xaaaaaaabUL,\n-    0xc00aaaaaUL, 0x0e157de0UL, 0x403d6d3dUL, 0x11111111UL, 0x40111111UL,\n-    0xa738201fUL, 0xc042bbceUL, 0x05b05b06UL, 0xc015b05bUL, 0x452b75e3UL,\n-    0x4047da36UL, 0x1ba1ba1cUL, 0x401ba1baUL, 0x00000000UL, 0xbff00000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x40000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0xc7ab4d5aUL, 0xc0085e24UL, 0x00000000UL, 0x00000000UL, 0xe93ea75dUL,\n-    0x400b963dUL, 0x00000000UL, 0x00000000UL, 0x94a7f25aUL, 0xc00f37e2UL,\n-    0x4b6261cbUL, 0xbff5f984UL, 0x5a9dd812UL, 0x4011aab0UL, 0x74c30018UL,\n-    0x3ffaf5a5UL, 0x7f2ce8e3UL, 0xc013fe8bUL, 0xfe8e54faUL, 0xbffd7334UL,\n-    0x670d618dUL, 0x4016a10cUL, 0x4db97058UL, 0x4000e012UL, 0x24df44ddUL,\n-    0xc0199c5fUL, 0x697d6eceUL, 0xc003006eUL, 0x83298b82UL, 0x401cfc4dUL,\n-    0x19d490d6UL, 0x40058c19UL, 0x2ae42850UL, 0xbfea4300UL, 0x118e20e6UL,\n-    0x3c7a6db8UL, 0x00000000UL, 0x40000000UL, 0xe33345b8UL, 0xbfd4e526UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x2b2c49d0UL,\n-    0xbff2de9cUL, 0x00000000UL, 0x00000000UL, 0x2655bc98UL, 0x3ff33e58UL,\n-    0x00000000UL, 0x00000000UL, 0xff691fa2UL, 0xbff3972eUL, 0xe93463bdUL,\n-    0xbfeeed87UL, 0x070e10a0UL, 0x3ff3f5b2UL, 0xf4d790a4UL, 0x3ff20c10UL,\n-    0xa04e8ea3UL, 0xbff4541aUL, 0x386accd3UL, 0xbff1369eUL, 0x222a66ddUL,\n-    0x3ff4b521UL, 0x22a9777eUL, 0x3ff20817UL, 0x52a04a6eUL, 0xbff5178fUL,\n-    0xddaa0031UL, 0xbff22137UL, 0x4447d47cUL, 0x3ff57c01UL, 0x1e9c7f1dUL,\n-    0x3ff29311UL, 0x2ab7f990UL, 0xbfe561b8UL, 0x209c7df1UL, 0xbc87a8c5UL,\n-    0x00000000UL, 0x3ff00000UL, 0x4170bcc6UL, 0x3fdc92d8UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xcc03e501UL, 0xbfdff10fUL,\n-    0x00000000UL, 0x00000000UL, 0x44a4e845UL, 0x3fddb63bUL, 0x00000000UL,\n-    0x00000000UL, 0x3768ad9fUL, 0xbfdb72a4UL, 0x3dd01ccaUL, 0xbfe5fdb9UL,\n-    0xa61d2811UL, 0x3fd972b2UL, 0x5645ad0bUL, 0x3fe977f9UL, 0xd013b3abUL,\n-    0xbfd78ca3UL, 0xbf0bf914UL, 0xbfe4f192UL, 0x4d53e730UL, 0x3fd5d060UL,\n-    0x3f8b9000UL, 0x3fe49933UL, 0xe2b82f08UL, 0xbfd4322aUL, 0x5936a835UL,\n-    0xbfe27ae1UL, 0xb1c61c9bUL, 0x3fd2b3fbUL, 0xef478605UL, 0x3fe1659eUL,\n-    0x190834ecUL, 0xbfe11ab7UL, 0xcdb625eaUL, 0x3c8e564bUL, 0x00000000UL,\n-    0x3ff00000UL, 0xb07217e3UL, 0x3fd248f1UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x56f37042UL, 0xbfccfc56UL, 0x00000000UL,\n-    0x00000000UL, 0xaa563951UL, 0x3fc90125UL, 0x00000000UL, 0x00000000UL,\n-    0x3d0e7c5dUL, 0xbfc50533UL, 0x9bed9b2eUL, 0xbfdf0ed9UL, 0x5fe7c47cUL,\n-    0x3fc1f250UL, 0x96c125e5UL, 0x3fe2edd9UL, 0x5a02bbd8UL, 0xbfbe5c71UL,\n-    0x86362c20UL, 0xbfda08b7UL, 0x4b4435edUL, 0x3fb9d342UL, 0x4b494091UL,\n-    0x3fd911bdUL, 0xb56658beUL, 0xbfb5e4c7UL, 0x93a2fd76UL, 0xbfd3c092UL,\n-    0xda271794UL, 0x3fb29910UL, 0x3303df2bUL, 0x3fd189beUL, 0x99fcef32UL,\n-    0xbfda8279UL, 0xb68c1467UL, 0xbc708b2fUL, 0x00000000UL, 0x3ff00000UL,\n-    0x980c4337UL, 0x3fc5f619UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x9314533eUL, 0xbfbb8ec5UL, 0x00000000UL, 0x00000000UL,\n-    0x09aa36d0UL, 0x3fb6d3f4UL, 0x00000000UL, 0x00000000UL, 0xdcb427fdUL,\n-    0xbfb13950UL, 0xd87ab0bbUL, 0xbfd5335eUL, 0xce0ae8a5UL, 0x3fabb382UL,\n-    0x79143126UL, 0x3fddba41UL, 0x5f2b28d4UL, 0xbfa552f1UL, 0x59f21a6dUL,\n-    0xbfd015abUL, 0x22c27d95UL, 0x3fa0e984UL, 0xe19fc6aaUL, 0x3fd0576cUL,\n-    0x8f2c2950UL, 0xbf9a4898UL, 0xc0b3f22cUL, 0xbfc59462UL, 0x1883a4b8UL,\n-    0x3f94b61cUL, 0x3f838640UL, 0x3fc30eb8UL, 0x355c63dcUL, 0xbfd36a08UL,\n-    0x1dce993dUL, 0x3c6d704dUL, 0x00000000UL, 0x3ff00000UL, 0x2b82ab63UL,\n-    0x3fb78e92UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x5a279ea3UL, 0xbfaa3407UL, 0x00000000UL, 0x00000000UL, 0x432d65faUL,\n-    0x3fa70153UL, 0x00000000UL, 0x00000000UL, 0x891a4602UL, 0xbf9d03efUL,\n-    0xd62ca5f8UL, 0xbfca77d9UL, 0xb35f4628UL, 0x3f97a265UL, 0x433258faUL,\n-    0x3fd8cf51UL, 0xb58fd909UL, 0xbf8f88e3UL, 0x01771ceaUL, 0xbfc2b154UL,\n-    0xf3562f8eUL, 0x3f888f57UL, 0xc028a723UL, 0x3fc7370fUL, 0x20b7f9f0UL,\n-    0xbf80f44cUL, 0x214368e9UL, 0xbfb6dfaaUL, 0x28891863UL, 0x3f79b4b6UL,\n-    0x172dbbf0UL, 0x3fb6cb8eUL, 0xe0553158UL, 0xbfc975f5UL, 0x593fe814UL,\n-    0xbc2ef5d3UL, 0x00000000UL, 0x3ff00000UL, 0x03dec550UL, 0x3fa44203UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x4e435f9bUL,\n-    0xbf953f83UL, 0x00000000UL, 0x00000000UL, 0x3c6e8e46UL, 0x3f9b74eaUL,\n-    0x00000000UL, 0x00000000UL, 0xda5b7511UL, 0xbf85ad63UL, 0xdc230b9bUL,\n-    0xbfb97558UL, 0x26cb3788UL, 0x3f881308UL, 0x76fc4985UL, 0x3fd62ac9UL,\n-    0x77bb08baUL, 0xbf757c85UL, 0xb6247521UL, 0xbfb1381eUL, 0x5922170cUL,\n-    0x3f754e95UL, 0x8746482dUL, 0x3fc27f83UL, 0x11055b30UL, 0xbf64e391UL,\n-    0x3e666320UL, 0xbfa3e609UL, 0x0de9dae3UL, 0x3f6301dfUL, 0x1f1dca06UL,\n-    0x3fafa8aeUL, 0x8c5b2da2UL, 0xbfb936bbUL, 0x4e88f7a5UL, 0xbc587d05UL,\n-    0x00000000UL, 0x3ff00000UL, 0xa8935dd9UL, 0x3f83dde2UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x6dc9c883UL, 0x3fe45f30UL,\n-    0x6dc9c883UL, 0x40245f30UL, 0x00000000UL, 0x43780000UL, 0x00000000UL,\n-    0x43380000UL, 0x54444000UL, 0x3fb921fbUL, 0x54440000UL, 0x3fb921fbUL,\n-    0x67674000UL, 0xbd32e7b9UL, 0x4c4c0000UL, 0x3d468c23UL, 0x3707344aUL,\n-    0x3aa8a2e0UL, 0x03707345UL, 0x3ae98a2eUL, 0x00000000UL, 0x80000000UL,\n-    0x00000000UL, 0x80000000UL, 0x676733afUL, 0x3d32e7b9UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x7ff00000UL, 0x00000000UL, 0x00000000UL, 0xfffc0000UL,\n-    0xffffffffUL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x43600000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x3c800000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ca00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL, 0x00000000UL,\n-    0x40300000UL, 0x00000000UL, 0x3ff00000UL\n-};\n-\n-void MacroAssembler::fast_tan(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n-\n-  Label L_2TAG_PACKET_0_0_2, L_2TAG_PACKET_1_0_2, L_2TAG_PACKET_2_0_2, L_2TAG_PACKET_3_0_2;\n-  Label L_2TAG_PACKET_4_0_2;\n-\n-  assert_different_registers(tmp, eax, ecx, edx);\n-\n-  address static_const_table_tan = (address)_static_const_table_tan;\n-\n-  subl(rsp, 120);\n-  movl(Address(rsp, 56), tmp);\n-  lea(tmp, ExternalAddress(static_const_table_tan));\n-  movsd(xmm0, Address(rsp, 128));\n-  pextrw(eax, xmm0, 3);\n-  andl(eax, 32767);\n-  subl(eax, 14368);\n-  cmpl(eax, 2216);\n-  jcc(Assembler::above, L_2TAG_PACKET_0_0_2);\n-  movdqu(xmm5, Address(tmp, 5840));\n-  movdqu(xmm6, Address(tmp, 5856));\n-  unpcklpd(xmm0, xmm0);\n-  movdqu(xmm4, Address(tmp, 5712));\n-  andpd(xmm4, xmm0);\n-  movdqu(xmm1, Address(tmp, 5632));\n-  mulpd(xmm1, xmm0);\n-  por(xmm5, xmm4);\n-  addpd(xmm1, xmm5);\n-  movdqu(xmm7, xmm1);\n-  unpckhpd(xmm7, xmm7);\n-  cvttsd2sil(edx, xmm7);\n-  cvttpd2dq(xmm1, xmm1);\n-  cvtdq2pd(xmm1, xmm1);\n-  mulpd(xmm1, xmm6);\n-  movdqu(xmm3, Address(tmp, 5664));\n-  movsd(xmm5, Address(tmp, 5728));\n-  addl(edx, 469248);\n-  movdqu(xmm4, Address(tmp, 5680));\n-  mulpd(xmm3, xmm1);\n-  andl(edx, 31);\n-  mulsd(xmm5, xmm1);\n-  movl(ecx, edx);\n-  mulpd(xmm4, xmm1);\n-  shll(ecx, 1);\n-  subpd(xmm0, xmm3);\n-  mulpd(xmm1, Address(tmp, 5696));\n-  addl(edx, ecx);\n-  shll(ecx, 2);\n-  addl(edx, ecx);\n-  addsd(xmm5, xmm0);\n-  movdqu(xmm2, xmm0);\n-  subpd(xmm0, xmm4);\n-  movsd(xmm6, Address(tmp, 5744));\n-  shll(edx, 4);\n-  lea(eax, Address(tmp, 0));\n-  andpd(xmm5, Address(tmp, 5776));\n-  movdqu(xmm3, xmm0);\n-  addl(eax, edx);\n-  subpd(xmm2, xmm0);\n-  unpckhpd(xmm0, xmm0);\n-  divsd(xmm6, xmm5);\n-  subpd(xmm2, xmm4);\n-  movdqu(xmm7, Address(eax, 16));\n-  subsd(xmm3, xmm5);\n-  mulpd(xmm7, xmm0);\n-  subpd(xmm2, xmm1);\n-  movdqu(xmm1, Address(eax, 48));\n-  mulpd(xmm1, xmm0);\n-  movdqu(xmm4, Address(eax, 96));\n-  mulpd(xmm4, xmm0);\n-  addsd(xmm2, xmm3);\n-  movdqu(xmm3, xmm0);\n-  mulpd(xmm0, xmm0);\n-  addpd(xmm7, Address(eax, 0));\n-  addpd(xmm1, Address(eax, 32));\n-  mulpd(xmm1, xmm0);\n-  addpd(xmm4, Address(eax, 80));\n-  addpd(xmm7, xmm1);\n-  movdqu(xmm1, Address(eax, 112));\n-  mulpd(xmm1, xmm0);\n-  mulpd(xmm0, xmm0);\n-  addpd(xmm4, xmm1);\n-  movdqu(xmm1, Address(eax, 64));\n-  mulpd(xmm1, xmm0);\n-  addpd(xmm7, xmm1);\n-  movdqu(xmm1, xmm3);\n-  mulpd(xmm3, xmm0);\n-  mulsd(xmm0, xmm0);\n-  mulpd(xmm1, Address(eax, 144));\n-  mulpd(xmm4, xmm3);\n-  movdqu(xmm3, xmm1);\n-  addpd(xmm7, xmm4);\n-  movdqu(xmm4, xmm1);\n-  mulsd(xmm0, xmm7);\n-  unpckhpd(xmm7, xmm7);\n-  addsd(xmm0, xmm7);\n-  unpckhpd(xmm1, xmm1);\n-  addsd(xmm3, xmm1);\n-  subsd(xmm4, xmm3);\n-  addsd(xmm1, xmm4);\n-  movdqu(xmm4, xmm2);\n-  movsd(xmm7, Address(eax, 144));\n-  unpckhpd(xmm2, xmm2);\n-  addsd(xmm7, Address(eax, 152));\n-  mulsd(xmm7, xmm2);\n-  addsd(xmm7, Address(eax, 136));\n-  addsd(xmm7, xmm1);\n-  addsd(xmm0, xmm7);\n-  movsd(xmm7, Address(tmp, 5744));\n-  mulsd(xmm4, xmm6);\n-  movsd(xmm2, Address(eax, 168));\n-  andpd(xmm2, xmm6);\n-  mulsd(xmm5, xmm2);\n-  mulsd(xmm6, Address(eax, 160));\n-  subsd(xmm7, xmm5);\n-  subsd(xmm2, Address(eax, 128));\n-  subsd(xmm7, xmm4);\n-  mulsd(xmm7, xmm6);\n-  movdqu(xmm4, xmm3);\n-  subsd(xmm3, xmm2);\n-  addsd(xmm2, xmm3);\n-  subsd(xmm4, xmm2);\n-  addsd(xmm0, xmm4);\n-  subsd(xmm0, xmm7);\n-  addsd(xmm0, xmm3);\n-  movsd(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_0_0_2);\n-  jcc(Assembler::greater, L_2TAG_PACKET_2_0_2);\n-  shrl(eax, 4);\n-  cmpl(eax, 268434558);\n-  jcc(Assembler::notEqual, L_2TAG_PACKET_3_0_2);\n-  movdqu(xmm3, xmm0);\n-  mulsd(xmm3, Address(tmp, 5808));\n-\n-  bind(L_2TAG_PACKET_3_0_2);\n-  movsd(xmm3, Address(tmp, 5792));\n-  mulsd(xmm3, xmm0);\n-  addsd(xmm3, xmm0);\n-  mulsd(xmm3, Address(tmp, 5808));\n-  movsd(Address(rsp, 0), xmm3);\n-  fld_d(Address(rsp, 0));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_2_0_2);\n-  movq(xmm7, Address(tmp, 5712));\n-  andpd(xmm7, xmm0);\n-  xorpd(xmm7, xmm0);\n-  ucomisd(xmm7, Address(tmp, 5760));\n-  jcc(Assembler::equal, L_2TAG_PACKET_4_0_2);\n-  subl(rsp, 32);\n-  movsd(Address(rsp, 0), xmm0);\n-  lea(eax, Address(rsp, 40));\n-  movl(Address(rsp, 8), eax);\n-  movl(eax, 2);\n-  movl(Address(rsp, 12), eax);\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlibm_tan_cot_huge())));\n-  addl(rsp, 32);\n-  fld_d(Address(rsp, 8));\n-  jmp(L_2TAG_PACKET_1_0_2);\n-\n-  bind(L_2TAG_PACKET_4_0_2);\n-  movq(Address(rsp, 0), xmm0);\n-  fld_d(Address(rsp, 0));\n-  fsub_d(Address(rsp, 0));\n-\n-  bind(L_2TAG_PACKET_1_0_2);\n-  movl(tmp, Address(rsp, 56));\n-}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_32_tan.cpp","additions":0,"deletions":1172,"binary":false,"changes":1172,"status":"deleted"},{"patch":"@@ -1,2854 +0,0 @@\n-\/*\n- * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"asm\/macroAssembler.inline.hpp\"\n-#include \"code\/compiledIC.hpp\"\n-#include \"code\/debugInfoRec.hpp\"\n-#include \"code\/nativeInst.hpp\"\n-#include \"code\/vtableStubs.hpp\"\n-#include \"compiler\/oopMap.hpp\"\n-#include \"gc\/shared\/gcLocker.hpp\"\n-#include \"gc\/shared\/barrierSet.hpp\"\n-#include \"gc\/shared\/barrierSetAssembler.hpp\"\n-#include \"interpreter\/interpreter.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-#include \"oops\/klass.inline.hpp\"\n-#include \"prims\/methodHandles.hpp\"\n-#include \"runtime\/jniHandles.hpp\"\n-#include \"runtime\/safepointMechanism.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"runtime\/signature.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"runtime\/timerTrace.hpp\"\n-#include \"runtime\/vframeArray.hpp\"\n-#include \"runtime\/vm_version.hpp\"\n-#include \"utilities\/align.hpp\"\n-#include \"vmreg_x86.inline.hpp\"\n-#ifdef COMPILER1\n-#include \"c1\/c1_Runtime1.hpp\"\n-#endif\n-#ifdef COMPILER2\n-#include \"opto\/runtime.hpp\"\n-#endif\n-\n-#define __ masm->\n-\n-#ifdef PRODUCT\n-#define BLOCK_COMMENT(str) \/* nothing *\/\n-#else\n-#define BLOCK_COMMENT(str) __ block_comment(str)\n-#endif \/\/ PRODUCT\n-\n-const int StackAlignmentInSlots = StackAlignmentInBytes \/ VMRegImpl::stack_slot_size;\n-\n-class RegisterSaver {\n-  \/\/ Capture info about frame layout\n-#define DEF_XMM_OFFS(regnum) xmm ## regnum ## _off = xmm_off + (regnum)*16\/BytesPerInt, xmm ## regnum ## H_off\n-  enum layout {\n-                fpu_state_off = 0,\n-                fpu_state_end = fpu_state_off+FPUStateSizeInWords,\n-                st0_off, st0H_off,\n-                st1_off, st1H_off,\n-                st2_off, st2H_off,\n-                st3_off, st3H_off,\n-                st4_off, st4H_off,\n-                st5_off, st5H_off,\n-                st6_off, st6H_off,\n-                st7_off, st7H_off,\n-                xmm_off,\n-                DEF_XMM_OFFS(0),\n-                DEF_XMM_OFFS(1),\n-                DEF_XMM_OFFS(2),\n-                DEF_XMM_OFFS(3),\n-                DEF_XMM_OFFS(4),\n-                DEF_XMM_OFFS(5),\n-                DEF_XMM_OFFS(6),\n-                DEF_XMM_OFFS(7),\n-                flags_off = xmm7_off + 16\/BytesPerInt + 1, \/\/ 16-byte stack alignment fill word\n-                rdi_off,\n-                rsi_off,\n-                ignore_off,  \/\/ extra copy of rbp,\n-                rsp_off,\n-                rbx_off,\n-                rdx_off,\n-                rcx_off,\n-                rax_off,\n-                \/\/ The frame sender code expects that rbp will be in the \"natural\" place and\n-                \/\/ will override any oopMap setting for it. We must therefore force the layout\n-                \/\/ so that it agrees with the frame sender code.\n-                rbp_off,\n-                return_off,      \/\/ slot for return address\n-                reg_save_size };\n-  enum { FPU_regs_live = flags_off - fpu_state_end };\n-\n-  public:\n-\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words,\n-                                     int* total_frame_words, bool verify_fpu = true, bool save_vectors = false);\n-  static void restore_live_registers(MacroAssembler* masm, bool restore_vectors = false);\n-\n-  static int rax_offset() { return rax_off; }\n-  static int rbx_offset() { return rbx_off; }\n-\n-  \/\/ Offsets into the register save area\n-  \/\/ Used by deoptimization when it is managing result register\n-  \/\/ values on its own\n-\n-  static int raxOffset(void) { return rax_off; }\n-  static int rdxOffset(void) { return rdx_off; }\n-  static int rbxOffset(void) { return rbx_off; }\n-  static int xmm0Offset(void) { return xmm0_off; }\n-  \/\/ This really returns a slot in the fp save area, which one is not important\n-  static int fpResultOffset(void) { return st0_off; }\n-\n-  \/\/ During deoptimization only the result register need to be restored\n-  \/\/ all the other values have already been extracted.\n-\n-  static void restore_result_registers(MacroAssembler* masm);\n-\n-};\n-\n-OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words,\n-                                           int* total_frame_words, bool verify_fpu, bool save_vectors) {\n-  int num_xmm_regs = XMMRegister::number_of_registers;\n-  int ymm_bytes = num_xmm_regs * 16;\n-  int zmm_bytes = num_xmm_regs * 32;\n-#ifdef COMPILER2\n-  int opmask_state_bytes = KRegister::number_of_registers * 8;\n-  if (save_vectors) {\n-    assert(UseAVX > 0, \"Vectors larger than 16 byte long are supported only with AVX\");\n-    assert(MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n-    \/\/ Save upper half of YMM registers\n-    int vect_bytes = ymm_bytes;\n-    if (UseAVX > 2) {\n-      \/\/ Save upper half of ZMM registers as well\n-      vect_bytes += zmm_bytes;\n-      additional_frame_words += opmask_state_bytes \/ wordSize;\n-    }\n-    additional_frame_words += vect_bytes \/ wordSize;\n-  }\n-#else\n-  assert(!save_vectors, \"vectors are generated only by C2\");\n-#endif\n-  int frame_size_in_bytes = (reg_save_size + additional_frame_words) * wordSize;\n-  int frame_words = frame_size_in_bytes \/ wordSize;\n-  *total_frame_words = frame_words;\n-\n-  assert(FPUStateSizeInWords == 27, \"update stack layout\");\n-\n-  \/\/ save registers, fpu state, and flags\n-  \/\/ We assume caller has already has return address slot on the stack\n-  \/\/ We push epb twice in this sequence because we want the real rbp,\n-  \/\/ to be under the return like a normal enter and we want to use pusha\n-  \/\/ We push by hand instead of using push.\n-  __ enter();\n-  __ pusha();\n-  __ pushf();\n-  __ subptr(rsp,FPU_regs_live*wordSize); \/\/ Push FPU registers space\n-  __ push_FPU_state();          \/\/ Save FPU state & init\n-\n-  if (verify_fpu) {\n-    \/\/ Some stubs may have non standard FPU control word settings so\n-    \/\/ only check and reset the value when it required to be the\n-    \/\/ standard value.  The safepoint blob in particular can be used\n-    \/\/ in methods which are using the 24 bit control word for\n-    \/\/ optimized float math.\n-\n-#ifdef ASSERT\n-    \/\/ Make sure the control word has the expected value\n-    Label ok;\n-    __ cmpw(Address(rsp, 0), StubRoutines::x86::fpu_cntrl_wrd_std());\n-    __ jccb(Assembler::equal, ok);\n-    __ stop(\"corrupted control word detected\");\n-    __ bind(ok);\n-#endif\n-\n-    \/\/ Reset the control word to guard against exceptions being unmasked\n-    \/\/ since fstp_d can cause FPU stack underflow exceptions.  Write it\n-    \/\/ into the on stack copy and then reload that to make sure that the\n-    \/\/ current and future values are correct.\n-    __ movw(Address(rsp, 0), StubRoutines::x86::fpu_cntrl_wrd_std());\n-  }\n-\n-  __ frstor(Address(rsp, 0));\n-  if (!verify_fpu) {\n-    \/\/ Set the control word so that exceptions are masked for the\n-    \/\/ following code.\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-  }\n-\n-  int off = st0_off;\n-  int delta = st1_off - off;\n-\n-  \/\/ Save the FPU registers in de-opt-able form\n-  for (int n = 0; n < FloatRegister::number_of_registers; n++) {\n-    __ fstp_d(Address(rsp, off*wordSize));\n-    off += delta;\n-  }\n-\n-  off = xmm0_off;\n-  delta = xmm1_off - off;\n-  if(UseSSE == 1) {\n-    \/\/ Save the XMM state\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ movflt(Address(rsp, off*wordSize), as_XMMRegister(n));\n-      off += delta;\n-    }\n-  } else if(UseSSE >= 2) {\n-    \/\/ Save whole 128bit (16 bytes) XMM registers\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ movdqu(Address(rsp, off*wordSize), as_XMMRegister(n));\n-      off += delta;\n-    }\n-  }\n-\n-#ifdef COMPILER2\n-  if (save_vectors) {\n-    __ subptr(rsp, ymm_bytes);\n-    \/\/ Save upper half of YMM registers\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ vextractf128_high(Address(rsp, n*16), as_XMMRegister(n));\n-    }\n-    if (UseAVX > 2) {\n-      __ subptr(rsp, zmm_bytes);\n-      \/\/ Save upper half of ZMM registers\n-      for (int n = 0; n < num_xmm_regs; n++) {\n-        __ vextractf64x4_high(Address(rsp, n*32), as_XMMRegister(n));\n-      }\n-      __ subptr(rsp, opmask_state_bytes);\n-      \/\/ Save opmask registers\n-      for (int n = 0; n < KRegister::number_of_registers; n++) {\n-        __ kmov(Address(rsp, n*8), as_KRegister(n));\n-      }\n-    }\n-  }\n-#else\n-  assert(!save_vectors, \"vectors are generated only by C2\");\n-#endif\n-\n-  __ vzeroupper();\n-\n-  \/\/ Set an oopmap for the call site.  This oopmap will map all\n-  \/\/ oop-registers and debug-info registers as callee-saved.  This\n-  \/\/ will allow deoptimization at this safepoint to find all possible\n-  \/\/ debug-info recordings, as well as let GC find all oops.\n-\n-  OopMapSet *oop_maps = new OopMapSet();\n-  OopMap* map =  new OopMap( frame_words, 0 );\n-\n-#define STACK_OFFSET(x) VMRegImpl::stack2reg((x) + additional_frame_words)\n-#define NEXTREG(x) (x)->as_VMReg()->next()\n-\n-  map->set_callee_saved(STACK_OFFSET(rax_off), rax->as_VMReg());\n-  map->set_callee_saved(STACK_OFFSET(rcx_off), rcx->as_VMReg());\n-  map->set_callee_saved(STACK_OFFSET(rdx_off), rdx->as_VMReg());\n-  map->set_callee_saved(STACK_OFFSET(rbx_off), rbx->as_VMReg());\n-  \/\/ rbp, location is known implicitly, no oopMap\n-  map->set_callee_saved(STACK_OFFSET(rsi_off), rsi->as_VMReg());\n-  map->set_callee_saved(STACK_OFFSET(rdi_off), rdi->as_VMReg());\n-\n-  \/\/ %%% This is really a waste but we'll keep things as they were for now for the upper component\n-  off = st0_off;\n-  delta = st1_off - off;\n-  for (int n = 0; n < FloatRegister::number_of_registers; n++) {\n-    FloatRegister freg_name = as_FloatRegister(n);\n-    map->set_callee_saved(STACK_OFFSET(off), freg_name->as_VMReg());\n-    map->set_callee_saved(STACK_OFFSET(off+1), NEXTREG(freg_name));\n-    off += delta;\n-  }\n-  off = xmm0_off;\n-  delta = xmm1_off - off;\n-  for (int n = 0; n < num_xmm_regs; n++) {\n-    XMMRegister xmm_name = as_XMMRegister(n);\n-    map->set_callee_saved(STACK_OFFSET(off), xmm_name->as_VMReg());\n-    map->set_callee_saved(STACK_OFFSET(off+1), NEXTREG(xmm_name));\n-    off += delta;\n-  }\n-#undef NEXTREG\n-#undef STACK_OFFSET\n-\n-  return map;\n-}\n-\n-void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {\n-  int opmask_state_bytes = 0;\n-  int additional_frame_bytes = 0;\n-  int num_xmm_regs = XMMRegister::number_of_registers;\n-  int ymm_bytes = num_xmm_regs * 16;\n-  int zmm_bytes = num_xmm_regs * 32;\n-  \/\/ Recover XMM & FPU state\n-#ifdef COMPILER2\n-  if (restore_vectors) {\n-    assert(UseAVX > 0, \"Vectors larger than 16 byte long are supported only with AVX\");\n-    assert(MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n-    \/\/ Save upper half of YMM registers\n-    additional_frame_bytes = ymm_bytes;\n-    if (UseAVX > 2) {\n-      \/\/ Save upper half of ZMM registers as well\n-      additional_frame_bytes += zmm_bytes;\n-      opmask_state_bytes = KRegister::number_of_registers * 8;\n-      additional_frame_bytes += opmask_state_bytes;\n-    }\n-  }\n-#else\n-  assert(!restore_vectors, \"vectors are generated only by C2\");\n-#endif\n-\n-  int off = xmm0_off;\n-  int delta = xmm1_off - off;\n-\n-  __ vzeroupper();\n-\n-  if (UseSSE == 1) {\n-    \/\/ Restore XMM registers\n-    assert(additional_frame_bytes == 0, \"\");\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ movflt(as_XMMRegister(n), Address(rsp, off*wordSize));\n-      off += delta;\n-    }\n-  } else if (UseSSE >= 2) {\n-    \/\/ Restore whole 128bit (16 bytes) XMM registers. Do this before restoring YMM and\n-    \/\/ ZMM because the movdqu instruction zeros the upper part of the XMM register.\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ movdqu(as_XMMRegister(n), Address(rsp, off*wordSize+additional_frame_bytes));\n-      off += delta;\n-    }\n-  }\n-\n-  if (restore_vectors) {\n-    off = additional_frame_bytes - ymm_bytes;\n-    \/\/ Restore upper half of YMM registers.\n-    for (int n = 0; n < num_xmm_regs; n++) {\n-      __ vinsertf128_high(as_XMMRegister(n), Address(rsp, n*16+off));\n-    }\n-    if (UseAVX > 2) {\n-      \/\/ Restore upper half of ZMM registers.\n-      off = opmask_state_bytes;\n-      for (int n = 0; n < num_xmm_regs; n++) {\n-        __ vinsertf64x4_high(as_XMMRegister(n), Address(rsp, n*32+off));\n-      }\n-      for (int n = 0; n < KRegister::number_of_registers; n++) {\n-        __ kmov(as_KRegister(n), Address(rsp, n*8));\n-      }\n-    }\n-    __ addptr(rsp, additional_frame_bytes);\n-  }\n-\n-  __ pop_FPU_state();\n-  __ addptr(rsp, FPU_regs_live*wordSize); \/\/ Pop FPU registers\n-\n-  __ popf();\n-  __ popa();\n-  \/\/ Get the rbp, described implicitly by the frame sender code (no oopMap)\n-  __ pop(rbp);\n-}\n-\n-void RegisterSaver::restore_result_registers(MacroAssembler* masm) {\n-\n-  \/\/ Just restore result register. Only used by deoptimization. By\n-  \/\/ now any callee save register that needs to be restore to a c2\n-  \/\/ caller of the deoptee has been extracted into the vframeArray\n-  \/\/ and will be stuffed into the c2i adapter we create for later\n-  \/\/ restoration so only result registers need to be restored here.\n-  \/\/\n-\n-  __ frstor(Address(rsp, 0));      \/\/ Restore fpu state\n-\n-  \/\/ Recover XMM & FPU state\n-  if( UseSSE == 1 ) {\n-    __ movflt(xmm0, Address(rsp, xmm0_off*wordSize));\n-  } else if( UseSSE >= 2 ) {\n-    __ movdbl(xmm0, Address(rsp, xmm0_off*wordSize));\n-  }\n-  __ movptr(rax, Address(rsp, rax_off*wordSize));\n-  __ movptr(rdx, Address(rsp, rdx_off*wordSize));\n-  \/\/ Pop all of the register save are off the stack except the return address\n-  __ addptr(rsp, return_off * wordSize);\n-}\n-\n-\/\/ Is vector's size (in bytes) bigger than a size saved by default?\n-\/\/ 16 bytes XMM registers are saved by default using SSE2 movdqu instructions.\n-\/\/ Note, MaxVectorSize == 0 with UseSSE < 2 and vectors are not generated.\n-bool SharedRuntime::is_wide_vector(int size) {\n-  return size > 16;\n-}\n-\n-\/\/ The java_calling_convention describes stack locations as ideal slots on\n-\/\/ a frame with no abi restrictions. Since we must observe abi restrictions\n-\/\/ (like the placement of the register window) the slots must be biased by\n-\/\/ the following value.\n-static int reg2offset_in(VMReg r) {\n-  \/\/ Account for saved rbp, and return address\n-  \/\/ This should really be in_preserve_stack_slots\n-  return (r->reg2stack() + 2) * VMRegImpl::stack_slot_size;\n-}\n-\n-static int reg2offset_out(VMReg r) {\n-  return (r->reg2stack() + SharedRuntime::out_preserve_stack_slots()) * VMRegImpl::stack_slot_size;\n-}\n-\n-\/\/ ---------------------------------------------------------------------------\n-\/\/ Read the array of BasicTypes from a signature, and compute where the\n-\/\/ arguments should go.  Values in the VMRegPair regs array refer to 4-byte\n-\/\/ quantities.  Values less than SharedInfo::stack0 are registers, those above\n-\/\/ refer to 4-byte stack slots.  All stack slots are based off of the stack pointer\n-\/\/ as framesizes are fixed.\n-\/\/ VMRegImpl::stack0 refers to the first slot 0(sp).\n-\/\/ and VMRegImpl::stack0+1 refers to the memory word 4-byes higher.\n-\/\/ Register up to Register::number_of_registers are the 32-bit\n-\/\/ integer registers.\n-\n-\/\/ Pass first two oop\/int args in registers ECX and EDX.\n-\/\/ Pass first two float\/double args in registers XMM0 and XMM1.\n-\/\/ Doubles have precedence, so if you pass a mix of floats and doubles\n-\/\/ the doubles will grab the registers before the floats will.\n-\n-\/\/ Note: the INPUTS in sig_bt are in units of Java argument words, which are\n-\/\/ either 32-bit or 64-bit depending on the build.  The OUTPUTS are in 32-bit\n-\/\/ units regardless of build. Of course for i486 there is no 64 bit build\n-\n-\n-\/\/ ---------------------------------------------------------------------------\n-\/\/ The compiled Java calling convention.\n-\/\/ Pass first two oop\/int args in registers ECX and EDX.\n-\/\/ Pass first two float\/double args in registers XMM0 and XMM1.\n-\/\/ Doubles have precedence, so if you pass a mix of floats and doubles\n-\/\/ the doubles will grab the registers before the floats will.\n-int SharedRuntime::java_calling_convention(const BasicType *sig_bt,\n-                                           VMRegPair *regs,\n-                                           int total_args_passed) {\n-  uint    stack = 0;          \/\/ Starting stack position for args on stack\n-\n-\n-  \/\/ Pass first two oop\/int args in registers ECX and EDX.\n-  uint reg_arg0 = 9999;\n-  uint reg_arg1 = 9999;\n-\n-  \/\/ Pass first two float\/double args in registers XMM0 and XMM1.\n-  \/\/ Doubles have precedence, so if you pass a mix of floats and doubles\n-  \/\/ the doubles will grab the registers before the floats will.\n-  \/\/ CNC - TURNED OFF FOR non-SSE.\n-  \/\/       On Intel we have to round all doubles (and most floats) at\n-  \/\/       call sites by storing to the stack in any case.\n-  \/\/ UseSSE=0 ==> Don't Use ==> 9999+0\n-  \/\/ UseSSE=1 ==> Floats only ==> 9999+1\n-  \/\/ UseSSE>=2 ==> Floats or doubles ==> 9999+2\n-  enum { fltarg_dontuse = 9999+0, fltarg_float_only = 9999+1, fltarg_flt_dbl = 9999+2 };\n-  uint fargs = (UseSSE>=2) ? 2 : UseSSE;\n-  uint freg_arg0 = 9999+fargs;\n-  uint freg_arg1 = 9999+fargs;\n-\n-  \/\/ Pass doubles & longs aligned on the stack.  First count stack slots for doubles\n-  int i;\n-  for( i = 0; i < total_args_passed; i++) {\n-    if( sig_bt[i] == T_DOUBLE ) {\n-      \/\/ first 2 doubles go in registers\n-      if( freg_arg0 == fltarg_flt_dbl ) freg_arg0 = i;\n-      else if( freg_arg1 == fltarg_flt_dbl ) freg_arg1 = i;\n-      else \/\/ Else double is passed low on the stack to be aligned.\n-        stack += 2;\n-    } else if( sig_bt[i] == T_LONG ) {\n-      stack += 2;\n-    }\n-  }\n-  int dstack = 0;             \/\/ Separate counter for placing doubles\n-\n-  \/\/ Now pick where all else goes.\n-  for( i = 0; i < total_args_passed; i++) {\n-    \/\/ From the type and the argument number (count) compute the location\n-    switch( sig_bt[i] ) {\n-    case T_SHORT:\n-    case T_CHAR:\n-    case T_BYTE:\n-    case T_BOOLEAN:\n-    case T_INT:\n-    case T_ARRAY:\n-    case T_OBJECT:\n-    case T_ADDRESS:\n-      if( reg_arg0 == 9999 )  {\n-        reg_arg0 = i;\n-        regs[i].set1(rcx->as_VMReg());\n-      } else if( reg_arg1 == 9999 )  {\n-        reg_arg1 = i;\n-        regs[i].set1(rdx->as_VMReg());\n-      } else {\n-        regs[i].set1(VMRegImpl::stack2reg(stack++));\n-      }\n-      break;\n-    case T_FLOAT:\n-      if( freg_arg0 == fltarg_flt_dbl || freg_arg0 == fltarg_float_only ) {\n-        freg_arg0 = i;\n-        regs[i].set1(xmm0->as_VMReg());\n-      } else if( freg_arg1 == fltarg_flt_dbl || freg_arg1 == fltarg_float_only ) {\n-        freg_arg1 = i;\n-        regs[i].set1(xmm1->as_VMReg());\n-      } else {\n-        regs[i].set1(VMRegImpl::stack2reg(stack++));\n-      }\n-      break;\n-    case T_LONG:\n-      assert((i + 1) < total_args_passed && sig_bt[i+1] == T_VOID, \"missing Half\" );\n-      regs[i].set2(VMRegImpl::stack2reg(dstack));\n-      dstack += 2;\n-      break;\n-    case T_DOUBLE:\n-      assert((i + 1) < total_args_passed && sig_bt[i+1] == T_VOID, \"missing Half\" );\n-      if( freg_arg0 == (uint)i ) {\n-        regs[i].set2(xmm0->as_VMReg());\n-      } else if( freg_arg1 == (uint)i ) {\n-        regs[i].set2(xmm1->as_VMReg());\n-      } else {\n-        regs[i].set2(VMRegImpl::stack2reg(dstack));\n-        dstack += 2;\n-      }\n-      break;\n-    case T_VOID: regs[i].set_bad(); break;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-    }\n-  }\n-\n-  return stack;\n-}\n-\n-\/\/ Patch the callers callsite with entry to compiled code if it exists.\n-static void patch_callers_callsite(MacroAssembler *masm) {\n-  Label L;\n-  __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n-  __ jcc(Assembler::equal, L);\n-  \/\/ Schedule the branch target address early.\n-  \/\/ Call into the VM to patch the caller, then jump to compiled callee\n-  \/\/ rax, isn't live so capture return address while we easily can\n-  __ movptr(rax, Address(rsp, 0));\n-  __ pusha();\n-  __ pushf();\n-\n-  if (UseSSE == 1) {\n-    __ subptr(rsp, 2*wordSize);\n-    __ movflt(Address(rsp, 0), xmm0);\n-    __ movflt(Address(rsp, wordSize), xmm1);\n-  }\n-  if (UseSSE >= 2) {\n-    __ subptr(rsp, 4*wordSize);\n-    __ movdbl(Address(rsp, 0), xmm0);\n-    __ movdbl(Address(rsp, 2*wordSize), xmm1);\n-  }\n-#ifdef COMPILER2\n-  \/\/ C2 may leave the stack dirty if not in SSE2+ mode\n-  if (UseSSE >= 2) {\n-    __ verify_FPU(0, \"c2i transition should have clean FPU stack\");\n-  } else {\n-    __ empty_FPU_stack();\n-  }\n-#endif \/* COMPILER2 *\/\n-\n-  \/\/ VM needs caller's callsite\n-  __ push(rax);\n-  \/\/ VM needs target method\n-  __ push(rbx);\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::fixup_callers_callsite)));\n-  __ addptr(rsp, 2*wordSize);\n-\n-  if (UseSSE == 1) {\n-    __ movflt(xmm0, Address(rsp, 0));\n-    __ movflt(xmm1, Address(rsp, wordSize));\n-    __ addptr(rsp, 2*wordSize);\n-  }\n-  if (UseSSE >= 2) {\n-    __ movdbl(xmm0, Address(rsp, 0));\n-    __ movdbl(xmm1, Address(rsp, 2*wordSize));\n-    __ addptr(rsp, 4*wordSize);\n-  }\n-\n-  __ popf();\n-  __ popa();\n-  __ bind(L);\n-}\n-\n-\n-static void move_c2i_double(MacroAssembler *masm, XMMRegister r, int st_off) {\n-  int next_off = st_off - Interpreter::stackElementSize;\n-  __ movdbl(Address(rsp, next_off), r);\n-}\n-\n-static void gen_c2i_adapter(MacroAssembler *masm,\n-                            int total_args_passed,\n-                            int comp_args_on_stack,\n-                            const BasicType *sig_bt,\n-                            const VMRegPair *regs,\n-                            Label& skip_fixup) {\n-  \/\/ Before we get into the guts of the C2I adapter, see if we should be here\n-  \/\/ at all.  We've come from compiled code and are attempting to jump to the\n-  \/\/ interpreter, which means the caller made a static call to get here\n-  \/\/ (vcalls always get a compiled target if there is one).  Check for a\n-  \/\/ compiled target.  If there is one, we need to patch the caller's call.\n-  patch_callers_callsite(masm);\n-\n-  __ bind(skip_fixup);\n-\n-#ifdef COMPILER2\n-  \/\/ C2 may leave the stack dirty if not in SSE2+ mode\n-  if (UseSSE >= 2) {\n-    __ verify_FPU(0, \"c2i transition should have clean FPU stack\");\n-  } else {\n-    __ empty_FPU_stack();\n-  }\n-#endif \/* COMPILER2 *\/\n-\n-  \/\/ Since all args are passed on the stack, total_args_passed * interpreter_\n-  \/\/ stack_element_size  is the\n-  \/\/ space we need.\n-  int extraspace = total_args_passed * Interpreter::stackElementSize;\n-\n-  \/\/ Get return address\n-  __ pop(rax);\n-\n-  \/\/ set senderSP value\n-  __ movptr(rsi, rsp);\n-\n-  __ subptr(rsp, extraspace);\n-\n-  \/\/ Now write the args into the outgoing interpreter space\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n-\n-    \/\/ st_off points to lowest address on stack.\n-    int st_off = ((total_args_passed - 1) - i) * Interpreter::stackElementSize;\n-    int next_off = st_off - Interpreter::stackElementSize;\n-\n-    \/\/ Say 4 args:\n-    \/\/ i   st_off\n-    \/\/ 0   12 T_LONG\n-    \/\/ 1    8 T_VOID\n-    \/\/ 2    4 T_OBJECT\n-    \/\/ 3    0 T_BOOL\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n-    if (!r_1->is_valid()) {\n-      assert(!r_2->is_valid(), \"\");\n-      continue;\n-    }\n-\n-    if (r_1->is_stack()) {\n-      \/\/ memory to memory use fpu stack top\n-      int ld_off = r_1->reg2stack() * VMRegImpl::stack_slot_size + extraspace;\n-\n-      if (!r_2->is_valid()) {\n-        __ movl(rdi, Address(rsp, ld_off));\n-        __ movptr(Address(rsp, st_off), rdi);\n-      } else {\n-\n-        \/\/ ld_off == LSW, ld_off+VMRegImpl::stack_slot_size == MSW\n-        \/\/ st_off == MSW, st_off-wordSize == LSW\n-\n-        __ movptr(rdi, Address(rsp, ld_off));\n-        __ movptr(Address(rsp, next_off), rdi);\n-        __ movptr(rdi, Address(rsp, ld_off + wordSize));\n-        __ movptr(Address(rsp, st_off), rdi);\n-      }\n-    } else if (r_1->is_Register()) {\n-      Register r = r_1->as_Register();\n-      if (!r_2->is_valid()) {\n-        __ movl(Address(rsp, st_off), r);\n-      } else {\n-        \/\/ long\/double in gpr\n-        ShouldNotReachHere();\n-      }\n-    } else {\n-      assert(r_1->is_XMMRegister(), \"\");\n-      if (!r_2->is_valid()) {\n-        __ movflt(Address(rsp, st_off), r_1->as_XMMRegister());\n-      } else {\n-        assert(sig_bt[i] == T_DOUBLE || sig_bt[i] == T_LONG, \"wrong type\");\n-        move_c2i_double(masm, r_1->as_XMMRegister(), st_off);\n-      }\n-    }\n-  }\n-\n-  \/\/ Schedule the branch target address early.\n-  __ movptr(rcx, Address(rbx, in_bytes(Method::interpreter_entry_offset())));\n-  \/\/ And repush original return address\n-  __ push(rax);\n-  __ jmp(rcx);\n-}\n-\n-\n-static void move_i2c_double(MacroAssembler *masm, XMMRegister r, Register saved_sp, int ld_off) {\n-  int next_val_off = ld_off - Interpreter::stackElementSize;\n-  __ movdbl(r, Address(saved_sp, next_val_off));\n-}\n-\n-static void range_check(MacroAssembler* masm, Register pc_reg, Register temp_reg,\n-                        address code_start, address code_end,\n-                        Label& L_ok) {\n-  Label L_fail;\n-  __ lea(temp_reg, AddressLiteral(code_start, relocInfo::none));\n-  __ cmpptr(pc_reg, temp_reg);\n-  __ jcc(Assembler::belowEqual, L_fail);\n-  __ lea(temp_reg, AddressLiteral(code_end, relocInfo::none));\n-  __ cmpptr(pc_reg, temp_reg);\n-  __ jcc(Assembler::below, L_ok);\n-  __ bind(L_fail);\n-}\n-\n-void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,\n-                                    int total_args_passed,\n-                                    int comp_args_on_stack,\n-                                    const BasicType *sig_bt,\n-                                    const VMRegPair *regs) {\n-  \/\/ Note: rsi contains the senderSP on entry. We must preserve it since\n-  \/\/ we may do a i2c -> c2i transition if we lose a race where compiled\n-  \/\/ code goes non-entrant while we get args ready.\n-\n-  \/\/ Adapters can be frameless because they do not require the caller\n-  \/\/ to perform additional cleanup work, such as correcting the stack pointer.\n-  \/\/ An i2c adapter is frameless because the *caller* frame, which is interpreted,\n-  \/\/ routinely repairs its own stack pointer (from interpreter_frame_last_sp),\n-  \/\/ even if a callee has modified the stack pointer.\n-  \/\/ A c2i adapter is frameless because the *callee* frame, which is interpreted,\n-  \/\/ routinely repairs its caller's stack pointer (from sender_sp, which is set\n-  \/\/ up via the senderSP register).\n-  \/\/ In other words, if *either* the caller or callee is interpreted, we can\n-  \/\/ get the stack pointer repaired after a call.\n-  \/\/ This is why c2i and i2c adapters cannot be indefinitely composed.\n-  \/\/ In particular, if a c2i adapter were to somehow call an i2c adapter,\n-  \/\/ both caller and callee would be compiled methods, and neither would\n-  \/\/ clean up the stack pointer changes performed by the two adapters.\n-  \/\/ If this happens, control eventually transfers back to the compiled\n-  \/\/ caller, but with an uncorrected stack, causing delayed havoc.\n-\n-  \/\/ Pick up the return address\n-  __ movptr(rax, Address(rsp, 0));\n-\n-  if (VerifyAdapterCalls &&\n-      (Interpreter::code() != nullptr || StubRoutines::final_stubs_code() != nullptr)) {\n-    \/\/ So, let's test for cascading c2i\/i2c adapters right now.\n-    \/\/  assert(Interpreter::contains($return_addr) ||\n-    \/\/         StubRoutines::contains($return_addr),\n-    \/\/         \"i2c adapter must return to an interpreter frame\");\n-    __ block_comment(\"verify_i2c { \");\n-    Label L_ok;\n-    if (Interpreter::code() != nullptr) {\n-      range_check(masm, rax, rdi,\n-                  Interpreter::code()->code_start(), Interpreter::code()->code_end(),\n-                  L_ok);\n-    }\n-    if (StubRoutines::initial_stubs_code() != nullptr) {\n-      range_check(masm, rax, rdi,\n-                  StubRoutines::initial_stubs_code()->code_begin(),\n-                  StubRoutines::initial_stubs_code()->code_end(),\n-                  L_ok);\n-    }\n-    if (StubRoutines::final_stubs_code() != nullptr) {\n-      range_check(masm, rax, rdi,\n-                  StubRoutines::final_stubs_code()->code_begin(),\n-                  StubRoutines::final_stubs_code()->code_end(),\n-                  L_ok);\n-    }\n-    const char* msg = \"i2c adapter must return to an interpreter frame\";\n-    __ block_comment(msg);\n-    __ stop(msg);\n-    __ bind(L_ok);\n-    __ block_comment(\"} verify_i2ce \");\n-  }\n-\n-  \/\/ Must preserve original SP for loading incoming arguments because\n-  \/\/ we need to align the outgoing SP for compiled code.\n-  __ movptr(rdi, rsp);\n-\n-  \/\/ Cut-out for having no stack args.  Since up to 2 int\/oop args are passed\n-  \/\/ in registers, we will occasionally have no stack args.\n-  int comp_words_on_stack = 0;\n-  if (comp_args_on_stack) {\n-    \/\/ Sig words on the stack are greater-than VMRegImpl::stack0.  Those in\n-    \/\/ registers are below.  By subtracting stack0, we either get a negative\n-    \/\/ number (all values in registers) or the maximum stack slot accessed.\n-    \/\/ int comp_args_on_stack = VMRegImpl::reg2stack(max_arg);\n-    \/\/ Convert 4-byte stack slots to words.\n-    comp_words_on_stack = align_up(comp_args_on_stack*4, wordSize)>>LogBytesPerWord;\n-    \/\/ Round up to miminum stack alignment, in wordSize\n-    comp_words_on_stack = align_up(comp_words_on_stack, 2);\n-    __ subptr(rsp, comp_words_on_stack * wordSize);\n-  }\n-\n-  \/\/ Align the outgoing SP\n-  __ andptr(rsp, -(StackAlignmentInBytes));\n-\n-  \/\/ push the return address on the stack (note that pushing, rather\n-  \/\/ than storing it, yields the correct frame alignment for the callee)\n-  __ push(rax);\n-\n-  \/\/ Put saved SP in another register\n-  const Register saved_sp = rax;\n-  __ movptr(saved_sp, rdi);\n-\n-\n-  \/\/ Will jump to the compiled code just as if compiled code was doing it.\n-  \/\/ Pre-load the register-jump target early, to schedule it better.\n-  __ movptr(rdi, Address(rbx, in_bytes(Method::from_compiled_offset())));\n-\n-  \/\/ Now generate the shuffle code.  Pick up all register args and move the\n-  \/\/ rest through the floating point stack top.\n-  for (int i = 0; i < total_args_passed; i++) {\n-    if (sig_bt[i] == T_VOID) {\n-      \/\/ Longs and doubles are passed in native word order, but misaligned\n-      \/\/ in the 32-bit build.\n-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), \"missing half\");\n-      continue;\n-    }\n-\n-    \/\/ Pick up 0, 1 or 2 words from SP+offset.\n-\n-    assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(),\n-            \"scrambled load targets?\");\n-    \/\/ Load in argument order going down.\n-    int ld_off = (total_args_passed - i) * Interpreter::stackElementSize;\n-    \/\/ Point to interpreter value (vs. tag)\n-    int next_off = ld_off - Interpreter::stackElementSize;\n-    \/\/\n-    \/\/\n-    \/\/\n-    VMReg r_1 = regs[i].first();\n-    VMReg r_2 = regs[i].second();\n-    if (!r_1->is_valid()) {\n-      assert(!r_2->is_valid(), \"\");\n-      continue;\n-    }\n-    if (r_1->is_stack()) {\n-      \/\/ Convert stack slot to an SP offset (+ wordSize to account for return address )\n-      int st_off = regs[i].first()->reg2stack()*VMRegImpl::stack_slot_size + wordSize;\n-\n-      \/\/ We can use rsi as a temp here because compiled code doesn't need rsi as an input\n-      \/\/ and if we end up going thru a c2i because of a miss a reasonable value of rsi\n-      \/\/ we be generated.\n-      if (!r_2->is_valid()) {\n-        \/\/ __ fld_s(Address(saved_sp, ld_off));\n-        \/\/ __ fstp_s(Address(rsp, st_off));\n-        __ movl(rsi, Address(saved_sp, ld_off));\n-        __ movptr(Address(rsp, st_off), rsi);\n-      } else {\n-        \/\/ Interpreter local[n] == MSW, local[n+1] == LSW however locals\n-        \/\/ are accessed as negative so LSW is at LOW address\n-\n-        \/\/ ld_off is MSW so get LSW\n-        \/\/ st_off is LSW (i.e. reg.first())\n-        \/\/ __ fld_d(Address(saved_sp, next_off));\n-        \/\/ __ fstp_d(Address(rsp, st_off));\n-        \/\/\n-        \/\/ We are using two VMRegs. This can be either T_OBJECT, T_ADDRESS, T_LONG, or T_DOUBLE\n-        \/\/ the interpreter allocates two slots but only uses one for thr T_LONG or T_DOUBLE case\n-        \/\/ So we must adjust where to pick up the data to match the interpreter.\n-        \/\/\n-        \/\/ Interpreter local[n] == MSW, local[n+1] == LSW however locals\n-        \/\/ are accessed as negative so LSW is at LOW address\n-\n-        \/\/ ld_off is MSW so get LSW\n-        __ movptr(rsi, Address(saved_sp, next_off));\n-        __ movptr(Address(rsp, st_off), rsi);\n-        __ movptr(rsi, Address(saved_sp, ld_off));\n-        __ movptr(Address(rsp, st_off + wordSize), rsi);\n-      }\n-    } else if (r_1->is_Register()) {  \/\/ Register argument\n-      Register r = r_1->as_Register();\n-      assert(r != rax, \"must be different\");\n-      if (r_2->is_valid()) {\n-        \/\/\n-        \/\/ We are using two VMRegs. This can be either T_OBJECT, T_ADDRESS, T_LONG, or T_DOUBLE\n-        \/\/ the interpreter allocates two slots but only uses one for thr T_LONG or T_DOUBLE case\n-        \/\/ So we must adjust where to pick up the data to match the interpreter.\n-\n-        \/\/ this can be a misaligned move\n-        __ movptr(r, Address(saved_sp, next_off));\n-        assert(r_2->as_Register() != rax, \"need another temporary register\");\n-        \/\/ Remember r_1 is low address (and LSB on x86)\n-        \/\/ So r_2 gets loaded from high address regardless of the platform\n-        __ movptr(r_2->as_Register(), Address(saved_sp, ld_off));\n-      } else {\n-        __ movl(r, Address(saved_sp, ld_off));\n-      }\n-    } else {\n-      assert(r_1->is_XMMRegister(), \"\");\n-      if (!r_2->is_valid()) {\n-        __ movflt(r_1->as_XMMRegister(), Address(saved_sp, ld_off));\n-      } else {\n-        move_i2c_double(masm, r_1->as_XMMRegister(), saved_sp, ld_off);\n-      }\n-    }\n-  }\n-\n-  \/\/ 6243940 We might end up in handle_wrong_method if\n-  \/\/ the callee is deoptimized as we race thru here. If that\n-  \/\/ happens we don't want to take a safepoint because the\n-  \/\/ caller frame will look interpreted and arguments are now\n-  \/\/ \"compiled\" so it is much better to make this transition\n-  \/\/ invisible to the stack walking code. Unfortunately if\n-  \/\/ we try and find the callee by normal means a safepoint\n-  \/\/ is possible. So we stash the desired callee in the thread\n-  \/\/ and the vm will find there should this case occur.\n-\n-  __ get_thread(rax);\n-  __ movptr(Address(rax, JavaThread::callee_target_offset()), rbx);\n-\n-  \/\/ move Method* to rax, in case we end up in an c2i adapter.\n-  \/\/ the c2i adapters expect Method* in rax, (c2) because c2's\n-  \/\/ resolve stubs return the result (the method) in rax,.\n-  \/\/ I'd love to fix this.\n-  __ mov(rax, rbx);\n-\n-  __ jmp(rdi);\n-}\n-\n-\/\/ ---------------------------------------------------------------\n-AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,\n-                                                            int total_args_passed,\n-                                                            int comp_args_on_stack,\n-                                                            const BasicType *sig_bt,\n-                                                            const VMRegPair *regs,\n-                                                            AdapterFingerPrint* fingerprint) {\n-  address i2c_entry = __ pc();\n-\n-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);\n-\n-  \/\/ -------------------------------------------------------------------------\n-  \/\/ Generate a C2I adapter.  On entry we know rbx, holds the Method* during calls\n-  \/\/ to the interpreter.  The args start out packed in the compiled layout.  They\n-  \/\/ need to be unpacked into the interpreter layout.  This will almost always\n-  \/\/ require some stack space.  We grow the current (compiled) stack, then repack\n-  \/\/ the args.  We  finally end in a jump to the generic interpreter entry point.\n-  \/\/ On exit from the interpreter, the interpreter will restore our SP (lest the\n-  \/\/ compiled code, which relies solely on SP and not EBP, get sick).\n-\n-  address c2i_unverified_entry = __ pc();\n-  Label skip_fixup;\n-\n-  Register data = rax;\n-  Register receiver = rcx;\n-  Register temp = rbx;\n-\n-  {\n-    __ ic_check(1 \/* end_alignment *\/);\n-    __ movptr(rbx, Address(data, CompiledICData::speculated_method_offset()));\n-    \/\/ Method might have been compiled since the call site was patched to\n-    \/\/ interpreted if that is the case treat it as a miss so we can get\n-    \/\/ the call site corrected.\n-    __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), NULL_WORD);\n-    __ jcc(Assembler::equal, skip_fixup);\n-  }\n-\n-  address c2i_entry = __ pc();\n-\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->c2i_entry_barrier(masm);\n-\n-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);\n-\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry);\n-}\n-\n-int SharedRuntime::c_calling_convention(const BasicType *sig_bt,\n-                                         VMRegPair *regs,\n-                                         int total_args_passed) {\n-\n-\/\/ We return the amount of VMRegImpl stack slots we need to reserve for all\n-\/\/ the arguments NOT counting out_preserve_stack_slots.\n-\n-  uint    stack = 0;        \/\/ All arguments on stack\n-\n-  for( int i = 0; i < total_args_passed; i++) {\n-    \/\/ From the type and the argument number (count) compute the location\n-    switch( sig_bt[i] ) {\n-    case T_BOOLEAN:\n-    case T_CHAR:\n-    case T_FLOAT:\n-    case T_BYTE:\n-    case T_SHORT:\n-    case T_INT:\n-    case T_OBJECT:\n-    case T_ARRAY:\n-    case T_ADDRESS:\n-    case T_METADATA:\n-      regs[i].set1(VMRegImpl::stack2reg(stack++));\n-      break;\n-    case T_LONG:\n-    case T_DOUBLE: \/\/ The stack numbering is reversed from Java\n-      \/\/ Since C arguments do not get reversed, the ordering for\n-      \/\/ doubles on the stack must be opposite the Java convention\n-      assert((i + 1) < total_args_passed && sig_bt[i+1] == T_VOID, \"missing Half\" );\n-      regs[i].set2(VMRegImpl::stack2reg(stack));\n-      stack += 2;\n-      break;\n-    case T_VOID: regs[i].set_bad(); break;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-    }\n-  }\n-  return stack;\n-}\n-\n-int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n-                                             uint num_bits,\n-                                             uint total_args_passed) {\n-  Unimplemented();\n-  return 0;\n-}\n-\n-\/\/ A simple move of integer like type\n-static void simple_move32(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  if (src.first()->is_stack()) {\n-    if (dst.first()->is_stack()) {\n-      \/\/ stack to stack\n-      \/\/ __ ld(FP, reg2offset(src.first()), L5);\n-      \/\/ __ st(L5, SP, reg2offset(dst.first()));\n-      __ movl2ptr(rax, Address(rbp, reg2offset_in(src.first())));\n-      __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);\n-    } else {\n-      \/\/ stack to reg\n-      __ movl2ptr(dst.first()->as_Register(),  Address(rbp, reg2offset_in(src.first())));\n-    }\n-  } else if (dst.first()->is_stack()) {\n-    \/\/ reg to stack\n-    \/\/ no need to sign extend on 64bit\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), src.first()->as_Register());\n-  } else {\n-    if (dst.first() != src.first()) {\n-      __ mov(dst.first()->as_Register(), src.first()->as_Register());\n-    }\n-  }\n-}\n-\n-\/\/ An oop arg. Must pass a handle not the oop itself\n-static void object_move(MacroAssembler* masm,\n-                        OopMap* map,\n-                        int oop_handle_offset,\n-                        int framesize_in_slots,\n-                        VMRegPair src,\n-                        VMRegPair dst,\n-                        bool is_receiver,\n-                        int* receiver_offset) {\n-\n-  \/\/ Because of the calling conventions we know that src can be a\n-  \/\/ register or a stack location. dst can only be a stack location.\n-\n-  assert(dst.first()->is_stack(), \"must be stack\");\n-  \/\/ must pass a handle. First figure out the location we use as a handle\n-\n-  if (src.first()->is_stack()) {\n-    \/\/ Oop is already on the stack as an argument\n-    Register rHandle = rax;\n-    Label nil;\n-    __ xorptr(rHandle, rHandle);\n-    __ cmpptr(Address(rbp, reg2offset_in(src.first())), NULL_WORD);\n-    __ jcc(Assembler::equal, nil);\n-    __ lea(rHandle, Address(rbp, reg2offset_in(src.first())));\n-    __ bind(nil);\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rHandle);\n-\n-    int offset_in_older_frame = src.first()->reg2stack() + SharedRuntime::out_preserve_stack_slots();\n-    map->set_oop(VMRegImpl::stack2reg(offset_in_older_frame + framesize_in_slots));\n-    if (is_receiver) {\n-      *receiver_offset = (offset_in_older_frame + framesize_in_slots) * VMRegImpl::stack_slot_size;\n-    }\n-  } else {\n-    \/\/ Oop is in a register we must store it to the space we reserve\n-    \/\/ on the stack for oop_handles\n-    const Register rOop = src.first()->as_Register();\n-    const Register rHandle = rax;\n-    int oop_slot = (rOop == rcx ? 0 : 1) * VMRegImpl::slots_per_word + oop_handle_offset;\n-    int offset = oop_slot*VMRegImpl::stack_slot_size;\n-    Label skip;\n-    __ movptr(Address(rsp, offset), rOop);\n-    map->set_oop(VMRegImpl::stack2reg(oop_slot));\n-    __ xorptr(rHandle, rHandle);\n-    __ cmpptr(rOop, NULL_WORD);\n-    __ jcc(Assembler::equal, skip);\n-    __ lea(rHandle, Address(rsp, offset));\n-    __ bind(skip);\n-    \/\/ Store the handle parameter\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rHandle);\n-    if (is_receiver) {\n-      *receiver_offset = offset;\n-    }\n-  }\n-}\n-\n-\/\/ A float arg may have to do float reg int reg conversion\n-static void float_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-  assert(!src.second()->is_valid() && !dst.second()->is_valid(), \"bad float_move\");\n-\n-  \/\/ Because of the calling convention we know that src is either a stack location\n-  \/\/ or an xmm register. dst can only be a stack location.\n-\n-  assert(dst.first()->is_stack() && ( src.first()->is_stack() || src.first()->is_XMMRegister()), \"bad parameters\");\n-\n-  if (src.first()->is_stack()) {\n-    __ movl(rax, Address(rbp, reg2offset_in(src.first())));\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);\n-  } else {\n-    \/\/ reg to stack\n-    __ movflt(Address(rsp, reg2offset_out(dst.first())), src.first()->as_XMMRegister());\n-  }\n-}\n-\n-\/\/ A long move\n-static void long_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-\n-  \/\/ The only legal possibility for a long_move VMRegPair is:\n-  \/\/ 1: two stack slots (possibly unaligned)\n-  \/\/ as neither the java  or C calling convention will use registers\n-  \/\/ for longs.\n-\n-  if (src.first()->is_stack() && dst.first()->is_stack()) {\n-    assert(src.second()->is_stack() && dst.second()->is_stack(), \"must be all stack\");\n-    __ movptr(rax, Address(rbp, reg2offset_in(src.first())));\n-    __ movptr(rbx, Address(rbp, reg2offset_in(src.second())));\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);\n-    __ movptr(Address(rsp, reg2offset_out(dst.second())), rbx);\n-  } else {\n-    ShouldNotReachHere();\n-  }\n-}\n-\n-\/\/ A double move\n-static void double_move(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {\n-\n-  \/\/ The only legal possibilities for a double_move VMRegPair are:\n-  \/\/ The painful thing here is that like long_move a VMRegPair might be\n-\n-  \/\/ Because of the calling convention we know that src is either\n-  \/\/   1: a single physical register (xmm registers only)\n-  \/\/   2: two stack slots (possibly unaligned)\n-  \/\/ dst can only be a pair of stack slots.\n-\n-  assert(dst.first()->is_stack() && (src.first()->is_XMMRegister() || src.first()->is_stack()), \"bad args\");\n-\n-  if (src.first()->is_stack()) {\n-    \/\/ source is all stack\n-    __ movptr(rax, Address(rbp, reg2offset_in(src.first())));\n-    __ movptr(rbx, Address(rbp, reg2offset_in(src.second())));\n-    __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);\n-    __ movptr(Address(rsp, reg2offset_out(dst.second())), rbx);\n-  } else {\n-    \/\/ reg to stack\n-    \/\/ No worries about stack alignment\n-    __ movdbl(Address(rsp, reg2offset_out(dst.first())), src.first()->as_XMMRegister());\n-  }\n-}\n-\n-\n-void SharedRuntime::save_native_result(MacroAssembler *masm, BasicType ret_type, int frame_slots) {\n-  \/\/ We always ignore the frame_slots arg and just use the space just below frame pointer\n-  \/\/ which by this time is free to use\n-  switch (ret_type) {\n-  case T_FLOAT:\n-    __ fstp_s(Address(rbp, -wordSize));\n-    break;\n-  case T_DOUBLE:\n-    __ fstp_d(Address(rbp, -2*wordSize));\n-    break;\n-  case T_VOID:  break;\n-  case T_LONG:\n-    __ movptr(Address(rbp, -wordSize), rax);\n-    __ movptr(Address(rbp, -2*wordSize), rdx);\n-    break;\n-  default: {\n-    __ movptr(Address(rbp, -wordSize), rax);\n-    }\n-  }\n-}\n-\n-void SharedRuntime::restore_native_result(MacroAssembler *masm, BasicType ret_type, int frame_slots) {\n-  \/\/ We always ignore the frame_slots arg and just use the space just below frame pointer\n-  \/\/ which by this time is free to use\n-  switch (ret_type) {\n-  case T_FLOAT:\n-    __ fld_s(Address(rbp, -wordSize));\n-    break;\n-  case T_DOUBLE:\n-    __ fld_d(Address(rbp, -2*wordSize));\n-    break;\n-  case T_LONG:\n-    __ movptr(rax, Address(rbp, -wordSize));\n-    __ movptr(rdx, Address(rbp, -2*wordSize));\n-    break;\n-  case T_VOID:  break;\n-  default: {\n-    __ movptr(rax, Address(rbp, -wordSize));\n-    }\n-  }\n-}\n-\n-static void verify_oop_args(MacroAssembler* masm,\n-                            const methodHandle& method,\n-                            const BasicType* sig_bt,\n-                            const VMRegPair* regs) {\n-  Register temp_reg = rbx;  \/\/ not part of any compiled calling seq\n-  if (VerifyOops) {\n-    for (int i = 0; i < method->size_of_parameters(); i++) {\n-      if (is_reference_type(sig_bt[i])) {\n-        VMReg r = regs[i].first();\n-        assert(r->is_valid(), \"bad oop arg\");\n-        if (r->is_stack()) {\n-          __ movptr(temp_reg, Address(rsp, r->reg2stack() * VMRegImpl::stack_slot_size + wordSize));\n-          __ verify_oop(temp_reg);\n-        } else {\n-          __ verify_oop(r->as_Register());\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-static void gen_special_dispatch(MacroAssembler* masm,\n-                                 const methodHandle& method,\n-                                 const BasicType* sig_bt,\n-                                 const VMRegPair* regs) {\n-  verify_oop_args(masm, method, sig_bt, regs);\n-  vmIntrinsics::ID iid = method->intrinsic_id();\n-\n-  \/\/ Now write the args into the outgoing interpreter space\n-  bool     has_receiver   = false;\n-  Register receiver_reg   = noreg;\n-  int      member_arg_pos = -1;\n-  Register member_reg     = noreg;\n-  int      ref_kind       = MethodHandles::signature_polymorphic_intrinsic_ref_kind(iid);\n-  if (ref_kind != 0) {\n-    member_arg_pos = method->size_of_parameters() - 1;  \/\/ trailing MemberName argument\n-    member_reg = rbx;  \/\/ known to be free at this point\n-    has_receiver = MethodHandles::ref_kind_has_receiver(ref_kind);\n-  } else if (iid == vmIntrinsics::_invokeBasic) {\n-    has_receiver = true;\n-  } else {\n-    fatal(\"unexpected intrinsic id %d\", vmIntrinsics::as_int(iid));\n-  }\n-\n-  if (member_reg != noreg) {\n-    \/\/ Load the member_arg into register, if necessary.\n-    SharedRuntime::check_member_name_argument_is_last_argument(method, sig_bt, regs);\n-    VMReg r = regs[member_arg_pos].first();\n-    if (r->is_stack()) {\n-      __ movptr(member_reg, Address(rsp, r->reg2stack() * VMRegImpl::stack_slot_size + wordSize));\n-    } else {\n-      \/\/ no data motion is needed\n-      member_reg = r->as_Register();\n-    }\n-  }\n-\n-  if (has_receiver) {\n-    \/\/ Make sure the receiver is loaded into a register.\n-    assert(method->size_of_parameters() > 0, \"oob\");\n-    assert(sig_bt[0] == T_OBJECT, \"receiver argument must be an object\");\n-    VMReg r = regs[0].first();\n-    assert(r->is_valid(), \"bad receiver arg\");\n-    if (r->is_stack()) {\n-      \/\/ Porting note:  This assumes that compiled calling conventions always\n-      \/\/ pass the receiver oop in a register.  If this is not true on some\n-      \/\/ platform, pick a temp and load the receiver from stack.\n-      fatal(\"receiver always in a register\");\n-      receiver_reg = rcx;  \/\/ known to be free at this point\n-      __ movptr(receiver_reg, Address(rsp, r->reg2stack() * VMRegImpl::stack_slot_size + wordSize));\n-    } else {\n-      \/\/ no data motion is needed\n-      receiver_reg = r->as_Register();\n-    }\n-  }\n-\n-  \/\/ Figure out which address we are really jumping to:\n-  MethodHandles::generate_method_handle_dispatch(masm, iid,\n-                                                 receiver_reg, member_reg, \/*for_compiler_entry:*\/ true);\n-}\n-\n-\/\/ ---------------------------------------------------------------------------\n-\/\/ Generate a native wrapper for a given method.  The method takes arguments\n-\/\/ in the Java compiled code convention, marshals them to the native\n-\/\/ convention (handlizes oops, etc), transitions to native, makes the call,\n-\/\/ returns to java state (possibly blocking), unhandlizes any result and\n-\/\/ returns.\n-\/\/\n-\/\/ Critical native functions are a shorthand for the use of\n-\/\/ GetPrimtiveArrayCritical and disallow the use of any other JNI\n-\/\/ functions.  The wrapper is expected to unpack the arguments before\n-\/\/ passing them to the callee. Critical native functions leave the state _in_Java,\n-\/\/ since they cannot stop for GC.\n-\/\/ Some other parts of JNI setup are skipped like the tear down of the JNI handle\n-\/\/ block and the check for pending exceptions it's impossible for them\n-\/\/ to be thrown.\n-\/\/\n-\/\/\n-nmethod* SharedRuntime::generate_native_wrapper(MacroAssembler* masm,\n-                                                const methodHandle& method,\n-                                                int compile_id,\n-                                                BasicType* in_sig_bt,\n-                                                VMRegPair* in_regs,\n-                                                BasicType ret_type) {\n-  if (method->is_method_handle_intrinsic()) {\n-    vmIntrinsics::ID iid = method->intrinsic_id();\n-    intptr_t start = (intptr_t)__ pc();\n-    int vep_offset = ((intptr_t)__ pc()) - start;\n-    gen_special_dispatch(masm,\n-                         method,\n-                         in_sig_bt,\n-                         in_regs);\n-    int frame_complete = ((intptr_t)__ pc()) - start;  \/\/ not complete, period\n-    __ flush();\n-    int stack_slots = SharedRuntime::out_preserve_stack_slots();  \/\/ no out slots at all, actually\n-    return nmethod::new_native_nmethod(method,\n-                                       compile_id,\n-                                       masm->code(),\n-                                       vep_offset,\n-                                       frame_complete,\n-                                       stack_slots \/ VMRegImpl::slots_per_word,\n-                                       in_ByteSize(-1),\n-                                       in_ByteSize(-1),\n-                                       (OopMapSet*)nullptr);\n-  }\n-  address native_func = method->native_function();\n-  assert(native_func != nullptr, \"must have function\");\n-\n-  \/\/ An OopMap for lock (and class if static)\n-  OopMapSet *oop_maps = new OopMapSet();\n-\n-  \/\/ We have received a description of where all the java arg are located\n-  \/\/ on entry to the wrapper. We need to convert these args to where\n-  \/\/ the jni function will expect them. To figure out where they go\n-  \/\/ we convert the java signature to a C signature by inserting\n-  \/\/ the hidden arguments as arg[0] and possibly arg[1] (static method)\n-\n-  const int total_in_args = method->size_of_parameters();\n-  int  total_c_args       = total_in_args + (method->is_static() ? 2 : 1);\n-\n-  BasicType* out_sig_bt = NEW_RESOURCE_ARRAY(BasicType, total_c_args);\n-  VMRegPair* out_regs   = NEW_RESOURCE_ARRAY(VMRegPair, total_c_args);\n-\n-  int argc = 0;\n-  out_sig_bt[argc++] = T_ADDRESS;\n-  if (method->is_static()) {\n-    out_sig_bt[argc++] = T_OBJECT;\n-  }\n-\n-  for (int i = 0; i < total_in_args ; i++ ) {\n-    out_sig_bt[argc++] = in_sig_bt[i];\n-  }\n-\n-  \/\/ Now figure out where the args must be stored and how much stack space\n-  \/\/ they require.\n-  int out_arg_slots;\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, total_c_args);\n-\n-  \/\/ Compute framesize for the wrapper.  We need to handlize all oops in\n-  \/\/ registers a max of 2 on x86.\n-\n-  \/\/ Calculate the total number of stack slots we will need.\n-\n-  \/\/ First count the abi requirement plus all of the outgoing args\n-  int stack_slots = SharedRuntime::out_preserve_stack_slots() + out_arg_slots;\n-\n-  \/\/ Now the space for the inbound oop handle area\n-  int total_save_slots = 2 * VMRegImpl::slots_per_word; \/\/ 2 arguments passed in registers\n-\n-  int oop_handle_offset = stack_slots;\n-  stack_slots += total_save_slots;\n-\n-  \/\/ Now any space we need for handlizing a klass if static method\n-\n-  int klass_slot_offset = 0;\n-  int klass_offset = -1;\n-  int lock_slot_offset = 0;\n-  bool is_static = false;\n-\n-  if (method->is_static()) {\n-    klass_slot_offset = stack_slots;\n-    stack_slots += VMRegImpl::slots_per_word;\n-    klass_offset = klass_slot_offset * VMRegImpl::stack_slot_size;\n-    is_static = true;\n-  }\n-\n-  \/\/ Plus a lock if needed\n-\n-  if (method->is_synchronized()) {\n-    lock_slot_offset = stack_slots;\n-    stack_slots += VMRegImpl::slots_per_word;\n-  }\n-\n-  \/\/ Now a place (+2) to save return values or temp during shuffling\n-  \/\/ + 2 for return address (which we own) and saved rbp,\n-  stack_slots += 4;\n-\n-  \/\/ Ok The space we have allocated will look like:\n-  \/\/\n-  \/\/\n-  \/\/ FP-> |                     |\n-  \/\/      |---------------------|\n-  \/\/      | 2 slots for moves   |\n-  \/\/      |---------------------|\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset  (-lock_slot_rbp_offset)\n-  \/\/      | klass (if static)   |\n-  \/\/      |---------------------| <- klass_slot_offset\n-  \/\/      | oopHandle area      |\n-  \/\/      |---------------------| <- oop_handle_offset (a max of 2 registers)\n-  \/\/      | outbound memory     |\n-  \/\/      | based arguments     |\n-  \/\/      |                     |\n-  \/\/      |---------------------|\n-  \/\/      |                     |\n-  \/\/ SP-> | out_preserved_slots |\n-  \/\/\n-  \/\/\n-  \/\/ ****************************************************************************\n-  \/\/ WARNING - on Windows Java Natives use pascal calling convention and pop the\n-  \/\/ arguments off of the stack after the jni call. Before the call we can use\n-  \/\/ instructions that are SP relative. After the jni call we switch to FP\n-  \/\/ relative instructions instead of re-adjusting the stack on windows.\n-  \/\/ ****************************************************************************\n-\n-\n-  \/\/ Now compute actual number of stack words we need rounding to make\n-  \/\/ stack properly aligned.\n-  stack_slots = align_up(stack_slots, StackAlignmentInSlots);\n-\n-  int stack_size = stack_slots * VMRegImpl::stack_slot_size;\n-\n-  intptr_t start = (intptr_t)__ pc();\n-\n-  \/\/ First thing make an ic check to see if we should even be here\n-\n-  \/\/ We are free to use all registers as temps without saving them and\n-  \/\/ restoring them except rbp. rbp is the only callee save register\n-  \/\/ as far as the interpreter and the compiler(s) are concerned.\n-\n-\n-  const Register receiver = rcx;\n-  Label exception_pending;\n-\n-  __ verify_oop(receiver);\n-  \/\/ verified entry must be aligned for code patching.\n-  __ ic_check(8 \/* end_alignment *\/);\n-\n-  int vep_offset = ((intptr_t)__ pc()) - start;\n-\n-#ifdef COMPILER1\n-  \/\/ For Object.hashCode, System.identityHashCode try to pull hashCode from object header if available.\n-  if ((InlineObjectHash && method->intrinsic_id() == vmIntrinsics::_hashCode) || (method->intrinsic_id() == vmIntrinsics::_identityHashCode)) {\n-    inline_check_hashcode_from_object_header(masm, method, rcx \/*obj_reg*\/, rax \/*result*\/);\n-   }\n-#endif \/\/ COMPILER1\n-\n-  \/\/ The instruction at the verified entry point must be 5 bytes or longer\n-  \/\/ because it can be patched on the fly by make_non_entrant. The stack bang\n-  \/\/ instruction fits that requirement.\n-\n-  \/\/ Generate stack overflow check\n-  __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n-\n-  \/\/ Generate a new frame for the wrapper.\n-  __ enter();\n-  \/\/ -2 because return address is already present and so is saved rbp\n-  __ subptr(rsp, stack_size - 2*wordSize);\n-\n-\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->nmethod_entry_barrier(masm, nullptr \/* slow_path *\/, nullptr \/* continuation *\/);\n-\n-  \/\/ Frame is now completed as far as size and linkage.\n-  int frame_complete = ((intptr_t)__ pc()) - start;\n-\n-  \/\/ Calculate the difference between rsp and rbp,. We need to know it\n-  \/\/ after the native call because on windows Java Natives will pop\n-  \/\/ the arguments and it is painful to do rsp relative addressing\n-  \/\/ in a platform independent way. So after the call we switch to\n-  \/\/ rbp, relative addressing.\n-\n-  int fp_adjustment = stack_size - 2*wordSize;\n-\n-#ifdef COMPILER2\n-  \/\/ C2 may leave the stack dirty if not in SSE2+ mode\n-  if (UseSSE >= 2) {\n-    __ verify_FPU(0, \"c2i transition should have clean FPU stack\");\n-  } else {\n-    __ empty_FPU_stack();\n-  }\n-#endif \/* COMPILER2 *\/\n-\n-  \/\/ Compute the rbp, offset for any slots used after the jni call\n-\n-  int lock_slot_rbp_offset = (lock_slot_offset*VMRegImpl::stack_slot_size) - fp_adjustment;\n-\n-  \/\/ We use rdi as a thread pointer because it is callee save and\n-  \/\/ if we load it once it is usable thru the entire wrapper\n-  const Register thread = rdi;\n-\n-   \/\/ We use rsi as the oop handle for the receiver\/klass\n-   \/\/ It is callee save so it survives the call to native\n-\n-   const Register oop_handle_reg = rsi;\n-\n-   __ get_thread(thread);\n-\n-  \/\/\n-  \/\/ We immediately shuffle the arguments so that any vm call we have to\n-  \/\/ make from here on out (sync slow path, jvmti, etc.) we will have\n-  \/\/ captured the oops from our caller and have a valid oopMap for\n-  \/\/ them.\n-\n-  \/\/ -----------------\n-  \/\/ The Grand Shuffle\n-  \/\/\n-  \/\/ Natives require 1 or 2 extra arguments over the normal ones: the JNIEnv*\n-  \/\/ and, if static, the class mirror instead of a receiver.  This pretty much\n-  \/\/ guarantees that register layout will not match (and x86 doesn't use reg\n-  \/\/ parms though amd does).  Since the native abi doesn't use register args\n-  \/\/ and the java conventions does we don't have to worry about collisions.\n-  \/\/ All of our moved are reg->stack or stack->stack.\n-  \/\/ We ignore the extra arguments during the shuffle and handle them at the\n-  \/\/ last moment. The shuffle is described by the two calling convention\n-  \/\/ vectors we have in our possession. We simply walk the java vector to\n-  \/\/ get the source locations and the c vector to get the destinations.\n-\n-  int c_arg = method->is_static() ? 2 : 1;\n-\n-  \/\/ Record rsp-based slot for receiver on stack for non-static methods\n-  int receiver_offset = -1;\n-\n-  \/\/ This is a trick. We double the stack slots so we can claim\n-  \/\/ the oops in the caller's frame. Since we are sure to have\n-  \/\/ more args than the caller doubling is enough to make\n-  \/\/ sure we can capture all the incoming oop args from the\n-  \/\/ caller.\n-  \/\/\n-  OopMap* map = new OopMap(stack_slots * 2, 0 \/* arg_slots*\/);\n-\n-  \/\/ Mark location of rbp,\n-  \/\/ map->set_callee_saved(VMRegImpl::stack2reg( stack_slots - 2), stack_slots * 2, 0, rbp->as_VMReg());\n-\n-  \/\/ We know that we only have args in at most two integer registers (rcx, rdx). So rax, rbx\n-  \/\/ Are free to temporaries if we have to do  stack to steck moves.\n-  \/\/ All inbound args are referenced based on rbp, and all outbound args via rsp.\n-\n-  for (int i = 0; i < total_in_args ; i++, c_arg++ ) {\n-    switch (in_sig_bt[i]) {\n-      case T_ARRAY:\n-      case T_OBJECT:\n-        object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],\n-                    ((i == 0) && (!is_static)),\n-                    &receiver_offset);\n-        break;\n-      case T_VOID:\n-        break;\n-\n-      case T_FLOAT:\n-        float_move(masm, in_regs[i], out_regs[c_arg]);\n-          break;\n-\n-      case T_DOUBLE:\n-        assert( i + 1 < total_in_args &&\n-                in_sig_bt[i + 1] == T_VOID &&\n-                out_sig_bt[c_arg+1] == T_VOID, \"bad arg list\");\n-        double_move(masm, in_regs[i], out_regs[c_arg]);\n-        break;\n-\n-      case T_LONG :\n-        long_move(masm, in_regs[i], out_regs[c_arg]);\n-        break;\n-\n-      case T_ADDRESS: assert(false, \"found T_ADDRESS in java args\");\n-\n-      default:\n-        simple_move32(masm, in_regs[i], out_regs[c_arg]);\n-    }\n-  }\n-\n-  \/\/ Pre-load a static method's oop into rsi.  Used both by locking code and\n-  \/\/ the normal JNI call code.\n-  if (method->is_static()) {\n-\n-    \/\/  load opp into a register\n-    __ movoop(oop_handle_reg, JNIHandles::make_local(method->method_holder()->java_mirror()));\n-\n-    \/\/ Now handlize the static class mirror it's known not-null.\n-    __ movptr(Address(rsp, klass_offset), oop_handle_reg);\n-    map->set_oop(VMRegImpl::stack2reg(klass_slot_offset));\n-\n-    \/\/ Now get the handle\n-    __ lea(oop_handle_reg, Address(rsp, klass_offset));\n-    \/\/ store the klass handle as second argument\n-    __ movptr(Address(rsp, wordSize), oop_handle_reg);\n-  }\n-\n-  \/\/ Change state to native (we save the return address in the thread, since it might not\n-  \/\/ be pushed on the stack when we do a stack traversal). It is enough that the pc()\n-  \/\/ points into the right code segment. It does not have to be the correct return pc.\n-  \/\/ We use the same pc\/oopMap repeatedly when we call out\n-\n-  intptr_t the_pc = (intptr_t) __ pc();\n-  oop_maps->add_gc_map(the_pc - start, map);\n-\n-  __ set_last_Java_frame(thread, rsp, noreg, (address)the_pc, noreg);\n-\n-\n-  \/\/ We have all of the arguments setup at this point. We must not touch any register\n-  \/\/ argument registers at this point (what if we save\/restore them there are no oop?\n-\n-  if (DTraceMethodProbes) {\n-    __ mov_metadata(rax, method());\n-    __ call_VM_leaf(\n-         CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_entry),\n-         thread, rax);\n-  }\n-\n-  \/\/ RedefineClasses() tracing support for obsolete method entry\n-  if (log_is_enabled(Trace, redefine, class, obsolete)) {\n-    __ mov_metadata(rax, method());\n-    __ call_VM_leaf(\n-         CAST_FROM_FN_PTR(address, SharedRuntime::rc_trace_method_entry),\n-         thread, rax);\n-  }\n-\n-  \/\/ These are register definitions we need for locking\/unlocking\n-  const Register swap_reg = rax;  \/\/ Must use rax, for cmpxchg instruction\n-  const Register obj_reg  = rcx;  \/\/ Will contain the oop\n-  const Register lock_reg = rdx;  \/\/ Address of compiler lock object (BasicLock)\n-\n-  Label slow_path_lock;\n-  Label lock_done;\n-\n-  \/\/ Lock a synchronized method\n-  if (method->is_synchronized()) {\n-    Label count_mon;\n-\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n-    \/\/ Get the handle (the 2nd argument)\n-    __ movptr(oop_handle_reg, Address(rsp, wordSize));\n-\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(rbp, lock_slot_rbp_offset));\n-\n-    \/\/ Load the oop from the handle\n-    __ movptr(obj_reg, Address(oop_handle_reg, 0));\n-\n-    if (LockingMode == LM_MONITOR) {\n-      __ jmp(slow_path_lock);\n-    } else if (LockingMode == LM_LEGACY) {\n-      \/\/ Load immediate 1 into swap_reg %rax,\n-      __ movptr(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, count_mon);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n-      \/\/ Lacking registers and thread on x86_32. Always take slow path.\n-      __ jmp(slow_path_lock);\n-    }\n-    __ bind(count_mon);\n-    __ inc_held_monitor_count();\n-\n-    \/\/ Slow path will re-enter here\n-    __ bind(lock_done);\n-  }\n-\n-\n-  \/\/ Finally just about ready to make the JNI call\n-\n-  \/\/ get JNIEnv* which is first argument to native\n-  __ lea(rdx, Address(thread, in_bytes(JavaThread::jni_environment_offset())));\n-  __ movptr(Address(rsp, 0), rdx);\n-\n-  \/\/ Now set thread in native\n-  __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n-\n-  __ call(RuntimeAddress(native_func));\n-\n-  \/\/ Verify or restore cpu control state after JNI call\n-  __ restore_cpu_control_state_after_jni(noreg);\n-\n-  \/\/ WARNING - on Windows Java Natives use pascal calling convention and pop the\n-  \/\/ arguments off of the stack. We could just re-adjust the stack pointer here\n-  \/\/ and continue to do SP relative addressing but we instead switch to FP\n-  \/\/ relative addressing.\n-\n-  \/\/ Unpack native results.\n-  switch (ret_type) {\n-  case T_BOOLEAN: __ c2bool(rax);            break;\n-  case T_CHAR   : __ andptr(rax, 0xFFFF);    break;\n-  case T_BYTE   : __ sign_extend_byte (rax); break;\n-  case T_SHORT  : __ sign_extend_short(rax); break;\n-  case T_INT    : \/* nothing to do *\/        break;\n-  case T_DOUBLE :\n-  case T_FLOAT  :\n-    \/\/ Result is in st0 we'll save as needed\n-    break;\n-  case T_ARRAY:                 \/\/ Really a handle\n-  case T_OBJECT:                \/\/ Really a handle\n-      break; \/\/ can't de-handlize until after safepoint check\n-  case T_VOID: break;\n-  case T_LONG: break;\n-  default       : ShouldNotReachHere();\n-  }\n-\n-  \/\/ Switch thread to \"native transition\" state before reading the synchronization state.\n-  \/\/ This additional state is necessary because reading and testing the synchronization\n-  \/\/ state is not atomic w.r.t. GC, as this scenario demonstrates:\n-  \/\/     Java thread A, in _thread_in_native state, loads _not_synchronized and is preempted.\n-  \/\/     VM thread changes sync state to synchronizing and suspends threads for GC.\n-  \/\/     Thread A is resumed to finish this native method, but doesn't block here since it\n-  \/\/     didn't see any synchronization is progress, and escapes.\n-  __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native_trans);\n-\n-  \/\/ Force this write out before the read below\n-  if (!UseSystemMemoryBarrier) {\n-    __ membar(Assembler::Membar_mask_bits(\n-              Assembler::LoadLoad | Assembler::LoadStore |\n-              Assembler::StoreLoad | Assembler::StoreStore));\n-  }\n-\n-  if (AlwaysRestoreFPU) {\n-    \/\/ Make sure the control word is correct.\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-  }\n-\n-  \/\/ check for safepoint operation in progress and\/or pending suspend requests\n-  { Label Continue, slow_path;\n-\n-    __ safepoint_poll(slow_path, thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    __ cmpl(Address(thread, JavaThread::suspend_flags_offset()), 0);\n-    __ jcc(Assembler::equal, Continue);\n-    __ bind(slow_path);\n-\n-    \/\/ Don't use call_VM as it will see a possible pending exception and forward it\n-    \/\/ and never return here preventing us from clearing _last_native_pc down below.\n-    \/\/ Also can't use call_VM_leaf either as it will check to see if rsi & rdi are\n-    \/\/ preserved and correspond to the bcp\/locals pointers. So we do a runtime call\n-    \/\/ by hand.\n-    \/\/\n-    __ vzeroupper();\n-\n-    save_native_result(masm, ret_type, stack_slots);\n-    __ push(thread);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address,\n-                                              JavaThread::check_special_condition_for_native_trans)));\n-    __ increment(rsp, wordSize);\n-    \/\/ Restore any method result value\n-    restore_native_result(masm, ret_type, stack_slots);\n-    __ bind(Continue);\n-  }\n-\n-  \/\/ change thread state\n-  __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_Java);\n-\n-  Label reguard;\n-  Label reguard_done;\n-  __ cmpl(Address(thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n-  __ jcc(Assembler::equal, reguard);\n-\n-  \/\/ slow path reguard  re-enters here\n-  __ bind(reguard_done);\n-\n-  \/\/ Handle possible exception (will unlock if necessary)\n-\n-  \/\/ native result if any is live\n-\n-  \/\/ Unlock\n-  Label slow_path_unlock;\n-  Label unlock_done;\n-  if (method->is_synchronized()) {\n-\n-    Label fast_done;\n-\n-    \/\/ Get locked oop from the handle we passed to jni\n-    __ movptr(obj_reg, Address(oop_handle_reg, 0));\n-\n-    if (LockingMode == LM_LEGACY) {\n-      Label not_recur;\n-      \/\/ Simple recursive lock?\n-      __ cmpptr(Address(rbp, lock_slot_rbp_offset), NULL_WORD);\n-      __ jcc(Assembler::notEqual, not_recur);\n-      __ dec_held_monitor_count();\n-      __ jmpb(fast_done);\n-      __ bind(not_recur);\n-    }\n-\n-    \/\/ Must save rax, if it is live now because cmpxchg must use it\n-    if (ret_type != T_FLOAT && ret_type != T_DOUBLE && ret_type != T_VOID) {\n-      save_native_result(masm, ret_type, stack_slots);\n-    }\n-\n-    if (LockingMode == LM_MONITOR) {\n-      __ jmp(slow_path_unlock);\n-    } else if (LockingMode == LM_LEGACY) {\n-      \/\/  get old displaced header\n-      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n-      __ dec_held_monitor_count();\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n-      __ lightweight_unlock(obj_reg, swap_reg, thread, lock_reg, slow_path_unlock);\n-      __ dec_held_monitor_count();\n-    }\n-\n-    \/\/ slow path re-enters here\n-    __ bind(unlock_done);\n-    if (ret_type != T_FLOAT && ret_type != T_DOUBLE && ret_type != T_VOID) {\n-      restore_native_result(masm, ret_type, stack_slots);\n-    }\n-\n-    __ bind(fast_done);\n-  }\n-\n-  if (DTraceMethodProbes) {\n-    \/\/ Tell dtrace about this method exit\n-    save_native_result(masm, ret_type, stack_slots);\n-    __ mov_metadata(rax, method());\n-    __ call_VM_leaf(\n-         CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit),\n-         thread, rax);\n-    restore_native_result(masm, ret_type, stack_slots);\n-  }\n-\n-  \/\/ We can finally stop using that last_Java_frame we setup ages ago\n-\n-  __ reset_last_Java_frame(thread, false);\n-\n-  \/\/ Unbox oop result, e.g. JNIHandles::resolve value.\n-  if (is_reference_type(ret_type)) {\n-    __ resolve_jobject(rax \/* value *\/,\n-                       thread \/* thread *\/,\n-                       rcx \/* tmp *\/);\n-  }\n-\n-  if (CheckJNICalls) {\n-    \/\/ clear_pending_jni_exception_check\n-    __ movptr(Address(thread, JavaThread::pending_jni_exception_check_fn_offset()), NULL_WORD);\n-  }\n-\n-  \/\/ reset handle block\n-  __ movptr(rcx, Address(thread, JavaThread::active_handles_offset()));\n-  __ movl(Address(rcx, JNIHandleBlock::top_offset()), NULL_WORD);\n-\n-  \/\/ Any exception pending?\n-  __ cmpptr(Address(thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n-  __ jcc(Assembler::notEqual, exception_pending);\n-\n-  \/\/ no exception, we're almost done\n-\n-  \/\/ check that only result value is on FPU stack\n-  __ verify_FPU(ret_type == T_FLOAT || ret_type == T_DOUBLE ? 1 : 0, \"native_wrapper normal exit\");\n-\n-  \/\/ Fixup floating pointer results so that result looks like a return from a compiled method\n-  if (ret_type == T_FLOAT) {\n-    if (UseSSE >= 1) {\n-      \/\/ Pop st0 and store as float and reload into xmm register\n-      __ fstp_s(Address(rbp, -4));\n-      __ movflt(xmm0, Address(rbp, -4));\n-    }\n-  } else if (ret_type == T_DOUBLE) {\n-    if (UseSSE >= 2) {\n-      \/\/ Pop st0 and store as double and reload into xmm register\n-      __ fstp_d(Address(rbp, -8));\n-      __ movdbl(xmm0, Address(rbp, -8));\n-    }\n-  }\n-\n-  \/\/ Return\n-\n-  __ leave();\n-  __ ret(0);\n-\n-  \/\/ Unexpected paths are out of line and go here\n-\n-  \/\/ Slow path locking & unlocking\n-  if (method->is_synchronized()) {\n-\n-    \/\/ BEGIN Slow path lock\n-\n-    __ bind(slow_path_lock);\n-\n-    \/\/ has last_Java_frame setup. No exceptions so do vanilla call not call_VM\n-    \/\/ args are (oop obj, BasicLock* lock, JavaThread* thread)\n-    __ push(thread);\n-    __ push(lock_reg);\n-    __ push(obj_reg);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_locking_C)));\n-    __ addptr(rsp, 3*wordSize);\n-\n-#ifdef ASSERT\n-    { Label L;\n-    __ cmpptr(Address(thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n-    __ jcc(Assembler::equal, L);\n-    __ stop(\"no pending exception allowed on exit from monitorenter\");\n-    __ bind(L);\n-    }\n-#endif\n-    __ jmp(lock_done);\n-\n-    \/\/ END Slow path lock\n-\n-    \/\/ BEGIN Slow path unlock\n-    __ bind(slow_path_unlock);\n-    __ vzeroupper();\n-    \/\/ Slow path unlock\n-\n-    if (ret_type == T_FLOAT || ret_type == T_DOUBLE ) {\n-      save_native_result(masm, ret_type, stack_slots);\n-    }\n-    \/\/ Save pending exception around call to VM (which contains an EXCEPTION_MARK)\n-\n-    __ pushptr(Address(thread, in_bytes(Thread::pending_exception_offset())));\n-    __ movptr(Address(thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n-\n-\n-    \/\/ should be a peal\n-    \/\/ +wordSize because of the push above\n-    \/\/ args are (oop obj, BasicLock* lock, JavaThread* thread)\n-    __ push(thread);\n-    __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-    __ push(rax);\n-\n-    __ push(obj_reg);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::complete_monitor_unlocking_C)));\n-    __ addptr(rsp, 3*wordSize);\n-#ifdef ASSERT\n-    {\n-      Label L;\n-      __ cmpptr(Address(thread, in_bytes(Thread::pending_exception_offset())), NULL_WORD);\n-      __ jcc(Assembler::equal, L);\n-      __ stop(\"no pending exception allowed on exit complete_monitor_unlocking_C\");\n-      __ bind(L);\n-    }\n-#endif \/* ASSERT *\/\n-\n-    __ popptr(Address(thread, in_bytes(Thread::pending_exception_offset())));\n-\n-    if (ret_type == T_FLOAT || ret_type == T_DOUBLE ) {\n-      restore_native_result(masm, ret_type, stack_slots);\n-    }\n-    __ jmp(unlock_done);\n-    \/\/ END Slow path unlock\n-\n-  }\n-\n-  \/\/ SLOW PATH Reguard the stack if needed\n-\n-  __ bind(reguard);\n-  __ vzeroupper();\n-  save_native_result(masm, ret_type, stack_slots);\n-  {\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages)));\n-  }\n-  restore_native_result(masm, ret_type, stack_slots);\n-  __ jmp(reguard_done);\n-\n-\n-  \/\/ BEGIN EXCEPTION PROCESSING\n-\n-  \/\/ Forward  the exception\n-  __ bind(exception_pending);\n-\n-  \/\/ remove possible return value from FPU register stack\n-  __ empty_FPU_stack();\n-\n-  \/\/ pop our frame\n-  __ leave();\n-  \/\/ and forward the exception\n-  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-  __ flush();\n-\n-  nmethod *nm = nmethod::new_native_nmethod(method,\n-                                            compile_id,\n-                                            masm->code(),\n-                                            vep_offset,\n-                                            frame_complete,\n-                                            stack_slots \/ VMRegImpl::slots_per_word,\n-                                            (is_static ? in_ByteSize(klass_offset) : in_ByteSize(receiver_offset)),\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n-                                            oop_maps);\n-\n-  return nm;\n-\n-}\n-\n-\/\/ this function returns the adjust size (in number of words) to a c2i adapter\n-\/\/ activation for use during deoptimization\n-int Deoptimization::last_frame_adjust(int callee_parameters, int callee_locals ) {\n-  return (callee_locals - callee_parameters) * Interpreter::stackElementWords;\n-}\n-\n-\n-\/\/ Number of stack slots between incoming argument block and the start of\n-\/\/ a new frame.  The PROLOG must add this many slots to the stack.  The\n-\/\/ EPILOG must remove this many slots.  Intel needs one slot for\n-\/\/ return address and one for rbp, (must save rbp)\n-uint SharedRuntime::in_preserve_stack_slots() {\n-  return 2+VerifyStackAtCalls;\n-}\n-\n-uint SharedRuntime::out_preserve_stack_slots() {\n-  return 0;\n-}\n-\n-VMReg SharedRuntime::thread_register() {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n-\/\/------------------------------generate_deopt_blob----------------------------\n-void SharedRuntime::generate_deopt_blob() {\n-  \/\/ allocate space for the code\n-  ResourceMark rm;\n-  \/\/ setup code generation tools\n-  \/\/ note: the buffer code size must account for StackShadowPages=50\n-  const char* name = SharedRuntime::stub_name(SharedStubId::deopt_id);\n-  CodeBuffer   buffer(name, 1536, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-  int frame_size_in_words;\n-  OopMap* map = nullptr;\n-  \/\/ Account for the extra args we place on the stack\n-  \/\/ by the time we call fetch_unroll_info\n-  const int additional_words = 2; \/\/ deopt kind, thread\n-\n-  OopMapSet *oop_maps = new OopMapSet();\n-\n-  \/\/ -------------\n-  \/\/ This code enters when returning to a de-optimized nmethod.  A return\n-  \/\/ address has been pushed on the stack, and return values are in\n-  \/\/ registers.\n-  \/\/ If we are doing a normal deopt then we were called from the patched\n-  \/\/ nmethod from the point we returned to the nmethod. So the return\n-  \/\/ address on the stack is wrong by NativeCall::instruction_size\n-  \/\/ We will adjust the value to it looks like we have the original return\n-  \/\/ address on the stack (like when we eagerly deoptimized).\n-  \/\/ In the case of an exception pending with deoptimized then we enter\n-  \/\/ with a return address on the stack that points after the call we patched\n-  \/\/ into the exception handler. We have the following register state:\n-  \/\/    rax,: exception\n-  \/\/    rbx,: exception handler\n-  \/\/    rdx: throwing pc\n-  \/\/ So in this case we simply jam rdx into the useless return address and\n-  \/\/ the stack looks just like we want.\n-  \/\/\n-  \/\/ At this point we need to de-opt.  We save the argument return\n-  \/\/ registers.  We call the first C routine, fetch_unroll_info().  This\n-  \/\/ routine captures the return values and returns a structure which\n-  \/\/ describes the current frame size and the sizes of all replacement frames.\n-  \/\/ The current frame is compiled code and may contain many inlined\n-  \/\/ functions, each with their own JVM state.  We pop the current frame, then\n-  \/\/ push all the new frames.  Then we call the C routine unpack_frames() to\n-  \/\/ populate these frames.  Finally unpack_frames() returns us the new target\n-  \/\/ address.  Notice that callee-save registers are BLOWN here; they have\n-  \/\/ already been captured in the vframeArray at the time the return PC was\n-  \/\/ patched.\n-  address start = __ pc();\n-  Label cont;\n-\n-  \/\/ Prolog for non exception case!\n-\n-  \/\/ Save everything in sight.\n-\n-  map = RegisterSaver::save_live_registers(masm, additional_words, &frame_size_in_words, false);\n-  \/\/ Normal deoptimization\n-  __ push(Deoptimization::Unpack_deopt);\n-  __ jmp(cont);\n-\n-  int reexecute_offset = __ pc() - start;\n-\n-  \/\/ Reexecute case\n-  \/\/ return address is the pc describes what bci to do re-execute at\n-\n-  \/\/ No need to update map as each call to save_live_registers will produce identical oopmap\n-  (void) RegisterSaver::save_live_registers(masm, additional_words, &frame_size_in_words, false);\n-\n-  __ push(Deoptimization::Unpack_reexecute);\n-  __ jmp(cont);\n-\n-  int exception_offset = __ pc() - start;\n-\n-  \/\/ Prolog for exception case\n-\n-  \/\/ all registers are dead at this entry point, except for rax, and\n-  \/\/ rdx which contain the exception oop and exception pc\n-  \/\/ respectively.  Set them in TLS and fall thru to the\n-  \/\/ unpack_with_exception_in_tls entry point.\n-\n-  __ get_thread(rdi);\n-  __ movptr(Address(rdi, JavaThread::exception_pc_offset()), rdx);\n-  __ movptr(Address(rdi, JavaThread::exception_oop_offset()), rax);\n-\n-  int exception_in_tls_offset = __ pc() - start;\n-\n-  \/\/ new implementation because exception oop is now passed in JavaThread\n-\n-  \/\/ Prolog for exception case\n-  \/\/ All registers must be preserved because they might be used by LinearScan\n-  \/\/ Exceptiop oop and throwing PC are passed in JavaThread\n-  \/\/ tos: stack at point of call to method that threw the exception (i.e. only\n-  \/\/ args are on the stack, no return address)\n-\n-  \/\/ make room on stack for the return address\n-  \/\/ It will be patched later with the throwing pc. The correct value is not\n-  \/\/ available now because loading it from memory would destroy registers.\n-  __ push(0);\n-\n-  \/\/ Save everything in sight.\n-\n-  \/\/ No need to update map as each call to save_live_registers will produce identical oopmap\n-  (void) RegisterSaver::save_live_registers(masm, additional_words, &frame_size_in_words, false);\n-\n-  \/\/ Now it is safe to overwrite any register\n-\n-  \/\/ store the correct deoptimization type\n-  __ push(Deoptimization::Unpack_exception);\n-\n-  \/\/ load throwing pc from JavaThread and patch it as the return address\n-  \/\/ of the current frame. Then clear the field in JavaThread\n-  __ get_thread(rdi);\n-  __ movptr(rdx, Address(rdi, JavaThread::exception_pc_offset()));\n-  __ movptr(Address(rbp, wordSize), rdx);\n-  __ movptr(Address(rdi, JavaThread::exception_pc_offset()), NULL_WORD);\n-\n-#ifdef ASSERT\n-  \/\/ verify that there is really an exception oop in JavaThread\n-  __ movptr(rax, Address(rdi, JavaThread::exception_oop_offset()));\n-  __ verify_oop(rax);\n-\n-  \/\/ verify that there is no pending exception\n-  Label no_pending_exception;\n-  __ movptr(rax, Address(rdi, Thread::pending_exception_offset()));\n-  __ testptr(rax, rax);\n-  __ jcc(Assembler::zero, no_pending_exception);\n-  __ stop(\"must not have pending exception here\");\n-  __ bind(no_pending_exception);\n-#endif\n-\n-  __ bind(cont);\n-\n-  \/\/ Compiled code leaves the floating point stack dirty, empty it.\n-  __ empty_FPU_stack();\n-\n-\n-  \/\/ Call C code.  Need thread and this frame, but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.\n-  __ get_thread(rcx);\n-  __ push(rcx);\n-  \/\/ fetch_unroll_info needs to call last_java_frame()\n-  __ set_last_Java_frame(rcx, noreg, noreg, nullptr, noreg);\n-\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::fetch_unroll_info)));\n-\n-  \/\/ Need to have an oopmap that tells fetch_unroll_info where to\n-  \/\/ find any register it might need.\n-\n-  oop_maps->add_gc_map( __ pc()-start, map);\n-\n-  \/\/ Discard args to fetch_unroll_info\n-  __ pop(rcx);\n-  __ pop(rcx);\n-\n-  __ get_thread(rcx);\n-  __ reset_last_Java_frame(rcx, false);\n-\n-  \/\/ Load UnrollBlock into EDI\n-  __ mov(rdi, rax);\n-\n-  \/\/ Move the unpack kind to a safe place in the UnrollBlock because\n-  \/\/ we are very short of registers\n-\n-  Address unpack_kind(rdi, Deoptimization::UnrollBlock::unpack_kind_offset());\n-  \/\/ retrieve the deopt kind from the UnrollBlock.\n-  __ movl(rax, unpack_kind);\n-\n-   Label noException;\n-  __ cmpl(rax, Deoptimization::Unpack_exception);   \/\/ Was exception pending?\n-  __ jcc(Assembler::notEqual, noException);\n-  __ movptr(rax, Address(rcx, JavaThread::exception_oop_offset()));\n-  __ movptr(rdx, Address(rcx, JavaThread::exception_pc_offset()));\n-  __ movptr(Address(rcx, JavaThread::exception_oop_offset()), NULL_WORD);\n-  __ movptr(Address(rcx, JavaThread::exception_pc_offset()), NULL_WORD);\n-\n-  __ verify_oop(rax);\n-\n-  \/\/ Overwrite the result registers with the exception results.\n-  __ movptr(Address(rsp, RegisterSaver::raxOffset()*wordSize), rax);\n-  __ movptr(Address(rsp, RegisterSaver::rdxOffset()*wordSize), rdx);\n-\n-  __ bind(noException);\n-\n-  \/\/ Stack is back to only having register save data on the stack.\n-  \/\/ Now restore the result registers. Everything else is either dead or captured\n-  \/\/ in the vframeArray.\n-\n-  RegisterSaver::restore_result_registers(masm);\n-\n-  \/\/ Non standard control word may be leaked out through a safepoint blob, and we can\n-  \/\/ deopt at a poll point with the non standard control word. However, we should make\n-  \/\/ sure the control word is correct after restore_result_registers.\n-  __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-\n-  \/\/ All of the register save area has been popped of the stack. Only the\n-  \/\/ return address remains.\n-\n-  \/\/ Pop all the frames we must move\/replace.\n-  \/\/\n-  \/\/ Frame picture (youngest to oldest)\n-  \/\/ 1: self-frame (no frame link)\n-  \/\/ 2: deopting frame  (no frame link)\n-  \/\/ 3: caller of deopting frame (could be compiled\/interpreted).\n-  \/\/\n-  \/\/ Note: by leaving the return address of self-frame on the stack\n-  \/\/ and using the size of frame 2 to adjust the stack\n-  \/\/ when we are done the return to frame 3 will still be on the stack.\n-\n-  \/\/ Pop deoptimized frame\n-  __ addptr(rsp, Address(rdi,Deoptimization::UnrollBlock::size_of_deoptimized_frame_offset()));\n-\n-  \/\/ sp should be pointing at the return address to the caller (3)\n-\n-  \/\/ Pick up the initial fp we should save\n-  \/\/ restore rbp before stack bang because if stack overflow is thrown it needs to be pushed (and preserved)\n-  __ movptr(rbp, Address(rdi, Deoptimization::UnrollBlock::initial_info_offset()));\n-\n-#ifdef ASSERT\n-  \/\/ Compilers generate code that bang the stack by as much as the\n-  \/\/ interpreter would need. So this stack banging should never\n-  \/\/ trigger a fault. Verify that it does not on non product builds.\n-  __ movl(rbx, Address(rdi ,Deoptimization::UnrollBlock::total_frame_sizes_offset()));\n-  __ bang_stack_size(rbx, rcx);\n-#endif\n-\n-  \/\/ Load array of frame pcs into ECX\n-  __ movptr(rcx,Address(rdi,Deoptimization::UnrollBlock::frame_pcs_offset()));\n-\n-  __ pop(rsi); \/\/ trash the old pc\n-\n-  \/\/ Load array of frame sizes into ESI\n-  __ movptr(rsi,Address(rdi,Deoptimization::UnrollBlock::frame_sizes_offset()));\n-\n-  Address counter(rdi, Deoptimization::UnrollBlock::counter_temp_offset());\n-\n-  __ movl(rbx, Address(rdi, Deoptimization::UnrollBlock::number_of_frames_offset()));\n-  __ movl(counter, rbx);\n-\n-  \/\/ Now adjust the caller's stack to make up for the extra locals\n-  \/\/ but record the original sp so that we can save it in the skeletal interpreter\n-  \/\/ frame and the stack walking of interpreter_sender will get the unextended sp\n-  \/\/ value and not the \"real\" sp value.\n-\n-  Address sp_temp(rdi, Deoptimization::UnrollBlock::sender_sp_temp_offset());\n-  __ movptr(sp_temp, rsp);\n-  __ movl2ptr(rbx, Address(rdi, Deoptimization::UnrollBlock::caller_adjustment_offset()));\n-  __ subptr(rsp, rbx);\n-\n-  \/\/ Push interpreter frames in a loop\n-  Label loop;\n-  __ bind(loop);\n-  __ movptr(rbx, Address(rsi, 0));      \/\/ Load frame size\n-  __ subptr(rbx, 2*wordSize);           \/\/ we'll push pc and rbp, by hand\n-  __ pushptr(Address(rcx, 0));          \/\/ save return address\n-  __ enter();                           \/\/ save old & set new rbp,\n-  __ subptr(rsp, rbx);                  \/\/ Prolog!\n-  __ movptr(rbx, sp_temp);              \/\/ sender's sp\n-  \/\/ This value is corrected by layout_activation_impl\n-  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n-  __ movptr(Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize), rbx); \/\/ Make it walkable\n-  __ movptr(sp_temp, rsp);              \/\/ pass to next frame\n-  __ addptr(rsi, wordSize);             \/\/ Bump array pointer (sizes)\n-  __ addptr(rcx, wordSize);             \/\/ Bump array pointer (pcs)\n-  __ decrementl(counter);             \/\/ decrement counter\n-  __ jcc(Assembler::notZero, loop);\n-  __ pushptr(Address(rcx, 0));          \/\/ save final return address\n-\n-  \/\/ Re-push self-frame\n-  __ enter();                           \/\/ save old & set new rbp,\n-\n-  \/\/  Return address and rbp, are in place\n-  \/\/ We'll push additional args later. Just allocate a full sized\n-  \/\/ register save area\n-  __ subptr(rsp, (frame_size_in_words-additional_words - 2) * wordSize);\n-\n-  \/\/ Restore frame locals after moving the frame\n-  __ movptr(Address(rsp, RegisterSaver::raxOffset()*wordSize), rax);\n-  __ movptr(Address(rsp, RegisterSaver::rdxOffset()*wordSize), rdx);\n-  __ fstp_d(Address(rsp, RegisterSaver::fpResultOffset()*wordSize));   \/\/ Pop float stack and store in local\n-  if( UseSSE>=2 ) __ movdbl(Address(rsp, RegisterSaver::xmm0Offset()*wordSize), xmm0);\n-  if( UseSSE==1 ) __ movflt(Address(rsp, RegisterSaver::xmm0Offset()*wordSize), xmm0);\n-\n-  \/\/ Set up the args to unpack_frame\n-\n-  __ pushl(unpack_kind);                     \/\/ get the unpack_kind value\n-  __ get_thread(rcx);\n-  __ push(rcx);\n-\n-  \/\/ set last_Java_sp, last_Java_fp\n-  __ set_last_Java_frame(rcx, noreg, rbp, nullptr, noreg);\n-\n-  \/\/ Call C code.  Need thread but NOT official VM entry\n-  \/\/ crud.  We cannot block on this call, no GC can happen.  Call should\n-  \/\/ restore return values to their stack-slots with the new SP.\n-  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, Deoptimization::unpack_frames)));\n-  \/\/ Set an oopmap for the call site\n-  oop_maps->add_gc_map( __ pc()-start, new OopMap( frame_size_in_words, 0 ));\n-\n-  \/\/ rax, contains the return result type\n-  __ push(rax);\n-\n-  __ get_thread(rcx);\n-  __ reset_last_Java_frame(rcx, false);\n-\n-  \/\/ Collect return values\n-  __ movptr(rax,Address(rsp, (RegisterSaver::raxOffset() + additional_words + 1)*wordSize));\n-  __ movptr(rdx,Address(rsp, (RegisterSaver::rdxOffset() + additional_words + 1)*wordSize));\n-\n-  \/\/ Clear floating point stack before returning to interpreter\n-  __ empty_FPU_stack();\n-\n-  \/\/ Check if we should push the float or double return value.\n-  Label results_done, yes_double_value;\n-  __ cmpl(Address(rsp, 0), T_DOUBLE);\n-  __ jcc (Assembler::zero, yes_double_value);\n-  __ cmpl(Address(rsp, 0), T_FLOAT);\n-  __ jcc (Assembler::notZero, results_done);\n-\n-  \/\/ return float value as expected by interpreter\n-  if( UseSSE>=1 ) __ movflt(xmm0, Address(rsp, (RegisterSaver::xmm0Offset() + additional_words + 1)*wordSize));\n-  else            __ fld_d(Address(rsp, (RegisterSaver::fpResultOffset() + additional_words + 1)*wordSize));\n-  __ jmp(results_done);\n-\n-  \/\/ return double value as expected by interpreter\n-  __ bind(yes_double_value);\n-  if( UseSSE>=2 ) __ movdbl(xmm0, Address(rsp, (RegisterSaver::xmm0Offset() + additional_words + 1)*wordSize));\n-  else            __ fld_d(Address(rsp, (RegisterSaver::fpResultOffset() + additional_words + 1)*wordSize));\n-\n-  __ bind(results_done);\n-\n-  \/\/ Pop self-frame.\n-  __ leave();                              \/\/ Epilog!\n-\n-  \/\/ Jump to interpreter\n-  __ ret(0);\n-\n-  \/\/ -------------\n-  \/\/ make sure all code is generated\n-  masm->flush();\n-\n-  _deopt_blob = DeoptimizationBlob::create( &buffer, oop_maps, 0, exception_offset, reexecute_offset, frame_size_in_words);\n-  _deopt_blob->set_unpack_with_exception_in_tls_offset(exception_in_tls_offset);\n-}\n-\n-\/\/------------------------------generate_handler_blob------\n-\/\/\n-\/\/ Generate a special Compile2Runtime blob that saves all registers,\n-\/\/ setup oopmap, and calls safepoint code to stop the compiled code for\n-\/\/ a safepoint.\n-\/\/\n-SafepointBlob* SharedRuntime::generate_handler_blob(SharedStubId id, address call_ptr) {\n-\n-  \/\/ Account for thread arg in our frame\n-  const int additional_words = 1;\n-  int frame_size_in_words;\n-\n-  assert (StubRoutines::forward_exception_entry() != nullptr, \"must be generated before\");\n-  assert(is_polling_page_id(id), \"expected a polling page stub id\");\n-\n-  ResourceMark rm;\n-  OopMapSet *oop_maps = new OopMapSet();\n-  OopMap* map;\n-\n-  \/\/ allocate space for the code\n-  \/\/ setup code generation tools\n-  const char* name = SharedRuntime::stub_name(id);\n-  CodeBuffer   buffer(name, 2048, 1024);\n-  MacroAssembler* masm = new MacroAssembler(&buffer);\n-\n-  const Register java_thread = rdi; \/\/ callee-saved for VC++\n-  address start   = __ pc();\n-  address call_pc = nullptr;\n-  bool cause_return = (id == SharedStubId::polling_page_return_handler_id);\n-  bool save_vectors = (id == SharedStubId::polling_page_vectors_safepoint_handler_id);\n-\n-  \/\/ If cause_return is true we are at a poll_return and there is\n-  \/\/ the return address on the stack to the caller on the nmethod\n-  \/\/ that is safepoint. We can leave this return on the stack and\n-  \/\/ effectively complete the return and safepoint in the caller.\n-  \/\/ Otherwise we push space for a return address that the safepoint\n-  \/\/ handler will install later to make the stack walking sensible.\n-  if (!cause_return)\n-    __ push(rbx);  \/\/ Make room for return address (or push it again)\n-\n-  map = RegisterSaver::save_live_registers(masm, additional_words, &frame_size_in_words, false, save_vectors);\n-\n-  \/\/ The following is basically a call_VM. However, we need the precise\n-  \/\/ address of the call in order to generate an oopmap. Hence, we do all the\n-  \/\/ work ourselves.\n-\n-  \/\/ Push thread argument and setup last_Java_sp\n-  __ get_thread(java_thread);\n-  __ push(java_thread);\n-  __ set_last_Java_frame(java_thread, noreg, noreg, nullptr, noreg);\n-\n-  \/\/ if this was not a poll_return then we need to correct the return address now.\n-  if (!cause_return) {\n-    \/\/ Get the return pc saved by the signal handler and stash it in its appropriate place on the stack.\n-    \/\/ Additionally, rbx is a callee saved register and we can look at it later to determine\n-    \/\/ if someone changed the return address for us!\n-    __ movptr(rbx, Address(java_thread, JavaThread::saved_exception_pc_offset()));\n-    __ movptr(Address(rbp, wordSize), rbx);\n-  }\n-\n-  \/\/ do the call\n-  __ call(RuntimeAddress(call_ptr));\n-\n-  \/\/ Set an oopmap for the call site.  This oopmap will map all\n-  \/\/ oop-registers and debug-info registers as callee-saved.  This\n-  \/\/ will allow deoptimization at this safepoint to find all possible\n-  \/\/ debug-info recordings, as well as let GC find all oops.\n-\n-  oop_maps->add_gc_map( __ pc() - start, map);\n-\n-  \/\/ Discard arg\n-  __ pop(rcx);\n-\n-  Label noException;\n-\n-  \/\/ Clear last_Java_sp again\n-  __ get_thread(java_thread);\n-  __ reset_last_Java_frame(java_thread, false);\n-\n-  __ cmpptr(Address(java_thread, Thread::pending_exception_offset()), NULL_WORD);\n-  __ jcc(Assembler::equal, noException);\n-\n-  \/\/ Exception pending\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n-\n-  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-  __ bind(noException);\n-\n-  Label no_adjust, bail, not_special;\n-  if (!cause_return) {\n-    \/\/ If our stashed return pc was modified by the runtime we avoid touching it\n-    __ cmpptr(rbx, Address(rbp, wordSize));\n-    __ jccb(Assembler::notEqual, no_adjust);\n-\n-    \/\/ Skip over the poll instruction.\n-    \/\/ See NativeInstruction::is_safepoint_poll()\n-    \/\/ Possible encodings:\n-    \/\/      85 00       test   %eax,(%rax)\n-    \/\/      85 01       test   %eax,(%rcx)\n-    \/\/      85 02       test   %eax,(%rdx)\n-    \/\/      85 03       test   %eax,(%rbx)\n-    \/\/      85 06       test   %eax,(%rsi)\n-    \/\/      85 07       test   %eax,(%rdi)\n-    \/\/\n-    \/\/      85 04 24    test   %eax,(%rsp)\n-    \/\/      85 45 00    test   %eax,0x0(%rbp)\n-\n-#ifdef ASSERT\n-    __ movptr(rax, rbx); \/\/ remember where 0x85 should be, for verification below\n-#endif\n-    \/\/ rsp\/rbp base encoding takes 3 bytes with the following register values:\n-    \/\/ rsp 0x04\n-    \/\/ rbp 0x05\n-    __ movzbl(rcx, Address(rbx, 1));\n-    __ andptr(rcx, 0x07); \/\/ looking for 0x04 .. 0x05\n-    __ subptr(rcx, 4);    \/\/ looking for 0x00 .. 0x01\n-    __ cmpptr(rcx, 1);\n-    __ jcc(Assembler::above, not_special);\n-    __ addptr(rbx, 1);\n-    __ bind(not_special);\n-#ifdef ASSERT\n-    \/\/ Verify the correct encoding of the poll we're about to skip.\n-    __ cmpb(Address(rax, 0), NativeTstRegMem::instruction_code_memXregl);\n-    __ jcc(Assembler::notEqual, bail);\n-    \/\/ Mask out the modrm bits\n-    __ testb(Address(rax, 1), NativeTstRegMem::modrm_mask);\n-    \/\/ rax encodes to 0, so if the bits are nonzero it's incorrect\n-    __ jcc(Assembler::notZero, bail);\n-#endif\n-    \/\/ Adjust return pc forward to step over the safepoint poll instruction\n-    __ addptr(rbx, 2);\n-    __ movptr(Address(rbp, wordSize), rbx);\n-  }\n-\n-  __ bind(no_adjust);\n-  \/\/ Normal exit, register restoring and exit\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n-\n-  __ ret(0);\n-\n-#ifdef ASSERT\n-  __ bind(bail);\n-  __ stop(\"Attempting to adjust pc to skip safepoint poll but the return point is not what we expected\");\n-#endif\n-\n-  \/\/ make sure all code is generated\n-  masm->flush();\n-\n-  \/\/ Fill-out other meta info\n-  return SafepointBlob::create(&buffer, oop_maps, frame_size_in_words);\n-}\n-\n-\/\/\n-\/\/ generate_resolve_blob - call resolution (static\/virtual\/opt-virtual\/ic-miss\n-\/\/\n-\/\/ Generate a stub that calls into vm to find out the proper destination\n-\/\/ of a java call. All the argument registers are live at this point\n-\/\/ but since this is generic code we don't know what they are and the caller\n-\/\/ must do any gc of the args.\n-\/\/\n-RuntimeStub* SharedRuntime::generate_resolve_blob(SharedStubId id, address destination) {\n-  assert (StubRoutines::forward_exception_entry() != nullptr, \"must be generated before\");\n-  assert(is_resolve_id(id), \"expected a resolve stub id\");\n-\n-  \/\/ allocate space for the code\n-  ResourceMark rm;\n-\n-  const char* name = SharedRuntime::stub_name(id);\n-  CodeBuffer buffer(name, 1000, 512);\n-  MacroAssembler* masm                = new MacroAssembler(&buffer);\n-\n-  int frame_size_words;\n-  enum frame_layout {\n-                thread_off,\n-                extra_words };\n-\n-  OopMapSet *oop_maps = new OopMapSet();\n-  OopMap* map = nullptr;\n-\n-  int start = __ offset();\n-\n-  map = RegisterSaver::save_live_registers(masm, extra_words, &frame_size_words);\n-\n-  int frame_complete = __ offset();\n-\n-  const Register thread = rdi;\n-  __ get_thread(rdi);\n-\n-  __ push(thread);\n-  __ set_last_Java_frame(thread, noreg, rbp, nullptr, noreg);\n-\n-  __ call(RuntimeAddress(destination));\n-\n-\n-  \/\/ Set an oopmap for the call site.\n-  \/\/ We need this not only for callee-saved registers, but also for volatile\n-  \/\/ registers that the compiler might be keeping live across a safepoint.\n-\n-  oop_maps->add_gc_map( __ offset() - start, map);\n-\n-  \/\/ rax, contains the address we are going to jump to assuming no exception got installed\n-\n-  __ addptr(rsp, wordSize);\n-\n-  \/\/ clear last_Java_sp\n-  __ reset_last_Java_frame(thread, true);\n-  \/\/ check for pending exceptions\n-  Label pending;\n-  __ cmpptr(Address(thread, Thread::pending_exception_offset()), NULL_WORD);\n-  __ jcc(Assembler::notEqual, pending);\n-\n-  \/\/ get the returned Method*\n-  __ get_vm_result_2(rbx, thread);\n-  __ movptr(Address(rsp, RegisterSaver::rbx_offset() * wordSize), rbx);\n-\n-  __ movptr(Address(rsp, RegisterSaver::rax_offset() * wordSize), rax);\n-\n-  RegisterSaver::restore_live_registers(masm);\n-\n-  \/\/ We are back to the original state on entry and ready to go.\n-\n-  __ jmp(rax);\n-\n-  \/\/ Pending exception after the safepoint\n-\n-  __ bind(pending);\n-\n-  RegisterSaver::restore_live_registers(masm);\n-\n-  \/\/ exception pending => remove activation and forward to exception handler\n-\n-  __ get_thread(thread);\n-  __ movptr(Address(thread, JavaThread::vm_result_offset()), NULL_WORD);\n-  __ movptr(rax, Address(thread, Thread::pending_exception_offset()));\n-  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-  \/\/ -------------\n-  \/\/ make sure all code is generated\n-  masm->flush();\n-\n-  \/\/ return the  blob\n-  \/\/ frame_size_words or bytes??\n-  return RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_words, oop_maps, true);\n-}\n-\n-  \/\/------------------------------------------------------------------------------------------------------------------------\n-  \/\/ Continuation point for throwing of implicit exceptions that are not handled in\n-  \/\/ the current activation. Fabricates an exception oop and initiates normal\n-  \/\/ exception dispatching in this frame.\n-  \/\/\n-  \/\/ Previously the compiler (c2) allowed for callee save registers on Java calls.\n-  \/\/ This is no longer true after adapter frames were removed but could possibly\n-  \/\/ be brought back in the future if the interpreter code was reworked and it\n-  \/\/ was deemed worthwhile. The comment below was left to describe what must\n-  \/\/ happen here if callee saves were resurrected. As it stands now this stub\n-  \/\/ could actually be a vanilla BufferBlob and have now oopMap at all.\n-  \/\/ Since it doesn't make much difference we've chosen to leave it the\n-  \/\/ way it was in the callee save days and keep the comment.\n-\n-  \/\/ If we need to preserve callee-saved values we need a callee-saved oop map and\n-  \/\/ therefore have to make these stubs into RuntimeStubs rather than BufferBlobs.\n-  \/\/ If the compiler needs all registers to be preserved between the fault\n-  \/\/ point and the exception handler then it must assume responsibility for that in\n-  \/\/ AbstractCompiler::continuation_for_implicit_null_exception or\n-  \/\/ continuation_for_implicit_division_by_zero_exception. All other implicit\n-  \/\/ exceptions (e.g., NullPointerException or AbstractMethodError on entry) are\n-  \/\/ either at call sites or otherwise assume that stack unwinding will be initiated,\n-  \/\/ so caller saved registers were assumed volatile in the compiler.\n-RuntimeStub* SharedRuntime::generate_throw_exception(SharedStubId id, address runtime_entry) {\n-  assert(is_throw_id(id), \"expected a throw stub id\");\n-\n-  const char* name = SharedRuntime::stub_name(id);\n-\n-  \/\/ Information about frame layout at time of blocking runtime call.\n-  \/\/ Note that we only have to preserve callee-saved registers since\n-  \/\/ the compilers are responsible for supplying a continuation point\n-  \/\/ if they expect all registers to be preserved.\n-  enum layout {\n-    thread_off,    \/\/ last_java_sp\n-    arg1_off,\n-    arg2_off,\n-    rbp_off,       \/\/ callee saved register\n-    ret_pc,\n-    framesize\n-  };\n-\n-  int insts_size = 256;\n-  int locs_size  = 32;\n-\n-  ResourceMark rm;\n-  const char* timer_msg = \"SharedRuntime generate_throw_exception\";\n-  TraceTime timer(timer_msg, TRACETIME_LOG(Info, startuptime));\n-\n-  CodeBuffer code(name, insts_size, locs_size);\n-  OopMapSet* oop_maps  = new OopMapSet();\n-  MacroAssembler* masm = new MacroAssembler(&code);\n-\n-  address start = __ pc();\n-\n-  \/\/ This is an inlined and slightly modified version of call_VM\n-  \/\/ which has the ability to fetch the return PC out of\n-  \/\/ thread-local storage and also sets up last_Java_sp slightly\n-  \/\/ differently than the real call_VM\n-  Register java_thread = rbx;\n-  __ get_thread(java_thread);\n-\n-  __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  \/\/ pc and rbp, already pushed\n-  __ subptr(rsp, (framesize-2) * wordSize); \/\/ prolog\n-\n-  \/\/ Frame is now completed as far as size and linkage.\n-\n-  int frame_complete = __ pc() - start;\n-\n-  \/\/ push java thread (becomes first argument of C function)\n-  __ movptr(Address(rsp, thread_off * wordSize), java_thread);\n-  \/\/ Set up last_Java_sp and last_Java_fp\n-  __ set_last_Java_frame(java_thread, rsp, rbp, nullptr, noreg);\n-\n-  \/\/ Call runtime\n-  BLOCK_COMMENT(\"call runtime_entry\");\n-  __ call(RuntimeAddress(runtime_entry));\n-  \/\/ Generate oop map\n-  OopMap* map =  new OopMap(framesize, 0);\n-  oop_maps->add_gc_map(__ pc() - start, map);\n-\n-  \/\/ restore the thread (cannot use the pushed argument since arguments\n-  \/\/ may be overwritten by C code generated by an optimizing compiler);\n-  \/\/ however can use the register value directly if it is callee saved.\n-  __ get_thread(java_thread);\n-\n-  __ reset_last_Java_frame(java_thread, true);\n-\n-  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-  \/\/ check for pending exceptions\n-#ifdef ASSERT\n-  Label L;\n-  __ cmpptr(Address(java_thread, Thread::pending_exception_offset()), NULL_WORD);\n-  __ jcc(Assembler::notEqual, L);\n-  __ should_not_reach_here();\n-  __ bind(L);\n-#endif \/* ASSERT *\/\n-  __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));\n-\n-\n-  RuntimeStub* stub = RuntimeStub::new_runtime_stub(name, &code, frame_complete, framesize, oop_maps, false);\n-  return stub;\n-}\n-\n-#if INCLUDE_JFR\n-\n-static void jfr_prologue(address the_pc, MacroAssembler* masm) {\n-  Register java_thread = rdi;\n-  __ get_thread(java_thread);\n-  __ set_last_Java_frame(java_thread, rsp, rbp, the_pc, noreg);\n-  __ movptr(Address(rsp, 0), java_thread);\n-}\n-\n-\/\/ The handle is dereferenced through a load barrier.\n-static void jfr_epilogue(MacroAssembler* masm) {\n-  Register java_thread = rdi;\n-  __ get_thread(java_thread);\n-  __ reset_last_Java_frame(java_thread, true);\n-}\n-\n-\/\/ For c2: c_rarg0 is junk, call to runtime to write a checkpoint.\n-\/\/ It returns a jobject handle to the event writer.\n-\/\/ The handle is dereferenced and the return value is the event writer oop.\n-RuntimeStub* SharedRuntime::generate_jfr_write_checkpoint() {\n-  enum layout {\n-    FPUState_off         = 0,\n-    rbp_off              = FPUStateSizeInWords,\n-    rdi_off,\n-    rsi_off,\n-    rcx_off,\n-    rbx_off,\n-    saved_argument_off,\n-    saved_argument_off2, \/\/ 2nd half of double\n-    framesize\n-  };\n-\n-  int insts_size = 1024;\n-  int locs_size = 64;\n-  const char* name = SharedRuntime::stub_name(SharedStubId::jfr_write_checkpoint_id);\n-  CodeBuffer code(name, insts_size, locs_size);\n-  OopMapSet* oop_maps = new OopMapSet();\n-  MacroAssembler* masm = new MacroAssembler(&code);\n-\n-  address start = __ pc();\n-  __ enter();\n-  int frame_complete = __ pc() - start;\n-  address the_pc = __ pc();\n-  jfr_prologue(the_pc, masm);\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::write_checkpoint), 1);\n-  jfr_epilogue(masm);\n-  __ resolve_global_jobject(rax, rdi, rdx);\n-  __ leave();\n-  __ ret(0);\n-\n-  OopMap* map = new OopMap(framesize, 1); \/\/ rbp\n-  oop_maps->add_gc_map(the_pc - start, map);\n-\n-  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-    RuntimeStub::new_runtime_stub(name, &code, frame_complete,\n-                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                  oop_maps, false);\n-  return stub;\n-}\n-\n-\/\/ For c2: call to return a leased buffer.\n-RuntimeStub* SharedRuntime::generate_jfr_return_lease() {\n-  enum layout {\n-    FPUState_off = 0,\n-    rbp_off = FPUStateSizeInWords,\n-    rdi_off,\n-    rsi_off,\n-    rcx_off,\n-    rbx_off,\n-    saved_argument_off,\n-    saved_argument_off2, \/\/ 2nd half of double\n-    framesize\n-  };\n-\n-  int insts_size = 1024;\n-  int locs_size = 64;\n-  const char* name = SharedRuntime::stub_name(SharedStubId::jfr_return_lease_id);\n-  CodeBuffer code(name, insts_size, locs_size);\n-  OopMapSet* oop_maps = new OopMapSet();\n-  MacroAssembler* masm = new MacroAssembler(&code);\n-\n-  address start = __ pc();\n-  __ enter();\n-  int frame_complete = __ pc() - start;\n-  address the_pc = __ pc();\n-  jfr_prologue(the_pc, masm);\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, JfrIntrinsicSupport::return_lease), 1);\n-  jfr_epilogue(masm);\n-  __ leave();\n-  __ ret(0);\n-\n-  OopMap* map = new OopMap(framesize, 1); \/\/ rbp\n-  oop_maps->add_gc_map(the_pc - start, map);\n-\n-  RuntimeStub* stub = \/\/ codeBlob framesize is in words (not VMRegImpl::slot_size)\n-    RuntimeStub::new_runtime_stub(name, &code, frame_complete,\n-                                  (framesize >> (LogBytesPerWord - LogBytesPerInt)),\n-                                  oop_maps, false);\n-  return stub;\n-}\n-\n-#endif \/\/ INCLUDE_JFR\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":0,"deletions":2854,"binary":false,"changes":2854,"status":"deleted"},{"patch":"@@ -1,4314 +0,0 @@\n-\/*\n- * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"asm\/macroAssembler.inline.hpp\"\n-#include \"compiler\/oopMap.hpp\"\n-#include \"gc\/shared\/barrierSet.hpp\"\n-#include \"gc\/shared\/barrierSetAssembler.hpp\"\n-#include \"gc\/shared\/barrierSetNMethod.hpp\"\n-#include \"interpreter\/interpreter.hpp\"\n-#include \"memory\/universe.hpp\"\n-#include \"nativeInst_x86.hpp\"\n-#include \"oops\/instanceOop.hpp\"\n-#include \"oops\/method.hpp\"\n-#include \"oops\/objArrayKlass.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"prims\/methodHandles.hpp\"\n-#include \"runtime\/frame.inline.hpp\"\n-#include \"runtime\/handles.inline.hpp\"\n-#include \"runtime\/javaThread.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"runtime\/stubCodeGenerator.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#ifdef COMPILER2\n-#include \"opto\/runtime.hpp\"\n-#endif\n-\n-\/\/ Declaration and definition of StubGenerator (no .hpp file).\n-\/\/ For a more detailed description of the stub routine structure\n-\/\/ see the comment in stubRoutines.hpp\n-\n-#define __ _masm->\n-#define a__ ((Assembler*)_masm)->\n-\n-#ifdef PRODUCT\n-#define BLOCK_COMMENT(str) \/* nothing *\/\n-#else\n-#define BLOCK_COMMENT(str) __ block_comment(str)\n-#endif\n-\n-#define BIND(label) bind(label); BLOCK_COMMENT(#label \":\")\n-\n-const int FPU_CNTRL_WRD_MASK = 0xFFFF;\n-\n-ATTRIBUTE_ALIGNED(16) static const uint32_t KEY_SHUFFLE_MASK[] = {\n-    0x00010203UL, 0x04050607UL, 0x08090A0BUL, 0x0C0D0E0FUL,\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const uint32_t COUNTER_SHUFFLE_MASK[] = {\n-    0x0C0D0E0FUL, 0x08090A0BUL, 0x04050607UL, 0x00010203UL,\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const uint32_t GHASH_BYTE_SWAP_MASK[] = {\n-    0x0C0D0E0FUL, 0x08090A0BUL, 0x04050607UL, 0x00010203UL,\n-};\n-\n-ATTRIBUTE_ALIGNED(16) static const uint32_t GHASH_LONG_SWAP_MASK[] = {\n-    0x0B0A0908UL, 0x0F0E0D0CUL, 0x03020100UL, 0x07060504UL,\n-};\n-\n-\/\/ -------------------------------------------------------------------------------------------------------------------------\n-\/\/ Stub Code definitions\n-\n-class StubGenerator: public StubCodeGenerator {\n- private:\n-\n-#ifdef PRODUCT\n-#define inc_counter_np(counter) ((void)0)\n-#else\n-  void inc_counter_np_(uint& counter) {\n-    __ incrementl(ExternalAddress((address)&counter));\n-  }\n-#define inc_counter_np(counter) \\\n-  BLOCK_COMMENT(\"inc_counter \" #counter); \\\n-  inc_counter_np_(counter);\n-#endif \/\/PRODUCT\n-\n-  void inc_copy_counter_np(BasicType t) {\n-#ifndef PRODUCT\n-    switch (t) {\n-    case T_BYTE:    inc_counter_np(SharedRuntime::_jbyte_array_copy_ctr); return;\n-    case T_SHORT:   inc_counter_np(SharedRuntime::_jshort_array_copy_ctr); return;\n-    case T_INT:     inc_counter_np(SharedRuntime::_jint_array_copy_ctr); return;\n-    case T_LONG:    inc_counter_np(SharedRuntime::_jlong_array_copy_ctr); return;\n-    case T_OBJECT:  inc_counter_np(SharedRuntime::_oop_array_copy_ctr); return;\n-    default:        ShouldNotReachHere();\n-    }\n-#endif \/\/PRODUCT\n-  }\n-\n-  \/\/------------------------------------------------------------------------------------------------------------------------\n-  \/\/ Call stubs are used to call Java from C\n-  \/\/\n-  \/\/    [ return_from_Java     ] <--- rsp\n-  \/\/    [ argument word n      ]\n-  \/\/      ...\n-  \/\/ -N [ argument word 1      ]\n-  \/\/ -7 [ Possible padding for stack alignment ]\n-  \/\/ -6 [ Possible padding for stack alignment ]\n-  \/\/ -5 [ Possible padding for stack alignment ]\n-  \/\/ -4 [ mxcsr save           ] <--- rsp_after_call\n-  \/\/ -3 [ saved rbx,            ]\n-  \/\/ -2 [ saved rsi            ]\n-  \/\/ -1 [ saved rdi            ]\n-  \/\/  0 [ saved rbp,            ] <--- rbp,\n-  \/\/  1 [ return address       ]\n-  \/\/  2 [ ptr. to call wrapper ]\n-  \/\/  3 [ result               ]\n-  \/\/  4 [ result_type          ]\n-  \/\/  5 [ method               ]\n-  \/\/  6 [ entry_point          ]\n-  \/\/  7 [ parameters           ]\n-  \/\/  8 [ parameter_size       ]\n-  \/\/  9 [ thread               ]\n-\n-\n-  address generate_call_stub(address& return_address) {\n-    StubGenStubId stub_id = StubGenStubId::call_stub_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    \/\/ stub code parameters \/ addresses\n-    assert(frame::entry_frame_call_wrapper_offset == 2, \"adjust this code\");\n-    bool  sse_save = false;\n-    const Address rsp_after_call(rbp, -4 * wordSize); \/\/ same as in generate_catch_exception()!\n-    const int     locals_count_in_bytes  (4*wordSize);\n-    const Address mxcsr_save    (rbp, -4 * wordSize);\n-    const Address saved_rbx     (rbp, -3 * wordSize);\n-    const Address saved_rsi     (rbp, -2 * wordSize);\n-    const Address saved_rdi     (rbp, -1 * wordSize);\n-    const Address result        (rbp,  3 * wordSize);\n-    const Address result_type   (rbp,  4 * wordSize);\n-    const Address method        (rbp,  5 * wordSize);\n-    const Address entry_point   (rbp,  6 * wordSize);\n-    const Address parameters    (rbp,  7 * wordSize);\n-    const Address parameter_size(rbp,  8 * wordSize);\n-    const Address thread        (rbp,  9 * wordSize); \/\/ same as in generate_catch_exception()!\n-    sse_save =  UseSSE > 0;\n-\n-    \/\/ stub code\n-    __ enter();\n-    __ movptr(rcx, parameter_size);              \/\/ parameter counter\n-    __ shlptr(rcx, Interpreter::logStackElementSize); \/\/ convert parameter count to bytes\n-    __ addptr(rcx, locals_count_in_bytes);       \/\/ reserve space for register saves\n-    __ subptr(rsp, rcx);\n-    __ andptr(rsp, -(StackAlignmentInBytes));    \/\/ Align stack\n-\n-    \/\/ save rdi, rsi, & rbx, according to C calling conventions\n-    __ movptr(saved_rdi, rdi);\n-    __ movptr(saved_rsi, rsi);\n-    __ movptr(saved_rbx, rbx);\n-\n-    \/\/ save and initialize %mxcsr\n-    if (sse_save) {\n-      Label skip_ldmx;\n-      __ cmp32_mxcsr_std(mxcsr_save, rax);\n-      __ jcc(Assembler::equal, skip_ldmx);\n-      __ ldmxcsr(mxcsr_std);\n-      __ bind(skip_ldmx);\n-    }\n-\n-    \/\/ make sure the control word is correct.\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-\n-#ifdef ASSERT\n-    \/\/ make sure we have no pending exceptions\n-    { Label L;\n-      __ movptr(rcx, thread);\n-      __ cmpptr(Address(rcx, Thread::pending_exception_offset()), NULL_WORD);\n-      __ jcc(Assembler::equal, L);\n-      __ stop(\"StubRoutines::call_stub: entered with pending exception\");\n-      __ bind(L);\n-    }\n-#endif\n-\n-    \/\/ pass parameters if any\n-    BLOCK_COMMENT(\"pass parameters if any\");\n-    Label parameters_done;\n-    __ movl(rcx, parameter_size);  \/\/ parameter counter\n-    __ testl(rcx, rcx);\n-    __ jcc(Assembler::zero, parameters_done);\n-\n-    \/\/ parameter passing loop\n-\n-    Label loop;\n-    \/\/ Copy Java parameters in reverse order (receiver last)\n-    \/\/ Note that the argument order is inverted in the process\n-    \/\/ source is rdx[rcx: N-1..0]\n-    \/\/ dest   is rsp[rbx: 0..N-1]\n-\n-    __ movptr(rdx, parameters);          \/\/ parameter pointer\n-    __ xorptr(rbx, rbx);\n-\n-    __ BIND(loop);\n-\n-    \/\/ get parameter\n-    __ movptr(rax, Address(rdx, rcx, Interpreter::stackElementScale(), -wordSize));\n-    __ movptr(Address(rsp, rbx, Interpreter::stackElementScale(),\n-                    Interpreter::expr_offset_in_bytes(0)), rax);          \/\/ store parameter\n-    __ increment(rbx);\n-    __ decrement(rcx);\n-    __ jcc(Assembler::notZero, loop);\n-\n-    \/\/ call Java function\n-    __ BIND(parameters_done);\n-    __ movptr(rbx, method);           \/\/ get Method*\n-    __ movptr(rax, entry_point);      \/\/ get entry_point\n-    __ mov(rsi, rsp);                 \/\/ set sender sp\n-    BLOCK_COMMENT(\"call Java function\");\n-    __ call(rax);\n-\n-    BLOCK_COMMENT(\"call_stub_return_address:\");\n-    return_address = __ pc();\n-\n-#ifdef COMPILER2\n-    {\n-      Label L_skip;\n-      if (UseSSE >= 2) {\n-        __ verify_FPU(0, \"call_stub_return\");\n-      } else {\n-        for (int i = 1; i < 8; i++) {\n-          __ ffree(i);\n-        }\n-\n-        \/\/ UseSSE <= 1 so double result should be left on TOS\n-        __ movl(rsi, result_type);\n-        __ cmpl(rsi, T_DOUBLE);\n-        __ jcc(Assembler::equal, L_skip);\n-        if (UseSSE == 0) {\n-          \/\/ UseSSE == 0 so float result should be left on TOS\n-          __ cmpl(rsi, T_FLOAT);\n-          __ jcc(Assembler::equal, L_skip);\n-        }\n-        __ ffree(0);\n-      }\n-      __ BIND(L_skip);\n-    }\n-#endif \/\/ COMPILER2\n-\n-    \/\/ store result depending on type\n-    \/\/ (everything that is not T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)\n-    __ movptr(rdi, result);\n-    Label is_long, is_float, is_double, exit;\n-    __ movl(rsi, result_type);\n-    __ cmpl(rsi, T_LONG);\n-    __ jcc(Assembler::equal, is_long);\n-    __ cmpl(rsi, T_FLOAT);\n-    __ jcc(Assembler::equal, is_float);\n-    __ cmpl(rsi, T_DOUBLE);\n-    __ jcc(Assembler::equal, is_double);\n-\n-    \/\/ handle T_INT case\n-    __ movl(Address(rdi, 0), rax);\n-    __ BIND(exit);\n-\n-    \/\/ check that FPU stack is empty\n-    __ verify_FPU(0, \"generate_call_stub\");\n-\n-    \/\/ pop parameters\n-    __ lea(rsp, rsp_after_call);\n-\n-    \/\/ restore %mxcsr\n-    if (sse_save) {\n-      __ ldmxcsr(mxcsr_save);\n-    }\n-\n-    \/\/ restore rdi, rsi and rbx,\n-    __ movptr(rbx, saved_rbx);\n-    __ movptr(rsi, saved_rsi);\n-    __ movptr(rdi, saved_rdi);\n-    __ addptr(rsp, 4*wordSize);\n-\n-    \/\/ return\n-    __ pop(rbp);\n-    __ ret(0);\n-\n-    \/\/ handle return types different from T_INT\n-    __ BIND(is_long);\n-    __ movl(Address(rdi, 0 * wordSize), rax);\n-    __ movl(Address(rdi, 1 * wordSize), rdx);\n-    __ jmp(exit);\n-\n-    __ BIND(is_float);\n-    \/\/ interpreter uses xmm0 for return values\n-    if (UseSSE >= 1) {\n-      __ movflt(Address(rdi, 0), xmm0);\n-    } else {\n-      __ fstp_s(Address(rdi, 0));\n-    }\n-    __ jmp(exit);\n-\n-    __ BIND(is_double);\n-    \/\/ interpreter uses xmm0 for return values\n-    if (UseSSE >= 2) {\n-      __ movdbl(Address(rdi, 0), xmm0);\n-    } else {\n-      __ fstp_d(Address(rdi, 0));\n-    }\n-    __ jmp(exit);\n-\n-    return start;\n-  }\n-\n-\n-  \/\/------------------------------------------------------------------------------------------------------------------------\n-  \/\/ Return point for a Java call if there's an exception thrown in Java code.\n-  \/\/ The exception is caught and transformed into a pending exception stored in\n-  \/\/ JavaThread that can be tested from within the VM.\n-  \/\/\n-  \/\/ Note: Usually the parameters are removed by the callee. In case of an exception\n-  \/\/       crossing an activation frame boundary, that is not the case if the callee\n-  \/\/       is compiled code => need to setup the rsp.\n-  \/\/\n-  \/\/ rax,: exception oop\n-\n-  address generate_catch_exception() {\n-    StubGenStubId stub_id = StubGenStubId::catch_exception_id;\n-    StubCodeMark mark(this, stub_id);\n-    const Address rsp_after_call(rbp, -4 * wordSize); \/\/ same as in generate_call_stub()!\n-    const Address thread        (rbp,  9 * wordSize); \/\/ same as in generate_call_stub()!\n-    address start = __ pc();\n-\n-    \/\/ get thread directly\n-    __ movptr(rcx, thread);\n-#ifdef ASSERT\n-    \/\/ verify that threads correspond\n-    { Label L;\n-      __ get_thread(rbx);\n-      __ cmpptr(rbx, rcx);\n-      __ jcc(Assembler::equal, L);\n-      __ stop(\"StubRoutines::catch_exception: threads must correspond\");\n-      __ bind(L);\n-    }\n-#endif\n-    \/\/ set pending exception\n-    __ verify_oop(rax);\n-    __ movptr(Address(rcx, Thread::pending_exception_offset()), rax);\n-    __ lea(Address(rcx, Thread::exception_file_offset()),\n-           ExternalAddress((address)__FILE__), noreg);\n-    __ movl(Address(rcx, Thread::exception_line_offset()), __LINE__ );\n-    \/\/ complete return to VM\n-    assert(StubRoutines::_call_stub_return_address != nullptr, \"_call_stub_return_address must have been generated before\");\n-    __ jump(RuntimeAddress(StubRoutines::_call_stub_return_address));\n-\n-    return start;\n-  }\n-\n-\n-  \/\/------------------------------------------------------------------------------------------------------------------------\n-  \/\/ Continuation point for runtime calls returning with a pending exception.\n-  \/\/ The pending exception check happened in the runtime or native call stub.\n-  \/\/ The pending exception in Thread is converted into a Java-level exception.\n-  \/\/\n-  \/\/ Contract with Java-level exception handlers:\n-  \/\/ rax: exception\n-  \/\/ rdx: throwing pc\n-  \/\/\n-  \/\/ NOTE: At entry of this stub, exception-pc must be on stack !!\n-\n-  address generate_forward_exception() {\n-    StubGenStubId stub_id = StubGenStubId::forward_exception_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    const Register thread = rcx;\n-\n-    \/\/ other registers used in this stub\n-    const Register exception_oop = rax;\n-    const Register handler_addr  = rbx;\n-    const Register exception_pc  = rdx;\n-\n-    \/\/ Upon entry, the sp points to the return address returning into Java\n-    \/\/ (interpreted or compiled) code; i.e., the return address becomes the\n-    \/\/ throwing pc.\n-    \/\/\n-    \/\/ Arguments pushed before the runtime call are still on the stack but\n-    \/\/ the exception handler will reset the stack pointer -> ignore them.\n-    \/\/ A potential result in registers can be ignored as well.\n-\n-#ifdef ASSERT\n-    \/\/ make sure this code is only executed if there is a pending exception\n-    { Label L;\n-      __ get_thread(thread);\n-      __ cmpptr(Address(thread, Thread::pending_exception_offset()), NULL_WORD);\n-      __ jcc(Assembler::notEqual, L);\n-      __ stop(\"StubRoutines::forward exception: no pending exception (1)\");\n-      __ bind(L);\n-    }\n-#endif\n-\n-    \/\/ compute exception handler into rbx,\n-    __ get_thread(thread);\n-    __ movptr(exception_pc, Address(rsp, 0));\n-    BLOCK_COMMENT(\"call exception_handler_for_return_address\");\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), thread, exception_pc);\n-    __ mov(handler_addr, rax);\n-\n-    \/\/ setup rax & rdx, remove return address & clear pending exception\n-    __ get_thread(thread);\n-    __ pop(exception_pc);\n-    __ movptr(exception_oop, Address(thread, Thread::pending_exception_offset()));\n-    __ movptr(Address(thread, Thread::pending_exception_offset()), NULL_WORD);\n-\n-#ifdef ASSERT\n-    \/\/ make sure exception is set\n-    { Label L;\n-      __ testptr(exception_oop, exception_oop);\n-      __ jcc(Assembler::notEqual, L);\n-      __ stop(\"StubRoutines::forward exception: no pending exception (2)\");\n-      __ bind(L);\n-    }\n-#endif\n-\n-    \/\/ Verify that there is really a valid exception in RAX.\n-    __ verify_oop(exception_oop);\n-\n-    \/\/ continue at exception handler (return address removed)\n-    \/\/ rax: exception\n-    \/\/ rbx: exception handler\n-    \/\/ rdx: throwing pc\n-    __ jmp(handler_addr);\n-\n-    return start;\n-  }\n-\n-  \/\/----------------------------------------------------------------------------------------------------\n-  \/\/ Support for void verify_mxcsr()\n-  \/\/\n-  \/\/ This routine is used with -Xcheck:jni to verify that native\n-  \/\/ JNI code does not return to Java code without restoring the\n-  \/\/ MXCSR register to our expected state.\n-\n-\n-  address generate_verify_mxcsr() {\n-    StubGenStubId stub_id = StubGenStubId::verify_mxcsr_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    const Address mxcsr_save(rsp, 0);\n-\n-    if (CheckJNICalls && UseSSE > 0 ) {\n-      Label ok_ret;\n-      __ push(rax);\n-      __ subptr(rsp, wordSize);      \/\/ allocate a temp location\n-      __ cmp32_mxcsr_std(mxcsr_save, rax);\n-      __ jcc(Assembler::equal, ok_ret);\n-\n-      __ warn(\"MXCSR changed by native JNI code.\");\n-\n-      ExternalAddress mxcsr_std(StubRoutines::x86::addr_mxcsr_std());\n-      __ ldmxcsr(mxcsr_std);\n-\n-      __ bind(ok_ret);\n-      __ addptr(rsp, wordSize);\n-      __ pop(rax);\n-    }\n-\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-\n-  \/\/---------------------------------------------------------------------------\n-  \/\/ Support for void verify_fpu_cntrl_wrd()\n-  \/\/\n-  \/\/ This routine is used with -Xcheck:jni to verify that native\n-  \/\/ JNI code does not return to Java code without restoring the\n-  \/\/ FP control word to our expected state.\n-\n-  address generate_verify_fpu_cntrl_wrd() {\n-    StubGenStubId stub_id = StubGenStubId::verify_fpu_cntrl_word_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    const Address fpu_cntrl_wrd_save(rsp, 0);\n-\n-    if (CheckJNICalls) {\n-      Label ok_ret;\n-      __ push(rax);\n-      __ subptr(rsp, wordSize);      \/\/ allocate a temp location\n-      __ fnstcw(fpu_cntrl_wrd_save);\n-      __ movl(rax, fpu_cntrl_wrd_save);\n-      __ andl(rax, FPU_CNTRL_WRD_MASK);\n-      ExternalAddress fpu_std(StubRoutines::x86::addr_fpu_cntrl_wrd_std());\n-      __ cmp32(rax, fpu_std);\n-      __ jcc(Assembler::equal, ok_ret);\n-\n-      __ warn(\"Floating point control word changed by native JNI code.\");\n-\n-      __ fldcw(fpu_std);\n-\n-      __ bind(ok_ret);\n-      __ addptr(rsp, wordSize);\n-      __ pop(rax);\n-    }\n-\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-  \/\/---------------------------------------------------------------------------\n-  \/\/ Wrapper for slow-case handling of double-to-integer conversion\n-  \/\/ d2i or f2i fast case failed either because it is nan or because\n-  \/\/ of under\/overflow.\n-  \/\/ Input:  FPU TOS: float value\n-  \/\/ Output: rax, (rdx): integer (long) result\n-\n-  address generate_d2i_wrapper(BasicType t, address fcn) {\n-    StubGenStubId stub_id = StubGenStubId::d2i_wrapper_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-  \/\/ Capture info about frame layout\n-  enum layout { FPUState_off         = 0,\n-                rbp_off              = FPUStateSizeInWords,\n-                rdi_off,\n-                rsi_off,\n-                rcx_off,\n-                rbx_off,\n-                saved_argument_off,\n-                saved_argument_off2, \/\/ 2nd half of double\n-                framesize\n-  };\n-\n-  assert(FPUStateSizeInWords == 27, \"update stack layout\");\n-\n-    \/\/ Save outgoing argument to stack across push_FPU_state()\n-    __ subptr(rsp, wordSize * 2);\n-    __ fstp_d(Address(rsp, 0));\n-\n-    \/\/ Save CPU & FPU state\n-    __ push(rbx);\n-    __ push(rcx);\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ push(rbp);\n-    __ push_FPU_state();\n-\n-    \/\/ push_FPU_state() resets the FP top of stack\n-    \/\/ Load original double into FP top of stack\n-    __ fld_d(Address(rsp, saved_argument_off * wordSize));\n-    \/\/ Store double into stack as outgoing argument\n-    __ subptr(rsp, wordSize*2);\n-    __ fst_d(Address(rsp, 0));\n-\n-    \/\/ Prepare FPU for doing math in C-land\n-    __ empty_FPU_stack();\n-    \/\/ Call the C code to massage the double.  Result in EAX\n-    if (t == T_INT)\n-      { BLOCK_COMMENT(\"SharedRuntime::d2i\"); }\n-    else if (t == T_LONG)\n-      { BLOCK_COMMENT(\"SharedRuntime::d2l\"); }\n-    __ call_VM_leaf( fcn, 2 );\n-\n-    \/\/ Restore CPU & FPU state\n-    __ pop_FPU_state();\n-    __ pop(rbp);\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ pop(rcx);\n-    __ pop(rbx);\n-    __ addptr(rsp, wordSize * 2);\n-\n-    __ ret(0);\n-\n-    return start;\n-  }\n-  \/\/---------------------------------------------------------------------------------------------------\n-\n-  address generate_vector_mask(StubGenStubId stub_id, int32_t mask) {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    for (int i = 0; i < 16; i++) {\n-      __ emit_data(mask, relocInfo::none, 0);\n-    }\n-\n-    return start;\n-  }\n-\n-  address generate_count_leading_zeros_lut() {\n-    __ align64();\n-    StubGenStubId stub_id = StubGenStubId::vector_count_leading_zeros_lut_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x02020304, relocInfo::none, 0);\n-    __ emit_data(0x01010101, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x02020304, relocInfo::none, 0);\n-    __ emit_data(0x01010101, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x02020304, relocInfo::none, 0);\n-    __ emit_data(0x01010101, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x02020304, relocInfo::none, 0);\n-    __ emit_data(0x01010101, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-\n-  address generate_popcount_avx_lut() {\n-    __ align64();\n-    StubGenStubId stub_id = StubGenStubId::vector_popcount_lut_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x02010100, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x04030302, relocInfo::none, 0);\n-    __ emit_data(0x02010100, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x04030302, relocInfo::none, 0);\n-    __ emit_data(0x02010100, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x04030302, relocInfo::none, 0);\n-    __ emit_data(0x02010100, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x03020201, relocInfo::none, 0);\n-    __ emit_data(0x04030302, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-\n-  address generate_iota_indices() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_iota_indices_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    \/\/ B\n-    __ emit_data(0x03020100, relocInfo::none, 0);\n-    __ emit_data(0x07060504, relocInfo::none, 0);\n-    __ emit_data(0x0B0A0908, relocInfo::none, 0);\n-    __ emit_data(0x0F0E0D0C, relocInfo::none, 0);\n-    __ emit_data(0x13121110, relocInfo::none, 0);\n-    __ emit_data(0x17161514, relocInfo::none, 0);\n-    __ emit_data(0x1B1A1918, relocInfo::none, 0);\n-    __ emit_data(0x1F1E1D1C, relocInfo::none, 0);\n-    __ emit_data(0x23222120, relocInfo::none, 0);\n-    __ emit_data(0x27262524, relocInfo::none, 0);\n-    __ emit_data(0x2B2A2928, relocInfo::none, 0);\n-    __ emit_data(0x2F2E2D2C, relocInfo::none, 0);\n-    __ emit_data(0x33323130, relocInfo::none, 0);\n-    __ emit_data(0x37363534, relocInfo::none, 0);\n-    __ emit_data(0x3B3A3938, relocInfo::none, 0);\n-    __ emit_data(0x3F3E3D3C, relocInfo::none, 0);\n-\n-    \/\/ W\n-    __ emit_data(0x00010000, relocInfo::none, 0);\n-    __ emit_data(0x00030002, relocInfo::none, 0);\n-    __ emit_data(0x00050004, relocInfo::none, 0);\n-    __ emit_data(0x00070006, relocInfo::none, 0);\n-    __ emit_data(0x00090008, relocInfo::none, 0);\n-    __ emit_data(0x000B000A, relocInfo::none, 0);\n-    __ emit_data(0x000D000C, relocInfo::none, 0);\n-    __ emit_data(0x000F000E, relocInfo::none, 0);\n-    __ emit_data(0x00110010, relocInfo::none, 0);\n-    __ emit_data(0x00130012, relocInfo::none, 0);\n-    __ emit_data(0x00150014, relocInfo::none, 0);\n-    __ emit_data(0x00170016, relocInfo::none, 0);\n-    __ emit_data(0x00190018, relocInfo::none, 0);\n-    __ emit_data(0x001B001A, relocInfo::none, 0);\n-    __ emit_data(0x001D001C, relocInfo::none, 0);\n-    __ emit_data(0x001F001E, relocInfo::none, 0);\n-\n-    \/\/ D\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000001, relocInfo::none, 0);\n-    __ emit_data(0x00000002, relocInfo::none, 0);\n-    __ emit_data(0x00000003, relocInfo::none, 0);\n-    __ emit_data(0x00000004, relocInfo::none, 0);\n-    __ emit_data(0x00000005, relocInfo::none, 0);\n-    __ emit_data(0x00000006, relocInfo::none, 0);\n-    __ emit_data(0x00000007, relocInfo::none, 0);\n-    __ emit_data(0x00000008, relocInfo::none, 0);\n-    __ emit_data(0x00000009, relocInfo::none, 0);\n-    __ emit_data(0x0000000A, relocInfo::none, 0);\n-    __ emit_data(0x0000000B, relocInfo::none, 0);\n-    __ emit_data(0x0000000C, relocInfo::none, 0);\n-    __ emit_data(0x0000000D, relocInfo::none, 0);\n-    __ emit_data(0x0000000E, relocInfo::none, 0);\n-    __ emit_data(0x0000000F, relocInfo::none, 0);\n-\n-    \/\/ Q\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000001, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000002, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000003, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000004, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000005, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000006, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000007, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-\n-    \/\/ D - FP\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 0.0f\n-    __ emit_data(0x3F800000, relocInfo::none, 0); \/\/ 1.0f\n-    __ emit_data(0x40000000, relocInfo::none, 0); \/\/ 2.0f\n-    __ emit_data(0x40400000, relocInfo::none, 0); \/\/ 3.0f\n-    __ emit_data(0x40800000, relocInfo::none, 0); \/\/ 4.0f\n-    __ emit_data(0x40A00000, relocInfo::none, 0); \/\/ 5.0f\n-    __ emit_data(0x40C00000, relocInfo::none, 0); \/\/ 6.0f\n-    __ emit_data(0x40E00000, relocInfo::none, 0); \/\/ 7.0f\n-    __ emit_data(0x41000000, relocInfo::none, 0); \/\/ 8.0f\n-    __ emit_data(0x41100000, relocInfo::none, 0); \/\/ 9.0f\n-    __ emit_data(0x41200000, relocInfo::none, 0); \/\/ 10.0f\n-    __ emit_data(0x41300000, relocInfo::none, 0); \/\/ 11.0f\n-    __ emit_data(0x41400000, relocInfo::none, 0); \/\/ 12.0f\n-    __ emit_data(0x41500000, relocInfo::none, 0); \/\/ 13.0f\n-    __ emit_data(0x41600000, relocInfo::none, 0); \/\/ 14.0f\n-    __ emit_data(0x41700000, relocInfo::none, 0); \/\/ 15.0f\n-\n-    \/\/ Q - FP\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 0.0d\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 1.0d\n-    __ emit_data(0x3FF00000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 2.0d\n-    __ emit_data(0x40000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 3.0d\n-    __ emit_data(0x40080000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 4.0d\n-    __ emit_data(0x40100000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 5.0d\n-    __ emit_data(0x40140000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 6.0d\n-    __ emit_data(0x40180000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0); \/\/ 7.0d\n-    __ emit_data(0x401c0000, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_reverse_bit_lut() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_reverse_bit_lut_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x0C040800, relocInfo::none, 0);\n-    __ emit_data(0x0E060A02, relocInfo::none, 0);\n-    __ emit_data(0x0D050901, relocInfo::none, 0);\n-    __ emit_data(0x0F070B03, relocInfo::none, 0);\n-    __ emit_data(0x0C040800, relocInfo::none, 0);\n-    __ emit_data(0x0E060A02, relocInfo::none, 0);\n-    __ emit_data(0x0D050901, relocInfo::none, 0);\n-    __ emit_data(0x0F070B03, relocInfo::none, 0);\n-    __ emit_data(0x0C040800, relocInfo::none, 0);\n-    __ emit_data(0x0E060A02, relocInfo::none, 0);\n-    __ emit_data(0x0D050901, relocInfo::none, 0);\n-    __ emit_data(0x0F070B03, relocInfo::none, 0);\n-    __ emit_data(0x0C040800, relocInfo::none, 0);\n-    __ emit_data(0x0E060A02, relocInfo::none, 0);\n-    __ emit_data(0x0D050901, relocInfo::none, 0);\n-    __ emit_data(0x0F070B03, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_reverse_byte_perm_mask_long() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_long_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_reverse_byte_perm_mask_int() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_int_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x08090A0B, relocInfo::none, 0);\n-    __ emit_data(0x0C0D0E0F, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_reverse_byte_perm_mask_short() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_reverse_byte_perm_mask_short_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x02030001, relocInfo::none, 0);\n-    __ emit_data(0x06070405, relocInfo::none, 0);\n-    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n-    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n-    __ emit_data(0x02030001, relocInfo::none, 0);\n-    __ emit_data(0x06070405, relocInfo::none, 0);\n-    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n-    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n-    __ emit_data(0x02030001, relocInfo::none, 0);\n-    __ emit_data(0x06070405, relocInfo::none, 0);\n-    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n-    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n-    __ emit_data(0x02030001, relocInfo::none, 0);\n-    __ emit_data(0x06070405, relocInfo::none, 0);\n-    __ emit_data(0x0A0B0809, relocInfo::none, 0);\n-    __ emit_data(0x0E0F0C0D, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_byte_shuffle_mask() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_byte_shuffle_mask_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x70707070, relocInfo::none, 0);\n-    __ emit_data(0x70707070, relocInfo::none, 0);\n-    __ emit_data(0x70707070, relocInfo::none, 0);\n-    __ emit_data(0x70707070, relocInfo::none, 0);\n-    __ emit_data(0xF0F0F0F0, relocInfo::none, 0);\n-    __ emit_data(0xF0F0F0F0, relocInfo::none, 0);\n-    __ emit_data(0xF0F0F0F0, relocInfo::none, 0);\n-    __ emit_data(0xF0F0F0F0, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_vector_mask_long_double(StubGenStubId stub_id, int32_t maskhi, int32_t masklo) {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    for (int i = 0; i < 8; i++) {\n-      __ emit_data(masklo, relocInfo::none, 0);\n-      __ emit_data(maskhi, relocInfo::none, 0);\n-    }\n-\n-    return start;\n-  }\n-\n-  \/\/----------------------------------------------------------------------------------------------------\n-\n-  address generate_vector_byte_perm_mask() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::vector_byte_perm_mask_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    __ emit_data(0x00000001, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000003, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000005, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000007, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000002, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000004, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000006, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-\n-    return start;\n-  }\n-\n-  address generate_vector_custom_i32(StubGenStubId stub_id, Assembler::AvxVectorLen len,\n-                                     int32_t val0, int32_t val1, int32_t val2, int32_t val3,\n-                                     int32_t val4 = 0, int32_t val5 = 0, int32_t val6 = 0, int32_t val7 = 0,\n-                                     int32_t val8 = 0, int32_t val9 = 0, int32_t val10 = 0, int32_t val11 = 0,\n-                                     int32_t val12 = 0, int32_t val13 = 0, int32_t val14 = 0, int32_t val15 = 0) {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    assert(len != Assembler::AVX_NoVec, \"vector len must be specified\");\n-    __ emit_data(val0, relocInfo::none, 0);\n-    __ emit_data(val1, relocInfo::none, 0);\n-    __ emit_data(val2, relocInfo::none, 0);\n-    __ emit_data(val3, relocInfo::none, 0);\n-    if (len >= Assembler::AVX_256bit) {\n-      __ emit_data(val4, relocInfo::none, 0);\n-      __ emit_data(val5, relocInfo::none, 0);\n-      __ emit_data(val6, relocInfo::none, 0);\n-      __ emit_data(val7, relocInfo::none, 0);\n-      if (len >= Assembler::AVX_512bit) {\n-        __ emit_data(val8, relocInfo::none, 0);\n-        __ emit_data(val9, relocInfo::none, 0);\n-        __ emit_data(val10, relocInfo::none, 0);\n-        __ emit_data(val11, relocInfo::none, 0);\n-        __ emit_data(val12, relocInfo::none, 0);\n-        __ emit_data(val13, relocInfo::none, 0);\n-        __ emit_data(val14, relocInfo::none, 0);\n-        __ emit_data(val15, relocInfo::none, 0);\n-      }\n-    }\n-\n-    return start;\n-  }\n-\n-  \/\/----------------------------------------------------------------------------------------------------\n-  \/\/ Non-destructive plausibility checks for oops\n-\n-  address generate_verify_oop() {\n-    StubGenStubId stub_id = StubGenStubId::verify_oop_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    \/\/ Incoming arguments on stack after saving rax,:\n-    \/\/\n-    \/\/ [tos    ]: saved rdx\n-    \/\/ [tos + 1]: saved EFLAGS\n-    \/\/ [tos + 2]: return address\n-    \/\/ [tos + 3]: char* error message\n-    \/\/ [tos + 4]: oop   object to verify\n-    \/\/ [tos + 5]: saved rax, - saved by caller and bashed\n-\n-    Label exit, error;\n-    __ pushf();\n-    __ incrementl(ExternalAddress((address) StubRoutines::verify_oop_count_addr()));\n-    __ push(rdx);                                \/\/ save rdx\n-    \/\/ make sure object is 'reasonable'\n-    __ movptr(rax, Address(rsp, 4 * wordSize));    \/\/ get object\n-    __ testptr(rax, rax);\n-    __ jcc(Assembler::zero, exit);               \/\/ if obj is null it is ok\n-\n-    \/\/ Check if the oop is in the right area of memory\n-    const int oop_mask = Universe::verify_oop_mask();\n-    const int oop_bits = Universe::verify_oop_bits();\n-    __ mov(rdx, rax);\n-    __ andptr(rdx, oop_mask);\n-    __ cmpptr(rdx, oop_bits);\n-    __ jcc(Assembler::notZero, error);\n-\n-    \/\/ make sure klass is 'reasonable', which is not zero.\n-    __ movptr(rax, Address(rax, oopDesc::klass_offset_in_bytes())); \/\/ get klass\n-    __ testptr(rax, rax);\n-    __ jcc(Assembler::zero, error);              \/\/ if klass is null it is broken\n-\n-    \/\/ return if everything seems ok\n-    __ bind(exit);\n-    __ movptr(rax, Address(rsp, 5 * wordSize));  \/\/ get saved rax, back\n-    __ pop(rdx);                                 \/\/ restore rdx\n-    __ popf();                                   \/\/ restore EFLAGS\n-    __ ret(3 * wordSize);                        \/\/ pop arguments\n-\n-    \/\/ handle errors\n-    __ bind(error);\n-    __ movptr(rax, Address(rsp, 5 * wordSize));  \/\/ get saved rax, back\n-    __ pop(rdx);                                 \/\/ get saved rdx back\n-    __ popf();                                   \/\/ get saved EFLAGS off stack -- will be ignored\n-    __ pusha();                                  \/\/ push registers (eip = return address & msg are already pushed)\n-    BLOCK_COMMENT(\"call MacroAssembler::debug\");\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug32)));\n-    __ hlt();\n-    return start;\n-  }\n-\n-\n-  \/\/ Copy 64 bytes chunks\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   from        - source array address\n-  \/\/   to_from     - destination array address - from\n-  \/\/   qword_count - 8-bytes element count, negative\n-  \/\/\n-  void xmm_copy_forward(Register from, Register to_from, Register qword_count) {\n-    assert( UseSSE >= 2, \"supported cpu only\" );\n-    Label L_copy_64_bytes_loop, L_copy_64_bytes, L_copy_8_bytes, L_exit;\n-\n-    \/\/ Copy 64-byte chunks\n-    __ jmpb(L_copy_64_bytes);\n-    __ align(OptoLoopAlignment);\n-  __ BIND(L_copy_64_bytes_loop);\n-\n-    if (UseUnalignedLoadStores) {\n-      if (UseAVX > 2) {\n-        __ evmovdqul(xmm0, Address(from, 0), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(from, to_from, Address::times_1, 0), xmm0, Assembler::AVX_512bit);\n-      } else if (UseAVX == 2) {\n-        __ vmovdqu(xmm0, Address(from,  0));\n-        __ vmovdqu(Address(from, to_from, Address::times_1,  0), xmm0);\n-        __ vmovdqu(xmm1, Address(from, 32));\n-        __ vmovdqu(Address(from, to_from, Address::times_1, 32), xmm1);\n-      } else {\n-        __ movdqu(xmm0, Address(from, 0));\n-        __ movdqu(Address(from, to_from, Address::times_1, 0), xmm0);\n-        __ movdqu(xmm1, Address(from, 16));\n-        __ movdqu(Address(from, to_from, Address::times_1, 16), xmm1);\n-        __ movdqu(xmm2, Address(from, 32));\n-        __ movdqu(Address(from, to_from, Address::times_1, 32), xmm2);\n-        __ movdqu(xmm3, Address(from, 48));\n-        __ movdqu(Address(from, to_from, Address::times_1, 48), xmm3);\n-      }\n-    } else {\n-      __ movq(xmm0, Address(from, 0));\n-      __ movq(Address(from, to_from, Address::times_1, 0), xmm0);\n-      __ movq(xmm1, Address(from, 8));\n-      __ movq(Address(from, to_from, Address::times_1, 8), xmm1);\n-      __ movq(xmm2, Address(from, 16));\n-      __ movq(Address(from, to_from, Address::times_1, 16), xmm2);\n-      __ movq(xmm3, Address(from, 24));\n-      __ movq(Address(from, to_from, Address::times_1, 24), xmm3);\n-      __ movq(xmm4, Address(from, 32));\n-      __ movq(Address(from, to_from, Address::times_1, 32), xmm4);\n-      __ movq(xmm5, Address(from, 40));\n-      __ movq(Address(from, to_from, Address::times_1, 40), xmm5);\n-      __ movq(xmm6, Address(from, 48));\n-      __ movq(Address(from, to_from, Address::times_1, 48), xmm6);\n-      __ movq(xmm7, Address(from, 56));\n-      __ movq(Address(from, to_from, Address::times_1, 56), xmm7);\n-    }\n-\n-    __ addl(from, 64);\n-  __ BIND(L_copy_64_bytes);\n-    __ subl(qword_count, 8);\n-    __ jcc(Assembler::greaterEqual, L_copy_64_bytes_loop);\n-\n-    if (UseUnalignedLoadStores && (UseAVX == 2)) {\n-      \/\/ clean upper bits of YMM registers\n-      __ vpxor(xmm0, xmm0);\n-      __ vpxor(xmm1, xmm1);\n-    }\n-    __ addl(qword_count, 8);\n-    __ jccb(Assembler::zero, L_exit);\n-    \/\/\n-    \/\/ length is too short, just copy qwords\n-    \/\/\n-  __ BIND(L_copy_8_bytes);\n-    __ movq(xmm0, Address(from, 0));\n-    __ movq(Address(from, to_from, Address::times_1), xmm0);\n-    __ addl(from, 8);\n-    __ decrement(qword_count);\n-    __ jcc(Assembler::greater, L_copy_8_bytes);\n-  __ BIND(L_exit);\n-  }\n-\n-  address generate_disjoint_copy(StubGenStubId stub_id, address* entry) {\n-    BasicType t;\n-    bool aligned;\n-    Address::ScaleFactor sf;\n-    bool dest_uninitialized;\n-\n-    switch (stub_id) {\n-    case jbyte_disjoint_arraycopy_id:\n-      t = T_BYTE;\n-      aligned = false;\n-      sf = Address::times_1;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jbyte_disjoint_arraycopy_id:\n-      t = T_BYTE;\n-      aligned = true;\n-      sf = Address::times_1;\n-      dest_uninitialized = false;\n-      break;\n-    case jshort_disjoint_arraycopy_id:\n-      t = T_SHORT;\n-      aligned = false;\n-      sf = Address::times_2;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jshort_disjoint_arraycopy_id:\n-      t = T_SHORT;\n-      aligned = true;\n-      sf = Address::times_2;\n-      dest_uninitialized = false;\n-      break;\n-    case jint_disjoint_arraycopy_id:\n-      t = T_INT;\n-      aligned = true;\n-      sf = Address::times_4;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jint_disjoint_arraycopy_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case jint_disjoint_arraycopy\n-      ShouldNotReachHere();\n-      break;\n-    case jlong_disjoint_arraycopy_id:\n-    case arrayof_jlong_disjoint_arraycopy_id:\n-      \/\/ Handled by a special generator routine on 32 bit\n-      ShouldNotReachHere();\n-      break;\n-    case oop_disjoint_arraycopy_id:\n-      t = T_OBJECT;\n-      aligned = true;\n-      sf = Address::times_ptr;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_oop_disjoint_arraycopy_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case oop_disjoint_arraycopy\n-      ShouldNotReachHere();\n-      break;\n-    case oop_disjoint_arraycopy_uninit_id:\n-      t = T_OBJECT;\n-      aligned = true;\n-      sf = Address::times_ptr;\n-      dest_uninitialized = true;\n-      break;\n-    case arrayof_oop_disjoint_arraycopy_uninit_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case oop_disjoint_arraycopy_uninit\n-      ShouldNotReachHere();\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_0_count, L_exit, L_skip_align1, L_skip_align2, L_copy_byte;\n-    Label L_copy_2_bytes, L_copy_4_bytes, L_copy_64_bytes;\n-\n-    int shift = Address::times_ptr - sf;\n-\n-    const Register from     = rsi;  \/\/ source array address\n-    const Register to       = rdi;  \/\/ destination array address\n-    const Register count    = rcx;  \/\/ elements count\n-    const Register to_from  = to;   \/\/ (to - from)\n-    const Register saved_to = rdx;  \/\/ saved destination array address\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ movptr(from , Address(rsp, 12+ 4));\n-    __ movptr(to   , Address(rsp, 12+ 8));\n-    __ movl(count, Address(rsp, 12+ 12));\n-\n-    if (entry != nullptr) {\n-      *entry = __ pc(); \/\/ Entry point from conjoint arraycopy stub.\n-      BLOCK_COMMENT(\"Entry:\");\n-    }\n-\n-    if (t == T_OBJECT) {\n-      __ testl(count, count);\n-      __ jcc(Assembler::zero, L_0_count);\n-    }\n-\n-    DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;\n-    if (dest_uninitialized) {\n-      decorators |= IS_DEST_UNINITIALIZED;\n-    }\n-    if (aligned) {\n-      decorators |= ARRAYCOPY_ALIGNED;\n-    }\n-\n-    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    bs->arraycopy_prologue(_masm, decorators, t, from, to, count);\n-    {\n-      bool add_entry = (t != T_OBJECT && (!aligned || t == T_INT));\n-      \/\/ UnsafeMemoryAccess page error: continue after unsafe access\n-      UnsafeMemoryAccessMark umam(this, add_entry, true);\n-      __ subptr(to, from); \/\/ to --> to_from\n-      __ cmpl(count, 2<<shift); \/\/ Short arrays (< 8 bytes) copy by element\n-      __ jcc(Assembler::below, L_copy_4_bytes); \/\/ use unsigned cmp\n-      if (!UseUnalignedLoadStores && !aligned && (t == T_BYTE || t == T_SHORT)) {\n-        \/\/ align source address at 4 bytes address boundary\n-        if (t == T_BYTE) {\n-          \/\/ One byte misalignment happens only for byte arrays\n-          __ testl(from, 1);\n-          __ jccb(Assembler::zero, L_skip_align1);\n-          __ movb(rax, Address(from, 0));\n-          __ movb(Address(from, to_from, Address::times_1, 0), rax);\n-          __ increment(from);\n-          __ decrement(count);\n-        __ BIND(L_skip_align1);\n-        }\n-        \/\/ Two bytes misalignment happens only for byte and short (char) arrays\n-        __ testl(from, 2);\n-        __ jccb(Assembler::zero, L_skip_align2);\n-        __ movw(rax, Address(from, 0));\n-        __ movw(Address(from, to_from, Address::times_1, 0), rax);\n-        __ addptr(from, 2);\n-        __ subl(count, 1<<(shift-1));\n-      __ BIND(L_skip_align2);\n-      }\n-      if (!UseXMMForArrayCopy) {\n-        __ mov(rax, count);      \/\/ save 'count'\n-        __ shrl(count, shift); \/\/ bytes count\n-        __ addptr(to_from, from);\/\/ restore 'to'\n-        __ rep_mov();\n-        __ subptr(to_from, from);\/\/ restore 'to_from'\n-        __ mov(count, rax);      \/\/ restore 'count'\n-        __ jmpb(L_copy_2_bytes); \/\/ all dwords were copied\n-      } else {\n-        if (!UseUnalignedLoadStores) {\n-          \/\/ align to 8 bytes, we know we are 4 byte aligned to start\n-          __ testptr(from, 4);\n-          __ jccb(Assembler::zero, L_copy_64_bytes);\n-          __ movl(rax, Address(from, 0));\n-          __ movl(Address(from, to_from, Address::times_1, 0), rax);\n-          __ addptr(from, 4);\n-          __ subl(count, 1<<shift);\n-        }\n-      __ BIND(L_copy_64_bytes);\n-        __ mov(rax, count);\n-        __ shrl(rax, shift+1);  \/\/ 8 bytes chunk count\n-        \/\/\n-        \/\/ Copy 8-byte chunks through XMM registers, 8 per iteration of the loop\n-        \/\/\n-        xmm_copy_forward(from, to_from, rax);\n-      }\n-      \/\/ copy tailing dword\n-    __ BIND(L_copy_4_bytes);\n-      __ testl(count, 1<<shift);\n-      __ jccb(Assembler::zero, L_copy_2_bytes);\n-      __ movl(rax, Address(from, 0));\n-      __ movl(Address(from, to_from, Address::times_1, 0), rax);\n-      if (t == T_BYTE || t == T_SHORT) {\n-        __ addptr(from, 4);\n-      __ BIND(L_copy_2_bytes);\n-        \/\/ copy tailing word\n-        __ testl(count, 1<<(shift-1));\n-        __ jccb(Assembler::zero, L_copy_byte);\n-        __ movw(rax, Address(from, 0));\n-        __ movw(Address(from, to_from, Address::times_1, 0), rax);\n-        if (t == T_BYTE) {\n-          __ addptr(from, 2);\n-        __ BIND(L_copy_byte);\n-          \/\/ copy tailing byte\n-          __ testl(count, 1);\n-          __ jccb(Assembler::zero, L_exit);\n-          __ movb(rax, Address(from, 0));\n-          __ movb(Address(from, to_from, Address::times_1, 0), rax);\n-        __ BIND(L_exit);\n-        } else {\n-        __ BIND(L_copy_byte);\n-        }\n-      } else {\n-      __ BIND(L_copy_2_bytes);\n-      }\n-    }\n-\n-    __ movl(count, Address(rsp, 12+12)); \/\/ reread 'count'\n-    bs->arraycopy_epilogue(_masm, decorators, t, from, to, count);\n-\n-    if (t == T_OBJECT) {\n-    __ BIND(L_0_count);\n-    }\n-    inc_copy_counter_np(t);\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ vzeroupper();\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ ret(0);\n-    return start;\n-  }\n-\n-\n-  address generate_fill(StubGenStubId stub_id) {\n-    BasicType t;\n-    bool aligned;\n-    switch(stub_id) {\n-    case jbyte_fill_id:\n-      t = T_BYTE;\n-      aligned = false;\n-      break;\n-    case jshort_fill_id:\n-      t = T_SHORT;\n-      aligned = false;\n-      break;\n-    case jint_fill_id:\n-      t = T_INT;\n-      aligned = false;\n-      break;\n-    case arrayof_jbyte_fill_id:\n-      t = T_BYTE;\n-      aligned = true;\n-      break;\n-    case arrayof_jshort_fill_id:\n-      t = T_SHORT;\n-      aligned = true;\n-      break;\n-    case arrayof_jint_fill_id:\n-      t = T_INT;\n-      aligned = true;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-\n-    const Register to       = rdi;  \/\/ source array address\n-    const Register value    = rdx;  \/\/ value\n-    const Register count    = rsi;  \/\/ elements count\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ movptr(to   , Address(rsp, 12+ 4));\n-    __ movl(value, Address(rsp, 12+ 8));\n-    __ movl(count, Address(rsp, 12+ 12));\n-\n-    __ generate_fill(t, aligned, to, value, count, rax, xmm0);\n-\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  address generate_conjoint_copy(StubGenStubId stub_id,\n-                                 address nooverlap_target,\n-                                 address* entry) {\n-    BasicType t;\n-    bool aligned;\n-    Address::ScaleFactor sf;\n-    bool dest_uninitialized;\n-\n-    switch (stub_id) {\n-    case jbyte_arraycopy_id:\n-      t = T_BYTE;\n-      aligned = false;\n-      sf = Address::times_1;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jbyte_arraycopy_id:\n-      t = T_BYTE;\n-      aligned = true;\n-      sf = Address::times_1;\n-      dest_uninitialized = false;\n-      break;\n-    case jshort_arraycopy_id:\n-      t = T_SHORT;\n-      aligned = false;\n-      sf = Address::times_2;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jshort_arraycopy_id:\n-      t = T_SHORT;\n-      aligned = true;\n-      sf = Address::times_2;\n-      dest_uninitialized = false;\n-      break;\n-    case jint_arraycopy_id:\n-      t = T_INT;\n-      aligned = true;\n-      sf = Address::times_4;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_jint_arraycopy_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case jint_arraycopy\n-      ShouldNotReachHere();\n-      break;\n-    case jlong_arraycopy_id:\n-    case arrayof_jlong_arraycopy_id:\n-      \/\/ Handled by a special generator routine on 32 bit\n-      ShouldNotReachHere();\n-      break;\n-    case oop_arraycopy_id:\n-      t = T_OBJECT;\n-      aligned = true;\n-      sf = Address::times_ptr;\n-      dest_uninitialized = false;\n-      break;\n-    case arrayof_oop_arraycopy_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case oop_arraycopy\n-      ShouldNotReachHere();\n-      break;\n-    case oop_arraycopy_uninit_id:\n-      t = T_OBJECT;\n-      aligned = true;\n-      sf = Address::times_ptr;\n-      dest_uninitialized = true;\n-      break;\n-    case arrayof_oop_arraycopy_uninit_id:\n-      \/\/ since this is always aligned we can (should!) use the same\n-      \/\/ stub as for case oop_arraycopy_uninit\n-      ShouldNotReachHere();\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_0_count, L_exit, L_skip_align1, L_skip_align2, L_copy_byte;\n-    Label L_copy_2_bytes, L_copy_4_bytes, L_copy_8_bytes, L_copy_8_bytes_loop;\n-\n-    int shift = Address::times_ptr - sf;\n-\n-    const Register src   = rax;  \/\/ source array address\n-    const Register dst   = rdx;  \/\/ destination array address\n-    const Register from  = rsi;  \/\/ source array address\n-    const Register to    = rdi;  \/\/ destination array address\n-    const Register count = rcx;  \/\/ elements count\n-    const Register end   = rax;  \/\/ array end address\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ movptr(src  , Address(rsp, 12+ 4));   \/\/ from\n-    __ movptr(dst  , Address(rsp, 12+ 8));   \/\/ to\n-    __ movl2ptr(count, Address(rsp, 12+12)); \/\/ count\n-\n-    if (entry != nullptr) {\n-      *entry = __ pc(); \/\/ Entry point from generic arraycopy stub.\n-      BLOCK_COMMENT(\"Entry:\");\n-    }\n-\n-    \/\/ nooverlap_target expects arguments in rsi and rdi.\n-    __ mov(from, src);\n-    __ mov(to  , dst);\n-\n-    \/\/ arrays overlap test: dispatch to disjoint stub if necessary.\n-    RuntimeAddress nooverlap(nooverlap_target);\n-    __ cmpptr(dst, src);\n-    __ lea(end, Address(src, count, sf, 0)); \/\/ src + count * elem_size\n-    __ jump_cc(Assembler::belowEqual, nooverlap);\n-    __ cmpptr(dst, end);\n-    __ jump_cc(Assembler::aboveEqual, nooverlap);\n-\n-    if (t == T_OBJECT) {\n-      __ testl(count, count);\n-      __ jcc(Assembler::zero, L_0_count);\n-    }\n-\n-    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n-    if (dest_uninitialized) {\n-      decorators |= IS_DEST_UNINITIALIZED;\n-    }\n-    if (aligned) {\n-      decorators |= ARRAYCOPY_ALIGNED;\n-    }\n-\n-    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    bs->arraycopy_prologue(_masm, decorators, t, from, to, count);\n-\n-    {\n-      bool add_entry = (t != T_OBJECT && (!aligned || t == T_INT));\n-      \/\/ UnsafeMemoryAccess page error: continue after unsafe access\n-      UnsafeMemoryAccessMark umam(this, add_entry, true);\n-      \/\/ copy from high to low\n-      __ cmpl(count, 2<<shift); \/\/ Short arrays (< 8 bytes) copy by element\n-      __ jcc(Assembler::below, L_copy_4_bytes); \/\/ use unsigned cmp\n-      if (t == T_BYTE || t == T_SHORT) {\n-        \/\/ Align the end of destination array at 4 bytes address boundary\n-        __ lea(end, Address(dst, count, sf, 0));\n-        if (t == T_BYTE) {\n-          \/\/ One byte misalignment happens only for byte arrays\n-          __ testl(end, 1);\n-          __ jccb(Assembler::zero, L_skip_align1);\n-          __ decrement(count);\n-          __ movb(rdx, Address(from, count, sf, 0));\n-          __ movb(Address(to, count, sf, 0), rdx);\n-        __ BIND(L_skip_align1);\n-        }\n-        \/\/ Two bytes misalignment happens only for byte and short (char) arrays\n-        __ testl(end, 2);\n-        __ jccb(Assembler::zero, L_skip_align2);\n-        __ subptr(count, 1<<(shift-1));\n-        __ movw(rdx, Address(from, count, sf, 0));\n-        __ movw(Address(to, count, sf, 0), rdx);\n-      __ BIND(L_skip_align2);\n-        __ cmpl(count, 2<<shift); \/\/ Short arrays (< 8 bytes) copy by element\n-        __ jcc(Assembler::below, L_copy_4_bytes);\n-      }\n-\n-      if (!UseXMMForArrayCopy) {\n-        __ std();\n-        __ mov(rax, count); \/\/ Save 'count'\n-        __ mov(rdx, to);    \/\/ Save 'to'\n-        __ lea(rsi, Address(from, count, sf, -4));\n-        __ lea(rdi, Address(to  , count, sf, -4));\n-        __ shrptr(count, shift); \/\/ bytes count\n-        __ rep_mov();\n-        __ cld();\n-        __ mov(count, rax); \/\/ restore 'count'\n-        __ andl(count, (1<<shift)-1);      \/\/ mask the number of rest elements\n-        __ movptr(from, Address(rsp, 12+4)); \/\/ reread 'from'\n-        __ mov(to, rdx);   \/\/ restore 'to'\n-        __ jmpb(L_copy_2_bytes); \/\/ all dword were copied\n-      } else {\n-        \/\/ Align to 8 bytes the end of array. It is aligned to 4 bytes already.\n-        __ testptr(end, 4);\n-        __ jccb(Assembler::zero, L_copy_8_bytes);\n-        __ subl(count, 1<<shift);\n-        __ movl(rdx, Address(from, count, sf, 0));\n-        __ movl(Address(to, count, sf, 0), rdx);\n-        __ jmpb(L_copy_8_bytes);\n-\n-        __ align(OptoLoopAlignment);\n-        \/\/ Move 8 bytes\n-      __ BIND(L_copy_8_bytes_loop);\n-        __ movq(xmm0, Address(from, count, sf, 0));\n-        __ movq(Address(to, count, sf, 0), xmm0);\n-      __ BIND(L_copy_8_bytes);\n-        __ subl(count, 2<<shift);\n-        __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);\n-        __ addl(count, 2<<shift);\n-      }\n-    __ BIND(L_copy_4_bytes);\n-      \/\/ copy prefix qword\n-      __ testl(count, 1<<shift);\n-      __ jccb(Assembler::zero, L_copy_2_bytes);\n-      __ movl(rdx, Address(from, count, sf, -4));\n-      __ movl(Address(to, count, sf, -4), rdx);\n-\n-      if (t == T_BYTE || t == T_SHORT) {\n-          __ subl(count, (1<<shift));\n-        __ BIND(L_copy_2_bytes);\n-          \/\/ copy prefix dword\n-          __ testl(count, 1<<(shift-1));\n-          __ jccb(Assembler::zero, L_copy_byte);\n-          __ movw(rdx, Address(from, count, sf, -2));\n-          __ movw(Address(to, count, sf, -2), rdx);\n-          if (t == T_BYTE) {\n-            __ subl(count, 1<<(shift-1));\n-          __ BIND(L_copy_byte);\n-            \/\/ copy prefix byte\n-            __ testl(count, 1);\n-            __ jccb(Assembler::zero, L_exit);\n-            __ movb(rdx, Address(from, 0));\n-            __ movb(Address(to, 0), rdx);\n-          __ BIND(L_exit);\n-          } else {\n-          __ BIND(L_copy_byte);\n-          }\n-      } else {\n-      __ BIND(L_copy_2_bytes);\n-      }\n-    }\n-\n-    __ movl2ptr(count, Address(rsp, 12+12)); \/\/ reread count\n-    bs->arraycopy_epilogue(_masm, decorators, t, from, to, count);\n-\n-    if (t == T_OBJECT) {\n-    __ BIND(L_0_count);\n-    }\n-    inc_copy_counter_np(t);\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ ret(0);\n-    return start;\n-  }\n-\n-\n-  address generate_disjoint_long_copy(address* entry) {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::jlong_disjoint_arraycopy_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_copy_8_bytes, L_copy_8_bytes_loop;\n-    const Register from       = rax;  \/\/ source array address\n-    const Register to         = rdx;  \/\/ destination array address\n-    const Register count      = rcx;  \/\/ elements count\n-    const Register to_from    = rdx;  \/\/ (to - from)\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ movptr(from , Address(rsp, 8+0));       \/\/ from\n-    __ movptr(to   , Address(rsp, 8+4));       \/\/ to\n-    __ movl2ptr(count, Address(rsp, 8+8));     \/\/ count\n-\n-    *entry = __ pc(); \/\/ Entry point from conjoint arraycopy stub.\n-    BLOCK_COMMENT(\"Entry:\");\n-\n-    {\n-      \/\/ UnsafeMemoryAccess page error: continue after unsafe access\n-      UnsafeMemoryAccessMark umam(this, true, true);\n-      __ subptr(to, from); \/\/ to --> to_from\n-      if (UseXMMForArrayCopy) {\n-        xmm_copy_forward(from, to_from, count);\n-      } else {\n-        __ jmpb(L_copy_8_bytes);\n-        __ align(OptoLoopAlignment);\n-      __ BIND(L_copy_8_bytes_loop);\n-        __ fild_d(Address(from, 0));\n-        __ fistp_d(Address(from, to_from, Address::times_1));\n-        __ addptr(from, 8);\n-      __ BIND(L_copy_8_bytes);\n-        __ decrement(count);\n-        __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);\n-      }\n-    }\n-    inc_copy_counter_np(T_LONG);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ vzeroupper();\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  address generate_conjoint_long_copy(address nooverlap_target, address* entry) {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::jlong_arraycopy_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_copy_8_bytes, L_copy_8_bytes_loop;\n-    const Register from       = rax;  \/\/ source array address\n-    const Register to         = rdx;  \/\/ destination array address\n-    const Register count      = rcx;  \/\/ elements count\n-    const Register end_from   = rax;  \/\/ source array end address\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ movptr(from , Address(rsp, 8+0));       \/\/ from\n-    __ movptr(to   , Address(rsp, 8+4));       \/\/ to\n-    __ movl2ptr(count, Address(rsp, 8+8));     \/\/ count\n-\n-    *entry = __ pc(); \/\/ Entry point from generic arraycopy stub.\n-    BLOCK_COMMENT(\"Entry:\");\n-\n-    \/\/ arrays overlap test\n-    __ cmpptr(to, from);\n-    RuntimeAddress nooverlap(nooverlap_target);\n-    __ jump_cc(Assembler::belowEqual, nooverlap);\n-    __ lea(end_from, Address(from, count, Address::times_8, 0));\n-    __ cmpptr(to, end_from);\n-    __ movptr(from, Address(rsp, 8));  \/\/ from\n-    __ jump_cc(Assembler::aboveEqual, nooverlap);\n-\n-    {\n-      \/\/ UnsafeMemoryAccess page error: continue after unsafe access\n-      UnsafeMemoryAccessMark umam(this, true, true);\n-\n-      __ jmpb(L_copy_8_bytes);\n-\n-      __ align(OptoLoopAlignment);\n-    __ BIND(L_copy_8_bytes_loop);\n-      if (UseXMMForArrayCopy) {\n-        __ movq(xmm0, Address(from, count, Address::times_8));\n-        __ movq(Address(to, count, Address::times_8), xmm0);\n-      } else {\n-        __ fild_d(Address(from, count, Address::times_8));\n-        __ fistp_d(Address(to, count, Address::times_8));\n-      }\n-    __ BIND(L_copy_8_bytes);\n-      __ decrement(count);\n-      __ jcc(Assembler::greaterEqual, L_copy_8_bytes_loop);\n-\n-    }\n-    inc_copy_counter_np(T_LONG);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ ret(0);\n-    return start;\n-  }\n-\n-\n-  \/\/ Helper for generating a dynamic type check.\n-  \/\/ The sub_klass must be one of {rbx, rdx, rsi}.\n-  \/\/ The temp is killed.\n-  void generate_type_check(Register sub_klass,\n-                           Address& super_check_offset_addr,\n-                           Address& super_klass_addr,\n-                           Register temp,\n-                           Label* L_success, Label* L_failure) {\n-    BLOCK_COMMENT(\"type_check:\");\n-\n-    Label L_fallthrough;\n-#define LOCAL_JCC(assembler_con, label_ptr)                             \\\n-    if (label_ptr != nullptr)  __ jcc(assembler_con, *(label_ptr));        \\\n-    else                    __ jcc(assembler_con, L_fallthrough) \/*omit semi*\/\n-\n-    \/\/ The following is a strange variation of the fast path which requires\n-    \/\/ one less register, because needed values are on the argument stack.\n-    \/\/ __ check_klass_subtype_fast_path(sub_klass, *super_klass*, temp,\n-    \/\/                                  L_success, L_failure, null);\n-    assert_different_registers(sub_klass, temp);\n-\n-    int sc_offset = in_bytes(Klass::secondary_super_cache_offset());\n-\n-    \/\/ if the pointers are equal, we are done (e.g., String[] elements)\n-    __ cmpptr(sub_klass, super_klass_addr);\n-    LOCAL_JCC(Assembler::equal, L_success);\n-\n-    \/\/ check the supertype display:\n-    __ movl2ptr(temp, super_check_offset_addr);\n-    Address super_check_addr(sub_klass, temp, Address::times_1, 0);\n-    __ movptr(temp, super_check_addr); \/\/ load displayed supertype\n-    __ cmpptr(temp, super_klass_addr); \/\/ test the super type\n-    LOCAL_JCC(Assembler::equal, L_success);\n-\n-    \/\/ if it was a primary super, we can just fail immediately\n-    __ cmpl(super_check_offset_addr, sc_offset);\n-    LOCAL_JCC(Assembler::notEqual, L_failure);\n-\n-    \/\/ The repne_scan instruction uses fixed registers, which will get spilled.\n-    \/\/ We happen to know this works best when super_klass is in rax.\n-    Register super_klass = temp;\n-    __ movptr(super_klass, super_klass_addr);\n-    __ check_klass_subtype_slow_path(sub_klass, super_klass, noreg, noreg,\n-                                     L_success, L_failure);\n-\n-    __ bind(L_fallthrough);\n-\n-    if (L_success == nullptr) { BLOCK_COMMENT(\"L_success:\"); }\n-    if (L_failure == nullptr) { BLOCK_COMMENT(\"L_failure:\"); }\n-\n-#undef LOCAL_JCC\n-  }\n-\n-  \/\/\n-  \/\/  Generate checkcasting array copy stub\n-  \/\/\n-  \/\/  Input:\n-  \/\/    4(rsp)   - source array address\n-  \/\/    8(rsp)   - destination array address\n-  \/\/   12(rsp)   - element count, can be zero\n-  \/\/   16(rsp)   - size_t ckoff (super_check_offset)\n-  \/\/   20(rsp)   - oop ckval (super_klass)\n-  \/\/\n-  \/\/  Output:\n-  \/\/    rax, ==  0  -  success\n-  \/\/    rax, == -1^K - failure, where K is partial transfer count\n-  \/\/\n-  address generate_checkcast_copy(StubGenStubId stub_id, address* entry) {\n-    bool dest_uninitialized;\n-    switch(stub_id) {\n-    case checkcast_arraycopy_id:\n-      dest_uninitialized = false;\n-      break;\n-    case checkcast_arraycopy_uninit_id:\n-      dest_uninitialized = true;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_load_element, L_store_element, L_do_card_marks, L_done;\n-\n-    \/\/ register use:\n-    \/\/  rax, rdx, rcx -- loop control (end_from, end_to, count)\n-    \/\/  rdi, rsi      -- element access (oop, klass)\n-    \/\/  rbx,           -- temp\n-    const Register from       = rax;    \/\/ source array address\n-    const Register to         = rdx;    \/\/ destination array address\n-    const Register length     = rcx;    \/\/ elements count\n-    const Register elem       = rdi;    \/\/ each oop copied\n-    const Register elem_klass = rsi;    \/\/ each elem._klass (sub_klass)\n-    const Register temp       = rbx;    \/\/ lone remaining temp\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ push(rbx);\n-\n-    Address   from_arg(rsp, 16+ 4);     \/\/ from\n-    Address     to_arg(rsp, 16+ 8);     \/\/ to\n-    Address length_arg(rsp, 16+12);     \/\/ elements count\n-    Address  ckoff_arg(rsp, 16+16);     \/\/ super_check_offset\n-    Address  ckval_arg(rsp, 16+20);     \/\/ super_klass\n-\n-    \/\/ Load up:\n-    __ movptr(from,     from_arg);\n-    __ movptr(to,         to_arg);\n-    __ movl2ptr(length, length_arg);\n-\n-    if (entry != nullptr) {\n-      *entry = __ pc(); \/\/ Entry point from generic arraycopy stub.\n-      BLOCK_COMMENT(\"Entry:\");\n-    }\n-\n-    \/\/---------------------------------------------------------------\n-    \/\/ Assembler stub will be used for this call to arraycopy\n-    \/\/ if the two arrays are subtypes of Object[] but the\n-    \/\/ destination array type is not equal to or a supertype\n-    \/\/ of the source type.  Each element must be separately\n-    \/\/ checked.\n-\n-    \/\/ Loop-invariant addresses.  They are exclusive end pointers.\n-    Address end_from_addr(from, length, Address::times_ptr, 0);\n-    Address   end_to_addr(to,   length, Address::times_ptr, 0);\n-\n-    Register end_from = from;           \/\/ re-use\n-    Register end_to   = to;             \/\/ re-use\n-    Register count    = length;         \/\/ re-use\n-\n-    \/\/ Loop-variant addresses.  They assume post-incremented count < 0.\n-    Address from_element_addr(end_from, count, Address::times_ptr, 0);\n-    Address   to_element_addr(end_to,   count, Address::times_ptr, 0);\n-    Address elem_klass_addr(elem, oopDesc::klass_offset_in_bytes());\n-\n-    DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_CHECKCAST;\n-    if (dest_uninitialized) {\n-      decorators |= IS_DEST_UNINITIALIZED;\n-    }\n-\n-    BasicType type = T_OBJECT;\n-    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n-\n-    \/\/ Copy from low to high addresses, indexed from the end of each array.\n-    __ lea(end_from, end_from_addr);\n-    __ lea(end_to,   end_to_addr);\n-    assert(length == count, \"\");        \/\/ else fix next line:\n-    __ negptr(count);                   \/\/ negate and test the length\n-    __ jccb(Assembler::notZero, L_load_element);\n-\n-    \/\/ Empty array:  Nothing to do.\n-    __ xorptr(rax, rax);                  \/\/ return 0 on (trivial) success\n-    __ jmp(L_done);\n-\n-    \/\/ ======== begin loop ========\n-    \/\/ (Loop is rotated; its entry is L_load_element.)\n-    \/\/ Loop control:\n-    \/\/   for (count = -count; count != 0; count++)\n-    \/\/ Base pointers src, dst are biased by 8*count,to last element.\n-    __ align(OptoLoopAlignment);\n-\n-    __ BIND(L_store_element);\n-    __ movptr(to_element_addr, elem);     \/\/ store the oop\n-    __ increment(count);                \/\/ increment the count toward zero\n-    __ jccb(Assembler::zero, L_do_card_marks);\n-\n-    \/\/ ======== loop entry is here ========\n-    __ BIND(L_load_element);\n-    __ movptr(elem, from_element_addr);   \/\/ load the oop\n-    __ testptr(elem, elem);\n-    __ jccb(Assembler::zero, L_store_element);\n-\n-    \/\/ (Could do a trick here:  Remember last successful non-null\n-    \/\/ element stored and make a quick oop equality check on it.)\n-\n-    __ movptr(elem_klass, elem_klass_addr); \/\/ query the object klass\n-    generate_type_check(elem_klass, ckoff_arg, ckval_arg, temp,\n-                        &L_store_element, nullptr);\n-    \/\/ (On fall-through, we have failed the element type check.)\n-    \/\/ ======== end loop ========\n-\n-    \/\/ It was a real error; we must depend on the caller to finish the job.\n-    \/\/ Register \"count\" = -1 * number of *remaining* oops, length_arg = *total* oops.\n-    \/\/ Emit GC store barriers for the oops we have copied (length_arg + count),\n-    \/\/ and report their number to the caller.\n-    assert_different_registers(to, count, rax);\n-    Label L_post_barrier;\n-    __ addl(count, length_arg);         \/\/ transfers = (length - remaining)\n-    __ movl2ptr(rax, count);            \/\/ save the value\n-    __ notptr(rax);                     \/\/ report (-1^K) to caller (does not affect flags)\n-    __ jccb(Assembler::notZero, L_post_barrier);\n-    __ jmp(L_done); \/\/ K == 0, nothing was copied, skip post barrier\n-\n-    \/\/ Come here on success only.\n-    __ BIND(L_do_card_marks);\n-    __ xorptr(rax, rax);                \/\/ return 0 on success\n-    __ movl2ptr(count, length_arg);\n-\n-    __ BIND(L_post_barrier);\n-    __ movptr(to, to_arg);              \/\/ reload\n-    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n-\n-    \/\/ Common exit point (success or failure).\n-    __ BIND(L_done);\n-    __ pop(rbx);\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    inc_counter_np(SharedRuntime::_checkcast_array_copy_ctr);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-  \/\/\n-  \/\/  Generate 'unsafe' array copy stub\n-  \/\/  Though just as safe as the other stubs, it takes an unscaled\n-  \/\/  size_t argument instead of an element count.\n-  \/\/\n-  \/\/  Input:\n-  \/\/    4(rsp)   - source array address\n-  \/\/    8(rsp)   - destination array address\n-  \/\/   12(rsp)   - byte count, can be zero\n-  \/\/\n-  \/\/  Output:\n-  \/\/    rax, ==  0  -  success\n-  \/\/    rax, == -1  -  need to call System.arraycopy\n-  \/\/\n-  \/\/ Examines the alignment of the operands and dispatches\n-  \/\/ to a long, int, short, or byte copy loop.\n-  \/\/\n-  address generate_unsafe_copy(address byte_copy_entry,\n-                               address short_copy_entry,\n-                               address int_copy_entry,\n-                               address long_copy_entry) {\n-\n-    Label L_long_aligned, L_int_aligned, L_short_aligned;\n-\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::unsafe_arraycopy_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    const Register from       = rax;  \/\/ source array address\n-    const Register to         = rdx;  \/\/ destination array address\n-    const Register count      = rcx;  \/\/ elements count\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-    Address  from_arg(rsp, 12+ 4);      \/\/ from\n-    Address    to_arg(rsp, 12+ 8);      \/\/ to\n-    Address count_arg(rsp, 12+12);      \/\/ byte count\n-\n-    \/\/ Load up:\n-    __ movptr(from ,  from_arg);\n-    __ movptr(to   ,    to_arg);\n-    __ movl2ptr(count, count_arg);\n-\n-    \/\/ bump this on entry, not on exit:\n-    inc_counter_np(SharedRuntime::_unsafe_array_copy_ctr);\n-\n-    const Register bits = rsi;\n-    __ mov(bits, from);\n-    __ orptr(bits, to);\n-    __ orptr(bits, count);\n-\n-    __ testl(bits, BytesPerLong-1);\n-    __ jccb(Assembler::zero, L_long_aligned);\n-\n-    __ testl(bits, BytesPerInt-1);\n-    __ jccb(Assembler::zero, L_int_aligned);\n-\n-    __ testl(bits, BytesPerShort-1);\n-    __ jump_cc(Assembler::notZero, RuntimeAddress(byte_copy_entry));\n-\n-    __ BIND(L_short_aligned);\n-    __ shrptr(count, LogBytesPerShort); \/\/ size => short_count\n-    __ movl(count_arg, count);          \/\/ update 'count'\n-    __ jump(RuntimeAddress(short_copy_entry));\n-\n-    __ BIND(L_int_aligned);\n-    __ shrptr(count, LogBytesPerInt); \/\/ size => int_count\n-    __ movl(count_arg, count);          \/\/ update 'count'\n-    __ jump(RuntimeAddress(int_copy_entry));\n-\n-    __ BIND(L_long_aligned);\n-    __ shrptr(count, LogBytesPerLong); \/\/ size => qword_count\n-    __ movl(count_arg, count);          \/\/ update 'count'\n-    __ pop(rdi); \/\/ Do pops here since jlong_arraycopy stub does not do it.\n-    __ pop(rsi);\n-    __ jump(RuntimeAddress(long_copy_entry));\n-\n-    return start;\n-  }\n-\n-\n-  \/\/ Perform range checks on the proposed arraycopy.\n-  \/\/ Smashes src_pos and dst_pos.  (Uses them up for temps.)\n-  void arraycopy_range_checks(Register src,\n-                              Register src_pos,\n-                              Register dst,\n-                              Register dst_pos,\n-                              Address& length,\n-                              Label& L_failed) {\n-    BLOCK_COMMENT(\"arraycopy_range_checks:\");\n-    const Register src_end = src_pos;   \/\/ source array end position\n-    const Register dst_end = dst_pos;   \/\/ destination array end position\n-    __ addl(src_end, length); \/\/ src_pos + length\n-    __ addl(dst_end, length); \/\/ dst_pos + length\n-\n-    \/\/  if (src_pos + length > arrayOop(src)->length() ) FAIL;\n-    __ cmpl(src_end, Address(src, arrayOopDesc::length_offset_in_bytes()));\n-    __ jcc(Assembler::above, L_failed);\n-\n-    \/\/  if (dst_pos + length > arrayOop(dst)->length() ) FAIL;\n-    __ cmpl(dst_end, Address(dst, arrayOopDesc::length_offset_in_bytes()));\n-    __ jcc(Assembler::above, L_failed);\n-\n-    BLOCK_COMMENT(\"arraycopy_range_checks done\");\n-  }\n-\n-\n-  \/\/\n-  \/\/  Generate generic array copy stubs\n-  \/\/\n-  \/\/  Input:\n-  \/\/     4(rsp)    -  src oop\n-  \/\/     8(rsp)    -  src_pos\n-  \/\/    12(rsp)    -  dst oop\n-  \/\/    16(rsp)    -  dst_pos\n-  \/\/    20(rsp)    -  element count\n-  \/\/\n-  \/\/  Output:\n-  \/\/    rax, ==  0  -  success\n-  \/\/    rax, == -1^K - failure, where K is partial transfer count\n-  \/\/\n-  address generate_generic_copy(address entry_jbyte_arraycopy,\n-                                address entry_jshort_arraycopy,\n-                                address entry_jint_arraycopy,\n-                                address entry_oop_arraycopy,\n-                                address entry_jlong_arraycopy,\n-                                address entry_checkcast_arraycopy) {\n-    Label L_failed, L_failed_0, L_objArray;\n-\n-    { int modulus = CodeEntryAlignment;\n-      int target  = modulus - 5; \/\/ 5 = sizeof jmp(L_failed)\n-      int advance = target - (__ offset() % modulus);\n-      if (advance < 0)  advance += modulus;\n-      if (advance > 0)  __ nop(advance);\n-    }\n-    StubGenStubId stub_id = StubGenStubId::generic_arraycopy_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    \/\/ Short-hop target to L_failed.  Makes for denser prologue code.\n-    __ BIND(L_failed_0);\n-    __ jmp(L_failed);\n-    assert(__ offset() % CodeEntryAlignment == 0, \"no further alignment needed\");\n-\n-    __ align(CodeEntryAlignment);\n-    address start = __ pc();\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-\n-    \/\/ bump this on entry, not on exit:\n-    inc_counter_np(SharedRuntime::_generic_array_copy_ctr);\n-\n-    \/\/ Input values\n-    Address SRC     (rsp, 12+ 4);\n-    Address SRC_POS (rsp, 12+ 8);\n-    Address DST     (rsp, 12+12);\n-    Address DST_POS (rsp, 12+16);\n-    Address LENGTH  (rsp, 12+20);\n-\n-    \/\/-----------------------------------------------------------------------\n-    \/\/ Assembler stub will be used for this call to arraycopy\n-    \/\/ if the following conditions are met:\n-    \/\/\n-    \/\/ (1) src and dst must not be null.\n-    \/\/ (2) src_pos must not be negative.\n-    \/\/ (3) dst_pos must not be negative.\n-    \/\/ (4) length  must not be negative.\n-    \/\/ (5) src klass and dst klass should be the same and not null.\n-    \/\/ (6) src and dst should be arrays.\n-    \/\/ (7) src_pos + length must not exceed length of src.\n-    \/\/ (8) dst_pos + length must not exceed length of dst.\n-    \/\/\n-\n-    const Register src     = rax;       \/\/ source array oop\n-    const Register src_pos = rsi;\n-    const Register dst     = rdx;       \/\/ destination array oop\n-    const Register dst_pos = rdi;\n-    const Register length  = rcx;       \/\/ transfer count\n-\n-    \/\/  if (src == null) return -1;\n-    __ movptr(src, SRC);      \/\/ src oop\n-    __ testptr(src, src);\n-    __ jccb(Assembler::zero, L_failed_0);\n-\n-    \/\/  if (src_pos < 0) return -1;\n-    __ movl2ptr(src_pos, SRC_POS);  \/\/ src_pos\n-    __ testl(src_pos, src_pos);\n-    __ jccb(Assembler::negative, L_failed_0);\n-\n-    \/\/  if (dst == nullptr) return -1;\n-    __ movptr(dst, DST);      \/\/ dst oop\n-    __ testptr(dst, dst);\n-    __ jccb(Assembler::zero, L_failed_0);\n-\n-    \/\/  if (dst_pos < 0) return -1;\n-    __ movl2ptr(dst_pos, DST_POS);  \/\/ dst_pos\n-    __ testl(dst_pos, dst_pos);\n-    __ jccb(Assembler::negative, L_failed_0);\n-\n-    \/\/  if (length < 0) return -1;\n-    __ movl2ptr(length, LENGTH);   \/\/ length\n-    __ testl(length, length);\n-    __ jccb(Assembler::negative, L_failed_0);\n-\n-    \/\/  if (src->klass() == nullptr) return -1;\n-    Address src_klass_addr(src, oopDesc::klass_offset_in_bytes());\n-    Address dst_klass_addr(dst, oopDesc::klass_offset_in_bytes());\n-    const Register rcx_src_klass = rcx;    \/\/ array klass\n-    __ movptr(rcx_src_klass, Address(src, oopDesc::klass_offset_in_bytes()));\n-\n-#ifdef ASSERT\n-    \/\/  assert(src->klass() != nullptr);\n-    BLOCK_COMMENT(\"assert klasses not null\");\n-    { Label L1, L2;\n-      __ testptr(rcx_src_klass, rcx_src_klass);\n-      __ jccb(Assembler::notZero, L2);   \/\/ it is broken if klass is null\n-      __ bind(L1);\n-      __ stop(\"broken null klass\");\n-      __ bind(L2);\n-      __ cmpptr(dst_klass_addr, NULL_WORD);\n-      __ jccb(Assembler::equal, L1);      \/\/ this would be broken also\n-      BLOCK_COMMENT(\"assert done\");\n-    }\n-#endif \/\/ASSERT\n-\n-    \/\/ Load layout helper (32-bits)\n-    \/\/\n-    \/\/  |array_tag|     | header_size | element_type |     |log2_element_size|\n-    \/\/ 32        30    24            16              8     2                 0\n-    \/\/\n-    \/\/   array_tag: typeArray = 0x3, objArray = 0x2, non-array = 0x0\n-    \/\/\n-\n-    int lh_offset = in_bytes(Klass::layout_helper_offset());\n-    Address src_klass_lh_addr(rcx_src_klass, lh_offset);\n-\n-    \/\/ Handle objArrays completely differently...\n-    jint objArray_lh = Klass::array_layout_helper(T_OBJECT);\n-    __ cmpl(src_klass_lh_addr, objArray_lh);\n-    __ jcc(Assembler::equal, L_objArray);\n-\n-    \/\/  if (src->klass() != dst->klass()) return -1;\n-    __ cmpptr(rcx_src_klass, dst_klass_addr);\n-    __ jccb(Assembler::notEqual, L_failed_0);\n-\n-    const Register rcx_lh = rcx;  \/\/ layout helper\n-    assert(rcx_lh == rcx_src_klass, \"known alias\");\n-    __ movl(rcx_lh, src_klass_lh_addr);\n-\n-    \/\/  if (!src->is_Array()) return -1;\n-    __ cmpl(rcx_lh, Klass::_lh_neutral_value);\n-    __ jcc(Assembler::greaterEqual, L_failed_0); \/\/ signed cmp\n-\n-    \/\/ At this point, it is known to be a typeArray (array_tag 0x3).\n-#ifdef ASSERT\n-    { Label L;\n-      __ cmpl(rcx_lh, (Klass::_lh_array_tag_type_value << Klass::_lh_array_tag_shift));\n-      __ jcc(Assembler::greaterEqual, L); \/\/ signed cmp\n-      __ stop(\"must be a primitive array\");\n-      __ bind(L);\n-    }\n-#endif\n-\n-    assert_different_registers(src, src_pos, dst, dst_pos, rcx_lh);\n-    arraycopy_range_checks(src, src_pos, dst, dst_pos, LENGTH, L_failed);\n-\n-    \/\/ TypeArrayKlass\n-    \/\/\n-    \/\/ src_addr = (src + array_header_in_bytes()) + (src_pos << log2elemsize);\n-    \/\/ dst_addr = (dst + array_header_in_bytes()) + (dst_pos << log2elemsize);\n-    \/\/\n-    const Register rsi_offset = rsi; \/\/ array offset\n-    const Register src_array  = src; \/\/ src array offset\n-    const Register dst_array  = dst; \/\/ dst array offset\n-    const Register rdi_elsize = rdi; \/\/ log2 element size\n-\n-    __ mov(rsi_offset, rcx_lh);\n-    __ shrptr(rsi_offset, Klass::_lh_header_size_shift);\n-    __ andptr(rsi_offset, Klass::_lh_header_size_mask);   \/\/ array_offset\n-    __ addptr(src_array, rsi_offset);  \/\/ src array offset\n-    __ addptr(dst_array, rsi_offset);  \/\/ dst array offset\n-    __ andptr(rcx_lh, Klass::_lh_log2_element_size_mask); \/\/ log2 elsize\n-\n-    \/\/ next registers should be set before the jump to corresponding stub\n-    const Register from       = src; \/\/ source array address\n-    const Register to         = dst; \/\/ destination array address\n-    const Register count      = rcx; \/\/ elements count\n-    \/\/ some of them should be duplicated on stack\n-#define FROM   Address(rsp, 12+ 4)\n-#define TO     Address(rsp, 12+ 8)   \/\/ Not used now\n-#define COUNT  Address(rsp, 12+12)   \/\/ Only for oop arraycopy\n-\n-    BLOCK_COMMENT(\"scale indexes to element size\");\n-    __ movl2ptr(rsi, SRC_POS);  \/\/ src_pos\n-    __ shlptr(rsi);             \/\/ src_pos << rcx (log2 elsize)\n-    assert(src_array == from, \"\");\n-    __ addptr(from, rsi);       \/\/ from = src_array + SRC_POS << log2 elsize\n-    __ movl2ptr(rdi, DST_POS);  \/\/ dst_pos\n-    __ shlptr(rdi);             \/\/ dst_pos << rcx (log2 elsize)\n-    assert(dst_array == to, \"\");\n-    __ addptr(to,  rdi);        \/\/ to   = dst_array + DST_POS << log2 elsize\n-    __ movptr(FROM, from);      \/\/ src_addr\n-    __ mov(rdi_elsize, rcx_lh); \/\/ log2 elsize\n-    __ movl2ptr(count, LENGTH); \/\/ elements count\n-\n-    BLOCK_COMMENT(\"choose copy loop based on element size\");\n-    __ cmpl(rdi_elsize, 0);\n-\n-    __ jump_cc(Assembler::equal, RuntimeAddress(entry_jbyte_arraycopy));\n-    __ cmpl(rdi_elsize, LogBytesPerShort);\n-    __ jump_cc(Assembler::equal, RuntimeAddress(entry_jshort_arraycopy));\n-    __ cmpl(rdi_elsize, LogBytesPerInt);\n-    __ jump_cc(Assembler::equal, RuntimeAddress(entry_jint_arraycopy));\n-#ifdef ASSERT\n-    __ cmpl(rdi_elsize, LogBytesPerLong);\n-    __ jccb(Assembler::notEqual, L_failed);\n-#endif\n-    __ pop(rdi); \/\/ Do pops here since jlong_arraycopy stub does not do it.\n-    __ pop(rsi);\n-    __ jump(RuntimeAddress(entry_jlong_arraycopy));\n-\n-  __ BIND(L_failed);\n-    __ xorptr(rax, rax);\n-    __ notptr(rax); \/\/ return -1\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    \/\/ ObjArrayKlass\n-  __ BIND(L_objArray);\n-    \/\/ live at this point:  rcx_src_klass, src[_pos], dst[_pos]\n-\n-    Label L_plain_copy, L_checkcast_copy;\n-    \/\/  test array classes for subtyping\n-    __ cmpptr(rcx_src_klass, dst_klass_addr); \/\/ usual case is exact equality\n-    __ jccb(Assembler::notEqual, L_checkcast_copy);\n-\n-    \/\/ Identically typed arrays can be copied without element-wise checks.\n-    assert_different_registers(src, src_pos, dst, dst_pos, rcx_src_klass);\n-    arraycopy_range_checks(src, src_pos, dst, dst_pos, LENGTH, L_failed);\n-\n-  __ BIND(L_plain_copy);\n-    __ movl2ptr(count, LENGTH); \/\/ elements count\n-    __ movl2ptr(src_pos, SRC_POS);  \/\/ reload src_pos\n-    __ lea(from, Address(src, src_pos, Address::times_ptr,\n-                 arrayOopDesc::base_offset_in_bytes(T_OBJECT))); \/\/ src_addr\n-    __ movl2ptr(dst_pos, DST_POS);  \/\/ reload dst_pos\n-    __ lea(to,   Address(dst, dst_pos, Address::times_ptr,\n-                 arrayOopDesc::base_offset_in_bytes(T_OBJECT))); \/\/ dst_addr\n-    __ movptr(FROM,  from);   \/\/ src_addr\n-    __ movptr(TO,    to);     \/\/ dst_addr\n-    __ movl(COUNT, count);  \/\/ count\n-    __ jump(RuntimeAddress(entry_oop_arraycopy));\n-\n-  __ BIND(L_checkcast_copy);\n-    \/\/ live at this point:  rcx_src_klass, dst[_pos], src[_pos]\n-    {\n-      \/\/ Handy offsets:\n-      int  ek_offset = in_bytes(ObjArrayKlass::element_klass_offset());\n-      int sco_offset = in_bytes(Klass::super_check_offset_offset());\n-\n-      Register rsi_dst_klass = rsi;\n-      Register rdi_temp      = rdi;\n-      assert(rsi_dst_klass == src_pos, \"expected alias w\/ src_pos\");\n-      assert(rdi_temp      == dst_pos, \"expected alias w\/ dst_pos\");\n-      Address dst_klass_lh_addr(rsi_dst_klass, lh_offset);\n-\n-      \/\/ Before looking at dst.length, make sure dst is also an objArray.\n-      __ movptr(rsi_dst_klass, dst_klass_addr);\n-      __ cmpl(dst_klass_lh_addr, objArray_lh);\n-      __ jccb(Assembler::notEqual, L_failed);\n-\n-      \/\/ It is safe to examine both src.length and dst.length.\n-      __ movl2ptr(src_pos, SRC_POS);        \/\/ reload rsi\n-      arraycopy_range_checks(src, src_pos, dst, dst_pos, LENGTH, L_failed);\n-      \/\/ (Now src_pos and dst_pos are killed, but not src and dst.)\n-\n-      \/\/ We'll need this temp (don't forget to pop it after the type check).\n-      __ push(rbx);\n-      Register rbx_src_klass = rbx;\n-\n-      __ mov(rbx_src_klass, rcx_src_klass); \/\/ spill away from rcx\n-      __ movptr(rsi_dst_klass, dst_klass_addr);\n-      Address super_check_offset_addr(rsi_dst_klass, sco_offset);\n-      Label L_fail_array_check;\n-      generate_type_check(rbx_src_klass,\n-                          super_check_offset_addr, dst_klass_addr,\n-                          rdi_temp, nullptr, &L_fail_array_check);\n-      \/\/ (On fall-through, we have passed the array type check.)\n-      __ pop(rbx);\n-      __ jmp(L_plain_copy);\n-\n-      __ BIND(L_fail_array_check);\n-      \/\/ Reshuffle arguments so we can call checkcast_arraycopy:\n-\n-      \/\/ match initial saves for checkcast_arraycopy\n-      \/\/ push(rsi);    \/\/ already done; see above\n-      \/\/ push(rdi);    \/\/ already done; see above\n-      \/\/ push(rbx);    \/\/ already done; see above\n-\n-      \/\/ Marshal outgoing arguments now, freeing registers.\n-      Address   from_arg(rsp, 16+ 4);   \/\/ from\n-      Address     to_arg(rsp, 16+ 8);   \/\/ to\n-      Address length_arg(rsp, 16+12);   \/\/ elements count\n-      Address  ckoff_arg(rsp, 16+16);   \/\/ super_check_offset\n-      Address  ckval_arg(rsp, 16+20);   \/\/ super_klass\n-\n-      Address SRC_POS_arg(rsp, 16+ 8);\n-      Address DST_POS_arg(rsp, 16+16);\n-      Address  LENGTH_arg(rsp, 16+20);\n-      \/\/ push rbx, changed the incoming offsets (why not just use rbp,??)\n-      \/\/ assert(SRC_POS_arg.disp() == SRC_POS.disp() + 4, \"\");\n-\n-      __ movptr(rbx, Address(rsi_dst_klass, ek_offset));\n-      __ movl2ptr(length, LENGTH_arg);    \/\/ reload elements count\n-      __ movl2ptr(src_pos, SRC_POS_arg);  \/\/ reload src_pos\n-      __ movl2ptr(dst_pos, DST_POS_arg);  \/\/ reload dst_pos\n-\n-      __ movptr(ckval_arg, rbx);          \/\/ destination element type\n-      __ movl(rbx, Address(rbx, sco_offset));\n-      __ movl(ckoff_arg, rbx);          \/\/ corresponding class check offset\n-\n-      __ movl(length_arg, length);      \/\/ outgoing length argument\n-\n-      __ lea(from, Address(src, src_pos, Address::times_ptr,\n-                            arrayOopDesc::base_offset_in_bytes(T_OBJECT)));\n-      __ movptr(from_arg, from);\n-\n-      __ lea(to, Address(dst, dst_pos, Address::times_ptr,\n-                          arrayOopDesc::base_offset_in_bytes(T_OBJECT)));\n-      __ movptr(to_arg, to);\n-      __ jump(RuntimeAddress(entry_checkcast_arraycopy));\n-    }\n-\n-    return start;\n-  }\n-\n-  void generate_arraycopy_stubs() {\n-    address entry;\n-    address entry_jbyte_arraycopy;\n-    address entry_jshort_arraycopy;\n-    address entry_jint_arraycopy;\n-    address entry_oop_arraycopy;\n-    address entry_jlong_arraycopy;\n-    address entry_checkcast_arraycopy;\n-\n-    StubRoutines::_arrayof_jbyte_disjoint_arraycopy =\n-        generate_disjoint_copy(StubGenStubId::arrayof_jbyte_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jbyte_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::arrayof_jbyte_arraycopy_id, entry, nullptr);\n-    StubRoutines::_jbyte_disjoint_arraycopy =\n-      generate_disjoint_copy(StubGenStubId::jbyte_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jbyte_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::jbyte_arraycopy_id,  entry, &entry_jbyte_arraycopy);\n-\n-    StubRoutines::_arrayof_jshort_disjoint_arraycopy =\n-        generate_disjoint_copy(StubGenStubId::arrayof_jshort_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_arrayof_jshort_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::arrayof_jshort_arraycopy_id, entry, nullptr);\n-    StubRoutines::_jshort_disjoint_arraycopy =\n-        generate_disjoint_copy(StubGenStubId::jshort_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jshort_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::jshort_arraycopy_id, entry, &entry_jshort_arraycopy);\n-\n-    \/\/ Next arrays are always aligned on 4 bytes at least.\n-    StubRoutines::_jint_disjoint_arraycopy =\n-        generate_disjoint_copy(StubGenStubId::jint_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_jint_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::jint_arraycopy_id, entry, &entry_jint_arraycopy);\n-\n-    StubRoutines::_oop_disjoint_arraycopy =\n-        generate_disjoint_copy(StubGenStubId::oop_disjoint_arraycopy_id, &entry);\n-    StubRoutines::_oop_arraycopy =\n-        generate_conjoint_copy(StubGenStubId::oop_arraycopy_id, entry, &entry_oop_arraycopy);\n-\n-    StubRoutines::_oop_disjoint_arraycopy_uninit =\n-        generate_disjoint_copy(StubGenStubId::oop_disjoint_arraycopy_uninit_id, &entry);\n-    StubRoutines::_oop_arraycopy_uninit =\n-        generate_conjoint_copy(StubGenStubId::oop_arraycopy_uninit_id, entry, nullptr);\n-\n-    StubRoutines::_jlong_disjoint_arraycopy =\n-        generate_disjoint_long_copy(&entry);\n-    StubRoutines::_jlong_arraycopy =\n-        generate_conjoint_long_copy(entry, &entry_jlong_arraycopy);\n-\n-    StubRoutines::_jbyte_fill = generate_fill(StubGenStubId::jbyte_fill_id);\n-    StubRoutines::_jshort_fill = generate_fill(StubGenStubId::jshort_fill_id);\n-    StubRoutines::_jint_fill = generate_fill(StubGenStubId::jint_fill_id);\n-    StubRoutines::_arrayof_jbyte_fill = generate_fill(StubGenStubId::arrayof_jbyte_fill_id);\n-    StubRoutines::_arrayof_jshort_fill = generate_fill(StubGenStubId::arrayof_jshort_fill_id);\n-    StubRoutines::_arrayof_jint_fill = generate_fill(StubGenStubId::arrayof_jint_fill_id);\n-\n-    StubRoutines::_arrayof_jint_disjoint_arraycopy       = StubRoutines::_jint_disjoint_arraycopy;\n-    StubRoutines::_arrayof_oop_disjoint_arraycopy        = StubRoutines::_oop_disjoint_arraycopy;\n-    StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit = StubRoutines::_oop_disjoint_arraycopy_uninit;\n-    StubRoutines::_arrayof_jlong_disjoint_arraycopy      = StubRoutines::_jlong_disjoint_arraycopy;\n-\n-    StubRoutines::_arrayof_jint_arraycopy       = StubRoutines::_jint_arraycopy;\n-    StubRoutines::_arrayof_oop_arraycopy        = StubRoutines::_oop_arraycopy;\n-    StubRoutines::_arrayof_oop_arraycopy_uninit = StubRoutines::_oop_arraycopy_uninit;\n-    StubRoutines::_arrayof_jlong_arraycopy      = StubRoutines::_jlong_arraycopy;\n-\n-    StubRoutines::_checkcast_arraycopy =\n-      generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_id, &entry_checkcast_arraycopy);\n-    StubRoutines::_checkcast_arraycopy_uninit =\n-      generate_checkcast_copy(StubGenStubId::checkcast_arraycopy_uninit_id, nullptr);\n-\n-    StubRoutines::_unsafe_arraycopy =\n-        generate_unsafe_copy(entry_jbyte_arraycopy,\n-                             entry_jshort_arraycopy,\n-                             entry_jint_arraycopy,\n-                             entry_jlong_arraycopy);\n-\n-    StubRoutines::_generic_arraycopy =\n-        generate_generic_copy( entry_jbyte_arraycopy,\n-                               entry_jshort_arraycopy,\n-                               entry_jint_arraycopy,\n-                               entry_oop_arraycopy,\n-                               entry_jlong_arraycopy,\n-                               entry_checkcast_arraycopy);\n-  }\n-\n-  \/\/ AES intrinsic stubs\n-  enum {AESBlockSize = 16};\n-\n-  address key_shuffle_mask_addr() {\n-    return (address)KEY_SHUFFLE_MASK;\n-  }\n-\n-  address counter_shuffle_mask_addr() {\n-    return (address)COUNTER_SHUFFLE_MASK;\n-  }\n-\n-  \/\/ Utility routine for loading a 128-bit key word in little endian format\n-  \/\/ can optionally specify that the shuffle mask is already in an xmmregister\n-  void load_key(XMMRegister xmmdst, Register key, int offset, XMMRegister xmm_shuf_mask = xnoreg) {\n-    __ movdqu(xmmdst, Address(key, offset));\n-    if (xmm_shuf_mask != xnoreg) {\n-      __ pshufb(xmmdst, xmm_shuf_mask);\n-    } else {\n-      __ pshufb(xmmdst, ExternalAddress(key_shuffle_mask_addr()));\n-    }\n-  }\n-\n-  \/\/ aesenc using specified key+offset\n-  \/\/ can optionally specify that the shuffle mask is already in an xmmregister\n-  void aes_enc_key(XMMRegister xmmdst, XMMRegister xmmtmp, Register key, int offset, XMMRegister xmm_shuf_mask = xnoreg) {\n-    load_key(xmmtmp, key, offset, xmm_shuf_mask);\n-    __ aesenc(xmmdst, xmmtmp);\n-  }\n-\n-  \/\/ aesdec using specified key+offset\n-  \/\/ can optionally specify that the shuffle mask is already in an xmmregister\n-  void aes_dec_key(XMMRegister xmmdst, XMMRegister xmmtmp, Register key, int offset, XMMRegister xmm_shuf_mask = xnoreg) {\n-    load_key(xmmtmp, key, offset, xmm_shuf_mask);\n-    __ aesdec(xmmdst, xmmtmp);\n-  }\n-\n-  \/\/ Utility routine for increase 128bit counter (iv in CTR mode)\n-  \/\/  XMM_128bit,  D3, D2, D1, D0\n-  void inc_counter(Register reg, XMMRegister xmmdst, int inc_delta, Label& next_block) {\n-    __ pextrd(reg, xmmdst, 0x0);\n-    __ addl(reg, inc_delta);\n-    __ pinsrd(xmmdst, reg, 0x0);\n-    __ jcc(Assembler::carryClear, next_block); \/\/ jump if no carry\n-\n-    __ pextrd(reg, xmmdst, 0x01); \/\/ Carry-> D1\n-    __ addl(reg, 0x01);\n-    __ pinsrd(xmmdst, reg, 0x01);\n-    __ jcc(Assembler::carryClear, next_block); \/\/ jump if no carry\n-\n-    __ pextrd(reg, xmmdst, 0x02); \/\/ Carry-> D2\n-    __ addl(reg, 0x01);\n-    __ pinsrd(xmmdst, reg, 0x02);\n-    __ jcc(Assembler::carryClear, next_block); \/\/ jump if no carry\n-\n-    __ pextrd(reg, xmmdst, 0x03); \/\/ Carry -> D3\n-    __ addl(reg, 0x01);\n-    __ pinsrd(xmmdst, reg, 0x03);\n-\n-    __ BIND(next_block);          \/\/ next instruction\n-  }\n-\n-\n-  \/\/ Arguments:\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source byte array address\n-  \/\/   c_rarg1   - destination byte array address\n-  \/\/   c_rarg2   - K (key) in little endian int array\n-  \/\/\n-  address generate_aescrypt_encryptBlock() {\n-    assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::aescrypt_encryptBlock_id;\n-    StubCodeMark mark(this, stub_id);\n-    Label L_doLast;\n-    address start = __ pc();\n-\n-    const Register from        = rdx;      \/\/ source array address\n-    const Register to          = rdx;      \/\/ destination array address\n-    const Register key         = rcx;      \/\/ key array address\n-    const Register keylen      = rax;\n-    const Address  from_param(rbp, 8+0);\n-    const Address  to_param  (rbp, 8+4);\n-    const Address  key_param (rbp, 8+8);\n-\n-    const XMMRegister xmm_result = xmm0;\n-    const XMMRegister xmm_key_shuf_mask = xmm1;\n-    const XMMRegister xmm_temp1  = xmm2;\n-    const XMMRegister xmm_temp2  = xmm3;\n-    const XMMRegister xmm_temp3  = xmm4;\n-    const XMMRegister xmm_temp4  = xmm5;\n-\n-    __ enter();   \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-    __ movptr(from, from_param);\n-    __ movptr(key, key_param);\n-\n-    \/\/ keylen could be only {11, 13, 15} * 4 = {44, 52, 60}\n-    __ movl(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-\n-    __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-    __ movdqu(xmm_result, Address(from, 0));  \/\/ get 16 bytes of input\n-    __ movptr(to, to_param);\n-\n-    \/\/ For encryption, the java expanded key ordering is just what we need\n-\n-    load_key(xmm_temp1, key, 0x00, xmm_key_shuf_mask);\n-    __ pxor(xmm_result, xmm_temp1);\n-\n-    load_key(xmm_temp1, key, 0x10, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0x20, xmm_key_shuf_mask);\n-    load_key(xmm_temp3, key, 0x30, xmm_key_shuf_mask);\n-    load_key(xmm_temp4, key, 0x40, xmm_key_shuf_mask);\n-\n-    __ aesenc(xmm_result, xmm_temp1);\n-    __ aesenc(xmm_result, xmm_temp2);\n-    __ aesenc(xmm_result, xmm_temp3);\n-    __ aesenc(xmm_result, xmm_temp4);\n-\n-    load_key(xmm_temp1, key, 0x50, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0x60, xmm_key_shuf_mask);\n-    load_key(xmm_temp3, key, 0x70, xmm_key_shuf_mask);\n-    load_key(xmm_temp4, key, 0x80, xmm_key_shuf_mask);\n-\n-    __ aesenc(xmm_result, xmm_temp1);\n-    __ aesenc(xmm_result, xmm_temp2);\n-    __ aesenc(xmm_result, xmm_temp3);\n-    __ aesenc(xmm_result, xmm_temp4);\n-\n-    load_key(xmm_temp1, key, 0x90, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xa0, xmm_key_shuf_mask);\n-\n-    __ cmpl(keylen, 44);\n-    __ jccb(Assembler::equal, L_doLast);\n-\n-    __ aesenc(xmm_result, xmm_temp1);\n-    __ aesenc(xmm_result, xmm_temp2);\n-\n-    load_key(xmm_temp1, key, 0xb0, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xc0, xmm_key_shuf_mask);\n-\n-    __ cmpl(keylen, 52);\n-    __ jccb(Assembler::equal, L_doLast);\n-\n-    __ aesenc(xmm_result, xmm_temp1);\n-    __ aesenc(xmm_result, xmm_temp2);\n-\n-    load_key(xmm_temp1, key, 0xd0, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xe0, xmm_key_shuf_mask);\n-\n-    __ BIND(L_doLast);\n-    __ aesenc(xmm_result, xmm_temp1);\n-    __ aesenclast(xmm_result, xmm_temp2);\n-    __ movdqu(Address(to, 0), xmm_result);        \/\/ store the result\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-\n-  \/\/ Arguments:\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source byte array address\n-  \/\/   c_rarg1   - destination byte array address\n-  \/\/   c_rarg2   - K (key) in little endian int array\n-  \/\/\n-  address generate_aescrypt_decryptBlock() {\n-    assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::aescrypt_decryptBlock_id;\n-    StubCodeMark mark(this, stub_id);\n-    Label L_doLast;\n-    address start = __ pc();\n-\n-    const Register from        = rdx;      \/\/ source array address\n-    const Register to          = rdx;      \/\/ destination array address\n-    const Register key         = rcx;      \/\/ key array address\n-    const Register keylen      = rax;\n-    const Address  from_param(rbp, 8+0);\n-    const Address  to_param  (rbp, 8+4);\n-    const Address  key_param (rbp, 8+8);\n-\n-    const XMMRegister xmm_result = xmm0;\n-    const XMMRegister xmm_key_shuf_mask = xmm1;\n-    const XMMRegister xmm_temp1  = xmm2;\n-    const XMMRegister xmm_temp2  = xmm3;\n-    const XMMRegister xmm_temp3  = xmm4;\n-    const XMMRegister xmm_temp4  = xmm5;\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-\n-    __ movptr(from, from_param);\n-    __ movptr(key, key_param);\n-\n-    \/\/ keylen could be only {11, 13, 15} * 4 = {44, 52, 60}\n-    __ movl(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-\n-    __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-    __ movdqu(xmm_result, Address(from, 0));\n-    __ movptr(to, to_param);\n-\n-    \/\/ for decryption java expanded key ordering is rotated one position from what we want\n-    \/\/ so we start from 0x10 here and hit 0x00 last\n-    \/\/ we don't know if the key is aligned, hence not using load-execute form\n-    load_key(xmm_temp1, key, 0x10, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0x20, xmm_key_shuf_mask);\n-    load_key(xmm_temp3, key, 0x30, xmm_key_shuf_mask);\n-    load_key(xmm_temp4, key, 0x40, xmm_key_shuf_mask);\n-\n-    __ pxor  (xmm_result, xmm_temp1);\n-    __ aesdec(xmm_result, xmm_temp2);\n-    __ aesdec(xmm_result, xmm_temp3);\n-    __ aesdec(xmm_result, xmm_temp4);\n-\n-    load_key(xmm_temp1, key, 0x50, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0x60, xmm_key_shuf_mask);\n-    load_key(xmm_temp3, key, 0x70, xmm_key_shuf_mask);\n-    load_key(xmm_temp4, key, 0x80, xmm_key_shuf_mask);\n-\n-    __ aesdec(xmm_result, xmm_temp1);\n-    __ aesdec(xmm_result, xmm_temp2);\n-    __ aesdec(xmm_result, xmm_temp3);\n-    __ aesdec(xmm_result, xmm_temp4);\n-\n-    load_key(xmm_temp1, key, 0x90, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xa0, xmm_key_shuf_mask);\n-    load_key(xmm_temp3, key, 0x00, xmm_key_shuf_mask);\n-\n-    __ cmpl(keylen, 44);\n-    __ jccb(Assembler::equal, L_doLast);\n-\n-    __ aesdec(xmm_result, xmm_temp1);\n-    __ aesdec(xmm_result, xmm_temp2);\n-\n-    load_key(xmm_temp1, key, 0xb0, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xc0, xmm_key_shuf_mask);\n-\n-    __ cmpl(keylen, 52);\n-    __ jccb(Assembler::equal, L_doLast);\n-\n-    __ aesdec(xmm_result, xmm_temp1);\n-    __ aesdec(xmm_result, xmm_temp2);\n-\n-    load_key(xmm_temp1, key, 0xd0, xmm_key_shuf_mask);\n-    load_key(xmm_temp2, key, 0xe0, xmm_key_shuf_mask);\n-\n-    __ BIND(L_doLast);\n-    __ aesdec(xmm_result, xmm_temp1);\n-    __ aesdec(xmm_result, xmm_temp2);\n-\n-    \/\/ for decryption the aesdeclast operation is always on key+0x00\n-    __ aesdeclast(xmm_result, xmm_temp3);\n-    __ movdqu(Address(to, 0), xmm_result);  \/\/ store the result\n-    __ xorptr(rax, rax); \/\/ return 0\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-  void handleSOERegisters(bool saving) {\n-    const int saveFrameSizeInBytes = 4 * wordSize;\n-    const Address saved_rbx     (rbp, -3 * wordSize);\n-    const Address saved_rsi     (rbp, -2 * wordSize);\n-    const Address saved_rdi     (rbp, -1 * wordSize);\n-\n-    if (saving) {\n-      __ subptr(rsp, saveFrameSizeInBytes);\n-      __ movptr(saved_rsi, rsi);\n-      __ movptr(saved_rdi, rdi);\n-      __ movptr(saved_rbx, rbx);\n-    } else {\n-      \/\/ restoring\n-      __ movptr(rsi, saved_rsi);\n-      __ movptr(rdi, saved_rdi);\n-      __ movptr(rbx, saved_rbx);\n-    }\n-  }\n-\n-  \/\/ Arguments:\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source byte array address\n-  \/\/   c_rarg1   - destination byte array address\n-  \/\/   c_rarg2   - K (key) in little endian int array\n-  \/\/   c_rarg3   - r vector byte array address\n-  \/\/   c_rarg4   - input length\n-  \/\/\n-  \/\/ Output:\n-  \/\/   rax       - input length\n-  \/\/\n-  address generate_cipherBlockChaining_encryptAESCrypt() {\n-    assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::cipherBlockChaining_encryptAESCrypt_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Label L_exit, L_key_192_256, L_key_256, L_loopTop_128, L_loopTop_192, L_loopTop_256;\n-    const Register from        = rsi;      \/\/ source array address\n-    const Register to          = rdx;      \/\/ destination array address\n-    const Register key         = rcx;      \/\/ key array address\n-    const Register rvec        = rdi;      \/\/ r byte array initialized from initvector array address\n-                                           \/\/ and left with the results of the last encryption block\n-    const Register len_reg     = rbx;      \/\/ src len (must be multiple of blocksize 16)\n-    const Register pos         = rax;\n-\n-    \/\/ xmm register assignments for the loops below\n-    const XMMRegister xmm_result = xmm0;\n-    const XMMRegister xmm_temp   = xmm1;\n-    \/\/ first 6 keys preloaded into xmm2-xmm7\n-    const int XMM_REG_NUM_KEY_FIRST = 2;\n-    const int XMM_REG_NUM_KEY_LAST  = 7;\n-    const XMMRegister xmm_key0   = as_XMMRegister(XMM_REG_NUM_KEY_FIRST);\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    handleSOERegisters(true \/*saving*\/);\n-\n-    \/\/ load registers from incoming parameters\n-    const Address  from_param(rbp, 8+0);\n-    const Address  to_param  (rbp, 8+4);\n-    const Address  key_param (rbp, 8+8);\n-    const Address  rvec_param (rbp, 8+12);\n-    const Address  len_param  (rbp, 8+16);\n-    __ movptr(from , from_param);\n-    __ movptr(to   , to_param);\n-    __ movptr(key  , key_param);\n-    __ movptr(rvec , rvec_param);\n-    __ movptr(len_reg , len_param);\n-\n-    const XMMRegister xmm_key_shuf_mask = xmm_temp;  \/\/ used temporarily to swap key bytes up front\n-    __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-    \/\/ load up xmm regs 2 thru 7 with keys 0-5\n-    for (int rnum = XMM_REG_NUM_KEY_FIRST, offset = 0x00; rnum  <= XMM_REG_NUM_KEY_LAST; rnum++) {\n-      load_key(as_XMMRegister(rnum), key, offset, xmm_key_shuf_mask);\n-      offset += 0x10;\n-    }\n-\n-    __ movdqu(xmm_result, Address(rvec, 0x00));   \/\/ initialize xmm_result with r vec\n-\n-    \/\/ now split to different paths depending on the keylen (len in ints of AESCrypt.KLE array (52=192, or 60=256))\n-    __ movl(rax, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-    __ cmpl(rax, 44);\n-    __ jcc(Assembler::notEqual, L_key_192_256);\n-\n-    \/\/ 128 bit code follows here\n-    __ movl(pos, 0);\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_loopTop_128);\n-    __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-    __ pxor  (xmm_result, xmm_temp);                                \/\/ xor with the current r vector\n-\n-    __ pxor  (xmm_result, xmm_key0);                                \/\/ do the aes rounds\n-    for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum  <= XMM_REG_NUM_KEY_LAST; rnum++) {\n-      __ aesenc(xmm_result, as_XMMRegister(rnum));\n-    }\n-    for (int key_offset = 0x60; key_offset <= 0x90; key_offset += 0x10) {\n-      aes_enc_key(xmm_result, xmm_temp, key, key_offset);\n-    }\n-    load_key(xmm_temp, key, 0xa0);\n-    __ aesenclast(xmm_result, xmm_temp);\n-\n-    __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);     \/\/ store into the next 16 bytes of output\n-    \/\/ no need to store r to memory until we exit\n-    __ addptr(pos, AESBlockSize);\n-    __ subptr(len_reg, AESBlockSize);\n-    __ jcc(Assembler::notEqual, L_loopTop_128);\n-\n-    __ BIND(L_exit);\n-    __ movdqu(Address(rvec, 0), xmm_result);     \/\/ final value of r stored in rvec of CipherBlockChaining object\n-\n-    handleSOERegisters(false \/*restoring*\/);\n-    __ movptr(rax, len_param); \/\/ return length\n-    __ leave();                                  \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    __ BIND(L_key_192_256);\n-    \/\/ here rax = len in ints of AESCrypt.KLE array (52=192, or 60=256)\n-    __ cmpl(rax, 52);\n-    __ jcc(Assembler::notEqual, L_key_256);\n-\n-    \/\/ 192-bit code follows here (could be changed to use more xmm registers)\n-    __ movl(pos, 0);\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_loopTop_192);\n-    __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-    __ pxor  (xmm_result, xmm_temp);                                \/\/ xor with the current r vector\n-\n-    __ pxor  (xmm_result, xmm_key0);                                \/\/ do the aes rounds\n-    for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum  <= XMM_REG_NUM_KEY_LAST; rnum++) {\n-      __ aesenc(xmm_result, as_XMMRegister(rnum));\n-    }\n-    for (int key_offset = 0x60; key_offset <= 0xb0; key_offset += 0x10) {\n-      aes_enc_key(xmm_result, xmm_temp, key, key_offset);\n-    }\n-    load_key(xmm_temp, key, 0xc0);\n-    __ aesenclast(xmm_result, xmm_temp);\n-\n-    __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);   \/\/ store into the next 16 bytes of output\n-    \/\/ no need to store r to memory until we exit\n-    __ addptr(pos, AESBlockSize);\n-    __ subptr(len_reg, AESBlockSize);\n-    __ jcc(Assembler::notEqual, L_loopTop_192);\n-    __ jmp(L_exit);\n-\n-    __ BIND(L_key_256);\n-    \/\/ 256-bit code follows here (could be changed to use more xmm registers)\n-    __ movl(pos, 0);\n-    __ align(OptoLoopAlignment);\n-    __ BIND(L_loopTop_256);\n-    __ movdqu(xmm_temp, Address(from, pos, Address::times_1, 0));   \/\/ get next 16 bytes of input\n-    __ pxor  (xmm_result, xmm_temp);                                \/\/ xor with the current r vector\n-\n-    __ pxor  (xmm_result, xmm_key0);                                \/\/ do the aes rounds\n-    for (int rnum = XMM_REG_NUM_KEY_FIRST + 1; rnum  <= XMM_REG_NUM_KEY_LAST; rnum++) {\n-      __ aesenc(xmm_result, as_XMMRegister(rnum));\n-    }\n-    for (int key_offset = 0x60; key_offset <= 0xd0; key_offset += 0x10) {\n-      aes_enc_key(xmm_result, xmm_temp, key, key_offset);\n-    }\n-    load_key(xmm_temp, key, 0xe0);\n-    __ aesenclast(xmm_result, xmm_temp);\n-\n-    __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result);   \/\/ store into the next 16 bytes of output\n-    \/\/ no need to store r to memory until we exit\n-    __ addptr(pos, AESBlockSize);\n-    __ subptr(len_reg, AESBlockSize);\n-    __ jcc(Assembler::notEqual, L_loopTop_256);\n-    __ jmp(L_exit);\n-\n-    return start;\n-  }\n-\n-\n-  \/\/ CBC AES Decryption.\n-  \/\/ In 32-bit stub, because of lack of registers we do not try to parallelize 4 blocks at a time.\n-  \/\/\n-  \/\/ Arguments:\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source byte array address\n-  \/\/   c_rarg1   - destination byte array address\n-  \/\/   c_rarg2   - K (key) in little endian int array\n-  \/\/   c_rarg3   - r vector byte array address\n-  \/\/   c_rarg4   - input length\n-  \/\/\n-  \/\/ Output:\n-  \/\/   rax       - input length\n-  \/\/\n-\n-  address generate_cipherBlockChaining_decryptAESCrypt_Parallel() {\n-    assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::cipherBlockChaining_decryptAESCrypt_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    const Register from        = rsi;      \/\/ source array address\n-    const Register to          = rdx;      \/\/ destination array address\n-    const Register key         = rcx;      \/\/ key array address\n-    const Register rvec        = rdi;      \/\/ r byte array initialized from initvector array address\n-                                           \/\/ and left with the results of the last encryption block\n-    const Register len_reg     = rbx;      \/\/ src len (must be multiple of blocksize 16)\n-    const Register pos         = rax;\n-\n-    const int PARALLEL_FACTOR = 4;\n-    const int ROUNDS[3] = { 10, 12, 14 }; \/\/aes rounds for key128, key192, key256\n-\n-    Label L_exit;\n-    Label L_singleBlock_loopTop[3]; \/\/128, 192, 256\n-    Label L_multiBlock_loopTop[3]; \/\/128, 192, 256\n-\n-    const XMMRegister xmm_prev_block_cipher = xmm0; \/\/ holds cipher of previous block\n-    const XMMRegister xmm_key_shuf_mask = xmm1;\n-\n-    const XMMRegister xmm_key_tmp0 = xmm2;\n-    const XMMRegister xmm_key_tmp1 = xmm3;\n-\n-    \/\/ registers holding the six results in the parallelized loop\n-    const XMMRegister xmm_result0 = xmm4;\n-    const XMMRegister xmm_result1 = xmm5;\n-    const XMMRegister xmm_result2 = xmm6;\n-    const XMMRegister xmm_result3 = xmm7;\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    handleSOERegisters(true \/*saving*\/);\n-\n-    \/\/ load registers from incoming parameters\n-    const Address  from_param(rbp, 8+0);\n-    const Address  to_param  (rbp, 8+4);\n-    const Address  key_param (rbp, 8+8);\n-    const Address  rvec_param (rbp, 8+12);\n-    const Address  len_param  (rbp, 8+16);\n-\n-    __ movptr(from , from_param);\n-    __ movptr(to   , to_param);\n-    __ movptr(key  , key_param);\n-    __ movptr(rvec , rvec_param);\n-    __ movptr(len_reg , len_param);\n-\n-    __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-    __ movdqu(xmm_prev_block_cipher, Address(rvec, 0x00)); \/\/ initialize with initial rvec\n-\n-    __ xorptr(pos, pos);\n-\n-    \/\/ now split to different paths depending on the keylen (len in ints of AESCrypt.KLE array (52=192, or 60=256))\n-    \/\/ rvec is reused\n-    __ movl(rvec, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-    __ cmpl(rvec, 52);\n-    __ jcc(Assembler::equal, L_multiBlock_loopTop[1]);\n-    __ cmpl(rvec, 60);\n-    __ jcc(Assembler::equal, L_multiBlock_loopTop[2]);\n-\n-#define DoFour(opc, src_reg)           \\\n-  __ opc(xmm_result0, src_reg);         \\\n-  __ opc(xmm_result1, src_reg);         \\\n-  __ opc(xmm_result2, src_reg);         \\\n-  __ opc(xmm_result3, src_reg);         \\\n-\n-    for (int k = 0; k < 3; ++k) {\n-      __ align(OptoLoopAlignment);\n-      __ BIND(L_multiBlock_loopTop[k]);\n-      __ cmpptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ see if at least 4 blocks left\n-      __ jcc(Assembler::less, L_singleBlock_loopTop[k]);\n-\n-      __ movdqu(xmm_result0, Address(from, pos, Address::times_1, 0 * AESBlockSize)); \/\/ get next 4 blocks into xmmresult registers\n-      __ movdqu(xmm_result1, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-      __ movdqu(xmm_result2, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-      __ movdqu(xmm_result3, Address(from, pos, Address::times_1, 3 * AESBlockSize));\n-\n-      \/\/ the java expanded key ordering is rotated one position from what we want\n-      \/\/ so we start from 0x10 here and hit 0x00 last\n-      load_key(xmm_key_tmp0, key, 0x10, xmm_key_shuf_mask);\n-      DoFour(pxor, xmm_key_tmp0); \/\/xor with first key\n-      \/\/ do the aes dec rounds\n-      for (int rnum = 1; rnum <= ROUNDS[k];) {\n-        \/\/load two keys at a time\n-        \/\/k1->0x20, ..., k9->0xa0, k10->0x00\n-        load_key(xmm_key_tmp1, key, (rnum + 1) * 0x10, xmm_key_shuf_mask);\n-        load_key(xmm_key_tmp0, key, ((rnum + 2) % (ROUNDS[k] + 1)) * 0x10, xmm_key_shuf_mask); \/\/ hit 0x00 last!\n-        DoFour(aesdec, xmm_key_tmp1);\n-        rnum++;\n-        if (rnum != ROUNDS[k]) {\n-          DoFour(aesdec, xmm_key_tmp0);\n-        }\n-        else {\n-          DoFour(aesdeclast, xmm_key_tmp0);\n-        }\n-        rnum++;\n-      }\n-\n-      \/\/ for each result, xor with the r vector of previous cipher block\n-      __ pxor(xmm_result0, xmm_prev_block_cipher);\n-      __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-      __ pxor(xmm_result1, xmm_prev_block_cipher);\n-      __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-      __ pxor(xmm_result2, xmm_prev_block_cipher);\n-      __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-      __ pxor(xmm_result3, xmm_prev_block_cipher);\n-      __ movdqu(xmm_prev_block_cipher, Address(from, pos, Address::times_1, 3 * AESBlockSize)); \/\/ this will carry over to next set of blocks\n-\n-            \/\/ store 4 results into the next 64 bytes of output\n-       __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);\n-       __ movdqu(Address(to, pos, Address::times_1, 1 * AESBlockSize), xmm_result1);\n-       __ movdqu(Address(to, pos, Address::times_1, 2 * AESBlockSize), xmm_result2);\n-       __ movdqu(Address(to, pos, Address::times_1, 3 * AESBlockSize), xmm_result3);\n-\n-       __ addptr(pos, 4 * AESBlockSize);\n-       __ subptr(len_reg, 4 * AESBlockSize);\n-       __ jmp(L_multiBlock_loopTop[k]);\n-\n-       \/\/singleBlock starts here\n-       __ align(OptoLoopAlignment);\n-       __ BIND(L_singleBlock_loopTop[k]);\n-       __ cmpptr(len_reg, 0); \/\/ any blocks left?\n-       __ jcc(Assembler::equal, L_exit);\n-       __ movdqu(xmm_result0, Address(from, pos, Address::times_1, 0)); \/\/ get next 16 bytes of cipher input\n-       __ movdqa(xmm_result1, xmm_result0);\n-\n-       load_key(xmm_key_tmp0, key, 0x10, xmm_key_shuf_mask);\n-       __ pxor(xmm_result0, xmm_key_tmp0);\n-       \/\/ do the aes dec rounds\n-       for (int rnum = 1; rnum < ROUNDS[k]; rnum++) {\n-         \/\/ the java expanded key ordering is rotated one position from what we want\n-         load_key(xmm_key_tmp0, key, (rnum + 1) * 0x10, xmm_key_shuf_mask);\n-         __ aesdec(xmm_result0, xmm_key_tmp0);\n-       }\n-       load_key(xmm_key_tmp0, key, 0x00, xmm_key_shuf_mask);\n-       __ aesdeclast(xmm_result0, xmm_key_tmp0);\n-       __ pxor(xmm_result0, xmm_prev_block_cipher); \/\/ xor with the current r vector\n-       __ movdqu(Address(to, pos, Address::times_1, 0), xmm_result0); \/\/ store into the next 16 bytes of output\n-       \/\/ no need to store r to memory until we exit\n-       __ movdqa(xmm_prev_block_cipher, xmm_result1); \/\/ set up next r vector with cipher input from this block\n-\n-       __ addptr(pos, AESBlockSize);\n-       __ subptr(len_reg, AESBlockSize);\n-       __ jmp(L_singleBlock_loopTop[k]);\n-    }\/\/for 128\/192\/256\n-\n-    __ BIND(L_exit);\n-    __ movptr(rvec, rvec_param);                        \/\/ restore this since reused earlier\n-    __ movdqu(Address(rvec, 0), xmm_prev_block_cipher); \/\/ final value of r stored in rvec of CipherBlockChaining object\n-    handleSOERegisters(false \/*restoring*\/);\n-    __ movptr(rax, len_param);                          \/\/ return length\n-    __ leave();                                         \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-  \/\/ CTR AES crypt.\n-  \/\/ In 32-bit stub, parallelize 4 blocks at a time\n-  \/\/ Arguments:\n-  \/\/\n-  \/\/ Inputs:\n-  \/\/   c_rarg0   - source byte array address\n-  \/\/   c_rarg1   - destination byte array address\n-  \/\/   c_rarg2   - K (key) in little endian int array\n-  \/\/   c_rarg3   - counter vector byte array address\n-  \/\/   c_rarg4   - input length\n-  \/\/\n-  \/\/ Output:\n-  \/\/   rax       - input length\n-  \/\/\n-  address generate_counterMode_AESCrypt_Parallel() {\n-    assert(UseAES, \"need AES instructions and misaligned SSE support\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::counterMode_AESCrypt_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    const Register from        = rsi;      \/\/ source array address\n-    const Register to          = rdx;      \/\/ destination array address\n-    const Register key         = rcx;      \/\/ key array address\n-    const Register counter     = rdi;      \/\/ counter byte array initialized from initvector array address\n-                                           \/\/ and updated with the incremented counter in the end\n-    const Register len_reg     = rbx;\n-    const Register pos         = rax;\n-\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    handleSOERegisters(true \/*saving*\/); \/\/ save rbx, rsi, rdi\n-\n-    \/\/ load registers from incoming parameters\n-    const Address  from_param(rbp, 8+0);\n-    const Address  to_param  (rbp, 8+4);\n-    const Address  key_param (rbp, 8+8);\n-    const Address  rvec_param (rbp, 8+12);\n-    const Address  len_param  (rbp, 8+16);\n-    const Address  saved_counter_param(rbp, 8 + 20);\n-    const Address  used_addr_param(rbp, 8 + 24);\n-\n-    __ movptr(from , from_param);\n-    __ movptr(to   , to_param);\n-    __ movptr(len_reg , len_param);\n-\n-    \/\/ Use the partially used encrpyted counter from last invocation\n-    Label L_exit_preLoop, L_preLoop_start;\n-\n-    \/\/ Use the registers 'counter' and 'key' here in this preloop\n-    \/\/ to hold of last 2 params 'used' and 'saved_encCounter_start'\n-    Register used = counter;\n-    Register saved_encCounter_start = key;\n-    Register used_addr = saved_encCounter_start;\n-\n-    __ movptr(used_addr, used_addr_param);\n-    __ movptr(used, Address(used_addr, 0));\n-    __ movptr(saved_encCounter_start, saved_counter_param);\n-\n-    __ BIND(L_preLoop_start);\n-    __ cmpptr(used, 16);\n-    __ jcc(Assembler::aboveEqual, L_exit_preLoop);\n-    __ cmpptr(len_reg, 0);\n-    __ jcc(Assembler::lessEqual, L_exit_preLoop);\n-    __ movb(rax, Address(saved_encCounter_start, used));\n-    __ xorb(rax, Address(from, 0));\n-    __ movb(Address(to, 0), rax);\n-    __ addptr(from, 1);\n-    __ addptr(to, 1);\n-    __ addptr(used, 1);\n-    __ subptr(len_reg, 1);\n-\n-    __ jmp(L_preLoop_start);\n-\n-    __ BIND(L_exit_preLoop);\n-    __ movptr(used_addr, used_addr_param);\n-    __ movptr(used_addr, used_addr_param);\n-    __ movl(Address(used_addr, 0), used);\n-\n-    \/\/ load the parameters 'key' and 'counter'\n-    __ movptr(key, key_param);\n-    __ movptr(counter, rvec_param);\n-\n-    \/\/ xmm register assignments for the loops below\n-    const XMMRegister xmm_curr_counter      = xmm0;\n-    const XMMRegister xmm_counter_shuf_mask = xmm1;  \/\/ need to be reloaded\n-    const XMMRegister xmm_key_shuf_mask     = xmm2;  \/\/ need to be reloaded\n-    const XMMRegister xmm_key               = xmm3;\n-    const XMMRegister xmm_result0           = xmm4;\n-    const XMMRegister xmm_result1           = xmm5;\n-    const XMMRegister xmm_result2           = xmm6;\n-    const XMMRegister xmm_result3           = xmm7;\n-    const XMMRegister xmm_from0             = xmm1;   \/\/reuse XMM register\n-    const XMMRegister xmm_from1             = xmm2;\n-    const XMMRegister xmm_from2             = xmm3;\n-    const XMMRegister xmm_from3             = xmm4;\n-\n-    \/\/for key_128, key_192, key_256\n-    const int rounds[3] = {10, 12, 14};\n-    Label L_singleBlockLoopTop[3];\n-    Label L_multiBlock_loopTop[3];\n-    Label L_key192_top, L_key256_top;\n-    Label L_incCounter[3][4]; \/\/ 3: different key length,  4: 4 blocks at a time\n-    Label L_incCounter_single[3]; \/\/for single block, key128, key192, key256\n-    Label L_processTail_insr[3], L_processTail_4_insr[3], L_processTail_2_insr[3], L_processTail_1_insr[3], L_processTail_exit_insr[3];\n-    Label L_processTail_extr[3], L_processTail_4_extr[3], L_processTail_2_extr[3], L_processTail_1_extr[3], L_processTail_exit_extr[3];\n-\n-    Label L_exit;\n-    const int PARALLEL_FACTOR = 4;  \/\/because of the limited register number\n-\n-    \/\/ initialize counter with initial counter\n-    __ movdqu(xmm_curr_counter, Address(counter, 0x00));\n-    __ movdqu(xmm_counter_shuf_mask, ExternalAddress(counter_shuffle_mask_addr()));\n-    __ pshufb(xmm_curr_counter, xmm_counter_shuf_mask); \/\/counter is shuffled for increase\n-\n-    \/\/ key length could be only {11, 13, 15} * 4 = {44, 52, 60}\n-    __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-    __ movl(rax, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n-    __ cmpl(rax, 52);\n-    __ jcc(Assembler::equal, L_key192_top);\n-    __ cmpl(rax, 60);\n-    __ jcc(Assembler::equal, L_key256_top);\n-\n-    \/\/key128 begins here\n-    __ movptr(pos, 0); \/\/ init pos before L_multiBlock_loopTop\n-\n-#define CTR_DoFour(opc, src_reg)               \\\n-    __ opc(xmm_result0, src_reg);              \\\n-    __ opc(xmm_result1, src_reg);              \\\n-    __ opc(xmm_result2, src_reg);              \\\n-    __ opc(xmm_result3, src_reg);\n-\n-    \/\/ k == 0 :  generate code for key_128\n-    \/\/ k == 1 :  generate code for key_192\n-    \/\/ k == 2 :  generate code for key_256\n-    for (int k = 0; k < 3; ++k) {\n-      \/\/multi blocks starts here\n-      __ align(OptoLoopAlignment);\n-      __ BIND(L_multiBlock_loopTop[k]);\n-      __ cmpptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ see if at least PARALLEL_FACTOR blocks left\n-      __ jcc(Assembler::less, L_singleBlockLoopTop[k]);\n-\n-      __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-      __ movdqu(xmm_counter_shuf_mask, ExternalAddress(counter_shuffle_mask_addr()));\n-\n-      \/\/load, then increase counters\n-      CTR_DoFour(movdqa, xmm_curr_counter);\n-      __ push(rbx);\n-      inc_counter(rbx, xmm_result1, 0x01, L_incCounter[k][0]);\n-      inc_counter(rbx, xmm_result2, 0x02, L_incCounter[k][1]);\n-      inc_counter(rbx, xmm_result3, 0x03, L_incCounter[k][2]);\n-      inc_counter(rbx, xmm_curr_counter, 0x04, L_incCounter[k][3]);\n-      __ pop (rbx);\n-\n-      load_key(xmm_key, key, 0x00, xmm_key_shuf_mask); \/\/ load Round 0 key. interleaving for better performance\n-\n-      CTR_DoFour(pshufb, xmm_counter_shuf_mask); \/\/ after increased, shuffled counters back for PXOR\n-      CTR_DoFour(pxor, xmm_key);   \/\/PXOR with Round 0 key\n-\n-      for (int i = 1; i < rounds[k]; ++i) {\n-        load_key(xmm_key, key, (0x10 * i), xmm_key_shuf_mask);\n-        CTR_DoFour(aesenc, xmm_key);\n-      }\n-      load_key(xmm_key, key, (0x10 * rounds[k]), xmm_key_shuf_mask);\n-      CTR_DoFour(aesenclast, xmm_key);\n-\n-      \/\/ get next PARALLEL_FACTOR blocks into xmm_from registers\n-      __ movdqu(xmm_from0, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-      __ movdqu(xmm_from1, Address(from, pos, Address::times_1, 1 * AESBlockSize));\n-      __ movdqu(xmm_from2, Address(from, pos, Address::times_1, 2 * AESBlockSize));\n-\n-      \/\/ PXOR with input text\n-      __ pxor(xmm_result0, xmm_from0); \/\/result0 is xmm4\n-      __ pxor(xmm_result1, xmm_from1);\n-      __ pxor(xmm_result2, xmm_from2);\n-\n-      \/\/ store PARALLEL_FACTOR results into the next 64 bytes of output\n-      __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);\n-      __ movdqu(Address(to, pos, Address::times_1, 1 * AESBlockSize), xmm_result1);\n-      __ movdqu(Address(to, pos, Address::times_1, 2 * AESBlockSize), xmm_result2);\n-\n-      \/\/ do it here after xmm_result0 is saved, because xmm_from3 reuse the same register of xmm_result0.\n-      __ movdqu(xmm_from3, Address(from, pos, Address::times_1, 3 * AESBlockSize));\n-      __ pxor(xmm_result3, xmm_from3);\n-      __ movdqu(Address(to, pos, Address::times_1, 3 * AESBlockSize), xmm_result3);\n-\n-      __ addptr(pos, PARALLEL_FACTOR * AESBlockSize); \/\/ increase the length of crypt text\n-      __ subptr(len_reg, PARALLEL_FACTOR * AESBlockSize); \/\/ decrease the remaining length\n-      __ jmp(L_multiBlock_loopTop[k]);\n-\n-      \/\/ singleBlock starts here\n-      __ align(OptoLoopAlignment);\n-      __ BIND(L_singleBlockLoopTop[k]);\n-      __ cmpptr(len_reg, 0);\n-      __ jcc(Assembler::equal, L_exit);\n-      __ movdqu(xmm_key_shuf_mask, ExternalAddress(key_shuffle_mask_addr()));\n-      __ movdqu(xmm_counter_shuf_mask, ExternalAddress(counter_shuffle_mask_addr()));\n-      __ movdqa(xmm_result0, xmm_curr_counter);\n-      load_key(xmm_key, key, 0x00, xmm_key_shuf_mask);\n-      __ push(rbx);\/\/rbx is used for increasing counter\n-      inc_counter(rbx, xmm_curr_counter, 0x01, L_incCounter_single[k]);\n-      __ pop (rbx);\n-      __ pshufb(xmm_result0, xmm_counter_shuf_mask);\n-      __ pxor(xmm_result0, xmm_key);\n-      for (int i = 1; i < rounds[k]; i++) {\n-        load_key(xmm_key, key, (0x10 * i), xmm_key_shuf_mask);\n-        __ aesenc(xmm_result0, xmm_key);\n-      }\n-      load_key(xmm_key, key, (0x10 * rounds[k]), xmm_key_shuf_mask);\n-      __ aesenclast(xmm_result0, xmm_key);\n-      __ cmpptr(len_reg, AESBlockSize);\n-      __ jcc(Assembler::less, L_processTail_insr[k]);\n-        __ movdqu(xmm_from0, Address(from, pos, Address::times_1, 0 * AESBlockSize));\n-        __ pxor(xmm_result0, xmm_from0);\n-        __ movdqu(Address(to, pos, Address::times_1, 0 * AESBlockSize), xmm_result0);\n-        __ addptr(pos, AESBlockSize);\n-        __ subptr(len_reg, AESBlockSize);\n-        __ jmp(L_singleBlockLoopTop[k]);\n-\n-      __ BIND(L_processTail_insr[k]);                                               \/\/ Process the tail part of the input array\n-        __ addptr(pos, len_reg);                                                    \/\/ 1. Insert bytes from src array into xmm_from0 register\n-        __ testptr(len_reg, 8);\n-        __ jcc(Assembler::zero, L_processTail_4_insr[k]);\n-          __ subptr(pos,8);\n-          __ pinsrd(xmm_from0, Address(from, pos), 0);\n-          __ pinsrd(xmm_from0, Address(from, pos, Address::times_1, 4), 1);\n-        __ BIND(L_processTail_4_insr[k]);\n-        __ testptr(len_reg, 4);\n-        __ jcc(Assembler::zero, L_processTail_2_insr[k]);\n-          __ subptr(pos,4);\n-          __ pslldq(xmm_from0, 4);\n-          __ pinsrd(xmm_from0, Address(from, pos), 0);\n-        __ BIND(L_processTail_2_insr[k]);\n-        __ testptr(len_reg, 2);\n-        __ jcc(Assembler::zero, L_processTail_1_insr[k]);\n-          __ subptr(pos, 2);\n-          __ pslldq(xmm_from0, 2);\n-          __ pinsrw(xmm_from0, Address(from, pos), 0);\n-        __ BIND(L_processTail_1_insr[k]);\n-        __ testptr(len_reg, 1);\n-        __ jcc(Assembler::zero, L_processTail_exit_insr[k]);\n-          __ subptr(pos, 1);\n-          __ pslldq(xmm_from0, 1);\n-          __ pinsrb(xmm_from0, Address(from, pos), 0);\n-        __ BIND(L_processTail_exit_insr[k]);\n-\n-        __ movptr(saved_encCounter_start, saved_counter_param);\n-        __ movdqu(Address(saved_encCounter_start, 0), xmm_result0);               \/\/ 2. Perform pxor of the encrypted counter and plaintext Bytes.\n-        __ pxor(xmm_result0, xmm_from0);                                          \/\/    Also the encrypted counter is saved for next invocation.\n-\n-        __ testptr(len_reg, 8);\n-        __ jcc(Assembler::zero, L_processTail_4_extr[k]);                        \/\/ 3. Extract bytes from xmm_result0 into the dest. array\n-          __ pextrd(Address(to, pos), xmm_result0, 0);\n-          __ pextrd(Address(to, pos, Address::times_1, 4), xmm_result0, 1);\n-          __ psrldq(xmm_result0, 8);\n-          __ addptr(pos, 8);\n-        __ BIND(L_processTail_4_extr[k]);\n-        __ testptr(len_reg, 4);\n-        __ jcc(Assembler::zero, L_processTail_2_extr[k]);\n-          __ pextrd(Address(to, pos), xmm_result0, 0);\n-          __ psrldq(xmm_result0, 4);\n-          __ addptr(pos, 4);\n-        __ BIND(L_processTail_2_extr[k]);\n-        __ testptr(len_reg, 2);\n-        __ jcc(Assembler::zero, L_processTail_1_extr[k]);\n-          __ pextrb(Address(to, pos), xmm_result0, 0);\n-          __ pextrb(Address(to, pos, Address::times_1, 1), xmm_result0, 1);\n-          __ psrldq(xmm_result0, 2);\n-          __ addptr(pos, 2);\n-        __ BIND(L_processTail_1_extr[k]);\n-        __ testptr(len_reg, 1);\n-        __ jcc(Assembler::zero, L_processTail_exit_extr[k]);\n-          __ pextrb(Address(to, pos), xmm_result0, 0);\n-\n-        __ BIND(L_processTail_exit_extr[k]);\n-        __ movptr(used_addr, used_addr_param);\n-        __ movl(Address(used_addr, 0), len_reg);\n-        __ jmp(L_exit);\n-    }\n-\n-    __ BIND(L_exit);\n-    __ movdqu(xmm_counter_shuf_mask, ExternalAddress(counter_shuffle_mask_addr()));\n-    __ pshufb(xmm_curr_counter, xmm_counter_shuf_mask); \/\/counter is shuffled back.\n-    __ movdqu(Address(counter, 0), xmm_curr_counter); \/\/save counter back\n-    handleSOERegisters(false \/*restoring*\/);\n-    __ movptr(rax, len_param); \/\/ return length\n-    __ leave();                \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    __ BIND (L_key192_top);\n-    __ movptr(pos, 0); \/\/ init pos before L_multiBlock_loopTop\n-    __ jmp(L_multiBlock_loopTop[1]); \/\/key192\n-\n-    __ BIND (L_key256_top);\n-    __ movptr(pos, 0); \/\/ init pos before L_multiBlock_loopTop\n-    __ jmp(L_multiBlock_loopTop[2]); \/\/key192\n-\n-    return start;\n-  }\n-\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.MD5.implCompress(byte[] b, int ofs)\n-  address generate_md5_implCompress(StubGenStubId stub_id) {\n-    bool multi_block;\n-    switch(stub_id) {\n-    case StubGenStubId::md5_implCompress_id:\n-      multi_block = false;\n-      break;\n-    case StubGenStubId::md5_implCompressMB_id:\n-      multi_block = true;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    const Register buf_param = rbp;\n-    const Address state_param(rsp, 0 * wordSize);\n-    const Address ofs_param  (rsp, 1 * wordSize);\n-    const Address limit_param(rsp, 2 * wordSize);\n-\n-    __ enter();\n-    __ push(rbx);\n-    __ push(rdi);\n-    __ push(rsi);\n-    __ push(rbp);\n-    __ subptr(rsp, 3 * wordSize);\n-\n-    __ movptr(rsi, Address(rbp, 8 + 4));\n-    __ movptr(state_param, rsi);\n-    if (multi_block) {\n-      __ movptr(rsi, Address(rbp, 8 + 8));\n-      __ movptr(ofs_param, rsi);\n-      __ movptr(rsi, Address(rbp, 8 + 12));\n-      __ movptr(limit_param, rsi);\n-    }\n-    __ movptr(buf_param, Address(rbp, 8 + 0)); \/\/ do it last because it override rbp\n-    __ fast_md5(buf_param, state_param, ofs_param, limit_param, multi_block);\n-\n-    __ addptr(rsp, 3 * wordSize);\n-    __ pop(rbp);\n-    __ pop(rsi);\n-    __ pop(rdi);\n-    __ pop(rbx);\n-    __ leave();\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  address generate_upper_word_mask() {\n-    __ align64();\n-    StubGenStubId stub_id = StubGenStubId::upper_word_mask_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0x00000000, relocInfo::none, 0);\n-    __ emit_data(0xFFFFFFFF, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  address generate_shuffle_byte_flip_mask() {\n-    __ align64();\n-    StubGenStubId stub_id = StubGenStubId::shuffle_byte_flip_mask_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x0c0d0e0f, relocInfo::none, 0);\n-    __ emit_data(0x08090a0b, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n-  address generate_sha1_implCompress(StubGenStubId stub_id) {\n-    bool multi_block;\n-    switch(stub_id) {\n-    case StubGenStubId::sha1_implCompress_id:\n-      multi_block = false;\n-      break;\n-    case StubGenStubId::sha1_implCompressMB_id:\n-      multi_block = true;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Register buf   = rax;\n-    Register state = rdx;\n-    Register ofs   = rcx;\n-    Register limit = rdi;\n-\n-    const Address  buf_param(rbp, 8 + 0);\n-    const Address  state_param(rbp, 8 + 4);\n-    const Address  ofs_param(rbp, 8 + 8);\n-    const Address  limit_param(rbp, 8 + 12);\n-\n-    const XMMRegister abcd = xmm0;\n-    const XMMRegister e0 = xmm1;\n-    const XMMRegister e1 = xmm2;\n-    const XMMRegister msg0 = xmm3;\n-\n-    const XMMRegister msg1 = xmm4;\n-    const XMMRegister msg2 = xmm5;\n-    const XMMRegister msg3 = xmm6;\n-    const XMMRegister shuf_mask = xmm7;\n-\n-    __ enter();\n-    __ subptr(rsp, 8 * wordSize);\n-    handleSOERegisters(true \/*saving*\/);\n-\n-    __ movptr(buf, buf_param);\n-    __ movptr(state, state_param);\n-    if (multi_block) {\n-      __ movptr(ofs, ofs_param);\n-      __ movptr(limit, limit_param);\n-    }\n-\n-    __ fast_sha1(abcd, e0, e1, msg0, msg1, msg2, msg3, shuf_mask,\n-      buf, state, ofs, limit, rsp, multi_block);\n-\n-    handleSOERegisters(false \/*restoring*\/);\n-    __ addptr(rsp, 8 * wordSize);\n-    __ leave();\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  address generate_pshuffle_byte_flip_mask() {\n-    __ align64();\n-    StubGenStubId stub_id = StubGenStubId::pshuffle_byte_flip_mask_id;\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-    __ emit_data(0x00010203, relocInfo::none, 0);\n-    __ emit_data(0x04050607, relocInfo::none, 0);\n-    __ emit_data(0x08090a0b, relocInfo::none, 0);\n-    __ emit_data(0x0c0d0e0f, relocInfo::none, 0);\n-    return start;\n-  }\n-\n-  \/\/ ofs and limit are use for multi-block byte array.\n-  \/\/ int com.sun.security.provider.DigestBase.implCompressMultiBlock(byte[] b, int ofs, int limit)\n- address generate_sha256_implCompress(StubGenStubId stub_id) {\n-    bool multi_block;\n-    switch(stub_id) {\n-    case StubGenStubId::sha256_implCompress_id:\n-      multi_block = false;\n-      break;\n-    case StubGenStubId::sha256_implCompressMB_id:\n-      multi_block = true;\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, stub_id);\n-    address start = __ pc();\n-\n-    Register buf = rbx;\n-    Register state = rsi;\n-    Register ofs = rdx;\n-    Register limit = rcx;\n-\n-    const Address  buf_param(rbp, 8 + 0);\n-    const Address  state_param(rbp, 8 + 4);\n-    const Address  ofs_param(rbp, 8 + 8);\n-    const Address  limit_param(rbp, 8 + 12);\n-\n-    const XMMRegister msg = xmm0;\n-    const XMMRegister state0 = xmm1;\n-    const XMMRegister state1 = xmm2;\n-    const XMMRegister msgtmp0 = xmm3;\n-\n-    const XMMRegister msgtmp1 = xmm4;\n-    const XMMRegister msgtmp2 = xmm5;\n-    const XMMRegister msgtmp3 = xmm6;\n-    const XMMRegister msgtmp4 = xmm7;\n-\n-    __ enter();\n-    __ subptr(rsp, 8 * wordSize);\n-    handleSOERegisters(true \/*saving*\/);\n-    __ movptr(buf, buf_param);\n-    __ movptr(state, state_param);\n-    if (multi_block) {\n-     __ movptr(ofs, ofs_param);\n-     __ movptr(limit, limit_param);\n-    }\n-\n-    __ fast_sha256(msg, state0, state1, msgtmp0, msgtmp1, msgtmp2, msgtmp3, msgtmp4,\n-      buf, state, ofs, limit, rsp, multi_block);\n-\n-    handleSOERegisters(false);\n-    __ addptr(rsp, 8 * wordSize);\n-    __ leave();\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  \/\/ byte swap x86 long\n-  address ghash_long_swap_mask_addr() {\n-    return (address)GHASH_LONG_SWAP_MASK;\n-  }\n-\n-  \/\/ byte swap x86 byte array\n-  address ghash_byte_swap_mask_addr() {\n-    return (address)GHASH_BYTE_SWAP_MASK;\n-  }\n-\n-  \/* Single and multi-block ghash operations *\/\n-  address generate_ghash_processBlocks() {\n-    assert(UseGHASHIntrinsics, \"need GHASH intrinsics and CLMUL support\");\n-    __ align(CodeEntryAlignment);\n-    Label L_ghash_loop, L_exit;\n-    StubGenStubId stub_id = StubGenStubId::ghash_processBlocks_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    address start = __ pc();\n-\n-    const Register state        = rdi;\n-    const Register subkeyH      = rsi;\n-    const Register data         = rdx;\n-    const Register blocks       = rcx;\n-\n-    const Address  state_param(rbp, 8+0);\n-    const Address  subkeyH_param(rbp, 8+4);\n-    const Address  data_param(rbp, 8+8);\n-    const Address  blocks_param(rbp, 8+12);\n-\n-    const XMMRegister xmm_temp0 = xmm0;\n-    const XMMRegister xmm_temp1 = xmm1;\n-    const XMMRegister xmm_temp2 = xmm2;\n-    const XMMRegister xmm_temp3 = xmm3;\n-    const XMMRegister xmm_temp4 = xmm4;\n-    const XMMRegister xmm_temp5 = xmm5;\n-    const XMMRegister xmm_temp6 = xmm6;\n-    const XMMRegister xmm_temp7 = xmm7;\n-\n-    __ enter();\n-    handleSOERegisters(true);  \/\/ Save registers\n-\n-    __ movptr(state, state_param);\n-    __ movptr(subkeyH, subkeyH_param);\n-    __ movptr(data, data_param);\n-    __ movptr(blocks, blocks_param);\n-\n-    __ movdqu(xmm_temp0, Address(state, 0));\n-    __ pshufb(xmm_temp0, ExternalAddress(ghash_long_swap_mask_addr()));\n-\n-    __ movdqu(xmm_temp1, Address(subkeyH, 0));\n-    __ pshufb(xmm_temp1, ExternalAddress(ghash_long_swap_mask_addr()));\n-\n-    __ BIND(L_ghash_loop);\n-    __ movdqu(xmm_temp2, Address(data, 0));\n-    __ pshufb(xmm_temp2, ExternalAddress(ghash_byte_swap_mask_addr()));\n-\n-    __ pxor(xmm_temp0, xmm_temp2);\n-\n-    \/\/\n-    \/\/ Multiply with the hash key\n-    \/\/\n-    __ movdqu(xmm_temp3, xmm_temp0);\n-    __ pclmulqdq(xmm_temp3, xmm_temp1, 0);      \/\/ xmm3 holds a0*b0\n-    __ movdqu(xmm_temp4, xmm_temp0);\n-    __ pclmulqdq(xmm_temp4, xmm_temp1, 16);     \/\/ xmm4 holds a0*b1\n-\n-    __ movdqu(xmm_temp5, xmm_temp0);\n-    __ pclmulqdq(xmm_temp5, xmm_temp1, 1);      \/\/ xmm5 holds a1*b0\n-    __ movdqu(xmm_temp6, xmm_temp0);\n-    __ pclmulqdq(xmm_temp6, xmm_temp1, 17);     \/\/ xmm6 holds a1*b1\n-\n-    __ pxor(xmm_temp4, xmm_temp5);      \/\/ xmm4 holds a0*b1 + a1*b0\n-\n-    __ movdqu(xmm_temp5, xmm_temp4);    \/\/ move the contents of xmm4 to xmm5\n-    __ psrldq(xmm_temp4, 8);    \/\/ shift by xmm4 64 bits to the right\n-    __ pslldq(xmm_temp5, 8);    \/\/ shift by xmm5 64 bits to the left\n-    __ pxor(xmm_temp3, xmm_temp5);\n-    __ pxor(xmm_temp6, xmm_temp4);      \/\/ Register pair <xmm6:xmm3> holds the result\n-                                        \/\/ of the carry-less multiplication of\n-                                        \/\/ xmm0 by xmm1.\n-\n-    \/\/ We shift the result of the multiplication by one bit position\n-    \/\/ to the left to cope for the fact that the bits are reversed.\n-    __ movdqu(xmm_temp7, xmm_temp3);\n-    __ movdqu(xmm_temp4, xmm_temp6);\n-    __ pslld (xmm_temp3, 1);\n-    __ pslld(xmm_temp6, 1);\n-    __ psrld(xmm_temp7, 31);\n-    __ psrld(xmm_temp4, 31);\n-    __ movdqu(xmm_temp5, xmm_temp7);\n-    __ pslldq(xmm_temp4, 4);\n-    __ pslldq(xmm_temp7, 4);\n-    __ psrldq(xmm_temp5, 12);\n-    __ por(xmm_temp3, xmm_temp7);\n-    __ por(xmm_temp6, xmm_temp4);\n-    __ por(xmm_temp6, xmm_temp5);\n-\n-    \/\/\n-    \/\/ First phase of the reduction\n-    \/\/\n-    \/\/ Move xmm3 into xmm4, xmm5, xmm7 in order to perform the shifts\n-    \/\/ independently.\n-    __ movdqu(xmm_temp7, xmm_temp3);\n-    __ movdqu(xmm_temp4, xmm_temp3);\n-    __ movdqu(xmm_temp5, xmm_temp3);\n-    __ pslld(xmm_temp7, 31);    \/\/ packed right shift shifting << 31\n-    __ pslld(xmm_temp4, 30);    \/\/ packed right shift shifting << 30\n-    __ pslld(xmm_temp5, 25);    \/\/ packed right shift shifting << 25\n-    __ pxor(xmm_temp7, xmm_temp4);      \/\/ xor the shifted versions\n-    __ pxor(xmm_temp7, xmm_temp5);\n-    __ movdqu(xmm_temp4, xmm_temp7);\n-    __ pslldq(xmm_temp7, 12);\n-    __ psrldq(xmm_temp4, 4);\n-    __ pxor(xmm_temp3, xmm_temp7);      \/\/ first phase of the reduction complete\n-\n-    \/\/\n-    \/\/ Second phase of the reduction\n-    \/\/\n-    \/\/ Make 3 copies of xmm3 in xmm2, xmm5, xmm7 for doing these\n-    \/\/ shift operations.\n-    __ movdqu(xmm_temp2, xmm_temp3);\n-    __ movdqu(xmm_temp7, xmm_temp3);\n-    __ movdqu(xmm_temp5, xmm_temp3);\n-    __ psrld(xmm_temp2, 1);     \/\/ packed left shifting >> 1\n-    __ psrld(xmm_temp7, 2);     \/\/ packed left shifting >> 2\n-    __ psrld(xmm_temp5, 7);     \/\/ packed left shifting >> 7\n-    __ pxor(xmm_temp2, xmm_temp7);      \/\/ xor the shifted versions\n-    __ pxor(xmm_temp2, xmm_temp5);\n-    __ pxor(xmm_temp2, xmm_temp4);\n-    __ pxor(xmm_temp3, xmm_temp2);\n-    __ pxor(xmm_temp6, xmm_temp3);      \/\/ the result is in xmm6\n-\n-    __ decrement(blocks);\n-    __ jcc(Assembler::zero, L_exit);\n-    __ movdqu(xmm_temp0, xmm_temp6);\n-    __ addptr(data, 16);\n-    __ jmp(L_ghash_loop);\n-\n-    __ BIND(L_exit);\n-       \/\/ Byte swap 16-byte result\n-    __ pshufb(xmm_temp6, ExternalAddress(ghash_long_swap_mask_addr()));\n-    __ movdqu(Address(state, 0), xmm_temp6);   \/\/ store the result\n-\n-    handleSOERegisters(false);  \/\/ restore registers\n-    __ leave();\n-    __ ret(0);\n-    return start;\n-  }\n-\n-  \/**\n-   *  Arguments:\n-   *\n-   * Inputs:\n-   *   rsp(4)   - int crc\n-   *   rsp(8)   - byte* buf\n-   *   rsp(12)  - int length\n-   *\n-   * Output:\n-   *       rax   - int crc result\n-   *\/\n-  address generate_updateBytesCRC32() {\n-    assert(UseCRC32Intrinsics, \"need AVX and CLMUL instructions\");\n-\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::updateBytesCRC32_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    address start = __ pc();\n-\n-    const Register crc   = rdx;  \/\/ crc\n-    const Register buf   = rsi;  \/\/ source java byte array address\n-    const Register len   = rcx;  \/\/ length\n-    const Register table = rdi;  \/\/ crc_table address (reuse register)\n-    const Register tmp   = rbx;\n-    assert_different_registers(crc, buf, len, table, tmp, rax);\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ push(rsi);\n-    __ push(rdi);\n-    __ push(rbx);\n-\n-    Address crc_arg(rbp, 8 + 0);\n-    Address buf_arg(rbp, 8 + 4);\n-    Address len_arg(rbp, 8 + 8);\n-\n-    \/\/ Load up:\n-    __ movl(crc,   crc_arg);\n-    __ movptr(buf, buf_arg);\n-    __ movl(len,   len_arg);\n-\n-    __ kernel_crc32(crc, buf, len, table, tmp);\n-\n-    __ movl(rax, crc);\n-    __ pop(rbx);\n-    __ pop(rdi);\n-    __ pop(rsi);\n-    __ vzeroupper();\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n-  \/**\n-  *  Arguments:\n-  *\n-  * Inputs:\n-  *   rsp(4)   - int crc\n-  *   rsp(8)   - byte* buf\n-  *   rsp(12)  - int length\n-  *   rsp(16)  - table_start - optional (present only when doing a library_calll,\n-  *              not used by x86 algorithm)\n-  *\n-  * Output:\n-  *       rax  - int crc result\n-  *\/\n-  address generate_updateBytesCRC32C(bool is_pclmulqdq_supported) {\n-    assert(UseCRC32CIntrinsics, \"need SSE4_2\");\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::updateBytesCRC32C_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    address start = __ pc();\n-    const Register crc = rax;  \/\/ crc\n-    const Register buf = rcx;  \/\/ source java byte array address\n-    const Register len = rdx;  \/\/ length\n-    const Register d = rbx;\n-    const Register g = rsi;\n-    const Register h = rdi;\n-    const Register empty = noreg; \/\/ will never be used, in order not\n-                                  \/\/ to change a signature for crc32c_IPL_Alg2_Alt2\n-                                  \/\/ between 64\/32 I'm just keeping it here\n-    assert_different_registers(crc, buf, len, d, g, h);\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    Address crc_arg(rsp, 4 + 4 + 0); \/\/ ESP+4 +\n-                                     \/\/ we need to add additional 4 because __ enter\n-                                     \/\/ have just pushed ebp on a stack\n-    Address buf_arg(rsp, 4 + 4 + 4);\n-    Address len_arg(rsp, 4 + 4 + 8);\n-      \/\/ Load up:\n-      __ movl(crc, crc_arg);\n-      __ movl(buf, buf_arg);\n-      __ movl(len, len_arg);\n-      __ push(d);\n-      __ push(g);\n-      __ push(h);\n-      __ crc32c_ipl_alg2_alt2(crc, buf, len,\n-                              d, g, h,\n-                              empty, empty, empty,\n-                              xmm0, xmm1, xmm2,\n-                              is_pclmulqdq_supported);\n-      __ pop(h);\n-      __ pop(g);\n-      __ pop(d);\n-    __ vzeroupper();\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n- address generate_libmExp() {\n-    StubGenStubId stub_id = StubGenStubId::dexp_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    address start = __ pc();\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ fast_exp(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-                rax, rcx, rdx, rbx);\n-    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-    __ ret(0);\n-\n-    return start;\n-\n-  }\n-\n- address generate_libmLog() {\n-   StubGenStubId stub_id = StubGenStubId::dlog_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_log(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rcx, rdx, rbx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n- address generate_libmLog10() {\n-   StubGenStubId stub_id = StubGenStubId::dlog10_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_log10(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rcx, rdx, rbx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n- address generate_libmPow() {\n-   StubGenStubId stub_id = StubGenStubId::dpow_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_pow(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rcx, rdx, rbx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n- address generate_libm_reduce_pi04l() {\n-   StubGenStubId stub_id = StubGenStubId::dlibm_reduce_pi04l_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ libm_reduce_pi04l(rax, rcx, rdx, rbx, rsi, rdi, rbp, rsp);\n-\n-   return start;\n-\n- }\n-\n- address generate_libm_sin_cos_huge() {\n-   StubGenStubId stub_id = StubGenStubId::dlibm_sin_cos_huge_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ libm_sincos_huge(xmm0, xmm1, rax, rcx, rdx, rbx, rsi, rdi, rbp, rsp);\n-\n-   return start;\n-\n- }\n-\n- address generate_libmSin() {\n-   StubGenStubId stub_id = StubGenStubId::dsin_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_sin(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rbx, rdx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n- address generate_libmCos() {\n-   StubGenStubId stub_id = StubGenStubId::dcos_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_cos(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rcx, rdx, rbx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n- address generate_libm_tan_cot_huge() {\n-   StubGenStubId stub_id = StubGenStubId::dlibm_tan_cot_huge_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ libm_tancot_huge(xmm0, xmm1, rax, rcx, rdx, rbx, rsi, rdi, rbp, rsp);\n-\n-   return start;\n-\n- }\n-\n- address generate_libmTan() {\n-   StubGenStubId stub_id = StubGenStubId::dtan_id;\n-   StubCodeMark mark(this, stub_id);\n-\n-   address start = __ pc();\n-\n-   BLOCK_COMMENT(\"Entry:\");\n-   __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ fast_tan(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n-               rax, rcx, rdx, rbx);\n-   __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n-   __ ret(0);\n-\n-   return start;\n-\n- }\n-\n-  address generate_method_entry_barrier() {\n-    __ align(CodeEntryAlignment);\n-    StubGenStubId stub_id = StubGenStubId::method_entry_barrier_id;\n-    StubCodeMark mark(this, stub_id);\n-\n-    Label deoptimize_label;\n-\n-    address start = __ pc();\n-\n-    __ push(-1); \/\/ cookie, this is used for writing the new rsp when deoptimizing\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-    __ enter(); \/\/ save rbp\n-\n-    \/\/ save rbx, because we want to use that value.\n-    \/\/ We could do without it but then we depend on the number of slots used by pusha\n-    __ push(rbx);\n-\n-    __ lea(rbx, Address(rsp, wordSize * 3)); \/\/ 1 for cookie, 1 for rbp, 1 for rbx - this should be the return address\n-\n-    __ pusha();\n-\n-    \/\/ xmm0 and xmm1 may be used for passing float\/double arguments\n-\n-    if (UseSSE >= 2) {\n-      const int xmm_size = wordSize * 4;\n-      __ subptr(rsp, xmm_size * 2);\n-      __ movdbl(Address(rsp, xmm_size * 1), xmm1);\n-      __ movdbl(Address(rsp, xmm_size * 0), xmm0);\n-    } else if (UseSSE >= 1) {\n-      const int xmm_size = wordSize * 2;\n-      __ subptr(rsp, xmm_size * 2);\n-      __ movflt(Address(rsp, xmm_size * 1), xmm1);\n-      __ movflt(Address(rsp, xmm_size * 0), xmm0);\n-    }\n-\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<int (*)(address*)>(BarrierSetNMethod::nmethod_stub_entry_barrier)), rbx);\n-\n-    if (UseSSE >= 2) {\n-      const int xmm_size = wordSize * 4;\n-      __ movdbl(xmm0, Address(rsp, xmm_size * 0));\n-      __ movdbl(xmm1, Address(rsp, xmm_size * 1));\n-      __ addptr(rsp, xmm_size * 2);\n-    } else if (UseSSE >= 1) {\n-      const int xmm_size = wordSize * 2;\n-      __ movflt(xmm0, Address(rsp, xmm_size * 0));\n-      __ movflt(xmm1, Address(rsp, xmm_size * 1));\n-      __ addptr(rsp, xmm_size * 2);\n-    }\n-\n-    __ cmpl(rax, 1); \/\/ 1 means deoptimize\n-    __ jcc(Assembler::equal, deoptimize_label);\n-\n-    __ popa();\n-    __ pop(rbx);\n-\n-    __ leave();\n-\n-    __ addptr(rsp, 1 * wordSize); \/\/ cookie\n-    __ ret(0);\n-\n-    __ BIND(deoptimize_label);\n-\n-    __ popa();\n-    __ pop(rbx);\n-\n-    __ leave();\n-\n-    \/\/ this can be taken out, but is good for verification purposes. getting a SIGSEGV\n-    \/\/ here while still having a correct stack is valuable\n-    __ testptr(rsp, Address(rsp, 0));\n-\n-    __ movptr(rsp, Address(rsp, 0)); \/\/ new rsp was written in the barrier\n-    __ jmp(Address(rsp, -1 * wordSize)); \/\/ jmp target should be callers verified_entry_point\n-\n-    return start;\n-  }\n-\n- private:\n-\n-  void create_control_words() {\n-    \/\/ Round to nearest, 53-bit mode, exceptions masked\n-    StubRoutines::x86::_fpu_cntrl_wrd_std   = 0x027F;\n-    \/\/ Round to zero, 53-bit mode, exception mased\n-    StubRoutines::x86::_fpu_cntrl_wrd_trunc = 0x0D7F;\n-    \/\/ Round to nearest, 24-bit mode, exceptions masked\n-    StubRoutines::x86::_fpu_cntrl_wrd_24    = 0x007F;\n-    \/\/ Round to nearest, 64-bit mode, exceptions masked, flags specialized\n-    StubRoutines::x86::_mxcsr_std           = EnableX86ECoreOpts ? 0x1FBF : 0x1F80;\n-    \/\/ Note: the following two constants are 80-bit values\n-    \/\/       layout is critical for correct loading by FPU.\n-    \/\/ Bias for strict fp multiply\/divide\n-    StubRoutines::x86::_fpu_subnormal_bias1[0]= 0x00000000; \/\/ 2^(-15360) == 0x03ff 8000 0000 0000 0000\n-    StubRoutines::x86::_fpu_subnormal_bias1[1]= 0x80000000;\n-    StubRoutines::x86::_fpu_subnormal_bias1[2]= 0x03ff;\n-    \/\/ Un-Bias for strict fp multiply\/divide\n-    StubRoutines::x86::_fpu_subnormal_bias2[0]= 0x00000000; \/\/ 2^(+15360) == 0x7bff 8000 0000 0000 0000\n-    StubRoutines::x86::_fpu_subnormal_bias2[1]= 0x80000000;\n-    StubRoutines::x86::_fpu_subnormal_bias2[2]= 0x7bff;\n-  }\n-\n-  address generate_cont_thaw() {\n-    if (!Continuations::enabled()) return nullptr;\n-    Unimplemented();\n-    return nullptr;\n-  }\n-\n-  address generate_cont_returnBarrier() {\n-    if (!Continuations::enabled()) return nullptr;\n-    Unimplemented();\n-    return nullptr;\n-  }\n-\n-  address generate_cont_returnBarrier_exception() {\n-    if (!Continuations::enabled()) return nullptr;\n-    Unimplemented();\n-    return nullptr;\n-  }\n-\n-  \/\/---------------------------------------------------------------------------\n-  \/\/ Initialization\n-\n-  void generate_initial_stubs() {\n-    \/\/ Generates all stubs and initializes the entry points\n-\n-    \/\/------------------------------------------------------------------------------------------------------------------------\n-    \/\/ entry points that exist in all platforms\n-    \/\/ Note: This is code that could be shared among different platforms - however the benefit seems to be smaller than\n-    \/\/       the disadvantage of having a much more complicated generator structure. See also comment in stubRoutines.hpp.\n-    StubRoutines::_forward_exception_entry      = generate_forward_exception();\n-\n-    StubRoutines::_call_stub_entry              =\n-      generate_call_stub(StubRoutines::_call_stub_return_address);\n-    \/\/ is referenced by megamorphic call\n-    StubRoutines::_catch_exception_entry        = generate_catch_exception();\n-\n-    \/\/ platform dependent\n-    create_control_words();\n-\n-    \/\/ Initialize table for copy memory (arraycopy) check.\n-    if (UnsafeMemoryAccess::_table == nullptr) {\n-      UnsafeMemoryAccess::create_table(16 + 4); \/\/ 16 for copyMemory; 4 for setMemory\n-    }\n-\n-    StubRoutines::x86::_verify_mxcsr_entry         = generate_verify_mxcsr();\n-    StubRoutines::x86::_verify_fpu_cntrl_wrd_entry = generate_verify_fpu_cntrl_wrd();\n-    StubRoutines::x86::_d2i_wrapper                = generate_d2i_wrapper(T_INT,  CAST_FROM_FN_PTR(address, SharedRuntime::d2i));\n-    StubRoutines::x86::_d2l_wrapper                = generate_d2i_wrapper(T_LONG, CAST_FROM_FN_PTR(address, SharedRuntime::d2l));\n-\n-    if (UseCRC32Intrinsics) {\n-      \/\/ set table address before stub generation which use it\n-      StubRoutines::_crc_table_adr = (address)StubRoutines::x86::_crc_table;\n-      StubRoutines::_updateBytesCRC32 = generate_updateBytesCRC32();\n-    }\n-\n-    if (UseCRC32CIntrinsics) {\n-      bool supports_clmul = VM_Version::supports_clmul();\n-      StubRoutines::x86::generate_CRC32C_table(supports_clmul);\n-      StubRoutines::_crc32c_table_addr = (address)StubRoutines::x86::_crc32c_table;\n-      StubRoutines::_updateBytesCRC32C = generate_updateBytesCRC32C(supports_clmul);\n-    }\n-    if (VM_Version::supports_sse2() && UseLibmIntrinsic && InlineIntrinsics) {\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dexp)) {\n-        StubRoutines::_dexp = generate_libmExp();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dlog)) {\n-        StubRoutines::_dlog = generate_libmLog();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dlog10)) {\n-        StubRoutines::_dlog10 = generate_libmLog10();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dpow)) {\n-        StubRoutines::_dpow = generate_libmPow();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||\n-        vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos) ||\n-        vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {\n-        StubRoutines::_dlibm_reduce_pi04l = generate_libm_reduce_pi04l();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||\n-        vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos)) {\n-        StubRoutines::_dlibm_sin_cos_huge = generate_libm_sin_cos_huge();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin)) {\n-        StubRoutines::_dsin = generate_libmSin();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos)) {\n-        StubRoutines::_dcos = generate_libmCos();\n-      }\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {\n-        StubRoutines::_dlibm_tan_cot_huge = generate_libm_tan_cot_huge();\n-        StubRoutines::_dtan = generate_libmTan();\n-      }\n-    }\n-  }\n-\n-  void generate_continuation_stubs() {\n-    \/\/ Continuation stubs:\n-    StubRoutines::_cont_thaw          = generate_cont_thaw();\n-    StubRoutines::_cont_returnBarrier = generate_cont_returnBarrier();\n-    StubRoutines::_cont_returnBarrierExc = generate_cont_returnBarrier_exception();\n-  }\n-\n-  void generate_final_stubs() {\n-    \/\/ Generates all stubs and initializes the entry points\n-\n-    \/\/ support for verify_oop (must happen after universe_init)\n-    StubRoutines::_verify_oop_subroutine_entry     = generate_verify_oop();\n-\n-    \/\/ arraycopy stubs used by compilers\n-    generate_arraycopy_stubs();\n-\n-    StubRoutines::_method_entry_barrier = generate_method_entry_barrier();\n-  }\n-\n-  void generate_compiler_stubs() {\n-#if COMPILER2_OR_JVMCI\n-\n-    \/\/ entry points that are C2\/JVMCI specific\n-\n-    StubRoutines::x86::_vector_float_sign_mask = generate_vector_mask(StubGenStubId::vector_float_sign_mask_id, 0x7FFFFFFF);\n-    StubRoutines::x86::_vector_float_sign_flip = generate_vector_mask(StubGenStubId::vector_float_sign_flip_id, 0x80000000);\n-    StubRoutines::x86::_vector_double_sign_mask = generate_vector_mask_long_double(StubGenStubId::vector_double_sign_mask_id, 0x7FFFFFFF, 0xFFFFFFFF);\n-    StubRoutines::x86::_vector_double_sign_flip = generate_vector_mask_long_double(StubGenStubId::vector_double_sign_flip_id, 0x80000000, 0x00000000);\n-    StubRoutines::x86::_vector_short_to_byte_mask = generate_vector_mask(StubGenStubId::vector_short_to_byte_mask_id, 0x00ff00ff);\n-    StubRoutines::x86::_vector_int_to_byte_mask = generate_vector_mask(StubGenStubId::vector_int_to_byte_mask_id, 0x000000ff);\n-    StubRoutines::x86::_vector_int_to_short_mask = generate_vector_mask(StubGenStubId::vector_int_to_short_mask_id, 0x0000ffff);\n-    StubRoutines::x86::_vector_32_bit_mask = generate_vector_custom_i32(StubGenStubId::vector_32_bit_mask_id, Assembler::AVX_512bit,\n-                                                                        0xFFFFFFFF, 0, 0, 0);\n-    StubRoutines::x86::_vector_64_bit_mask = generate_vector_custom_i32(StubGenStubId::vector_64_bit_mask_id, Assembler::AVX_512bit,\n-                                                                        0xFFFFFFFF, 0xFFFFFFFF, 0, 0);\n-    StubRoutines::x86::_vector_int_shuffle_mask = generate_vector_mask(StubGenStubId::vector_int_shuffle_mask_id, 0x03020100);\n-    StubRoutines::x86::_vector_byte_shuffle_mask = generate_vector_byte_shuffle_mask();\n-    StubRoutines::x86::_vector_short_shuffle_mask = generate_vector_mask(StubGenStubId::vector_short_shuffle_mask_id, 0x01000100);\n-    StubRoutines::x86::_vector_long_shuffle_mask = generate_vector_mask_long_double(StubGenStubId::vector_long_shuffle_mask_id, 0x00000001, 0x0);\n-    StubRoutines::x86::_vector_byte_perm_mask = generate_vector_byte_perm_mask();\n-    StubRoutines::x86::_vector_long_sign_mask = generate_vector_mask_long_double(StubGenStubId::vector_long_sign_mask_id, 0x80000000, 0x00000000);\n-    StubRoutines::x86::_vector_all_bits_set = generate_vector_mask(StubGenStubId::vector_all_bits_set_id, 0xFFFFFFFF);\n-    StubRoutines::x86::_vector_int_mask_cmp_bits = generate_vector_mask(StubGenStubId::vector_int_mask_cmp_bits_id, 0x00000001);\n-    StubRoutines::x86::_vector_iota_indices = generate_iota_indices();\n-    StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut();\n-    StubRoutines::x86::_vector_reverse_bit_lut = generate_vector_reverse_bit_lut();\n-    StubRoutines::x86::_vector_reverse_byte_perm_mask_long = generate_vector_reverse_byte_perm_mask_long();\n-    StubRoutines::x86::_vector_reverse_byte_perm_mask_int = generate_vector_reverse_byte_perm_mask_int();\n-    StubRoutines::x86::_vector_reverse_byte_perm_mask_short = generate_vector_reverse_byte_perm_mask_short();\n-\n-    if (VM_Version::supports_avx2() && !VM_Version::supports_avx512_vpopcntdq()) {\n-      \/\/ lut implementation influenced by counting 1s algorithm from section 5-1 of Hackers' Delight.\n-      StubRoutines::x86::_vector_popcount_lut = generate_popcount_avx_lut();\n-    }\n-\n-    \/\/ don't bother generating these AES intrinsic stubs unless global flag is set\n-    if (UseAESIntrinsics) {\n-      StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();\n-      StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();\n-      StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();\n-      StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();\n-    }\n-\n-    if (UseAESCTRIntrinsics) {\n-      StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();\n-    }\n-\n-    if (UseMD5Intrinsics) {\n-      StubRoutines::_md5_implCompress = generate_md5_implCompress(StubGenStubId::md5_implCompress_id);\n-      StubRoutines::_md5_implCompressMB = generate_md5_implCompress(StubGenStubId::md5_implCompressMB_id);\n-    }\n-    if (UseSHA1Intrinsics) {\n-      StubRoutines::x86::_upper_word_mask_addr = generate_upper_word_mask();\n-      StubRoutines::x86::_shuffle_byte_flip_mask_addr = generate_shuffle_byte_flip_mask();\n-      StubRoutines::_sha1_implCompress = generate_sha1_implCompress(StubGenStubId::sha1_implCompress_id);\n-      StubRoutines::_sha1_implCompressMB = generate_sha1_implCompress(StubGenStubId::sha1_implCompressMB_id);\n-    }\n-    if (UseSHA256Intrinsics) {\n-      StubRoutines::x86::_k256_adr = (address)StubRoutines::x86::_k256;\n-      StubRoutines::x86::_pshuffle_byte_flip_mask_addr = generate_pshuffle_byte_flip_mask();\n-      StubRoutines::_sha256_implCompress = generate_sha256_implCompress(StubGenStubId::sha256_implCompress_id);\n-      StubRoutines::_sha256_implCompressMB = generate_sha256_implCompress(StubGenStubId::sha256_implCompressMB_id);\n-    }\n-\n-    \/\/ Generate GHASH intrinsics code\n-    if (UseGHASHIntrinsics) {\n-      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n-    }\n-#endif \/\/ COMPILER2_OR_JVMCI\n-  }\n-\n-\n- public:\n-  StubGenerator(CodeBuffer* code, StubGenBlobId blob_id) : StubCodeGenerator(code, blob_id) {\n-    switch(blob_id) {\n-    case initial_id:\n-      generate_initial_stubs();\n-      break;\n-     case continuation_id:\n-      generate_continuation_stubs();\n-      break;\n-    case compiler_id:\n-      generate_compiler_stubs();\n-      break;\n-    case final_id:\n-      generate_final_stubs();\n-      break;\n-    default:\n-      fatal(\"unexpected blob id: %d\", blob_id);\n-      break;\n-    };\n-  }\n-}; \/\/ end class declaration\n-\n-void StubGenerator_generate(CodeBuffer* code, StubGenBlobId blob_id) {\n-  StubGenerator g(code, blob_id);\n-}\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":0,"deletions":4314,"binary":false,"changes":4314,"status":"deleted"},{"patch":"@@ -1,41 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"runtime\/deoptimization.hpp\"\n-#include \"runtime\/frame.inline.hpp\"\n-#include \"runtime\/javaThread.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-\n-\/\/ Implementation of the platform-specific part of StubRoutines - for\n-\/\/ a description of how to extend it, see the stubRoutines.hpp file.\n-\n-jint StubRoutines::x86::_fpu_cntrl_wrd_std   = 0;\n-jint StubRoutines::x86::_fpu_cntrl_wrd_24    = 0;\n-jint StubRoutines::x86::_fpu_cntrl_wrd_trunc = 0;\n-\n-jint StubRoutines::x86::_mxcsr_std = 0;\n-\n-jint StubRoutines::x86::_fpu_subnormal_bias1[3] = { 0, 0, 0 };\n-jint StubRoutines::x86::_fpu_subnormal_bias2[3] = { 0, 0, 0 };\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86_32.cpp","additions":0,"deletions":41,"binary":false,"changes":41,"status":"deleted"},{"patch":"@@ -1,509 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"compiler\/disassembler.hpp\"\n-#include \"interpreter\/interp_masm.hpp\"\n-#include \"interpreter\/interpreter.hpp\"\n-#include \"interpreter\/interpreterRuntime.hpp\"\n-#include \"interpreter\/templateInterpreterGenerator.hpp\"\n-#include \"runtime\/arguments.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-\n-#define __ Disassembler::hook<InterpreterMacroAssembler>(__FILE__, __LINE__, _masm)->\n-\n-\n-address TemplateInterpreterGenerator::generate_slow_signature_handler() {\n-  address entry = __ pc();\n-  \/\/ rbx,: method\n-  \/\/ rcx: temporary\n-  \/\/ rdi: pointer to locals\n-  \/\/ rsp: end of copied parameters area\n-  __ mov(rcx, rsp);\n-  __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::slow_signature_handler), rbx, rdi, rcx);\n-  __ ret(0);\n-  return entry;\n-}\n-\n-\/**\n- * Method entry for static native methods:\n- *   int java.util.zip.CRC32.update(int crc, int b)\n- *\/\n-address TemplateInterpreterGenerator::generate_CRC32_update_entry() {\n-  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n-  address entry = __ pc();\n-\n-  \/\/ rbx: Method*\n-  \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n-  \/\/ rdx: scratch\n-  \/\/ rdi: scratch\n-\n-  Label slow_path;\n-  \/\/ If we need a safepoint check, generate full interpreter entry.\n-  __ get_thread(rdi);\n-  __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-  \/\/ We don't generate local frame and don't align stack because\n-  \/\/ we call stub code and there is no safepoint on this path.\n-\n-  \/\/ Load parameters\n-  const Register crc = rax;  \/\/ crc\n-  const Register val = rdx;  \/\/ source java byte value\n-  const Register tbl = rdi;  \/\/ scratch\n-\n-  \/\/ Arguments are reversed on java expression stack\n-  __ movl(val, Address(rsp,   wordSize)); \/\/ byte value\n-  __ movl(crc, Address(rsp, 2*wordSize)); \/\/ Initial CRC\n-\n-  __ lea(tbl, ExternalAddress(StubRoutines::crc_table_addr()));\n-  __ notl(crc); \/\/ ~crc\n-  __ update_byte_crc32(crc, val, tbl);\n-  __ notl(crc); \/\/ ~crc\n-  \/\/ result in rax\n-\n-  \/\/ _areturn\n-  __ pop(rdi);                \/\/ get return address\n-  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-  __ jmp(rdi);\n-\n-  \/\/ generate a vanilla native entry as the slow path\n-  __ bind(slow_path);\n-  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-  return entry;\n-}\n-\n-\/**\n- * Method entry for static native methods:\n- *   int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int len)\n- *   int java.util.zip.CRC32.updateByteBuffer(int crc, long buf, int off, int len)\n- *\/\n-address TemplateInterpreterGenerator::generate_CRC32_updateBytes_entry(AbstractInterpreter::MethodKind kind) {\n-  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n-  address entry = __ pc();\n-\n-  \/\/ rbx,: Method*\n-  \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n-  \/\/ rdx: scratch\n-  \/\/ rdi: scratch\n-\n-  Label slow_path;\n-  \/\/ If we need a safepoint check, generate full interpreter entry.\n-  __ get_thread(rdi);\n-  __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-  \/\/ We don't generate local frame and don't align stack because\n-  \/\/ we call stub code and there is no safepoint on this path.\n-\n-  \/\/ Load parameters\n-  const Register crc = rax;  \/\/ crc\n-  const Register buf = rdx;  \/\/ source java byte array address\n-  const Register len = rdi;  \/\/ length\n-\n-  \/\/ value              x86_32\n-  \/\/ interp. arg ptr    ESP + 4\n-  \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int len)\n-  \/\/                                         3           2      1        0\n-  \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long buf, int off, int len)\n-  \/\/                                              4         2,3      1        0\n-\n-  \/\/ Arguments are reversed on java expression stack\n-  __ movl(len,   Address(rsp,   4 + 0)); \/\/ Length\n-  \/\/ Calculate address of start element\n-  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n-    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long buf\n-    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-    __ movl(crc,   Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n-  } else {\n-    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n-    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-    __ movl(crc,   Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n-  }\n-\n-  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()), crc, buf, len);\n-  \/\/ result in rax\n-\n-  \/\/ _areturn\n-  __ pop(rdi);                \/\/ get return address\n-  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-  __ jmp(rdi);\n-\n-  \/\/ generate a vanilla native entry as the slow path\n-  __ bind(slow_path);\n-  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-  return entry;\n-}\n-\n-\/**\n-* Method entry for static native methods:\n-*   int java.util.zip.CRC32C.updateBytes(int crc, byte[] b, int off, int end)\n-*   int java.util.zip.CRC32C.updateByteBuffer(int crc, long address, int off, int end)\n-*\/\n-address TemplateInterpreterGenerator::generate_CRC32C_updateBytes_entry(AbstractInterpreter::MethodKind kind) {\n-  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n-  address entry = __ pc();\n-  \/\/ Load parameters\n-  const Register crc = rax;  \/\/ crc\n-  const Register buf = rcx;  \/\/ source java byte array address\n-  const Register len = rdx;  \/\/ length\n-  const Register end = len;\n-\n-  \/\/ value              x86_32\n-  \/\/ interp. arg ptr    ESP + 4\n-  \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int end)\n-  \/\/                                         3           2      1        0\n-  \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long address, int off, int end)\n-  \/\/                                              4         2,3          1        0\n-\n-  \/\/ Arguments are reversed on java expression stack\n-  __ movl(end, Address(rsp, 4 + 0)); \/\/ end\n-  __ subl(len, Address(rsp, 4 + 1 * wordSize));  \/\/ end - offset == length\n-  \/\/ Calculate address of start element\n-  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n-    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long address\n-    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-    __ movl(crc, Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n-  } else {\n-    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n-    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-    __ movl(crc, Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n-  }\n-  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()), crc, buf, len);\n-  \/\/ result in rax\n-  \/\/ _areturn\n-  __ pop(rdi);                \/\/ get return address\n-  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-  __ jmp(rdi);\n-\n-  return entry;\n-}\n-\n-\/**\n- * Method entry for static native method:\n- *    java.lang.Float.intBitsToFloat(int bits)\n- *\/\n-address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() {\n-  if (UseSSE >= 1) {\n-    address entry = __ pc();\n-\n-    \/\/ rsi: the sender's SP\n-\n-    \/\/ Skip safepoint check (compiler intrinsic versions of this method\n-    \/\/ do not perform safepoint checks either).\n-\n-    \/\/ Load 'bits' into xmm0 (interpreter returns results in xmm0)\n-    __ movflt(xmm0, Address(rsp, wordSize));\n-\n-    \/\/ Return\n-    __ pop(rdi); \/\/ get return address\n-    __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-    __ jmp(rdi);\n-    return entry;\n-  }\n-\n-  return nullptr;\n-}\n-\n-\/**\n- * Method entry for static native method:\n- *    java.lang.Float.floatToRawIntBits(float value)\n- *\/\n-address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() {\n-  if (UseSSE >= 1) {\n-    address entry = __ pc();\n-\n-    \/\/ rsi: the sender's SP\n-\n-    \/\/ Skip safepoint check (compiler intrinsic versions of this method\n-    \/\/ do not perform safepoint checks either).\n-\n-    \/\/ Load the parameter (a floating-point value) into rax.\n-    __ movl(rax, Address(rsp, wordSize));\n-\n-    \/\/ Return\n-    __ pop(rdi); \/\/ get return address\n-    __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-    __ jmp(rdi);\n-    return entry;\n-  }\n-\n-  return nullptr;\n-}\n-\n-\n-\/**\n- * Method entry for static native method:\n- *    java.lang.Double.longBitsToDouble(long bits)\n- *\/\n-address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() {\n-   if (UseSSE >= 2) {\n-     address entry = __ pc();\n-\n-     \/\/ rsi: the sender's SP\n-\n-     \/\/ Skip safepoint check (compiler intrinsic versions of this method\n-     \/\/ do not perform safepoint checks either).\n-\n-     \/\/ Load 'bits' into xmm0 (interpreter returns results in xmm0)\n-     __ movdbl(xmm0, Address(rsp, wordSize));\n-\n-     \/\/ Return\n-     __ pop(rdi); \/\/ get return address\n-     __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-     __ jmp(rdi);\n-     return entry;\n-   }\n-\n-   return nullptr;\n-}\n-\n-\/**\n- * Method entry for static native method:\n- *    java.lang.Double.doubleToRawLongBits(double value)\n- *\/\n-address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() {\n-  if (UseSSE >= 2) {\n-    address entry = __ pc();\n-\n-    \/\/ rsi: the sender's SP\n-\n-    \/\/ Skip safepoint check (compiler intrinsic versions of this method\n-    \/\/ do not perform safepoint checks either).\n-\n-    \/\/ Load the parameter (a floating-point value) into rax.\n-    __ movl(rdx, Address(rsp, 2*wordSize));\n-    __ movl(rax, Address(rsp, wordSize));\n-\n-    \/\/ Return\n-    __ pop(rdi); \/\/ get return address\n-    __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-    __ jmp(rdi);\n-    return entry;\n-  }\n-\n-  return nullptr;\n-}\n-\n-\/**\n- * Method entry for static method:\n- *    java.lang.Float.float16ToFloat(short floatBinary16)\n- *\/\n-address TemplateInterpreterGenerator::generate_Float_float16ToFloat_entry() {\n-  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n-  address entry = __ pc();\n-\n-  \/\/ rsi: the sender's SP\n-\n-  \/\/ Load value into xmm0 and convert\n-  __ movswl(rax, Address(rsp, wordSize));\n-  __ flt16_to_flt(xmm0, rax);\n-\n-  \/\/ Return\n-  __ pop(rdi); \/\/ get return address\n-  __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-  __ jmp(rdi);\n-  return entry;\n-}\n-\n-\/**\n- * Method entry for static method:\n- *    java.lang.Float.floatToFloat16(float value)\n- *\/\n-address TemplateInterpreterGenerator::generate_Float_floatToFloat16_entry() {\n-  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n-  address entry = __ pc();\n-\n-  \/\/ rsi: the sender's SP\n-\n-  \/\/ Load value into xmm0, convert and put result into rax\n-  __ movflt(xmm0, Address(rsp, wordSize));\n-  __ flt_to_flt16(rax, xmm0, xmm1);\n-\n-  \/\/ Return\n-  __ pop(rdi); \/\/ get return address\n-  __ mov(rsp, rsi); \/\/ set rsp to the sender's SP\n-  __ jmp(rdi);\n-  return entry;\n-}\n-\n-address TemplateInterpreterGenerator::generate_math_entry(AbstractInterpreter::MethodKind kind) {\n-\n-  \/\/ rbx,: Method*\n-  \/\/ rcx: scratrch\n-  \/\/ rsi: sender sp\n-\n-  address entry_point = __ pc();\n-\n-  \/\/ These don't need a safepoint check because they aren't virtually\n-  \/\/ callable. We won't enter these intrinsics from compiled code.\n-  \/\/ If in the future we added an intrinsic which was virtually callable\n-  \/\/ we'd have to worry about how to safepoint so that this code is used.\n-\n-  \/\/ mathematical functions inlined by compiler\n-  \/\/ (interpreter must provide identical implementation\n-  \/\/ in order to avoid monotonicity bugs when switching\n-  \/\/ from interpreter to compiler in the middle of some\n-  \/\/ computation)\n-  \/\/\n-  \/\/ stack: [ ret adr ] <-- rsp\n-  \/\/        [ lo(arg) ]\n-  \/\/        [ hi(arg) ]\n-  \/\/\n-  if (kind == Interpreter::java_lang_math_tanh) {\n-    return nullptr;\n-  }\n-\n-  if (kind == Interpreter::java_lang_math_fmaD) {\n-    if (!UseFMA) {\n-      return nullptr; \/\/ Generate a vanilla entry\n-    }\n-    __ movdbl(xmm2, Address(rsp, 5 * wordSize));\n-    __ movdbl(xmm1, Address(rsp, 3 * wordSize));\n-    __ movdbl(xmm0, Address(rsp, 1 * wordSize));\n-    __ fmad(xmm0, xmm1, xmm2, xmm0);\n-    __ pop(rdi);                               \/\/ get return address\n-    __ mov(rsp, rsi);                          \/\/ set sp to sender sp\n-    __ jmp(rdi);\n-\n-    return entry_point;\n-  } else if (kind == Interpreter::java_lang_math_fmaF) {\n-    if (!UseFMA) {\n-      return nullptr; \/\/ Generate a vanilla entry\n-    }\n-    __ movflt(xmm2, Address(rsp, 3 * wordSize));\n-    __ movflt(xmm1, Address(rsp, 2 * wordSize));\n-    __ movflt(xmm0, Address(rsp, 1 * wordSize));\n-    __ fmaf(xmm0, xmm1, xmm2, xmm0);\n-    __ pop(rdi);                               \/\/ get return address\n-    __ mov(rsp, rsi);                          \/\/ set sp to sender sp\n-    __ jmp(rdi);\n-\n-    return entry_point;\n- }\n-\n-  __ fld_d(Address(rsp, 1*wordSize));\n-  switch (kind) {\n-    case Interpreter::java_lang_math_sin :\n-        __ subptr(rsp, 2 * wordSize);\n-        __ fstp_d(Address(rsp, 0));\n-        if (VM_Version::supports_sse2() && StubRoutines::dsin() != nullptr) {\n-          __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dsin())));\n-        } else {\n-          __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dsin));\n-        }\n-        __ addptr(rsp, 2 * wordSize);\n-        break;\n-    case Interpreter::java_lang_math_cos :\n-        __ subptr(rsp, 2 * wordSize);\n-        __ fstp_d(Address(rsp, 0));\n-        if (VM_Version::supports_sse2() && StubRoutines::dcos() != nullptr) {\n-          __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dcos())));\n-        } else {\n-          __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dcos));\n-        }\n-        __ addptr(rsp, 2 * wordSize);\n-        break;\n-    case Interpreter::java_lang_math_tan :\n-        __ subptr(rsp, 2 * wordSize);\n-        __ fstp_d(Address(rsp, 0));\n-        if (StubRoutines::dtan() != nullptr) {\n-          __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dtan())));\n-        } else {\n-          __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dtan));\n-        }\n-        __ addptr(rsp, 2 * wordSize);\n-        break;\n-    case Interpreter::java_lang_math_sqrt:\n-        __ fsqrt();\n-        break;\n-    case Interpreter::java_lang_math_abs:\n-        __ fabs();\n-        break;\n-    case Interpreter::java_lang_math_log:\n-        __ subptr(rsp, 2 * wordSize);\n-        __ fstp_d(Address(rsp, 0));\n-        if (StubRoutines::dlog() != nullptr) {\n-          __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlog())));\n-        } else {\n-          __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dlog));\n-        }\n-        __ addptr(rsp, 2 * wordSize);\n-        break;\n-    case Interpreter::java_lang_math_log10:\n-        __ subptr(rsp, 2 * wordSize);\n-        __ fstp_d(Address(rsp, 0));\n-        if (StubRoutines::dlog10() != nullptr) {\n-          __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dlog10())));\n-        } else {\n-          __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dlog10));\n-        }\n-        __ addptr(rsp, 2 * wordSize);\n-        break;\n-    case Interpreter::java_lang_math_pow:\n-      __ fld_d(Address(rsp, 3*wordSize)); \/\/ second argument\n-      __ subptr(rsp, 4 * wordSize);\n-      __ fstp_d(Address(rsp, 0));\n-      __ fstp_d(Address(rsp, 2 * wordSize));\n-      if (StubRoutines::dpow() != nullptr) {\n-        __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dpow())));\n-      } else {\n-        __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dpow));\n-      }\n-      __ addptr(rsp, 4 * wordSize);\n-      break;\n-    case Interpreter::java_lang_math_exp:\n-      __ subptr(rsp, 2*wordSize);\n-      __ fstp_d(Address(rsp, 0));\n-      if (StubRoutines::dexp() != nullptr) {\n-        __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::dexp())));\n-      } else {\n-        __ call_VM_leaf0(CAST_FROM_FN_PTR(address, SharedRuntime::dexp));\n-      }\n-      __ addptr(rsp, 2*wordSize);\n-    break;\n-    default                              :\n-        ShouldNotReachHere();\n-  }\n-\n-  \/\/ return double result in xmm0 for interpreter and compilers.\n-  if (UseSSE >= 2) {\n-    __ subptr(rsp, 2*wordSize);\n-    __ fstp_d(Address(rsp, 0));\n-    __ movdbl(xmm0, Address(rsp, 0));\n-    __ addptr(rsp, 2*wordSize);\n-  }\n-\n-  \/\/ done, result in FPU ST(0) or XMM0\n-  __ pop(rdi);                               \/\/ get return address\n-  __ mov(rsp, rsi);                          \/\/ set sp to sender sp\n-  __ jmp(rdi);\n-\n-  return entry_point;\n-}\n-\n-\/\/ Not supported\n-address TemplateInterpreterGenerator::generate_currentThread() { return nullptr; }\n-\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86_32.cpp","additions":0,"deletions":509,"binary":false,"changes":509,"status":"deleted"},{"patch":"@@ -1,33 +0,0 @@\n-\/*\n- * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"prims\/upcallLinker.hpp\"\n-\n-address UpcallLinker::make_upcall_stub(jobject receiver, Symbol* signature,\n-                                       BasicType* out_sig_bt, int total_out_args,\n-                                       BasicType ret_type,\n-                                       jobject jabi, jobject jconv,\n-                                       bool needs_return_buffer, int ret_buf_size) {\n-  ShouldNotCallThis();\n-  return nullptr;\n-}\n","filename":"src\/hotspot\/cpu\/x86\/upcallLinker_x86_32.cpp","additions":0,"deletions":33,"binary":false,"changes":33,"status":"deleted"},{"patch":"@@ -1,265 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"code\/compiledIC.hpp\"\n-#include \"code\/vtableStubs.hpp\"\n-#include \"interp_masm_x86.hpp\"\n-#include \"memory\/resourceArea.hpp\"\n-#include \"oops\/instanceKlass.hpp\"\n-#include \"oops\/klassVtable.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"vmreg_x86.inline.hpp\"\n-#ifdef COMPILER2\n-#include \"opto\/runtime.hpp\"\n-#endif\n-\n-\/\/ machine-dependent part of VtableStubs: create VtableStub of correct size and\n-\/\/ initialize its code\n-\n-#define __ masm->\n-\n-#ifndef PRODUCT\n-extern \"C\" void bad_compiled_vtable_index(JavaThread* thread, oop receiver, int index);\n-#endif\n-\n-\/\/ These stubs are used by the compiler only.\n-\/\/ Argument registers, which must be preserved:\n-\/\/   rcx - receiver (always first argument)\n-\/\/   rdx - second argument (if any)\n-\/\/ Other registers that might be usable:\n-\/\/   rax - inline cache register (is interface for itable stub)\n-\/\/   rbx - method (used when calling out to interpreter)\n-\/\/ Available now, but may become callee-save at some point:\n-\/\/   rsi, rdi\n-\/\/ Note that rax and rdx are also used for return values.\n-\n-VtableStub* VtableStubs::create_vtable_stub(int vtable_index) {\n-  \/\/ Read \"A word on VtableStub sizing\" in share\/code\/vtableStubs.hpp for details on stub sizing.\n-  const int stub_code_length = code_size_limit(true);\n-  VtableStub* s = new(stub_code_length) VtableStub(true, vtable_index);\n-  \/\/ Can be null if there is no free space in the code cache.\n-  if (s == nullptr) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Count unused bytes in instruction sequences of variable size.\n-  \/\/ We add them to the computed buffer size in order to avoid\n-  \/\/ overflow in subsequently generated stubs.\n-  address   start_pc;\n-  int       slop_bytes = 0;\n-  int       slop_delta = 0;\n-  \/\/ No variance was detected in vtable stub sizes. Setting index_dependent_slop == 0 will unveil any deviation from this observation.\n-  const int index_dependent_slop     = 0;\n-\n-  ResourceMark    rm;\n-  CodeBuffer      cb(s->entry_point(), stub_code_length);\n-  MacroAssembler* masm = new MacroAssembler(&cb);\n-\n-#if (!defined(PRODUCT) && defined(COMPILER2))\n-  if (CountCompiledCalls) {\n-    __ incrementl(ExternalAddress((address) SharedRuntime::nof_megamorphic_calls_addr()));\n-  }\n-#endif\n-\n-  \/\/ get receiver (need to skip return address on top of stack)\n-  assert(VtableStub::receiver_location() == rcx->as_VMReg(), \"receiver expected in rcx\");\n-\n-  \/\/ get receiver klass\n-  address npe_addr = __ pc();\n-  __ movptr(rax, Address(rcx, oopDesc::klass_offset_in_bytes()));\n-\n-#ifndef PRODUCT\n-  if (DebugVtables) {\n-    Label L;\n-    start_pc = __ pc();\n-    \/\/ check offset vs vtable length\n-    __ cmpl(Address(rax, Klass::vtable_length_offset()), vtable_index*vtableEntry::size());\n-    slop_delta  = 10 - (__ pc() - start_pc);  \/\/ cmpl varies in length, depending on data\n-    slop_bytes += slop_delta;\n-    assert(slop_delta >= 0, \"negative slop(%d) encountered, adjust code size estimate!\", slop_delta);\n-\n-    __ jcc(Assembler::greater, L);\n-    __ movl(rbx, vtable_index);\n-    \/\/ VTABLE TODO: find upper bound for call_VM length.\n-    start_pc = __ pc();\n-    __ call_VM(noreg, CAST_FROM_FN_PTR(address, bad_compiled_vtable_index), rcx, rbx);\n-    slop_delta  = 500 - (__ pc() - start_pc);\n-    slop_bytes += slop_delta;\n-    assert(slop_delta >= 0, \"negative slop(%d) encountered, adjust code size estimate!\", slop_delta);\n-    __ bind(L);\n-  }\n-#endif \/\/ PRODUCT\n-\n-  const Register method = rbx;\n-\n-  \/\/ load Method* and target address\n-  start_pc = __ pc();\n-  __ lookup_virtual_method(rax, vtable_index, method);\n-  slop_delta  = 6 - (int)(__ pc() - start_pc);\n-  slop_bytes += slop_delta;\n-  assert(slop_delta >= 0, \"negative slop(%d) encountered, adjust code size estimate!\", slop_delta);\n-\n-#ifndef PRODUCT\n-  if (DebugVtables) {\n-    Label L;\n-    __ cmpptr(method, NULL_WORD);\n-    __ jcc(Assembler::equal, L);\n-    __ cmpptr(Address(method, Method::from_compiled_offset()), NULL_WORD);\n-    __ jcc(Assembler::notZero, L);\n-    __ stop(\"Vtable entry is null\");\n-    __ bind(L);\n-  }\n-#endif \/\/ PRODUCT\n-\n-  \/\/ rax: receiver klass\n-  \/\/ method (rbx): Method*\n-  \/\/ rcx: receiver\n-  address ame_addr = __ pc();\n-  __ jmp( Address(method, Method::from_compiled_offset()));\n-\n-  masm->flush();\n-  slop_bytes += index_dependent_slop; \/\/ add'l slop for size variance due to large itable offsets\n-  bookkeeping(masm, tty, s, npe_addr, ame_addr, true, vtable_index, slop_bytes, index_dependent_slop);\n-\n-  return s;\n-}\n-\n-\n-VtableStub* VtableStubs::create_itable_stub(int itable_index) {\n-  \/\/ Read \"A word on VtableStub sizing\" in share\/code\/vtableStubs.hpp for details on stub sizing.\n-  const int stub_code_length = code_size_limit(false);\n-  VtableStub* s = new(stub_code_length) VtableStub(false, itable_index);\n-  \/\/ Can be null if there is no free space in the code cache.\n-  if (s == nullptr) {\n-    return nullptr;\n-  }\n-  \/\/ Count unused bytes in instruction sequences of variable size.\n-  \/\/ We add them to the computed buffer size in order to avoid\n-  \/\/ overflow in subsequently generated stubs.\n-  address   start_pc;\n-  int       slop_bytes = 0;\n-  int       slop_delta = 0;\n-  const int index_dependent_slop = (itable_index == 0) ? 4 :     \/\/ code size change with transition from 8-bit to 32-bit constant (@index == 32).\n-                                   (itable_index < 32) ? 3 : 0;  \/\/ index == 0 generates even shorter code.\n-\n-  ResourceMark    rm;\n-  CodeBuffer      cb(s->entry_point(), stub_code_length);\n-  MacroAssembler* masm = new MacroAssembler(&cb);\n-\n-#if (!defined(PRODUCT) && defined(COMPILER2))\n-  if (CountCompiledCalls) {\n-    __ incrementl(ExternalAddress((address) SharedRuntime::nof_megamorphic_calls_addr()));\n-  }\n-#endif \/* PRODUCT *\/\n-\n-  \/\/ Entry arguments:\n-  \/\/  rax: CompiledICData\n-  \/\/  rcx: Receiver\n-\n-  \/\/ Most registers are in use; we'll use rax, rbx, rcx, rdx, rsi, rdi\n-  \/\/ (If we need to make rsi, rdi callee-save, do a push\/pop here.)\n-  const Register recv_klass_reg     = rsi;\n-  const Register holder_klass_reg   = rax; \/\/ declaring interface klass (DEFC)\n-  const Register resolved_klass_reg = rdi; \/\/ resolved interface klass (REFC)\n-  const Register temp_reg           = rdx;\n-  const Register method             = rbx;\n-  const Register icdata_reg         = rax;\n-  const Register receiver           = rcx;\n-\n-  __ movptr(resolved_klass_reg, Address(icdata_reg, CompiledICData::itable_refc_klass_offset()));\n-  __ movptr(holder_klass_reg,   Address(icdata_reg, CompiledICData::itable_defc_klass_offset()));\n-\n-  Label L_no_such_interface;\n-\n-  \/\/ get receiver klass (also an implicit null-check)\n-  assert(VtableStub::receiver_location() ==  rcx->as_VMReg(), \"receiver expected in  rcx\");\n-  address npe_addr = __ pc();\n-  __ load_klass(recv_klass_reg, rcx, noreg);\n-\n-  start_pc = __ pc();\n-  __ push(rdx); \/\/ temp_reg\n-\n-  \/\/ Receiver subtype check against REFC.\n-  \/\/ Get selected method from declaring class and itable index\n-  __ lookup_interface_method_stub(recv_klass_reg, \/\/ input\n-                                  holder_klass_reg, \/\/ input\n-                                  resolved_klass_reg, \/\/ input\n-                                  method, \/\/ output\n-                                  temp_reg,\n-                                  noreg,\n-                                  receiver, \/\/ input (x86_32 only: to restore recv_klass value)\n-                                  itable_index,\n-                                  L_no_such_interface);\n-  const ptrdiff_t  lookupSize = __ pc() - start_pc;\n-\n-  \/\/ We expect we need index_dependent_slop extra bytes. Reason:\n-  \/\/ The emitted code in lookup_interface_method changes when itable_index exceeds 31.\n-  \/\/ For windows, a narrow estimate was found to be 104. Other OSes not tested.\n-  const ptrdiff_t estimate = 104;\n-  const ptrdiff_t codesize = lookupSize + index_dependent_slop;\n-  slop_delta  = (int)(estimate - codesize);\n-  slop_bytes += slop_delta;\n-  assert(slop_delta >= 0, \"itable #%d: Code size estimate (%d) for lookup_interface_method too small, required: %d\", itable_index, (int)estimate, (int)codesize);\n-\n-  \/\/ method (rbx): Method*\n-  \/\/ rcx: receiver\n-\n-#ifdef ASSERT\n-  if (DebugVtables) {\n-    Label L1;\n-    __ cmpptr(method, NULL_WORD);\n-    __ jcc(Assembler::equal, L1);\n-    __ cmpptr(Address(method, Method::from_compiled_offset()), NULL_WORD);\n-    __ jcc(Assembler::notZero, L1);\n-    __ stop(\"Method* is null\");\n-    __ bind(L1);\n-  }\n-#endif \/\/ ASSERT\n-\n-  __ pop(rdx);\n-  address ame_addr = __ pc();\n-  __ jmp(Address(method, Method::from_compiled_offset()));\n-\n-  __ bind(L_no_such_interface);\n-  \/\/ Handle IncompatibleClassChangeError in itable stubs.\n-  \/\/ More detailed error message.\n-  \/\/ We force resolving of the call site by jumping to the \"handle\n-  \/\/ wrong method\" stub, and so let the interpreter runtime do all the\n-  \/\/ dirty work.\n-  __ pop(rdx);\n-  __ jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));\n-\n-  masm->flush();\n-  slop_bytes += index_dependent_slop; \/\/ add'l slop for size variance due to large itable offsets\n-  bookkeeping(masm, tty, s, npe_addr, ame_addr, false, itable_index, slop_bytes, index_dependent_slop);\n-\n-  return s;\n-}\n-\n-int VtableStub::pd_code_alignment() {\n-  \/\/ x86 cache line size is 64 bytes, but we want to limit alignment loss.\n-  const unsigned int icache_line_size = wordSize;\n-  return icache_line_size;\n-}\n","filename":"src\/hotspot\/cpu\/x86\/vtableStubs_x86_32.cpp","additions":0,"deletions":265,"binary":false,"changes":265,"status":"deleted"},{"patch":"@@ -1,13702 +0,0 @@\n-\/\/\n-\/\/ Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n-\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-\/\/\n-\/\/ This code is free software; you can redistribute it and\/or modify it\n-\/\/ under the terms of the GNU General Public License version 2 only, as\n-\/\/ published by the Free Software Foundation.\n-\/\/\n-\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n-\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-\/\/ version 2 for more details (a copy is included in the LICENSE file that\n-\/\/ accompanied this code).\n-\/\/\n-\/\/ You should have received a copy of the GNU General Public License version\n-\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n-\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-\/\/\n-\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-\/\/ or visit www.oracle.com if you need additional information or have any\n-\/\/ questions.\n-\/\/\n-\/\/\n-\n-\/\/ X86 Architecture Description File\n-\n-\/\/----------REGISTER DEFINITION BLOCK------------------------------------------\n-\/\/ This information is used by the matcher and the register allocator to\n-\/\/ describe individual registers and classes of registers within the target\n-\/\/ architecture.\n-\n-register %{\n-\/\/----------Architecture Description Register Definitions----------------------\n-\/\/ General Registers\n-\/\/ \"reg_def\"  name ( register save type, C convention save type,\n-\/\/                   ideal register type, encoding );\n-\/\/ Register Save Types:\n-\/\/\n-\/\/ NS  = No-Save:       The register allocator assumes that these registers\n-\/\/                      can be used without saving upon entry to the method, &\n-\/\/                      that they do not need to be saved at call sites.\n-\/\/\n-\/\/ SOC = Save-On-Call:  The register allocator assumes that these registers\n-\/\/                      can be used without saving upon entry to the method,\n-\/\/                      but that they must be saved at call sites.\n-\/\/\n-\/\/ SOE = Save-On-Entry: The register allocator assumes that these registers\n-\/\/                      must be saved before using them upon entry to the\n-\/\/                      method, but they do not need to be saved at call\n-\/\/                      sites.\n-\/\/\n-\/\/ AS  = Always-Save:   The register allocator assumes that these registers\n-\/\/                      must be saved before using them upon entry to the\n-\/\/                      method, & that they must be saved at call sites.\n-\/\/\n-\/\/ Ideal Register Type is used to determine how to save & restore a\n-\/\/ register.  Op_RegI will get spilled with LoadI\/StoreI, Op_RegP will get\n-\/\/ spilled with LoadP\/StoreP.  If the register supports both, use Op_RegI.\n-\/\/\n-\/\/ The encoding number is the actual bit-pattern placed into the opcodes.\n-\n-\/\/ General Registers\n-\/\/ Previously set EBX, ESI, and EDI as save-on-entry for java code\n-\/\/ Turn off SOE in java-code due to frequent use of uncommon-traps.\n-\/\/ Now that allocator is better, turn on ESI and EDI as SOE registers.\n-\n-reg_def EBX(SOC, SOE, Op_RegI, 3, rbx->as_VMReg());\n-reg_def ECX(SOC, SOC, Op_RegI, 1, rcx->as_VMReg());\n-reg_def ESI(SOC, SOE, Op_RegI, 6, rsi->as_VMReg());\n-reg_def EDI(SOC, SOE, Op_RegI, 7, rdi->as_VMReg());\n-\/\/ now that adapter frames are gone EBP is always saved and restored by the prolog\/epilog code\n-reg_def EBP(NS, SOE, Op_RegI, 5, rbp->as_VMReg());\n-reg_def EDX(SOC, SOC, Op_RegI, 2, rdx->as_VMReg());\n-reg_def EAX(SOC, SOC, Op_RegI, 0, rax->as_VMReg());\n-reg_def ESP( NS,  NS, Op_RegI, 4, rsp->as_VMReg());\n-\n-\/\/ Float registers.  We treat TOS\/FPR0 special.  It is invisible to the\n-\/\/ allocator, and only shows up in the encodings.\n-reg_def FPR0L( SOC, SOC, Op_RegF, 0, VMRegImpl::Bad());\n-reg_def FPR0H( SOC, SOC, Op_RegF, 0, VMRegImpl::Bad());\n-\/\/ Ok so here's the trick FPR1 is really st(0) except in the midst\n-\/\/ of emission of assembly for a machnode. During the emission the fpu stack\n-\/\/ is pushed making FPR1 == st(1) temporarily. However at any safepoint\n-\/\/ the stack will not have this element so FPR1 == st(0) from the\n-\/\/ oopMap viewpoint. This same weirdness with numbering causes\n-\/\/ instruction encoding to have to play games with the register\n-\/\/ encode to correct for this 0\/1 issue. See MachSpillCopyNode::implementation\n-\/\/ where it does flt->flt moves to see an example\n-\/\/\n-reg_def FPR1L( SOC, SOC, Op_RegF, 1, as_FloatRegister(0)->as_VMReg());\n-reg_def FPR1H( SOC, SOC, Op_RegF, 1, as_FloatRegister(0)->as_VMReg()->next());\n-reg_def FPR2L( SOC, SOC, Op_RegF, 2, as_FloatRegister(1)->as_VMReg());\n-reg_def FPR2H( SOC, SOC, Op_RegF, 2, as_FloatRegister(1)->as_VMReg()->next());\n-reg_def FPR3L( SOC, SOC, Op_RegF, 3, as_FloatRegister(2)->as_VMReg());\n-reg_def FPR3H( SOC, SOC, Op_RegF, 3, as_FloatRegister(2)->as_VMReg()->next());\n-reg_def FPR4L( SOC, SOC, Op_RegF, 4, as_FloatRegister(3)->as_VMReg());\n-reg_def FPR4H( SOC, SOC, Op_RegF, 4, as_FloatRegister(3)->as_VMReg()->next());\n-reg_def FPR5L( SOC, SOC, Op_RegF, 5, as_FloatRegister(4)->as_VMReg());\n-reg_def FPR5H( SOC, SOC, Op_RegF, 5, as_FloatRegister(4)->as_VMReg()->next());\n-reg_def FPR6L( SOC, SOC, Op_RegF, 6, as_FloatRegister(5)->as_VMReg());\n-reg_def FPR6H( SOC, SOC, Op_RegF, 6, as_FloatRegister(5)->as_VMReg()->next());\n-reg_def FPR7L( SOC, SOC, Op_RegF, 7, as_FloatRegister(6)->as_VMReg());\n-reg_def FPR7H( SOC, SOC, Op_RegF, 7, as_FloatRegister(6)->as_VMReg()->next());\n-\/\/\n-\/\/ Empty fill registers, which are never used, but supply alignment to xmm regs\n-\/\/\n-reg_def FILL0( SOC, SOC, Op_RegF, 8, VMRegImpl::Bad());\n-reg_def FILL1( SOC, SOC, Op_RegF, 9, VMRegImpl::Bad());\n-reg_def FILL2( SOC, SOC, Op_RegF, 10, VMRegImpl::Bad());\n-reg_def FILL3( SOC, SOC, Op_RegF, 11, VMRegImpl::Bad());\n-reg_def FILL4( SOC, SOC, Op_RegF, 12, VMRegImpl::Bad());\n-reg_def FILL5( SOC, SOC, Op_RegF, 13, VMRegImpl::Bad());\n-reg_def FILL6( SOC, SOC, Op_RegF, 14, VMRegImpl::Bad());\n-reg_def FILL7( SOC, SOC, Op_RegF, 15, VMRegImpl::Bad());\n-\n-\/\/ Specify priority of register selection within phases of register\n-\/\/ allocation.  Highest priority is first.  A useful heuristic is to\n-\/\/ give registers a low priority when they are required by machine\n-\/\/ instructions, like EAX and EDX.  Registers which are used as\n-\/\/ pairs must fall on an even boundary (witness the FPR#L's in this list).\n-\/\/ For the Intel integer registers, the equivalent Long pairs are\n-\/\/ EDX:EAX, EBX:ECX, and EDI:EBP.\n-alloc_class chunk0( ECX,   EBX,   EBP,   EDI,   EAX,   EDX,   ESI, ESP,\n-                    FPR0L, FPR0H, FPR1L, FPR1H, FPR2L, FPR2H,\n-                    FPR3L, FPR3H, FPR4L, FPR4H, FPR5L, FPR5H,\n-                    FPR6L, FPR6H, FPR7L, FPR7H,\n-                    FILL0, FILL1, FILL2, FILL3, FILL4, FILL5, FILL6, FILL7);\n-\n-\n-\/\/----------Architecture Description Register Classes--------------------------\n-\/\/ Several register classes are automatically defined based upon information in\n-\/\/ this architecture description.\n-\/\/ 1) reg_class inline_cache_reg           ( \/* as def'd in frame section *\/ )\n-\/\/ 2) reg_class stack_slots( \/* one chunk of stack-based \"registers\" *\/ )\n-\/\/\n-\/\/ Class for no registers (empty set).\n-reg_class no_reg();\n-\n-\/\/ Class for all registers\n-reg_class any_reg_with_ebp(EAX, EDX, EBP, EDI, ESI, ECX, EBX, ESP);\n-\/\/ Class for all registers (excluding EBP)\n-reg_class any_reg_no_ebp(EAX, EDX, EDI, ESI, ECX, EBX, ESP);\n-\/\/ Dynamic register class that selects at runtime between register classes\n-\/\/ any_reg and any_no_ebp_reg (depending on the value of the flag PreserveFramePointer).\n-\/\/ Equivalent to: return PreserveFramePointer ? any_no_ebp_reg : any_reg;\n-reg_class_dynamic any_reg(any_reg_no_ebp, any_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Class for general registers\n-reg_class int_reg_with_ebp(EAX, EDX, EBP, EDI, ESI, ECX, EBX);\n-\/\/ Class for general registers (excluding EBP).\n-\/\/ It is also safe for use by tailjumps (we don't want to allocate in ebp).\n-\/\/ Used also if the PreserveFramePointer flag is true.\n-reg_class int_reg_no_ebp(EAX, EDX, EDI, ESI, ECX, EBX);\n-\/\/ Dynamic register class that selects between int_reg and int_reg_no_ebp.\n-reg_class_dynamic int_reg(int_reg_no_ebp, int_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Class of \"X\" registers\n-reg_class int_x_reg(EBX, ECX, EDX, EAX);\n-\n-\/\/ Class of registers that can appear in an address with no offset.\n-\/\/ EBP and ESP require an extra instruction byte for zero offset.\n-\/\/ Used in fast-unlock\n-reg_class p_reg(EDX, EDI, ESI, EBX);\n-\n-\/\/ Class for general registers excluding ECX\n-reg_class ncx_reg_with_ebp(EAX, EDX, EBP, EDI, ESI, EBX);\n-\/\/ Class for general registers excluding ECX (and EBP)\n-reg_class ncx_reg_no_ebp(EAX, EDX, EDI, ESI, EBX);\n-\/\/ Dynamic register class that selects between ncx_reg and ncx_reg_no_ebp.\n-reg_class_dynamic ncx_reg(ncx_reg_no_ebp, ncx_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Class for general registers excluding EAX\n-reg_class nax_reg(EDX, EDI, ESI, ECX, EBX);\n-\n-\/\/ Class for general registers excluding EAX and EBX.\n-reg_class nabx_reg_with_ebp(EDX, EDI, ESI, ECX, EBP);\n-\/\/ Class for general registers excluding EAX and EBX (and EBP)\n-reg_class nabx_reg_no_ebp(EDX, EDI, ESI, ECX);\n-\/\/ Dynamic register class that selects between nabx_reg and nabx_reg_no_ebp.\n-reg_class_dynamic nabx_reg(nabx_reg_no_ebp, nabx_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Class of EAX (for multiply and divide operations)\n-reg_class eax_reg(EAX);\n-\n-\/\/ Class of EBX (for atomic add)\n-reg_class ebx_reg(EBX);\n-\n-\/\/ Class of ECX (for shift and JCXZ operations and cmpLTMask)\n-reg_class ecx_reg(ECX);\n-\n-\/\/ Class of EDX (for multiply and divide operations)\n-reg_class edx_reg(EDX);\n-\n-\/\/ Class of EDI (for synchronization)\n-reg_class edi_reg(EDI);\n-\n-\/\/ Class of ESI (for synchronization)\n-reg_class esi_reg(ESI);\n-\n-\/\/ Singleton class for stack pointer\n-reg_class sp_reg(ESP);\n-\n-\/\/ Singleton class for instruction pointer\n-\/\/ reg_class ip_reg(EIP);\n-\n-\/\/ Class of integer register pairs\n-reg_class long_reg_with_ebp( EAX,EDX, ECX,EBX, EBP,EDI );\n-\/\/ Class of integer register pairs (excluding EBP and EDI);\n-reg_class long_reg_no_ebp( EAX,EDX, ECX,EBX );\n-\/\/ Dynamic register class that selects between long_reg and long_reg_no_ebp.\n-reg_class_dynamic long_reg(long_reg_no_ebp, long_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Class of integer register pairs that aligns with calling convention\n-reg_class eadx_reg( EAX,EDX );\n-reg_class ebcx_reg( ECX,EBX );\n-reg_class ebpd_reg( EBP,EDI );\n-\n-\/\/ Not AX or DX, used in divides\n-reg_class nadx_reg_with_ebp(EBX, ECX, ESI, EDI, EBP);\n-\/\/ Not AX or DX (and neither EBP), used in divides\n-reg_class nadx_reg_no_ebp(EBX, ECX, ESI, EDI);\n-\/\/ Dynamic register class that selects between nadx_reg and nadx_reg_no_ebp.\n-reg_class_dynamic nadx_reg(nadx_reg_no_ebp, nadx_reg_with_ebp, %{ PreserveFramePointer %});\n-\n-\/\/ Floating point registers.  Notice FPR0 is not a choice.\n-\/\/ FPR0 is not ever allocated; we use clever encodings to fake\n-\/\/ a 2-address instructions out of Intels FP stack.\n-reg_class fp_flt_reg( FPR1L,FPR2L,FPR3L,FPR4L,FPR5L,FPR6L,FPR7L );\n-\n-reg_class fp_dbl_reg( FPR1L,FPR1H, FPR2L,FPR2H, FPR3L,FPR3H,\n-                      FPR4L,FPR4H, FPR5L,FPR5H, FPR6L,FPR6H,\n-                      FPR7L,FPR7H );\n-\n-reg_class fp_flt_reg0( FPR1L );\n-reg_class fp_dbl_reg0( FPR1L,FPR1H );\n-reg_class fp_dbl_reg1( FPR2L,FPR2H );\n-reg_class fp_dbl_notreg0( FPR2L,FPR2H, FPR3L,FPR3H, FPR4L,FPR4H,\n-                          FPR5L,FPR5H, FPR6L,FPR6H, FPR7L,FPR7H );\n-\n-%}\n-\n-\n-\/\/----------SOURCE BLOCK-------------------------------------------------------\n-\/\/ This is a block of C++ code which provides values, functions, and\n-\/\/ definitions necessary in the rest of the architecture description\n-source_hpp %{\n-\/\/ Must be visible to the DFA in dfa_x86_32.cpp\n-extern bool is_operand_hi32_zero(Node* n);\n-%}\n-\n-source %{\n-#define   RELOC_IMM32    Assembler::imm_operand\n-#define   RELOC_DISP32   Assembler::disp32_operand\n-\n-#define __ masm->\n-\n-\/\/ How to find the high register of a Long pair, given the low register\n-#define   HIGH_FROM_LOW(x) (as_Register((x)->encoding()+2))\n-#define   HIGH_FROM_LOW_ENC(x) ((x)+2)\n-\n-\/\/ These masks are used to provide 128-bit aligned bitmasks to the XMM\n-\/\/ instructions, to allow sign-masking or sign-bit flipping.  They allow\n-\/\/ fast versions of NegF\/NegD and AbsF\/AbsD.\n-\n-void reg_mask_init() {}\n-\n-\/\/ Note: 'double' and 'long long' have 32-bits alignment on x86.\n-static jlong* double_quadword(jlong *adr, jlong lo, jlong hi) {\n-  \/\/ Use the expression (adr)&(~0xF) to provide 128-bits aligned address\n-  \/\/ of 128-bits operands for SSE instructions.\n-  jlong *operand = (jlong*)(((uintptr_t)adr)&((uintptr_t)(~0xF)));\n-  \/\/ Store the value to a 128-bits operand.\n-  operand[0] = lo;\n-  operand[1] = hi;\n-  return operand;\n-}\n-\n-\/\/ Buffer for 128-bits masks used by SSE instructions.\n-static jlong fp_signmask_pool[(4+1)*2]; \/\/ 4*128bits(data) + 128bits(alignment)\n-\n-\/\/ Static initialization during VM startup.\n-static jlong *float_signmask_pool  = double_quadword(&fp_signmask_pool[1*2], CONST64(0x7FFFFFFF7FFFFFFF), CONST64(0x7FFFFFFF7FFFFFFF));\n-static jlong *double_signmask_pool = double_quadword(&fp_signmask_pool[2*2], CONST64(0x7FFFFFFFFFFFFFFF), CONST64(0x7FFFFFFFFFFFFFFF));\n-static jlong *float_signflip_pool  = double_quadword(&fp_signmask_pool[3*2], CONST64(0x8000000080000000), CONST64(0x8000000080000000));\n-static jlong *double_signflip_pool = double_quadword(&fp_signmask_pool[4*2], CONST64(0x8000000000000000), CONST64(0x8000000000000000));\n-\n-\/\/ Offset hacking within calls.\n-static int pre_call_resets_size() {\n-  int size = 0;\n-  Compile* C = Compile::current();\n-  if (C->in_24_bit_fp_mode()) {\n-    size += 6; \/\/ fldcw\n-  }\n-  if (VM_Version::supports_vzeroupper()) {\n-    size += 3; \/\/ vzeroupper\n-  }\n-  return size;\n-}\n-\n-\/\/ !!!!! Special hack to get all type of calls to specify the byte offset\n-\/\/       from the start of the call to the point where the return address\n-\/\/       will point.\n-int MachCallStaticJavaNode::ret_addr_offset() {\n-  return 5 + pre_call_resets_size();  \/\/ 5 bytes from start of call to where return address points\n-}\n-\n-int MachCallDynamicJavaNode::ret_addr_offset() {\n-  return 10 + pre_call_resets_size();  \/\/ 10 bytes from start of call to where return address points\n-}\n-\n-static int sizeof_FFree_Float_Stack_All = -1;\n-\n-int MachCallRuntimeNode::ret_addr_offset() {\n-  assert(sizeof_FFree_Float_Stack_All != -1, \"must have been emitted already\");\n-  return 5 + pre_call_resets_size() + (_leaf_no_fp ? 0 : sizeof_FFree_Float_Stack_All);\n-}\n-\n-\/\/\n-\/\/ Compute padding required for nodes which need alignment\n-\/\/\n-\n-\/\/ The address of the call instruction needs to be 4-byte aligned to\n-\/\/ ensure that it does not span a cache line so that it can be patched.\n-int CallStaticJavaDirectNode::compute_padding(int current_offset) const {\n-  current_offset += pre_call_resets_size();  \/\/ skip fldcw, if any\n-  current_offset += 1;      \/\/ skip call opcode byte\n-  return align_up(current_offset, alignment_required()) - current_offset;\n-}\n-\n-\/\/ The address of the call instruction needs to be 4-byte aligned to\n-\/\/ ensure that it does not span a cache line so that it can be patched.\n-int CallDynamicJavaDirectNode::compute_padding(int current_offset) const {\n-  current_offset += pre_call_resets_size();  \/\/ skip fldcw, if any\n-  current_offset += 5;      \/\/ skip MOV instruction\n-  current_offset += 1;      \/\/ skip call opcode byte\n-  return align_up(current_offset, alignment_required()) - current_offset;\n-}\n-\n-\/\/ EMIT_RM()\n-void emit_rm(C2_MacroAssembler *masm, int f1, int f2, int f3) {\n-  unsigned char c = (unsigned char)((f1 << 6) | (f2 << 3) | f3);\n-  __ emit_int8(c);\n-}\n-\n-\/\/ EMIT_CC()\n-void emit_cc(C2_MacroAssembler *masm, int f1, int f2) {\n-  unsigned char c = (unsigned char)( f1 | f2 );\n-  __ emit_int8(c);\n-}\n-\n-\/\/ EMIT_OPCODE()\n-void emit_opcode(C2_MacroAssembler *masm, int code) {\n-  __ emit_int8((unsigned char) code);\n-}\n-\n-\/\/ EMIT_OPCODE() w\/ relocation information\n-void emit_opcode(C2_MacroAssembler *masm, int code, relocInfo::relocType reloc, int offset = 0) {\n-  __ relocate(__ inst_mark() + offset, reloc);\n-  emit_opcode(masm, code);\n-}\n-\n-\/\/ EMIT_D8()\n-void emit_d8(C2_MacroAssembler *masm, int d8) {\n-  __ emit_int8((unsigned char) d8);\n-}\n-\n-\/\/ EMIT_D16()\n-void emit_d16(C2_MacroAssembler *masm, int d16) {\n-  __ emit_int16(d16);\n-}\n-\n-\/\/ EMIT_D32()\n-void emit_d32(C2_MacroAssembler *masm, int d32) {\n-  __ emit_int32(d32);\n-}\n-\n-\/\/ emit 32 bit value and construct relocation entry from relocInfo::relocType\n-void emit_d32_reloc(C2_MacroAssembler *masm, int d32, relocInfo::relocType reloc,\n-        int format) {\n-  __ relocate(__ inst_mark(), reloc, format);\n-  __ emit_int32(d32);\n-}\n-\n-\/\/ emit 32 bit value and construct relocation entry from RelocationHolder\n-void emit_d32_reloc(C2_MacroAssembler *masm, int d32, RelocationHolder const& rspec,\n-        int format) {\n-#ifdef ASSERT\n-  if (rspec.reloc()->type() == relocInfo::oop_type && d32 != 0 && d32 != (int)Universe::non_oop_word()) {\n-    assert(oopDesc::is_oop(cast_to_oop(d32)), \"cannot embed broken oops in code\");\n-  }\n-#endif\n-  __ relocate(__ inst_mark(), rspec, format);\n-  __ emit_int32(d32);\n-}\n-\n-\/\/ Access stack slot for load or store\n-void store_to_stackslot(C2_MacroAssembler *masm, int opcode, int rm_field, int disp) {\n-  emit_opcode( masm, opcode );               \/\/ (e.g., FILD   [ESP+src])\n-  if( -128 <= disp && disp <= 127 ) {\n-    emit_rm( masm, 0x01, rm_field, ESP_enc );  \/\/ R\/M byte\n-    emit_rm( masm, 0x00, ESP_enc, ESP_enc);    \/\/ SIB byte\n-    emit_d8 (masm, disp);     \/\/ Displacement  \/\/ R\/M byte\n-  } else {\n-    emit_rm( masm, 0x02, rm_field, ESP_enc );  \/\/ R\/M byte\n-    emit_rm( masm, 0x00, ESP_enc, ESP_enc);    \/\/ SIB byte\n-    emit_d32(masm, disp);     \/\/ Displacement  \/\/ R\/M byte\n-  }\n-}\n-\n-   \/\/ rRegI ereg, memory mem) %{    \/\/ emit_reg_mem\n-void encode_RegMem( C2_MacroAssembler *masm, int reg_encoding, int base, int index, int scale, int displace, relocInfo::relocType disp_reloc ) {\n-  \/\/ There is no index & no scale, use form without SIB byte\n-  if ((index == 0x4) &&\n-      (scale == 0) && (base != ESP_enc)) {\n-    \/\/ If no displacement, mode is 0x0; unless base is [EBP]\n-    if ( (displace == 0) && (base != EBP_enc) ) {\n-      emit_rm(masm, 0x0, reg_encoding, base);\n-    }\n-    else {                    \/\/ If 8-bit displacement, mode 0x1\n-      if ((displace >= -128) && (displace <= 127)\n-          && (disp_reloc == relocInfo::none) ) {\n-        emit_rm(masm, 0x1, reg_encoding, base);\n-        emit_d8(masm, displace);\n-      }\n-      else {                  \/\/ If 32-bit displacement\n-        if (base == -1) { \/\/ Special flag for absolute address\n-          emit_rm(masm, 0x0, reg_encoding, 0x5);\n-          \/\/ (manual lies; no SIB needed here)\n-          if ( disp_reloc != relocInfo::none ) {\n-            emit_d32_reloc(masm, displace, disp_reloc, 1);\n-          } else {\n-            emit_d32      (masm, displace);\n-          }\n-        }\n-        else {                \/\/ Normal base + offset\n-          emit_rm(masm, 0x2, reg_encoding, base);\n-          if ( disp_reloc != relocInfo::none ) {\n-            emit_d32_reloc(masm, displace, disp_reloc, 1);\n-          } else {\n-            emit_d32      (masm, displace);\n-          }\n-        }\n-      }\n-    }\n-  }\n-  else {                      \/\/ Else, encode with the SIB byte\n-    \/\/ If no displacement, mode is 0x0; unless base is [EBP]\n-    if (displace == 0 && (base != EBP_enc)) {  \/\/ If no displacement\n-      emit_rm(masm, 0x0, reg_encoding, 0x4);\n-      emit_rm(masm, scale, index, base);\n-    }\n-    else {                    \/\/ If 8-bit displacement, mode 0x1\n-      if ((displace >= -128) && (displace <= 127)\n-          && (disp_reloc == relocInfo::none) ) {\n-        emit_rm(masm, 0x1, reg_encoding, 0x4);\n-        emit_rm(masm, scale, index, base);\n-        emit_d8(masm, displace);\n-      }\n-      else {                  \/\/ If 32-bit displacement\n-        if (base == 0x04 ) {\n-          emit_rm(masm, 0x2, reg_encoding, 0x4);\n-          emit_rm(masm, scale, index, 0x04);\n-        } else {\n-          emit_rm(masm, 0x2, reg_encoding, 0x4);\n-          emit_rm(masm, scale, index, base);\n-        }\n-        if ( disp_reloc != relocInfo::none ) {\n-          emit_d32_reloc(masm, displace, disp_reloc, 1);\n-        } else {\n-          emit_d32      (masm, displace);\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-\n-void encode_Copy( C2_MacroAssembler *masm, int dst_encoding, int src_encoding ) {\n-  if( dst_encoding == src_encoding ) {\n-    \/\/ reg-reg copy, use an empty encoding\n-  } else {\n-    emit_opcode( masm, 0x8B );\n-    emit_rm(masm, 0x3, dst_encoding, src_encoding );\n-  }\n-}\n-\n-void emit_cmpfp_fixup(MacroAssembler* masm) {\n-  Label exit;\n-  __ jccb(Assembler::noParity, exit);\n-  __ pushf();\n-  \/\/\n-  \/\/ comiss\/ucomiss instructions set ZF,PF,CF flags and\n-  \/\/ zero OF,AF,SF for NaN values.\n-  \/\/ Fixup flags by zeroing ZF,PF so that compare of NaN\n-  \/\/ values returns 'less than' result (CF is set).\n-  \/\/ Leave the rest of flags unchanged.\n-  \/\/\n-  \/\/    7 6 5 4 3 2 1 0\n-  \/\/   |S|Z|r|A|r|P|r|C|  (r - reserved bit)\n-  \/\/    0 0 1 0 1 0 1 1   (0x2B)\n-  \/\/\n-  __ andl(Address(rsp, 0), 0xffffff2b);\n-  __ popf();\n-  __ bind(exit);\n-}\n-\n-static void emit_cmpfp3(MacroAssembler* masm, Register dst) {\n-  Label done;\n-  __ movl(dst, -1);\n-  __ jcc(Assembler::parity, done);\n-  __ jcc(Assembler::below, done);\n-  __ setb(Assembler::notEqual, dst);\n-  __ movzbl(dst, dst);\n-  __ bind(done);\n-}\n-\n-\n-\/\/=============================================================================\n-const RegMask& MachConstantBaseNode::_out_RegMask = RegMask::Empty;\n-\n-int ConstantTable::calculate_table_base_offset() const {\n-  return 0;  \/\/ absolute addressing, no offset\n-}\n-\n-bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }\n-void MachConstantBaseNode::postalloc_expand(GrowableArray <Node *> *nodes, PhaseRegAlloc *ra_) {\n-  ShouldNotReachHere();\n-}\n-\n-void MachConstantBaseNode::emit(C2_MacroAssembler* masm, PhaseRegAlloc* ra_) const {\n-  \/\/ Empty encoding\n-}\n-\n-uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {\n-  return 0;\n-}\n-\n-#ifndef PRODUCT\n-void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {\n-  st->print(\"# MachConstantBaseNode (empty encoding)\");\n-}\n-#endif\n-\n-\n-\/\/=============================================================================\n-#ifndef PRODUCT\n-void MachPrologNode::format(PhaseRegAlloc* ra_, outputStream* st) const {\n-  Compile* C = ra_->C;\n-\n-  int framesize = C->output()->frame_size_in_bytes();\n-  int bangsize = C->output()->bang_size_in_bytes();\n-  assert((framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n-  \/\/ Remove wordSize for return addr which is already pushed.\n-  framesize -= wordSize;\n-\n-  if (C->output()->need_stack_bang(bangsize)) {\n-    framesize -= wordSize;\n-    st->print(\"# stack bang (%d bytes)\", bangsize);\n-    st->print(\"\\n\\t\");\n-    st->print(\"PUSH   EBP\\t# Save EBP\");\n-    if (PreserveFramePointer) {\n-      st->print(\"\\n\\t\");\n-      st->print(\"MOV    EBP, ESP\\t# Save the caller's SP into EBP\");\n-    }\n-    if (framesize) {\n-      st->print(\"\\n\\t\");\n-      st->print(\"SUB    ESP, #%d\\t# Create frame\",framesize);\n-    }\n-  } else {\n-    st->print(\"SUB    ESP, #%d\\t# Create frame\",framesize);\n-    st->print(\"\\n\\t\");\n-    framesize -= wordSize;\n-    st->print(\"MOV    [ESP + #%d], EBP\\t# Save EBP\",framesize);\n-    if (PreserveFramePointer) {\n-      st->print(\"\\n\\t\");\n-      st->print(\"MOV    EBP, ESP\\t# Save the caller's SP into EBP\");\n-      if (framesize > 0) {\n-        st->print(\"\\n\\t\");\n-        st->print(\"ADD    EBP, #%d\", framesize);\n-      }\n-    }\n-  }\n-\n-  if (VerifyStackAtCalls) {\n-    st->print(\"\\n\\t\");\n-    framesize -= wordSize;\n-    st->print(\"MOV    [ESP + #%d], 0xBADB100D\\t# Majik cookie for stack depth check\",framesize);\n-  }\n-\n-  if( C->in_24_bit_fp_mode() ) {\n-    st->print(\"\\n\\t\");\n-    st->print(\"FLDCW  \\t# load 24 bit fpu control word\");\n-  }\n-  if (UseSSE >= 2 && VerifyFPU) {\n-    st->print(\"\\n\\t\");\n-    st->print(\"# verify FPU stack (must be clean on entry)\");\n-  }\n-\n-#ifdef ASSERT\n-  if (VerifyStackAtCalls) {\n-    st->print(\"\\n\\t\");\n-    st->print(\"# stack alignment check\");\n-  }\n-#endif\n-  st->cr();\n-}\n-#endif\n-\n-\n-void MachPrologNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc *ra_) const {\n-  Compile* C = ra_->C;\n-\n-  int framesize = C->output()->frame_size_in_bytes();\n-  int bangsize = C->output()->bang_size_in_bytes();\n-\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != nullptr);\n-\n-  C->output()->set_frame_complete(__ offset());\n-\n-  if (C->has_mach_constant_base_node()) {\n-    \/\/ NOTE: We set the table base offset here because users might be\n-    \/\/ emitted before MachConstantBaseNode.\n-    ConstantTable& constant_table = C->output()->constant_table();\n-    constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());\n-  }\n-}\n-\n-uint MachPrologNode::size(PhaseRegAlloc *ra_) const {\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it the hard way\n-}\n-\n-int MachPrologNode::reloc() const {\n-  return 0; \/\/ a large enough number\n-}\n-\n-\/\/=============================================================================\n-#ifndef PRODUCT\n-void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {\n-  Compile *C = ra_->C;\n-  int framesize = C->output()->frame_size_in_bytes();\n-  assert((framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n-  \/\/ Remove two words for return addr and rbp,\n-  framesize -= 2*wordSize;\n-\n-  if (C->max_vector_size() > 16) {\n-    st->print(\"VZEROUPPER\");\n-    st->cr(); st->print(\"\\t\");\n-  }\n-  if (C->in_24_bit_fp_mode()) {\n-    st->print(\"FLDCW  standard control word\");\n-    st->cr(); st->print(\"\\t\");\n-  }\n-  if (framesize) {\n-    st->print(\"ADD    ESP,%d\\t# Destroy frame\",framesize);\n-    st->cr(); st->print(\"\\t\");\n-  }\n-  st->print_cr(\"POPL   EBP\"); st->print(\"\\t\");\n-  if (do_polling() && C->is_method_compilation()) {\n-    st->print(\"CMPL    rsp, poll_offset[thread]  \\n\\t\"\n-              \"JA      #safepoint_stub\\t\"\n-              \"# Safepoint: poll for GC\");\n-  }\n-}\n-#endif\n-\n-void MachEpilogNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc *ra_) const {\n-  Compile *C = ra_->C;\n-\n-  if (C->max_vector_size() > 16) {\n-    \/\/ Clear upper bits of YMM registers when current compiled code uses\n-    \/\/ wide vectors to avoid AVX <-> SSE transition penalty during call.\n-    __ vzeroupper();\n-  }\n-  \/\/ If method set FPU control word, restore to standard control word\n-  if (C->in_24_bit_fp_mode()) {\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-  }\n-\n-  int framesize = C->output()->frame_size_in_bytes();\n-  assert((framesize & (StackAlignmentInBytes-1)) == 0, \"frame size not aligned\");\n-  \/\/ Remove two words for return addr and rbp,\n-  framesize -= 2*wordSize;\n-\n-  \/\/ Note that VerifyStackAtCalls' Majik cookie does not change the frame size popped here\n-\n-  if (framesize >= 128) {\n-    emit_opcode(masm, 0x81); \/\/ add  SP, #framesize\n-    emit_rm(masm, 0x3, 0x00, ESP_enc);\n-    emit_d32(masm, framesize);\n-  } else if (framesize) {\n-    emit_opcode(masm, 0x83); \/\/ add  SP, #framesize\n-    emit_rm(masm, 0x3, 0x00, ESP_enc);\n-    emit_d8(masm, framesize);\n-  }\n-\n-  emit_opcode(masm, 0x58 | EBP_enc);\n-\n-  if (StackReservedPages > 0 && C->has_reserved_stack_access()) {\n-    __ reserved_stack_check();\n-  }\n-\n-  if (do_polling() && C->is_method_compilation()) {\n-    Register thread = as_Register(EBX_enc);\n-    __ get_thread(thread);\n-    Label dummy_label;\n-    Label* code_stub = &dummy_label;\n-    if (!C->output()->in_scratch_emit_size()) {\n-      C2SafepointPollStub* stub = new (C->comp_arena()) C2SafepointPollStub(__ offset());\n-      C->output()->add_stub(stub);\n-      code_stub = &stub->entry();\n-    }\n-    __ set_inst_mark();\n-    __ relocate(relocInfo::poll_return_type);\n-    __ clear_inst_mark();\n-    __ safepoint_poll(*code_stub, thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n-  }\n-}\n-\n-uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n-int MachEpilogNode::reloc() const {\n-  return 0; \/\/ a large enough number\n-}\n-\n-const Pipeline * MachEpilogNode::pipeline() const {\n-  return MachNode::pipeline_class();\n-}\n-\n-\/\/=============================================================================\n-\n-enum RC { rc_bad, rc_int, rc_kreg, rc_float, rc_xmm, rc_stack };\n-static enum RC rc_class( OptoReg::Name reg ) {\n-\n-  if( !OptoReg::is_valid(reg)  ) return rc_bad;\n-  if (OptoReg::is_stack(reg)) return rc_stack;\n-\n-  VMReg r = OptoReg::as_VMReg(reg);\n-  if (r->is_Register()) return rc_int;\n-  if (r->is_FloatRegister()) {\n-    assert(UseSSE < 2, \"shouldn't be used in SSE2+ mode\");\n-    return rc_float;\n-  }\n-  if (r->is_KRegister()) return rc_kreg;\n-  assert(r->is_XMMRegister(), \"must be\");\n-  return rc_xmm;\n-}\n-\n-static int impl_helper( C2_MacroAssembler *masm, bool do_size, bool is_load, int offset, int reg,\n-                        int opcode, const char *op_str, int size, outputStream* st ) {\n-  if( masm ) {\n-    masm->set_inst_mark();\n-    emit_opcode  (masm, opcode );\n-    encode_RegMem(masm, Matcher::_regEncode[reg], ESP_enc, 0x4, 0, offset, relocInfo::none);\n-    masm->clear_inst_mark();\n-#ifndef PRODUCT\n-  } else if( !do_size ) {\n-    if( size != 0 ) st->print(\"\\n\\t\");\n-    if( opcode == 0x8B || opcode == 0x89 ) { \/\/ MOV\n-      if( is_load ) st->print(\"%s   %s,[ESP + #%d]\",op_str,Matcher::regName[reg],offset);\n-      else          st->print(\"%s   [ESP + #%d],%s\",op_str,offset,Matcher::regName[reg]);\n-    } else { \/\/ FLD, FST, PUSH, POP\n-      st->print(\"%s [ESP + #%d]\",op_str,offset);\n-    }\n-#endif\n-  }\n-  int offset_size = (offset == 0) ? 0 : ((offset <= 127) ? 1 : 4);\n-  return size+3+offset_size;\n-}\n-\n-\/\/ Helper for XMM registers.  Extra opcode bits, limited syntax.\n-static int impl_x_helper( C2_MacroAssembler *masm, bool do_size, bool is_load,\n-                         int offset, int reg_lo, int reg_hi, int size, outputStream* st ) {\n-  int in_size_in_bits = Assembler::EVEX_32bit;\n-  int evex_encoding = 0;\n-  if (reg_lo+1 == reg_hi) {\n-    in_size_in_bits = Assembler::EVEX_64bit;\n-    evex_encoding = Assembler::VEX_W;\n-  }\n-  if (masm) {\n-    \/\/ EVEX spills remain EVEX: Compressed displacemement is better than AVX on spill mem operations,\n-    \/\/                          it maps more cases to single byte displacement\n-    __ set_managed();\n-    if (reg_lo+1 == reg_hi) { \/\/ double move?\n-      if (is_load) {\n-        __ movdbl(as_XMMRegister(Matcher::_regEncode[reg_lo]), Address(rsp, offset));\n-      } else {\n-        __ movdbl(Address(rsp, offset), as_XMMRegister(Matcher::_regEncode[reg_lo]));\n-      }\n-    } else {\n-      if (is_load) {\n-        __ movflt(as_XMMRegister(Matcher::_regEncode[reg_lo]), Address(rsp, offset));\n-      } else {\n-        __ movflt(Address(rsp, offset), as_XMMRegister(Matcher::_regEncode[reg_lo]));\n-      }\n-    }\n-#ifndef PRODUCT\n-  } else if (!do_size) {\n-    if (size != 0) st->print(\"\\n\\t\");\n-    if (reg_lo+1 == reg_hi) { \/\/ double move?\n-      if (is_load) st->print(\"%s %s,[ESP + #%d]\",\n-                              UseXmmLoadAndClearUpper ? \"MOVSD \" : \"MOVLPD\",\n-                              Matcher::regName[reg_lo], offset);\n-      else         st->print(\"MOVSD  [ESP + #%d],%s\",\n-                              offset, Matcher::regName[reg_lo]);\n-    } else {\n-      if (is_load) st->print(\"MOVSS  %s,[ESP + #%d]\",\n-                              Matcher::regName[reg_lo], offset);\n-      else         st->print(\"MOVSS  [ESP + #%d],%s\",\n-                              offset, Matcher::regName[reg_lo]);\n-    }\n-#endif\n-  }\n-  bool is_single_byte = false;\n-  if ((UseAVX > 2) && (offset != 0)) {\n-    is_single_byte = Assembler::query_compressed_disp_byte(offset, true, 0, Assembler::EVEX_T1S, in_size_in_bits, evex_encoding);\n-  }\n-  int offset_size = 0;\n-  if (UseAVX > 2 ) {\n-    offset_size = (offset == 0) ? 0 : ((is_single_byte) ? 1 : 4);\n-  } else {\n-    offset_size = (offset == 0) ? 0 : ((offset <= 127) ? 1 : 4);\n-  }\n-  size += (UseAVX > 2) ? 2 : 0; \/\/ Need an additional two bytes for EVEX\n-  \/\/ VEX_2bytes prefix is used if UseAVX > 0, so it takes the same 2 bytes as SIMD prefix.\n-  return size+5+offset_size;\n-}\n-\n-\n-static int impl_movx_helper( C2_MacroAssembler *masm, bool do_size, int src_lo, int dst_lo,\n-                            int src_hi, int dst_hi, int size, outputStream* st ) {\n-  if (masm) {\n-    \/\/ EVEX spills remain EVEX: logic complex between full EVEX, partial and AVX, manage EVEX spill code one way.\n-    __ set_managed();\n-    if (src_lo+1 == src_hi && dst_lo+1 == dst_hi) { \/\/ double move?\n-      __ movdbl(as_XMMRegister(Matcher::_regEncode[dst_lo]),\n-                as_XMMRegister(Matcher::_regEncode[src_lo]));\n-    } else {\n-      __ movflt(as_XMMRegister(Matcher::_regEncode[dst_lo]),\n-                as_XMMRegister(Matcher::_regEncode[src_lo]));\n-    }\n-#ifndef PRODUCT\n-  } else if (!do_size) {\n-    if (size != 0) st->print(\"\\n\\t\");\n-    if (UseXmmRegToRegMoveAll) {\/\/Use movaps,movapd to move between xmm registers\n-      if (src_lo+1 == src_hi && dst_lo+1 == dst_hi) { \/\/ double move?\n-        st->print(\"MOVAPD %s,%s\",Matcher::regName[dst_lo],Matcher::regName[src_lo]);\n-      } else {\n-        st->print(\"MOVAPS %s,%s\",Matcher::regName[dst_lo],Matcher::regName[src_lo]);\n-      }\n-    } else {\n-      if( src_lo+1 == src_hi && dst_lo+1 == dst_hi ) { \/\/ double move?\n-        st->print(\"MOVSD  %s,%s\",Matcher::regName[dst_lo],Matcher::regName[src_lo]);\n-      } else {\n-        st->print(\"MOVSS  %s,%s\",Matcher::regName[dst_lo],Matcher::regName[src_lo]);\n-      }\n-    }\n-#endif\n-  }\n-  \/\/ VEX_2bytes prefix is used if UseAVX > 0, and it takes the same 2 bytes as SIMD prefix.\n-  \/\/ Only MOVAPS SSE prefix uses 1 byte.  EVEX uses an additional 2 bytes.\n-  int sz = (UseAVX > 2) ? 6 : 4;\n-  if (!(src_lo+1 == src_hi && dst_lo+1 == dst_hi) &&\n-      UseXmmRegToRegMoveAll && (UseAVX == 0)) sz = 3;\n-  return size + sz;\n-}\n-\n-static int impl_movgpr2x_helper( C2_MacroAssembler *masm, bool do_size, int src_lo, int dst_lo,\n-                            int src_hi, int dst_hi, int size, outputStream* st ) {\n-  \/\/ 32-bit\n-  if (masm) {\n-    \/\/ EVEX spills remain EVEX: logic complex between full EVEX, partial and AVX, manage EVEX spill code one way.\n-    __ set_managed();\n-    __ movdl(as_XMMRegister(Matcher::_regEncode[dst_lo]),\n-             as_Register(Matcher::_regEncode[src_lo]));\n-#ifndef PRODUCT\n-  } else if (!do_size) {\n-    st->print(\"movdl   %s, %s\\t# spill\", Matcher::regName[dst_lo], Matcher::regName[src_lo]);\n-#endif\n-  }\n-  return (UseAVX> 2) ? 6 : 4;\n-}\n-\n-\n-static int impl_movx2gpr_helper( C2_MacroAssembler *masm, bool do_size, int src_lo, int dst_lo,\n-                                 int src_hi, int dst_hi, int size, outputStream* st ) {\n-  \/\/ 32-bit\n-  if (masm) {\n-    \/\/ EVEX spills remain EVEX: logic complex between full EVEX, partial and AVX, manage EVEX spill code one way.\n-    __ set_managed();\n-    __ movdl(as_Register(Matcher::_regEncode[dst_lo]),\n-             as_XMMRegister(Matcher::_regEncode[src_lo]));\n-#ifndef PRODUCT\n-  } else if (!do_size) {\n-    st->print(\"movdl   %s, %s\\t# spill\", Matcher::regName[dst_lo], Matcher::regName[src_lo]);\n-#endif\n-  }\n-  return (UseAVX> 2) ? 6 : 4;\n-}\n-\n-static int impl_mov_helper( C2_MacroAssembler *masm, bool do_size, int src, int dst, int size, outputStream* st ) {\n-  if( masm ) {\n-    emit_opcode(masm, 0x8B );\n-    emit_rm    (masm, 0x3, Matcher::_regEncode[dst], Matcher::_regEncode[src] );\n-#ifndef PRODUCT\n-  } else if( !do_size ) {\n-    if( size != 0 ) st->print(\"\\n\\t\");\n-    st->print(\"MOV    %s,%s\",Matcher::regName[dst],Matcher::regName[src]);\n-#endif\n-  }\n-  return size+2;\n-}\n-\n-static int impl_fp_store_helper( C2_MacroAssembler *masm, bool do_size, int src_lo, int src_hi, int dst_lo, int dst_hi,\n-                                 int offset, int size, outputStream* st ) {\n-  if( src_lo != FPR1L_num ) {      \/\/ Move value to top of FP stack, if not already there\n-    if( masm ) {\n-      emit_opcode( masm, 0xD9 );  \/\/ FLD (i.e., push it)\n-      emit_d8( masm, 0xC0-1+Matcher::_regEncode[src_lo] );\n-#ifndef PRODUCT\n-    } else if( !do_size ) {\n-      if( size != 0 ) st->print(\"\\n\\t\");\n-      st->print(\"FLD    %s\",Matcher::regName[src_lo]);\n-#endif\n-    }\n-    size += 2;\n-  }\n-\n-  int st_op = (src_lo != FPR1L_num) ? EBX_num \/*store & pop*\/ : EDX_num \/*store no pop*\/;\n-  const char *op_str;\n-  int op;\n-  if( src_lo+1 == src_hi && dst_lo+1 == dst_hi ) { \/\/ double store?\n-    op_str = (src_lo != FPR1L_num) ? \"FSTP_D\" : \"FST_D \";\n-    op = 0xDD;\n-  } else {                   \/\/ 32-bit store\n-    op_str = (src_lo != FPR1L_num) ? \"FSTP_S\" : \"FST_S \";\n-    op = 0xD9;\n-    assert( !OptoReg::is_valid(src_hi) && !OptoReg::is_valid(dst_hi), \"no non-adjacent float-stores\" );\n-  }\n-\n-  return impl_helper(masm,do_size,false,offset,st_op,op,op_str,size, st);\n-}\n-\n-\/\/ Next two methods are shared by 32- and 64-bit VM. They are defined in x86.ad.\n-static void vec_mov_helper(C2_MacroAssembler *masm, int src_lo, int dst_lo,\n-                          int src_hi, int dst_hi, uint ireg, outputStream* st);\n-\n-void vec_spill_helper(C2_MacroAssembler *masm, bool is_load,\n-                            int stack_offset, int reg, uint ireg, outputStream* st);\n-\n-static void vec_stack_to_stack_helper(C2_MacroAssembler *masm, int src_offset,\n-                                     int dst_offset, uint ireg, outputStream* st) {\n-  if (masm) {\n-    switch (ireg) {\n-    case Op_VecS:\n-      __ pushl(Address(rsp, src_offset));\n-      __ popl (Address(rsp, dst_offset));\n-      break;\n-    case Op_VecD:\n-      __ pushl(Address(rsp, src_offset));\n-      __ popl (Address(rsp, dst_offset));\n-      __ pushl(Address(rsp, src_offset+4));\n-      __ popl (Address(rsp, dst_offset+4));\n-      break;\n-    case Op_VecX:\n-      __ movdqu(Address(rsp, -16), xmm0);\n-      __ movdqu(xmm0, Address(rsp, src_offset));\n-      __ movdqu(Address(rsp, dst_offset), xmm0);\n-      __ movdqu(xmm0, Address(rsp, -16));\n-      break;\n-    case Op_VecY:\n-      __ vmovdqu(Address(rsp, -32), xmm0);\n-      __ vmovdqu(xmm0, Address(rsp, src_offset));\n-      __ vmovdqu(Address(rsp, dst_offset), xmm0);\n-      __ vmovdqu(xmm0, Address(rsp, -32));\n-      break;\n-    case Op_VecZ:\n-      __ evmovdquq(Address(rsp, -64), xmm0, 2);\n-      __ evmovdquq(xmm0, Address(rsp, src_offset), 2);\n-      __ evmovdquq(Address(rsp, dst_offset), xmm0, 2);\n-      __ evmovdquq(xmm0, Address(rsp, -64), 2);\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-#ifndef PRODUCT\n-  } else {\n-    switch (ireg) {\n-    case Op_VecS:\n-      st->print(\"pushl   [rsp + #%d]\\t# 32-bit mem-mem spill\\n\\t\"\n-                \"popl    [rsp + #%d]\",\n-                src_offset, dst_offset);\n-      break;\n-    case Op_VecD:\n-      st->print(\"pushl   [rsp + #%d]\\t# 64-bit mem-mem spill\\n\\t\"\n-                \"popq    [rsp + #%d]\\n\\t\"\n-                \"pushl   [rsp + #%d]\\n\\t\"\n-                \"popq    [rsp + #%d]\",\n-                src_offset, dst_offset, src_offset+4, dst_offset+4);\n-      break;\n-     case Op_VecX:\n-      st->print(\"movdqu  [rsp - #16], xmm0\\t# 128-bit mem-mem spill\\n\\t\"\n-                \"movdqu  xmm0, [rsp + #%d]\\n\\t\"\n-                \"movdqu  [rsp + #%d], xmm0\\n\\t\"\n-                \"movdqu  xmm0, [rsp - #16]\",\n-                src_offset, dst_offset);\n-      break;\n-    case Op_VecY:\n-      st->print(\"vmovdqu [rsp - #32], xmm0\\t# 256-bit mem-mem spill\\n\\t\"\n-                \"vmovdqu xmm0, [rsp + #%d]\\n\\t\"\n-                \"vmovdqu [rsp + #%d], xmm0\\n\\t\"\n-                \"vmovdqu xmm0, [rsp - #32]\",\n-                src_offset, dst_offset);\n-      break;\n-    case Op_VecZ:\n-      st->print(\"vmovdqu [rsp - #64], xmm0\\t# 512-bit mem-mem spill\\n\\t\"\n-                \"vmovdqu xmm0, [rsp + #%d]\\n\\t\"\n-                \"vmovdqu [rsp + #%d], xmm0\\n\\t\"\n-                \"vmovdqu xmm0, [rsp - #64]\",\n-                src_offset, dst_offset);\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-#endif\n-  }\n-}\n-\n-uint MachSpillCopyNode::implementation( C2_MacroAssembler *masm, PhaseRegAlloc *ra_, bool do_size, outputStream* st ) const {\n-  \/\/ Get registers to move\n-  OptoReg::Name src_second = ra_->get_reg_second(in(1));\n-  OptoReg::Name src_first = ra_->get_reg_first(in(1));\n-  OptoReg::Name dst_second = ra_->get_reg_second(this );\n-  OptoReg::Name dst_first = ra_->get_reg_first(this );\n-\n-  enum RC src_second_rc = rc_class(src_second);\n-  enum RC src_first_rc = rc_class(src_first);\n-  enum RC dst_second_rc = rc_class(dst_second);\n-  enum RC dst_first_rc = rc_class(dst_first);\n-\n-  assert( OptoReg::is_valid(src_first) && OptoReg::is_valid(dst_first), \"must move at least 1 register\" );\n-\n-  \/\/ Generate spill code!\n-  int size = 0;\n-\n-  if( src_first == dst_first && src_second == dst_second )\n-    return size;            \/\/ Self copy, no move\n-\n-  if (bottom_type()->isa_vect() != nullptr && bottom_type()->isa_vectmask() == nullptr) {\n-    uint ireg = ideal_reg();\n-    assert((src_first_rc != rc_int && dst_first_rc != rc_int), \"sanity\");\n-    assert((src_first_rc != rc_float && dst_first_rc != rc_float), \"sanity\");\n-    assert((ireg == Op_VecS || ireg == Op_VecD || ireg == Op_VecX || ireg == Op_VecY || ireg == Op_VecZ ), \"sanity\");\n-    if( src_first_rc == rc_stack && dst_first_rc == rc_stack ) {\n-      \/\/ mem -> mem\n-      int src_offset = ra_->reg2offset(src_first);\n-      int dst_offset = ra_->reg2offset(dst_first);\n-      vec_stack_to_stack_helper(masm, src_offset, dst_offset, ireg, st);\n-    } else if (src_first_rc == rc_xmm && dst_first_rc == rc_xmm ) {\n-      vec_mov_helper(masm, src_first, dst_first, src_second, dst_second, ireg, st);\n-    } else if (src_first_rc == rc_xmm && dst_first_rc == rc_stack ) {\n-      int stack_offset = ra_->reg2offset(dst_first);\n-      vec_spill_helper(masm, false, stack_offset, src_first, ireg, st);\n-    } else if (src_first_rc == rc_stack && dst_first_rc == rc_xmm ) {\n-      int stack_offset = ra_->reg2offset(src_first);\n-      vec_spill_helper(masm, true,  stack_offset, dst_first, ireg, st);\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-    return 0;\n-  }\n-\n-  \/\/ --------------------------------------\n-  \/\/ Check for mem-mem move.  push\/pop to move.\n-  if( src_first_rc == rc_stack && dst_first_rc == rc_stack ) {\n-    if( src_second == dst_first ) { \/\/ overlapping stack copy ranges\n-      assert( src_second_rc == rc_stack && dst_second_rc == rc_stack, \"we only expect a stk-stk copy here\" );\n-      size = impl_helper(masm,do_size,true ,ra_->reg2offset(src_second),ESI_num,0xFF,\"PUSH  \",size, st);\n-      size = impl_helper(masm,do_size,false,ra_->reg2offset(dst_second),EAX_num,0x8F,\"POP   \",size, st);\n-      src_second_rc = dst_second_rc = rc_bad;  \/\/ flag as already moved the second bits\n-    }\n-    \/\/ move low bits\n-    size = impl_helper(masm,do_size,true ,ra_->reg2offset(src_first),ESI_num,0xFF,\"PUSH  \",size, st);\n-    size = impl_helper(masm,do_size,false,ra_->reg2offset(dst_first),EAX_num,0x8F,\"POP   \",size, st);\n-    if( src_second_rc == rc_stack && dst_second_rc == rc_stack ) { \/\/ mov second bits\n-      size = impl_helper(masm,do_size,true ,ra_->reg2offset(src_second),ESI_num,0xFF,\"PUSH  \",size, st);\n-      size = impl_helper(masm,do_size,false,ra_->reg2offset(dst_second),EAX_num,0x8F,\"POP   \",size, st);\n-    }\n-    return size;\n-  }\n-\n-  \/\/ --------------------------------------\n-  \/\/ Check for integer reg-reg copy\n-  if( src_first_rc == rc_int && dst_first_rc == rc_int )\n-    size = impl_mov_helper(masm,do_size,src_first,dst_first,size, st);\n-\n-  \/\/ Check for integer store\n-  if( src_first_rc == rc_int && dst_first_rc == rc_stack )\n-    size = impl_helper(masm,do_size,false,ra_->reg2offset(dst_first),src_first,0x89,\"MOV \",size, st);\n-\n-  \/\/ Check for integer load\n-  if( src_first_rc == rc_stack && dst_first_rc == rc_int )\n-    size = impl_helper(masm,do_size,true ,ra_->reg2offset(src_first),dst_first,0x8B,\"MOV \",size, st);\n-\n-  \/\/ Check for integer reg-xmm reg copy\n-  if( src_first_rc == rc_int && dst_first_rc == rc_xmm ) {\n-    assert( (src_second_rc == rc_bad && dst_second_rc == rc_bad),\n-            \"no 64 bit integer-float reg moves\" );\n-    return impl_movgpr2x_helper(masm,do_size,src_first,dst_first,src_second, dst_second, size, st);\n-  }\n-  \/\/ --------------------------------------\n-  \/\/ Check for float reg-reg copy\n-  if( src_first_rc == rc_float && dst_first_rc == rc_float ) {\n-    assert( (src_second_rc == rc_bad && dst_second_rc == rc_bad) ||\n-            (src_first+1 == src_second && dst_first+1 == dst_second), \"no non-adjacent float-moves\" );\n-    if( masm ) {\n-\n-      \/\/ Note the mucking with the register encode to compensate for the 0\/1\n-      \/\/ indexing issue mentioned in a comment in the reg_def sections\n-      \/\/ for FPR registers many lines above here.\n-\n-      if( src_first != FPR1L_num ) {\n-        emit_opcode  (masm, 0xD9 );           \/\/ FLD    ST(i)\n-        emit_d8      (masm, 0xC0+Matcher::_regEncode[src_first]-1 );\n-        emit_opcode  (masm, 0xDD );           \/\/ FSTP   ST(i)\n-        emit_d8      (masm, 0xD8+Matcher::_regEncode[dst_first] );\n-     } else {\n-        emit_opcode  (masm, 0xDD );           \/\/ FST    ST(i)\n-        emit_d8      (masm, 0xD0+Matcher::_regEncode[dst_first]-1 );\n-     }\n-#ifndef PRODUCT\n-    } else if( !do_size ) {\n-      if( size != 0 ) st->print(\"\\n\\t\");\n-      if( src_first != FPR1L_num ) st->print(\"FLD    %s\\n\\tFSTP   %s\",Matcher::regName[src_first],Matcher::regName[dst_first]);\n-      else                      st->print(             \"FST    %s\",                            Matcher::regName[dst_first]);\n-#endif\n-    }\n-    return size + ((src_first != FPR1L_num) ? 2+2 : 2);\n-  }\n-\n-  \/\/ Check for float store\n-  if( src_first_rc == rc_float && dst_first_rc == rc_stack ) {\n-    return impl_fp_store_helper(masm,do_size,src_first,src_second,dst_first,dst_second,ra_->reg2offset(dst_first),size, st);\n-  }\n-\n-  \/\/ Check for float load\n-  if( dst_first_rc == rc_float && src_first_rc == rc_stack ) {\n-    int offset = ra_->reg2offset(src_first);\n-    const char *op_str;\n-    int op;\n-    if( src_first+1 == src_second && dst_first+1 == dst_second ) { \/\/ double load?\n-      op_str = \"FLD_D\";\n-      op = 0xDD;\n-    } else {                   \/\/ 32-bit load\n-      op_str = \"FLD_S\";\n-      op = 0xD9;\n-      assert( src_second_rc == rc_bad && dst_second_rc == rc_bad, \"no non-adjacent float-loads\" );\n-    }\n-    if( masm ) {\n-      masm->set_inst_mark();\n-      emit_opcode  (masm, op );\n-      encode_RegMem(masm, 0x0, ESP_enc, 0x4, 0, offset, relocInfo::none);\n-      emit_opcode  (masm, 0xDD );           \/\/ FSTP   ST(i)\n-      emit_d8      (masm, 0xD8+Matcher::_regEncode[dst_first] );\n-      masm->clear_inst_mark();\n-#ifndef PRODUCT\n-    } else if( !do_size ) {\n-      if( size != 0 ) st->print(\"\\n\\t\");\n-      st->print(\"%s  ST,[ESP + #%d]\\n\\tFSTP   %s\",op_str, offset,Matcher::regName[dst_first]);\n-#endif\n-    }\n-    int offset_size = (offset == 0) ? 0 : ((offset <= 127) ? 1 : 4);\n-    return size + 3+offset_size+2;\n-  }\n-\n-  \/\/ Check for xmm reg-reg copy\n-  if( src_first_rc == rc_xmm && dst_first_rc == rc_xmm ) {\n-    assert( (src_second_rc == rc_bad && dst_second_rc == rc_bad) ||\n-            (src_first+1 == src_second && dst_first+1 == dst_second),\n-            \"no non-adjacent float-moves\" );\n-    return impl_movx_helper(masm,do_size,src_first,dst_first,src_second, dst_second, size, st);\n-  }\n-\n-  \/\/ Check for xmm reg-integer reg copy\n-  if( src_first_rc == rc_xmm && dst_first_rc == rc_int ) {\n-    assert( (src_second_rc == rc_bad && dst_second_rc == rc_bad),\n-            \"no 64 bit float-integer reg moves\" );\n-    return impl_movx2gpr_helper(masm,do_size,src_first,dst_first,src_second, dst_second, size, st);\n-  }\n-\n-  \/\/ Check for xmm store\n-  if( src_first_rc == rc_xmm && dst_first_rc == rc_stack ) {\n-    return impl_x_helper(masm,do_size,false,ra_->reg2offset(dst_first), src_first, src_second, size, st);\n-  }\n-\n-  \/\/ Check for float xmm load\n-  if( src_first_rc == rc_stack && dst_first_rc == rc_xmm ) {\n-    return impl_x_helper(masm,do_size,true ,ra_->reg2offset(src_first),dst_first, dst_second, size, st);\n-  }\n-\n-  \/\/ Copy from float reg to xmm reg\n-  if( src_first_rc == rc_float && dst_first_rc == rc_xmm ) {\n-    \/\/ copy to the top of stack from floating point reg\n-    \/\/ and use LEA to preserve flags\n-    if( masm ) {\n-      emit_opcode(masm,0x8D);  \/\/ LEA  ESP,[ESP-8]\n-      emit_rm(masm, 0x1, ESP_enc, 0x04);\n-      emit_rm(masm, 0x0, 0x04, ESP_enc);\n-      emit_d8(masm,0xF8);\n-#ifndef PRODUCT\n-    } else if( !do_size ) {\n-      if( size != 0 ) st->print(\"\\n\\t\");\n-      st->print(\"LEA    ESP,[ESP-8]\");\n-#endif\n-    }\n-    size += 4;\n-\n-    size = impl_fp_store_helper(masm,do_size,src_first,src_second,dst_first,dst_second,0,size, st);\n-\n-    \/\/ Copy from the temp memory to the xmm reg.\n-    size = impl_x_helper(masm,do_size,true ,0,dst_first, dst_second, size, st);\n-\n-    if( masm ) {\n-      emit_opcode(masm,0x8D);  \/\/ LEA  ESP,[ESP+8]\n-      emit_rm(masm, 0x1, ESP_enc, 0x04);\n-      emit_rm(masm, 0x0, 0x04, ESP_enc);\n-      emit_d8(masm,0x08);\n-#ifndef PRODUCT\n-    } else if( !do_size ) {\n-      if( size != 0 ) st->print(\"\\n\\t\");\n-      st->print(\"LEA    ESP,[ESP+8]\");\n-#endif\n-    }\n-    size += 4;\n-    return size;\n-  }\n-\n-  \/\/ AVX-512 opmask specific spilling.\n-  if (src_first_rc == rc_stack && dst_first_rc == rc_kreg) {\n-    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n-    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n-    int offset = ra_->reg2offset(src_first);\n-    if (masm != nullptr) {\n-      __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), Address(rsp, offset));\n-#ifndef PRODUCT\n-    } else {\n-      st->print(\"KMOV    %s, [ESP + %d]\", Matcher::regName[dst_first], offset);\n-#endif\n-    }\n-    return 0;\n-  }\n-\n-  if (src_first_rc == rc_kreg && dst_first_rc == rc_stack) {\n-    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n-    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n-    int offset = ra_->reg2offset(dst_first);\n-    if (masm != nullptr) {\n-      __ kmov(Address(rsp, offset), as_KRegister(Matcher::_regEncode[src_first]));\n-#ifndef PRODUCT\n-    } else {\n-      st->print(\"KMOV    [ESP + %d], %s\", offset, Matcher::regName[src_first]);\n-#endif\n-    }\n-    return 0;\n-  }\n-\n-  if (src_first_rc == rc_kreg && dst_first_rc == rc_int) {\n-    Unimplemented();\n-    return 0;\n-  }\n-\n-  if (src_first_rc == rc_int && dst_first_rc == rc_kreg) {\n-    Unimplemented();\n-    return 0;\n-  }\n-\n-  if (src_first_rc == rc_kreg && dst_first_rc == rc_kreg) {\n-    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n-    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n-    if (masm != nullptr) {\n-      __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n-#ifndef PRODUCT\n-    } else {\n-      st->print(\"KMOV    %s, %s\", Matcher::regName[dst_first], Matcher::regName[src_first]);\n-#endif\n-    }\n-    return 0;\n-  }\n-\n-  assert( size > 0, \"missed a case\" );\n-\n-  \/\/ --------------------------------------------------------------------\n-  \/\/ Check for second bits still needing moving.\n-  if( src_second == dst_second )\n-    return size;               \/\/ Self copy; no move\n-  assert( src_second_rc != rc_bad && dst_second_rc != rc_bad, \"src_second & dst_second cannot be Bad\" );\n-\n-  \/\/ Check for second word int-int move\n-  if( src_second_rc == rc_int && dst_second_rc == rc_int )\n-    return impl_mov_helper(masm,do_size,src_second,dst_second,size, st);\n-\n-  \/\/ Check for second word integer store\n-  if( src_second_rc == rc_int && dst_second_rc == rc_stack )\n-    return impl_helper(masm,do_size,false,ra_->reg2offset(dst_second),src_second,0x89,\"MOV \",size, st);\n-\n-  \/\/ Check for second word integer load\n-  if( dst_second_rc == rc_int && src_second_rc == rc_stack )\n-    return impl_helper(masm,do_size,true ,ra_->reg2offset(src_second),dst_second,0x8B,\"MOV \",size, st);\n-\n-  Unimplemented();\n-  return 0; \/\/ Mute compiler\n-}\n-\n-#ifndef PRODUCT\n-void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream* st) const {\n-  implementation( nullptr, ra_, false, st );\n-}\n-#endif\n-\n-void MachSpillCopyNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc *ra_) const {\n-  implementation( masm, ra_, false, nullptr );\n-}\n-\n-uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {\n-  return MachNode::size(ra_);\n-}\n-\n-\n-\/\/=============================================================================\n-#ifndef PRODUCT\n-void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {\n-  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());\n-  int reg = ra_->get_reg_first(this);\n-  st->print(\"LEA    %s,[ESP + #%d]\",Matcher::regName[reg],offset);\n-}\n-#endif\n-\n-void BoxLockNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc *ra_) const {\n-  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());\n-  int reg = ra_->get_encode(this);\n-  if( offset >= 128 ) {\n-    emit_opcode(masm, 0x8D);      \/\/ LEA  reg,[SP+offset]\n-    emit_rm(masm, 0x2, reg, 0x04);\n-    emit_rm(masm, 0x0, 0x04, ESP_enc);\n-    emit_d32(masm, offset);\n-  }\n-  else {\n-    emit_opcode(masm, 0x8D);      \/\/ LEA  reg,[SP+offset]\n-    emit_rm(masm, 0x1, reg, 0x04);\n-    emit_rm(masm, 0x0, 0x04, ESP_enc);\n-    emit_d8(masm, offset);\n-  }\n-}\n-\n-uint BoxLockNode::size(PhaseRegAlloc *ra_) const {\n-  int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());\n-  if( offset >= 128 ) {\n-    return 7;\n-  }\n-  else {\n-    return 4;\n-  }\n-}\n-\n-\/\/=============================================================================\n-#ifndef PRODUCT\n-void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream* st ) const {\n-  st->print_cr(  \"CMP    EAX,[ECX+4]\\t# Inline cache check\");\n-  st->print_cr(\"\\tJNE    SharedRuntime::handle_ic_miss_stub\");\n-  st->print_cr(\"\\tNOP\");\n-  st->print_cr(\"\\tNOP\");\n-  if( !OptoBreakpoint )\n-    st->print_cr(\"\\tNOP\");\n-}\n-#endif\n-\n-void MachUEPNode::emit(C2_MacroAssembler *masm, PhaseRegAlloc *ra_) const {\n-  __ ic_check(CodeEntryAlignment);\n-}\n-\n-uint MachUEPNode::size(PhaseRegAlloc *ra_) const {\n-  return MachNode::size(ra_); \/\/ too many variables; just compute it\n-                              \/\/ the hard way\n-}\n-\n-\n-\/\/=============================================================================\n-\n-\/\/ Vector calling convention not supported.\n-bool Matcher::supports_vector_calling_convention() {\n-  return false;\n-}\n-\n-OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n-  Unimplemented();\n-  return OptoRegPair(0, 0);\n-}\n-\n-\/\/ Is this branch offset short enough that a short branch can be used?\n-\/\/\n-\/\/ NOTE: If the platform does not provide any short branch variants, then\n-\/\/       this method should return false for offset 0.\n-bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {\n-  \/\/ The passed offset is relative to address of the branch.\n-  \/\/ On 86 a branch displacement is calculated relative to address\n-  \/\/ of a next instruction.\n-  offset -= br_size;\n-\n-  \/\/ the short version of jmpConUCF2 contains multiple branches,\n-  \/\/ making the reach slightly less\n-  if (rule == jmpConUCF2_rule)\n-    return (-126 <= offset && offset <= 125);\n-  return (-128 <= offset && offset <= 127);\n-}\n-\n-\/\/ Return whether or not this register is ever used as an argument.  This\n-\/\/ function is used on startup to build the trampoline stubs in generateOptoStub.\n-\/\/ Registers not mentioned will be killed by the VM call in the trampoline, and\n-\/\/ arguments in those registers not be available to the callee.\n-bool Matcher::can_be_java_arg( int reg ) {\n-  if(  reg == ECX_num   || reg == EDX_num   ) return true;\n-  if( (reg == XMM0_num  || reg == XMM1_num ) && UseSSE>=1 ) return true;\n-  if( (reg == XMM0b_num || reg == XMM1b_num) && UseSSE>=2 ) return true;\n-  return false;\n-}\n-\n-bool Matcher::is_spillable_arg( int reg ) {\n-  return can_be_java_arg(reg);\n-}\n-\n-uint Matcher::int_pressure_limit()\n-{\n-  return (INTPRESSURE == -1) ? 6 : INTPRESSURE;\n-}\n-\n-uint Matcher::float_pressure_limit()\n-{\n-  return (FLOATPRESSURE == -1) ? 6 : FLOATPRESSURE;\n-}\n-\n-bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {\n-  \/\/ Use hardware integer DIV instruction when\n-  \/\/ it is faster than a code which use multiply.\n-  \/\/ Only when constant divisor fits into 32 bit\n-  \/\/ (min_jint is excluded to get only correct\n-  \/\/ positive 32 bit values from negative).\n-  return VM_Version::has_fast_idiv() &&\n-         (divisor == (int)divisor && divisor != min_jint);\n-}\n-\n-\/\/ Register for DIVI projection of divmodI\n-RegMask Matcher::divI_proj_mask() {\n-  return EAX_REG_mask();\n-}\n-\n-\/\/ Register for MODI projection of divmodI\n-RegMask Matcher::modI_proj_mask() {\n-  return EDX_REG_mask();\n-}\n-\n-\/\/ Register for DIVL projection of divmodL\n-RegMask Matcher::divL_proj_mask() {\n-  ShouldNotReachHere();\n-  return RegMask();\n-}\n-\n-\/\/ Register for MODL projection of divmodL\n-RegMask Matcher::modL_proj_mask() {\n-  ShouldNotReachHere();\n-  return RegMask();\n-}\n-\n-const RegMask Matcher::method_handle_invoke_SP_save_mask() {\n-  return NO_REG_mask();\n-}\n-\n-\/\/ Returns true if the high 32 bits of the value is known to be zero.\n-bool is_operand_hi32_zero(Node* n) {\n-  int opc = n->Opcode();\n-  if (opc == Op_AndL) {\n-    Node* o2 = n->in(2);\n-    if (o2->is_Con() && (o2->get_long() & 0xFFFFFFFF00000000LL) == 0LL) {\n-      return true;\n-    }\n-  }\n-  if (opc == Op_ConL && (n->get_long() & 0xFFFFFFFF00000000LL) == 0LL) {\n-    return true;\n-  }\n-  return false;\n-}\n-\n-%}\n-\n-\/\/----------ENCODING BLOCK-----------------------------------------------------\n-\/\/ This block specifies the encoding classes used by the compiler to output\n-\/\/ byte streams.  Encoding classes generate functions which are called by\n-\/\/ Machine Instruction Nodes in order to generate the bit encoding of the\n-\/\/ instruction.  Operands specify their base encoding interface with the\n-\/\/ interface keyword.  There are currently supported four interfaces,\n-\/\/ REG_INTER, CONST_INTER, MEMORY_INTER, & COND_INTER.  REG_INTER causes an\n-\/\/ operand to generate a function which returns its register number when\n-\/\/ queried.   CONST_INTER causes an operand to generate a function which\n-\/\/ returns the value of the constant when queried.  MEMORY_INTER causes an\n-\/\/ operand to generate four functions which return the Base Register, the\n-\/\/ Index Register, the Scale Value, and the Offset Value of the operand when\n-\/\/ queried.  COND_INTER causes an operand to generate six functions which\n-\/\/ return the encoding code (ie - encoding bits for the instruction)\n-\/\/ associated with each basic boolean condition for a conditional instruction.\n-\/\/ Instructions specify two basic values for encoding.  They use the\n-\/\/ ins_encode keyword to specify their encoding class (which must be one of\n-\/\/ the class names specified in the encoding block), and they use the\n-\/\/ opcode keyword to specify, in order, their primary, secondary, and\n-\/\/ tertiary opcode.  Only the opcode sections which a particular instruction\n-\/\/ needs for encoding need to be specified.\n-encode %{\n-  \/\/ Build emit functions for each basic byte or larger field in the intel\n-  \/\/ encoding scheme (opcode, rm, sib, immediate), and call them from C++\n-  \/\/ code in the enc_class source block.  Emit functions will live in the\n-  \/\/ main source block for now.  In future, we can generalize this by\n-  \/\/ adding a syntax that specifies the sizes of fields in an order,\n-  \/\/ so that the adlc can build the emit functions automagically\n-\n-  \/\/ Set instruction mark in MacroAssembler. This is used only in\n-  \/\/ instructions that emit bytes directly to the CodeBuffer wraped\n-  \/\/ in the MacroAssembler. Should go away once all \"instruct\" are\n-  \/\/ patched to emit bytes only using methods in MacroAssembler.\n-  enc_class SetInstMark %{\n-    __ set_inst_mark();\n-  %}\n-\n-  enc_class ClearInstMark %{\n-    __ clear_inst_mark();\n-  %}\n-\n-  \/\/ Emit primary opcode\n-  enc_class OpcP %{\n-    emit_opcode(masm, $primary);\n-  %}\n-\n-  \/\/ Emit secondary opcode\n-  enc_class OpcS %{\n-    emit_opcode(masm, $secondary);\n-  %}\n-\n-  \/\/ Emit opcode directly\n-  enc_class Opcode(immI d8) %{\n-    emit_opcode(masm, $d8$$constant);\n-  %}\n-\n-  enc_class SizePrefix %{\n-    emit_opcode(masm,0x66);\n-  %}\n-\n-  enc_class RegReg (rRegI dst, rRegI src) %{    \/\/ RegReg(Many)\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class OpcRegReg (immI opcode, rRegI dst, rRegI src) %{    \/\/ OpcRegReg(Many)\n-    emit_opcode(masm,$opcode$$constant);\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class mov_r32_imm0( rRegI dst ) %{\n-    emit_opcode( masm, 0xB8 + $dst$$reg ); \/\/ 0xB8+ rd   -- MOV r32  ,imm32\n-    emit_d32   ( masm, 0x0  );             \/\/                         imm32==0x0\n-  %}\n-\n-  enc_class cdq_enc %{\n-    \/\/ Full implementation of Java idiv and irem; checks for\n-    \/\/ special case as described in JVM spec., p.243 & p.271.\n-    \/\/\n-    \/\/         normal case                           special case\n-    \/\/\n-    \/\/ input : rax,: dividend                         min_int\n-    \/\/         reg: divisor                          -1\n-    \/\/\n-    \/\/ output: rax,: quotient  (= rax, idiv reg)       min_int\n-    \/\/         rdx: remainder (= rax, irem reg)       0\n-    \/\/\n-    \/\/  Code sequnce:\n-    \/\/\n-    \/\/  81 F8 00 00 00 80    cmp         rax,80000000h\n-    \/\/  0F 85 0B 00 00 00    jne         normal_case\n-    \/\/  33 D2                xor         rdx,edx\n-    \/\/  83 F9 FF             cmp         rcx,0FFh\n-    \/\/  0F 84 03 00 00 00    je          done\n-    \/\/                  normal_case:\n-    \/\/  99                   cdq\n-    \/\/  F7 F9                idiv        rax,ecx\n-    \/\/                  done:\n-    \/\/\n-    emit_opcode(masm,0x81); emit_d8(masm,0xF8);\n-    emit_opcode(masm,0x00); emit_d8(masm,0x00);\n-    emit_opcode(masm,0x00); emit_d8(masm,0x80);                     \/\/ cmp rax,80000000h\n-    emit_opcode(masm,0x0F); emit_d8(masm,0x85);\n-    emit_opcode(masm,0x0B); emit_d8(masm,0x00);\n-    emit_opcode(masm,0x00); emit_d8(masm,0x00);                     \/\/ jne normal_case\n-    emit_opcode(masm,0x33); emit_d8(masm,0xD2);                     \/\/ xor rdx,edx\n-    emit_opcode(masm,0x83); emit_d8(masm,0xF9); emit_d8(masm,0xFF); \/\/ cmp rcx,0FFh\n-    emit_opcode(masm,0x0F); emit_d8(masm,0x84);\n-    emit_opcode(masm,0x03); emit_d8(masm,0x00);\n-    emit_opcode(masm,0x00); emit_d8(masm,0x00);                     \/\/ je done\n-    \/\/ normal_case:\n-    emit_opcode(masm,0x99);                                         \/\/ cdq\n-    \/\/ idiv (note: must be emitted by the user of this rule)\n-    \/\/ normal:\n-  %}\n-\n-  \/\/ Dense encoding for older common ops\n-  enc_class Opc_plus(immI opcode, rRegI reg) %{\n-    emit_opcode(masm, $opcode$$constant + $reg$$reg);\n-  %}\n-\n-\n-  \/\/ Opcde enc_class for 8\/32 bit immediate instructions with sign-extension\n-  enc_class OpcSE (immI imm) %{ \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (($imm$$constant >= -128) && ($imm$$constant <= 127)) {\n-      emit_opcode(masm, $primary | 0x02);\n-    }\n-    else {                          \/\/ If 32-bit immediate\n-      emit_opcode(masm, $primary);\n-    }\n-  %}\n-\n-  enc_class OpcSErm (rRegI dst, immI imm) %{    \/\/ OpcSEr\/m\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (($imm$$constant >= -128) && ($imm$$constant <= 127)) {\n-      emit_opcode(masm, $primary | 0x02);    }\n-    else {                          \/\/ If 32-bit immediate\n-      emit_opcode(masm, $primary);\n-    }\n-    \/\/ Emit r\/m byte with secondary opcode, after primary opcode.\n-    emit_rm(masm, 0x3, $secondary, $dst$$reg);\n-  %}\n-\n-  enc_class Con8or32 (immI imm) %{    \/\/ Con8or32(storeImmI), 8 or 32 bits\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    if (($imm$$constant >= -128) && ($imm$$constant <= 127)) {\n-      $$$emit8$imm$$constant;\n-    }\n-    else {                          \/\/ If 32-bit immediate\n-      \/\/ Output immediate\n-      $$$emit32$imm$$constant;\n-    }\n-  %}\n-\n-  enc_class Long_OpcSErm_Lo(eRegL dst, immL imm) %{\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    int con = (int)$imm$$constant; \/\/ Throw away top bits\n-    emit_opcode(masm, ((con >= -128) && (con <= 127)) ? ($primary | 0x02) : $primary);\n-    \/\/ Emit r\/m byte with secondary opcode, after primary opcode.\n-    emit_rm(masm, 0x3, $secondary, $dst$$reg);\n-    if ((con >= -128) && (con <= 127)) emit_d8 (masm,con);\n-    else                               emit_d32(masm,con);\n-  %}\n-\n-  enc_class Long_OpcSErm_Hi(eRegL dst, immL imm) %{\n-    \/\/ Emit primary opcode and set sign-extend bit\n-    \/\/ Check for 8-bit immediate, and set sign extend bit in opcode\n-    int con = (int)($imm$$constant >> 32); \/\/ Throw away bottom bits\n-    emit_opcode(masm, ((con >= -128) && (con <= 127)) ? ($primary | 0x02) : $primary);\n-    \/\/ Emit r\/m byte with tertiary opcode, after primary opcode.\n-    emit_rm(masm, 0x3, $tertiary, HIGH_FROM_LOW_ENC($dst$$reg));\n-    if ((con >= -128) && (con <= 127)) emit_d8 (masm,con);\n-    else                               emit_d32(masm,con);\n-  %}\n-\n-  enc_class OpcSReg (rRegI dst) %{    \/\/ BSWAP\n-    emit_cc(masm, $secondary, $dst$$reg );\n-  %}\n-\n-  enc_class bswap_long_bytes(eRegL dst) %{ \/\/ BSWAP\n-    int destlo = $dst$$reg;\n-    int desthi = HIGH_FROM_LOW_ENC(destlo);\n-    \/\/ bswap lo\n-    emit_opcode(masm, 0x0F);\n-    emit_cc(masm, 0xC8, destlo);\n-    \/\/ bswap hi\n-    emit_opcode(masm, 0x0F);\n-    emit_cc(masm, 0xC8, desthi);\n-    \/\/ xchg lo and hi\n-    emit_opcode(masm, 0x87);\n-    emit_rm(masm, 0x3, destlo, desthi);\n-  %}\n-\n-  enc_class RegOpc (rRegI div) %{    \/\/ IDIV, IMOD, JMP indirect, ...\n-    emit_rm(masm, 0x3, $secondary, $div$$reg );\n-  %}\n-\n-  enc_class enc_cmov(cmpOp cop ) %{ \/\/ CMOV\n-    $$$emit8$primary;\n-    emit_cc(masm, $secondary, $cop$$cmpcode);\n-  %}\n-\n-  enc_class enc_cmov_dpr(cmpOp cop, regDPR src ) %{ \/\/ CMOV\n-    int op = 0xDA00 + $cop$$cmpcode + ($src$$reg-1);\n-    emit_d8(masm, op >> 8 );\n-    emit_d8(masm, op & 255);\n-  %}\n-\n-  \/\/ emulate a CMOV with a conditional branch around a MOV\n-  enc_class enc_cmov_branch( cmpOp cop, immI brOffs ) %{ \/\/ CMOV\n-    \/\/ Invert sense of branch from sense of CMOV\n-    emit_cc( masm, 0x70, ($cop$$cmpcode^1) );\n-    emit_d8( masm, $brOffs$$constant );\n-  %}\n-\n-  enc_class enc_PartialSubtypeCheck( ) %{\n-    Register Redi = as_Register(EDI_enc); \/\/ result register\n-    Register Reax = as_Register(EAX_enc); \/\/ super class\n-    Register Recx = as_Register(ECX_enc); \/\/ killed\n-    Register Resi = as_Register(ESI_enc); \/\/ sub class\n-    Label miss;\n-\n-    \/\/ NB: Callers may assume that, when $result is a valid register,\n-    \/\/ check_klass_subtype_slow_path sets it to a nonzero value.\n-     __ check_klass_subtype_slow_path(Resi, Reax, Recx, Redi,\n-                                     nullptr, &miss,\n-                                     \/*set_cond_codes:*\/ true);\n-    if ($primary) {\n-      __ xorptr(Redi, Redi);\n-    }\n-    __ bind(miss);\n-  %}\n-\n-  enc_class FFree_Float_Stack_All %{    \/\/ Free_Float_Stack_All\n-    int start = __ offset();\n-    if (UseSSE >= 2) {\n-      if (VerifyFPU) {\n-        __ verify_FPU(0, \"must be empty in SSE2+ mode\");\n-      }\n-    } else {\n-      \/\/ External c_calling_convention expects the FPU stack to be 'clean'.\n-      \/\/ Compiled code leaves it dirty.  Do cleanup now.\n-      __ empty_FPU_stack();\n-    }\n-    if (sizeof_FFree_Float_Stack_All == -1) {\n-      sizeof_FFree_Float_Stack_All = __ offset() - start;\n-    } else {\n-      assert(__ offset() - start == sizeof_FFree_Float_Stack_All, \"wrong size\");\n-    }\n-  %}\n-\n-  enc_class Verify_FPU_For_Leaf %{\n-    if( VerifyFPU ) {\n-      __ verify_FPU( -3, \"Returning from Runtime Leaf call\");\n-    }\n-  %}\n-\n-  enc_class Java_To_Runtime (method meth) %{    \/\/ CALL Java_To_Runtime, Java_To_Runtime_Leaf\n-    \/\/ This is the instruction starting address for relocation info.\n-    __ set_inst_mark();\n-    $$$emit8$primary;\n-    \/\/ CALL directly to the runtime\n-    emit_d32_reloc(masm, ($meth$$method - (int)(__ pc()) - 4),\n-                runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-\n-    if (UseSSE >= 2) {\n-      BasicType rt = tf()->return_type();\n-\n-      if ((rt == T_FLOAT || rt == T_DOUBLE) && !return_value_is_used()) {\n-        \/\/ A C runtime call where the return value is unused.  In SSE2+\n-        \/\/ mode the result needs to be removed from the FPU stack.  It's\n-        \/\/ likely that this function call could be removed by the\n-        \/\/ optimizer if the C function is a pure function.\n-        __ ffree(0);\n-      } else if (rt == T_FLOAT) {\n-        __ lea(rsp, Address(rsp, -4));\n-        __ fstp_s(Address(rsp, 0));\n-        __ movflt(xmm0, Address(rsp, 0));\n-        __ lea(rsp, Address(rsp,  4));\n-      } else if (rt == T_DOUBLE) {\n-        __ lea(rsp, Address(rsp, -8));\n-        __ fstp_d(Address(rsp, 0));\n-        __ movdbl(xmm0, Address(rsp, 0));\n-        __ lea(rsp, Address(rsp,  8));\n-      }\n-    }\n-  %}\n-\n-  enc_class pre_call_resets %{\n-    \/\/ If method sets FPU control word restore it here\n-    debug_only(int off0 = __ offset());\n-    if (ra_->C->in_24_bit_fp_mode()) {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-    }\n-    \/\/ Clear upper bits of YMM registers when current compiled code uses\n-    \/\/ wide vectors to avoid AVX <-> SSE transition penalty during call.\n-    __ vzeroupper();\n-    debug_only(int off1 = __ offset());\n-    assert(off1 - off0 == pre_call_resets_size(), \"correct size prediction\");\n-  %}\n-\n-  enc_class post_call_FPU %{\n-    \/\/ If method sets FPU control word do it here also\n-    if (Compile::current()->in_24_bit_fp_mode()) {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_24()));\n-    }\n-  %}\n-\n-  enc_class Java_Static_Call (method meth) %{    \/\/ JAVA STATIC CALL\n-    \/\/ CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine\n-    \/\/ who we intended to call.\n-    __ set_inst_mark();\n-    $$$emit8$primary;\n-\n-    if (!_method) {\n-      emit_d32_reloc(masm, ($meth$$method - (int)(__ pc()) - 4),\n-                     runtime_call_Relocation::spec(),\n-                     RELOC_IMM32);\n-      __ clear_inst_mark();\n-      __ post_call_nop();\n-    } else {\n-      int method_index = resolved_method_index(masm);\n-      RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)\n-                                                  : static_call_Relocation::spec(method_index);\n-      emit_d32_reloc(masm, ($meth$$method - (int)(__ pc()) - 4),\n-                     rspec, RELOC_DISP32);\n-      __ post_call_nop();\n-      address mark = __ inst_mark();\n-      if (CodeBuffer::supports_shared_stubs() && _method->can_be_statically_bound()) {\n-        \/\/ Calls of the same statically bound method can share\n-        \/\/ a stub to the interpreter.\n-        __ code()->shared_stub_to_interp_for(_method, __ code()->insts()->mark_off());\n-        __ clear_inst_mark();\n-      } else {\n-        \/\/ Emit stubs for static call.\n-        address stub = CompiledDirectCall::emit_to_interp_stub(masm, mark);\n-        __ clear_inst_mark();\n-        if (stub == nullptr) {\n-          ciEnv::current()->record_failure(\"CodeCache is full\");\n-          return;\n-        }\n-      }\n-    }\n-  %}\n-\n-  enc_class Java_Dynamic_Call (method meth) %{    \/\/ JAVA DYNAMIC CALL\n-    __ ic_call((address)$meth$$method, resolved_method_index(masm));\n-    __ post_call_nop();\n-  %}\n-\n-  enc_class Java_Compiled_Call (method meth) %{    \/\/ JAVA COMPILED CALL\n-    int disp = in_bytes(Method::from_compiled_offset());\n-    assert( -128 <= disp && disp <= 127, \"compiled_code_offset isn't small\");\n-\n-    \/\/ CALL *[EAX+in_bytes(Method::from_compiled_code_entry_point_offset())]\n-    __ set_inst_mark();\n-    $$$emit8$primary;\n-    emit_rm(masm, 0x01, $secondary, EAX_enc );  \/\/ R\/M byte\n-    emit_d8(masm, disp);             \/\/ Displacement\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-  %}\n-\n-  enc_class RegOpcImm (rRegI dst, immI8 shift) %{    \/\/ SHL, SAR, SHR\n-    $$$emit8$primary;\n-    emit_rm(masm, 0x3, $secondary, $dst$$reg);\n-    $$$emit8$shift$$constant;\n-  %}\n-\n-  enc_class LdImmI (rRegI dst, immI src) %{    \/\/ Load Immediate\n-    \/\/ Load immediate does not have a zero or sign extended version\n-    \/\/ for 8-bit immediates\n-    emit_opcode(masm, 0xB8 + $dst$$reg);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class LdImmP (rRegI dst, immI src) %{    \/\/ Load Immediate\n-    \/\/ Load immediate does not have a zero or sign extended version\n-    \/\/ for 8-bit immediates\n-    emit_opcode(masm, $primary + $dst$$reg);\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class LdImmL_Lo( eRegL dst, immL src) %{    \/\/ Load Immediate\n-    \/\/ Load immediate does not have a zero or sign extended version\n-    \/\/ for 8-bit immediates\n-    int dst_enc = $dst$$reg;\n-    int src_con = $src$$constant & 0x0FFFFFFFFL;\n-    if (src_con == 0) {\n-      \/\/ xor dst, dst\n-      emit_opcode(masm, 0x33);\n-      emit_rm(masm, 0x3, dst_enc, dst_enc);\n-    } else {\n-      emit_opcode(masm, $primary + dst_enc);\n-      emit_d32(masm, src_con);\n-    }\n-  %}\n-\n-  enc_class LdImmL_Hi( eRegL dst, immL src) %{    \/\/ Load Immediate\n-    \/\/ Load immediate does not have a zero or sign extended version\n-    \/\/ for 8-bit immediates\n-    int dst_enc = $dst$$reg + 2;\n-    int src_con = ((julong)($src$$constant)) >> 32;\n-    if (src_con == 0) {\n-      \/\/ xor dst, dst\n-      emit_opcode(masm, 0x33);\n-      emit_rm(masm, 0x3, dst_enc, dst_enc);\n-    } else {\n-      emit_opcode(masm, $primary + dst_enc);\n-      emit_d32(masm, src_con);\n-    }\n-  %}\n-\n-\n-  \/\/ Encode a reg-reg copy.  If it is useless, then empty encoding.\n-  enc_class enc_Copy( rRegI dst, rRegI src ) %{\n-    encode_Copy( masm, $dst$$reg, $src$$reg );\n-  %}\n-\n-  enc_class enc_CopyL_Lo( rRegI dst, eRegL src ) %{\n-    encode_Copy( masm, $dst$$reg, $src$$reg );\n-  %}\n-\n-  enc_class RegReg (rRegI dst, rRegI src) %{    \/\/ RegReg(Many)\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class RegReg_Lo(eRegL dst, eRegL src) %{    \/\/ RegReg(Many)\n-    $$$emit8$primary;\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class RegReg_Hi(eRegL dst, eRegL src) %{    \/\/ RegReg(Many)\n-    $$$emit8$secondary;\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), HIGH_FROM_LOW_ENC($src$$reg));\n-  %}\n-\n-  enc_class RegReg_Lo2(eRegL dst, eRegL src) %{    \/\/ RegReg(Many)\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class RegReg_Hi2(eRegL dst, eRegL src) %{    \/\/ RegReg(Many)\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), HIGH_FROM_LOW_ENC($src$$reg));\n-  %}\n-\n-  enc_class RegReg_HiLo( eRegL src, rRegI dst ) %{\n-    emit_rm(masm, 0x3, $dst$$reg, HIGH_FROM_LOW_ENC($src$$reg));\n-  %}\n-\n-  enc_class Con32 (immI src) %{    \/\/ Con32(storeImmI)\n-    \/\/ Output immediate\n-    $$$emit32$src$$constant;\n-  %}\n-\n-  enc_class Con32FPR_as_bits(immFPR src) %{        \/\/ storeF_imm\n-    \/\/ Output Float immediate bits\n-    jfloat jf = $src$$constant;\n-    int    jf_as_bits = jint_cast( jf );\n-    emit_d32(masm, jf_as_bits);\n-  %}\n-\n-  enc_class Con32F_as_bits(immF src) %{      \/\/ storeX_imm\n-    \/\/ Output Float immediate bits\n-    jfloat jf = $src$$constant;\n-    int    jf_as_bits = jint_cast( jf );\n-    emit_d32(masm, jf_as_bits);\n-  %}\n-\n-  enc_class Con16 (immI src) %{    \/\/ Con16(storeImmI)\n-    \/\/ Output immediate\n-    $$$emit16$src$$constant;\n-  %}\n-\n-  enc_class Con_d32(immI src) %{\n-    emit_d32(masm,$src$$constant);\n-  %}\n-\n-  enc_class conmemref (eRegP t1) %{    \/\/ Con32(storeImmI)\n-    \/\/ Output immediate memory reference\n-    emit_rm(masm, 0x00, $t1$$reg, 0x05 );\n-    emit_d32(masm, 0x00);\n-  %}\n-\n-  enc_class lock_prefix( ) %{\n-    emit_opcode(masm,0xF0);         \/\/ [Lock]\n-  %}\n-\n-  \/\/ Cmp-xchg long value.\n-  \/\/ Note: we need to swap rbx, and rcx before and after the\n-  \/\/       cmpxchg8 instruction because the instruction uses\n-  \/\/       rcx as the high order word of the new value to store but\n-  \/\/       our register encoding uses rbx,.\n-  enc_class enc_cmpxchg8(eSIRegP mem_ptr) %{\n-\n-    \/\/ XCHG  rbx,ecx\n-    emit_opcode(masm,0x87);\n-    emit_opcode(masm,0xD9);\n-    \/\/ [Lock]\n-    emit_opcode(masm,0xF0);\n-    \/\/ CMPXCHG8 [Eptr]\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xC7);\n-    emit_rm( masm, 0x0, 1, $mem_ptr$$reg );\n-    \/\/ XCHG  rbx,ecx\n-    emit_opcode(masm,0x87);\n-    emit_opcode(masm,0xD9);\n-  %}\n-\n-  enc_class enc_cmpxchg(eSIRegP mem_ptr) %{\n-    \/\/ [Lock]\n-    emit_opcode(masm,0xF0);\n-\n-    \/\/ CMPXCHG [Eptr]\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xB1);\n-    emit_rm( masm, 0x0, 1, $mem_ptr$$reg );\n-  %}\n-\n-  enc_class enc_cmpxchgb(eSIRegP mem_ptr) %{\n-    \/\/ [Lock]\n-    emit_opcode(masm,0xF0);\n-\n-    \/\/ CMPXCHGB [Eptr]\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xB0);\n-    emit_rm( masm, 0x0, 1, $mem_ptr$$reg );\n-  %}\n-\n-  enc_class enc_cmpxchgw(eSIRegP mem_ptr) %{\n-    \/\/ [Lock]\n-    emit_opcode(masm,0xF0);\n-\n-    \/\/ 16-bit mode\n-    emit_opcode(masm, 0x66);\n-\n-    \/\/ CMPXCHGW [Eptr]\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xB1);\n-    emit_rm( masm, 0x0, 1, $mem_ptr$$reg );\n-  %}\n-\n-  enc_class enc_flags_ne_to_boolean( iRegI res ) %{\n-    int res_encoding = $res$$reg;\n-\n-    \/\/ MOV  res,0\n-    emit_opcode( masm, 0xB8 + res_encoding);\n-    emit_d32( masm, 0 );\n-    \/\/ JNE,s  fail\n-    emit_opcode(masm,0x75);\n-    emit_d8(masm, 5 );\n-    \/\/ MOV  res,1\n-    emit_opcode( masm, 0xB8 + res_encoding);\n-    emit_d32( masm, 1 );\n-    \/\/ fail:\n-  %}\n-\n-  enc_class RegMem (rRegI ereg, memory mem) %{    \/\/ emit_reg_mem\n-    int reg_encoding = $ereg$$reg;\n-    int base  = $mem$$base;\n-    int index = $mem$$index;\n-    int scale = $mem$$scale;\n-    int displace = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc();\n-    encode_RegMem(masm, reg_encoding, base, index, scale, displace, disp_reloc);\n-  %}\n-\n-  enc_class RegMem_Hi(eRegL ereg, memory mem) %{    \/\/ emit_reg_mem\n-    int reg_encoding = HIGH_FROM_LOW_ENC($ereg$$reg);  \/\/ Hi register of pair, computed from lo\n-    int base  = $mem$$base;\n-    int index = $mem$$index;\n-    int scale = $mem$$scale;\n-    int displace = $mem$$disp + 4;      \/\/ Offset is 4 further in memory\n-    assert( $mem->disp_reloc() == relocInfo::none, \"Cannot add 4 to oop\" );\n-    encode_RegMem(masm, reg_encoding, base, index, scale, displace, relocInfo::none);\n-  %}\n-\n-  enc_class move_long_small_shift( eRegL dst, immI_1_31 cnt ) %{\n-    int r1, r2;\n-    if( $tertiary == 0xA4 ) { r1 = $dst$$reg;  r2 = HIGH_FROM_LOW_ENC($dst$$reg); }\n-    else                    { r2 = $dst$$reg;  r1 = HIGH_FROM_LOW_ENC($dst$$reg); }\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,$tertiary);\n-    emit_rm(masm, 0x3, r1, r2);\n-    emit_d8(masm,$cnt$$constant);\n-    emit_d8(masm,$primary);\n-    emit_rm(masm, 0x3, $secondary, r1);\n-    emit_d8(masm,$cnt$$constant);\n-  %}\n-\n-  enc_class move_long_big_shift_sign( eRegL dst, immI_32_63 cnt ) %{\n-    emit_opcode( masm, 0x8B ); \/\/ Move\n-    emit_rm(masm, 0x3, $dst$$reg, HIGH_FROM_LOW_ENC($dst$$reg));\n-    if( $cnt$$constant > 32 ) { \/\/ Shift, if not by zero\n-      emit_d8(masm,$primary);\n-      emit_rm(masm, 0x3, $secondary, $dst$$reg);\n-      emit_d8(masm,$cnt$$constant-32);\n-    }\n-    emit_d8(masm,$primary);\n-    emit_rm(masm, 0x3, $secondary, HIGH_FROM_LOW_ENC($dst$$reg));\n-    emit_d8(masm,31);\n-  %}\n-\n-  enc_class move_long_big_shift_clr( eRegL dst, immI_32_63 cnt ) %{\n-    int r1, r2;\n-    if( $secondary == 0x5 ) { r1 = $dst$$reg;  r2 = HIGH_FROM_LOW_ENC($dst$$reg); }\n-    else                    { r2 = $dst$$reg;  r1 = HIGH_FROM_LOW_ENC($dst$$reg); }\n-\n-    emit_opcode( masm, 0x8B ); \/\/ Move r1,r2\n-    emit_rm(masm, 0x3, r1, r2);\n-    if( $cnt$$constant > 32 ) { \/\/ Shift, if not by zero\n-      emit_opcode(masm,$primary);\n-      emit_rm(masm, 0x3, $secondary, r1);\n-      emit_d8(masm,$cnt$$constant-32);\n-    }\n-    emit_opcode(masm,0x33);  \/\/ XOR r2,r2\n-    emit_rm(masm, 0x3, r2, r2);\n-  %}\n-\n-  \/\/ Clone of RegMem but accepts an extra parameter to access each\n-  \/\/ half of a double in memory; it never needs relocation info.\n-  enc_class Mov_MemD_half_to_Reg (immI opcode, memory mem, immI disp_for_half, rRegI rm_reg) %{\n-    emit_opcode(masm,$opcode$$constant);\n-    int reg_encoding = $rm_reg$$reg;\n-    int base     = $mem$$base;\n-    int index    = $mem$$index;\n-    int scale    = $mem$$scale;\n-    int displace = $mem$$disp + $disp_for_half$$constant;\n-    relocInfo::relocType disp_reloc = relocInfo::none;\n-    encode_RegMem(masm, reg_encoding, base, index, scale, displace, disp_reloc);\n-  %}\n-\n-  \/\/ !!!!! Special Custom Code used by MemMove, and stack access instructions !!!!!\n-  \/\/\n-  \/\/ Clone of RegMem except the RM-byte's reg\/opcode field is an ADLC-time constant\n-  \/\/ and it never needs relocation information.\n-  \/\/ Frequently used to move data between FPU's Stack Top and memory.\n-  enc_class RMopc_Mem_no_oop (immI rm_opcode, memory mem) %{\n-    int rm_byte_opcode = $rm_opcode$$constant;\n-    int base     = $mem$$base;\n-    int index    = $mem$$index;\n-    int scale    = $mem$$scale;\n-    int displace = $mem$$disp;\n-    assert( $mem->disp_reloc() == relocInfo::none, \"No oops here because no reloc info allowed\" );\n-    encode_RegMem(masm, rm_byte_opcode, base, index, scale, displace, relocInfo::none);\n-  %}\n-\n-  enc_class RMopc_Mem (immI rm_opcode, memory mem) %{\n-    int rm_byte_opcode = $rm_opcode$$constant;\n-    int base     = $mem$$base;\n-    int index    = $mem$$index;\n-    int scale    = $mem$$scale;\n-    int displace = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc(); \/\/ disp-as-oop when working with static globals\n-    encode_RegMem(masm, rm_byte_opcode, base, index, scale, displace, disp_reloc);\n-  %}\n-\n-  enc_class RegLea (rRegI dst, rRegI src0, immI src1 ) %{    \/\/ emit_reg_lea\n-    int reg_encoding = $dst$$reg;\n-    int base         = $src0$$reg;      \/\/ 0xFFFFFFFF indicates no base\n-    int index        = 0x04;            \/\/ 0x04 indicates no index\n-    int scale        = 0x00;            \/\/ 0x00 indicates no scale\n-    int displace     = $src1$$constant; \/\/ 0x00 indicates no displacement\n-    relocInfo::relocType disp_reloc = relocInfo::none;\n-    encode_RegMem(masm, reg_encoding, base, index, scale, displace, disp_reloc);\n-  %}\n-\n-  enc_class min_enc (rRegI dst, rRegI src) %{    \/\/ MIN\n-    \/\/ Compare dst,src\n-    emit_opcode(masm,0x3B);\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-    \/\/ jmp dst < src around move\n-    emit_opcode(masm,0x7C);\n-    emit_d8(masm,2);\n-    \/\/ move dst,src\n-    emit_opcode(masm,0x8B);\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class max_enc (rRegI dst, rRegI src) %{    \/\/ MAX\n-    \/\/ Compare dst,src\n-    emit_opcode(masm,0x3B);\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-    \/\/ jmp dst > src around move\n-    emit_opcode(masm,0x7F);\n-    emit_d8(masm,2);\n-    \/\/ move dst,src\n-    emit_opcode(masm,0x8B);\n-    emit_rm(masm, 0x3, $dst$$reg, $src$$reg);\n-  %}\n-\n-  enc_class enc_FPR_store(memory mem, regDPR src) %{\n-    \/\/ If src is FPR1, we can just FST to store it.\n-    \/\/ Else we need to FLD it to FPR1, then FSTP to store\/pop it.\n-    int reg_encoding = 0x2; \/\/ Just store\n-    int base  = $mem$$base;\n-    int index = $mem$$index;\n-    int scale = $mem$$scale;\n-    int displace = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc(); \/\/ disp-as-oop when working with static globals\n-    if( $src$$reg != FPR1L_enc ) {\n-      reg_encoding = 0x3;  \/\/ Store & pop\n-      emit_opcode( masm, 0xD9 ); \/\/ FLD (i.e., push it)\n-      emit_d8( masm, 0xC0-1+$src$$reg );\n-    }\n-    __ set_inst_mark();       \/\/ Mark start of opcode for reloc info in mem operand\n-    emit_opcode(masm,$primary);\n-    encode_RegMem(masm, reg_encoding, base, index, scale, displace, disp_reloc);\n-    __ clear_inst_mark();\n-  %}\n-\n-  enc_class neg_reg(rRegI dst) %{\n-    \/\/ NEG $dst\n-    emit_opcode(masm,0xF7);\n-    emit_rm(masm, 0x3, 0x03, $dst$$reg );\n-  %}\n-\n-  enc_class setLT_reg(eCXRegI dst) %{\n-    \/\/ SETLT $dst\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0x9C);\n-    emit_rm( masm, 0x3, 0x4, $dst$$reg );\n-  %}\n-\n-  enc_class enc_cmpLTP(ncxRegI p, ncxRegI q, ncxRegI y, eCXRegI tmp) %{    \/\/ cadd_cmpLT\n-    int tmpReg = $tmp$$reg;\n-\n-    \/\/ SUB $p,$q\n-    emit_opcode(masm,0x2B);\n-    emit_rm(masm, 0x3, $p$$reg, $q$$reg);\n-    \/\/ SBB $tmp,$tmp\n-    emit_opcode(masm,0x1B);\n-    emit_rm(masm, 0x3, tmpReg, tmpReg);\n-    \/\/ AND $tmp,$y\n-    emit_opcode(masm,0x23);\n-    emit_rm(masm, 0x3, tmpReg, $y$$reg);\n-    \/\/ ADD $p,$tmp\n-    emit_opcode(masm,0x03);\n-    emit_rm(masm, 0x3, $p$$reg, tmpReg);\n-  %}\n-\n-  enc_class shift_left_long( eRegL dst, eCXRegI shift ) %{\n-    \/\/ TEST shift,32\n-    emit_opcode(masm,0xF7);\n-    emit_rm(masm, 0x3, 0, ECX_enc);\n-    emit_d32(masm,0x20);\n-    \/\/ JEQ,s small\n-    emit_opcode(masm, 0x74);\n-    emit_d8(masm, 0x04);\n-    \/\/ MOV    $dst.hi,$dst.lo\n-    emit_opcode( masm, 0x8B );\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), $dst$$reg );\n-    \/\/ CLR    $dst.lo\n-    emit_opcode(masm, 0x33);\n-    emit_rm(masm, 0x3, $dst$$reg, $dst$$reg);\n-\/\/ small:\n-    \/\/ SHLD   $dst.hi,$dst.lo,$shift\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xA5);\n-    emit_rm(masm, 0x3, $dst$$reg, HIGH_FROM_LOW_ENC($dst$$reg));\n-    \/\/ SHL    $dst.lo,$shift\"\n-    emit_opcode(masm,0xD3);\n-    emit_rm(masm, 0x3, 0x4, $dst$$reg );\n-  %}\n-\n-  enc_class shift_right_long( eRegL dst, eCXRegI shift ) %{\n-    \/\/ TEST shift,32\n-    emit_opcode(masm,0xF7);\n-    emit_rm(masm, 0x3, 0, ECX_enc);\n-    emit_d32(masm,0x20);\n-    \/\/ JEQ,s small\n-    emit_opcode(masm, 0x74);\n-    emit_d8(masm, 0x04);\n-    \/\/ MOV    $dst.lo,$dst.hi\n-    emit_opcode( masm, 0x8B );\n-    emit_rm(masm, 0x3, $dst$$reg, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    \/\/ CLR    $dst.hi\n-    emit_opcode(masm, 0x33);\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), HIGH_FROM_LOW_ENC($dst$$reg));\n-\/\/ small:\n-    \/\/ SHRD   $dst.lo,$dst.hi,$shift\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xAD);\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), $dst$$reg);\n-    \/\/ SHR    $dst.hi,$shift\"\n-    emit_opcode(masm,0xD3);\n-    emit_rm(masm, 0x3, 0x5, HIGH_FROM_LOW_ENC($dst$$reg) );\n-  %}\n-\n-  enc_class shift_right_arith_long( eRegL dst, eCXRegI shift ) %{\n-    \/\/ TEST shift,32\n-    emit_opcode(masm,0xF7);\n-    emit_rm(masm, 0x3, 0, ECX_enc);\n-    emit_d32(masm,0x20);\n-    \/\/ JEQ,s small\n-    emit_opcode(masm, 0x74);\n-    emit_d8(masm, 0x05);\n-    \/\/ MOV    $dst.lo,$dst.hi\n-    emit_opcode( masm, 0x8B );\n-    emit_rm(masm, 0x3, $dst$$reg, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    \/\/ SAR    $dst.hi,31\n-    emit_opcode(masm, 0xC1);\n-    emit_rm(masm, 0x3, 7, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    emit_d8(masm, 0x1F );\n-\/\/ small:\n-    \/\/ SHRD   $dst.lo,$dst.hi,$shift\n-    emit_opcode(masm,0x0F);\n-    emit_opcode(masm,0xAD);\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), $dst$$reg);\n-    \/\/ SAR    $dst.hi,$shift\"\n-    emit_opcode(masm,0xD3);\n-    emit_rm(masm, 0x3, 0x7, HIGH_FROM_LOW_ENC($dst$$reg) );\n-  %}\n-\n-\n-  \/\/ ----------------- Encodings for floating point unit -----------------\n-  \/\/ May leave result in FPU-TOS or FPU reg depending on opcodes\n-  enc_class OpcReg_FPR(regFPR src) %{    \/\/ FMUL, FDIV\n-    $$$emit8$primary;\n-    emit_rm(masm, 0x3, $secondary, $src$$reg );\n-  %}\n-\n-  \/\/ Pop argument in FPR0 with FSTP ST(0)\n-  enc_class PopFPU() %{\n-    emit_opcode( masm, 0xDD );\n-    emit_d8( masm, 0xD8 );\n-  %}\n-\n-  \/\/ !!!!! equivalent to Pop_Reg_F\n-  enc_class Pop_Reg_DPR( regDPR dst ) %{\n-    emit_opcode( masm, 0xDD );           \/\/ FSTP   ST(i)\n-    emit_d8( masm, 0xD8+$dst$$reg );\n-  %}\n-\n-  enc_class Push_Reg_DPR( regDPR dst ) %{\n-    emit_opcode( masm, 0xD9 );\n-    emit_d8( masm, 0xC0-1+$dst$$reg );   \/\/ FLD ST(i-1)\n-  %}\n-\n-  enc_class strictfp_bias1( regDPR dst ) %{\n-    emit_opcode( masm, 0xDB );           \/\/ FLD m80real\n-    emit_opcode( masm, 0x2D );\n-    emit_d32( masm, (int)StubRoutines::x86::addr_fpu_subnormal_bias1() );\n-    emit_opcode( masm, 0xDE );           \/\/ FMULP ST(dst), ST0\n-    emit_opcode( masm, 0xC8+$dst$$reg );\n-  %}\n-\n-  enc_class strictfp_bias2( regDPR dst ) %{\n-    emit_opcode( masm, 0xDB );           \/\/ FLD m80real\n-    emit_opcode( masm, 0x2D );\n-    emit_d32( masm, (int)StubRoutines::x86::addr_fpu_subnormal_bias2() );\n-    emit_opcode( masm, 0xDE );           \/\/ FMULP ST(dst), ST0\n-    emit_opcode( masm, 0xC8+$dst$$reg );\n-  %}\n-\n-  \/\/ Special case for moving an integer register to a stack slot.\n-  enc_class OpcPRegSS( stackSlotI dst, rRegI src ) %{ \/\/ RegSS\n-    store_to_stackslot( masm, $primary, $src$$reg, $dst$$disp );\n-  %}\n-\n-  \/\/ Special case for moving a register to a stack slot.\n-  enc_class RegSS( stackSlotI dst, rRegI src ) %{ \/\/ RegSS\n-    \/\/ Opcode already emitted\n-    emit_rm( masm, 0x02, $src$$reg, ESP_enc );   \/\/ R\/M byte\n-    emit_rm( masm, 0x00, ESP_enc, ESP_enc);          \/\/ SIB byte\n-    emit_d32(masm, $dst$$disp);   \/\/ Displacement\n-  %}\n-\n-  \/\/ Push the integer in stackSlot 'src' onto FP-stack\n-  enc_class Push_Mem_I( memory src ) %{    \/\/ FILD   [ESP+src]\n-    store_to_stackslot( masm, $primary, $secondary, $src$$disp );\n-  %}\n-\n-  \/\/ Push FPU's TOS float to a stack-slot, and pop FPU-stack\n-  enc_class Pop_Mem_FPR( stackSlotF dst ) %{ \/\/ FSTP_S [ESP+dst]\n-    store_to_stackslot( masm, 0xD9, 0x03, $dst$$disp );\n-  %}\n-\n-  \/\/ Same as Pop_Mem_F except for opcode\n-  \/\/ Push FPU's TOS double to a stack-slot, and pop FPU-stack\n-  enc_class Pop_Mem_DPR( stackSlotD dst ) %{ \/\/ FSTP_D [ESP+dst]\n-    store_to_stackslot( masm, 0xDD, 0x03, $dst$$disp );\n-  %}\n-\n-  enc_class Pop_Reg_FPR( regFPR dst ) %{\n-    emit_opcode( masm, 0xDD );           \/\/ FSTP   ST(i)\n-    emit_d8( masm, 0xD8+$dst$$reg );\n-  %}\n-\n-  enc_class Push_Reg_FPR( regFPR dst ) %{\n-    emit_opcode( masm, 0xD9 );           \/\/ FLD    ST(i-1)\n-    emit_d8( masm, 0xC0-1+$dst$$reg );\n-  %}\n-\n-  \/\/ Push FPU's float to a stack-slot, and pop FPU-stack\n-  enc_class Pop_Mem_Reg_FPR( stackSlotF dst, regFPR src ) %{\n-    int pop = 0x02;\n-    if ($src$$reg != FPR1L_enc) {\n-      emit_opcode( masm, 0xD9 );         \/\/ FLD    ST(i-1)\n-      emit_d8( masm, 0xC0-1+$src$$reg );\n-      pop = 0x03;\n-    }\n-    store_to_stackslot( masm, 0xD9, pop, $dst$$disp ); \/\/ FST<P>_S  [ESP+dst]\n-  %}\n-\n-  \/\/ Push FPU's double to a stack-slot, and pop FPU-stack\n-  enc_class Pop_Mem_Reg_DPR( stackSlotD dst, regDPR src ) %{\n-    int pop = 0x02;\n-    if ($src$$reg != FPR1L_enc) {\n-      emit_opcode( masm, 0xD9 );         \/\/ FLD    ST(i-1)\n-      emit_d8( masm, 0xC0-1+$src$$reg );\n-      pop = 0x03;\n-    }\n-    store_to_stackslot( masm, 0xDD, pop, $dst$$disp ); \/\/ FST<P>_D  [ESP+dst]\n-  %}\n-\n-  \/\/ Push FPU's double to a FPU-stack-slot, and pop FPU-stack\n-  enc_class Pop_Reg_Reg_DPR( regDPR dst, regFPR src ) %{\n-    int pop = 0xD0 - 1; \/\/ -1 since we skip FLD\n-    if ($src$$reg != FPR1L_enc) {\n-      emit_opcode( masm, 0xD9 );         \/\/ FLD    ST(src-1)\n-      emit_d8( masm, 0xC0-1+$src$$reg );\n-      pop = 0xD8;\n-    }\n-    emit_opcode( masm, 0xDD );\n-    emit_d8( masm, pop+$dst$$reg );      \/\/ FST<P> ST(i)\n-  %}\n-\n-\n-  enc_class Push_Reg_Mod_DPR( regDPR dst, regDPR src) %{\n-    \/\/ load dst in FPR0\n-    emit_opcode( masm, 0xD9 );\n-    emit_d8( masm, 0xC0-1+$dst$$reg );\n-    if ($src$$reg != FPR1L_enc) {\n-      \/\/ fincstp\n-      emit_opcode (masm, 0xD9);\n-      emit_opcode (masm, 0xF7);\n-      \/\/ swap src with FPR1:\n-      \/\/ FXCH FPR1 with src\n-      emit_opcode(masm, 0xD9);\n-      emit_d8(masm, 0xC8-1+$src$$reg );\n-      \/\/ fdecstp\n-      emit_opcode (masm, 0xD9);\n-      emit_opcode (masm, 0xF6);\n-    }\n-  %}\n-\n-  enc_class Push_ResultD(regD dst) %{\n-    __ fstp_d(Address(rsp, 0));\n-    __ movdbl($dst$$XMMRegister, Address(rsp, 0));\n-    __ addptr(rsp, 8);\n-  %}\n-\n-  enc_class Push_ResultF(regF dst, immI d8) %{\n-    __ fstp_s(Address(rsp, 0));\n-    __ movflt($dst$$XMMRegister, Address(rsp, 0));\n-    __ addptr(rsp, $d8$$constant);\n-  %}\n-\n-  enc_class Push_SrcD(regD src) %{\n-    __ subptr(rsp, 8);\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-  %}\n-\n-  enc_class push_stack_temp_qword() %{\n-    __ subptr(rsp, 8);\n-  %}\n-\n-  enc_class pop_stack_temp_qword() %{\n-    __ addptr(rsp, 8);\n-  %}\n-\n-  enc_class push_xmm_to_fpr1(regD src) %{\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-  %}\n-\n-  enc_class fnstsw_sahf_skip_parity() %{\n-    \/\/ fnstsw ax\n-    emit_opcode( masm, 0xDF );\n-    emit_opcode( masm, 0xE0 );\n-    \/\/ sahf\n-    emit_opcode( masm, 0x9E );\n-    \/\/ jnp  ::skip\n-    emit_opcode( masm, 0x7B );\n-    emit_opcode( masm, 0x05 );\n-  %}\n-\n-  enc_class fpu_flags() %{\n-    \/\/ fnstsw_ax\n-    emit_opcode( masm, 0xDF);\n-    emit_opcode( masm, 0xE0);\n-    \/\/ test ax,0x0400\n-    emit_opcode( masm, 0x66 );   \/\/ operand-size prefix for 16-bit immediate\n-    emit_opcode( masm, 0xA9 );\n-    emit_d16   ( masm, 0x0400 );\n-    \/\/ \/\/ \/\/ This sequence works, but stalls for 12-16 cycles on PPro\n-    \/\/ \/\/ test rax,0x0400\n-    \/\/ emit_opcode( masm, 0xA9 );\n-    \/\/ emit_d32   ( masm, 0x00000400 );\n-    \/\/\n-    \/\/ jz exit (no unordered comparison)\n-    emit_opcode( masm, 0x74 );\n-    emit_d8    ( masm, 0x02 );\n-    \/\/ mov ah,1 - treat as LT case (set carry flag)\n-    emit_opcode( masm, 0xB4 );\n-    emit_d8    ( masm, 0x01 );\n-    \/\/ sahf\n-    emit_opcode( masm, 0x9E);\n-  %}\n-\n-  enc_class cmpF_P6_fixup() %{\n-    \/\/ Fixup the integer flags in case comparison involved a NaN\n-    \/\/\n-    \/\/ JNP exit (no unordered comparison, P-flag is set by NaN)\n-    emit_opcode( masm, 0x7B );\n-    emit_d8    ( masm, 0x03 );\n-    \/\/ MOV AH,1 - treat as LT case (set carry flag)\n-    emit_opcode( masm, 0xB4 );\n-    emit_d8    ( masm, 0x01 );\n-    \/\/ SAHF\n-    emit_opcode( masm, 0x9E);\n-    \/\/ NOP     \/\/ target for branch to avoid branch to branch\n-    emit_opcode( masm, 0x90);\n-  %}\n-\n-\/\/     fnstsw_ax();\n-\/\/     sahf();\n-\/\/     movl(dst, nan_result);\n-\/\/     jcc(Assembler::parity, exit);\n-\/\/     movl(dst, less_result);\n-\/\/     jcc(Assembler::below, exit);\n-\/\/     movl(dst, equal_result);\n-\/\/     jcc(Assembler::equal, exit);\n-\/\/     movl(dst, greater_result);\n-\n-\/\/ less_result     =  1;\n-\/\/ greater_result  = -1;\n-\/\/ equal_result    = 0;\n-\/\/ nan_result      = -1;\n-\n-  enc_class CmpF_Result(rRegI dst) %{\n-    \/\/ fnstsw_ax();\n-    emit_opcode( masm, 0xDF);\n-    emit_opcode( masm, 0xE0);\n-    \/\/ sahf\n-    emit_opcode( masm, 0x9E);\n-    \/\/ movl(dst, nan_result);\n-    emit_opcode( masm, 0xB8 + $dst$$reg);\n-    emit_d32( masm, -1 );\n-    \/\/ jcc(Assembler::parity, exit);\n-    emit_opcode( masm, 0x7A );\n-    emit_d8    ( masm, 0x13 );\n-    \/\/ movl(dst, less_result);\n-    emit_opcode( masm, 0xB8 + $dst$$reg);\n-    emit_d32( masm, -1 );\n-    \/\/ jcc(Assembler::below, exit);\n-    emit_opcode( masm, 0x72 );\n-    emit_d8    ( masm, 0x0C );\n-    \/\/ movl(dst, equal_result);\n-    emit_opcode( masm, 0xB8 + $dst$$reg);\n-    emit_d32( masm, 0 );\n-    \/\/ jcc(Assembler::equal, exit);\n-    emit_opcode( masm, 0x74 );\n-    emit_d8    ( masm, 0x05 );\n-    \/\/ movl(dst, greater_result);\n-    emit_opcode( masm, 0xB8 + $dst$$reg);\n-    emit_d32( masm, 1 );\n-  %}\n-\n-\n-  \/\/ Compare the longs and set flags\n-  \/\/ BROKEN!  Do Not use as-is\n-  enc_class cmpl_test( eRegL src1, eRegL src2 ) %{\n-    \/\/ CMP    $src1.hi,$src2.hi\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($src1$$reg), HIGH_FROM_LOW_ENC($src2$$reg) );\n-    \/\/ JNE,s  done\n-    emit_opcode(masm,0x75);\n-    emit_d8(masm, 2 );\n-    \/\/ CMP    $src1.lo,$src2.lo\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, $src1$$reg, $src2$$reg );\n-\/\/ done:\n-  %}\n-\n-  enc_class convert_int_long( regL dst, rRegI src ) %{\n-    \/\/ mov $dst.lo,$src\n-    int dst_encoding = $dst$$reg;\n-    int src_encoding = $src$$reg;\n-    encode_Copy( masm, dst_encoding  , src_encoding );\n-    \/\/ mov $dst.hi,$src\n-    encode_Copy( masm, HIGH_FROM_LOW_ENC(dst_encoding), src_encoding );\n-    \/\/ sar $dst.hi,31\n-    emit_opcode( masm, 0xC1 );\n-    emit_rm(masm, 0x3, 7, HIGH_FROM_LOW_ENC(dst_encoding) );\n-    emit_d8(masm, 0x1F );\n-  %}\n-\n-  enc_class convert_long_double( eRegL src ) %{\n-    \/\/ push $src.hi\n-    emit_opcode(masm, 0x50+HIGH_FROM_LOW_ENC($src$$reg));\n-    \/\/ push $src.lo\n-    emit_opcode(masm, 0x50+$src$$reg  );\n-    \/\/ fild 64-bits at [SP]\n-    emit_opcode(masm,0xdf);\n-    emit_d8(masm, 0x6C);\n-    emit_d8(masm, 0x24);\n-    emit_d8(masm, 0x00);\n-    \/\/ pop stack\n-    emit_opcode(masm, 0x83); \/\/ add  SP, #8\n-    emit_rm(masm, 0x3, 0x00, ESP_enc);\n-    emit_d8(masm, 0x8);\n-  %}\n-\n-  enc_class multiply_con_and_shift_high( eDXRegI dst, nadxRegI src1, eADXRegL_low_only src2, immI_32_63 cnt, eFlagsReg cr ) %{\n-    \/\/ IMUL   EDX:EAX,$src1\n-    emit_opcode( masm, 0xF7 );\n-    emit_rm( masm, 0x3, 0x5, $src1$$reg );\n-    \/\/ SAR    EDX,$cnt-32\n-    int shift_count = ((int)$cnt$$constant) - 32;\n-    if (shift_count > 0) {\n-      emit_opcode(masm, 0xC1);\n-      emit_rm(masm, 0x3, 7, $dst$$reg );\n-      emit_d8(masm, shift_count);\n-    }\n-  %}\n-\n-  \/\/ this version doesn't have add sp, 8\n-  enc_class convert_long_double2( eRegL src ) %{\n-    \/\/ push $src.hi\n-    emit_opcode(masm, 0x50+HIGH_FROM_LOW_ENC($src$$reg));\n-    \/\/ push $src.lo\n-    emit_opcode(masm, 0x50+$src$$reg  );\n-    \/\/ fild 64-bits at [SP]\n-    emit_opcode(masm,0xdf);\n-    emit_d8(masm, 0x6C);\n-    emit_d8(masm, 0x24);\n-    emit_d8(masm, 0x00);\n-  %}\n-\n-  enc_class long_int_multiply( eADXRegL dst, nadxRegI src) %{\n-    \/\/ Basic idea: long = (long)int * (long)int\n-    \/\/ IMUL EDX:EAX, src\n-    emit_opcode( masm, 0xF7 );\n-    emit_rm( masm, 0x3, 0x5, $src$$reg);\n-  %}\n-\n-  enc_class long_uint_multiply( eADXRegL dst, nadxRegI src) %{\n-    \/\/ Basic Idea:  long = (int & 0xffffffffL) * (int & 0xffffffffL)\n-    \/\/ MUL EDX:EAX, src\n-    emit_opcode( masm, 0xF7 );\n-    emit_rm( masm, 0x3, 0x4, $src$$reg);\n-  %}\n-\n-  enc_class long_multiply( eADXRegL dst, eRegL src, rRegI tmp ) %{\n-    \/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-    \/\/             hi(result) = hi(x_lo * y_lo) + lo(x_hi * y_lo) + lo(x_lo * y_hi)\n-    \/\/ MOV    $tmp,$src.lo\n-    encode_Copy( masm, $tmp$$reg, $src$$reg );\n-    \/\/ IMUL   $tmp,EDX\n-    emit_opcode( masm, 0x0F );\n-    emit_opcode( masm, 0xAF );\n-    emit_rm( masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    \/\/ MOV    EDX,$src.hi\n-    encode_Copy( masm, HIGH_FROM_LOW_ENC($dst$$reg), HIGH_FROM_LOW_ENC($src$$reg) );\n-    \/\/ IMUL   EDX,EAX\n-    emit_opcode( masm, 0x0F );\n-    emit_opcode( masm, 0xAF );\n-    emit_rm( masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), $dst$$reg );\n-    \/\/ ADD    $tmp,EDX\n-    emit_opcode( masm, 0x03 );\n-    emit_rm( masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    \/\/ MUL   EDX:EAX,$src.lo\n-    emit_opcode( masm, 0xF7 );\n-    emit_rm( masm, 0x3, 0x4, $src$$reg );\n-    \/\/ ADD    EDX,ESI\n-    emit_opcode( masm, 0x03 );\n-    emit_rm( masm, 0x3, HIGH_FROM_LOW_ENC($dst$$reg), $tmp$$reg );\n-  %}\n-\n-  enc_class long_multiply_con( eADXRegL dst, immL_127 src, rRegI tmp ) %{\n-    \/\/ Basic idea: lo(result) = lo(src * y_lo)\n-    \/\/             hi(result) = hi(src * y_lo) + lo(src * y_hi)\n-    \/\/ IMUL   $tmp,EDX,$src\n-    emit_opcode( masm, 0x6B );\n-    emit_rm( masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($dst$$reg) );\n-    emit_d8( masm, (int)$src$$constant );\n-    \/\/ MOV    EDX,$src\n-    emit_opcode(masm, 0xB8 + EDX_enc);\n-    emit_d32( masm, (int)$src$$constant );\n-    \/\/ MUL   EDX:EAX,EDX\n-    emit_opcode( masm, 0xF7 );\n-    emit_rm( masm, 0x3, 0x4, EDX_enc );\n-    \/\/ ADD    EDX,ESI\n-    emit_opcode( masm, 0x03 );\n-    emit_rm( masm, 0x3, EDX_enc, $tmp$$reg );\n-  %}\n-\n-  enc_class long_div( eRegL src1, eRegL src2 ) %{\n-    \/\/ PUSH src1.hi\n-    emit_opcode(masm, HIGH_FROM_LOW_ENC(0x50+$src1$$reg) );\n-    \/\/ PUSH src1.lo\n-    emit_opcode(masm,               0x50+$src1$$reg  );\n-    \/\/ PUSH src2.hi\n-    emit_opcode(masm, HIGH_FROM_LOW_ENC(0x50+$src2$$reg) );\n-    \/\/ PUSH src2.lo\n-    emit_opcode(masm,               0x50+$src2$$reg  );\n-    \/\/ CALL directly to the runtime\n-    __ set_inst_mark();\n-    emit_opcode(masm,0xE8);       \/\/ Call into runtime\n-    emit_d32_reloc(masm, (CAST_FROM_FN_PTR(address, SharedRuntime::ldiv) - __ pc()) - 4, runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-    \/\/ Restore stack\n-    emit_opcode(masm, 0x83); \/\/ add  SP, #framesize\n-    emit_rm(masm, 0x3, 0x00, ESP_enc);\n-    emit_d8(masm, 4*4);\n-  %}\n-\n-  enc_class long_mod( eRegL src1, eRegL src2 ) %{\n-    \/\/ PUSH src1.hi\n-    emit_opcode(masm, HIGH_FROM_LOW_ENC(0x50+$src1$$reg) );\n-    \/\/ PUSH src1.lo\n-    emit_opcode(masm,               0x50+$src1$$reg  );\n-    \/\/ PUSH src2.hi\n-    emit_opcode(masm, HIGH_FROM_LOW_ENC(0x50+$src2$$reg) );\n-    \/\/ PUSH src2.lo\n-    emit_opcode(masm,               0x50+$src2$$reg  );\n-    \/\/ CALL directly to the runtime\n-    __ set_inst_mark();\n-    emit_opcode(masm,0xE8);       \/\/ Call into runtime\n-    emit_d32_reloc(masm, (CAST_FROM_FN_PTR(address, SharedRuntime::lrem ) - __ pc()) - 4, runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-    \/\/ Restore stack\n-    emit_opcode(masm, 0x83); \/\/ add  SP, #framesize\n-    emit_rm(masm, 0x3, 0x00, ESP_enc);\n-    emit_d8(masm, 4*4);\n-  %}\n-\n-  enc_class long_cmp_flags0( eRegL src, rRegI tmp ) %{\n-    \/\/ MOV   $tmp,$src.lo\n-    emit_opcode(masm, 0x8B);\n-    emit_rm(masm, 0x3, $tmp$$reg, $src$$reg);\n-    \/\/ OR    $tmp,$src.hi\n-    emit_opcode(masm, 0x0B);\n-    emit_rm(masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($src$$reg));\n-  %}\n-\n-  enc_class long_cmp_flags1( eRegL src1, eRegL src2 ) %{\n-    \/\/ CMP    $src1.lo,$src2.lo\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, $src1$$reg, $src2$$reg );\n-    \/\/ JNE,s  skip\n-    emit_cc(masm, 0x70, 0x5);\n-    emit_d8(masm,2);\n-    \/\/ CMP    $src1.hi,$src2.hi\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, HIGH_FROM_LOW_ENC($src1$$reg), HIGH_FROM_LOW_ENC($src2$$reg) );\n-  %}\n-\n-  enc_class long_cmp_flags2( eRegL src1, eRegL src2, rRegI tmp ) %{\n-    \/\/ CMP    $src1.lo,$src2.lo\\t! Long compare; set flags for low bits\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, $src1$$reg, $src2$$reg );\n-    \/\/ MOV    $tmp,$src1.hi\n-    emit_opcode( masm, 0x8B );\n-    emit_rm(masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($src1$$reg) );\n-    \/\/ SBB   $tmp,$src2.hi\\t! Compute flags for long compare\n-    emit_opcode( masm, 0x1B );\n-    emit_rm(masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($src2$$reg) );\n-  %}\n-\n-  enc_class long_cmp_flags3( eRegL src, rRegI tmp ) %{\n-    \/\/ XOR    $tmp,$tmp\n-    emit_opcode(masm,0x33);  \/\/ XOR\n-    emit_rm(masm,0x3, $tmp$$reg, $tmp$$reg);\n-    \/\/ CMP    $tmp,$src.lo\n-    emit_opcode( masm, 0x3B );\n-    emit_rm(masm, 0x3, $tmp$$reg, $src$$reg );\n-    \/\/ SBB    $tmp,$src.hi\n-    emit_opcode( masm, 0x1B );\n-    emit_rm(masm, 0x3, $tmp$$reg, HIGH_FROM_LOW_ENC($src$$reg) );\n-  %}\n-\n- \/\/ Sniff, sniff... smells like Gnu Superoptimizer\n-  enc_class neg_long( eRegL dst ) %{\n-    emit_opcode(masm,0xF7);    \/\/ NEG hi\n-    emit_rm    (masm,0x3, 0x3, HIGH_FROM_LOW_ENC($dst$$reg));\n-    emit_opcode(masm,0xF7);    \/\/ NEG lo\n-    emit_rm    (masm,0x3, 0x3,               $dst$$reg );\n-    emit_opcode(masm,0x83);    \/\/ SBB hi,0\n-    emit_rm    (masm,0x3, 0x3, HIGH_FROM_LOW_ENC($dst$$reg));\n-    emit_d8    (masm,0 );\n-  %}\n-\n-  enc_class enc_pop_rdx() %{\n-    emit_opcode(masm,0x5A);\n-  %}\n-\n-  enc_class enc_rethrow() %{\n-    __ set_inst_mark();\n-    emit_opcode(masm, 0xE9);        \/\/ jmp    entry\n-    emit_d32_reloc(masm, (int)OptoRuntime::rethrow_stub() - ((int)__ pc())-4,\n-                   runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-  %}\n-\n-\n-  \/\/ Convert a double to an int.  Java semantics require we do complex\n-  \/\/ manglelations in the corner cases.  So we set the rounding mode to\n-  \/\/ 'zero', store the darned double down as an int, and reset the\n-  \/\/ rounding mode to 'nearest'.  The hardware throws an exception which\n-  \/\/ patches up the correct value directly to the stack.\n-  enc_class DPR2I_encoding( regDPR src ) %{\n-    \/\/ Flip to round-to-zero mode.  We attempted to allow invalid-op\n-    \/\/ exceptions here, so that a NAN or other corner-case value will\n-    \/\/ thrown an exception (but normal values get converted at full speed).\n-    \/\/ However, I2C adapters and other float-stack manglers leave pending\n-    \/\/ invalid-op exceptions hanging.  We would have to clear them before\n-    \/\/ enabling them and that is more expensive than just testing for the\n-    \/\/ invalid value Intel stores down in the corner cases.\n-    emit_opcode(masm,0xD9);            \/\/ FLDCW  trunc\n-    emit_opcode(masm,0x2D);\n-    emit_d32(masm,(int)StubRoutines::x86::addr_fpu_cntrl_wrd_trunc());\n-    \/\/ Allocate a word\n-    emit_opcode(masm,0x83);            \/\/ SUB ESP,4\n-    emit_opcode(masm,0xEC);\n-    emit_d8(masm,0x04);\n-    \/\/ Encoding assumes a double has been pushed into FPR0.\n-    \/\/ Store down the double as an int, popping the FPU stack\n-    emit_opcode(masm,0xDB);            \/\/ FISTP [ESP]\n-    emit_opcode(masm,0x1C);\n-    emit_d8(masm,0x24);\n-    \/\/ Restore the rounding mode; mask the exception\n-    emit_opcode(masm,0xD9);            \/\/ FLDCW   std\/24-bit mode\n-    emit_opcode(masm,0x2D);\n-    emit_d32( masm, Compile::current()->in_24_bit_fp_mode()\n-        ? (int)StubRoutines::x86::addr_fpu_cntrl_wrd_24()\n-        : (int)StubRoutines::x86::addr_fpu_cntrl_wrd_std());\n-\n-    \/\/ Load the converted int; adjust CPU stack\n-    emit_opcode(masm,0x58);       \/\/ POP EAX\n-    emit_opcode(masm,0x3D);       \/\/ CMP EAX,imm\n-    emit_d32   (masm,0x80000000); \/\/         0x80000000\n-    emit_opcode(masm,0x75);       \/\/ JNE around_slow_call\n-    emit_d8    (masm,0x07);       \/\/ Size of slow_call\n-    \/\/ Push src onto stack slow-path\n-    emit_opcode(masm,0xD9 );      \/\/ FLD     ST(i)\n-    emit_d8    (masm,0xC0-1+$src$$reg );\n-    \/\/ CALL directly to the runtime\n-    __ set_inst_mark();\n-    emit_opcode(masm,0xE8);       \/\/ Call into runtime\n-    emit_d32_reloc(masm, (StubRoutines::x86::d2i_wrapper() - __ pc()) - 4, runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-    \/\/ Carry on here...\n-  %}\n-\n-  enc_class DPR2L_encoding( regDPR src ) %{\n-    emit_opcode(masm,0xD9);            \/\/ FLDCW  trunc\n-    emit_opcode(masm,0x2D);\n-    emit_d32(masm,(int)StubRoutines::x86::addr_fpu_cntrl_wrd_trunc());\n-    \/\/ Allocate a word\n-    emit_opcode(masm,0x83);            \/\/ SUB ESP,8\n-    emit_opcode(masm,0xEC);\n-    emit_d8(masm,0x08);\n-    \/\/ Encoding assumes a double has been pushed into FPR0.\n-    \/\/ Store down the double as a long, popping the FPU stack\n-    emit_opcode(masm,0xDF);            \/\/ FISTP [ESP]\n-    emit_opcode(masm,0x3C);\n-    emit_d8(masm,0x24);\n-    \/\/ Restore the rounding mode; mask the exception\n-    emit_opcode(masm,0xD9);            \/\/ FLDCW   std\/24-bit mode\n-    emit_opcode(masm,0x2D);\n-    emit_d32( masm, Compile::current()->in_24_bit_fp_mode()\n-        ? (int)StubRoutines::x86::addr_fpu_cntrl_wrd_24()\n-        : (int)StubRoutines::x86::addr_fpu_cntrl_wrd_std());\n-\n-    \/\/ Load the converted int; adjust CPU stack\n-    emit_opcode(masm,0x58);       \/\/ POP EAX\n-    emit_opcode(masm,0x5A);       \/\/ POP EDX\n-    emit_opcode(masm,0x81);       \/\/ CMP EDX,imm\n-    emit_d8    (masm,0xFA);       \/\/ rdx\n-    emit_d32   (masm,0x80000000); \/\/         0x80000000\n-    emit_opcode(masm,0x75);       \/\/ JNE around_slow_call\n-    emit_d8    (masm,0x07+4);     \/\/ Size of slow_call\n-    emit_opcode(masm,0x85);       \/\/ TEST EAX,EAX\n-    emit_opcode(masm,0xC0);       \/\/ 2\/rax,\/rax,\n-    emit_opcode(masm,0x75);       \/\/ JNE around_slow_call\n-    emit_d8    (masm,0x07);       \/\/ Size of slow_call\n-    \/\/ Push src onto stack slow-path\n-    emit_opcode(masm,0xD9 );      \/\/ FLD     ST(i)\n-    emit_d8    (masm,0xC0-1+$src$$reg );\n-    \/\/ CALL directly to the runtime\n-    __ set_inst_mark();\n-    emit_opcode(masm,0xE8);       \/\/ Call into runtime\n-    emit_d32_reloc(masm, (StubRoutines::x86::d2l_wrapper() - __ pc()) - 4, runtime_call_Relocation::spec(), RELOC_IMM32 );\n-    __ clear_inst_mark();\n-    __ post_call_nop();\n-    \/\/ Carry on here...\n-  %}\n-\n-  enc_class FMul_ST_reg( eRegFPR src1 ) %{\n-    \/\/ Operand was loaded from memory into fp ST (stack top)\n-    \/\/ FMUL   ST,$src  \/* D8 C8+i *\/\n-    emit_opcode(masm, 0xD8);\n-    emit_opcode(masm, 0xC8 + $src1$$reg);\n-  %}\n-\n-  enc_class FAdd_ST_reg( eRegFPR src2 ) %{\n-    \/\/ FADDP  ST,src2  \/* D8 C0+i *\/\n-    emit_opcode(masm, 0xD8);\n-    emit_opcode(masm, 0xC0 + $src2$$reg);\n-    \/\/could use FADDP  src2,fpST  \/* DE C0+i *\/\n-  %}\n-\n-  enc_class FAddP_reg_ST( eRegFPR src2 ) %{\n-    \/\/ FADDP  src2,ST  \/* DE C0+i *\/\n-    emit_opcode(masm, 0xDE);\n-    emit_opcode(masm, 0xC0 + $src2$$reg);\n-  %}\n-\n-  enc_class subFPR_divFPR_encode( eRegFPR src1, eRegFPR src2) %{\n-    \/\/ Operand has been loaded into fp ST (stack top)\n-      \/\/ FSUB   ST,$src1\n-      emit_opcode(masm, 0xD8);\n-      emit_opcode(masm, 0xE0 + $src1$$reg);\n-\n-      \/\/ FDIV\n-      emit_opcode(masm, 0xD8);\n-      emit_opcode(masm, 0xF0 + $src2$$reg);\n-  %}\n-\n-  enc_class MulFAddF (eRegFPR src1, eRegFPR src2) %{\n-    \/\/ Operand was loaded from memory into fp ST (stack top)\n-    \/\/ FADD   ST,$src  \/* D8 C0+i *\/\n-    emit_opcode(masm, 0xD8);\n-    emit_opcode(masm, 0xC0 + $src1$$reg);\n-\n-    \/\/ FMUL  ST,src2  \/* D8 C*+i *\/\n-    emit_opcode(masm, 0xD8);\n-    emit_opcode(masm, 0xC8 + $src2$$reg);\n-  %}\n-\n-\n-  enc_class MulFAddFreverse (eRegFPR src1, eRegFPR src2) %{\n-    \/\/ Operand was loaded from memory into fp ST (stack top)\n-    \/\/ FADD   ST,$src  \/* D8 C0+i *\/\n-    emit_opcode(masm, 0xD8);\n-    emit_opcode(masm, 0xC0 + $src1$$reg);\n-\n-    \/\/ FMULP  src2,ST  \/* DE C8+i *\/\n-    emit_opcode(masm, 0xDE);\n-    emit_opcode(masm, 0xC8 + $src2$$reg);\n-  %}\n-\n-  \/\/ Atomically load the volatile long\n-  enc_class enc_loadL_volatile( memory mem, stackSlotL dst ) %{\n-    emit_opcode(masm,0xDF);\n-    int rm_byte_opcode = 0x05;\n-    int base     = $mem$$base;\n-    int index    = $mem$$index;\n-    int scale    = $mem$$scale;\n-    int displace = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc(); \/\/ disp-as-oop when working with static globals\n-    encode_RegMem(masm, rm_byte_opcode, base, index, scale, displace, disp_reloc);\n-    store_to_stackslot( masm, 0x0DF, 0x07, $dst$$disp );\n-  %}\n-\n-  \/\/ Volatile Store Long.  Must be atomic, so move it into\n-  \/\/ the FP TOS and then do a 64-bit FIST.  Has to probe the\n-  \/\/ target address before the store (for null-ptr checks)\n-  \/\/ so the memory operand is used twice in the encoding.\n-  enc_class enc_storeL_volatile( memory mem, stackSlotL src ) %{\n-    store_to_stackslot( masm, 0x0DF, 0x05, $src$$disp );\n-    __ set_inst_mark();            \/\/ Mark start of FIST in case $mem has an oop\n-    emit_opcode(masm,0xDF);\n-    int rm_byte_opcode = 0x07;\n-    int base     = $mem$$base;\n-    int index    = $mem$$index;\n-    int scale    = $mem$$scale;\n-    int displace = $mem$$disp;\n-    relocInfo::relocType disp_reloc = $mem->disp_reloc(); \/\/ disp-as-oop when working with static globals\n-    encode_RegMem(masm, rm_byte_opcode, base, index, scale, displace, disp_reloc);\n-    __ clear_inst_mark();\n-  %}\n-\n-%}\n-\n-\n-\/\/----------FRAME--------------------------------------------------------------\n-\/\/ Definition of frame structure and management information.\n-\/\/\n-\/\/  S T A C K   L A Y O U T    Allocators stack-slot number\n-\/\/                             |   (to get allocators register number\n-\/\/  G  Owned by    |        |  v    add OptoReg::stack0())\n-\/\/  r   CALLER     |        |\n-\/\/  o     |        +--------+      pad to even-align allocators stack-slot\n-\/\/  w     V        |  pad0  |        numbers; owned by CALLER\n-\/\/  t   -----------+--------+----> Matcher::_in_arg_limit, unaligned\n-\/\/  h     ^        |   in   |  5\n-\/\/        |        |  args  |  4   Holes in incoming args owned by SELF\n-\/\/  |     |        |        |  3\n-\/\/  |     |        +--------+\n-\/\/  V     |        | old out|      Empty on Intel, window on Sparc\n-\/\/        |    old |preserve|      Must be even aligned.\n-\/\/        |     SP-+--------+----> Matcher::_old_SP, even aligned\n-\/\/        |        |   in   |  3   area for Intel ret address\n-\/\/     Owned by    |preserve|      Empty on Sparc.\n-\/\/       SELF      +--------+\n-\/\/        |        |  pad2  |  2   pad to align old SP\n-\/\/        |        +--------+  1\n-\/\/        |        | locks  |  0\n-\/\/        |        +--------+----> OptoReg::stack0(), even aligned\n-\/\/        |        |  pad1  | 11   pad to align new SP\n-\/\/        |        +--------+\n-\/\/        |        |        | 10\n-\/\/        |        | spills |  9   spills\n-\/\/        V        |        |  8   (pad0 slot for callee)\n-\/\/      -----------+--------+----> Matcher::_out_arg_limit, unaligned\n-\/\/        ^        |  out   |  7\n-\/\/        |        |  args  |  6   Holes in outgoing args owned by CALLEE\n-\/\/     Owned by    +--------+\n-\/\/      CALLEE     | new out|  6   Empty on Intel, window on Sparc\n-\/\/        |    new |preserve|      Must be even-aligned.\n-\/\/        |     SP-+--------+----> Matcher::_new_SP, even aligned\n-\/\/        |        |        |\n-\/\/\n-\/\/ Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is\n-\/\/         known from SELF's arguments and the Java calling convention.\n-\/\/         Region 6-7 is determined per call site.\n-\/\/ Note 2: If the calling convention leaves holes in the incoming argument\n-\/\/         area, those holes are owned by SELF.  Holes in the outgoing area\n-\/\/         are owned by the CALLEE.  Holes should not be necessary in the\n-\/\/         incoming area, as the Java calling convention is completely under\n-\/\/         the control of the AD file.  Doubles can be sorted and packed to\n-\/\/         avoid holes.  Holes in the outgoing arguments may be necessary for\n-\/\/         varargs C calling conventions.\n-\/\/ Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is\n-\/\/         even aligned with pad0 as needed.\n-\/\/         Region 6 is even aligned.  Region 6-7 is NOT even aligned;\n-\/\/         region 6-11 is even aligned; it may be padded out more so that\n-\/\/         the region from SP to FP meets the minimum stack alignment.\n-\n-frame %{\n-  \/\/ These three registers define part of the calling convention\n-  \/\/ between compiled code and the interpreter.\n-  inline_cache_reg(EAX);                \/\/ Inline Cache Register\n-\n-  \/\/ Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]\n-  cisc_spilling_operand_name(indOffset32);\n-\n-  \/\/ Number of stack slots consumed by locking an object\n-  sync_stack_slots(1);\n-\n-  \/\/ Compiled code's Frame Pointer\n-  frame_pointer(ESP);\n-  \/\/ Interpreter stores its frame pointer in a register which is\n-  \/\/ stored to the stack by I2CAdaptors.\n-  \/\/ I2CAdaptors convert from interpreted java to compiled java.\n-  interpreter_frame_pointer(EBP);\n-\n-  \/\/ Stack alignment requirement\n-  \/\/ Alignment size in bytes (128-bit -> 16 bytes)\n-  stack_alignment(StackAlignmentInBytes);\n-\n-  \/\/ Number of outgoing stack slots killed above the out_preserve_stack_slots\n-  \/\/ for calls to C.  Supports the var-args backing area for register parms.\n-  varargs_C_out_slots_killed(0);\n-\n-  \/\/ The after-PROLOG location of the return address.  Location of\n-  \/\/ return address specifies a type (REG or STACK) and a number\n-  \/\/ representing the register number (i.e. - use a register name) or\n-  \/\/ stack slot.\n-  \/\/ Ret Addr is on stack in slot 0 if no locks or verification or alignment.\n-  \/\/ Otherwise, it is above the locks and verification slot and alignment word\n-  return_addr(STACK - 1 +\n-              align_up((Compile::current()->in_preserve_stack_slots() +\n-                        Compile::current()->fixed_slots()),\n-                       stack_alignment_in_slots()));\n-\n-  \/\/ Location of C & interpreter return values\n-  c_return_value %{\n-    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, \"only return normal values\" );\n-    static int lo[Op_RegL+1] = { 0, 0, OptoReg::Bad, EAX_num,      EAX_num,      FPR1L_num,    FPR1L_num, EAX_num };\n-    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, OptoReg::Bad, OptoReg::Bad, FPR1H_num, EDX_num };\n-\n-    \/\/ in SSE2+ mode we want to keep the FPU stack clean so pretend\n-    \/\/ that C functions return float and double results in XMM0.\n-    if( ideal_reg == Op_RegD && UseSSE>=2 )\n-      return OptoRegPair(XMM0b_num,XMM0_num);\n-    if( ideal_reg == Op_RegF && UseSSE>=2 )\n-      return OptoRegPair(OptoReg::Bad,XMM0_num);\n-\n-    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);\n-  %}\n-\n-  \/\/ Location of return values\n-  return_value %{\n-    assert( ideal_reg >= Op_RegI && ideal_reg <= Op_RegL, \"only return normal values\" );\n-    static int lo[Op_RegL+1] = { 0, 0, OptoReg::Bad, EAX_num,      EAX_num,      FPR1L_num,    FPR1L_num, EAX_num };\n-    static int hi[Op_RegL+1] = { 0, 0, OptoReg::Bad, OptoReg::Bad, OptoReg::Bad, OptoReg::Bad, FPR1H_num, EDX_num };\n-    if( ideal_reg == Op_RegD && UseSSE>=2 )\n-      return OptoRegPair(XMM0b_num,XMM0_num);\n-    if( ideal_reg == Op_RegF && UseSSE>=1 )\n-      return OptoRegPair(OptoReg::Bad,XMM0_num);\n-    return OptoRegPair(hi[ideal_reg],lo[ideal_reg]);\n-  %}\n-\n-%}\n-\n-\/\/----------ATTRIBUTES---------------------------------------------------------\n-\/\/----------Operand Attributes-------------------------------------------------\n-op_attrib op_cost(0);        \/\/ Required cost attribute\n-\n-\/\/----------Instruction Attributes---------------------------------------------\n-ins_attrib ins_cost(100);       \/\/ Required cost attribute\n-ins_attrib ins_size(8);         \/\/ Required size attribute (in bits)\n-ins_attrib ins_short_branch(0); \/\/ Required flag: is this instruction a\n-                                \/\/ non-matching short branch variant of some\n-                                                            \/\/ long branch?\n-ins_attrib ins_alignment(1);    \/\/ Required alignment attribute (must be a power of 2)\n-                                \/\/ specifies the alignment that some part of the instruction (not\n-                                \/\/ necessarily the start) requires.  If > 1, a compute_padding()\n-                                \/\/ function must be provided for the instruction\n-\n-\/\/----------OPERANDS-----------------------------------------------------------\n-\/\/ Operand definitions must precede instruction definitions for correct parsing\n-\/\/ in the ADLC because operands constitute user defined types which are used in\n-\/\/ instruction definitions.\n-\n-\/\/----------Simple Operands----------------------------------------------------\n-\/\/ Immediate Operands\n-\/\/ Integer Immediate\n-operand immI() %{\n-  match(ConI);\n-\n-  op_cost(10);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for test vs zero\n-operand immI_0() %{\n-  predicate(n->get_int() == 0);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for increment\n-operand immI_1() %{\n-  predicate(n->get_int() == 1);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for decrement\n-operand immI_M1() %{\n-  predicate(n->get_int() == -1);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Valid scale values for addressing modes\n-operand immI2() %{\n-  predicate(0 <= n->get_int() && (n->get_int() <= 3));\n-  match(ConI);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI8() %{\n-  predicate((-128 <= n->get_int()) && (n->get_int() <= 127));\n-  match(ConI);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immU8() %{\n-  predicate((0 <= n->get_int()) && (n->get_int() <= 255));\n-  match(ConI);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI16() %{\n-  predicate((-32768 <= n->get_int()) && (n->get_int() <= 32767));\n-  match(ConI);\n-\n-  op_cost(10);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Int Immediate non-negative\n-operand immU31()\n-%{\n-  predicate(n->get_int() >= 0);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for long shifts\n-operand immI_32() %{\n-  predicate( n->get_int() == 32 );\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_1_31() %{\n-  predicate( n->get_int() >= 1 && n->get_int() <= 31 );\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_32_63() %{\n-  predicate( n->get_int() >= 32 && n->get_int() <= 63 );\n-  match(ConI);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_2() %{\n-  predicate( n->get_int() == 2 );\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_3() %{\n-  predicate( n->get_int() == 3 );\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_4()\n-%{\n-  predicate(n->get_int() == 4);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_8()\n-%{\n-  predicate(n->get_int() == 8);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Pointer Immediate\n-operand immP() %{\n-  match(ConP);\n-\n-  op_cost(10);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Null Pointer Immediate\n-operand immP0() %{\n-  predicate( n->get_ptr() == 0 );\n-  match(ConP);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long Immediate\n-operand immL() %{\n-  match(ConL);\n-\n-  op_cost(20);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long Immediate zero\n-operand immL0() %{\n-  predicate( n->get_long() == 0L );\n-  match(ConL);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long Immediate zero\n-operand immL_M1() %{\n-  predicate( n->get_long() == -1L );\n-  match(ConL);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long immediate from 0 to 127.\n-\/\/ Used for a shorter form of long mul by 10.\n-operand immL_127() %{\n-  predicate((0 <= n->get_long()) && (n->get_long() <= 127));\n-  match(ConL);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long Immediate: low 32-bit mask\n-operand immL_32bits() %{\n-  predicate(n->get_long() == 0xFFFFFFFFL);\n-  match(ConL);\n-  op_cost(0);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Long Immediate: low 32-bit mask\n-operand immL32() %{\n-  predicate(n->get_long() == (int)(n->get_long()));\n-  match(ConL);\n-  op_cost(20);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/Double Immediate zero\n-operand immDPR0() %{\n-  \/\/ Do additional (and counter-intuitive) test against NaN to work around VC++\n-  \/\/ bug that generates code such that NaNs compare equal to 0.0\n-  predicate( UseSSE<=1 && n->getd() == 0.0 && !g_isnan(n->getd()) );\n-  match(ConD);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Double Immediate one\n-operand immDPR1() %{\n-  predicate( UseSSE<=1 && n->getd() == 1.0 );\n-  match(ConD);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Double Immediate\n-operand immDPR() %{\n-  predicate(UseSSE<=1);\n-  match(ConD);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immD() %{\n-  predicate(UseSSE>=2);\n-  match(ConD);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Double Immediate zero\n-operand immD0() %{\n-  \/\/ Do additional (and counter-intuitive) test against NaN to work around VC++\n-  \/\/ bug that generates code such that NaNs compare equal to 0.0 AND do not\n-  \/\/ compare equal to -0.0.\n-  predicate( UseSSE>=2 && jlong_cast(n->getd()) == 0 );\n-  match(ConD);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Float Immediate zero\n-operand immFPR0() %{\n-  predicate(UseSSE == 0 && n->getf() == 0.0F);\n-  match(ConF);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Float Immediate one\n-operand immFPR1() %{\n-  predicate(UseSSE == 0 && n->getf() == 1.0F);\n-  match(ConF);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Float Immediate\n-operand immFPR() %{\n-  predicate( UseSSE == 0 );\n-  match(ConF);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Float Immediate\n-operand immF() %{\n-  predicate(UseSSE >= 1);\n-  match(ConF);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Float Immediate zero.  Zero and not -0.0\n-operand immF0() %{\n-  predicate( UseSSE >= 1 && jint_cast(n->getf()) == 0 );\n-  match(ConF);\n-\n-  op_cost(5);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Immediates for special shifts (sign extend)\n-\n-\/\/ Constants for increment\n-operand immI_16() %{\n-  predicate( n->get_int() == 16 );\n-  match(ConI);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_24() %{\n-  predicate( n->get_int() == 24 );\n-  match(ConI);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for byte-wide masking\n-operand immI_255() %{\n-  predicate( n->get_int() == 255 );\n-  match(ConI);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-\/\/ Constant for short-wide masking\n-operand immI_65535() %{\n-  predicate(n->get_int() == 65535);\n-  match(ConI);\n-\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand kReg()\n-%{\n-  constraint(ALLOC_IN_RC(vectmask_reg));\n-  match(RegVectMask);\n-  format %{%}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Register Operands\n-\/\/ Integer Register\n-operand rRegI() %{\n-  constraint(ALLOC_IN_RC(int_reg));\n-  match(RegI);\n-  match(xRegI);\n-  match(eAXRegI);\n-  match(eBXRegI);\n-  match(eCXRegI);\n-  match(eDXRegI);\n-  match(eDIRegI);\n-  match(eSIRegI);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Subset of Integer Register\n-operand xRegI(rRegI reg) %{\n-  constraint(ALLOC_IN_RC(int_x_reg));\n-  match(reg);\n-  match(eAXRegI);\n-  match(eBXRegI);\n-  match(eCXRegI);\n-  match(eDXRegI);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Special Registers\n-operand eAXRegI(xRegI reg) %{\n-  constraint(ALLOC_IN_RC(eax_reg));\n-  match(reg);\n-  match(rRegI);\n-\n-  format %{ \"EAX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Special Registers\n-operand eBXRegI(xRegI reg) %{\n-  constraint(ALLOC_IN_RC(ebx_reg));\n-  match(reg);\n-  match(rRegI);\n-\n-  format %{ \"EBX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eCXRegI(xRegI reg) %{\n-  constraint(ALLOC_IN_RC(ecx_reg));\n-  match(reg);\n-  match(rRegI);\n-\n-  format %{ \"ECX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eDXRegI(xRegI reg) %{\n-  constraint(ALLOC_IN_RC(edx_reg));\n-  match(reg);\n-  match(rRegI);\n-\n-  format %{ \"EDX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eDIRegI(xRegI reg) %{\n-  constraint(ALLOC_IN_RC(edi_reg));\n-  match(reg);\n-  match(rRegI);\n-\n-  format %{ \"EDI\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand nadxRegI() %{\n-  constraint(ALLOC_IN_RC(nadx_reg));\n-  match(RegI);\n-  match(eBXRegI);\n-  match(eCXRegI);\n-  match(eSIRegI);\n-  match(eDIRegI);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand ncxRegI() %{\n-  constraint(ALLOC_IN_RC(ncx_reg));\n-  match(RegI);\n-  match(eAXRegI);\n-  match(eDXRegI);\n-  match(eSIRegI);\n-  match(eDIRegI);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ \/\/ This operand was used by cmpFastUnlock, but conflicted with 'object' reg\n-\/\/ \/\/\n-operand eSIRegI(xRegI reg) %{\n-   constraint(ALLOC_IN_RC(esi_reg));\n-   match(reg);\n-   match(rRegI);\n-\n-   format %{ \"ESI\" %}\n-   interface(REG_INTER);\n-%}\n-\n-\/\/ Pointer Register\n-operand anyRegP() %{\n-  constraint(ALLOC_IN_RC(any_reg));\n-  match(RegP);\n-  match(eAXRegP);\n-  match(eBXRegP);\n-  match(eCXRegP);\n-  match(eDIRegP);\n-  match(eRegP);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eRegP() %{\n-  constraint(ALLOC_IN_RC(int_reg));\n-  match(RegP);\n-  match(eAXRegP);\n-  match(eBXRegP);\n-  match(eCXRegP);\n-  match(eDIRegP);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand rRegP() %{\n-  constraint(ALLOC_IN_RC(int_reg));\n-  match(RegP);\n-  match(eAXRegP);\n-  match(eBXRegP);\n-  match(eCXRegP);\n-  match(eDIRegP);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ On windows95, EBP is not safe to use for implicit null tests.\n-operand eRegP_no_EBP() %{\n-  constraint(ALLOC_IN_RC(int_reg_no_ebp));\n-  match(RegP);\n-  match(eAXRegP);\n-  match(eBXRegP);\n-  match(eCXRegP);\n-  match(eDIRegP);\n-\n-  op_cost(100);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand pRegP() %{\n-  constraint(ALLOC_IN_RC(p_reg));\n-  match(RegP);\n-  match(eBXRegP);\n-  match(eDXRegP);\n-  match(eSIRegP);\n-  match(eDIRegP);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Special Registers\n-\/\/ Return a pointer value\n-operand eAXRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(eax_reg));\n-  match(reg);\n-  format %{ \"EAX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Used in AtomicAdd\n-operand eBXRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(ebx_reg));\n-  match(reg);\n-  format %{ \"EBX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Tail-call (interprocedural jump) to interpreter\n-operand eCXRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(ecx_reg));\n-  match(reg);\n-  format %{ \"ECX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eDXRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(edx_reg));\n-  match(reg);\n-  format %{ \"EDX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eSIRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(esi_reg));\n-  match(reg);\n-  format %{ \"ESI\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Used in rep stosw\n-operand eDIRegP(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(edi_reg));\n-  match(reg);\n-  format %{ \"EDI\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eRegL() %{\n-  constraint(ALLOC_IN_RC(long_reg));\n-  match(RegL);\n-  match(eADXRegL);\n-\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eADXRegL( eRegL reg ) %{\n-  constraint(ALLOC_IN_RC(eadx_reg));\n-  match(reg);\n-\n-  format %{ \"EDX:EAX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eBCXRegL( eRegL reg ) %{\n-  constraint(ALLOC_IN_RC(ebcx_reg));\n-  match(reg);\n-\n-  format %{ \"EBX:ECX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eBDPRegL( eRegL reg ) %{\n-  constraint(ALLOC_IN_RC(ebpd_reg));\n-  match(reg);\n-\n-  format %{ \"EBP:EDI\" %}\n-  interface(REG_INTER);\n-%}\n-\/\/ Special case for integer high multiply\n-operand eADXRegL_low_only() %{\n-  constraint(ALLOC_IN_RC(eadx_reg));\n-  match(RegL);\n-\n-  format %{ \"EAX\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Flags register, used as output of compare instructions\n-operand rFlagsReg() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-\n-  format %{ \"EFLAGS\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Flags register, used as output of compare instructions\n-operand eFlagsReg() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-\n-  format %{ \"EFLAGS\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Flags register, used as output of FLOATING POINT compare instructions\n-operand eFlagsRegU() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-\n-  format %{ \"EFLAGS_U\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand eFlagsRegUCF() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  predicate(false);\n-\n-  format %{ \"EFLAGS_U_CF\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Condition Code Register used by long compare\n-operand flagsReg_long_LTGE() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_LTGE\" %}\n-  interface(REG_INTER);\n-%}\n-operand flagsReg_long_EQNE() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_EQNE\" %}\n-  interface(REG_INTER);\n-%}\n-operand flagsReg_long_LEGT() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_LEGT\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Condition Code Register used by unsigned long compare\n-operand flagsReg_ulong_LTGE() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_U_LTGE\" %}\n-  interface(REG_INTER);\n-%}\n-operand flagsReg_ulong_EQNE() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_U_EQNE\" %}\n-  interface(REG_INTER);\n-%}\n-operand flagsReg_ulong_LEGT() %{\n-  constraint(ALLOC_IN_RC(int_flags));\n-  match(RegFlags);\n-  format %{ \"FLAGS_U_LEGT\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Float register operands\n-operand regDPR() %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_dbl_reg));\n-  match(RegD);\n-  match(regDPR1);\n-  match(regDPR2);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand regDPR1(regDPR reg) %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_dbl_reg0));\n-  match(reg);\n-  format %{ \"FPR1\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand regDPR2(regDPR reg) %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_dbl_reg1));\n-  match(reg);\n-  format %{ \"FPR2\" %}\n-  interface(REG_INTER);\n-%}\n-\n-operand regnotDPR1(regDPR reg) %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_dbl_notreg0));\n-  match(reg);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Float register operands\n-operand regFPR() %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_flt_reg));\n-  match(RegF);\n-  match(regFPR1);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Float register operands\n-operand regFPR1(regFPR reg) %{\n-  predicate( UseSSE < 2 );\n-  constraint(ALLOC_IN_RC(fp_flt_reg0));\n-  match(reg);\n-  format %{ \"FPR1\" %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ XMM Float register operands\n-operand regF() %{\n-  predicate( UseSSE>=1 );\n-  constraint(ALLOC_IN_RC(float_reg_legacy));\n-  match(RegF);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand legRegF() %{\n-  predicate( UseSSE>=1 );\n-  constraint(ALLOC_IN_RC(float_reg_legacy));\n-  match(RegF);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Float register operands\n-operand vlRegF() %{\n-   constraint(ALLOC_IN_RC(float_reg_vl));\n-   match(RegF);\n-\n-   format %{ %}\n-   interface(REG_INTER);\n-%}\n-\n-\/\/ XMM Double register operands\n-operand regD() %{\n-  predicate( UseSSE>=2 );\n-  constraint(ALLOC_IN_RC(double_reg_legacy));\n-  match(RegD);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Double register operands\n-operand legRegD() %{\n-  predicate( UseSSE>=2 );\n-  constraint(ALLOC_IN_RC(double_reg_legacy));\n-  match(RegD);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vlRegD() %{\n-   constraint(ALLOC_IN_RC(double_reg_vl));\n-   match(RegD);\n-\n-   format %{ %}\n-   interface(REG_INTER);\n-%}\n-\n-\/\/----------Memory Operands----------------------------------------------------\n-\/\/ Direct Memory Operand\n-operand direct(immP addr) %{\n-  match(addr);\n-\n-  format %{ \"[$addr]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0xFFFFFFFF);\n-    index(0x4);\n-    scale(0x0);\n-    disp($addr);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Operand\n-operand indirect(eRegP reg) %{\n-  constraint(ALLOC_IN_RC(int_reg));\n-  match(reg);\n-\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp(0x0);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Short Offset Operand\n-operand indOffset8(eRegP reg, immI8 off) %{\n-  match(AddP reg off);\n-\n-  format %{ \"[$reg + $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Long Offset Operand\n-operand indOffset32(eRegP reg, immI off) %{\n-  match(AddP reg off);\n-\n-  format %{ \"[$reg + $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Long Offset Operand\n-operand indOffset32X(rRegI reg, immP off) %{\n-  match(AddP off reg);\n-\n-  format %{ \"[$reg + $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Index Register Plus Offset Operand\n-operand indIndexOffset(eRegP reg, rRegI ireg, immI off) %{\n-  match(AddP (AddP reg ireg) off);\n-\n-  op_cost(10);\n-  format %{\"[$reg + $off + $ireg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index($ireg);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Index Register Plus Offset Operand\n-operand indIndex(eRegP reg, rRegI ireg) %{\n-  match(AddP reg ireg);\n-\n-  op_cost(10);\n-  format %{\"[$reg + $ireg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index($ireg);\n-    scale(0x0);\n-    disp(0x0);\n-  %}\n-%}\n-\n-\/\/ \/\/ -------------------------------------------------------------------------\n-\/\/ \/\/ 486 architecture doesn't support \"scale * index + offset\" with out a base\n-\/\/ \/\/ -------------------------------------------------------------------------\n-\/\/ \/\/ Scaled Memory Operands\n-\/\/ \/\/ Indirect Memory Times Scale Plus Offset Operand\n-\/\/ operand indScaleOffset(immP off, rRegI ireg, immI2 scale) %{\n-\/\/   match(AddP off (LShiftI ireg scale));\n-\/\/\n-\/\/   op_cost(10);\n-\/\/   format %{\"[$off + $ireg << $scale]\" %}\n-\/\/   interface(MEMORY_INTER) %{\n-\/\/     base(0x4);\n-\/\/     index($ireg);\n-\/\/     scale($scale);\n-\/\/     disp($off);\n-\/\/   %}\n-\/\/ %}\n-\n-\/\/ Indirect Memory Times Scale Plus Index Register\n-operand indIndexScale(eRegP reg, rRegI ireg, immI2 scale) %{\n-  match(AddP reg (LShiftI ireg scale));\n-\n-  op_cost(10);\n-  format %{\"[$reg + $ireg << $scale]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index($ireg);\n-    scale($scale);\n-    disp(0x0);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Times Scale Plus Index Register Plus Offset Operand\n-operand indIndexScaleOffset(eRegP reg, immI off, rRegI ireg, immI2 scale) %{\n-  match(AddP (AddP reg (LShiftI ireg scale)) off);\n-\n-  op_cost(10);\n-  format %{\"[$reg + $off + $ireg << $scale]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index($ireg);\n-    scale($scale);\n-    disp($off);\n-  %}\n-%}\n-\n-\/\/----------Load Long Memory Operands------------------------------------------\n-\/\/ The load-long idiom will use it's address expression again after loading\n-\/\/ the first word of the long.  If the load-long destination overlaps with\n-\/\/ registers used in the addressing expression, the 2nd half will be loaded\n-\/\/ from a clobbered address.  Fix this by requiring that load-long use\n-\/\/ address registers that do not overlap with the load-long target.\n-\n-\/\/ load-long support\n-operand load_long_RegP() %{\n-  constraint(ALLOC_IN_RC(esi_reg));\n-  match(RegP);\n-  match(eSIRegP);\n-  op_cost(100);\n-  format %{  %}\n-  interface(REG_INTER);\n-%}\n-\n-\/\/ Indirect Memory Operand Long\n-operand load_long_indirect(load_long_RegP reg) %{\n-  constraint(ALLOC_IN_RC(esi_reg));\n-  match(reg);\n-\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp(0x0);\n-  %}\n-%}\n-\n-\/\/ Indirect Memory Plus Long Offset Operand\n-operand load_long_indOffset32(load_long_RegP reg, immI off) %{\n-  match(AddP reg off);\n-\n-  format %{ \"[$reg + $off]\" %}\n-  interface(MEMORY_INTER) %{\n-    base($reg);\n-    index(0x4);\n-    scale(0x0);\n-    disp($off);\n-  %}\n-%}\n-\n-opclass load_long_memory(load_long_indirect, load_long_indOffset32);\n-\n-\n-\/\/----------Special Memory Operands--------------------------------------------\n-\/\/ Stack Slot Operand - This operand is used for loading and storing temporary\n-\/\/                      values on the stack where a match requires a value to\n-\/\/                      flow through memory.\n-operand stackSlotP(sRegP reg) %{\n-  constraint(ALLOC_IN_RC(stack_slots));\n-  \/\/ No match rule because this operand is only generated in matching\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0x4);   \/\/ ESP\n-    index(0x4);  \/\/ No Index\n-    scale(0x0);  \/\/ No Scale\n-    disp($reg);  \/\/ Stack Offset\n-  %}\n-%}\n-\n-operand stackSlotI(sRegI reg) %{\n-  constraint(ALLOC_IN_RC(stack_slots));\n-  \/\/ No match rule because this operand is only generated in matching\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0x4);   \/\/ ESP\n-    index(0x4);  \/\/ No Index\n-    scale(0x0);  \/\/ No Scale\n-    disp($reg);  \/\/ Stack Offset\n-  %}\n-%}\n-\n-operand stackSlotF(sRegF reg) %{\n-  constraint(ALLOC_IN_RC(stack_slots));\n-  \/\/ No match rule because this operand is only generated in matching\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0x4);   \/\/ ESP\n-    index(0x4);  \/\/ No Index\n-    scale(0x0);  \/\/ No Scale\n-    disp($reg);  \/\/ Stack Offset\n-  %}\n-%}\n-\n-operand stackSlotD(sRegD reg) %{\n-  constraint(ALLOC_IN_RC(stack_slots));\n-  \/\/ No match rule because this operand is only generated in matching\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0x4);   \/\/ ESP\n-    index(0x4);  \/\/ No Index\n-    scale(0x0);  \/\/ No Scale\n-    disp($reg);  \/\/ Stack Offset\n-  %}\n-%}\n-\n-operand stackSlotL(sRegL reg) %{\n-  constraint(ALLOC_IN_RC(stack_slots));\n-  \/\/ No match rule because this operand is only generated in matching\n-  format %{ \"[$reg]\" %}\n-  interface(MEMORY_INTER) %{\n-    base(0x4);   \/\/ ESP\n-    index(0x4);  \/\/ No Index\n-    scale(0x0);  \/\/ No Scale\n-    disp($reg);  \/\/ Stack Offset\n-  %}\n-%}\n-\n-\/\/----------Conditional Branch Operands----------------------------------------\n-\/\/ Comparison Op  - This is the operation of the comparison, and is limited to\n-\/\/                  the following set of codes:\n-\/\/                  L (<), LE (<=), G (>), GE (>=), E (==), NE (!=)\n-\/\/\n-\/\/ Other attributes of the comparison, such as unsignedness, are specified\n-\/\/ by the comparison instruction that sets a condition code flags register.\n-\/\/ That result is represented by a flags operand whose subtype is appropriate\n-\/\/ to the unsignedness (etc.) of the comparison.\n-\/\/\n-\/\/ Later, the instruction which matches both the Comparison Op (a Bool) and\n-\/\/ the flags (produced by the Cmp) specifies the coding of the comparison op\n-\/\/ by matching a specific subtype of Bool operand below, such as cmpOpU.\n-\n-\/\/ Comparison Code\n-operand cmpOp() %{\n-  match(Bool);\n-\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0xC, \"l\");\n-    greater_equal(0xD, \"ge\");\n-    less_equal(0xE, \"le\");\n-    greater(0xF, \"g\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\/\/ Comparison Code, unsigned compare.  Used by FP also, with\n-\/\/ C2 (unordered) turned into GT or LT already.  The other bits\n-\/\/ C0 and C3 are turned into Carry & Zero flags.\n-operand cmpOpU() %{\n-  match(Bool);\n-\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0x2, \"b\");\n-    greater_equal(0x3, \"nb\");\n-    less_equal(0x6, \"be\");\n-    greater(0x7, \"nbe\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\/\/ Floating comparisons that don't require any fixup for the unordered case\n-operand cmpOpUCF() %{\n-  match(Bool);\n-  predicate(n->as_Bool()->_test._test == BoolTest::lt ||\n-            n->as_Bool()->_test._test == BoolTest::ge ||\n-            n->as_Bool()->_test._test == BoolTest::le ||\n-            n->as_Bool()->_test._test == BoolTest::gt);\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0x2, \"b\");\n-    greater_equal(0x3, \"nb\");\n-    less_equal(0x6, \"be\");\n-    greater(0x7, \"nbe\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\n-\/\/ Floating comparisons that can be fixed up with extra conditional jumps\n-operand cmpOpUCF2() %{\n-  match(Bool);\n-  predicate(n->as_Bool()->_test._test == BoolTest::ne ||\n-            n->as_Bool()->_test._test == BoolTest::eq);\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0x2, \"b\");\n-    greater_equal(0x3, \"nb\");\n-    less_equal(0x6, \"be\");\n-    greater(0x7, \"nbe\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\/\/ Comparison Code for FP conditional move\n-operand cmpOp_fcmov() %{\n-  match(Bool);\n-\n-  predicate(n->as_Bool()->_test._test != BoolTest::overflow &&\n-            n->as_Bool()->_test._test != BoolTest::no_overflow);\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal        (0x0C8);\n-    not_equal    (0x1C8);\n-    less         (0x0C0);\n-    greater_equal(0x1C0);\n-    less_equal   (0x0D0);\n-    greater      (0x1D0);\n-    overflow(0x0, \"o\"); \/\/ not really supported by the instruction\n-    no_overflow(0x1, \"no\"); \/\/ not really supported by the instruction\n-  %}\n-%}\n-\n-\/\/ Comparison Code used in long compares\n-operand cmpOp_commute() %{\n-  match(Bool);\n-\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0xF, \"g\");\n-    greater_equal(0xE, \"le\");\n-    less_equal(0xD, \"ge\");\n-    greater(0xC, \"l\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\/\/ Comparison Code used in unsigned long compares\n-operand cmpOpU_commute() %{\n-  match(Bool);\n-\n-  format %{ \"\" %}\n-  interface(COND_INTER) %{\n-    equal(0x4, \"e\");\n-    not_equal(0x5, \"ne\");\n-    less(0x7, \"nbe\");\n-    greater_equal(0x6, \"be\");\n-    less_equal(0x3, \"nb\");\n-    greater(0x2, \"b\");\n-    overflow(0x0, \"o\");\n-    no_overflow(0x1, \"no\");\n-  %}\n-%}\n-\n-\/\/----------OPERAND CLASSES----------------------------------------------------\n-\/\/ Operand Classes are groups of operands that are used as to simplify\n-\/\/ instruction definitions by not requiring the AD writer to specify separate\n-\/\/ instructions for every form of operand when the instruction accepts\n-\/\/ multiple operand types with the same basic encoding and format.  The classic\n-\/\/ case of this is memory operands.\n-\n-opclass memory(direct, indirect, indOffset8, indOffset32, indOffset32X, indIndexOffset,\n-               indIndex, indIndexScale, indIndexScaleOffset);\n-\n-\/\/ Long memory operations are encoded in 2 instructions and a +4 offset.\n-\/\/ This means some kind of offset is always required and you cannot use\n-\/\/ an oop as the offset (done when working on static globals).\n-opclass long_memory(direct, indirect, indOffset8, indOffset32, indIndexOffset,\n-                    indIndex, indIndexScale, indIndexScaleOffset);\n-\n-\n-\/\/----------PIPELINE-----------------------------------------------------------\n-\/\/ Rules which define the behavior of the target architectures pipeline.\n-pipeline %{\n-\n-\/\/----------ATTRIBUTES---------------------------------------------------------\n-attributes %{\n-  variable_size_instructions;        \/\/ Fixed size instructions\n-  max_instructions_per_bundle = 3;   \/\/ Up to 3 instructions per bundle\n-  instruction_unit_size = 1;         \/\/ An instruction is 1 bytes long\n-  instruction_fetch_unit_size = 16;  \/\/ The processor fetches one line\n-  instruction_fetch_units = 1;       \/\/ of 16 bytes\n-\n-  \/\/ List of nop instructions\n-  nops( MachNop );\n-%}\n-\n-\/\/----------RESOURCES----------------------------------------------------------\n-\/\/ Resources are the functional units available to the machine\n-\n-\/\/ Generic P2\/P3 pipeline\n-\/\/ 3 decoders, only D0 handles big operands; a \"bundle\" is the limit of\n-\/\/ 3 instructions decoded per cycle.\n-\/\/ 2 load\/store ops per cycle, 1 branch, 1 FPU,\n-\/\/ 2 ALU op, only ALU0 handles mul\/div instructions.\n-resources( D0, D1, D2, DECODE = D0 | D1 | D2,\n-           MS0, MS1, MEM = MS0 | MS1,\n-           BR, FPU,\n-           ALU0, ALU1, ALU = ALU0 | ALU1 );\n-\n-\/\/----------PIPELINE DESCRIPTION-----------------------------------------------\n-\/\/ Pipeline Description specifies the stages in the machine's pipeline\n-\n-\/\/ Generic P2\/P3 pipeline\n-pipe_desc(S0, S1, S2, S3, S4, S5);\n-\n-\/\/----------PIPELINE CLASSES---------------------------------------------------\n-\/\/ Pipeline Classes describe the stages in which input and output are\n-\/\/ referenced by the hardware pipeline.\n-\n-\/\/ Naming convention: ialu or fpu\n-\/\/ Then: _reg\n-\/\/ Then: _reg if there is a 2nd register\n-\/\/ Then: _long if it's a pair of instructions implementing a long\n-\/\/ Then: _fat if it requires the big decoder\n-\/\/   Or: _mem if it requires the big decoder and a memory unit.\n-\n-\/\/ Integer ALU reg operation\n-pipe_class ialu_reg(rRegI dst) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    dst    : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Long ALU reg operation\n-pipe_class ialu_reg_long(eRegL dst) %{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    dst    : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-    ALU    : S3(2);     \/\/ both alus\n-%}\n-\n-\/\/ Integer ALU reg operation using big decoder\n-pipe_class ialu_reg_fat(rRegI dst) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    dst    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Long ALU reg operation using big decoder\n-pipe_class ialu_reg_long_fat(eRegL dst) %{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    dst    : S3(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S3(2);     \/\/ any 2 alus\n-%}\n-\n-\/\/ Integer ALU reg-reg operation\n-pipe_class ialu_reg_reg(rRegI dst, rRegI src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Long ALU reg-reg operation\n-pipe_class ialu_reg_reg_long(eRegL dst, eRegL src) %{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    src    : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-    ALU    : S3(2);     \/\/ both alus\n-%}\n-\n-\/\/ Integer ALU reg-reg operation\n-pipe_class ialu_reg_reg_fat(rRegI dst, memory src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Long ALU reg-reg operation\n-pipe_class ialu_reg_reg_long_fat(eRegL dst, eRegL src) %{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    src    : S3(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S3(2);     \/\/ both alus\n-%}\n-\n-\/\/ Integer ALU reg-mem operation\n-pipe_class ialu_reg_mem(rRegI dst, memory mem) %{\n-    single_instruction;\n-    dst    : S5(write);\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S4;        \/\/ any alu\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Long ALU reg-mem operation\n-pipe_class ialu_reg_long_mem(eRegL dst, load_long_memory mem) %{\n-    instruction_count(2);\n-    dst    : S5(write);\n-    mem    : S3(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S4(2);     \/\/ any 2 alus\n-    MEM    : S3(2);     \/\/ both mems\n-%}\n-\n-\/\/ Integer mem operation (prefetch)\n-pipe_class ialu_mem(memory mem)\n-%{\n-    single_instruction;\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Integer Store to Memory\n-pipe_class ialu_mem_reg(memory mem, rRegI src) %{\n-    single_instruction;\n-    mem    : S3(read);\n-    src    : S5(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S4;        \/\/ any alu\n-    MEM    : S3;\n-%}\n-\n-\/\/ Long Store to Memory\n-pipe_class ialu_mem_long_reg(memory mem, eRegL src) %{\n-    instruction_count(2);\n-    mem    : S3(read);\n-    src    : S5(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S4(2);     \/\/ any 2 alus\n-    MEM    : S3(2);     \/\/ Both mems\n-%}\n-\n-\/\/ Integer Store to Memory\n-pipe_class ialu_mem_imm(memory mem) %{\n-    single_instruction;\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S4;        \/\/ any alu\n-    MEM    : S3;\n-%}\n-\n-\/\/ Integer ALU0 reg-reg operation\n-pipe_class ialu_reg_reg_alu0(rRegI dst, rRegI src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    D0     : S0;        \/\/ Big decoder only\n-    ALU0   : S3;        \/\/ only alu0\n-%}\n-\n-\/\/ Integer ALU0 reg-mem operation\n-pipe_class ialu_reg_mem_alu0(rRegI dst, memory mem) %{\n-    single_instruction;\n-    dst    : S5(write);\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU0   : S4;        \/\/ ALU0 only\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Integer ALU reg-reg operation\n-pipe_class ialu_cr_reg_reg(eFlagsReg cr, rRegI src1, rRegI src2) %{\n-    single_instruction;\n-    cr     : S4(write);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Integer ALU reg-imm operation\n-pipe_class ialu_cr_reg_imm(eFlagsReg cr, rRegI src1) %{\n-    single_instruction;\n-    cr     : S4(write);\n-    src1   : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-    ALU    : S3;        \/\/ any alu\n-%}\n-\n-\/\/ Integer ALU reg-mem operation\n-pipe_class ialu_cr_reg_mem(eFlagsReg cr, rRegI src1, memory src2) %{\n-    single_instruction;\n-    cr     : S4(write);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    ALU    : S4;        \/\/ any alu\n-    MEM    : S3;\n-%}\n-\n-\/\/ Conditional move reg-reg\n-pipe_class pipe_cmplt( rRegI p, rRegI q, rRegI y ) %{\n-    instruction_count(4);\n-    y      : S4(read);\n-    q      : S3(read);\n-    p      : S3(read);\n-    DECODE : S0(4);     \/\/ any decoder\n-%}\n-\n-\/\/ Conditional move reg-reg\n-pipe_class pipe_cmov_reg( rRegI dst, rRegI src, eFlagsReg cr ) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    cr     : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-%}\n-\n-\/\/ Conditional move reg-mem\n-pipe_class pipe_cmov_mem( eFlagsReg cr, rRegI dst, memory src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    cr     : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-    MEM    : S3;\n-%}\n-\n-\/\/ Conditional move reg-reg long\n-pipe_class pipe_cmov_reg_long( eFlagsReg cr, eRegL dst, eRegL src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    cr     : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-%}\n-\n-\/\/ Conditional move double reg-reg\n-pipe_class pipe_cmovDPR_reg( eFlagsReg cr, regDPR1 dst, regDPR src) %{\n-    single_instruction;\n-    dst    : S4(write);\n-    src    : S3(read);\n-    cr     : S3(read);\n-    DECODE : S0;        \/\/ any decoder\n-%}\n-\n-\/\/ Float reg-reg operation\n-pipe_class fpu_reg(regDPR dst) %{\n-    instruction_count(2);\n-    dst    : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-    FPU    : S3;\n-%}\n-\n-\/\/ Float reg-reg operation\n-pipe_class fpu_reg_reg(regDPR dst, regDPR src) %{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    src    : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-    FPU    : S3;\n-%}\n-\n-\/\/ Float reg-reg operation\n-pipe_class fpu_reg_reg_reg(regDPR dst, regDPR src1, regDPR src2) %{\n-    instruction_count(3);\n-    dst    : S4(write);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    DECODE : S0(3);     \/\/ any 3 decoders\n-    FPU    : S3(2);\n-%}\n-\n-\/\/ Float reg-reg operation\n-pipe_class fpu_reg_reg_reg_reg(regDPR dst, regDPR src1, regDPR src2, regDPR src3) %{\n-    instruction_count(4);\n-    dst    : S4(write);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    src3   : S3(read);\n-    DECODE : S0(4);     \/\/ any 3 decoders\n-    FPU    : S3(2);\n-%}\n-\n-\/\/ Float reg-reg operation\n-pipe_class fpu_reg_mem_reg_reg(regDPR dst, memory src1, regDPR src2, regDPR src3) %{\n-    instruction_count(4);\n-    dst    : S4(write);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    src3   : S3(read);\n-    DECODE : S1(3);     \/\/ any 3 decoders\n-    D0     : S0;        \/\/ Big decoder only\n-    FPU    : S3(2);\n-    MEM    : S3;\n-%}\n-\n-\/\/ Float reg-mem operation\n-pipe_class fpu_reg_mem(regDPR dst, memory mem) %{\n-    instruction_count(2);\n-    dst    : S5(write);\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    DECODE : S1;        \/\/ any decoder for FPU POP\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Float reg-mem operation\n-pipe_class fpu_reg_reg_mem(regDPR dst, regDPR src1, memory mem) %{\n-    instruction_count(3);\n-    dst    : S5(write);\n-    src1   : S3(read);\n-    mem    : S3(read);\n-    D0     : S0;        \/\/ big decoder only\n-    DECODE : S1(2);     \/\/ any decoder for FPU POP\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Float mem-reg operation\n-pipe_class fpu_mem_reg(memory mem, regDPR src) %{\n-    instruction_count(2);\n-    src    : S5(read);\n-    mem    : S3(read);\n-    DECODE : S0;        \/\/ any decoder for FPU PUSH\n-    D0     : S1;        \/\/ big decoder only\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-pipe_class fpu_mem_reg_reg(memory mem, regDPR src1, regDPR src2) %{\n-    instruction_count(3);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    mem    : S3(read);\n-    DECODE : S0(2);     \/\/ any decoder for FPU PUSH\n-    D0     : S1;        \/\/ big decoder only\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-pipe_class fpu_mem_reg_mem(memory mem, regDPR src1, memory src2) %{\n-    instruction_count(3);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    mem    : S4(read);\n-    DECODE : S0;        \/\/ any decoder for FPU PUSH\n-    D0     : S0(2);     \/\/ big decoder only\n-    FPU    : S4;\n-    MEM    : S3(2);     \/\/ any mem\n-%}\n-\n-pipe_class fpu_mem_mem(memory dst, memory src1) %{\n-    instruction_count(2);\n-    src1   : S3(read);\n-    dst    : S4(read);\n-    D0     : S0(2);     \/\/ big decoder only\n-    MEM    : S3(2);     \/\/ any mem\n-%}\n-\n-pipe_class fpu_mem_mem_mem(memory dst, memory src1, memory src2) %{\n-    instruction_count(3);\n-    src1   : S3(read);\n-    src2   : S3(read);\n-    dst    : S4(read);\n-    D0     : S0(3);     \/\/ big decoder only\n-    FPU    : S4;\n-    MEM    : S3(3);     \/\/ any mem\n-%}\n-\n-pipe_class fpu_mem_reg_con(memory mem, regDPR src1) %{\n-    instruction_count(3);\n-    src1   : S4(read);\n-    mem    : S4(read);\n-    DECODE : S0;        \/\/ any decoder for FPU PUSH\n-    D0     : S0(2);     \/\/ big decoder only\n-    FPU    : S4;\n-    MEM    : S3(2);     \/\/ any mem\n-%}\n-\n-\/\/ Float load constant\n-pipe_class fpu_reg_con(regDPR dst) %{\n-    instruction_count(2);\n-    dst    : S5(write);\n-    D0     : S0;        \/\/ big decoder only for the load\n-    DECODE : S1;        \/\/ any decoder for FPU POP\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ Float load constant\n-pipe_class fpu_reg_reg_con(regDPR dst, regDPR src) %{\n-    instruction_count(3);\n-    dst    : S5(write);\n-    src    : S3(read);\n-    D0     : S0;        \/\/ big decoder only for the load\n-    DECODE : S1(2);     \/\/ any decoder for FPU POP\n-    FPU    : S4;\n-    MEM    : S3;        \/\/ any mem\n-%}\n-\n-\/\/ UnConditional branch\n-pipe_class pipe_jmp( label labl ) %{\n-    single_instruction;\n-    BR   : S3;\n-%}\n-\n-\/\/ Conditional branch\n-pipe_class pipe_jcc( cmpOp cmp, eFlagsReg cr, label labl ) %{\n-    single_instruction;\n-    cr    : S1(read);\n-    BR    : S3;\n-%}\n-\n-\/\/ Allocation idiom\n-pipe_class pipe_cmpxchg( eRegP dst, eRegP heap_ptr ) %{\n-    instruction_count(1); force_serialization;\n-    fixed_latency(6);\n-    heap_ptr : S3(read);\n-    DECODE   : S0(3);\n-    D0       : S2;\n-    MEM      : S3;\n-    ALU      : S3(2);\n-    dst      : S5(write);\n-    BR       : S5;\n-%}\n-\n-\/\/ Generic big\/slow expanded idiom\n-pipe_class pipe_slow(  ) %{\n-    instruction_count(10); multiple_bundles; force_serialization;\n-    fixed_latency(100);\n-    D0  : S0(2);\n-    MEM : S3(2);\n-%}\n-\n-\/\/ The real do-nothing guy\n-pipe_class empty( ) %{\n-    instruction_count(0);\n-%}\n-\n-\/\/ Define the class for the Nop node\n-define %{\n-   MachNop = empty;\n-%}\n-\n-%}\n-\n-\/\/----------INSTRUCTIONS-------------------------------------------------------\n-\/\/\n-\/\/ match      -- States which machine-independent subtree may be replaced\n-\/\/               by this instruction.\n-\/\/ ins_cost   -- The estimated cost of this instruction is used by instruction\n-\/\/               selection to identify a minimum cost tree of machine\n-\/\/               instructions that matches a tree of machine-independent\n-\/\/               instructions.\n-\/\/ format     -- A string providing the disassembly for this instruction.\n-\/\/               The value of an instruction's operand may be inserted\n-\/\/               by referring to it with a '$' prefix.\n-\/\/ opcode     -- Three instruction opcodes may be provided.  These are referred\n-\/\/               to within an encode class as $primary, $secondary, and $tertiary\n-\/\/               respectively.  The primary opcode is commonly used to\n-\/\/               indicate the type of machine instruction, while secondary\n-\/\/               and tertiary are often used for prefix options or addressing\n-\/\/               modes.\n-\/\/ ins_encode -- A list of encode classes with parameters. The encode class\n-\/\/               name must have been defined in an 'enc_class' specification\n-\/\/               in the encode section of the architecture description.\n-\n-\/\/ Dummy reg-to-reg vector moves. Removed during post-selection cleanup.\n-\/\/ Load Float\n-instruct MoveF2LEG(legRegF dst, regF src) %{\n-  match(Set dst src);\n-  format %{ \"movss $dst,$src\\t# if src != dst load float (4 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Float\n-instruct MoveLEG2F(regF dst, legRegF src) %{\n-  match(Set dst src);\n-  format %{ \"movss $dst,$src\\t# if src != dst load float (4 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Float\n-instruct MoveF2VL(vlRegF dst, regF src) %{\n-  match(Set dst src);\n-  format %{ \"movss $dst,$src\\t! load float (4 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Float\n-instruct MoveVL2F(regF dst, vlRegF src) %{\n-  match(Set dst src);\n-  format %{ \"movss $dst,$src\\t! load float (4 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\n-\n-\/\/ Load Double\n-instruct MoveD2LEG(legRegD dst, regD src) %{\n-  match(Set dst src);\n-  format %{ \"movsd $dst,$src\\t# if src != dst load double (8 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Double\n-instruct MoveLEG2D(regD dst, legRegD src) %{\n-  match(Set dst src);\n-  format %{ \"movsd $dst,$src\\t# if src != dst load double (8 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Double\n-instruct MoveD2VL(vlRegD dst, regD src) %{\n-  match(Set dst src);\n-  format %{ \"movsd $dst,$src\\t! load double (8 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Load Double\n-instruct MoveVL2D(regD dst, vlRegD src) %{\n-  match(Set dst src);\n-  format %{ \"movsd $dst,$src\\t! load double (8 bytes)\" %}\n-  ins_encode %{\n-    ShouldNotReachHere();\n-  %}\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/----------BSWAP-Instruction--------------------------------------------------\n-instruct bytes_reverse_int(rRegI dst) %{\n-  match(Set dst (ReverseBytesI dst));\n-\n-  format %{ \"BSWAP  $dst\" %}\n-  opcode(0x0F, 0xC8);\n-  ins_encode( OpcP, OpcSReg(dst) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct bytes_reverse_long(eRegL dst) %{\n-  match(Set dst (ReverseBytesL dst));\n-\n-  format %{ \"BSWAP  $dst.lo\\n\\t\"\n-            \"BSWAP  $dst.hi\\n\\t\"\n-            \"XCHG   $dst.lo $dst.hi\" %}\n-\n-  ins_cost(125);\n-  ins_encode( bswap_long_bytes(dst) );\n-  ins_pipe( ialu_reg_reg);\n-%}\n-\n-instruct bytes_reverse_unsigned_short(rRegI dst, eFlagsReg cr) %{\n-  match(Set dst (ReverseBytesUS dst));\n-  effect(KILL cr);\n-\n-  format %{ \"BSWAP  $dst\\n\\t\"\n-            \"SHR    $dst,16\\n\\t\" %}\n-  ins_encode %{\n-    __ bswapl($dst$$Register);\n-    __ shrl($dst$$Register, 16);\n-  %}\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct bytes_reverse_short(rRegI dst, eFlagsReg cr) %{\n-  match(Set dst (ReverseBytesS dst));\n-  effect(KILL cr);\n-\n-  format %{ \"BSWAP  $dst\\n\\t\"\n-            \"SAR    $dst,16\\n\\t\" %}\n-  ins_encode %{\n-    __ bswapl($dst$$Register);\n-    __ sarl($dst$$Register, 16);\n-  %}\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\n-\/\/---------- Zeros Count Instructions ------------------------------------------\n-\n-instruct countLeadingZerosI(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  predicate(UseCountLeadingZerosInstruction);\n-  match(Set dst (CountLeadingZerosI src));\n-  effect(KILL cr);\n-\n-  format %{ \"LZCNT  $dst, $src\\t# count leading zeros (int)\" %}\n-  ins_encode %{\n-    __ lzcntl($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countLeadingZerosI_bsr(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  predicate(!UseCountLeadingZerosInstruction);\n-  match(Set dst (CountLeadingZerosI src));\n-  effect(KILL cr);\n-\n-  format %{ \"BSR    $dst, $src\\t# count leading zeros (int)\\n\\t\"\n-            \"JNZ    skip\\n\\t\"\n-            \"MOV    $dst, -1\\n\"\n-      \"skip:\\n\\t\"\n-            \"NEG    $dst\\n\\t\"\n-            \"ADD    $dst, 31\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    Label skip;\n-    __ bsrl(Rdst, Rsrc);\n-    __ jccb(Assembler::notZero, skip);\n-    __ movl(Rdst, -1);\n-    __ bind(skip);\n-    __ negl(Rdst);\n-    __ addl(Rdst, BitsPerInt - 1);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countLeadingZerosL(rRegI dst, eRegL src, eFlagsReg cr) %{\n-  predicate(UseCountLeadingZerosInstruction);\n-  match(Set dst (CountLeadingZerosL src));\n-  effect(TEMP dst, KILL cr);\n-\n-  format %{ \"LZCNT  $dst, $src.hi\\t# count leading zeros (long)\\n\\t\"\n-            \"JNC    done\\n\\t\"\n-            \"LZCNT  $dst, $src.lo\\n\\t\"\n-            \"ADD    $dst, 32\\n\"\n-      \"done:\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    Label done;\n-    __ lzcntl(Rdst, HIGH_FROM_LOW(Rsrc));\n-    __ jccb(Assembler::carryClear, done);\n-    __ lzcntl(Rdst, Rsrc);\n-    __ addl(Rdst, BitsPerInt);\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countLeadingZerosL_bsr(rRegI dst, eRegL src, eFlagsReg cr) %{\n-  predicate(!UseCountLeadingZerosInstruction);\n-  match(Set dst (CountLeadingZerosL src));\n-  effect(TEMP dst, KILL cr);\n-\n-  format %{ \"BSR    $dst, $src.hi\\t# count leading zeros (long)\\n\\t\"\n-            \"JZ     msw_is_zero\\n\\t\"\n-            \"ADD    $dst, 32\\n\\t\"\n-            \"JMP    not_zero\\n\"\n-      \"msw_is_zero:\\n\\t\"\n-            \"BSR    $dst, $src.lo\\n\\t\"\n-            \"JNZ    not_zero\\n\\t\"\n-            \"MOV    $dst, -1\\n\"\n-      \"not_zero:\\n\\t\"\n-            \"NEG    $dst\\n\\t\"\n-            \"ADD    $dst, 63\\n\" %}\n- ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    Label msw_is_zero;\n-    Label not_zero;\n-    __ bsrl(Rdst, HIGH_FROM_LOW(Rsrc));\n-    __ jccb(Assembler::zero, msw_is_zero);\n-    __ addl(Rdst, BitsPerInt);\n-    __ jmpb(not_zero);\n-    __ bind(msw_is_zero);\n-    __ bsrl(Rdst, Rsrc);\n-    __ jccb(Assembler::notZero, not_zero);\n-    __ movl(Rdst, -1);\n-    __ bind(not_zero);\n-    __ negl(Rdst);\n-    __ addl(Rdst, BitsPerLong - 1);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countTrailingZerosI(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  predicate(UseCountTrailingZerosInstruction);\n-  match(Set dst (CountTrailingZerosI src));\n-  effect(KILL cr);\n-\n-  format %{ \"TZCNT    $dst, $src\\t# count trailing zeros (int)\" %}\n-  ins_encode %{\n-    __ tzcntl($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countTrailingZerosI_bsf(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  predicate(!UseCountTrailingZerosInstruction);\n-  match(Set dst (CountTrailingZerosI src));\n-  effect(KILL cr);\n-\n-  format %{ \"BSF    $dst, $src\\t# count trailing zeros (int)\\n\\t\"\n-            \"JNZ    done\\n\\t\"\n-            \"MOV    $dst, 32\\n\"\n-      \"done:\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Label done;\n-    __ bsfl(Rdst, $src$$Register);\n-    __ jccb(Assembler::notZero, done);\n-    __ movl(Rdst, BitsPerInt);\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countTrailingZerosL(rRegI dst, eRegL src, eFlagsReg cr) %{\n-  predicate(UseCountTrailingZerosInstruction);\n-  match(Set dst (CountTrailingZerosL src));\n-  effect(TEMP dst, KILL cr);\n-\n-  format %{ \"TZCNT  $dst, $src.lo\\t# count trailing zeros (long) \\n\\t\"\n-            \"JNC    done\\n\\t\"\n-            \"TZCNT  $dst, $src.hi\\n\\t\"\n-            \"ADD    $dst, 32\\n\"\n-            \"done:\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    Label done;\n-    __ tzcntl(Rdst, Rsrc);\n-    __ jccb(Assembler::carryClear, done);\n-    __ tzcntl(Rdst, HIGH_FROM_LOW(Rsrc));\n-    __ addl(Rdst, BitsPerInt);\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct countTrailingZerosL_bsf(rRegI dst, eRegL src, eFlagsReg cr) %{\n-  predicate(!UseCountTrailingZerosInstruction);\n-  match(Set dst (CountTrailingZerosL src));\n-  effect(TEMP dst, KILL cr);\n-\n-  format %{ \"BSF    $dst, $src.lo\\t# count trailing zeros (long)\\n\\t\"\n-            \"JNZ    done\\n\\t\"\n-            \"BSF    $dst, $src.hi\\n\\t\"\n-            \"JNZ    msw_not_zero\\n\\t\"\n-            \"MOV    $dst, 32\\n\"\n-      \"msw_not_zero:\\n\\t\"\n-            \"ADD    $dst, 32\\n\"\n-      \"done:\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    Label msw_not_zero;\n-    Label done;\n-    __ bsfl(Rdst, Rsrc);\n-    __ jccb(Assembler::notZero, done);\n-    __ bsfl(Rdst, HIGH_FROM_LOW(Rsrc));\n-    __ jccb(Assembler::notZero, msw_not_zero);\n-    __ movl(Rdst, BitsPerInt);\n-    __ bind(msw_not_zero);\n-    __ addl(Rdst, BitsPerInt);\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-\n-\/\/---------- Population Count Instructions -------------------------------------\n-\n-instruct popCountI(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  predicate(UsePopCountInstruction);\n-  match(Set dst (PopCountI src));\n-  effect(KILL cr);\n-\n-  format %{ \"POPCNT $dst, $src\" %}\n-  ins_encode %{\n-    __ popcntl($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct popCountI_mem(rRegI dst, memory mem, eFlagsReg cr) %{\n-  predicate(UsePopCountInstruction);\n-  match(Set dst (PopCountI (LoadI mem)));\n-  effect(KILL cr);\n-\n-  format %{ \"POPCNT $dst, $mem\" %}\n-  ins_encode %{\n-    __ popcntl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-\/\/ Note: Long.bitCount(long) returns an int.\n-instruct popCountL(rRegI dst, eRegL src, rRegI tmp, eFlagsReg cr) %{\n-  predicate(UsePopCountInstruction);\n-  match(Set dst (PopCountL src));\n-  effect(KILL cr, TEMP tmp, TEMP dst);\n-\n-  format %{ \"POPCNT $dst, $src.lo\\n\\t\"\n-            \"POPCNT $tmp, $src.hi\\n\\t\"\n-            \"ADD    $dst, $tmp\" %}\n-  ins_encode %{\n-    __ popcntl($dst$$Register, $src$$Register);\n-    __ popcntl($tmp$$Register, HIGH_FROM_LOW($src$$Register));\n-    __ addl($dst$$Register, $tmp$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-\/\/ Note: Long.bitCount(long) returns an int.\n-instruct popCountL_mem(rRegI dst, memory mem, rRegI tmp, eFlagsReg cr) %{\n-  predicate(UsePopCountInstruction);\n-  match(Set dst (PopCountL (LoadL mem)));\n-  effect(KILL cr, TEMP tmp, TEMP dst);\n-\n-  format %{ \"POPCNT $dst, $mem\\n\\t\"\n-            \"POPCNT $tmp, $mem+4\\n\\t\"\n-            \"ADD    $dst, $tmp\" %}\n-  ins_encode %{\n-    \/\/__ popcntl($dst$$Register, $mem$$Address$$first);\n-    \/\/__ popcntl($tmp$$Register, $mem$$Address$$second);\n-    __ popcntl($dst$$Register, Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none));\n-    __ popcntl($tmp$$Register, Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none));\n-    __ addl($dst$$Register, $tmp$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-\n-\/\/----------Load\/Store\/Move Instructions---------------------------------------\n-\/\/----------Load Instructions--------------------------------------------------\n-\/\/ Load Byte (8bit signed)\n-instruct loadB(xRegI dst, memory mem) %{\n-  match(Set dst (LoadB mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX8 $dst,$mem\\t# byte\" %}\n-\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $mem$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Byte (8bit signed) into Long Register\n-instruct loadB2L(eRegL dst, memory mem, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (LoadB mem)));\n-  effect(KILL cr);\n-\n-  ins_cost(375);\n-  format %{ \"MOVSX8 $dst.lo,$mem\\t# byte -> long\\n\\t\"\n-            \"MOV    $dst.hi,$dst.lo\\n\\t\"\n-            \"SAR    $dst.hi,7\" %}\n-\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $mem$$Address);\n-    __ movl(HIGH_FROM_LOW($dst$$Register), $dst$$Register); \/\/ This is always a different register.\n-    __ sarl(HIGH_FROM_LOW($dst$$Register), 7); \/\/ 24+1 MSB are already signed extended.\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Byte (8bit UNsigned)\n-instruct loadUB(xRegI dst, memory mem) %{\n-  match(Set dst (LoadUB mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOVZX8 $dst,$mem\\t# ubyte -> int\" %}\n-\n-  ins_encode %{\n-    __ movzbl($dst$$Register, $mem$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Byte (8 bit UNsigned) into Long Register\n-instruct loadUB2L(eRegL dst, memory mem, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (LoadUB mem)));\n-  effect(KILL cr);\n-\n-  ins_cost(250);\n-  format %{ \"MOVZX8 $dst.lo,$mem\\t# ubyte -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzbl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Byte (8 bit UNsigned) with mask into Long Register\n-instruct loadUB2L_immI(eRegL dst, memory mem, immI mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadUB mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOVZX8 $dst.lo,$mem\\t# ubyte & 32-bit mask -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\\n\\t\"\n-            \"AND    $dst.lo,right_n_bits($mask, 8)\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzbl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-    __ andl(Rdst, $mask$$constant & right_n_bits(8));\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Short (16bit signed)\n-instruct loadS(rRegI dst, memory mem) %{\n-  match(Set dst (LoadS mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX  $dst,$mem\\t# short\" %}\n-\n-  ins_encode %{\n-    __ movswl($dst$$Register, $mem$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Short (16 bit signed) to Byte (8 bit signed)\n-instruct loadS2B(rRegI dst, memory mem, immI_24 twentyfour) %{\n-  match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX  $dst, $mem\\t# short -> byte\" %}\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Short (16bit signed) into Long Register\n-instruct loadS2L(eRegL dst, memory mem, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (LoadS mem)));\n-  effect(KILL cr);\n-\n-  ins_cost(375);\n-  format %{ \"MOVSX  $dst.lo,$mem\\t# short -> long\\n\\t\"\n-            \"MOV    $dst.hi,$dst.lo\\n\\t\"\n-            \"SAR    $dst.hi,15\" %}\n-\n-  ins_encode %{\n-    __ movswl($dst$$Register, $mem$$Address);\n-    __ movl(HIGH_FROM_LOW($dst$$Register), $dst$$Register); \/\/ This is always a different register.\n-    __ sarl(HIGH_FROM_LOW($dst$$Register), 15); \/\/ 16+1 MSB are already signed extended.\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Short\/Char (16bit unsigned)\n-instruct loadUS(rRegI dst, memory mem) %{\n-  match(Set dst (LoadUS mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOVZX  $dst,$mem\\t# ushort\/char -> int\" %}\n-\n-  ins_encode %{\n-    __ movzwl($dst$$Register, $mem$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Short\/Char (16 bit UNsigned) to Byte (8 bit signed)\n-instruct loadUS2B(rRegI dst, memory mem, immI_24 twentyfour) %{\n-  match(Set dst (RShiftI (LShiftI (LoadUS mem) twentyfour) twentyfour));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX  $dst, $mem\\t# ushort -> byte\" %}\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Short\/Char (16 bit UNsigned) into Long Register\n-instruct loadUS2L(eRegL dst, memory mem, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (LoadUS mem)));\n-  effect(KILL cr);\n-\n-  ins_cost(250);\n-  format %{ \"MOVZX  $dst.lo,$mem\\t# ushort\/char -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-\n-  ins_encode %{\n-    __ movzwl($dst$$Register, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($dst$$Register));\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Short\/Char (16 bit UNsigned) with mask 0xFF into Long Register\n-instruct loadUS2L_immI_255(eRegL dst, memory mem, immI_255 mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOVZX8 $dst.lo,$mem\\t# ushort\/char & 0xFF -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzbl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Short\/Char (16 bit UNsigned) with a 32-bit mask into Long Register\n-instruct loadUS2L_immI(eRegL dst, memory mem, immI mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOVZX  $dst.lo, $mem\\t# ushort\/char & 32-bit mask -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\\n\\t\"\n-            \"AND    $dst.lo,right_n_bits($mask, 16)\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzwl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-    __ andl(Rdst, $mask$$constant & right_n_bits(16));\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer\n-instruct loadI(rRegI dst, memory mem) %{\n-  match(Set dst (LoadI mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $dst,$mem\\t# int\" %}\n-\n-  ins_encode %{\n-    __ movl($dst$$Register, $mem$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer (32 bit signed) to Byte (8 bit signed)\n-instruct loadI2B(rRegI dst, memory mem, immI_24 twentyfour) %{\n-  match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX  $dst, $mem\\t# int -> byte\" %}\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer (32 bit signed) to Unsigned Byte (8 bit UNsigned)\n-instruct loadI2UB(rRegI dst, memory mem, immI_255 mask) %{\n-  match(Set dst (AndI (LoadI mem) mask));\n-\n-  ins_cost(125);\n-  format %{ \"MOVZX  $dst, $mem\\t# int -> ubyte\" %}\n-  ins_encode %{\n-    __ movzbl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer (32 bit signed) to Short (16 bit signed)\n-instruct loadI2S(rRegI dst, memory mem, immI_16 sixteen) %{\n-  match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));\n-\n-  ins_cost(125);\n-  format %{ \"MOVSX  $dst, $mem\\t# int -> short\" %}\n-  ins_encode %{\n-    __ movswl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer (32 bit signed) to Unsigned Short\/Char (16 bit UNsigned)\n-instruct loadI2US(rRegI dst, memory mem, immI_65535 mask) %{\n-  match(Set dst (AndI (LoadI mem) mask));\n-\n-  ins_cost(125);\n-  format %{ \"MOVZX  $dst, $mem\\t# int -> ushort\/char\" %}\n-  ins_encode %{\n-    __ movzwl($dst$$Register, $mem$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer into Long Register\n-instruct loadI2L(eRegL dst, memory mem, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (LoadI mem)));\n-  effect(KILL cr);\n-\n-  ins_cost(375);\n-  format %{ \"MOV    $dst.lo,$mem\\t# int -> long\\n\\t\"\n-            \"MOV    $dst.hi,$dst.lo\\n\\t\"\n-            \"SAR    $dst.hi,31\" %}\n-\n-  ins_encode %{\n-    __ movl($dst$$Register, $mem$$Address);\n-    __ movl(HIGH_FROM_LOW($dst$$Register), $dst$$Register); \/\/ This is always a different register.\n-    __ sarl(HIGH_FROM_LOW($dst$$Register), 31);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer with mask 0xFF into Long Register\n-instruct loadI2L_immI_255(eRegL dst, memory mem, immI_255 mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOVZX8 $dst.lo,$mem\\t# int & 0xFF -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzbl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer with mask 0xFFFF into Long Register\n-instruct loadI2L_immI_65535(eRegL dst, memory mem, immI_65535 mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOVZX  $dst.lo,$mem\\t# int & 0xFFFF -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movzwl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Integer with 31-bit mask into Long Register\n-instruct loadI2L_immU31(eRegL dst, memory mem, immU31 mask, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L (AndI (LoadI mem) mask)));\n-  effect(KILL cr);\n-\n-  format %{ \"MOV    $dst.lo,$mem\\t# int & 31-bit mask -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\\n\\t\"\n-            \"AND    $dst.lo,$mask\" %}\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    __ movl(Rdst, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rdst));\n-    __ andl(Rdst, $mask$$constant);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Unsigned Integer into Long Register\n-instruct loadUI2L(eRegL dst, memory mem, immL_32bits mask, eFlagsReg cr) %{\n-  match(Set dst (AndL (ConvI2L (LoadI mem)) mask));\n-  effect(KILL cr);\n-\n-  ins_cost(250);\n-  format %{ \"MOV    $dst.lo,$mem\\t# uint -> long\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-\n-  ins_encode %{\n-    __ movl($dst$$Register, $mem$$Address);\n-    __ xorl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($dst$$Register));\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Load Long.  Cannot clobber address while loading, so restrict address\n-\/\/ register to ESI\n-instruct loadL(eRegL dst, load_long_memory mem) %{\n-  predicate(!((LoadLNode*)n)->require_atomic_access());\n-  match(Set dst (LoadL mem));\n-\n-  ins_cost(250);\n-  format %{ \"MOV    $dst.lo,$mem\\t# long\\n\\t\"\n-            \"MOV    $dst.hi,$mem+4\" %}\n-\n-  ins_encode %{\n-    Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);\n-    Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);\n-    __ movl($dst$$Register, Amemlo);\n-    __ movl(HIGH_FROM_LOW($dst$$Register), Amemhi);\n-  %}\n-\n-  ins_pipe(ialu_reg_long_mem);\n-%}\n-\n-\/\/ Volatile Load Long.  Must be atomic, so do 64-bit FILD\n-\/\/ then store it down to the stack and reload on the int\n-\/\/ side.\n-instruct loadL_volatile(stackSlotL dst, memory mem) %{\n-  predicate(UseSSE<=1 && ((LoadLNode*)n)->require_atomic_access());\n-  match(Set dst (LoadL mem));\n-\n-  ins_cost(200);\n-  format %{ \"FILD   $mem\\t# Atomic volatile long load\\n\\t\"\n-            \"FISTp  $dst\" %}\n-  ins_encode(enc_loadL_volatile(mem,dst));\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct loadLX_volatile(stackSlotL dst, memory mem, regD tmp) %{\n-  predicate(UseSSE>=2 && ((LoadLNode*)n)->require_atomic_access());\n-  match(Set dst (LoadL mem));\n-  effect(TEMP tmp);\n-  ins_cost(180);\n-  format %{ \"MOVSD  $tmp,$mem\\t# Atomic volatile long load\\n\\t\"\n-            \"MOVSD  $dst,$tmp\" %}\n-  ins_encode %{\n-    __ movdbl($tmp$$XMMRegister, $mem$$Address);\n-    __ movdbl(Address(rsp, $dst$$disp), $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct loadLX_reg_volatile(eRegL dst, memory mem, regD tmp) %{\n-  predicate(UseSSE>=2 && ((LoadLNode*)n)->require_atomic_access());\n-  match(Set dst (LoadL mem));\n-  effect(TEMP tmp);\n-  ins_cost(160);\n-  format %{ \"MOVSD  $tmp,$mem\\t# Atomic volatile long load\\n\\t\"\n-            \"MOVD   $dst.lo,$tmp\\n\\t\"\n-            \"PSRLQ  $tmp,32\\n\\t\"\n-            \"MOVD   $dst.hi,$tmp\" %}\n-  ins_encode %{\n-    __ movdbl($tmp$$XMMRegister, $mem$$Address);\n-    __ movdl($dst$$Register, $tmp$$XMMRegister);\n-    __ psrlq($tmp$$XMMRegister, 32);\n-    __ movdl(HIGH_FROM_LOW($dst$$Register), $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Load Range\n-instruct loadRange(rRegI dst, memory mem) %{\n-  match(Set dst (LoadRange mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $dst,$mem\" %}\n-  opcode(0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\n-\/\/ Load Pointer\n-instruct loadP(eRegP dst, memory mem) %{\n-  match(Set dst (LoadP mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $dst,$mem\" %}\n-  opcode(0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ Load Klass Pointer\n-instruct loadKlass(eRegP dst, memory mem) %{\n-  match(Set dst (LoadKlass mem));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $dst,$mem\" %}\n-  opcode(0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ Load Double\n-instruct loadDPR(regDPR dst, memory mem) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (LoadD mem));\n-\n-  ins_cost(150);\n-  format %{ \"FLD_D  ST,$mem\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDD);               \/* DD \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),\n-              Pop_Reg_DPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Load Double to XMM\n-instruct loadD(regD dst, memory mem) %{\n-  predicate(UseSSE>=2 && UseXmmLoadAndClearUpper);\n-  match(Set dst (LoadD mem));\n-  ins_cost(145);\n-  format %{ \"MOVSD  $dst,$mem\" %}\n-  ins_encode %{\n-    __ movdbl ($dst$$XMMRegister, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct loadD_partial(regD dst, memory mem) %{\n-  predicate(UseSSE>=2 && !UseXmmLoadAndClearUpper);\n-  match(Set dst (LoadD mem));\n-  ins_cost(145);\n-  format %{ \"MOVLPD $dst,$mem\" %}\n-  ins_encode %{\n-    __ movdbl ($dst$$XMMRegister, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Load to XMM register (single-precision floating point)\n-\/\/ MOVSS instruction\n-instruct loadF(regF dst, memory mem) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (LoadF mem));\n-  ins_cost(145);\n-  format %{ \"MOVSS  $dst,$mem\" %}\n-  ins_encode %{\n-    __ movflt ($dst$$XMMRegister, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Load Float\n-instruct loadFPR(regFPR dst, memory mem) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (LoadF mem));\n-\n-  ins_cost(150);\n-  format %{ \"FLD_S  ST,$mem\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xD9);               \/* D9 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Load Effective Address\n-instruct leaP8(eRegP dst, indOffset8 mem) %{\n-  match(Set dst mem);\n-\n-  ins_cost(110);\n-  format %{ \"LEA    $dst,$mem\" %}\n-  opcode(0x8D);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_reg_fat );\n-%}\n-\n-instruct leaP32(eRegP dst, indOffset32 mem) %{\n-  match(Set dst mem);\n-\n-  ins_cost(110);\n-  format %{ \"LEA    $dst,$mem\" %}\n-  opcode(0x8D);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_reg_fat );\n-%}\n-\n-instruct leaPIdxOff(eRegP dst, indIndexOffset mem) %{\n-  match(Set dst mem);\n-\n-  ins_cost(110);\n-  format %{ \"LEA    $dst,$mem\" %}\n-  opcode(0x8D);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_reg_fat );\n-%}\n-\n-instruct leaPIdxScale(eRegP dst, indIndexScale mem) %{\n-  match(Set dst mem);\n-\n-  ins_cost(110);\n-  format %{ \"LEA    $dst,$mem\" %}\n-  opcode(0x8D);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_reg_fat );\n-%}\n-\n-instruct leaPIdxScaleOff(eRegP dst, indIndexScaleOffset mem) %{\n-  match(Set dst mem);\n-\n-  ins_cost(110);\n-  format %{ \"LEA    $dst,$mem\" %}\n-  opcode(0x8D);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,mem), ClearInstMark);\n-  ins_pipe( ialu_reg_reg_fat );\n-%}\n-\n-\/\/ Load Constant\n-instruct loadConI(rRegI dst, immI src) %{\n-  match(Set dst src);\n-\n-  format %{ \"MOV    $dst,$src\" %}\n-  ins_encode( SetInstMark, LdImmI(dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_fat );\n-%}\n-\n-\/\/ Load Constant zero\n-instruct loadConI0(rRegI dst, immI_0 src, eFlagsReg cr) %{\n-  match(Set dst src);\n-  effect(KILL cr);\n-\n-  ins_cost(50);\n-  format %{ \"XOR    $dst,$dst\" %}\n-  opcode(0x33);  \/* + rd *\/\n-  ins_encode( OpcP, RegReg( dst, dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct loadConP(eRegP dst, immP src) %{\n-  match(Set dst src);\n-\n-  format %{ \"MOV    $dst,$src\" %}\n-  opcode(0xB8);  \/* + rd *\/\n-  ins_encode( SetInstMark, LdImmP(dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_fat );\n-%}\n-\n-instruct loadConL(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst src);\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"MOV    $dst.lo,$src.lo\\n\\t\"\n-            \"MOV    $dst.hi,$src.hi\" %}\n-  opcode(0xB8);\n-  ins_encode( LdImmL_Lo(dst, src), LdImmL_Hi(dst, src) );\n-  ins_pipe( ialu_reg_long_fat );\n-%}\n-\n-instruct loadConL0(eRegL dst, immL0 src, eFlagsReg cr) %{\n-  match(Set dst src);\n-  effect(KILL cr);\n-  ins_cost(150);\n-  format %{ \"XOR    $dst.lo,$dst.lo\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-  opcode(0x33,0x33);\n-  ins_encode( RegReg_Lo(dst,dst), RegReg_Hi(dst, dst) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immFPR().\n-instruct loadConFPR(regFPR dst, immFPR con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-  format %{ \"FLD_S  ST,[$constantaddress]\\t# load from constant table: float=$con\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fld_s($constantaddress($con));\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immFPR0().\n-instruct loadConFPR0(regFPR dst, immFPR0 con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-  format %{ \"FLDZ   ST\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fldz();\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immFPR1().\n-instruct loadConFPR1(regFPR dst, immFPR1 con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-  format %{ \"FLD1   ST\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fld1();\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immF().\n-instruct loadConF(regF dst, immF con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-  format %{ \"MOVSS  $dst,[$constantaddress]\\t# load from constant table: float=$con\" %}\n-  ins_encode %{\n-    __ movflt($dst$$XMMRegister, $constantaddress($con));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immF0().\n-instruct loadConF0(regF dst, immF0 src) %{\n-  match(Set dst src);\n-  ins_cost(100);\n-  format %{ \"XORPS  $dst,$dst\\t# float 0.0\" %}\n-  ins_encode %{\n-    __ xorps($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immDPR().\n-instruct loadConDPR(regDPR dst, immDPR con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-\n-  format %{ \"FLD_D  ST,[$constantaddress]\\t# load from constant table: double=$con\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fld_d($constantaddress($con));\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immDPR0().\n-instruct loadConDPR0(regDPR dst, immDPR0 con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-\n-  format %{ \"FLDZ   ST\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fldz();\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immDPR1().\n-instruct loadConDPR1(regDPR dst, immDPR1 con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-\n-  format %{ \"FLD1   ST\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  ins_encode %{\n-    __ fld1();\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_con);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immD().\n-instruct loadConD(regD dst, immD con) %{\n-  match(Set dst con);\n-  ins_cost(125);\n-  format %{ \"MOVSD  $dst,[$constantaddress]\\t# load from constant table: double=$con\" %}\n-  ins_encode %{\n-    __ movdbl($dst$$XMMRegister, $constantaddress($con));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ The instruction usage is guarded by predicate in operand immD0().\n-instruct loadConD0(regD dst, immD0 src) %{\n-  match(Set dst src);\n-  ins_cost(100);\n-  format %{ \"XORPD  $dst,$dst\\t# double 0.0\" %}\n-  ins_encode %{\n-    __ xorpd ($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Load Stack Slot\n-instruct loadSSI(rRegI dst, stackSlotI src) %{\n-  match(Set dst src);\n-  ins_cost(125);\n-\n-  format %{ \"MOV    $dst,$src\" %}\n-  opcode(0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,src), ClearInstMark);\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-instruct loadSSL(eRegL dst, stackSlotL src) %{\n-  match(Set dst src);\n-\n-  ins_cost(200);\n-  format %{ \"MOV    $dst,$src.lo\\n\\t\"\n-            \"MOV    $dst+4,$src.hi\" %}\n-  opcode(0x8B, 0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, src ), OpcS, RegMem_Hi( dst, src ), ClearInstMark );\n-  ins_pipe( ialu_mem_long_reg );\n-%}\n-\n-\/\/ Load Stack Slot\n-instruct loadSSP(eRegP dst, stackSlotP src) %{\n-  match(Set dst src);\n-  ins_cost(125);\n-\n-  format %{ \"MOV    $dst,$src\" %}\n-  opcode(0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,src), ClearInstMark);\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ Load Stack Slot\n-instruct loadSSF(regFPR dst, stackSlotF src) %{\n-  match(Set dst src);\n-  ins_cost(125);\n-\n-  format %{ \"FLD_S  $src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xD9);               \/* D9 \/0, FLD m32real *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem_no_oop(0x00,src),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Load Stack Slot\n-instruct loadSSD(regDPR dst, stackSlotD src) %{\n-  match(Set dst src);\n-  ins_cost(125);\n-\n-  format %{ \"FLD_D  $src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDD);               \/* DD \/0, FLD m64real *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem_no_oop(0x00,src),\n-              Pop_Reg_DPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Prefetch instructions for allocation.\n-\/\/ Must be safe to execute with invalid address (cannot fault).\n-\n-instruct prefetchAlloc0( memory mem ) %{\n-  predicate(UseSSE==0 && AllocatePrefetchInstr!=3);\n-  match(PrefetchAllocation mem);\n-  ins_cost(0);\n-  size(0);\n-  format %{ \"Prefetch allocation (non-SSE is empty encoding)\" %}\n-  ins_encode();\n-  ins_pipe(empty);\n-%}\n-\n-instruct prefetchAlloc( memory mem ) %{\n-  predicate(AllocatePrefetchInstr==3);\n-  match( PrefetchAllocation mem );\n-  ins_cost(100);\n-\n-  format %{ \"PREFETCHW $mem\\t! Prefetch allocation into L1 cache and mark modified\" %}\n-  ins_encode %{\n-    __ prefetchw($mem$$Address);\n-  %}\n-  ins_pipe(ialu_mem);\n-%}\n-\n-instruct prefetchAllocNTA( memory mem ) %{\n-  predicate(UseSSE>=1 && AllocatePrefetchInstr==0);\n-  match(PrefetchAllocation mem);\n-  ins_cost(100);\n-\n-  format %{ \"PREFETCHNTA $mem\\t! Prefetch allocation into non-temporal cache for write\" %}\n-  ins_encode %{\n-    __ prefetchnta($mem$$Address);\n-  %}\n-  ins_pipe(ialu_mem);\n-%}\n-\n-instruct prefetchAllocT0( memory mem ) %{\n-  predicate(UseSSE>=1 && AllocatePrefetchInstr==1);\n-  match(PrefetchAllocation mem);\n-  ins_cost(100);\n-\n-  format %{ \"PREFETCHT0 $mem\\t! Prefetch allocation into L1 and L2 caches for write\" %}\n-  ins_encode %{\n-    __ prefetcht0($mem$$Address);\n-  %}\n-  ins_pipe(ialu_mem);\n-%}\n-\n-instruct prefetchAllocT2( memory mem ) %{\n-  predicate(UseSSE>=1 && AllocatePrefetchInstr==2);\n-  match(PrefetchAllocation mem);\n-  ins_cost(100);\n-\n-  format %{ \"PREFETCHT2 $mem\\t! Prefetch allocation into L2 cache for write\" %}\n-  ins_encode %{\n-    __ prefetcht2($mem$$Address);\n-  %}\n-  ins_pipe(ialu_mem);\n-%}\n-\n-\/\/----------Store Instructions-------------------------------------------------\n-\n-\/\/ Store Byte\n-instruct storeB(memory mem, xRegI src) %{\n-  match(Set mem (StoreB mem src));\n-\n-  ins_cost(125);\n-  format %{ \"MOV8   $mem,$src\" %}\n-  opcode(0x88);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Char\/Short\n-instruct storeC(memory mem, rRegI src) %{\n-  match(Set mem (StoreC mem src));\n-\n-  ins_cost(125);\n-  format %{ \"MOV16  $mem,$src\" %}\n-  opcode(0x89, 0x66);\n-  ins_encode( SetInstMark, OpcS, OpcP, RegMem( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Integer\n-instruct storeI(memory mem, rRegI src) %{\n-  match(Set mem (StoreI mem src));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $mem,$src\" %}\n-  opcode(0x89);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Long\n-instruct storeL(long_memory mem, eRegL src) %{\n-  predicate(!((StoreLNode*)n)->require_atomic_access());\n-  match(Set mem (StoreL mem src));\n-\n-  ins_cost(200);\n-  format %{ \"MOV    $mem,$src.lo\\n\\t\"\n-            \"MOV    $mem+4,$src.hi\" %}\n-  opcode(0x89, 0x89);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, mem ), OpcS, RegMem_Hi( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_mem_long_reg );\n-%}\n-\n-\/\/ Store Long to Integer\n-instruct storeL2I(memory mem, eRegL src) %{\n-  match(Set mem (StoreI mem (ConvL2I src)));\n-\n-  format %{ \"MOV    $mem,$src.lo\\t# long -> int\" %}\n-  ins_encode %{\n-    __ movl($mem$$Address, $src$$Register);\n-  %}\n-  ins_pipe(ialu_mem_reg);\n-%}\n-\n-\/\/ Volatile Store Long.  Must be atomic, so move it into\n-\/\/ the FP TOS and then do a 64-bit FIST.  Has to probe the\n-\/\/ target address before the store (for null-ptr checks)\n-\/\/ so the memory operand is used twice in the encoding.\n-instruct storeL_volatile(memory mem, stackSlotL src, eFlagsReg cr ) %{\n-  predicate(UseSSE<=1 && ((StoreLNode*)n)->require_atomic_access());\n-  match(Set mem (StoreL mem src));\n-  effect( KILL cr );\n-  ins_cost(400);\n-  format %{ \"CMP    $mem,EAX\\t# Probe address for implicit null check\\n\\t\"\n-            \"FILD   $src\\n\\t\"\n-            \"FISTp  $mem\\t # 64-bit atomic volatile long store\" %}\n-  opcode(0x3B);\n-  ins_encode( SetInstMark, OpcP, RegMem( EAX, mem ), enc_storeL_volatile(mem,src), ClearInstMark);\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct storeLX_volatile(memory mem, stackSlotL src, regD tmp, eFlagsReg cr) %{\n-  predicate(UseSSE>=2 && ((StoreLNode*)n)->require_atomic_access());\n-  match(Set mem (StoreL mem src));\n-  effect( TEMP tmp, KILL cr );\n-  ins_cost(380);\n-  format %{ \"CMP    $mem,EAX\\t# Probe address for implicit null check\\n\\t\"\n-            \"MOVSD  $tmp,$src\\n\\t\"\n-            \"MOVSD  $mem,$tmp\\t # 64-bit atomic volatile long store\" %}\n-  ins_encode %{\n-    __ cmpl(rax, $mem$$Address);\n-    __ movdbl($tmp$$XMMRegister, Address(rsp, $src$$disp));\n-    __ movdbl($mem$$Address, $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct storeLX_reg_volatile(memory mem, eRegL src, regD tmp2, regD tmp, eFlagsReg cr) %{\n-  predicate(UseSSE>=2 && ((StoreLNode*)n)->require_atomic_access());\n-  match(Set mem (StoreL mem src));\n-  effect( TEMP tmp2 , TEMP tmp, KILL cr );\n-  ins_cost(360);\n-  format %{ \"CMP    $mem,EAX\\t# Probe address for implicit null check\\n\\t\"\n-            \"MOVD   $tmp,$src.lo\\n\\t\"\n-            \"MOVD   $tmp2,$src.hi\\n\\t\"\n-            \"PUNPCKLDQ $tmp,$tmp2\\n\\t\"\n-            \"MOVSD  $mem,$tmp\\t # 64-bit atomic volatile long store\" %}\n-  ins_encode %{\n-    __ cmpl(rax, $mem$$Address);\n-    __ movdl($tmp$$XMMRegister, $src$$Register);\n-    __ movdl($tmp2$$XMMRegister, HIGH_FROM_LOW($src$$Register));\n-    __ punpckldq($tmp$$XMMRegister, $tmp2$$XMMRegister);\n-    __ movdbl($mem$$Address, $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Store Pointer; for storing unknown oops and raw pointers\n-instruct storeP(memory mem, anyRegP src) %{\n-  match(Set mem (StoreP mem src));\n-\n-  ins_cost(125);\n-  format %{ \"MOV    $mem,$src\" %}\n-  opcode(0x89);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Integer Immediate\n-instruct storeImmI(memory mem, immI src) %{\n-  match(Set mem (StoreI mem src));\n-\n-  ins_cost(150);\n-  format %{ \"MOV    $mem,$src\" %}\n-  opcode(0xC7);               \/* C7 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem), Con32(src), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store Short\/Char Immediate\n-instruct storeImmI16(memory mem, immI16 src) %{\n-  predicate(UseStoreImmI16);\n-  match(Set mem (StoreC mem src));\n-\n-  ins_cost(150);\n-  format %{ \"MOV16  $mem,$src\" %}\n-  opcode(0xC7);     \/* C7 \/0 Same as 32 store immediate with prefix *\/\n-  ins_encode( SetInstMark, SizePrefix, OpcP, RMopc_Mem(0x00,mem), Con16(src), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store Pointer Immediate; null pointers or constant oops that do not\n-\/\/ need card-mark barriers.\n-instruct storeImmP(memory mem, immP src) %{\n-  match(Set mem (StoreP mem src));\n-\n-  ins_cost(150);\n-  format %{ \"MOV    $mem,$src\" %}\n-  opcode(0xC7);               \/* C7 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem), Con32( src ), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store Byte Immediate\n-instruct storeImmB(memory mem, immI8 src) %{\n-  match(Set mem (StoreB mem src));\n-\n-  ins_cost(150);\n-  format %{ \"MOV8   $mem,$src\" %}\n-  opcode(0xC6);               \/* C6 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem), Con8or32(src), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store Double\n-instruct storeDPR( memory mem, regDPR1 src) %{\n-  predicate(UseSSE<=1);\n-  match(Set mem (StoreD mem src));\n-\n-  ins_cost(100);\n-  format %{ \"FST_D  $mem,$src\" %}\n-  opcode(0xDD);       \/* DD \/2 *\/\n-  ins_encode( enc_FPR_store(mem,src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Store double does rounding on x86\n-instruct storeDPR_rounded( memory mem, regDPR1 src) %{\n-  predicate(UseSSE<=1);\n-  match(Set mem (StoreD mem (RoundDouble src)));\n-\n-  ins_cost(100);\n-  format %{ \"FST_D  $mem,$src\\t# round\" %}\n-  opcode(0xDD);       \/* DD \/2 *\/\n-  ins_encode( enc_FPR_store(mem,src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Store XMM register to memory (double-precision floating points)\n-\/\/ MOVSD instruction\n-instruct storeD(memory mem, regD src) %{\n-  predicate(UseSSE>=2);\n-  match(Set mem (StoreD mem src));\n-  ins_cost(95);\n-  format %{ \"MOVSD  $mem,$src\" %}\n-  ins_encode %{\n-    __ movdbl($mem$$Address, $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Store XMM register to memory (single-precision floating point)\n-\/\/ MOVSS instruction\n-instruct storeF(memory mem, regF src) %{\n-  predicate(UseSSE>=1);\n-  match(Set mem (StoreF mem src));\n-  ins_cost(95);\n-  format %{ \"MOVSS  $mem,$src\" %}\n-  ins_encode %{\n-    __ movflt($mem$$Address, $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ Store Float\n-instruct storeFPR( memory mem, regFPR1 src) %{\n-  predicate(UseSSE==0);\n-  match(Set mem (StoreF mem src));\n-\n-  ins_cost(100);\n-  format %{ \"FST_S  $mem,$src\" %}\n-  opcode(0xD9);       \/* D9 \/2 *\/\n-  ins_encode( enc_FPR_store(mem,src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Store Float does rounding on x86\n-instruct storeFPR_rounded( memory mem, regFPR1 src) %{\n-  predicate(UseSSE==0);\n-  match(Set mem (StoreF mem (RoundFloat src)));\n-\n-  ins_cost(100);\n-  format %{ \"FST_S  $mem,$src\\t# round\" %}\n-  opcode(0xD9);       \/* D9 \/2 *\/\n-  ins_encode( enc_FPR_store(mem,src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Store Float does rounding on x86\n-instruct storeFPR_Drounded( memory mem, regDPR1 src) %{\n-  predicate(UseSSE<=1);\n-  match(Set mem (StoreF mem (ConvD2F src)));\n-\n-  ins_cost(100);\n-  format %{ \"FST_S  $mem,$src\\t# D-round\" %}\n-  opcode(0xD9);       \/* D9 \/2 *\/\n-  ins_encode( enc_FPR_store(mem,src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Store immediate Float value (it is faster than store from FPU register)\n-\/\/ The instruction usage is guarded by predicate in operand immFPR().\n-instruct storeFPR_imm( memory mem, immFPR src) %{\n-  match(Set mem (StoreF mem src));\n-\n-  ins_cost(50);\n-  format %{ \"MOV    $mem,$src\\t# store float\" %}\n-  opcode(0xC7);               \/* C7 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),  Con32FPR_as_bits(src), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store immediate Float value (it is faster than store from XMM register)\n-\/\/ The instruction usage is guarded by predicate in operand immF().\n-instruct storeF_imm( memory mem, immF src) %{\n-  match(Set mem (StoreF mem src));\n-\n-  ins_cost(50);\n-  format %{ \"MOV    $mem,$src\\t# store float\" %}\n-  opcode(0xC7);               \/* C7 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),  Con32F_as_bits(src), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Store Integer to stack slot\n-instruct storeSSI(stackSlotI dst, rRegI src) %{\n-  match(Set dst src);\n-\n-  ins_cost(100);\n-  format %{ \"MOV    $dst,$src\" %}\n-  opcode(0x89);\n-  ins_encode( OpcPRegSS( dst, src ) );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Integer to stack slot\n-instruct storeSSP(stackSlotP dst, eRegP src) %{\n-  match(Set dst src);\n-\n-  ins_cost(100);\n-  format %{ \"MOV    $dst,$src\" %}\n-  opcode(0x89);\n-  ins_encode( OpcPRegSS( dst, src ) );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Store Long to stack slot\n-instruct storeSSL(stackSlotL dst, eRegL src) %{\n-  match(Set dst src);\n-\n-  ins_cost(200);\n-  format %{ \"MOV    $dst,$src.lo\\n\\t\"\n-            \"MOV    $dst+4,$src.hi\" %}\n-  opcode(0x89, 0x89);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), OpcS, RegMem_Hi( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_long_reg );\n-%}\n-\n-\/\/----------MemBar Instructions-----------------------------------------------\n-\/\/ Memory barrier flavors\n-\n-instruct membar_acquire() %{\n-  match(MemBarAcquire);\n-  match(LoadFence);\n-  ins_cost(400);\n-\n-  size(0);\n-  format %{ \"MEMBAR-acquire ! (empty encoding)\" %}\n-  ins_encode();\n-  ins_pipe(empty);\n-%}\n-\n-instruct membar_acquire_lock() %{\n-  match(MemBarAcquireLock);\n-  ins_cost(0);\n-\n-  size(0);\n-  format %{ \"MEMBAR-acquire (prior CMPXCHG in FastLock so empty encoding)\" %}\n-  ins_encode( );\n-  ins_pipe(empty);\n-%}\n-\n-instruct membar_release() %{\n-  match(MemBarRelease);\n-  match(StoreFence);\n-  ins_cost(400);\n-\n-  size(0);\n-  format %{ \"MEMBAR-release ! (empty encoding)\" %}\n-  ins_encode( );\n-  ins_pipe(empty);\n-%}\n-\n-instruct membar_release_lock() %{\n-  match(MemBarReleaseLock);\n-  ins_cost(0);\n-\n-  size(0);\n-  format %{ \"MEMBAR-release (a FastUnlock follows so empty encoding)\" %}\n-  ins_encode( );\n-  ins_pipe(empty);\n-%}\n-\n-instruct membar_volatile(eFlagsReg cr) %{\n-  match(MemBarVolatile);\n-  effect(KILL cr);\n-  ins_cost(400);\n-\n-  format %{\n-    $$template\n-    $$emit$$\"LOCK ADDL [ESP + #0], 0\\t! membar_volatile\"\n-  %}\n-  ins_encode %{\n-    __ membar(Assembler::StoreLoad);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct unnecessary_membar_volatile() %{\n-  match(MemBarVolatile);\n-  predicate(Matcher::post_store_load_barrier(n));\n-  ins_cost(0);\n-\n-  size(0);\n-  format %{ \"MEMBAR-volatile (unnecessary so empty encoding)\" %}\n-  ins_encode( );\n-  ins_pipe(empty);\n-%}\n-\n-instruct membar_storestore() %{\n-  match(MemBarStoreStore);\n-  match(StoreStoreFence);\n-  ins_cost(0);\n-\n-  size(0);\n-  format %{ \"MEMBAR-storestore (empty encoding)\" %}\n-  ins_encode( );\n-  ins_pipe(empty);\n-%}\n-\n-\/\/----------Move Instructions--------------------------------------------------\n-instruct castX2P(eAXRegP dst, eAXRegI src) %{\n-  match(Set dst (CastX2P src));\n-  format %{ \"# X2P  $dst, $src\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe(empty);\n-%}\n-\n-instruct castP2X(rRegI dst, eRegP src ) %{\n-  match(Set dst (CastP2X src));\n-  ins_cost(50);\n-  format %{ \"MOV    $dst, $src\\t# CastP2X\" %}\n-  ins_encode( enc_Copy( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\/\/----------Conditional Move---------------------------------------------------\n-\/\/ Conditional move\n-instruct jmovI_reg(cmpOp cop, eFlagsReg cr, rRegI dst, rRegI src) %{\n-  predicate(!VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"J$cop,us skip\\t# signed cmove\\n\\t\"\n-            \"MOV    $dst,$src\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label Lskip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), Lskip);\n-    __ movl($dst$$Register, $src$$Register);\n-    __ bind(Lskip);\n-  %}\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct jmovI_regU(cmpOpU cop, eFlagsRegU cr, rRegI dst, rRegI src) %{\n-  predicate(!VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"J$cop,us skip\\t# unsigned cmove\\n\\t\"\n-            \"MOV    $dst,$src\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label Lskip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), Lskip);\n-    __ movl($dst$$Register, $src$$Register);\n-    __ bind(Lskip);\n-  %}\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovI_reg(rRegI dst, rRegI src, eFlagsReg cr, cmpOp cop ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovI_regU( cmpOpU cop, eFlagsRegU cr, rRegI dst, rRegI src ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovI_regUCF( cmpOpUCF cop, eFlagsRegUCF cr, rRegI dst, rRegI src ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovI_regU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-\/\/ Conditional move\n-instruct cmovI_mem(cmpOp cop, eFlagsReg cr, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  format %{ \"CMOV$cop $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cop), RegMem( dst, src ), ClearInstMark );\n-  ins_pipe( pipe_cmov_mem );\n-%}\n-\n-\/\/ Conditional move\n-instruct cmovI_memU(cmpOpU cop, eFlagsRegU cr, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  format %{ \"CMOV$cop $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cop), RegMem( dst, src ), ClearInstMark );\n-  ins_pipe( pipe_cmov_mem );\n-%}\n-\n-instruct cmovI_memUCF(cmpOpUCF cop, eFlagsRegUCF cr, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveI (Binary cop cr) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  expand %{\n-    cmovI_memU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-\/\/ Conditional move\n-instruct cmovP_reg(eRegP dst, eRegP src, eFlagsReg cr, cmpOp cop ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-\/\/ Conditional move (non-P6 version)\n-\/\/ Note:  a CMoveP is generated for  stubs and native wrappers\n-\/\/        regardless of whether we are on a P6, so we\n-\/\/        emulate a cmov here\n-instruct cmovP_reg_nonP6(eRegP dst, eRegP src, eFlagsReg cr, cmpOp cop ) %{\n-  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));\n-  ins_cost(300);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-          \"MOV    $dst,$src\\t# pointer\\n\"\n-      \"skip:\" %}\n-  opcode(0x8b);\n-  ins_encode( enc_cmov_branch(cop, 0x2), OpcP, RegReg(dst, src));\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-\/\/ Conditional move\n-instruct cmovP_regU(cmpOpU cop, eFlagsRegU cr, eRegP dst, eRegP src ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovP_regUCF(cmpOpUCF cop, eFlagsRegUCF cr, eRegP dst, eRegP src ) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveP (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovP_regU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-\/\/ DISABLED: Requires the ADLC to emit a bottom_type call that\n-\/\/ correctly meets the two pointer arguments; one is an incoming\n-\/\/ register but the other is a memory operand.  ALSO appears to\n-\/\/ be buggy with implicit null checks.\n-\/\/\n-\/\/\/\/ Conditional move\n-\/\/instruct cmovP_mem(cmpOp cop, eFlagsReg cr, eRegP dst, memory src) %{\n-\/\/  predicate(VM_Version::supports_cmov() );\n-\/\/  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));\n-\/\/  ins_cost(250);\n-\/\/  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-\/\/  opcode(0x0F,0x40);\n-\/\/  ins_encode( enc_cmov(cop), RegMem( dst, src ) );\n-\/\/  ins_pipe( pipe_cmov_mem );\n-\/\/%}\n-\/\/\n-\/\/\/\/ Conditional move\n-\/\/instruct cmovP_memU(cmpOpU cop, eFlagsRegU cr, eRegP dst, memory src) %{\n-\/\/  predicate(VM_Version::supports_cmov() );\n-\/\/  match(Set dst (CMoveP (Binary cop cr) (Binary dst (LoadP src))));\n-\/\/  ins_cost(250);\n-\/\/  format %{ \"CMOV$cop $dst,$src\\t# ptr\" %}\n-\/\/  opcode(0x0F,0x40);\n-\/\/  ins_encode( enc_cmov(cop), RegMem( dst, src ) );\n-\/\/  ins_pipe( pipe_cmov_mem );\n-\/\/%}\n-\n-\/\/ Conditional move\n-instruct fcmovDPR_regU(cmpOp_fcmov cop, eFlagsRegU cr, regDPR1 dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"FCMOV$cop $dst,$src\\t# double\" %}\n-  opcode(0xDA);\n-  ins_encode( enc_cmov_dpr(cop,src) );\n-  ins_pipe( pipe_cmovDPR_reg );\n-%}\n-\n-\/\/ Conditional move\n-instruct fcmovFPR_regU(cmpOp_fcmov cop, eFlagsRegU cr, regFPR1 dst, regFPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"FCMOV$cop $dst,$src\\t# float\" %}\n-  opcode(0xDA);\n-  ins_encode( enc_cmov_dpr(cop,src) );\n-  ins_pipe( pipe_cmovDPR_reg );\n-%}\n-\n-\/\/ Float CMOV on Intel doesn't handle *signed* compares, only unsigned.\n-instruct fcmovDPR_regS(cmpOp cop, eFlagsReg cr, regDPR dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-            \"MOV    $dst,$src\\t# double\\n\"\n-      \"skip:\" %}\n-  opcode (0xdd, 0x3);     \/* DD D8+i or DD \/3 *\/\n-  ins_encode( enc_cmov_branch( cop, 0x4 ), Push_Reg_DPR(src), OpcP, RegOpc(dst) );\n-  ins_pipe( pipe_cmovDPR_reg );\n-%}\n-\n-\/\/ Float CMOV on Intel doesn't handle *signed* compares, only unsigned.\n-instruct fcmovFPR_regS(cmpOp cop, eFlagsReg cr, regFPR dst, regFPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop    skip\\n\\t\"\n-            \"MOV    $dst,$src\\t# float\\n\"\n-      \"skip:\" %}\n-  opcode (0xdd, 0x3);     \/* DD D8+i or DD \/3 *\/\n-  ins_encode( enc_cmov_branch( cop, 0x4 ), Push_Reg_FPR(src), OpcP, RegOpc(dst) );\n-  ins_pipe( pipe_cmovDPR_reg );\n-%}\n-\n-\/\/ No CMOVE with SSE\/SSE2\n-instruct fcmovF_regS(cmpOp cop, eFlagsReg cr, regF dst, regF src) %{\n-  predicate (UseSSE>=1);\n-  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-            \"MOVSS  $dst,$src\\t# float\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label skip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), skip);\n-    __ movflt($dst$$XMMRegister, $src$$XMMRegister);\n-    __ bind(skip);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ No CMOVE with SSE\/SSE2\n-instruct fcmovD_regS(cmpOp cop, eFlagsReg cr, regD dst, regD src) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-            \"MOVSD  $dst,$src\\t# float\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label skip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), skip);\n-    __ movdbl($dst$$XMMRegister, $src$$XMMRegister);\n-    __ bind(skip);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ unsigned version\n-instruct fcmovF_regU(cmpOpU cop, eFlagsRegU cr, regF dst, regF src) %{\n-  predicate (UseSSE>=1);\n-  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-            \"MOVSS  $dst,$src\\t# float\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label skip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), skip);\n-    __ movflt($dst$$XMMRegister, $src$$XMMRegister);\n-    __ bind(skip);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct fcmovF_regUCF(cmpOpUCF cop, eFlagsRegUCF cr, regF dst, regF src) %{\n-  predicate (UseSSE>=1);\n-  match(Set dst (CMoveF (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovF_regU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-\/\/ unsigned version\n-instruct fcmovD_regU(cmpOpU cop, eFlagsRegU cr, regD dst, regD src) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"Jn$cop   skip\\n\\t\"\n-            \"MOVSD  $dst,$src\\t# float\\n\"\n-      \"skip:\" %}\n-  ins_encode %{\n-    Label skip;\n-    \/\/ Invert sense of branch from sense of CMOV\n-    __ jccb((Assembler::Condition)($cop$$cmpcode^1), skip);\n-    __ movdbl($dst$$XMMRegister, $src$$XMMRegister);\n-    __ bind(skip);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct fcmovD_regUCF(cmpOpUCF cop, eFlagsRegUCF cr, regD dst, regD src) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst (CMoveD (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovD_regU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-instruct cmovL_reg(cmpOp cop, eFlagsReg cr, eRegL dst, eRegL src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cop $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg_Lo2( dst, src ), enc_cmov(cop), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovL_regU(cmpOpU cop, eFlagsRegU cr, eRegL dst, eRegL src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cop $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cop $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cop), RegReg_Lo2( dst, src ), enc_cmov(cop), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovL_regUCF(cmpOpUCF cop, eFlagsRegUCF cr, eRegL dst, eRegL src) %{\n-  predicate(VM_Version::supports_cmov() );\n-  match(Set dst (CMoveL (Binary cop cr) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovL_regU(cop, cr, dst, src);\n-  %}\n-%}\n-\n-\/\/----------Arithmetic Instructions--------------------------------------------\n-\/\/----------Addition Instructions----------------------------------------------\n-\n-\/\/ Integer Addition Instructions\n-instruct addI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (AddI dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x03);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct addI_eReg_imm(rRegI dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (AddI dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x81, 0x00); \/* \/0 id *\/\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct incI_eReg(rRegI dst, immI_1 src, eFlagsReg cr) %{\n-  predicate(UseIncDec);\n-  match(Set dst (AddI dst src));\n-  effect(KILL cr);\n-\n-  size(1);\n-  format %{ \"INC    $dst\" %}\n-  opcode(0x40); \/*  *\/\n-  ins_encode( Opc_plus( primary, dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct leaI_eReg_immI(rRegI dst, rRegI src0, immI src1) %{\n-  match(Set dst (AddI src0 src1));\n-  ins_cost(110);\n-\n-  format %{ \"LEA    $dst,[$src0 + $src1]\" %}\n-  opcode(0x8D); \/* 0x8D \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegLea( dst, src0, src1 ), ClearInstMark );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct leaP_eReg_immI(eRegP dst, eRegP src0, immI src1) %{\n-  match(Set dst (AddP src0 src1));\n-  ins_cost(110);\n-\n-  format %{ \"LEA    $dst,[$src0 + $src1]\\t# ptr\" %}\n-  opcode(0x8D); \/* 0x8D \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegLea( dst, src0, src1 ), ClearInstMark );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct decI_eReg(rRegI dst, immI_M1 src, eFlagsReg cr) %{\n-  predicate(UseIncDec);\n-  match(Set dst (AddI dst src));\n-  effect(KILL cr);\n-\n-  size(1);\n-  format %{ \"DEC    $dst\" %}\n-  opcode(0x48); \/*  *\/\n-  ins_encode( Opc_plus( primary, dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct addP_eReg(eRegP dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (AddP dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x03);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct addP_eReg_imm(eRegP dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (AddP dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x81,0x00); \/* Opcode 81 \/0 id *\/\n-  \/\/ ins_encode( RegImm( dst, src) );\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct addI_eReg_mem(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (AddI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x03);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-instruct addI_mem_eReg(memory dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AddI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x01);  \/* Opcode 01 \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Add Memory with Immediate\n-instruct addI_mem_imm(memory dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AddI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"ADD    $dst,$src\" %}\n-  opcode(0x81);               \/* Opcode 81 \/0 id *\/\n-  ins_encode( SetInstMark, OpcSE( src ), RMopc_Mem(0x00,dst), Con8or32(src), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-instruct incI_mem(memory dst, immI_1 src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AddI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"INC    $dst\" %}\n-  opcode(0xFF);               \/* Opcode FF \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,dst), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-instruct decI_mem(memory dst, immI_M1 src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AddI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"DEC    $dst\" %}\n-  opcode(0xFF);               \/* Opcode FF \/1 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x01,dst), ClearInstMark);\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\n-instruct checkCastPP( eRegP dst ) %{\n-  match(Set dst (CheckCastPP dst));\n-\n-  size(0);\n-  format %{ \"#checkcastPP of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_pipe( empty );\n-%}\n-\n-instruct castPP( eRegP dst ) %{\n-  match(Set dst (CastPP dst));\n-  format %{ \"#castPP of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_pipe( empty );\n-%}\n-\n-instruct castII( rRegI dst ) %{\n-  match(Set dst (CastII dst));\n-  format %{ \"#castII of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-instruct castLL( eRegL dst ) %{\n-  match(Set dst (CastLL dst));\n-  format %{ \"#castLL of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-instruct castFF( regF dst ) %{\n-  predicate(UseSSE >= 1);\n-  match(Set dst (CastFF dst));\n-  format %{ \"#castFF of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-instruct castDD( regD dst ) %{\n-  predicate(UseSSE >= 2);\n-  match(Set dst (CastDD dst));\n-  format %{ \"#castDD of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-instruct castFF_PR( regFPR dst ) %{\n-  predicate(UseSSE < 1);\n-  match(Set dst (CastFF dst));\n-  format %{ \"#castFF of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-instruct castDD_PR( regDPR dst ) %{\n-  predicate(UseSSE < 2);\n-  match(Set dst (CastDD dst));\n-  format %{ \"#castDD of $dst\" %}\n-  ins_encode( \/*empty encoding*\/ );\n-  ins_cost(0);\n-  ins_pipe( empty );\n-%}\n-\n-\/\/ No flag versions for CompareAndSwap{P,I,L} because matcher can't match them\n-\n-instruct compareAndSwapL( rRegI res, eSIRegP mem_ptr, eADXRegL oldval, eBCXRegL newval, eFlagsReg cr ) %{\n-  match(Set res (CompareAndSwapL mem_ptr (Binary oldval newval)));\n-  match(Set res (WeakCompareAndSwapL mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, KILL oldval);\n-  format %{ \"CMPXCHG8 [$mem_ptr],$newval\\t# If EDX:EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\"\n-            \"MOV    $res,0\\n\\t\"\n-            \"JNE,s  fail\\n\\t\"\n-            \"MOV    $res,1\\n\"\n-          \"fail:\" %}\n-  ins_encode( enc_cmpxchg8(mem_ptr),\n-              enc_flags_ne_to_boolean(res) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndSwapP( rRegI res,  pRegP mem_ptr, eAXRegP oldval, eCXRegP newval, eFlagsReg cr) %{\n-  match(Set res (CompareAndSwapP mem_ptr (Binary oldval newval)));\n-  match(Set res (WeakCompareAndSwapP mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, KILL oldval);\n-  format %{ \"CMPXCHG [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\"\n-            \"MOV    $res,0\\n\\t\"\n-            \"JNE,s  fail\\n\\t\"\n-            \"MOV    $res,1\\n\"\n-          \"fail:\" %}\n-  ins_encode( enc_cmpxchg(mem_ptr), enc_flags_ne_to_boolean(res) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndSwapB( rRegI res, pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr ) %{\n-  match(Set res (CompareAndSwapB mem_ptr (Binary oldval newval)));\n-  match(Set res (WeakCompareAndSwapB mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, KILL oldval);\n-  format %{ \"CMPXCHGB [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\"\n-            \"MOV    $res,0\\n\\t\"\n-            \"JNE,s  fail\\n\\t\"\n-            \"MOV    $res,1\\n\"\n-          \"fail:\" %}\n-  ins_encode( enc_cmpxchgb(mem_ptr),\n-              enc_flags_ne_to_boolean(res) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndSwapS( rRegI res, pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr ) %{\n-  match(Set res (CompareAndSwapS mem_ptr (Binary oldval newval)));\n-  match(Set res (WeakCompareAndSwapS mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, KILL oldval);\n-  format %{ \"CMPXCHGW [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\"\n-            \"MOV    $res,0\\n\\t\"\n-            \"JNE,s  fail\\n\\t\"\n-            \"MOV    $res,1\\n\"\n-          \"fail:\" %}\n-  ins_encode( enc_cmpxchgw(mem_ptr),\n-              enc_flags_ne_to_boolean(res) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndSwapI( rRegI res, pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr) %{\n-  match(Set res (CompareAndSwapI mem_ptr (Binary oldval newval)));\n-  match(Set res (WeakCompareAndSwapI mem_ptr (Binary oldval newval)));\n-  effect(KILL cr, KILL oldval);\n-  format %{ \"CMPXCHG [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\"\n-            \"MOV    $res,0\\n\\t\"\n-            \"JNE,s  fail\\n\\t\"\n-            \"MOV    $res,1\\n\"\n-          \"fail:\" %}\n-  ins_encode( enc_cmpxchg(mem_ptr), enc_flags_ne_to_boolean(res) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeL( eSIRegP mem_ptr, eADXRegL oldval, eBCXRegL newval, eFlagsReg cr ) %{\n-  match(Set oldval (CompareAndExchangeL mem_ptr (Binary oldval newval)));\n-  effect(KILL cr);\n-  format %{ \"CMPXCHG8 [$mem_ptr],$newval\\t# If EDX:EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\" %}\n-  ins_encode( enc_cmpxchg8(mem_ptr) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeP( pRegP mem_ptr, eAXRegP oldval, eCXRegP newval, eFlagsReg cr) %{\n-  match(Set oldval (CompareAndExchangeP mem_ptr (Binary oldval newval)));\n-  effect(KILL cr);\n-  format %{ \"CMPXCHG [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\" %}\n-  ins_encode( enc_cmpxchg(mem_ptr) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeB( pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr) %{\n-  match(Set oldval (CompareAndExchangeB mem_ptr (Binary oldval newval)));\n-  effect(KILL cr);\n-  format %{ \"CMPXCHGB [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\" %}\n-  ins_encode( enc_cmpxchgb(mem_ptr) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeS( pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr) %{\n-  match(Set oldval (CompareAndExchangeS mem_ptr (Binary oldval newval)));\n-  effect(KILL cr);\n-  format %{ \"CMPXCHGW [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\" %}\n-  ins_encode( enc_cmpxchgw(mem_ptr) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct compareAndExchangeI( pRegP mem_ptr, eAXRegI oldval, eCXRegI newval, eFlagsReg cr) %{\n-  match(Set oldval (CompareAndExchangeI mem_ptr (Binary oldval newval)));\n-  effect(KILL cr);\n-  format %{ \"CMPXCHG [$mem_ptr],$newval\\t# If EAX==[$mem_ptr] Then store $newval into [$mem_ptr]\\n\\t\" %}\n-  ins_encode( enc_cmpxchg(mem_ptr) );\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xaddB_no_res( memory mem, Universe dummy, immI add, eFlagsReg cr) %{\n-  predicate(n->as_LoadStore()->result_not_used());\n-  match(Set dummy (GetAndAddB mem add));\n-  effect(KILL cr);\n-  format %{ \"ADDB  [$mem],$add\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ addb($mem$$Address, $add$$constant);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-\/\/ Important to match to xRegI: only 8-bit regs.\n-instruct xaddB( memory mem, xRegI newval, eFlagsReg cr) %{\n-  match(Set newval (GetAndAddB mem newval));\n-  effect(KILL cr);\n-  format %{ \"XADDB  [$mem],$newval\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ xaddb($mem$$Address, $newval$$Register);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xaddS_no_res( memory mem, Universe dummy, immI add, eFlagsReg cr) %{\n-  predicate(n->as_LoadStore()->result_not_used());\n-  match(Set dummy (GetAndAddS mem add));\n-  effect(KILL cr);\n-  format %{ \"ADDS  [$mem],$add\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ addw($mem$$Address, $add$$constant);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xaddS( memory mem, rRegI newval, eFlagsReg cr) %{\n-  match(Set newval (GetAndAddS mem newval));\n-  effect(KILL cr);\n-  format %{ \"XADDS  [$mem],$newval\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ xaddw($mem$$Address, $newval$$Register);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xaddI_no_res( memory mem, Universe dummy, immI add, eFlagsReg cr) %{\n-  predicate(n->as_LoadStore()->result_not_used());\n-  match(Set dummy (GetAndAddI mem add));\n-  effect(KILL cr);\n-  format %{ \"ADDL  [$mem],$add\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ addl($mem$$Address, $add$$constant);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xaddI( memory mem, rRegI newval, eFlagsReg cr) %{\n-  match(Set newval (GetAndAddI mem newval));\n-  effect(KILL cr);\n-  format %{ \"XADDL  [$mem],$newval\" %}\n-  ins_encode %{\n-    __ lock();\n-    __ xaddl($mem$$Address, $newval$$Register);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-\/\/ Important to match to xRegI: only 8-bit regs.\n-instruct xchgB( memory mem, xRegI newval) %{\n-  match(Set newval (GetAndSetB mem newval));\n-  format %{ \"XCHGB  $newval,[$mem]\" %}\n-  ins_encode %{\n-    __ xchgb($newval$$Register, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xchgS( memory mem, rRegI newval) %{\n-  match(Set newval (GetAndSetS mem newval));\n-  format %{ \"XCHGW  $newval,[$mem]\" %}\n-  ins_encode %{\n-    __ xchgw($newval$$Register, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xchgI( memory mem, rRegI newval) %{\n-  match(Set newval (GetAndSetI mem newval));\n-  format %{ \"XCHGL  $newval,[$mem]\" %}\n-  ins_encode %{\n-    __ xchgl($newval$$Register, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-instruct xchgP( memory mem, pRegP newval) %{\n-  match(Set newval (GetAndSetP mem newval));\n-  format %{ \"XCHGL  $newval,[$mem]\" %}\n-  ins_encode %{\n-    __ xchgl($newval$$Register, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_cmpxchg );\n-%}\n-\n-\/\/----------Subtraction Instructions-------------------------------------------\n-\n-\/\/ Integer Subtraction Instructions\n-instruct subI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (SubI dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SUB    $dst,$src\" %}\n-  opcode(0x2B);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct subI_eReg_imm(rRegI dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (SubI dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"SUB    $dst,$src\" %}\n-  opcode(0x81,0x05);  \/* Opcode 81 \/5 *\/\n-  \/\/ ins_encode( RegImm( dst, src) );\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct subI_eReg_mem(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (SubI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"SUB    $dst,$src\" %}\n-  opcode(0x2B);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-instruct subI_mem_eReg(memory dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (SubI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"SUB    $dst,$src\" %}\n-  opcode(0x29);  \/* Opcode 29 \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Subtract from a pointer\n-instruct subP_eReg(eRegP dst, rRegI src, immI_0 zero, eFlagsReg cr) %{\n-  match(Set dst (AddP dst (SubI zero src)));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SUB    $dst,$src\" %}\n-  opcode(0x2B);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct negI_eReg(rRegI dst, immI_0 zero, eFlagsReg cr) %{\n-  match(Set dst (SubI zero dst));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"NEG    $dst\" %}\n-  opcode(0xF7,0x03);  \/\/ Opcode F7 \/3\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/----------Multiplication\/Division Instructions-------------------------------\n-\/\/ Integer Multiplication Instructions\n-\/\/ Multiply Register\n-instruct mulI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (MulI dst src));\n-  effect(KILL cr);\n-\n-  size(3);\n-  ins_cost(300);\n-  format %{ \"IMUL   $dst,$src\" %}\n-  opcode(0xAF, 0x0F);\n-  ins_encode( OpcS, OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-\/\/ Multiply 32-bit Immediate\n-instruct mulI_eReg_imm(rRegI dst, rRegI src, immI imm, eFlagsReg cr) %{\n-  match(Set dst (MulI src imm));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"IMUL   $dst,$src,$imm\" %}\n-  opcode(0x69);  \/* 69 \/r id *\/\n-  ins_encode( OpcSE(imm), RegReg( dst, src ), Con8or32( imm ) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-instruct loadConL_low_only(eADXRegL_low_only dst, immL32 src, eFlagsReg cr) %{\n-  match(Set dst src);\n-  effect(KILL cr);\n-\n-  \/\/ Note that this is artificially increased to make it more expensive than loadConL\n-  ins_cost(250);\n-  format %{ \"MOV    EAX,$src\\t\/\/ low word only\" %}\n-  opcode(0xB8);\n-  ins_encode( LdImmL_Lo(dst, src) );\n-  ins_pipe( ialu_reg_fat );\n-%}\n-\n-\/\/ Multiply by 32-bit Immediate, taking the shifted high order results\n-\/\/  (special case for shift by 32)\n-instruct mulI_imm_high(eDXRegI dst, nadxRegI src1, eADXRegL_low_only src2, immI_32 cnt, eFlagsReg cr) %{\n-  match(Set dst (ConvL2I (RShiftL (MulL (ConvI2L src1) src2) cnt)));\n-  predicate( _kids[0]->_kids[0]->_kids[1]->_leaf->Opcode() == Op_ConL &&\n-             _kids[0]->_kids[0]->_kids[1]->_leaf->as_Type()->type()->is_long()->get_con() >= min_jint &&\n-             _kids[0]->_kids[0]->_kids[1]->_leaf->as_Type()->type()->is_long()->get_con() <= max_jint );\n-  effect(USE src1, KILL cr);\n-\n-  \/\/ Note that this is adjusted by 150 to compensate for the overcosting of loadConL_low_only\n-  ins_cost(0*100 + 1*400 - 150);\n-  format %{ \"IMUL   EDX:EAX,$src1\" %}\n-  ins_encode( multiply_con_and_shift_high( dst, src1, src2, cnt, cr ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply by 32-bit Immediate, taking the shifted high order results\n-instruct mulI_imm_RShift_high(eDXRegI dst, nadxRegI src1, eADXRegL_low_only src2, immI_32_63 cnt, eFlagsReg cr) %{\n-  match(Set dst (ConvL2I (RShiftL (MulL (ConvI2L src1) src2) cnt)));\n-  predicate( _kids[0]->_kids[0]->_kids[1]->_leaf->Opcode() == Op_ConL &&\n-             _kids[0]->_kids[0]->_kids[1]->_leaf->as_Type()->type()->is_long()->get_con() >= min_jint &&\n-             _kids[0]->_kids[0]->_kids[1]->_leaf->as_Type()->type()->is_long()->get_con() <= max_jint );\n-  effect(USE src1, KILL cr);\n-\n-  \/\/ Note that this is adjusted by 150 to compensate for the overcosting of loadConL_low_only\n-  ins_cost(1*100 + 1*400 - 150);\n-  format %{ \"IMUL   EDX:EAX,$src1\\n\\t\"\n-            \"SAR    EDX,$cnt-32\" %}\n-  ins_encode( multiply_con_and_shift_high( dst, src1, src2, cnt, cr ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply Memory 32-bit Immediate\n-instruct mulI_mem_imm(rRegI dst, memory src, immI imm, eFlagsReg cr) %{\n-  match(Set dst (MulI (LoadI src) imm));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"IMUL   $dst,$src,$imm\" %}\n-  opcode(0x69);  \/* 69 \/r id *\/\n-  ins_encode( SetInstMark, OpcSE(imm), RegMem( dst, src ), Con8or32( imm ), ClearInstMark );\n-  ins_pipe( ialu_reg_mem_alu0 );\n-%}\n-\n-\/\/ Multiply Memory\n-instruct mulI(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (MulI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(350);\n-  format %{ \"IMUL   $dst,$src\" %}\n-  opcode(0xAF, 0x0F);\n-  ins_encode( SetInstMark, OpcS, OpcP, RegMem( dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem_alu0 );\n-%}\n-\n-instruct mulAddS2I_rReg(rRegI dst, rRegI src1, rRegI src2, rRegI src3, eFlagsReg cr)\n-%{\n-  match(Set dst (MulAddS2I (Binary dst src1) (Binary src2 src3)));\n-  effect(KILL cr, KILL src2);\n-\n-  expand %{ mulI_eReg(dst, src1, cr);\n-           mulI_eReg(src2, src3, cr);\n-           addI_eReg(dst, src2, cr); %}\n-%}\n-\n-\/\/ Multiply Register Int to Long\n-instruct mulI2L(eADXRegL dst, eAXRegI src, nadxRegI src1, eFlagsReg flags) %{\n-  \/\/ Basic Idea: long = (long)int * (long)int\n-  match(Set dst (MulL (ConvI2L src) (ConvI2L src1)));\n-  effect(DEF dst, USE src, USE src1, KILL flags);\n-\n-  ins_cost(300);\n-  format %{ \"IMUL   $dst,$src1\" %}\n-\n-  ins_encode( long_int_multiply( dst, src1 ) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-instruct mulIS_eReg(eADXRegL dst, immL_32bits mask, eFlagsReg flags, eAXRegI src, nadxRegI src1) %{\n-  \/\/ Basic Idea:  long = (int & 0xffffffffL) * (int & 0xffffffffL)\n-  match(Set dst (MulL (AndL (ConvI2L src) mask) (AndL (ConvI2L src1) mask)));\n-  effect(KILL flags);\n-\n-  ins_cost(300);\n-  format %{ \"MUL    $dst,$src1\" %}\n-\n-  ins_encode( long_uint_multiply(dst, src1) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-\/\/ Multiply Register Long\n-instruct mulL_eReg(eADXRegL dst, eRegL src, rRegI tmp, eFlagsReg cr) %{\n-  match(Set dst (MulL dst src));\n-  effect(KILL cr, TEMP tmp);\n-  ins_cost(4*100+3*400);\n-\/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-\/\/             hi(result) = hi(x_lo * y_lo) + lo(x_hi * y_lo) + lo(x_lo * y_hi)\n-  format %{ \"MOV    $tmp,$src.lo\\n\\t\"\n-            \"IMUL   $tmp,EDX\\n\\t\"\n-            \"MOV    EDX,$src.hi\\n\\t\"\n-            \"IMUL   EDX,EAX\\n\\t\"\n-            \"ADD    $tmp,EDX\\n\\t\"\n-            \"MUL    EDX:EAX,$src.lo\\n\\t\"\n-            \"ADD    EDX,$tmp\" %}\n-  ins_encode( long_multiply( dst, src, tmp ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply Register Long where the left operand's high 32 bits are zero\n-instruct mulL_eReg_lhi0(eADXRegL dst, eRegL src, rRegI tmp, eFlagsReg cr) %{\n-  predicate(is_operand_hi32_zero(n->in(1)));\n-  match(Set dst (MulL dst src));\n-  effect(KILL cr, TEMP tmp);\n-  ins_cost(2*100+2*400);\n-\/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-\/\/             hi(result) = hi(x_lo * y_lo) + lo(x_lo * y_hi) where lo(x_hi * y_lo) = 0 because x_hi = 0\n-  format %{ \"MOV    $tmp,$src.hi\\n\\t\"\n-            \"IMUL   $tmp,EAX\\n\\t\"\n-            \"MUL    EDX:EAX,$src.lo\\n\\t\"\n-            \"ADD    EDX,$tmp\" %}\n-  ins_encode %{\n-    __ movl($tmp$$Register, HIGH_FROM_LOW($src$$Register));\n-    __ imull($tmp$$Register, rax);\n-    __ mull($src$$Register);\n-    __ addl(rdx, $tmp$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply Register Long where the right operand's high 32 bits are zero\n-instruct mulL_eReg_rhi0(eADXRegL dst, eRegL src, rRegI tmp, eFlagsReg cr) %{\n-  predicate(is_operand_hi32_zero(n->in(2)));\n-  match(Set dst (MulL dst src));\n-  effect(KILL cr, TEMP tmp);\n-  ins_cost(2*100+2*400);\n-\/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-\/\/             hi(result) = hi(x_lo * y_lo) + lo(x_hi * y_lo) where lo(x_lo * y_hi) = 0 because y_hi = 0\n-  format %{ \"MOV    $tmp,$src.lo\\n\\t\"\n-            \"IMUL   $tmp,EDX\\n\\t\"\n-            \"MUL    EDX:EAX,$src.lo\\n\\t\"\n-            \"ADD    EDX,$tmp\" %}\n-  ins_encode %{\n-    __ movl($tmp$$Register, $src$$Register);\n-    __ imull($tmp$$Register, rdx);\n-    __ mull($src$$Register);\n-    __ addl(rdx, $tmp$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply Register Long where the left and the right operands' high 32 bits are zero\n-instruct mulL_eReg_hi0(eADXRegL dst, eRegL src, eFlagsReg cr) %{\n-  predicate(is_operand_hi32_zero(n->in(1)) && is_operand_hi32_zero(n->in(2)));\n-  match(Set dst (MulL dst src));\n-  effect(KILL cr);\n-  ins_cost(1*400);\n-\/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-\/\/             hi(result) = hi(x_lo * y_lo) where lo(x_hi * y_lo) = 0 and lo(x_lo * y_hi) = 0 because x_hi = 0 and y_hi = 0\n-  format %{ \"MUL    EDX:EAX,$src.lo\\n\\t\" %}\n-  ins_encode %{\n-    __ mull($src$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Multiply Register Long by small constant\n-instruct mulL_eReg_con(eADXRegL dst, immL_127 src, rRegI tmp, eFlagsReg cr) %{\n-  match(Set dst (MulL dst src));\n-  effect(KILL cr, TEMP tmp);\n-  ins_cost(2*100+2*400);\n-  size(12);\n-\/\/ Basic idea: lo(result) = lo(src * EAX)\n-\/\/             hi(result) = hi(src * EAX) + lo(src * EDX)\n-  format %{ \"IMUL   $tmp,EDX,$src\\n\\t\"\n-            \"MOV    EDX,$src\\n\\t\"\n-            \"MUL    EDX\\t# EDX*EAX -> EDX:EAX\\n\\t\"\n-            \"ADD    EDX,$tmp\" %}\n-  ins_encode( long_multiply_con( dst, src, tmp ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Integer DIV with Register\n-instruct divI_eReg(eAXRegI rax, eDXRegI rdx, eCXRegI div, eFlagsReg cr) %{\n-  match(Set rax (DivI rax div));\n-  effect(KILL rdx, KILL cr);\n-  size(26);\n-  ins_cost(30*100+10*100);\n-  format %{ \"CMP    EAX,0x80000000\\n\\t\"\n-            \"JNE,s  normal\\n\\t\"\n-            \"XOR    EDX,EDX\\n\\t\"\n-            \"CMP    ECX,-1\\n\\t\"\n-            \"JE,s   done\\n\"\n-    \"normal: CDQ\\n\\t\"\n-            \"IDIV   $div\\n\\t\"\n-    \"done:\"        %}\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode( cdq_enc, OpcP, RegOpc(div) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-\/\/ Divide Register Long\n-instruct divL_eReg(eADXRegL dst, eRegL src1, eRegL src2) %{\n-  match(Set dst (DivL src1 src2));\n-  effect(CALL);\n-  ins_cost(10000);\n-  format %{ \"PUSH   $src1.hi\\n\\t\"\n-            \"PUSH   $src1.lo\\n\\t\"\n-            \"PUSH   $src2.hi\\n\\t\"\n-            \"PUSH   $src2.lo\\n\\t\"\n-            \"CALL   SharedRuntime::ldiv\\n\\t\"\n-            \"ADD    ESP,16\" %}\n-  ins_encode( long_div(src1,src2) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Integer DIVMOD with Register, both quotient and mod results\n-instruct divModI_eReg_divmod(eAXRegI rax, eDXRegI rdx, eCXRegI div, eFlagsReg cr) %{\n-  match(DivModI rax div);\n-  effect(KILL cr);\n-  size(26);\n-  ins_cost(30*100+10*100);\n-  format %{ \"CMP    EAX,0x80000000\\n\\t\"\n-            \"JNE,s  normal\\n\\t\"\n-            \"XOR    EDX,EDX\\n\\t\"\n-            \"CMP    ECX,-1\\n\\t\"\n-            \"JE,s   done\\n\"\n-    \"normal: CDQ\\n\\t\"\n-            \"IDIV   $div\\n\\t\"\n-    \"done:\"        %}\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode( cdq_enc, OpcP, RegOpc(div) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Integer MOD with Register\n-instruct modI_eReg(eDXRegI rdx, eAXRegI rax, eCXRegI div, eFlagsReg cr) %{\n-  match(Set rdx (ModI rax div));\n-  effect(KILL rax, KILL cr);\n-\n-  size(26);\n-  ins_cost(300);\n-  format %{ \"CDQ\\n\\t\"\n-            \"IDIV   $div\" %}\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode( cdq_enc, OpcP, RegOpc(div) );\n-  ins_pipe( ialu_reg_reg_alu0 );\n-%}\n-\n-\/\/ Remainder Register Long\n-instruct modL_eReg(eADXRegL dst, eRegL src1, eRegL src2) %{\n-  match(Set dst (ModL src1 src2));\n-  effect(CALL);\n-  ins_cost(10000);\n-  format %{ \"PUSH   $src1.hi\\n\\t\"\n-            \"PUSH   $src1.lo\\n\\t\"\n-            \"PUSH   $src2.hi\\n\\t\"\n-            \"PUSH   $src2.lo\\n\\t\"\n-            \"CALL   SharedRuntime::lrem\\n\\t\"\n-            \"ADD    ESP,16\" %}\n-  ins_encode( long_mod(src1,src2) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Divide Register Long (no special case since divisor != -1)\n-instruct divL_eReg_imm32( eADXRegL dst, immL32 imm, rRegI tmp, rRegI tmp2, eFlagsReg cr ) %{\n-  match(Set dst (DivL dst imm));\n-  effect( TEMP tmp, TEMP tmp2, KILL cr );\n-  ins_cost(1000);\n-  format %{ \"MOV    $tmp,abs($imm) # ldiv EDX:EAX,$imm\\n\\t\"\n-            \"XOR    $tmp2,$tmp2\\n\\t\"\n-            \"CMP    $tmp,EDX\\n\\t\"\n-            \"JA,s   fast\\n\\t\"\n-            \"MOV    $tmp2,EAX\\n\\t\"\n-            \"MOV    EAX,EDX\\n\\t\"\n-            \"MOV    EDX,0\\n\\t\"\n-            \"JLE,s  pos\\n\\t\"\n-            \"LNEG   EAX : $tmp2\\n\\t\"\n-            \"DIV    $tmp # unsigned division\\n\\t\"\n-            \"XCHG   EAX,$tmp2\\n\\t\"\n-            \"DIV    $tmp\\n\\t\"\n-            \"LNEG   $tmp2 : EAX\\n\\t\"\n-            \"JMP,s  done\\n\"\n-    \"pos:\\n\\t\"\n-            \"DIV    $tmp\\n\\t\"\n-            \"XCHG   EAX,$tmp2\\n\"\n-    \"fast:\\n\\t\"\n-            \"DIV    $tmp\\n\"\n-    \"done:\\n\\t\"\n-            \"MOV    EDX,$tmp2\\n\\t\"\n-            \"NEG    EDX:EAX # if $imm < 0\" %}\n-  ins_encode %{\n-    int con = (int)$imm$$constant;\n-    assert(con != 0 && con != -1 && con != min_jint, \"wrong divisor\");\n-    int pcon = (con > 0) ? con : -con;\n-    Label Lfast, Lpos, Ldone;\n-\n-    __ movl($tmp$$Register, pcon);\n-    __ xorl($tmp2$$Register,$tmp2$$Register);\n-    __ cmpl($tmp$$Register, HIGH_FROM_LOW($dst$$Register));\n-    __ jccb(Assembler::above, Lfast); \/\/ result fits into 32 bit\n-\n-    __ movl($tmp2$$Register, $dst$$Register); \/\/ save\n-    __ movl($dst$$Register, HIGH_FROM_LOW($dst$$Register));\n-    __ movl(HIGH_FROM_LOW($dst$$Register),0); \/\/ preserve flags\n-    __ jccb(Assembler::lessEqual, Lpos); \/\/ result is positive\n-\n-    \/\/ Negative dividend.\n-    \/\/ convert value to positive to use unsigned division\n-    __ lneg($dst$$Register, $tmp2$$Register);\n-    __ divl($tmp$$Register);\n-    __ xchgl($dst$$Register, $tmp2$$Register);\n-    __ divl($tmp$$Register);\n-    \/\/ revert result back to negative\n-    __ lneg($tmp2$$Register, $dst$$Register);\n-    __ jmpb(Ldone);\n-\n-    __ bind(Lpos);\n-    __ divl($tmp$$Register); \/\/ Use unsigned division\n-    __ xchgl($dst$$Register, $tmp2$$Register);\n-    \/\/ Fallthrow for final divide, tmp2 has 32 bit hi result\n-\n-    __ bind(Lfast);\n-    \/\/ fast path: src is positive\n-    __ divl($tmp$$Register); \/\/ Use unsigned division\n-\n-    __ bind(Ldone);\n-    __ movl(HIGH_FROM_LOW($dst$$Register),$tmp2$$Register);\n-    if (con < 0) {\n-      __ lneg(HIGH_FROM_LOW($dst$$Register), $dst$$Register);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Remainder Register Long (remainder fit into 32 bits)\n-instruct modL_eReg_imm32( eADXRegL dst, immL32 imm, rRegI tmp, rRegI tmp2, eFlagsReg cr ) %{\n-  match(Set dst (ModL dst imm));\n-  effect( TEMP tmp, TEMP tmp2, KILL cr );\n-  ins_cost(1000);\n-  format %{ \"MOV    $tmp,abs($imm) # lrem EDX:EAX,$imm\\n\\t\"\n-            \"CMP    $tmp,EDX\\n\\t\"\n-            \"JA,s   fast\\n\\t\"\n-            \"MOV    $tmp2,EAX\\n\\t\"\n-            \"MOV    EAX,EDX\\n\\t\"\n-            \"MOV    EDX,0\\n\\t\"\n-            \"JLE,s  pos\\n\\t\"\n-            \"LNEG   EAX : $tmp2\\n\\t\"\n-            \"DIV    $tmp # unsigned division\\n\\t\"\n-            \"MOV    EAX,$tmp2\\n\\t\"\n-            \"DIV    $tmp\\n\\t\"\n-            \"NEG    EDX\\n\\t\"\n-            \"JMP,s  done\\n\"\n-    \"pos:\\n\\t\"\n-            \"DIV    $tmp\\n\\t\"\n-            \"MOV    EAX,$tmp2\\n\"\n-    \"fast:\\n\\t\"\n-            \"DIV    $tmp\\n\"\n-    \"done:\\n\\t\"\n-            \"MOV    EAX,EDX\\n\\t\"\n-            \"SAR    EDX,31\\n\\t\" %}\n-  ins_encode %{\n-    int con = (int)$imm$$constant;\n-    assert(con != 0 && con != -1 && con != min_jint, \"wrong divisor\");\n-    int pcon = (con > 0) ? con : -con;\n-    Label  Lfast, Lpos, Ldone;\n-\n-    __ movl($tmp$$Register, pcon);\n-    __ cmpl($tmp$$Register, HIGH_FROM_LOW($dst$$Register));\n-    __ jccb(Assembler::above, Lfast); \/\/ src is positive and result fits into 32 bit\n-\n-    __ movl($tmp2$$Register, $dst$$Register); \/\/ save\n-    __ movl($dst$$Register, HIGH_FROM_LOW($dst$$Register));\n-    __ movl(HIGH_FROM_LOW($dst$$Register),0); \/\/ preserve flags\n-    __ jccb(Assembler::lessEqual, Lpos); \/\/ result is positive\n-\n-    \/\/ Negative dividend.\n-    \/\/ convert value to positive to use unsigned division\n-    __ lneg($dst$$Register, $tmp2$$Register);\n-    __ divl($tmp$$Register);\n-    __ movl($dst$$Register, $tmp2$$Register);\n-    __ divl($tmp$$Register);\n-    \/\/ revert remainder back to negative\n-    __ negl(HIGH_FROM_LOW($dst$$Register));\n-    __ jmpb(Ldone);\n-\n-    __ bind(Lpos);\n-    __ divl($tmp$$Register);\n-    __ movl($dst$$Register, $tmp2$$Register);\n-\n-    __ bind(Lfast);\n-    \/\/ fast path: src is positive\n-    __ divl($tmp$$Register);\n-\n-    __ bind(Ldone);\n-    __ movl($dst$$Register, HIGH_FROM_LOW($dst$$Register));\n-    __ sarl(HIGH_FROM_LOW($dst$$Register), 31); \/\/ result sign\n-\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Integer Shift Instructions\n-\/\/ Shift Left by one\n-instruct shlI_eReg_1(rRegI dst, immI_1 shift, eFlagsReg cr) %{\n-  match(Set dst (LShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SHL    $dst,$shift\" %}\n-  opcode(0xD1, 0x4);  \/* D1 \/4 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Shift Left by 8-bit immediate\n-instruct salI_eReg_imm(rRegI dst, immI8 shift, eFlagsReg cr) %{\n-  match(Set dst (LShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(3);\n-  format %{ \"SHL    $dst,$shift\" %}\n-  opcode(0xC1, 0x4);  \/* C1 \/4 ib *\/\n-  ins_encode( RegOpcImm( dst, shift) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Shift Left by variable\n-instruct salI_eReg_CL(rRegI dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (LShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SHL    $dst,$shift\" %}\n-  opcode(0xD3, 0x4);  \/* D3 \/4 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\/\/ Arithmetic shift right by one\n-instruct sarI_eReg_1(rRegI dst, immI_1 shift, eFlagsReg cr) %{\n-  match(Set dst (RShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SAR    $dst,$shift\" %}\n-  opcode(0xD1, 0x7);  \/* D1 \/7 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Arithmetic shift right by one\n-instruct sarI_mem_1(memory dst, immI_1 shift, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (RShiftI (LoadI dst) shift)));\n-  effect(KILL cr);\n-  format %{ \"SAR    $dst,$shift\" %}\n-  opcode(0xD1, 0x7);  \/* D1 \/7 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(secondary,dst), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Arithmetic Shift Right by 8-bit immediate\n-instruct sarI_eReg_imm(rRegI dst, immI8 shift, eFlagsReg cr) %{\n-  match(Set dst (RShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(3);\n-  format %{ \"SAR    $dst,$shift\" %}\n-  opcode(0xC1, 0x7);  \/* C1 \/7 ib *\/\n-  ins_encode( RegOpcImm( dst, shift ) );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Arithmetic Shift Right by 8-bit immediate\n-instruct sarI_mem_imm(memory dst, immI8 shift, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (RShiftI (LoadI dst) shift)));\n-  effect(KILL cr);\n-\n-  format %{ \"SAR    $dst,$shift\" %}\n-  opcode(0xC1, 0x7);  \/* C1 \/7 ib *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(secondary, dst ), Con8or32(shift), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ Arithmetic Shift Right by variable\n-instruct sarI_eReg_CL(rRegI dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (RShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SAR    $dst,$shift\" %}\n-  opcode(0xD3, 0x7);  \/* D3 \/7 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\/\/ Logical shift right by one\n-instruct shrI_eReg_1(rRegI dst, immI_1 shift, eFlagsReg cr) %{\n-  match(Set dst (URShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SHR    $dst,$shift\" %}\n-  opcode(0xD1, 0x5);  \/* D1 \/5 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Logical Shift Right by 8-bit immediate\n-instruct shrI_eReg_imm(rRegI dst, immI8 shift, eFlagsReg cr) %{\n-  match(Set dst (URShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(3);\n-  format %{ \"SHR    $dst,$shift\" %}\n-  opcode(0xC1, 0x5);  \/* C1 \/5 ib *\/\n-  ins_encode( RegOpcImm( dst, shift) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\n-\/\/ Logical Shift Right by 24, followed by Arithmetic Shift Left by 24.\n-\/\/ This idiom is used by the compiler for the i2b bytecode.\n-instruct i2b(rRegI dst, xRegI src, immI_24 twentyfour) %{\n-  match(Set dst (RShiftI (LShiftI src twentyfour) twentyfour));\n-\n-  size(3);\n-  format %{ \"MOVSX  $dst,$src :8\" %}\n-  ins_encode %{\n-    __ movsbl($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-\/\/ Logical Shift Right by 16, followed by Arithmetic Shift Left by 16.\n-\/\/ This idiom is used by the compiler the i2s bytecode.\n-instruct i2s(rRegI dst, xRegI src, immI_16 sixteen) %{\n-  match(Set dst (RShiftI (LShiftI src sixteen) sixteen));\n-\n-  size(3);\n-  format %{ \"MOVSX  $dst,$src :16\" %}\n-  ins_encode %{\n-    __ movswl($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-\n-\/\/ Logical Shift Right by variable\n-instruct shrI_eReg_CL(rRegI dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (URShiftI dst shift));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"SHR    $dst,$shift\" %}\n-  opcode(0xD3, 0x5);  \/* D3 \/5 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\n-\/\/----------Logical Instructions-----------------------------------------------\n-\/\/----------Integer Logical Instructions---------------------------------------\n-\/\/ And Instructions\n-\/\/ And Register with Register\n-instruct andI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (AndI dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"AND    $dst,$src\" %}\n-  opcode(0x23);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\/\/ And Register with Immediate\n-instruct andI_eReg_imm(rRegI dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (AndI dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"AND    $dst,$src\" %}\n-  opcode(0x81,0x04);  \/* Opcode 81 \/4 *\/\n-  \/\/ ins_encode( RegImm( dst, src) );\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ And Register with Memory\n-instruct andI_eReg_mem(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (AndI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"AND    $dst,$src\" %}\n-  opcode(0x23);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ And Memory with Register\n-instruct andI_mem_eReg(memory dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AndI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"AND    $dst,$src\" %}\n-  opcode(0x21);  \/* Opcode 21 \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ And Memory with Immediate\n-instruct andI_mem_imm(memory dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (AndI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"AND    $dst,$src\" %}\n-  opcode(0x81, 0x4);  \/* Opcode 81 \/4 id *\/\n-  \/\/ ins_encode( MemImm( dst, src) );\n-  ins_encode( SetInstMark, OpcSE( src ), RMopc_Mem(secondary, dst ), Con8or32(src), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ BMI1 instructions\n-instruct andnI_rReg_rReg_rReg(rRegI dst, rRegI src1, rRegI src2, immI_M1 minus_1, eFlagsReg cr) %{\n-  match(Set dst (AndI (XorI src1 minus_1) src2));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  format %{ \"ANDNL  $dst, $src1, $src2\" %}\n-\n-  ins_encode %{\n-    __ andnl($dst$$Register, $src1$$Register, $src2$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct andnI_rReg_rReg_mem(rRegI dst, rRegI src1, memory src2, immI_M1 minus_1, eFlagsReg cr) %{\n-  match(Set dst (AndI (XorI src1 minus_1) (LoadI src2) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"ANDNL  $dst, $src1, $src2\" %}\n-\n-  ins_encode %{\n-    __ andnl($dst$$Register, $src1$$Register, $src2$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsiI_rReg_rReg(rRegI dst, rRegI src, immI_0 imm_zero, eFlagsReg cr) %{\n-  match(Set dst (AndI (SubI imm_zero src) src));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  format %{ \"BLSIL  $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsil($dst$$Register, $src$$Register);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsiI_rReg_mem(rRegI dst, memory src, immI_0 imm_zero, eFlagsReg cr) %{\n-  match(Set dst (AndI (SubI imm_zero (LoadI src) ) (LoadI src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"BLSIL  $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsil($dst$$Register, $src$$Address);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsmskI_rReg_rReg(rRegI dst, rRegI src, immI_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (XorI (AddI src minus_1) src));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  format %{ \"BLSMSKL $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsmskl($dst$$Register, $src$$Register);\n-  %}\n-\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsmskI_rReg_mem(rRegI dst, memory src, immI_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (XorI (AddI (LoadI src) minus_1) (LoadI src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"BLSMSKL $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsmskl($dst$$Register, $src$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsrI_rReg_rReg(rRegI dst, rRegI src, immI_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (AndI (AddI src minus_1) src) );\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  format %{ \"BLSRL  $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsrl($dst$$Register, $src$$Register);\n-  %}\n-\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsrI_rReg_mem(rRegI dst, memory src, immI_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (AndI (AddI (LoadI src) minus_1) (LoadI src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"BLSRL  $dst, $src\" %}\n-\n-  ins_encode %{\n-    __ blsrl($dst$$Register, $src$$Address);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Or Instructions\n-\/\/ Or Register with Register\n-instruct orI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (OrI dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x0B);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct orI_eReg_castP2X(rRegI dst, eRegP src, eFlagsReg cr) %{\n-  match(Set dst (OrI dst (CastP2X src)));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x0B);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\n-\/\/ Or Register with Immediate\n-instruct orI_eReg_imm(rRegI dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (OrI dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x81,0x01);  \/* Opcode 81 \/1 id *\/\n-  \/\/ ins_encode( RegImm( dst, src) );\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Or Register with Memory\n-instruct orI_eReg_mem(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (OrI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x0B);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ Or Memory with Register\n-instruct orI_mem_eReg(memory dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (OrI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x09);  \/* Opcode 09 \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Or Memory with Immediate\n-instruct orI_mem_imm(memory dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (OrI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"OR     $dst,$src\" %}\n-  opcode(0x81,0x1);  \/* Opcode 81 \/1 id *\/\n-  \/\/ ins_encode( MemImm( dst, src) );\n-  ins_encode( SetInstMark, OpcSE( src ), RMopc_Mem(secondary, dst ), Con8or32(src), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/ ROL\/ROR\n-\/\/ ROL expand\n-instruct rolI_eReg_imm1(rRegI dst, immI_1 shift, eFlagsReg cr) %{\n-  effect(USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROL    $dst, $shift\" %}\n-  opcode(0xD1, 0x0); \/* Opcode D1 \/0 *\/\n-  ins_encode( OpcP, RegOpc( dst ));\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct rolI_eReg_imm8(rRegI dst, immI8 shift, eFlagsReg cr) %{\n-  effect(USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROL    $dst, $shift\" %}\n-  opcode(0xC1, 0x0); \/*Opcode \/C1  \/0  *\/\n-  ins_encode( RegOpcImm(dst, shift) );\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct rolI_eReg_CL(ncxRegI dst, eCXRegI shift, eFlagsReg cr) %{\n-  effect(USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROL    $dst, $shift\" %}\n-  opcode(0xD3, 0x0);    \/* Opcode D3 \/0 *\/\n-  ins_encode(OpcP, RegOpc(dst));\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\/\/ end of ROL expand\n-\n-\/\/ ROL 32bit by one once\n-instruct rolI_eReg_i1(rRegI dst, immI_1 lshift, immI_M1 rshift, eFlagsReg cr) %{\n-  match(Set dst ( OrI (LShiftI dst lshift) (URShiftI dst rshift)));\n-\n-  expand %{\n-    rolI_eReg_imm1(dst, lshift, cr);\n-  %}\n-%}\n-\n-\/\/ ROL 32bit var by imm8 once\n-instruct rolI_eReg_i8(rRegI dst, immI8 lshift, immI8 rshift, eFlagsReg cr) %{\n-  predicate(  0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));\n-  match(Set dst ( OrI (LShiftI dst lshift) (URShiftI dst rshift)));\n-\n-  expand %{\n-    rolI_eReg_imm8(dst, lshift, cr);\n-  %}\n-%}\n-\n-\/\/ ROL 32bit var by var once\n-instruct rolI_eReg_Var_C0(ncxRegI dst, eCXRegI shift, immI_0 zero, eFlagsReg cr) %{\n-  match(Set dst ( OrI (LShiftI dst shift) (URShiftI dst (SubI zero shift))));\n-\n-  expand %{\n-    rolI_eReg_CL(dst, shift, cr);\n-  %}\n-%}\n-\n-\/\/ ROL 32bit var by var once\n-instruct rolI_eReg_Var_C32(ncxRegI dst, eCXRegI shift, immI_32 c32, eFlagsReg cr) %{\n-  match(Set dst ( OrI (LShiftI dst shift) (URShiftI dst (SubI c32 shift))));\n-\n-  expand %{\n-    rolI_eReg_CL(dst, shift, cr);\n-  %}\n-%}\n-\n-\/\/ ROR expand\n-instruct rorI_eReg_imm1(rRegI dst, immI_1 shift, eFlagsReg cr) %{\n-  effect(USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROR    $dst, $shift\" %}\n-  opcode(0xD1,0x1);  \/* Opcode D1 \/1 *\/\n-  ins_encode( OpcP, RegOpc( dst ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct rorI_eReg_imm8(rRegI dst, immI8 shift, eFlagsReg cr) %{\n-  effect (USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROR    $dst, $shift\" %}\n-  opcode(0xC1, 0x1); \/* Opcode \/C1 \/1 ib *\/\n-  ins_encode( RegOpcImm(dst, shift) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-instruct rorI_eReg_CL(ncxRegI dst, eCXRegI shift, eFlagsReg cr)%{\n-  effect(USE_DEF dst, USE shift, KILL cr);\n-\n-  format %{ \"ROR    $dst, $shift\" %}\n-  opcode(0xD3, 0x1);    \/* Opcode D3 \/1 *\/\n-  ins_encode(OpcP, RegOpc(dst));\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\/\/ end of ROR expand\n-\n-\/\/ ROR right once\n-instruct rorI_eReg_i1(rRegI dst, immI_1 rshift, immI_M1 lshift, eFlagsReg cr) %{\n-  match(Set dst ( OrI (URShiftI dst rshift) (LShiftI dst lshift)));\n-\n-  expand %{\n-    rorI_eReg_imm1(dst, rshift, cr);\n-  %}\n-%}\n-\n-\/\/ ROR 32bit by immI8 once\n-instruct rorI_eReg_i8(rRegI dst, immI8 rshift, immI8 lshift, eFlagsReg cr) %{\n-  predicate(  0 == ((n->in(1)->in(2)->get_int() + n->in(2)->in(2)->get_int()) & 0x1f));\n-  match(Set dst ( OrI (URShiftI dst rshift) (LShiftI dst lshift)));\n-\n-  expand %{\n-    rorI_eReg_imm8(dst, rshift, cr);\n-  %}\n-%}\n-\n-\/\/ ROR 32bit var by var once\n-instruct rorI_eReg_Var_C0(ncxRegI dst, eCXRegI shift, immI_0 zero, eFlagsReg cr) %{\n-  match(Set dst ( OrI (URShiftI dst shift) (LShiftI dst (SubI zero shift))));\n-\n-  expand %{\n-    rorI_eReg_CL(dst, shift, cr);\n-  %}\n-%}\n-\n-\/\/ ROR 32bit var by var once\n-instruct rorI_eReg_Var_C32(ncxRegI dst, eCXRegI shift, immI_32 c32, eFlagsReg cr) %{\n-  match(Set dst ( OrI (URShiftI dst shift) (LShiftI dst (SubI c32 shift))));\n-\n-  expand %{\n-    rorI_eReg_CL(dst, shift, cr);\n-  %}\n-%}\n-\n-\/\/ Xor Instructions\n-\/\/ Xor Register with Register\n-instruct xorI_eReg(rRegI dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (XorI dst src));\n-  effect(KILL cr);\n-\n-  size(2);\n-  format %{ \"XOR    $dst,$src\" %}\n-  opcode(0x33);\n-  ins_encode( OpcP, RegReg( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-\/\/ Xor Register with Immediate -1\n-instruct xorI_eReg_im1(rRegI dst, immI_M1 imm) %{\n-  match(Set dst (XorI dst imm));\n-\n-  size(2);\n-  format %{ \"NOT    $dst\" %}\n-  ins_encode %{\n-     __ notl($dst$$Register);\n-  %}\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Xor Register with Immediate\n-instruct xorI_eReg_imm(rRegI dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (XorI dst src));\n-  effect(KILL cr);\n-\n-  format %{ \"XOR    $dst,$src\" %}\n-  opcode(0x81,0x06);  \/* Opcode 81 \/6 id *\/\n-  \/\/ ins_encode( RegImm( dst, src) );\n-  ins_encode( OpcSErm( dst, src ), Con8or32( src ) );\n-  ins_pipe( ialu_reg );\n-%}\n-\n-\/\/ Xor Register with Memory\n-instruct xorI_eReg_mem(rRegI dst, memory src, eFlagsReg cr) %{\n-  match(Set dst (XorI dst (LoadI src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"XOR    $dst,$src\" %}\n-  opcode(0x33);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst, src), ClearInstMark );\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-\/\/ Xor Memory with Register\n-instruct xorI_mem_eReg(memory dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (XorI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(150);\n-  format %{ \"XOR    $dst,$src\" %}\n-  opcode(0x31);  \/* Opcode 31 \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\/\/ Xor Memory with Immediate\n-instruct xorI_mem_imm(memory dst, immI src, eFlagsReg cr) %{\n-  match(Set dst (StoreI dst (XorI (LoadI dst) src)));\n-  effect(KILL cr);\n-\n-  ins_cost(125);\n-  format %{ \"XOR    $dst,$src\" %}\n-  opcode(0x81,0x6);  \/* Opcode 81 \/6 id *\/\n-  ins_encode( SetInstMark, OpcSE( src ), RMopc_Mem(secondary, dst ), Con8or32(src), ClearInstMark );\n-  ins_pipe( ialu_mem_imm );\n-%}\n-\n-\/\/----------Convert Int to Boolean---------------------------------------------\n-\n-instruct movI_nocopy(rRegI dst, rRegI src) %{\n-  effect( DEF dst, USE src );\n-  format %{ \"MOV    $dst,$src\" %}\n-  ins_encode( enc_Copy( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct ci2b( rRegI dst, rRegI src, eFlagsReg cr ) %{\n-  effect( USE_DEF dst, USE src, KILL cr );\n-\n-  size(4);\n-  format %{ \"NEG    $dst\\n\\t\"\n-            \"ADC    $dst,$src\" %}\n-  ins_encode( neg_reg(dst),\n-              OpcRegReg(0x13,dst,src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-instruct convI2B( rRegI dst, rRegI src, eFlagsReg cr ) %{\n-  match(Set dst (Conv2B src));\n-\n-  expand %{\n-    movI_nocopy(dst,src);\n-    ci2b(dst,src,cr);\n-  %}\n-%}\n-\n-instruct movP_nocopy(rRegI dst, eRegP src) %{\n-  effect( DEF dst, USE src );\n-  format %{ \"MOV    $dst,$src\" %}\n-  ins_encode( enc_Copy( dst, src) );\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct cp2b( rRegI dst, eRegP src, eFlagsReg cr ) %{\n-  effect( USE_DEF dst, USE src, KILL cr );\n-  format %{ \"NEG    $dst\\n\\t\"\n-            \"ADC    $dst,$src\" %}\n-  ins_encode( neg_reg(dst),\n-              OpcRegReg(0x13,dst,src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-instruct convP2B( rRegI dst, eRegP src, eFlagsReg cr ) %{\n-  match(Set dst (Conv2B src));\n-\n-  expand %{\n-    movP_nocopy(dst,src);\n-    cp2b(dst,src,cr);\n-  %}\n-%}\n-\n-instruct cmpLTMask(eCXRegI dst, ncxRegI p, ncxRegI q, eFlagsReg cr) %{\n-  match(Set dst (CmpLTMask p q));\n-  effect(KILL cr);\n-  ins_cost(400);\n-\n-  \/\/ SETlt can only use low byte of EAX,EBX, ECX, or EDX as destination\n-  format %{ \"XOR    $dst,$dst\\n\\t\"\n-            \"CMP    $p,$q\\n\\t\"\n-            \"SETlt  $dst\\n\\t\"\n-            \"NEG    $dst\" %}\n-  ins_encode %{\n-    Register Rp = $p$$Register;\n-    Register Rq = $q$$Register;\n-    Register Rd = $dst$$Register;\n-    Label done;\n-    __ xorl(Rd, Rd);\n-    __ cmpl(Rp, Rq);\n-    __ setb(Assembler::less, Rd);\n-    __ negl(Rd);\n-  %}\n-\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct cmpLTMask0(rRegI dst, immI_0 zero, eFlagsReg cr) %{\n-  match(Set dst (CmpLTMask dst zero));\n-  effect(DEF dst, KILL cr);\n-  ins_cost(100);\n-\n-  format %{ \"SAR    $dst,31\\t# cmpLTMask0\" %}\n-  ins_encode %{\n-  __ sarl($dst$$Register, 31);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-\/* better to save a register than avoid a branch *\/\n-instruct cadd_cmpLTMask(rRegI p, rRegI q, rRegI y, eFlagsReg cr) %{\n-  match(Set p (AddI (AndI (CmpLTMask p q) y) (SubI p q)));\n-  effect(KILL cr);\n-  ins_cost(400);\n-  format %{ \"SUB    $p,$q\\t# cadd_cmpLTMask\\n\\t\"\n-            \"JGE    done\\n\\t\"\n-            \"ADD    $p,$y\\n\"\n-            \"done:  \" %}\n-  ins_encode %{\n-    Register Rp = $p$$Register;\n-    Register Rq = $q$$Register;\n-    Register Ry = $y$$Register;\n-    Label done;\n-    __ subl(Rp, Rq);\n-    __ jccb(Assembler::greaterEqual, done);\n-    __ addl(Rp, Ry);\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(pipe_cmplt);\n-%}\n-\n-\/* better to save a register than avoid a branch *\/\n-instruct and_cmpLTMask(rRegI p, rRegI q, rRegI y, eFlagsReg cr) %{\n-  match(Set y (AndI (CmpLTMask p q) y));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-\n-  format %{ \"CMPL     $p, $q\\t# and_cmpLTMask\\n\\t\"\n-            \"JLT      done\\n\\t\"\n-            \"XORL     $y, $y\\n\"\n-            \"done:  \" %}\n-  ins_encode %{\n-    Register Rp = $p$$Register;\n-    Register Rq = $q$$Register;\n-    Register Ry = $y$$Register;\n-    Label done;\n-    __ cmpl(Rp, Rq);\n-    __ jccb(Assembler::less, done);\n-    __ xorl(Ry, Ry);\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(pipe_cmplt);\n-%}\n-\n-\/* If I enable this, I encourage spilling in the inner loop of compress.\n-instruct cadd_cmpLTMask_mem(ncxRegI p, ncxRegI q, memory y, eCXRegI tmp, eFlagsReg cr) %{\n-  match(Set p (AddI (AndI (CmpLTMask p q) (LoadI y)) (SubI p q)));\n-*\/\n-\/\/----------Overflow Math Instructions-----------------------------------------\n-\n-instruct overflowAddI_eReg(eFlagsReg cr, eAXRegI op1, rRegI op2)\n-%{\n-  match(Set cr (OverflowAddI op1 op2));\n-  effect(DEF cr, USE_KILL op1, USE op2);\n-\n-  format %{ \"ADD    $op1, $op2\\t# overflow check int\" %}\n-\n-  ins_encode %{\n-    __ addl($op1$$Register, $op2$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-instruct overflowAddI_rReg_imm(eFlagsReg cr, eAXRegI op1, immI op2)\n-%{\n-  match(Set cr (OverflowAddI op1 op2));\n-  effect(DEF cr, USE_KILL op1, USE op2);\n-\n-  format %{ \"ADD    $op1, $op2\\t# overflow check int\" %}\n-\n-  ins_encode %{\n-    __ addl($op1$$Register, $op2$$constant);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-instruct overflowSubI_rReg(eFlagsReg cr, rRegI op1, rRegI op2)\n-%{\n-  match(Set cr (OverflowSubI op1 op2));\n-\n-  format %{ \"CMP    $op1, $op2\\t# overflow check int\" %}\n-  ins_encode %{\n-    __ cmpl($op1$$Register, $op2$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-instruct overflowSubI_rReg_imm(eFlagsReg cr, rRegI op1, immI op2)\n-%{\n-  match(Set cr (OverflowSubI op1 op2));\n-\n-  format %{ \"CMP    $op1, $op2\\t# overflow check int\" %}\n-  ins_encode %{\n-    __ cmpl($op1$$Register, $op2$$constant);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-instruct overflowNegI_rReg(eFlagsReg cr, immI_0 zero, eAXRegI op2)\n-%{\n-  match(Set cr (OverflowSubI zero op2));\n-  effect(DEF cr, USE_KILL op2);\n-\n-  format %{ \"NEG    $op2\\t# overflow check int\" %}\n-  ins_encode %{\n-    __ negl($op2$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-instruct overflowMulI_rReg(eFlagsReg cr, eAXRegI op1, rRegI op2)\n-%{\n-  match(Set cr (OverflowMulI op1 op2));\n-  effect(DEF cr, USE_KILL op1, USE op2);\n-\n-  format %{ \"IMUL    $op1, $op2\\t# overflow check int\" %}\n-  ins_encode %{\n-    __ imull($op1$$Register, $op2$$Register);\n-  %}\n-  ins_pipe(ialu_reg_reg_alu0);\n-%}\n-\n-instruct overflowMulI_rReg_imm(eFlagsReg cr, rRegI op1, immI op2, rRegI tmp)\n-%{\n-  match(Set cr (OverflowMulI op1 op2));\n-  effect(DEF cr, TEMP tmp, USE op1, USE op2);\n-\n-  format %{ \"IMUL    $tmp, $op1, $op2\\t# overflow check int\" %}\n-  ins_encode %{\n-    __ imull($tmp$$Register, $op1$$Register, $op2$$constant);\n-  %}\n-  ins_pipe(ialu_reg_reg_alu0);\n-%}\n-\n-\/\/ Integer Absolute Instructions\n-instruct absI_rReg(rRegI dst, rRegI src, rRegI tmp, eFlagsReg cr)\n-%{\n-  match(Set dst (AbsI src));\n-  effect(TEMP dst, TEMP tmp, KILL cr);\n-  format %{ \"movl $tmp, $src\\n\\t\"\n-            \"sarl $tmp, 31\\n\\t\"\n-            \"movl $dst, $src\\n\\t\"\n-            \"xorl $dst, $tmp\\n\\t\"\n-            \"subl $dst, $tmp\\n\"\n-          %}\n-  ins_encode %{\n-    __ movl($tmp$$Register, $src$$Register);\n-    __ sarl($tmp$$Register, 31);\n-    __ movl($dst$$Register, $src$$Register);\n-    __ xorl($dst$$Register, $tmp$$Register);\n-    __ subl($dst$$Register, $tmp$$Register);\n-  %}\n-\n-  ins_pipe(ialu_reg_reg);\n-%}\n-\n-\/\/----------Long Instructions------------------------------------------------\n-\/\/ Add Long Register with Register\n-instruct addL_eReg(eRegL dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (AddL dst src));\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"ADD    $dst.lo,$src.lo\\n\\t\"\n-            \"ADC    $dst.hi,$src.hi\" %}\n-  opcode(0x03, 0x13);\n-  ins_encode( RegReg_Lo(dst, src), RegReg_Hi(dst,src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Add Long Register with Immediate\n-instruct addL_eReg_imm(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst (AddL dst src));\n-  effect(KILL cr);\n-  format %{ \"ADD    $dst.lo,$src.lo\\n\\t\"\n-            \"ADC    $dst.hi,$src.hi\" %}\n-  opcode(0x81,0x00,0x02);  \/* Opcode 81 \/0, 81 \/2 *\/\n-  ins_encode( Long_OpcSErm_Lo( dst, src ), Long_OpcSErm_Hi( dst, src ) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Add Long Register with Memory\n-instruct addL_eReg_mem(eRegL dst, load_long_memory mem, eFlagsReg cr) %{\n-  match(Set dst (AddL dst (LoadL mem)));\n-  effect(KILL cr);\n-  ins_cost(125);\n-  format %{ \"ADD    $dst.lo,$mem\\n\\t\"\n-            \"ADC    $dst.hi,$mem+4\" %}\n-  opcode(0x03, 0x13);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, mem), OpcS, RegMem_Hi(dst,mem), ClearInstMark );\n-  ins_pipe( ialu_reg_long_mem );\n-%}\n-\n-\/\/ Subtract Long Register with Register.\n-instruct subL_eReg(eRegL dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (SubL dst src));\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"SUB    $dst.lo,$src.lo\\n\\t\"\n-            \"SBB    $dst.hi,$src.hi\" %}\n-  opcode(0x2B, 0x1B);\n-  ins_encode( RegReg_Lo(dst, src), RegReg_Hi(dst,src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Subtract Long Register with Immediate\n-instruct subL_eReg_imm(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst (SubL dst src));\n-  effect(KILL cr);\n-  format %{ \"SUB    $dst.lo,$src.lo\\n\\t\"\n-            \"SBB    $dst.hi,$src.hi\" %}\n-  opcode(0x81,0x05,0x03);  \/* Opcode 81 \/5, 81 \/3 *\/\n-  ins_encode( Long_OpcSErm_Lo( dst, src ), Long_OpcSErm_Hi( dst, src ) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Subtract Long Register with Memory\n-instruct subL_eReg_mem(eRegL dst, load_long_memory mem, eFlagsReg cr) %{\n-  match(Set dst (SubL dst (LoadL mem)));\n-  effect(KILL cr);\n-  ins_cost(125);\n-  format %{ \"SUB    $dst.lo,$mem\\n\\t\"\n-            \"SBB    $dst.hi,$mem+4\" %}\n-  opcode(0x2B, 0x1B);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, mem), OpcS, RegMem_Hi(dst,mem), ClearInstMark );\n-  ins_pipe( ialu_reg_long_mem );\n-%}\n-\n-instruct negL_eReg(eRegL dst, immL0 zero, eFlagsReg cr) %{\n-  match(Set dst (SubL zero dst));\n-  effect(KILL cr);\n-  ins_cost(300);\n-  format %{ \"NEG    $dst.hi\\n\\tNEG    $dst.lo\\n\\tSBB    $dst.hi,0\" %}\n-  ins_encode( neg_long(dst) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ And Long Register with Register\n-instruct andL_eReg(eRegL dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (AndL dst src));\n-  effect(KILL cr);\n-  format %{ \"AND    $dst.lo,$src.lo\\n\\t\"\n-            \"AND    $dst.hi,$src.hi\" %}\n-  opcode(0x23,0x23);\n-  ins_encode( RegReg_Lo( dst, src), RegReg_Hi( dst, src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ And Long Register with Immediate\n-instruct andL_eReg_imm(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst (AndL dst src));\n-  effect(KILL cr);\n-  format %{ \"AND    $dst.lo,$src.lo\\n\\t\"\n-            \"AND    $dst.hi,$src.hi\" %}\n-  opcode(0x81,0x04,0x04);  \/* Opcode 81 \/4, 81 \/4 *\/\n-  ins_encode( Long_OpcSErm_Lo( dst, src ), Long_OpcSErm_Hi( dst, src ) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ And Long Register with Memory\n-instruct andL_eReg_mem(eRegL dst, load_long_memory mem, eFlagsReg cr) %{\n-  match(Set dst (AndL dst (LoadL mem)));\n-  effect(KILL cr);\n-  ins_cost(125);\n-  format %{ \"AND    $dst.lo,$mem\\n\\t\"\n-            \"AND    $dst.hi,$mem+4\" %}\n-  opcode(0x23, 0x23);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, mem), OpcS, RegMem_Hi(dst,mem), ClearInstMark );\n-  ins_pipe( ialu_reg_long_mem );\n-%}\n-\n-\/\/ BMI1 instructions\n-instruct andnL_eReg_eReg_eReg(eRegL dst, eRegL src1, eRegL src2, immL_M1 minus_1, eFlagsReg cr) %{\n-  match(Set dst (AndL (XorL src1 minus_1) src2));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  format %{ \"ANDNL  $dst.lo, $src1.lo, $src2.lo\\n\\t\"\n-            \"ANDNL  $dst.hi, $src1.hi, $src2.hi\"\n-         %}\n-\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc1 = $src1$$Register;\n-    Register Rsrc2 = $src2$$Register;\n-    __ andnl(Rdst, Rsrc1, Rsrc2);\n-    __ andnl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc1), HIGH_FROM_LOW(Rsrc2));\n-  %}\n-  ins_pipe(ialu_reg_reg_long);\n-%}\n-\n-instruct andnL_eReg_eReg_mem(eRegL dst, eRegL src1, memory src2, immL_M1 minus_1, eFlagsReg cr) %{\n-  match(Set dst (AndL (XorL src1 minus_1) (LoadL src2) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  ins_cost(125);\n-  format %{ \"ANDNL  $dst.lo, $src1.lo, $src2\\n\\t\"\n-            \"ANDNL  $dst.hi, $src1.hi, $src2+4\"\n-         %}\n-\n-  ins_encode %{\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc1 = $src1$$Register;\n-    Address src2_hi = Address::make_raw($src2$$base, $src2$$index, $src2$$scale, $src2$$disp + 4, relocInfo::none);\n-\n-    __ andnl(Rdst, Rsrc1, $src2$$Address);\n-    __ andnl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc1), src2_hi);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsiL_eReg_eReg(eRegL dst, eRegL src, immL0 imm_zero, eFlagsReg cr) %{\n-  match(Set dst (AndL (SubL imm_zero src) src));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  format %{ \"MOVL   $dst.hi, 0\\n\\t\"\n-            \"BLSIL  $dst.lo, $src.lo\\n\\t\"\n-            \"JNZ    done\\n\\t\"\n-            \"BLSIL  $dst.hi, $src.hi\\n\"\n-            \"done:\"\n-         %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    __ movl(HIGH_FROM_LOW(Rdst), 0);\n-    __ blsil(Rdst, Rsrc);\n-    __ jccb(Assembler::notZero, done);\n-    __ blsil(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc));\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsiL_eReg_mem(eRegL dst, memory src, immL0 imm_zero, eFlagsReg cr) %{\n-  match(Set dst (AndL (SubL imm_zero (LoadL src) ) (LoadL src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  ins_cost(125);\n-  format %{ \"MOVL   $dst.hi, 0\\n\\t\"\n-            \"BLSIL  $dst.lo, $src\\n\\t\"\n-            \"JNZ    done\\n\\t\"\n-            \"BLSIL  $dst.hi, $src+4\\n\"\n-            \"done:\"\n-         %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Address src_hi = Address::make_raw($src$$base, $src$$index, $src$$scale, $src$$disp + 4, relocInfo::none);\n-\n-    __ movl(HIGH_FROM_LOW(Rdst), 0);\n-    __ blsil(Rdst, $src$$Address);\n-    __ jccb(Assembler::notZero, done);\n-    __ blsil(HIGH_FROM_LOW(Rdst), src_hi);\n-    __ bind(done);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsmskL_eReg_eReg(eRegL dst, eRegL src, immL_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (XorL (AddL src minus_1) src));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  format %{ \"MOVL    $dst.hi, 0\\n\\t\"\n-            \"BLSMSKL $dst.lo, $src.lo\\n\\t\"\n-            \"JNC     done\\n\\t\"\n-            \"BLSMSKL $dst.hi, $src.hi\\n\"\n-            \"done:\"\n-         %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    __ movl(HIGH_FROM_LOW(Rdst), 0);\n-    __ blsmskl(Rdst, Rsrc);\n-    __ jccb(Assembler::carryClear, done);\n-    __ blsmskl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc));\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsmskL_eReg_mem(eRegL dst, memory src, immL_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (XorL (AddL (LoadL src) minus_1) (LoadL src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  ins_cost(125);\n-  format %{ \"MOVL    $dst.hi, 0\\n\\t\"\n-            \"BLSMSKL $dst.lo, $src\\n\\t\"\n-            \"JNC     done\\n\\t\"\n-            \"BLSMSKL $dst.hi, $src+4\\n\"\n-            \"done:\"\n-         %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Address src_hi = Address::make_raw($src$$base, $src$$index, $src$$scale, $src$$disp + 4, relocInfo::none);\n-\n-    __ movl(HIGH_FROM_LOW(Rdst), 0);\n-    __ blsmskl(Rdst, $src$$Address);\n-    __ jccb(Assembler::carryClear, done);\n-    __ blsmskl(HIGH_FROM_LOW(Rdst), src_hi);\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-instruct blsrL_eReg_eReg(eRegL dst, eRegL src, immL_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (AndL (AddL src minus_1) src) );\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  format %{ \"MOVL   $dst.hi, $src.hi\\n\\t\"\n-            \"BLSRL  $dst.lo, $src.lo\\n\\t\"\n-            \"JNC    done\\n\\t\"\n-            \"BLSRL  $dst.hi, $src.hi\\n\"\n-            \"done:\"\n-  %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Register Rsrc = $src$$Register;\n-    __ movl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc));\n-    __ blsrl(Rdst, Rsrc);\n-    __ jccb(Assembler::carryClear, done);\n-    __ blsrl(HIGH_FROM_LOW(Rdst), HIGH_FROM_LOW(Rsrc));\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(ialu_reg);\n-%}\n-\n-instruct blsrL_eReg_mem(eRegL dst, memory src, immL_M1 minus_1, eFlagsReg cr)\n-%{\n-  match(Set dst (AndL (AddL (LoadL src) minus_1) (LoadL src) ));\n-  predicate(UseBMI1Instructions);\n-  effect(KILL cr, TEMP dst);\n-\n-  ins_cost(125);\n-  format %{ \"MOVL   $dst.hi, $src+4\\n\\t\"\n-            \"BLSRL  $dst.lo, $src\\n\\t\"\n-            \"JNC    done\\n\\t\"\n-            \"BLSRL  $dst.hi, $src+4\\n\"\n-            \"done:\"\n-  %}\n-\n-  ins_encode %{\n-    Label done;\n-    Register Rdst = $dst$$Register;\n-    Address src_hi = Address::make_raw($src$$base, $src$$index, $src$$scale, $src$$disp + 4, relocInfo::none);\n-    __ movl(HIGH_FROM_LOW(Rdst), src_hi);\n-    __ blsrl(Rdst, $src$$Address);\n-    __ jccb(Assembler::carryClear, done);\n-    __ blsrl(HIGH_FROM_LOW(Rdst), src_hi);\n-    __ bind(done);\n-  %}\n-\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\/\/ Or Long Register with Register\n-instruct orl_eReg(eRegL dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (OrL dst src));\n-  effect(KILL cr);\n-  format %{ \"OR     $dst.lo,$src.lo\\n\\t\"\n-            \"OR     $dst.hi,$src.hi\" %}\n-  opcode(0x0B,0x0B);\n-  ins_encode( RegReg_Lo( dst, src), RegReg_Hi( dst, src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Or Long Register with Immediate\n-instruct orl_eReg_imm(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst (OrL dst src));\n-  effect(KILL cr);\n-  format %{ \"OR     $dst.lo,$src.lo\\n\\t\"\n-            \"OR     $dst.hi,$src.hi\" %}\n-  opcode(0x81,0x01,0x01);  \/* Opcode 81 \/1, 81 \/1 *\/\n-  ins_encode( Long_OpcSErm_Lo( dst, src ), Long_OpcSErm_Hi( dst, src ) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Or Long Register with Memory\n-instruct orl_eReg_mem(eRegL dst, load_long_memory mem, eFlagsReg cr) %{\n-  match(Set dst (OrL dst (LoadL mem)));\n-  effect(KILL cr);\n-  ins_cost(125);\n-  format %{ \"OR     $dst.lo,$mem\\n\\t\"\n-            \"OR     $dst.hi,$mem+4\" %}\n-  opcode(0x0B,0x0B);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, mem), OpcS, RegMem_Hi(dst,mem), ClearInstMark );\n-  ins_pipe( ialu_reg_long_mem );\n-%}\n-\n-\/\/ Xor Long Register with Register\n-instruct xorl_eReg(eRegL dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (XorL dst src));\n-  effect(KILL cr);\n-  format %{ \"XOR    $dst.lo,$src.lo\\n\\t\"\n-            \"XOR    $dst.hi,$src.hi\" %}\n-  opcode(0x33,0x33);\n-  ins_encode( RegReg_Lo( dst, src), RegReg_Hi( dst, src) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Xor Long Register with Immediate -1\n-instruct xorl_eReg_im1(eRegL dst, immL_M1 imm) %{\n-  match(Set dst (XorL dst imm));\n-  format %{ \"NOT    $dst.lo\\n\\t\"\n-            \"NOT    $dst.hi\" %}\n-  ins_encode %{\n-     __ notl($dst$$Register);\n-     __ notl(HIGH_FROM_LOW($dst$$Register));\n-  %}\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Xor Long Register with Immediate\n-instruct xorl_eReg_imm(eRegL dst, immL src, eFlagsReg cr) %{\n-  match(Set dst (XorL dst src));\n-  effect(KILL cr);\n-  format %{ \"XOR    $dst.lo,$src.lo\\n\\t\"\n-            \"XOR    $dst.hi,$src.hi\" %}\n-  opcode(0x81,0x06,0x06);  \/* Opcode 81 \/6, 81 \/6 *\/\n-  ins_encode( Long_OpcSErm_Lo( dst, src ), Long_OpcSErm_Hi( dst, src ) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Xor Long Register with Memory\n-instruct xorl_eReg_mem(eRegL dst, load_long_memory mem, eFlagsReg cr) %{\n-  match(Set dst (XorL dst (LoadL mem)));\n-  effect(KILL cr);\n-  ins_cost(125);\n-  format %{ \"XOR    $dst.lo,$mem\\n\\t\"\n-            \"XOR    $dst.hi,$mem+4\" %}\n-  opcode(0x33,0x33);\n-  ins_encode( SetInstMark, OpcP, RegMem( dst, mem), OpcS, RegMem_Hi(dst,mem), ClearInstMark );\n-  ins_pipe( ialu_reg_long_mem );\n-%}\n-\n-\/\/ Shift Left Long by 1\n-instruct shlL_eReg_1(eRegL dst, immI_1 cnt, eFlagsReg cr) %{\n-  predicate(UseNewLongLShift);\n-  match(Set dst (LShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(100);\n-  format %{ \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-  %}\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Left Long by 2\n-instruct shlL_eReg_2(eRegL dst, immI_2 cnt, eFlagsReg cr) %{\n-  predicate(UseNewLongLShift);\n-  match(Set dst (LShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(100);\n-  format %{ \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\\n\\t\"\n-            \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-  %}\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Left Long by 3\n-instruct shlL_eReg_3(eRegL dst, immI_3 cnt, eFlagsReg cr) %{\n-  predicate(UseNewLongLShift);\n-  match(Set dst (LShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(100);\n-  format %{ \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\\n\\t\"\n-            \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\\n\\t\"\n-            \"ADD    $dst.lo,$dst.lo\\n\\t\"\n-            \"ADC    $dst.hi,$dst.hi\" %}\n-  ins_encode %{\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-    __ addl($dst$$Register,$dst$$Register);\n-    __ adcl(HIGH_FROM_LOW($dst$$Register),HIGH_FROM_LOW($dst$$Register));\n-  %}\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Left Long by 1-31\n-instruct shlL_eReg_1_31(eRegL dst, immI_1_31 cnt, eFlagsReg cr) %{\n-  match(Set dst (LShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"SHLD   $dst.hi,$dst.lo,$cnt\\n\\t\"\n-            \"SHL    $dst.lo,$cnt\" %}\n-  opcode(0xC1, 0x4, 0xA4);  \/* 0F\/A4, then C1 \/4 ib *\/\n-  ins_encode( move_long_small_shift(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Left Long by 32-63\n-instruct shlL_eReg_32_63(eRegL dst, immI_32_63 cnt, eFlagsReg cr) %{\n-  match(Set dst (LShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(300);\n-  format %{ \"MOV    $dst.hi,$dst.lo\\n\"\n-          \"\\tSHL    $dst.hi,$cnt-32\\n\"\n-          \"\\tXOR    $dst.lo,$dst.lo\" %}\n-  opcode(0xC1, 0x4);  \/* C1 \/4 ib *\/\n-  ins_encode( move_long_big_shift_clr(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Left Long by variable\n-instruct salL_eReg_CL(eRegL dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (LShiftL dst shift));\n-  effect(KILL cr);\n-  ins_cost(500+200);\n-  size(17);\n-  format %{ \"TEST   $shift,32\\n\\t\"\n-            \"JEQ,s  small\\n\\t\"\n-            \"MOV    $dst.hi,$dst.lo\\n\\t\"\n-            \"XOR    $dst.lo,$dst.lo\\n\"\n-    \"small:\\tSHLD   $dst.hi,$dst.lo,$shift\\n\\t\"\n-            \"SHL    $dst.lo,$shift\" %}\n-  ins_encode( shift_left_long( dst, shift ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Shift Right Long by 1-31\n-instruct shrL_eReg_1_31(eRegL dst, immI_1_31 cnt, eFlagsReg cr) %{\n-  match(Set dst (URShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"SHRD   $dst.lo,$dst.hi,$cnt\\n\\t\"\n-            \"SHR    $dst.hi,$cnt\" %}\n-  opcode(0xC1, 0x5, 0xAC);  \/* 0F\/AC, then C1 \/5 ib *\/\n-  ins_encode( move_long_small_shift(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Right Long by 32-63\n-instruct shrL_eReg_32_63(eRegL dst, immI_32_63 cnt, eFlagsReg cr) %{\n-  match(Set dst (URShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(300);\n-  format %{ \"MOV    $dst.lo,$dst.hi\\n\"\n-          \"\\tSHR    $dst.lo,$cnt-32\\n\"\n-          \"\\tXOR    $dst.hi,$dst.hi\" %}\n-  opcode(0xC1, 0x5);  \/* C1 \/5 ib *\/\n-  ins_encode( move_long_big_shift_clr(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Right Long by variable\n-instruct shrL_eReg_CL(eRegL dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (URShiftL dst shift));\n-  effect(KILL cr);\n-  ins_cost(600);\n-  size(17);\n-  format %{ \"TEST   $shift,32\\n\\t\"\n-            \"JEQ,s  small\\n\\t\"\n-            \"MOV    $dst.lo,$dst.hi\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\\n\"\n-    \"small:\\tSHRD   $dst.lo,$dst.hi,$shift\\n\\t\"\n-            \"SHR    $dst.hi,$shift\" %}\n-  ins_encode( shift_right_long( dst, shift ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Shift Right Long by 1-31\n-instruct sarL_eReg_1_31(eRegL dst, immI_1_31 cnt, eFlagsReg cr) %{\n-  match(Set dst (RShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(200);\n-  format %{ \"SHRD   $dst.lo,$dst.hi,$cnt\\n\\t\"\n-            \"SAR    $dst.hi,$cnt\" %}\n-  opcode(0xC1, 0x7, 0xAC);  \/* 0F\/AC, then C1 \/7 ib *\/\n-  ins_encode( move_long_small_shift(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Right Long by 32-63\n-instruct sarL_eReg_32_63( eRegL dst, immI_32_63 cnt, eFlagsReg cr) %{\n-  match(Set dst (RShiftL dst cnt));\n-  effect(KILL cr);\n-  ins_cost(300);\n-  format %{ \"MOV    $dst.lo,$dst.hi\\n\"\n-          \"\\tSAR    $dst.lo,$cnt-32\\n\"\n-          \"\\tSAR    $dst.hi,31\" %}\n-  opcode(0xC1, 0x7);  \/* C1 \/7 ib *\/\n-  ins_encode( move_long_big_shift_sign(dst,cnt) );\n-  ins_pipe( ialu_reg_long );\n-%}\n-\n-\/\/ Shift Right arithmetic Long by variable\n-instruct sarL_eReg_CL(eRegL dst, eCXRegI shift, eFlagsReg cr) %{\n-  match(Set dst (RShiftL dst shift));\n-  effect(KILL cr);\n-  ins_cost(600);\n-  size(18);\n-  format %{ \"TEST   $shift,32\\n\\t\"\n-            \"JEQ,s  small\\n\\t\"\n-            \"MOV    $dst.lo,$dst.hi\\n\\t\"\n-            \"SAR    $dst.hi,31\\n\"\n-    \"small:\\tSHRD   $dst.lo,$dst.hi,$shift\\n\\t\"\n-            \"SAR    $dst.hi,$shift\" %}\n-  ins_encode( shift_right_arith_long( dst, shift ) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/----------Double Instructions------------------------------------------------\n-\/\/ Double Math\n-\n-\/\/ Compare & branch\n-\n-\/\/ P6 version of float compare, sets condition codes in EFLAGS\n-instruct cmpDPR_cc_P6(eFlagsRegU cr, regDPR src1, regDPR src2, eAXRegI rax) %{\n-  predicate(VM_Version::supports_cmov() && UseSSE <=1);\n-  match(Set cr (CmpD src1 src2));\n-  effect(KILL rax);\n-  ins_cost(150);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FUCOMIP ST,$src2  \/\/ P6 instruction\\n\\t\"\n-            \"JNP    exit\\n\\t\"\n-            \"MOV    ah,1       \/\/ saw a NaN, set CF\\n\\t\"\n-            \"SAHF\\n\"\n-     \"exit:\\tNOP               \/\/ avoid branch to branch\" %}\n-  opcode(0xDF, 0x05); \/* DF E8+i or DF \/5 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              cmpF_P6_fixup );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpDPR_cc_P6CF(eFlagsRegUCF cr, regDPR src1, regDPR src2) %{\n-  predicate(VM_Version::supports_cmov() && UseSSE <=1);\n-  match(Set cr (CmpD src1 src2));\n-  ins_cost(150);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FUCOMIP ST,$src2  \/\/ P6 instruction\" %}\n-  opcode(0xDF, 0x05); \/* DF E8+i or DF \/5 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare & branch\n-instruct cmpDPR_cc(eFlagsRegU cr, regDPR src1, regDPR src2, eAXRegI rax) %{\n-  predicate(UseSSE<=1);\n-  match(Set cr (CmpD src1 src2));\n-  effect(KILL rax);\n-  ins_cost(200);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FCOMp  $src2\\n\\t\"\n-            \"FNSTSW AX\\n\\t\"\n-            \"TEST   AX,0x400\\n\\t\"\n-            \"JZ,s   flags\\n\\t\"\n-            \"MOV    AH,1\\t# unordered treat as LT\\n\"\n-    \"flags:\\tSAHF\" %}\n-  opcode(0xD8, 0x3); \/* D8 D8+i or D8 \/3 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              fpu_flags);\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare vs zero into -1,0,1\n-instruct cmpDPR_0(rRegI dst, regDPR src1, immDPR0 zero, eAXRegI rax, eFlagsReg cr) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (CmpD3 src1 zero));\n-  effect(KILL cr, KILL rax);\n-  ins_cost(280);\n-  format %{ \"FTSTD  $dst,$src1\" %}\n-  opcode(0xE4, 0xD9);\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcS, OpcP, PopFPU,\n-              CmpF_Result(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1\n-instruct cmpDPR_reg(rRegI dst, regDPR src1, regDPR src2, eAXRegI rax, eFlagsReg cr) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (CmpD3 src1 src2));\n-  effect(KILL cr, KILL rax);\n-  ins_cost(300);\n-  format %{ \"FCMPD  $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x3); \/* D8 D8+i or D8 \/3 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              CmpF_Result(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ float compare and set condition codes in EFLAGS by XMM regs\n-instruct cmpD_cc(eFlagsRegU cr, regD src1, regD src2) %{\n-  predicate(UseSSE>=2);\n-  match(Set cr (CmpD src1 src2));\n-  ins_cost(145);\n-  format %{ \"UCOMISD $src1,$src2\\n\\t\"\n-            \"JNP,s   exit\\n\\t\"\n-            \"PUSHF\\t# saw NaN, set CF\\n\\t\"\n-            \"AND     [rsp], #0xffffff2b\\n\\t\"\n-            \"POPF\\n\"\n-    \"exit:\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$XMMRegister);\n-    emit_cmpfp_fixup(masm);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpD_ccCF(eFlagsRegUCF cr, regD src1, regD src2) %{\n-  predicate(UseSSE>=2);\n-  match(Set cr (CmpD src1 src2));\n-  ins_cost(100);\n-  format %{ \"UCOMISD $src1,$src2\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ float compare and set condition codes in EFLAGS by XMM regs\n-instruct cmpD_ccmem(eFlagsRegU cr, regD src1, memory src2) %{\n-  predicate(UseSSE>=2);\n-  match(Set cr (CmpD src1 (LoadD src2)));\n-  ins_cost(145);\n-  format %{ \"UCOMISD $src1,$src2\\n\\t\"\n-            \"JNP,s   exit\\n\\t\"\n-            \"PUSHF\\t# saw NaN, set CF\\n\\t\"\n-            \"AND     [rsp], #0xffffff2b\\n\\t\"\n-            \"POPF\\n\"\n-    \"exit:\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$Address);\n-    emit_cmpfp_fixup(masm);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpD_ccmemCF(eFlagsRegUCF cr, regD src1, memory src2) %{\n-  predicate(UseSSE>=2);\n-  match(Set cr (CmpD src1 (LoadD src2)));\n-  ins_cost(100);\n-  format %{ \"UCOMISD $src1,$src2\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1 in XMM\n-instruct cmpD_reg(xRegI dst, regD src1, regD src2, eFlagsReg cr) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (CmpD3 src1 src2));\n-  effect(KILL cr);\n-  ins_cost(255);\n-  format %{ \"UCOMISD $src1, $src2\\n\\t\"\n-            \"MOV     $dst, #-1\\n\\t\"\n-            \"JP,s    done\\n\\t\"\n-            \"JB,s    done\\n\\t\"\n-            \"SETNE   $dst\\n\\t\"\n-            \"MOVZB   $dst, $dst\\n\"\n-    \"done:\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$XMMRegister);\n-    emit_cmpfp3(masm, $dst$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1 in XMM and memory\n-instruct cmpD_regmem(xRegI dst, regD src1, memory src2, eFlagsReg cr) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (CmpD3 src1 (LoadD src2)));\n-  effect(KILL cr);\n-  ins_cost(275);\n-  format %{ \"UCOMISD $src1, $src2\\n\\t\"\n-            \"MOV     $dst, #-1\\n\\t\"\n-            \"JP,s    done\\n\\t\"\n-            \"JB,s    done\\n\\t\"\n-            \"SETNE   $dst\\n\\t\"\n-            \"MOVZB   $dst, $dst\\n\"\n-    \"done:\" %}\n-  ins_encode %{\n-    __ ucomisd($src1$$XMMRegister, $src2$$Address);\n-    emit_cmpfp3(masm, $dst$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-instruct subDPR_reg(regDPR dst, regDPR src) %{\n-  predicate (UseSSE <=1);\n-  match(Set dst (SubD dst src));\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"DSUBp  $dst,ST\" %}\n-  opcode(0xDE, 0x5); \/* DE E8+i  or DE \/5 *\/\n-  ins_cost(150);\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct subDPR_reg_round(stackSlotD dst, regDPR src1, regDPR src2) %{\n-  predicate (UseSSE <=1);\n-  match(Set dst (RoundDouble (SubD src1 src2)));\n-  ins_cost(250);\n-\n-  format %{ \"FLD    $src2\\n\\t\"\n-            \"DSUB   ST,$src1\\n\\t\"\n-            \"FSTP_D $dst\\t# D-round\" %}\n-  opcode(0xD8, 0x5);\n-  ins_encode( Push_Reg_DPR(src2),\n-              OpcP, RegOpc(src1), Pop_Mem_DPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\n-\n-instruct subDPR_reg_mem(regDPR dst, memory src) %{\n-  predicate (UseSSE <=1);\n-  match(Set dst (SubD dst (LoadD src)));\n-  ins_cost(150);\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"DSUBp  $dst,ST\" %}\n-  opcode(0xDE, 0x5, 0xDD); \/* DE C0+i *\/  \/* LoadD  DD \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src),\n-              OpcP, RegOpc(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct absDPR_reg(regDPR1 dst, regDPR1 src) %{\n-  predicate (UseSSE<=1);\n-  match(Set dst (AbsD src));\n-  ins_cost(100);\n-  format %{ \"FABS\" %}\n-  opcode(0xE1, 0xD9);\n-  ins_encode( OpcS, OpcP );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct negDPR_reg(regDPR1 dst, regDPR1 src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (NegD src));\n-  ins_cost(100);\n-  format %{ \"FCHS\" %}\n-  opcode(0xE0, 0xD9);\n-  ins_encode( OpcS, OpcP );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct addDPR_reg(regDPR dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (AddD dst src));\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"DADD   $dst,ST\" %}\n-  size(4);\n-  ins_cost(150);\n-  opcode(0xDE, 0x0); \/* DE C0+i or DE \/0*\/\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\n-instruct addDPR_reg_round(stackSlotD dst, regDPR src1, regDPR src2) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (RoundDouble (AddD src1 src2)));\n-  ins_cost(250);\n-\n-  format %{ \"FLD    $src2\\n\\t\"\n-            \"DADD   ST,$src1\\n\\t\"\n-            \"FSTP_D $dst\\t# D-round\" %}\n-  opcode(0xD8, 0x0); \/* D8 C0+i or D8 \/0*\/\n-  ins_encode( Push_Reg_DPR(src2),\n-              OpcP, RegOpc(src1), Pop_Mem_DPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\n-\n-instruct addDPR_reg_mem(regDPR dst, memory src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (AddD dst (LoadD src)));\n-  ins_cost(150);\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"DADDp  $dst,ST\" %}\n-  opcode(0xDE, 0x0, 0xDD); \/* DE C0+i *\/  \/* LoadD  DD \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src),\n-              OpcP, RegOpc(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ add-to-memory\n-instruct addDPR_mem_reg(memory dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (StoreD dst (RoundDouble (AddD (LoadD dst) src))));\n-  ins_cost(150);\n-\n-  format %{ \"FLD_D  $dst\\n\\t\"\n-            \"DADD   ST,$src\\n\\t\"\n-            \"FST_D  $dst\" %}\n-  opcode(0xDD, 0x0);\n-  ins_encode( SetInstMark, Opcode(0xDD), RMopc_Mem(0x00,dst),\n-              Opcode(0xD8), RegOpc(src), ClearInstMark,\n-              SetInstMark,\n-              Opcode(0xDD), RMopc_Mem(0x03,dst),\n-              ClearInstMark);\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct addDPR_reg_imm1(regDPR dst, immDPR1 con) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (AddD dst con));\n-  ins_cost(125);\n-  format %{ \"FLD1\\n\\t\"\n-            \"DADDp  $dst,ST\" %}\n-  ins_encode %{\n-    __ fld1();\n-    __ faddp($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg);\n-%}\n-\n-instruct addDPR_reg_imm(regDPR dst, immDPR con) %{\n-  predicate(UseSSE<=1 && _kids[1]->_leaf->getd() != 0.0 && _kids[1]->_leaf->getd() != 1.0 );\n-  match(Set dst (AddD dst con));\n-  ins_cost(200);\n-  format %{ \"FLD_D  [$constantaddress]\\t# load from constant table: double=$con\\n\\t\"\n-            \"DADDp  $dst,ST\" %}\n-  ins_encode %{\n-    __ fld_d($constantaddress($con));\n-    __ faddp($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_mem);\n-%}\n-\n-instruct addDPR_reg_imm_round(stackSlotD dst, regDPR src, immDPR con) %{\n-  predicate(UseSSE<=1 && _kids[0]->_kids[1]->_leaf->getd() != 0.0 && _kids[0]->_kids[1]->_leaf->getd() != 1.0 );\n-  match(Set dst (RoundDouble (AddD src con)));\n-  ins_cost(200);\n-  format %{ \"FLD_D  [$constantaddress]\\t# load from constant table: double=$con\\n\\t\"\n-            \"DADD   ST,$src\\n\\t\"\n-            \"FSTP_D $dst\\t# D-round\" %}\n-  ins_encode %{\n-    __ fld_d($constantaddress($con));\n-    __ fadd($src$$reg);\n-    __ fstp_d(Address(rsp, $dst$$disp));\n-  %}\n-  ins_pipe(fpu_mem_reg_con);\n-%}\n-\n-instruct mulDPR_reg(regDPR dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (MulD dst src));\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"DMULp  $dst,ST\" %}\n-  opcode(0xDE, 0x1); \/* DE C8+i or DE \/1*\/\n-  ins_cost(150);\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Strict FP instruction biases argument before multiply then\n-\/\/ biases result to avoid double rounding of subnormals.\n-\/\/\n-\/\/ scale arg1 by multiplying arg1 by 2^(-15360)\n-\/\/ load arg2\n-\/\/ multiply scaled arg1 by arg2\n-\/\/ rescale product by 2^(15360)\n-\/\/\n-instruct strictfp_mulDPR_reg(regDPR1 dst, regnotDPR1 src) %{\n-  predicate( UseSSE<=1 && Compile::current()->has_method() );\n-  match(Set dst (MulD dst src));\n-  ins_cost(1);   \/\/ Select this instruction for all FP double multiplies\n-\n-  format %{ \"FLD    StubRoutines::x86::_fpu_subnormal_bias1\\n\\t\"\n-            \"DMULp  $dst,ST\\n\\t\"\n-            \"FLD    $src\\n\\t\"\n-            \"DMULp  $dst,ST\\n\\t\"\n-            \"FLD    StubRoutines::x86::_fpu_subnormal_bias2\\n\\t\"\n-            \"DMULp  $dst,ST\\n\\t\" %}\n-  opcode(0xDE, 0x1); \/* DE C8+i or DE \/1*\/\n-  ins_encode( strictfp_bias1(dst),\n-              Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst),\n-              strictfp_bias2(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct mulDPR_reg_imm(regDPR dst, immDPR con) %{\n-  predicate( UseSSE<=1 && _kids[1]->_leaf->getd() != 0.0 && _kids[1]->_leaf->getd() != 1.0 );\n-  match(Set dst (MulD dst con));\n-  ins_cost(200);\n-  format %{ \"FLD_D  [$constantaddress]\\t# load from constant table: double=$con\\n\\t\"\n-            \"DMULp  $dst,ST\" %}\n-  ins_encode %{\n-    __ fld_d($constantaddress($con));\n-    __ fmulp($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_mem);\n-%}\n-\n-\n-instruct mulDPR_reg_mem(regDPR dst, memory src) %{\n-  predicate( UseSSE<=1 );\n-  match(Set dst (MulD dst (LoadD src)));\n-  ins_cost(200);\n-  format %{ \"FLD_D  $src\\n\\t\"\n-            \"DMULp  $dst,ST\" %}\n-  opcode(0xDE, 0x1, 0xDD); \/* DE C8+i or DE \/1*\/  \/* LoadD  DD \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src),\n-              OpcP, RegOpc(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/\n-\/\/ Cisc-alternate to reg-reg multiply\n-instruct mulDPR_reg_mem_cisc(regDPR dst, regDPR src, memory mem) %{\n-  predicate( UseSSE<=1 );\n-  match(Set dst (MulD src (LoadD mem)));\n-  ins_cost(250);\n-  format %{ \"FLD_D  $mem\\n\\t\"\n-            \"DMUL   ST,$src\\n\\t\"\n-            \"FSTP_D $dst\" %}\n-  opcode(0xD8, 0x1, 0xD9); \/* D8 C8+i *\/  \/* LoadD D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,mem),\n-              OpcReg_FPR(src),\n-              Pop_Reg_DPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_reg_mem );\n-%}\n-\n-\n-\/\/ MACRO3 -- addDPR a mulDPR\n-\/\/ This instruction is a '2-address' instruction in that the result goes\n-\/\/ back to src2.  This eliminates a move from the macro; possibly the\n-\/\/ register allocator will have to add it back (and maybe not).\n-instruct addDPR_mulDPR_reg(regDPR src2, regDPR src1, regDPR src0) %{\n-  predicate( UseSSE<=1 );\n-  match(Set src2 (AddD (MulD src0 src1) src2));\n-  format %{ \"FLD    $src0\\t# ===MACRO3d===\\n\\t\"\n-            \"DMUL   ST,$src1\\n\\t\"\n-            \"DADDp  $src2,ST\" %}\n-  ins_cost(250);\n-  opcode(0xDD); \/* LoadD DD \/0 *\/\n-  ins_encode( Push_Reg_FPR(src0),\n-              FMul_ST_reg(src1),\n-              FAddP_reg_ST(src2) );\n-  ins_pipe( fpu_reg_reg_reg );\n-%}\n-\n-\n-\/\/ MACRO3 -- subDPR a mulDPR\n-instruct subDPR_mulDPR_reg(regDPR src2, regDPR src1, regDPR src0) %{\n-  predicate( UseSSE<=1 );\n-  match(Set src2 (SubD (MulD src0 src1) src2));\n-  format %{ \"FLD    $src0\\t# ===MACRO3d===\\n\\t\"\n-            \"DMUL   ST,$src1\\n\\t\"\n-            \"DSUBRp $src2,ST\" %}\n-  ins_cost(250);\n-  ins_encode( Push_Reg_FPR(src0),\n-              FMul_ST_reg(src1),\n-              Opcode(0xDE), Opc_plus(0xE0,src2));\n-  ins_pipe( fpu_reg_reg_reg );\n-%}\n-\n-\n-instruct divDPR_reg(regDPR dst, regDPR src) %{\n-  predicate( UseSSE<=1 );\n-  match(Set dst (DivD dst src));\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FDIVp  $dst,ST\" %}\n-  opcode(0xDE, 0x7); \/* DE F8+i or DE \/7*\/\n-  ins_cost(150);\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Strict FP instruction biases argument before division then\n-\/\/ biases result, to avoid double rounding of subnormals.\n-\/\/\n-\/\/ scale dividend by multiplying dividend by 2^(-15360)\n-\/\/ load divisor\n-\/\/ divide scaled dividend by divisor\n-\/\/ rescale quotient by 2^(15360)\n-\/\/\n-instruct strictfp_divDPR_reg(regDPR1 dst, regnotDPR1 src) %{\n-  predicate (UseSSE<=1);\n-  match(Set dst (DivD dst src));\n-  predicate( UseSSE<=1 && Compile::current()->has_method() );\n-  ins_cost(01);\n-\n-  format %{ \"FLD    StubRoutines::x86::_fpu_subnormal_bias1\\n\\t\"\n-            \"DMULp  $dst,ST\\n\\t\"\n-            \"FLD    $src\\n\\t\"\n-            \"FDIVp  $dst,ST\\n\\t\"\n-            \"FLD    StubRoutines::x86::_fpu_subnormal_bias2\\n\\t\"\n-            \"DMULp  $dst,ST\\n\\t\" %}\n-  opcode(0xDE, 0x7); \/* DE F8+i or DE \/7*\/\n-  ins_encode( strictfp_bias1(dst),\n-              Push_Reg_DPR(src),\n-              OpcP, RegOpc(dst),\n-              strictfp_bias2(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct atanDPR_reg(regDPR dst, regDPR src) %{\n-  predicate (UseSSE<=1);\n-  match(Set dst(AtanD dst src));\n-  format %{ \"DATA   $dst,$src\" %}\n-  opcode(0xD9, 0xF3);\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcP, OpcS, RegOpc(dst) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct atanD_reg(regD dst, regD src, eFlagsReg cr) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst(AtanD dst src));\n-  effect(KILL cr); \/\/ Push_{Src|Result}D() uses \"{SUB|ADD} ESP,8\"\n-  format %{ \"DATA   $dst,$src\" %}\n-  opcode(0xD9, 0xF3);\n-  ins_encode( Push_SrcD(src),\n-              OpcP, OpcS, Push_ResultD(dst) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct sqrtDPR_reg(regDPR dst, regDPR src) %{\n-  predicate (UseSSE<=1);\n-  match(Set dst (SqrtD src));\n-  format %{ \"DSQRT  $dst,$src\" %}\n-  opcode(0xFA, 0xD9);\n-  ins_encode( Push_Reg_DPR(src),\n-              OpcS, OpcP, Pop_Reg_DPR(dst) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/-------------Float Instructions-------------------------------\n-\/\/ Float Math\n-\n-\/\/ Code for float compare:\n-\/\/     fcompp();\n-\/\/     fwait(); fnstsw_ax();\n-\/\/     sahf();\n-\/\/     movl(dst, unordered_result);\n-\/\/     jcc(Assembler::parity, exit);\n-\/\/     movl(dst, less_result);\n-\/\/     jcc(Assembler::below, exit);\n-\/\/     movl(dst, equal_result);\n-\/\/     jcc(Assembler::equal, exit);\n-\/\/     movl(dst, greater_result);\n-\/\/   exit:\n-\n-\/\/ P6 version of float compare, sets condition codes in EFLAGS\n-instruct cmpFPR_cc_P6(eFlagsRegU cr, regFPR src1, regFPR src2, eAXRegI rax) %{\n-  predicate(VM_Version::supports_cmov() && UseSSE == 0);\n-  match(Set cr (CmpF src1 src2));\n-  effect(KILL rax);\n-  ins_cost(150);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FUCOMIP ST,$src2  \/\/ P6 instruction\\n\\t\"\n-            \"JNP    exit\\n\\t\"\n-            \"MOV    ah,1       \/\/ saw a NaN, set CF (treat as LT)\\n\\t\"\n-            \"SAHF\\n\"\n-     \"exit:\\tNOP               \/\/ avoid branch to branch\" %}\n-  opcode(0xDF, 0x05); \/* DF E8+i or DF \/5 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              cmpF_P6_fixup );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpFPR_cc_P6CF(eFlagsRegUCF cr, regFPR src1, regFPR src2) %{\n-  predicate(VM_Version::supports_cmov() && UseSSE == 0);\n-  match(Set cr (CmpF src1 src2));\n-  ins_cost(100);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FUCOMIP ST,$src2  \/\/ P6 instruction\" %}\n-  opcode(0xDF, 0x05); \/* DF E8+i or DF \/5 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ Compare & branch\n-instruct cmpFPR_cc(eFlagsRegU cr, regFPR src1, regFPR src2, eAXRegI rax) %{\n-  predicate(UseSSE == 0);\n-  match(Set cr (CmpF src1 src2));\n-  effect(KILL rax);\n-  ins_cost(200);\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FCOMp  $src2\\n\\t\"\n-            \"FNSTSW AX\\n\\t\"\n-            \"TEST   AX,0x400\\n\\t\"\n-            \"JZ,s   flags\\n\\t\"\n-            \"MOV    AH,1\\t# unordered treat as LT\\n\"\n-    \"flags:\\tSAHF\" %}\n-  opcode(0xD8, 0x3); \/* D8 D8+i or D8 \/3 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              fpu_flags);\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare vs zero into -1,0,1\n-instruct cmpFPR_0(rRegI dst, regFPR src1, immFPR0 zero, eAXRegI rax, eFlagsReg cr) %{\n-  predicate(UseSSE == 0);\n-  match(Set dst (CmpF3 src1 zero));\n-  effect(KILL cr, KILL rax);\n-  ins_cost(280);\n-  format %{ \"FTSTF  $dst,$src1\" %}\n-  opcode(0xE4, 0xD9);\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcS, OpcP, PopFPU,\n-              CmpF_Result(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1\n-instruct cmpFPR_reg(rRegI dst, regFPR src1, regFPR src2, eAXRegI rax, eFlagsReg cr) %{\n-  predicate(UseSSE == 0);\n-  match(Set dst (CmpF3 src1 src2));\n-  effect(KILL cr, KILL rax);\n-  ins_cost(300);\n-  format %{ \"FCMPF  $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x3); \/* D8 D8+i or D8 \/3 *\/\n-  ins_encode( Push_Reg_DPR(src1),\n-              OpcP, RegOpc(src2),\n-              CmpF_Result(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ float compare and set condition codes in EFLAGS by XMM regs\n-instruct cmpF_cc(eFlagsRegU cr, regF src1, regF src2) %{\n-  predicate(UseSSE>=1);\n-  match(Set cr (CmpF src1 src2));\n-  ins_cost(145);\n-  format %{ \"UCOMISS $src1,$src2\\n\\t\"\n-            \"JNP,s   exit\\n\\t\"\n-            \"PUSHF\\t# saw NaN, set CF\\n\\t\"\n-            \"AND     [rsp], #0xffffff2b\\n\\t\"\n-            \"POPF\\n\"\n-    \"exit:\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$XMMRegister);\n-    emit_cmpfp_fixup(masm);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpF_ccCF(eFlagsRegUCF cr, regF src1, regF src2) %{\n-  predicate(UseSSE>=1);\n-  match(Set cr (CmpF src1 src2));\n-  ins_cost(100);\n-  format %{ \"UCOMISS $src1,$src2\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ float compare and set condition codes in EFLAGS by XMM regs\n-instruct cmpF_ccmem(eFlagsRegU cr, regF src1, memory src2) %{\n-  predicate(UseSSE>=1);\n-  match(Set cr (CmpF src1 (LoadF src2)));\n-  ins_cost(165);\n-  format %{ \"UCOMISS $src1,$src2\\n\\t\"\n-            \"JNP,s   exit\\n\\t\"\n-            \"PUSHF\\t# saw NaN, set CF\\n\\t\"\n-            \"AND     [rsp], #0xffffff2b\\n\\t\"\n-            \"POPF\\n\"\n-    \"exit:\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$Address);\n-    emit_cmpfp_fixup(masm);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct cmpF_ccmemCF(eFlagsRegUCF cr, regF src1, memory src2) %{\n-  predicate(UseSSE>=1);\n-  match(Set cr (CmpF src1 (LoadF src2)));\n-  ins_cost(100);\n-  format %{ \"UCOMISS $src1,$src2\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1 in XMM\n-instruct cmpF_reg(xRegI dst, regF src1, regF src2, eFlagsReg cr) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (CmpF3 src1 src2));\n-  effect(KILL cr);\n-  ins_cost(255);\n-  format %{ \"UCOMISS $src1, $src2\\n\\t\"\n-            \"MOV     $dst, #-1\\n\\t\"\n-            \"JP,s    done\\n\\t\"\n-            \"JB,s    done\\n\\t\"\n-            \"SETNE   $dst\\n\\t\"\n-            \"MOVZB   $dst, $dst\\n\"\n-    \"done:\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$XMMRegister);\n-    emit_cmpfp3(masm, $dst$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Compare into -1,0,1 in XMM and memory\n-instruct cmpF_regmem(xRegI dst, regF src1, memory src2, eFlagsReg cr) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (CmpF3 src1 (LoadF src2)));\n-  effect(KILL cr);\n-  ins_cost(275);\n-  format %{ \"UCOMISS $src1, $src2\\n\\t\"\n-            \"MOV     $dst, #-1\\n\\t\"\n-            \"JP,s    done\\n\\t\"\n-            \"JB,s    done\\n\\t\"\n-            \"SETNE   $dst\\n\\t\"\n-            \"MOVZB   $dst, $dst\\n\"\n-    \"done:\" %}\n-  ins_encode %{\n-    __ ucomiss($src1$$XMMRegister, $src2$$Address);\n-    emit_cmpfp3(masm, $dst$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct subFPR24_reg(stackSlotF dst, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (SubF src1 src2));\n-\n-  format %{ \"FSUB   $dst,$src1 - $src2\" %}\n-  opcode(0xD8, 0x4); \/* D8 E0+i or D8 \/4 mod==0x3 ;; result in TOS *\/\n-  ins_encode( Push_Reg_FPR(src1),\n-              OpcReg_FPR(src2),\n-              Pop_Mem_FPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct subFPR_reg(regFPR dst, regFPR src) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (SubF dst src));\n-\n-  format %{ \"FSUB   $dst,$src\" %}\n-  opcode(0xDE, 0x5); \/* DE E8+i  or DE \/5 *\/\n-  ins_encode( Push_Reg_FPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_reg(stackSlotF dst, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src1 src2));\n-\n-  format %{ \"FADD   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x0); \/* D8 C0+i *\/\n-  ins_encode( Push_Reg_FPR(src2),\n-              OpcReg_FPR(src1),\n-              Pop_Mem_FPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct addFPR_reg(regFPR dst, regFPR src) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF dst src));\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FADDp  $dst,ST\" %}\n-  opcode(0xDE, 0x0); \/* DE C0+i or DE \/0*\/\n-  ins_encode( Push_Reg_FPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct absFPR_reg(regFPR1 dst, regFPR1 src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (AbsF src));\n-  ins_cost(100);\n-  format %{ \"FABS\" %}\n-  opcode(0xE1, 0xD9);\n-  ins_encode( OpcS, OpcP );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct negFPR_reg(regFPR1 dst, regFPR1 src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (NegF src));\n-  ins_cost(100);\n-  format %{ \"FCHS\" %}\n-  opcode(0xE0, 0xD9);\n-  ins_encode( OpcS, OpcP );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\/\/ Cisc-alternate to addFPR_reg\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_reg_mem(stackSlotF dst, regFPR src1, memory src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src1 (LoadF src2)));\n-\n-  format %{ \"FLD    $src2\\n\\t\"\n-            \"FADD   ST,$src1\\n\\t\"\n-            \"FSTP_S $dst\" %}\n-  opcode(0xD8, 0x0, 0xD9); \/* D8 C0+i *\/  \/* LoadF  D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcReg_FPR(src1),\n-              Pop_Mem_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_mem_reg_mem );\n-%}\n-\/\/\n-\/\/ Cisc-alternate to addFPR_reg\n-\/\/ This instruction does not round to 24-bits\n-instruct addFPR_reg_mem(regFPR dst, memory src) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF dst (LoadF src)));\n-\n-  format %{ \"FADD   $dst,$src\" %}\n-  opcode(0xDE, 0x0, 0xD9); \/* DE C0+i or DE \/0*\/  \/* LoadF  D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src),\n-              OpcP, RegOpc(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ \/\/ Following two instructions for _222_mpegaudio\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_mem_reg(stackSlotF dst, regFPR src2, memory src1 ) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src1 src2));\n-\n-  format %{ \"FADD   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x0, 0xD9); \/* D8 C0+i *\/  \/* LoadF  D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src1),\n-              OpcReg_FPR(src2),\n-              Pop_Mem_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_mem_reg_mem );\n-%}\n-\n-\/\/ Cisc-spill variant\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_mem_cisc(stackSlotF dst, memory src1, memory src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src1 (LoadF src2)));\n-\n-  format %{ \"FADD   $dst,$src1,$src2 cisc\" %}\n-  opcode(0xD8, 0x0, 0xD9); \/* D8 C0+i *\/  \/* LoadF  D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcP, RMopc_Mem(secondary,src1),\n-              Pop_Mem_FPR(dst),\n-              ClearInstMark);\n-  ins_pipe( fpu_mem_mem_mem );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_mem_mem(stackSlotF dst, memory src1, memory src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src1 src2));\n-\n-  format %{ \"FADD   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x0, 0xD9); \/* D8 \/0 *\/  \/* LoadF  D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcP, RMopc_Mem(secondary,src1),\n-              Pop_Mem_FPR(dst),\n-              ClearInstMark);\n-  ins_pipe( fpu_mem_mem_mem );\n-%}\n-\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct addFPR24_reg_imm(stackSlotF dst, regFPR src, immFPR con) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src con));\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FADD_S [$constantaddress]\\t# load from constant table: float=$con\\n\\t\"\n-            \"FSTP_S $dst\"  %}\n-  ins_encode %{\n-    __ fld_s($src$$reg - 1);  \/\/ FLD ST(i-1)\n-    __ fadd_s($constantaddress($con));\n-    __ fstp_s(Address(rsp, $dst$$disp));\n-  %}\n-  ins_pipe(fpu_mem_reg_con);\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct addFPR_reg_imm(regFPR dst, regFPR src, immFPR con) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF src con));\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FADD_S [$constantaddress]\\t# load from constant table: float=$con\\n\\t\"\n-            \"FSTP   $dst\"  %}\n-  ins_encode %{\n-    __ fld_s($src$$reg - 1);  \/\/ FLD ST(i-1)\n-    __ fadd_s($constantaddress($con));\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_reg_con);\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct mulFPR24_reg(stackSlotF dst, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src1 src2));\n-\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FMUL   $src2\\n\\t\"\n-            \"FSTP_S $dst\"  %}\n-  opcode(0xD8, 0x1); \/* D8 C8+i or D8 \/1 ;; result in TOS *\/\n-  ins_encode( Push_Reg_FPR(src1),\n-              OpcReg_FPR(src2),\n-              Pop_Mem_FPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct mulFPR_reg(regFPR dst, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src1 src2));\n-\n-  format %{ \"FLD    $src1\\n\\t\"\n-            \"FMUL   $src2\\n\\t\"\n-            \"FSTP_S $dst\"  %}\n-  opcode(0xD8, 0x1); \/* D8 C8+i *\/\n-  ins_encode( Push_Reg_FPR(src2),\n-              OpcReg_FPR(src1),\n-              Pop_Reg_FPR(dst) );\n-  ins_pipe( fpu_reg_reg_reg );\n-%}\n-\n-\n-\/\/ Spill to obtain 24-bit precision\n-\/\/ Cisc-alternate to reg-reg multiply\n-instruct mulFPR24_reg_mem(stackSlotF dst, regFPR src1, memory src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src1 (LoadF src2)));\n-\n-  format %{ \"FLD_S  $src2\\n\\t\"\n-            \"FMUL   $src1\\n\\t\"\n-            \"FSTP_S $dst\"  %}\n-  opcode(0xD8, 0x1, 0xD9); \/* D8 C8+i or DE \/1*\/  \/* LoadF D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcReg_FPR(src1),\n-              Pop_Mem_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_mem_reg_mem );\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-\/\/ Cisc-alternate to reg-reg multiply\n-instruct mulFPR_reg_mem(regFPR dst, regFPR src1, memory src2) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src1 (LoadF src2)));\n-\n-  format %{ \"FMUL   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x1, 0xD9); \/* D8 C8+i *\/  \/* LoadF D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcReg_FPR(src1),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_reg_mem );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct mulFPR24_mem_mem(stackSlotF dst, memory src1, memory src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src1 src2));\n-\n-  format %{ \"FMUL   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x1, 0xD9); \/* D8 \/1 *\/  \/* LoadF D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,src2),\n-              OpcP, RMopc_Mem(secondary,src1),\n-              Pop_Mem_FPR(dst),\n-              ClearInstMark );\n-  ins_pipe( fpu_mem_mem_mem );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct mulFPR24_reg_imm(stackSlotF dst, regFPR src, immFPR con) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src con));\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FMUL_S [$constantaddress]\\t# load from constant table: float=$con\\n\\t\"\n-            \"FSTP_S $dst\"  %}\n-  ins_encode %{\n-    __ fld_s($src$$reg - 1);  \/\/ FLD ST(i-1)\n-    __ fmul_s($constantaddress($con));\n-    __ fstp_s(Address(rsp, $dst$$disp));\n-  %}\n-  ins_pipe(fpu_mem_reg_con);\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct mulFPR_reg_imm(regFPR dst, regFPR src, immFPR con) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF src con));\n-\n-  format %{ \"FLD    $src\\n\\t\"\n-            \"FMUL_S [$constantaddress]\\t# load from constant table: float=$con\\n\\t\"\n-            \"FSTP   $dst\"  %}\n-  ins_encode %{\n-    __ fld_s($src$$reg - 1);  \/\/ FLD ST(i-1)\n-    __ fmul_s($constantaddress($con));\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe(fpu_reg_reg_con);\n-%}\n-\n-\n-\/\/\n-\/\/ MACRO1 -- subsume unshared load into mulFPR\n-\/\/ This instruction does not round to 24-bits\n-instruct mulFPR_reg_load1(regFPR dst, regFPR src, memory mem1 ) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (MulF (LoadF mem1) src));\n-\n-  format %{ \"FLD    $mem1    ===MACRO1===\\n\\t\"\n-            \"FMUL   ST,$src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xD8, 0x1, 0xD9); \/* D8 C8+i or D8 \/1 *\/  \/* LoadF D9 \/0 *\/\n-  ins_encode( SetInstMark, Opcode(tertiary), RMopc_Mem(0x00,mem1),\n-              OpcReg_FPR(src),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_reg_mem );\n-%}\n-\/\/\n-\/\/ MACRO2 -- addFPR a mulFPR which subsumed an unshared load\n-\/\/ This instruction does not round to 24-bits\n-instruct addFPR_mulFPR_reg_load1(regFPR dst, memory mem1, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (AddF (MulF (LoadF mem1) src1) src2));\n-  ins_cost(95);\n-\n-  format %{ \"FLD    $mem1     ===MACRO2===\\n\\t\"\n-            \"FMUL   ST,$src1  subsume mulFPR left load\\n\\t\"\n-            \"FADD   ST,$src2\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xD9); \/* LoadF D9 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem1),\n-              FMul_ST_reg(src1),\n-              FAdd_ST_reg(src2),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem_reg_reg );\n-%}\n-\n-\/\/ MACRO3 -- addFPR a mulFPR\n-\/\/ This instruction does not round to 24-bits.  It is a '2-address'\n-\/\/ instruction in that the result goes back to src2.  This eliminates\n-\/\/ a move from the macro; possibly the register allocator will have\n-\/\/ to add it back (and maybe not).\n-instruct addFPR_mulFPR_reg(regFPR src2, regFPR src1, regFPR src0) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set src2 (AddF (MulF src0 src1) src2));\n-\n-  format %{ \"FLD    $src0     ===MACRO3===\\n\\t\"\n-            \"FMUL   ST,$src1\\n\\t\"\n-            \"FADDP  $src2,ST\" %}\n-  opcode(0xD9); \/* LoadF D9 \/0 *\/\n-  ins_encode( Push_Reg_FPR(src0),\n-              FMul_ST_reg(src1),\n-              FAddP_reg_ST(src2) );\n-  ins_pipe( fpu_reg_reg_reg );\n-%}\n-\n-\/\/ MACRO4 -- divFPR subFPR\n-\/\/ This instruction does not round to 24-bits\n-instruct subFPR_divFPR_reg(regFPR dst, regFPR src1, regFPR src2, regFPR src3) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (DivF (SubF src2 src1) src3));\n-\n-  format %{ \"FLD    $src2   ===MACRO4===\\n\\t\"\n-            \"FSUB   ST,$src1\\n\\t\"\n-            \"FDIV   ST,$src3\\n\\t\"\n-            \"FSTP  $dst\" %}\n-  opcode(0xDE, 0x7); \/* DE F8+i or DE \/7*\/\n-  ins_encode( Push_Reg_FPR(src2),\n-              subFPR_divFPR_encode(src1,src3),\n-              Pop_Reg_FPR(dst) );\n-  ins_pipe( fpu_reg_reg_reg_reg );\n-%}\n-\n-\/\/ Spill to obtain 24-bit precision\n-instruct divFPR24_reg(stackSlotF dst, regFPR src1, regFPR src2) %{\n-  predicate(UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (DivF src1 src2));\n-\n-  format %{ \"FDIV   $dst,$src1,$src2\" %}\n-  opcode(0xD8, 0x6); \/* D8 F0+i or DE \/6*\/\n-  ins_encode( Push_Reg_FPR(src1),\n-              OpcReg_FPR(src2),\n-              Pop_Mem_FPR(dst) );\n-  ins_pipe( fpu_mem_reg_reg );\n-%}\n-\/\/\n-\/\/ This instruction does not round to 24-bits\n-instruct divFPR_reg(regFPR dst, regFPR src) %{\n-  predicate(UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (DivF dst src));\n-\n-  format %{ \"FDIV   $dst,$src\" %}\n-  opcode(0xDE, 0x7); \/* DE F8+i or DE \/7*\/\n-  ins_encode( Push_Reg_FPR(src),\n-              OpcP, RegOpc(dst) );\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-\n-\/\/----------Arithmetic Conversion Instructions---------------------------------\n-\/\/ The conversions operations are all Alpha sorted.  Please keep it that way!\n-\n-instruct roundFloat_mem_reg(stackSlotF dst, regFPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (RoundFloat src));\n-  ins_cost(125);\n-  format %{ \"FST_S  $dst,$src\\t# F-round\" %}\n-  ins_encode( Pop_Mem_Reg_FPR(dst, src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-instruct roundDouble_mem_reg(stackSlotD dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (RoundDouble src));\n-  ins_cost(125);\n-  format %{ \"FST_D  $dst,$src\\t# D-round\" %}\n-  ins_encode( Pop_Mem_Reg_DPR(dst, src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-\/\/ Force rounding to 24-bit precision and 6-bit exponent\n-instruct convDPR2FPR_reg(stackSlotF dst, regDPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (ConvD2F src));\n-  format %{ \"FST_S  $dst,$src\\t# F-round\" %}\n-  expand %{\n-    roundFloat_mem_reg(dst,src);\n-  %}\n-%}\n-\n-\/\/ Force rounding to 24-bit precision and 6-bit exponent\n-instruct convDPR2F_reg(regF dst, regDPR src, eFlagsReg cr) %{\n-  predicate(UseSSE==1);\n-  match(Set dst (ConvD2F src));\n-  effect( KILL cr );\n-  format %{ \"SUB    ESP,4\\n\\t\"\n-            \"FST_S  [ESP],$src\\t# F-round\\n\\t\"\n-            \"MOVSS  $dst,[ESP]\\n\\t\"\n-            \"ADD ESP,4\" %}\n-  ins_encode %{\n-    __ subptr(rsp, 4);\n-    if ($src$$reg != FPR1L_enc) {\n-      __ fld_s($src$$reg-1);\n-      __ fstp_s(Address(rsp, 0));\n-    } else {\n-      __ fst_s(Address(rsp, 0));\n-    }\n-    __ movflt($dst$$XMMRegister, Address(rsp, 0));\n-    __ addptr(rsp, 4);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Force rounding double precision to single precision\n-instruct convD2F_reg(regF dst, regD src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (ConvD2F src));\n-  format %{ \"CVTSD2SS $dst,$src\\t# F-round\" %}\n-  ins_encode %{\n-    __ cvtsd2ss ($dst$$XMMRegister, $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convFPR2DPR_reg_reg(regDPR dst, regFPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (ConvF2D src));\n-  format %{ \"FST_S  $dst,$src\\t# D-round\" %}\n-  ins_encode( Pop_Reg_Reg_DPR(dst, src));\n-  ins_pipe( fpu_reg_reg );\n-%}\n-\n-instruct convFPR2D_reg(stackSlotD dst, regFPR src) %{\n-  predicate(UseSSE==1);\n-  match(Set dst (ConvF2D src));\n-  format %{ \"FST_D  $dst,$src\\t# D-round\" %}\n-  expand %{\n-    roundDouble_mem_reg(dst,src);\n-  %}\n-%}\n-\n-instruct convF2DPR_reg(regDPR dst, regF src, eFlagsReg cr) %{\n-  predicate(UseSSE==1);\n-  match(Set dst (ConvF2D src));\n-  effect( KILL cr );\n-  format %{ \"SUB    ESP,4\\n\\t\"\n-            \"MOVSS  [ESP] $src\\n\\t\"\n-            \"FLD_S  [ESP]\\n\\t\"\n-            \"ADD    ESP,4\\n\\t\"\n-            \"FSTP   $dst\\t# D-round\" %}\n-  ins_encode %{\n-    __ subptr(rsp, 4);\n-    __ movflt(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_s(Address(rsp, 0));\n-    __ addptr(rsp, 4);\n-    __ fstp_d($dst$$reg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convF2D_reg(regD dst, regF src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (ConvF2D src));\n-  format %{ \"CVTSS2SD $dst,$src\\t# D-round\" %}\n-  ins_encode %{\n-    __ cvtss2sd ($dst$$XMMRegister, $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Convert a double to an int.  If the double is a NAN, stuff a zero in instead.\n-instruct convDPR2I_reg_reg( eAXRegI dst, eDXRegI tmp, regDPR src, eFlagsReg cr ) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (ConvD2I src));\n-  effect( KILL tmp, KILL cr );\n-  format %{ \"FLD    $src\\t# Convert double to int \\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"SUB    ESP,4\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"CMP    EAX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"FLD_D  $src\\n\\t\"\n-            \"CALL   d2i_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode( Push_Reg_DPR(src), DPR2I_encoding(src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Convert a double to an int.  If the double is a NAN, stuff a zero in instead.\n-instruct convD2I_reg_reg( eAXRegI dst, eDXRegI tmp, regD src, eFlagsReg cr ) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (ConvD2I src));\n-  effect( KILL tmp, KILL cr );\n-  format %{ \"CVTTSD2SI $dst, $src\\n\\t\"\n-            \"CMP    $dst,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"SUB    ESP, 8\\n\\t\"\n-            \"MOVSD  [ESP], $src\\n\\t\"\n-            \"FLD_D  [ESP]\\n\\t\"\n-            \"ADD    ESP, 8\\n\\t\"\n-            \"CALL   d2i_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode %{\n-    Label fast;\n-    __ cvttsd2sil($dst$$Register, $src$$XMMRegister);\n-    __ cmpl($dst$$Register, 0x80000000);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ subptr(rsp, 8);\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-    __ addptr(rsp, 8);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::x86::d2i_wrapper())));\n-    __ post_call_nop();\n-    __ bind(fast);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convDPR2L_reg_reg( eADXRegL dst, regDPR src, eFlagsReg cr ) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (ConvD2L src));\n-  effect( KILL cr );\n-  format %{ \"FLD    $src\\t# Convert double to long\\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"SUB    ESP,8\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"POP    EDX\\n\\t\"\n-            \"CMP    EDX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"TEST   EAX,EAX\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"FLD    $src\\n\\t\"\n-            \"CALL   d2l_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode( Push_Reg_DPR(src),  DPR2L_encoding(src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ XMM lacks a float\/double->long conversion, so use the old FPU stack.\n-instruct convD2L_reg_reg( eADXRegL dst, regD src, eFlagsReg cr ) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst (ConvD2L src));\n-  effect( KILL cr );\n-  format %{ \"SUB    ESP,8\\t# Convert double to long\\n\\t\"\n-            \"MOVSD  [ESP],$src\\n\\t\"\n-            \"FLD_D  [ESP]\\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"POP    EDX\\n\\t\"\n-            \"CMP    EDX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"TEST   EAX,EAX\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"SUB    ESP,8\\n\\t\"\n-            \"MOVSD  [ESP],$src\\n\\t\"\n-            \"FLD_D  [ESP]\\n\\t\"\n-            \"ADD    ESP,8\\n\\t\"\n-            \"CALL   d2l_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode %{\n-    Label fast;\n-    __ subptr(rsp, 8);\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_trunc()));\n-    __ fistp_d(Address(rsp, 0));\n-    \/\/ Restore the rounding mode, mask the exception\n-    if (Compile::current()->in_24_bit_fp_mode()) {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_24()));\n-    } else {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-    }\n-    \/\/ Load the converted long, adjust CPU stack\n-    __ pop(rax);\n-    __ pop(rdx);\n-    __ cmpl(rdx, 0x80000000);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ testl(rax, rax);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ subptr(rsp, 8);\n-    __ movdbl(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_d(Address(rsp, 0));\n-    __ addptr(rsp, 8);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::x86::d2l_wrapper())));\n-    __ post_call_nop();\n-    __ bind(fast);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Convert a double to an int.  Java semantics require we do complex\n-\/\/ manglations in the corner cases.  So we set the rounding mode to\n-\/\/ 'zero', store the darned double down as an int, and reset the\n-\/\/ rounding mode to 'nearest'.  The hardware stores a flag value down\n-\/\/ if we would overflow or converted a NAN; we check for this and\n-\/\/ and go the slow path if needed.\n-instruct convFPR2I_reg_reg(eAXRegI dst, eDXRegI tmp, regFPR src, eFlagsReg cr ) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (ConvF2I src));\n-  effect( KILL tmp, KILL cr );\n-  format %{ \"FLD    $src\\t# Convert float to int \\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"SUB    ESP,4\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"CMP    EAX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"FLD    $src\\n\\t\"\n-            \"CALL   d2i_wrapper\\n\"\n-      \"fast:\" %}\n-  \/\/ DPR2I_encoding works for FPR2I\n-  ins_encode( Push_Reg_FPR(src), DPR2I_encoding(src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Convert a float in xmm to an int reg.\n-instruct convF2I_reg(eAXRegI dst, eDXRegI tmp, regF src, eFlagsReg cr ) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (ConvF2I src));\n-  effect( KILL tmp, KILL cr );\n-  format %{ \"CVTTSS2SI $dst, $src\\n\\t\"\n-            \"CMP    $dst,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"SUB    ESP, 4\\n\\t\"\n-            \"MOVSS  [ESP], $src\\n\\t\"\n-            \"FLD    [ESP]\\n\\t\"\n-            \"ADD    ESP, 4\\n\\t\"\n-            \"CALL   d2i_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode %{\n-    Label fast;\n-    __ cvttss2sil($dst$$Register, $src$$XMMRegister);\n-    __ cmpl($dst$$Register, 0x80000000);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ subptr(rsp, 4);\n-    __ movflt(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_s(Address(rsp, 0));\n-    __ addptr(rsp, 4);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::x86::d2i_wrapper())));\n-    __ post_call_nop();\n-    __ bind(fast);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convFPR2L_reg_reg( eADXRegL dst, regFPR src, eFlagsReg cr ) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (ConvF2L src));\n-  effect( KILL cr );\n-  format %{ \"FLD    $src\\t# Convert float to long\\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"SUB    ESP,8\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"POP    EDX\\n\\t\"\n-            \"CMP    EDX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"TEST   EAX,EAX\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"FLD    $src\\n\\t\"\n-            \"CALL   d2l_wrapper\\n\"\n-      \"fast:\" %}\n-  \/\/ DPR2L_encoding works for FPR2L\n-  ins_encode( Push_Reg_FPR(src), DPR2L_encoding(src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ XMM lacks a float\/double->long conversion, so use the old FPU stack.\n-instruct convF2L_reg_reg( eADXRegL dst, regF src, eFlagsReg cr ) %{\n-  predicate (UseSSE>=1);\n-  match(Set dst (ConvF2L src));\n-  effect( KILL cr );\n-  format %{ \"SUB    ESP,8\\t# Convert float to long\\n\\t\"\n-            \"MOVSS  [ESP],$src\\n\\t\"\n-            \"FLD_S  [ESP]\\n\\t\"\n-            \"FLDCW  trunc mode\\n\\t\"\n-            \"FISTp  [ESP + #0]\\n\\t\"\n-            \"FLDCW  std\/24-bit mode\\n\\t\"\n-            \"POP    EAX\\n\\t\"\n-            \"POP    EDX\\n\\t\"\n-            \"CMP    EDX,0x80000000\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"TEST   EAX,EAX\\n\\t\"\n-            \"JNE,s  fast\\n\\t\"\n-            \"SUB    ESP,4\\t# Convert float to long\\n\\t\"\n-            \"MOVSS  [ESP],$src\\n\\t\"\n-            \"FLD_S  [ESP]\\n\\t\"\n-            \"ADD    ESP,4\\n\\t\"\n-            \"CALL   d2l_wrapper\\n\"\n-      \"fast:\" %}\n-  ins_encode %{\n-    Label fast;\n-    __ subptr(rsp, 8);\n-    __ movflt(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_s(Address(rsp, 0));\n-    __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_trunc()));\n-    __ fistp_d(Address(rsp, 0));\n-    \/\/ Restore the rounding mode, mask the exception\n-    if (Compile::current()->in_24_bit_fp_mode()) {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_24()));\n-    } else {\n-      __ fldcw(ExternalAddress(StubRoutines::x86::addr_fpu_cntrl_wrd_std()));\n-    }\n-    \/\/ Load the converted long, adjust CPU stack\n-    __ pop(rax);\n-    __ pop(rdx);\n-    __ cmpl(rdx, 0x80000000);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ testl(rax, rax);\n-    __ jccb(Assembler::notEqual, fast);\n-    __ subptr(rsp, 4);\n-    __ movflt(Address(rsp, 0), $src$$XMMRegister);\n-    __ fld_s(Address(rsp, 0));\n-    __ addptr(rsp, 4);\n-    __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, StubRoutines::x86::d2l_wrapper())));\n-    __ post_call_nop();\n-    __ bind(fast);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convI2DPR_reg(regDPR dst, stackSlotI src) %{\n-  predicate( UseSSE<=1 );\n-  match(Set dst (ConvI2D src));\n-  format %{ \"FILD   $src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDB, 0x0);  \/* DB \/0 *\/\n-  ins_encode(Push_Mem_I(src), Pop_Reg_DPR(dst));\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct convI2D_reg(regD dst, rRegI src) %{\n-  predicate( UseSSE>=2 && !UseXmmI2D );\n-  match(Set dst (ConvI2D src));\n-  format %{ \"CVTSI2SD $dst,$src\" %}\n-  ins_encode %{\n-    __ cvtsi2sdl ($dst$$XMMRegister, $src$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convI2D_mem(regD dst, memory mem) %{\n-  predicate( UseSSE>=2 );\n-  match(Set dst (ConvI2D (LoadI mem)));\n-  format %{ \"CVTSI2SD $dst,$mem\" %}\n-  ins_encode %{\n-    __ cvtsi2sdl ($dst$$XMMRegister, $mem$$Address);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convXI2D_reg(regD dst, rRegI src)\n-%{\n-  predicate( UseSSE>=2 && UseXmmI2D );\n-  match(Set dst (ConvI2D src));\n-\n-  format %{ \"MOVD  $dst,$src\\n\\t\"\n-            \"CVTDQ2PD $dst,$dst\\t# i2d\" %}\n-  ins_encode %{\n-    __ movdl($dst$$XMMRegister, $src$$Register);\n-    __ cvtdq2pd($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n-  ins_pipe(pipe_slow); \/\/ XXX\n-%}\n-\n-instruct convI2DPR_mem(regDPR dst, memory mem) %{\n-  predicate( UseSSE<=1 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (ConvI2D (LoadI mem)));\n-  format %{ \"FILD   $mem\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDB);      \/* DB \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),\n-              Pop_Reg_DPR(dst), ClearInstMark);\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Convert a byte to a float; no rounding step needed.\n-instruct conv24I2FPR_reg(regFPR dst, stackSlotI src) %{\n-  predicate( UseSSE==0 && n->in(1)->Opcode() == Op_AndI && n->in(1)->in(2)->is_Con() && n->in(1)->in(2)->get_int() == 255 );\n-  match(Set dst (ConvI2F src));\n-  format %{ \"FILD   $src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-\n-  opcode(0xDB, 0x0);  \/* DB \/0 *\/\n-  ins_encode(Push_Mem_I(src), Pop_Reg_FPR(dst));\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ In 24-bit mode, force exponent rounding by storing back out\n-instruct convI2FPR_SSF(stackSlotF dst, stackSlotI src) %{\n-  predicate( UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (ConvI2F src));\n-  ins_cost(200);\n-  format %{ \"FILD   $src\\n\\t\"\n-            \"FSTP_S $dst\" %}\n-  opcode(0xDB, 0x0);  \/* DB \/0 *\/\n-  ins_encode( Push_Mem_I(src),\n-              Pop_Mem_FPR(dst));\n-  ins_pipe( fpu_mem_mem );\n-%}\n-\n-\/\/ In 24-bit mode, force exponent rounding by storing back out\n-instruct convI2FPR_SSF_mem(stackSlotF dst, memory mem) %{\n-  predicate( UseSSE==0 && Compile::current()->select_24_bit_instr());\n-  match(Set dst (ConvI2F (LoadI mem)));\n-  ins_cost(200);\n-  format %{ \"FILD   $mem\\n\\t\"\n-            \"FSTP_S $dst\" %}\n-  opcode(0xDB);  \/* DB \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),\n-              Pop_Mem_FPR(dst), ClearInstMark);\n-  ins_pipe( fpu_mem_mem );\n-%}\n-\n-\/\/ This instruction does not round to 24-bits\n-instruct convI2FPR_reg(regFPR dst, stackSlotI src) %{\n-  predicate( UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (ConvI2F src));\n-  format %{ \"FILD   $src\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDB, 0x0);  \/* DB \/0 *\/\n-  ins_encode( Push_Mem_I(src),\n-              Pop_Reg_FPR(dst));\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ This instruction does not round to 24-bits\n-instruct convI2FPR_mem(regFPR dst, memory mem) %{\n-  predicate( UseSSE==0 && !Compile::current()->select_24_bit_instr());\n-  match(Set dst (ConvI2F (LoadI mem)));\n-  format %{ \"FILD   $mem\\n\\t\"\n-            \"FSTP   $dst\" %}\n-  opcode(0xDB);      \/* DB \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,mem),\n-              Pop_Reg_FPR(dst), ClearInstMark);\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\/\/ Convert an int to a float in xmm; no rounding step needed.\n-instruct convI2F_reg(regF dst, rRegI src) %{\n-  predicate( UseSSE==1 || ( UseSSE>=2 && !UseXmmI2F ));\n-  match(Set dst (ConvI2F src));\n-  format %{ \"CVTSI2SS $dst, $src\" %}\n-  ins_encode %{\n-    __ cvtsi2ssl ($dst$$XMMRegister, $src$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n- instruct convXI2F_reg(regF dst, rRegI src)\n-%{\n-  predicate( UseSSE>=2 && UseXmmI2F );\n-  match(Set dst (ConvI2F src));\n-\n-  format %{ \"MOVD  $dst,$src\\n\\t\"\n-            \"CVTDQ2PS $dst,$dst\\t# i2f\" %}\n-  ins_encode %{\n-    __ movdl($dst$$XMMRegister, $src$$Register);\n-    __ cvtdq2ps($dst$$XMMRegister, $dst$$XMMRegister);\n-  %}\n-  ins_pipe(pipe_slow); \/\/ XXX\n-%}\n-\n-instruct convI2L_reg( eRegL dst, rRegI src, eFlagsReg cr) %{\n-  match(Set dst (ConvI2L src));\n-  effect(KILL cr);\n-  ins_cost(375);\n-  format %{ \"MOV    $dst.lo,$src\\n\\t\"\n-            \"MOV    $dst.hi,$src\\n\\t\"\n-            \"SAR    $dst.hi,31\" %}\n-  ins_encode(convert_int_long(dst,src));\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Zero-extend convert int to long\n-instruct convI2L_reg_zex(eRegL dst, rRegI src, immL_32bits mask, eFlagsReg flags ) %{\n-  match(Set dst (AndL (ConvI2L src) mask) );\n-  effect( KILL flags );\n-  ins_cost(250);\n-  format %{ \"MOV    $dst.lo,$src\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\" %}\n-  opcode(0x33); \/\/ XOR\n-  ins_encode(enc_Copy(dst,src), OpcP, RegReg_Hi2(dst,dst) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Zero-extend long\n-instruct zerox_long(eRegL dst, eRegL src, immL_32bits mask, eFlagsReg flags ) %{\n-  match(Set dst (AndL src mask) );\n-  effect( KILL flags );\n-  ins_cost(250);\n-  format %{ \"MOV    $dst.lo,$src.lo\\n\\t\"\n-            \"XOR    $dst.hi,$dst.hi\\n\\t\" %}\n-  opcode(0x33); \/\/ XOR\n-  ins_encode(enc_Copy(dst,src), OpcP, RegReg_Hi2(dst,dst) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-instruct convL2DPR_reg( stackSlotD dst, eRegL src, eFlagsReg cr) %{\n-  predicate (UseSSE<=1);\n-  match(Set dst (ConvL2D src));\n-  effect( KILL cr );\n-  format %{ \"PUSH   $src.hi\\t# Convert long to double\\n\\t\"\n-            \"PUSH   $src.lo\\n\\t\"\n-            \"FILD   ST,[ESP + #0]\\n\\t\"\n-            \"ADD    ESP,8\\n\\t\"\n-            \"FSTP_D $dst\\t# D-round\" %}\n-  opcode(0xDF, 0x5);  \/* DF \/5 *\/\n-  ins_encode(convert_long_double(src), Pop_Mem_DPR(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convL2D_reg( regD dst, eRegL src, eFlagsReg cr) %{\n-  predicate (UseSSE>=2);\n-  match(Set dst (ConvL2D src));\n-  effect( KILL cr );\n-  format %{ \"PUSH   $src.hi\\t# Convert long to double\\n\\t\"\n-            \"PUSH   $src.lo\\n\\t\"\n-            \"FILD_D [ESP]\\n\\t\"\n-            \"FSTP_D [ESP]\\n\\t\"\n-            \"MOVSD  $dst,[ESP]\\n\\t\"\n-            \"ADD    ESP,8\" %}\n-  opcode(0xDF, 0x5);  \/* DF \/5 *\/\n-  ins_encode(convert_long_double2(src), Push_ResultD(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convL2F_reg( regF dst, eRegL src, eFlagsReg cr) %{\n-  predicate (UseSSE>=1);\n-  match(Set dst (ConvL2F src));\n-  effect( KILL cr );\n-  format %{ \"PUSH   $src.hi\\t# Convert long to single float\\n\\t\"\n-            \"PUSH   $src.lo\\n\\t\"\n-            \"FILD_D [ESP]\\n\\t\"\n-            \"FSTP_S [ESP]\\n\\t\"\n-            \"MOVSS  $dst,[ESP]\\n\\t\"\n-            \"ADD    ESP,8\" %}\n-  opcode(0xDF, 0x5);  \/* DF \/5 *\/\n-  ins_encode(convert_long_double2(src), Push_ResultF(dst,0x8));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convL2FPR_reg( stackSlotF dst, eRegL src, eFlagsReg cr) %{\n-  match(Set dst (ConvL2F src));\n-  effect( KILL cr );\n-  format %{ \"PUSH   $src.hi\\t# Convert long to single float\\n\\t\"\n-            \"PUSH   $src.lo\\n\\t\"\n-            \"FILD   ST,[ESP + #0]\\n\\t\"\n-            \"ADD    ESP,8\\n\\t\"\n-            \"FSTP_S $dst\\t# F-round\" %}\n-  opcode(0xDF, 0x5);  \/* DF \/5 *\/\n-  ins_encode(convert_long_double(src), Pop_Mem_FPR(dst));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct convL2I_reg( rRegI dst, eRegL src ) %{\n-  match(Set dst (ConvL2I src));\n-  effect( DEF dst, USE src );\n-  format %{ \"MOV    $dst,$src.lo\" %}\n-  ins_encode(enc_CopyL_Lo(dst,src));\n-  ins_pipe( ialu_reg_reg );\n-%}\n-\n-instruct MoveF2I_stack_reg(rRegI dst, stackSlotF src) %{\n-  match(Set dst (MoveF2I src));\n-  effect( DEF dst, USE src );\n-  ins_cost(100);\n-  format %{ \"MOV    $dst,$src\\t# MoveF2I_stack_reg\" %}\n-  ins_encode %{\n-    __ movl($dst$$Register, Address(rsp, $src$$disp));\n-  %}\n-  ins_pipe( ialu_reg_mem );\n-%}\n-\n-instruct MoveFPR2I_reg_stack(stackSlotI dst, regFPR src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (MoveF2I src));\n-  effect( DEF dst, USE src );\n-\n-  ins_cost(125);\n-  format %{ \"FST_S  $dst,$src\\t# MoveF2I_reg_stack\" %}\n-  ins_encode( Pop_Mem_Reg_FPR(dst, src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-instruct MoveF2I_reg_stack_sse(stackSlotI dst, regF src) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (MoveF2I src));\n-  effect( DEF dst, USE src );\n-\n-  ins_cost(95);\n-  format %{ \"MOVSS  $dst,$src\\t# MoveF2I_reg_stack_sse\" %}\n-  ins_encode %{\n-    __ movflt(Address(rsp, $dst$$disp), $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveF2I_reg_reg_sse(rRegI dst, regF src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (MoveF2I src));\n-  effect( DEF dst, USE src );\n-  ins_cost(85);\n-  format %{ \"MOVD   $dst,$src\\t# MoveF2I_reg_reg_sse\" %}\n-  ins_encode %{\n-    __ movdl($dst$$Register, $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveI2F_reg_stack(stackSlotF dst, rRegI src) %{\n-  match(Set dst (MoveI2F src));\n-  effect( DEF dst, USE src );\n-\n-  ins_cost(100);\n-  format %{ \"MOV    $dst,$src\\t# MoveI2F_reg_stack\" %}\n-  ins_encode %{\n-    __ movl(Address(rsp, $dst$$disp), $src$$Register);\n-  %}\n-  ins_pipe( ialu_mem_reg );\n-%}\n-\n-\n-instruct MoveI2FPR_stack_reg(regFPR dst, stackSlotI src) %{\n-  predicate(UseSSE==0);\n-  match(Set dst (MoveI2F src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(125);\n-  format %{ \"FLD_S  $src\\n\\t\"\n-            \"FSTP   $dst\\t# MoveI2F_stack_reg\" %}\n-  opcode(0xD9);               \/* D9 \/0, FLD m32real *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem_no_oop(0x00,src),\n-              Pop_Reg_FPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-instruct MoveI2F_stack_reg_sse(regF dst, stackSlotI src) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (MoveI2F src));\n-  effect( DEF dst, USE src );\n-\n-  ins_cost(95);\n-  format %{ \"MOVSS  $dst,$src\\t# MoveI2F_stack_reg_sse\" %}\n-  ins_encode %{\n-    __ movflt($dst$$XMMRegister, Address(rsp, $src$$disp));\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveI2F_reg_reg_sse(regF dst, rRegI src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (MoveI2F src));\n-  effect( DEF dst, USE src );\n-\n-  ins_cost(85);\n-  format %{ \"MOVD   $dst,$src\\t# MoveI2F_reg_reg_sse\" %}\n-  ins_encode %{\n-    __ movdl($dst$$XMMRegister, $src$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveD2L_stack_reg(eRegL dst, stackSlotD src) %{\n-  match(Set dst (MoveD2L src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(250);\n-  format %{ \"MOV    $dst.lo,$src\\n\\t\"\n-            \"MOV    $dst.hi,$src+4\\t# MoveD2L_stack_reg\" %}\n-  opcode(0x8B, 0x8B);\n-  ins_encode( SetInstMark, OpcP, RegMem(dst,src), OpcS, RegMem_Hi(dst,src), ClearInstMark);\n-  ins_pipe( ialu_mem_long_reg );\n-%}\n-\n-instruct MoveDPR2L_reg_stack(stackSlotL dst, regDPR src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (MoveD2L src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(125);\n-  format %{ \"FST_D  $dst,$src\\t# MoveD2L_reg_stack\" %}\n-  ins_encode( Pop_Mem_Reg_DPR(dst, src) );\n-  ins_pipe( fpu_mem_reg );\n-%}\n-\n-instruct MoveD2L_reg_stack_sse(stackSlotL dst, regD src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (MoveD2L src));\n-  effect(DEF dst, USE src);\n-  ins_cost(95);\n-  format %{ \"MOVSD  $dst,$src\\t# MoveD2L_reg_stack_sse\" %}\n-  ins_encode %{\n-    __ movdbl(Address(rsp, $dst$$disp), $src$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveD2L_reg_reg_sse(eRegL dst, regD src, regD tmp) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (MoveD2L src));\n-  effect(DEF dst, USE src, TEMP tmp);\n-  ins_cost(85);\n-  format %{ \"MOVD   $dst.lo,$src\\n\\t\"\n-            \"PSHUFLW $tmp,$src,0x4E\\n\\t\"\n-            \"MOVD   $dst.hi,$tmp\\t# MoveD2L_reg_reg_sse\" %}\n-  ins_encode %{\n-    __ movdl($dst$$Register, $src$$XMMRegister);\n-    __ pshuflw($tmp$$XMMRegister, $src$$XMMRegister, 0x4e);\n-    __ movdl(HIGH_FROM_LOW($dst$$Register), $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveL2D_reg_stack(stackSlotD dst, eRegL src) %{\n-  match(Set dst (MoveL2D src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(200);\n-  format %{ \"MOV    $dst,$src.lo\\n\\t\"\n-            \"MOV    $dst+4,$src.hi\\t# MoveL2D_reg_stack\" %}\n-  opcode(0x89, 0x89);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, dst ), OpcS, RegMem_Hi( src, dst ), ClearInstMark );\n-  ins_pipe( ialu_mem_long_reg );\n-%}\n-\n-\n-instruct MoveL2DPR_stack_reg(regDPR dst, stackSlotL src) %{\n-  predicate(UseSSE<=1);\n-  match(Set dst (MoveL2D src));\n-  effect(DEF dst, USE src);\n-  ins_cost(125);\n-\n-  format %{ \"FLD_D  $src\\n\\t\"\n-            \"FSTP   $dst\\t# MoveL2D_stack_reg\" %}\n-  opcode(0xDD);               \/* DD \/0, FLD m64real *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem_no_oop(0x00,src),\n-              Pop_Reg_DPR(dst), ClearInstMark );\n-  ins_pipe( fpu_reg_mem );\n-%}\n-\n-\n-instruct MoveL2D_stack_reg_sse(regD dst, stackSlotL src) %{\n-  predicate(UseSSE>=2 && UseXmmLoadAndClearUpper);\n-  match(Set dst (MoveL2D src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(95);\n-  format %{ \"MOVSD  $dst,$src\\t# MoveL2D_stack_reg_sse\" %}\n-  ins_encode %{\n-    __ movdbl($dst$$XMMRegister, Address(rsp, $src$$disp));\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveL2D_stack_reg_sse_partial(regD dst, stackSlotL src) %{\n-  predicate(UseSSE>=2 && !UseXmmLoadAndClearUpper);\n-  match(Set dst (MoveL2D src));\n-  effect(DEF dst, USE src);\n-\n-  ins_cost(95);\n-  format %{ \"MOVLPD $dst,$src\\t# MoveL2D_stack_reg_sse\" %}\n-  ins_encode %{\n-    __ movdbl($dst$$XMMRegister, Address(rsp, $src$$disp));\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct MoveL2D_reg_reg_sse(regD dst, eRegL src, regD tmp) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (MoveL2D src));\n-  effect(TEMP dst, USE src, TEMP tmp);\n-  ins_cost(85);\n-  format %{ \"MOVD   $dst,$src.lo\\n\\t\"\n-            \"MOVD   $tmp,$src.hi\\n\\t\"\n-            \"PUNPCKLDQ $dst,$tmp\\t# MoveL2D_reg_reg_sse\" %}\n-  ins_encode %{\n-    __ movdl($dst$$XMMRegister, $src$$Register);\n-    __ movdl($tmp$$XMMRegister, HIGH_FROM_LOW($src$$Register));\n-    __ punpckldq($dst$$XMMRegister, $tmp$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/----------------------------- CompressBits\/ExpandBits ------------------------\n-\n-instruct compressBitsL_reg(eADXRegL dst, eBCXRegL src, eBDPRegL mask, eSIRegI rtmp, regF xtmp, eFlagsReg cr) %{\n-  predicate(n->bottom_type()->isa_long());\n-  match(Set dst (CompressBits src mask));\n-  effect(TEMP rtmp, TEMP xtmp, KILL cr);\n-  format %{ \"compress_bits $dst, $src, $mask\\t! using $rtmp and $xtmp as TEMP\" %}\n-  ins_encode %{\n-    Label exit, partail_result;\n-    \/\/ Parallely extract both upper and lower 32 bits of source into destination register pair.\n-    \/\/ Merge the results of upper and lower destination registers such that upper destination\n-    \/\/ results are contiguously laid out after the lower destination result.\n-    __ pextl($dst$$Register, $src$$Register, $mask$$Register);\n-    __ pextl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($src$$Register), HIGH_FROM_LOW($mask$$Register));\n-    __ popcntl($rtmp$$Register, $mask$$Register);\n-    \/\/ Skip merging if bit count of lower mask register is equal to 32 (register size).\n-    __ cmpl($rtmp$$Register, 32);\n-    __ jccb(Assembler::equal, exit);\n-    \/\/ Due to constraint on number of GPRs on 32 bit target, using XMM register as potential spill slot.\n-    __ movdl($xtmp$$XMMRegister, $rtmp$$Register);\n-    \/\/ Shift left the contents of upper destination register by true bit count of lower mask register\n-    \/\/ and merge with lower destination register.\n-    __ shlxl($rtmp$$Register, HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n-    __ orl($dst$$Register, $rtmp$$Register);\n-    __ movdl($rtmp$$Register, $xtmp$$XMMRegister);\n-    \/\/ Zero out upper destination register if true bit count of lower 32 bit mask is zero\n-    \/\/ since contents of upper destination have already been copied to lower destination\n-    \/\/ register.\n-    __ cmpl($rtmp$$Register, 0);\n-    __ jccb(Assembler::greater, partail_result);\n-    __ movl(HIGH_FROM_LOW($dst$$Register), 0);\n-    __ jmp(exit);\n-    __ bind(partail_result);\n-    \/\/ Perform right shift over upper destination register to move out bits already copied\n-    \/\/ to lower destination register.\n-    __ subl($rtmp$$Register, 32);\n-    __ negl($rtmp$$Register);\n-    __ shrxl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n-    __ bind(exit);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct expandBitsL_reg(eADXRegL dst, eBCXRegL src, eBDPRegL mask, eSIRegI rtmp, regF xtmp, eFlagsReg cr) %{\n-  predicate(n->bottom_type()->isa_long());\n-  match(Set dst (ExpandBits src mask));\n-  effect(TEMP rtmp, TEMP xtmp, KILL cr);\n-  format %{ \"expand_bits $dst, $src, $mask\\t! using $rtmp and $xtmp as TEMP\" %}\n-  ins_encode %{\n-    \/\/ Extraction operation sequentially reads the bits from source register starting from LSB\n-    \/\/ and lays them out into destination register at bit locations corresponding to true bits\n-    \/\/ in mask register. Thus number of source bits read are equal to combined true bit count\n-    \/\/ of mask register pair.\n-    Label exit, mask_clipping;\n-    __ pdepl($dst$$Register, $src$$Register, $mask$$Register);\n-    __ pdepl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($src$$Register), HIGH_FROM_LOW($mask$$Register));\n-    __ popcntl($rtmp$$Register, $mask$$Register);\n-    \/\/ If true bit count of lower mask register is 32 then none of bit of lower source register\n-    \/\/ will feed to upper destination register.\n-    __ cmpl($rtmp$$Register, 32);\n-    __ jccb(Assembler::equal, exit);\n-    \/\/ Due to constraint on number of GPRs on 32 bit target, using XMM register as potential spill slot.\n-    __ movdl($xtmp$$XMMRegister, $rtmp$$Register);\n-    \/\/ Shift right the contents of lower source register to remove already consumed bits.\n-    __ shrxl($rtmp$$Register, $src$$Register, $rtmp$$Register);\n-    \/\/ Extract the bits from lower source register starting from LSB under the influence\n-    \/\/ of upper mask register.\n-    __ pdepl(HIGH_FROM_LOW($dst$$Register), $rtmp$$Register, HIGH_FROM_LOW($mask$$Register));\n-    __ movdl($rtmp$$Register, $xtmp$$XMMRegister);\n-    __ subl($rtmp$$Register, 32);\n-    __ negl($rtmp$$Register);\n-    __ movdl($xtmp$$XMMRegister, $mask$$Register);\n-    __ movl($mask$$Register, HIGH_FROM_LOW($mask$$Register));\n-    \/\/ Clear the set bits in upper mask register which have been used to extract the contents\n-    \/\/ from lower source register.\n-    __ bind(mask_clipping);\n-    __ blsrl($mask$$Register, $mask$$Register);\n-    __ decrementl($rtmp$$Register, 1);\n-    __ jccb(Assembler::greater, mask_clipping);\n-    \/\/ Starting from LSB extract the bits from upper source register under the influence of\n-    \/\/ remaining set bits in upper mask register.\n-    __ pdepl($rtmp$$Register, HIGH_FROM_LOW($src$$Register), $mask$$Register);\n-    \/\/ Merge the partial results extracted from lower and upper source register bits.\n-    __ orl(HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n-    __ movdl($mask$$Register, $xtmp$$XMMRegister);\n-    __ bind(exit);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ =======================================================================\n-\/\/ Fast clearing of an array\n-\/\/ Small non-constant length ClearArray for non-AVX512 targets.\n-instruct rep_stos(eCXRegI cnt, eDIRegP base, regD tmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n-  predicate(!((ClearArrayNode*)n)->is_large() && (UseAVX <= 2));\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n-\n-  format %{ $$template\n-    $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-    $$emit$$\"CMP    InitArrayShortSize,rcx\\n\\t\"\n-    $$emit$$\"JG     LARGE\\n\\t\"\n-    $$emit$$\"SHL    ECX, 1\\n\\t\"\n-    $$emit$$\"DEC    ECX\\n\\t\"\n-    $$emit$$\"JS     DONE\\t# Zero length\\n\\t\"\n-    $$emit$$\"MOV    EAX,(EDI,ECX,4)\\t# LOOP\\n\\t\"\n-    $$emit$$\"DEC    ECX\\n\\t\"\n-    $$emit$$\"JGE    LOOP\\n\\t\"\n-    $$emit$$\"JMP    DONE\\n\\t\"\n-    $$emit$$\"# LARGE:\\n\\t\"\n-    if (UseFastStosb) {\n-       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n-       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    } else if (UseXMMForObjInit) {\n-       $$emit$$\"MOV     RDI,RAX\\n\\t\"\n-       $$emit$$\"VPXOR    YMM0,YMM0,YMM0\\n\\t\"\n-       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n-       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n-       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n-       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n-       $$emit$$\"JGE     L_loop\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JL      L_tail\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n-       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n-       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JLE     L_end\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n-       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"JGE     L_sloop\\n\\t\"\n-       $$emit$$\"# L_end:\\n\\t\"\n-    } else {\n-       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n-       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    }\n-    $$emit$$\"# DONE\"\n-  %}\n-  ins_encode %{\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, false, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Small non-constant length ClearArray for AVX512 targets.\n-instruct rep_stos_evex(eCXRegI cnt, eDIRegP base, legRegD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n-  predicate(!((ClearArrayNode*)n)->is_large() && (UseAVX > 2));\n-  match(Set dummy (ClearArray cnt base));\n-  ins_cost(125);\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n-\n-  format %{ $$template\n-    $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-    $$emit$$\"CMP    InitArrayShortSize,rcx\\n\\t\"\n-    $$emit$$\"JG     LARGE\\n\\t\"\n-    $$emit$$\"SHL    ECX, 1\\n\\t\"\n-    $$emit$$\"DEC    ECX\\n\\t\"\n-    $$emit$$\"JS     DONE\\t# Zero length\\n\\t\"\n-    $$emit$$\"MOV    EAX,(EDI,ECX,4)\\t# LOOP\\n\\t\"\n-    $$emit$$\"DEC    ECX\\n\\t\"\n-    $$emit$$\"JGE    LOOP\\n\\t\"\n-    $$emit$$\"JMP    DONE\\n\\t\"\n-    $$emit$$\"# LARGE:\\n\\t\"\n-    if (UseFastStosb) {\n-       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n-       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    } else if (UseXMMForObjInit) {\n-       $$emit$$\"MOV     RDI,RAX\\n\\t\"\n-       $$emit$$\"VPXOR    YMM0,YMM0,YMM0\\n\\t\"\n-       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n-       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n-       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n-       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n-       $$emit$$\"JGE     L_loop\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JL      L_tail\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n-       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n-       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JLE     L_end\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n-       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"JGE     L_sloop\\n\\t\"\n-       $$emit$$\"# L_end:\\n\\t\"\n-    } else {\n-       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n-       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    }\n-    $$emit$$\"# DONE\"\n-  %}\n-  ins_encode %{\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Large non-constant length ClearArray for non-AVX512 targets.\n-instruct rep_stos_large(eCXRegI cnt, eDIRegP base, regD tmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n-  predicate((UseAVX <= 2) && ((ClearArrayNode*)n)->is_large());\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n-  format %{ $$template\n-    if (UseFastStosb) {\n-       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n-       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    } else if (UseXMMForObjInit) {\n-       $$emit$$\"MOV     RDI,RAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"VPXOR   YMM0,YMM0,YMM0\\n\\t\"\n-       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n-       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n-       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n-       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n-       $$emit$$\"JGE     L_loop\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JL      L_tail\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n-       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n-       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JLE     L_end\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n-       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"JGE     L_sloop\\n\\t\"\n-       $$emit$$\"# L_end:\\n\\t\"\n-    } else {\n-       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n-       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    }\n-    $$emit$$\"# DONE\"\n-  %}\n-  ins_encode %{\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, true, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Large non-constant length ClearArray for AVX512 targets.\n-instruct rep_stos_large_evex(eCXRegI cnt, eDIRegP base, legRegD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n-  predicate((UseAVX > 2) && ((ClearArrayNode*)n)->is_large());\n-  match(Set dummy (ClearArray cnt base));\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n-  format %{ $$template\n-    if (UseFastStosb) {\n-       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n-       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    } else if (UseXMMForObjInit) {\n-       $$emit$$\"MOV     RDI,RAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"VPXOR   YMM0,YMM0,YMM0\\n\\t\"\n-       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n-       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n-       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n-       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n-       $$emit$$\"JGE     L_loop\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JL      L_tail\\n\\t\"\n-       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n-       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n-       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n-       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n-       $$emit$$\"JLE     L_end\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n-       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n-       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n-       $$emit$$\"DEC     RCX\\n\\t\"\n-       $$emit$$\"JGE     L_sloop\\n\\t\"\n-       $$emit$$\"# L_end:\\n\\t\"\n-    } else {\n-       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n-       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n-       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n-    }\n-    $$emit$$\"# DONE\"\n-  %}\n-  ins_encode %{\n-    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n-                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Small constant length ClearArray for AVX512 targets.\n-instruct rep_stos_im(immI cnt, kReg ktmp, eRegP base, regD tmp, rRegI zero, Universe dummy, eFlagsReg cr)\n-%{\n-  predicate(!((ClearArrayNode*)n)->is_large() && (MaxVectorSize >= 32) && VM_Version::supports_avx512vl());\n-  match(Set dummy (ClearArray cnt base));\n-  ins_cost(100);\n-  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n-  format %{ \"clear_mem_imm $base , $cnt  \\n\\t\" %}\n-  ins_encode %{\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct string_compareL(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                         eAXRegI result, regD tmp1, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareL_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                              eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareU(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                         eAXRegI result, regD tmp1, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareU_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                              eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareLU(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                          eAXRegI result, regD tmp1, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareLU_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n-                               eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareUL(eSIRegP str1, eDXRegI cnt1, eDIRegP str2, eCXRegI cnt2,\n-                          eAXRegI result, regD tmp1, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str2$$Register, $str1$$Register,\n-                      $cnt2$$Register, $cnt1$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compareUL_evex(eSIRegP str1, eDXRegI cnt1, eDIRegP str2, eCXRegI cnt2,\n-                               eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n-  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n-\n-  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n-  ins_encode %{\n-    __ string_compare($str2$$Register, $str1$$Register,\n-                      $cnt2$$Register, $cnt1$$Register, $result$$Register,\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ fast string equals\n-instruct string_equals(eDIRegP str1, eSIRegP str2, eCXRegI cnt, eAXRegI result,\n-                       regD tmp1, regD tmp2, eBXRegI tmp3, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw());\n-  match(Set result (StrEquals (Binary str1 str2) cnt));\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n-\n-  format %{ \"String Equals $str1,$str2,$cnt -> $result    \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n-  ins_encode %{\n-    __ arrays_equals(false, $str1$$Register, $str2$$Register,\n-                     $cnt$$Register, $result$$Register, $tmp3$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n-  %}\n-\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_equals_evex(eDIRegP str1, eSIRegP str2, eCXRegI cnt, eAXRegI result,\n-                            regD tmp1, regD tmp2, kReg ktmp, eBXRegI tmp3, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw());\n-  match(Set result (StrEquals (Binary str1 str2) cnt));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n-\n-  format %{ \"String Equals $str1,$str2,$cnt -> $result    \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n-  ins_encode %{\n-    __ arrays_equals(false, $str1$$Register, $str2$$Register,\n-                     $cnt$$Register, $result$$Register, $tmp3$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n-  %}\n-\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ fast search of substring with known size.\n-instruct string_indexof_conL(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, immI int_cnt2,\n-                             eBXRegI result, regD vec1, eAXRegI cnt2, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::LL));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf byte[] $str1,$cnt1,$str2,$int_cnt2 -> $result   \/\/ KILL $vec1, $cnt1, $cnt2, $tmp\" %}\n-  ins_encode %{\n-    int icnt2 = (int)$int_cnt2$$constant;\n-    if (icnt2 >= 16) {\n-      \/\/ IndexOf for constant substrings with size >= 16 elements\n-      \/\/ which don't need to be loaded through stack.\n-      __ string_indexofC8($str1$$Register, $str2$$Register,\n-                          $cnt1$$Register, $cnt2$$Register,\n-                          icnt2, $result$$Register,\n-                          $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::LL);\n-    } else {\n-      \/\/ Small strings are loaded through stack if they cross page boundary.\n-      __ string_indexof($str1$$Register, $str2$$Register,\n-                        $cnt1$$Register, $cnt2$$Register,\n-                        icnt2, $result$$Register,\n-                        $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::LL);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ fast search of substring with known size.\n-instruct string_indexof_conU(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, immI int_cnt2,\n-                             eBXRegI result, regD vec1, eAXRegI cnt2, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::UU));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$str2,$int_cnt2 -> $result   \/\/ KILL $vec1, $cnt1, $cnt2, $tmp\" %}\n-  ins_encode %{\n-    int icnt2 = (int)$int_cnt2$$constant;\n-    if (icnt2 >= 8) {\n-      \/\/ IndexOf for constant substrings with size >= 8 elements\n-      \/\/ which don't need to be loaded through stack.\n-      __ string_indexofC8($str1$$Register, $str2$$Register,\n-                          $cnt1$$Register, $cnt2$$Register,\n-                          icnt2, $result$$Register,\n-                          $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UU);\n-    } else {\n-      \/\/ Small strings are loaded through stack if they cross page boundary.\n-      __ string_indexof($str1$$Register, $str2$$Register,\n-                        $cnt1$$Register, $cnt2$$Register,\n-                        icnt2, $result$$Register,\n-                        $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UU);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ fast search of substring with known size.\n-instruct string_indexof_conUL(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, immI int_cnt2,\n-                             eBXRegI result, regD vec1, eAXRegI cnt2, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::UL));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$str2,$int_cnt2 -> $result   \/\/ KILL $vec1, $cnt1, $cnt2, $tmp\" %}\n-  ins_encode %{\n-    int icnt2 = (int)$int_cnt2$$constant;\n-    if (icnt2 >= 8) {\n-      \/\/ IndexOf for constant substrings with size >= 8 elements\n-      \/\/ which don't need to be loaded through stack.\n-      __ string_indexofC8($str1$$Register, $str2$$Register,\n-                          $cnt1$$Register, $cnt2$$Register,\n-                          icnt2, $result$$Register,\n-                          $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UL);\n-    } else {\n-      \/\/ Small strings are loaded through stack if they cross page boundary.\n-      __ string_indexof($str1$$Register, $str2$$Register,\n-                        $cnt1$$Register, $cnt2$$Register,\n-                        icnt2, $result$$Register,\n-                        $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UL);\n-    }\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_indexofL(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, eAXRegI cnt2,\n-                         eBXRegI result, regD vec1, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::LL));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL all\" %}\n-  ins_encode %{\n-    __ string_indexof($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register,\n-                      (-1), $result$$Register,\n-                      $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::LL);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_indexofU(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, eAXRegI cnt2,\n-                         eBXRegI result, regD vec1, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::UU));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL all\" %}\n-  ins_encode %{\n-    __ string_indexof($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register,\n-                      (-1), $result$$Register,\n-                      $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UU);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_indexofUL(eDIRegP str1, eDXRegI cnt1, eSIRegP str2, eAXRegI cnt2,\n-                         eBXRegI result, regD vec1, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfNode*)n)->encoding() == StrIntrinsicNode::UL));\n-  match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));\n-  effect(TEMP vec1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL tmp, KILL cr);\n-\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL all\" %}\n-  ins_encode %{\n-    __ string_indexof($str1$$Register, $str2$$Register,\n-                      $cnt1$$Register, $cnt2$$Register,\n-                      (-1), $result$$Register,\n-                      $vec1$$XMMRegister, $tmp$$Register, StrIntrinsicNode::UL);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n-                              eBXRegI result, regD vec1, regD vec2, regD vec3, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U));\n-  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n-  effect(TEMP vec1, TEMP vec2, TEMP vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n-  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n-  ins_encode %{\n-    __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n-                           $vec1$$XMMRegister, $vec2$$XMMRegister, $vec3$$XMMRegister, $tmp$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct stringL_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n-                              eBXRegI result, regD vec1, regD vec2, regD vec3, eCXRegI tmp, eFlagsReg cr) %{\n-  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L));\n-  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n-  effect(TEMP vec1, TEMP vec2, TEMP vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n-  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n-  ins_encode %{\n-    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n-                           $vec1$$XMMRegister, $vec2$$XMMRegister, $vec3$$XMMRegister, $tmp$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ fast array equals\n-instruct array_equalsB(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n-                       regD tmp1, regD tmp2, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n-%{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n-  match(Set result (AryEq ary1 ary2));\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n-  \/\/ins_cost(300);\n-\n-  format %{ \"Array Equals byte[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n-  ins_encode %{\n-    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n-                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct array_equalsB_evex(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n-                       regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n-%{\n-  predicate(VM_Version::supports_avx512vlbw() && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n-  match(Set result (AryEq ary1 ary2));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n-  \/\/ins_cost(300);\n-\n-  format %{ \"Array Equals byte[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n-  ins_encode %{\n-    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n-                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct array_equalsC(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n-                       regD tmp1, regD tmp2, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n-%{\n-  predicate(!VM_Version::supports_avx512vlbw() && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n-  match(Set result (AryEq ary1 ary2));\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n-  \/\/ins_cost(300);\n-\n-  format %{ \"Array Equals char[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n-  ins_encode %{\n-    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n-                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct array_equalsC_evex(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n-                            regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n-%{\n-  predicate(VM_Version::supports_avx512vlbw() && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n-  match(Set result (AryEq ary1 ary2));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n-  \/\/ins_cost(300);\n-\n-  format %{ \"Array Equals char[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n-  ins_encode %{\n-    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n-                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct count_positives(eSIRegP ary1, eCXRegI len, eAXRegI result,\n-                         regD tmp1, regD tmp2, eBXRegI tmp3, eFlagsReg cr)\n-%{\n-  predicate(!VM_Version::supports_avx512vlbw() || !VM_Version::supports_bmi2());\n-  match(Set result (CountPositives ary1 len));\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n-\n-  format %{ \"countPositives byte[] $ary1,$len -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n-  ins_encode %{\n-    __ count_positives($ary1$$Register, $len$$Register,\n-                       $result$$Register, $tmp3$$Register,\n-                       $tmp1$$XMMRegister, $tmp2$$XMMRegister, knoreg, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct count_positives_evex(eSIRegP ary1, eCXRegI len, eAXRegI result,\n-                              regD tmp1, regD tmp2, kReg ktmp1, kReg ktmp2, eBXRegI tmp3, eFlagsReg cr)\n-%{\n-  predicate(VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2());\n-  match(Set result (CountPositives ary1 len));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp1, TEMP ktmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n-\n-  format %{ \"countPositives byte[] $ary1,$len -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n-  ins_encode %{\n-    __ count_positives($ary1$$Register, $len$$Register,\n-                       $result$$Register, $tmp3$$Register,\n-                       $tmp1$$XMMRegister, $tmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ fast char[] to byte[] compression\n-instruct string_compress(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2,\n-                         regD tmp3, regD tmp4, eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() || !VM_Version::supports_bmi2());\n-  match(Set result (StrCompressedCopy src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n-\n-  format %{ \"String Compress $src,$dst -> $result    \/\/ KILL RAX, RCX, RDX\" %}\n-  ins_encode %{\n-    __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,\n-                           $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n-                           knoreg, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_compress_evex(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2,\n-                              regD tmp3, regD tmp4, kReg ktmp1, kReg ktmp2, eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2());\n-  match(Set result (StrCompressedCopy src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ktmp1, TEMP ktmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n-\n-  format %{ \"String Compress $src,$dst -> $result    \/\/ KILL RAX, RCX, RDX\" %}\n-  ins_encode %{\n-    __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,\n-                           $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n-                           $ktmp1$$KRegister, $ktmp2$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ fast byte[] to char[] inflation\n-instruct string_inflate(Universe dummy, eSIRegP src, eDIRegP dst, eDXRegI len,\n-                        regD tmp1, eCXRegI tmp2, eFlagsReg cr) %{\n-  predicate(!VM_Version::supports_avx512vlbw() || !VM_Version::supports_bmi2());\n-  match(Set dummy (StrInflatedCopy src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n-\n-  format %{ \"String Inflate $src,$dst    \/\/ KILL $tmp1, $tmp2\" %}\n-  ins_encode %{\n-    __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,\n-                          $tmp1$$XMMRegister, $tmp2$$Register, knoreg);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct string_inflate_evex(Universe dummy, eSIRegP src, eDIRegP dst, eDXRegI len,\n-                             regD tmp1, kReg ktmp, eCXRegI tmp2, eFlagsReg cr) %{\n-  predicate(VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2());\n-  match(Set dummy (StrInflatedCopy src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n-\n-  format %{ \"String Inflate $src,$dst    \/\/ KILL $tmp1, $tmp2\" %}\n-  ins_encode %{\n-    __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,\n-                          $tmp1$$XMMRegister, $tmp2$$Register, $ktmp$$KRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ encode char[] to byte[] in ISO_8859_1\n-instruct encode_iso_array(eSIRegP src, eDIRegP dst, eDXRegI len,\n-                          regD tmp1, regD tmp2, regD tmp3, regD tmp4,\n-                          eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n-  predicate(!((EncodeISOArrayNode*)n)->is_ascii());\n-  match(Set result (EncodeISOArray src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n-\n-  format %{ \"Encode iso array $src,$dst,$len -> $result    \/\/ KILL ECX, EDX, $tmp1, $tmp2, $tmp3, $tmp4, ESI, EDI \" %}\n-  ins_encode %{\n-    __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,\n-                        $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n-                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, false);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ encode char[] to byte[] in ASCII\n-instruct encode_ascii_array(eSIRegP src, eDIRegP dst, eDXRegI len,\n-                            regD tmp1, regD tmp2, regD tmp3, regD tmp4,\n-                            eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n-  predicate(((EncodeISOArrayNode*)n)->is_ascii());\n-  match(Set result (EncodeISOArray src (Binary dst len)));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n-\n-  format %{ \"Encode ascii array $src,$dst,$len -> $result    \/\/ KILL ECX, EDX, $tmp1, $tmp2, $tmp3, $tmp4, ESI, EDI \" %}\n-  ins_encode %{\n-    __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,\n-                        $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n-                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, true);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/----------Control Flow Instructions------------------------------------------\n-\/\/ Signed compare Instructions\n-instruct compI_eReg(eFlagsReg cr, rRegI op1, rRegI op2) %{\n-  match(Set cr (CmpI op1 op2));\n-  effect( DEF cr, USE op1, USE op2 );\n-  format %{ \"CMP    $op1,$op2\" %}\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( OpcP, RegReg( op1, op2) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-instruct compI_eReg_imm(eFlagsReg cr, rRegI op1, immI op2) %{\n-  match(Set cr (CmpI op1 op2));\n-  effect( DEF cr, USE op1 );\n-  format %{ \"CMP    $op1,$op2\" %}\n-  opcode(0x81,0x07);  \/* Opcode 81 \/7 *\/\n-  \/\/ ins_encode( RegImm( op1, op2) );  \/* Was CmpImm *\/\n-  ins_encode( OpcSErm( op1, op2 ), Con8or32( op2 ) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ Cisc-spilled version of cmpI_eReg\n-instruct compI_eReg_mem(eFlagsReg cr, rRegI op1, memory op2) %{\n-  match(Set cr (CmpI op1 (LoadI op2)));\n-\n-  format %{ \"CMP    $op1,$op2\" %}\n-  ins_cost(500);\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( op1, op2), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_mem );\n-%}\n-\n-instruct testI_reg( eFlagsReg cr, rRegI src, immI_0 zero ) %{\n-  match(Set cr (CmpI src zero));\n-  effect( DEF cr, USE src );\n-\n-  format %{ \"TEST   $src,$src\" %}\n-  opcode(0x85);\n-  ins_encode( OpcP, RegReg( src, src ) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-instruct testI_reg_imm( eFlagsReg cr, rRegI src, immI con, immI_0 zero ) %{\n-  match(Set cr (CmpI (AndI src con) zero));\n-\n-  format %{ \"TEST   $src,$con\" %}\n-  opcode(0xF7,0x00);\n-  ins_encode( OpcP, RegOpc(src), Con32(con) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-instruct testI_reg_mem( eFlagsReg cr, rRegI src, memory mem, immI_0 zero ) %{\n-  match(Set cr (CmpI (AndI src mem) zero));\n-\n-  format %{ \"TEST   $src,$mem\" %}\n-  opcode(0x85);\n-  ins_encode( SetInstMark, OpcP, RegMem( src, mem ), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_mem );\n-%}\n-\n-\/\/ Unsigned compare Instructions; really, same as signed except they\n-\/\/ produce an eFlagsRegU instead of eFlagsReg.\n-instruct compU_eReg(eFlagsRegU cr, rRegI op1, rRegI op2) %{\n-  match(Set cr (CmpU op1 op2));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( OpcP, RegReg( op1, op2) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-instruct compU_eReg_imm(eFlagsRegU cr, rRegI op1, immI op2) %{\n-  match(Set cr (CmpU op1 op2));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  opcode(0x81,0x07);  \/* Opcode 81 \/7 *\/\n-  ins_encode( OpcSErm( op1, op2 ), Con8or32( op2 ) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ \/\/ Cisc-spilled version of cmpU_eReg\n-instruct compU_eReg_mem(eFlagsRegU cr, rRegI op1, memory op2) %{\n-  match(Set cr (CmpU op1 (LoadI op2)));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  ins_cost(500);\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( op1, op2), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_mem );\n-%}\n-\n-\/\/ \/\/ Cisc-spilled version of cmpU_eReg\n-\/\/instruct compU_mem_eReg(eFlagsRegU cr, memory op1, rRegI op2) %{\n-\/\/  match(Set cr (CmpU (LoadI op1) op2));\n-\/\/\n-\/\/  format %{ \"CMPu   $op1,$op2\" %}\n-\/\/  ins_cost(500);\n-\/\/  opcode(0x39);  \/* Opcode 39 \/r *\/\n-\/\/  ins_encode( OpcP, RegMem( op1, op2) );\n-\/\/%}\n-\n-instruct testU_reg( eFlagsRegU cr, rRegI src, immI_0 zero ) %{\n-  match(Set cr (CmpU src zero));\n-\n-  format %{ \"TESTu  $src,$src\" %}\n-  opcode(0x85);\n-  ins_encode( OpcP, RegReg( src, src ) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ Unsigned pointer compare Instructions\n-instruct compP_eReg(eFlagsRegU cr, eRegP op1, eRegP op2) %{\n-  match(Set cr (CmpP op1 op2));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( OpcP, RegReg( op1, op2) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-instruct compP_eReg_imm(eFlagsRegU cr, eRegP op1, immP op2) %{\n-  match(Set cr (CmpP op1 op2));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  opcode(0x81,0x07);  \/* Opcode 81 \/7 *\/\n-  ins_encode( SetInstMark, OpcSErm( op1, op2 ), Con8or32( op2 ), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ \/\/ Cisc-spilled version of cmpP_eReg\n-instruct compP_eReg_mem(eFlagsRegU cr, eRegP op1, memory op2) %{\n-  match(Set cr (CmpP op1 (LoadP op2)));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  ins_cost(500);\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( op1, op2), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_mem );\n-%}\n-\n-\/\/ \/\/ Cisc-spilled version of cmpP_eReg\n-\/\/instruct compP_mem_eReg(eFlagsRegU cr, memory op1, eRegP op2) %{\n-\/\/  match(Set cr (CmpP (LoadP op1) op2));\n-\/\/\n-\/\/  format %{ \"CMPu   $op1,$op2\" %}\n-\/\/  ins_cost(500);\n-\/\/  opcode(0x39);  \/* Opcode 39 \/r *\/\n-\/\/  ins_encode( OpcP, RegMem( op1, op2) );\n-\/\/%}\n-\n-\/\/ Compare raw pointer (used in out-of-heap check).\n-\/\/ Only works because non-oop pointers must be raw pointers\n-\/\/ and raw pointers have no anti-dependencies.\n-instruct compP_mem_eReg( eFlagsRegU cr, eRegP op1, memory op2 ) %{\n-  predicate( n->in(2)->in(2)->bottom_type()->reloc() == relocInfo::none );\n-  match(Set cr (CmpP op1 (LoadP op2)));\n-\n-  format %{ \"CMPu   $op1,$op2\" %}\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode( SetInstMark, OpcP, RegMem( op1, op2), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_mem );\n-%}\n-\n-\/\/\n-\/\/ This will generate a signed flags result. This should be ok\n-\/\/ since any compare to a zero should be eq\/neq.\n-instruct testP_reg( eFlagsReg cr, eRegP src, immP0 zero ) %{\n-  match(Set cr (CmpP src zero));\n-\n-  format %{ \"TEST   $src,$src\" %}\n-  opcode(0x85);\n-  ins_encode( OpcP, RegReg( src, src ) );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ Cisc-spilled version of testP_reg\n-\/\/ This will generate a signed flags result. This should be ok\n-\/\/ since any compare to a zero should be eq\/neq.\n-instruct testP_Reg_mem( eFlagsReg cr, memory op, immI_0 zero ) %{\n-  match(Set cr (CmpP (LoadP op) zero));\n-\n-  format %{ \"TEST   $op,0xFFFFFFFF\" %}\n-  ins_cost(500);\n-  opcode(0xF7);               \/* Opcode F7 \/0 *\/\n-  ins_encode( SetInstMark, OpcP, RMopc_Mem(0x00,op), Con_d32(0xFFFFFFFF), ClearInstMark );\n-  ins_pipe( ialu_cr_reg_imm );\n-%}\n-\n-\/\/ Yanked all unsigned pointer compare operations.\n-\/\/ Pointer compares are done with CmpP which is already unsigned.\n-\n-\/\/----------Max and Min--------------------------------------------------------\n-\/\/ Min Instructions\n-\/\/\/\/\n-\/\/   *** Min and Max using the conditional move are slower than the\n-\/\/   *** branch version on a Pentium III.\n-\/\/ \/\/ Conditional move for min\n-\/\/instruct cmovI_reg_lt( rRegI op2, rRegI op1, eFlagsReg cr ) %{\n-\/\/  effect( USE_DEF op2, USE op1, USE cr );\n-\/\/  format %{ \"CMOVlt $op2,$op1\\t! min\" %}\n-\/\/  opcode(0x4C,0x0F);\n-\/\/  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );\n-\/\/  ins_pipe( pipe_cmov_reg );\n-\/\/%}\n-\/\/\n-\/\/\/\/ Min Register with Register (P6 version)\n-\/\/instruct minI_eReg_p6( rRegI op1, rRegI op2 ) %{\n-\/\/  predicate(VM_Version::supports_cmov() );\n-\/\/  match(Set op2 (MinI op1 op2));\n-\/\/  ins_cost(200);\n-\/\/  expand %{\n-\/\/    eFlagsReg cr;\n-\/\/    compI_eReg(cr,op1,op2);\n-\/\/    cmovI_reg_lt(op2,op1,cr);\n-\/\/  %}\n-\/\/%}\n-\n-\/\/ Min Register with Register (generic version)\n-instruct minI_eReg(rRegI dst, rRegI src, eFlagsReg flags) %{\n-  match(Set dst (MinI dst src));\n-  effect(KILL flags);\n-  ins_cost(300);\n-\n-  format %{ \"MIN    $dst,$src\" %}\n-  opcode(0xCC);\n-  ins_encode( min_enc(dst,src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Max Register with Register\n-\/\/   *** Min and Max using the conditional move are slower than the\n-\/\/   *** branch version on a Pentium III.\n-\/\/ \/\/ Conditional move for max\n-\/\/instruct cmovI_reg_gt( rRegI op2, rRegI op1, eFlagsReg cr ) %{\n-\/\/  effect( USE_DEF op2, USE op1, USE cr );\n-\/\/  format %{ \"CMOVgt $op2,$op1\\t! max\" %}\n-\/\/  opcode(0x4F,0x0F);\n-\/\/  ins_encode( OpcS, OpcP, RegReg( op2, op1 ) );\n-\/\/  ins_pipe( pipe_cmov_reg );\n-\/\/%}\n-\/\/\n-\/\/ \/\/ Max Register with Register (P6 version)\n-\/\/instruct maxI_eReg_p6( rRegI op1, rRegI op2 ) %{\n-\/\/  predicate(VM_Version::supports_cmov() );\n-\/\/  match(Set op2 (MaxI op1 op2));\n-\/\/  ins_cost(200);\n-\/\/  expand %{\n-\/\/    eFlagsReg cr;\n-\/\/    compI_eReg(cr,op1,op2);\n-\/\/    cmovI_reg_gt(op2,op1,cr);\n-\/\/  %}\n-\/\/%}\n-\n-\/\/ Max Register with Register (generic version)\n-instruct maxI_eReg(rRegI dst, rRegI src, eFlagsReg flags) %{\n-  match(Set dst (MaxI dst src));\n-  effect(KILL flags);\n-  ins_cost(300);\n-\n-  format %{ \"MAX    $dst,$src\" %}\n-  opcode(0xCC);\n-  ins_encode( max_enc(dst,src) );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ Counted Loop limit node which represents exact final iterator value.\n-\/\/ Note: the resulting value should fit into integer range since\n-\/\/ counted loops have limit check on overflow.\n-instruct loopLimit_eReg(eAXRegI limit, nadxRegI init, immI stride, eDXRegI limit_hi, nadxRegI tmp, eFlagsReg flags) %{\n-  match(Set limit (LoopLimit (Binary init limit) stride));\n-  effect(TEMP limit_hi, TEMP tmp, KILL flags);\n-  ins_cost(300);\n-\n-  format %{ \"loopLimit $init,$limit,$stride  # $limit = $init + $stride *( $limit - $init + $stride -1)\/ $stride, kills $limit_hi\" %}\n-  ins_encode %{\n-    int strd = (int)$stride$$constant;\n-    assert(strd != 1 && strd != -1, \"sanity\");\n-    int m1 = (strd > 0) ? 1 : -1;\n-    \/\/ Convert limit to long (EAX:EDX)\n-    __ cdql();\n-    \/\/ Convert init to long (init:tmp)\n-    __ movl($tmp$$Register, $init$$Register);\n-    __ sarl($tmp$$Register, 31);\n-    \/\/ $limit - $init\n-    __ subl($limit$$Register, $init$$Register);\n-    __ sbbl($limit_hi$$Register, $tmp$$Register);\n-    \/\/ + ($stride - 1)\n-    if (strd > 0) {\n-      __ addl($limit$$Register, (strd - 1));\n-      __ adcl($limit_hi$$Register, 0);\n-      __ movl($tmp$$Register, strd);\n-    } else {\n-      __ addl($limit$$Register, (strd + 1));\n-      __ adcl($limit_hi$$Register, -1);\n-      __ lneg($limit_hi$$Register, $limit$$Register);\n-      __ movl($tmp$$Register, -strd);\n-    }\n-    \/\/ signed division: (EAX:EDX) \/ pos_stride\n-    __ idivl($tmp$$Register);\n-    if (strd < 0) {\n-      \/\/ restore sign\n-      __ negl($tmp$$Register);\n-    }\n-    \/\/ (EAX) * stride\n-    __ mull($tmp$$Register);\n-    \/\/ + init (ignore upper bits)\n-    __ addl($limit$$Register, $init$$Register);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ Branch Instructions\n-\/\/ Jump Table\n-instruct jumpXtnd(rRegI switch_val) %{\n-  match(Jump switch_val);\n-  ins_cost(350);\n-  format %{  \"JMP    [$constantaddress](,$switch_val,1)\\n\\t\" %}\n-  ins_encode %{\n-    \/\/ Jump to Address(table_base + switch_reg)\n-    Address index(noreg, $switch_val$$Register, Address::times_1);\n-    __ jump(ArrayAddress($constantaddress, index), noreg);\n-  %}\n-  ins_pipe(pipe_jmp);\n-%}\n-\n-\/\/ Jump Direct - Label defines a relative address from JMP+1\n-instruct jmpDir(label labl) %{\n-  match(Goto);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"JMP    $labl\" %}\n-  size(5);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jmp(*L, false); \/\/ Always long jump\n-  %}\n-  ins_pipe( pipe_jmp );\n-%}\n-\n-\/\/ Jump Direct Conditional - Label defines a relative address from Jcc+1\n-instruct jmpCon(cmpOp cop, eFlagsReg cr, label labl) %{\n-  match(If cop cr);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop    $labl\" %}\n-  size(6);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jcc((Assembler::Condition)($cop$$cmpcode), *L, false); \/\/ Always long jump\n-  %}\n-  ins_pipe( pipe_jcc );\n-%}\n-\n-\/\/ Jump Direct Conditional - Label defines a relative address from Jcc+1\n-instruct jmpLoopEnd(cmpOp cop, eFlagsReg cr, label labl) %{\n-  match(CountedLoopEnd cop cr);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop    $labl\\t# Loop end\" %}\n-  size(6);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jcc((Assembler::Condition)($cop$$cmpcode), *L, false); \/\/ Always long jump\n-  %}\n-  ins_pipe( pipe_jcc );\n-%}\n-\n-\/\/ Jump Direct Conditional - using unsigned comparison\n-instruct jmpConU(cmpOpU cop, eFlagsRegU cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop,u  $labl\" %}\n-  size(6);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jcc((Assembler::Condition)($cop$$cmpcode), *L, false); \/\/ Always long jump\n-  %}\n-  ins_pipe(pipe_jcc);\n-%}\n-\n-instruct jmpConUCF(cmpOpUCF cop, eFlagsRegUCF cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(200);\n-  format %{ \"J$cop,u  $labl\" %}\n-  size(6);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jcc((Assembler::Condition)($cop$$cmpcode), *L, false); \/\/ Always long jump\n-  %}\n-  ins_pipe(pipe_jcc);\n-%}\n-\n-instruct jmpConUCF2(cmpOpUCF2 cop, eFlagsRegUCF cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(200);\n-  format %{ $$template\n-    if ($cop$$cmpcode == Assembler::notEqual) {\n-      $$emit$$\"JP,u   $labl\\n\\t\"\n-      $$emit$$\"J$cop,u   $labl\"\n-    } else {\n-      $$emit$$\"JP,u   done\\n\\t\"\n-      $$emit$$\"J$cop,u   $labl\\n\\t\"\n-      $$emit$$\"done:\"\n-    }\n-  %}\n-  ins_encode %{\n-    Label* l = $labl$$label;\n-    if ($cop$$cmpcode == Assembler::notEqual) {\n-      __ jcc(Assembler::parity, *l, false);\n-      __ jcc(Assembler::notEqual, *l, false);\n-    } else if ($cop$$cmpcode == Assembler::equal) {\n-      Label done;\n-      __ jccb(Assembler::parity, done);\n-      __ jcc(Assembler::equal, *l, false);\n-      __ bind(done);\n-    } else {\n-       ShouldNotReachHere();\n-    }\n-  %}\n-  ins_pipe(pipe_jcc);\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ The 2nd slow-half of a subtype check.  Scan the subklass's 2ndary superklass\n-\/\/ array for an instance of the superklass.  Set a hidden internal cache on a\n-\/\/ hit (cache is checked with exposed code in gen_subtype_check()).  Return\n-\/\/ NZ for a miss or zero for a hit.  The encoding ALSO sets flags.\n-instruct partialSubtypeCheck( eDIRegP result, eSIRegP sub, eAXRegP super, eCXRegI rcx, eFlagsReg cr ) %{\n-  match(Set result (PartialSubtypeCheck sub super));\n-  effect( KILL rcx, KILL cr );\n-\n-  ins_cost(1100);  \/\/ slightly larger than the next version\n-  format %{ \"MOV    EDI,[$sub+Klass::secondary_supers]\\n\\t\"\n-            \"MOV    ECX,[EDI+ArrayKlass::length]\\t# length to scan\\n\\t\"\n-            \"ADD    EDI,ArrayKlass::base_offset\\t# Skip to start of data; set NZ in case count is zero\\n\\t\"\n-            \"REPNE SCASD\\t# Scan *EDI++ for a match with EAX while CX-- != 0\\n\\t\"\n-            \"JNE,s  miss\\t\\t# Missed: EDI not-zero\\n\\t\"\n-            \"MOV    [$sub+Klass::secondary_super_cache],$super\\t# Hit: update cache\\n\\t\"\n-            \"XOR    $result,$result\\t\\t Hit: EDI zero\\n\\t\"\n-     \"miss:\\t\" %}\n-\n-  opcode(0x1); \/\/ Force a XOR of EDI\n-  ins_encode( enc_PartialSubtypeCheck() );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct partialSubtypeCheck_vs_Zero( eFlagsReg cr, eSIRegP sub, eAXRegP super, eCXRegI rcx, eDIRegP result, immP0 zero ) %{\n-  match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));\n-  effect( KILL rcx, KILL result );\n-\n-  ins_cost(1000);\n-  format %{ \"MOV    EDI,[$sub+Klass::secondary_supers]\\n\\t\"\n-            \"MOV    ECX,[EDI+ArrayKlass::length]\\t# length to scan\\n\\t\"\n-            \"ADD    EDI,ArrayKlass::base_offset\\t# Skip to start of data; set NZ in case count is zero\\n\\t\"\n-            \"REPNE SCASD\\t# Scan *EDI++ for a match with EAX while CX-- != 0\\n\\t\"\n-            \"JNE,s  miss\\t\\t# Missed: flags NZ\\n\\t\"\n-            \"MOV    [$sub+Klass::secondary_super_cache],$super\\t# Hit: update cache, flags Z\\n\\t\"\n-     \"miss:\\t\" %}\n-\n-  opcode(0x0);  \/\/ No need to XOR EDI\n-  ins_encode( enc_PartialSubtypeCheck() );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ Branch Instructions -- short offset versions\n-\/\/\n-\/\/ These instructions are used to replace jumps of a long offset (the default\n-\/\/ match) with jumps of a shorter offset.  These instructions are all tagged\n-\/\/ with the ins_short_branch attribute, which causes the ADLC to suppress the\n-\/\/ match rules in general matching.  Instead, the ADLC generates a conversion\n-\/\/ method in the MachNode which can be used to do in-place replacement of the\n-\/\/ long variant with the shorter variant.  The compiler will determine if a\n-\/\/ branch can be taken by the is_short_branch_offset() predicate in the machine\n-\/\/ specific code section of the file.\n-\n-\/\/ Jump Direct - Label defines a relative address from JMP+1\n-instruct jmpDir_short(label labl) %{\n-  match(Goto);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"JMP,s  $labl\" %}\n-  size(2);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jmpb(*L);\n-  %}\n-  ins_pipe( pipe_jmp );\n-  ins_short_branch(1);\n-%}\n-\n-\/\/ Jump Direct Conditional - Label defines a relative address from Jcc+1\n-instruct jmpCon_short(cmpOp cop, eFlagsReg cr, label labl) %{\n-  match(If cop cr);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop,s  $labl\" %}\n-  size(2);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jccb((Assembler::Condition)($cop$$cmpcode), *L);\n-  %}\n-  ins_pipe( pipe_jcc );\n-  ins_short_branch(1);\n-%}\n-\n-\/\/ Jump Direct Conditional - Label defines a relative address from Jcc+1\n-instruct jmpLoopEnd_short(cmpOp cop, eFlagsReg cr, label labl) %{\n-  match(CountedLoopEnd cop cr);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop,s  $labl\\t# Loop end\" %}\n-  size(2);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jccb((Assembler::Condition)($cop$$cmpcode), *L);\n-  %}\n-  ins_pipe( pipe_jcc );\n-  ins_short_branch(1);\n-%}\n-\n-\/\/ Jump Direct Conditional - using unsigned comparison\n-instruct jmpConU_short(cmpOpU cop, eFlagsRegU cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop,us $labl\" %}\n-  size(2);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jccb((Assembler::Condition)($cop$$cmpcode), *L);\n-  %}\n-  ins_pipe( pipe_jcc );\n-  ins_short_branch(1);\n-%}\n-\n-instruct jmpConUCF_short(cmpOpUCF cop, eFlagsRegUCF cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ \"J$cop,us $labl\" %}\n-  size(2);\n-  ins_encode %{\n-    Label* L = $labl$$label;\n-    __ jccb((Assembler::Condition)($cop$$cmpcode), *L);\n-  %}\n-  ins_pipe( pipe_jcc );\n-  ins_short_branch(1);\n-%}\n-\n-instruct jmpConUCF2_short(cmpOpUCF2 cop, eFlagsRegUCF cmp, label labl) %{\n-  match(If cop cmp);\n-  effect(USE labl);\n-\n-  ins_cost(300);\n-  format %{ $$template\n-    if ($cop$$cmpcode == Assembler::notEqual) {\n-      $$emit$$\"JP,u,s   $labl\\n\\t\"\n-      $$emit$$\"J$cop,u,s   $labl\"\n-    } else {\n-      $$emit$$\"JP,u,s   done\\n\\t\"\n-      $$emit$$\"J$cop,u,s  $labl\\n\\t\"\n-      $$emit$$\"done:\"\n-    }\n-  %}\n-  size(4);\n-  ins_encode %{\n-    Label* l = $labl$$label;\n-    if ($cop$$cmpcode == Assembler::notEqual) {\n-      __ jccb(Assembler::parity, *l);\n-      __ jccb(Assembler::notEqual, *l);\n-    } else if ($cop$$cmpcode == Assembler::equal) {\n-      Label done;\n-      __ jccb(Assembler::parity, done);\n-      __ jccb(Assembler::equal, *l);\n-      __ bind(done);\n-    } else {\n-       ShouldNotReachHere();\n-    }\n-  %}\n-  ins_pipe(pipe_jcc);\n-  ins_short_branch(1);\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ Long Compare\n-\/\/\n-\/\/ Currently we hold longs in 2 registers.  Comparing such values efficiently\n-\/\/ is tricky.  The flavor of compare used depends on whether we are testing\n-\/\/ for LT, LE, or EQ.  For a simple LT test we can check just the sign bit.\n-\/\/ The GE test is the negated LT test.  The LE test can be had by commuting\n-\/\/ the operands (yielding a GE test) and then negating; negate again for the\n-\/\/ GT test.  The EQ test is done by ORcc'ing the high and low halves, and the\n-\/\/ NE test is negated from that.\n-\n-\/\/ Due to a shortcoming in the ADLC, it mixes up expressions like:\n-\/\/ (foo (CmpI (CmpL X Y) 0)) and (bar (CmpI (CmpL X 0L) 0)).  Note the\n-\/\/ difference between 'Y' and '0L'.  The tree-matches for the CmpI sections\n-\/\/ are collapsed internally in the ADLC's dfa-gen code.  The match for\n-\/\/ (CmpI (CmpL X Y) 0) is silently replaced with (CmpI (CmpL X 0L) 0) and the\n-\/\/ foo match ends up with the wrong leaf.  One fix is to not match both\n-\/\/ reg-reg and reg-zero forms of long-compare.  This is unfortunate because\n-\/\/ both forms beat the trinary form of long-compare and both are very useful\n-\/\/ on Intel which has so few registers.\n-\n-\/\/ Manifest a CmpL result in an integer register.  Very painful.\n-\/\/ This is the test to avoid.\n-instruct cmpL3_reg_reg(eSIRegI dst, eRegL src1, eRegL src2, eFlagsReg flags ) %{\n-  match(Set dst (CmpL3 src1 src2));\n-  effect( KILL flags );\n-  ins_cost(1000);\n-  format %{ \"XOR    $dst,$dst\\n\\t\"\n-            \"CMP    $src1.hi,$src2.hi\\n\\t\"\n-            \"JLT,s  m_one\\n\\t\"\n-            \"JGT,s  p_one\\n\\t\"\n-            \"CMP    $src1.lo,$src2.lo\\n\\t\"\n-            \"JB,s   m_one\\n\\t\"\n-            \"JEQ,s  done\\n\"\n-    \"p_one:\\tINC    $dst\\n\\t\"\n-            \"JMP,s  done\\n\"\n-    \"m_one:\\tDEC    $dst\\n\"\n-     \"done:\" %}\n-  ins_encode %{\n-    Label p_one, m_one, done;\n-    __ xorptr($dst$$Register, $dst$$Register);\n-    __ cmpl(HIGH_FROM_LOW($src1$$Register), HIGH_FROM_LOW($src2$$Register));\n-    __ jccb(Assembler::less,    m_one);\n-    __ jccb(Assembler::greater, p_one);\n-    __ cmpl($src1$$Register, $src2$$Register);\n-    __ jccb(Assembler::below,   m_one);\n-    __ jccb(Assembler::equal,   done);\n-    __ bind(p_one);\n-    __ incrementl($dst$$Register);\n-    __ jmpb(done);\n-    __ bind(m_one);\n-    __ decrementl($dst$$Register);\n-    __ bind(done);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for LT or GE\n-\/\/ compares.  Can be used for LE or GT compares by reversing arguments.\n-\/\/ NOT GOOD FOR EQ\/NE tests.\n-instruct cmpL_zero_flags_LTGE( flagsReg_long_LTGE flags, eRegL src, immL0 zero ) %{\n-  match( Set flags (CmpL src zero ));\n-  ins_cost(100);\n-  format %{ \"TEST   $src.hi,$src.hi\" %}\n-  opcode(0x85);\n-  ins_encode( OpcP, RegReg_Hi2( src, src ) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for LT or GE\n-\/\/ compares.  Can be used for LE or GT compares by reversing arguments.\n-\/\/ NOT GOOD FOR EQ\/NE tests.\n-instruct cmpL_reg_flags_LTGE( flagsReg_long_LTGE flags, eRegL src1, eRegL src2, rRegI tmp ) %{\n-  match( Set flags (CmpL src1 src2 ));\n-  effect( TEMP tmp );\n-  ins_cost(300);\n-  format %{ \"CMP    $src1.lo,$src2.lo\\t! Long compare; set flags for low bits\\n\\t\"\n-            \"MOV    $tmp,$src1.hi\\n\\t\"\n-            \"SBB    $tmp,$src2.hi\\t! Compute flags for long compare\" %}\n-  ins_encode( long_cmp_flags2( src1, src2, tmp ) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-\/\/ Long compares reg < zero\/req OR reg >= zero\/req.\n-\/\/ Just a wrapper for a normal branch, plus the predicate test.\n-instruct cmpL_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate( _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge );\n-  expand %{\n-    jmpCon(cmp,flags,labl);    \/\/ JLT or JGE...\n-  %}\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for LT or GE\n-\/\/ compares.  Can be used for LE or GT compares by reversing arguments.\n-\/\/ NOT GOOD FOR EQ\/NE tests.\n-instruct cmpUL_zero_flags_LTGE(flagsReg_ulong_LTGE flags, eRegL src, immL0 zero) %{\n-  match(Set flags (CmpUL src zero));\n-  ins_cost(100);\n-  format %{ \"TEST   $src.hi,$src.hi\" %}\n-  opcode(0x85);\n-  ins_encode(OpcP, RegReg_Hi2(src, src));\n-  ins_pipe(ialu_cr_reg_reg);\n-%}\n-\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for LT or GE\n-\/\/ compares.  Can be used for LE or GT compares by reversing arguments.\n-\/\/ NOT GOOD FOR EQ\/NE tests.\n-instruct cmpUL_reg_flags_LTGE(flagsReg_ulong_LTGE flags, eRegL src1, eRegL src2, rRegI tmp) %{\n-  match(Set flags (CmpUL src1 src2));\n-  effect(TEMP tmp);\n-  ins_cost(300);\n-  format %{ \"CMP    $src1.lo,$src2.lo\\t! Unsigned long compare; set flags for low bits\\n\\t\"\n-            \"MOV    $tmp,$src1.hi\\n\\t\"\n-            \"SBB    $tmp,$src2.hi\\t! Compute flags for unsigned long compare\" %}\n-  ins_encode(long_cmp_flags2(src1, src2, tmp));\n-  ins_pipe(ialu_cr_reg_reg);\n-%}\n-\n-\/\/ Unsigned long compares reg < zero\/req OR reg >= zero\/req.\n-\/\/ Just a wrapper for a normal branch, plus the predicate test.\n-instruct cmpUL_LTGE(cmpOpU cmp, flagsReg_ulong_LTGE flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate(_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge);\n-  expand %{\n-    jmpCon(cmp, flags, labl);    \/\/ JLT or JGE...\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE longs.\n-instruct cmovLL_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, eRegL dst, eRegL src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  ins_cost(400);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg_Lo2( dst, src ), enc_cmov(cmp), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovLL_mem_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, eRegL dst, load_long_memory src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  ins_cost(500);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem(dst, src), enc_cmov(cmp), RegMem_Hi(dst, src), ClearInstMark );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovLL_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegL dst, eRegL src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  ins_cost(400);\n-  expand %{\n-    cmovLL_reg_LTGE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-instruct cmovLL_mem_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegL dst, load_long_memory src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  ins_cost(500);\n-  expand %{\n-    cmovLL_mem_LTGE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ints.\n-instruct cmovII_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovII_mem_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem( dst, src ), ClearInstMark );\n-  ins_pipe( pipe_cmov_mem );\n-%}\n-\n-instruct cmovII_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovII_reg_LTGE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-instruct cmovII_mem_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  expand %{\n-    cmovII_mem_LTGE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ptrs.\n-instruct cmovPP_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n-instruct cmovPP_reg_LTGE_U(cmpOpU cmp, flagsReg_ulong_LTGE flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovPP_reg_LTGE(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDDPR_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, regDPR dst, regDPR src) %{\n-  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovDPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDD_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, regD dst, regD src) %{\n-  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovD_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-instruct cmovFFPR_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, regFPR dst, regFPR src) %{\n-  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovFPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-instruct cmovFF_reg_LTGE(cmpOp cmp, flagsReg_long_LTGE flags, regF dst, regF src) %{\n-  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::lt || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ge ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovF_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for EQ\/NE compares.\n-instruct cmpL_zero_flags_EQNE( flagsReg_long_EQNE flags, eRegL src, immL0 zero, rRegI tmp ) %{\n-  match( Set flags (CmpL src zero ));\n-  effect(TEMP tmp);\n-  ins_cost(200);\n-  format %{ \"MOV    $tmp,$src.lo\\n\\t\"\n-            \"OR     $tmp,$src.hi\\t! Long is EQ\/NE 0?\" %}\n-  ins_encode( long_cmp_flags0( src, tmp ) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for EQ\/NE compares.\n-instruct cmpL_reg_flags_EQNE( flagsReg_long_EQNE flags, eRegL src1, eRegL src2 ) %{\n-  match( Set flags (CmpL src1 src2 ));\n-  ins_cost(200+300);\n-  format %{ \"CMP    $src1.lo,$src2.lo\\t! Long compare; set flags for low bits\\n\\t\"\n-            \"JNE,s  skip\\n\\t\"\n-            \"CMP    $src1.hi,$src2.hi\\n\\t\"\n-     \"skip:\\t\" %}\n-  ins_encode( long_cmp_flags1( src1, src2 ) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-\/\/ Long compare reg == zero\/reg OR reg != zero\/reg\n-\/\/ Just a wrapper for a normal branch, plus the predicate test.\n-instruct cmpL_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate( _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne );\n-  expand %{\n-    jmpCon(cmp,flags,labl);    \/\/ JEQ or JNE...\n-  %}\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for EQ\/NE compares.\n-instruct cmpUL_zero_flags_EQNE(flagsReg_ulong_EQNE flags, eRegL src, immL0 zero, rRegI tmp) %{\n-  match(Set flags (CmpUL src zero));\n-  effect(TEMP tmp);\n-  ins_cost(200);\n-  format %{ \"MOV    $tmp,$src.lo\\n\\t\"\n-            \"OR     $tmp,$src.hi\\t! Unsigned long is EQ\/NE 0?\" %}\n-  ins_encode(long_cmp_flags0(src, tmp));\n-  ins_pipe(ialu_reg_reg_long);\n-%}\n-\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for EQ\/NE compares.\n-instruct cmpUL_reg_flags_EQNE(flagsReg_ulong_EQNE flags, eRegL src1, eRegL src2) %{\n-  match(Set flags (CmpUL src1 src2));\n-  ins_cost(200+300);\n-  format %{ \"CMP    $src1.lo,$src2.lo\\t! Unsigned long compare; set flags for low bits\\n\\t\"\n-            \"JNE,s  skip\\n\\t\"\n-            \"CMP    $src1.hi,$src2.hi\\n\\t\"\n-     \"skip:\\t\" %}\n-  ins_encode(long_cmp_flags1(src1, src2));\n-  ins_pipe(ialu_cr_reg_reg);\n-%}\n-\n-\/\/ Unsigned long compare reg == zero\/reg OR reg != zero\/reg\n-\/\/ Just a wrapper for a normal branch, plus the predicate test.\n-instruct cmpUL_EQNE(cmpOpU cmp, flagsReg_ulong_EQNE flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate(_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne);\n-  expand %{\n-    jmpCon(cmp, flags, labl);    \/\/ JEQ or JNE...\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE longs.\n-instruct cmovLL_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, eRegL dst, eRegL src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  ins_cost(400);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg_Lo2( dst, src ), enc_cmov(cmp), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovLL_mem_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, eRegL dst, load_long_memory src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  ins_cost(500);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem(dst, src), enc_cmov(cmp), RegMem_Hi(dst, src), ClearInstMark );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ints.\n-instruct cmovII_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovII_mem_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem( dst, src ), ClearInstMark );\n-  ins_pipe( pipe_cmov_mem );\n-%}\n-\n-instruct cmovII_reg_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovII_reg_EQNE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-instruct cmovII_mem_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  expand %{\n-    cmovII_mem_EQNE(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ptrs.\n-instruct cmovPP_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n-instruct cmovPP_reg_EQNE_U(cmpOpU cmp, flagsReg_ulong_EQNE flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovPP_reg_EQNE(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDDPR_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, regDPR dst, regDPR src) %{\n-  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovDPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDD_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, regD dst, regD src) %{\n-  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovD_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-instruct cmovFFPR_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, regFPR dst, regFPR src) %{\n-  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovFPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-instruct cmovFF_reg_EQNE(cmpOp cmp, flagsReg_long_EQNE flags, regF dst, regF src) %{\n-  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::eq || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::ne ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovF_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for LE or GT compares.\n-\/\/ Same as cmpL_reg_flags_LEGT except must negate src\n-instruct cmpL_zero_flags_LEGT( flagsReg_long_LEGT flags, eRegL src, immL0 zero, rRegI tmp ) %{\n-  match( Set flags (CmpL src zero ));\n-  effect( TEMP tmp );\n-  ins_cost(300);\n-  format %{ \"XOR    $tmp,$tmp\\t# Long compare for -$src < 0, use commuted test\\n\\t\"\n-            \"CMP    $tmp,$src.lo\\n\\t\"\n-            \"SBB    $tmp,$src.hi\\n\\t\" %}\n-  ins_encode( long_cmp_flags3(src, tmp) );\n-  ins_pipe( ialu_reg_reg_long );\n-%}\n-\n-\/\/ Manifest a CmpL result in the normal flags.  Only good for LE or GT compares.\n-\/\/ Same as cmpL_reg_flags_LTGE except operands swapped.  Swapping operands\n-\/\/ requires a commuted test to get the same result.\n-instruct cmpL_reg_flags_LEGT( flagsReg_long_LEGT flags, eRegL src1, eRegL src2, rRegI tmp ) %{\n-  match( Set flags (CmpL src1 src2 ));\n-  effect( TEMP tmp );\n-  ins_cost(300);\n-  format %{ \"CMP    $src2.lo,$src1.lo\\t! Long compare, swapped operands, use with commuted test\\n\\t\"\n-            \"MOV    $tmp,$src2.hi\\n\\t\"\n-            \"SBB    $tmp,$src1.hi\\t! Compute flags for long compare\" %}\n-  ins_encode( long_cmp_flags2( src2, src1, tmp ) );\n-  ins_pipe( ialu_cr_reg_reg );\n-%}\n-\n-\/\/ Long compares reg < zero\/req OR reg >= zero\/req.\n-\/\/ Just a wrapper for a normal branch, plus the predicate test\n-instruct cmpL_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate( _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le );\n-  ins_cost(300);\n-  expand %{\n-    jmpCon(cmp,flags,labl);    \/\/ JGT or JLE...\n-  %}\n-%}\n-\n-\/\/======\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for LE or GT compares.\n-\/\/ Same as cmpUL_reg_flags_LEGT except must negate src\n-instruct cmpUL_zero_flags_LEGT(flagsReg_ulong_LEGT flags, eRegL src, immL0 zero, rRegI tmp) %{\n-  match(Set flags (CmpUL src zero));\n-  effect(TEMP tmp);\n-  ins_cost(300);\n-  format %{ \"XOR    $tmp,$tmp\\t# Unsigned long compare for -$src < 0, use commuted test\\n\\t\"\n-            \"CMP    $tmp,$src.lo\\n\\t\"\n-            \"SBB    $tmp,$src.hi\\n\\t\" %}\n-  ins_encode(long_cmp_flags3(src, tmp));\n-  ins_pipe(ialu_reg_reg_long);\n-%}\n-\n-\/\/ Manifest a CmpUL result in the normal flags.  Only good for LE or GT compares.\n-\/\/ Same as cmpUL_reg_flags_LTGE except operands swapped.  Swapping operands\n-\/\/ requires a commuted test to get the same result.\n-instruct cmpUL_reg_flags_LEGT(flagsReg_ulong_LEGT flags, eRegL src1, eRegL src2, rRegI tmp) %{\n-  match(Set flags (CmpUL src1 src2));\n-  effect(TEMP tmp);\n-  ins_cost(300);\n-  format %{ \"CMP    $src2.lo,$src1.lo\\t! Unsigned long compare, swapped operands, use with commuted test\\n\\t\"\n-            \"MOV    $tmp,$src2.hi\\n\\t\"\n-            \"SBB    $tmp,$src1.hi\\t! Compute flags for unsigned long compare\" %}\n-  ins_encode(long_cmp_flags2( src2, src1, tmp));\n-  ins_pipe(ialu_cr_reg_reg);\n-%}\n-\n-\/\/ Unsigned long compares reg < zero\/req OR reg >= zero\/req.\n-\/\/ Just a wrapper for a normal branch, plus the predicate test\n-instruct cmpUL_LEGT(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, label labl) %{\n-  match(If cmp flags);\n-  effect(USE labl);\n-  predicate(_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt || _kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le);\n-  ins_cost(300);\n-  expand %{\n-    jmpCon(cmp, flags, labl);    \/\/ JGT or JLE...\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE longs.\n-instruct cmovLL_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, eRegL dst, eRegL src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  ins_cost(400);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg_Lo2( dst, src ), enc_cmov(cmp), RegReg_Hi2( dst, src ) );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovLL_mem_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, eRegL dst, load_long_memory src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  ins_cost(500);\n-  format %{ \"CMOV$cmp $dst.lo,$src.lo\\n\\t\"\n-            \"CMOV$cmp $dst.hi,$src.hi+4\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem(dst, src), enc_cmov(cmp), RegMem_Hi(dst, src), ClearInstMark );\n-  ins_pipe( pipe_cmov_reg_long );\n-%}\n-\n-instruct cmovLL_reg_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, eRegL dst, eRegL src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst src)));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  ins_cost(400);\n-  expand %{\n-    cmovLL_reg_LEGT(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-instruct cmovLL_mem_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, eRegL dst, load_long_memory src) %{\n-  match(Set dst (CMoveL (Binary cmp flags) (Binary dst (LoadL src))));\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  ins_cost(500);\n-  expand %{\n-    cmovLL_mem_LEGT(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ints.\n-instruct cmovII_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-instruct cmovII_mem_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( SetInstMark, enc_cmov(cmp), RegMem( dst, src ), ClearInstMark );\n-  ins_pipe( pipe_cmov_mem );\n-%}\n-\n-instruct cmovII_reg_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, rRegI dst, rRegI src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovII_reg_LEGT(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-instruct cmovII_mem_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, rRegI dst, memory src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveI (Binary cmp flags) (Binary dst (LoadI src))));\n-  ins_cost(250);\n-  expand %{\n-    cmovII_mem_LEGT(cmp, flags, dst, src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE ptrs.\n-instruct cmovPP_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  format %{ \"CMOV$cmp $dst,$src\" %}\n-  opcode(0x0F,0x40);\n-  ins_encode( enc_cmov(cmp), RegReg( dst, src ) );\n-  ins_pipe( pipe_cmov_reg );\n-%}\n-\n-\/\/ Compare 2 unsigned longs and CMOVE ptrs.\n-instruct cmovPP_reg_LEGT_U(cmpOpU_commute cmp, flagsReg_ulong_LEGT flags, eRegP dst, eRegP src) %{\n-  predicate(VM_Version::supports_cmov() && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveP (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    cmovPP_reg_LEGT(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDDPR_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, regDPR dst, regDPR src) %{\n-  predicate( UseSSE<=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovDPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\/\/ Compare 2 longs and CMOVE doubles\n-instruct cmovDD_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, regD dst, regD src) %{\n-  predicate( UseSSE>=2 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveD (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovD_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-instruct cmovFFPR_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, regFPR dst, regFPR src) %{\n-  predicate( UseSSE==0 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovFPR_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\n-instruct cmovFF_reg_LEGT(cmpOp_commute cmp, flagsReg_long_LEGT flags, regF dst, regF src) %{\n-  predicate( UseSSE>=1 && ( _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::le || _kids[0]->_kids[0]->_leaf->as_Bool()->_test._test == BoolTest::gt ));\n-  match(Set dst (CMoveF (Binary cmp flags) (Binary dst src)));\n-  ins_cost(200);\n-  expand %{\n-    fcmovF_regS(cmp,flags,dst,src);\n-  %}\n-%}\n-\n-\n-\/\/ ============================================================================\n-\/\/ Procedure Call\/Return Instructions\n-\/\/ Call Java Static Instruction\n-\/\/ Note: If this code changes, the corresponding ret_addr_offset() and\n-\/\/       compute_padding() functions will have to be adjusted.\n-instruct CallStaticJavaDirect(method meth) %{\n-  match(CallStaticJava);\n-  effect(USE meth);\n-\n-  ins_cost(300);\n-  format %{ \"CALL,static \" %}\n-  opcode(0xE8); \/* E8 cd *\/\n-  ins_encode( pre_call_resets,\n-              Java_Static_Call( meth ),\n-              call_epilog,\n-              post_call_FPU );\n-  ins_pipe( pipe_slow );\n-  ins_alignment(4);\n-%}\n-\n-\/\/ Call Java Dynamic Instruction\n-\/\/ Note: If this code changes, the corresponding ret_addr_offset() and\n-\/\/       compute_padding() functions will have to be adjusted.\n-instruct CallDynamicJavaDirect(method meth) %{\n-  match(CallDynamicJava);\n-  effect(USE meth);\n-\n-  ins_cost(300);\n-  format %{ \"MOV    EAX,(oop)-1\\n\\t\"\n-            \"CALL,dynamic\" %}\n-  opcode(0xE8); \/* E8 cd *\/\n-  ins_encode( pre_call_resets,\n-              Java_Dynamic_Call( meth ),\n-              call_epilog,\n-              post_call_FPU );\n-  ins_pipe( pipe_slow );\n-  ins_alignment(4);\n-%}\n-\n-\/\/ Call Runtime Instruction\n-instruct CallRuntimeDirect(method meth) %{\n-  match(CallRuntime );\n-  effect(USE meth);\n-\n-  ins_cost(300);\n-  format %{ \"CALL,runtime \" %}\n-  opcode(0xE8); \/* E8 cd *\/\n-  \/\/ Use FFREEs to clear entries in float stack\n-  ins_encode( pre_call_resets,\n-              FFree_Float_Stack_All,\n-              Java_To_Runtime( meth ),\n-              post_call_FPU );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ Call runtime without safepoint\n-instruct CallLeafDirect(method meth) %{\n-  match(CallLeaf);\n-  effect(USE meth);\n-\n-  ins_cost(300);\n-  format %{ \"CALL_LEAF,runtime \" %}\n-  opcode(0xE8); \/* E8 cd *\/\n-  ins_encode( pre_call_resets,\n-              FFree_Float_Stack_All,\n-              Java_To_Runtime( meth ),\n-              Verify_FPU_For_Leaf, post_call_FPU );\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct CallLeafNoFPDirect(method meth) %{\n-  match(CallLeafNoFP);\n-  effect(USE meth);\n-\n-  ins_cost(300);\n-  format %{ \"CALL_LEAF_NOFP,runtime \" %}\n-  opcode(0xE8); \/* E8 cd *\/\n-  ins_encode(pre_call_resets, Java_To_Runtime(meth));\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\n-\/\/ Return Instruction\n-\/\/ Remove the return address & jump to it.\n-instruct Ret() %{\n-  match(Return);\n-  format %{ \"RET\" %}\n-  opcode(0xC3);\n-  ins_encode(OpcP);\n-  ins_pipe( pipe_jmp );\n-%}\n-\n-\/\/ Tail Call; Jump from runtime stub to Java code.\n-\/\/ Also known as an 'interprocedural jump'.\n-\/\/ Target of jump will eventually return to caller.\n-\/\/ TailJump below removes the return address.\n-\/\/ Don't use ebp for 'jump_target' because a MachEpilogNode has already been\n-\/\/ emitted just above the TailCall which has reset ebp to the caller state.\n-instruct TailCalljmpInd(eRegP_no_EBP jump_target, eBXRegP method_ptr) %{\n-  match(TailCall jump_target method_ptr);\n-  ins_cost(300);\n-  format %{ \"JMP    $jump_target \\t# EBX holds method\" %}\n-  opcode(0xFF, 0x4);  \/* Opcode FF \/4 *\/\n-  ins_encode( OpcP, RegOpc(jump_target) );\n-  ins_pipe( pipe_jmp );\n-%}\n-\n-\n-\/\/ Tail Jump; remove the return address; jump to target.\n-\/\/ TailCall above leaves the return address around.\n-instruct tailjmpInd(eRegP_no_EBP jump_target, eAXRegP ex_oop) %{\n-  match( TailJump jump_target ex_oop );\n-  ins_cost(300);\n-  format %{ \"POP    EDX\\t# pop return address into dummy\\n\\t\"\n-            \"JMP    $jump_target \" %}\n-  opcode(0xFF, 0x4);  \/* Opcode FF \/4 *\/\n-  ins_encode( enc_pop_rdx,\n-              OpcP, RegOpc(jump_target) );\n-  ins_pipe( pipe_jmp );\n-%}\n-\n-\/\/ Forward exception.\n-instruct ForwardExceptionjmp()\n-%{\n-  match(ForwardException);\n-\n-  format %{ \"JMP    forward_exception_stub\" %}\n-  ins_encode %{\n-    __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()), noreg);\n-  %}\n-  ins_pipe(pipe_jmp);\n-%}\n-\n-\/\/ Create exception oop: created by stack-crawling runtime code.\n-\/\/ Created exception is now available to this handler, and is setup\n-\/\/ just prior to jumping to this handler.  No code emitted.\n-instruct CreateException( eAXRegP ex_oop )\n-%{\n-  match(Set ex_oop (CreateEx));\n-\n-  size(0);\n-  \/\/ use the following format syntax\n-  format %{ \"# exception oop is in EAX; no code emitted\" %}\n-  ins_encode();\n-  ins_pipe( empty );\n-%}\n-\n-\n-\/\/ Rethrow exception:\n-\/\/ The exception oop will come in the first argument position.\n-\/\/ Then JUMP (not call) to the rethrow stub code.\n-instruct RethrowException()\n-%{\n-  match(Rethrow);\n-\n-  \/\/ use the following format syntax\n-  format %{ \"JMP    rethrow_stub\" %}\n-  ins_encode(enc_rethrow);\n-  ins_pipe( pipe_jmp );\n-%}\n-\n-\/\/ inlined locking and unlocking\n-\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, eRegP thread) %{\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, USE_KILL box, TEMP thread);\n-  ins_cost(300);\n-  format %{ \"FASTLOCK $object,$box\\t! kills $box,$tmp,$scr\" %}\n-  ins_encode %{\n-    __ get_thread($thread$$Register);\n-    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n-                 $scr$$Register, noreg, noreg, $thread$$Register, nullptr);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct cmpFastUnlock(eFlagsReg cr, eRegP object, eAXRegP box, eRegP tmp ) %{\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, USE_KILL box);\n-  ins_cost(300);\n-  format %{ \"FASTUNLOCK $object,$box\\t! kills $box,$tmp\" %}\n-  ins_encode %{\n-    __ fast_unlock($object$$Register, $box$$Register, $tmp$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct cmpFastLockLightweight(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI eax_reg, eRegP tmp, eRegP thread) %{\n-  predicate(LockingMode == LM_LIGHTWEIGHT);\n-  match(Set cr (FastLock object box));\n-  effect(TEMP eax_reg, TEMP tmp, USE_KILL box, TEMP thread);\n-  ins_cost(300);\n-  format %{ \"FASTLOCK $object,$box\\t! kills $box,$eax_reg,$tmp\" %}\n-  ins_encode %{\n-    __ get_thread($thread$$Register);\n-    __ fast_lock_lightweight($object$$Register, $box$$Register, $eax_reg$$Register, $tmp$$Register, $thread$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct cmpFastUnlockLightweight(eFlagsReg cr, eRegP object, eAXRegP eax_reg, eRegP tmp, eRegP thread) %{\n-  predicate(LockingMode == LM_LIGHTWEIGHT);\n-  match(Set cr (FastUnlock object eax_reg));\n-  effect(TEMP tmp, USE_KILL eax_reg, TEMP thread);\n-  ins_cost(300);\n-  format %{ \"FASTUNLOCK $object,$eax_reg\\t! kills $eax_reg,$tmp\" %}\n-  ins_encode %{\n-    __ get_thread($thread$$Register);\n-    __ fast_unlock_lightweight($object$$Register, $eax_reg$$Register, $tmp$$Register, $thread$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct mask_all_evexL_LT32(kReg dst, eRegL src) %{\n-  predicate(Matcher::vector_length(n) <= 32);\n-  match(Set dst (MaskAll src));\n-  format %{ \"mask_all_evexL_LE32 $dst, $src \\t\" %}\n-  ins_encode %{\n-    int mask_len = Matcher::vector_length(this);\n-    __ vector_maskall_operation($dst$$KRegister, $src$$Register, mask_len);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct mask_all_evexL_GT32(kReg dst, eRegL src, kReg ktmp) %{\n-  predicate(Matcher::vector_length(n) > 32);\n-  match(Set dst (MaskAll src));\n-  effect(TEMP ktmp);\n-  format %{ \"mask_all_evexL_GT32 $dst, $src \\t! using $ktmp as TEMP \" %}\n-  ins_encode %{\n-    int mask_len = Matcher::vector_length(this);\n-    __ vector_maskall_operation32($dst$$KRegister, $src$$Register, $ktmp$$KRegister, mask_len);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct mask_all_evexI_GT32(kReg dst, rRegI src, kReg ktmp) %{\n-  predicate(Matcher::vector_length(n) > 32);\n-  match(Set dst (MaskAll src));\n-  effect(TEMP ktmp);\n-  format %{ \"mask_all_evexI_GT32 $dst, $src \\t! using $ktmp as TEMP\" %}\n-  ins_encode %{\n-    int mask_len = Matcher::vector_length(this);\n-    __ vector_maskall_operation32($dst$$KRegister, $src$$Register, $ktmp$$KRegister, mask_len);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-\/\/ ============================================================================\n-\/\/ Safepoint Instruction\n-instruct safePoint_poll_tls(eFlagsReg cr, eRegP_no_EBP poll) %{\n-  match(SafePoint poll);\n-  effect(KILL cr, USE poll);\n-\n-  format %{ \"TSTL   #EAX,[$poll]\\t! Safepoint: poll for GC\" %}\n-  ins_cost(125);\n-  \/\/ EBP would need size(3)\n-  size(2); \/* setting an explicit size will cause debug builds to assert if size is incorrect *\/\n-  ins_encode %{\n-    __ set_inst_mark();\n-    __ relocate(relocInfo::poll_type);\n-    __ clear_inst_mark();\n-    address pre_pc = __ pc();\n-    __ testl(rax, Address($poll$$Register, 0));\n-    address post_pc = __ pc();\n-    guarantee(pre_pc[0] == 0x85, \"must emit test-ax [reg]\");\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n-\n-\/\/ ============================================================================\n-\/\/ This name is KNOWN by the ADLC and cannot be changed.\n-\/\/ The ADLC forces a 'TypeRawPtr::BOTTOM' output type\n-\/\/ for this guy.\n-instruct tlsLoadP(eRegP dst, eFlagsReg cr) %{\n-  match(Set dst (ThreadLocal));\n-  effect(DEF dst, KILL cr);\n-\n-  format %{ \"MOV    $dst, Thread::current()\" %}\n-  ins_encode %{\n-    Register dstReg = as_Register($dst$$reg);\n-    __ get_thread(dstReg);\n-  %}\n-  ins_pipe( ialu_reg_fat );\n-%}\n-\n-\n-\n-\/\/----------PEEPHOLE RULES-----------------------------------------------------\n-\/\/ These must follow all instruction definitions as they use the names\n-\/\/ defined in the instructions definitions.\n-\/\/\n-\/\/ peepmatch ( root_instr_name [preceding_instruction]* );\n-\/\/\n-\/\/ peepconstraint %{\n-\/\/ (instruction_number.operand_name relational_op instruction_number.operand_name\n-\/\/  [, ...] );\n-\/\/ \/\/ instruction numbers are zero-based using left to right order in peepmatch\n-\/\/\n-\/\/ peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );\n-\/\/ \/\/ provide an instruction_number.operand_name for each operand that appears\n-\/\/ \/\/ in the replacement instruction's match rule\n-\/\/\n-\/\/ ---------VM FLAGS---------------------------------------------------------\n-\/\/\n-\/\/ All peephole optimizations can be turned off using -XX:-OptoPeephole\n-\/\/\n-\/\/ Each peephole rule is given an identifying number starting with zero and\n-\/\/ increasing by one in the order seen by the parser.  An individual peephole\n-\/\/ can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#\n-\/\/ on the command-line.\n-\/\/\n-\/\/ ---------CURRENT LIMITATIONS----------------------------------------------\n-\/\/\n-\/\/ Only match adjacent instructions in same basic block\n-\/\/ Only equality constraints\n-\/\/ Only constraints between operands, not (0.dest_reg == EAX_enc)\n-\/\/ Only one replacement instruction\n-\/\/\n-\/\/ ---------EXAMPLE----------------------------------------------------------\n-\/\/\n-\/\/ \/\/ pertinent parts of existing instructions in architecture description\n-\/\/ instruct movI(rRegI dst, rRegI src) %{\n-\/\/   match(Set dst (CopyI src));\n-\/\/ %}\n-\/\/\n-\/\/ instruct incI_eReg(rRegI dst, immI_1 src, eFlagsReg cr) %{\n-\/\/   match(Set dst (AddI dst src));\n-\/\/   effect(KILL cr);\n-\/\/ %}\n-\/\/\n-\/\/ \/\/ Change (inc mov) to lea\n-\/\/ peephole %{\n-\/\/   \/\/ increment preceded by register-register move\n-\/\/   peepmatch ( incI_eReg movI );\n-\/\/   \/\/ require that the destination register of the increment\n-\/\/   \/\/ match the destination register of the move\n-\/\/   peepconstraint ( 0.dst == 1.dst );\n-\/\/   \/\/ construct a replacement instruction that sets\n-\/\/   \/\/ the destination to ( move's source register + one )\n-\/\/   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );\n-\/\/ %}\n-\/\/\n-\/\/ Implementation no longer uses movX instructions since\n-\/\/ machine-independent system no longer uses CopyX nodes.\n-\/\/\n-\/\/ peephole %{\n-\/\/   peepmatch ( incI_eReg movI );\n-\/\/   peepconstraint ( 0.dst == 1.dst );\n-\/\/   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );\n-\/\/ %}\n-\/\/\n-\/\/ peephole %{\n-\/\/   peepmatch ( decI_eReg movI );\n-\/\/   peepconstraint ( 0.dst == 1.dst );\n-\/\/   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );\n-\/\/ %}\n-\/\/\n-\/\/ peephole %{\n-\/\/   peepmatch ( addI_eReg_imm movI );\n-\/\/   peepconstraint ( 0.dst == 1.dst );\n-\/\/   peepreplace ( leaI_eReg_immI( 0.dst 1.src 0.src ) );\n-\/\/ %}\n-\/\/\n-\/\/ peephole %{\n-\/\/   peepmatch ( addP_eReg_imm movP );\n-\/\/   peepconstraint ( 0.dst == 1.dst );\n-\/\/   peepreplace ( leaP_eReg_immI( 0.dst 1.src 0.src ) );\n-\/\/ %}\n-\n-\/\/ \/\/ Change load of spilled value to only a spill\n-\/\/ instruct storeI(memory mem, rRegI src) %{\n-\/\/   match(Set mem (StoreI mem src));\n-\/\/ %}\n-\/\/\n-\/\/ instruct loadI(rRegI dst, memory mem) %{\n-\/\/   match(Set dst (LoadI mem));\n-\/\/ %}\n-\/\/\n-peephole %{\n-  peepmatch ( loadI storeI );\n-  peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );\n-  peepreplace ( storeI( 1.mem 1.mem 1.src ) );\n-%}\n-\n-\/\/----------SMARTSPILL RULES---------------------------------------------------\n-\/\/ These must follow all instruction definitions as they use the names\n-\/\/ defined in the instructions definitions.\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":0,"deletions":13702,"binary":false,"changes":13702,"status":"deleted"},{"patch":"@@ -1,525 +0,0 @@\n-#\n-# Copyright (c) 2004, 2024, Oracle and\/or its affiliates. All rights reserved.\n-# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-#\n-# This code is free software; you can redistribute it and\/or modify it\n-# under the terms of the GNU General Public License version 2 only, as\n-# published by the Free Software Foundation.\n-#\n-# This code is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-# version 2 for more details (a copy is included in the LICENSE file that\n-# accompanied this code).\n-#\n-# You should have received a copy of the GNU General Public License version\n-# 2 along with this work; if not, write to the Free Software Foundation,\n-# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-#\n-# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-# or visit www.oracle.com if you need additional information or have any\n-# questions.\n-#\n-\n-#include \"defs.S.inc\"\n-\n-        # NOTE WELL!  The _Copy functions are called directly\n-        # from server-compiler-generated code via CallLeafNoFP,\n-        # which means that they *must* either not use floating\n-        # point or use it in the same manner as does the server\n-        # compiler.\n-\n-        .text\n-\n-# Set fpu to 53 bit precision.  This happens too early to use a stub.\n-        .p2align 4,,15\n-DECLARE_FUNC(fixcw):\n-        pushl    $0x27f\n-        fldcw    0(%esp)\n-        popl     %eax\n-        ret\n-\n-        .p2align 4,,15\n-DECLARE_FUNC(SpinPause):\n-        rep\n-        nop\n-        movl    $1, %eax\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_bytes(void* from,\n-        #                                               void* to,\n-        #                                               size_t count)\n-        #\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_arrayof_conjoint_bytes):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -1(%esi,%ecx),%eax   # from + count - 1\n-        jbe      acb_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      acb_CopyLeft\n-        # copy from low to high\n-acb_CopyRight:\n-        cmpl     $3,%ecx\n-        jbe      5f\n-1:      movl     %ecx,%eax\n-        shrl     $2,%ecx\n-        jz       4f\n-        cmpl     $32,%ecx\n-        ja       3f\n-        # copy aligned dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-        # copy aligned dwords\n-3:      rep;     smovl\n-4:      movl     %eax,%ecx\n-5:      andl     $3,%ecx\n-        jz       7f\n-        # copy suffix\n-        xorl     %eax,%eax\n-6:      movb     (%esi,%eax,1),%dl\n-        movb     %dl,(%edi,%eax,1)\n-        addl     $1,%eax\n-        subl     $1,%ecx\n-        jnz      6b\n-7:      popl     %edi\n-        popl     %esi\n-        ret\n-acb_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx),%edi   # to + count - 4\n-        movl     %eax,%esi            # from + count - 1\n-        movl     %ecx,%eax\n-        subl     $3,%esi              # from + count - 4\n-        cmpl     $3,%ecx\n-        jbe      5f\n-1:      shrl     $2,%ecx\n-        jz       4f\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        rep;     smovl\n-        jmp      4f\n-        .space 8\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      movl     %eax,%ecx\n-5:      andl     $3,%ecx\n-        jz       7f\n-        subl     %esi,%edi\n-        addl     $3,%esi\n-6:      movb     (%esi),%dl\n-        movb     %dl,(%edi,%esi,1)\n-        subl     $1,%esi\n-        subl     $1,%ecx\n-        jnz      6b\n-7:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jshorts_atomic(void* from,\n-        #                                                void* to,\n-        #                                                size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jshorts_atomic):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax # from + count*2 - 2\n-        jbe      cs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      cs_CopyLeft\n-        # copy from low to high\n-cs_CopyRight:\n-        # align source address at dword address boundary\n-        movl     %esi,%eax            # original from\n-        andl     $3,%eax              # either 0 or 2\n-        jz       1f                   # no prefix\n-        # copy prefix\n-        subl     $1,%ecx\n-        jl       5f                   # zero count\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-        addl     %eax,%esi            # %eax == 2\n-        addl     %eax,%edi\n-1:      movl     %ecx,%eax            # word count less prefix\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        # copy aligned dwords\n-        rep;     smovl\n-        jmp      4f\n-        # copy aligned dwords\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      popl     %edi\n-        popl     %esi\n-        ret\n-        # copy from high to low\n-cs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi # to + count*2 - 4\n-        movl     %eax,%esi            # from + count*2 - 2\n-        movl     %ecx,%eax\n-        subl     $2,%esi              # from + count*2 - 4\n-1:      sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        ja       3f                   # > 32 dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        addl     $2,%esi\n-        addl     $2,%edi\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_jshorts(void* from,\n-        #                                                 void* to,\n-        #                                                 size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_arrayof_conjoint_jshorts):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax # from + count*2 - 2\n-        jbe      acs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      acs_CopyLeft\n-acs_CopyRight:\n-        movl     %ecx,%eax            # word count\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        # copy aligned dwords\n-        rep;     smovl\n-        jmp      4f\n-        # copy aligned dwords\n-        .space 5\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      popl     %edi\n-        popl     %esi\n-        ret\n-acs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi # to + count*2 - 4\n-        movl     %eax,%esi            # from + count*2 - 2\n-        movl     %ecx,%eax\n-        subl     $2,%esi              # from + count*2 - 4\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        ja       3f                   # > 32 dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        addl     $2,%esi\n-        addl     $2,%edi\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jints_atomic(void* from,\n-        #                                              void* to,\n-        #                                              size_t count)\n-        # Equivalent to\n-        #   arrayof_conjoint_jints\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jints_atomic):\n-DECLARE_FUNC(_Copy_arrayof_conjoint_jints):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -4(%esi,%ecx,4),%eax # from + count*4 - 4\n-        jbe      ci_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      ci_CopyLeft\n-ci_CopyRight:\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        rep;     smovl\n-        popl     %edi\n-        popl     %esi\n-        ret\n-        .space 10\n-2:      subl     %esi,%edi\n-        jmp      4f\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-4:      subl     $1,%ecx\n-        jge      3b\n-        popl     %edi\n-        popl     %esi\n-        ret\n-ci_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,4),%edi # to + count*4 - 4\n-        cmpl     $32,%ecx\n-        ja       4f                   # > 32 dwords\n-        subl     %eax,%edi            # eax == from + count*4 - 4\n-        jmp      3f\n-        .p2align 4,,15\n-2:      movl     (%eax),%edx\n-        movl     %edx,(%edi,%eax,1)\n-        subl     $4,%eax\n-3:      subl     $1,%ecx\n-        jge      2b\n-        cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-4:      movl     %eax,%esi            # from + count*4 - 4\n-        rep;     smovl\n-        cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jlongs_atomic(jlong* from,\n-        #                                               jlong* to,\n-        #                                               size_t count)\n-        #\n-        # 32-bit\n-        #\n-        # count treated as signed\n-        #\n-        # \/\/ if (from > to) {\n-        #   while (--count >= 0) {\n-        #     *to++ = *from++;\n-        #   }\n-        # } else {\n-        #   while (--count >= 0) {\n-        #     to[count] = from[count];\n-        #   }\n-        # }\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jlongs_atomic):\n-        movl     4+8(%esp),%ecx       # count\n-        movl     4+0(%esp),%eax       # from\n-        movl     4+4(%esp),%edx       # to\n-        cmpl     %eax,%edx\n-        jae      cla_CopyLeft\n-cla_CopyRight:\n-        subl     %eax,%edx\n-        jmp      2f\n-        .p2align 4,,15\n-1:      fildll   (%eax)\n-        fistpll  (%edx,%eax,1)\n-        addl     $8,%eax\n-2:      subl     $1,%ecx\n-        jge      1b\n-        ret\n-        .p2align 4,,15\n-3:      fildll   (%eax,%ecx,8)\n-        fistpll  (%edx,%ecx,8)\n-cla_CopyLeft:\n-        subl     $1,%ecx\n-        jge      3b\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_jshorts(void* from,\n-        #                                                 void* to,\n-        #                                                 size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_mmx_Copy_arrayof_conjoint_jshorts):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi\n-        movl     8+ 8(%esp),%edi\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax\n-        jbe      mmx_acs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      mmx_acs_CopyLeft\n-mmx_acs_CopyRight:\n-        movl     %ecx,%eax\n-        sarl     %ecx\n-        je       5f\n-        cmpl     $33,%ecx\n-        jae      3f\n-1:      subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      5f\n-3:      smovl # align to 8 bytes, we know we are 4 byte aligned to start\n-        subl     $1,%ecx\n-4:      .p2align 4,,15\n-        movq     0(%esi),%mm0\n-        addl     $64,%edi\n-        movq     8(%esi),%mm1\n-        subl     $16,%ecx\n-        movq     16(%esi),%mm2\n-        movq     %mm0,-64(%edi)\n-        movq     24(%esi),%mm0\n-        movq     %mm1,-56(%edi)\n-        movq     32(%esi),%mm1\n-        movq     %mm2,-48(%edi)\n-        movq     40(%esi),%mm2\n-        movq     %mm0,-40(%edi)\n-        movq     48(%esi),%mm0\n-        movq     %mm1,-32(%edi)\n-        movq     56(%esi),%mm1\n-        movq     %mm2,-24(%edi)\n-        movq     %mm0,-16(%edi)\n-        addl     $64,%esi\n-        movq     %mm1,-8(%edi)\n-        cmpl     $16,%ecx\n-        jge      4b\n-        emms\n-        testl    %ecx,%ecx\n-        ja       1b\n-5:      andl     $1,%eax\n-        je       7f\n-6:      movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-7:      popl     %edi\n-        popl     %esi\n-        ret\n-mmx_acs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi\n-        movl     %eax,%esi\n-        movl     %ecx,%eax\n-        subl     $2,%esi\n-        sarl     %ecx\n-        je       4f\n-        cmpl     $32,%ecx\n-        ja       3f\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax\n-        je       6f\n-        addl     $2,%esi\n-        addl     $2,%edi\n-5:      movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-6:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-\n-        # Support for int64_t Atomic::cmpxchg(int64_t compare_value,\n-        #                                     volatile int64_t* dest,\n-        #                                     int64_t exchange_value)\n-        #\n-        .p2align 4,,15\n-DECLARE_FUNC(_Atomic_cmpxchg_long):\n-                                   #  8(%esp) : return PC\n-        pushl    %ebx              #  4(%esp) : old %ebx\n-        pushl    %edi              #  0(%esp) : old %edi\n-        movl     12(%esp), %ebx    # 12(%esp) : exchange_value (low)\n-        movl     16(%esp), %ecx    # 16(%esp) : exchange_value (high)\n-        movl     24(%esp), %eax    # 24(%esp) : compare_value (low)\n-        movl     28(%esp), %edx    # 28(%esp) : compare_value (high)\n-        movl     20(%esp), %edi    # 20(%esp) : dest\n-        lock\n-        cmpxchg8b (%edi)\n-        popl     %edi\n-        popl     %ebx\n-        ret\n-\n-\n-        # Support for int64_t Atomic::load and Atomic::store.\n-        # void _Atomic_move_long(const volatile int64_t* src, volatile int64_t* dst)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Atomic_move_long):\n-        movl     4(%esp), %eax   # src\n-        fildll    (%eax)\n-        movl     8(%esp), %eax   # dest\n-        fistpll   (%eax)\n-        ret\n","filename":"src\/hotspot\/os_cpu\/bsd_x86\/bsd_x86_32.S","additions":0,"deletions":525,"binary":false,"changes":525,"status":"deleted"},{"patch":"@@ -1,518 +0,0 @@\n-#\n-# Copyright (c) 2004, 2024, Oracle and\/or its affiliates. All rights reserved.\n-# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-#\n-# This code is free software; you can redistribute it and\/or modify it\n-# under the terms of the GNU General Public License version 2 only, as\n-# published by the Free Software Foundation.\n-#\n-# This code is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-# version 2 for more details (a copy is included in the LICENSE file that\n-# accompanied this code).\n-#\n-# You should have received a copy of the GNU General Public License version\n-# 2 along with this work; if not, write to the Free Software Foundation,\n-# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-#\n-# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-# or visit www.oracle.com if you need additional information or have any\n-# questions.\n-#\n-\n-#include \"defs.S.inc\"\n-\n-        # NOTE WELL!  The _Copy functions are called directly\n-        # from server-compiler-generated code via CallLeafNoFP,\n-        # which means that they *must* either not use floating\n-        # point or use it in the same manner as does the server\n-        # compiler.\n-\n-        .text\n-\n-        .p2align 4,,15\n-DECLARE_FUNC(SpinPause):\n-        rep\n-        nop\n-        movl    $1, %eax\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_bytes(void* from,\n-        #                                               void* to,\n-        #                                               size_t count)\n-        #\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_arrayof_conjoint_bytes):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -1(%esi,%ecx),%eax   # from + count - 1\n-        jbe      acb_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      acb_CopyLeft\n-        # copy from low to high\n-acb_CopyRight:\n-        cmpl     $3,%ecx\n-        jbe      5f\n-1:      movl     %ecx,%eax\n-        shrl     $2,%ecx\n-        jz       4f\n-        cmpl     $32,%ecx\n-        ja       3f\n-        # copy aligned dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-        # copy aligned dwords\n-3:      rep;     smovl\n-4:      movl     %eax,%ecx\n-5:      andl     $3,%ecx\n-        jz       7f\n-        # copy suffix\n-        xorl     %eax,%eax\n-6:      movb     (%esi,%eax,1),%dl\n-        movb     %dl,(%edi,%eax,1)\n-        addl     $1,%eax\n-        subl     $1,%ecx\n-        jnz      6b\n-7:      popl     %edi\n-        popl     %esi\n-        ret\n-acb_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx),%edi   # to + count - 4\n-        movl     %eax,%esi            # from + count - 1\n-        movl     %ecx,%eax\n-        subl     $3,%esi              # from + count - 4\n-        cmpl     $3,%ecx\n-        jbe      5f\n-1:      shrl     $2,%ecx\n-        jz       4f\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        rep;     smovl\n-        jmp      4f\n-        .space 8\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      movl     %eax,%ecx\n-5:      andl     $3,%ecx\n-        jz       7f\n-        subl     %esi,%edi\n-        addl     $3,%esi\n-6:      movb     (%esi),%dl\n-        movb     %dl,(%edi,%esi,1)\n-        subl     $1,%esi\n-        subl     $1,%ecx\n-        jnz      6b\n-7:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jshorts_atomic(void* from,\n-        #                                                void* to,\n-        #                                                size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jshorts_atomic):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax # from + count*2 - 2\n-        jbe      cs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      cs_CopyLeft\n-        # copy from low to high\n-cs_CopyRight:\n-        # align source address at dword address boundary\n-        movl     %esi,%eax            # original from\n-        andl     $3,%eax              # either 0 or 2\n-        jz       1f                   # no prefix\n-        # copy prefix\n-        subl     $1,%ecx\n-        jl       5f                   # zero count\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-        addl     %eax,%esi            # %eax == 2\n-        addl     %eax,%edi\n-1:      movl     %ecx,%eax            # word count less prefix\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        # copy aligned dwords\n-        rep;     smovl\n-        jmp      4f\n-        # copy aligned dwords\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      popl     %edi\n-        popl     %esi\n-        ret\n-        # copy from high to low\n-cs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi # to + count*2 - 4\n-        movl     %eax,%esi            # from + count*2 - 2\n-        movl     %ecx,%eax\n-        subl     $2,%esi              # from + count*2 - 4\n-1:      sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        ja       3f                   # > 32 dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        addl     $2,%esi\n-        addl     $2,%edi\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_jshorts(void* from,\n-        #                                                 void* to,\n-        #                                                 size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_arrayof_conjoint_jshorts):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax # from + count*2 - 2\n-        jbe      acs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      acs_CopyLeft\n-acs_CopyRight:\n-        movl     %ecx,%eax            # word count\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        # copy aligned dwords\n-        rep;     smovl\n-        jmp      4f\n-        # copy aligned dwords\n-        .space 5\n-2:      subl     %esi,%edi\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      3b\n-        addl     %esi,%edi\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      popl     %edi\n-        popl     %esi\n-        ret\n-acs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi # to + count*2 - 4\n-        movl     %eax,%esi            # from + count*2 - 2\n-        movl     %ecx,%eax\n-        subl     $2,%esi              # from + count*2 - 4\n-        sarl     %ecx                 # dword count\n-        jz       4f                   # no dwords to move\n-        cmpl     $32,%ecx\n-        ja       3f                   # > 32 dwords\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax              # suffix count\n-        jz       5f                   # no suffix\n-        # copy suffix\n-        addl     $2,%esi\n-        addl     $2,%edi\n-        movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-5:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jints_atomic(void* from,\n-        #                                              void* to,\n-        #                                              size_t count)\n-        # Equivalent to\n-        #   arrayof_conjoint_jints\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jints_atomic):\n-DECLARE_FUNC(_Copy_arrayof_conjoint_jints):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx      # count\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi      # from\n-        movl     8+ 8(%esp),%edi      # to\n-        cmpl     %esi,%edi\n-        leal     -4(%esi,%ecx,4),%eax # from + count*4 - 4\n-        jbe      ci_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      ci_CopyLeft\n-ci_CopyRight:\n-        cmpl     $32,%ecx\n-        jbe      2f                   # <= 32 dwords\n-        rep;     smovl\n-        popl     %edi\n-        popl     %esi\n-        ret\n-        .space 10\n-2:      subl     %esi,%edi\n-        jmp      4f\n-        .p2align 4,,15\n-3:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-4:      subl     $1,%ecx\n-        jge      3b\n-        popl     %edi\n-        popl     %esi\n-        ret\n-ci_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,4),%edi # to + count*4 - 4\n-        cmpl     $32,%ecx\n-        ja       4f                   # > 32 dwords\n-        subl     %eax,%edi            # eax == from + count*4 - 4\n-        jmp      3f\n-        .p2align 4,,15\n-2:      movl     (%eax),%edx\n-        movl     %edx,(%edi,%eax,1)\n-        subl     $4,%eax\n-3:      subl     $1,%ecx\n-        jge      2b\n-        cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-4:      movl     %eax,%esi            # from + count*4 - 4\n-        rep;     smovl\n-        cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-        # Support for void Copy::conjoint_jlongs_atomic(jlong* from,\n-        #                                               jlong* to,\n-        #                                               size_t count)\n-        #\n-        # 32-bit\n-        #\n-        # count treated as signed\n-        \/*\n-        #\n-        # if (from > to) {\n-        #   while (--count >= 0) {\n-        #     *to++ = *from++;\n-        #   }\n-        # } else {\n-        #   while (--count >= 0) {\n-        #     to[count] = from[count];\n-        #   }\n-        # }\n-        *\/\n-        .p2align 4,,15\n-DECLARE_FUNC(_Copy_conjoint_jlongs_atomic):\n-        movl     4+8(%esp),%ecx       # count\n-        movl     4+0(%esp),%eax       # from\n-        movl     4+4(%esp),%edx       # to\n-        cmpl     %eax,%edx\n-        jae      cla_CopyLeft\n-cla_CopyRight:\n-        subl     %eax,%edx\n-        jmp      2f\n-        .p2align 4,,15\n-1:      fildll   (%eax)\n-        fistpll  (%edx,%eax,1)\n-        addl     $8,%eax\n-2:      subl     $1,%ecx\n-        jge      1b\n-        ret\n-        .p2align 4,,15\n-3:      fildll   (%eax,%ecx,8)\n-        fistpll  (%edx,%ecx,8)\n-cla_CopyLeft:\n-        subl     $1,%ecx\n-        jge      3b\n-        ret\n-\n-        # Support for void Copy::arrayof_conjoint_jshorts(void* from,\n-        #                                                 void* to,\n-        #                                                 size_t count)\n-        .p2align 4,,15\n-DECLARE_FUNC(_mmx_Copy_arrayof_conjoint_jshorts):\n-        pushl    %esi\n-        movl     4+12(%esp),%ecx\n-        pushl    %edi\n-        movl     8+ 4(%esp),%esi\n-        movl     8+ 8(%esp),%edi\n-        cmpl     %esi,%edi\n-        leal     -2(%esi,%ecx,2),%eax\n-        jbe      mmx_acs_CopyRight\n-        cmpl     %eax,%edi\n-        jbe      mmx_acs_CopyLeft\n-mmx_acs_CopyRight:\n-        movl     %ecx,%eax\n-        sarl     %ecx\n-        je       5f\n-        cmpl     $33,%ecx\n-        jae      3f\n-1:      subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        addl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      5f\n-3:      smovl # align to 8 bytes, we know we are 4 byte aligned to start\n-        subl     $1,%ecx\n-4:      .p2align 4,,15\n-        movq     0(%esi),%mm0\n-        addl     $64,%edi\n-        movq     8(%esi),%mm1\n-        subl     $16,%ecx\n-        movq     16(%esi),%mm2\n-        movq     %mm0,-64(%edi)\n-        movq     24(%esi),%mm0\n-        movq     %mm1,-56(%edi)\n-        movq     32(%esi),%mm1\n-        movq     %mm2,-48(%edi)\n-        movq     40(%esi),%mm2\n-        movq     %mm0,-40(%edi)\n-        movq     48(%esi),%mm0\n-        movq     %mm1,-32(%edi)\n-        movq     56(%esi),%mm1\n-        movq     %mm2,-24(%edi)\n-        movq     %mm0,-16(%edi)\n-        addl     $64,%esi\n-        movq     %mm1,-8(%edi)\n-        cmpl     $16,%ecx\n-        jge      4b\n-        emms\n-        testl    %ecx,%ecx\n-        ja       1b\n-5:      andl     $1,%eax\n-        je       7f\n-6:      movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-7:\tpopl     %edi\n-        popl     %esi\n-        ret\n-mmx_acs_CopyLeft:\n-        std\n-        leal     -4(%edi,%ecx,2),%edi\n-        movl     %eax,%esi\n-        movl     %ecx,%eax\n-        subl     $2,%esi\n-        sarl     %ecx\n-        je       4f\n-        cmpl     $32,%ecx\n-        ja       3f\n-        subl     %esi,%edi\n-        .p2align 4,,15\n-2:      movl     (%esi),%edx\n-        movl     %edx,(%edi,%esi,1)\n-        subl     $4,%esi\n-        subl     $1,%ecx\n-        jnz      2b\n-        addl     %esi,%edi\n-        jmp      4f\n-3:      rep;     smovl\n-4:      andl     $1,%eax\n-        je       6f\n-        addl     $2,%esi\n-        addl     $2,%edi\n-5:      movw     (%esi),%dx\n-        movw     %dx,(%edi)\n-6:      cld\n-        popl     %edi\n-        popl     %esi\n-        ret\n-\n-\n-        # Support for jlong Atomic::cmpxchg(volatile jlong* dest,\n-        #                                   jlong compare_value,\n-        #                                   jlong exchange_value)\n-        #\n-        .p2align 4,,15\n-DECLARE_FUNC(_Atomic_cmpxchg_long):\n-                                   #  8(%esp) : return PC\n-        pushl    %ebx              #  4(%esp) : old %ebx\n-        pushl    %edi              #  0(%esp) : old %edi\n-        movl     12(%esp), %ebx    # 12(%esp) : exchange_value (low)\n-        movl     16(%esp), %ecx    # 16(%esp) : exchange_value (high)\n-        movl     24(%esp), %eax    # 24(%esp) : compare_value (low)\n-        movl     28(%esp), %edx    # 28(%esp) : compare_value (high)\n-        movl     20(%esp), %edi    # 20(%esp) : dest\n-        lock cmpxchg8b (%edi)\n-        popl     %edi\n-        popl     %ebx\n-        ret\n-\n-\n-        # Support for jlong Atomic::load and Atomic::store.\n-        # void _Atomic_move_long(const volatile jlong* src, volatile jlong* dst)\n-        .p2align 4,,15\n-DECLARE_FUNC(_Atomic_move_long):\n-        movl     4(%esp), %eax   # src\n-        fildll    (%eax)\n-        movl     8(%esp), %eax   # dest\n-        fistpll   (%eax)\n-        ret\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/linux_x86_32.S","additions":0,"deletions":518,"binary":false,"changes":518,"status":"deleted"},{"patch":"@@ -1,41 +0,0 @@\n-#\n-# Copyright (c) 2022 SAP SE. All rights reserved.\n-# Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n-# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-#\n-# This code is free software; you can redistribute it and\/or modify it\n-# under the terms of the GNU General Public License version 2 only, as\n-# published by the Free Software Foundation.\n-#\n-# This code is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-# version 2 for more details (a copy is included in the LICENSE file that\n-# accompanied this code).\n-#\n-# You should have received a copy of the GNU General Public License version\n-# 2 along with this work; if not, write to the Free Software Foundation,\n-# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-#\n-# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-# or visit www.oracle.com if you need additional information or have any\n-# questions.\n-#\n-\n-#include \"defs.S.inc\"\n-\n-    .text\n-\n-    # Support for int SafeFetch32(int* address, int defaultval);\n-    #\n-    #  8(%esp) : default value\n-    #  4(%esp) : crash address\n-    #  0(%esp) : return pc\n-DECLARE_FUNC(SafeFetch32_impl):\n-    movl 4(%esp),%ecx         # load address from stack\n-DECLARE_FUNC(_SafeFetch32_fault):\n-    movl (%ecx), %eax         # load target value, may fault\n-    ret\n-DECLARE_FUNC(_SafeFetch32_continuation):\n-    movl 8(%esp),%eax         # load default value from stack\n-    ret\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/safefetch_linux_x86_32.S","additions":0,"deletions":41,"binary":false,"changes":41,"status":"deleted"}]}