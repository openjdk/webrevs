{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -2555,0 +2555,5 @@\n+  INSN1(ld1, 0b001101010, 0b0000);\n+  INSN2(ld2, 0b001101011, 0b0000);\n+  INSN3(ld3, 0b001101010, 0b0010);\n+  INSN4(ld4, 0b001101011, 0b0010);\n+\n@@ -2589,0 +2594,1 @@\n+    if (opc2 ==  0b101101) guarantee(T != T8B && T != T16B, \"incorrect arrangement\");   \\\n@@ -2612,0 +2618,2 @@\n+  INSN(sqdmulh,0, 0b101101, false); \/\/ accepted arrangements: T4H, T8H, T2S, T4S\n+  INSN(shsubv, 0, 0b001001, false); \/\/ accepted arrangements: T8B, T16B, T4H, T8H, T2S, T4S\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-  do_arch_blob(compiler, 30000 ZGC_ONLY(+10000))                        \\\n+  do_arch_blob(compiler, 50000 ZGC_ONLY(+10000))                        \\\n","filename":"src\/hotspot\/cpu\/aarch64\/stubDeclarations_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4066,0 +4066,89 @@\n+  \/\/ Execute one round of keccak of two computations in parallel.\n+  \/\/ One of the states should be loaded into the lower halves of\n+  \/\/ the vector registers v0-v24, the other should be loaded into\n+  \/\/ the upper halves of those registers. The ld1r instruction loads\n+  \/\/ the round constant into both halves of register v31.\n+  \/\/ Intermediate results c0...c5 and d0...d5 are computed\n+  \/\/ in registers v25...v30.\n+  \/\/ All vector instructions that are used operate on both register\n+  \/\/ halves in parallel.\n+  \/\/ If only a single computation is needed, one can only load the lower halves.\n+  void keccak_round(Register rscratch1) {\n+  __ eor3(v29, __ T16B, v4, v9, v14);       \/\/ c4 = a4 ^ a9 ^ a14\n+  __ eor3(v26, __ T16B, v1, v6, v11);       \/\/ c1 = a1 ^ a16 ^ a11\n+  __ eor3(v28, __ T16B, v3, v8, v13);       \/\/ c3 = a3 ^ a8 ^a13\n+  __ eor3(v25, __ T16B, v0, v5, v10);       \/\/ c0 = a0 ^ a5 ^ a10\n+  __ eor3(v27, __ T16B, v2, v7, v12);       \/\/ c2 = a2 ^ a7 ^ a12\n+  __ eor3(v29, __ T16B, v29, v19, v24);     \/\/ c4 ^= a19 ^ a24\n+  __ eor3(v26, __ T16B, v26, v16, v21);     \/\/ c1 ^= a16 ^ a21\n+  __ eor3(v28, __ T16B, v28, v18, v23);     \/\/ c3 ^= a18 ^ a23\n+  __ eor3(v25, __ T16B, v25, v15, v20);     \/\/ c0 ^= a15 ^ a20\n+  __ eor3(v27, __ T16B, v27, v17, v22);     \/\/ c2 ^= a17 ^ a22\n+\n+  __ rax1(v30, __ T2D, v29, v26);           \/\/ d0 = c4 ^ rol(c1, 1)\n+  __ rax1(v26, __ T2D, v26, v28);           \/\/ d2 = c1 ^ rol(c3, 1)\n+  __ rax1(v28, __ T2D, v28, v25);           \/\/ d4 = c3 ^ rol(c0, 1)\n+  __ rax1(v25, __ T2D, v25, v27);           \/\/ d1 = c0 ^ rol(c2, 1)\n+  __ rax1(v27, __ T2D, v27, v29);           \/\/ d3 = c2 ^ rol(c4, 1)\n+\n+  __ eor(v0, __ T16B, v0, v30);             \/\/ a0 = a0 ^ d0\n+  __ xar(v29, __ T2D, v1,  v25, (64 - 1));  \/\/ a10' = rol((a1^d1), 1)\n+  __ xar(v1,  __ T2D, v6,  v25, (64 - 44)); \/\/ a1 = rol(a6^d1), 44)\n+  __ xar(v6,  __ T2D, v9,  v28, (64 - 20)); \/\/ a6 = rol((a9^d4), 20)\n+  __ xar(v9,  __ T2D, v22, v26, (64 - 61)); \/\/ a9 = rol((a22^d2), 61)\n+  __ xar(v22, __ T2D, v14, v28, (64 - 39)); \/\/ a22 = rol((a14^d4), 39)\n+  __ xar(v14, __ T2D, v20, v30, (64 - 18)); \/\/ a14 = rol((a20^d0), 18)\n+  __ xar(v31, __ T2D, v2,  v26, (64 - 62)); \/\/ a20' = rol((a2^d2), 62)\n+  __ xar(v2,  __ T2D, v12, v26, (64 - 43)); \/\/ a2 = rol((a12^d2), 43)\n+  __ xar(v12, __ T2D, v13, v27, (64 - 25)); \/\/ a12 = rol((a13^d3), 25)\n+  __ xar(v13, __ T2D, v19, v28, (64 - 8));  \/\/ a13 = rol((a19^d4), 8)\n+  __ xar(v19, __ T2D, v23, v27, (64 - 56)); \/\/ a19 = rol((a23^d3), 56)\n+  __ xar(v23, __ T2D, v15, v30, (64 - 41)); \/\/ a23 = rol((a15^d0), 41)\n+  __ xar(v15, __ T2D, v4,  v28, (64 - 27)); \/\/ a15 = rol((a4^d4), 27)\n+  __ xar(v28, __ T2D, v24, v28, (64 - 14)); \/\/ a4' = rol((a24^d4), 14)\n+  __ xar(v24, __ T2D, v21, v25, (64 - 2));  \/\/ a24 = rol((a21^d1), 2)\n+  __ xar(v8,  __ T2D, v8,  v27, (64 - 55)); \/\/ a21' = rol((a8^d3), 55)\n+  __ xar(v4,  __ T2D, v16, v25, (64 - 45)); \/\/ a8' = rol((a16^d1), 45)\n+  __ xar(v16, __ T2D, v5,  v30, (64 - 36)); \/\/ a16 = rol((a5^d0), 36)\n+  __ xar(v5,  __ T2D, v3,  v27, (64 - 28)); \/\/ a5 = rol((a3^d3), 28)\n+  __ xar(v27, __ T2D, v18, v27, (64 - 21)); \/\/ a3' = rol((a18^d3), 21)\n+  __ xar(v3,  __ T2D, v17, v26, (64 - 15)); \/\/ a18' = rol((a17^d2), 15)\n+  __ xar(v25, __ T2D, v11, v25, (64 - 10)); \/\/ a17' = rol((a11^d1), 10)\n+  __ xar(v26, __ T2D, v7,  v26, (64 - 6));  \/\/ a11' = rol((a7^d2), 6)\n+  __ xar(v30, __ T2D, v10, v30, (64 - 3));  \/\/ a7' = rol((a10^d0), 3)\n+\n+  __ bcax(v20, __ T16B, v31, v22, v8);      \/\/ a20 = a20' ^ (~a21 & a22')\n+  __ bcax(v21, __ T16B, v8,  v23, v22);     \/\/ a21 = a21' ^ (~a22 & a23)\n+  __ bcax(v22, __ T16B, v22, v24, v23);     \/\/ a22 = a22 ^ (~a23 & a24)\n+  __ bcax(v23, __ T16B, v23, v31, v24);     \/\/ a23 = a23 ^ (~a24 & a20')\n+  __ bcax(v24, __ T16B, v24, v8,  v31);     \/\/ a24 = a24 ^ (~a20' & a21')\n+\n+  __ ld1r(v31, __ T2D, __ post(rscratch1, 8)); \/\/ rc = round_constants[i]\n+\n+  __ bcax(v17, __ T16B, v25, v19, v3);      \/\/ a17 = a17' ^ (~a18' & a19)\n+  __ bcax(v18, __ T16B, v3,  v15, v19);     \/\/ a18 = a18' ^ (~a19 & a15')\n+  __ bcax(v19, __ T16B, v19, v16, v15);     \/\/ a19 = a19 ^ (~a15 & a16)\n+  __ bcax(v15, __ T16B, v15, v25, v16);     \/\/ a15 = a15 ^ (~a16 & a17')\n+  __ bcax(v16, __ T16B, v16, v3,  v25);     \/\/ a16 = a16 ^ (~a17' & a18')\n+\n+  __ bcax(v10, __ T16B, v29, v12, v26);     \/\/ a10 = a10' ^ (~a11' & a12)\n+  __ bcax(v11, __ T16B, v26, v13, v12);     \/\/ a11 = a11' ^ (~a12 & a13)\n+  __ bcax(v12, __ T16B, v12, v14, v13);     \/\/ a12 = a12 ^ (~a13 & a14)\n+  __ bcax(v13, __ T16B, v13, v29, v14);     \/\/ a13 = a13 ^ (~a14 & a10')\n+  __ bcax(v14, __ T16B, v14, v26, v29);     \/\/ a14 = a14 ^ (~a10' & a11')\n+\n+  __ bcax(v7, __ T16B, v30, v9,  v4);       \/\/ a7 = a7' ^ (~a8' & a9)\n+  __ bcax(v8, __ T16B, v4,  v5,  v9);       \/\/ a8 = a8' ^ (~a9 & a5)\n+  __ bcax(v9, __ T16B, v9,  v6,  v5);       \/\/ a9 = a9 ^ (~a5 & a6)\n+  __ bcax(v5, __ T16B, v5,  v30, v6);       \/\/ a5 = a5 ^ (~a6 & a7)\n+  __ bcax(v6, __ T16B, v6,  v4,  v30);      \/\/ a6 = a6 ^ (~a7 & a8')\n+\n+  __ bcax(v3, __ T16B, v27, v0,  v28);      \/\/ a3 = a3' ^ (~a4' & a0)\n+  __ bcax(v4, __ T16B, v28, v1,  v0);       \/\/ a4 = a4' ^ (~a0 & a1)\n+  __ bcax(v0, __ T16B, v0,  v2,  v1);       \/\/ a0 = a0 ^ (~a1 & a2)\n+  __ bcax(v1, __ T16B, v1,  v27, v2);       \/\/ a1 = a1 ^ (~a2 & a3)\n+  __ bcax(v2, __ T16B, v2,  v28, v27);      \/\/ a2 = a2 ^ (~a3 & a4')\n+\n+  __ eor(v0, __ T16B, v0, v31);             \/\/ a0 = a0 ^ rc\n+  }\n+\n@@ -4170,1 +4259,1 @@\n-    \/\/ block_size == 144, bit5 == 0, SHA3-244\n+    \/\/ block_size == 144, bit5 == 0, SHA3-224\n@@ -4199,76 +4288,1 @@\n-    __ eor3(v29, __ T16B, v4, v9, v14);\n-    __ eor3(v26, __ T16B, v1, v6, v11);\n-    __ eor3(v28, __ T16B, v3, v8, v13);\n-    __ eor3(v25, __ T16B, v0, v5, v10);\n-    __ eor3(v27, __ T16B, v2, v7, v12);\n-    __ eor3(v29, __ T16B, v29, v19, v24);\n-    __ eor3(v26, __ T16B, v26, v16, v21);\n-    __ eor3(v28, __ T16B, v28, v18, v23);\n-    __ eor3(v25, __ T16B, v25, v15, v20);\n-    __ eor3(v27, __ T16B, v27, v17, v22);\n-\n-    __ rax1(v30, __ T2D, v29, v26);\n-    __ rax1(v26, __ T2D, v26, v28);\n-    __ rax1(v28, __ T2D, v28, v25);\n-    __ rax1(v25, __ T2D, v25, v27);\n-    __ rax1(v27, __ T2D, v27, v29);\n-\n-    __ eor(v0, __ T16B, v0, v30);\n-    __ xar(v29, __ T2D, v1,  v25, (64 - 1));\n-    __ xar(v1,  __ T2D, v6,  v25, (64 - 44));\n-    __ xar(v6,  __ T2D, v9,  v28, (64 - 20));\n-    __ xar(v9,  __ T2D, v22, v26, (64 - 61));\n-    __ xar(v22, __ T2D, v14, v28, (64 - 39));\n-    __ xar(v14, __ T2D, v20, v30, (64 - 18));\n-    __ xar(v31, __ T2D, v2,  v26, (64 - 62));\n-    __ xar(v2,  __ T2D, v12, v26, (64 - 43));\n-    __ xar(v12, __ T2D, v13, v27, (64 - 25));\n-    __ xar(v13, __ T2D, v19, v28, (64 - 8));\n-    __ xar(v19, __ T2D, v23, v27, (64 - 56));\n-    __ xar(v23, __ T2D, v15, v30, (64 - 41));\n-    __ xar(v15, __ T2D, v4,  v28, (64 - 27));\n-    __ xar(v28, __ T2D, v24, v28, (64 - 14));\n-    __ xar(v24, __ T2D, v21, v25, (64 - 2));\n-    __ xar(v8,  __ T2D, v8,  v27, (64 - 55));\n-    __ xar(v4,  __ T2D, v16, v25, (64 - 45));\n-    __ xar(v16, __ T2D, v5,  v30, (64 - 36));\n-    __ xar(v5,  __ T2D, v3,  v27, (64 - 28));\n-    __ xar(v27, __ T2D, v18, v27, (64 - 21));\n-    __ xar(v3,  __ T2D, v17, v26, (64 - 15));\n-    __ xar(v25, __ T2D, v11, v25, (64 - 10));\n-    __ xar(v26, __ T2D, v7,  v26, (64 - 6));\n-    __ xar(v30, __ T2D, v10, v30, (64 - 3));\n-\n-    __ bcax(v20, __ T16B, v31, v22, v8);\n-    __ bcax(v21, __ T16B, v8,  v23, v22);\n-    __ bcax(v22, __ T16B, v22, v24, v23);\n-    __ bcax(v23, __ T16B, v23, v31, v24);\n-    __ bcax(v24, __ T16B, v24, v8,  v31);\n-\n-    __ ld1r(v31, __ T2D, __ post(rscratch1, 8));\n-\n-    __ bcax(v17, __ T16B, v25, v19, v3);\n-    __ bcax(v18, __ T16B, v3,  v15, v19);\n-    __ bcax(v19, __ T16B, v19, v16, v15);\n-    __ bcax(v15, __ T16B, v15, v25, v16);\n-    __ bcax(v16, __ T16B, v16, v3,  v25);\n-\n-    __ bcax(v10, __ T16B, v29, v12, v26);\n-    __ bcax(v11, __ T16B, v26, v13, v12);\n-    __ bcax(v12, __ T16B, v12, v14, v13);\n-    __ bcax(v13, __ T16B, v13, v29, v14);\n-    __ bcax(v14, __ T16B, v14, v26, v29);\n-\n-    __ bcax(v7, __ T16B, v30, v9,  v4);\n-    __ bcax(v8, __ T16B, v4,  v5,  v9);\n-    __ bcax(v9, __ T16B, v9,  v6,  v5);\n-    __ bcax(v5, __ T16B, v5,  v30, v6);\n-    __ bcax(v6, __ T16B, v6,  v4,  v30);\n-\n-    __ bcax(v3, __ T16B, v27, v0,  v28);\n-    __ bcax(v4, __ T16B, v28, v1,  v0);\n-    __ bcax(v0, __ T16B, v0,  v2,  v1);\n-    __ bcax(v1, __ T16B, v1,  v27, v2);\n-    __ bcax(v2, __ T16B, v2,  v28, v27);\n-\n-    __ eor(v0, __ T16B, v0, v31);\n+    keccak_round(rscratch1);\n@@ -4293,0 +4307,89 @@\n+    \/\/ restore callee-saved registers\n+    __ ldpd(v14, v15, Address(sp, 48));\n+    __ ldpd(v12, v13, Address(sp, 32));\n+    __ ldpd(v10, v11, Address(sp, 16));\n+    __ ldpd(v8, v9, __ post(sp, 64));\n+\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - long[]  state0\n+  \/\/   c_rarg1   - long[]  state1\n+  address generate_double_keccak() {\n+    static const uint64_t round_consts[24] = {\n+      0x0000000000000001L, 0x0000000000008082L, 0x800000000000808AL,\n+      0x8000000080008000L, 0x000000000000808BL, 0x0000000080000001L,\n+      0x8000000080008081L, 0x8000000000008009L, 0x000000000000008AL,\n+      0x0000000000000088L, 0x0000000080008009L, 0x000000008000000AL,\n+      0x000000008000808BL, 0x800000000000008BL, 0x8000000000008089L,\n+      0x8000000000008003L, 0x8000000000008002L, 0x8000000000000080L,\n+      0x000000000000800AL, 0x800000008000000AL, 0x8000000080008081L,\n+      0x8000000000008080L, 0x0000000080000001L, 0x8000000080008008L\n+    };\n+\n+    \/\/ Implements the double_keccak() method of the\n+    \/\/ sun.secyrity.provider.SHA3Parallel class\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"double_keccak\");\n+    address start = __ pc();\n+    __ enter();\n+\n+    Register state0        = c_rarg0;\n+    Register state1        = c_rarg1;\n+\n+    Label rounds24_loop;\n+\n+    \/\/ save callee-saved registers\n+    __ stpd(v8, v9, __ pre(sp, -64));\n+    __ stpd(v10, v11, Address(sp, 16));\n+    __ stpd(v12, v13, Address(sp, 32));\n+    __ stpd(v14, v15, Address(sp, 48));\n+\n+    \/\/ load states\n+    __ add(rscratch1, state0, 32);\n+    __ ld4(v0, v1, v2,  v3, __ D, 0,  state0);\n+    __ ld4(v4, v5, v6,  v7, __ D, 0, __ post(rscratch1, 32));\n+    __ ld4(v8, v9, v10, v11, __ D, 0, __ post(rscratch1, 32));\n+    __ ld4(v12, v13, v14, v15, __ D, 0, __ post(rscratch1, 32));\n+    __ ld4(v16, v17, v18, v19, __ D, 0, __ post(rscratch1, 32));\n+    __ ld4(v20, v21, v22, v23, __ D, 0, __ post(rscratch1, 32));\n+    __ ld1(v24, __ D, 0, rscratch1);\n+    __ add(rscratch1, state1, 32);\n+    __ ld4(v0, v1, v2,  v3,  __ D, 1, state1);\n+    __ ld4(v4, v5, v6,  v7, __ D, 1, __ post(rscratch1, 32));\n+    __ ld4(v8, v9, v10, v11, __ D, 1, __ post(rscratch1, 32));\n+    __ ld4(v12, v13, v14, v15, __ D, 1, __ post(rscratch1, 32));\n+    __ ld4(v16, v17, v18, v19, __ D, 1, __ post(rscratch1, 32));\n+    __ ld4(v20, v21, v22, v23, __ D, 1, __ post(rscratch1, 32));\n+    __ ld1(v24, __ D, 1, rscratch1);\n+\n+    \/\/ 24 keccak rounds\n+    __ movw(rscratch2, 24);\n+\n+    \/\/ load round_constants base\n+    __ lea(rscratch1, ExternalAddress((address) round_consts));\n+\n+    __ BIND(rounds24_loop);\n+    __ subw(rscratch2, rscratch2, 1);\n+    keccak_round(rscratch1);\n+    __ cbnzw(rscratch2, rounds24_loop);\n+\n+    __ st4(v0, v1, v2,  v3,  __ D, 0, __ post(state0, 32));\n+    __ st4(v4, v5, v6,  v7,  __ D, 0, __ post(state0, 32));\n+    __ st4(v8, v9, v10, v11, __ D, 0, __ post(state0, 32));\n+    __ st4(v12, v13, v14, v15, __ D, 0, __ post(state0, 32));\n+    __ st4(v16, v17, v18, v19, __ D, 0, __ post(state0, 32));\n+    __ st4(v20, v21, v22, v23, __ D, 0, __ post(state0, 32));\n+    __ st1(v24, __ D, 0, state0);\n+    __ st4(v0, v1, v2,  v3,  __ D, 1, __ post(state1, 32));\n+    __ st4(v4, v5, v6,  v7, __ D, 1, __ post(state1, 32));\n+    __ st4(v8, v9, v10, v11, __ D, 1, __ post(state1, 32));\n+    __ st4(v12, v13, v14, v15, __ D, 1, __ post(state1, 32));\n+    __ st4(v16, v17, v18, v19, __ D, 1, __ post(state1, 32));\n+    __ st4(v20, v21, v22, v23, __ D, 1, __ post(state1, 32));\n+    __ st1(v24, __ D, 1, state1);\n+\n+    \/\/ restore callee-saved vector registers\n@@ -4298,0 +4401,2 @@\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n@@ -4471,0 +4576,955 @@\n+  void dilithium_load16zetas(int o0, Register zetas) {\n+    __ ldpq(as_FloatRegister(o0), as_FloatRegister(o0 + 1), __ post (zetas, 32));\n+    __ ldpq(as_FloatRegister(o0 + 2), as_FloatRegister(o0 + 3), __ post (zetas, 32));\n+\n+  }\n+\n+  void dilithium_load32zetas(Register zetas) {\n+    dilithium_load16zetas(16, zetas);\n+    dilithium_load16zetas(20, zetas);\n+  }\n+\n+  \/\/ 2x16 32-bit Montgomery multiplications in parallel\n+  \/\/ See the montMul() method of the sun.security.provider.ML_DSA class.\n+  \/\/ Here MONT_R_BITS is 32, so the right shift by it is implicit.\n+  \/\/ The constants qInv = MONT_Q_INV_MOD_R and q = MONT_Q are loaded in\n+  \/\/ (all 32-bit chunks of) vector registers v30 and v31, resp.\n+  \/\/ The inputs are b[i]s in v0-v7 and c[i]s v16-v23 and\n+  \/\/ the results are a[i]s in v16-v23, four 32-bit values in each register\n+  \/\/ and we do a_i = b_i * c_i * 2^-32 mod MONT_Q for all\n+  void dilithium_montmul32(bool by_constant) {\n+    FloatRegister vr0 = by_constant ? v29 : v0;\n+    FloatRegister vr1 = by_constant ? v29 : v1;\n+    FloatRegister vr2 = by_constant ? v29 : v2;\n+    FloatRegister vr3 = by_constant ? v29 : v3;\n+    FloatRegister vr4 = by_constant ? v29 : v4;\n+    FloatRegister vr5 = by_constant ? v29 : v5;\n+    FloatRegister vr6 = by_constant ? v29 : v6;\n+    FloatRegister vr7 = by_constant ? v29 : v7;\n+\n+    __ sqdmulh(v24, __ T4S, vr0, v16); \/\/ aHigh = hi32(2 * b * c)\n+    __ mulv(v16, __ T4S, vr0, v16);    \/\/ aLow = lo32(b * c)\n+    __ sqdmulh(v25, __ T4S, vr1, v17);\n+    __ mulv(v17, __ T4S, vr1, v17);\n+    __ sqdmulh(v26, __ T4S, vr2, v18);\n+    __ mulv(v18, __ T4S, vr2, v18);\n+    __ sqdmulh(v27, __ T4S, vr3, v19);\n+    __ mulv(v19, __ T4S, vr3, v19);\n+\n+    __ mulv(v16, __ T4S, v16, v30);     \/\/ m = aLow * qinv\n+    __ mulv(v17, __ T4S, v17, v30);\n+    __ mulv(v18, __ T4S, v18, v30);\n+    __ mulv(v19, __ T4S, v19, v30);\n+\n+    __ sqdmulh(v16, __ T4S, v16, v31);  \/\/ n = hi32(2 * m * q)\n+    __ sqdmulh(v17, __ T4S, v17, v31);\n+    __ sqdmulh(v18, __ T4S, v18, v31);\n+    __ sqdmulh(v19, __ T4S, v19, v31);\n+\n+    __ shsubv(v16, __ T4S, v24, v16);   \/\/ a = (aHigh - n) \/ 2\n+    __ shsubv(v17, __ T4S, v25, v17);\n+    __ shsubv(v18, __ T4S, v26, v18);\n+    __ shsubv(v19, __ T4S, v27, v19);\n+\n+    __ sqdmulh(v24, __ T4S, vr4, v20);\n+    __ mulv(v20, __ T4S, vr4, v20);\n+    __ sqdmulh(v25, __ T4S, vr5, v21);\n+    __ mulv(v21, __ T4S, vr5, v21);\n+    __ sqdmulh(v26, __ T4S, vr6, v22);\n+    __ mulv(v22, __ T4S, vr6, v22);\n+    __ sqdmulh(v27, __ T4S, vr7, v23);\n+    __ mulv(v23, __ T4S, vr7, v23);\n+\n+    __ mulv(v20, __ T4S, v20, v30);\n+    __ mulv(v21, __ T4S, v21, v30);\n+    __ mulv(v22, __ T4S, v22, v30);\n+    __ mulv(v23, __ T4S, v23, v30);\n+\n+    __ sqdmulh(v20, __ T4S, v20, v31);\n+    __ sqdmulh(v21, __ T4S, v21, v31);\n+    __ sqdmulh(v22, __ T4S, v22, v31);\n+    __ sqdmulh(v23, __ T4S, v23, v31);\n+\n+    __ shsubv(v20, __ T4S, v24, v20);\n+    __ shsubv(v21, __ T4S, v25, v21);\n+    __ shsubv(v22, __ T4S, v26, v22);\n+    __ shsubv(v23, __ T4S, v27, v23);\n+  }\n+\n+ \/\/ Do the addition and subtraction done in the ntt algorithm.\n+ \/\/ See sun.security.provider.ML_DSA.implDilithiumAlmostNttJava()\n+  void dilithium_add_sub32() {\n+    __ addv(v24, __ T4S, v0, v16); \/\/ coeffs[j] = coeffs[j] + tmp;\n+    __ addv(v25, __ T4S, v1, v17);\n+    __ addv(v26, __ T4S, v2, v18);\n+    __ addv(v27, __ T4S, v3, v19);\n+    __ addv(v28, __ T4S, v4, v20);\n+    __ addv(v29, __ T4S, v5, v21);\n+    __ addv(v30, __ T4S, v6, v22);\n+    __ addv(v31, __ T4S, v7, v23);\n+\n+    __ subv(v0, __ T4S, v0, v16);  \/\/ coeffs[j + l] = coeffs[j] - tmp;\n+    __ subv(v1, __ T4S, v1, v17);\n+    __ subv(v2, __ T4S, v2, v18);\n+    __ subv(v3, __ T4S, v3, v19);\n+    __ subv(v4, __ T4S, v4, v20);\n+    __ subv(v5, __ T4S, v5, v21);\n+    __ subv(v6, __ T4S, v6, v22);\n+    __ subv(v7, __ T4S, v7, v23);\n+  }\n+\n+  \/\/ Do the same computation that\n+  \/\/ dilithium_montmul32() and dilithium_add_sub32() does,\n+  \/\/ except for only 4x4 32-bit vector elements and with\n+  \/\/ different register usage.\n+  void dilithium_montmul_sub_add16() {\n+    __ sqdmulh(v24, __ T4S, v1, v16);\n+    __ mulv(v16, __ T4S, v1, v16);\n+    __ sqdmulh(v25, __ T4S, v3, v17);\n+    __ mulv(v17, __ T4S, v3, v17);\n+    __ sqdmulh(v26, __ T4S, v5, v18);\n+    __ mulv(v18, __ T4S, v5, v18);\n+    __ sqdmulh(v27, __ T4S, v7, v19);\n+    __ mulv(v19, __ T4S, v7, v19);\n+\n+    __ mulv(v16, __ T4S, v16, v30);\n+    __ mulv(v17, __ T4S, v17, v30);\n+    __ mulv(v18, __ T4S, v18, v30);\n+    __ mulv(v19, __ T4S, v19, v30);\n+\n+    __ sqdmulh(v16, __ T4S, v16, v31);\n+    __ sqdmulh(v17, __ T4S, v17, v31);\n+    __ sqdmulh(v18, __ T4S, v18, v31);\n+    __ sqdmulh(v19, __ T4S, v19, v31);\n+\n+    __ shsubv(v16, __ T4S, v24, v16);\n+    __ shsubv(v17, __ T4S, v25, v17);\n+    __ shsubv(v18, __ T4S, v26, v18);\n+    __ shsubv(v19, __ T4S, v27, v19);\n+\n+    __ subv(v1, __ T4S, v0, v16);\n+    __ subv(v3, __ T4S, v2, v17);\n+    __ subv(v5, __ T4S, v4, v18);\n+    __ subv(v7, __ T4S, v6, v19);\n+\n+    __ addv(v0, __ T4S, v0, v16);\n+    __ addv(v2, __ T4S, v2, v17);\n+    __ addv(v4, __ T4S, v4, v18);\n+    __ addv(v6, __ T4S, v6, v19);\n+  }\n+\n+  \/\/ At these levels, the indices that correspond to the 'j's (and 'j+l's)\n+  \/\/ in the Java implementation come in sequences of at least 8, so we\n+  \/\/ can use ldpq to collect the corresponding data into pairs of vector\n+  \/\/ registers.\n+  \/\/ We collect the coefficients corresponding to the 'j+l' indexes into\n+  \/\/ the vector registers v0-v7, the zetas into the vector registers v16-v23\n+  \/\/ then we do the (Montgomery) multiplications by the zetas in parallel\n+  \/\/ into v16-v23, load the coeffs corresponding to the 'j' indexes into\n+  \/\/ v0-v7, then do the additions into v24-v31 and the subtractions into\n+  \/\/ v0-v7 and finally save the results back to the coeffs array.\n+  void dilithiumNttLevel0_4(const Register dilithiumConsts,\n+    const Register coeffs, const Register zetas) {\n+    int c1 = 0;\n+    int c2 = 512;\n+    int startIncr;\n+    int incr1 = 32;\n+    int incr2 = 64;\n+    int incr3 = 96;\n+\n+    for (int level = 0; level < 5; level++) {\n+      int c1Start = c1;\n+      int c2Start = c2;\n+      if (level == 3) {\n+        incr1 = 32;\n+        incr2 = 128;\n+        incr3 = 160;\n+      } else if (level == 4) {\n+        incr1 = 64;\n+        incr2 = 128;\n+        incr3 = 192;\n+      }\n+\n+      for (int i = 0; i < 4; i++) {\n+        __ ldpq(v30, v31, Address(dilithiumConsts, 0)); \/\/ qInv, q\n+        __ ldpq(v0, v1, Address(coeffs, c2Start));\n+        __ ldpq(v2, v3, Address(coeffs, c2Start + incr1));\n+        __ ldpq(v4, v5, Address(coeffs, c2Start + incr2));\n+        __ ldpq(v6, v7, Address(coeffs, c2Start + incr3));\n+        dilithium_load32zetas(zetas);\n+        dilithium_montmul32(false);\n+        __ ldpq(v0, v1, Address(coeffs, c1Start));\n+        __ ldpq(v2, v3, Address(coeffs, c1Start + incr1));\n+        __ ldpq(v4, v5, Address(coeffs, c1Start + incr2));\n+        __ ldpq(v6, v7, Address(coeffs, c1Start + incr3));\n+        dilithium_add_sub32();\n+        __ stpq(v24, v25, Address(coeffs, c1Start));\n+        __ stpq(v26, v27, Address(coeffs, c1Start + incr1));\n+        __ stpq(v28, v29, Address(coeffs, c1Start + incr2));\n+        __ stpq(v30, v31, Address(coeffs, c1Start + incr3));\n+        __ stpq(v0, v1, Address(coeffs, c2Start));\n+        __ stpq(v2, v3, Address(coeffs, c2Start + incr1));\n+        __ stpq(v4, v5, Address(coeffs, c2Start + incr2));\n+        __ stpq(v6, v7, Address(coeffs, c2Start + incr3));\n+\n+        int k = 4 * level + i;\n+\n+        if (k > 7) {\n+          startIncr = 256;\n+        } else if (k == 5) {\n+          startIncr = 384;\n+        } else {\n+          startIncr = 128;\n+        }\n+\n+        c1Start += startIncr;\n+        c2Start += startIncr;\n+      }\n+\n+      c2 \/= 2;\n+    }\n+  }\n+\n+  \/\/ Dilithium NTT function except for the final \"normalization\" to |coeff| < Q.\n+  \/\/ Implements the method\n+  \/\/ static int implDilithiumAlmostNtt(int[] coeffs, int zetas[]) {}\n+  \/\/ of the Java class sun.security.provider\n+  \/\/\n+  \/\/ coeffs (int[256]) = c_rarg0\n+  \/\/ zetas (int[256]) = c_rarg1\n+  address generate_dilithiumAlmostNtt() {\n+\n+    __ align(CodeEntryAlignment);\n+    StubGenStubId stub_id = StubGenStubId::dilithiumAlmostNtt_id;\n+    StubCodeMark mark(this, stub_id);\n+    address start = __ pc();\n+    __ enter();\n+\n+    const Register coeffs = c_rarg0;\n+    const Register zetas = c_rarg1;\n+\n+    const Register tmpAddr = r9;\n+    const Register dilithiumConsts = r10;\n+    const Register result = r11;\n+\n+    __ add(result, coeffs, 0);\n+    __ lea(dilithiumConsts, ExternalAddress((address) StubRoutines::aarch64::_dilithiumConsts));\n+\n+    \/\/ Each level represents one iteration of the outer for loop of the Java version\n+\n+    \/\/ level 0-4\n+    dilithiumNttLevel0_4(dilithiumConsts, coeffs, zetas);\n+\n+    \/\/ level 5\n+    for (int i = 0; i < 1024; i += 256) {\n+      __ ldpq(v30, v31, Address(dilithiumConsts, 0));  \/\/ qInv, q\n+      __ ldr(v0, __ Q, Address(coeffs, i + 16));\n+      __ ldr(v1, __ Q, Address(coeffs, i + 48));\n+      __ ldr(v2, __ Q, Address(coeffs, i + 80));\n+      __ ldr(v3, __ Q, Address(coeffs, i + 112));\n+      __ ldr(v4, __ Q, Address(coeffs, i + 144));\n+      __ ldr(v5, __ Q, Address(coeffs, i + 176));\n+      __ ldr(v6, __ Q, Address(coeffs, i + 208));\n+      __ ldr(v7, __ Q, Address(coeffs, i + 240));\n+      dilithium_load32zetas(zetas);\n+      dilithium_montmul32(false);\n+      __ ldr(v0, __ Q, Address(coeffs, i));\n+      __ ldr(v1, __ Q, Address(coeffs, i + 32));\n+      __ ldr(v2, __ Q, Address(coeffs, i + 64));\n+      __ ldr(v3, __ Q, Address(coeffs, i + 96));\n+      __ ldr(v4, __ Q, Address(coeffs, i + 128));\n+      __ ldr(v5, __ Q, Address(coeffs, i + 160));\n+      __ ldr(v6, __ Q, Address(coeffs, i + 192));\n+      __ ldr(v7, __ Q, Address(coeffs, i + 224));\n+      dilithium_add_sub32();\n+      __ str(v24, __ Q, Address(coeffs, i));\n+      __ str(v25, __ Q, Address(coeffs, i + 32));\n+      __ str(v26, __ Q, Address(coeffs, i + 64));\n+      __ str(v27, __ Q, Address(coeffs, i + 96));\n+      __ str(v28, __ Q, Address(coeffs, i + 128));\n+      __ str(v29, __ Q, Address(coeffs, i + 160));\n+      __ str(v30, __ Q, Address(coeffs, i + 192));\n+      __ str(v31, __ Q, Address(coeffs, i + 224));\n+      __ str(v0, __ Q, Address(coeffs, i + 16));\n+      __ str(v1, __ Q, Address(coeffs, i + 48));\n+      __ str(v2, __ Q, Address(coeffs, i + 80));\n+      __ str(v3, __ Q, Address(coeffs, i + 112));\n+      __ str(v4, __ Q, Address(coeffs, i + 144));\n+      __ str(v5, __ Q, Address(coeffs, i + 176));\n+      __ str(v6, __ Q, Address(coeffs, i + 208));\n+      __ str(v7, __ Q, Address(coeffs, i + 240));\n+    }\n+\n+    \/\/ level 6\n+    for (int i = 0; i < 1024; i += 128) {\n+      __ ldpq(v30, v31, Address(dilithiumConsts, 0));  \/\/ qInv, q\n+      __ add(tmpAddr, coeffs, i);\n+      __ ld2(v0, v1, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ ld2(v2, v3, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ ld2(v4, v5, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ ld2(v6, v7, __ T2D, tmpAddr);\n+      dilithium_load16zetas(16, zetas);\n+      dilithium_montmul_sub_add16();\n+      __ add(tmpAddr, coeffs, i);\n+      __ st2(v0, v1, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ st2(v2, v3, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ st2(v4, v5, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ st2(v6, v7, __ T2D, tmpAddr);\n+    }\n+\n+    \/\/ level 7\n+    for (int i = 0; i < 1024; i += 128) {\n+      __ ldpq(v30, v31, Address(dilithiumConsts, 0));  \/\/ qInv, q\n+      __ add(tmpAddr, coeffs, i);\n+      __ ld2(v0, v1, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ ld2(v2, v3, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ ld2(v4, v5, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ ld2(v6, v7, __ T4S, tmpAddr);\n+      dilithium_load16zetas(16, zetas);\n+      dilithium_montmul_sub_add16();\n+      __ add(tmpAddr, coeffs, i);\n+      __ st2(v0, v1, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ st2(v2, v3, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ st2(v4, v5, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ st2(v6, v7, __ T4S, tmpAddr);\n+    }\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n+    __ ret(lr);\n+\n+    return start;\n+\n+  }\n+\n+  \/\/ Do the computations that can be found in the body of the loop in\n+  \/\/ sun.security.provider.ML_DSA.implDilithiumAlmostInverseNttJava()\n+  \/\/ for 16 coefficients in parallel:\n+  \/\/ tmp = coeffs[j];\n+  \/\/ coeffs[j] = (tmp + coeffs[j + l]);\n+  \/\/ coeffs[j + l] = montMul(tmp - coeffs[j + l], -MONT_ZETAS_FOR_NTT[m]);\n+  \/\/ coefss[j]s are loaded in v0, v2, v4 and v6,\n+  \/\/ coeffs[j + l]s in v1, v3, v5 and v7,\n+  \/\/ the corresponding zetas in v16, v17, v18 and v19.\n+  void dilithium_sub_add_montmul16() {\n+    __ subv(v20, __ T4S, v0, v1);\n+    __ subv(v21, __ T4S, v2, v3);\n+    __ subv(v22, __ T4S, v4, v5);\n+    __ subv(v23, __ T4S, v6, v7);\n+\n+    __ addv(v0, __ T4S, v0, v1);\n+    __ addv(v2, __ T4S, v2, v3);\n+    __ addv(v4, __ T4S, v4, v5);\n+    __ addv(v6, __ T4S, v6, v7);\n+\n+    __ sqdmulh(v24, __ T4S, v20, v16); \/\/ aHigh = hi32(2 * b * c)\n+    __ mulv(v1, __ T4S, v20, v16);     \/\/ aLow = lo32(b * c)\n+    __ sqdmulh(v25, __ T4S, v21, v17);\n+    __ mulv(v3, __ T4S, v21, v17);\n+    __ sqdmulh(v26, __ T4S, v22, v18);\n+    __ mulv(v5, __ T4S, v22, v18);\n+    __ sqdmulh(v27, __ T4S, v23, v19);\n+    __ mulv(v7, __ T4S, v23, v19);\n+\n+    __ mulv(v1, __ T4S, v1, v30);      \/\/ m = (aLow * q)\n+    __ mulv(v3, __ T4S, v3, v30);\n+    __ mulv(v5, __ T4S, v5, v30);\n+    __ mulv(v7, __ T4S, v7, v30);\n+\n+    __ sqdmulh(v1, __ T4S, v1, v31);  \/\/ n = hi32(2 * m * q)\n+    __ sqdmulh(v3, __ T4S, v3, v31);\n+    __ sqdmulh(v5, __ T4S, v5, v31);\n+    __ sqdmulh(v7, __ T4S, v7, v31);\n+\n+    __ shsubv(v1, __ T4S, v24, v1);  \/\/ a = (aHigh  - n) \/ 2\n+    __ shsubv(v3, __ T4S, v25, v3);\n+    __ shsubv(v5, __ T4S, v26, v5);\n+    __ shsubv(v7, __ T4S, v27, v7);\n+  }\n+\n+  \/\/ At these levels, the indices that correspond to the 'j's (and 'j+l's)\n+  \/\/ in the Java implementation come in sequences of at least 8, so we\n+  \/\/ can use ldpq to collect the corresponding data into pairs of vector\n+  \/\/ registers\n+  \/\/ We collect the coefficients that correspond to the 'j's into v0-v7\n+  \/\/ the coefficiets that correspond to the 'j+l's into v16-v23 then\n+  \/\/ do the additions into v24-v31 and the subtractions into v0-v7 then\n+  \/\/ save the result of the additions, load the zetas into v16-v23\n+  \/\/ do the (Montgomery) multiplications by zeta in parallel into v16-v23\n+  \/\/ finally save the results back to the coeffs array\n+  void dilithiumInverseNttLevel3_7(const Register dilithiumConsts,\n+    const Register coeffs, const Register zetas) {\n+    int c1 = 0;\n+    int c2 = 32;\n+    int startIncr;\n+    int incr1;\n+    int incr2;\n+    int incr3;\n+\n+    for (int level = 3; level < 8; level++) {\n+      int c1Start = c1;\n+      int c2Start = c2;\n+      if (level == 3) {\n+        incr1 = 64;\n+        incr2 = 128;\n+        incr3 = 192;\n+      } else if (level == 4) {\n+        incr1 = 32;\n+        incr2 = 128;\n+        incr3 = 160;\n+      } else {\n+        incr1 = 32;\n+        incr2 = 64;\n+        incr3 = 96;\n+      }\n+\n+      for (int i = 0; i < 4; i++) {\n+        __ ldpq(v0, v1, Address(coeffs, c1Start));\n+        __ ldpq(v2, v3, Address(coeffs, c1Start + incr1));\n+        __ ldpq(v4, v5, Address(coeffs, c1Start + incr2));\n+        __ ldpq(v6, v7, Address(coeffs, c1Start + incr3));\n+        __ ldpq(v16, v17, Address(coeffs, c2Start));\n+        __ ldpq(v18, v19, Address(coeffs, c2Start + incr1));\n+        __ ldpq(v20, v21, Address(coeffs, c2Start + incr2));\n+        __ ldpq(v22, v23, Address(coeffs, c2Start + incr3));\n+        dilithium_add_sub32();\n+        __ stpq(v24, v25, Address(coeffs, c1Start));\n+        __ stpq(v26, v27, Address(coeffs, c1Start + incr1));\n+        __ stpq(v28, v29, Address(coeffs, c1Start + incr2));\n+        __ stpq(v30, v31, Address(coeffs, c1Start + incr3));\n+        __ ldpq(v30, v31, Address(dilithiumConsts, 0));   \/\/ qInv, q\n+        dilithium_load32zetas(zetas);\n+        dilithium_montmul32(false);\n+        __ stpq(v16, v17, Address(coeffs, c2Start));\n+        __ stpq(v18, v19, Address(coeffs, c2Start + incr1));\n+        __ stpq(v20, v21, Address(coeffs, c2Start + incr2));\n+        __ stpq(v22, v23, Address(coeffs, c2Start + incr3));\n+\n+        int k = 4 * level + i;\n+\n+        if (k < 24) {\n+          startIncr = 256;\n+        } else if (k == 25) {\n+          startIncr = 384;\n+        } else {\n+          startIncr = 128;\n+        }\n+\n+        c1Start += startIncr;\n+        c2Start += startIncr;\n+      }\n+\n+      c2 *= 2;\n+    }\n+  }\n+\n+  \/\/ Dilithium Inverse NTT function except the final mod Q division by 2^256.\n+  \/\/ Implements the method\n+  \/\/ static int implDilithiumAlmostInverseNtt(int[] coeffs, int[] zetas) {} of\n+  \/\/ the sun.security.provider.ML_DSA class.\n+  \/\/\n+  \/\/ coeffs (int[256]) = c_rarg0\n+  \/\/ zetas (int[256]) = c_rarg1\n+  address generate_dilithiumAlmostInverseNtt() {\n+\n+    __ align(CodeEntryAlignment);\n+    StubGenStubId stub_id = StubGenStubId::dilithiumAlmostInverseNtt_id;\n+    StubCodeMark mark(this, stub_id);\n+    address start = __ pc();\n+    __ enter();\n+\n+    const Register coeffs = c_rarg0;\n+    const Register zetas = c_rarg1;\n+\n+    const Register tmpAddr = r9;\n+    const Register dilithiumConsts = r10;\n+    const Register result = r11;\n+\n+    __ add(result, coeffs, 0);\n+    __ lea(dilithiumConsts, ExternalAddress((address) StubRoutines::aarch64::_dilithiumConsts));\n+\n+    \/\/ Each level represents one iteration of the outer for loop of the Java version\n+    \/\/ level0\n+    for (int i = 0; i < 1024; i += 128) {\n+      __ ldpq(v30, v31, Address(dilithiumConsts, 0));  \/\/ qInv, q\n+      __ add(tmpAddr, coeffs, i);\n+      __ ld2(v0, v1, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ ld2(v2, v3, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ ld2(v4, v5, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ ld2(v6, v7, __ T4S, tmpAddr);\n+      dilithium_load16zetas(16, zetas);\n+      dilithium_sub_add_montmul16();\n+      __ add(tmpAddr, coeffs, i);\n+      __ st2(v0, v1, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ st2(v2, v3, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ st2(v4, v5, __ T4S, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ st2(v6, v7, __ T4S, tmpAddr);\n+    }\n+\n+    \/\/ level 1\n+    for (int i = 0; i < 1024; i += 128) {\n+      __ add(tmpAddr, coeffs, i);\n+      __ ld2(v0, v1, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ ld2(v2, v3, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ ld2(v4, v5, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ ld2(v6, v7, __ T2D, tmpAddr);\n+      dilithium_load16zetas(16, zetas);\n+      dilithium_sub_add_montmul16();\n+      __ add(tmpAddr, coeffs, i);\n+      __ st2(v0, v1, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 32);\n+      __ st2(v2, v3, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 64);\n+      __ st2(v4, v5, __ T2D, tmpAddr);\n+      __ add(tmpAddr, coeffs, i + 96);\n+      __ st2(v6, v7, __ T2D, tmpAddr);\n+    }\n+\n+    \/\/level 2\n+    for (int i = 0; i < 1024; i += 256) {\n+      __ ldr(v0, __ Q, Address(coeffs, i));\n+      __ ldr(v1, __ Q, Address(coeffs, i + 32));\n+      __ ldr(v2, __ Q, Address(coeffs, i + 64));\n+      __ ldr(v3, __ Q, Address(coeffs, i + 96));\n+      __ ldr(v4, __ Q, Address(coeffs, i + 128));\n+      __ ldr(v5, __ Q, Address(coeffs, i + 160));\n+      __ ldr(v6, __ Q, Address(coeffs, i + 192));\n+      __ ldr(v7, __ Q, Address(coeffs, i + 224));\n+      __ ldr(v16, __ Q, Address(coeffs, i + 16));\n+      __ ldr(v17, __ Q, Address(coeffs, i + 48));\n+      __ ldr(v18, __ Q, Address(coeffs, i + 80));\n+      __ ldr(v19, __ Q, Address(coeffs, i + 112));\n+      __ ldr(v20, __ Q, Address(coeffs, i + 144));\n+      __ ldr(v21, __ Q, Address(coeffs, i + 176));\n+      __ ldr(v22, __ Q, Address(coeffs, i + 208));\n+      __ ldr(v23, __ Q, Address(coeffs, i + 240));\n+      dilithium_add_sub32();\n+      __ str(v24, __ Q, Address(coeffs, i));\n+      __ str(v25, __ Q, Address(coeffs, i + 32));\n+      __ str(v26, __ Q, Address(coeffs, i + 64));\n+      __ str(v27, __ Q, Address(coeffs, i + 96));\n+      __ str(v28, __ Q, Address(coeffs, i + 128));\n+      __ str(v29, __ Q, Address(coeffs, i + 160));\n+      __ str(v30, __ Q, Address(coeffs, i + 192));\n+      __ str(v31, __ Q, Address(coeffs, i + 224));\n+      dilithium_load32zetas(zetas);\n+      __ ldpq(v30, v31, Address(dilithiumConsts, 0));  \/\/ qInv, q\n+      dilithium_montmul32(false);\n+      __ str(v16, __ Q, Address(coeffs, i + 16));\n+      __ str(v17, __ Q, Address(coeffs, i + 48));\n+      __ str(v18, __ Q, Address(coeffs, i + 80));\n+      __ str(v19, __ Q, Address(coeffs, i + 112));\n+      __ str(v20, __ Q, Address(coeffs, i + 144));\n+      __ str(v21, __ Q, Address(coeffs, i + 176));\n+      __ str(v22, __ Q, Address(coeffs, i + 208));\n+      __ str(v23, __ Q, Address(coeffs, i + 240));\n+    }\n+\n+    \/\/ level 3-7\n+    dilithiumInverseNttLevel3_7(dilithiumConsts, coeffs, zetas);\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n+    __ ret(lr);\n+\n+    return start;\n+\n+  }\n+\n+  \/\/ Dilithium multiply polynomials in the NTT domain.\n+  \/\/ Straightforward implementation of the method\n+  \/\/ static int implDilithiumNttMult(\n+  \/\/              int[] result, int[] ntta, int[] nttb {} of\n+  \/\/ the sun.security.provider.ML_DSA class.\n+  \/\/\n+  \/\/ result (int[256]) = c_rarg0\n+  \/\/ poly1 (int[256]) = c_rarg1\n+  \/\/ poly2 (int[256]) = c_rarg2\n+  address generate_dilithiumNttMult() {\n+\n+    __ align(CodeEntryAlignment);\n+    StubGenStubId stub_id = StubGenStubId::dilithiumNttMult_id;\n+    StubCodeMark mark(this, stub_id);\n+    address start = __ pc();\n+    __ enter();\n+\n+    Label L_loop;\n+\n+    const Register result = c_rarg0;\n+    const Register poly1 = c_rarg1;\n+    const Register poly2 = c_rarg2;\n+\n+    const Register dilithiumConsts = r10;\n+    const Register len = r11;\n+\n+    __ lea(dilithiumConsts, ExternalAddress((address) StubRoutines::aarch64::_dilithiumConsts));\n+\n+    __ ldpq(v30, v31, Address(dilithiumConsts, 0));   \/\/ qInv, q\n+    __ ldr(v29, __ Q, Address(dilithiumConsts, 48));  \/\/ rSquare\n+\n+    __ mov(len, zr);\n+    __ add(len, len, 1024);\n+\n+    __ BIND(L_loop);\n+\n+    __ ldpq(v0, v1, __ post(poly1, 32));\n+    __ ldpq(v2, v3, __ post(poly1, 32));\n+    __ ldpq(v4, v5, __ post(poly1, 32));\n+    __ ldpq(v6, v7, __ post(poly1, 32));\n+    __ ldpq(v16, v17, __ post(poly2, 32));\n+    __ ldpq(v18, v19, __ post(poly2, 32));\n+    __ ldpq(v20, v21, __ post(poly2, 32));\n+    __ ldpq(v22, v23, __ post(poly2, 32));\n+    dilithium_montmul32(false);\n+    dilithium_montmul32(true);\n+    __ stpq(v16, v17, __ post(result, 32));\n+    __ stpq(v18, v19, __ post(result, 32));\n+    __ stpq(v20, v21, __ post(result, 32));\n+    __ stpq(v22, v23, __ post(result, 32));\n+\n+    __ sub(len, len, 128);\n+    __ cmp(len, (u1)128);\n+    __ br(Assembler::GE, L_loop);\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n+    __ ret(lr);\n+\n+    return start;\n+\n+  }\n+\n+  \/\/ Dilithium Motgomery multiply an array by a constant.\n+  \/\/ A straightforward implementation of the method\n+  \/\/ static int implDilithiumMontMulByConstant(int[] coeffs, int constant) {}\n+  \/\/ of the sun.security.provider.MLDSA class\n+  \/\/\n+  \/\/ coeffs (int[256]) = c_rarg0\n+  \/\/ constant (int) = c_rarg1\n+  address generate_dilithiumMontMulByConstant() {\n+\n+    __ align(CodeEntryAlignment);\n+    StubGenStubId stub_id = StubGenStubId::dilithiumMontMulByConstant_id;\n+    StubCodeMark mark(this, stub_id);\n+    address start = __ pc();\n+    __ enter();\n+\n+    Label L_loop;\n+\n+    const Register coeffs = c_rarg0;\n+    const Register constant = c_rarg1;\n+\n+    const Register dilithiumConsts = r10;\n+    const Register result = r11;\n+    const Register len = r12;\n+\n+    __ add(result, coeffs, 0);\n+    __ lea(dilithiumConsts, ExternalAddress((address) StubRoutines::aarch64::_dilithiumConsts));\n+\n+    __ ldpq(v30, v31, Address(dilithiumConsts, 0));   \/\/ qInv, q\n+    __ dup(v29, __ T4S, constant);\n+    __ mov(len, zr);\n+    __ add(len, len, 1024);\n+\n+    __ BIND(L_loop);\n+\n+    __ ldpq(v16, v17, __ post(coeffs, 32));\n+    __ ldpq(v18, v19, __ post(coeffs, 32));\n+    __ ldpq(v20, v21, __ post(coeffs, 32));\n+    __ ldpq(v22, v23, __ post(coeffs, 32));\n+    dilithium_montmul32(true);\n+    __ stpq(v16, v17, __ post(result, 32));\n+    __ stpq(v18, v19, __ post(result, 32));\n+    __ stpq(v20, v21, __ post(result, 32));\n+    __ stpq(v22, v23, __ post(result, 32));\n+\n+    __ sub(len, len, 128);\n+    __ cmp(len, (u1)128);\n+    __ br(Assembler::GE, L_loop);\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n+  \/\/ Dilithium decompose poly.\n+  \/\/ Implements the method\n+  \/\/ static int implDilithiumDecomposePoly(int[] coeffs, int constant) {}\n+  \/\/ of the sun.security.provider.ML_DSA class\n+  \/\/\n+  \/\/ input (int[256]) = c_rarg0\n+  \/\/ lowPart (int[256]) = c_rarg1\n+  \/\/ highPart (int[256]) = c_rarg2\n+  \/\/ twoGamma2  (int) = c_rarg3\n+  \/\/ multiplier (int) = c_rarg4\n+  address generate_dilithiumDecomposePoly() {\n+\n+    __ align(CodeEntryAlignment);\n+    StubGenStubId stub_id = StubGenStubId::dilithiumDecomposePoly_id;\n+    StubCodeMark mark(this, stub_id);\n+    address start = __ pc();\n+    __ enter();\n+\n+    Label L_loop;\n+\n+    const Register input = c_rarg0;\n+    const Register lowPart = c_rarg1;\n+    const Register highPart = c_rarg2;\n+    const Register twoGamma2 = c_rarg3;\n+    const Register multiplier = c_rarg4;\n+\n+    const Register len = r9;\n+    const Register dilithiumConsts = r10;\n+    const Register tmp = r11;\n+\n+    __ lea(dilithiumConsts, ExternalAddress((address) StubRoutines::aarch64::_dilithiumConsts));\n+\n+    \/\/ save callee-saved registers\n+    __ stpd(v8, v9, __ pre(sp, -64));\n+    __ stpd(v10, v11, Address(sp, 16));\n+    __ stpd(v12, v13, Address(sp, 32));\n+    __ stpd(v14, v15, Address(sp, 48));\n+\n+\n+    __ mov(tmp, zr);\n+    __ add(tmp, tmp, 1);\n+    __ dup(v25, __ T4S, tmp); \/\/ 1\n+    __ ldr(v30, __ Q, Address(dilithiumConsts, 16)); \/\/ q\n+    __ ldr(v31, __ Q, Address(dilithiumConsts, 64)); \/\/ addend for mod q reduce\n+    __ dup(v28, __ T4S, twoGamma2); \/\/ 2 * gamma2\n+    __ dup(v29, __ T4S, multiplier); \/\/ multiplier for mod 2 * gamma reduce\n+    __ subv(v26, __ T4S, v30, v25); \/\/ q - 1\n+    __ sshr(v27, __ T4S, v28, 1); \/\/ gamma2\n+\n+    __ mov(len, zr);\n+    __ add(len, len, 1024);\n+\n+    __ BIND(L_loop);\n+\n+    __ ld4(v0, v1, v2, v3, __ T4S, __ post(input, 64));\n+\n+    \/\/ rplus in v0\n+    \/\/  rplus = rplus - ((rplus + 5373807) >> 23) * dilithium_q;\n+    __ addv(v4, __ T4S, v0, v31);\n+    __ addv(v5, __ T4S, v1, v31);\n+    __ addv(v6, __ T4S, v2, v31);\n+    __ addv(v7, __ T4S, v3, v31);\n+\n+    __ sshr(v4, __ T4S, v4, 23);\n+    __ sshr(v5, __ T4S, v5, 23);\n+    __ sshr(v6, __ T4S, v6, 23);\n+    __ sshr(v7, __ T4S, v7, 23);\n+\n+    __ mulv(v4, __ T4S, v4, v30);\n+    __ mulv(v5, __ T4S, v5, v30);\n+    __ mulv(v6, __ T4S, v6, v30);\n+    __ mulv(v7, __ T4S, v7, v30);\n+\n+    __ subv(v0, __ T4S, v0, v4);\n+    __ subv(v1, __ T4S, v1, v5);\n+    __ subv(v2, __ T4S, v2, v6);\n+    __ subv(v3, __ T4S, v3, v7);\n+\n+    \/\/ rplus in v0\n+    \/\/ rplus = rplus + ((rplus >> 31) & dilithium_q);\n+    __ sshr(v4, __ T4S, v0, 31);\n+    __ sshr(v5, __ T4S, v1, 31);\n+    __ sshr(v6, __ T4S, v2, 31);\n+    __ sshr(v7, __ T4S, v3, 31);\n+\n+    __ andr(v4, __ T16B, v4, v30);\n+    __ andr(v5, __ T16B, v5, v30);\n+    __ andr(v6, __ T16B, v6, v30);\n+    __ andr(v7, __ T16B, v7, v30);\n+\n+    __ addv(v0, __ T4S, v0, v4);\n+    __ addv(v1, __ T4S, v1, v5);\n+    __ addv(v2, __ T4S, v2, v6);\n+    __ addv(v3, __ T4S, v3, v7);\n+\n+    \/\/ rplus in v0\n+    \/\/ int quotient = (rplus * multiplier) >> 22;\n+    __ mulv(v4, __ T4S, v0, v29);\n+    __ mulv(v5, __ T4S, v1, v29);\n+    __ mulv(v6, __ T4S, v2, v29);\n+    __ mulv(v7, __ T4S, v3, v29);\n+\n+    __ sshr(v4, __ T4S, v4, 22);\n+    __ sshr(v5, __ T4S, v5, 22);\n+    __ sshr(v6, __ T4S, v6, 22);\n+    __ sshr(v7, __ T4S, v7, 22);\n+\n+    \/\/ quotient in v4\n+    \/\/ int r0 = rplus - quotient * twoGamma2;\n+    __ mulv(v8, __ T4S, v4, v28);\n+    __ mulv(v9, __ T4S, v5, v28);\n+    __ mulv(v10, __ T4S, v6, v28);\n+    __ mulv(v11, __ T4S, v7, v28);\n+\n+    __ subv(v8, __ T4S, v0, v8);\n+    __ subv(v9, __ T4S, v1, v9);\n+    __ subv(v10, __ T4S, v2, v10);\n+    __ subv(v11, __ T4S, v3, v11);\n+\n+    \/\/ r0 in v8\n+    \/\/ int mask = (twoGamma2 - r0) >> 22;\n+    __ subv(v12, __ T4S, v28, v8);\n+    __ subv(v13, __ T4S, v28, v9);\n+    __ subv(v14, __ T4S, v28, v10);\n+    __ subv(v15, __ T4S, v28, v11);\n+\n+    __ sshr(v12, __ T4S, v12, 22);\n+    __ sshr(v13, __ T4S, v13, 22);\n+    __ sshr(v14, __ T4S, v14, 22);\n+    __ sshr(v15, __ T4S, v15, 22);\n+\n+    \/\/ mask in v12\n+    \/\/ r0 -= (mask & twoGamma2);\n+    __ andr(v16, __ T16B, v12, v28);\n+    __ andr(v17, __ T16B, v13, v28);\n+    __ andr(v18, __ T16B, v14, v28);\n+    __ andr(v19, __ T16B, v15, v28);\n+\n+    __ subv(v8, __ T4S, v8, v16);\n+    __ subv(v9, __ T4S, v9, v17);\n+    __ subv(v10, __ T4S, v10, v18);\n+    __ subv(v11, __ T4S, v11, v19);\n+\n+    \/\/ r0 in v8\n+    \/\/  quotient += (mask & 1);\n+    __ andr(v16, __ T16B, v12, v25);\n+    __ andr(v17, __ T16B, v13, v25);\n+    __ andr(v18, __ T16B, v14, v25);\n+    __ andr(v19, __ T16B, v15, v25);\n+\n+    __ addv(v4, __ T4S, v4, v16);\n+    __ addv(v5, __ T4S, v5, v17);\n+    __ addv(v6, __ T4S, v6, v18);\n+    __ addv(v7, __ T4S, v7, v19);\n+\n+    \/\/ mask = (twoGamma2 \/ 2 - r0) >> 31;\n+    __ subv(v12, __ T4S, v27, v8);\n+    __ subv(v13, __ T4S, v27, v9);\n+    __ subv(v14, __ T4S, v27, v10);\n+    __ subv(v15, __ T4S, v27, v11);\n+\n+    __ sshr(v12, __ T4S, v12, 31);\n+    __ sshr(v13, __ T4S, v13, 31);\n+    __ sshr(v14, __ T4S, v14, 31);\n+    __ sshr(v15, __ T4S, v15, 31);\n+\n+    \/\/ r0 -= (mask & twoGamma2);\n+    __ andr(v16, __ T16B, v12, v28);\n+    __ andr(v17, __ T16B, v13, v28);\n+    __ andr(v18, __ T16B, v14, v28);\n+    __ andr(v19, __ T16B, v15, v28);\n+\n+    __ subv(v8, __ T4S, v8, v16);\n+    __ subv(v9, __ T4S, v9, v17);\n+    __ subv(v10, __ T4S, v10, v18);\n+    __ subv(v11, __ T4S, v11, v19);\n+\n+    \/\/ quotient += (mask & 1);\n+    __ andr(v16, __ T16B, v12, v25);\n+    __ andr(v17, __ T16B, v13, v25);\n+    __ andr(v18, __ T16B, v14, v25);\n+    __ andr(v19, __ T16B, v15, v25);\n+\n+    __ addv(v4, __ T4S, v4, v16);\n+    __ addv(v5, __ T4S, v5, v17);\n+    __ addv(v6, __ T4S, v6, v18);\n+    __ addv(v7, __ T4S, v7, v19);\n+\n+    \/\/ int r1 = rplus - r0 - (dilithium_q - 1);\n+    __ subv(v16, __ T4S, v0, v8);\n+    __ subv(v17, __ T4S, v1, v9);\n+    __ subv(v18, __ T4S, v2, v10);\n+    __ subv(v19, __ T4S, v3, v11);\n+\n+    __ subv(v16, __ T4S, v16, v26);\n+    __ subv(v17, __ T4S, v17, v26);\n+    __ subv(v18, __ T4S, v18, v26);\n+    __ subv(v19, __ T4S, v19, v26);\n+\n+    \/\/ r1 in v16\n+    \/\/ r1 = (r1 | (-r1)) >> 31; \/\/ 0 if rplus - r0 == (dilithium_q - 1), -1 otherwise\n+    __ negr(v20, __ T4S, v16);\n+    __ negr(v21, __ T4S, v17);\n+    __ negr(v22, __ T4S, v18);\n+    __ negr(v23, __ T4S, v19);\n+\n+    __ orr(v16, __ T16B, v16, v20);\n+    __ orr(v17, __ T16B, v17, v21);\n+    __ orr(v18, __ T16B, v18, v22);\n+    __ orr(v19, __ T16B, v19, v23);\n+\n+    __ sshr(v0, __ T4S, v16, 31);\n+    __ sshr(v1, __ T4S, v17, 31);\n+    __ sshr(v2, __ T4S, v18, 31);\n+    __ sshr(v3, __ T4S, v19, 31);\n+\n+    \/\/ r1 in v0\n+    \/\/ r0 += ~r1;\n+    __ notr(v20, __ T16B, v0);\n+    __ notr(v21, __ T16B, v1);\n+    __ notr(v22, __ T16B, v2);\n+    __ notr(v23, __ T16B, v3);\n+\n+    __ addv(v8, __ T4S, v8, v20);\n+    __ addv(v9, __ T4S, v9, v21);\n+    __ addv(v10, __ T4S, v10, v22);\n+    __ addv(v11, __ T4S, v11, v23);\n+\n+    \/\/ r0 in v8\n+    \/\/ r1 = r1 & quotient;\n+    __ andr(v0, __ T16B, v4, v0);\n+    __ andr(v1, __ T16B, v5, v1);\n+    __ andr(v2, __ T16B, v6, v2);\n+    __ andr(v3, __ T16B, v7, v3);\n+\n+    \/\/ r1 in v0\n+    \/\/ lowPart[m] = r0;\n+    \/\/ highPart[m] = r1;\n+    __ st4(v8, v9, v10, v11, __ T4S, __ post(lowPart, 64));\n+    __ st4(v0, v1, v2, v3, __ T4S, __ post(highPart, 64));\n+\n+\n+    __ sub(len, len, 64);\n+    __ cmp(len, (u1)64);\n+    __ br(Assembler::GE, L_loop);\n+\n+    \/\/ restore callee-saved vector registers\n+    __ ldpd(v14, v15, Address(sp, 48));\n+    __ ldpd(v12, v13, Address(sp, 32));\n+    __ ldpd(v10, v11, Address(sp, 16));\n+    __ ldpd(v8, v9, __ post(sp, 64));\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ mov(r0, zr); \/\/ return 0\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n@@ -8872,0 +9932,8 @@\n+    if (UseDilithiumIntrinsics) {\n+      StubRoutines::_dilithiumAlmostNtt = generate_dilithiumAlmostNtt();\n+      StubRoutines::_dilithiumAlmostInverseNtt = generate_dilithiumAlmostInverseNtt();\n+      StubRoutines::_dilithiumNttMult = generate_dilithiumNttMult();\n+      StubRoutines::_dilithiumMontMulByConstant = generate_dilithiumMontMulByConstant();\n+      StubRoutines::_dilithiumDecomposePoly = generate_dilithiumDecomposePoly();\n+    }\n+\n@@ -8914,0 +9982,1 @@\n+      StubRoutines::_double_keccak         = generate_double_keccak();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":1146,"deletions":77,"binary":false,"changes":1223,"status":"modified"},{"patch":"@@ -51,0 +51,9 @@\n+ATTRIBUTE_ALIGNED(64) uint32_t StubRoutines::aarch64::_dilithiumConsts[] =\n+{\n+    58728449, 58728449, 58728449, 58728449, \/\/ montQInvModR\n+    8380417, 8380417, 8380417, 8380417, \/\/ dilithium_q\n+    16382, 16382, 16382, 16382, \/\/ toMont((dilithium_n)^-1 (mod dilithium_q))\n+    2365951, 2365951, 2365951, 2365951, \/\/ montRSquareModQ\n+    5373807, 5373807, 5373807, 5373807 \/\/ addend for modular reduce\n+};\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -113,0 +113,1 @@\n+  static uint32_t _dilithiumConsts[];\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -417,0 +417,11 @@\n+  if (_features & CPU_ASIMD) {\n+      if (FLAG_IS_DEFAULT(UseDilithiumIntrinsics)) {\n+          UseDilithiumIntrinsics = true;\n+      }\n+  } else if (UseDilithiumIntrinsics) {\n+      if (!FLAG_IS_DEFAULT(UseDilithiumIntrinsics)) {\n+          warning(\"Dilithium intrinsic requires ASIMD instructions\");\n+      }\n+      FLAG_SET_DEFAULT(UseDilithiumIntrinsics, false);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -482,0 +482,1 @@\n+  case vmIntrinsics::_double_keccak:\n@@ -494,0 +495,7 @@\n+  case vmIntrinsics::_dilithiumAlmostNtt:\n+  case vmIntrinsics::_dilithiumAlmostInverseNtt:\n+  case vmIntrinsics::_dilithiumNttMult:\n+  case vmIntrinsics::_dilithiumMontMulByConstant:\n+  case vmIntrinsics::_dilithiumDecomposePoly:\n+    if (!UseDilithiumIntrinsics) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -527,0 +527,6 @@\n+  \/* support for sun.security.provider.SHAKE128Parallel *\/                                                              \\\n+  do_class(sun_security_provider_sha3_parallel,                \"sun\/security\/provider\/SHA3Parallel\")                    \\\n+   do_intrinsic(_double_keccak, sun_security_provider_sha3_parallel, double_keccak_name, double_keccak_signature, F_S)   \\\n+   do_name(     double_keccak_name,                                 \"doubleKeccak\")                                     \\\n+   do_signature(double_keccak_signature,                            \"([J[J)I\")                                          \\\n+                                                                                                                        \\\n@@ -572,0 +578,20 @@\n+  \/* support for sun.security.provider.ML_DSA *\/                                                                        \\\n+ do_class(sun_security_provider_ML_DSA,      \"sun\/security\/provider\/ML_DSA\")                                            \\\n+   do_signature(IaII_signature, \"([II)I\")                                                                               \\\n+   do_signature(IaIaI_signature, \"([I[I)I\")                                                                             \\\n+   do_signature(IaIaIaI_signature, \"([I[I[I)I\")                                                                         \\\n+   do_signature(IaIaIaIII_signature, \"([I[I[III)I\")                                                                     \\\n+  do_intrinsic(_dilithiumAlmostNtt, sun_security_provider_ML_DSA, dilithiumAlmostNtt_name, IaIaI_signature, F_S)        \\\n+   do_name(dilithiumAlmostNtt_name,                            \"implDilithiumAlmostNtt\")                                \\\n+  do_intrinsic(_dilithiumAlmostInverseNtt, sun_security_provider_ML_DSA,                                                \\\n+                dilithiumAlmostInverseNtt_name, IaIaI_signature, F_S)                                                   \\\n+   do_name(dilithiumAlmostInverseNtt_name,                     \"implDilithiumAlmostInverseNtt\")                         \\\n+  do_intrinsic(_dilithiumNttMult, sun_security_provider_ML_DSA, dilithiumNttMult_name, IaIaIaI_signature, F_S)          \\\n+   do_name(dilithiumNttMult_name,                              \"implDilithiumNttMult\")                                  \\\n+  do_intrinsic(_dilithiumMontMulByConstant, sun_security_provider_ML_DSA,                                               \\\n+                dilithiumMontMulByConstant_name, IaII_signature, F_S)                                                   \\\n+   do_name(dilithiumMontMulByConstant_name,                    \"implDilithiumMontMulByConstant\")                        \\\n+  do_intrinsic(_dilithiumDecomposePoly, sun_security_provider_ML_DSA,                                                   \\\n+                dilithiumDecomposePoly_name, IaIaIaIII_signature, F_S)                                                  \\\n+   do_name(dilithiumDecomposePoly_name,                    \"implDilithiumDecomposePoly\")                                \\\n+                                                                                                                        \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -398,0 +398,1 @@\n+  static_field(StubRoutines,                _double_keccak,                                   address)                               \\\n@@ -399,0 +400,5 @@\n+  static_field(StubRoutines,                _dilithiumAlmostNtt,                              address)                               \\\n+  static_field(StubRoutines,                _dilithiumAlmostInverseNtt,                       address)                               \\\n+  static_field(StubRoutines,                _dilithiumNttMult,                                address)                               \\\n+  static_field(StubRoutines,                _dilithiumMontMulByConstant,                      address)                               \\\n+  static_field(StubRoutines,                _dilithiumDecomposePoly,                          address)                               \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -781,0 +781,1 @@\n+  case vmIntrinsics::_double_keccak:\n@@ -790,0 +791,5 @@\n+  case vmIntrinsics::_dilithiumAlmostNtt:\n+  case vmIntrinsics::_dilithiumAlmostInverseNtt:\n+  case vmIntrinsics::_dilithiumNttMult:\n+  case vmIntrinsics::_dilithiumMontMulByConstant:\n+  case vmIntrinsics::_dilithiumDecomposePoly:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2195,0 +2195,5 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"dilithiumAlmostNtt\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"dilithiumAlmostInverseNtt\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"dilithiumNttMult\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"dilithiumMontMulByConstant\") == 0 ||\n+                  strcmp(call->as_CallLeaf()->_name, \"dilithiumDecomposePoly\") == 0 ||\n@@ -2206,0 +2211,1 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"double_keccak\") == 0 ||\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -599,0 +599,2 @@\n+  case vmIntrinsics::_double_keccak:\n+    return inline_double_keccak();\n@@ -629,0 +631,10 @@\n+  case vmIntrinsics::_dilithiumAlmostNtt:\n+    return inline_dilithiumAlmostNtt();\n+  case vmIntrinsics::_dilithiumAlmostInverseNtt:\n+    return inline_dilithiumAlmostInverseNtt();\n+  case vmIntrinsics::_dilithiumNttMult:\n+    return inline_dilithiumNttMult();\n+  case vmIntrinsics::_dilithiumMontMulByConstant:\n+    return inline_dilithiumMontMulByConstant();\n+  case vmIntrinsics::_dilithiumDecomposePoly:\n+    return inline_dilithiumDecomposePoly();\n@@ -7635,0 +7647,170 @@\n+\/\/------------------------------inline_dilithiumAlmostNtt\n+bool LibraryCallKit::inline_dilithiumAlmostNtt() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseDilithiumIntrinsics, \"need Dilithium intrinsics support\");\n+  assert(callee()->signature()->size() == 2, \"dilithiumAlmostNtt has 2 parameters\");\n+\n+  stubAddr = StubRoutines::dilithiumAlmostNtt();\n+  stubName = \"dilithiumAlmostNtt\";\n+  if (!stubAddr) return false;\n+\n+  Node* coeffs          = argument(0);\n+  Node* ntt_zetas        = argument(1);\n+\n+  coeffs = must_be_not_null(coeffs, true);\n+  ntt_zetas = must_be_not_null(ntt_zetas, true);\n+\n+  Node* coeffs_start  = array_element_address(coeffs, intcon(0), T_INT);\n+  assert(coeffs_start, \"coeffs is null\");\n+  Node* ntt_zetas_start  = array_element_address(ntt_zetas, intcon(0), T_INT);\n+  assert(ntt_zetas_start, \"ntt_zetas is null\");\n+  Node* dilithiumAlmostNtt = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::dilithiumAlmostNtt_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  coeffs_start, ntt_zetas_start);\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(dilithiumAlmostNtt, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n+\/\/------------------------------inline_dilithiumAlmostInverseNtt\n+bool LibraryCallKit::inline_dilithiumAlmostInverseNtt() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseDilithiumIntrinsics, \"need Dilithium intrinsics support\");\n+  assert(callee()->signature()->size() == 2, \"dilithiumAlmostInverseNtt has 2 parameters\");\n+\n+  stubAddr = StubRoutines::dilithiumAlmostInverseNtt();\n+  stubName = \"dilithiumAlmostInverseNtt\";\n+  if (!stubAddr) return false;\n+\n+  Node* coeffs          = argument(0);\n+  Node* zetas           = argument(1);\n+\n+  coeffs = must_be_not_null(coeffs, true);\n+  zetas = must_be_not_null(zetas, true);\n+\n+  Node* coeffs_start  = array_element_address(coeffs, intcon(0), T_INT);\n+  assert(coeffs_start, \"coeffs is null\");\n+  Node* zetas_start  = array_element_address(zetas, intcon(0), T_INT);\n+  assert(zetas_start, \"inverseNtt_zetas is null\");\n+  Node* dilithiumAlmostInverseNtt = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::dilithiumAlmostInverseNtt_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  coeffs_start, zetas_start);\n+\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(dilithiumAlmostInverseNtt, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n+\/\/------------------------------inline_dilithiumNttMult\n+bool LibraryCallKit::inline_dilithiumNttMult() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseDilithiumIntrinsics, \"need Dilithium intrinsics support\");\n+  assert(callee()->signature()->size() == 3, \"dilithiumNttMult has 3 parameters\");\n+\n+  stubAddr = StubRoutines::dilithiumNttMult();\n+  stubName = \"dilithiumNttMult\";\n+  if (!stubAddr) return false;\n+\n+  Node* result          = argument(0);\n+  Node* ntta            = argument(1);\n+  Node* nttb            = argument(2);\n+\n+  result = must_be_not_null(result, true);\n+  ntta = must_be_not_null(ntta, true);\n+  nttb = must_be_not_null(nttb, true);\n+\n+  Node* result_start  = array_element_address(result, intcon(0), T_INT);\n+  assert(result_start, \"result is null\");\n+  Node* ntta_start  = array_element_address(ntta, intcon(0), T_INT);\n+  assert(ntta_start, \"ntta is null\");\n+  Node* nttb_start  = array_element_address(nttb, intcon(0), T_INT);\n+  assert(nttb_start, \"nttb is null\");\n+  Node* dilithiumNttMult = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::dilithiumNttMult_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  result_start, ntta_start, nttb_start);\n+\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(dilithiumNttMult, TypeFunc::Parms));\n+  set_result(retvalue);\n+\n+  return true;\n+}\n+\n+\/\/------------------------------inline_dilithiumMontMulByConstant\n+bool LibraryCallKit::inline_dilithiumMontMulByConstant() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseDilithiumIntrinsics, \"need Dilithium intrinsics support\");\n+  assert(callee()->signature()->size() == 2, \"dilithiumMontMulByConstant has 2 parameters\");\n+\n+  stubAddr = StubRoutines::dilithiumMontMulByConstant();\n+  stubName = \"dilithiumMontMulByConstant\";\n+  if (!stubAddr) return false;\n+\n+  Node* coeffs          = argument(0);\n+  Node* constant        = argument(1);\n+\n+  coeffs = must_be_not_null(coeffs, true);\n+\n+  Node* coeffs_start  = array_element_address(coeffs, intcon(0), T_INT);\n+  assert(coeffs_start, \"coeffs is null\");\n+  Node* dilithiumMontMulByConstant = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::dilithiumMontMulByConstant_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  coeffs_start, constant);\n+\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(dilithiumMontMulByConstant, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n+\n+\/\/------------------------------inline_dilithiumDecomposePoly\n+bool LibraryCallKit::inline_dilithiumDecomposePoly() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseDilithiumIntrinsics, \"need Dilithium intrinsics support\");\n+  assert(callee()->signature()->size() == 5, \"dilithiumDecomposePoly has 5 parameters\");\n+\n+  stubAddr = StubRoutines::dilithiumDecomposePoly();\n+  stubName = \"dilithiumDecomposePoly\";\n+  if (!stubAddr) return false;\n+\n+  Node* input          = argument(0);\n+  Node* lowPart        = argument(1);\n+  Node* highPart       = argument(2);\n+  Node* twoGamma2      = argument(3);\n+  Node* multiplier     = argument(4);\n+\n+  input = must_be_not_null(input, true);\n+  lowPart = must_be_not_null(lowPart, true);\n+  highPart = must_be_not_null(highPart, true);\n+\n+  Node* input_start  = array_element_address(input, intcon(0), T_INT);\n+  assert(input_start, \"input is null\");\n+  Node* lowPart_start  = array_element_address(lowPart, intcon(0), T_INT);\n+  assert(lowPart_start, \"lowPart is null\");\n+  Node* highPart_start  = array_element_address(highPart, intcon(0), T_INT);\n+  assert(highPart_start, \"highPart is null\");\n+\n+  Node* dilithiumDecomposePoly = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::dilithiumDecomposePoly_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  input_start, lowPart_start, highPart_start,\n+                                  twoGamma2, multiplier);\n+\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(dilithiumDecomposePoly, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n@@ -7898,0 +8080,32 @@\n+\/\/------------------------------inline_double_keccak\n+bool LibraryCallKit::inline_double_keccak() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseSHA3Intrinsics, \"need SHA3 intrinsics support\");\n+  assert(callee()->signature()->size() == 2, \"double_keccak has 2 parameters\");\n+\n+  stubAddr = StubRoutines::double_keccak();\n+  stubName = \"double_keccak\";\n+  if (!stubAddr) return false;\n+\n+  Node* status0        = argument(0);\n+  Node* status1        = argument(1);\n+\n+  status0 = must_be_not_null(status0, true);\n+  status1 = must_be_not_null(status1, true);\n+\n+  Node* status0_start  = array_element_address(status0, intcon(0), T_LONG);\n+  assert(status0_start, \"status0 is null\");\n+  Node* status1_start  = array_element_address(status1, intcon(0), T_LONG);\n+  assert(status1_start, \"status1 is null\");\n+  Node* double_keccak = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::double_keccak_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  status0_start, status1_start);\n+  \/\/ return an int\n+  Node* retvalue = _gvn.transform(new ProjNode(double_keccak, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":214,"deletions":0,"binary":false,"changes":214,"status":"modified"},{"patch":"@@ -316,0 +316,5 @@\n+  bool inline_dilithiumAlmostNtt();\n+  bool inline_dilithiumAlmostInverseNtt();\n+  bool inline_dilithiumNttMult();\n+  bool inline_dilithiumMontMulByConstant();\n+  bool inline_dilithiumDecomposePoly();\n@@ -322,0 +327,1 @@\n+  bool inline_double_keccak();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -232,0 +232,1 @@\n+const TypeFunc* OptoRuntime::_double_keccak_Type                  = nullptr;\n@@ -241,0 +242,7 @@\n+\n+const TypeFunc* OptoRuntime::_dilithiumAlmostNtt_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_dilithiumAlmostInverseNtt_Type      = nullptr;\n+const TypeFunc* OptoRuntime::_dilithiumNttMult_Type               = nullptr;\n+const TypeFunc* OptoRuntime::_dilithiumMontMulByConstant_Type     = nullptr;\n+const TypeFunc* OptoRuntime::_dilithiumDecomposePoly_Type         = nullptr;\n+\n@@ -1172,0 +1180,3 @@\n+\/*\n+ * int implCompressMultiBlock(byte[] b, int ofs, int limit)\n+ *\/\n@@ -1193,0 +1204,19 @@\n+\/\/ SHAKE128Parallel doubleKeccak function\n+static const TypeFunc* make_double_keccak_Type() {\n+    int argcnt = 2;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ status0\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ status1\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n@@ -1378,0 +1408,99 @@\n+\/\/ Dilithium NTT function except for the final \"normalization\" to |coeff| < Q\n+static const TypeFunc* make_dilithiumAlmostNtt_Type() {\n+    int argcnt = 2;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ coeffs\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ NTT zetas\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n+\/\/ Dilithium inverse NTT function except the final mod Q division by 2^256\n+static const TypeFunc* make_dilithiumAlmostInverseNtt_Type() {\n+    int argcnt = 2;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ coeffs\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ inverse NTT zetas\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n+\/\/ Dilithium NTT multiply function\n+static const TypeFunc* make_dilithiumNttMult_Type() {\n+    int argcnt = 3;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ result\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ ntta\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ nttb\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n+\/\/ Dilithium Montgomery multiply a polynome coefficient array by a constant\n+static const TypeFunc* make_dilithiumMontMulByConstant_Type() {\n+    int argcnt = 2;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ coeffs\n+    fields[argp++] = TypeInt::INT;          \/\/ constant multiplier\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n+\/\/ Dilithium decompose polynomial\n+static const TypeFunc* make_dilithiumDecomposePoly_Type() {\n+    int argcnt = 5;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ input\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ lowPart\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ highPart\n+    fields[argp++] = TypeInt::INT;          \/\/ 2 * gamma2\n+    fields[argp++] = TypeInt::INT;          \/\/ multiplier\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n@@ -1981,0 +2110,1 @@\n+  _double_keccak_Type                 = make_double_keccak_Type();\n@@ -1990,0 +2120,7 @@\n+\n+  _dilithiumAlmostNtt_Type            = make_dilithiumAlmostNtt_Type();\n+  _dilithiumAlmostInverseNtt_Type     = make_dilithiumAlmostInverseNtt_Type();\n+  _dilithiumNttMult_Type              = make_dilithiumNttMult_Type();\n+  _dilithiumMontMulByConstant_Type    = make_dilithiumMontMulByConstant_Type();\n+  _dilithiumDecomposePoly_Type        = make_dilithiumDecomposePoly_Type();\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":137,"deletions":0,"binary":false,"changes":137,"status":"modified"},{"patch":"@@ -173,0 +173,1 @@\n+  static const TypeFunc* _double_keccak_Type;\n@@ -182,0 +183,5 @@\n+  static const TypeFunc* _dilithiumAlmostNtt_Type;\n+  static const TypeFunc* _dilithiumAlmostInverseNtt_Type;\n+  static const TypeFunc* _dilithiumNttMult_Type;\n+  static const TypeFunc* _dilithiumMontMulByConstant_Type;\n+  static const TypeFunc* _dilithiumDecomposePoly_Type;\n@@ -528,0 +534,5 @@\n+  static inline const TypeFunc* double_keccak_Type() {\n+    assert(_double_keccak_Type != nullptr, \"should be initialized\");\n+    return _double_keccak_Type;\n+  }\n+\n@@ -576,0 +587,25 @@\n+  static inline const TypeFunc* dilithiumAlmostNtt_Type() {\n+    assert(_dilithiumAlmostNtt_Type != nullptr, \"should be initialized\");\n+    return _dilithiumAlmostNtt_Type;\n+  }\n+\n+  static inline const TypeFunc* dilithiumAlmostInverseNtt_Type() {\n+    assert(_dilithiumAlmostInverseNtt_Type != nullptr, \"should be initialized\");\n+    return _dilithiumAlmostInverseNtt_Type;\n+  }\n+\n+  static inline const TypeFunc* dilithiumNttMult_Type() {\n+    assert(_dilithiumNttMult_Type != nullptr, \"should be initialized\");\n+    return _dilithiumNttMult_Type;\n+  }\n+\n+  static inline const TypeFunc* dilithiumMontMulByConstant_Type() {\n+    assert(_dilithiumMontMulByConstant_Type != nullptr, \"should be initialized\");\n+    return _dilithiumMontMulByConstant_Type;\n+  }\n+\n+  static inline const TypeFunc* dilithiumDecomposePoly_Type() {\n+    assert(_dilithiumDecomposePoly_Type != nullptr, \"should be initialized\");\n+    return _dilithiumDecomposePoly_Type;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -328,0 +328,3 @@\n+  product(bool, UseDilithiumIntrinsics, false, DIAGNOSTIC,                  \\\n+          \"Use intrinsics for the vectorized version of Dilithium\")         \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -499,1 +499,1 @@\n-\/\/ relevant template macros ahve been defined\n+\/\/ relevant template macros have been defined\n@@ -680,0 +680,15 @@\n+  do_stub(compiler, dilithiumAlmostNtt)                                 \\\n+  do_entry(compiler, dilithiumAlmostNtt,                                \\\n+           dilithiumAlmostNtt, dilithiumAlmostNtt)                      \\\n+  do_stub(compiler, dilithiumAlmostInverseNtt)                          \\\n+  do_entry(compiler, dilithiumAlmostInverseNtt,                         \\\n+           dilithiumAlmostInverseNtt, dilithiumAlmostInverseNtt)        \\\n+  do_stub(compiler, dilithiumNttMult)                                   \\\n+  do_entry(compiler, dilithiumNttMult,                                  \\\n+           dilithiumNttMult, dilithiumNttMult)                          \\\n+  do_stub(compiler, dilithiumMontMulByConstant)                         \\\n+  do_entry(compiler, dilithiumMontMulByConstant,                        \\\n+           dilithiumMontMulByConstant, dilithiumMontMulByConstant)      \\\n+  do_stub(compiler, dilithiumDecomposePoly)                             \\\n+  do_entry(compiler, dilithiumDecomposePoly,                            \\\n+           dilithiumDecomposePoly, dilithiumDecomposePoly)              \\\n@@ -730,0 +745,2 @@\n+  do_stub(compiler, double_keccak)                                      \\\n+  do_entry(compiler, double_keccak, double_keccak, double_keccak)       \\\n@@ -1045,1 +1062,0 @@\n-\n@@ -1067,1 +1083,0 @@\n-\n","filename":"src\/hotspot\/share\/runtime\/stubDeclarations.hpp","additions":18,"deletions":3,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -102,0 +102,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n@@ -30,0 +31,1 @@\n+import sun.security.provider.SHA3Parallel.Shake128Parallel;\n@@ -31,0 +33,1 @@\n+import java.security.InvalidAlgorithmParameterException;\n@@ -47,1 +50,1 @@\n-\n+    private static final int SHAKE128_BLOCK_SIZE = 168; \/\/ the block length for SHAKE128\n@@ -101,33 +104,274 @@\n-    private static final int[] MONT_ZETAS_FOR_INVERSE_NTT = new int[]{\n-        -1976782, 846154, -1400424, -3937738, 1362209, 48306, -3919660, 554416,\n-        3545687, -1612842, 976891, -183443, 2286327, 420899, 2235985, 2939036,\n-        3833893, 260646, 1104333, 1667432, -1910376, 1803090, -1723600, 426683,\n-        -472078, -1717735, 975884, -2213111, -269760, -3866901, -3523897, 3038916,\n-        1799107, 3694233, -1652634, -810149, -3014001, -1616392, -162844, 3183426,\n-        1207385, -185531, -3369112, -1957272, 164721, -2454455, -2432395, 2013608,\n-        3776993, -594136, 3724270, 2584293, 1846953, 1671176, 2831860, 542412,\n-        -3406031, -2235880, -777191, -1500165, 1374803, 2546312, -1917081, 1279661,\n-        1962642, -3306115, -1312455, 451100, 1430225, 3318210, -1237275, 1333058,\n-        1050970, -1903435, -1869119, 2994039, 3548272, -2635921, -1250494, 3767016,\n-        -1595974, -2486353, -1247620, -4055324, -1265009, 2590150, -2691481, -2842341,\n-        -203044, -1735879, 3342277, -3437287, -4108315, 2437823, -286988, -342297,\n-        3595838, 768622, 525098, 3556995, -3207046, -2031748, 3122442, 655327,\n-        522500, 43260, 1613174, -495491, -819034, -909542, -1859098, -900702,\n-        3193378, 1197226, 3759364, 3520352, -3513181, 1235728, -2434439, -266997,\n-        3562462, 2446433, -2244091, 3342478, -3817976, -2316500, -3407706, -2091667,\n-        -3839961, 3628969, 3881060, 3019102, 1439742, 812732, 1584928, -1285669,\n-        -1341330, -1315589, 177440, 2409325, 1851402, -3159746, 3553272, -189548,\n-        1316856, -759969, 210977, -2389356, 3249728, -1653064, 8578, 3724342,\n-        -3958618, -904516, 1100098, -44288, -3097992, -508951, -264944, 3343383,\n-        1430430, -1852771, -1349076, 381987, 1308169, 22981, 1228525, 671102,\n-        2477047, 411027, 3693493, 2967645, -2715295, -2147896, 983419, -3412210,\n-        -126922, 3632928, 3157330, 3190144, 1000202, 4083598, -1939314, 1257611,\n-        1585221, -2176455, -3475950, 1452451, 3041255, 3677745, 1528703, 3930395,\n-        2797779, -2071892, 2556880, -3900724, -3881043, -954230, -531354, -811944,\n-        -3699596, 1600420, 2140649, -3507263, 3821735, -3505694, 1643818, 1699267,\n-        539299, -2348700, 300467, -3539968, 2867647, -3574422, 3043716, 3861115,\n-        -3915439, 2537516, 3592148, 1661693, -3530437, -3077325, -95776, -2706023,\n-        -280005, -4010497, 19422, -1757237, 3277672, 1399561, 3859737, 2118186,\n-        2108549, -2619752, 1119584, 549488, -3585928, 1079900, -1024112, -2725464,\n-        -2680103, -3111497, 2884855, -3119733, 2091905, 359251, -2353451, -1826347,\n-        -466468, 876248, 777960, -237124, 518909, 2608894, -25847\n+    private static final int[] MONT_ZETAS_FOR_VECTOR_NTT = new int[]{\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+            25847, 25847, 25847, 25847, 25847, 25847, 25847, 25847,\n+\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894, -2608894,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+            -518909, -518909, -518909, -518909, -518909, -518909, -518909, -518909,\n+\n+            237124, 237124, 237124, 237124, 237124, 237124, 237124, 237124,\n+            237124, 237124, 237124, 237124, 237124, 237124, 237124, 237124,\n+            237124, 237124, 237124, 237124, 237124, 237124, 237124, 237124,\n+            237124, 237124, 237124, 237124, 237124, 237124, 237124, 237124,\n+            -777960, -777960, -777960, -777960, -777960, -777960, -777960, -777960,\n+            -777960, -777960, -777960, -777960, -777960, -777960, -777960, -777960,\n+            -777960, -777960, -777960, -777960, -777960, -777960, -777960, -777960,\n+            -777960, -777960, -777960, -777960, -777960, -777960, -777960, -777960,\n+            -876248, -876248, -876248, -876248, -876248, -876248, -876248, -876248,\n+            -876248, -876248, -876248, -876248, -876248, -876248, -876248, -876248,\n+            -876248, -876248, -876248, -876248, -876248, -876248, -876248, -876248,\n+            -876248, -876248, -876248, -876248, -876248, -876248, -876248, -876248,\n+            466468, 466468, 466468, 466468, 466468, 466468, 466468, 466468,\n+            466468, 466468, 466468, 466468, 466468, 466468, 466468, 466468,\n+            466468, 466468, 466468, 466468, 466468, 466468, 466468, 466468,\n+            466468, 466468, 466468, 466468, 466468, 466468, 466468, 466468,\n+\n+            1826347, 1826347, 1826347, 1826347, 1826347, 1826347, 1826347, 1826347,\n+            1826347, 1826347, 1826347, 1826347, 1826347, 1826347, 1826347, 1826347,\n+            2353451, 2353451, 2353451, 2353451, 2353451, 2353451, 2353451, 2353451,\n+            2353451, 2353451, 2353451, 2353451, 2353451, 2353451, 2353451, 2353451,\n+            -359251, -359251, -359251, -359251, -359251, -359251, -359251, -359251,\n+            -359251, -359251, -359251, -359251, -359251, -359251, -359251, -359251,\n+            -2091905, -2091905, -2091905, -2091905, -2091905, -2091905, -2091905, -2091905,\n+            -2091905, -2091905, -2091905, -2091905, -2091905, -2091905, -2091905, -2091905,\n+            3119733, 3119733, 3119733, 3119733, 3119733, 3119733, 3119733, 3119733,\n+            3119733, 3119733, 3119733, 3119733, 3119733, 3119733, 3119733, 3119733,\n+            -2884855, -2884855, -2884855, -2884855, -2884855, -2884855, -2884855, -2884855,\n+            -2884855, -2884855, -2884855, -2884855, -2884855, -2884855, -2884855, -2884855,\n+            3111497, 3111497, 3111497, 3111497, 3111497, 3111497, 3111497, 3111497,\n+            3111497, 3111497, 3111497, 3111497, 3111497, 3111497, 3111497, 3111497,\n+            2680103, 2680103, 2680103, 2680103, 2680103, 2680103, 2680103, 2680103,\n+            2680103, 2680103, 2680103, 2680103, 2680103, 2680103, 2680103, 2680103,\n+\n+            2725464, 2725464, 2725464, 2725464, 2725464, 2725464, 2725464, 2725464,\n+            1024112, 1024112, 1024112, 1024112, 1024112, 1024112, 1024112, 1024112,\n+            -1079900, -1079900, -1079900, -1079900, -1079900, -1079900, -1079900, -1079900,\n+            3585928, 3585928, 3585928, 3585928, 3585928, 3585928, 3585928, 3585928,\n+            -549488, -549488, -549488, -549488, -549488, -549488, -549488, -549488,\n+            -1119584, -1119584, -1119584, -1119584, -1119584, -1119584, -1119584, -1119584,\n+            2619752, 2619752, 2619752, 2619752, 2619752, 2619752, 2619752, 2619752,\n+            -2108549, -2108549, -2108549, -2108549, -2108549, -2108549, -2108549, -2108549,\n+            -2118186, -2118186, -2118186, -2118186, -2118186, -2118186, -2118186, -2118186,\n+            -3859737, -3859737, -3859737, -3859737, -3859737, -3859737, -3859737, -3859737,\n+            -1399561, -1399561, -1399561, -1399561, -1399561, -1399561, -1399561, -1399561,\n+            -3277672, -3277672, -3277672, -3277672, -3277672, -3277672, -3277672, -3277672,\n+            1757237, 1757237, 1757237, 1757237, 1757237, 1757237, 1757237, 1757237,\n+            -19422, -19422, -19422, -19422, -19422, -19422, -19422, -19422,\n+            4010497, 4010497, 4010497, 4010497, 4010497, 4010497, 4010497, 4010497,\n+            280005, 280005, 280005, 280005, 280005, 280005, 280005, 280005,\n+\n+            2706023, 2706023, 2706023, 2706023, 95776, 95776, 95776, 95776,\n+            3077325, 3077325, 3077325, 3077325, 3530437, 3530437, 3530437, 3530437,\n+            -1661693, -1661693, -1661693, -1661693, -3592148, -3592148, -3592148, -3592148,\n+            -2537516, -2537516, -2537516, -2537516, 3915439, 3915439, 3915439, 3915439,\n+            -3861115, -3861115, -3861115, -3861115, -3043716, -3043716, -3043716, -3043716,\n+            3574422, 3574422, 3574422, 3574422, -2867647, -2867647, -2867647, -2867647,\n+            3539968, 3539968, 3539968, 3539968, -300467, -300467, -300467, -300467,\n+            2348700, 2348700, 2348700, 2348700, -539299, -539299, -539299, -539299,\n+            -1699267, -1699267, -1699267, -1699267, -1643818, -1643818, -1643818, -1643818,\n+            3505694, 3505694, 3505694, 3505694, -3821735, -3821735, -3821735, -3821735,\n+            3507263, 3507263, 3507263, 3507263, -2140649, -2140649, -2140649, -2140649,\n+            -1600420, -1600420, -1600420, -1600420, 3699596, 3699596, 3699596, 3699596,\n+            811944, 811944, 811944, 811944, 531354, 531354, 531354, 531354,\n+            954230, 954230, 954230, 954230, 3881043, 3881043, 3881043, 3881043,\n+            3900724, 3900724, 3900724, 3900724, -2556880, -2556880, -2556880, -2556880,\n+            2071892, 2071892, 2071892, 2071892, -2797779, -2797779, -2797779, -2797779,\n+\n+            -3930395, -3930395, -1528703, -1528703, -3677745, -3677745, -3041255, -3041255,\n+            -1452451, -1452451, 3475950, 3475950, 2176455, 2176455, -1585221, -1585221,\n+            -1257611, -1257611, 1939314, 1939314, -4083598, -4083598, -1000202, -1000202,\n+            -3190144, -3190144, -3157330, -3157330, -3632928, -3632928, 126922, 126922,\n+            3412210, 3412210, -983419, -983419, 2147896, 2147896, 2715295, 2715295,\n+            -2967645, -2967645, -3693493, -3693493, -411027, -411027, -2477047, -2477047,\n+            -671102, -671102, -1228525, -1228525, -22981, -22981, -1308169, -1308169,\n+            -381987, -381987, 1349076, 1349076, 1852771, 1852771, -1430430, -1430430,\n+            -3343383, -3343383, 264944, 264944, 508951, 508951, 3097992, 3097992,\n+            44288, 44288, -1100098, -1100098, 904516, 904516, 3958618, 3958618,\n+            -3724342, -3724342, -8578, -8578, 1653064, 1653064, -3249728, -3249728,\n+            2389356, 2389356, -210977, -210977, 759969, 759969, -1316856, -1316856,\n+            189548, 189548, -3553272, -3553272, 3159746, 3159746, -1851402, -1851402,\n+            -2409325, -2409325, -177440, -177440, 1315589, 1315589, 1341330, 1341330,\n+            1285669, 1285669, -1584928, -1584928, -812732, -812732, -1439742, -1439742,\n+            -3019102, -3019102, -3881060, -3881060, -3628969, -3628969, 3839961, 3839961,\n+\n+            2091667, 3407706, 2316500, 3817976, -3342478, 2244091, -2446433, -3562462,\n+            266997, 2434439, -1235728, 3513181, -3520352, -3759364, -1197226, -3193378,\n+            900702, 1859098, 909542, 819034, 495491, -1613174, -43260, -522500,\n+            -655327, -3122442, 2031748, 3207046, -3556995, -525098, -768622, -3595838,\n+            342297, 286988, -2437823, 4108315, 3437287, -3342277, 1735879, 203044,\n+            2842341, 2691481, -2590150, 1265009, 4055324, 1247620, 2486353, 1595974,\n+            -3767016, 1250494, 2635921, -3548272, -2994039, 1869119, 1903435, -1050970,\n+            -1333058, 1237275, -3318210, -1430225, -451100, 1312455, 3306115, -1962642,\n+            -1279661, 1917081, -2546312, -1374803, 1500165, 777191, 2235880, 3406031,\n+            -542412, -2831860, -1671176, -1846953, -2584293, -3724270, 594136, -3776993,\n+            -2013608, 2432395, 2454455, -164721, 1957272, 3369112, 185531, -1207385,\n+            -3183426, 162844, 1616392, 3014001, 810149, 1652634, -3694233, -1799107,\n+            -3038916, 3523897, 3866901, 269760, 2213111, -975884, 1717735, 472078,\n+            -426683, 1723600, -1803090, 1910376, -1667432, -1104333, -260646, -3833893,\n+            -2939036, -2235985, -420899, -2286327, 183443, -976891, 1612842, -3545687,\n+            -554416, 3919660, -48306, -1362209, 3937738, 1400424, -846154, 1976782\n+    };\n+\n+    private static final int[] MONT_ZETAS_FOR_VECTOR_INVERSE_NTT = new int[]{\n+            -1976782, 846154, -1400424, -3937738, 1362209, 48306, -3919660, 554416,\n+            3545687, -1612842, 976891, -183443, 2286327, 420899, 2235985, 2939036,\n+            3833893, 260646, 1104333, 1667432, -1910376, 1803090, -1723600, 426683,\n+            -472078, -1717735, 975884, -2213111, -269760, -3866901, -3523897, 3038916,\n+            1799107, 3694233, -1652634, -810149, -3014001, -1616392, -162844, 3183426,\n+            1207385, -185531, -3369112, -1957272, 164721, -2454455, -2432395, 2013608,\n+            3776993, -594136, 3724270, 2584293, 1846953, 1671176, 2831860, 542412,\n+            -3406031, -2235880, -777191, -1500165, 1374803, 2546312, -1917081, 1279661,\n+            1962642, -3306115, -1312455, 451100, 1430225, 3318210, -1237275, 1333058,\n+            1050970, -1903435, -1869119, 2994039, 3548272, -2635921, -1250494, 3767016,\n+            -1595974, -2486353, -1247620, -4055324, -1265009, 2590150, -2691481, -2842341,\n+            -203044, -1735879, 3342277, -3437287, -4108315, 2437823, -286988, -342297,\n+            3595838, 768622, 525098, 3556995, -3207046, -2031748, 3122442, 655327,\n+            522500, 43260, 1613174, -495491, -819034, -909542, -1859098, -900702,\n+            3193378, 1197226, 3759364, 3520352, -3513181, 1235728, -2434439, -266997,\n+            3562462, 2446433, -2244091, 3342478, -3817976, -2316500, -3407706, -2091667,\n+\n+            -3839961, -3839961, 3628969, 3628969, 3881060, 3881060, 3019102, 3019102,\n+            1439742, 1439742, 812732, 812732, 1584928, 1584928, -1285669, -1285669,\n+            -1341330, - 1341330, -1315589, -1315589, 177440, 177440, 2409325, 2409325,\n+            1851402, 1851402, -3159746, -3159746, 3553272, 3553272, -189548, -189548,\n+            1316856, 1316856, -759969, -759969, 210977, 210977, -2389356, -2389356,\n+            3249728, 3249728, -1653064, -1653064, 8578, 8578, 3724342, 3724342,\n+            -3958618, -3958618, -904516, -904516, 1100098, 1100098, -44288, -44288,\n+            -3097992, -3097992, -508951, -508951, -264944, -264944, 3343383, 3343383,\n+            1430430, 1430430, -1852771, -1852771, -1349076, -1349076, 381987, 381987,\n+            1308169, 1308169, 22981, 22981, 1228525, 1228525, 671102, 671102,\n+            2477047, 2477047, 411027, 411027, 3693493, 3693493, 2967645, 2967645,\n+            -2715295, -2715295, -2147896, -2147896, 983419, 983419, -3412210, -3412210,\n+            -126922, -126922, 3632928, 3632928, 3157330, 3157330, 3190144, 3190144,\n+            1000202, 1000202, 4083598, 4083598, -1939314, -1939314, 1257611, 1257611,\n+            1585221, 1585221, -2176455, -2176455, -3475950, -3475950, 1452451, 1452451,\n+            3041255, 3041255, 3677745, 3677745, 1528703, 1528703, 3930395, 3930395,\n+\n+            2797779, 2797779, 2797779, 2797779, -2071892, -2071892, -2071892, -2071892,\n+            2556880, 2556880, 2556880, 2556880, -3900724, -3900724, -3900724, -3900724,\n+            -3881043, -3881043, -3881043, -3881043, -954230, -954230, -954230, -954230,\n+            -531354, -531354, -531354, -531354, -811944, -811944, -811944, -811944,\n+            -3699596, -3699596, -3699596, -3699596, 1600420, 1600420, 1600420, 1600420,\n+            2140649, 2140649, 2140649, 2140649, -3507263, -3507263, -3507263, -3507263,\n+            3821735, 3821735, 3821735, 3821735, -3505694, -3505694, -3505694, -3505694,\n+            1643818, 1643818, 1643818, 1643818, 1699267, 1699267, 1699267, 1699267,\n+            539299, 539299, 539299, 539299, -2348700, -2348700, -2348700, -2348700,\n+            300467, 300467, 300467, 300467, -3539968, -3539968, -3539968, -3539968,\n+            2867647, 2867647, 2867647, 2867647, -3574422, -3574422, -3574422, -3574422,\n+            3043716, 3043716, 3043716, 3043716, 3861115, 3861115, 3861115, 3861115,\n+            -3915439, -3915439, -3915439, -3915439, 2537516, 2537516, 2537516, 2537516,\n+            3592148, 3592148, 3592148, 3592148, 1661693, 1661693, 1661693, 1661693,\n+            -3530437, -3530437, -3530437, -3530437, -3077325, -3077325, -3077325, -3077325,\n+            -95776, -95776, -95776, -95776, -2706023, -2706023, -2706023, -2706023,\n+\n+            -280005, -280005, -280005, -280005, -280005, -280005, -280005, -280005,\n+            -4010497, -4010497, -4010497, -4010497, -4010497, -4010497, -4010497, -4010497,\n+            19422, 19422, 19422, 19422, 19422, 19422, 19422, 19422,\n+            -1757237, -1757237, -1757237, -1757237, -1757237, -1757237, -1757237, -1757237,\n+            3277672, 3277672, 3277672, 3277672, 3277672, 3277672, 3277672, 3277672,\n+            1399561, 1399561, 1399561, 1399561, 1399561, 1399561, 1399561, 1399561,\n+            3859737, 3859737, 3859737, 3859737, 3859737, 3859737, 3859737, 3859737,\n+            2118186, 2118186, 2118186, 2118186, 2118186, 2118186, 2118186, 2118186,\n+            2108549, 2108549, 2108549, 2108549, 2108549, 2108549, 2108549, 2108549,\n+            -2619752, -2619752, -2619752, -2619752, -2619752, -2619752, -2619752, -2619752,\n+            1119584, 1119584, 1119584, 1119584, 1119584, 1119584, 1119584, 1119584,\n+            549488, 549488, 549488, 549488, 549488, 549488, 549488, 549488,\n+            -3585928, -3585928, -3585928, -3585928, -3585928, -3585928, -3585928, -3585928,\n+            1079900, 1079900, 1079900, 1079900, 1079900, 1079900, 1079900, 1079900,\n+            -1024112, -1024112, -1024112, -1024112, -1024112, -1024112, -1024112, -1024112,\n+            -2725464, -2725464, -2725464, -2725464, -2725464, -2725464, -2725464, -2725464,\n+\n+            -2680103, -2680103, -2680103, -2680103, -2680103, -2680103, -2680103, -2680103,\n+            -2680103, -2680103, -2680103, -2680103, -2680103, -2680103, -2680103, -2680103,\n+            -3111497, -3111497, -3111497, -3111497, -3111497, -3111497, -3111497, -3111497,\n+            -3111497, -3111497, -3111497, -3111497, -3111497, -3111497, -3111497, -3111497,\n+            2884855, 2884855, 2884855, 2884855, 2884855, 2884855, 2884855, 2884855,\n+            2884855, 2884855, 2884855, 2884855, 2884855, 2884855, 2884855, 2884855,\n+            -3119733, -3119733, -3119733, -3119733, -3119733, -3119733, -3119733, -3119733,\n+            -3119733, -3119733, -3119733, -3119733, -3119733, -3119733, -3119733, -3119733,\n+            2091905, 2091905, 2091905, 2091905, 2091905, 2091905, 2091905, 2091905,\n+            2091905, 2091905, 2091905, 2091905, 2091905, 2091905, 2091905, 2091905,\n+            359251, 359251, 359251, 359251, 359251, 359251, 359251, 359251,\n+            359251, 359251, 359251, 359251, 359251, 359251, 359251, 359251,\n+            -2353451, -2353451, -2353451, -2353451, -2353451, -2353451, -2353451, -2353451,\n+            -2353451, -2353451, -2353451, -2353451, -2353451, -2353451, -2353451, -2353451,\n+            -1826347, -1826347, -1826347, -1826347, -1826347, -1826347, -1826347, -1826347,\n+            -1826347, -1826347, -1826347, -1826347, -1826347, -1826347, -1826347, -1826347,\n+\n+            -466468, -466468, -466468, -466468, -466468, -466468, -466468, -466468,\n+            -466468, -466468, -466468, -466468, -466468, -466468, -466468, -466468,\n+            -466468, -466468, -466468, -466468, -466468, -466468, -466468, -466468,\n+            -466468, -466468, -466468, -466468, -466468, -466468, -466468, -466468,\n+            876248, 876248, 876248, 876248, 876248, 876248, 876248, 876248,\n+            876248, 876248, 876248, 876248, 876248, 876248, 876248, 876248,\n+            876248, 876248, 876248, 876248, 876248, 876248, 876248, 876248,\n+            876248, 876248, 876248, 876248, 876248, 876248, 876248, 876248,\n+            777960, 777960, 777960, 777960, 777960, 777960, 777960, 777960,\n+            777960, 777960, 777960, 777960, 777960, 777960, 777960, 777960,\n+            777960, 777960, 777960, 777960, 777960, 777960, 777960, 777960,\n+            777960, 777960, 777960, 777960, 777960, 777960, 777960, 777960,\n+            -237124, -237124, -237124, -237124, -237124, -237124, -237124, -237124,\n+            -237124, -237124, -237124, -237124, -237124, -237124, -237124, -237124,\n+            -237124, -237124, -237124, -237124, -237124, -237124, -237124, -237124,\n+            -237124, -237124, -237124, -237124, -237124, -237124, -237124, -237124,\n+\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            518909, 518909, 518909, 518909, 518909, 518909, 518909, 518909,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+            2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894, 2608894,\n+\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847,\n+            -25847, -25847, -25847, -25847, -25847, -25847, -25847, -25847\n@@ -851,5 +1095,1 @@\n-    int[][][] generateA(byte[] seed) {\n-        int blockSize = 168;  \/\/ the size of one block of SHAKE128 output\n-        var xof = new SHAKE128(0);\n-        byte[] xofSeed = new byte[A_SEED_LEN + 2];\n-        System.arraycopy(seed, 0, xofSeed, 0, A_SEED_LEN);\n+    private int[][][] generateA(byte[] seed) {\n@@ -858,25 +1098,68 @@\n-        for (int i = 0; i < mlDsa_k; i++) {\n-            for (int j = 0; j < mlDsa_l; j++) {\n-                xofSeed[A_SEED_LEN] = (byte) j;\n-                xofSeed[A_SEED_LEN + 1] = (byte) i;\n-                xof.reset();\n-                xof.update(xofSeed);\n-\n-                byte[] rawAij = new byte[blockSize];\n-                int[] aij = new int[ML_DSA_N];\n-                int ofs = 0;\n-                int rawOfs = blockSize;\n-                int tmp;\n-                while (ofs < ML_DSA_N) {\n-                    if (rawOfs == blockSize) {\n-                        \/\/ works because 3 divides blockSize (=168)\n-                        xof.squeeze(rawAij, 0, blockSize);\n-                        rawOfs = 0;\n-                    }\n-                    tmp = (rawAij[rawOfs] & 0xFF) +\n-                            ((rawAij[rawOfs + 1] & 0xFF) << 8) +\n-                            ((rawAij[rawOfs + 2] & 0x7F) << 16);\n-                    rawOfs += 3;\n-                    if (tmp < ML_DSA_Q) {\n-                        aij[ofs] = tmp;\n-                        ofs++;\n+        int nrPar = 2;\n+        int rhoLen = seed.length;\n+        byte[] seedBuf = new byte[SHAKE128_BLOCK_SIZE];\n+        System.arraycopy(seed, 0, seedBuf, 0, seed.length);\n+        seedBuf[rhoLen + 2] = 0x1F;\n+        seedBuf[SHAKE128_BLOCK_SIZE - 1] = (byte)0x80;\n+        byte[][] xofBufArr = new byte[nrPar][SHAKE128_BLOCK_SIZE];\n+        int[] iIndex = new int[nrPar];\n+        int[] jIndex = new int[nrPar];\n+\n+        int[] parsedBuf = new int[SHAKE128_BLOCK_SIZE \/ 3];\n+\n+        int parInd = 0;\n+        boolean allDone;\n+        int[] ofs = new int[nrPar];\n+        Arrays.fill(ofs, 0);\n+        int[][] aij = new int[nrPar][];\n+        try {\n+            Shake128Parallel parXof = new Shake128Parallel(xofBufArr);\n+\n+            for (int i = 0; i < mlDsa_k; i++) {\n+                for (int j = 0; j < mlDsa_l; j++) {\n+                    xofBufArr[parInd] = seedBuf.clone();\n+                    xofBufArr[parInd][rhoLen] = (byte) j;\n+                    xofBufArr[parInd][rhoLen + 1] = (byte) i;\n+                    iIndex[parInd] = i;\n+                    jIndex[parInd] = j;\n+                    ofs[parInd] = 0;\n+                    aij[parInd] = new int[ML_DSA_N];\n+                    parInd++;\n+\n+                    if ((parInd == nrPar) ||\n+                            ((i == mlDsa_k - 1) && (j == mlDsa_l - 1))) {\n+                        parXof.reset(xofBufArr);\n+\n+                        allDone = false;\n+                        while (!allDone) {\n+                            allDone = true;\n+                            parXof.squeezeBlock();\n+                            for (int k = 0; k < parInd; k++) {\n+                                int parsedOfs = 0;\n+                                int tmp;\n+                                if (ofs[k] < ML_DSA_N) {\n+                                    for (int l = 0; l < SHAKE128_BLOCK_SIZE; l += 3) {\n+                                        byte[] rawBuf = xofBufArr[k];\n+                                        parsedBuf[l \/ 3] = (rawBuf[l] & 0xFF) +\n+                                                ((rawBuf[l + 1] & 0xFF) << 8) +\n+                                                ((rawBuf[l + 2] & 0x7F) << 16);\n+                                    }\n+                                }\n+                                while ((ofs[k] < ML_DSA_N) &&\n+                                        (parsedOfs < SHAKE128_BLOCK_SIZE \/ 3)) {\n+                                    tmp = parsedBuf[parsedOfs++];\n+                                    if (tmp < ML_DSA_Q) {\n+                                        aij[k][ofs[k]] = tmp;\n+                                        ofs[k]++;\n+                                    }\n+                                }\n+                                if (ofs[k] < ML_DSA_N) {\n+                                    allDone = false;\n+                                }\n+                            }\n+                        }\n+\n+                        for (int k = 0; k < parInd; k++) {\n+                            a[iIndex[k]][jIndex[k]] = aij[k];\n+                        }\n+                        parInd = 0;\n@@ -885,1 +1168,0 @@\n-                a[i][j] = aij;\n@@ -887,0 +1169,3 @@\n+        } catch (InvalidAlgorithmParameterException e) {\n+            \/\/ This should never happen since xofBufArr is of the correct size\n+            throw new RuntimeException(\"Internal error.\");\n@@ -888,0 +1173,1 @@\n+\n@@ -982,1 +1268,1 @@\n-            ML_DSA.mlDsaDecomposePoly(input[i], lowPart[i],\n+            mlDsaDecomposePoly(input[i], lowPart[i],\n@@ -1014,1 +1300,1 @@\n-        int[][] lowPart = new int[mlDsa_k][ML_DSA_N];\n+        int[][] lowPart = r;\n@@ -1033,1 +1319,12 @@\n-    public static int[] mlDsaNtt(int[] coeffs) {\n+    public static void mlDsaNtt(int[] coeffs) {\n+        implDilithiumAlmostNtt(coeffs, MONT_ZETAS_FOR_VECTOR_NTT);\n+        implDilithiumMontMulByConstant(coeffs,  MONT_R_MOD_Q);\n+    }\n+\n+    @IntrinsicCandidate\n+    static int implDilithiumAlmostNtt(int[] coeffs, int[] zetas) {\n+        implDilithiumAlmostNttJava(coeffs);\n+        return 1;\n+    }\n+\n+    static void implDilithiumAlmostNttJava(int[] coeffs) {\n@@ -1046,2 +1343,0 @@\n-        montMulByConstant(coeffs,  MONT_R_MOD_Q);\n-        return coeffs;\n@@ -1050,1 +1345,12 @@\n-    public static int[] mlDsaInverseNtt(int[] coeffs) {\n+    public static void mlDsaInverseNtt(int[] coeffs) {\n+        implDilithiumAlmostInverseNtt(coeffs, MONT_ZETAS_FOR_VECTOR_INVERSE_NTT);\n+        implDilithiumMontMulByConstant(coeffs, MONT_DIM_INVERSE);\n+    }\n+\n+    @IntrinsicCandidate\n+    static int implDilithiumAlmostInverseNtt(int[] coeffs, int[] zetas) {\n+        implDilithiumAlmostInverseNttJava(coeffs);\n+        return 1;\n+    }\n+\n+    static void implDilithiumAlmostInverseNttJava(int[] coeffs) {\n@@ -1052,1 +1358,1 @@\n-        int m = 0;\n+        int m = MONT_ZETAS_FOR_NTT.length - 1;\n@@ -1059,1 +1365,1 @@\n-                            MONT_ZETAS_FOR_INVERSE_NTT[m]);\n+                            -MONT_ZETAS_FOR_NTT[m]);\n@@ -1061,1 +1367,1 @@\n-                m++;\n+                m--;\n@@ -1064,2 +1370,0 @@\n-        montMulByConstant(coeffs, MONT_DIM_INVERSE);\n-        return coeffs;\n@@ -1081,0 +1385,11 @@\n+        implDilithiumNttMult(product, coeffs1, coeffs2);\n+    }\n+\n+\n+    @IntrinsicCandidate\n+    static int implDilithiumNttMult(int[] product, int[] coeffs1, int[] coeffs2) {\n+        implDilithiumNttMultJava(product, coeffs1, coeffs2);\n+        return 1;\n+    }\n+\n+    static void implDilithiumNttMultJava(int[] product, int[] coeffs1, int[] coeffs2) {\n@@ -1086,1 +1401,7 @@\n-    public static void montMulByConstant(int[] coeffs, int constant) {\n+    @IntrinsicCandidate\n+    static int implDilithiumMontMulByConstant(int[] coeffs, int constant) {\n+        implDilithiumMontMulByConstantJava(coeffs, constant);\n+        return 1;\n+    }\n+\n+    static void implDilithiumMontMulByConstantJava(int[] coeffs, int constant) {\n@@ -1094,0 +1415,13 @@\n+        implDilithiumDecomposePoly(input, lowPart, highPart,twoGamma2, multiplier);\n+    }\n+\n+    @IntrinsicCandidate\n+    static int implDilithiumDecomposePoly(int[] input, int[] lowPart, int[] highPart,\n+                                          int twoGamma2, int multiplier) {\n+        decomposePolyJava(input, lowPart, highPart, twoGamma2, multiplier);\n+        return 1;\n+    }\n+\n+    static void decomposePolyJava(int[] input, int[] lowPart, int[] highPart,\n+                                 int twoGamma2, int multiplier) {\n+        int dilithiumBarrettAddend = 5373807;\n@@ -1096,5 +1430,12 @@\n-            rplus = rplus - ((rplus + 5373807) >> 23) * ML_DSA_Q;\n-            rplus = rplus + ((rplus >> 31) & ML_DSA_Q);\n-            int r0 = rplus - ((rplus * multiplier) >> 22) * twoGamma2;\n-            r0 -= (((twoGamma2 - r0) >> 22) & twoGamma2);\n-            r0 -= (((twoGamma2 \/ 2 - r0) >> 31) & twoGamma2);\n+            rplus -= ((rplus + dilithiumBarrettAddend) >> 23) * ML_DSA_Q;\n+            rplus += ((rplus >> 31) & ML_DSA_Q);\n+\n+            int quotient = (rplus * multiplier) >> 22;\n+            int r0 = rplus - quotient * twoGamma2;\n+            int mask = (twoGamma2 - r0) >> 22;\n+            r0 -= (mask & twoGamma2);\n+            quotient += (mask & 1);\n+            mask = (twoGamma2 \/ 2 - r0) >> 31;\n+            r0 -= (mask & twoGamma2);\n+            quotient += (mask & 1);\n+\n@@ -1102,1 +1443,1 @@\n-            r1 = (r1 | (-r1)) >> 31;\n+            r1 = (r1 | (-r1)) >> 31; \/\/ 0 if rplus - r0 == (dilithium_q - 1), -1 otherwise\n@@ -1104,1 +1445,3 @@\n-            r1 = r1 & ((rplus - r0) \/ twoGamma2);\n+            \/\/ quotient = (rplus - r0) \/ twoGamma2;\n+            r1 = r1 & quotient;\n+\n@@ -1210,0 +1553,1 @@\n+    \/\/ see e.g. Algorithm 3 in https:\/\/eprint.iacr.org\/2018\/039.pdf\n","filename":"src\/java.base\/share\/classes\/sun\/security\/provider\/ML_DSA.java","additions":429,"deletions":85,"binary":false,"changes":514,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,14 @@\n+\/*\n+ * This class is for making it possible that NRPAR (= 2) (rather restricted)\n+ * SHAKE computations execute in parallel.\n+ * The restrictions are:\n+ *  1. The messages processed should be such that the absorb phase should\n+ * execute a single keccak() call and the byte arrays passed to the constructor\n+ * (or reset() method) of this class should be the message padded with the\n+ * appropriate padding described in\n+ * https:\/\/nvlpubs.nist.gov\/nistpubs\/fips\/nist.fips.202.pdf.\n+ *  2. The only available way for extracting data is the squeeze() method\n+ * that extracts exactly 1 block of data of each computation, delivering it\n+ * in the arrays that were passed to the class in the constructor (or the\n+ * reset() call).\n+ *\/\n","filename":"src\/java.base\/share\/classes\/sun\/security\/provider\/SHA3Parallel.java","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1836,0 +1836,5 @@\n+          [\"sqdmulh\", \"sqdmulh\", \"4H\"], [\"sqdmulh\", \"sqdmulh\", \"8H\"],\n+          [\"sqdmulh\", \"sqdmulh\", \"2S\"], [\"sqdmulh\", \"sqdmulh\", \"4S\"],\n+          [\"shsubv\", \"shsub\", \"8B\"], [\"shsubv\", \"shsub\", \"16B\"],\n+          [\"shsubv\", \"shsub\", \"4H\"], [\"shsubv\", \"shsub\", \"8H\"],\n+          [\"shsubv\", \"shsub\", \"2S\"], [\"shsubv\", \"shsub\", \"4S\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -748,6 +748,16 @@\n-    __ fmin(v24, __ T2S, v25, v26);                    \/\/       fmin    v24.2S, v25.2S, v26.2S\n-    __ fmin(v26, __ T4S, v27, v28);                    \/\/       fmin    v26.4S, v27.4S, v28.4S\n-    __ fmin(v16, __ T2D, v17, v18);                    \/\/       fmin    v16.2D, v17.2D, v18.2D\n-    __ facgt(v30, __ T2S, v31, v0);                    \/\/       facgt   v30.2S, v31.2S, v0.2S\n-    __ facgt(v3, __ T4S, v4, v5);                      \/\/       facgt   v3.4S, v4.4S, v5.4S\n-    __ facgt(v10, __ T2D, v11, v12);                   \/\/       facgt   v10.2D, v11.2D, v12.2D\n+    __ sqdmulh(v24, __ T4H, v25, v26);                 \/\/       sqdmulh v24.4H, v25.4H, v26.4H\n+    __ sqdmulh(v26, __ T8H, v27, v28);                 \/\/       sqdmulh v26.8H, v27.8H, v28.8H\n+    __ sqdmulh(v16, __ T2S, v17, v18);                 \/\/       sqdmulh v16.2S, v17.2S, v18.2S\n+    __ sqdmulh(v30, __ T4S, v31, v0);                  \/\/       sqdmulh v30.4S, v31.4S, v0.4S\n+    __ shsubv(v3, __ T8B, v4, v5);                     \/\/       shsub   v3.8B, v4.8B, v5.8B\n+    __ shsubv(v10, __ T16B, v11, v12);                 \/\/       shsub   v10.16B, v11.16B, v12.16B\n+    __ shsubv(v23, __ T4H, v24, v25);                  \/\/       shsub   v23.4H, v24.4H, v25.4H\n+    __ shsubv(v10, __ T8H, v11, v12);                  \/\/       shsub   v10.8H, v11.8H, v12.8H\n+    __ shsubv(v4, __ T2S, v5, v6);                     \/\/       shsub   v4.2S, v5.2S, v6.2S\n+    __ shsubv(v18, __ T4S, v19, v20);                  \/\/       shsub   v18.4S, v19.4S, v20.4S\n+    __ fmin(v2, __ T2S, v3, v4);                       \/\/       fmin    v2.2S, v3.2S, v4.2S\n+    __ fmin(v11, __ T4S, v12, v13);                    \/\/       fmin    v11.4S, v12.4S, v13.4S\n+    __ fmin(v8, __ T2D, v9, v10);                      \/\/       fmin    v8.2D, v9.2D, v10.2D\n+    __ facgt(v10, __ T2S, v11, v12);                   \/\/       facgt   v10.2S, v11.2S, v12.2S\n+    __ facgt(v15, __ T4S, v16, v17);                   \/\/       facgt   v15.4S, v16.4S, v17.4S\n+    __ facgt(v17, __ T2D, v18, v19);                   \/\/       facgt   v17.2D, v18.2D, v19.2D\n@@ -756,7 +766,1 @@\n-    __ fmlavs(v5, __ T2S, v6, v7, 1);                  \/\/       fmla    v5.2S, v6.2S, v7.S[1]\n-    __ mulvs(v9, __ T4S, v10, v11, 0);                 \/\/       mul     v9.4S, v10.4S, v11.S[0]\n-    __ fmlavs(v5, __ T2D, v6, v7, 0);                  \/\/       fmla    v5.2D, v6.2D, v7.D[0]\n-    __ fmlsvs(v5, __ T2S, v6, v7, 0);                  \/\/       fmls    v5.2S, v6.2S, v7.S[0]\n-    __ mulvs(v8, __ T4S, v9, v10, 1);                  \/\/       mul     v8.4S, v9.4S, v10.S[1]\n-    __ fmlsvs(v5, __ T2D, v6, v7, 0);                  \/\/       fmls    v5.2D, v6.2D, v7.D[0]\n-    __ fmulxvs(v6, __ T2S, v7, v8, 0);                 \/\/       fmulx   v6.2S, v7.2S, v8.S[0]\n+    __ fmlavs(v5, __ T2S, v6, v7, 0);                  \/\/       fmla    v5.2S, v6.2S, v7.S[0]\n@@ -764,4 +768,5 @@\n-    __ fmulxvs(v3, __ T2D, v4, v5, 0);                 \/\/       fmulx   v3.2D, v4.2D, v5.D[0]\n-    __ mulvs(v13, __ T4H, v14, v15, 2);                \/\/       mul     v13.4H, v14.4H, v15.H[2]\n-    __ mulvs(v2, __ T8H, v3, v4, 4);                   \/\/       mul     v2.8H, v3.8H, v4.H[4]\n-    __ mulvs(v2, __ T2S, v3, v4, 0);                   \/\/       mul     v2.2S, v3.2S, v4.S[0]\n+    __ fmlavs(v6, __ T2D, v7, v8, 0);                  \/\/       fmla    v6.2D, v7.2D, v8.D[0]\n+    __ fmlsvs(v3, __ T2S, v4, v5, 0);                  \/\/       fmls    v3.2S, v4.2S, v5.S[0]\n+    __ mulvs(v13, __ T4S, v14, v15, 2);                \/\/       mul     v13.4S, v14.4S, v15.S[2]\n+    __ fmlsvs(v2, __ T2D, v3, v4, 1);                  \/\/       fmls    v2.2D, v3.2D, v4.D[1]\n+    __ fmulxvs(v2, __ T2S, v3, v4, 0);                 \/\/       fmulx   v2.2S, v3.2S, v4.S[0]\n@@ -769,0 +774,5 @@\n+    __ fmulxvs(v8, __ T2D, v9, v10, 1);                \/\/       fmulx   v8.2D, v9.2D, v10.D[1]\n+    __ mulvs(v5, __ T4H, v6, v7, 2);                   \/\/       mul     v5.4H, v6.4H, v7.H[2]\n+    __ mulvs(v11, __ T8H, v12, v13, 5);                \/\/       mul     v11.8H, v12.8H, v13.H[5]\n+    __ mulvs(v13, __ T2S, v14, v15, 0);                \/\/       mul     v13.2S, v14.2S, v15.S[0]\n+    __ mulvs(v14, __ T4S, v15, v16, 2);                \/\/       mul     v14.4S, v15.4S, v16.S[2]\n@@ -771,44 +781,44 @@\n-    __ cm(Assembler::GT, v21, __ T8B, v22, v23);       \/\/       cmgt    v21.8B, v22.8B, v23.8B\n-    __ cm(Assembler::GT, v16, __ T16B, v17, v18);      \/\/       cmgt    v16.16B, v17.16B, v18.16B\n-    __ cm(Assembler::GT, v18, __ T4H, v19, v20);       \/\/       cmgt    v18.4H, v19.4H, v20.4H\n-    __ cm(Assembler::GT, v11, __ T8H, v12, v13);       \/\/       cmgt    v11.8H, v12.8H, v13.8H\n-    __ cm(Assembler::GT, v21, __ T2S, v22, v23);       \/\/       cmgt    v21.2S, v22.2S, v23.2S\n-    __ cm(Assembler::GT, v23, __ T4S, v24, v25);       \/\/       cmgt    v23.4S, v24.4S, v25.4S\n-    __ cm(Assembler::GT, v12, __ T2D, v13, v14);       \/\/       cmgt    v12.2D, v13.2D, v14.2D\n-    __ cm(Assembler::GE, v26, __ T8B, v27, v28);       \/\/       cmge    v26.8B, v27.8B, v28.8B\n-    __ cm(Assembler::GE, v23, __ T16B, v24, v25);      \/\/       cmge    v23.16B, v24.16B, v25.16B\n-    __ cm(Assembler::GE, v28, __ T4H, v29, v30);       \/\/       cmge    v28.4H, v29.4H, v30.4H\n-    __ cm(Assembler::GE, v14, __ T8H, v15, v16);       \/\/       cmge    v14.8H, v15.8H, v16.8H\n-    __ cm(Assembler::GE, v11, __ T2S, v12, v13);       \/\/       cmge    v11.2S, v12.2S, v13.2S\n-    __ cm(Assembler::GE, v24, __ T4S, v25, v26);       \/\/       cmge    v24.4S, v25.4S, v26.4S\n-    __ cm(Assembler::GE, v1, __ T2D, v2, v3);          \/\/       cmge    v1.2D, v2.2D, v3.2D\n-    __ cm(Assembler::EQ, v12, __ T8B, v13, v14);       \/\/       cmeq    v12.8B, v13.8B, v14.8B\n-    __ cm(Assembler::EQ, v31, __ T16B, v0, v1);        \/\/       cmeq    v31.16B, v0.16B, v1.16B\n-    __ cm(Assembler::EQ, v10, __ T4H, v11, v12);       \/\/       cmeq    v10.4H, v11.4H, v12.4H\n-    __ cm(Assembler::EQ, v16, __ T8H, v17, v18);       \/\/       cmeq    v16.8H, v17.8H, v18.8H\n-    __ cm(Assembler::EQ, v7, __ T2S, v8, v9);          \/\/       cmeq    v7.2S, v8.2S, v9.2S\n-    __ cm(Assembler::EQ, v2, __ T4S, v3, v4);          \/\/       cmeq    v2.4S, v3.4S, v4.4S\n-    __ cm(Assembler::EQ, v3, __ T2D, v4, v5);          \/\/       cmeq    v3.2D, v4.2D, v5.2D\n-    __ cm(Assembler::HI, v13, __ T8B, v14, v15);       \/\/       cmhi    v13.8B, v14.8B, v15.8B\n-    __ cm(Assembler::HI, v19, __ T16B, v20, v21);      \/\/       cmhi    v19.16B, v20.16B, v21.16B\n-    __ cm(Assembler::HI, v17, __ T4H, v18, v19);       \/\/       cmhi    v17.4H, v18.4H, v19.4H\n-    __ cm(Assembler::HI, v16, __ T8H, v17, v18);       \/\/       cmhi    v16.8H, v17.8H, v18.8H\n-    __ cm(Assembler::HI, v3, __ T2S, v4, v5);          \/\/       cmhi    v3.2S, v4.2S, v5.2S\n-    __ cm(Assembler::HI, v1, __ T4S, v2, v3);          \/\/       cmhi    v1.4S, v2.4S, v3.4S\n-    __ cm(Assembler::HI, v11, __ T2D, v12, v13);       \/\/       cmhi    v11.2D, v12.2D, v13.2D\n-    __ cm(Assembler::HS, v30, __ T8B, v31, v0);        \/\/       cmhs    v30.8B, v31.8B, v0.8B\n-    __ cm(Assembler::HS, v5, __ T16B, v6, v7);         \/\/       cmhs    v5.16B, v6.16B, v7.16B\n-    __ cm(Assembler::HS, v8, __ T4H, v9, v10);         \/\/       cmhs    v8.4H, v9.4H, v10.4H\n-    __ cm(Assembler::HS, v15, __ T8H, v16, v17);       \/\/       cmhs    v15.8H, v16.8H, v17.8H\n-    __ cm(Assembler::HS, v29, __ T2S, v30, v31);       \/\/       cmhs    v29.2S, v30.2S, v31.2S\n-    __ cm(Assembler::HS, v30, __ T4S, v31, v0);        \/\/       cmhs    v30.4S, v31.4S, v0.4S\n-    __ cm(Assembler::HS, v0, __ T2D, v1, v2);          \/\/       cmhs    v0.2D, v1.2D, v2.2D\n-    __ fcm(Assembler::EQ, v20, __ T2S, v21, v22);      \/\/       fcmeq   v20.2S, v21.2S, v22.2S\n-    __ fcm(Assembler::EQ, v7, __ T4S, v8, v9);         \/\/       fcmeq   v7.4S, v8.4S, v9.4S\n-    __ fcm(Assembler::EQ, v20, __ T2D, v21, v22);      \/\/       fcmeq   v20.2D, v21.2D, v22.2D\n-    __ fcm(Assembler::GT, v23, __ T2S, v24, v25);      \/\/       fcmgt   v23.2S, v24.2S, v25.2S\n-    __ fcm(Assembler::GT, v28, __ T4S, v29, v30);      \/\/       fcmgt   v28.4S, v29.4S, v30.4S\n-    __ fcm(Assembler::GT, v21, __ T2D, v22, v23);      \/\/       fcmgt   v21.2D, v22.2D, v23.2D\n-    __ fcm(Assembler::GE, v27, __ T2S, v28, v29);      \/\/       fcmge   v27.2S, v28.2S, v29.2S\n-    __ fcm(Assembler::GE, v25, __ T4S, v26, v27);      \/\/       fcmge   v25.4S, v26.4S, v27.4S\n-    __ fcm(Assembler::GE, v5, __ T2D, v6, v7);         \/\/       fcmge   v5.2D, v6.2D, v7.2D\n+    __ cm(Assembler::GT, v14, __ T8B, v15, v16);       \/\/       cmgt    v14.8B, v15.8B, v16.8B\n+    __ cm(Assembler::GT, v11, __ T16B, v12, v13);      \/\/       cmgt    v11.16B, v12.16B, v13.16B\n+    __ cm(Assembler::GT, v24, __ T4H, v25, v26);       \/\/       cmgt    v24.4H, v25.4H, v26.4H\n+    __ cm(Assembler::GT, v1, __ T8H, v2, v3);          \/\/       cmgt    v1.8H, v2.8H, v3.8H\n+    __ cm(Assembler::GT, v12, __ T2S, v13, v14);       \/\/       cmgt    v12.2S, v13.2S, v14.2S\n+    __ cm(Assembler::GT, v31, __ T4S, v0, v1);         \/\/       cmgt    v31.4S, v0.4S, v1.4S\n+    __ cm(Assembler::GT, v10, __ T2D, v11, v12);       \/\/       cmgt    v10.2D, v11.2D, v12.2D\n+    __ cm(Assembler::GE, v16, __ T8B, v17, v18);       \/\/       cmge    v16.8B, v17.8B, v18.8B\n+    __ cm(Assembler::GE, v7, __ T16B, v8, v9);         \/\/       cmge    v7.16B, v8.16B, v9.16B\n+    __ cm(Assembler::GE, v2, __ T4H, v3, v4);          \/\/       cmge    v2.4H, v3.4H, v4.4H\n+    __ cm(Assembler::GE, v3, __ T8H, v4, v5);          \/\/       cmge    v3.8H, v4.8H, v5.8H\n+    __ cm(Assembler::GE, v13, __ T2S, v14, v15);       \/\/       cmge    v13.2S, v14.2S, v15.2S\n+    __ cm(Assembler::GE, v19, __ T4S, v20, v21);       \/\/       cmge    v19.4S, v20.4S, v21.4S\n+    __ cm(Assembler::GE, v17, __ T2D, v18, v19);       \/\/       cmge    v17.2D, v18.2D, v19.2D\n+    __ cm(Assembler::EQ, v16, __ T8B, v17, v18);       \/\/       cmeq    v16.8B, v17.8B, v18.8B\n+    __ cm(Assembler::EQ, v3, __ T16B, v4, v5);         \/\/       cmeq    v3.16B, v4.16B, v5.16B\n+    __ cm(Assembler::EQ, v1, __ T4H, v2, v3);          \/\/       cmeq    v1.4H, v2.4H, v3.4H\n+    __ cm(Assembler::EQ, v11, __ T8H, v12, v13);       \/\/       cmeq    v11.8H, v12.8H, v13.8H\n+    __ cm(Assembler::EQ, v30, __ T2S, v31, v0);        \/\/       cmeq    v30.2S, v31.2S, v0.2S\n+    __ cm(Assembler::EQ, v5, __ T4S, v6, v7);          \/\/       cmeq    v5.4S, v6.4S, v7.4S\n+    __ cm(Assembler::EQ, v8, __ T2D, v9, v10);         \/\/       cmeq    v8.2D, v9.2D, v10.2D\n+    __ cm(Assembler::HI, v15, __ T8B, v16, v17);       \/\/       cmhi    v15.8B, v16.8B, v17.8B\n+    __ cm(Assembler::HI, v29, __ T16B, v30, v31);      \/\/       cmhi    v29.16B, v30.16B, v31.16B\n+    __ cm(Assembler::HI, v30, __ T4H, v31, v0);        \/\/       cmhi    v30.4H, v31.4H, v0.4H\n+    __ cm(Assembler::HI, v0, __ T8H, v1, v2);          \/\/       cmhi    v0.8H, v1.8H, v2.8H\n+    __ cm(Assembler::HI, v20, __ T2S, v21, v22);       \/\/       cmhi    v20.2S, v21.2S, v22.2S\n+    __ cm(Assembler::HI, v7, __ T4S, v8, v9);          \/\/       cmhi    v7.4S, v8.4S, v9.4S\n+    __ cm(Assembler::HI, v20, __ T2D, v21, v22);       \/\/       cmhi    v20.2D, v21.2D, v22.2D\n+    __ cm(Assembler::HS, v23, __ T8B, v24, v25);       \/\/       cmhs    v23.8B, v24.8B, v25.8B\n+    __ cm(Assembler::HS, v28, __ T16B, v29, v30);      \/\/       cmhs    v28.16B, v29.16B, v30.16B\n+    __ cm(Assembler::HS, v21, __ T4H, v22, v23);       \/\/       cmhs    v21.4H, v22.4H, v23.4H\n+    __ cm(Assembler::HS, v27, __ T8H, v28, v29);       \/\/       cmhs    v27.8H, v28.8H, v29.8H\n+    __ cm(Assembler::HS, v25, __ T2S, v26, v27);       \/\/       cmhs    v25.2S, v26.2S, v27.2S\n+    __ cm(Assembler::HS, v5, __ T4S, v6, v7);          \/\/       cmhs    v5.4S, v6.4S, v7.4S\n+    __ cm(Assembler::HS, v1, __ T2D, v2, v3);          \/\/       cmhs    v1.2D, v2.2D, v3.2D\n+    __ fcm(Assembler::EQ, v23, __ T2S, v24, v25);      \/\/       fcmeq   v23.2S, v24.2S, v25.2S\n+    __ fcm(Assembler::EQ, v16, __ T4S, v17, v18);      \/\/       fcmeq   v16.4S, v17.4S, v18.4S\n+    __ fcm(Assembler::EQ, v31, __ T2D, v0, v1);        \/\/       fcmeq   v31.2D, v0.2D, v1.2D\n+    __ fcm(Assembler::GT, v5, __ T2S, v6, v7);         \/\/       fcmgt   v5.2S, v6.2S, v7.2S\n+    __ fcm(Assembler::GT, v12, __ T4S, v13, v14);      \/\/       fcmgt   v12.4S, v13.4S, v14.4S\n+    __ fcm(Assembler::GT, v9, __ T2D, v10, v11);       \/\/       fcmgt   v9.2D, v10.2D, v11.2D\n+    __ fcm(Assembler::GE, v28, __ T2S, v29, v30);      \/\/       fcmge   v28.2S, v29.2S, v30.2S\n+    __ fcm(Assembler::GE, v15, __ T4S, v16, v17);      \/\/       fcmge   v15.4S, v16.4S, v17.4S\n+    __ fcm(Assembler::GE, v29, __ T2D, v30, v31);      \/\/       fcmge   v29.2D, v30.2D, v31.2D\n@@ -817,6 +827,6 @@\n-    __ sve_fcm(Assembler::EQ, p0, __ D, p7, z23, 0.0); \/\/       fcmeq   p0.d, p7\/z, z23.d, #0.0\n-    __ sve_fcm(Assembler::GT, p2, __ S, p7, z12, 0.0); \/\/       fcmgt   p2.s, p7\/z, z12.s, #0.0\n-    __ sve_fcm(Assembler::GE, p7, __ D, p7, z29, 0.0); \/\/       fcmge   p7.d, p7\/z, z29.d, #0.0\n-    __ sve_fcm(Assembler::LT, p9, __ S, p3, z31, 0.0); \/\/       fcmlt   p9.s, p3\/z, z31.s, #0.0\n-    __ sve_fcm(Assembler::LE, p9, __ D, p6, z31, 0.0); \/\/       fcmle   p9.d, p6\/z, z31.d, #0.0\n-    __ sve_fcm(Assembler::NE, p10, __ S, p2, z16, 0.0); \/\/      fcmne   p10.s, p2\/z, z16.s, #0.0\n+    __ sve_fcm(Assembler::EQ, p11, __ D, p7, z31, 0.0); \/\/      fcmeq   p11.d, p7\/z, z31.d, #0.0\n+    __ sve_fcm(Assembler::GT, p2, __ D, p7, z14, 0.0); \/\/       fcmgt   p2.d, p7\/z, z14.d, #0.0\n+    __ sve_fcm(Assembler::GE, p9, __ D, p4, z27, 0.0); \/\/       fcmge   p9.d, p4\/z, z27.d, #0.0\n+    __ sve_fcm(Assembler::LT, p6, __ S, p1, z11, 0.0); \/\/       fcmlt   p6.s, p1\/z, z11.s, #0.0\n+    __ sve_fcm(Assembler::LE, p15, __ D, p7, z17, 0.0); \/\/      fcmle   p15.d, p7\/z, z17.d, #0.0\n+    __ sve_fcm(Assembler::NE, p15, __ S, p5, z7, 0.0); \/\/       fcmne   p15.s, p5\/z, z7.s, #0.0\n@@ -825,10 +835,10 @@\n-    __ sve_cmp(Assembler::EQ, p4, __ D, p4, z6, 11);   \/\/       cmpeq   p4.d, p4\/z, z6.d, #11\n-    __ sve_cmp(Assembler::GT, p14, __ B, p2, z30, 4);  \/\/       cmpgt   p14.b, p2\/z, z30.b, #4\n-    __ sve_cmp(Assembler::GE, p5, __ D, p4, z4, 1);    \/\/       cmpge   p5.d, p4\/z, z4.d, #1\n-    __ sve_cmp(Assembler::LT, p11, __ D, p3, z3, 6);   \/\/       cmplt   p11.d, p3\/z, z3.d, #6\n-    __ sve_cmp(Assembler::LE, p9, __ S, p0, z19, -1);  \/\/       cmple   p9.s, p0\/z, z19.s, #-1\n-    __ sve_cmp(Assembler::NE, p3, __ S, p2, z12, -3);  \/\/       cmpne   p3.s, p2\/z, z12.s, #-3\n-    __ sve_cmp(Assembler::HS, p11, __ D, p4, z1, 20);  \/\/       cmphs   p11.d, p4\/z, z1.d, #20\n-    __ sve_cmp(Assembler::HI, p8, __ S, p5, z2, 53);   \/\/       cmphi   p8.s, p5\/z, z2.s, #53\n-    __ sve_cmp(Assembler::LS, p5, __ D, p6, z21, 49);  \/\/       cmpls   p5.d, p6\/z, z21.d, #49\n-    __ sve_cmp(Assembler::LO, p13, __ B, p7, z3, 97);  \/\/       cmplo   p13.b, p7\/z, z3.b, #97\n+    __ sve_cmp(Assembler::EQ, p5, __ D, p4, z4, 1);    \/\/       cmpeq   p5.d, p4\/z, z4.d, #1\n+    __ sve_cmp(Assembler::GT, p11, __ D, p3, z3, 6);   \/\/       cmpgt   p11.d, p3\/z, z3.d, #6\n+    __ sve_cmp(Assembler::GE, p9, __ S, p0, z19, -1);  \/\/       cmpge   p9.s, p0\/z, z19.s, #-1\n+    __ sve_cmp(Assembler::LT, p3, __ S, p2, z12, -3);  \/\/       cmplt   p3.s, p2\/z, z12.s, #-3\n+    __ sve_cmp(Assembler::LE, p11, __ D, p4, z1, -11); \/\/       cmple   p11.d, p4\/z, z1.d, #-11\n+    __ sve_cmp(Assembler::NE, p8, __ S, p5, z2, -3);   \/\/       cmpne   p8.s, p5\/z, z2.s, #-3\n+    __ sve_cmp(Assembler::HS, p5, __ D, p6, z21, 49);  \/\/       cmphs   p5.d, p6\/z, z21.d, #49\n+    __ sve_cmp(Assembler::HI, p13, __ B, p7, z3, 97);  \/\/       cmphi   p13.b, p7\/z, z3.b, #97\n+    __ sve_cmp(Assembler::LS, p9, __ H, p7, z17, 109); \/\/       cmpls   p9.h, p7\/z, z17.h, #109\n+    __ sve_cmp(Assembler::LO, p7, __ S, p5, z7, 127);  \/\/       cmplo   p7.s, p5\/z, z7.s, #127\n@@ -1089,9 +1099,9 @@\n-    __ swp(Assembler::xword, r19, r17, r9);            \/\/       swp     x19, x17, [x9]\n-    __ ldadd(Assembler::xword, r28, r27, r15);         \/\/       ldadd   x28, x27, [x15]\n-    __ ldbic(Assembler::xword, r7, r21, r23);          \/\/       ldclr   x7, x21, [x23]\n-    __ ldeor(Assembler::xword, zr, r25, r2);           \/\/       ldeor   xzr, x25, [x2]\n-    __ ldorr(Assembler::xword, zr, r27, r15);          \/\/       ldset   xzr, x27, [x15]\n-    __ ldsmin(Assembler::xword, r10, r23, r19);        \/\/       ldsmin  x10, x23, [x19]\n-    __ ldsmax(Assembler::xword, r3, r16, r0);          \/\/       ldsmax  x3, x16, [x0]\n-    __ ldumin(Assembler::xword, r25, r26, r23);        \/\/       ldumin  x25, x26, [x23]\n-    __ ldumax(Assembler::xword, r2, r16, r12);         \/\/       ldumax  x2, x16, [x12]\n+    __ swp(Assembler::xword, r25, r2, sp);             \/\/       swp     x25, x2, [sp]\n+    __ ldadd(Assembler::xword, r27, r16, r10);         \/\/       ldadd   x27, x16, [x10]\n+    __ ldbic(Assembler::xword, r23, r19, r3);          \/\/       ldclr   x23, x19, [x3]\n+    __ ldeor(Assembler::xword, r16, r0, r25);          \/\/       ldeor   x16, x0, [x25]\n+    __ ldorr(Assembler::xword, r26, r23, r2);          \/\/       ldset   x26, x23, [x2]\n+    __ ldsmin(Assembler::xword, r16, r12, r4);         \/\/       ldsmin  x16, x12, [x4]\n+    __ ldsmax(Assembler::xword, r28, r30, r29);        \/\/       ldsmax  x28, x30, [x29]\n+    __ ldumin(Assembler::xword, r16, r27, r6);         \/\/       ldumin  x16, x27, [x6]\n+    __ ldumax(Assembler::xword, r9, r29, r15);         \/\/       ldumax  x9, x29, [x15]\n@@ -1100,9 +1110,9 @@\n-    __ swpa(Assembler::xword, r4, r28, r30);           \/\/       swpa    x4, x28, [x30]\n-    __ ldadda(Assembler::xword, r29, r16, r27);        \/\/       ldadda  x29, x16, [x27]\n-    __ ldbica(Assembler::xword, r6, r9, r29);          \/\/       ldclra  x6, x9, [x29]\n-    __ ldeora(Assembler::xword, r16, r7, r4);          \/\/       ldeora  x16, x7, [x4]\n-    __ ldorra(Assembler::xword, r7, r15, r9);          \/\/       ldseta  x7, x15, [x9]\n-    __ ldsmina(Assembler::xword, r23, r8, r2);         \/\/       ldsmina x23, x8, [x2]\n-    __ ldsmaxa(Assembler::xword, r28, r21, sp);        \/\/       ldsmaxa x28, x21, [sp]\n-    __ ldumina(Assembler::xword, r5, r27, r0);         \/\/       ldumina x5, x27, [x0]\n-    __ ldumaxa(Assembler::xword, r17, r15, r4);        \/\/       ldumaxa x17, x15, [x4]\n+    __ swpa(Assembler::xword, r7, r4, r7);             \/\/       swpa    x7, x4, [x7]\n+    __ ldadda(Assembler::xword, r15, r9, r23);         \/\/       ldadda  x15, x9, [x23]\n+    __ ldbica(Assembler::xword, r8, r2, r28);          \/\/       ldclra  x8, x2, [x28]\n+    __ ldeora(Assembler::xword, r21, zr, r5);          \/\/       ldeora  x21, xzr, [x5]\n+    __ ldorra(Assembler::xword, r27, r0, r17);         \/\/       ldseta  x27, x0, [x17]\n+    __ ldsmina(Assembler::xword, r15, r4, r26);        \/\/       ldsmina x15, x4, [x26]\n+    __ ldsmaxa(Assembler::xword, r8, r28, r22);        \/\/       ldsmaxa x8, x28, [x22]\n+    __ ldumina(Assembler::xword, r27, r27, r25);       \/\/       ldumina x27, x27, [x25]\n+    __ ldumaxa(Assembler::xword, r23, r0, r4);         \/\/       ldumaxa x23, x0, [x4]\n@@ -1111,9 +1121,9 @@\n-    __ swpal(Assembler::xword, r26, r8, r28);          \/\/       swpal   x26, x8, [x28]\n-    __ ldaddal(Assembler::xword, r22, r27, r27);       \/\/       ldaddal x22, x27, [x27]\n-    __ ldbical(Assembler::xword, r25, r23, r0);        \/\/       ldclral x25, x23, [x0]\n-    __ ldeoral(Assembler::xword, r4, r6, r15);         \/\/       ldeoral x4, x6, [x15]\n-    __ ldorral(Assembler::xword, r0, r4, r15);         \/\/       ldsetal x0, x4, [x15]\n-    __ ldsminal(Assembler::xword, r1, r10, r7);        \/\/       ldsminal        x1, x10, [x7]\n-    __ ldsmaxal(Assembler::xword, r5, r10, r28);       \/\/       ldsmaxal        x5, x10, [x28]\n-    __ lduminal(Assembler::xword, r7, r20, r23);       \/\/       lduminal        x7, x20, [x23]\n-    __ ldumaxal(Assembler::xword, r21, r6, r11);       \/\/       ldumaxal        x21, x6, [x11]\n+    __ swpal(Assembler::xword, r6, r16, r0);           \/\/       swpal   x6, x16, [x0]\n+    __ ldaddal(Assembler::xword, r4, r15, r1);         \/\/       ldaddal x4, x15, [x1]\n+    __ ldbical(Assembler::xword, r10, r7, r5);         \/\/       ldclral x10, x7, [x5]\n+    __ ldeoral(Assembler::xword, r10, r28, r7);        \/\/       ldeoral x10, x28, [x7]\n+    __ ldorral(Assembler::xword, r20, r23, r21);       \/\/       ldsetal x20, x23, [x21]\n+    __ ldsminal(Assembler::xword, r6, r11, r8);        \/\/       ldsminal        x6, x11, [x8]\n+    __ ldsmaxal(Assembler::xword, r17, zr, r6);        \/\/       ldsmaxal        x17, xzr, [x6]\n+    __ lduminal(Assembler::xword, r17, r2, r12);       \/\/       lduminal        x17, x2, [x12]\n+    __ ldumaxal(Assembler::xword, r30, r29, r3);       \/\/       ldumaxal        x30, x29, [x3]\n@@ -1122,9 +1132,9 @@\n-    __ swpl(Assembler::xword, r8, r17, sp);            \/\/       swpl    x8, x17, [sp]\n-    __ ldaddl(Assembler::xword, r6, r17, r2);          \/\/       ldaddl  x6, x17, [x2]\n-    __ ldbicl(Assembler::xword, r12, r30, r29);        \/\/       ldclrl  x12, x30, [x29]\n-    __ ldeorl(Assembler::xword, r3, r27, r22);         \/\/       ldeorl  x3, x27, [x22]\n-    __ ldorrl(Assembler::xword, r29, r14, r13);        \/\/       ldsetl  x29, x14, [x13]\n-    __ ldsminl(Assembler::xword, r28, r17, r24);       \/\/       ldsminl x28, x17, [x24]\n-    __ ldsmaxl(Assembler::xword, r5, r2, r14);         \/\/       ldsmaxl x5, x2, [x14]\n-    __ lduminl(Assembler::xword, r10, r16, r11);       \/\/       lduminl x10, x16, [x11]\n-    __ ldumaxl(Assembler::xword, r27, r23, r12);       \/\/       ldumaxl x27, x23, [x12]\n+    __ swpl(Assembler::xword, r27, r22, r29);          \/\/       swpl    x27, x22, [x29]\n+    __ ldaddl(Assembler::xword, r14, r13, r28);        \/\/       ldaddl  x14, x13, [x28]\n+    __ ldbicl(Assembler::xword, r17, r24, r5);         \/\/       ldclrl  x17, x24, [x5]\n+    __ ldeorl(Assembler::xword, r2, r14, r10);         \/\/       ldeorl  x2, x14, [x10]\n+    __ ldorrl(Assembler::xword, r16, r11, r27);        \/\/       ldsetl  x16, x11, [x27]\n+    __ ldsminl(Assembler::xword, r23, r12, r4);        \/\/       ldsminl x23, x12, [x4]\n+    __ ldsmaxl(Assembler::xword, r22, r17, r4);        \/\/       ldsmaxl x22, x17, [x4]\n+    __ lduminl(Assembler::xword, r1, r19, r16);        \/\/       lduminl x1, x19, [x16]\n+    __ ldumaxl(Assembler::xword, r16, r13, r14);       \/\/       ldumaxl x16, x13, [x14]\n@@ -1133,9 +1143,9 @@\n-    __ swp(Assembler::word, r4, r22, r17);             \/\/       swp     w4, w22, [x17]\n-    __ ldadd(Assembler::word, r4, r1, r19);            \/\/       ldadd   w4, w1, [x19]\n-    __ ldbic(Assembler::word, r16, r16, r13);          \/\/       ldclr   w16, w16, [x13]\n-    __ ldeor(Assembler::word, r14, r12, r2);           \/\/       ldeor   w14, w12, [x2]\n-    __ ldorr(Assembler::word, r17, r3, r21);           \/\/       ldset   w17, w3, [x21]\n-    __ ldsmin(Assembler::word, r23, r5, r6);           \/\/       ldsmin  w23, w5, [x6]\n-    __ ldsmax(Assembler::word, r7, r19, r13);          \/\/       ldsmax  w7, w19, [x13]\n-    __ ldumin(Assembler::word, r28, r17, r16);         \/\/       ldumin  w28, w17, [x16]\n-    __ ldumax(Assembler::word, r6, r2, r29);           \/\/       ldumax  w6, w2, [x29]\n+    __ swp(Assembler::word, r12, r2, r17);             \/\/       swp     w12, w2, [x17]\n+    __ ldadd(Assembler::word, r3, r21, r23);           \/\/       ldadd   w3, w21, [x23]\n+    __ ldbic(Assembler::word, r5, r6, r7);             \/\/       ldclr   w5, w6, [x7]\n+    __ ldeor(Assembler::word, r19, r13, r28);          \/\/       ldeor   w19, w13, [x28]\n+    __ ldorr(Assembler::word, r17, r16, r6);           \/\/       ldset   w17, w16, [x6]\n+    __ ldsmin(Assembler::word, r2, r29, r3);           \/\/       ldsmin  w2, w29, [x3]\n+    __ ldsmax(Assembler::word, r4, r6, r15);           \/\/       ldsmax  w4, w6, [x15]\n+    __ ldumin(Assembler::word, r20, r13, r12);         \/\/       ldumin  w20, w13, [x12]\n+    __ ldumax(Assembler::word, r20, r8, r25);          \/\/       ldumax  w20, w8, [x25]\n@@ -1144,9 +1154,9 @@\n-    __ swpa(Assembler::word, r3, r4, r6);              \/\/       swpa    w3, w4, [x6]\n-    __ ldadda(Assembler::word, r16, r20, r13);         \/\/       ldadda  w16, w20, [x13]\n-    __ ldbica(Assembler::word, r12, r20, r8);          \/\/       ldclra  w12, w20, [x8]\n-    __ ldeora(Assembler::word, r25, r20, r19);         \/\/       ldeora  w25, w20, [x19]\n-    __ ldorra(Assembler::word, r0, r11, r24);          \/\/       ldseta  w0, w11, [x24]\n-    __ ldsmina(Assembler::word, r6, r20, sp);          \/\/       ldsmina w6, w20, [sp]\n-    __ ldsmaxa(Assembler::word, r14, r16, r6);         \/\/       ldsmaxa w14, w16, [x6]\n-    __ ldumina(Assembler::word, r0, r7, r15);          \/\/       ldumina w0, w7, [x15]\n-    __ ldumaxa(Assembler::word, r19, r26, r9);         \/\/       ldumaxa w19, w26, [x9]\n+    __ swpa(Assembler::word, r20, r19, r0);            \/\/       swpa    w20, w19, [x0]\n+    __ ldadda(Assembler::word, r11, r24, r6);          \/\/       ldadda  w11, w24, [x6]\n+    __ ldbica(Assembler::word, r20, zr, r14);          \/\/       ldclra  w20, wzr, [x14]\n+    __ ldeora(Assembler::word, r16, r6, r0);           \/\/       ldeora  w16, w6, [x0]\n+    __ ldorra(Assembler::word, r7, r15, r19);          \/\/       ldseta  w7, w15, [x19]\n+    __ ldsmina(Assembler::word, r26, r9, r10);         \/\/       ldsmina w26, w9, [x10]\n+    __ ldsmaxa(Assembler::word, r23, r21, r22);        \/\/       ldsmaxa w23, w21, [x22]\n+    __ ldumina(Assembler::word, r28, r2, r3);          \/\/       ldumina w28, w2, [x3]\n+    __ ldumaxa(Assembler::word, r15, r19, r20);        \/\/       ldumaxa w15, w19, [x20]\n@@ -1155,9 +1165,9 @@\n-    __ swpal(Assembler::word, r10, r23, r21);          \/\/       swpal   w10, w23, [x21]\n-    __ ldaddal(Assembler::word, r22, r28, r2);         \/\/       ldaddal w22, w28, [x2]\n-    __ ldbical(Assembler::word, r3, r15, r19);         \/\/       ldclral w3, w15, [x19]\n-    __ ldeoral(Assembler::word, r20, r7, r4);          \/\/       ldeoral w20, w7, [x4]\n-    __ ldorral(Assembler::word, r29, r7, r0);          \/\/       ldsetal w29, w7, [x0]\n-    __ ldsminal(Assembler::word, r9, r16, r20);        \/\/       ldsminal        w9, w16, [x20]\n-    __ ldsmaxal(Assembler::word, r23, r4, r16);        \/\/       ldsmaxal        w23, w4, [x16]\n-    __ lduminal(Assembler::word, r10, r23, r11);       \/\/       lduminal        w10, w23, [x11]\n-    __ ldumaxal(Assembler::word, r25, r6, sp);         \/\/       ldumaxal        w25, w6, [sp]\n+    __ swpal(Assembler::word, r7, r4, r29);            \/\/       swpal   w7, w4, [x29]\n+    __ ldaddal(Assembler::word, r7, r0, r9);           \/\/       ldaddal w7, w0, [x9]\n+    __ ldbical(Assembler::word, r16, r20, r23);        \/\/       ldclral w16, w20, [x23]\n+    __ ldeoral(Assembler::word, r4, r16, r10);         \/\/       ldeoral w4, w16, [x10]\n+    __ ldorral(Assembler::word, r23, r11, r25);        \/\/       ldsetal w23, w11, [x25]\n+    __ ldsminal(Assembler::word, r6, zr, r16);         \/\/       ldsminal        w6, wzr, [x16]\n+    __ ldsmaxal(Assembler::word, r13, r23, r12);       \/\/       ldsmaxal        w13, w23, [x12]\n+    __ lduminal(Assembler::word, r1, r14, r9);         \/\/       lduminal        w1, w14, [x9]\n+    __ ldumaxal(Assembler::word, r21, r16, r26);       \/\/       ldumaxal        w21, w16, [x26]\n@@ -1166,9 +1176,9 @@\n-    __ swpl(Assembler::word, r16, r13, r23);           \/\/       swpl    w16, w13, [x23]\n-    __ ldaddl(Assembler::word, r12, r1, r14);          \/\/       ldaddl  w12, w1, [x14]\n-    __ ldbicl(Assembler::word, r9, r21, r16);          \/\/       ldclrl  w9, w21, [x16]\n-    __ ldeorl(Assembler::word, r26, r15, r4);          \/\/       ldeorl  w26, w15, [x4]\n-    __ ldorrl(Assembler::word, r4, r16, r8);           \/\/       ldsetl  w4, w16, [x8]\n-    __ ldsminl(Assembler::word, r6, r30, r4);          \/\/       ldsminl w6, w30, [x4]\n-    __ ldsmaxl(Assembler::word, r29, r17, r29);        \/\/       ldsmaxl w29, w17, [x29]\n-    __ lduminl(Assembler::word, r26, r9, r15);         \/\/       lduminl w26, w9, [x15]\n-    __ ldumaxl(Assembler::word, r2, r11, r29);         \/\/       ldumaxl w2, w11, [x29]\n+    __ swpl(Assembler::word, r15, r4, r4);             \/\/       swpl    w15, w4, [x4]\n+    __ ldaddl(Assembler::word, r16, r8, r6);           \/\/       ldaddl  w16, w8, [x6]\n+    __ ldbicl(Assembler::word, r30, r4, r29);          \/\/       ldclrl  w30, w4, [x29]\n+    __ ldeorl(Assembler::word, r17, r29, r26);         \/\/       ldeorl  w17, w29, [x26]\n+    __ ldorrl(Assembler::word, r9, r15, r2);           \/\/       ldsetl  w9, w15, [x2]\n+    __ ldsminl(Assembler::word, r11, r29, r3);         \/\/       ldsminl w11, w29, [x3]\n+    __ ldsmaxl(Assembler::word, r7, r1, r27);          \/\/       ldsmaxl w7, w1, [x27]\n+    __ lduminl(Assembler::word, r21, r16, r14);        \/\/       lduminl w21, w16, [x14]\n+    __ ldumaxl(Assembler::word, r8, r16, r22);         \/\/       ldumaxl w8, w16, [x22]\n@@ -1177,4 +1187,4 @@\n-    __ bcax(v3, __ T16B, v7, v1, v27);                 \/\/       bcax            v3.16B, v7.16B, v1.16B, v27.16B\n-    __ eor3(v21, __ T16B, v18, v14, v8);               \/\/       eor3            v21.16B, v18.16B, v14.16B, v8.16B\n-    __ rax1(v18, __ T2D, v22, v25);                    \/\/       rax1            v18.2D, v22.2D, v25.2D\n-    __ xar(v5, __ T2D, v20, v21, 37);                  \/\/       xar             v5.2D, v20.2D, v21.2D, #37\n+    __ bcax(v25, __ T16B, v5, v20, v21);               \/\/       bcax            v25.16B, v5.16B, v20.16B, v21.16B\n+    __ eor3(v18, __ T16B, v23, v16, v30);              \/\/       eor3            v18.16B, v23.16B, v16.16B, v30.16B\n+    __ rax1(v20, __ T2D, v20, v0);                     \/\/       rax1            v20.2D, v20.2D, v0.2D\n+    __ xar(v4, __ T2D, v19, v24, 9);                   \/\/       xar             v4.2D, v19.2D, v24.2D, #9\n@@ -1183,4 +1193,4 @@\n-    __ sha512h(v23, __ T2D, v16, v30);                 \/\/       sha512h         q23, q16, v30.2D\n-    __ sha512h2(v20, __ T2D, v20, v0);                 \/\/       sha512h2                q20, q20, v0.2D\n-    __ sha512su0(v4, __ T2D, v19);                     \/\/       sha512su0               v4.2D, v19.2D\n-    __ sha512su1(v24, __ T2D, v4, v20);                \/\/       sha512su1               v24.2D, v4.2D, v20.2D\n+    __ sha512h(v20, __ T2D, v4, v24);                  \/\/       sha512h         q20, q4, v24.2D\n+    __ sha512h2(v26, __ T2D, v19, v2);                 \/\/       sha512h2                q26, q19, v2.2D\n+    __ sha512su0(v8, __ T2D, v8);                      \/\/       sha512su0               v8.2D, v8.2D\n+    __ sha512su1(v14, __ T2D, v24, v18);               \/\/       sha512su1               v14.2D, v24.2D, v18.2D\n@@ -1189,5 +1199,5 @@\n-    __ sve_add(z4, __ D, 210u);                        \/\/       add     z4.d, z4.d, #0xd2\n-    __ sve_sub(z19, __ B, 71u);                        \/\/       sub     z19.b, z19.b, #0x47\n-    __ sve_and(z8, __ H, 49663u);                      \/\/       and     z8.h, z8.h, #0xc1ff\n-    __ sve_eor(z31, __ S, 4294967231u);                \/\/       eor     z31.s, z31.s, #0xffffffbf\n-    __ sve_orr(z1, __ H, 16368u);                      \/\/       orr     z1.h, z1.h, #0x3ff0\n+    __ sve_add(z31, __ S, 36u);                        \/\/       add     z31.s, z31.s, #0x24\n+    __ sve_sub(z31, __ B, 85u);                        \/\/       sub     z31.b, z31.b, #0x55\n+    __ sve_and(z20, __ H, 4032u);                      \/\/       and     z20.h, z20.h, #0xfc0\n+    __ sve_eor(z7, __ D, 274877904896u);               \/\/       eor     z7.d, z7.d, #0x3ffffff800\n+    __ sve_orr(z27, __ B, 243u);                       \/\/       orr     z27.b, z27.b, #0xf3\n@@ -1196,5 +1206,5 @@\n-    __ sve_add(z0, __ H, 61u);                         \/\/       add     z0.h, z0.h, #0x3d\n-    __ sve_sub(z24, __ S, 36u);                        \/\/       sub     z24.s, z24.s, #0x24\n-    __ sve_and(z27, __ B, 243u);                       \/\/       and     z27.b, z27.b, #0xf3\n-    __ sve_eor(z24, __ H, 65534u);                     \/\/       eor     z24.h, z24.h, #0xfffe\n-    __ sve_orr(z22, __ S, 4294967293u);                \/\/       orr     z22.s, z22.s, #0xfffffffd\n+    __ sve_add(z24, __ H, 132u);                       \/\/       add     z24.h, z24.h, #0x84\n+    __ sve_sub(z31, __ S, 183u);                       \/\/       sub     z31.s, z31.s, #0xb7\n+    __ sve_and(z20, __ D, 4503599627354112u);          \/\/       and     z20.d, z20.d, #0xfffffffffc000\n+    __ sve_eor(z14, __ S, 4042322160u);                \/\/       eor     z14.s, z14.s, #0xf0f0f0f0\n+    __ sve_orr(z28, __ H, 32256u);                     \/\/       orr     z28.h, z28.h, #0x7e00\n@@ -1203,5 +1213,5 @@\n-    __ sve_add(z29, __ H, 113u);                       \/\/       add     z29.h, z29.h, #0x71\n-    __ sve_sub(z20, __ B, 165u);                       \/\/       sub     z20.b, z20.b, #0xa5\n-    __ sve_and(z28, __ H, 32256u);                     \/\/       and     z28.h, z28.h, #0x7e00\n-    __ sve_eor(z12, __ S, 4287102855u);                \/\/       eor     z12.s, z12.s, #0xff87ff87\n-    __ sve_orr(z9, __ S, 3825205247u);                 \/\/       orr     z9.s, z9.s, #0xe3ffffff\n+    __ sve_add(z12, __ S, 13u);                        \/\/       add     z12.s, z12.s, #0xd\n+    __ sve_sub(z24, __ H, 159u);                       \/\/       sub     z24.h, z24.h, #0x9f\n+    __ sve_and(z13, __ S, 2151677951u);                \/\/       and     z13.s, z13.s, #0x803fffff\n+    __ sve_eor(z5, __ B, 124u);                        \/\/       eor     z5.b, z5.b, #0x7c\n+    __ sve_orr(z8, __ H, 32768u);                      \/\/       orr     z8.h, z8.h, #0x8000\n@@ -1210,5 +1220,5 @@\n-    __ sve_add(z18, __ S, 41u);                        \/\/       add     z18.s, z18.s, #0x29\n-    __ sve_sub(z0, __ B, 98u);                         \/\/       sub     z0.b, z0.b, #0x62\n-    __ sve_and(z8, __ H, 32768u);                      \/\/       and     z8.h, z8.h, #0x8000\n-    __ sve_eor(z4, __ H, 508u);                        \/\/       eor     z4.h, z4.h, #0x1fc\n-    __ sve_orr(z0, __ H, 64512u);                      \/\/       orr     z0.h, z0.h, #0xfc00\n+    __ sve_add(z4, __ H, 243u);                        \/\/       add     z4.h, z4.h, #0xf3\n+    __ sve_sub(z5, __ B, 86u);                         \/\/       sub     z5.b, z5.b, #0x56\n+    __ sve_and(z22, __ D, 8064u);                      \/\/       and     z22.d, z22.d, #0x1f80\n+    __ sve_eor(z9, __ S, 130023424u);                  \/\/       eor     z9.s, z9.s, #0x7c00000\n+    __ sve_orr(z24, __ B, 62u);                        \/\/       orr     z24.b, z24.b, #0x3e\n@@ -1217,5 +1227,5 @@\n-    __ sve_add(z3, __ B, 79u);                         \/\/       add     z3.b, z3.b, #0x4f\n-    __ sve_sub(z19, __ D, 84u);                        \/\/       sub     z19.d, z19.d, #0x54\n-    __ sve_and(z24, __ B, 62u);                        \/\/       and     z24.b, z24.b, #0x3e\n-    __ sve_eor(z24, __ D, 18428729675200069887u);      \/\/       eor     z24.d, z24.d, #0xffc00000000000ff\n-    __ sve_orr(z11, __ D, 17296056810822168583u);      \/\/       orr     z11.d, z11.d, #0xf007f007f007f007\n+    __ sve_add(z24, __ D, 113u);                       \/\/       add     z24.d, z24.d, #0x71\n+    __ sve_sub(z21, __ H, 217u);                       \/\/       sub     z21.h, z21.h, #0xd9\n+    __ sve_and(z13, __ S, 3221229567u);                \/\/       and     z13.s, z13.s, #0xc0000fff\n+    __ sve_eor(z14, __ B, 131u);                       \/\/       eor     z14.b, z14.b, #0x83\n+    __ sve_orr(z22, __ S, 4042322160u);                \/\/       orr     z22.s, z22.s, #0xf0f0f0f0\n@@ -1224,5 +1234,5 @@\n-    __ sve_add(z31, __ S, 115u);                       \/\/       add     z31.s, z31.s, #0x73\n-    __ sve_sub(z3, __ D, 134u);                        \/\/       sub     z3.d, z3.d, #0x86\n-    __ sve_and(z22, __ S, 4042322160u);                \/\/       and     z22.s, z22.s, #0xf0f0f0f0\n-    __ sve_eor(z3, __ B, 225u);                        \/\/       eor     z3.b, z3.b, #0xe1\n-    __ sve_orr(z9, __ S, 4164941887u);                 \/\/       orr     z9.s, z9.s, #0xf83ff83f\n+    __ sve_add(z3, __ B, 215u);                        \/\/       add     z3.b, z3.b, #0xd7\n+    __ sve_sub(z19, __ H, 134u);                       \/\/       sub     z19.h, z19.h, #0x86\n+    __ sve_and(z17, __ S, 491520u);                    \/\/       and     z17.s, z17.s, #0x78000\n+    __ sve_eor(z2, __ D, 8796093020160u);              \/\/       eor     z2.d, z2.d, #0x7fffffff800\n+    __ sve_orr(z11, __ S, 3221229567u);                \/\/       orr     z11.s, z11.s, #0xc0000fff\n@@ -1231,56 +1241,56 @@\n-    __ sve_add(z0, __ D, z4, z2);                      \/\/       add     z0.d, z4.d, z2.d\n-    __ sve_sub(z14, __ S, z6, z11);                    \/\/       sub     z14.s, z6.s, z11.s\n-    __ sve_fadd(z14, __ S, z17, z30);                  \/\/       fadd    z14.s, z17.s, z30.s\n-    __ sve_fmul(z3, __ S, z3, z23);                    \/\/       fmul    z3.s, z3.s, z23.s\n-    __ sve_fsub(z3, __ S, z24, z28);                   \/\/       fsub    z3.s, z24.s, z28.s\n-    __ sve_abs(z19, __ D, p5, z7);                     \/\/       abs     z19.d, p5\/m, z7.d\n-    __ sve_add(z21, __ H, p3, z5);                     \/\/       add     z21.h, p3\/m, z21.h, z5.h\n-    __ sve_and(z26, __ S, p1, z22);                    \/\/       and     z26.s, p1\/m, z26.s, z22.s\n-    __ sve_asr(z17, __ H, p0, z3);                     \/\/       asr     z17.h, p0\/m, z17.h, z3.h\n-    __ sve_bic(z20, __ H, p3, z8);                     \/\/       bic     z20.h, p3\/m, z20.h, z8.h\n-    __ sve_clz(z14, __ H, p4, z17);                    \/\/       clz     z14.h, p4\/m, z17.h\n-    __ sve_cnt(z13, __ D, p6, z18);                    \/\/       cnt     z13.d, p6\/m, z18.d\n-    __ sve_eor(z19, __ H, p2, z16);                    \/\/       eor     z19.h, p2\/m, z19.h, z16.h\n-    __ sve_lsl(z27, __ S, p5, z28);                    \/\/       lsl     z27.s, p5\/m, z27.s, z28.s\n-    __ sve_lsr(z8, __ D, p2, z5);                      \/\/       lsr     z8.d, p2\/m, z8.d, z5.d\n-    __ sve_mul(z28, __ H, p2, z0);                     \/\/       mul     z28.h, p2\/m, z28.h, z0.h\n-    __ sve_neg(z25, __ B, p5, z21);                    \/\/       neg     z25.b, p5\/m, z21.b\n-    __ sve_not(z3, __ B, p5, z26);                     \/\/       not     z3.b, p5\/m, z26.b\n-    __ sve_orr(z26, __ S, p7, z19);                    \/\/       orr     z26.s, p7\/m, z26.s, z19.s\n-    __ sve_rbit(z1, __ D, p3, z14);                    \/\/       rbit    z1.d, p3\/m, z14.d\n-    __ sve_revb(z14, __ H, p0, z18);                   \/\/       revb    z14.h, p0\/m, z18.h\n-    __ sve_smax(z31, __ S, p5, z23);                   \/\/       smax    z31.s, p5\/m, z31.s, z23.s\n-    __ sve_smin(z30, __ B, p3, z8);                    \/\/       smin    z30.b, p3\/m, z30.b, z8.b\n-    __ sve_sub(z0, __ S, p3, z23);                     \/\/       sub     z0.s, p3\/m, z0.s, z23.s\n-    __ sve_fabs(z0, __ D, p4, z26);                    \/\/       fabs    z0.d, p4\/m, z26.d\n-    __ sve_fadd(z24, __ D, p3, z22);                   \/\/       fadd    z24.d, p3\/m, z24.d, z22.d\n-    __ sve_fdiv(z2, __ D, p0, z11);                    \/\/       fdiv    z2.d, p0\/m, z2.d, z11.d\n-    __ sve_fmax(z12, __ D, p5, z24);                   \/\/       fmax    z12.d, p5\/m, z12.d, z24.d\n-    __ sve_fmin(z9, __ D, p7, z17);                    \/\/       fmin    z9.d, p7\/m, z9.d, z17.d\n-    __ sve_fmul(z20, __ D, p5, z4);                    \/\/       fmul    z20.d, p5\/m, z20.d, z4.d\n-    __ sve_fneg(z13, __ D, p7, z22);                   \/\/       fneg    z13.d, p7\/m, z22.d\n-    __ sve_frintm(z31, __ D, p6, z18);                 \/\/       frintm  z31.d, p6\/m, z18.d\n-    __ sve_frintn(z15, __ D, p2, z13);                 \/\/       frintn  z15.d, p2\/m, z13.d\n-    __ sve_frintp(z20, __ S, p1, z1);                  \/\/       frintp  z20.s, p1\/m, z1.s\n-    __ sve_fsqrt(z14, __ S, p0, z7);                   \/\/       fsqrt   z14.s, p0\/m, z7.s\n-    __ sve_fsub(z12, __ D, p4, z4);                    \/\/       fsub    z12.d, p4\/m, z12.d, z4.d\n-    __ sve_fmad(z15, __ S, p0, z3, z30);               \/\/       fmad    z15.s, p0\/m, z3.s, z30.s\n-    __ sve_fmla(z20, __ D, p1, z20, z31);              \/\/       fmla    z20.d, p1\/m, z20.d, z31.d\n-    __ sve_fmls(z13, __ D, p3, z9, z14);               \/\/       fmls    z13.d, p3\/m, z9.d, z14.d\n-    __ sve_fmsb(z1, __ S, p3, z28, z3);                \/\/       fmsb    z1.s, p3\/m, z28.s, z3.s\n-    __ sve_fnmad(z26, __ S, p2, z25, z9);              \/\/       fnmad   z26.s, p2\/m, z25.s, z9.s\n-    __ sve_fnmsb(z26, __ D, p2, z14, z1);              \/\/       fnmsb   z26.d, p2\/m, z14.d, z1.d\n-    __ sve_fnmla(z26, __ D, p1, z29, z20);             \/\/       fnmla   z26.d, p1\/m, z29.d, z20.d\n-    __ sve_fnmls(z6, __ D, p7, z13, z1);               \/\/       fnmls   z6.d, p7\/m, z13.d, z1.d\n-    __ sve_mla(z11, __ B, p2, z1, z1);                 \/\/       mla     z11.b, p2\/m, z1.b, z1.b\n-    __ sve_mls(z27, __ B, p6, z15, z2);                \/\/       mls     z27.b, p6\/m, z15.b, z2.b\n-    __ sve_and(z30, z17, z25);                         \/\/       and     z30.d, z17.d, z25.d\n-    __ sve_eor(z2, z24, z3);                           \/\/       eor     z2.d, z24.d, z3.d\n-    __ sve_orr(z29, z13, z3);                          \/\/       orr     z29.d, z13.d, z3.d\n-    __ sve_bic(z14, z16, z28);                         \/\/       bic     z14.d, z16.d, z28.d\n-    __ sve_uzp1(z4, __ S, z11, z27);                   \/\/       uzp1    z4.s, z11.s, z27.s\n-    __ sve_uzp2(z2, __ D, z16, z1);                    \/\/       uzp2    z2.d, z16.d, z1.d\n-    __ sve_fabd(z7, __ D, p5, z31);                    \/\/       fabd    z7.d, p5\/m, z7.d, z31.d\n-    __ sve_bext(z16, __ S, z10, z22);                  \/\/       bext    z16.s, z10.s, z22.s\n-    __ sve_bdep(z29, __ B, z7, z22);                   \/\/       bdep    z29.b, z7.b, z22.b\n-    __ sve_eor3(z12, z24, z11);                        \/\/       eor3    z12.d, z12.d, z24.d, z11.d\n+    __ sve_add(z30, __ B, z12, z3);                    \/\/       add     z30.b, z12.b, z3.b\n+    __ sve_sub(z23, __ D, z9, z3);                     \/\/       sub     z23.d, z9.d, z3.d\n+    __ sve_fadd(z28, __ D, z3, z19);                   \/\/       fadd    z28.d, z3.d, z19.d\n+    __ sve_fmul(z7, __ S, z26, z21);                   \/\/       fmul    z7.s, z26.s, z21.s\n+    __ sve_fsub(z5, __ S, z8, z26);                    \/\/       fsub    z5.s, z8.s, z26.s\n+    __ sve_abs(z22, __ B, p4, z17);                    \/\/       abs     z22.b, p4\/m, z17.b\n+    __ sve_add(z3, __ H, p2, z20);                     \/\/       add     z3.h, p2\/m, z3.h, z20.h\n+    __ sve_and(z8, __ S, p3, z14);                     \/\/       and     z8.s, p3\/m, z8.s, z14.s\n+    __ sve_asr(z17, __ D, p2, z13);                    \/\/       asr     z17.d, p2\/m, z17.d, z13.d\n+    __ sve_bic(z18, __ H, p7, z19);                    \/\/       bic     z18.h, p7\/m, z18.h, z19.h\n+    __ sve_clz(z16, __ S, p3, z27);                    \/\/       clz     z16.s, p3\/m, z27.s\n+    __ sve_cnt(z28, __ H, p5, z8);                     \/\/       cnt     z28.h, p5\/m, z8.h\n+    __ sve_eor(z5, __ H, p7, z28);                     \/\/       eor     z5.h, p7\/m, z5.h, z28.h\n+    __ sve_lsl(z0, __ S, p3, z25);                     \/\/       lsl     z0.s, p3\/m, z0.s, z25.s\n+    __ sve_lsr(z21, __ S, p0, z3);                     \/\/       lsr     z21.s, p0\/m, z21.s, z3.s\n+    __ sve_mul(z26, __ D, p1, z26);                    \/\/       mul     z26.d, p1\/m, z26.d, z26.d\n+    __ sve_neg(z19, __ H, p4, z1);                     \/\/       neg     z19.h, p4\/m, z1.h\n+    __ sve_not(z14, __ B, p7, z14);                    \/\/       not     z14.b, p7\/m, z14.b\n+    __ sve_orr(z18, __ S, p0, z31);                    \/\/       orr     z18.s, p0\/m, z18.s, z31.s\n+    __ sve_rbit(z23, __ H, p5, z30);                   \/\/       rbit    z23.h, p5\/m, z30.h\n+    __ sve_revb(z8, __ S, p0, z0);                     \/\/       revb    z8.s, p0\/m, z0.s\n+    __ sve_smax(z23, __ S, p5, z0);                    \/\/       smax    z23.s, p5\/m, z23.s, z0.s\n+    __ sve_smin(z26, __ H, p6, z24);                   \/\/       smin    z26.h, p6\/m, z26.h, z24.h\n+    __ sve_sub(z22, __ B, p5, z2);                     \/\/       sub     z22.b, p5\/m, z22.b, z2.b\n+    __ sve_fabs(z11, __ D, p5, z12);                   \/\/       fabs    z11.d, p5\/m, z12.d\n+    __ sve_fadd(z24, __ D, p6, z9);                    \/\/       fadd    z24.d, p6\/m, z24.d, z9.d\n+    __ sve_fdiv(z17, __ D, p5, z20);                   \/\/       fdiv    z17.d, p5\/m, z17.d, z20.d\n+    __ sve_fmax(z4, __ D, p5, z13);                    \/\/       fmax    z4.d, p5\/m, z4.d, z13.d\n+    __ sve_fmin(z22, __ D, p7, z31);                   \/\/       fmin    z22.d, p7\/m, z22.d, z31.d\n+    __ sve_fmul(z18, __ S, p4, z15);                   \/\/       fmul    z18.s, p4\/m, z18.s, z15.s\n+    __ sve_fneg(z13, __ S, p7, z20);                   \/\/       fneg    z13.s, p7\/m, z20.s\n+    __ sve_frintm(z1, __ S, p3, z14);                  \/\/       frintm  z1.s, p3\/m, z14.s\n+    __ sve_frintn(z7, __ D, p2, z12);                  \/\/       frintn  z7.d, p2\/m, z12.d\n+    __ sve_frintp(z4, __ S, p6, z15);                  \/\/       frintp  z4.s, p6\/m, z15.s\n+    __ sve_fsqrt(z3, __ D, p7, z1);                    \/\/       fsqrt   z3.d, p7\/m, z1.d\n+    __ sve_fsub(z5, __ D, p5, z31);                    \/\/       fsub    z5.d, p5\/m, z5.d, z31.d\n+    __ sve_fmad(z13, __ D, p3, z9, z14);               \/\/       fmad    z13.d, p3\/m, z9.d, z14.d\n+    __ sve_fmla(z1, __ S, p3, z28, z3);                \/\/       fmla    z1.s, p3\/m, z28.s, z3.s\n+    __ sve_fmls(z26, __ S, p2, z25, z9);               \/\/       fmls    z26.s, p2\/m, z25.s, z9.s\n+    __ sve_fmsb(z26, __ D, p2, z14, z1);               \/\/       fmsb    z26.d, p2\/m, z14.d, z1.d\n+    __ sve_fnmad(z26, __ D, p1, z29, z20);             \/\/       fnmad   z26.d, p1\/m, z29.d, z20.d\n+    __ sve_fnmsb(z6, __ D, p7, z13, z1);               \/\/       fnmsb   z6.d, p7\/m, z13.d, z1.d\n+    __ sve_fnmla(z11, __ S, p2, z1, z1);               \/\/       fnmla   z11.s, p2\/m, z1.s, z1.s\n+    __ sve_fnmls(z27, __ S, p6, z15, z2);              \/\/       fnmls   z27.s, p6\/m, z15.s, z2.s\n+    __ sve_mla(z30, __ B, p4, z25, z2);                \/\/       mla     z30.b, p4\/m, z25.b, z2.b\n+    __ sve_mls(z24, __ H, p0, z26, z29);               \/\/       mls     z24.h, p0\/m, z26.h, z29.h\n+    __ sve_and(z3, z22, z14);                          \/\/       and     z3.d, z22.d, z14.d\n+    __ sve_eor(z28, z17, z4);                          \/\/       eor     z28.d, z17.d, z4.d\n+    __ sve_orr(z27, z16, z2);                          \/\/       orr     z27.d, z16.d, z2.d\n+    __ sve_bic(z1, z28, z7);                           \/\/       bic     z1.d, z28.d, z7.d\n+    __ sve_uzp1(z31, __ H, z28, z16);                  \/\/       uzp1    z31.h, z28.h, z16.h\n+    __ sve_uzp2(z22, __ B, z17, z29);                  \/\/       uzp2    z22.b, z17.b, z29.b\n+    __ sve_fabd(z22, __ D, p1, z12);                   \/\/       fabd    z22.d, p1\/m, z22.d, z12.d\n+    __ sve_bext(z11, __ H, z9, z11);                   \/\/       bext    z11.h, z9.h, z11.h\n+    __ sve_bdep(z0, __ S, z4, z23);                    \/\/       bdep    z0.s, z4.s, z23.s\n+    __ sve_eor3(z20, z4, z3);                          \/\/       eor3    z20.d, z20.d, z4.d, z3.d\n@@ -1289,9 +1299,9 @@\n-    __ sve_andv(v11, __ B, p2, z0);                    \/\/       andv b11, p2, z0.b\n-    __ sve_orv(v23, __ B, p5, z20);                    \/\/       orv b23, p5, z20.b\n-    __ sve_eorv(v3, __ B, p3, z15);                    \/\/       eorv b3, p3, z15.b\n-    __ sve_smaxv(v30, __ B, p6, z27);                  \/\/       smaxv b30, p6, z27.b\n-    __ sve_sminv(v21, __ D, p6, z10);                  \/\/       sminv d21, p6, z10.d\n-    __ sve_fminv(v3, __ S, p6, z4);                    \/\/       fminv s3, p6, z4.s\n-    __ sve_fmaxv(v6, __ S, p0, z21);                   \/\/       fmaxv s6, p0, z21.s\n-    __ sve_fadda(v25, __ D, p6, z30);                  \/\/       fadda d25, p6, d25, z30.d\n-    __ sve_uaddv(v31, __ H, p4, z1);                   \/\/       uaddv d31, p4, z1.h\n+    __ sve_andv(v15, __ D, p1, z30);                   \/\/       andv d15, p1, z30.d\n+    __ sve_orv(v27, __ D, p1, z21);                    \/\/       orv d27, p1, z21.d\n+    __ sve_eorv(v10, __ D, p7, z3);                    \/\/       eorv d10, p7, z3.d\n+    __ sve_smaxv(v4, __ B, p2, z6);                    \/\/       smaxv b4, p2, z6.b\n+    __ sve_sminv(v21, __ D, p1, z25);                  \/\/       sminv d21, p1, z25.d\n+    __ sve_fminv(v30, __ D, p6, z31);                  \/\/       fminv d30, p6, z31.d\n+    __ sve_fmaxv(v1, __ D, p2, z12);                   \/\/       fmaxv d1, p2, z12.d\n+    __ sve_fadda(v13, __ D, p2, z25);                  \/\/       fadda d13, p2, d13, z25.d\n+    __ sve_uaddv(v1, __ D, p7, z23);                   \/\/       uaddv d1, p7, z23.d\n@@ -1300,5 +1310,5 @@\n-    __ saddwv(v12, v13, __ T8H, v14, __ T8B);          \/\/       saddw   v12.8H, v13.8H, v14.8B\n-    __ saddwv2(v30, v31, __ T8H, v0, __ T16B);         \/\/       saddw2  v30.8H, v31.8H, v0.16B\n-    __ saddwv(v13, v14, __ T4S, v15, __ T4H);          \/\/       saddw   v13.4S, v14.4S, v15.4H\n-    __ saddwv2(v8, v9, __ T4S, v10, __ T8H);           \/\/       saddw2  v8.4S, v9.4S, v10.8H\n-    __ saddwv(v25, v26, __ T2D, v27, __ T2S);          \/\/       saddw   v25.2D, v26.2D, v27.2S\n+    __ saddwv(v20, v21, __ T8H, v22, __ T8B);          \/\/       saddw   v20.8H, v21.8H, v22.8B\n+    __ saddwv2(v0, v1, __ T8H, v2, __ T16B);           \/\/       saddw2  v0.8H, v1.8H, v2.16B\n+    __ saddwv(v21, v22, __ T4S, v23, __ T4H);          \/\/       saddw   v21.4S, v22.4S, v23.4H\n+    __ saddwv2(v7, v8, __ T4S, v9, __ T8H);            \/\/       saddw2  v7.4S, v8.4S, v9.8H\n+    __ saddwv(v31, v0, __ T2D, v1, __ T2S);            \/\/       saddw   v31.2D, v0.2D, v1.2S\n@@ -1306,6 +1316,6 @@\n-    __ uaddwv(v1, v2, __ T8H, v3, __ T8B);             \/\/       uaddw   v1.8H, v2.8H, v3.8B\n-    __ uaddwv2(v31, v0, __ T8H, v1, __ T16B);          \/\/       uaddw2  v31.8H, v0.8H, v1.16B\n-    __ uaddwv(v23, v24, __ T4S, v25, __ T4H);          \/\/       uaddw   v23.4S, v24.4S, v25.4H\n-    __ uaddwv2(v31, v0, __ T4S, v1, __ T8H);           \/\/       uaddw2  v31.4S, v0.4S, v1.8H\n-    __ uaddwv(v20, v21, __ T2D, v22, __ T2S);          \/\/       uaddw   v20.2D, v21.2D, v22.2S\n-    __ uaddwv2(v0, v1, __ T2D, v2, __ T4S);            \/\/       uaddw2  v0.2D, v1.2D, v2.4S\n+    __ uaddwv(v27, v28, __ T8H, v29, __ T8B);          \/\/       uaddw   v27.8H, v28.8H, v29.8B\n+    __ uaddwv2(v22, v23, __ T8H, v24, __ T16B);        \/\/       uaddw2  v22.8H, v23.8H, v24.16B\n+    __ uaddwv(v8, v9, __ T4S, v10, __ T4H);            \/\/       uaddw   v8.4S, v9.4S, v10.4H\n+    __ uaddwv2(v29, v30, __ T4S, v31, __ T8H);         \/\/       uaddw2  v29.4S, v30.4S, v31.8H\n+    __ uaddwv(v26, v27, __ T2D, v28, __ T2S);          \/\/       uaddw   v26.2D, v27.2D, v28.2S\n+    __ uaddwv2(v20, v21, __ T2D, v22, __ T4S);         \/\/       uaddw2  v20.2D, v21.2D, v22.4S\n@@ -1330,7 +1340,7 @@\n-    0x14000000,     0x17ffffd7,     0x14000441,     0x94000000,\n-    0x97ffffd4,     0x9400043e,     0x3400000a,     0x34fffa2a,\n-    0x3400876a,     0x35000008,     0x35fff9c8,     0x35008708,\n-    0xb400000b,     0xb4fff96b,     0xb40086ab,     0xb500001d,\n-    0xb5fff91d,     0xb500865d,     0x10000013,     0x10fff8b3,\n-    0x100085f3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36308576,     0x3758000c,     0x375ff7cc,     0x3758850c,\n+    0x14000000,     0x17ffffd7,     0x1400044b,     0x94000000,\n+    0x97ffffd4,     0x94000448,     0x3400000a,     0x34fffa2a,\n+    0x340088aa,     0x35000008,     0x35fff9c8,     0x35008848,\n+    0xb400000b,     0xb4fff96b,     0xb40087eb,     0xb500001d,\n+    0xb5fff91d,     0xb500879d,     0x10000013,     0x10fff8b3,\n+    0x10008733,     0x90000013,     0x36300016,     0x3637f836,\n+    0x363086b6,     0x3758000c,     0x375ff7cc,     0x3758864c,\n@@ -1341,13 +1351,13 @@\n-    0x540082e0,     0x54000001,     0x54fff541,     0x54008281,\n-    0x54000002,     0x54fff4e2,     0x54008222,     0x54000002,\n-    0x54fff482,     0x540081c2,     0x54000003,     0x54fff423,\n-    0x54008163,     0x54000003,     0x54fff3c3,     0x54008103,\n-    0x54000004,     0x54fff364,     0x540080a4,     0x54000005,\n-    0x54fff305,     0x54008045,     0x54000006,     0x54fff2a6,\n-    0x54007fe6,     0x54000007,     0x54fff247,     0x54007f87,\n-    0x54000008,     0x54fff1e8,     0x54007f28,     0x54000009,\n-    0x54fff189,     0x54007ec9,     0x5400000a,     0x54fff12a,\n-    0x54007e6a,     0x5400000b,     0x54fff0cb,     0x54007e0b,\n-    0x5400000c,     0x54fff06c,     0x54007dac,     0x5400000d,\n-    0x54fff00d,     0x54007d4d,     0x5400000e,     0x54ffefae,\n-    0x54007cee,     0x5400000f,     0x54ffef4f,     0x54007c8f,\n+    0x54008420,     0x54000001,     0x54fff541,     0x540083c1,\n+    0x54000002,     0x54fff4e2,     0x54008362,     0x54000002,\n+    0x54fff482,     0x54008302,     0x54000003,     0x54fff423,\n+    0x540082a3,     0x54000003,     0x54fff3c3,     0x54008243,\n+    0x54000004,     0x54fff364,     0x540081e4,     0x54000005,\n+    0x54fff305,     0x54008185,     0x54000006,     0x54fff2a6,\n+    0x54008126,     0x54000007,     0x54fff247,     0x540080c7,\n+    0x54000008,     0x54fff1e8,     0x54008068,     0x54000009,\n+    0x54fff189,     0x54008009,     0x5400000a,     0x54fff12a,\n+    0x54007faa,     0x5400000b,     0x54fff0cb,     0x54007f4b,\n+    0x5400000c,     0x54fff06c,     0x54007eec,     0x5400000d,\n+    0x54fff00d,     0x54007e8d,     0x5400000e,     0x54ffefae,\n+    0x54007e2e,     0x5400000f,     0x54ffef4f,     0x54007dcf,\n@@ -1474,129 +1484,132 @@\n-    0x4eabad49,     0x0ebaf738,     0x4ebcf77a,     0x4ef2f630,\n-    0x2ea0effe,     0x6ea5ec83,     0x6eeced6a,     0x0fa710c5,\n-    0x4f8b8149,     0x4fc710c5,     0x0f8750c5,     0x4faa8128,\n-    0x4fc750c5,     0x2f8890e6,     0x4fa880e6,     0x6fc59083,\n-    0x0f6f81cd,     0x4f448862,     0x0f848062,     0x4fab8149,\n-    0x0e3736d5,     0x4e323630,     0x0e743672,     0x4e6d358b,\n-    0x0eb736d5,     0x4eb93717,     0x4eee35ac,     0x0e3c3f7a,\n-    0x4e393f17,     0x0e7e3fbc,     0x4e703dee,     0x0ead3d8b,\n-    0x4eba3f38,     0x4ee33c41,     0x2e2e8dac,     0x6e218c1f,\n-    0x2e6c8d6a,     0x6e728e30,     0x2ea98d07,     0x6ea48c62,\n-    0x6ee58c83,     0x2e2f35cd,     0x6e353693,     0x2e733651,\n-    0x6e723630,     0x2ea53483,     0x6ea33441,     0x6eed358b,\n-    0x2e203ffe,     0x6e273cc5,     0x2e6a3d28,     0x6e713e0f,\n-    0x2ebf3fdd,     0x6ea03ffe,     0x6ee23c20,     0x0e36e6b4,\n-    0x4e29e507,     0x4e76e6b4,     0x2eb9e717,     0x6ebee7bc,\n-    0x6ef7e6d5,     0x2e3de79b,     0x6e3be759,     0x6e67e4c5,\n-    0x65d23ee0,     0x65903d92,     0x65d03fa7,     0x65912fe9,\n-    0x65d13bf9,     0x65932a0a,     0x25cb90c4,     0x25040bde,\n-    0x25c11085,     0x25c62c6b,     0x259f2279,     0x259d8993,\n-    0x24e5102b,     0x24ad5458,     0x24ec7ab5,     0x24387c6d,\n-    0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,     0x7a42cbe2,\n-    0x93df03ff,     0xc820ffff,     0x8822fc7f,     0xc8247cbf,\n-    0x88267fff,     0x4e010fe0,     0x5e040420,     0x4e081fe1,\n-    0x4e0c1fe1,     0x4e0a1fe1,     0x4e071fe1,     0x4e042c20,\n-    0x4e062c20,     0x4e052c20,     0x4e083c20,     0x0e0c3c20,\n-    0x0e0a3c20,     0x0e073c20,     0x9eae0020,     0x0f03f409,\n-    0x6f03f40e,     0x4cc0ac3f,     0x0ea1b820,     0x4e21c862,\n-    0x4e61b8a4,     0x05a08020,     0x05104fe0,     0x05505001,\n-    0x05906fe2,     0x05d03005,     0x05101fea,     0x05901feb,\n-    0x04b0e3e0,     0x0470e7e1,     0x042f9c20,     0x043f9c35,\n-    0x047f9c20,     0x04ff9c20,     0x04299420,     0x04319160,\n-    0x0461943e,     0x04a19020,     0x04038100,     0x040381a0,\n-    0x040387e1,     0x04438be2,     0x04c38fe3,     0x040181e0,\n-    0x04018100,     0x04018621,     0x04418b22,     0x04418822,\n-    0x04818c23,     0x040081e0,     0x04008120,     0x04008761,\n-    0x04008621,     0x04408822,     0x04808c23,     0x042053ff,\n-    0x047f5401,     0x25208028,     0x2538cfe0,     0x2578d001,\n-    0x25b8efe2,     0x25f8f007,     0x2538dfea,     0x25b8dfeb,\n-    0xa400a3e0,     0xa420a7e0,     0xa4484be0,     0xa467afe0,\n-    0xa4a8a7ea,     0xa547a814,     0xa4084ffe,     0xa55c53e0,\n-    0xa5e1540b,     0xe400fbf6,     0xe408ffff,     0xe420e7e0,\n-    0xe4484be0,     0xe460efe0,     0xe547e400,     0xe4014be0,\n-    0xe4a84fe0,     0xe5f15000,     0x858043e0,     0x85a043ff,\n-    0xe59f5d08,     0x0420e3e9,     0x0460e3ea,     0x04a0e3eb,\n-    0x04e0e3ec,     0x25104042,     0x25104871,     0x25904861,\n-    0x25904c92,     0x05344020,     0x05744041,     0x05b44062,\n-    0x05f44083,     0x252c8840,     0x253c1420,     0x25681572,\n-    0x25a21ce3,     0x25ea1e34,     0x253c0421,     0x25680572,\n-    0x25a20ce3,     0x25ea0e34,     0x0522c020,     0x05e6c0a4,\n-    0x2401a001,     0x2443a051,     0x24858881,     0x24c78cd1,\n-    0x24850891,     0x24c70cc1,     0x250f9001,     0x25508051,\n-    0x25802491,     0x25df28c1,     0x25850c81,     0x251e10d1,\n-    0x65816001,     0x65c36051,     0x65854891,     0x65c74cc1,\n-    0x05733820,     0x05b238a4,     0x05f138e6,     0x0570396a,\n-    0x65d0a001,     0x65d6a443,     0x65d4a826,     0x6594ac26,\n-    0x6554ac26,     0x6556ac26,     0x6552ac26,     0x65cbac85,\n-    0x65caac01,     0x6589ac85,     0x6588ac01,     0x65c9ac85,\n-    0x65c8ac01,     0x65dea833,     0x659ca509,     0x65d8a801,\n-    0x65dcac01,     0x655cb241,     0x0520a1e0,     0x0521a601,\n-    0x052281e0,     0x05238601,     0x04a14026,     0x042244a6,\n-    0x046344a6,     0x04a444a6,     0x04e544a7,     0x0568aca7,\n-    0x05b23230,     0x853040af,     0xc5b040af,     0xe57080af,\n-    0xe5b080af,     0x25034440,     0x254054c4,     0x25034640,\n-    0x25415a05,     0x25834440,     0x25c54489,     0x250b5d3a,\n-    0x2550dc20,     0x2518e3e1,     0x2518e021,     0x2518e0a1,\n-    0x2518e121,     0x2518e1a1,     0x2558e3e2,     0x2558e042,\n-    0x2558e0c2,     0x2558e142,     0x2598e3e3,     0x2598e063,\n-    0x2598e0e3,     0x2598e163,     0x25d8e3e4,     0x25d8e084,\n-    0x25d8e104,     0x25d8e184,     0x2518e407,     0x05214800,\n-    0x05614800,     0x05a14800,     0x05e14800,     0x05214c00,\n-    0x05614c00,     0x05a14c00,     0x05e14c00,     0x05304001,\n-    0x05314001,     0x05a18610,     0x05e18610,     0x05271e11,\n-    0x6545e891,     0x6585e891,     0x65c5e891,     0x6545c891,\n-    0x6585c891,     0x65c5c891,     0x45b0c210,     0x45f1c231,\n-    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,\n-    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,\n-    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,\n-    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,\n-    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,\n-    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,\n-    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,\n-    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,\n-    0xf8338131,     0xf83c01fb,     0xf82712f5,     0xf83f2059,\n-    0xf83f31fb,     0xf82a5277,     0xf8234010,     0xf83972fa,\n-    0xf8226190,     0xf8a483dc,     0xf8bd0370,     0xf8a613a9,\n-    0xf8b02087,     0xf8a7312f,     0xf8b75048,     0xf8bc43f5,\n-    0xf8a5701b,     0xf8b1608f,     0xf8fa8388,     0xf8f6037b,\n-    0xf8f91017,     0xf8e421e6,     0xf8e031e4,     0xf8e150ea,\n-    0xf8e5438a,     0xf8e772f4,     0xf8f56166,     0xf86883f1,\n-    0xf8660051,     0xf86c13be,     0xf86322db,     0xf87d31ae,\n-    0xf87c5311,     0xf86541c2,     0xf86a7170,     0xf87b6197,\n-    0xb8248236,     0xb8240261,     0xb83011b0,     0xb82e204c,\n-    0xb83132a3,     0xb83750c5,     0xb82741b3,     0xb83c7211,\n-    0xb82663a2,     0xb8a380c4,     0xb8b001b4,     0xb8ac1114,\n-    0xb8b92274,     0xb8a0330b,     0xb8a653f4,     0xb8ae40d0,\n-    0xb8a071e7,     0xb8b3613a,     0xb8ea82b7,     0xb8f6005c,\n-    0xb8e3126f,     0xb8f42087,     0xb8fd3007,     0xb8e95290,\n-    0xb8f74204,     0xb8ea7177,     0xb8f963e6,     0xb87082ed,\n-    0xb86c01c1,     0xb8691215,     0xb87a208f,     0xb8643110,\n-    0xb866509e,     0xb87d43b1,     0xb87a71e9,     0xb86263ab,\n-    0xce216ce3,     0xce0e2255,     0xce798ed2,     0xce959685,\n-    0xce7e8217,     0xce608694,     0xcec08264,     0xce748898,\n-    0x25e0da44,     0x2521c8f3,     0x05801548,     0x0540cbdf,\n-    0x05006521,     0x2560c7a0,     0x25a1c498,     0x058026bb,\n-    0x05407dd8,     0x0500f3d6,     0x2560ce3d,     0x2521d4b4,\n-    0x05803cbc,     0x05404d6c,     0x05001b89,     0x25a0c532,\n-    0x2521cc40,     0x05800c08,     0x054074c4,     0x050034a0,\n-    0x2520c9e3,     0x25e1ca93,     0x05803e98,     0x05425238,\n-    0x050024cb,     0x25a0ce7f,     0x25e1d0c3,     0x05802676,\n-    0x05401e63,     0x05002d49,     0x04e20080,     0x04ab04ce,\n-    0x659e022e,     0x65970863,     0x659c0703,     0x04d6b4f3,\n-    0x04400cb5,     0x049a06da,     0x04508071,     0x045b0d14,\n-    0x0459b22e,     0x04daba4d,     0x04590a13,     0x0493979b,\n-    0x04d188a8,     0x0450081c,     0x0417b6b9,     0x041eb743,\n-    0x04981e7a,     0x05e78dc1,     0x0564824e,     0x048816ff,\n-    0x040a0d1e,     0x04810ee0,     0x04dcb340,     0x65c08ed8,\n-    0x65cd8162,     0x65c6970c,     0x65c79e29,     0x65c29494,\n-    0x04ddbecd,     0x65c2ba5f,     0x65c0a9af,     0x6581a434,\n-    0x658da0ee,     0x65c1908c,     0x65be806f,     0x65ff0694,\n-    0x65ee2d2d,     0x65a3af81,     0x65a9cb3a,     0x65e1e9da,\n-    0x65f447ba,     0x65e17da6,     0x0401482b,     0x040279fb,\n-    0x0439323e,     0x04a33302,     0x046331bd,     0x04fc320e,\n-    0x05bb6964,     0x05e16e02,     0x65c897e7,     0x4596b150,\n-    0x4516b4fd,     0x0438396c,     0x041a280b,     0x04183697,\n-    0x04192de3,     0x04083b7e,     0x04ca3955,     0x65873883,\n-    0x658622a6,     0x65d83bd9,     0x0441303f,     0x0e2e11ac,\n-    0x4e2013fe,     0x0e6f11cd,     0x4e6a1128,     0x0ebb1359,\n-    0x4ebf13dd,     0x2e231041,     0x6e21101f,     0x2e791317,\n-    0x6e61101f,     0x2eb612b4,     0x6ea21020,\n+    0x4eabad49,     0x0e7ab738,     0x4e7cb77a,     0x0eb2b630,\n+    0x4ea0b7fe,     0x0e252483,     0x4e2c256a,     0x0e792717,\n+    0x4e6c256a,     0x0ea624a4,     0x4eb42672,     0x0ea4f462,\n+    0x4eadf58b,     0x4eeaf528,     0x2eaced6a,     0x6eb1ee0f,\n+    0x6ef3ee51,     0x0f8710c5,     0x4fa880e6,     0x4fc810e6,\n+    0x0f855083,     0x4f8f89cd,     0x4fc45862,     0x2f849062,\n+    0x4fab8149,     0x6fca9928,     0x0f6780c5,     0x4f5d898b,\n+    0x0f8f81cd,     0x4f9089ee,     0x0e3035ee,     0x4e2d358b,\n+    0x0e7a3738,     0x4e633441,     0x0eae35ac,     0x4ea1341f,\n+    0x4eec356a,     0x0e323e30,     0x4e293d07,     0x0e643c62,\n+    0x4e653c83,     0x0eaf3dcd,     0x4eb53e93,     0x4ef33e51,\n+    0x2e328e30,     0x6e258c83,     0x2e638c41,     0x6e6d8d8b,\n+    0x2ea08ffe,     0x6ea78cc5,     0x6eea8d28,     0x2e31360f,\n+    0x6e3f37dd,     0x2e6037fe,     0x6e623420,     0x2eb636b4,\n+    0x6ea93507,     0x6ef636b4,     0x2e393f17,     0x6e3e3fbc,\n+    0x2e773ed5,     0x6e7d3f9b,     0x2ebb3f59,     0x6ea73cc5,\n+    0x6ee33c41,     0x0e39e717,     0x4e32e630,     0x4e61e41f,\n+    0x2ea7e4c5,     0x6eaee5ac,     0x6eebe549,     0x2e3ee7bc,\n+    0x6e31e60f,     0x6e7fe7dd,     0x65d23feb,     0x65d03dd2,\n+    0x65d03369,     0x65912566,     0x65d13e3f,     0x659334ef,\n+    0x25c19085,     0x25c60c7b,     0x259f0269,     0x259d2983,\n+    0x25d5303b,     0x259d9458,     0x24ec5aa5,     0x24385c7d,\n+    0x247b7e39,     0x24bff4e7,     0xba5fd3e3,     0x3a5f03e5,\n+    0xfa411be4,     0x7a42cbe2,     0x93df03ff,     0xc820ffff,\n+    0x8822fc7f,     0xc8247cbf,     0x88267fff,     0x4e010fe0,\n+    0x5e040420,     0x4e081fe1,     0x4e0c1fe1,     0x4e0a1fe1,\n+    0x4e071fe1,     0x4e042c20,     0x4e062c20,     0x4e052c20,\n+    0x4e083c20,     0x0e0c3c20,     0x0e0a3c20,     0x0e073c20,\n+    0x9eae0020,     0x0f03f409,     0x6f03f40e,     0x4cc0ac3f,\n+    0x0ea1b820,     0x4e21c862,     0x4e61b8a4,     0x05a08020,\n+    0x05104fe0,     0x05505001,     0x05906fe2,     0x05d03005,\n+    0x05101fea,     0x05901feb,     0x04b0e3e0,     0x0470e7e1,\n+    0x042f9c20,     0x043f9c35,     0x047f9c20,     0x04ff9c20,\n+    0x04299420,     0x04319160,     0x0461943e,     0x04a19020,\n+    0x04038100,     0x040381a0,     0x040387e1,     0x04438be2,\n+    0x04c38fe3,     0x040181e0,     0x04018100,     0x04018621,\n+    0x04418b22,     0x04418822,     0x04818c23,     0x040081e0,\n+    0x04008120,     0x04008761,     0x04008621,     0x04408822,\n+    0x04808c23,     0x042053ff,     0x047f5401,     0x25208028,\n+    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n+    0x2538dfea,     0x25b8dfeb,     0xa400a3e0,     0xa420a7e0,\n+    0xa4484be0,     0xa467afe0,     0xa4a8a7ea,     0xa547a814,\n+    0xa4084ffe,     0xa55c53e0,     0xa5e1540b,     0xe400fbf6,\n+    0xe408ffff,     0xe420e7e0,     0xe4484be0,     0xe460efe0,\n+    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n+    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x0420e3e9,\n+    0x0460e3ea,     0x04a0e3eb,     0x04e0e3ec,     0x25104042,\n+    0x25104871,     0x25904861,     0x25904c92,     0x05344020,\n+    0x05744041,     0x05b44062,     0x05f44083,     0x252c8840,\n+    0x253c1420,     0x25681572,     0x25a21ce3,     0x25ea1e34,\n+    0x253c0421,     0x25680572,     0x25a20ce3,     0x25ea0e34,\n+    0x0522c020,     0x05e6c0a4,     0x2401a001,     0x2443a051,\n+    0x24858881,     0x24c78cd1,     0x24850891,     0x24c70cc1,\n+    0x250f9001,     0x25508051,     0x25802491,     0x25df28c1,\n+    0x25850c81,     0x251e10d1,     0x65816001,     0x65c36051,\n+    0x65854891,     0x65c74cc1,     0x05733820,     0x05b238a4,\n+    0x05f138e6,     0x0570396a,     0x65d0a001,     0x65d6a443,\n+    0x65d4a826,     0x6594ac26,     0x6554ac26,     0x6556ac26,\n+    0x6552ac26,     0x65cbac85,     0x65caac01,     0x6589ac85,\n+    0x6588ac01,     0x65c9ac85,     0x65c8ac01,     0x65dea833,\n+    0x659ca509,     0x65d8a801,     0x65dcac01,     0x655cb241,\n+    0x0520a1e0,     0x0521a601,     0x052281e0,     0x05238601,\n+    0x04a14026,     0x042244a6,     0x046344a6,     0x04a444a6,\n+    0x04e544a7,     0x0568aca7,     0x05b23230,     0x853040af,\n+    0xc5b040af,     0xe57080af,     0xe5b080af,     0x25034440,\n+    0x254054c4,     0x25034640,     0x25415a05,     0x25834440,\n+    0x25c54489,     0x250b5d3a,     0x2550dc20,     0x2518e3e1,\n+    0x2518e021,     0x2518e0a1,     0x2518e121,     0x2518e1a1,\n+    0x2558e3e2,     0x2558e042,     0x2558e0c2,     0x2558e142,\n+    0x2598e3e3,     0x2598e063,     0x2598e0e3,     0x2598e163,\n+    0x25d8e3e4,     0x25d8e084,     0x25d8e104,     0x25d8e184,\n+    0x2518e407,     0x05214800,     0x05614800,     0x05a14800,\n+    0x05e14800,     0x05214c00,     0x05614c00,     0x05a14c00,\n+    0x05e14c00,     0x05304001,     0x05314001,     0x05a18610,\n+    0x05e18610,     0x05271e11,     0x6545e891,     0x6585e891,\n+    0x65c5e891,     0x6545c891,     0x6585c891,     0x65c5c891,\n+    0x45b0c210,     0x45f1c231,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf83983e2,     0xf83b0150,\n+    0xf8371073,     0xf8302320,     0xf83a3057,     0xf830508c,\n+    0xf83c43be,     0xf83070db,     0xf82961fd,     0xf8a780e4,\n+    0xf8af02e9,     0xf8a81382,     0xf8b520bf,     0xf8bb3220,\n+    0xf8af5344,     0xf8a842dc,     0xf8bb733b,     0xf8b76080,\n+    0xf8e68010,     0xf8e4002f,     0xf8ea10a7,     0xf8ea20fc,\n+    0xf8f432b7,     0xf8e6510b,     0xf8f140df,     0xf8f17182,\n+    0xf8fe607d,     0xf87b83b6,     0xf86e038d,     0xf87110b8,\n+    0xf862214e,     0xf870336b,     0xf877508c,     0xf8764091,\n+    0xf8617213,     0xf87061cd,     0xb82c8222,     0xb82302f5,\n+    0xb82510e6,     0xb833238d,     0xb83130d0,     0xb822507d,\n+    0xb82441e6,     0xb834718d,     0xb8346328,     0xb8b48013,\n+    0xb8ab00d8,     0xb8b411df,     0xb8b02006,     0xb8a7326f,\n+    0xb8ba5149,     0xb8b742d5,     0xb8bc7062,     0xb8af6293,\n+    0xb8e783a4,     0xb8e70120,     0xb8f012f4,     0xb8e42150,\n+    0xb8f7332b,     0xb8e6521f,     0xb8ed4197,     0xb8e1712e,\n+    0xb8f56350,     0xb86f8084,     0xb87000c8,     0xb87e13a4,\n+    0xb871235d,     0xb869304f,     0xb86b507d,     0xb8674361,\n+    0xb87571d0,     0xb86862d0,     0xce3454b9,     0xce107af2,\n+    0xce608e94,     0xce982664,     0xce788094,     0xce62867a,\n+    0xcec08108,     0xce728b0e,     0x25a0c49f,     0x2521cabf,\n+    0x058054b4,     0x0543ab47,     0x050026bb,     0x2560d098,\n+    0x25a1d6ff,     0x058394b4,     0x0540266e,     0x05003cbc,\n+    0x25a0c1ac,     0x2561d3f8,     0x05800acd,     0x05403685,\n+    0x05000c08,     0x2560de64,     0x2521cac5,     0x0583c8b6,\n+    0x05405089,     0x05003e98,     0x25e0ce38,     0x2561db35,\n+    0x058011ad,     0x05400e4e,     0x05002676,     0x2520dae3,\n+    0x2561d0d3,     0x05808871,     0x0543abe2,     0x050011ab,\n+    0x0423019e,     0x04e30537,     0x65d3007c,     0x65950b47,\n+    0x659a0505,     0x0416b236,     0x04400a83,     0x049a0dc8,\n+    0x04d089b1,     0x045b1e72,     0x0499af70,     0x045ab51c,\n+    0x04591f85,     0x04938f20,     0x04918075,     0x04d0075a,\n+    0x0457b033,     0x041ebdce,     0x049803f2,     0x056797d7,\n+    0x05a48008,     0x04881417,     0x044a1b1a,     0x04011456,\n+    0x04dcb58b,     0x65c09938,     0x65cd9691,     0x65c695a4,\n+    0x65c79ff6,     0x658291f2,     0x049dbe8d,     0x6582adc1,\n+    0x65c0a987,     0x6581b9e4,     0x65cdbc23,     0x65c197e5,\n+    0x65ee8d2d,     0x65a30f81,     0x65a92b3a,     0x65e1a9da,\n+    0x65f4c7ba,     0x65e1fda6,     0x65a1482b,     0x65a279fb,\n+    0x0402533e,     0x045d6358,     0x042e32c3,     0x04a4323c,\n+    0x0462321b,     0x04e73381,     0x05706b9f,     0x053d6e36,\n+    0x65c88596,     0x454bb12b,     0x4597b480,     0x04243874,\n+    0x04da27cf,     0x04d826bb,     0x04d93c6a,     0x040828c4,\n+    0x04ca2735,     0x65c73bfe,     0x65c62981,     0x65d82b2d,\n+    0x04c13ee1,     0x0e3612b4,     0x4e221020,     0x0e7712d5,\n+    0x4e691107,     0x0ea1101f,     0x4ebf13dd,     0x2e3d139b,\n+    0x6e3812f6,     0x2e6a1128,     0x6e7f13dd,     0x2ebc137a,\n+    0x6eb612b4,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":425,"deletions":412,"binary":false,"changes":837,"status":"modified"}]}