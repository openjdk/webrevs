{"files":[{"patch":"@@ -122,2 +122,0 @@\n-#ifdef _LP64\n-\n@@ -160,24 +158,0 @@\n-#else \/\/ LP64\n-\n-Address Address::make_array(ArrayAddress adr) {\n-  AddressLiteral base = adr.base();\n-  Address index = adr.index();\n-  assert(index._disp == 0, \"must not have disp\"); \/\/ maybe it can?\n-  Address array(index._base, index._index, index._scale, (intptr_t) base.target());\n-  array._rspec = base._rspec;\n-  return array;\n-}\n-\n-\/\/ exceedingly dangerous constructor\n-Address::Address(address loc, RelocationHolder spec) {\n-  _base  = noreg;\n-  _index = noreg;\n-  _scale = no_scale;\n-  _disp  = (intptr_t) loc;\n-  _rspec = spec;\n-  _xmmindex = xnoreg;\n-  _isxmmindex = false;\n-}\n-\n-#endif \/\/ _LP64\n-\n@@ -217,1 +191,0 @@\n-  NOT_LP64(_is_managed = false;)\n@@ -747,2 +720,2 @@\n-      \/\/ Do rip-rel adjustment for 64bit\n-      LP64_ONLY(adjusted -=  (next_ip - inst_mark()));\n+      \/\/ Do rip-rel adjustment\n+      adjusted -=  (next_ip - inst_mark());\n@@ -849,1 +822,1 @@\n-    LP64_ONLY(assert(false, \"shouldn't have that prefix\"));\n+    assert(false, \"shouldn't have that prefix\");\n@@ -862,1 +835,0 @@\n-    NOT_LP64(assert(false, \"64bit prefixes\"));\n@@ -866,1 +838,0 @@\n-    NOT_LP64(assert(false, \"64bit prefixes\"));\n@@ -880,1 +851,0 @@\n-    NOT_LP64(assert(false, \"64bit prefixes\"));\n@@ -919,1 +889,0 @@\n-      NOT_LP64(assert(false, \"64bit prefix found\"));\n@@ -923,1 +892,0 @@\n-      NOT_LP64(assert(false, \"64bit prefix found\"));\n@@ -948,4 +916,0 @@\n-#ifndef _LP64\n-    assert(which == imm_operand || which == disp32_operand,\n-           \"which %d is_64_bit %d ip \" INTPTR_FORMAT, which, is_64bit, p2i(ip));\n-#else\n@@ -955,1 +919,0 @@\n-#endif \/\/ _LP64\n@@ -1116,2 +1079,0 @@\n-    NOT_LP64(assert((0xC0 & *ip) == 0xC0, \"shouldn't have LDS and LES instructions\"));\n-\n@@ -1219,1 +1180,0 @@\n-      NOT_LP64(assert(false, \"found 64bit prefix\"));\n@@ -1221,0 +1181,1 @@\n+      \/\/ fall-through\n@@ -1235,1 +1196,0 @@\n-#ifdef _LP64\n@@ -1237,4 +1197,0 @@\n-#else\n-  \/\/ assert(which != imm_operand || has_imm32, \"instruction has no imm32 field\");\n-  assert(which != imm_operand || has_disp32, \"instruction has no imm32 field\");\n-#endif \/\/ LP64\n@@ -1295,1 +1251,0 @@\n-#ifdef _LP64\n@@ -1297,3 +1252,0 @@\n-#else\n-  assert(which == imm_operand, \"instruction has only an imm field\");\n-#endif \/\/ LP64\n@@ -1322,2 +1274,1 @@\n-    assert(format == imm_operand || format == disp32_operand\n-           LP64_ONLY(|| format == narrow_oop_operand), \"format ok\");\n+    assert(format == imm_operand || format == disp32_operand || format == narrow_oop_operand, \"format ok\");\n@@ -1833,3 +1784,0 @@\n-  \/\/ suspect disp32 is always good\n-  int operand = LP64_ONLY(disp32_operand) NOT_LP64(imm_operand);\n-\n@@ -1843,1 +1791,1 @@\n-    emit_data(offs - long_size, rtype, operand);\n+    emit_data(offs - long_size, rtype, disp32_operand);\n@@ -1850,1 +1798,1 @@\n-    emit_data(int(0), rtype, operand);\n+    emit_data(int(0), rtype, disp32_operand);\n@@ -1877,2 +1825,1 @@\n-  int operand = LP64_ONLY(disp32_operand) NOT_LP64(call32_operand);\n-  emit_data((int) disp, rspec, operand);\n+  emit_data((int) disp, rspec, disp32_operand);\n@@ -1890,1 +1837,0 @@\n-  NOT_LP64(guarantee(VM_Version::supports_cmov(), \"illegal instruction\"));\n@@ -1903,1 +1849,0 @@\n-  NOT_LP64(guarantee(VM_Version::supports_cmov(), \"illegal instruction\"));\n@@ -2094,2 +2039,1 @@\n-    LP64_ONLY(case 8:)\n-      \/\/ This instruction is not valid in 32 bits\n+    case 8:\n@@ -2114,1 +2058,1 @@\n-    LP64_ONLY(prefix(crc, v, p);)\n+    prefix(crc, v, p);\n@@ -2143,2 +2087,1 @@\n-    LP64_ONLY(case 8:)\n-      \/\/ This instruction is not valid in 32 bits\n+    case 8:\n@@ -2151,1 +2094,1 @@\n-    LP64_ONLY(prefix(crc, adr, p);)\n+    prefix(crc, adr, p);\n@@ -2843,1 +2786,0 @@\n-#ifdef _LP64\n@@ -2861,1 +2803,0 @@\n-#endif\n@@ -2919,1 +2860,1 @@\n-  LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));\n+  movq(dst, src);\n@@ -2944,1 +2885,0 @@\n-  NOT_LP64(assert(dst->has_byte_register(), \"must have byte register\"));\n@@ -3935,1 +3875,0 @@\n-  NOT_LP64(assert(src->has_byte_register(), \"must have byte register\"));\n@@ -4085,1 +4024,0 @@\n-  NOT_LP64(assert(src->has_byte_register(), \"must have byte register\"));\n@@ -5813,10 +5751,0 @@\n-#ifndef _LP64 \/\/ no 32bit push\/pop on amd64\n-void Assembler::popl(Address dst) {\n-  \/\/ NOTE: this will adjust stack by 8byte on 64bits\n-  InstructionMark im(this);\n-  prefix(dst);\n-  emit_int8((unsigned char)0x8F);\n-  emit_operand(rax, dst, 0);\n-}\n-#endif\n-\n@@ -6223,1 +6151,0 @@\n-#ifdef _LP64\n@@ -6285,2 +6212,0 @@\n-#endif \/\/_LP64\n-\n@@ -6304,10 +6229,0 @@\n-#ifndef _LP64 \/\/ no 32bit push\/pop on amd64\n-void Assembler::pushl(Address src) {\n-  \/\/ Note this will push 64bit on 64bit\n-  InstructionMark im(this);\n-  prefix(src);\n-  emit_int8((unsigned char)0xFF);\n-  emit_operand(rsi, src, 0);\n-}\n-#endif\n-\n@@ -6356,2 +6271,1 @@\n-  LP64_ONLY(emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xA5);)\n-  NOT_LP64( emit_int16((unsigned char)0xF3,        (unsigned char)0xA5);)\n+  emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xA5);\n@@ -6364,2 +6278,1 @@\n-  LP64_ONLY(emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xAA);)\n-  NOT_LP64( emit_int16((unsigned char)0xF3,        (unsigned char)0xAA);)\n+  emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xAA);\n@@ -6372,3 +6285,2 @@\n-  \/\/ LP64:STOSQ, LP32:STOSD\n-  LP64_ONLY(emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xAB);)\n-  NOT_LP64( emit_int16((unsigned char)0xF3,        (unsigned char)0xAB);)\n+  \/\/ STOSQ\n+  emit_int24((unsigned char)0xF3, REX_W, (unsigned char)0xAB);\n@@ -6381,2 +6293,1 @@\n-  LP64_ONLY(emit_int24((unsigned char)0xF2, REX_W, (unsigned char)0xAF);)\n-  NOT_LP64( emit_int16((unsigned char)0xF2,        (unsigned char)0xAF);)\n+  emit_int24((unsigned char)0xF2, REX_W, (unsigned char)0xAF);\n@@ -6385,1 +6296,0 @@\n-#ifdef _LP64\n@@ -6392,1 +6302,0 @@\n-#endif\n@@ -6467,1 +6376,0 @@\n-#ifdef _LP64\n@@ -6530,9 +6438,0 @@\n- }\n-#endif\n-\n-void Assembler::sahf() {\n-#ifdef _LP64\n-  \/\/ Not supported in 64bit mode\n-  ShouldNotReachHere();\n-#endif\n-  emit_int8((unsigned char)0x9E);\n@@ -6991,1 +6890,0 @@\n-#ifdef _LP64\n@@ -7017,1 +6915,0 @@\n-#endif\n@@ -7211,1 +7108,0 @@\n-  NOT_LP64(assert(dst->has_byte_register(), \"must have byte register\"));\n@@ -12875,48 +12771,0 @@\n-#ifndef _LP64\n-\/\/ 32bit only pieces of the assembler\n-\n-void Assembler::emms() {\n-  NOT_LP64(assert(VM_Version::supports_mmx(), \"\"));\n-  emit_int16(0x0F, 0x77);\n-}\n-\n-void Assembler::vzeroupper() {\n-  vzeroupper_uncached();\n-}\n-\n-void Assembler::cmp_literal32(Register src1, int32_t imm32, RelocationHolder const& rspec) {\n-  \/\/ NO PREFIX AS NEVER 64BIT\n-  InstructionMark im(this);\n-  emit_int16((unsigned char)0x81, (0xF8 | src1->encoding()));\n-  emit_data(imm32, rspec, 0);\n-}\n-\n-void Assembler::cmp_literal32(Address src1, int32_t imm32, RelocationHolder const& rspec) {\n-  \/\/ NO PREFIX AS NEVER 64BIT (not even 32bit versions of 64bit regs\n-  InstructionMark im(this);\n-  emit_int8((unsigned char)0x81);\n-  emit_operand(rdi, src1, 4);\n-  emit_data(imm32, rspec, 0);\n-}\n-\n-\/\/ The 64-bit (32bit platform) cmpxchg compares the value at adr with the contents of rdx:rax,\n-\/\/ and stores rcx:rbx into adr if so; otherwise, the value at adr is loaded\n-\/\/ into rdx:rax.  The ZF is set if the compared values were equal, and cleared otherwise.\n-void Assembler::cmpxchg8(Address adr) {\n-  InstructionMark im(this);\n-  emit_int16(0x0F, (unsigned char)0xC7);\n-  emit_operand(rcx, adr, 0);\n-}\n-\n-void Assembler::decl(Register dst) {\n-  \/\/ Don't use it directly. Use MacroAssembler::decrementl() instead.\n- emit_int8(0x48 | dst->encoding());\n-}\n-\n-void Assembler::edecl(Register dst, Register src, bool no_flags) {\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  (void) evex_prefix_and_encode_ndd(0, dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_3C, &attributes, no_flags);\n-  emit_int8(0x48 | src->encoding());\n-}\n-#endif \/\/ !_LP64\n-\n@@ -13056,1 +12904,1 @@\n-    if (UseAVX > 2 && !attributes->is_evex_instruction() && !is_managed()) {\n+    if (UseAVX > 2 && !attributes->is_evex_instruction()) {\n@@ -13071,1 +12919,0 @@\n-  clear_managed();\n@@ -13119,1 +12966,1 @@\n-    if (UseAVX > 2 && !attributes->is_evex_instruction() && !is_managed()) {\n+    if (UseAVX > 2 && !attributes->is_evex_instruction()) {\n@@ -13141,1 +12988,0 @@\n-  clear_managed();\n@@ -14041,49 +13887,0 @@\n-#ifndef _LP64\n-\n-void Assembler::incl(Register dst) {\n-  \/\/ Don't use it directly. Use MacroAssembler::incrementl() instead.\n-  emit_int8(0x40 | dst->encoding());\n-}\n-\n-void Assembler::eincl(Register dst, Register src, bool no_flags) {\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  (void) evex_prefix_and_encode_ndd(0, dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_3C, &attributes, no_flags);\n-  emit_int8(0x40 | src->encoding());\n-}\n-\n-void Assembler::lea(Register dst, Address src) {\n-  leal(dst, src);\n-}\n-\n-void Assembler::mov_literal32(Address dst, int32_t imm32, RelocationHolder const& rspec) {\n-  InstructionMark im(this);\n-  emit_int8((unsigned char)0xC7);\n-  emit_operand(rax, dst, 4);\n-  emit_data((int)imm32, rspec, 0);\n-}\n-\n-void Assembler::mov_literal32(Register dst, int32_t imm32, RelocationHolder const& rspec) {\n-  InstructionMark im(this);\n-  int encode = prefix_and_encode(dst->encoding());\n-  emit_int8((0xB8 | encode));\n-  emit_data((int)imm32, rspec, 0);\n-}\n-\n-void Assembler::popa() { \/\/ 32bit\n-  emit_int8(0x61);\n-}\n-\n-void Assembler::push_literal32(int32_t imm32, RelocationHolder const& rspec) {\n-  InstructionMark im(this);\n-  emit_int8(0x68);\n-  emit_data(imm32, rspec, 0);\n-}\n-\n-void Assembler::pusha() { \/\/ 32bit\n-  emit_int8(0x60);\n-}\n-\n-#else \/\/ LP64\n-\n-\/\/ 64bit only pieces of the assembler\n-\n@@ -16042,1 +15839,0 @@\n-#ifdef _LP64\n@@ -16197,1 +15993,0 @@\n-#endif\n@@ -16542,2 +16337,0 @@\n-#endif \/\/ !LP64\n-\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":20,"deletions":227,"binary":false,"changes":247,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-#ifdef _LP64\n@@ -52,5 +51,0 @@\n-#else\n-    n_register_parameters = 0,   \/\/ 0 registers used to pass arguments\n-    n_int_register_parameters_j   = 0,\n-    n_float_register_parameters_j = 0\n-#endif \/\/ _LP64\n@@ -61,1 +55,0 @@\n-#ifdef _LP64\n@@ -141,9 +134,0 @@\n-#else\n-\/\/ rscratch1 will appear in 32bit code that is dead but of course must compile\n-\/\/ Using noreg ensures if the dead code is incorrectly live and executed it\n-\/\/ will cause an assertion failure\n-#define rscratch1 noreg\n-#define rscratch2 noreg\n-\n-#endif \/\/ _LP64\n-\n@@ -171,1 +155,1 @@\n-    times_ptr = LP64_ONLY(times_8) NOT_LP64(times_4)\n+    times_ptr = times_8\n@@ -200,1 +184,0 @@\n-  NOT_LP64(Address(address loc, RelocationHolder spec);)\n@@ -459,1 +442,1 @@\n-const int FPUStateSizeInWords = NOT_LP64(27) LP64_ONLY(2688 \/ wordSize);\n+const int FPUStateSizeInWords = 2688 \/ wordSize;\n@@ -631,4 +614,1 @@\n-#ifndef _LP64\n-    _WhichOperand_limit = 3\n-#else\n-     narrow_oop_operand = 3,     \/\/ embedded 32-bit immediate narrow oop\n+    narrow_oop_operand = 3,      \/\/ embedded 32-bit immediate narrow oop\n@@ -636,1 +616,0 @@\n-#endif\n@@ -724,1 +703,0 @@\n-  NOT_LP64(bool _is_managed;)\n@@ -910,2 +888,2 @@\n-  bool always_reachable(AddressLiteral adr) NOT_LP64( { return true; } );\n-  bool        reachable(AddressLiteral adr) NOT_LP64( { return true; } );\n+  bool always_reachable(AddressLiteral adr);\n+  bool        reachable(AddressLiteral adr);\n@@ -917,12 +895,0 @@\n-  \/\/ 32BIT ONLY SECTION\n-#ifndef _LP64\n-  \/\/ Make these disappear in 64bit mode since they would never be correct\n-  void cmp_literal32(Register src1, int32_t imm32, RelocationHolder const& rspec);   \/\/ 32BIT ONLY\n-  void cmp_literal32(Address src1, int32_t imm32, RelocationHolder const& rspec);    \/\/ 32BIT ONLY\n-\n-  void mov_literal32(Register dst, int32_t imm32, RelocationHolder const& rspec);    \/\/ 32BIT ONLY\n-  void mov_literal32(Address dst, int32_t imm32, RelocationHolder const& rspec);     \/\/ 32BIT ONLY\n-\n-  void push_literal32(int32_t imm32, RelocationHolder const& rspec);                 \/\/ 32BIT ONLY\n-#else\n-  \/\/ 64BIT ONLY SECTION\n@@ -936,1 +902,0 @@\n-#endif \/\/ _LP64\n@@ -1020,6 +985,0 @@\n-  void set_managed(void) { NOT_LP64(_is_managed = true;) }\n-  void clear_managed(void) { NOT_LP64(_is_managed = false;) }\n-  bool is_managed(void) {\n-    NOT_LP64(return _is_managed;)\n-    LP64_ONLY(return false;) }\n-\n@@ -1030,1 +989,0 @@\n-#ifdef _LP64\n@@ -1050,1 +1008,0 @@\n-#endif\n@@ -1072,1 +1029,0 @@\n-#ifdef _LP64\n@@ -1074,1 +1030,0 @@\n-#endif\n@@ -1124,1 +1079,0 @@\n-#ifdef _LP64\n@@ -1132,1 +1086,0 @@\n-#endif\n@@ -1209,1 +1162,0 @@\n-#ifdef _LP64\n@@ -1212,1 +1164,0 @@\n-#endif\n@@ -1398,4 +1349,0 @@\n-#ifndef _LP64\n-  void emms();\n-#endif \/\/ !_LP64\n-\n@@ -1420,1 +1367,0 @@\n-#ifdef _LP64\n@@ -1425,1 +1371,0 @@\n-#endif\n@@ -1438,1 +1383,0 @@\n-#ifdef _LP64\n@@ -1451,1 +1395,0 @@\n-#endif\n@@ -1503,1 +1446,0 @@\n-#ifdef _LP64\n@@ -1505,1 +1447,0 @@\n-#endif\n@@ -1517,1 +1458,0 @@\n-#ifdef _LP64\n@@ -1522,1 +1462,0 @@\n-#endif\n@@ -1682,1 +1621,0 @@\n-#ifdef _LP64\n@@ -1688,1 +1626,0 @@\n-#endif\n@@ -1703,1 +1640,0 @@\n-#ifdef _LP64\n@@ -1712,1 +1648,0 @@\n-#endif\n@@ -1717,1 +1652,0 @@\n-#ifdef _LP64\n@@ -1720,1 +1654,0 @@\n-#endif\n@@ -1734,1 +1667,0 @@\n-#ifdef _LP64\n@@ -1737,1 +1669,0 @@\n-#endif\n@@ -1742,1 +1673,0 @@\n-#ifdef _LP64\n@@ -1745,1 +1675,0 @@\n-#endif\n@@ -1753,1 +1682,0 @@\n-#ifdef _LP64\n@@ -1759,1 +1687,0 @@\n-#endif\n@@ -1774,1 +1701,0 @@\n-#ifdef _LP64\n@@ -1779,1 +1705,0 @@\n-#endif\n@@ -1786,1 +1711,0 @@\n-#ifdef _LP64\n@@ -1793,1 +1717,0 @@\n-#endif\n@@ -2012,5 +1935,0 @@\n-#ifndef _LP64 \/\/ no 32bit push\/pop on amd64\n-  void popl(Address dst);\n-#endif\n-\n-#ifdef _LP64\n@@ -2019,1 +1937,0 @@\n-#endif\n@@ -2031,1 +1948,0 @@\n-#ifdef _LP64\n@@ -2036,1 +1952,0 @@\n-#endif\n@@ -2128,4 +2043,0 @@\n-#ifndef _LP64 \/\/ no 32bit push\/pop on amd64\n-  void pushl(Address src);\n-#endif\n-\n@@ -2163,1 +2074,0 @@\n-#ifdef _LP64\n@@ -2176,3 +2086,0 @@\n-#endif\n-\n-  void sahf();\n@@ -2198,1 +2105,0 @@\n-#ifdef _LP64\n@@ -2216,1 +2122,0 @@\n-#endif\n@@ -2257,1 +2162,0 @@\n-#ifdef _LP64\n@@ -2262,1 +2166,0 @@\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":5,"deletions":102,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -32,49 +32,1 @@\n-#ifndef _LP64\n-inline int Assembler::prefix_and_encode(int reg_enc, bool byteinst, bool is_map1)\n-{\n-    int opc_prefix = is_map1 ? 0x0F00 : 0;\n-    return opc_prefix | reg_enc;\n-}\n-\n-inline int Assembler::prefixq_and_encode(int reg_enc, bool is_map1) {\n-    int opc_prefix = is_map1 ? 0xF00 : 0;\n-    return opc_prefix | reg_enc;\n-}\n-\n-inline int Assembler::prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte, bool is_map1) {\n-    int opc_prefix = is_map1 ? 0xF00 : 0;\n-    return opc_prefix | (dst_enc << 3 | src_enc);\n-}\n-\n-inline int Assembler::prefixq_and_encode(int dst_enc, int src_enc, bool is_map1) {\n-    int opc_prefix = is_map1 ? 0xF00 : 0;\n-    return opc_prefix | dst_enc << 3 | src_enc;\n-}\n-\n-inline void Assembler::prefix(Register reg) {}\n-inline void Assembler::prefix(Register dst, Register src, Prefix p) {}\n-inline void Assembler::prefix(Register dst, Address adr, Prefix p) {}\n-\n-inline void Assembler::prefix(Address adr, bool is_map1) {\n-    if (is_map1) {\n-        emit_int8(0x0F);\n-    }\n-}\n-\n-inline void Assembler::prefixq(Address adr) {}\n-\n-inline void Assembler::prefix(Address adr, Register reg,  bool byteinst, bool is_map1) {\n-    if (is_map1) {\n-        emit_int8(0x0F);\n-    }\n-}\n-inline void Assembler::prefixq(Address adr, Register reg, bool is_map1) {\n-    if (is_map1) {\n-        emit_int8(0x0F);\n-    }\n-}\n-\n-inline void Assembler::prefix(Address adr, XMMRegister reg) {}\n-inline void Assembler::prefixq(Address adr, XMMRegister reg) {}\n-\n-#endif \/\/ _LP64\n+\/\/ TODO: Remove?\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.inline.hpp","additions":1,"deletions":49,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -96,369 +96,0 @@\n-\/\/ First all the versions that have distinct versions depending on 32\/64 bit\n-\/\/ Unless the difference is trivial (1 line or so).\n-\n-#ifndef _LP64\n-\n-\/\/ 32bit versions\n-\n-Address MacroAssembler::as_Address(AddressLiteral adr) {\n-  return Address(adr.target(), adr.rspec());\n-}\n-\n-Address MacroAssembler::as_Address(ArrayAddress adr, Register rscratch) {\n-  assert(rscratch == noreg, \"\");\n-  return Address::make_array(adr);\n-}\n-\n-void MacroAssembler::call_VM_leaf_base(address entry_point,\n-                                       int number_of_arguments) {\n-  call(RuntimeAddress(entry_point));\n-  increment(rsp, number_of_arguments * wordSize);\n-}\n-\n-void MacroAssembler::cmpklass(Address src1, Metadata* obj) {\n-  cmp_literal32(src1, (int32_t)obj, metadata_Relocation::spec_for_immediate());\n-}\n-\n-\n-void MacroAssembler::cmpklass(Register src1, Metadata* obj) {\n-  cmp_literal32(src1, (int32_t)obj, metadata_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::cmpoop(Address src1, jobject obj) {\n-  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::cmpoop(Register src1, jobject obj, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::extend_sign(Register hi, Register lo) {\n-  \/\/ According to Intel Doc. AP-526, \"Integer Divide\", p.18.\n-  if (VM_Version::is_P6() && hi == rdx && lo == rax) {\n-    cdql();\n-  } else {\n-    movl(hi, lo);\n-    sarl(hi, 31);\n-  }\n-}\n-\n-\/\/ 32bit can do a case table jump in one instruction but we no longer allow the base\n-\/\/ to be installed in the Address class\n-void MacroAssembler::jump(ArrayAddress entry, Register rscratch) {\n-  assert(rscratch == noreg, \"not needed\");\n-  jmp(as_Address(entry, noreg));\n-}\n-\n-\/\/ Note: y_lo will be destroyed\n-void MacroAssembler::lcmp2int(Register x_hi, Register x_lo, Register y_hi, Register y_lo) {\n-  \/\/ Long compare for Java (semantics as described in JVM spec.)\n-  Label high, low, done;\n-\n-  cmpl(x_hi, y_hi);\n-  jcc(Assembler::less, low);\n-  jcc(Assembler::greater, high);\n-  \/\/ x_hi is the return register\n-  xorl(x_hi, x_hi);\n-  cmpl(x_lo, y_lo);\n-  jcc(Assembler::below, low);\n-  jcc(Assembler::equal, done);\n-\n-  bind(high);\n-  xorl(x_hi, x_hi);\n-  increment(x_hi);\n-  jmp(done);\n-\n-  bind(low);\n-  xorl(x_hi, x_hi);\n-  decrementl(x_hi);\n-\n-  bind(done);\n-}\n-\n-void MacroAssembler::lea(Register dst, AddressLiteral src) {\n-  mov_literal32(dst, (int32_t)src.target(), src.rspec());\n-}\n-\n-void MacroAssembler::lea(Address dst, AddressLiteral adr, Register rscratch) {\n-  assert(rscratch == noreg, \"not needed\");\n-\n-  \/\/ leal(dst, as_Address(adr));\n-  \/\/ see note in movl as to why we must use a move\n-  mov_literal32(dst, (int32_t)adr.target(), adr.rspec());\n-}\n-\n-void MacroAssembler::leave() {\n-  mov(rsp, rbp);\n-  pop(rbp);\n-}\n-\n-void MacroAssembler::lmul(int x_rsp_offset, int y_rsp_offset) {\n-  \/\/ Multiplication of two Java long values stored on the stack\n-  \/\/ as illustrated below. Result is in rdx:rax.\n-  \/\/\n-  \/\/ rsp ---> [  ??  ] \\               \\\n-  \/\/            ....    | y_rsp_offset  |\n-  \/\/          [ y_lo ] \/  (in bytes)    | x_rsp_offset\n-  \/\/          [ y_hi ]                  | (in bytes)\n-  \/\/            ....                    |\n-  \/\/          [ x_lo ]                 \/\n-  \/\/          [ x_hi ]\n-  \/\/            ....\n-  \/\/\n-  \/\/ Basic idea: lo(result) = lo(x_lo * y_lo)\n-  \/\/             hi(result) = hi(x_lo * y_lo) + lo(x_hi * y_lo) + lo(x_lo * y_hi)\n-  Address x_hi(rsp, x_rsp_offset + wordSize); Address x_lo(rsp, x_rsp_offset);\n-  Address y_hi(rsp, y_rsp_offset + wordSize); Address y_lo(rsp, y_rsp_offset);\n-  Label quick;\n-  \/\/ load x_hi, y_hi and check if quick\n-  \/\/ multiplication is possible\n-  movl(rbx, x_hi);\n-  movl(rcx, y_hi);\n-  movl(rax, rbx);\n-  orl(rbx, rcx);                                 \/\/ rbx, = 0 <=> x_hi = 0 and y_hi = 0\n-  jcc(Assembler::zero, quick);                   \/\/ if rbx, = 0 do quick multiply\n-  \/\/ do full multiplication\n-  \/\/ 1st step\n-  mull(y_lo);                                    \/\/ x_hi * y_lo\n-  movl(rbx, rax);                                \/\/ save lo(x_hi * y_lo) in rbx,\n-  \/\/ 2nd step\n-  movl(rax, x_lo);\n-  mull(rcx);                                     \/\/ x_lo * y_hi\n-  addl(rbx, rax);                                \/\/ add lo(x_lo * y_hi) to rbx,\n-  \/\/ 3rd step\n-  bind(quick);                                   \/\/ note: rbx, = 0 if quick multiply!\n-  movl(rax, x_lo);\n-  mull(y_lo);                                    \/\/ x_lo * y_lo\n-  addl(rdx, rbx);                                \/\/ correct hi(x_lo * y_lo)\n-}\n-\n-void MacroAssembler::lneg(Register hi, Register lo) {\n-  negl(lo);\n-  adcl(hi, 0);\n-  negl(hi);\n-}\n-\n-void MacroAssembler::lshl(Register hi, Register lo) {\n-  \/\/ Java shift left long support (semantics as described in JVM spec., p.305)\n-  \/\/ (basic idea for shift counts s >= n: x << s == (x << n) << (s - n))\n-  \/\/ shift value is in rcx !\n-  assert(hi != rcx, \"must not use rcx\");\n-  assert(lo != rcx, \"must not use rcx\");\n-  const Register s = rcx;                        \/\/ shift count\n-  const int      n = BitsPerWord;\n-  Label L;\n-  andl(s, 0x3f);                                 \/\/ s := s & 0x3f (s < 0x40)\n-  cmpl(s, n);                                    \/\/ if (s < n)\n-  jcc(Assembler::less, L);                       \/\/ else (s >= n)\n-  movl(hi, lo);                                  \/\/ x := x << n\n-  xorl(lo, lo);\n-  \/\/ Note: subl(s, n) is not needed since the Intel shift instructions work rcx mod n!\n-  bind(L);                                       \/\/ s (mod n) < n\n-  shldl(hi, lo);                                 \/\/ x := x << s\n-  shll(lo);\n-}\n-\n-\n-void MacroAssembler::lshr(Register hi, Register lo, bool sign_extension) {\n-  \/\/ Java shift right long support (semantics as described in JVM spec., p.306 & p.310)\n-  \/\/ (basic idea for shift counts s >= n: x >> s == (x >> n) >> (s - n))\n-  assert(hi != rcx, \"must not use rcx\");\n-  assert(lo != rcx, \"must not use rcx\");\n-  const Register s = rcx;                        \/\/ shift count\n-  const int      n = BitsPerWord;\n-  Label L;\n-  andl(s, 0x3f);                                 \/\/ s := s & 0x3f (s < 0x40)\n-  cmpl(s, n);                                    \/\/ if (s < n)\n-  jcc(Assembler::less, L);                       \/\/ else (s >= n)\n-  movl(lo, hi);                                  \/\/ x := x >> n\n-  if (sign_extension) sarl(hi, 31);\n-  else                xorl(hi, hi);\n-  \/\/ Note: subl(s, n) is not needed since the Intel shift instructions work rcx mod n!\n-  bind(L);                                       \/\/ s (mod n) < n\n-  shrdl(lo, hi);                                 \/\/ x := x >> s\n-  if (sign_extension) sarl(hi);\n-  else                shrl(hi);\n-}\n-\n-void MacroAssembler::movoop(Register dst, jobject obj) {\n-  mov_literal32(dst, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::movoop(Address dst, jobject obj, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  mov_literal32(dst, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::mov_metadata(Register dst, Metadata* obj) {\n-  mov_literal32(dst, (int32_t)obj, metadata_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::mov_metadata(Address dst, Metadata* obj, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  mov_literal32(dst, (int32_t)obj, metadata_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::movptr(Register dst, AddressLiteral src) {\n-  if (src.is_lval()) {\n-    mov_literal32(dst, (intptr_t)src.target(), src.rspec());\n-  } else {\n-    movl(dst, as_Address(src));\n-  }\n-}\n-\n-void MacroAssembler::movptr(ArrayAddress dst, Register src, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  movl(as_Address(dst, noreg), src);\n-}\n-\n-void MacroAssembler::movptr(Register dst, ArrayAddress src) {\n-  movl(dst, as_Address(src, noreg));\n-}\n-\n-void MacroAssembler::movptr(Address dst, intptr_t src, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  movl(dst, src);\n-}\n-\n-void MacroAssembler::pushoop(jobject obj, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  push_literal32((int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::pushklass(Metadata* obj, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  push_literal32((int32_t)obj, metadata_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::pushptr(AddressLiteral src, Register rscratch) {\n-  assert(rscratch == noreg, \"redundant\");\n-  if (src.is_lval()) {\n-    push_literal32((int32_t)src.target(), src.rspec());\n-  } else {\n-    pushl(as_Address(src));\n-  }\n-}\n-\n-static void pass_arg0(MacroAssembler* masm, Register arg) {\n-  masm->push(arg);\n-}\n-\n-static void pass_arg1(MacroAssembler* masm, Register arg) {\n-  masm->push(arg);\n-}\n-\n-static void pass_arg2(MacroAssembler* masm, Register arg) {\n-  masm->push(arg);\n-}\n-\n-static void pass_arg3(MacroAssembler* masm, Register arg) {\n-  masm->push(arg);\n-}\n-\n-#ifndef PRODUCT\n-extern \"C\" void findpc(intptr_t x);\n-#endif\n-\n-void MacroAssembler::debug32(int rdi, int rsi, int rbp, int rsp, int rbx, int rdx, int rcx, int rax, int eip, char* msg) {\n-  \/\/ In order to get locks to work, we need to fake a in_VM state\n-  JavaThread* thread = JavaThread::current();\n-  JavaThreadState saved_state = thread->thread_state();\n-  thread->set_thread_state(_thread_in_vm);\n-  if (ShowMessageBoxOnError) {\n-    JavaThread* thread = JavaThread::current();\n-    JavaThreadState saved_state = thread->thread_state();\n-    thread->set_thread_state(_thread_in_vm);\n-    if (CountBytecodes || TraceBytecodes || StopInterpreterAt) {\n-      ttyLocker ttyl;\n-      BytecodeCounter::print();\n-    }\n-    \/\/ To see where a verify_oop failed, get $ebx+40\/X for this frame.\n-    \/\/ This is the value of eip which points to where verify_oop will return.\n-    if (os::message_box(msg, \"Execution stopped, print registers?\")) {\n-      print_state32(rdi, rsi, rbp, rsp, rbx, rdx, rcx, rax, eip);\n-      BREAKPOINT;\n-    }\n-  }\n-  fatal(\"DEBUG MESSAGE: %s\", msg);\n-}\n-\n-void MacroAssembler::print_state32(int rdi, int rsi, int rbp, int rsp, int rbx, int rdx, int rcx, int rax, int eip) {\n-  ttyLocker ttyl;\n-  DebuggingContext debugging{};\n-  tty->print_cr(\"eip = 0x%08x\", eip);\n-#ifndef PRODUCT\n-  if ((WizardMode || Verbose) && PrintMiscellaneous) {\n-    tty->cr();\n-    findpc(eip);\n-    tty->cr();\n-  }\n-#endif\n-#define PRINT_REG(rax) \\\n-  { tty->print(\"%s = \", #rax); os::print_location(tty, rax); }\n-  PRINT_REG(rax);\n-  PRINT_REG(rbx);\n-  PRINT_REG(rcx);\n-  PRINT_REG(rdx);\n-  PRINT_REG(rdi);\n-  PRINT_REG(rsi);\n-  PRINT_REG(rbp);\n-  PRINT_REG(rsp);\n-#undef PRINT_REG\n-  \/\/ Print some words near top of staack.\n-  int* dump_sp = (int*) rsp;\n-  for (int col1 = 0; col1 < 8; col1++) {\n-    tty->print(\"(rsp+0x%03x) 0x%08x: \", (int)((intptr_t)dump_sp - (intptr_t)rsp), (intptr_t)dump_sp);\n-    os::print_location(tty, *dump_sp++);\n-  }\n-  for (int row = 0; row < 16; row++) {\n-    tty->print(\"(rsp+0x%03x) 0x%08x: \", (int)((intptr_t)dump_sp - (intptr_t)rsp), (intptr_t)dump_sp);\n-    for (int col = 0; col < 8; col++) {\n-      tty->print(\" 0x%08x\", *dump_sp++);\n-    }\n-    tty->cr();\n-  }\n-  \/\/ Print some instructions around pc:\n-  Disassembler::decode((address)eip-64, (address)eip);\n-  tty->print_cr(\"--------\");\n-  Disassembler::decode((address)eip, (address)eip+32);\n-}\n-\n-void MacroAssembler::stop(const char* msg) {\n-  \/\/ push address of message\n-  ExternalAddress message((address)msg);\n-  pushptr(message.addr(), noreg);\n-  { Label L; call(L, relocInfo::none); bind(L); }     \/\/ push eip\n-  pusha();                                            \/\/ push registers\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::debug32)));\n-  hlt();\n-}\n-\n-void MacroAssembler::warn(const char* msg) {\n-  push_CPU_state();\n-\n-  \/\/ push address of message\n-  ExternalAddress message((address)msg);\n-  pushptr(message.addr(), noreg);\n-\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, warning)));\n-  addl(rsp, wordSize);       \/\/ discard argument\n-  pop_CPU_state();\n-}\n-\n-void MacroAssembler::print_state() {\n-  { Label L; call(L, relocInfo::none); bind(L); }     \/\/ push eip\n-  pusha();                                            \/\/ push registers\n-\n-  push_CPU_state();\n-  call(RuntimeAddress(CAST_FROM_FN_PTR(address, MacroAssembler::print_state32)));\n-  pop_CPU_state();\n-\n-  popa();\n-  addl(rsp, wordSize);\n-}\n-\n-#else \/\/ _LP64\n-\n-\/\/ 64 bit versions\n-\n@@ -1076,4 +707,0 @@\n-#endif \/\/ _LP64\n-\n-\/\/ Now versions that are common to 32\/64 bit\n-\n@@ -1081,1 +708,1 @@\n-  LP64_ONLY(addq(dst, imm32)) NOT_LP64(addl(dst, imm32));\n+  addq(dst, imm32);\n@@ -1085,1 +712,1 @@\n-  LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src));\n+  addq(dst, src);\n@@ -1089,1 +716,1 @@\n-  LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src));\n+  addq(dst, src);\n@@ -1199,1 +826,1 @@\n-  LP64_ONLY(andq(dst, imm32)) NOT_LP64(andl(dst, imm32));\n+  andq(dst, imm32);\n@@ -1202,1 +829,0 @@\n-#ifdef _LP64\n@@ -1213,1 +839,0 @@\n-#endif\n@@ -1231,1 +856,0 @@\n-#ifdef _LP64\n@@ -1247,1 +871,0 @@\n-#endif\n@@ -1279,2 +902,0 @@\n-  Register thread = NOT_LP64(rsi) LP64_ONLY(r15_thread);\n-  NOT_LP64(get_thread(rsi);)\n@@ -1282,1 +903,1 @@\n-  cmpptr(rsp, Address(thread, JavaThread::reserved_stack_activation_offset()));\n+  cmpptr(rsp, Address(r15_thread, JavaThread::reserved_stack_activation_offset()));\n@@ -1285,1 +906,1 @@\n-  call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), thread);\n+  call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), r15_thread);\n@@ -1323,1 +944,0 @@\n-#ifdef _LP64\n@@ -1326,3 +946,0 @@\n-#else\n-  movptr(rax, (intptr_t)Universe::non_oop_word());\n-#endif\n@@ -1333,2 +950,1 @@\n-  return\n-      LP64_ONLY(UseCompactObjectHeaders ? 17 : 14) NOT_LP64(12);\n+  return UseCompactObjectHeaders ? 17 : 14;\n@@ -1338,1 +954,1 @@\n-  Register receiver = LP64_ONLY(j_rarg0) NOT_LP64(rcx);\n+  Register receiver = j_rarg0;\n@@ -1340,1 +956,1 @@\n-  Register temp = LP64_ONLY(rscratch1) NOT_LP64(rbx);\n+  Register temp = rscratch1;\n@@ -1350,1 +966,0 @@\n-#ifdef _LP64\n@@ -1354,3 +969,1 @@\n-  } else\n-#endif\n-  if (UseCompressedClassPointers) {\n+  } else if (UseCompressedClassPointers) {\n@@ -1421,1 +1034,1 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2));\n+  assert_different_registers(arg_1, c_rarg2);\n@@ -1443,2 +1056,2 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_2, c_rarg3));\n+  assert_different_registers(arg_1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_2, c_rarg3);\n@@ -1478,1 +1091,1 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2));\n+  assert_different_registers(arg_1, c_rarg2);\n@@ -1491,2 +1104,2 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_2, c_rarg3));\n+  assert_different_registers(arg_1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_2, c_rarg3);\n@@ -1523,1 +1136,1 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2));\n+  assert_different_registers(arg_1, c_rarg2);\n@@ -1536,2 +1149,2 @@\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_2, c_rarg3));\n+  assert_different_registers(arg_1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_2, c_rarg3);\n@@ -1648,1 +1261,1 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1));\n+  assert_different_registers(arg_0, c_rarg1);\n@@ -1655,2 +1268,2 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1, c_rarg2));\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2));\n+  assert_different_registers(arg_0, c_rarg1, c_rarg2);\n+  assert_different_registers(arg_1, c_rarg2);\n@@ -1664,3 +1277,3 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_2, c_rarg3));\n+  assert_different_registers(arg_0, c_rarg1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_2, c_rarg3);\n@@ -1680,1 +1293,1 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1));\n+  assert_different_registers(arg_0, c_rarg1);\n@@ -1687,2 +1300,2 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1, c_rarg2));\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2));\n+  assert_different_registers(arg_0, c_rarg1, c_rarg2);\n+  assert_different_registers(arg_1, c_rarg2);\n@@ -1696,3 +1309,3 @@\n-  LP64_ONLY(assert_different_registers(arg_0, c_rarg1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_1, c_rarg2, c_rarg3));\n-  LP64_ONLY(assert_different_registers(arg_2, c_rarg3));\n+  assert_different_registers(arg_0, c_rarg1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_1, c_rarg2, c_rarg3);\n+  assert_different_registers(arg_2, c_rarg3);\n@@ -1811,1 +1424,0 @@\n-#ifdef _LP64\n@@ -1823,8 +1435,0 @@\n-#else\n-  assert(rscratch == noreg, \"not needed\");\n-  if (src2.is_lval()) {\n-    cmp_literal32(src1, (int32_t)src2.target(), src2.rspec());\n-  } else {\n-    cmpl(src1, as_Address(src2));\n-  }\n-#endif \/\/ _LP64\n@@ -1835,1 +1439,0 @@\n-#ifdef _LP64\n@@ -1839,4 +1442,0 @@\n-#else\n-  assert(rscratch == noreg, \"not needed\");\n-  cmp_literal32(src1, (int32_t)src2.target(), src2.rspec());\n-#endif \/\/ _LP64\n@@ -1853,1 +1452,0 @@\n-#ifdef _LP64\n@@ -1858,1 +1456,0 @@\n-#endif\n@@ -1874,1 +1471,1 @@\n-  LP64_ONLY(cmpxchgq(reg, adr)) NOT_LP64(cmpxchgl(reg, adr));\n+  cmpxchgq(reg, adr);\n@@ -2196,9 +1793,2 @@\n-  int off;\n-  if (LP64_ONLY(true ||) VM_Version::is_P6()) {\n-    off = offset();\n-    movsbl(dst, src); \/\/ movsxb\n-  } else {\n-    off = load_unsigned_byte(dst, src);\n-    shll(dst, 24);\n-    sarl(dst, 24);\n-  }\n+  int off = offset();\n+  movsbl(dst, src); \/\/ movsxb\n@@ -2213,12 +1803,5 @@\n-  int off;\n-  if (LP64_ONLY(true ||) VM_Version::is_P6()) {\n-    \/\/ This is dubious to me since it seems safe to do a signed 16 => 64 bit\n-    \/\/ version but this is what 64bit has always done. This seems to imply\n-    \/\/ that users are only using 32bits worth.\n-    off = offset();\n-    movswl(dst, src); \/\/ movsxw\n-  } else {\n-    off = load_unsigned_short(dst, src);\n-    shll(dst, 16);\n-    sarl(dst, 16);\n-  }\n+  \/\/ This is dubious to me since it seems safe to do a signed 16 => 64 bit\n+  \/\/ version but this is what 64bit has always done. This seems to imply\n+  \/\/ that users are only using 32bits worth.\n+  int off = offset();\n+  movswl(dst, src); \/\/ movsxw\n@@ -2231,9 +1814,2 @@\n-  int off;\n-  if (LP64_ONLY(true || ) VM_Version::is_P6() || src.uses(dst)) {\n-    off = offset();\n-    movzbl(dst, src); \/\/ movzxb\n-  } else {\n-    xorl(dst, dst);\n-    off = offset();\n-    movb(dst, src);\n-  }\n+  int off = offset();\n+  movzbl(dst, src); \/\/ movzxb\n@@ -2247,9 +1823,2 @@\n-  int off;\n-  if (LP64_ONLY(true ||) VM_Version::is_P6() || src.uses(dst)) {\n-    off = offset();\n-    movzwl(dst, src); \/\/ movzxw\n-  } else {\n-    xorl(dst, dst);\n-    off = offset();\n-    movw(dst, src);\n-  }\n+  int off = offset();\n+  movzwl(dst, src); \/\/ movzxw\n@@ -2261,7 +1830,0 @@\n-#ifndef _LP64\n-  case  8:\n-    assert(dst2 != noreg, \"second dest register required\");\n-    movl(dst,  src);\n-    movl(dst2, src.plus_disp(BytesPerInt));\n-    break;\n-#else\n@@ -2269,1 +1831,0 @@\n-#endif\n@@ -2279,7 +1840,0 @@\n-#ifndef _LP64\n-  case  8:\n-    assert(src2 != noreg, \"second source register required\");\n-    movl(dst,                        src);\n-    movl(dst.plus_disp(BytesPerInt), src2);\n-    break;\n-#else\n@@ -2287,1 +1841,0 @@\n-#endif\n@@ -2406,1 +1959,1 @@\n-  LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));\n+  movq(dst, src);\n@@ -2410,1 +1963,1 @@\n-  LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));\n+  movq(dst, src);\n@@ -2415,1 +1968,0 @@\n-#ifdef _LP64\n@@ -2423,3 +1975,0 @@\n-#else\n-  movl(dst, src);\n-#endif\n@@ -2429,1 +1978,1 @@\n-  LP64_ONLY(movq(dst, src)) NOT_LP64(movl(dst, src));\n+  movq(dst, src);\n@@ -2433,1 +1982,1 @@\n-  LP64_ONLY(movslq(dst, src)) NOT_LP64(movl(dst, src));\n+  movslq(dst, src);\n@@ -2811,1 +2360,0 @@\n-#ifdef _LP64\n@@ -2813,1 +2361,0 @@\n-#endif\n@@ -2821,3 +2368,0 @@\n-#ifndef _LP64\n-  frstor(Address(rsp, 0));\n-#else\n@@ -2825,1 +2369,0 @@\n-#endif\n@@ -2831,1 +2374,1 @@\n-  LP64_ONLY(addq(rsp, 8));\n+  addq(rsp, 8);\n@@ -2844,4 +2387,0 @@\n-#ifndef _LP64\n-  fnsave(Address(rsp, 0));\n-  fwait();\n-#else\n@@ -2849,1 +2388,0 @@\n-#endif \/\/ LP64\n@@ -2856,1 +2394,1 @@\n-  LP64_ONLY(subq(rsp, 8));\n+  subq(rsp, 8);\n@@ -2966,1 +2504,1 @@\n-  LP64_ONLY(shlq(dst, imm8)) NOT_LP64(shll(dst, imm8));\n+  shlq(dst, imm8);\n@@ -2970,1 +2508,1 @@\n-  LP64_ONLY(shrq(dst, imm8)) NOT_LP64(shrl(dst, imm8));\n+  shrq(dst, imm8);\n@@ -2974,6 +2512,1 @@\n-  if (LP64_ONLY(true ||) (VM_Version::is_P6() && reg->has_byte_register())) {\n-    movsbl(reg, reg); \/\/ movsxb\n-  } else {\n-    shll(reg, 24);\n-    sarl(reg, 24);\n-  }\n+  movsbl(reg, reg); \/\/ movsxb\n@@ -2983,6 +2516,1 @@\n-  if (LP64_ONLY(true ||) VM_Version::is_P6()) {\n-    movswl(reg, reg); \/\/ movsxw\n-  } else {\n-    shll(reg, 16);\n-    sarl(reg, 16);\n-  }\n+  movswl(reg, reg); \/\/ movsxw\n@@ -3012,2 +2540,0 @@\n-#ifdef _LP64\n-\n@@ -3030,2 +2556,0 @@\n-#endif\n-\n@@ -3877,1 +3401,1 @@\n-  LP64_ONLY(subq(dst, imm32)) NOT_LP64(subl(dst, imm32));\n+  subq(dst, imm32);\n@@ -3882,1 +3406,1 @@\n-  LP64_ONLY(subq_imm32(dst, imm32)) NOT_LP64(subl_imm32(dst, imm32));\n+  subq_imm32(dst, imm32);\n@@ -3886,1 +3410,1 @@\n-  LP64_ONLY(subq(dst, src)) NOT_LP64(subl(dst, src));\n+  subq(dst, src);\n@@ -3904,1 +3428,1 @@\n-  LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));\n+  testq(dst, src);\n@@ -3920,1 +3444,0 @@\n-#ifdef _LP64\n@@ -3926,4 +3449,0 @@\n-#else\n-  regs += RegSet::of(rax, rcx, rdx);\n-#endif\n-#ifdef _LP64\n@@ -3933,1 +3452,0 @@\n-#endif\n@@ -4103,15 +3621,1 @@\n-#ifndef _LP64\n-  \/\/ index could have not been a multiple of 8 (i.e., bit 2 was set)\n-  {\n-    Label even;\n-    \/\/ note: if index was a multiple of 8, then it cannot\n-    \/\/       be 0 now otherwise it must have been 0 before\n-    \/\/       => if it is even, we don't need to check for 0 again\n-    jcc(Assembler::carryClear, even);\n-    \/\/ clear topmost word (no jump would be needed if conditional assignment worked here)\n-    movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);\n-    \/\/ index could be 0 now, must check again\n-    jcc(Assembler::zero, done);\n-    bind(even);\n-  }\n-#endif \/\/ !_LP64\n+\n@@ -4123,1 +3627,0 @@\n-    NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)\n@@ -4500,3 +4003,2 @@\n-  NOT_LP64(  incrementl(pst_counter_addr) );\n-  LP64_ONLY( lea(rcx, pst_counter_addr) );\n-  LP64_ONLY( incrementl(Address(rcx, 0)) );\n+  lea(rcx, pst_counter_addr);\n+  incrementl(Address(rcx, 0));\n@@ -4548,16 +4050,0 @@\n-#ifndef _LP64\n-\n-\/\/ 32-bit x86 only: always use the linear search.\n-void MacroAssembler::check_klass_subtype_slow_path(Register sub_klass,\n-                                                   Register super_klass,\n-                                                   Register temp_reg,\n-                                                   Register temp2_reg,\n-                                                   Label* L_success,\n-                                                   Label* L_failure,\n-                                                   bool set_cond_codes) {\n-  check_klass_subtype_slow_path_linear\n-    (sub_klass, super_klass, temp_reg, temp2_reg, L_success, L_failure, set_cond_codes);\n-}\n-\n-#else \/\/ _LP64\n-\n@@ -5147,2 +4633,0 @@\n-#endif \/\/ LP64\n-\n@@ -5203,1 +4687,0 @@\n-#ifdef _LP64\n@@ -5205,1 +4688,0 @@\n-#endif\n@@ -5263,1 +4745,0 @@\n-#ifdef _LP64\n@@ -5265,1 +4746,0 @@\n-#endif\n@@ -5273,1 +4753,1 @@\n-    pushptr(Address(rax, LP64_ONLY(2 *) BytesPerWord));\n+    pushptr(Address(rax, 2 * BytesPerWord));\n@@ -5300,1 +4780,0 @@\n-    Register thread_reg = NOT_LP64(rbx) LP64_ONLY(r15_thread);\n@@ -5303,2 +4782,0 @@\n-    NOT_LP64(push(thread_reg));\n-    NOT_LP64(get_thread(thread_reg));\n@@ -5306,2 +4783,2 @@\n-    movptr(t1, Address(thread_reg, in_bytes(JavaThread::tlab_top_offset())));\n-    cmpptr(t1, Address(thread_reg, in_bytes(JavaThread::tlab_start_offset())));\n+    movptr(t1, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));\n+    cmpptr(t1, Address(r15_thread, in_bytes(JavaThread::tlab_start_offset())));\n@@ -5313,2 +4790,2 @@\n-    movptr(t1, Address(thread_reg, in_bytes(JavaThread::tlab_end_offset())));\n-    cmpptr(t1, Address(thread_reg, in_bytes(JavaThread::tlab_top_offset())));\n+    movptr(t1, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));\n+    cmpptr(t1, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));\n@@ -5320,1 +4797,0 @@\n-    NOT_LP64(pop(thread_reg));\n@@ -5661,1 +5137,0 @@\n-#ifdef _LP64\n@@ -5667,1 +5142,0 @@\n-#endif\n@@ -5672,1 +5146,1 @@\n-#ifdef _LP64\n+\n@@ -5679,3 +5153,1 @@\n-  } else\n-#endif\n-  {\n+  } else {\n@@ -5690,1 +5162,0 @@\n-#ifdef _LP64\n@@ -5694,2 +5165,1 @@\n-  } else\n-#endif\n+  } else {\n@@ -5697,0 +5167,1 @@\n+  }\n@@ -5700,1 +5171,0 @@\n-#ifdef _LP64\n@@ -5708,3 +5178,1 @@\n-  } else\n-#endif\n-  {\n+  } else {\n@@ -5716,1 +5184,0 @@\n-#ifdef _LP64\n@@ -5726,3 +5193,1 @@\n-  } else\n-#endif\n-  {\n+  } else {\n@@ -5777,1 +5242,0 @@\n-#ifdef _LP64\n@@ -6099,2 +5563,0 @@\n-#endif \/\/ _LP64\n-\n@@ -6279,2 +5741,0 @@\n-    NOT_LP64(shlptr(cnt, 1);) \/\/ convert to number of 32-bit words for 32-bit VM\n-\n@@ -6301,1 +5761,0 @@\n-    NOT_LP64(shlptr(cnt, 1);) \/\/ convert to number of 32-bit words for 32-bit VM\n@@ -6319,1 +5778,1 @@\n-#if defined(COMPILER2) && defined(_LP64)\n+#if defined(COMPILER2)\n@@ -6699,1 +6158,0 @@\n-#ifdef _LP64\n@@ -7874,1 +7332,0 @@\n-#endif\n@@ -8097,1 +7554,0 @@\n-#ifdef _LP64\n@@ -8615,78 +8071,0 @@\n-#else\n-void MacroAssembler::crc32c_ipl_alg4(Register in_out, uint32_t n,\n-                                     Register tmp1, Register tmp2, Register tmp3,\n-                                     XMMRegister xtmp1, XMMRegister xtmp2) {\n-  lea(tmp3, ExternalAddress(StubRoutines::crc32c_table_addr()));\n-  if (n > 0) {\n-    addl(tmp3, n * 256 * 8);\n-  }\n-  \/\/    Q1 = TABLEExt[n][B & 0xFF];\n-  movl(tmp1, in_out);\n-  andl(tmp1, 0x000000FF);\n-  shll(tmp1, 3);\n-  addl(tmp1, tmp3);\n-  movq(xtmp1, Address(tmp1, 0));\n-\n-  \/\/    Q2 = TABLEExt[n][B >> 8 & 0xFF];\n-  movl(tmp2, in_out);\n-  shrl(tmp2, 8);\n-  andl(tmp2, 0x000000FF);\n-  shll(tmp2, 3);\n-  addl(tmp2, tmp3);\n-  movq(xtmp2, Address(tmp2, 0));\n-\n-  psllq(xtmp2, 8);\n-  pxor(xtmp1, xtmp2);\n-\n-  \/\/    Q3 = TABLEExt[n][B >> 16 & 0xFF];\n-  movl(tmp2, in_out);\n-  shrl(tmp2, 16);\n-  andl(tmp2, 0x000000FF);\n-  shll(tmp2, 3);\n-  addl(tmp2, tmp3);\n-  movq(xtmp2, Address(tmp2, 0));\n-\n-  psllq(xtmp2, 16);\n-  pxor(xtmp1, xtmp2);\n-\n-  \/\/    Q4 = TABLEExt[n][B >> 24 & 0xFF];\n-  shrl(in_out, 24);\n-  andl(in_out, 0x000000FF);\n-  shll(in_out, 3);\n-  addl(in_out, tmp3);\n-  movq(xtmp2, Address(in_out, 0));\n-\n-  psllq(xtmp2, 24);\n-  pxor(xtmp1, xtmp2); \/\/ Result in CXMM\n-  \/\/    return Q1 ^ Q2 << 8 ^ Q3 << 16 ^ Q4 << 24;\n-}\n-\n-void MacroAssembler::crc32c_pclmulqdq(XMMRegister w_xtmp1,\n-                                      Register in_out,\n-                                      uint32_t const_or_pre_comp_const_index, bool is_pclmulqdq_supported,\n-                                      XMMRegister w_xtmp2,\n-                                      Register tmp1,\n-                                      Register n_tmp2, Register n_tmp3) {\n-  if (is_pclmulqdq_supported) {\n-    movdl(w_xtmp1, in_out);\n-\n-    movl(tmp1, const_or_pre_comp_const_index);\n-    movdl(w_xtmp2, tmp1);\n-    pclmulqdq(w_xtmp1, w_xtmp2, 0);\n-    \/\/ Keep result in XMM since GPR is 32 bit in length\n-  } else {\n-    crc32c_ipl_alg4(in_out, const_or_pre_comp_const_index, tmp1, n_tmp2, n_tmp3, w_xtmp1, w_xtmp2);\n-  }\n-}\n-\n-void MacroAssembler::crc32c_rec_alt2(uint32_t const_or_pre_comp_const_index_u1, uint32_t const_or_pre_comp_const_index_u2, bool is_pclmulqdq_supported, Register in_out, Register in1, Register in2,\n-                                     XMMRegister w_xtmp1, XMMRegister w_xtmp2, XMMRegister w_xtmp3,\n-                                     Register tmp1, Register tmp2,\n-                                     Register n_tmp3) {\n-  crc32c_pclmulqdq(w_xtmp1, in_out, const_or_pre_comp_const_index_u1, is_pclmulqdq_supported, w_xtmp3, tmp1, tmp2, n_tmp3);\n-  crc32c_pclmulqdq(w_xtmp2, in1, const_or_pre_comp_const_index_u2, is_pclmulqdq_supported, w_xtmp3, tmp1, tmp2, n_tmp3);\n-\n-  psllq(w_xtmp1, 1);\n-  movdl(tmp1, w_xtmp1);\n-  psrlq(w_xtmp1, 32);\n-  movdl(in_out, w_xtmp1);\n@@ -8694,70 +8072,0 @@\n-  xorl(tmp2, tmp2);\n-  crc32(tmp2, tmp1, 4);\n-  xorl(in_out, tmp2);\n-\n-  psllq(w_xtmp2, 1);\n-  movdl(tmp1, w_xtmp2);\n-  psrlq(w_xtmp2, 32);\n-  movdl(in1, w_xtmp2);\n-\n-  xorl(tmp2, tmp2);\n-  crc32(tmp2, tmp1, 4);\n-  xorl(in1, tmp2);\n-  xorl(in_out, in1);\n-  xorl(in_out, in2);\n-}\n-\n-void MacroAssembler::crc32c_proc_chunk(uint32_t size, uint32_t const_or_pre_comp_const_index_u1, uint32_t const_or_pre_comp_const_index_u2, bool is_pclmulqdq_supported,\n-                                       Register in_out1, Register in_out2, Register in_out3,\n-                                       Register tmp1, Register tmp2, Register tmp3,\n-                                       XMMRegister w_xtmp1, XMMRegister w_xtmp2, XMMRegister w_xtmp3,\n-                                       Register tmp4, Register tmp5,\n-                                       Register n_tmp6) {\n-  Label L_processPartitions;\n-  Label L_processPartition;\n-  Label L_exit;\n-\n-  bind(L_processPartitions);\n-  cmpl(in_out1, 3 * size);\n-  jcc(Assembler::less, L_exit);\n-    xorl(tmp1, tmp1);\n-    xorl(tmp2, tmp2);\n-    movl(tmp3, in_out2);\n-    addl(tmp3, size);\n-\n-    bind(L_processPartition);\n-      crc32(in_out3, Address(in_out2, 0), 4);\n-      crc32(tmp1, Address(in_out2, size), 4);\n-      crc32(tmp2, Address(in_out2, size*2), 4);\n-      crc32(in_out3, Address(in_out2, 0+4), 4);\n-      crc32(tmp1, Address(in_out2, size+4), 4);\n-      crc32(tmp2, Address(in_out2, size*2+4), 4);\n-      addl(in_out2, 8);\n-      cmpl(in_out2, tmp3);\n-      jcc(Assembler::less, L_processPartition);\n-\n-        push(tmp3);\n-        push(in_out1);\n-        push(in_out2);\n-        tmp4 = tmp3;\n-        tmp5 = in_out1;\n-        n_tmp6 = in_out2;\n-\n-      crc32c_rec_alt2(const_or_pre_comp_const_index_u1, const_or_pre_comp_const_index_u2, is_pclmulqdq_supported, in_out3, tmp1, tmp2,\n-            w_xtmp1, w_xtmp2, w_xtmp3,\n-            tmp4, tmp5,\n-            n_tmp6);\n-\n-        pop(in_out2);\n-        pop(in_out1);\n-        pop(tmp3);\n-\n-    addl(in_out2, 2 * size);\n-    subl(in_out1, 3 * size);\n-    jmp(L_processPartitions);\n-\n-  bind(L_exit);\n-}\n-#endif \/\/LP64\n-\n-#ifdef _LP64\n@@ -8855,78 +8163,0 @@\n-#else\n-void MacroAssembler::crc32c_ipl_alg2_alt2(Register in_out, Register in1, Register in2,\n-                                          Register tmp1, Register  tmp2, Register tmp3,\n-                                          Register tmp4, Register  tmp5, Register tmp6,\n-                                          XMMRegister w_xtmp1, XMMRegister w_xtmp2, XMMRegister w_xtmp3,\n-                                          bool is_pclmulqdq_supported) {\n-  uint32_t const_or_pre_comp_const_index[CRC32C_NUM_PRECOMPUTED_CONSTANTS];\n-  Label L_wordByWord;\n-  Label L_byteByByteProlog;\n-  Label L_byteByByte;\n-  Label L_exit;\n-\n-  if (is_pclmulqdq_supported) {\n-    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::crc32c_table_addr();\n-    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 1);\n-\n-    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 2);\n-    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 3);\n-\n-    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 4);\n-    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 5);\n-  } else {\n-    const_or_pre_comp_const_index[0] = 1;\n-    const_or_pre_comp_const_index[1] = 0;\n-\n-    const_or_pre_comp_const_index[2] = 3;\n-    const_or_pre_comp_const_index[3] = 2;\n-\n-    const_or_pre_comp_const_index[4] = 5;\n-    const_or_pre_comp_const_index[5] = 4;\n-  }\n-  crc32c_proc_chunk(CRC32C_HIGH, const_or_pre_comp_const_index[0], const_or_pre_comp_const_index[1], is_pclmulqdq_supported,\n-                    in2, in1, in_out,\n-                    tmp1, tmp2, tmp3,\n-                    w_xtmp1, w_xtmp2, w_xtmp3,\n-                    tmp4, tmp5,\n-                    tmp6);\n-  crc32c_proc_chunk(CRC32C_MIDDLE, const_or_pre_comp_const_index[2], const_or_pre_comp_const_index[3], is_pclmulqdq_supported,\n-                    in2, in1, in_out,\n-                    tmp1, tmp2, tmp3,\n-                    w_xtmp1, w_xtmp2, w_xtmp3,\n-                    tmp4, tmp5,\n-                    tmp6);\n-  crc32c_proc_chunk(CRC32C_LOW, const_or_pre_comp_const_index[4], const_or_pre_comp_const_index[5], is_pclmulqdq_supported,\n-                    in2, in1, in_out,\n-                    tmp1, tmp2, tmp3,\n-                    w_xtmp1, w_xtmp2, w_xtmp3,\n-                    tmp4, tmp5,\n-                    tmp6);\n-  movl(tmp1, in2);\n-  andl(tmp1, 0x00000007);\n-  negl(tmp1);\n-  addl(tmp1, in2);\n-  addl(tmp1, in1);\n-\n-  BIND(L_wordByWord);\n-  cmpl(in1, tmp1);\n-  jcc(Assembler::greaterEqual, L_byteByByteProlog);\n-    crc32(in_out, Address(in1,0), 4);\n-    addl(in1, 4);\n-    jmp(L_wordByWord);\n-\n-  BIND(L_byteByByteProlog);\n-  andl(in2, 0x00000007);\n-  movl(tmp2, 1);\n-\n-  BIND(L_byteByByte);\n-  cmpl(tmp2, in2);\n-  jccb(Assembler::greater, L_exit);\n-    movb(tmp1, Address(in1, 0));\n-    crc32(in_out, tmp1, 1);\n-    incl(in1);\n-    incl(tmp2);\n-    jmp(L_byteByByte);\n-\n-  BIND(L_exit);\n-}\n-#endif \/\/ LP64\n@@ -9926,1 +9156,0 @@\n-#ifdef _LP64\n@@ -10103,1 +9332,0 @@\n-#endif\n@@ -10107,1 +9335,0 @@\n-#ifdef _LP64\n@@ -10271,2 +9498,0 @@\n-#endif \/\/ _LP64\n-\n@@ -10458,1 +9683,0 @@\n-#ifdef _LP64\n@@ -10507,1 +9731,0 @@\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":72,"deletions":849,"binary":false,"changes":921,"status":"modified"},{"patch":"@@ -143,4 +143,4 @@\n-  void increment(Register reg, int value = 1) { LP64_ONLY(incrementq(reg, value)) NOT_LP64(incrementl(reg, value)) ; }\n-  void decrement(Register reg, int value = 1) { LP64_ONLY(decrementq(reg, value)) NOT_LP64(decrementl(reg, value)) ; }\n-  void increment(Address dst, int value = 1)  { LP64_ONLY(incrementq(dst, value)) NOT_LP64(incrementl(dst, value)) ; }\n-  void decrement(Address dst, int value = 1)  { LP64_ONLY(decrementq(dst, value)) NOT_LP64(decrementl(dst, value)) ; }\n+  void increment(Register reg, int value = 1) { incrementq(reg, value); }\n+  void decrement(Register reg, int value = 1) { decrementq(reg, value); }\n+  void increment(Address dst, int value = 1)  { incrementq(dst, value); }\n+  void decrement(Address dst, int value = 1)  { decrementq(dst, value); }\n@@ -224,1 +224,0 @@\n-#ifdef _LP64\n@@ -240,1 +239,0 @@\n-#endif \/\/ _LP64\n@@ -354,1 +352,0 @@\n-#ifdef _LP64\n@@ -356,1 +353,0 @@\n-#endif\n@@ -382,1 +378,0 @@\n-#ifdef _LP64\n@@ -417,2 +412,0 @@\n-#endif \/\/ _LP64\n-\n@@ -585,1 +578,0 @@\n-#ifdef _LP64\n@@ -595,1 +587,0 @@\n-#endif\n@@ -632,1 +623,0 @@\n-#ifdef _LP64\n@@ -660,1 +650,0 @@\n-#endif\n@@ -769,1 +758,1 @@\n-  void addptr(Address dst, int32_t src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)) ; }\n+  void addptr(Address dst, int32_t src) { addq(dst, src); }\n@@ -772,1 +761,1 @@\n-  void addptr(Register dst, Address src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)); }\n+  void addptr(Register dst, Address src) { addq(dst, src); }\n@@ -781,1 +770,1 @@\n-  void andptr(Register src1, Register src2) { LP64_ONLY(andq(src1, src2)) NOT_LP64(andl(src1, src2)) ; }\n+  void andptr(Register src1, Register src2) { andq(src1, src2); }\n@@ -783,1 +772,0 @@\n-#ifdef _LP64\n@@ -786,1 +774,0 @@\n-#endif\n@@ -799,6 +786,0 @@\n-#ifndef _LP64\n-  void cmpklass(Address dst, Metadata* obj);\n-  void cmpklass(Register dst, Metadata* obj);\n-  void cmpoop(Address dst, jobject obj);\n-#endif \/\/ _LP64\n-\n@@ -814,3 +795,2 @@\n-  void cmpptr(Register src1, Register src2) { LP64_ONLY(cmpq(src1, src2)) NOT_LP64(cmpl(src1, src2)) ; }\n-  void cmpptr(Register src1, Address src2) { LP64_ONLY(cmpq(src1, src2)) NOT_LP64(cmpl(src1, src2)) ; }\n-  \/\/ void cmpptr(Address src1, Register src2) { LP64_ONLY(cmpq(src1, src2)) NOT_LP64(cmpl(src1, src2)) ; }\n+  void cmpptr(Register src1, Register src2) { cmpq(src1, src2); }\n+  void cmpptr(Register src1, Address src2) { cmpq(src1, src2); }\n@@ -818,2 +798,2 @@\n-  void cmpptr(Register src1, int32_t src2) { LP64_ONLY(cmpq(src1, src2)) NOT_LP64(cmpl(src1, src2)) ; }\n-  void cmpptr(Address src1, int32_t src2) { LP64_ONLY(cmpq(src1, src2)) NOT_LP64(cmpl(src1, src2)) ; }\n+  void cmpptr(Register src1, int32_t src2) { cmpq(src1, src2); }\n+  void cmpptr(Address src1, int32_t src2) { cmpq(src1, src2); }\n@@ -828,2 +808,2 @@\n-  void imulptr(Register dst, Register src) { LP64_ONLY(imulq(dst, src)) NOT_LP64(imull(dst, src)); }\n-  void imulptr(Register dst, Register src, int imm32) { LP64_ONLY(imulq(dst, src, imm32)) NOT_LP64(imull(dst, src, imm32)); }\n+  void imulptr(Register dst, Register src) { imulq(dst, src); }\n+  void imulptr(Register dst, Register src, int imm32) { imulq(dst, src, imm32); }\n@@ -832,1 +812,1 @@\n-  void negptr(Register dst) { LP64_ONLY(negq(dst)) NOT_LP64(negl(dst)); }\n+  void negptr(Register dst) { negq(dst); }\n@@ -834,1 +814,1 @@\n-  void notptr(Register dst) { LP64_ONLY(notq(dst)) NOT_LP64(notl(dst)); }\n+  void notptr(Register dst) { notq(dst); }\n@@ -837,1 +817,1 @@\n-  void shlptr(Register dst) { LP64_ONLY(shlq(dst)) NOT_LP64(shll(dst)); }\n+  void shlptr(Register dst) { shlq(dst); }\n@@ -840,1 +820,1 @@\n-  void shrptr(Register dst) { LP64_ONLY(shrq(dst)) NOT_LP64(shrl(dst)); }\n+  void shrptr(Register dst) { shrq(dst); }\n@@ -842,2 +822,2 @@\n-  void sarptr(Register dst) { LP64_ONLY(sarq(dst)) NOT_LP64(sarl(dst)); }\n-  void sarptr(Register dst, int32_t src) { LP64_ONLY(sarq(dst, src)) NOT_LP64(sarl(dst, src)); }\n+  void sarptr(Register dst) { sarq(dst); }\n+  void sarptr(Register dst, int32_t src) { sarq(dst, src); }\n@@ -845,1 +825,1 @@\n-  void subptr(Address dst, int32_t src) { LP64_ONLY(subq(dst, src)) NOT_LP64(subl(dst, src)); }\n+  void subptr(Address dst, int32_t src) { subq(dst, src); }\n@@ -847,1 +827,1 @@\n-  void subptr(Register dst, Address src) { LP64_ONLY(subq(dst, src)) NOT_LP64(subl(dst, src)); }\n+  void subptr(Register dst, Address src) { subq(dst, src); }\n@@ -857,2 +837,2 @@\n-  void sbbptr(Address dst, int32_t src) { LP64_ONLY(sbbq(dst, src)) NOT_LP64(sbbl(dst, src)); }\n-  void sbbptr(Register dst, int32_t src) { LP64_ONLY(sbbq(dst, src)) NOT_LP64(sbbl(dst, src)); }\n+  void sbbptr(Address dst, int32_t src) { sbbq(dst, src); }\n+  void sbbptr(Register dst, int32_t src) { sbbq(dst, src); }\n@@ -860,2 +840,2 @@\n-  void xchgptr(Register src1, Register src2) { LP64_ONLY(xchgq(src1, src2)) NOT_LP64(xchgl(src1, src2)) ; }\n-  void xchgptr(Register src1, Address src2) { LP64_ONLY(xchgq(src1, src2)) NOT_LP64(xchgl(src1, src2)) ; }\n+  void xchgptr(Register src1, Register src2) { xchgq(src1, src2); }\n+  void xchgptr(Register src1, Address src2) { xchgq(src1, src2); }\n@@ -863,1 +843,1 @@\n-  void xaddptr(Address src1, Register src2) { LP64_ONLY(xaddq(src1, src2)) NOT_LP64(xaddl(src1, src2)) ; }\n+  void xaddptr(Address src1, Register src2) { xaddq(src1, src2); }\n@@ -873,1 +853,0 @@\n-#ifdef _LP64\n@@ -876,3 +855,2 @@\n-#endif\n-  void atomic_incptr(AddressLiteral counter_addr, Register rscratch = noreg) { LP64_ONLY(atomic_incq(counter_addr, rscratch)) NOT_LP64(atomic_incl(counter_addr, rscratch)) ; }\n-  void atomic_incptr(Address counter_addr) { LP64_ONLY(atomic_incq(counter_addr)) NOT_LP64(atomic_incl(counter_addr)) ; }\n+  void atomic_incptr(AddressLiteral counter_addr, Register rscratch = noreg) { atomic_incq(counter_addr, rscratch); }\n+  void atomic_incptr(Address counter_addr) { atomic_incq(counter_addr); }\n@@ -896,4 +874,4 @@\n-  void orptr(Register dst, Address src) { LP64_ONLY(orq(dst, src)) NOT_LP64(orl(dst, src)); }\n-  void orptr(Register dst, Register src) { LP64_ONLY(orq(dst, src)) NOT_LP64(orl(dst, src)); }\n-  void orptr(Register dst, int32_t src) { LP64_ONLY(orq(dst, src)) NOT_LP64(orl(dst, src)); }\n-  void orptr(Address dst, int32_t imm32) { LP64_ONLY(orq(dst, imm32)) NOT_LP64(orl(dst, imm32)); }\n+  void orptr(Register dst, Address src) { orq(dst, src); }\n+  void orptr(Register dst, Register src) { orq(dst, src); }\n+  void orptr(Register dst, int32_t src) { orq(dst, src); }\n+  void orptr(Address dst, int32_t imm32) { orq(dst, imm32); }\n@@ -901,3 +879,3 @@\n-  void testptr(Register src, int32_t imm32) {  LP64_ONLY(testq(src, imm32)) NOT_LP64(testl(src, imm32)); }\n-  void testptr(Register src1, Address src2) { LP64_ONLY(testq(src1, src2)) NOT_LP64(testl(src1, src2)); }\n-  void testptr(Address src, int32_t imm32) {  LP64_ONLY(testq(src, imm32)) NOT_LP64(testl(src, imm32)); }\n+  void testptr(Register src, int32_t imm32) { testq(src, imm32); }\n+  void testptr(Register src1, Address src2) { testq(src1, src2); }\n+  void testptr(Address src, int32_t imm32) { testq(src, imm32); }\n@@ -906,2 +884,2 @@\n-  void xorptr(Register dst, Register src) { LP64_ONLY(xorq(dst, src)) NOT_LP64(xorl(dst, src)); }\n-  void xorptr(Register dst, Address src) { LP64_ONLY(xorq(dst, src)) NOT_LP64(xorl(dst, src)); }\n+  void xorptr(Register dst, Register src) { xorq(dst, src); }\n+  void xorptr(Register dst, Address src) { xorq(dst, src); }\n@@ -1036,1 +1014,0 @@\n-#ifdef _LP64\n@@ -1086,1 +1063,0 @@\n-#endif \/\/ _LP64\n@@ -1096,1 +1072,0 @@\n-#ifdef _LP64\n@@ -1101,6 +1076,0 @@\n-#else\n-  void fast_sha256(XMMRegister msg, XMMRegister state0, XMMRegister state1, XMMRegister msgtmp0,\n-                   XMMRegister msgtmp1, XMMRegister msgtmp2, XMMRegister msgtmp3, XMMRegister msgtmp4,\n-                   Register buf, Register state, Register ofs, Register limit, Register rsp,\n-                   bool multi_block);\n-#endif\n@@ -1112,46 +1081,0 @@\n-#ifndef _LP64\n- private:\n-  \/\/ Initialized in macroAssembler_x86_constants.cpp\n-  static address ONES;\n-  static address L_2IL0FLOATPACKET_0;\n-  static address PI4_INV;\n-  static address PI4X3;\n-  static address PI4X4;\n-\n- public:\n-  void fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                Register rax, Register rcx, Register rdx, Register tmp1);\n-\n-  void fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                Register rax, Register rcx, Register rdx, Register tmp);\n-\n-  void fast_pow(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4,\n-                XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register rax, Register rcx,\n-                Register rdx, Register tmp);\n-\n-  void fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                Register rax, Register rbx, Register rdx);\n-\n-  void fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                Register rax, Register rcx, Register rdx, Register tmp);\n-\n-  void libm_sincos_huge(XMMRegister xmm0, XMMRegister xmm1, Register eax, Register ecx,\n-                        Register edx, Register ebx, Register esi, Register edi,\n-                        Register ebp, Register esp);\n-\n-  void libm_reduce_pi04l(Register eax, Register ecx, Register edx, Register ebx,\n-                         Register esi, Register edi, Register ebp, Register esp);\n-\n-  void libm_tancot_huge(XMMRegister xmm0, XMMRegister xmm1, Register eax, Register ecx,\n-                        Register edx, Register ebx, Register esi, Register edi,\n-                        Register ebp, Register esp);\n-\n-  void fast_tan(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n-                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n-                Register rax, Register rcx, Register rdx, Register tmp);\n-#endif \/\/ !_LP64\n-\n@@ -1924,2 +1847,2 @@\n-  void cmovptr(Condition cc, Register dst, Address  src) { LP64_ONLY(cmovq(cc, dst, src)) NOT_LP64(cmov32(cc, dst, src)); }\n-  void cmovptr(Condition cc, Register dst, Register src) { LP64_ONLY(cmovq(cc, dst, src)) NOT_LP64(cmov32(cc, dst, src)); }\n+  void cmovptr(Condition cc, Register dst, Address  src) { cmovq(cc, dst, src); }\n+  void cmovptr(Condition cc, Register dst, Register src) { cmovq(cc, dst, src); }\n@@ -1964,2 +1887,2 @@\n-  void pushptr(Address src) { LP64_ONLY(pushq(src)) NOT_LP64(pushl(src)); }\n-  void popptr(Address src) { LP64_ONLY(popq(src)) NOT_LP64(popl(src)); }\n+  void pushptr(Address src) { pushq(src); }\n+  void popptr(Address src) { popq(src); }\n@@ -1971,2 +1894,2 @@\n-  void movl2ptr(Register dst, Address src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(movl(dst, src)); }\n-  void movl2ptr(Register dst, Register src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(if (dst != src) movl(dst, src)); }\n+  void movl2ptr(Register dst, Address src) { movslq(dst, src); }\n+  void movl2ptr(Register dst, Register src) { movslq(dst, src); }\n@@ -1995,1 +1918,0 @@\n-#ifdef _LP64\n@@ -2036,1 +1958,0 @@\n-#endif\n@@ -2042,2 +1963,0 @@\n-\n-#ifdef _LP64\n@@ -2048,1 +1967,0 @@\n-#endif \/\/ _LP64\n@@ -2054,1 +1972,0 @@\n-#ifdef _LP64\n@@ -2057,5 +1974,0 @@\n-#else\n-  void crc32c_ipl_alg4(Register in_out, uint32_t n,\n-                       Register tmp1, Register tmp2, Register tmp3,\n-                       XMMRegister xtmp1, XMMRegister xtmp2);\n-#endif\n@@ -2086,1 +1998,0 @@\n-#ifdef _LP64\n@@ -2089,1 +2000,0 @@\n-#endif \/\/ _LP64\n@@ -2123,1 +2033,0 @@\n-#ifdef _LP64\n@@ -2138,1 +2047,0 @@\n-#endif \/\/ _LP64\n@@ -2147,1 +2055,0 @@\n-#ifdef _LP64\n@@ -2151,1 +2058,0 @@\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":43,"deletions":137,"binary":false,"changes":180,"status":"modified"},{"patch":"@@ -238,1 +238,0 @@\n-#ifdef _LP64\n@@ -243,6 +242,0 @@\n-#else\n-void MacroAssembler::fast_sha256(XMMRegister msg, XMMRegister state0, XMMRegister state1, XMMRegister msgtmp0,\n-  XMMRegister msgtmp1, XMMRegister msgtmp2, XMMRegister msgtmp3, XMMRegister msgtmp4,\n-  Register buf, Register state, Register ofs, Register limit, Register rsp,\n-  bool multi_block) {\n-#endif\n@@ -263,1 +256,0 @@\n-#ifdef _LP64\n@@ -265,1 +257,0 @@\n-#endif\n@@ -274,1 +265,0 @@\n-#ifdef _LP64\n@@ -276,3 +266,0 @@\n-#else\n-  pshufb(msg, ExternalAddress(pshuffle_byte_flip_mask));\n-#endif\n@@ -287,1 +274,0 @@\n-#ifdef _LP64\n@@ -289,3 +275,0 @@\n-#else\n-  pshufb(msg, ExternalAddress(pshuffle_byte_flip_mask));\n-#endif\n@@ -301,1 +284,0 @@\n-#ifdef _LP64\n@@ -303,3 +285,0 @@\n-#else\n-  pshufb(msg, ExternalAddress(pshuffle_byte_flip_mask));\n-#endif\n@@ -315,1 +294,0 @@\n-#ifdef _LP64\n@@ -317,3 +295,0 @@\n-#else\n-  pshufb(msg, ExternalAddress(pshuffle_byte_flip_mask));\n-#endif\n@@ -494,1 +469,0 @@\n-#ifdef _LP64\n@@ -1699,2 +1673,0 @@\n-\n-#endif \/\/#ifdef _LP64\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_sha.cpp","additions":0,"deletions":28,"binary":false,"changes":28,"status":"modified"}]}