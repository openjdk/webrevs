{"files":[{"patch":"@@ -65,0 +65,1 @@\n+#include \"gc\/g1\/g1ReviseYoungListTargetLengthTask.hpp\"\n@@ -1163,0 +1164,1 @@\n+  _revise_young_length_task(nullptr),\n@@ -1471,0 +1473,5 @@\n+  if (policy()->use_adaptive_young_list_length()) {\n+    _revise_young_length_task = new G1ReviseYoungLengthTargetLengthTask(\"Revise Young Length List Task\");\n+    _service_thread->register_task(_revise_young_length_task);\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -87,0 +87,1 @@\n+class G1ReviseYoungLengthTargetLengthTask;\n@@ -175,0 +176,1 @@\n+  G1ReviseYoungLengthTargetLengthTask* _revise_young_length_task;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -395,1 +395,5 @@\n-  return 50;\n+\n+  \/\/ Use a prime number close to 50ms, different to other components that derive\n+  \/\/ their wait time from the try_get_available_bytes_estimate() call to minimize\n+  \/\/ interference.\n+  return 53;\n@@ -517,8 +521,0 @@\n-\/\/ Wake up the control thread less frequently when the time available until\n-\/\/ the next GC is longer.  But don't increase the wait time too rapidly.\n-\/\/ This reduces the number of control thread wakeups that just immediately\n-\/\/ go back to waiting, while still being responsive to behavior changes.\n-static uint64_t compute_adjust_wait_time_ms(double available_ms) {\n-  return static_cast<uint64_t>(sqrt(available_ms) * 4.0);\n-}\n-\n@@ -534,3 +530,3 @@\n-    double available_ms = _threads_needed.predicted_time_until_next_gc_ms();\n-    uint64_t wait_time_ms = compute_adjust_wait_time_ms(available_ms);\n-    return MAX2(wait_time_ms, adjust_threads_period_ms());\n+    double available_time_ms = _threads_needed.predicted_time_until_next_gc_ms();\n+\n+    return _policy->adjust_wait_time_ms(available_time_ms, adjust_threads_period_ms());\n@@ -545,49 +541,0 @@\n-class G1ConcurrentRefine::RemSetSamplingClosure : public G1HeapRegionClosure {\n-  size_t _sampled_code_root_rs_length;\n-\n-public:\n-  RemSetSamplingClosure() :\n-    _sampled_code_root_rs_length(0) {}\n-\n-  bool do_heap_region(G1HeapRegion* r) override {\n-    G1HeapRegionRemSet* rem_set = r->rem_set();\n-    _sampled_code_root_rs_length += rem_set->code_roots_list_length();\n-    return false;\n-  }\n-\n-  size_t sampled_code_root_rs_length() const { return _sampled_code_root_rs_length; }\n-};\n-\n-\/\/ Adjust the target length (in regions) of the young gen, based on the\n-\/\/ current length of the remembered sets.\n-\/\/\n-\/\/ At the end of the GC G1 determines the length of the young gen based on\n-\/\/ how much time the next GC can take, and when the next GC may occur\n-\/\/ according to the MMU.\n-\/\/\n-\/\/ The assumption is that a significant part of the GC is spent on scanning\n-\/\/ the remembered sets (and many other components), so this thread constantly\n-\/\/ reevaluates the prediction for the remembered set scanning costs, and potentially\n-\/\/ resizes the young gen. This may do a premature GC or even increase the young\n-\/\/ gen size to keep pause time length goal.\n-void G1ConcurrentRefine::adjust_young_list_target_length() {\n-  if (_policy->use_adaptive_young_list_length()) {\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-    G1CollectionSet* cset = g1h->collection_set();\n-    RemSetSamplingClosure cl;\n-    cset->iterate(&cl);\n-\n-    size_t pending_cards;\n-    size_t current_to_collection_set_cards;\n-    {\n-      MutexLocker x(G1RareEvent_lock, Mutex::_no_safepoint_check_flag);\n-      G1Policy* p = g1h->policy();\n-      pending_cards = p->current_pending_cards();\n-      current_to_collection_set_cards = p->current_to_collection_set_cards();\n-    }\n-    _policy->revise_young_list_target_length(pending_cards,\n-                                             current_to_collection_set_cards,\n-                                             cl.sampled_code_root_rs_length());\n-  }\n-}\n-\n@@ -610,12 +557,2 @@\n-  \/\/ Getting used young bytes requires holding Heap_lock.  But we can't use\n-  \/\/ normal lock and block until available.  Blocking on the lock could\n-  \/\/ deadlock with a GC VMOp that is holding the lock and requesting a\n-  \/\/ safepoint.  Instead try to lock, and if fail then skip adjustment for\n-  \/\/ this iteration and retry the adjustment later.\n-  if (Heap_lock->try_lock()) {\n-    size_t used_bytes = _policy->estimate_used_young_bytes_locked();\n-    Heap_lock->unlock();\n-\n-    adjust_young_list_target_length();\n-    size_t young_bytes = _policy->young_list_target_length() * G1HeapRegion::GrainBytes;\n-    size_t available_bytes = young_bytes - MIN2(young_bytes, used_bytes);\n+  size_t available_bytes = 0;\n+  if (_policy->try_get_available_bytes_estimate(available_bytes)) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRefine.cpp","additions":10,"deletions":73,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -252,3 +252,0 @@\n-  class RemSetSamplingClosure;  \/\/ Helper class for adjusting young length.\n-  void adjust_young_list_target_length();\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRefine.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -219,1 +219,1 @@\n-      MutexLocker x(G1RareEvent_lock, Mutex::_no_safepoint_check_flag);\n+      MutexLocker x(G1ReviseYoungLength_lock, Mutex::_no_safepoint_check_flag);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRefineThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -55,20 +55,1 @@\n-  const G1Analytics* analytics = _policy->analytics();\n-\n-  \/\/ Estimate time until next GC, based on remaining bytes available for\n-  \/\/ allocation and the allocation rate.\n-  double alloc_region_rate = analytics->predict_alloc_rate_ms();\n-  double alloc_bytes_rate = alloc_region_rate * G1HeapRegion::GrainBytes;\n-  if (alloc_bytes_rate == 0.0) {\n-    \/\/ A zero rate indicates we don't yet have data to use for predictions.\n-    \/\/ Since we don't have any idea how long until the next GC, use a time of\n-    \/\/ zero.\n-    _predicted_time_until_next_gc_ms = 0.0;\n-  } else {\n-    \/\/ If the heap size is large and the allocation rate is small, we can get\n-    \/\/ a predicted time until next GC that is so large it can cause problems\n-    \/\/ (such as overflow) in other calculations.  Limit the prediction to one\n-    \/\/ hour, which is still large in this context.\n-    const double one_hour_ms = 60.0 * 60.0 * MILLIUNITS;\n-    double raw_time_ms = available_bytes \/ alloc_bytes_rate;\n-    _predicted_time_until_next_gc_ms = MIN2(raw_time_ms, one_hour_ms);\n-  }\n+  _predicted_time_until_next_gc_ms = _policy->predict_time_to_next_gc_ms(available_bytes);\n@@ -77,0 +58,1 @@\n+  const G1Analytics* analytics = _policy->analytics();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentRefineThreadsNeeded.cpp","additions":2,"deletions":20,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -636,1 +636,1 @@\n-  assert(SafepointSynchronize::is_at_safepoint() || G1RareEvent_lock->is_locked(),\n+  assert(SafepointSynchronize::is_at_safepoint() || G1ReviseYoungLength_lock->is_locked(),\n@@ -638,1 +638,1 @@\n-         BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()), BOOL_TO_STR(G1RareEvent_lock->is_locked()));\n+         BOOL_TO_STR(SafepointSynchronize::is_at_safepoint()), BOOL_TO_STR(G1ReviseYoungLength_lock->is_locked()));\n@@ -1436,0 +1436,42 @@\n+bool G1Policy::try_get_available_bytes_estimate(size_t& available_bytes) const {\n+  \/\/ Getting used young bytes requires holding Heap_lock.  But we can't use\n+  \/\/ normal lock and block until available.  Blocking on the lock could\n+  \/\/ deadlock with a GC VMOp that is holding the lock and requesting a\n+  \/\/ safepoint.  Instead try to lock, and return the result of that attempt,\n+  \/\/ and the estimate if successful.\n+  if (Heap_lock->try_lock()) {\n+    size_t used_bytes = estimate_used_young_bytes_locked();\n+    Heap_lock->unlock();\n+\n+    size_t young_bytes = young_list_target_length() * G1HeapRegion::GrainBytes;\n+    available_bytes = young_bytes - MIN2(young_bytes, used_bytes);\n+    return true;\n+  } else {\n+    available_bytes = 0;\n+    return false;\n+  }\n+}\n+\n+double G1Policy::predict_time_to_next_gc_ms(size_t available_bytes) const {\n+  double alloc_region_rate = _analytics->predict_alloc_rate_ms();\n+  double alloc_bytes_rate = alloc_region_rate * G1HeapRegion::GrainBytes;\n+  if (alloc_bytes_rate == 0.0) {\n+    \/\/ A zero rate indicates we don't yet have data to use for predictions.\n+    \/\/ Since we don't have any idea how long until the next GC, use a time of\n+    \/\/ zero.\n+    return 0.0;\n+  } else {\n+    \/\/ If the heap size is large and the allocation rate is small, we can get\n+    \/\/ a predicted time until next GC that is so large it can cause problems\n+    \/\/ (such as overflow) in other calculations.  Limit the prediction to one\n+    \/\/ hour, which is still large in this context.\n+    const double one_hour_ms = 60.0 * 60.0 * MILLIUNITS;\n+    double raw_time_ms = available_bytes \/ alloc_bytes_rate;\n+    return MIN2(raw_time_ms, one_hour_ms);\n+  }\n+}\n+\n+uint64_t G1Policy::adjust_wait_time_ms(double wait_time_ms, uint64_t min_time_ms) {\n+  return MAX2(static_cast<uint64_t>(sqrt(wait_time_ms) * 4.0), min_time_ms);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":44,"deletions":2,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -338,1 +338,0 @@\n-\n@@ -372,0 +371,16 @@\n+  \/\/ Try to get an estimate of the currently available bytes in the young gen. This\n+  \/\/ operation considers itself low-priority: if other threads need the resources\n+  \/\/ required to get the information, return false to indicate that the caller\n+  \/\/ should retry \"soon\".\n+  bool try_get_available_bytes_estimate(size_t& bytes) const;\n+  \/\/ Estimate time until next GC, based on remaining bytes available for\n+  \/\/ allocation and the allocation rate.\n+  double predict_time_to_next_gc_ms(size_t available_bytes) const;\n+\n+  \/\/ Adjust wait times to make them less frequent the longer the next GC is away.\n+  \/\/ But don't increase the wait time too rapidly, further bound it by min_time_ms.\n+  \/\/ This reduces the number of thread wakeups that just immediately\n+  \/\/ go back to waiting, while still being responsive to behavior changes.\n+  uint64_t adjust_wait_time_ms(double wait_time_ms, uint64_t min_time_ms);\n+\n+private:\n@@ -376,0 +391,2 @@\n+public:\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -0,0 +1,97 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1Policy.hpp\"\n+#include \"gc\/g1\/g1ReviseYoungListTargetLengthTask.hpp\"\n+#include \"gc\/g1\/g1ServiceThread.hpp\"\n+#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n+\n+\n+jlong G1ReviseYoungLengthTargetLengthTask::reschedule_delay_ms() const {\n+  G1Policy* policy = G1CollectedHeap::heap()->policy();\n+  size_t available_bytes;\n+  if (policy->try_get_available_bytes_estimate(available_bytes)) {\n+    double predicted_time_to_next_gc_ms = policy->predict_time_to_next_gc_ms(available_bytes);\n+\n+    \/\/ Use a prime number close to 50ms as minimum time, different to other components\n+    \/\/ that derive their wait time from the try_get_available_bytes_estimate() call\n+    \/\/ to minimize interference.\n+    uint64_t const min_wait_time_ms = 47;\n+\n+    return policy->adjust_wait_time_ms(predicted_time_to_next_gc_ms, min_wait_time_ms);\n+  } else {\n+    \/\/ Failed to get estimate of available bytes. Try again asap.\n+    return 1;\n+  }\n+}\n+\n+class G1ReviseYoungLengthTargetLengthTask::RemSetSamplingClosure : public G1HeapRegionClosure {\n+  size_t _sampled_code_root_rs_length;\n+\n+public:\n+  RemSetSamplingClosure() : _sampled_code_root_rs_length(0) { }\n+\n+  bool do_heap_region(G1HeapRegion* r) override {\n+    G1HeapRegionRemSet* rem_set = r->rem_set();\n+    _sampled_code_root_rs_length += rem_set->code_roots_list_length();\n+    return false;\n+  }\n+\n+  size_t sampled_code_root_rs_length() const { return _sampled_code_root_rs_length; }\n+};\n+\n+void G1ReviseYoungLengthTargetLengthTask::adjust_young_list_target_length() {\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+  G1Policy* policy = g1h->policy();\n+\n+  assert(policy->use_adaptive_young_list_length(), \"should not call otherwise\");\n+\n+  size_t pending_cards;\n+  size_t current_to_collection_set_cards;\n+  {\n+    MutexLocker x(G1ReviseYoungLength_lock, Mutex::_no_safepoint_check_flag);\n+    G1Policy* p = g1h->policy();\n+    pending_cards = p->current_pending_cards();\n+    current_to_collection_set_cards = p->current_to_collection_set_cards();\n+  }\n+\n+  RemSetSamplingClosure cl;\n+  g1h->collection_set()->iterate(&cl);\n+\n+  policy->revise_young_list_target_length(pending_cards,\n+                                          current_to_collection_set_cards,\n+                                          cl.sampled_code_root_rs_length());\n+}\n+\n+G1ReviseYoungLengthTargetLengthTask::G1ReviseYoungLengthTargetLengthTask(const char* name) :\n+  G1ServiceTask(name) { }\n+\n+void G1ReviseYoungLengthTargetLengthTask::execute() {\n+  SuspendibleThreadSetJoiner sts;\n+\n+  adjust_young_list_target_length();\n+\n+  schedule(reschedule_delay_ms());\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ReviseYoungListTargetLengthTask.cpp","additions":97,"deletions":0,"binary":false,"changes":97,"status":"added"},{"patch":"@@ -0,0 +1,63 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1REVISEYOUNGLISTTARGETLENGTHTASK_HPP\n+#define SHARE_GC_G1_G1REVISEYOUNGLISTTARGETLENGTHTASK_HPP\n+\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n+#include \"gc\/g1\/g1HeapRegionRemSet.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreePool.hpp\"\n+#include \"gc\/g1\/g1ServiceThread.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+#include \"utilities\/ticks.hpp\"\n+\n+\/\/ ServiceTask to revise the young generation target length.\n+class G1ReviseYoungLengthTargetLengthTask : public G1ServiceTask {\n+\n+  \/\/ The delay used to reschedule this task.\n+  jlong reschedule_delay_ms() const;\n+\n+  class RemSetSamplingClosure; \/\/ Helper class for calculating remembered set summary.\n+\n+  \/\/ Adjust the target length (in regions) of the young gen, based on the\n+  \/\/ current length of the remembered sets.\n+  \/\/\n+  \/\/ At the end of the GC G1 determines the length of the young gen based on\n+  \/\/ how much time the next GC can take, and when the next GC may occur\n+  \/\/ according to the MMU.\n+  \/\/\n+  \/\/ The assumption is that a significant part of the GC is spent on scanning\n+  \/\/ the remembered sets (and many other components), so this thread constantly\n+  \/\/ reevaluates the prediction for the remembered set scanning costs, and potentially\n+  \/\/ resizes the young gen. This may do a premature GC or even increase the young\n+  \/\/ gen size to keep pause time length goal.\n+  void adjust_young_list_target_length();\n+\n+public:\n+  explicit G1ReviseYoungLengthTargetLengthTask(const char* name);\n+\n+  void execute() override;\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1REVISEYOUNGLISTTARGETLENGTHTASK_HPP\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ReviseYoungListTargetLengthTask.hpp","additions":63,"deletions":0,"binary":false,"changes":63,"status":"added"},{"patch":"@@ -74,0 +74,1 @@\n+Mutex*   G1ReviseYoungLength_lock     = nullptr;\n@@ -331,0 +332,1 @@\n+    MUTEX_DEFL(G1ReviseYoungLength_lock     , PaddedMutex  , Threads_lock, true);\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -75,0 +75,1 @@\n+extern Mutex*   G1ReviseYoungLength_lock;        \/\/ Protects access to young gen length revising operations.\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}