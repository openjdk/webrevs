{"files":[{"patch":"@@ -3905,0 +3905,4 @@\n+\/\/ Whether the first instruction in the code emitted for this node is a\n+\/\/ candidate for implicit null check.\n+ins_attrib ins_has_initial_implicit_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -109,0 +109,5 @@\n+  \/\/ The vast majority of memory operands seen in practice are of indOffL8 type.\n+  \/\/ By construction, these memory operands do not lead to out-of-range offsets\n+  \/\/ (see definition of immLoffset8), so ldr is guaranteed to be the first\n+  \/\/ instruction emitted.\n+  ins_has_initial_implicit_null_check_candidate(opnd_array(1)->opcode() == INDOFFL8);\n@@ -116,0 +121,3 @@\n+    assert(!this->has_initial_implicit_null_check_candidate() ||\n+           Address::offset_ok_for_immed(ref_addr.offset(), exact_log2(8)),\n+           \"an instruction that can be used for implicit null checking should emit the candidate memory access first\");\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/z_aarch64.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  ins_has_initial_implicit_null_check_candidate(true);\n@@ -163,0 +164,1 @@\n+  ins_has_initial_implicit_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/z_ppc.ad","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3835,0 +3835,4 @@\n+\/\/ Whether the first instruction in the code emitted for this node is a\n+\/\/ candidate for implicit null check.\n+ins_attrib ins_has_initial_implicit_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -99,0 +99,1 @@\n+  ins_has_initial_implicit_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/z_riscv.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2707,0 +2707,3 @@\n+\/\/ Whether the first instruction in the code emitted for this node is a\n+\/\/ candidate for implicit null check.\n+ins_attrib ins_has_initial_implicit_null_check_candidate(false);\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -121,0 +121,1 @@\n+  ins_has_initial_implicit_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/z_x86_64.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2045,0 +2045,3 @@\n+\/\/ Whether the first instruction in the code emitted for this node is a\n+\/\/ candidate for implicit null check.\n+ins_attrib ins_has_initial_implicit_null_check_candidate(false);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1605,0 +1605,2 @@\n+      } else if (strcmp (attr->_ident, \"ins_has_initial_implicit_null_check_candidate\") == 0) {\n+        fprintf(fp, \"  virtual bool           has_initial_implicit_null_check_candidate() const { return %s; }\\n\", attr->_val);\n","filename":"src\/hotspot\/share\/adlc\/output_h.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -472,0 +472,6 @@\n+  \/\/ If necessary, hoist orphan node n into the end of block b.\n+  void maybe_hoist_into(Node* n, Block* b);\n+\n+  \/\/ Move node n from its current placement into the end of block b.\n+  void move_into(Node* n, Block* b);\n+\n","filename":"src\/hotspot\/share\/opto\/block.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -80,0 +80,28 @@\n+void PhaseCFG::move_into(Node* n, Block* b) {\n+  Block *old = get_block_for_node(n);\n+  old->find_remove(n);\n+  b->add_inst(n);\n+  map_node_to_block(n, b);\n+  \/\/ Check for Mach projections that also need to be moved.\n+  for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+    Node* out = n->fast_out(i);\n+    if (!out->is_MachProj()) {\n+      continue;\n+    }\n+    assert(!n->is_MachProj(), \"nested projections are not allowed\");\n+    move_into(out, b);\n+  }\n+}\n+\n+void PhaseCFG::maybe_hoist_into(Node* n, Block* b) {\n+  Block* current = get_block_for_node(n);\n+  if (current->dominates(b)) {\n+    return;\n+  }\n+  assert(b->dominates(current), \"sanity check: temp node placement\");\n+  \/\/ We only expect nodes without further inputs, like MachTemp or load Base.\n+  assert(n->req() == 0 || (n->req() == 1 && n->in(0) == (Node*)C->root()),\n+         \"need for recursive hoisting not expected\");\n+  move_into(n, b);\n+}\n+\n@@ -164,1 +192,2 @@\n-    if (mach->barrier_data() != 0) {\n+    if (mach->barrier_data() != 0 &&\n+        !mach->has_initial_implicit_null_check_candidate()) {\n@@ -166,4 +195,5 @@\n-      \/\/ not supported. These operations might expand into multiple assembly\n-      \/\/ instructions during code emission, including new memory accesses (e.g.\n-      \/\/ in G1's pre-barrier), which would invalidate the implicit null\n-      \/\/ exception table.\n+      \/\/ only supported if these are explicit marked as emitting a candidate\n+      \/\/ memory access instruction at their initial address. If not marked as\n+      \/\/ such, barrier-tagged operations might expand into one or several memory\n+      \/\/ access instructions located at arbitrary offsets from the initial\n+      \/\/ address, which would invalidate the implicit null exception table.\n@@ -325,0 +355,5 @@\n+      if (mach->in(j)->is_MachTemp()) {\n+        assert(mach->in(j)->outcnt() == 1, \"MachTemp nodes should not be shared\");\n+        \/\/ Ignore MachTemp inputs, they can be safely hoisted with the candidate.\n+        continue;\n+      }\n@@ -392,24 +427,1 @@\n-        Node *temp = val->in(i);\n-        Block *tempb = get_block_for_node(temp);\n-        if (!tempb->dominates(block)) {\n-          assert(block->dominates(tempb), \"sanity check: temp node placement\");\n-          \/\/ We only expect nodes without further inputs, like MachTemp or load Base.\n-          assert(temp->req() == 0 || (temp->req() == 1 && temp->in(0) == (Node*)C->root()),\n-                 \"need for recursive hoisting not expected\");\n-          tempb->find_remove(temp);\n-          block->add_inst(temp);\n-          map_node_to_block(temp, block);\n-        }\n-      }\n-      valb->find_remove(val);\n-      block->add_inst(val);\n-      map_node_to_block(val, block);\n-      \/\/ DecodeN on x86 may kill flags. Check for flag-killing projections\n-      \/\/ that also need to be hoisted.\n-      for (DUIterator_Fast jmax, j = val->fast_outs(jmax); j < jmax; j++) {\n-        Node* n = val->fast_out(j);\n-        if( n->is_MachProj() ) {\n-          get_block_for_node(n)->find_remove(n);\n-          block->add_inst(n);\n-          map_node_to_block(n, block);\n-        }\n+        maybe_hoist_into(val->in(i), block);\n@@ -417,0 +429,1 @@\n+      move_into(val, block);\n@@ -419,0 +432,10 @@\n+\n+  \/\/ Move any MachTemp inputs to the end of the test block.\n+  for (uint i = 0; i < best->req(); i++) {\n+    Node* n = best->in(i);\n+    if (n == nullptr || !n->is_MachTemp()) {\n+      continue;\n+    }\n+    maybe_hoist_into(n, block);\n+  }\n+\n@@ -420,4 +443,1 @@\n-  Block *old_block = get_block_for_node(best);\n-  old_block->find_remove(best);\n-  block->add_inst(best);\n-  map_node_to_block(best, block);\n+  move_into(best, block);\n@@ -433,11 +453,0 @@\n-  \/\/ Check for flag-killing projections that also need to be hoisted\n-  \/\/ Should be DU safe because no edge updates.\n-  for (DUIterator_Fast jmax, j = best->fast_outs(jmax); j < jmax; j++) {\n-    Node* n = best->fast_out(j);\n-    if( n->is_MachProj() ) {\n-      get_block_for_node(n)->find_remove(n);\n-      block->add_inst(n);\n-      map_node_to_block(n, block);\n-    }\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":53,"deletions":44,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -388,0 +388,9 @@\n+\n+  \/\/ Whether the first instruction in the code emitted for this node is a\n+  \/\/ candidate for implicit null check. This function is only defined for nodes\n+  \/\/ with barrier data that are expanded late.\n+  virtual bool has_initial_implicit_null_check_candidate() const {\n+    assert(barrier_data() != 0, \"only defined for nodes with barrier data\");\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2022,1 +2022,3 @@\n-      assert(n->in(1)->as_Mach()->barrier_data() == 0,\n+      MachNode* access = n->in(1)->as_Mach();\n+      assert(access->barrier_data() == 0 ||\n+             access->has_initial_implicit_null_check_candidate(),\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,240 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.gcbarriers;\n+\n+import compiler.lib.ir_framework.*;\n+import java.lang.invoke.VarHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.ref.Reference;\n+import java.lang.ref.ReferenceQueue;\n+import java.lang.ref.SoftReference;\n+import java.lang.ref.WeakReference;\n+import jdk.test.lib.Asserts;\n+\n+\/**\n+ * @test id=G1\n+ * @summary Test that implicit null checks are generated as expected for G1\n+ *          memory accesses with barriers.\n+ * @library \/test\/lib \/\n+ * @requires vm.gc.G1\n+ * @run driver compiler.gcbarriers.TestImplicitNullChecks G1\n+ *\/\n+\n+\/**\n+ * @test id=Z\n+ * @summary Test that implicit null checks are generated as expected for ZGC\n+            memory accesses with barriers.\n+ * @library \/test\/lib \/\n+ * @requires vm.gc.Z\n+ * @run driver compiler.gcbarriers.TestImplicitNullChecks Z\n+ *\/\n+\n+\n+public class TestImplicitNullChecks {\n+\n+    static class Outer {\n+        Object f;\n+    }\n+\n+    static class OuterWithVolatileField {\n+        volatile Object f;\n+    }\n+\n+    static final VarHandle fVarHandle;\n+    static {\n+        MethodHandles.Lookup l = MethodHandles.lookup();\n+        try {\n+            fVarHandle = l.findVarHandle(Outer.class, \"f\", Object.class);\n+        } catch (Exception e) {\n+            throw new Error(e);\n+        }\n+    }\n+\n+    public static void main(String[] args) {\n+        if (args.length != 1) {\n+            throw new IllegalArgumentException();\n+        }\n+        if (!args[0].equals(\"G1\") && !args[0].equals(\"Z\")) {\n+            throw new IllegalArgumentException();\n+        }\n+        TestFramework.runWithFlags(\"-XX:CompileCommand=inline,java.lang.ref.*::*\",\n+                                   \"-XX:-TieredCompilation\",\n+                                   \"-XX:+Use\" + args[0] + \"GC\");\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoad(Outer o) {\n+        return o.f;\n+    }\n+\n+    @Test\n+    \/\/ On aarch64, volatile loads always use indirect memory operands, which\n+    \/\/ leads to a pattern that cannot be exploited by the current C2 analysis.\n+    @IR(applyIfPlatform = {\"aarch64\", \"false\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadVolatile(OuterWithVolatileField o) {\n+        return o.f;\n+    }\n+\n+    @Run(test = {\"testLoad\",\n+                 \"testLoadVolatile\"},\n+         mode = RunMode.STANDALONE)\n+    static void runLoadTests() {\n+        {\n+            Outer o = new Outer();\n+            \/\/ Trigger compilation with implicit null check.\n+            for (int i = 0; i < 10_000; i++) {\n+                testLoad(o);\n+            }\n+            \/\/ Trigger null pointer exception.\n+            o = null;\n+            boolean nullPointerException = false;\n+            try {\n+                testLoad(o);\n+            } catch (NullPointerException e) { nullPointerException = true; }\n+            Asserts.assertTrue(nullPointerException);\n+        }\n+        {\n+            OuterWithVolatileField o = new OuterWithVolatileField();\n+            \/\/ Trigger compilation with implicit null check.\n+            for (int i = 0; i < 10_000; i++) {\n+                testLoadVolatile(o);\n+            }\n+            \/\/ Trigger null pointer exception.\n+            o = null;\n+            boolean nullPointerException = false;\n+            try {\n+                testLoadVolatile(o);\n+            } catch (NullPointerException e) { nullPointerException = true; }\n+            Asserts.assertTrue(nullPointerException);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 and ZGC stores cannot be currently used to implement implicit null\n+    \/\/ checks, because they expand into multiple memory access instructions that\n+    \/\/ are not necessarily located at the initial instruction start address.\n+    @IR(failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static void testStore(Outer o, Object o1) {\n+        o.f = o1;\n+    }\n+\n+    @Run(test = {\"testStore\"})\n+    static void runStoreTests() {\n+        {\n+            Outer o = new Outer();\n+            Object o1 = new Object();\n+            testStore(o, o1);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 and ZGC compare-and-exchange operations cannot be currently used to\n+    \/\/ implement implicit null checks, because they expand into multiple memory\n+    \/\/ access instructions that are not necessarily located at the initial\n+    \/\/ instruction start address. The same holds for testCompareAndSwap and\n+    \/\/ testGetAndSet below.\n+    @IR(failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testCompareAndExchange(Outer o, Object oldVal, Object newVal) {\n+        return fVarHandle.compareAndExchange(o, oldVal, newVal);\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static boolean testCompareAndSwap(Outer o, Object oldVal, Object newVal) {\n+        return fVarHandle.compareAndSet(o, oldVal, newVal);\n+    }\n+\n+    @Test\n+    @IR(failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testGetAndSet(Outer o, Object newVal) {\n+        return fVarHandle.getAndSet(o, newVal);\n+    }\n+\n+    @Run(test = {\"testCompareAndExchange\",\n+                 \"testCompareAndSwap\",\n+                 \"testGetAndSet\"})\n+    static void runAtomicTests() {\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testCompareAndExchange(o, oldVal, newVal);\n+        }\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testCompareAndSwap(o, oldVal, newVal);\n+        }\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testGetAndSet(o, newVal);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 reference loads use indirect memory operands, which leads to a pattern\n+    \/\/ that cannot be exploited by the current C2 analysis. The same holds for\n+    \/\/ testLoadWeakReference.\n+    @IR(applyIf = {\"UseG1GC\", \"false\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadSoftReference(SoftReference<Object> ref) {\n+        return ref.get();\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"UseG1GC\", \"false\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadWeakReference(WeakReference<Object> ref) {\n+        return ref.get();\n+    }\n+\n+    @Run(test = {\"testLoadSoftReference\",\n+                 \"testLoadWeakReference\"})\n+    static void runReferenceTests() {\n+        {\n+            Object o1 = new Object();\n+            SoftReference<Object> sref = new SoftReference<Object>(o1);\n+            Object o2 = testLoadSoftReference(sref);\n+        }\n+        {\n+            Object o1 = new Object();\n+            WeakReference<Object> wref = new WeakReference<Object>(o1);\n+            Object o2 = testLoadWeakReference(wref);\n+        }\n+    }\n+\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/gcbarriers\/TestImplicitNullChecks.java","additions":240,"deletions":0,"binary":false,"changes":240,"status":"added"},{"patch":"@@ -1313,0 +1313,5 @@\n+    public static final String NULL_CHECK = PREFIX + \"NULL_CHECK\" + POSTFIX;\n+    static {\n+        machOnlyNameRegex(NULL_CHECK, \"NullCheck\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"}]}