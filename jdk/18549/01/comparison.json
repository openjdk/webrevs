{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -107,0 +107,1 @@\n+  LOG_TAG(jmethod) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2270,0 +2270,11 @@\n+jmethodID InstanceKlass::update_jmethod_id(jmethodID* jmeths, Method* method, int idnum) {\n+  if (method->is_old() && !method->is_obsolete()) {\n+    \/\/ If the method passed in is old (but not obsolete), use the current version\n+    method = method_with_idnum((int)idnum);\n+    assert(method != nullptr, \"old and but not obsolete, so should exist\");\n+  }\n+  jmethodID new_id = Method::make_jmethod_id(class_loader_data(), method);\n+  Atomic::release_store(&jmeths[idnum+1], new_id);\n+  return new_id;\n+}\n+\n@@ -2276,1 +2287,2 @@\n-  size_t idnum = (size_t)method_h->method_idnum();\n+  Method* method = method_h();\n+  int idnum = method->method_idnum();\n@@ -2278,2 +2290,0 @@\n-  size_t length = 0;\n-  jmethodID id = nullptr;\n@@ -2291,1 +2301,1 @@\n-  \/\/ generally acquired in those two cases.\n+  \/\/ acquired in those two cases.\n@@ -2293,38 +2303,12 @@\n-  \/\/ If the RedefineClasses() API has been used, then this cache can\n-  \/\/ grow and we'll have transitions from non-null to bigger non-null.\n-  \/\/ Cache creation requires no leaks and we require safety between all\n-  \/\/ cache accesses and freeing of the old cache so a lock is generally\n-  \/\/ acquired when the RedefineClasses() API has been used.\n-\n-  if (jmeths != nullptr) {\n-    \/\/ the cache already exists\n-    if (!idnum_can_increment()) {\n-      \/\/ the cache can't grow so we can just get the current values\n-      get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-    } else {\n-      MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n-      get_jmethod_id_length_value(jmeths, idnum, &length, &id);\n-    }\n-  }\n-  \/\/ implied else:\n-  \/\/ we need to allocate a cache so default length and id values are good\n-\n-  if (jmeths == nullptr ||   \/\/ no cache yet\n-      length <= idnum ||     \/\/ cache is too short\n-      id == nullptr) {       \/\/ cache doesn't contain entry\n-\n-    \/\/ This function can be called by the VMThread or GC worker threads so we\n-    \/\/ have to do all things that might block on a safepoint before grabbing the lock.\n-    \/\/ Otherwise, we can deadlock with the VMThread or have a cache\n-    \/\/ consistency issue. These vars keep track of what we might have\n-    \/\/ to free after the lock is dropped.\n-    jmethodID  to_dealloc_id     = nullptr;\n-    jmethodID* to_dealloc_jmeths = nullptr;\n-\n-    \/\/ may not allocate new_jmeths or use it if we allocate it\n-    jmethodID* new_jmeths = nullptr;\n-    if (length <= idnum) {\n-      \/\/ allocate a new cache that might be used\n-      size_t size = MAX2(idnum+1, (size_t)idnum_allocated_count());\n-      new_jmeths = NEW_C_HEAP_ARRAY(jmethodID, size+1, mtClass);\n-      memset(new_jmeths, 0, (size+1)*sizeof(jmethodID));\n+  \/\/ If the RedefineClasses() API has been used, then this cache grows\n+  \/\/ in the redefinition safepoint.\n+\n+  if (jmeths == nullptr) {\n+    MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+    jmeths = methods_jmethod_ids_acquire();\n+    \/\/ Still null?\n+    if (jmeths == nullptr) {\n+      size_t size = idnum_allocated_count();\n+      assert(size > (size_t)idnum, \"should already have space\");\n+      jmeths = NEW_C_HEAP_ARRAY(jmethodID, size+1, mtClass);\n+      memset(jmeths, 0, (size+1)*sizeof(jmethodID));\n@@ -2332,17 +2316,2 @@\n-      new_jmeths[0] = (jmethodID)size;\n-    }\n-\n-    \/\/ allocate a new jmethodID that might be used\n-    {\n-      MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n-      jmethodID new_id = nullptr;\n-      if (method_h->is_old() && !method_h->is_obsolete()) {\n-        \/\/ The method passed in is old (but not obsolete), we need to use the current version\n-        Method* current_method = method_with_idnum((int)idnum);\n-        assert(current_method != nullptr, \"old and but not obsolete, so should exist\");\n-        new_id = Method::make_jmethod_id(class_loader_data(), current_method);\n-      } else {\n-        \/\/ It is the current version of the method or an obsolete method,\n-        \/\/ use the version passed in\n-        new_id = Method::make_jmethod_id(class_loader_data(), method_h());\n-      }\n+      jmeths[0] = (jmethodID)size;\n+      jmethodID new_id = update_jmethod_id(jmeths, method, idnum);\n@@ -2350,2 +2319,3 @@\n-      id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,\n-                                          &to_dealloc_id, &to_dealloc_jmeths);\n+      \/\/ publish jmeths\n+      release_set_methods_jmethod_ids(jmeths);\n+      return new_id;\n@@ -2353,0 +2323,1 @@\n+  }\n@@ -2354,8 +2325,7 @@\n-    \/\/ The lock has been dropped so we can free resources.\n-    \/\/ Free up either the old cache or the new cache if we allocated one.\n-    if (to_dealloc_jmeths != nullptr) {\n-      FreeHeap(to_dealloc_jmeths);\n-    }\n-    \/\/ free up the new ID since it wasn't needed\n-    if (to_dealloc_id != nullptr) {\n-      Method::destroy_jmethod_id(class_loader_data(), to_dealloc_id);\n+  jmethodID id = Atomic::load_acquire(&jmeths[idnum+1]);\n+  if (id == nullptr) {\n+    MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+    id = jmeths[idnum+1];\n+    \/\/ Still null?\n+    if (id == nullptr) {\n+      return update_jmethod_id(jmeths, method, idnum);\n@@ -2367,0 +2337,23 @@\n+void InstanceKlass::update_methods_jmethod_cache() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"only called at safepoint\");\n+  jmethodID* cache = _methods_jmethod_ids;\n+  if (cache != nullptr) {\n+    size_t size = idnum_allocated_count();\n+    size_t old_size = (size_t)cache[0];\n+    if (old_size < size+1) {\n+      \/\/ allocate a larger one and copy entries to the new one.\n+      \/\/ They've already been updated to point to new methods where applicable (ie. not obsolete)\n+      jmethodID* new_cache = NEW_C_HEAP_ARRAY(jmethodID, size+1, mtClass);\n+      memset(new_cache, 0, (size+1)*sizeof(jmethodID));\n+      \/\/ cache size is stored in element[0], other elements offset by one\n+      new_cache[0] = (jmethodID)size;\n+\n+      for (int i = 1; i <= (int)old_size; i++) {\n+        new_cache[i] = cache[i];\n+      }\n+      _methods_jmethod_ids = new_cache;\n+      FREE_C_HEAP_ARRAY(jmethodID, cache);\n+    }\n+  }\n+}\n+\n@@ -2387,71 +2380,0 @@\n-\/\/ Common code to fetch the jmethodID from the cache or update the\n-\/\/ cache with the new jmethodID. This function should never do anything\n-\/\/ that causes the caller to go to a safepoint or we can deadlock with\n-\/\/ the VMThread or have cache consistency issues.\n-\/\/\n-jmethodID InstanceKlass::get_jmethod_id_fetch_or_update(\n-            size_t idnum, jmethodID new_id,\n-            jmethodID* new_jmeths, jmethodID* to_dealloc_id_p,\n-            jmethodID** to_dealloc_jmeths_p) {\n-  assert(new_id != nullptr, \"sanity check\");\n-  assert(to_dealloc_id_p != nullptr, \"sanity check\");\n-  assert(to_dealloc_jmeths_p != nullptr, \"sanity check\");\n-  assert(JmethodIdCreation_lock->owned_by_self(), \"sanity check\");\n-\n-  \/\/ reacquire the cache - we are locked, single threaded or at a safepoint\n-  jmethodID* jmeths = methods_jmethod_ids_acquire();\n-  jmethodID  id     = nullptr;\n-  size_t     length = 0;\n-\n-  if (jmeths == nullptr ||                      \/\/ no cache yet\n-      (length = (size_t)jmeths[0]) <= idnum) {  \/\/ cache is too short\n-    if (jmeths != nullptr) {\n-      \/\/ copy any existing entries from the old cache\n-      for (size_t index = 0; index < length; index++) {\n-        new_jmeths[index+1] = jmeths[index+1];\n-      }\n-      *to_dealloc_jmeths_p = jmeths;  \/\/ save old cache for later delete\n-    }\n-    release_set_methods_jmethod_ids(jmeths = new_jmeths);\n-  } else {\n-    \/\/ fetch jmethodID (if any) from the existing cache\n-    id = jmeths[idnum+1];\n-    *to_dealloc_jmeths_p = new_jmeths;  \/\/ save new cache for later delete\n-  }\n-  if (id == nullptr) {\n-    \/\/ No matching jmethodID in the existing cache or we have a new\n-    \/\/ cache or we just grew the cache. This cache write is done here\n-    \/\/ by the first thread to win the foot race because a jmethodID\n-    \/\/ needs to be unique once it is generally available.\n-    id = new_id;\n-\n-    \/\/ The jmethodID cache can be read while unlocked so we have to\n-    \/\/ make sure the new jmethodID is complete before installing it\n-    \/\/ in the cache.\n-    Atomic::release_store(&jmeths[idnum+1], id);\n-  } else {\n-    *to_dealloc_id_p = new_id; \/\/ save new id for later delete\n-  }\n-  return id;\n-}\n-\n-\n-\/\/ Common code to get the jmethodID cache length and the jmethodID\n-\/\/ value at index idnum if there is one.\n-\/\/\n-void InstanceKlass::get_jmethod_id_length_value(jmethodID* cache,\n-       size_t idnum, size_t *length_p, jmethodID* id_p) {\n-  assert(cache != nullptr, \"sanity check\");\n-  assert(length_p != nullptr, \"sanity check\");\n-  assert(id_p != nullptr, \"sanity check\");\n-\n-  \/\/ cache size is stored in element[0], other elements offset by one\n-  *length_p = (size_t)cache[0];\n-  if (*length_p <= idnum) {  \/\/ cache is too short\n-    *id_p = nullptr;\n-  } else {\n-    *id_p = cache[idnum+1];  \/\/ fetch jmethodID (if any)\n-  }\n-}\n-\n-\n@@ -2460,1 +2382,1 @@\n-  size_t idnum = (size_t)method->method_idnum();\n+  int idnum = method->method_idnum();\n@@ -2462,7 +2384,1 @@\n-  size_t length;                                \/\/ length assigned as debugging crumb\n-  jmethodID id = nullptr;\n-  if (jmeths != nullptr &&                      \/\/ If there is a cache\n-      (length = (size_t)jmeths[0]) > idnum) {   \/\/ and if it is long enough,\n-    id = jmeths[idnum+1];                       \/\/ Look up the id (may be null)\n-  }\n-  return id;\n+  return (jmeths != nullptr) ? jmeths[idnum+1] : nullptr;\n@@ -2887,1 +2803,1 @@\n-  if (jmeths != (jmethodID*)nullptr) {\n+  if (jmeths != nullptr) {\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":65,"deletions":149,"binary":false,"changes":214,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -240,3 +240,3 @@\n-  JNIid*          _jni_ids;              \/\/ First JNI identifier for static fields in this class\n-  jmethodID*      volatile _methods_jmethod_ids;  \/\/ jmethodIDs corresponding to method_idnum, or null if none\n-  nmethodBucket*  volatile _dep_context;          \/\/ packed DependencyContext structure\n+  JNIid*          _jni_ids;                  \/\/ First JNI identifier for static fields in this class\n+  jmethodID* volatile _methods_jmethod_ids;  \/\/ jmethodIDs corresponding to method_idnum, or null if none\n+  nmethodBucket*  volatile _dep_context;     \/\/ packed DependencyContext structure\n@@ -797,6 +797,0 @@\n-  jmethodID get_jmethod_id_fetch_or_update(size_t idnum,\n-                     jmethodID new_id, jmethodID* new_jmeths,\n-                     jmethodID* to_dealloc_id_p,\n-                     jmethodID** to_dealloc_jmeths_p);\n-  static void get_jmethod_id_length_value(jmethodID* cache, size_t idnum,\n-                size_t *length_p, jmethodID* id_p);\n@@ -805,0 +799,1 @@\n+  void update_methods_jmethod_cache();\n@@ -1076,5 +1071,0 @@\n-  \/\/ The RedefineClasses() API can cause new method idnums to be needed\n-  \/\/ which will cause the caches to grow. Safety requires different\n-  \/\/ cache management logic if the caches can grow instead of just\n-  \/\/ going from null to non-null.\n-  bool idnum_can_increment() const      { return has_been_redefined(); }\n@@ -1085,0 +1075,1 @@\n+  jmethodID update_jmethod_id(jmethodID* jmeths, Method* method, int idnum);\n@@ -1086,1 +1077,0 @@\n-  \/\/ Lock during initialization\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":6,"deletions":16,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2146,8 +2146,0 @@\n-  \/\/ Doesn't really destroy it, just marks it as free so it can be reused.\n-  void destroy_method(Method** m) {\n-#ifdef ASSERT\n-    assert(contains(m), \"should be a methodID\");\n-#endif \/\/ ASSERT\n-    *m = _free_method;\n-  }\n-\n@@ -2206,0 +2198,3 @@\n+\n+  ResourceMark rm;\n+  log_info(jmethod)(\"Creating jmethodID for Method %s\", m->external_name());\n@@ -2218,8 +2213,0 @@\n-\/\/ Mark a jmethodID as free.  This is called when there is a data race in\n-\/\/ InstanceKlass while creating the jmethodID cache.\n-void Method::destroy_jmethod_id(ClassLoaderData* cld, jmethodID m) {\n-  Method** ptr = (Method**)m;\n-  assert(cld->jmethod_ids() != nullptr, \"should have method handles\");\n-  cld->jmethod_ids()->destroy_method(ptr);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":3,"deletions":16,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -703,1 +703,0 @@\n-  static void destroy_jmethod_id(ClassLoaderData* cld, jmethodID mid);\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -4353,1 +4353,2 @@\n-  \/\/ Leave arrays of jmethodIDs and itable index cache unchanged\n+  \/\/ Update jmethodID cache if present\n+  the_class->update_methods_jmethod_cache();\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -256,1 +256,0 @@\n-  volatile_nonstatic_field(InstanceKlass,      _methods_jmethod_ids,                          jmethodID*)                            \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}