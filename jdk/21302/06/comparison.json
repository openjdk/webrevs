{"files":[{"patch":"@@ -393,0 +393,142 @@\n+ArchiveWorkers::ArchiveWorkers() :\n+        _start_semaphore(0),\n+        _end_semaphore(0),\n+        _num_workers(max_workers()),\n+        _started_workers(0),\n+        _running_workers(0),\n+        _in_shutdown(false),\n+        _task(nullptr) {\n+  \/\/ Kick off pool startup by creating a single worker.\n+  start_worker_if_needed();\n+}\n+\n+ArchiveWorkers::~ArchiveWorkers() {\n+  \/\/ If nothing called shutdown yet, we need to gracefully shutdown now.\n+  shutdown();\n+}\n+\n+int ArchiveWorkers::max_workers() {\n+  return MAX2(0, MIN2(MAX_WORKERS, os::active_processor_count() \/ CPUS_PER_WORKER) - 1);\n+}\n+\n+bool ArchiveWorkers::is_parallel() {\n+  return _num_workers > 0;\n+}\n+\n+void ArchiveWorkers::shutdown() {\n+  if (is_parallel() &&\n+      Atomic::cmpxchg(&_in_shutdown, false, true, memory_order_relaxed) == false) {\n+    \/\/ Execute a shutdown task and block until all workers respond.\n+    run_task(&_shutdown_task);\n+  }\n+}\n+\n+void ArchiveWorkers::start_worker_if_needed() {\n+  while (true) {\n+    int cur = Atomic::load(&_started_workers);\n+    if (cur >= _num_workers) {\n+      return;\n+    }\n+    if (Atomic::cmpxchg(&_started_workers, cur, cur + 1, memory_order_relaxed) == cur) {\n+      break;\n+    }\n+  }\n+\n+  new ArchiveWorkerThread(this);\n+}\n+\n+void ArchiveWorkers::run_task(ArchiveWorkerTask* task) {\n+  assert(task == &_shutdown_task || !_in_shutdown, \"Should not be shutdown\");\n+  assert(Atomic::load(&_task) == nullptr, \"Should not have running tasks\");\n+\n+  if (is_parallel()) {\n+    run_task_multi(task);\n+  } else {\n+    run_task_single(task);\n+  }\n+}\n+\n+void ArchiveWorkers::run_task_single(ArchiveWorkerTask* task) {\n+  \/\/ Single thread needs no chunking.\n+  task->configure_max_chunks(1);\n+\n+  \/\/ Execute the task ourselves, as there are no workers.\n+  task->work(0, 1);\n+}\n+\n+void ArchiveWorkers::run_task_multi(ArchiveWorkerTask* task) {\n+  \/\/ Multiple threads can work with multiple chunks.\n+  task->configure_max_chunks(_num_workers * CHUNKS_PER_WORKER);\n+\n+  \/\/ Publish the task and signal workers to pick it up.\n+  Atomic::store(&_running_workers, _num_workers);\n+  Atomic::release_store(&_task, task);\n+  _start_semaphore.signal(_num_workers);\n+\n+  \/\/ Execute the task ourselves, while workers are catching up.\n+  \/\/ This allows us to hide parts of task handoff latency.\n+  task->run();\n+\n+  \/\/ Done executing task locally, wait for any remaining workers to complete,\n+  \/\/ and then do the final housekeeping.\n+  _end_semaphore.wait();\n+  Atomic::store(&_task, (ArchiveWorkerTask *) nullptr);\n+  OrderAccess::fence();\n+}\n+\n+void ArchiveWorkerTask::run() {\n+  while (true) {\n+    int chunk = Atomic::load(&_chunk);\n+    if (chunk >= _max_chunks) {\n+      return;\n+    }\n+    if (Atomic::cmpxchg(&_chunk, chunk, chunk + 1, memory_order_relaxed) == chunk) {\n+      assert(0 <= chunk && chunk < _max_chunks, \"Sanity\");\n+      work(chunk, _max_chunks);\n+    }\n+  }\n+}\n+\n+void ArchiveWorkerTask::configure_max_chunks(int max_chunks) {\n+  if (_max_chunks == 0) {\n+    _max_chunks = max_chunks;\n+  }\n+}\n+\n+bool ArchiveWorkers::run_as_worker() {\n+  assert(is_parallel(), \"Should be in parallel mode\");\n+  _start_semaphore.wait();\n+\n+  ArchiveWorkerTask* task = Atomic::load_acquire(&_task);\n+  task->run();\n+\n+  \/\/ Signal the pool the tasks are complete, if this is the last worker.\n+  if (Atomic::sub(&_running_workers, 1, memory_order_relaxed) == 0) {\n+    _end_semaphore.signal();\n+  }\n+\n+  \/\/ Continue if task was not a termination task.\n+  return (task != &_shutdown_task);\n+}\n+\n+ArchiveWorkerThread::ArchiveWorkerThread(ArchiveWorkers* pool) : NamedThread(), _pool(pool) {\n+  set_name(\"ArchiveWorkerThread\");\n+  os::create_thread(this, os::os_thread);\n+  os::start_thread(this);\n+}\n+\n+void ArchiveWorkerThread::run() {\n+  \/\/ Avalanche thread startup: each starting worker starts two others.\n+  _pool->start_worker_if_needed();\n+  _pool->start_worker_if_needed();\n+\n+  \/\/ Set ourselves up.\n+  os::set_priority(this, NearMaxPriority);\n+\n+  while (_pool->run_as_worker()) {\n+    \/\/ Work until terminated.\n+  }\n+\n+  \/\/ All work done in threads should be visible to caller.\n+  OrderAccess::fence();\n+}\n","filename":"src\/hotspot\/share\/cds\/archiveUtils.cpp","additions":142,"deletions":0,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+#include \"runtime\/nonJavaThread.hpp\"\n+#include \"runtime\/semaphore.hpp\"\n@@ -293,0 +295,91 @@\n+class ArchiveWorkers;\n+\n+\/\/ A task to be worked on by worker threads\n+class ArchiveWorkerTask : public CHeapObj<mtInternal> {\n+  friend class ArchiveWorkers;\n+  friend class ArchiveWorkerShutdownTask;\n+private:\n+  const char* _name;\n+  int _max_chunks;\n+  volatile int _chunk;\n+\n+  void run();\n+\n+  void configure_max_chunks(int max_chunks);\n+\n+public:\n+  ArchiveWorkerTask(const char* name) :\n+      _name(name), _max_chunks(0), _chunk(0) {}\n+  const char* name() const { return _name; }\n+  virtual void work(int chunk, int max_chunks) = 0;\n+};\n+\n+class ArchiveWorkerThread : public NamedThread {\n+  friend class ArchiveWorkers;\n+private:\n+  ArchiveWorkers* const _pool;\n+\n+public:\n+  ArchiveWorkerThread(ArchiveWorkers* pool);\n+  const char* type_name() const override { return \"Archive Worker Thread\"; }\n+  void run() override;\n+};\n+\n+class ArchiveWorkerShutdownTask : public ArchiveWorkerTask {\n+public:\n+  ArchiveWorkerShutdownTask() : ArchiveWorkerTask(\"Archive Worker Shutdown\") {\n+    \/\/ This task always have only one chunk.\n+    configure_max_chunks(1);\n+  }\n+  void work(int chunk, int max_chunks) override {\n+    \/\/ Do nothing.\n+  }\n+};\n+\n+\/\/ Special worker pool for archive workers. The goal for this pool is to\n+\/\/ startup fast, distribute spiky workloads efficiently, and being able to\n+\/\/ shutdown after use. This makes the implementation quite different from\n+\/\/ the normal GC worker pool.\n+class ArchiveWorkers {\n+  friend class ArchiveWorkerThread;\n+private:\n+  \/\/ The absolute limit on the number of archive workers. This should protect\n+  \/\/ from workers stumbling over each other on very large machines.\n+  static constexpr int MAX_WORKERS = 16;\n+\n+  \/\/ The reciprocal ratio for number of workers per CPU. We are targeting\n+  \/\/ to take 1\/2 CPUs to provide decent parallelism without letting workers\n+  \/\/ stumble over each other.\n+  static constexpr int CPUS_PER_WORKER = 2;\n+\n+  \/\/ Target number of chunks per worker. This should be large enough to even\n+  \/\/ out work imbalance, and small enough to keep bookkeeping overheads low.\n+  static constexpr int CHUNKS_PER_WORKER = 4;\n+\n+  static int max_workers();\n+\n+  ArchiveWorkerShutdownTask _shutdown_task;\n+  Semaphore _start_semaphore;\n+  Semaphore _end_semaphore;\n+\n+  int _num_workers;\n+  int _started_workers;\n+  int _running_workers;\n+  bool _in_shutdown;\n+  ArchiveWorkerTask* _task;\n+\n+  bool run_as_worker();\n+  void start_worker_if_needed();\n+\n+  void run_task_single(ArchiveWorkerTask* task);\n+  void run_task_multi(ArchiveWorkerTask* task);\n+\n+  bool is_parallel();\n+\n+public:\n+  ArchiveWorkers();\n+  ~ArchiveWorkers();\n+  void shutdown();\n+  void run_task(ArchiveWorkerTask* task);\n+};\n+\n","filename":"src\/hotspot\/share\/cds\/archiveUtils.hpp","additions":93,"deletions":0,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -97,0 +97,4 @@\n+                                                                            \\\n+  product(bool, ArchiveParallelRelocation, true, DIAGNOSTIC,                \\\n+          \"Use parallel relocation code to speed up startup.\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/cds\/cds_globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1741,0 +1741,3 @@\n+\n+  \/\/ Workers are no longer needed.\n+  _archive_workers.shutdown();\n@@ -1949,0 +1952,25 @@\n+class SharedDataRelocationTask : public ArchiveWorkerTask {\n+private:\n+  BitMapView* const _rw_bm;\n+  BitMapView* const _ro_bm;\n+  SharedDataRelocator* const _rw_reloc;\n+  SharedDataRelocator* const _ro_reloc;\n+\n+public:\n+  SharedDataRelocationTask(BitMapView* rw_bm, BitMapView* ro_bm, SharedDataRelocator* rw_reloc, SharedDataRelocator* ro_reloc) :\n+                           ArchiveWorkerTask(\"Shared Data Relocation\"),\n+                           _rw_bm(rw_bm), _ro_bm(ro_bm), _rw_reloc(rw_reloc), _ro_reloc(ro_reloc) {}\n+\n+  void work(int chunk, int max_chunks) override {\n+    work_on(chunk, max_chunks, _rw_bm, _rw_reloc);\n+    work_on(chunk, max_chunks, _ro_bm, _ro_reloc);\n+  }\n+\n+  void work_on(int chunk, int max_chunks, BitMapView* bm, SharedDataRelocator* reloc) {\n+    BitMap::idx_t size  = bm->size();\n+    BitMap::idx_t start = MIN2(size, size * chunk \/ max_chunks);\n+    BitMap::idx_t end   = MIN2(size, size * (chunk + 1) \/ max_chunks);\n+    bm->iterate(reloc, start, end);\n+  }\n+};\n+\n@@ -1987,2 +2015,8 @@\n-    rw_ptrmap.iterate(&rw_patcher);\n-    ro_ptrmap.iterate(&ro_patcher);\n+\n+    if (ArchiveParallelRelocation) {\n+      SharedDataRelocationTask task(&rw_ptrmap, &ro_ptrmap, &rw_patcher, &ro_patcher);\n+      _archive_workers.run_task(&task);\n+    } else {\n+      rw_ptrmap.iterate(&rw_patcher);\n+      ro_ptrmap.iterate(&ro_patcher);\n+    }\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":36,"deletions":2,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -345,0 +345,2 @@\n+  ArchiveWorkers _archive_workers;\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"}]}