{"files":[{"patch":"@@ -1129,4 +1129,0 @@\n-\/\/ Figure out which register class each belongs in: rc_int, rc_float or\n-\/\/ rc_stack.\n-enum RC { rc_bad, rc_int, rc_float, rc_predicate, rc_stack };\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -37,0 +37,4 @@\n+#ifdef COMPILER2\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -422,0 +426,201 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::encode_float_vector_register_size(const Node* node, OptoReg::Name opto_reg) {\n+  switch (node->ideal_reg()) {\n+    case Op_RegF:\n+      \/\/ No need to refine. The original encoding is already fine to distinguish.\n+      assert(opto_reg % 4 == 0, \"Float register should only occupy a single slot\");\n+      break;\n+    \/\/ Use different encoding values of the same fp\/vector register to help distinguish different sizes.\n+    \/\/ Such as V16. The OptoReg::name and its corresponding slot value are\n+    \/\/ \"V16\": 64, \"V16_H\": 65, \"V16_J\": 66, \"V16_K\": 67.\n+    case Op_RegD:\n+    case Op_VecD:\n+      opto_reg &= ~3;\n+      opto_reg |= 1;\n+      break;\n+    case Op_VecX:\n+      opto_reg &= ~3;\n+      opto_reg |= 2;\n+      break;\n+    case Op_VecA:\n+      opto_reg &= ~3;\n+      opto_reg |= 3;\n+      break;\n+    default:\n+      assert(false, \"unexpected ideal register\");\n+      ShouldNotReachHere();\n+  }\n+  return opto_reg;\n+}\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if (vm_reg->is_FloatRegister()) {\n+    opto_reg = encode_float_vector_register_size(node, opto_reg);\n+  }\n+\n+  return opto_reg;\n+}\n+\n+#undef __\n+#define __ _masm->\n+\n+void SaveLiveRegisters::initialize(BarrierStubC2* stub) {\n+  int index = -1;\n+  GrowableArray<RegisterData> registers;\n+  VMReg prev_vm_reg = VMRegImpl::Bad();\n+\n+  RegMaskIterator rmi(stub->live());\n+  while (rmi.has_next()) {\n+    OptoReg::Name opto_reg = rmi.next();\n+    VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+\n+    if (vm_reg->is_Register()) {\n+      \/\/ GPR may have one or two slots in regmask\n+      \/\/ Determine whether the current vm_reg is the same physical register as the previous one\n+      if (is_same_register(vm_reg, prev_vm_reg)) {\n+        registers.at(index)._slots++;\n+      } else {\n+        RegisterData reg_data = { vm_reg, 1 };\n+        index = registers.append(reg_data);\n+      }\n+    } else if (vm_reg->is_FloatRegister()) {\n+      \/\/ We have size encoding in OptoReg of stub->live()\n+      \/\/ After encoding, float\/neon\/sve register has only one slot in regmask\n+      \/\/ Decode it to get the actual size\n+      VMReg vm_reg_base = vm_reg->as_FloatRegister()->as_VMReg();\n+      int slots = decode_float_vector_register_size(opto_reg);\n+      RegisterData reg_data = { vm_reg_base, slots };\n+      index = registers.append(reg_data);\n+    } else if (vm_reg->is_PRegister()) {\n+      \/\/ PRegister has only one slot in regmask\n+      RegisterData reg_data = { vm_reg, 1 };\n+      index = registers.append(reg_data);\n+    } else {\n+      assert(false, \"Unknown register type\");\n+      ShouldNotReachHere();\n+    }\n+    prev_vm_reg = vm_reg;\n+  }\n+\n+  \/\/ Record registers that needs to be saved\/restored\n+  for (GrowableArrayIterator<RegisterData> it = registers.begin(); it != registers.end(); ++it) {\n+    RegisterData reg_data = *it;\n+    VMReg vm_reg = reg_data._reg;\n+    int slots = reg_data._slots;\n+    if (vm_reg->is_Register()) {\n+      assert(slots == 1 || slots == 2, \"Unexpected register save size\");\n+      _gp_regs += RegSet::of(vm_reg->as_Register());\n+    } else if (vm_reg->is_FloatRegister()) {\n+      if (slots == 1 || slots == 2) {\n+        _fp_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      } else if (slots == 4) {\n+        _neon_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      } else {\n+        assert(slots == Matcher::scalable_vector_reg_size(T_FLOAT), \"Unexpected register save size\");\n+        _sve_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      }\n+    } else {\n+      assert(vm_reg->is_PRegister() && slots == 1, \"Unknown register type\");\n+      _p_regs += PRegSet::of(vm_reg->as_PRegister());\n+    }\n+  }\n+\n+  \/\/ Remove C-ABI SOE registers, scratch regs and _ref register that will be updated\n+  if (stub->result() != noreg) {\n+    _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9, stub->result());\n+  } else {\n+    _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9);\n+  }\n+\n+  \/\/ Remove C-ABI SOE fp registers\n+  _fp_regs -= FloatRegSet::range(v8, v15);\n+}\n+\n+enum RC SaveLiveRegisters::rc_class(VMReg reg) {\n+  if (reg->is_reg()) {\n+    if (reg->is_Register()) {\n+      return rc_int;\n+    } else if (reg->is_FloatRegister()) {\n+      return rc_float;\n+    } else if (reg->is_PRegister()) {\n+      return rc_predicate;\n+    }\n+  }\n+  if (reg->is_stack()) {\n+    return rc_stack;\n+  }\n+  return rc_bad;\n+}\n+\n+bool SaveLiveRegisters::is_same_register(VMReg reg1, VMReg reg2) {\n+  if (reg1 == reg2) {\n+    return true;\n+  }\n+  if (rc_class(reg1) == rc_class(reg2)) {\n+    if (reg1->is_Register()) {\n+      return reg1->as_Register() == reg2->as_Register();\n+    } else if (reg1->is_FloatRegister()) {\n+      return reg1->as_FloatRegister() == reg2->as_FloatRegister();\n+    } else if (reg1->is_PRegister()) {\n+      return reg1->as_PRegister() == reg2->as_PRegister();\n+    }\n+  }\n+  return false;\n+}\n+\n+int SaveLiveRegisters::decode_float_vector_register_size(OptoReg::Name opto_reg) {\n+  switch (opto_reg & 3) {\n+    case 0:\n+      return 1;\n+    case 1:\n+      return 2;\n+    case 2:\n+      return 4;\n+    case 3:\n+      return Matcher::scalable_vector_reg_size(T_FLOAT);\n+    default:\n+      ShouldNotReachHere();\n+      return 0;\n+  }\n+}\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub)\n+  : _masm(masm),\n+    _gp_regs(),\n+    _fp_regs(),\n+    _neon_regs(),\n+    _sve_regs(),\n+    _p_regs() {\n+\n+  \/\/ Figure out what registers to save\/restore\n+  initialize(stub);\n+\n+  \/\/ Save registers\n+  __ push(_gp_regs, sp);\n+  __ push_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n+  __ push_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n+  __ push_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n+  __ push_p(_p_regs, sp);\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  \/\/ Restore registers\n+  __ pop_p(_p_regs, sp);\n+  __ pop_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n+  __ pop_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n+  __ pop_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n+\n+  \/\/ External runtime call may clobber ptrue reg\n+  __ reinitialize_ptrue();\n+\n+  __ pop(_gp_regs, sp);\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":205,"deletions":0,"binary":false,"changes":205,"status":"modified"},{"patch":"@@ -33,0 +33,6 @@\n+#ifdef COMPILER2\n+#include \"opto\/optoreg.hpp\"\n+\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -132,0 +138,46 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name encode_float_vector_register_size(const Node* node,\n+                                                  OptoReg::Name opto_reg);\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ blr(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+private:\n+  struct RegisterData {\n+    VMReg _reg;\n+    int   _slots; \/\/ slots occupied once pushed into stack\n+\n+    \/\/ Used by GrowableArray::find()\n+    bool operator == (const RegisterData& other) {\n+      return _reg == other._reg;\n+    }\n+  };\n+\n+  MacroAssembler* const _masm;\n+  RegSet                _gp_regs;\n+  FloatRegSet           _fp_regs;\n+  FloatRegSet           _neon_regs;\n+  FloatRegSet           _sve_regs;\n+  PRegSet               _p_regs;\n+\n+  static enum RC rc_class(VMReg reg);\n+  static bool is_same_register(VMReg reg1, VMReg reg2);\n+  static int decode_float_vector_register_size(OptoReg::Name opto_reg);\n+\n+public:\n+  void initialize(BarrierStubC2* stub);\n+  SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub);\n+  ~SaveLiveRegisters();\n@@ -134,0 +186,2 @@\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -1084,218 +1084,0 @@\n-OptoReg::Name ZBarrierSetAssembler::encode_float_vector_register_size(const Node* node, OptoReg::Name opto_reg) {\n-  switch (node->ideal_reg()) {\n-    case Op_RegF:\n-      \/\/ No need to refine. The original encoding is already fine to distinguish.\n-      assert(opto_reg % 4 == 0, \"Float register should only occupy a single slot\");\n-      break;\n-    \/\/ Use different encoding values of the same fp\/vector register to help distinguish different sizes.\n-    \/\/ Such as V16. The OptoReg::name and its corresponding slot value are\n-    \/\/ \"V16\": 64, \"V16_H\": 65, \"V16_J\": 66, \"V16_K\": 67.\n-    case Op_RegD:\n-    case Op_VecD:\n-      opto_reg &= ~3;\n-      opto_reg |= 1;\n-      break;\n-    case Op_VecX:\n-      opto_reg &= ~3;\n-      opto_reg |= 2;\n-      break;\n-    case Op_VecA:\n-      opto_reg &= ~3;\n-      opto_reg |= 3;\n-      break;\n-    default:\n-      assert(false, \"unexpected ideal register\");\n-      ShouldNotReachHere();\n-  }\n-  return opto_reg;\n-}\n-\n-OptoReg::Name ZBarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n-  if (!OptoReg::is_reg(opto_reg)) {\n-    return OptoReg::Bad;\n-  }\n-\n-  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-  if (vm_reg->is_FloatRegister()) {\n-    opto_reg = encode_float_vector_register_size(node, opto_reg);\n-  }\n-\n-  return opto_reg;\n-}\n-\n-#undef __\n-#define __ _masm->\n-\n-class ZSaveLiveRegisters {\n-private:\n-  struct RegisterData {\n-    VMReg _reg;\n-    int   _slots; \/\/ slots occupied once pushed into stack\n-\n-    \/\/ Used by GrowableArray::find()\n-    bool operator == (const RegisterData& other) {\n-      return _reg == other._reg;\n-    }\n-  };\n-\n-  MacroAssembler* const _masm;\n-  RegSet                _gp_regs;\n-  FloatRegSet           _fp_regs;\n-  FloatRegSet           _neon_regs;\n-  FloatRegSet           _sve_regs;\n-  PRegSet               _p_regs;\n-\n-public:\n-  void initialize(ZBarrierStubC2* stub) {\n-    int index = -1;\n-    GrowableArray<RegisterData> registers;\n-    VMReg prev_vm_reg = VMRegImpl::Bad();\n-\n-    RegMaskIterator rmi(stub->live());\n-    while (rmi.has_next()) {\n-      OptoReg::Name opto_reg = rmi.next();\n-      VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-\n-      if (vm_reg->is_Register()) {\n-        \/\/ GPR may have one or two slots in regmask\n-        \/\/ Determine whether the current vm_reg is the same physical register as the previous one\n-        if (is_same_register(vm_reg, prev_vm_reg)) {\n-          registers.at(index)._slots++;\n-        } else {\n-          RegisterData reg_data = { vm_reg, 1 };\n-          index = registers.append(reg_data);\n-        }\n-      } else if (vm_reg->is_FloatRegister()) {\n-        \/\/ We have size encoding in OptoReg of stub->live()\n-        \/\/ After encoding, float\/neon\/sve register has only one slot in regmask\n-        \/\/ Decode it to get the actual size\n-        VMReg vm_reg_base = vm_reg->as_FloatRegister()->as_VMReg();\n-        int slots = decode_float_vector_register_size(opto_reg);\n-        RegisterData reg_data = { vm_reg_base, slots };\n-        index = registers.append(reg_data);\n-      } else if (vm_reg->is_PRegister()) {\n-        \/\/ PRegister has only one slot in regmask\n-        RegisterData reg_data = { vm_reg, 1 };\n-        index = registers.append(reg_data);\n-      } else {\n-        assert(false, \"Unknown register type\");\n-        ShouldNotReachHere();\n-      }\n-      prev_vm_reg = vm_reg;\n-    }\n-\n-    \/\/ Record registers that needs to be saved\/restored\n-    for (GrowableArrayIterator<RegisterData> it = registers.begin(); it != registers.end(); ++it) {\n-      RegisterData reg_data = *it;\n-      VMReg vm_reg = reg_data._reg;\n-      int slots = reg_data._slots;\n-      if (vm_reg->is_Register()) {\n-        assert(slots == 1 || slots == 2, \"Unexpected register save size\");\n-        _gp_regs += RegSet::of(vm_reg->as_Register());\n-      } else if (vm_reg->is_FloatRegister()) {\n-        if (slots == 1 || slots == 2) {\n-          _fp_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n-        } else if (slots == 4) {\n-          _neon_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n-        } else {\n-          assert(slots == Matcher::scalable_vector_reg_size(T_FLOAT), \"Unexpected register save size\");\n-          _sve_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n-        }\n-      } else {\n-        assert(vm_reg->is_PRegister() && slots == 1, \"Unknown register type\");\n-        _p_regs += PRegSet::of(vm_reg->as_PRegister());\n-      }\n-    }\n-\n-    \/\/ Remove C-ABI SOE registers, scratch regs and _ref register that will be updated\n-    if (stub->result() != noreg) {\n-      _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9, stub->result());\n-    } else {\n-      _gp_regs -= RegSet::range(r19, r30) + RegSet::of(r8, r9);\n-    }\n-\n-    \/\/ Remove C-ABI SOE fp registers\n-    _fp_regs -= FloatRegSet::range(v8, v15);\n-  }\n-\n-  static enum RC rc_class(VMReg reg) {\n-    if (reg->is_reg()) {\n-      if (reg->is_Register()) {\n-        return rc_int;\n-      } else if (reg->is_FloatRegister()) {\n-        return rc_float;\n-      } else if (reg->is_PRegister()) {\n-        return rc_predicate;\n-      }\n-    }\n-    if (reg->is_stack()) {\n-      return rc_stack;\n-    }\n-    return rc_bad;\n-  }\n-\n-  static bool is_same_register(VMReg reg1, VMReg reg2) {\n-    if (reg1 == reg2) {\n-      return true;\n-    }\n-    if (rc_class(reg1) == rc_class(reg2)) {\n-      if (reg1->is_Register()) {\n-        return reg1->as_Register() == reg2->as_Register();\n-      } else if (reg1->is_FloatRegister()) {\n-        return reg1->as_FloatRegister() == reg2->as_FloatRegister();\n-      } else if (reg1->is_PRegister()) {\n-        return reg1->as_PRegister() == reg2->as_PRegister();\n-      }\n-    }\n-    return false;\n-  }\n-\n-  static int decode_float_vector_register_size(OptoReg::Name opto_reg) {\n-    switch (opto_reg & 3) {\n-      case 0:\n-        return 1;\n-      case 1:\n-        return 2;\n-      case 2:\n-        return 4;\n-      case 3:\n-        return Matcher::scalable_vector_reg_size(T_FLOAT);\n-      default:\n-        ShouldNotReachHere();\n-        return 0;\n-    }\n-  }\n-\n-  ZSaveLiveRegisters(MacroAssembler* masm, ZBarrierStubC2* stub)\n-    : _masm(masm),\n-      _gp_regs(),\n-      _fp_regs(),\n-      _neon_regs(),\n-      _sve_regs(),\n-      _p_regs() {\n-\n-    \/\/ Figure out what registers to save\/restore\n-    initialize(stub);\n-\n-    \/\/ Save registers\n-    __ push(_gp_regs, sp);\n-    __ push_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n-    __ push_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n-    __ push_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n-    __ push_p(_p_regs, sp);\n-  }\n-\n-  ~ZSaveLiveRegisters() {\n-    \/\/ Restore registers\n-    __ pop_p(_p_regs, sp);\n-    __ pop_fp(_sve_regs, sp, MacroAssembler::PushPopSVE);\n-    __ pop_fp(_neon_regs, sp, MacroAssembler::PushPopNeon);\n-    __ pop_fp(_fp_regs, sp, MacroAssembler::PushPopFp);\n-\n-    \/\/ External runtime call may clobber ptrue reg\n-    __ reinitialize_ptrue();\n-\n-    __ pop(_gp_regs, sp);\n-  }\n-};\n-\n@@ -1371,1 +1153,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n@@ -1403,1 +1185,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":2,"deletions":220,"binary":false,"changes":222,"status":"modified"},{"patch":"@@ -190,6 +190,0 @@\n-  OptoReg::Name encode_float_vector_register_size(const Node* node,\n-                                                  OptoReg::Name opto_reg);\n-\n-  OptoReg::Name refine_register(const Node* node,\n-                                OptoReg::Name opto_reg);\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -406,0 +406,3 @@\n+\/\/ High-level register class of an OptoReg or a VMReg register.\n+enum RC { rc_bad, rc_int, rc_float, rc_predicate, rc_stack };\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -245,0 +245,8 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  Unimplemented(); \/\/ This must be implemented to support late barrier expansion.\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/arm\/gc\/shared\/barrierSetAssembler_arm.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,6 @@\n+#ifdef COMPILER2\n+#include \"code\/vmreg.hpp\"\n+#include \"opto\/optoreg.hpp\"\n+\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -65,0 +71,5 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/arm\/gc\/shared\/barrierSetAssembler_arm.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -37,0 +37,3 @@\n+#ifdef COMPILER2\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -262,0 +265,116 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) const {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if ((vm_reg->is_Register() || vm_reg ->is_FloatRegister()) && (opto_reg & 1) != 0) {\n+    return OptoReg::Bad;\n+  }\n+\n+  return opto_reg;\n+}\n+\n+#undef __\n+#define __ _masm->\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler *masm, BarrierStubC2 *stub)\n+  : _masm(masm), _reg_mask(stub->live()), _result_reg(stub->result()) {\n+\n+  const int register_save_size = iterate_over_register_mask(ACTION_COUNT_ONLY) * BytesPerWord;\n+  _frame_size = align_up(register_save_size, frame::alignment_in_bytes)\n+                + frame::native_abi_reg_args_size;\n+\n+  __ save_LR_CR(R0);\n+  __ push_frame(_frame_size, R0);\n+\n+  iterate_over_register_mask(ACTION_SAVE, _frame_size);\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  iterate_over_register_mask(ACTION_RESTORE, _frame_size);\n+\n+  __ addi(R1_SP, R1_SP, _frame_size);\n+  __ restore_LR_CR(R0);\n+}\n+\n+int SaveLiveRegisters::iterate_over_register_mask(IterationAction action, int offset) {\n+  int reg_save_index = 0;\n+  RegMaskIterator live_regs_iterator(_reg_mask);\n+\n+  while(live_regs_iterator.has_next()) {\n+    const OptoReg::Name opto_reg = live_regs_iterator.next();\n+\n+    \/\/ Filter out stack slots (spilled registers, i.e., stack-allocated registers).\n+    if (!OptoReg::is_reg(opto_reg)) {\n+      continue;\n+    }\n+\n+    const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+    if (vm_reg->is_Register()) {\n+      Register std_reg = vm_reg->as_Register();\n+\n+      \/\/ '_result_reg' will hold the end result of the operation. Its content must thus not be preserved.\n+      if (std_reg == _result_reg) {\n+        continue;\n+      }\n+\n+      if (std_reg->encoding() >= R2->encoding() && std_reg->encoding() <= R12->encoding()) {\n+        reg_save_index++;\n+\n+        if (action == ACTION_SAVE) {\n+          _masm->std(std_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n+        } else if (action == ACTION_RESTORE) {\n+          _masm->ld(std_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n+        } else {\n+          assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n+        }\n+      }\n+    } else if (vm_reg->is_FloatRegister()) {\n+      FloatRegister fp_reg = vm_reg->as_FloatRegister();\n+      if (fp_reg->encoding() >= F0->encoding() && fp_reg->encoding() <= F13->encoding()) {\n+        reg_save_index++;\n+\n+        if (action == ACTION_SAVE) {\n+          _masm->stfd(fp_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n+        } else if (action == ACTION_RESTORE) {\n+          _masm->lfd(fp_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n+        } else {\n+          assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n+        }\n+      }\n+    } else if (vm_reg->is_ConditionRegister()) {\n+      \/\/ NOP. Conditions registers are covered by save_LR_CR\n+    } else if (vm_reg->is_VectorSRegister()) {\n+      assert(SuperwordUseVSX, \"or should not reach here\");\n+      VectorSRegister vs_reg = vm_reg->as_VectorSRegister();\n+      if (vs_reg->encoding() >= VSR32->encoding() && vs_reg->encoding() <= VSR51->encoding()) {\n+        reg_save_index += 2;\n+\n+        Register spill_addr = R0;\n+        if (action == ACTION_SAVE) {\n+          _masm->addi(spill_addr, R1_SP, offset - reg_save_index * BytesPerWord);\n+          _masm->stxvd2x(vs_reg, spill_addr);\n+        } else if (action == ACTION_RESTORE) {\n+          _masm->addi(spill_addr, R1_SP, offset - reg_save_index * BytesPerWord);\n+          _masm->lxvd2x(vs_reg, spill_addr);\n+        } else {\n+          assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n+        }\n+      }\n+    } else {\n+      if (vm_reg->is_SpecialRegister()) {\n+        fatal(\"Special registers are unsupported. Found register %s\", vm_reg->name());\n+      } else {\n+        fatal(\"Register type is not known\");\n+      }\n+    }\n+  }\n+\n+  return reg_save_index;\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/shared\/barrierSetAssembler_ppc.cpp","additions":119,"deletions":0,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -32,0 +32,8 @@\n+#ifdef COMPILER2\n+#include \"code\/vmreg.hpp\"\n+#include \"opto\/optoreg.hpp\"\n+#include \"opto\/regmask.hpp\"\n+\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -74,0 +82,35 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node, OptoReg::Name opto_reg) const;\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ call_VM_leaf(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+  MacroAssembler* _masm;\n+  RegMask _reg_mask;\n+  Register _result_reg;\n+  int _frame_size;\n+\n+ public:\n+  SaveLiveRegisters(MacroAssembler *masm, BarrierStubC2 *stub);\n+\n+  ~SaveLiveRegisters();\n+\n+ private:\n+  enum IterationAction : int {\n+    ACTION_SAVE,\n+    ACTION_RESTORE,\n+    ACTION_COUNT_ONLY\n+  };\n+\n+  int iterate_over_register_mask(IterationAction action, int offset = 0);\n@@ -76,0 +119,2 @@\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/shared\/barrierSetAssembler_ppc.hpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -841,126 +841,0 @@\n-OptoReg::Name ZBarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) const {\n-  if (!OptoReg::is_reg(opto_reg)) {\n-    return OptoReg::Bad;\n-  }\n-\n-  VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-  if ((vm_reg->is_Register() || vm_reg ->is_FloatRegister()) && (opto_reg & 1) != 0) {\n-    return OptoReg::Bad;\n-  }\n-\n-  return opto_reg;\n-}\n-\n-#define __ _masm->\n-\n-class ZSaveLiveRegisters {\n-  MacroAssembler* _masm;\n-  RegMask _reg_mask;\n-  Register _result_reg;\n-  int _frame_size;\n-\n- public:\n-  ZSaveLiveRegisters(MacroAssembler *masm, ZBarrierStubC2 *stub)\n-    : _masm(masm), _reg_mask(stub->live()), _result_reg(stub->result()) {\n-\n-    const int register_save_size = iterate_over_register_mask(ACTION_COUNT_ONLY) * BytesPerWord;\n-    _frame_size = align_up(register_save_size, frame::alignment_in_bytes)\n-                  + frame::native_abi_reg_args_size;\n-\n-    __ save_LR_CR(R0);\n-    __ push_frame(_frame_size, R0);\n-\n-    iterate_over_register_mask(ACTION_SAVE, _frame_size);\n-  }\n-\n-  ~ZSaveLiveRegisters() {\n-    iterate_over_register_mask(ACTION_RESTORE, _frame_size);\n-\n-    __ addi(R1_SP, R1_SP, _frame_size);\n-    __ restore_LR_CR(R0);\n-  }\n-\n- private:\n-  enum IterationAction : int {\n-    ACTION_SAVE,\n-    ACTION_RESTORE,\n-    ACTION_COUNT_ONLY\n-  };\n-\n-  int iterate_over_register_mask(IterationAction action, int offset = 0) {\n-    int reg_save_index = 0;\n-    RegMaskIterator live_regs_iterator(_reg_mask);\n-\n-    while(live_regs_iterator.has_next()) {\n-      const OptoReg::Name opto_reg = live_regs_iterator.next();\n-\n-      \/\/ Filter out stack slots (spilled registers, i.e., stack-allocated registers).\n-      if (!OptoReg::is_reg(opto_reg)) {\n-        continue;\n-      }\n-\n-      const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-      if (vm_reg->is_Register()) {\n-        Register std_reg = vm_reg->as_Register();\n-\n-        \/\/ '_result_reg' will hold the end result of the operation. Its content must thus not be preserved.\n-        if (std_reg == _result_reg) {\n-          continue;\n-        }\n-\n-        if (std_reg->encoding() >= R2->encoding() && std_reg->encoding() <= R12->encoding()) {\n-          reg_save_index++;\n-\n-          if (action == ACTION_SAVE) {\n-            _masm->std(std_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n-          } else if (action == ACTION_RESTORE) {\n-            _masm->ld(std_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n-          } else {\n-            assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n-          }\n-        }\n-      } else if (vm_reg->is_FloatRegister()) {\n-        FloatRegister fp_reg = vm_reg->as_FloatRegister();\n-        if (fp_reg->encoding() >= F0->encoding() && fp_reg->encoding() <= F13->encoding()) {\n-          reg_save_index++;\n-\n-          if (action == ACTION_SAVE) {\n-            _masm->stfd(fp_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n-          } else if (action == ACTION_RESTORE) {\n-            _masm->lfd(fp_reg, offset - reg_save_index * BytesPerWord, R1_SP);\n-          } else {\n-            assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n-          }\n-        }\n-      } else if (vm_reg->is_ConditionRegister()) {\n-        \/\/ NOP. Conditions registers are covered by save_LR_CR\n-      } else if (vm_reg->is_VectorSRegister()) {\n-        assert(SuperwordUseVSX, \"or should not reach here\");\n-        VectorSRegister vs_reg = vm_reg->as_VectorSRegister();\n-        if (vs_reg->encoding() >= VSR32->encoding() && vs_reg->encoding() <= VSR51->encoding()) {\n-          reg_save_index += 2;\n-\n-          Register spill_addr = R0;\n-          if (action == ACTION_SAVE) {\n-            _masm->addi(spill_addr, R1_SP, offset - reg_save_index * BytesPerWord);\n-            _masm->stxvd2x(vs_reg, spill_addr);\n-          } else if (action == ACTION_RESTORE) {\n-            _masm->addi(spill_addr, R1_SP, offset - reg_save_index * BytesPerWord);\n-            _masm->lxvd2x(vs_reg, spill_addr);\n-          } else {\n-            assert(action == ACTION_COUNT_ONLY, \"Sanity\");\n-          }\n-        }\n-      } else {\n-        if (vm_reg->is_SpecialRegister()) {\n-          fatal(\"Special registers are unsupported. Found register %s\", vm_reg->name());\n-        } else {\n-          fatal(\"Register type is not known\");\n-        }\n-      }\n-    }\n-\n-    return reg_save_index;\n-  }\n-};\n-\n@@ -1027,1 +901,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n@@ -1066,1 +940,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/zBarrierSetAssembler_ppc.cpp","additions":2,"deletions":128,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -108,2 +108,0 @@\n-  OptoReg::Name refine_register(const Node* node, OptoReg::Name opto_reg) const;\n-\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/zBarrierSetAssembler_ppc.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,3 @@\n+#ifdef COMPILER2\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -375,0 +378,69 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if (vm_reg->is_FloatRegister()) {\n+    return opto_reg & ~1;\n+  }\n+\n+  return opto_reg;\n+}\n+\n+#undef __\n+#define __ _masm->\n+\n+void SaveLiveRegisters::initialize(BarrierStubC2* stub) {\n+  \/\/ Record registers that needs to be saved\/restored\n+  RegMaskIterator rmi(stub->live());\n+  while (rmi.has_next()) {\n+    const OptoReg::Name opto_reg = rmi.next();\n+    if (OptoReg::is_reg(opto_reg)) {\n+      const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+      if (vm_reg->is_Register()) {\n+        _gp_regs += RegSet::of(vm_reg->as_Register());\n+      } else if (vm_reg->is_FloatRegister()) {\n+        _fp_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n+      } else if (vm_reg->is_VectorRegister()) {\n+        const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg & ~(VectorRegister::max_slots_per_register - 1));\n+        _vp_regs += VectorRegSet::of(vm_reg_base->as_VectorRegister());\n+      } else {\n+        fatal(\"Unknown register type\");\n+      }\n+    }\n+  }\n+\n+  \/\/ Remove C-ABI SOE registers, tmp regs and _ref register that will be updated\n+  if (stub->result() != noreg) {\n+    _gp_regs -= RegSet::range(x18, x27) + RegSet::of(x2) + RegSet::of(x8, x9) + RegSet::of(x5, stub->result());\n+  } else {\n+    _gp_regs -= RegSet::range(x18, x27) + RegSet::of(x2, x5) + RegSet::of(x8, x9);\n+  }\n+}\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub)\n+  : _masm(masm),\n+    _gp_regs(),\n+    _fp_regs(),\n+    _vp_regs() {\n+  \/\/ Figure out what registers to save\/restore\n+  initialize(stub);\n+\n+  \/\/ Save registers\n+  __ push_reg(_gp_regs, sp);\n+  __ push_fp(_fp_regs, sp);\n+  __ push_v(_vp_regs, sp);\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  \/\/ Restore registers\n+  __ pop_v(_vp_regs, sp);\n+  __ pop_fp(_fp_regs, sp);\n+  __ pop_reg(_gp_regs, sp);\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/shared\/barrierSetAssembler_riscv.cpp","additions":72,"deletions":0,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -34,0 +34,6 @@\n+#ifdef COMPILER2\n+#include \"opto\/optoreg.hpp\"\n+\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -109,0 +115,28 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ jalr(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+private:\n+  MacroAssembler* const _masm;\n+  RegSet                _gp_regs;\n+  FloatRegSet           _fp_regs;\n+  VectorRegSet          _vp_regs;\n+\n+public:\n+  void initialize(BarrierStubC2* stub);\n+  SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub);\n+  ~SaveLiveRegisters();\n@@ -111,0 +145,2 @@\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/shared\/barrierSetAssembler_riscv.hpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -645,13 +645,0 @@\n-OptoReg::Name ZBarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n-  if (!OptoReg::is_reg(opto_reg)) {\n-    return OptoReg::Bad;\n-  }\n-\n-  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-  if (vm_reg->is_FloatRegister()) {\n-    return opto_reg & ~1;\n-  }\n-\n-  return opto_reg;\n-}\n-\n@@ -661,58 +648,0 @@\n-class ZSaveLiveRegisters {\n-private:\n-  MacroAssembler* const _masm;\n-  RegSet                _gp_regs;\n-  FloatRegSet           _fp_regs;\n-  VectorRegSet          _vp_regs;\n-\n-public:\n-  void initialize(ZBarrierStubC2* stub) {\n-    \/\/ Record registers that needs to be saved\/restored\n-    RegMaskIterator rmi(stub->live());\n-    while (rmi.has_next()) {\n-      const OptoReg::Name opto_reg = rmi.next();\n-      if (OptoReg::is_reg(opto_reg)) {\n-        const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-        if (vm_reg->is_Register()) {\n-          _gp_regs += RegSet::of(vm_reg->as_Register());\n-        } else if (vm_reg->is_FloatRegister()) {\n-          _fp_regs += FloatRegSet::of(vm_reg->as_FloatRegister());\n-        } else if (vm_reg->is_VectorRegister()) {\n-          const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg & ~(VectorRegister::max_slots_per_register - 1));\n-          _vp_regs += VectorRegSet::of(vm_reg_base->as_VectorRegister());\n-        } else {\n-          fatal(\"Unknown register type\");\n-        }\n-      }\n-    }\n-\n-    \/\/ Remove C-ABI SOE registers, tmp regs and _ref register that will be updated\n-    if (stub->result() != noreg) {\n-      _gp_regs -= RegSet::range(x18, x27) + RegSet::of(x2) + RegSet::of(x8, x9) + RegSet::of(x5, stub->result());\n-    } else {\n-      _gp_regs -= RegSet::range(x18, x27) + RegSet::of(x2, x5) + RegSet::of(x8, x9);\n-    }\n-  }\n-\n-  ZSaveLiveRegisters(MacroAssembler* masm, ZBarrierStubC2* stub)\n-    : _masm(masm),\n-      _gp_regs(),\n-      _fp_regs(),\n-      _vp_regs() {\n-    \/\/ Figure out what registers to save\/restore\n-    initialize(stub);\n-\n-    \/\/ Save registers\n-    __ push_reg(_gp_regs, sp);\n-    __ push_fp(_fp_regs, sp);\n-    __ push_v(_vp_regs, sp);\n-  }\n-\n-  ~ZSaveLiveRegisters() {\n-    \/\/ Restore registers\n-    __ pop_v(_vp_regs, sp);\n-    __ pop_fp(_fp_regs, sp);\n-    __ pop_reg(_gp_regs, sp);\n-  }\n-};\n-\n@@ -784,1 +713,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n@@ -816,1 +745,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/zBarrierSetAssembler_riscv.cpp","additions":2,"deletions":73,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -169,3 +169,0 @@\n-  OptoReg::Name refine_register(const Node* node,\n-                                OptoReg::Name opto_reg);\n-\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/zBarrierSetAssembler_riscv.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -150,0 +150,8 @@\n+\n+#ifdef COMPILER2\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  Unimplemented(); \/\/ This must be implemented to support late barrier expansion.\n+}\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/s390\/gc\/shared\/barrierSetAssembler_s390.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -32,0 +32,6 @@\n+#ifdef COMPILER2\n+#include \"code\/vmreg.hpp\"\n+#include \"opto\/optoreg.hpp\"\n+\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -55,0 +61,5 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/s390\/gc\/shared\/barrierSetAssembler_s390.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -37,0 +37,3 @@\n+#ifdef COMPILER2\n+#include \"gc\/shared\/c2\/barrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -491,0 +494,277 @@\n+\n+#ifdef COMPILER2\n+\n+#ifdef _LP64\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  if (!OptoReg::is_reg(opto_reg)) {\n+    return OptoReg::Bad;\n+  }\n+\n+  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+  if (vm_reg->is_XMMRegister()) {\n+    opto_reg &= ~15;\n+    switch (node->ideal_reg()) {\n+    case Op_VecX:\n+      opto_reg |= 2;\n+      break;\n+    case Op_VecY:\n+      opto_reg |= 4;\n+      break;\n+    case Op_VecZ:\n+      opto_reg |= 8;\n+      break;\n+    default:\n+      opto_reg |= 1;\n+      break;\n+    }\n+  }\n+\n+  return opto_reg;\n+}\n+\n+\/\/ We use the vec_spill_helper from the x86.ad file to avoid reinventing this wheel\n+extern void vec_spill_helper(C2_MacroAssembler *masm, bool is_load,\n+                            int stack_offset, int reg, uint ireg, outputStream* st);\n+\n+#undef __\n+#define __ _masm->\n+\n+int SaveLiveRegisters::xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right) {\n+  if (left->_size == right->_size) {\n+    return 0;\n+  }\n+\n+  return (left->_size < right->_size) ? -1 : 1;\n+}\n+\n+int SaveLiveRegisters::xmm_slot_size(OptoReg::Name opto_reg) {\n+  \/\/ The low order 4 bytes denote what size of the XMM register is live\n+  return (opto_reg & 15) << 3;\n+}\n+\n+uint SaveLiveRegisters::xmm_ideal_reg_for_size(int reg_size) {\n+  switch (reg_size) {\n+  case 8:\n+    return Op_VecD;\n+  case 16:\n+    return Op_VecX;\n+  case 32:\n+    return Op_VecY;\n+  case 64:\n+    return Op_VecZ;\n+  default:\n+    fatal(\"Invalid register size %d\", reg_size);\n+    return 0;\n+  }\n+}\n+\n+bool SaveLiveRegisters::xmm_needs_vzeroupper() const {\n+  return _xmm_registers.is_nonempty() && _xmm_registers.at(0)._size > 16;\n+}\n+\n+void SaveLiveRegisters::xmm_register_save(const XMMRegisterData& reg_data) {\n+  const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n+  const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n+  _spill_offset -= reg_data._size;\n+  C2_MacroAssembler c2_masm(__ code());\n+  vec_spill_helper(&c2_masm, false \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n+}\n+\n+void SaveLiveRegisters::xmm_register_restore(const XMMRegisterData& reg_data) {\n+  const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n+  const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n+  C2_MacroAssembler c2_masm(__ code());\n+  vec_spill_helper(&c2_masm, true \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n+  _spill_offset += reg_data._size;\n+}\n+\n+void SaveLiveRegisters::gp_register_save(Register reg) {\n+  _spill_offset -= 8;\n+  __ movq(Address(rsp, _spill_offset), reg);\n+}\n+\n+void SaveLiveRegisters::opmask_register_save(KRegister reg) {\n+  _spill_offset -= 8;\n+  __ kmov(Address(rsp, _spill_offset), reg);\n+}\n+\n+void SaveLiveRegisters::gp_register_restore(Register reg) {\n+  __ movq(reg, Address(rsp, _spill_offset));\n+  _spill_offset += 8;\n+}\n+\n+void SaveLiveRegisters::opmask_register_restore(KRegister reg) {\n+  __ kmov(reg, Address(rsp, _spill_offset));\n+  _spill_offset += 8;\n+}\n+\n+void SaveLiveRegisters::initialize(BarrierStubC2* stub) {\n+  \/\/ Create mask of caller saved registers that need to\n+  \/\/ be saved\/restored if live\n+  RegMask caller_saved;\n+  caller_saved.Insert(OptoReg::as_OptoReg(rax->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rcx->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rdx->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rsi->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(rdi->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r8->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r9->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r10->as_VMReg()));\n+  caller_saved.Insert(OptoReg::as_OptoReg(r11->as_VMReg()));\n+\n+  if (stub->result() != noreg) {\n+    caller_saved.Remove(OptoReg::as_OptoReg(stub->result()->as_VMReg()));\n+  }\n+\n+  \/\/ Create mask of live registers\n+  RegMask live = stub->live();\n+\n+  int gp_spill_size = 0;\n+  int opmask_spill_size = 0;\n+  int xmm_spill_size = 0;\n+\n+  \/\/ Record registers that needs to be saved\/restored\n+  RegMaskIterator rmi(live);\n+  while (rmi.has_next()) {\n+    const OptoReg::Name opto_reg = rmi.next();\n+    const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n+\n+    if (vm_reg->is_Register()) {\n+      if (caller_saved.Member(opto_reg)) {\n+        _gp_registers.append(vm_reg->as_Register());\n+        gp_spill_size += 8;\n+      }\n+    } else if (vm_reg->is_KRegister()) {\n+      \/\/ All opmask registers are caller saved, thus spill the ones\n+      \/\/ which are live.\n+      if (_opmask_registers.find(vm_reg->as_KRegister()) == -1) {\n+        _opmask_registers.append(vm_reg->as_KRegister());\n+        opmask_spill_size += 8;\n+      }\n+    } else if (vm_reg->is_XMMRegister()) {\n+      \/\/ We encode in the low order 4 bits of the opto_reg, how large part of the register is live\n+      const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg & ~15);\n+      const int reg_size = xmm_slot_size(opto_reg);\n+      const XMMRegisterData reg_data = { vm_reg_base->as_XMMRegister(), reg_size };\n+      const int reg_index = _xmm_registers.find(reg_data);\n+      if (reg_index == -1) {\n+        \/\/ Not previously appended\n+        _xmm_registers.append(reg_data);\n+        xmm_spill_size += reg_size;\n+      } else {\n+        \/\/ Previously appended, update size\n+        const int reg_size_prev = _xmm_registers.at(reg_index)._size;\n+        if (reg_size > reg_size_prev) {\n+          _xmm_registers.at_put(reg_index, reg_data);\n+          xmm_spill_size += reg_size - reg_size_prev;\n+        }\n+      }\n+    } else {\n+      fatal(\"Unexpected register type\");\n+    }\n+  }\n+\n+  \/\/ Sort by size, largest first\n+  _xmm_registers.sort(xmm_compare_register_size);\n+\n+  \/\/ On Windows, the caller reserves stack space for spilling register arguments\n+  const int arg_spill_size = frame::arg_reg_save_area_bytes;\n+\n+  \/\/ Stack pointer must be 16 bytes aligned for the call\n+  _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + opmask_spill_size + arg_spill_size, 16);\n+}\n+\n+SaveLiveRegisters::SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub)\n+  : _masm(masm),\n+    _gp_registers(),\n+    _opmask_registers(),\n+    _xmm_registers(),\n+    _spill_size(0),\n+    _spill_offset(0) {\n+\n+  \/\/\n+  \/\/ Stack layout after registers have been spilled:\n+  \/\/\n+  \/\/ | ...            | original rsp, 16 bytes aligned\n+  \/\/ ------------------\n+  \/\/ | zmm0 high      |\n+  \/\/ | ...            |\n+  \/\/ | zmm0 low       | 16 bytes aligned\n+  \/\/ | ...            |\n+  \/\/ | ymm1 high      |\n+  \/\/ | ...            |\n+  \/\/ | ymm1 low       | 16 bytes aligned\n+  \/\/ | ...            |\n+  \/\/ | xmmN high      |\n+  \/\/ | ...            |\n+  \/\/ | xmmN low       | 8 bytes aligned\n+  \/\/ | reg0           | 8 bytes aligned\n+  \/\/ | reg1           |\n+  \/\/ | ...            |\n+  \/\/ | regN           | new rsp, if 16 bytes aligned\n+  \/\/ | <padding>      | else new rsp, 16 bytes aligned\n+  \/\/ ------------------\n+  \/\/\n+\n+  \/\/ Figure out what registers to save\/restore\n+  initialize(stub);\n+\n+  \/\/ Allocate stack space\n+  if (_spill_size > 0) {\n+    __ subptr(rsp, _spill_size);\n+  }\n+\n+  \/\/ Save XMM\/YMM\/ZMM registers\n+  for (int i = 0; i < _xmm_registers.length(); i++) {\n+    xmm_register_save(_xmm_registers.at(i));\n+  }\n+\n+  if (xmm_needs_vzeroupper()) {\n+    __ vzeroupper();\n+  }\n+\n+  \/\/ Save general purpose registers\n+  for (int i = 0; i < _gp_registers.length(); i++) {\n+    gp_register_save(_gp_registers.at(i));\n+  }\n+\n+  \/\/ Save opmask registers\n+  for (int i = 0; i < _opmask_registers.length(); i++) {\n+    opmask_register_save(_opmask_registers.at(i));\n+  }\n+}\n+\n+SaveLiveRegisters::~SaveLiveRegisters() {\n+  \/\/ Restore opmask registers\n+  for (int i = _opmask_registers.length() - 1; i >= 0; i--) {\n+    opmask_register_restore(_opmask_registers.at(i));\n+  }\n+\n+  \/\/ Restore general purpose registers\n+  for (int i = _gp_registers.length() - 1; i >= 0; i--) {\n+    gp_register_restore(_gp_registers.at(i));\n+  }\n+\n+  __ vzeroupper();\n+\n+  \/\/ Restore XMM\/YMM\/ZMM registers\n+  for (int i = _xmm_registers.length() - 1; i >= 0; i--) {\n+    xmm_register_restore(_xmm_registers.at(i));\n+  }\n+\n+  \/\/ Free stack space\n+  if (_spill_size > 0) {\n+    __ addptr(rsp, _spill_size);\n+  }\n+}\n+\n+#else \/\/ !_LP64\n+\n+OptoReg::Name BarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n+  Unimplemented(); \/\/ This must be implemented to support late barrier expansion.\n+}\n+\n+#endif \/\/ _LP64\n+\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":280,"deletions":0,"binary":false,"changes":280,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+#ifdef COMPILER2\n+#include \"opto\/optoreg.hpp\"\n@@ -32,0 +34,3 @@\n+class BarrierStubC2;\n+class Node;\n+#endif \/\/ COMPILER2\n@@ -109,0 +114,53 @@\n+\n+#ifdef COMPILER2\n+  OptoReg::Name refine_register(const Node* node,\n+                                OptoReg::Name opto_reg);\n+#endif \/\/ COMPILER2\n+};\n+\n+#ifdef COMPILER2\n+\n+#ifdef _LP64\n+\n+\/\/ This class saves and restores the registers that need to be preserved across\n+\/\/ the runtime call represented by a given C2 barrier stub. Use as follows:\n+\/\/ {\n+\/\/   SaveLiveRegisters save(masm, stub);\n+\/\/   ..\n+\/\/   __ call(RuntimeAddress(...);\n+\/\/   ..\n+\/\/ }\n+class SaveLiveRegisters {\n+private:\n+  struct XMMRegisterData {\n+    XMMRegister _reg;\n+    int         _size;\n+\n+    \/\/ Used by GrowableArray::find()\n+    bool operator == (const XMMRegisterData& other) {\n+      return _reg == other._reg;\n+    }\n+  };\n+\n+  MacroAssembler* const          _masm;\n+  GrowableArray<Register>        _gp_registers;\n+  GrowableArray<KRegister>       _opmask_registers;\n+  GrowableArray<XMMRegisterData> _xmm_registers;\n+  int                            _spill_size;\n+  int                            _spill_offset;\n+\n+  static int xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right);\n+  static int xmm_slot_size(OptoReg::Name opto_reg);\n+  static uint xmm_ideal_reg_for_size(int reg_size);\n+  bool xmm_needs_vzeroupper() const;\n+  void xmm_register_save(const XMMRegisterData& reg_data);\n+  void xmm_register_restore(const XMMRegisterData& reg_data);\n+  void gp_register_save(Register reg);\n+  void opmask_register_save(KRegister reg);\n+  void gp_register_restore(Register reg);\n+  void opmask_register_restore(KRegister reg);\n+  void initialize(BarrierStubC2* stub);\n+\n+public:\n+  SaveLiveRegisters(MacroAssembler* masm, BarrierStubC2* stub);\n+  ~SaveLiveRegisters();\n@@ -111,0 +169,4 @@\n+#endif \/\/ _LP64\n+\n+#endif \/\/ COMPILER2\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.hpp","additions":62,"deletions":0,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -1159,31 +1159,0 @@\n-OptoReg::Name ZBarrierSetAssembler::refine_register(const Node* node, OptoReg::Name opto_reg) {\n-  if (!OptoReg::is_reg(opto_reg)) {\n-    return OptoReg::Bad;\n-  }\n-\n-  const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-  if (vm_reg->is_XMMRegister()) {\n-    opto_reg &= ~15;\n-    switch (node->ideal_reg()) {\n-      case Op_VecX:\n-        opto_reg |= 2;\n-        break;\n-      case Op_VecY:\n-        opto_reg |= 4;\n-        break;\n-      case Op_VecZ:\n-        opto_reg |= 8;\n-        break;\n-      default:\n-        opto_reg |= 1;\n-        break;\n-    }\n-  }\n-\n-  return opto_reg;\n-}\n-\n-\/\/ We use the vec_spill_helper from the x86.ad file to avoid reinventing this wheel\n-extern void vec_spill_helper(C2_MacroAssembler *masm, bool is_load,\n-                            int stack_offset, int reg, uint ireg, outputStream* st);\n-\n@@ -1193,250 +1162,0 @@\n-class ZSaveLiveRegisters {\n-private:\n-  struct XMMRegisterData {\n-    XMMRegister _reg;\n-    int         _size;\n-\n-    \/\/ Used by GrowableArray::find()\n-    bool operator == (const XMMRegisterData& other) {\n-      return _reg == other._reg;\n-    }\n-  };\n-\n-  MacroAssembler* const          _masm;\n-  GrowableArray<Register>        _gp_registers;\n-  GrowableArray<KRegister>       _opmask_registers;\n-  GrowableArray<XMMRegisterData> _xmm_registers;\n-  int                            _spill_size;\n-  int                            _spill_offset;\n-\n-  static int xmm_compare_register_size(XMMRegisterData* left, XMMRegisterData* right) {\n-    if (left->_size == right->_size) {\n-      return 0;\n-    }\n-\n-    return (left->_size < right->_size) ? -1 : 1;\n-  }\n-\n-  static int xmm_slot_size(OptoReg::Name opto_reg) {\n-    \/\/ The low order 4 bytes denote what size of the XMM register is live\n-    return (opto_reg & 15) << 3;\n-  }\n-\n-  static uint xmm_ideal_reg_for_size(int reg_size) {\n-    switch (reg_size) {\n-    case 8:\n-      return Op_VecD;\n-    case 16:\n-      return Op_VecX;\n-    case 32:\n-      return Op_VecY;\n-    case 64:\n-      return Op_VecZ;\n-    default:\n-      fatal(\"Invalid register size %d\", reg_size);\n-      return 0;\n-    }\n-  }\n-\n-  bool xmm_needs_vzeroupper() const {\n-    return _xmm_registers.is_nonempty() && _xmm_registers.at(0)._size > 16;\n-  }\n-\n-  void xmm_register_save(const XMMRegisterData& reg_data) {\n-    const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n-    const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n-    _spill_offset -= reg_data._size;\n-    C2_MacroAssembler c2_masm(__ code());\n-    vec_spill_helper(&c2_masm, false \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n-  }\n-\n-  void xmm_register_restore(const XMMRegisterData& reg_data) {\n-    const OptoReg::Name opto_reg = OptoReg::as_OptoReg(reg_data._reg->as_VMReg());\n-    const uint ideal_reg = xmm_ideal_reg_for_size(reg_data._size);\n-    C2_MacroAssembler c2_masm(__ code());\n-    vec_spill_helper(&c2_masm, true \/* is_load *\/, _spill_offset, opto_reg, ideal_reg, tty);\n-    _spill_offset += reg_data._size;\n-  }\n-\n-  void gp_register_save(Register reg) {\n-    _spill_offset -= 8;\n-    __ movq(Address(rsp, _spill_offset), reg);\n-  }\n-\n-  void opmask_register_save(KRegister reg) {\n-    _spill_offset -= 8;\n-    __ kmov(Address(rsp, _spill_offset), reg);\n-  }\n-\n-  void gp_register_restore(Register reg) {\n-    __ movq(reg, Address(rsp, _spill_offset));\n-    _spill_offset += 8;\n-  }\n-\n-  void opmask_register_restore(KRegister reg) {\n-    __ kmov(reg, Address(rsp, _spill_offset));\n-    _spill_offset += 8;\n-  }\n-\n-  void initialize(ZBarrierStubC2* stub) {\n-    \/\/ Create mask of caller saved registers that need to\n-    \/\/ be saved\/restored if live\n-    RegMask caller_saved;\n-    caller_saved.Insert(OptoReg::as_OptoReg(rax->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(rcx->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(rdx->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(rsi->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(rdi->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(r8->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(r9->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(r10->as_VMReg()));\n-    caller_saved.Insert(OptoReg::as_OptoReg(r11->as_VMReg()));\n-\n-    if (stub->result() != noreg) {\n-      caller_saved.Remove(OptoReg::as_OptoReg(stub->result()->as_VMReg()));\n-    }\n-\n-    \/\/ Create mask of live registers\n-    RegMask live = stub->live();\n-\n-    int gp_spill_size = 0;\n-    int opmask_spill_size = 0;\n-    int xmm_spill_size = 0;\n-\n-    \/\/ Record registers that needs to be saved\/restored\n-    RegMaskIterator rmi(live);\n-    while (rmi.has_next()) {\n-      const OptoReg::Name opto_reg = rmi.next();\n-      const VMReg vm_reg = OptoReg::as_VMReg(opto_reg);\n-\n-      if (vm_reg->is_Register()) {\n-        if (caller_saved.Member(opto_reg)) {\n-          _gp_registers.append(vm_reg->as_Register());\n-          gp_spill_size += 8;\n-        }\n-      } else if (vm_reg->is_KRegister()) {\n-        \/\/ All opmask registers are caller saved, thus spill the ones\n-        \/\/ which are live.\n-        if (_opmask_registers.find(vm_reg->as_KRegister()) == -1) {\n-          _opmask_registers.append(vm_reg->as_KRegister());\n-          opmask_spill_size += 8;\n-        }\n-      } else if (vm_reg->is_XMMRegister()) {\n-        \/\/ We encode in the low order 4 bits of the opto_reg, how large part of the register is live\n-        const VMReg vm_reg_base = OptoReg::as_VMReg(opto_reg & ~15);\n-        const int reg_size = xmm_slot_size(opto_reg);\n-        const XMMRegisterData reg_data = { vm_reg_base->as_XMMRegister(), reg_size };\n-        const int reg_index = _xmm_registers.find(reg_data);\n-        if (reg_index == -1) {\n-          \/\/ Not previously appended\n-          _xmm_registers.append(reg_data);\n-          xmm_spill_size += reg_size;\n-        } else {\n-          \/\/ Previously appended, update size\n-          const int reg_size_prev = _xmm_registers.at(reg_index)._size;\n-          if (reg_size > reg_size_prev) {\n-            _xmm_registers.at_put(reg_index, reg_data);\n-            xmm_spill_size += reg_size - reg_size_prev;\n-          }\n-        }\n-      } else {\n-        fatal(\"Unexpected register type\");\n-      }\n-    }\n-\n-    \/\/ Sort by size, largest first\n-    _xmm_registers.sort(xmm_compare_register_size);\n-\n-    \/\/ On Windows, the caller reserves stack space for spilling register arguments\n-    const int arg_spill_size = frame::arg_reg_save_area_bytes;\n-\n-    \/\/ Stack pointer must be 16 bytes aligned for the call\n-    _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + opmask_spill_size + arg_spill_size, 16);\n-  }\n-\n-public:\n-  ZSaveLiveRegisters(MacroAssembler* masm, ZBarrierStubC2* stub)\n-    : _masm(masm),\n-      _gp_registers(),\n-      _opmask_registers(),\n-      _xmm_registers(),\n-      _spill_size(0),\n-      _spill_offset(0) {\n-\n-    \/\/\n-    \/\/ Stack layout after registers have been spilled:\n-    \/\/\n-    \/\/ | ...            | original rsp, 16 bytes aligned\n-    \/\/ ------------------\n-    \/\/ | zmm0 high      |\n-    \/\/ | ...            |\n-    \/\/ | zmm0 low       | 16 bytes aligned\n-    \/\/ | ...            |\n-    \/\/ | ymm1 high      |\n-    \/\/ | ...            |\n-    \/\/ | ymm1 low       | 16 bytes aligned\n-    \/\/ | ...            |\n-    \/\/ | xmmN high      |\n-    \/\/ | ...            |\n-    \/\/ | xmmN low       | 8 bytes aligned\n-    \/\/ | reg0           | 8 bytes aligned\n-    \/\/ | reg1           |\n-    \/\/ | ...            |\n-    \/\/ | regN           | new rsp, if 16 bytes aligned\n-    \/\/ | <padding>      | else new rsp, 16 bytes aligned\n-    \/\/ ------------------\n-    \/\/\n-\n-    \/\/ Figure out what registers to save\/restore\n-    initialize(stub);\n-\n-    \/\/ Allocate stack space\n-    if (_spill_size > 0) {\n-      __ subptr(rsp, _spill_size);\n-    }\n-\n-    \/\/ Save XMM\/YMM\/ZMM registers\n-    for (int i = 0; i < _xmm_registers.length(); i++) {\n-      xmm_register_save(_xmm_registers.at(i));\n-    }\n-\n-    if (xmm_needs_vzeroupper()) {\n-      __ vzeroupper();\n-    }\n-\n-    \/\/ Save general purpose registers\n-    for (int i = 0; i < _gp_registers.length(); i++) {\n-      gp_register_save(_gp_registers.at(i));\n-    }\n-\n-    \/\/ Save opmask registers\n-    for (int i = 0; i < _opmask_registers.length(); i++) {\n-      opmask_register_save(_opmask_registers.at(i));\n-    }\n-  }\n-\n-  ~ZSaveLiveRegisters() {\n-    \/\/ Restore opmask registers\n-    for (int i = _opmask_registers.length() - 1; i >= 0; i--) {\n-      opmask_register_restore(_opmask_registers.at(i));\n-    }\n-\n-    \/\/ Restore general purpose registers\n-    for (int i = _gp_registers.length() - 1; i >= 0; i--) {\n-      gp_register_restore(_gp_registers.at(i));\n-    }\n-\n-    __ vzeroupper();\n-\n-    \/\/ Restore XMM\/YMM\/ZMM registers\n-    for (int i = _xmm_registers.length() - 1; i >= 0; i--) {\n-      xmm_register_restore(_xmm_registers.at(i));\n-    }\n-\n-    \/\/ Free stack space\n-    if (_spill_size > 0) {\n-      __ addptr(rsp, _spill_size);\n-    }\n-  }\n-};\n-\n@@ -1507,1 +1226,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n@@ -1537,1 +1256,1 @@\n-    ZSaveLiveRegisters save_live_registers(masm, stub);\n+    SaveLiveRegisters save_live_registers(masm, stub);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.cpp","additions":2,"deletions":283,"binary":false,"changes":285,"status":"modified"},{"patch":"@@ -167,3 +167,0 @@\n-  OptoReg::Name refine_register(const Node* node,\n-                                OptoReg::Name opto_reg);\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -26,0 +26,2 @@\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"gc\/shared\/barrierSet.hpp\"\n@@ -29,0 +31,1 @@\n+#include \"opto\/block.hpp\"\n@@ -34,0 +37,2 @@\n+#include \"opto\/output.hpp\"\n+#include \"opto\/regalloc.hpp\"\n@@ -36,0 +41,1 @@\n+#include CPU_HEADER(gc\/shared\/barrierSetAssembler)\n@@ -80,0 +86,25 @@\n+static BarrierSetC2State* barrier_set_state() {\n+  return reinterpret_cast<BarrierSetC2State*>(Compile::current()->barrier_set_state());\n+}\n+\n+BarrierStubC2::BarrierStubC2(const MachNode* node)\n+  : _node(node),\n+    _entry(),\n+    _continuation() {}\n+\n+RegMask& BarrierStubC2::live() const {\n+  return *barrier_set_state()->live(_node);\n+}\n+\n+Label* BarrierStubC2::entry() {\n+  \/\/ The _entry will never be bound when in_scratch_emit_size() is true.\n+  \/\/ However, we still need to return a label that is not bound now, but\n+  \/\/ will eventually be bound. Any eventually bound label will do, as it\n+  \/\/ will only act as a placeholder, so we return the _continuation label.\n+  return Compile::current()->output()->in_scratch_emit_size() ? &_continuation : &_entry;\n+}\n+\n+Label* BarrierStubC2::continuation() {\n+  return &_continuation;\n+}\n+\n@@ -791,0 +822,73 @@\n+\n+void BarrierSetC2::compute_liveness_at_stubs() const {\n+  ResourceMark rm;\n+  Compile* const C = Compile::current();\n+  Arena* const A = Thread::current()->resource_area();\n+  PhaseCFG* const cfg = C->cfg();\n+  PhaseRegAlloc* const regalloc = C->regalloc();\n+  RegMask* const live = NEW_ARENA_ARRAY(A, RegMask, cfg->number_of_blocks() * sizeof(RegMask));\n+  BarrierSetAssembler* const bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  Block_List worklist;\n+\n+  for (uint i = 0; i < cfg->number_of_blocks(); ++i) {\n+    new ((void*)(live + i)) RegMask();\n+    worklist.push(cfg->get_block(i));\n+  }\n+\n+  while (worklist.size() > 0) {\n+    const Block* const block = worklist.pop();\n+    RegMask& old_live = live[block->_pre_order];\n+    RegMask new_live;\n+\n+    \/\/ Initialize to union of successors\n+    for (uint i = 0; i < block->_num_succs; i++) {\n+      const uint succ_id = block->_succs[i]->_pre_order;\n+      new_live.OR(live[succ_id]);\n+    }\n+\n+    \/\/ Walk block backwards, computing liveness\n+    for (int i = block->number_of_nodes() - 1; i >= 0; --i) {\n+      const Node* const node = block->get_node(i);\n+\n+      \/\/ Remove def bits\n+      const OptoReg::Name first = bs->refine_register(node, regalloc->get_reg_first(node));\n+      const OptoReg::Name second = bs->refine_register(node, regalloc->get_reg_second(node));\n+      if (first != OptoReg::Bad) {\n+        new_live.Remove(first);\n+      }\n+      if (second != OptoReg::Bad) {\n+        new_live.Remove(second);\n+      }\n+\n+      \/\/ Add use bits\n+      for (uint j = 1; j < node->req(); ++j) {\n+        const Node* const use = node->in(j);\n+        const OptoReg::Name first = bs->refine_register(use, regalloc->get_reg_first(use));\n+        const OptoReg::Name second = bs->refine_register(use, regalloc->get_reg_second(use));\n+        if (first != OptoReg::Bad) {\n+          new_live.Insert(first);\n+        }\n+        if (second != OptoReg::Bad) {\n+          new_live.Insert(second);\n+        }\n+      }\n+\n+       \/\/ If this node tracks liveness, update it\n+      RegMask* const regs = barrier_set_state()->live(node);\n+      if (regs != NULL) {\n+        regs->OR(new_live);\n+      }\n+    }\n+\n+    \/\/ Now at block top, see if we have any changes\n+    new_live.SUBTRACT(old_live);\n+    if (new_live.is_NotEmpty()) {\n+      \/\/ Liveness has refined, update and propagate to prior blocks\n+      old_live.OR(new_live);\n+      for (uint i = 1; i < block->num_preds(); ++i) {\n+        Block* const pred = cfg->get_block_for_node(block->pred(i));\n+        worklist.push(pred);\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":104,"deletions":0,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -208,0 +208,64 @@\n+class BarrierSetC2State : public ArenaObj {\n+protected:\n+  Node_Array                      _live;\n+  int                             _trampoline_stubs_count;\n+  int                             _stubs_start_offset;\n+\n+public:\n+  BarrierSetC2State(Arena* arena)\n+    : _live(arena),\n+      _trampoline_stubs_count(0),\n+      _stubs_start_offset(0) {}\n+\n+  RegMask* live(const Node* node) {\n+    if (!node->is_Mach() || !needs_liveness_data(node->as_Mach())) {\n+      \/\/ Don't need liveness for non-MachNodes or if the GC doesn't request it\n+      return nullptr;\n+    }\n+    RegMask* live = (RegMask*)_live[node->_idx];\n+    if (live == nullptr) {\n+      live = new (Compile::current()->comp_arena()->AmallocWords(sizeof(RegMask))) RegMask();\n+      _live.map(node->_idx, (Node*)live);\n+    }\n+\n+    return live;\n+  }\n+\n+  void inc_trampoline_stubs_count() {\n+    assert(_trampoline_stubs_count != INT_MAX, \"Overflow\");\n+    ++_trampoline_stubs_count;\n+  }\n+\n+  int trampoline_stubs_count() {\n+    return _trampoline_stubs_count;\n+  }\n+\n+  void set_stubs_start_offset(int offset) {\n+    _stubs_start_offset = offset;\n+  }\n+\n+  int stubs_start_offset() {\n+    return _stubs_start_offset;\n+  }\n+\n+  virtual bool needs_liveness_data(const MachNode* mach) const = 0;\n+};\n+\n+\/\/ This class represents the slow path in a C2 barrier. It is defined by a\n+\/\/ memory access, an entry point, and a continuation point (typically the end of\n+\/\/ the barrier). It provides a set of registers whose value is live across the\n+\/\/ barrier, and hence must be preserved across runtime calls from the stub.\n+class BarrierStubC2 : public ArenaObj {\n+protected:\n+  const MachNode* _node;\n+  Label           _entry;\n+  Label           _continuation;\n+\n+public:\n+  BarrierStubC2(const MachNode* node);\n+  RegMask& live() const;\n+  Label* entry();\n+  Label* continuation();\n+\n+  virtual Register result() const = 0;\n+};\n@@ -305,0 +369,1 @@\n+  virtual void compute_liveness_at_stubs() const;\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.hpp","additions":65,"deletions":0,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -123,1 +123,1 @@\n-class ZBarrierSetC2State : public ArenaObj {\n+class ZBarrierSetC2State : public BarrierSetC2State {\n@@ -126,3 +126,0 @@\n-  Node_Array                      _live;\n-  int                             _trampoline_stubs_count;\n-  int                             _stubs_start_offset;\n@@ -132,4 +129,2 @@\n-    : _stubs(new (arena) GrowableArray<ZBarrierStubC2*>(arena, 8,  0, nullptr)),\n-      _live(arena),\n-      _trampoline_stubs_count(0),\n-      _stubs_start_offset(0) {}\n+    : BarrierSetC2State(arena),\n+      _stubs(new (arena) GrowableArray<ZBarrierStubC2*>(arena, 8,  0, nullptr)) {}\n@@ -141,36 +136,3 @@\n-  RegMask* live(const Node* node) {\n-    if (!node->is_Mach()) {\n-      \/\/ Don't need liveness for non-MachNodes\n-      return nullptr;\n-    }\n-\n-    const MachNode* const mach = node->as_Mach();\n-    if (mach->barrier_data() == ZBarrierElided) {\n-      \/\/ Don't need liveness data for nodes without barriers\n-      return nullptr;\n-    }\n-\n-    RegMask* live = (RegMask*)_live[node->_idx];\n-    if (live == nullptr) {\n-      live = new (Compile::current()->comp_arena()->AmallocWords(sizeof(RegMask))) RegMask();\n-      _live.map(node->_idx, (Node*)live);\n-    }\n-\n-    return live;\n-  }\n-\n-  void inc_trampoline_stubs_count() {\n-    assert(_trampoline_stubs_count != INT_MAX, \"Overflow\");\n-    ++_trampoline_stubs_count;\n-  }\n-\n-  int trampoline_stubs_count() {\n-    return _trampoline_stubs_count;\n-  }\n-\n-  void set_stubs_start_offset(int offset) {\n-    _stubs_start_offset = offset;\n-  }\n-\n-  int stubs_start_offset() {\n-    return _stubs_start_offset;\n+  bool needs_liveness_data(const MachNode* mach) const {\n+    \/\/ Don't need liveness data for nodes without barriers\n+    return mach->barrier_data() != ZBarrierElided;\n@@ -204,24 +166,1 @@\n-ZBarrierStubC2::ZBarrierStubC2(const MachNode* node)\n-  : _node(node),\n-    _entry(),\n-    _continuation() {}\n-\n-Register ZBarrierStubC2::result() const {\n-  return noreg;\n-}\n-\n-RegMask& ZBarrierStubC2::live() const {\n-  return *barrier_set_state()->live(_node);\n-}\n-\n-Label* ZBarrierStubC2::entry() {\n-  \/\/ The _entry will never be bound when in_scratch_emit_size() is true.\n-  \/\/ However, we still need to return a label that is not bound now, but\n-  \/\/ will eventually be bound. Any eventually bound label will do, as it\n-  \/\/ will only act as a placeholder, so we return the _continuation label.\n-  return Compile::current()->output()->in_scratch_emit_size() ? &_continuation : &_entry;\n-}\n-\n-Label* ZBarrierStubC2::continuation() {\n-  return &_continuation;\n-}\n+ZBarrierStubC2::ZBarrierStubC2(const MachNode* node) : BarrierStubC2(node) {}\n@@ -887,75 +826,0 @@\n-\/\/ == Reduced spilling optimization ==\n-\n-void ZBarrierSetC2::compute_liveness_at_stubs() const {\n-  ResourceMark rm;\n-  Compile* const C = Compile::current();\n-  Arena* const A = Thread::current()->resource_area();\n-  PhaseCFG* const cfg = C->cfg();\n-  PhaseRegAlloc* const regalloc = C->regalloc();\n-  RegMask* const live = NEW_ARENA_ARRAY(A, RegMask, cfg->number_of_blocks() * sizeof(RegMask));\n-  ZBarrierSetAssembler* const bs = ZBarrierSet::assembler();\n-  Block_List worklist;\n-\n-  for (uint i = 0; i < cfg->number_of_blocks(); ++i) {\n-    new ((void*)(live + i)) RegMask();\n-    worklist.push(cfg->get_block(i));\n-  }\n-\n-  while (worklist.size() > 0) {\n-    const Block* const block = worklist.pop();\n-    RegMask& old_live = live[block->_pre_order];\n-    RegMask new_live;\n-\n-    \/\/ Initialize to union of successors\n-    for (uint i = 0; i < block->_num_succs; i++) {\n-      const uint succ_id = block->_succs[i]->_pre_order;\n-      new_live.OR(live[succ_id]);\n-    }\n-\n-    \/\/ Walk block backwards, computing liveness\n-    for (int i = block->number_of_nodes() - 1; i >= 0; --i) {\n-      const Node* const node = block->get_node(i);\n-\n-      \/\/ Remove def bits\n-      const OptoReg::Name first = bs->refine_register(node, regalloc->get_reg_first(node));\n-      const OptoReg::Name second = bs->refine_register(node, regalloc->get_reg_second(node));\n-      if (first != OptoReg::Bad) {\n-        new_live.Remove(first);\n-      }\n-      if (second != OptoReg::Bad) {\n-        new_live.Remove(second);\n-      }\n-\n-      \/\/ Add use bits\n-      for (uint j = 1; j < node->req(); ++j) {\n-        const Node* const use = node->in(j);\n-        const OptoReg::Name first = bs->refine_register(use, regalloc->get_reg_first(use));\n-        const OptoReg::Name second = bs->refine_register(use, regalloc->get_reg_second(use));\n-        if (first != OptoReg::Bad) {\n-          new_live.Insert(first);\n-        }\n-        if (second != OptoReg::Bad) {\n-          new_live.Insert(second);\n-        }\n-      }\n-\n-      \/\/ If this node tracks liveness, update it\n-      RegMask* const regs = barrier_set_state()->live(node);\n-      if (regs != nullptr) {\n-        regs->OR(new_live);\n-      }\n-    }\n-\n-    \/\/ Now at block top, see if we have any changes\n-    new_live.SUBTRACT(old_live);\n-    if (new_live.is_NotEmpty()) {\n-      \/\/ Liveness has refined, update and propagate to prior blocks\n-      old_live.OR(new_live);\n-      for (uint i = 1; i < block->num_preds(); ++i) {\n-        Block* const pred = cfg->get_block_for_node(block->pred(i));\n-        worklist.push(pred);\n-      }\n-    }\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":7,"deletions":143,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -44,1 +44,1 @@\n-class ZBarrierStubC2 : public ArenaObj {\n+class ZBarrierStubC2 : public BarrierStubC2 {\n@@ -46,4 +46,0 @@\n-  const MachNode* _node;\n-  Label           _entry;\n-  Label           _continuation;\n-\n@@ -58,4 +54,0 @@\n-  RegMask& live() const;\n-  Label* entry();\n-  Label* continuation();\n-\n@@ -111,1 +103,0 @@\n-  void compute_liveness_at_stubs() const;\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.hpp","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"}]}