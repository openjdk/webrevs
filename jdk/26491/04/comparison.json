{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -98,2 +98,0 @@\n-    \/\/ Reduce the number of available regs (to free Rheap_base) in case of compressed oops\n-    if (UseCompressedOops || UseCompressedClassPointers) return range - 1;\n","filename":"src\/hotspot\/cpu\/arm\/c1_FrameMap_arm.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2232,10 +2232,3 @@\n-      if (UseCompressedClassPointers) {\n-        \/\/ We don't need decode because we just need to compare\n-        __ ldr_u32(tmp, Address(src, oopDesc::klass_offset_in_bytes()));\n-        __ ldr_u32(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n-        __ cmp_32(tmp, tmp2);\n-      } else {\n-        __ load_klass(tmp, src);\n-        __ load_klass(tmp2, dst);\n-        __ cmp(tmp, tmp2);\n-      }\n+      __ load_klass(tmp, src);\n+      __ load_klass(tmp2, dst);\n+      __ cmp(tmp, tmp2);\n@@ -2464,6 +2457,1 @@\n-\n-  if (UseCompressedClassPointers) { \/\/ On 32 bit arm??\n-    __ ldr_u32(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n-  } else {\n-    __ ldr(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n-  }\n+  __ ldr(result, Address(obj, oopDesc::klass_offset_in_bytes()));\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":4,"deletions":16,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -248,1 +248,1 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompressedClassPointers && CompressedKlassPointers::needs_class_space()) {\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -837,1 +837,8 @@\n-#endif \/\/ _LP64\n+#else\n+  \/\/ +UseCompressedClassPointers on 32-bit: does not need class space. Klass can live wherever.\n+  if (UseCompressedClassPointers) {\n+    const address start = (address)os::vm_min_address(); \/\/ but not in the zero page\n+    const address end = (address)CompressedKlassPointers::max_klass_range_size();\n+    CompressedKlassPointers::initialize(start, end - start);\n+  }\n+#endif \/\/ __LP64\n@@ -844,1 +851,0 @@\n-#ifdef _LP64\n@@ -855,2 +861,0 @@\n-#endif\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -263,0 +263,10 @@\n+\n+#ifndef _LP64\n+  \/\/ On 32-bit, with +UseCompressedClassPointers, the whole address space is the encoding range. We therefore\n+  \/\/ don't need a class space. However, as a pragmatic workaround for pesty overflow problems on 32-bit, we leave\n+  \/\/ a small area at the end of the address space out of the encoding range. We just assume no Klass will ever live\n+  \/\/ there (it won't, for no OS we support on 32-bit has user-addressable memory up there).\n+  assert(!UseCompressedClassPointers ||\n+         rs.end() <= (char*)CompressedKlassPointers::max_klass_range_size(), \"Weirdly high address\");\n+#endif \/\/ _LP64\n+\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceNode.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -47,2 +47,0 @@\n-#ifdef _LP64\n-\n@@ -50,6 +48,12 @@\n-  \/\/ We disallow klass range sizes larger than 4GB even if the encoding\n-  \/\/ range would allow for a larger Klass range (e.g. Base=zero, shift=3 -> 32GB).\n-  \/\/ That is because many CPU-specific compiler decodings do not want the\n-  \/\/ shifted narrow Klass to spill over into the third quadrant of the 64-bit target\n-  \/\/ address, e.g. to use a 16-bit move for a simplified base addition.\n-  return MIN2(4 * G, max_encoding_range_size());\n+#ifdef _LP64\n+  const size_t encoding_allows = nth_bit(narrow_klass_pointer_bits() + max_shift());\n+  constexpr size_t cap = 4 * G;\n+  return MIN2(encoding_allows, cap);\n+#else\n+  \/\/ 32-bit: only 32-bit \"narrow\" Klass pointers allowed. If we ever support smaller narrow\n+  \/\/ Klass pointers here, coding needs to be revised.\n+  \/\/ We keep one page safety zone free to guard against size_t overflows on 32-bit. In practice\n+  \/\/ this is irrelevant because these upper address space parts are not user-addressable on\n+  \/\/ any of our 32-bit platforms.\n+  return align_down(UINT_MAX, os::vm_page_size());\n+#endif\n@@ -63,0 +67,1 @@\n+#ifdef _LP64\n@@ -65,0 +70,4 @@\n+#else\n+    _narrow_klass_pointer_bits = 32;\n+    _max_shift = 0;\n+#endif\n@@ -87,0 +96,4 @@\n+  \/\/ We should need a class space if address space is larger than what narrowKlass can address\n+  const bool should_need_class_space = (BytesPerWord * BitsPerByte) > narrow_klass_pointer_bits();\n+  ASSERT_HERE(should_need_class_space == needs_class_space());\n+\n@@ -99,1 +112,3 @@\n-  const address encoding_end = (address)(p2u(_base) + (uintptr_t)nth_bit(narrow_klass_pointer_bits() + _shift));\n+  const address encoding_end = (address)\n+      LP64_ONLY(p2u(_base) + (uintptr_t)nth_bit(narrow_klass_pointer_bits() + _shift))\n+      NOT_LP64(max_klass_range_size());\n@@ -242,0 +257,1 @@\n+#ifdef _LP64\n@@ -253,0 +269,1 @@\n+\n@@ -273,0 +290,8 @@\n+#else\n+    \/\/ 32-bit \"compressed class pointer\" mode\n+    _base = nullptr;\n+    _shift = 0;\n+    \/\/ as our \"protection zone\", we just assume the lowest protected parts of\n+    \/\/ the user address space.\n+    _protection_zone_size = os::vm_min_address();\n+#endif \/\/ LP64\n@@ -277,1 +302,1 @@\n-  \/\/ Initialize klass decode mode and check compability with decode instructions\n+  \/\/ Initialize JIT-specific decoding settings\n@@ -291,3 +316,2 @@\n-#ifdef ASSERT\n-  sanity_check_after_initialization();\n-#endif\n+\n+  DEBUG_ONLY(sanity_check_after_initialization();)\n@@ -344,1 +368,0 @@\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.cpp","additions":37,"deletions":14,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -146,0 +146,1 @@\n+\n@@ -190,4 +191,2 @@\n-  \/\/ Returns the maximum encoding range, given the current geometry (narrow klass bit size and shift)\n-  static size_t max_encoding_range_size() { return nth_bit(narrow_klass_pointer_bits() + max_shift()); }\n-\n-  \/\/ Returns the maximum allowed klass range size.\n+  \/\/ Returns the maximum allowed klass range size. It is calculated from the length of the encoding range\n+  \/\/ resulting from the current encoding settings (base, shift), capped to a certain max. value.\n@@ -196,0 +195,6 @@\n+  \/\/ On 64-bit, we need the class space to confine Klass structures to the encoding range, which is determined\n+  \/\/ by bit size of narrowKlass IDs and the shift. On 32-bit, we support compressed class pointer only\n+  \/\/ \"pro-forma\": narrowKlass have the same size as addresses (32 bits), and therefore the encoding range is\n+  \/\/ equal to the address space size. Here, we don't need a class space.\n+  static constexpr bool needs_class_space() { return LP64_ONLY(true) NOT_LP64(false); }\n+\n@@ -204,0 +209,1 @@\n+  \/\/ Note: CDS with +UCCP for 32-bit currently unsupported.\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.hpp","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -102,0 +102,1 @@\n+#ifdef _LP64\n@@ -104,0 +105,3 @@\n+#else\n+  return (address)SIZE_MAX;\n+#endif\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.inline.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#ifdef _LP64\n@@ -49,0 +50,9 @@\n+#else\n+  assert(_klass_mode == Undefined, \"ObjLayout initialized twice\");\n+  assert(!UseCompactObjectHeaders, \"COH unsupported on 32-bit\");\n+  \/\/ We support +-UseCompressedClassPointers on 32-bit, but the layout\n+  \/\/ is exactly the same as it was with uncompressed klass pointers\n+  _klass_mode = UseCompressedClassPointers ? Compressed : Uncompressed;\n+  _oop_base_offset_in_bytes = sizeof(markWord) + sizeof(Klass*);\n+  _oop_has_klass_gap = false;\n+#endif\n","filename":"src\/hotspot\/share\/oops\/objLayout.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-#ifdef _LP64\n@@ -43,3 +42,0 @@\n-#else\n-  return Uncompressed;\n-#endif\n","filename":"src\/hotspot\/share\/oops\/objLayout.inline.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -127,4 +127,0 @@\n-  product(bool, UseCompressedClassPointers, true,                           \\\n-          \"(Deprecated) Use 32-bit class pointers in 64-bit VM. \"           \\\n-          \"lp64_product means flag is always constant in 32 bit VM\")        \\\n-                                                                            \\\n@@ -149,1 +145,0 @@\n-const bool UseCompressedClassPointers = false;\n@@ -1401,0 +1396,3 @@\n+  product(bool, UseCompressedClassPointers, true,                           \\\n+          \"(Deprecated) Use 32-bit class pointers.\")                        \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1065,0 +1065,9 @@\n+\/\/ same as nth_bit(n), but allows handing in a type as template parameter. Allows\n+\/\/ us to use nth_bit with 64-bit types on 32-bit platforms\n+template<class T> inline T nth_bit_typed(int n) {\n+  return ((T)1) << n;\n+}\n+template<class T> inline T right_n_bits_typed(int n) {\n+  return nth_bit_typed<T>(n) - 1;\n+}\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1384,0 +1384,1 @@\n+#endif\n@@ -1392,1 +1393,0 @@\n-#endif\n","filename":"src\/hotspot\/share\/utilities\/vmError.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"oops\/compressedKlass.hpp\"\n@@ -40,2 +41,6 @@\n-  if (!UseCompressedClassPointers) {\n-    return;\n+  if (UseCompressedClassPointers && CompressedKlassPointers::needs_class_space()) {\n+    size_t reserved = MetaspaceUtils::reserved_bytes();\n+    EXPECT_GT(reserved, 0UL);\n+    size_t reserved_class = MetaspaceUtils::reserved_bytes(Metaspace::ClassType);\n+    EXPECT_GT(reserved_class, 0UL);\n+    EXPECT_LE(reserved_class, reserved);\n@@ -43,6 +48,0 @@\n-  size_t reserved = MetaspaceUtils::reserved_bytes();\n-  EXPECT_GT(reserved, 0UL);\n-\n-  size_t reserved_class = MetaspaceUtils::reserved_bytes(Metaspace::ClassType);\n-  EXPECT_GT(reserved_class, 0UL);\n-  EXPECT_LE(reserved_class, reserved);\n@@ -64,2 +63,6 @@\n-  if (!UseCompressedClassPointers) {\n-    return;\n+  if (UseCompressedClassPointers && CompressedKlassPointers::needs_class_space()) {\n+    size_t committed = MetaspaceUtils::committed_bytes();\n+    EXPECT_GT(committed, 0UL);\n+    size_t committed_class = MetaspaceUtils::committed_bytes(Metaspace::ClassType);\n+    EXPECT_GT(committed_class, 0UL);\n+    EXPECT_LE(committed_class, committed);\n@@ -67,6 +70,0 @@\n-  size_t committed = MetaspaceUtils::committed_bytes();\n-  EXPECT_GT(committed, 0UL);\n-\n-  size_t committed_class = MetaspaceUtils::committed_bytes(Metaspace::ClassType);\n-  EXPECT_GT(committed_class, 0UL);\n-  EXPECT_LE(committed_class, committed);\n@@ -108,1 +105,1 @@\n-  if (UseCompressedClassPointers) {\n+  if (CompressedKlassPointers::needs_class_space() && UseCompressedClassPointers) {\n","filename":"test\/hotspot\/gtest\/metaspace\/test_metaspaceUtils.cpp","additions":14,"deletions":17,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#ifdef _LP64\n@@ -51,0 +52,4 @@\n+#else\n+  ASSERT_EQ(CompressedKlassPointers::base(), (address)0);\n+  ASSERT_EQ(CompressedKlassPointers::encoding_range_end(), (address)(UINT_MAX));\n+#endif \/\/ _LP64\n","filename":"test\/hotspot\/gtest\/oops\/test_compressedKlass.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+ * @requires vm.bits == \"64\"\n@@ -43,0 +44,1 @@\n+ * @requires vm.bits == \"64\"\n@@ -50,0 +52,1 @@\n+ * @requires vm.bits == \"64\"\n@@ -57,0 +60,1 @@\n+ * @requires vm.bits == \"64\"\n@@ -61,0 +65,12 @@\n+\n+\/* Very basic test on 32-bit, where we only support a pro-forma Compressed Class Pointers implementation without\n+ * class space.\n+ *\/\n+\n+\/* @test id=32-bit\n+ * @library \/test\/lib\n+ * @requires vm.bits == \"32\"\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.xml\n+ * @run main\/native GTestWrapper --gtest_filter=CompressedKlass* -Xlog:metaspace* -Xmx128m -Xms128m -Xshare:off\n+ *\/\n","filename":"test\/hotspot\/jtreg\/gtest\/CompressedKlassGtest.java","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n- * @test\n+ * @test id=coh-off\n@@ -33,1 +33,13 @@\n- * @run driver TestVMConfigInHsErrFile\n+ * @run driver TestVMConfigInHsErrFile coh-off\n+ *\/\n+\n+\/*\n+ * @test id=coh-on\n+ * @summary Test that we see VM configs reported correctly in hs_err file\n+ * @library \/test\/lib\n+ * @requires vm.bits == \"64\"\n+ * @requires vm.flagless\n+ * @requires vm.debug\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @run driver TestVMConfigInHsErrFile coh-on\n@@ -45,2 +57,4 @@\n-    testCompactObjectHeaders();\n-    testCompressedClassPointers();\n+    switch (args[0]) {\n+      case \"coh-on\" -> testCompactObjectHeaders();\n+      case \"coh-off\" -> testCompressedClassPointers();\n+    }\n","filename":"test\/hotspot\/jtreg\/runtime\/ErrorHandling\/TestVMConfigInHsErrFile.java","additions":18,"deletions":4,"binary":false,"changes":22,"status":"modified"}]}