{"files":[{"patch":"@@ -92,4 +92,3 @@\n-  flags(AUTO_VECTORIZATION2_AFTER_REORDER,                    \"AutoVectorization 2, after Apply Memop Reordering\") \\\n-  flags(AUTO_VECTORIZATION3_AFTER_ADJUST_LIMIT,               \"AutoVectorization 3, after Adjusting Pre-loop Limit\") \\\n-  flags(AUTO_VECTORIZATION4_AFTER_SPECULATIVE_RUNTIME_CHECKS, \"AutoVectorization 4, after Adding Speculative Runtime Checks\") \\\n-  flags(AUTO_VECTORIZATION5_AFTER_APPLY,                      \"AutoVectorization 5, after Apply\") \\\n+  flags(AUTO_VECTORIZATION3_AFTER_ADJUST_LIMIT,               \"AutoVectorization 2, after Adjusting Pre-loop Limit\") \\\n+  flags(AUTO_VECTORIZATION4_AFTER_SPECULATIVE_RUNTIME_CHECKS, \"AutoVectorization 3, after Adding Speculative Runtime Checks\") \\\n+  flags(AUTO_VECTORIZATION5_AFTER_APPLY,                      \"AutoVectorization 4, after Apply\") \\\n","filename":"src\/hotspot\/share\/opto\/phasetype.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-  _mem_ref_for_main_loop_alignment(nullptr),\n+  _vpointer_for_main_loop_alignment(nullptr),\n@@ -458,1 +458,2 @@\n-\/\/ 9) Reorder the memory slices to co-locate members of the memory packs.\n+\/\/ 9) The packs are split and filtered, to ensure correctness and that\n+\/\/    all packs have corresponding vector nodes implemented in the backend.\n@@ -460,3 +461,7 @@\n-\/\/ 10) Generate ideal vector nodes for the final set of packs and where necessary,\n-\/\/    inserting scalar promotion, vector creation from multiple scalars, and\n-\/\/    extraction of scalar values from vectors.\n+\/\/ 10) VTransform (see vtransform.hpp)\n+\/\/     - construct from PackSet\n+\/\/     - schedule (detect circles)\n+\/\/     - apply\n+\/\/       - align main loop\n+\/\/       - add runtime checks (aliasing and alignment)\n+\/\/       - build new loop with vector C2 nodes\n@@ -501,1 +506,1 @@\n-  return schedule_and_apply();\n+  return do_vtransform();\n@@ -663,31 +668,0 @@\n-void VLoopMemorySlices::find_memory_slices() {\n-  assert(_heads.is_empty(), \"not yet computed\");\n-  assert(_tails.is_empty(), \"not yet computed\");\n-  CountedLoopNode* cl = _vloop.cl();\n-\n-  \/\/ Iterate over all memory phis\n-  for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {\n-    PhiNode* phi = cl->fast_out(i)->isa_Phi();\n-    if (phi != nullptr && _vloop.in_bb(phi) && phi->is_memory_phi()) {\n-      Node* phi_tail = phi->in(LoopNode::LoopBackControl);\n-      if (phi_tail != phi->in(LoopNode::EntryControl)) {\n-        _heads.push(phi);\n-        _tails.push(phi_tail->as_Mem());\n-      }\n-    }\n-  }\n-\n-  NOT_PRODUCT( if (_vloop.is_trace_memory_slices()) { print(); } )\n-}\n-\n-#ifndef PRODUCT\n-void VLoopMemorySlices::print() const {\n-  tty->print_cr(\"\\nVLoopMemorySlices::print: %s\",\n-                heads().length() > 0 ? \"\" : \"NONE\");\n-  for (int m = 0; m < heads().length(); m++) {\n-    tty->print(\"%6d \", m);  heads().at(m)->dump();\n-    tty->print(\"       \");  tails().at(m)->dump();\n-  }\n-}\n-#endif\n-\n@@ -696,0 +670,1 @@\n+  assert(head != nullptr && tail != nullptr, \"must be slice with memory state loop\");\n@@ -1579,1 +1554,1 @@\n-    _mem_ref_for_main_loop_alignment = mem;\n+    _vpointer_for_main_loop_alignment = &vpointer(mem);\n@@ -1949,1 +1924,3 @@\n-bool SuperWord::schedule_and_apply() const {\n+\/\/ Build VTransform from SuperWord Packset, and eventually apply it (create new vectorized C2 loop).\n+\/\/ See description at top of \"vtransform.hpp\".\n+bool SuperWord::do_vtransform() const {\n@@ -1962,1 +1939,1 @@\n-                        _mem_ref_for_main_loop_alignment,\n+                        _vpointer_for_main_loop_alignment,\n@@ -1991,0 +1968,1 @@\n+\/\/ See description at top of \"vtransform.hpp\".\n@@ -2005,3 +1983,0 @@\n-  _graph.apply_memops_reordering_with_schedule();\n-  C->print_method(PHASE_AUTO_VECTORIZATION2_AFTER_REORDER, 4, cl());\n-\n@@ -2019,92 +1994,0 @@\n-\/\/ We prepare the memory graph for the replacement of scalar memops with vector memops.\n-\/\/ We reorder all slices in parallel, ensuring that the memops inside each slice are\n-\/\/ ordered according to the _schedule. This means that all packed memops are consecutive\n-\/\/ in the memory graph after the reordering.\n-void VTransformGraph::apply_memops_reordering_with_schedule() const {\n-#ifndef PRODUCT\n-  assert(is_scheduled(), \"must be already scheduled\");\n-  if (_trace._info) {\n-    print_memops_schedule();\n-  }\n-#endif\n-\n-  ResourceMark rm;\n-  int max_slices = phase()->C->num_alias_types();\n-  \/\/ When iterating over the schedule, we keep track of the current memory state,\n-  \/\/ which is the Phi or a store in the loop.\n-  GrowableArray<Node*> current_state_in_slice(max_slices, max_slices, nullptr);\n-  \/\/ The memory state after the loop is the last store inside the loop. If we reorder the\n-  \/\/ loop we may have a different last store, and we need to adjust the uses accordingly.\n-  GrowableArray<Node*> old_last_store_in_slice(max_slices, max_slices, nullptr);\n-\n-  const GrowableArray<PhiNode*>& mem_slice_head = _vloop_analyzer.memory_slices().heads();\n-\n-  \/\/ (1) Set up the initial memory state from Phi. And find the old last store.\n-  for (int i = 0; i < mem_slice_head.length(); i++) {\n-    Node* phi  = mem_slice_head.at(i);\n-    assert(phi->is_Phi(), \"must be phi\");\n-    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n-    current_state_in_slice.at_put(alias_idx, phi);\n-\n-    \/\/ If we have a memory phi, we have a last store in the loop, find it over backedge.\n-    StoreNode* last_store = phi->in(2)->as_Store();\n-    old_last_store_in_slice.at_put(alias_idx, last_store);\n-  }\n-\n-  \/\/ (2) Walk over schedule, append memops to the current state\n-  \/\/     of that slice. If it is a Store, we take it as the new state.\n-  for_each_memop_in_schedule([&] (MemNode* n) {\n-    assert(n->is_Load() || n->is_Store(), \"only loads or stores\");\n-    int alias_idx = phase()->C->get_alias_index(n->adr_type());\n-    Node* current_state = current_state_in_slice.at(alias_idx);\n-    if (current_state == nullptr) {\n-      \/\/ If there are only loads in a slice, we never update the memory\n-      \/\/ state in the loop, hence there is no phi for the memory state.\n-      \/\/ We just keep the old memory state that was outside the loop.\n-      assert(n->is_Load() && !in_bb(n->in(MemNode::Memory)),\n-             \"only loads can have memory state from outside loop\");\n-    } else {\n-      igvn().replace_input_of(n, MemNode::Memory, current_state);\n-      if (n->is_Store()) {\n-        current_state_in_slice.at_put(alias_idx, n);\n-      }\n-    }\n-  });\n-\n-  \/\/ (3) For each slice, we add the current state to the backedge\n-  \/\/     in the Phi. Further, we replace uses of the old last store\n-  \/\/     with uses of the new last store (current_state).\n-  GrowableArray<Node*> uses_after_loop;\n-  for (int i = 0; i < mem_slice_head.length(); i++) {\n-    Node* phi  = mem_slice_head.at(i);\n-    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n-    Node* current_state = current_state_in_slice.at(alias_idx);\n-    assert(current_state != nullptr, \"slice is mapped\");\n-    assert(current_state != phi, \"did some work in between\");\n-    assert(current_state->is_Store(), \"sanity\");\n-    igvn().replace_input_of(phi, 2, current_state);\n-\n-    \/\/ Replace uses of old last store with current_state (new last store)\n-    \/\/ Do it in two loops: first find all the uses, and change the graph\n-    \/\/ in as second loop so that we do not break the iterator.\n-    Node* last_store = old_last_store_in_slice.at(alias_idx);\n-    assert(last_store != nullptr, \"we have a old last store\");\n-    uses_after_loop.clear();\n-    for (DUIterator_Fast kmax, k = last_store->fast_outs(kmax); k < kmax; k++) {\n-      Node* use = last_store->fast_out(k);\n-      if (!in_bb(use)) {\n-        uses_after_loop.push(use);\n-      }\n-    }\n-    for (int k = 0; k < uses_after_loop.length(); k++) {\n-      Node* use = uses_after_loop.at(k);\n-      for (uint j = 0; j < use->req(); j++) {\n-        Node* def = use->in(j);\n-        if (def == last_store) {\n-          igvn().replace_input_of(use, j, current_state);\n-        }\n-      }\n-    }\n-  }\n-}\n-\n@@ -2115,0 +1998,1 @@\n+  \/\/ Apply: transform the node and connect with inputs (no backedges).\n@@ -2124,0 +2008,10 @@\n+\n+  \/\/ Cleanup: connect backedges\n+  for (int i = 0; i < _schedule.length(); i++) {\n+    VTransformNode* vtn = _schedule.at(i);\n+    vtn->apply_backedge(apply_state);\n+  }\n+\n+  \/\/ Memory uses after the loop: used to connect to old last store,\n+  \/\/ now need to connect to new last store.\n+  apply_state.fix_memory_state_uses_after_loop();\n@@ -2777,1 +2671,1 @@\n-LoadNode::ControlDependency VTransformLoadVectorNode::control_dependency() const {\n+LoadNode::ControlDependency SuperWordVTransformBuilder::load_control_dependency(const Node_List* pack) const {\n@@ -2779,2 +2673,2 @@\n-  for (int i = 0; i < nodes().length(); i++) {\n-    Node* n = nodes().at(i);\n+  for (uint i = 0; i < pack->size(); i++) {\n+    Node* n = pack->at(i);\n@@ -2798,3 +2692,3 @@\n-void VTransform::determine_mem_ref_and_aw_for_main_loop_alignment() {\n-  if (_mem_ref_for_main_loop_alignment != nullptr) {\n-    assert(VLoop::vectors_should_be_aligned(), \"mem_ref only set if filtered for alignment\");\n+void VTransform::determine_vpointer_and_aw_for_main_loop_alignment() {\n+  if (_vpointer_for_main_loop_alignment != nullptr) {\n+    assert(VLoop::vectors_should_be_aligned(), \"vpointer_for_main_loop_alignment only set if filtered for alignment\");\n@@ -2804,1 +2698,1 @@\n-  MemNode const* mem_ref = nullptr;\n+  VPointer const* vpointer = nullptr;\n@@ -2806,0 +2700,1 @@\n+  bool vpointer_is_load = false;\n@@ -2811,1 +2706,0 @@\n-    MemNode* p0 = vtn->nodes().at(0)->as_Mem();\n@@ -2813,1 +2707,3 @@\n-    int vw = p0->memory_size() * vtn->nodes().length();\n+    int vw = vtn->vpointer().size();\n+    bool vtn_is_load = vtn->is_load_in_loop();\n+\n@@ -2823,2 +2719,2 @@\n-    bool prefer_store = mem_ref != nullptr && SuperWordAutomaticAlignment == 1 && mem_ref->is_Load() && p0->is_Store();\n-    bool prefer_load  = mem_ref != nullptr && SuperWordAutomaticAlignment == 2 && mem_ref->is_Store() && p0->is_Load();\n+    bool prefer_store = SuperWordAutomaticAlignment == 1 &&  vpointer_is_load && !vtn_is_load;\n+    bool prefer_load  = SuperWordAutomaticAlignment == 2 && !vpointer_is_load &&  vtn_is_load;\n@@ -2826,0 +2722,1 @@\n+      vpointer = &vtn->vpointer();\n@@ -2827,1 +2724,1 @@\n-      mem_ref = p0;\n+      vpointer_is_load = vtn_is_load;\n@@ -2830,2 +2727,2 @@\n-  assert(mem_ref != nullptr && max_aw > 0, \"found mem_ref and aw\");\n-  _mem_ref_for_main_loop_alignment = mem_ref;\n+  assert(vpointer != nullptr && max_aw > 0, \"found vpointer and aw\");\n+  _vpointer_for_main_loop_alignment = vpointer;\n@@ -2845,1 +2742,1 @@\n-\/\/ the address of \"_mem_ref_for_main_loop_alignment\" to \"_aw_for_main_loop_alignment\", which is a\n+\/\/ the address of \"_vpointer_for_main_loop_alignment\" to \"_aw_for_main_loop_alignment\", which is a\n@@ -2849,3 +2746,7 @@\n-  determine_mem_ref_and_aw_for_main_loop_alignment();\n-  const MemNode* align_to_ref = _mem_ref_for_main_loop_alignment;\n-  const int aw                = _aw_for_main_loop_alignment;\n+  determine_vpointer_and_aw_for_main_loop_alignment();\n+\n+  assert(cl()->is_main_loop(), \"can only do alignment for main loop\");\n+  assert(_vpointer_for_main_loop_alignment != nullptr &&\n+         _vpointer_for_main_loop_alignment->is_valid() &&\n+         _aw_for_main_loop_alignment > 0,\n+         \"must have alignment reference and aw\");\n@@ -2862,2 +2763,2 @@\n-  assert(align_to_ref != nullptr && aw > 0, \"must have alignment reference and aw\");\n-  assert(cl()->is_main_loop(), \"can only do alignment for main loop\");\n+  const VPointer& p = *_vpointer_for_main_loop_alignment;\n+  const int aw      = _aw_for_main_loop_alignment;\n@@ -2878,4 +2779,1 @@\n-  const VPointer& p = vpointer(align_to_ref);\n-  assert(p.is_valid(), \"sanity\");\n-\n-  \/\/ For the main-loop, we want the address of align_to_ref to be memory aligned\n+  \/\/ For the main-loop, we want the address of vpointer p to be memory aligned\n@@ -3016,3 +2914,1 @@\n-    tty->print(\"  align_to_ref:\");\n-    align_to_ref->dump();\n-    tty->print(\"  \");\n+    tty->print(\"  vpointer_for_main_loop_alignment\");\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":58,"deletions":162,"binary":false,"changes":220,"status":"modified"},{"patch":"@@ -413,1 +413,1 @@\n-  \/\/ Memory reference, and the alignment width (aw) for which we align the main-loop,\n+  \/\/ VPointer, and the alignment width (aw) for which we align the main-loop,\n@@ -415,1 +415,1 @@\n-  MemNode const* _mem_ref_for_main_loop_alignment;\n+  VPointer const* _vpointer_for_main_loop_alignment;\n@@ -660,1 +660,1 @@\n-  bool schedule_and_apply() const;\n+  bool do_vtransform() const;\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -40,0 +40,4 @@\n+\n+  \/\/ Build vtnodes for all uses of nodes from the loop, and connect them\n+  \/\/ as outputs to the nodes in the loop.\n+  build_uses_after_loop();\n@@ -53,2 +57,2 @@\n-  for (int i = 0; i < _vloop_analyzer.body().body().length(); i++) {\n-    Node* n = _vloop_analyzer.body().body().at(i);\n+  for (uint i = 0; i < _vloop.lpt()->_body.size(); i++) {\n+    Node* n = _vloop.lpt()->_body.at(i);\n@@ -64,0 +68,2 @@\n+    } else if (n->is_CountedLoop()) {\n+      vtn = new (_vtransform.arena()) VTransformCountedLoopNode(_vtransform, n->as_CountedLoop());\n@@ -124,2 +130,2 @@\n-  for (int i = 0; i < _vloop_analyzer.body().body().length(); i++) {\n-    Node* n = _vloop_analyzer.body().body().at(i);\n+  for (uint i = 0; i < _vloop.lpt()->_body.size(); i++) {\n+    Node* n = _vloop.lpt()->_body.at(i);\n@@ -138,6 +144,3 @@\n-      continue; \/\/ Is \"root\", has no dependency.\n-    } else if (n->is_Phi()) {\n-      \/\/ CountedLoop Phi's: ignore backedge (and entry value).\n-      assert(n->in(0) == _vloop.cl(), \"only Phi's from the CountedLoop allowed\");\n-      init_req_with_scalar(n, vtn, 0);\n-      continue;\n+      \/\/ Avoid self-loop, it only creates unnecessary issues in scheduling.\n+      init_req_with_scalar(n, vtn, LoopNode::EntryControl);\n+      init_req_with_scalar(n, vtn, LoopNode::LoopBackControl);\n@@ -150,0 +153,26 @@\n+\/\/ Build vtnodes for all uses of nodes from the loop, and connect them\n+\/\/ as outputs to the nodes in the loop.\n+void SuperWordVTransformBuilder::build_uses_after_loop() {\n+  for (uint i = 0; i < _vloop.lpt()->_body.size(); i++) {\n+    Node* n = _vloop.lpt()->_body.at(i);\n+    VTransformNode* vtn = get_vtnode(n);\n+\n+    for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+      Node* use = n->fast_out(i);\n+\n+      if (!_vloop.in_bb(use)) {\n+        VTransformNode* vtn_use = get_vtnode_or_wrap_as_outer(use);\n+\n+        \/\/ Set all edges\n+        for (uint j = 0; j < use->req(); j++) {\n+          Node* def = use->in(j);\n+          if (n == def && vtn_use->in_req(j) != vtn) {\n+            assert(vtn_use->in_req(j) == nullptr, \"should not yet be set\");\n+            vtn_use->init_req(j, vtn);\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+\n@@ -162,1 +191,2 @@\n-    vtn = new (_vtransform.arena()) VTransformLoadVectorNode(_vtransform, properties, vector_p, p0->adr_type());\n+    const LoadNode::ControlDependency control_dependency = load_control_dependency(pack);\n+    vtn = new (_vtransform.arena()) VTransformLoadVectorNode(_vtransform, properties, vector_p, p0->adr_type(), control_dependency);\n@@ -212,1 +242,0 @@\n-  vtn->set_nodes(pack);\n@@ -279,2 +308,2 @@\n-      BasicType element_type = p0->is_Convert() ? p0->in(1)->bottom_type()->basic_type() : _vloop_analyzer.types().velt_basic_type(p0);\n-      if (index == 2 && VectorNode::is_scalar_rotate(p0) && element_type == T_LONG) {\n+      BasicType element_bt = p0->is_Convert() ? p0->in(1)->bottom_type()->basic_type() : _vloop_analyzer.types().velt_basic_type(p0);\n+      if (index == 2 && VectorNode::is_scalar_rotate(p0) && element_bt == T_LONG) {\n@@ -287,1 +316,1 @@\n-      VTransformNode* replicate = new (_vtransform.arena()) VTransformReplicateNode(_vtransform, pack->size(), element_type);\n+      VTransformNode* replicate = new (_vtransform.arena()) VTransformReplicateNode(_vtransform, pack->size(), element_bt);\n@@ -310,0 +339,1 @@\n+  assert(vtn == get_vtnode_or_null(n), \"consistency\");\n","filename":"src\/hotspot\/share\/opto\/superwordVTransformBuilder.cpp","additions":45,"deletions":15,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+  void build_uses_after_loop();\n@@ -85,0 +86,1 @@\n+  LoadNode::ControlDependency load_control_dependency(const Node_List* pack) const;\n","filename":"src\/hotspot\/share\/opto\/superwordVTransformBuilder.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -185,0 +185,5 @@\n+  VStatus body_status = _body.construct();\n+  if (!body_status.is_success()) {\n+    return body_status;\n+  }\n+\n@@ -195,5 +200,0 @@\n-  VStatus body_status = _body.construct();\n-  if (!body_status.is_success()) {\n-    return body_status;\n-  }\n-\n@@ -209,0 +209,58 @@\n+\/\/ There are 2 kinds of slices:\n+\/\/ - No memory phi: only loads. All have the same input memory state from before the loop.\n+\/\/ - With memory phi. Chain of memory operations inside the loop.\n+void VLoopMemorySlices::find_memory_slices() {\n+  Compile* C = _vloop.phase()->C;\n+  \/\/ We iterate over the body, which is topologically sorted. Hence, if there is a phi\n+  \/\/ in a slice, we will find it first, and the loads and stores afterwards.\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n+    if (n->is_memory_phi()) {\n+      \/\/ Memory slice with stores (and maybe loads)\n+      PhiNode* phi = n->as_Phi();\n+      int alias_idx = C->get_alias_index(phi->adr_type());\n+      assert(_inputs.at(alias_idx) == nullptr, \"did not yet touch this slice\");\n+      _inputs.at_put(alias_idx, phi->in(1));\n+      _heads.at_put(alias_idx, phi);\n+    } else if (n->is_Load()) {\n+      LoadNode* load = n->as_Load();\n+      int alias_idx = C->get_alias_index(load->adr_type());\n+      PhiNode* head = _heads.at(alias_idx);\n+      if (head == nullptr) {\n+        \/\/ We did not find a phi on this slice yet -> must be a slice with only loads.\n+        assert(_inputs.at(alias_idx) == nullptr || _inputs.at(alias_idx) == load->in(1),\n+               \"not yet touched or the same input\");\n+        _inputs.at_put(alias_idx, load->in(1));\n+      } \/\/ else: the load belongs to a slice with a phi that already set heads and inputs.\n+#ifdef ASSERT\n+    } else if (n->is_Store()) {\n+      \/\/ Found a store. Make sure it is in a slice with a Phi.\n+      StoreNode* store = n->as_Store();\n+      int alias_idx = C->get_alias_index(store->adr_type());\n+      PhiNode* head = _heads.at(alias_idx);\n+      assert(head != nullptr, \"should have found a mem phi for this slice\");\n+#endif\n+    }\n+  }\n+  NOT_PRODUCT( if (_vloop.is_trace_memory_slices()) { print(); } )\n+}\n+\n+#ifndef PRODUCT\n+void VLoopMemorySlices::print() const {\n+  tty->print_cr(\"\\nVLoopMemorySlices::print: %s\",\n+                heads().length() > 0 ? \"\" : \"NONE\");\n+  for (int i = 0; i < _inputs.length(); i++) {\n+    Node* input = _inputs.at(i);\n+    PhiNode* head = _heads.at(i);\n+    if (input != nullptr) {\n+      tty->print(\"%3d input\", i);  input->dump();\n+      if (head == nullptr) {\n+        tty->print_cr(\"    load only\");\n+      } else {\n+        tty->print(\"    head \");  head->dump();\n+      }\n+    }\n+  }\n+}\n+#endif\n+\n@@ -270,1 +328,0 @@\n-  const GrowableArray<MemNode*>& mem_slice_tails = _memory_slices.tails();\n@@ -280,1 +337,4 @@\n-    MemNode* tail = mem_slice_tails.at(i);\n+    \/\/ If there is no head (memory-phi) for this slice, then we have either no memops\n+    \/\/ in the loop, or only loads. We do not need to add any memory edges in that case.\n+    if (head == nullptr) { continue; }\n+    MemNode* tail = head->in(2)->as_Mem();\n","filename":"src\/hotspot\/share\/opto\/vectorization.cpp","additions":67,"deletions":7,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -382,31 +382,0 @@\n-\/\/ Submodule of VLoopAnalyzer.\n-\/\/ Find the memory slices in the loop.\n-class VLoopMemorySlices : public StackObj {\n-private:\n-  const VLoop& _vloop;\n-\n-  GrowableArray<PhiNode*> _heads;\n-  GrowableArray<MemNode*> _tails;\n-\n-public:\n-  VLoopMemorySlices(Arena* arena, const VLoop& vloop) :\n-    _vloop(vloop),\n-    _heads(arena, 8, 0, nullptr),\n-    _tails(arena, 8, 0, nullptr) {};\n-  NONCOPYABLE(VLoopMemorySlices);\n-\n-  void find_memory_slices();\n-\n-  const GrowableArray<PhiNode*>& heads() const { return _heads; }\n-  const GrowableArray<MemNode*>& tails() const { return _tails; }\n-\n-  \/\/ Get all memory nodes of a slice, in reverse order\n-  void get_slice_in_reverse_order(PhiNode* head, MemNode* tail, GrowableArray<MemNode*>& slice) const;\n-\n-  bool same_memory_slice(MemNode* m1, MemNode* m2) const;\n-\n-#ifndef PRODUCT\n-  void print() const;\n-#endif\n-};\n-\n@@ -464,0 +433,67 @@\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ Find the memory slices in the loop. There are 3 kinds of slices:\n+\/\/ 1. no use in loop:                     inputs(i) = nullptr,   heads(i) = nullptr\n+\/\/ 2. stores in loop:                     inputs(i) = entry_mem, heads(i) = phi_mem\n+\/\/\n+\/\/    <mem state before loop> = entry_mem\n+\/\/                      |\n+\/\/         CountedLoop  |  +-----------------------+\n+\/\/                   |  v  v                       |\n+\/\/                   phi_mem                       |\n+\/\/                     |                           |\n+\/\/                   <stores (and maybe loads)>    |\n+\/\/                     |                           |\n+\/\/                     +---------------------------+\n+\/\/                     |\n+\/\/    <mem uses after loop>\n+\/\/\n+\/\/    Note: the mem uses after the loop are dependent on the last store in the loop.\n+\/\/          Once we vectorize, we may reorder the loads and stores, and replace\n+\/\/          scalar mem ops with vector mem ops. We will have to make sure that all\n+\/\/          uses after the loop use the new last store.\n+\/\/          See: VTransformApplyState::fix_memory_state_uses_after_loop\n+\/\/\n+\/\/ 3. only loads but no stores in loop:   inputs(i) = entry_mem, heads(i) = nullptr\n+\/\/\n+\/\/    <mem state before loop> = entry_mem\n+\/\/     |                 |\n+\/\/     |   CountedLoop   |\n+\/\/     |             |   |\n+\/\/     |            <loads in loop>\n+\/\/     |\n+\/\/    <mem uses after loop>\n+\/\/\n+\/\/    Note: the mem uses after the loop are NOT dependent any mem ops in the loop,\n+\/\/          since there are no stores.\n+\/\/\n+class VLoopMemorySlices : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+  const VLoopBody& _body;\n+\n+  GrowableArray<Node*>    _inputs;\n+  GrowableArray<PhiNode*> _heads;\n+\n+public:\n+  VLoopMemorySlices(Arena* arena, const VLoop& vloop, const VLoopBody& body) :\n+    _vloop(vloop),\n+    _body(body),\n+    _inputs(arena, num_slices(), num_slices(), nullptr),\n+    _heads(arena, num_slices(), num_slices(), nullptr) {};\n+  NONCOPYABLE(VLoopMemorySlices);\n+\n+  const GrowableArray<Node*>& inputs() const { return _inputs; }\n+  const GrowableArray<PhiNode*>& heads() const { return _heads; }\n+\n+  void find_memory_slices();\n+  void get_slice_in_reverse_order(PhiNode* head, MemNode* tail, GrowableArray<MemNode*>& slice) const;\n+  bool same_memory_slice(MemNode* m1, MemNode* m2) const;\n+\n+private:\n+#ifndef PRODUCT\n+  void print() const;\n+#endif\n+\n+  int num_slices() const { return _vloop.phase()->C->num_alias_types(); }\n+};\n+\n@@ -740,1 +776,0 @@\n-  VLoopMemorySlices    _memory_slices;\n@@ -742,0 +777,1 @@\n+  VLoopMemorySlices    _memory_slices;\n@@ -752,1 +788,0 @@\n-    _memory_slices   (&_arena, vloop),\n@@ -754,0 +789,1 @@\n+    _memory_slices   (&_arena, vloop, _body),\n","filename":"src\/hotspot\/share\/opto\/vectorization.hpp","additions":69,"deletions":33,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -81,0 +81,4 @@\n+\n+        \/\/ Skip LoopPhi backedge.\n+        if ((use->isa_LoopPhi() != nullptr || use->isa_CountedLoop() != nullptr) && use->in_req(2) == vtn) { continue; }\n+\n@@ -123,0 +127,5 @@\n+    \/\/ If an Outer node has both inputs and outputs, we will most likely have cycles in the final graph.\n+    \/\/ This is not a correctness problem, but it just will prevent vectorization. If this ever happens\n+    \/\/ try to find a way to avoid the cycle somehow.\n+    assert(vtn->isa_Outer() == nullptr || (vtn->has_strong_in_edge() != (vtn->out_strong_edges() > 0)),\n+           \"Outer nodes should either be inputs or outputs, but not both, otherwise we may get cycles\");\n@@ -720,0 +729,51 @@\n+void VTransformApplyState::init_memory_states_and_uses_after_loop() {\n+  const GrowableArray<Node*>& inputs = _vloop_analyzer.memory_slices().inputs();\n+  const GrowableArray<PhiNode*>& heads = _vloop_analyzer.memory_slices().heads();\n+  for (int i = 0; i < inputs.length(); i++) {\n+    PhiNode* head = heads.at(i);\n+    if (head != nullptr) {\n+      \/\/ Slice with Phi (i.e. with stores) -> start with the phi (phi_mem)\n+      _memory_states.at_put(i, head);\n+\n+      \/\/ Remember uses outside the loop of the last memory state (store).\n+      StoreNode* last_store = head->in(2)->as_Store();\n+      assert(vloop().in_bb(last_store), \"backedge store should be in the loop\");\n+      for (DUIterator_Fast jmax, j = last_store->fast_outs(jmax); j < jmax; j++) {\n+        Node* use = last_store->fast_out(j);\n+        if (!vloop().in_bb(use)) {\n+          for (uint k = 0; k < use->req(); k++) {\n+            if (use->in(k) == last_store) {\n+              _memory_state_uses_after_loop.push(MemoryStateUseAfterLoop(use, k, i));\n+            }\n+          }\n+        }\n+      }\n+    } else {\n+      \/\/ Slice without Phi (i.e. only loads) -> use the input state (entry_mem)\n+      _memory_states.at_put(i, inputs.at(i));\n+    }\n+  }\n+}\n+\n+\/\/ We may have reordered the scalar stores, or replaced them with vectors. Now\n+\/\/ the last memory state in the loop may have changed. Thus, we need to change\n+\/\/ the uses of the old last memory state the the new last memory state.\n+void VTransformApplyState::fix_memory_state_uses_after_loop() {\n+  for (int i = 0; i < _memory_state_uses_after_loop.length(); i++) {\n+    MemoryStateUseAfterLoop& use = _memory_state_uses_after_loop.at(i);\n+    Node* last_state = memory_state(use._alias_idx);\n+    phase()->igvn().replace_input_of(use._use, use._in_idx, last_state);\n+  }\n+}\n+\n+void VTransformNode::apply_vtn_inputs_to_node(Node* n, VTransformApplyState& apply_state) const {\n+  PhaseIdealLoop* phase = apply_state.phase();\n+  for (uint i = 0; i < req(); i++) {\n+    VTransformNode* vtn_def = in_req(i);\n+    if (vtn_def != nullptr) {\n+      Node* def = apply_state.transformed_node(vtn_def);\n+      phase->igvn().replace_input_of(n, i, def);\n+    }\n+  }\n+}\n+\n@@ -721,1 +781,8 @@\n-  \/\/ This was just wrapped. Now we simply unwrap without touching the inputs.\n+  apply_vtn_inputs_to_node(_node, apply_state);\n+  \/\/ The memory state has to be applied separately: the vtn does not hold it. This allows reordering.\n+  Node* mem = apply_state.memory_state(_node->adr_type());\n+  apply_state.phase()->igvn().replace_input_of(_node, 1, mem);\n+  if (_node->is_Store()) {\n+    apply_state.set_memory_state(_node->adr_type(), _node);\n+  }\n+\n@@ -726,1 +793,1 @@\n-  \/\/ This was just wrapped. Now we simply unwrap without touching the inputs.\n+  apply_vtn_inputs_to_node(_node, apply_state);\n@@ -731,1 +798,6 @@\n-  \/\/ This was just wrapped. Now we simply unwrap without touching the inputs.\n+  PhaseIdealLoop* phase = apply_state.phase();\n+  Node* in0 = apply_state.transformed_node(in_req(0));\n+  Node* in1 = apply_state.transformed_node(in_req(1));\n+  phase->igvn().replace_input_of(_node, 0, in0);\n+  phase->igvn().replace_input_of(_node, 1, in1);\n+  \/\/ Note: the backedge is hooked up later.\n@@ -735,0 +807,17 @@\n+\/\/ Cleanup backedges. In the schedule, the backedges come after their phis. Hence,\n+\/\/ we only have the transformed backedges after the phis are already transformed.\n+\/\/ We hook the backedges into the phis now, during cleanup.\n+void VTransformLoopPhiNode::apply_backedge(VTransformApplyState& apply_state) const {\n+  PhaseIdealLoop* phase = apply_state.phase();\n+  if (_node->is_memory_phi()) {\n+    \/\/ Memory phi\/backedge\n+    \/\/ The last memory state of that slice is the backedge.\n+    Node* last_state = apply_state.memory_state(_node->adr_type());\n+    phase->igvn().replace_input_of(_node, 2, last_state);\n+  } else {\n+    \/\/ Data phi\/backedge\n+    Node* in2 = apply_state.transformed_node(in_req(2));\n+    phase->igvn().replace_input_of(_node, 2, in2);\n+  }\n+}\n+\n@@ -736,1 +825,4 @@\n-  \/\/ This was just wrapped. Now we simply unwrap without touching the inputs.\n+  \/\/ We do not modify the inputs of the CountedLoop (and certainly not its backedge)\n+  if (!_node->is_CountedLoop()) {\n+    apply_vtn_inputs_to_node(_node, apply_state);\n+  }\n@@ -741,1 +833,1 @@\n-  \/\/ This was just wrapped. Now we simply unwrap without touching the inputs.\n+  apply_vtn_inputs_to_node(_node, apply_state);\n@@ -800,1 +892,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -815,1 +907,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -827,1 +919,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -846,1 +938,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -855,1 +947,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -864,1 +956,1 @@\n-  LoadNode* first = nodes().at(0)->as_Load();\n+  \/\/ The memory state has to be applied separately: the vtn does not hold it. This allows reordering.\n@@ -866,2 +958,1 @@\n-  \/\/ first has the correct memory state, determined by VTransformGraph::apply_memops_reordering_with_schedule\n-  Node* mem  = first->in(MemNode::Memory);\n+  Node* mem  = apply_state.memory_state(_adr_type);\n@@ -883,2 +974,1 @@\n-  LoadVectorNode* vn = LoadVectorNode::make(sopc, ctrl, mem, adr, _adr_type, vlen, bt,\n-                                            control_dependency());\n+  LoadVectorNode* vn = LoadVectorNode::make(sopc, ctrl, mem, adr, _adr_type, vlen, bt, _control_dependency);\n@@ -886,1 +976,1 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n+  register_new_node_from_vectorization(apply_state, vn);\n@@ -894,1 +984,1 @@\n-  StoreNode* first = nodes().at(0)->as_Store();\n+  \/\/ The memory state has to be applied separately: the vtn does not hold it. This allows reordering.\n@@ -896,2 +986,1 @@\n-  \/\/ first has the correct memory state, determined by VTransformGraph::apply_memops_reordering_with_schedule\n-  Node* mem  = first->in(MemNode::Memory);\n+  Node* mem  = apply_state.memory_state(_adr_type);\n@@ -903,6 +992,0 @@\n-  register_new_node_from_vectorization_and_replace_scalar_nodes(apply_state, vn);\n-  return VTransformApplyResult::make_vector(vn, vn->vect_type());\n-}\n-\n-void VTransformVectorNode::register_new_node_from_vectorization_and_replace_scalar_nodes(VTransformApplyState& apply_state, Node* vn) const {\n-  PhaseIdealLoop* phase = apply_state.phase();\n@@ -910,5 +993,2 @@\n-\n-  for (int i = 0; i < _nodes.length(); i++) {\n-    Node* n = _nodes.at(i);\n-    phase->igvn().replace_node(n, vn);\n-  }\n+  apply_state.set_memory_state(_adr_type, vn);\n+  return VTransformApplyResult::make_vector(vn, vn->vect_type());\n@@ -947,9 +1027,0 @@\n-void VTransformGraph::print_memops_schedule() const {\n-  tty->print_cr(\"\\nVTransformGraph::print_memops_schedule:\");\n-  int i = 0;\n-  for_each_memop_in_schedule([&] (MemNode* mem) {\n-    tty->print(\" %3d: \", i++);\n-    mem->dump();\n-  });\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/vtransform.cpp","additions":110,"deletions":39,"binary":false,"changes":149,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-\/\/   - From SuperWord, with the SuperWordVTransformBuilder.\n+\/\/   - From SuperWord PackSet, with the SuperWordVTransformBuilder.\n@@ -52,0 +52,2 @@\n+\/\/   - Align the main loop, by adjusting pre loop limit.\n+\/\/   - Add speculative runtime checks (alignment and aliasing).\n@@ -53,1 +55,7 @@\n-\/\/     possibly replacing old scalar C2 nodes.\n+\/\/     possibly replacing old scalar C2 nodes. We apply each vtnode in order\n+\/\/     of the schedule, so that all input vtnodes are already applied, i.e.\n+\/\/     all input vtnodes have already generated the transformed C2 nodes.\n+\/\/   - We also build the new memory graph on the fly. The schedule may have\n+\/\/     reordered the memory operations, and so we cannot use the old memory\n+\/\/     graph, but must build it from the scheduled order. We keep track of\n+\/\/     the current memory state in VTransformApplyState.\n@@ -68,0 +76,1 @@\n+class VTransformCountedLoopNode;\n@@ -179,1 +188,0 @@\n-  void apply_memops_reordering_with_schedule() const;\n@@ -190,3 +198,0 @@\n-  template<typename Callback>\n-  void for_each_memop_in_schedule(Callback callback) const;\n-\n@@ -196,1 +201,0 @@\n-  void print_memops_schedule() const;\n@@ -218,1 +222,1 @@\n-  \/\/ Memory reference, and the alignment width (aw) for which we align the main-loop,\n+  \/\/ VPointer, and the alignment width (aw) for which we align the main-loop,\n@@ -220,1 +224,1 @@\n-  MemNode const* _mem_ref_for_main_loop_alignment;\n+  VPointer const* _vpointer_for_main_loop_alignment;\n@@ -225,1 +229,1 @@\n-             MemNode const* mem_ref_for_main_loop_alignment,\n+             VPointer const* vpointer_for_main_loop_alignment,\n@@ -234,1 +238,1 @@\n-    _mem_ref_for_main_loop_alignment(mem_ref_for_main_loop_alignment),\n+    _vpointer_for_main_loop_alignment(vpointer_for_main_loop_alignment),\n@@ -260,1 +264,1 @@\n-  void determine_mem_ref_and_aw_for_main_loop_alignment();\n+  void determine_vpointer_and_aw_for_main_loop_alignment();\n@@ -274,1 +278,1 @@\n-\/\/ -> keep track of the already transformed nodes\n+\/\/ -> keep track of the already transformed nodes and the memory state.\n@@ -284,0 +288,22 @@\n+  \/\/ We keep track of the current memory state in each slice. If the slice has only\n+  \/\/ loads (and no phi), then this is always the input memory state from before the\n+  \/\/ loop. If there is a memory phi, this is initially the memory phi, and each time\n+  \/\/ a store is processed, it is updated to that store.\n+  GrowableArray<Node*> _memory_states;\n+\n+  \/\/ We need to keep track of the memory uses after the loop, for the slices that\n+  \/\/ have a memory phi.\n+  \/\/   use->in(in_idx) = <last memory state in loop of slice alias_idx>\n+  class MemoryStateUseAfterLoop : public StackObj {\n+  public:\n+    Node* _use;\n+    int _in_idx;\n+    int _alias_idx;\n+\n+    MemoryStateUseAfterLoop(Node* use, int in_idx, int alias_idx) :\n+      _use(use), _in_idx(in_idx), _alias_idx(alias_idx) {}\n+    MemoryStateUseAfterLoop() : MemoryStateUseAfterLoop(nullptr, 0, 0) {}\n+  };\n+\n+  GrowableArray<MemoryStateUseAfterLoop> _memory_state_uses_after_loop;\n+\n@@ -287,1 +313,2 @@\n-    _vtnode_idx_to_transformed_node(num_vtnodes, num_vtnodes, nullptr)\n+    _vtnode_idx_to_transformed_node(num_vtnodes, num_vtnodes, nullptr),\n+    _memory_states(num_slices(), num_slices(), nullptr)\n@@ -289,0 +316,1 @@\n+    init_memory_states_and_uses_after_loop();\n@@ -297,0 +325,19 @@\n+\n+  Node* memory_state(int alias_idx) const { return _memory_states.at(alias_idx); }\n+  void set_memory_state(int alias_idx, Node* n) { _memory_states.at_put(alias_idx, n); }\n+\n+  Node* memory_state(const TypePtr* adr_type) const {\n+    int alias_idx = phase()->C->get_alias_index(adr_type);\n+    return memory_state(alias_idx);\n+  }\n+\n+  void set_memory_state(const TypePtr* adr_type, Node* n) {\n+    int alias_idx = phase()->C->get_alias_index(adr_type);\n+    return set_memory_state(alias_idx, n);\n+  }\n+\n+  void fix_memory_state_uses_after_loop();\n+\n+private:\n+  int num_slices() const { return _vloop_analyzer.memory_slices().heads().length(); }\n+  void init_memory_states_and_uses_after_loop();\n@@ -436,0 +483,2 @@\n+  virtual VTransformLoopPhiNode* isa_LoopPhi() { return nullptr; }\n+  virtual VTransformCountedLoopNode* isa_CountedLoop() { return nullptr; }\n@@ -451,3 +500,2 @@\n-\n-  Node* find_transformed_input(int i, const GrowableArray<Node*>& vnode_idx_to_transformed_node) const;\n-\n+  virtual void apply_backedge(VTransformApplyState& apply_state) const {};\n+  void apply_vtn_inputs_to_node(Node* n, VTransformApplyState& apply_state) const;\n@@ -513,0 +561,1 @@\n+  virtual VTransformLoopPhiNode* isa_LoopPhi() override { return this; }\n@@ -514,0 +563,1 @@\n+  virtual void apply_backedge(VTransformApplyState& apply_state) const override;\n@@ -534,0 +584,10 @@\n+\/\/ Identity transform for CountedLoop, the only CFG node with a backedge.\n+class VTransformCountedLoopNode : public VTransformCFGNode {\n+public:\n+  VTransformCountedLoopNode(VTransform& vtransform, CountedLoopNode* n) :\n+    VTransformCFGNode(vtransform, n) {}\n+\n+  virtual VTransformCountedLoopNode* isa_CountedLoop() override { return this; }\n+  NOT_PRODUCT(virtual const char* name() const override { return \"CountedLoop\"; };)\n+};\n+\n@@ -635,2 +695,0 @@\n-protected:\n-  GrowableArray<Node*> _nodes;\n@@ -639,12 +697,1 @@\n-    VTransformNode(vtransform, req),\n-    _properties(properties),\n-    _nodes(vtransform.arena(),\n-           properties.vector_length(),\n-           properties.vector_length(),\n-           nullptr) {}\n-\n-  void set_nodes(const Node_List* pack) {\n-    for (uint k = 0; k < pack->size(); k++) {\n-      _nodes.at_put(k, pack->at(k));\n-    }\n-  }\n+    VTransformNode(vtransform, req), _properties(properties) {}\n@@ -752,1 +799,0 @@\n-  const GrowableArray<Node*>& nodes() const { return _nodes; }\n@@ -759,0 +805,3 @@\n+private:\n+  const LoadNode::ControlDependency _control_dependency;\n+\n@@ -761,2 +810,6 @@\n-  VTransformLoadVectorNode(VTransform& vtransform, const VTransformVectorNodeProperties properties, const VPointer& vpointer, const TypePtr* adr_type) :\n-    VTransformMemVectorNode(vtransform, 3, properties, vpointer, adr_type) {}\n+  VTransformLoadVectorNode(VTransform& vtransform,\n+                           const VTransformVectorNodeProperties properties,\n+                           const VPointer& vpointer,\n+                           const TypePtr* adr_type,\n+                           const LoadNode::ControlDependency control_dependency) :\n+    VTransformMemVectorNode(vtransform, 3, properties, vpointer, adr_type), _control_dependency(control_dependency) {}\n@@ -780,26 +833,0 @@\n-\n-\/\/ Invoke callback on all memops, in the order of the schedule.\n-template<typename Callback>\n-void VTransformGraph::for_each_memop_in_schedule(Callback callback) const {\n-  assert(_schedule.length() == _vtnodes.length(), \"schedule was computed\");\n-\n-  for (int i = 0; i < _schedule.length(); i++) {\n-    VTransformNode* vtn = _schedule.at(i);\n-\n-    \/\/ We must ignore nodes outside the loop.\n-    if (vtn->isa_Outer() != nullptr) { continue; }\n-\n-    VTransformMemopScalarNode* scalar = vtn->isa_MemopScalar();\n-    if (scalar != nullptr) {\n-      callback(scalar->node());\n-    }\n-\n-    VTransformMemVectorNode* vector = vtn->isa_MemVector();\n-    if (vector != nullptr) {\n-      for (int j = 0; j < vector->nodes().length(); j++) {\n-        callback(vector->nodes().at(j)->as_Mem());\n-      }\n-    }\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/vtransform.hpp","additions":87,"deletions":60,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -101,3 +101,3 @@\n-    AUTO_VECTORIZATION2_AFTER_REORDER(                   \"AutoVectorization 2, after Apply Memop Reordering\"),\n-    AUTO_VECTORIZATION3_AFTER_ADJUST_LIMIT(              \"AutoVectorization 3, after Adjusting Pre-loop Limit\"),\n-    AUTO_VECTORIZATION4_AFTER_SPECULATIVE_RUNTIME_CHECKS(\"AutoVectorization 4, after Adding Speculative Runtime Checks\"),\n+    AUTO_VECTORIZATION3_AFTER_ADJUST_LIMIT(              \"AutoVectorization 2, after Adjusting Pre-loop Limit\"),\n+    AUTO_VECTORIZATION4_AFTER_SPECULATIVE_RUNTIME_CHECKS(\"AutoVectorization 3, after Adding Speculative Runtime Checks\"),\n+    AUTO_VECTORIZATION5_AFTER_APPLY(                     \"AutoVectorization 4, after Apply\"),\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/CompilePhase.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"}]}