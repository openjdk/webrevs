{"files":[{"patch":"@@ -1473,0 +1473,19 @@\n+\/\/ Support class used to generate HPROF_GC_CLASS_DUMP records\n+\n+class ClassDumper : public KlassClosure {\n+ private:\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const { return _writer; }\n+\n+ public:\n+  ClassDumper(AbstractDumpWriter* writer) : _writer(writer) {}\n+\n+  void do_klass(Klass* k) {\n+    if (k->is_instance_klass()) {\n+      DumperSupport::dump_instance_class(writer(), k);\n+    } else {\n+      DumperSupport::dump_array_class(writer(), k);\n+    }\n+  }\n+};\n+\n@@ -1860,2 +1879,6 @@\n-\n-class VM_HeapDumper;\n+\/\/ Callback to dump thread-related data for unmounted virtual threads;\n+\/\/ implemented by VM_HeapDumper.\n+class UnmountedVThreadDumper {\n+ public:\n+  virtual void dump_vthread(oop vt, AbstractDumpWriter* segment_writer) = 0;\n+};\n@@ -1868,0 +1891,1 @@\n+  UnmountedVThreadDumper* _vthread_dumper;\n@@ -1872,3 +1896,2 @@\n-  HeapObjectDumper(AbstractDumpWriter* writer) {\n-    _writer = writer;\n-  }\n+  HeapObjectDumper(AbstractDumpWriter* writer, UnmountedVThreadDumper* vthread_dumper)\n+    : _writer(writer), _vthread_dumper(vthread_dumper) {}\n@@ -1896,0 +1919,3 @@\n+    if (java_lang_VirtualThread::is_instance(o) && ThreadDumper::should_dump_vthread(o)) {\n+      _vthread_dumper->dump_vthread(o, writer());\n+    }\n@@ -1912,0 +1938,3 @@\n+   bool   _started; \/\/ VM dumper started and acquired global writer lock\n+   Mutex* _global_writer_lock;\n+\n@@ -1914,1 +1943,1 @@\n-     _lock(new (std::nothrow) PaddedMonitor(Mutex::safepoint, \"DumperController_lock\")),\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::nosafepoint - 1, \"DumperController_lock\")),\n@@ -1916,1 +1945,9 @@\n-     _complete_number(0) { }\n+     _complete_number(0),\n+     _started(false),\n+     _global_writer_lock(new (std::nothrow) Mutex(Mutex::nosafepoint, \"DumpWriter_lock\"))\n+   {}\n+\n+   ~DumperController() {\n+     delete _lock;\n+     delete _global_writer_lock;\n+   }\n@@ -1918,1 +1955,21 @@\n-   ~DumperController() { delete _lock; }\n+   \/\/ parallel (non VM) dumpers must wait until VM dumper acquires global writer lock\n+   void wait_for_start_signal() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_started == false) {\n+       ml.wait();\n+     }\n+   }\n+\n+   void signal_start() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _started = true;\n+     ml.notify_all();\n+   }\n+\n+   void lock_global_writer() {\n+     _global_writer_lock->lock_without_safepoint_check();\n+   }\n+\n+   void unlock_global_writer() {\n+     _global_writer_lock->unlock();\n+   }\n@@ -1947,1 +2004,1 @@\n-  void merge_file(char* path);\n+  void merge_file(const char* path);\n@@ -1959,0 +2016,4 @@\n+\n+  \/\/ returns path for the parallel DumpWriter (resource allocated)\n+  static char* get_writer_path(const char* base_path, int seq);\n+\n@@ -1961,0 +2022,16 @@\n+char* DumpMerger::get_writer_path(const char* base_path, int seq) {\n+  \/\/ calculate required buffer size\n+    size_t buf_size = strlen(base_path)\n+                    + 2                 \/\/ \".p\"\n+                    + 1 + (seq \/ 10)    \/\/ number\n+                    + 1;                \/\/ '\\0'\n+\n+  char* path = NEW_RESOURCE_ARRAY(char, buf_size);\n+  memset(path, 0, buf_size);\n+\n+  os::snprintf(path, buf_size, \"%s.p%d\", base_path, seq);\n+\n+  return path;\n+}\n+\n+\n@@ -1981,1 +2058,1 @@\n-void DumpMerger::merge_file(char* path) {\n+void DumpMerger::merge_file(const char* path) {\n@@ -2019,1 +2096,1 @@\n-void DumpMerger::merge_file(char* path) {\n+void DumpMerger::merge_file(const char* path) {\n@@ -2055,1 +2132,0 @@\n-  char path[JVM_MAXPATHLEN];\n@@ -2057,2 +2133,2 @@\n-    memset(path, 0, JVM_MAXPATHLEN);\n-    os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", _path, i);\n+    ResourceMark rm;\n+    const char* path = get_writer_path(_path, i);\n@@ -2088,1 +2164,1 @@\n-class VM_HeapDumper : public VM_GC_Operation, public WorkerTask {\n+class VM_HeapDumper : public VM_GC_Operation, public WorkerTask, public UnmountedVThreadDumper {\n@@ -2108,2 +2184,3 @@\n-  \/\/ worker id of VMDumper thread.\n-  static const size_t VMDumperWorkerId = 0;\n+\n+  \/\/ Dumper id of VMDumper thread.\n+  static const int VMDumperId = 0;\n@@ -2111,1 +2188,5 @@\n-  static bool is_vm_dumper(uint worker_id) { return worker_id == VMDumperWorkerId; }\n+  static bool is_vm_dumper(int dumper_id) { return dumper_id == VMDumperId; }\n+  \/\/ the 1st dumper calling get_next_dumper_id becomes VM dumper\n+  int get_next_dumper_id() {\n+    return Atomic::fetch_then_add(&_dump_seq, 1);\n+  }\n@@ -2130,4 +2211,1 @@\n-  \/\/ create dump writer for every parallel dump thread\n-  DumpWriter* create_local_writer();\n-\n-  \/\/ writes a HPROF_LOAD_CLASS record\n+  \/\/ writes a HPROF_LOAD_CLASS record to global writer\n@@ -2136,3 +2214,0 @@\n-  \/\/ writes a HPROF_GC_CLASS_DUMP record for the given class\n-  static void do_class_dump(Klass* k);\n-\n@@ -2140,1 +2215,1 @@\n-  void dump_threads();\n+  void dump_threads(AbstractDumpWriter* writer);\n@@ -2151,1 +2226,1 @@\n-  void dump_stack_traces();\n+  void dump_stack_traces(AbstractDumpWriter* writer);\n@@ -2169,1 +2244,1 @@\n-    _dump_seq = 0;\n+    _dump_seq = VMDumperId;\n@@ -2203,1 +2278,1 @@\n-  bool can_parallel_dump(WorkerThreads* workers);\n+  void update_parallel_dump_count(WorkerThreads* workers);\n@@ -2209,0 +2284,3 @@\n+\n+  \/\/ UnmountedVThreadDumper implementation\n+  void dump_vthread(oop vt, AbstractDumpWriter* segment_writer);\n@@ -2252,9 +2330,0 @@\n-\/\/ writes a HPROF_GC_CLASS_DUMP record for the given class\n-void VM_HeapDumper::do_class_dump(Klass* k) {\n-  if (k->is_instance_klass()) {\n-    DumperSupport::dump_instance_class(writer(), k);\n-  } else {\n-    DumperSupport::dump_array_class(writer(), k);\n-  }\n-}\n-\n@@ -2263,5 +2332,5 @@\n-void VM_HeapDumper::dump_threads() {\n-    for (int i = 0; i < _thread_dumpers_count; i++) {\n-        _thread_dumpers[i]->dump_thread_obj(writer());\n-        _thread_dumpers[i]->dump_stack_refs(writer());\n-    }\n+void VM_HeapDumper::dump_threads(AbstractDumpWriter* writer) {\n+  for (int i = 0; i < _thread_dumpers_count; i++) {\n+    _thread_dumpers[i]->dump_thread_obj(writer);\n+    _thread_dumpers[i]->dump_stack_refs(writer);\n+  }\n@@ -2281,2 +2350,1 @@\n-bool VM_HeapDumper::can_parallel_dump(WorkerThreads* workers) {\n-  bool can_parallel = true;\n+void VM_HeapDumper::update_parallel_dump_count(WorkerThreads* workers) {\n@@ -2288,1 +2356,0 @@\n-    can_parallel = false;\n@@ -2290,9 +2357,1 @@\n-    \/\/ check if we have extra path room to accommodate segmented heap files\n-    const char* base_path = writer()->get_file_path();\n-    assert(base_path != nullptr, \"sanity check\");\n-    if ((strlen(base_path) + 7\/*.p\\d\\d\\d\\d\\0*\/) >= JVM_MAXPATHLEN) {\n-      _num_dumper_threads = 1;\n-      can_parallel = false;\n-    } else {\n-      _num_dumper_threads = clamp(num_requested_dump_threads, 2U, num_active_workers);\n-    }\n+    _num_dumper_threads = clamp(num_requested_dump_threads, 2U, num_active_workers);\n@@ -2300,1 +2359,1 @@\n-\n+  bool can_parallel = _num_dumper_threads > 1;\n@@ -2305,1 +2364,0 @@\n-  return can_parallel;\n@@ -2353,2 +2411,5 @@\n-  if (!can_parallel_dump(workers)) {\n-    work(VMDumperWorkerId);\n+  update_parallel_dump_count(workers);\n+  _dumper_controller = new (std::nothrow) DumperController(_num_dumper_threads);\n+\n+  if (!is_parallel_dump()) {\n+    work(VMDumperId);\n@@ -2356,2 +2417,0 @@\n-    uint heap_only_dumper_threads = _num_dumper_threads - 1 \/* VMDumper thread *\/;\n-    _dumper_controller = new (std::nothrow) DumperController(heap_only_dumper_threads);\n@@ -2369,17 +2428,0 @@\n-\/\/ prepare DumpWriter for every parallel dump thread\n-DumpWriter* VM_HeapDumper::create_local_writer() {\n-  char* path = NEW_RESOURCE_ARRAY(char, JVM_MAXPATHLEN);\n-  memset(path, 0, JVM_MAXPATHLEN);\n-\n-  \/\/ generate segmented heap file path\n-  const char* base_path = writer()->get_file_path();\n-  \/\/ share global compressor, local DumpWriter is not responsible for its life cycle\n-  AbstractCompressor* compressor = writer()->compressor();\n-  int seq = Atomic::fetch_then_add(&_dump_seq, 1);\n-  os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", base_path, seq);\n-\n-  \/\/ create corresponding writer for that\n-  DumpWriter* local_writer = new DumpWriter(path, writer()->is_overwrite(), compressor);\n-  return local_writer;\n-}\n-\n@@ -2388,1 +2430,11 @@\n-  if (is_vm_dumper(worker_id)) {\n+  int dumper_id = get_next_dumper_id();\n+\n+  if (is_vm_dumper(dumper_id)) {\n+    \/\/ lock global writer, it will be unlocked after VM Dumper finishes with non-heap data\n+    _dumper_controller->lock_global_writer();\n+    _dumper_controller->signal_start();\n+  } else {\n+    _dumper_controller->wait_for_start_signal();\n+  }\n+\n+  if (is_vm_dumper(dumper_id)) {\n@@ -2410,1 +2462,1 @@\n-    dump_stack_traces();\n+    dump_stack_traces(writer());\n@@ -2412,1 +2464,3 @@\n-    \/\/ HPROF_HEAP_DUMP\/HPROF_HEAP_DUMP_SEGMENT starts here\n+    \/\/ unlock global writer, so parallel dumpers can dump stack traces of unmounted virtual threads\n+    _dumper_controller->unlock_global_writer();\n+  }\n@@ -2414,5 +2468,1 @@\n-    \/\/ Writes HPROF_GC_CLASS_DUMP records\n-    {\n-      LockedClassesDo locked_dump_class(&do_class_dump);\n-      ClassLoaderDataGraph::classes_do(&locked_dump_class);\n-    }\n+  \/\/ HPROF_HEAP_DUMP\/HPROF_HEAP_DUMP_SEGMENT starts here\n@@ -2420,44 +2470,26 @@\n-    \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n-    dump_threads();\n-\n-    \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n-    JNIGlobalsDumper jni_dumper(writer());\n-    JNIHandles::oops_do(&jni_dumper);\n-    \/\/ technically not jni roots, but global roots\n-    \/\/ for things like preallocated throwable backtraces\n-    Universe::vm_global()->oops_do(&jni_dumper);\n-    \/\/ HPROF_GC_ROOT_STICKY_CLASS\n-    \/\/ These should be classes in the null class loader data, and not all classes\n-    \/\/ if !ClassUnloading\n-    StickyClassDumper class_dumper(writer());\n-    ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n-  }\n-\n-  \/\/ Heap iteration.\n-  \/\/ writes HPROF_GC_INSTANCE_DUMP records.\n-  \/\/ After each sub-record is written check_segment_length will be invoked\n-  \/\/ to check if the current segment exceeds a threshold. If so, a new\n-  \/\/ segment is started.\n-  \/\/ The HPROF_GC_CLASS_DUMP and HPROF_GC_INSTANCE_DUMP are the vast bulk\n-  \/\/ of the heap dump.\n-  if (!is_parallel_dump()) {\n-    assert(is_vm_dumper(worker_id), \"must be\");\n-    \/\/ == Serial dump\n-    ResourceMark rm;\n-    TraceTime timer(\"Dump heap objects\", TRACETIME_LOG(Info, heapdump));\n-    HeapObjectDumper obj_dumper(writer());\n-    Universe::heap()->object_iterate(&obj_dumper);\n-    writer()->finish_dump_segment();\n-    \/\/ Writes the HPROF_HEAP_DUMP_END record because merge does not happen in serial dump\n-    DumperSupport::end_of_dump(writer());\n-    writer()->flush();\n-  } else {\n-    \/\/ == Parallel dump\n-    ResourceMark rm;\n-    TraceTime timer(\"Dump heap objects in parallel\", TRACETIME_LOG(Info, heapdump));\n-    DumpWriter* local_writer = is_vm_dumper(worker_id) ? writer() : create_local_writer();\n-    if (!local_writer->has_error()) {\n-      HeapObjectDumper obj_dumper(local_writer);\n-      _poi->object_iterate(&obj_dumper, worker_id);\n-      local_writer->finish_dump_segment();\n-      local_writer->flush();\n+  ResourceMark rm;\n+  \/\/ share global compressor, local DumpWriter is not responsible for its life cycle\n+  DumpWriter segment_writer(DumpMerger::get_writer_path(writer()->get_file_path(), dumper_id),\n+                            writer()->is_overwrite(), writer()->compressor());\n+  if (!segment_writer.has_error()) {\n+    if (is_vm_dumper(dumper_id)) {\n+      \/\/ dump some non-heap subrecords to heap dump segment\n+      TraceTime timer(\"Dump non-objects (part 2)\", TRACETIME_LOG(Info, heapdump));\n+      \/\/ Writes HPROF_GC_CLASS_DUMP records\n+      ClassDumper class_dumper(&segment_writer);\n+      ClassLoaderDataGraph::classes_do(&class_dumper);\n+\n+      \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n+      dump_threads(&segment_writer);\n+\n+      \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n+      JNIGlobalsDumper jni_dumper(&segment_writer);\n+      JNIHandles::oops_do(&jni_dumper);\n+      \/\/ technically not jni roots, but global roots\n+      \/\/ for things like preallocated throwable backtraces\n+      Universe::vm_global()->oops_do(&jni_dumper);\n+      \/\/ HPROF_GC_ROOT_STICKY_CLASS\n+      \/\/ These should be classes in the null class loader data, and not all classes\n+      \/\/ if !ClassUnloading\n+      StickyClassDumper stiky_class_dumper(&segment_writer);\n+      ClassLoaderData::the_null_class_loader_data()->classes_do(&stiky_class_dumper);\n@@ -2465,2 +2497,13 @@\n-    if (is_vm_dumper(worker_id)) {\n-      _dumper_controller->wait_all_dumpers_complete();\n+\n+    \/\/ Heap iteration.\n+    \/\/ writes HPROF_GC_INSTANCE_DUMP records.\n+    \/\/ After each sub-record is written check_segment_length will be invoked\n+    \/\/ to check if the current segment exceeds a threshold. If so, a new\n+    \/\/ segment is started.\n+    \/\/ The HPROF_GC_CLASS_DUMP and HPROF_GC_INSTANCE_DUMP are the vast bulk\n+    \/\/ of the heap dump.\n+\n+    TraceTime timer(is_parallel_dump() ? \"Dump heap objects in parallel\" : \"Dump heap objects\", TRACETIME_LOG(Info, heapdump));\n+    HeapObjectDumper obj_dumper(&segment_writer, this);\n+    if (!is_parallel_dump()) {\n+      Universe::heap()->object_iterate(&obj_dumper);\n@@ -2468,3 +2511,2 @@\n-      _dumper_controller->dumper_complete(local_writer, writer());\n-      delete local_writer;\n-      return;\n+      \/\/ == Parallel dump\n+      _poi->object_iterate(&obj_dumper, worker_id);\n@@ -2472,0 +2514,15 @@\n+\n+    segment_writer.finish_dump_segment();\n+    segment_writer.flush();\n+  }\n+\n+  _dumper_controller->dumper_complete(&segment_writer, writer());\n+\n+  if (is_vm_dumper(dumper_id)) {\n+    _dumper_controller->wait_all_dumpers_complete();\n+\n+    \/\/ flush global writer\n+    writer()->flush();\n+\n+    \/\/ At this point, all fragments of the heapdump have been written to separate files.\n+    \/\/ We need to merge them into a complete heapdump and write HPROF_HEAP_DUMP_END at that time.\n@@ -2473,2 +2530,0 @@\n-  \/\/ At this point, all fragments of the heapdump have been written to separate files.\n-  \/\/ We need to merge them into a complete heapdump and write HPROF_HEAP_DUMP_END at that time.\n@@ -2477,1 +2532,1 @@\n-void VM_HeapDumper::dump_stack_traces() {\n+void VM_HeapDumper::dump_stack_traces(AbstractDumpWriter* writer) {\n@@ -2479,4 +2534,4 @@\n-  DumperSupport::write_header(writer(), HPROF_TRACE, 3 * sizeof(u4));\n-  writer()->write_u4((u4)STACK_TRACE_ID);\n-  writer()->write_u4(0);                    \/\/ thread number\n-  writer()->write_u4(0);                    \/\/ frame count\n+  DumperSupport::write_header(writer, HPROF_TRACE, 3 * sizeof(u4));\n+  writer->write_u4((u4)STACK_TRACE_ID);\n+  writer->write_u4(0);                    \/\/ thread number\n+  writer->write_u4(0);                    \/\/ frame count\n@@ -2506,1 +2561,1 @@\n-        thread_dumper->dump_stack_traces(writer(), _klass_map);\n+        thread_dumper->dump_stack_traces(writer, _klass_map);\n@@ -2516,1 +2571,1 @@\n-      thread_dumper->dump_stack_traces(writer(), _klass_map);\n+      thread_dumper->dump_stack_traces(writer, _klass_map);\n@@ -2521,0 +2576,16 @@\n+void VM_HeapDumper::dump_vthread(oop vt, AbstractDumpWriter* segment_writer) {\n+  \/\/ unmounted vthread has no JavaThread\n+  ThreadDumper thread_dumper(ThreadDumper::ThreadType::UnmountedVirtual, nullptr, vt);\n+  thread_dumper.init_serial_nums(&_thread_serial_num, &_frame_serial_num);\n+\n+  \/\/ write HPROF_TRACE\/HPROF_FRAME records to global writer\n+  _dumper_controller->lock_global_writer();\n+  thread_dumper.dump_stack_traces(writer(), _klass_map);\n+  _dumper_controller->unlock_global_writer();\n+\n+  \/\/ write HPROF_GC_ROOT_THREAD_OBJ\/HPROF_GC_ROOT_JAVA_FRAME\/HPROF_GC_ROOT_JNI_LOCAL subrecord\n+  \/\/ to segment writer\n+  thread_dumper.dump_thread_obj(segment_writer);\n+  thread_dumper.dump_stack_refs(segment_writer);\n+}\n+\n@@ -2562,3 +2633,1 @@\n-  \/\/ For serial dump, once VM_HeapDumper completes, the whole heap dump process\n-  \/\/ is done, no further phases needed. For parallel dump, the whole heap dump\n-  \/\/ process is done in two phases\n+  \/\/ Heap dump process is done in two phases\n@@ -2571,13 +2640,14 @@\n-  if (dumper.is_parallel_dump()) {\n-    DumpMerger merger(path, &writer, dumper.dump_seq());\n-    Thread* current_thread = Thread::current();\n-    if (current_thread->is_AttachListener_thread()) {\n-      \/\/ perform heapdump file merge operation in the current thread prevents us\n-      \/\/ from occupying the VM Thread, which in turn affects the occurrence of\n-      \/\/ GC and other VM operations.\n-      merger.do_merge();\n-    } else {\n-      \/\/ otherwise, performs it by VM thread\n-      VM_HeapDumpMerge op(&merger);\n-      VMThread::execute(&op);\n-    }\n+\n+  DumpMerger merger(path, &writer, dumper.dump_seq());\n+  Thread* current_thread = Thread::current();\n+  if (current_thread->is_AttachListener_thread()) {\n+    \/\/ perform heapdump file merge operation in the current thread prevents us\n+    \/\/ from occupying the VM Thread, which in turn affects the occurrence of\n+    \/\/ GC and other VM operations.\n+    merger.do_merge();\n+  } else {\n+    \/\/ otherwise, performs it by VM thread\n+    VM_HeapDumpMerge op(&merger);\n+    VMThread::execute(&op);\n+  }\n+  if (writer.error() != nullptr) {\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":230,"deletions":160,"binary":false,"changes":390,"status":"modified"},{"patch":"@@ -69,1 +69,0 @@\n-            appOut.shouldNotContain(\"Merge heap files complete\");\n","filename":"test\/hotspot\/jtreg\/serviceability\/dcmd\/gc\/HeapDumpParallelTest.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -186,0 +186,1 @@\n+            extraVMArgs.add(\"-Xlog:heapdump\");\n@@ -255,2 +256,1 @@\n-            \/\/ Dumping of unmounted vthreads is not implemented yet\n-            \/\/test(snapshot, VThreadInHeapDumpTarg.VThreadUnmountedReferenced.class);\n+            test(snapshot, VThreadInHeapDumpTarg.VThreadUnmountedReferenced.class);\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/HeapDump\/VThreadInHeapDump.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}