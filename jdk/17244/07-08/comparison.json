{"files":[{"patch":"@@ -196,1 +196,1 @@\n-static void set_size_of_unset_code_heap(CodeHeapInfo* heap, size_t available_size, size_t known_segments_size, size_t min_size) {\n+static void set_size_of_unset_code_heap(CodeHeapInfo* heap, size_t available_size, size_t used_size, size_t min_size) {\n@@ -198,1 +198,1 @@\n-  heap->size = (available_size > known_segments_size + min_size) ? (available_size - known_segments_size) : min_size;\n+  heap->size = (available_size > used_size + min_size) ? (available_size - used_size) : min_size;\n@@ -211,1 +211,1 @@\n-  size_t cache_size           = ReservedCodeCacheSize;\n+  size_t cache_size           = align_up(ReservedCodeCacheSize, min_size);\n@@ -224,3 +224,1 @@\n-  if (!heap_available(CodeBlobType::MethodNonProfiled)) {\n-    assert(false, \"MethodNonProfiled heap is always available for segmented code heap\");\n-  }\n+  assert(heap_available(CodeBlobType::MethodNonProfiled), \"MethodNonProfiled heap is always available for segmented code heap\");\n@@ -274,1 +272,1 @@\n-  if (non_profiled.enabled) {\n+  if (non_profiled.enabled) { \/\/ non_profiled.enabled is always ON for segmented code heap, leave it checked for clarity\n@@ -307,4 +305,0 @@\n-  \/\/ last adjustment: leftovers from page alignment go to non_nmethod segment\n-  non_nmethod.size += non_profiled.size & alignment_mask(min_size);\n-  non_nmethod.size += profiled.size & alignment_mask(min_size);\n-\n@@ -313,2 +307,3 @@\n-  non_nmethod.size = align_up(non_nmethod.size, min_size);\n-  non_profiled.size = align_down(non_profiled.size, min_size);\n+  non_profiled.size += non_nmethod.size & alignment_mask(min_size);\n+  non_profiled.size += profiled.size & alignment_mask(min_size);\n+  non_nmethod.size = align_down(non_nmethod.size, min_size);\n@@ -316,0 +311,1 @@\n+  non_profiled.size = align_down(non_profiled.size, min_size);\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":9,"deletions":13,"binary":false,"changes":22,"status":"modified"}]}