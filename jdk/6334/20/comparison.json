{"files":[{"patch":"@@ -138,0 +138,8 @@\n+#### Branch Protection\n+\n+In order to use Branch Protection features in the VM, `--enable-branch-protection`\n+must be used. This option requires C++ compiler support (GCC 9.1.0+ or Clang\n+10+). The resulting build can be run on both machines with and without support\n+for branch protection in hardware. Branch Protection is only supported for\n+Linux targets.\n+\n","filename":"doc\/building.md","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -808,0 +808,2 @@\n+  FLAGS_SETUP_BRANCH_PROTECTION\n+\n@@ -813,1 +815,1 @@\n-      $REPRODUCIBLE_CFLAGS\"\n+      $REPRODUCIBLE_CFLAGS $BRANCH_PROTECTION_CFLAGS\"\n@@ -818,1 +820,1 @@\n-      $FILE_MACRO_CFLAGS $REPRODUCIBLE_CFLAGS\"\n+      $FILE_MACRO_CFLAGS $REPRODUCIBLE_CFLAGS $BRANCH_PROTECTION_CFLAGS\"\n@@ -884,0 +886,21 @@\n+\n+AC_DEFUN_ONCE([FLAGS_SETUP_BRANCH_PROTECTION],\n+[\n+  # Is branch protection available?\n+  BRANCH_PROTECTION_AVAILABLE=false\n+  BRANCH_PROTECTION_FLAG=\"-mbranch-protection=standard\"\n+\n+  if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+    if test \"x$TOOLCHAIN_TYPE\" = xgcc || test \"x$TOOLCHAIN_TYPE\" = xclang; then\n+      FLAGS_COMPILER_CHECK_ARGUMENTS(ARGUMENT: [${BRANCH_PROTECTION_FLAG}],\n+          IF_TRUE: [BRANCH_PROTECTION_AVAILABLE=true])\n+    fi\n+  fi\n+\n+  BRANCH_PROTECTION_CFLAGS=\"\"\n+  UTIL_ARG_ENABLE(NAME: branch-protection, DEFAULT: false,\n+      RESULT: USE_BRANCH_PROTECTION, AVAILABLE: $BRANCH_PROTECTION_AVAILABLE,\n+      DESC: [enable branch protection when compiling C\/C++],\n+      IF_ENABLED: [ BRANCH_PROTECTION_CFLAGS=${BRANCH_PROTECTION_FLAG}])\n+  AC_SUBST(BRANCH_PROTECTION_CFLAGS)\n+])\n","filename":"make\/autoconf\/flags-cflags.m4","additions":26,"deletions":3,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-# Copyright (c) 2011, 2021, Oracle and\/or its affiliates. All rights reserved.\n+# Copyright (c) 2011, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -409,0 +409,1 @@\n+BRANCH_PROTECTION_CFLAGS := @BRANCH_PROTECTION_CFLAGS@\n","filename":"make\/autoconf\/spec.gmk.in","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1859,0 +1859,4 @@\n+  if (VM_Version::use_rop_protection()) {\n+    st->print(\"ldr zr, [lr]\\n\\t\");\n+    st->print(\"pacia  lr, rfp\\n\\t\");\n+  }\n@@ -1967,0 +1971,4 @@\n+  if (VM_Version::use_rop_protection()) {\n+    st->print(\"autia lr, rfp\\n\\t\");\n+    st->print(\"ldr zr, [lr]\\n\\t\");\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -990,19 +990,27 @@\n-  void hint(int imm) {\n-    system(0b00, 0b011, 0b0010, 0b0000, imm);\n-  }\n-\n-  void nop() {\n-    hint(0);\n-  }\n-\n-  void yield() {\n-    hint(1);\n-  }\n-\n-  void wfe() {\n-    hint(2);\n-  }\n-\n-  void wfi() {\n-    hint(3);\n-  }\n+  \/\/ Hint instructions\n+\n+#define INSN(NAME, crm, op2)               \\\n+  void NAME() {                            \\\n+    system(0b00, 0b011, 0b0010, crm, op2); \\\n+  }\n+\n+  INSN(nop,   0b000, 0b0000);\n+  INSN(yield, 0b000, 0b0001);\n+  INSN(wfe,   0b000, 0b0010);\n+  INSN(wfi,   0b000, 0b0011);\n+  INSN(sev,   0b000, 0b0100);\n+  INSN(sevl,  0b000, 0b0101);\n+\n+  INSN(autia1716, 0b0001, 0b100);\n+  INSN(autiasp,   0b0011, 0b101);\n+  INSN(autiaz,    0b0011, 0b100);\n+  INSN(autib1716, 0b0001, 0b110);\n+  INSN(autibsp,   0b0011, 0b111);\n+  INSN(autibz,    0b0011, 0b110);\n+  INSN(pacia1716, 0b0001, 0b000);\n+  INSN(paciasp,   0b0011, 0b001);\n+  INSN(paciaz,    0b0011, 0b000);\n+  INSN(pacib1716, 0b0001, 0b010);\n+  INSN(pacibsp,   0b0011, 0b011);\n+  INSN(pacibz,    0b0011, 0b010);\n+  INSN(xpaclri,   0b0000, 0b111);\n@@ -1010,7 +1018,1 @@\n-  void sev() {\n-    hint(4);\n-  }\n-\n-  void sevl() {\n-    hint(5);\n-  }\n+#undef INSN\n@@ -1102,1 +1104,2 @@\n-  void branch_reg(Register R, int opc) {\n+\n+  void branch_reg(int OP, int A, int M, Register RN, Register RM) {\n@@ -1105,4 +1108,6 @@\n-    f(opc, 24, 21);\n-    f(0b11111000000, 20, 10);\n-    rf(R, 5);\n-    f(0b00000, 4, 0);\n+    f(OP, 24, 21);\n+    f(0b111110000, 20, 12);\n+    f(A, 11, 11);\n+    f(M, 10, 10);\n+    rf(RN, 5);\n+    rf(RM, 0);\n@@ -1111,3 +1116,3 @@\n-#define INSN(NAME, opc)                         \\\n-  void NAME(Register R) {                       \\\n-    branch_reg(R, opc);                         \\\n+#define INSN(NAME, opc)              \\\n+  void NAME(Register RN) {           \\\n+    branch_reg(opc, 0, 0, RN, r0);    \\\n@@ -1124,3 +1129,3 @@\n-#define INSN(NAME, opc)                         \\\n-  void NAME() {                 \\\n-    branch_reg(dummy_reg, opc);         \\\n+#define INSN(NAME, opc)                     \\\n+  void NAME() {                             \\\n+    branch_reg(opc, 0, 0, dummy_reg, r0);    \\\n@@ -1132,0 +1137,34 @@\n+#undef INSN\n+\n+#define INSN(NAME, M)                                  \\\n+  void NAME() {                                        \\\n+    branch_reg(0b0010, 1, M, dummy_reg, dummy_reg);    \\\n+  }\n+\n+  INSN(retaa, 0);\n+  INSN(retab, 1);\n+\n+#undef INSN\n+\n+#define INSN(NAME, OP, M)                   \\\n+  void NAME(Register rn) {                  \\\n+    branch_reg(OP, 1, M, rn, dummy_reg);    \\\n+  }\n+\n+  INSN(braaz,  0b0000, 0);\n+  INSN(brabz,  0b0000, 1);\n+  INSN(blraaz, 0b0001, 0);\n+  INSN(blrabz, 0b0001, 1);\n+\n+#undef INSN\n+\n+#define INSN(NAME, OP, M)                  \\\n+  void NAME(Register rn, Register rm) {    \\\n+    branch_reg(OP, 1, M, rn, rm);          \\\n+  }\n+\n+  INSN(braa,  0b1000, 0);\n+  INSN(brab,  0b1000, 1);\n+  INSN(blraa, 0b1001, 0);\n+  INSN(blrab, 0b1001, 1);\n+\n@@ -1795,0 +1834,31 @@\n+  \/\/ PAC instructions\n+  INSN(pacia,  0b110, 0b00001, 0b00000);\n+  INSN(pacib,  0b110, 0b00001, 0b00001);\n+  INSN(pacda,  0b110, 0b00001, 0b00010);\n+  INSN(pacdb,  0b110, 0b00001, 0b00011);\n+  INSN(autia,  0b110, 0b00001, 0b00100);\n+  INSN(autib,  0b110, 0b00001, 0b00101);\n+  INSN(autda,  0b110, 0b00001, 0b00110);\n+  INSN(autdb,  0b110, 0b00001, 0b00111);\n+\n+#undef INSN\n+\n+#define INSN(NAME, op29, opcode2, opcode)                       \\\n+  void NAME(Register Rd) {                                      \\\n+    starti;                                                     \\\n+    f(opcode2, 20, 16);                                         \\\n+    data_processing(current_insn, op29, opcode, Rd, dummy_reg); \\\n+  }\n+\n+  \/\/ PAC instructions (with zero modifier)\n+  INSN(paciza,  0b110, 0b00001, 0b01000);\n+  INSN(pacizb,  0b110, 0b00001, 0b01001);\n+  INSN(pacdza,  0b110, 0b00001, 0b01010);\n+  INSN(pacdzb,  0b110, 0b00001, 0b01011);\n+  INSN(autiza,  0b110, 0b00001, 0b01100);\n+  INSN(autizb,  0b110, 0b00001, 0b01101);\n+  INSN(autdza,  0b110, 0b00001, 0b01110);\n+  INSN(autdzb,  0b110, 0b00001, 0b01111);\n+  INSN(xpaci,   0b110, 0b00001, 0b10000);\n+  INSN(xpacd,   0b110, 0b00001, 0b10001);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":107,"deletions":37,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -388,0 +388,1 @@\n+    __ authenticate_return_address(exception_pc, rscratch1);\n@@ -436,0 +437,1 @@\n+  __ protect_return_address(exception_pc, rscratch1);\n@@ -451,0 +453,1 @@\n+  __ protect_return_address(r0, rscratch1);\n@@ -499,0 +502,2 @@\n+  __ mov(r3, lr);\n+  __ protect_return_address();\n@@ -502,1 +507,1 @@\n-  __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), rthread, lr);\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::exception_handler_for_return_address), rthread, r3);\n@@ -515,0 +520,1 @@\n+  __ authenticate_return_address();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -131,1 +131,0 @@\n-      sender_pc = (address) this->fp()[return_addr_offset];\n@@ -138,0 +137,1 @@\n+      sender_pc = pauth_strip_verifiable((address) this->fp()[return_addr_offset], (address)saved_fp);\n@@ -154,1 +154,0 @@\n-      sender_pc = (address) *(sender_sp-1);\n@@ -157,0 +156,1 @@\n+      sender_pc = pauth_strip_verifiable((address) *(sender_sp-1), (address)saved_fp);\n@@ -271,0 +271,3 @@\n+  address signing_sp = (((address*) sp())[-2]);\n+  address signed_pc = pauth_sign_return_address(pc, (address)signing_sp);\n+  address pc_old = pauth_strip_verifiable(*pc_addr, (address)signing_sp);\n@@ -272,2 +275,6 @@\n-    tty->print_cr(\"patch_pc at address \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \" -> \" INTPTR_FORMAT \"]\",\n-                  p2i(pc_addr), p2i(*pc_addr), p2i(pc));\n+    tty->print(\"patch_pc at address \" INTPTR_FORMAT \" [\" INTPTR_FORMAT \" -> \" INTPTR_FORMAT \"]\",\n+                  p2i(pc_addr), p2i(pc_old), p2i(pc));\n+    if (VM_Version::use_rop_protection()) {\n+      tty->print(\" [signed \" INTPTR_FORMAT \" -> \" INTPTR_FORMAT \"]\", p2i(*pc_addr), p2i(signed_pc));\n+    }\n+    tty->print_cr(\"\");\n@@ -276,2 +283,0 @@\n-  \/\/ Only generated code frames should be patched, therefore the return address will not be signed.\n-  assert(pauth_ptr_is_raw(*pc_addr), \"cannot be signed\");\n@@ -280,2 +285,2 @@\n-  assert(_pc == *pc_addr || pc == *pc_addr, \"must be\");\n-  *pc_addr = pc;\n+  assert(_pc == pc_old || pc == pc_old, \"must be\");\n+  *pc_addr = signed_pc;\n@@ -457,1 +462,2 @@\n-  \/\/ Use the raw version of pc - the interpreter should not have signed it.\n+  \/\/ For ROP protection, Interpreter will have signed the sender_pc, but there is no requirement to authenticate it here.\n+  address sender_pc = pauth_strip_verifiable(sender_pc_maybe_signed(), (address)link());\n@@ -459,1 +465,1 @@\n-  return frame(sender_sp, unextended_sp, link(), sender_pc_maybe_signed());\n+  return frame(sender_sp, unextended_sp, link(), sender_pc);\n@@ -462,1 +468,0 @@\n-\n@@ -475,1 +480,3 @@\n-  address sender_pc = (address) *(l_sender_sp-1);\n+\n+  \/\/ For ROP protection, C1\/C2 will have signed the sender_pc, but there is no requirement to authenticate it here.\n+  address sender_pc = pauth_strip_verifiable((address) *(l_sender_sp-1), (address) *(l_sender_sp-2));\n@@ -523,0 +530,3 @@\n+  \/\/ Native code may or may not have signed the return address, we have no way to be sure or what\n+  \/\/ signing methods they used. Instead, just ensure the stripped value is used.\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":23,"deletions":13,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -274,1 +274,1 @@\n-    __ enter(); \/\/ barrier may call runtime\n+    __ enter(\/*strip_ret_addr*\/true); \/\/ barrier may call runtime\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2018, 2022, Red Hat, Inc. All rights reserved.\n@@ -240,1 +240,1 @@\n-  __ enter();\n+  __ enter(\/*strip_ret_addr*\/true);\n@@ -362,1 +362,1 @@\n-    __ enter();\n+    __ enter(\/*strip_ret_addr*\/true);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shenandoah\/shenandoahBarrierSetAssembler_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -81,1 +81,1 @@\n-  __ enter();\n+  __ enter(\/*strip_ret_addr*\/true);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -121,1 +121,3 @@\n-          range(1, 99)\n+          range(1, 99)                                                  \\\n+  product(ccstr, UseBranchProtection, \"none\",                           \\\n+          \"Branch Protection to use: none, standard, pac-ret\")          \\\n","filename":"src\/hotspot\/cpu\/aarch64\/globals_aarch64.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1140,0 +1140,2 @@\n+  strip_return_address(); \/\/ This might happen within a stack frame.\n+  protect_return_address();\n@@ -1153,0 +1155,1 @@\n+  authenticate_return_address();\n@@ -1169,0 +1172,2 @@\n+  strip_return_address(); \/\/ This might happen within a stack frame.\n+  protect_return_address();\n@@ -1189,0 +1194,1 @@\n+  authenticate_return_address();\n@@ -4299,0 +4305,1 @@\n+  protect_return_address();\n@@ -4331,0 +4338,1 @@\n+  authenticate_return_address();\n@@ -5172,0 +5180,1 @@\n+  protect_return_address();\n@@ -5181,0 +5190,1 @@\n+  authenticate_return_address();\n@@ -5272,0 +5282,99 @@\n+\n+\/\/ Stack frame creation\/removal\n+\n+void MacroAssembler::enter(bool strip_ret_addr) {\n+  if (strip_ret_addr) {\n+    \/\/ Addresses can only be signed once. If there are multiple nested frames being created\n+    \/\/ in the same function, then the return address needs stripping first.\n+    strip_return_address();\n+  }\n+  protect_return_address();\n+  stp(rfp, lr, Address(pre(sp, -2 * wordSize)));\n+  mov(rfp, sp);\n+}\n+\n+void MacroAssembler::leave() {\n+  mov(sp, rfp);\n+  ldp(rfp, lr, Address(post(sp, 2 * wordSize)));\n+  authenticate_return_address();\n+}\n+\n+\/\/ ROP Protection\n+\/\/ Use the AArch64 PAC feature to add ROP protection for generated code. Use whenever creating\/\n+\/\/ destroying stack frames or whenever directly loading\/storing the LR to memory.\n+\/\/ If ROP protection is not set then these functions are no-ops.\n+\/\/ For more details on PAC see pauth_aarch64.hpp.\n+\n+\/\/ Sign the LR. Use during construction of a stack frame, before storing the LR to memory.\n+\/\/ Uses the FP as the modifier.\n+\/\/\n+void MacroAssembler::protect_return_address() {\n+  if (VM_Version::use_rop_protection()) {\n+    check_return_address();\n+    \/\/ The standard convention for C code is to use paciasp, which uses SP as the modifier. This\n+    \/\/ works because in C code, FP and SP match on function entry. In the JDK, SP and FP may not\n+    \/\/ match, so instead explicitly use the FP.\n+    pacia(lr, rfp);\n+  }\n+}\n+\n+\/\/ Sign the return value in the given register. Use before updating the LR in the exisiting stack\n+\/\/ frame for the current function.\n+\/\/ Uses the FP from the start of the function as the modifier - which is stored at the address of\n+\/\/ the current FP.\n+\/\/\n+void MacroAssembler::protect_return_address(Register return_reg, Register temp_reg) {\n+  if (VM_Version::use_rop_protection()) {\n+    assert(PreserveFramePointer, \"PreserveFramePointer must be set for ROP protection\");\n+    check_return_address(return_reg);\n+    ldr(temp_reg, Address(rfp));\n+    pacia(return_reg, temp_reg);\n+  }\n+}\n+\n+\/\/ Authenticate the LR. Use before function return, after restoring FP and loading LR from memory.\n+\/\/\n+void MacroAssembler::authenticate_return_address(Register return_reg) {\n+  if (VM_Version::use_rop_protection()) {\n+    autia(return_reg, rfp);\n+    check_return_address(return_reg);\n+  }\n+}\n+\n+\/\/ Authenticate the return value in the given register. Use before updating the LR in the exisiting\n+\/\/ stack frame for the current function.\n+\/\/ Uses the FP from the start of the function as the modifier - which is stored at the address of\n+\/\/ the current FP.\n+\/\/\n+void MacroAssembler::authenticate_return_address(Register return_reg, Register temp_reg) {\n+  if (VM_Version::use_rop_protection()) {\n+    assert(PreserveFramePointer, \"PreserveFramePointer must be set for ROP protection\");\n+    ldr(temp_reg, Address(rfp));\n+    autia(return_reg, temp_reg);\n+    check_return_address(return_reg);\n+  }\n+}\n+\n+\/\/ Strip any PAC data from LR without performing any authentication. Use with caution - only if\n+\/\/ there is no guaranteed way of authenticating the LR.\n+\/\/\n+void MacroAssembler::strip_return_address() {\n+  if (VM_Version::use_rop_protection()) {\n+    xpaclri();\n+  }\n+}\n+\n+#ifndef PRODUCT\n+\/\/ PAC failures can be difficult to debug. After an authentication failure, a segfault will only\n+\/\/ occur when the pointer is used - ie when the program returns to the invalid LR. At this point\n+\/\/ it is difficult to debug back to the callee function.\n+\/\/ This function simply loads from the address in the given register.\n+\/\/ Use directly after authentication to catch authentication failures.\n+\/\/ Also use before signing to check that the pointer is valid and hasn't already been signed.\n+\/\/\n+void MacroAssembler::check_return_address(Register return_reg) {\n+  if (VM_Version::use_rop_protection()) {\n+    ldr(zr, Address(return_reg));\n+  }\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":109,"deletions":0,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -691,10 +691,10 @@\n-  void enter()\n-  {\n-    stp(rfp, lr, Address(pre(sp, -2 * wordSize)));\n-    mov(rfp, sp);\n-  }\n-  void leave()\n-  {\n-    mov(sp, rfp);\n-    ldp(rfp, lr, Address(post(sp, 2 * wordSize)));\n-  }\n+  void enter(bool strip_ret_addr = false);\n+  void leave();\n+\n+  \/\/ ROP Protection\n+  void protect_return_address();\n+  void protect_return_address(Register return_reg, Register temp_reg);\n+  void authenticate_return_address(Register return_reg = lr);\n+  void authenticate_return_address(Register return_reg, Register temp_reg);\n+  void strip_return_address();\n+  void check_return_address(Register return_reg=lr) PRODUCT_RETURN;\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Arm Limited. All rights reserved.\n+ * Copyright (c) 2021, 2022, Arm Limited. All rights reserved.\n@@ -30,0 +30,39 @@\n+\/\/ Support for ROP Protection in VM code.\n+\/\/ This is provided via the AArch64 PAC feature.\n+\/\/ For more details on PAC see The Arm ARM, section \"Pointer authentication in AArch64 state\".\n+\/\/\n+\/\/ PAC provides a method to sign and authenticate pointer values. Signing combines the register\n+\/\/ being signed, an additional modifier and a per-process secret key, writing the result to unused\n+\/\/ high bits of the signed register. Once signed a register must be authenticated or stripped\n+\/\/ before it can be used.\n+\/\/ Authentication reverses the signing operation, clearing the high bits. If the signed register\n+\/\/ or modifier has changed then authentication will fail and invalid data will be written to the\n+\/\/ high bits and the next time the pointer is used a segfault will be raised.\n+\/\/\n+\/\/ Assume a malicious attacker is able to edit the stack via an exploit. Control flow can be\n+\/\/ changed by re-writing the return values stored on the stack. ROP protection prevents this by\n+\/\/ signing return addresses before saving them on the stack, then authenticating when they are\n+\/\/ loaded back. The scope of this protection is per function (a value is signed and authenticated\n+\/\/ by the same function), therefore it is possible for different functions within the same\n+\/\/ program to use different signing methods.\n+\/\/\n+\/\/ The VM and native code is protected by compiling with the GCC AArch64 branch protection flag.\n+\/\/\n+\/\/ All generated code is protected via the ROP functions provided in macroAssembler.\n+\/\/\n+\/\/ In addition, the VM needs to be aware of PAC whenever viewing or editing the stack. Functions\n+\/\/ are provided here and in the OS specific files. We should assume all stack frames for generated\n+\/\/ code have signed return values. Rewriting the stack should ensure new values are correctly\n+\/\/ signed. However, we cannot make any assumptions about how (or if) native code uses PAC - here\n+\/\/ we should limit access to viewing via stripping.\n+\/\/\n+\n+\n+\/\/ Confirm the given pointer has not been signed - ie none of the high bits are set.\n+\/\/\n+\/\/ Note this can give false positives. The PAC signing can generate a signature with all signing\n+\/\/ bits as zeros, causing this function to return true. Therefore this should only be used for\n+\/\/ assert style checking. In addition, this function should never be used with a \"not\" to confirm\n+\/\/ a pointer is signed, as it will fail the above case. The only safe way to do this is to instead\n+\/\/ authenticate the pointer.\n+\/\/\n@@ -31,1 +70,0 @@\n-  \/\/ Confirm none of the high bits are set in the pointer.\n@@ -35,0 +73,11 @@\n+\/\/ Strip a return value (same as pauth_strip_pointer). When debug is enabled then authenticate\n+\/\/ instead.\n+\/\/\n+inline address pauth_strip_verifiable(address ret_addr, address modifier) {\n+  if (VM_Version::use_rop_protection()) {\n+    DEBUG_ONLY(ret_addr = pauth_authenticate_return_address(ret_addr, modifier);)\n+    NOT_DEBUG(ret_addr = pauth_strip_pointer(ret_addr));\n+  }\n+  return ret_addr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/pauth_aarch64.hpp","additions":51,"deletions":2,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -413,0 +413,1 @@\n+  __ authenticate_return_address(c_rarg1, rscratch1);\n@@ -2181,1 +2182,0 @@\n-\n@@ -2183,0 +2183,1 @@\n+  __ protect_return_address(r3, rscratch1);\n@@ -2290,0 +2291,1 @@\n+  __ authenticate_return_address();\n@@ -2431,0 +2433,1 @@\n+  __ protect_return_address();\n@@ -2505,0 +2508,1 @@\n+  __ authenticate_return_address();\n@@ -2627,0 +2631,5 @@\n+  \/\/ When the signal occured, the LR was either signed and stored on the stack (in which\n+  \/\/ case it will be restored from the stack before being used) or unsigned and not stored\n+  \/\/ on the stack. Stipping ensures we get the right value.\n+  __ strip_return_address();\n+\n@@ -2646,0 +2655,1 @@\n+    __ protect_return_address(r20, rscratch1);\n@@ -2686,0 +2696,1 @@\n+    __ authenticate_return_address(r20, rscratch1);\n@@ -2700,0 +2711,1 @@\n+    __ protect_return_address(r20, rscratch1);\n@@ -2860,0 +2872,1 @@\n+  __ protect_return_address();\n@@ -2913,0 +2926,1 @@\n+  __ authenticate_return_address(r3);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -835,0 +835,1 @@\n+  __ protect_return_address();\n@@ -1751,0 +1752,2 @@\n+    \/\/ This is a return address, so requires authenticating for PAC.\n+    __ authenticate_return_address(c_rarg1, rscratch1);\n@@ -1940,0 +1943,1 @@\n+  __ protect_return_address();\n@@ -1950,0 +1954,1 @@\n+  __ authenticate_return_address();\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -48,0 +48,1 @@\n+bool VM_Version::_rop_protection;\n@@ -410,0 +411,30 @@\n+  if (UseBranchProtection == nullptr || strcmp(UseBranchProtection, \"none\") == 0) {\n+    _rop_protection = false;\n+  } else if (strcmp(UseBranchProtection, \"standard\") == 0) {\n+    _rop_protection = false;\n+    \/\/ Enable PAC if this code has been built with branch-protection and the CPU\/OS supports it.\n+#ifdef __ARM_FEATURE_PAC_DEFAULT\n+    if ((_features & CPU_PACA) != 0) {\n+      _rop_protection = true;\n+    }\n+#endif\n+  } else if (strcmp(UseBranchProtection, \"pac-ret\") == 0) {\n+    _rop_protection = true;\n+#ifdef __ARM_FEATURE_PAC_DEFAULT\n+    if ((_features & CPU_PACA) == 0) {\n+      warning(\"ROP-protection specified, but not supported on this CPU.\");\n+      \/\/ Disable PAC to prevent illegal instruction crashes.\n+      _rop_protection = false;\n+    }\n+#else\n+    warning(\"ROP-protection specified, but this VM was built without ROP-protection support.\");\n+#endif\n+  } else {\n+    vm_exit_during_initialization(err_msg(\"Unsupported UseBranchProtection: %s\", UseBranchProtection));\n+  }\n+\n+  \/\/ The frame pointer must be preserved for ROP protection.\n+  if (_rop_protection == true) {\n+    PreserveFramePointer = true;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -48,0 +48,1 @@\n+  static bool _rop_protection;\n@@ -117,0 +118,1 @@\n+    decl(PACA,          \"paca\",          30)  \\\n@@ -120,1 +122,1 @@\n-    decl(A53MAC,        \"a53mac\",        30)\n+    decl(A53MAC,        \"a53mac\",        31)\n@@ -159,0 +161,1 @@\n+  static bool use_rop_protection() { return _rop_protection; }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Arm Limited. All rights reserved.\n+ * Copyright (c) 2021, 2022, Arm Limited. All rights reserved.\n@@ -28,11 +28,2 @@\n-#ifdef __APPLE__\n-#include <ptrauth.h>\n-#endif\n-\n-\/\/ Only the PAC instructions in the NOP space can be used. This ensures the\n-\/\/ binaries work on systems without PAC. Write these instructions using their\n-\/\/ alternate \"hint\" instructions to ensure older compilers can still be used.\n-\/\/ For Apple, use the provided interface as this may provide additional\n-\/\/ optimization.\n-\n-#define XPACLRI \"hint #0x7;\"\n+\/\/ OS specific Support for ROP Protection in VM code.\n+\/\/ For more details on PAC see pauth_aarch64.hpp.\n@@ -41,7 +32,2 @@\n-#ifdef __APPLE__\n-  return ptrauth_strip(ptr, ptrauth_key_asib);\n-#else\n-  register address result __asm__(\"x30\") = ptr;\n-  asm (XPACLRI : \"+r\"(result));\n-  return result;\n-#endif\n+  \/\/ No PAC support in BSD as of yet.\n+  return ptr;\n@@ -50,1 +36,9 @@\n-#undef XPACLRI\n+inline address pauth_sign_return_address(address ret_addr, address sp) {\n+  \/\/ No PAC support in BSD as of yet.\n+  return ret_addr;\n+}\n+\n+inline address pauth_authenticate_return_address(address ret_addr, address sp) {\n+  \/\/ No PAC support in BSD as of yet.\n+  return ret_addr;\n+}\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/pauth_bsd_aarch64.inline.hpp","additions":14,"deletions":20,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Arm Limited. All rights reserved.\n+ * Copyright (c) 2021, 2022, Arm Limited. All rights reserved.\n@@ -28,3 +28,2 @@\n-\/\/ Only the PAC instructions in the NOP space can be used. This ensures the\n-\/\/ binaries work on systems without PAC. Write these instructions using their\n-\/\/ alternate \"hint\" instructions to ensure older compilers can still be used.\n+\/\/ OS specific Support for ROP Protection in VM code.\n+\/\/ For more details on PAC see pauth_aarch64.hpp.\n@@ -32,1 +31,1 @@\n-#define XPACLRI \"hint #0x7;\"\n+inline bool pauth_ptr_is_raw(address ptr);\n@@ -34,0 +33,10 @@\n+\/\/ Use only the PAC instructions in the NOP space. This ensures the binaries work on systems\n+\/\/ without PAC. Write these instructions using their alternate \"hint\" instructions to ensure older\n+\/\/ compilers can still be used.\n+#define XPACLRI   \"hint #0x7;\"\n+#define PACIA1716 \"hint #0x8;\"\n+#define AUTIA1716 \"hint #0xc;\"\n+\n+\/\/ Strip an address. Use with caution - only if there is no guaranteed way of authenticating the\n+\/\/ value.\n+\/\/\n@@ -40,0 +49,28 @@\n+\/\/ Sign a return value, using the given modifier.\n+\/\/\n+inline address pauth_sign_return_address(address ret_addr, address sp) {\n+  if (VM_Version::use_rop_protection()) {\n+    \/\/ A pointer cannot be double signed.\n+    guarantee(pauth_ptr_is_raw(ret_addr), \"Return address is already signed\");\n+    register address r17 __asm(\"r17\") = ret_addr;\n+    register address r16 __asm(\"r16\") = sp;\n+    asm (PACIA1716 : \"+r\"(r17) : \"r\"(r16));\n+    ret_addr = r17;\n+  }\n+  return ret_addr;\n+}\n+\n+\/\/ Authenticate a return value, using the given modifier.\n+\/\/\n+inline address pauth_authenticate_return_address(address ret_addr, address sp) {\n+  if (VM_Version::use_rop_protection()) {\n+    register address r17 __asm(\"r17\") = ret_addr;\n+    register address r16 __asm(\"r16\") = sp;\n+    asm (AUTIA1716 : \"+r\"(r17) : \"r\"(r16));\n+    ret_addr = r17;\n+    \/\/ Ensure that the pointer authenticated.\n+    guarantee(pauth_ptr_is_raw(ret_addr), \"Return address did not authenticate\");\n+  }\n+  return ret_addr;\n+}\n+\n@@ -41,0 +78,2 @@\n+#undef PACIA1716\n+#undef AUTIA1716\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/pauth_linux_aarch64.inline.hpp","additions":44,"deletions":5,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -1,1 +1,1 @@\n-\/\/ Copyright (c) 2015, Red Hat Inc. All rights reserved.\n+\/\/ Copyright (c) 2015, 2022, Red Hat Inc. All rights reserved.\n@@ -32,0 +32,1 @@\n+\thint #0x19      \/\/ paciasp\n@@ -42,0 +43,1 @@\n+\thint #0x1d      \/\/ autiasp\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/threadLS_linux_aarch64.S","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -75,0 +75,4 @@\n+#ifndef HWCAP_PACA\n+#define HWCAP_PACA (1 << 30)\n+#endif\n+\n@@ -114,0 +118,1 @@\n+  static_assert(CPU_PACA    == HWCAP_PACA,    \"Flag CPU_PACA must follow Linux HWCAP\");\n@@ -127,1 +132,2 @@\n-      HWCAP_SVE);\n+      HWCAP_SVE     |\n+      HWCAP_PACA);\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/vm_version_linux_aarch64.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Arm Limited. All rights reserved.\n+ * Copyright (c) 2021, 2022, Arm Limited. All rights reserved.\n@@ -28,0 +28,3 @@\n+\/\/ OS specific Support for ROP Protection in VM code.\n+\/\/ For more details on PAC see pauth_aarch64.hpp.\n+\n@@ -33,1 +36,4 @@\n-#endif \/\/ OS_CPU_WINDOWS_AARCH64_PAUTH_WINDOWS_AARCH64_INLINE_HPP\n+inline address pauth_sign_return_address(address ret_addr, address sp) {\n+  \/\/ No PAC support in windows as of yet.\n+  return ret_addr;\n+}\n@@ -35,0 +41,6 @@\n+inline address pauth_authenticate_return_address(address ret_addr, address sp) {\n+  \/\/ No PAC support in windows as of yet.\n+  return ret_addr;\n+}\n+\n+#endif \/\/ OS_CPU_WINDOWS_AARCH64_PAUTH_WINDOWS_AARCH64_INLINE_HPP\n","filename":"src\/hotspot\/os_cpu\/windows_aarch64\/pauth_windows_aarch64.inline.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"runtime\/frame.inline.hpp\"\n@@ -57,0 +58,1 @@\n+  AARCH64_ONLY(return_address = pauth_strip_pointer(return_address));\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -741,0 +741,1 @@\n+  static_field(VM_Version, _rop_protection, bool)                       \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1468,0 +1468,6 @@\n+  \/\/ ret_pc will have been loaded from the stack, so for AArch64 will be signed.\n+  \/\/ This needs authenticating, but to do that here requires the fp of the previous frame.\n+  \/\/ A better way of doing it would be authenticate in the caller by adding a\n+  \/\/ AuthPAuthNode and using it in GraphKit::gen_stub. For now, just strip it.\n+  AARCH64_ONLY(ret_pc = pauth_strip_pointer(ret_pc));\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1113,0 +1113,5 @@\n+#ifdef AARCH64\n+  if (!pauth_ptr_is_raw(x)) {\n+    return false;\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1950,0 +1950,2 @@\n+  AARCH64_ONLY(assert(pauth_ptr_is_raw(caller_pc), \"should be raw\"));\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1,1 +1,1 @@\n-.\\\" Copyright (c) 1994, 2021, Oracle and\/or its affiliates. All rights reserved.\n+.\\\" Copyright (c) 1994, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -1973,0 +1973,26 @@\n+.TP\n+.B \\f[CB]\\-XX:UseBranchProtection=\\f[R]\\f[I]mode\\f[R]\n+Specifies the branch protection mode. All options other than none require\n+the VM to have been built with branch protection enabled. In addition, for\n+full protection, any native libraries provided by applications should be\n+compiled with the same level of protection. (AArch64 Linux only).\n+.RS\n+.PP\n+Possible \\f[I]mode\\f[R] arguments for this option include the\n+following:\n+.RS\n+.TP\n+.B \\f[CB]none\\f[R]\n+Do not use branch protection. This is the default value.\n+.RS\n+.RE\n+.TP\n+.B \\f[CB]standard\\f[R]\n+Enables all branch protection modes available on the current platform.\n+.RS\n+.RE\n+.TP\n+.B \\f[CB]pac-ret\\f[R]\n+Enables protection against ROP based attacks. (AArch64 8.3+ only)\n+.RS\n+.RE\n","filename":"src\/java.base\/share\/man\/java.1","additions":27,"deletions":1,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -180,0 +180,1 @@\n+        PACA,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.aarch64\/src\/jdk\/vm\/ci\/aarch64\/AArch64.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -212,0 +212,1 @@\n+        self.isPostfixException = False\n@@ -214,1 +215,3 @@\n-        if (self._name.endswith(\"wi\")):\n+        if self.isPostfixException:\n+            return self._name\n+        elif (self._name.endswith(\"wi\")):\n@@ -216,0 +219,2 @@\n+        elif (self._name.endswith(\"i\") | self._name.endswith(\"w\")):\n+            return self._name[:len(self._name)-1]\n@@ -217,4 +222,1 @@\n-            if (self._name.endswith(\"i\") | self._name.endswith(\"w\")):\n-                return self._name[:len(self._name)-1]\n-            else:\n-                return self._name\n+            return self._name\n@@ -351,0 +353,6 @@\n+class PostfixExceptionOneRegOp(OneRegOp):\n+\n+    def __init__(self, op):\n+        OneRegOp.__init__(self, op)\n+        self.isPostfixException=True\n+\n@@ -600,0 +608,7 @@\n+\n+class PostfixExceptionOp(Op):\n+\n+    def __init__(self, op):\n+        Op.__init__(self, op)\n+        self.isPostfixException=True\n+\n@@ -1338,1 +1353,7 @@\n-generate (Op, [\"nop\", \"eret\", \"drps\", \"isb\"])\n+generate (Op, [\"nop\", \"yield\", \"wfe\", \"sev\", \"sevl\",\n+               \"autia1716\", \"autiasp\", \"autiaz\", \"autib1716\", \"autibsp\", \"autibz\",\n+               \"pacia1716\", \"paciasp\", \"paciaz\", \"pacib1716\", \"pacibsp\", \"pacibz\",\n+               \"eret\", \"drps\", \"isb\",])\n+\n+# Ensure the \"i\" is not stripped off the end of the instruction\n+generate (PostfixExceptionOp, [\"wfi\", \"xpaclri\"])\n@@ -1345,1 +1366,7 @@\n-generate (OneRegOp, [\"br\", \"blr\"])\n+generate (OneRegOp, [\"br\", \"blr\",\n+                     \"paciza\", \"pacizb\", \"pacdza\", \"pacdzb\",\n+                     \"autiza\", \"autizb\", \"autdza\", \"autdzb\", \"xpacd\",\n+                     \"braaz\", \"brabz\", \"blraaz\", \"blrabz\"])\n+\n+# Ensure the \"i\" is not stripped off the end of the instruction\n+generate (PostfixExceptionOneRegOp, [\"xpaci\"])\n@@ -1390,1 +1417,4 @@\n-          \"rev16\", \"rev32\", \"rev\", \"clz\", \"cls\"])\n+          \"rev16\", \"rev32\", \"rev\", \"clz\", \"cls\",\n+          \"pacia\",  \"pacib\", \"pacda\", \"pacdb\", \"autia\", \"autib\", \"autda\", \"autdb\",\n+          \"braa\", \"brab\", \"blraa\", \"blrab\"])\n+\n@@ -1841,2 +1871,2 @@\n-# compile for sve with 8.2 and sha3 because of SHA3 crypto extension.\n-subprocess.check_call([AARCH64_AS, \"-march=armv8.2-a+sha3+sve\", \"aarch64ops.s\", \"-o\", \"aarch64ops.o\"])\n+# compile for sve with 8.3 and sha3 because of SHA3 crypto extension.\n+subprocess.check_call([AARCH64_AS, \"-march=armv8.3-a+sha3+sve\", \"aarch64ops.s\", \"-o\", \"aarch64ops.o\"])\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":40,"deletions":10,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -171,0 +171,16 @@\n+    __ yield();                                        \/\/       yield\n+    __ wfe();                                          \/\/       wfe\n+    __ sev();                                          \/\/       sev\n+    __ sevl();                                         \/\/       sevl\n+    __ autia1716();                                    \/\/       autia1716\n+    __ autiasp();                                      \/\/       autiasp\n+    __ autiaz();                                       \/\/       autiaz\n+    __ autib1716();                                    \/\/       autib1716\n+    __ autibsp();                                      \/\/       autibsp\n+    __ autibz();                                       \/\/       autibz\n+    __ pacia1716();                                    \/\/       pacia1716\n+    __ paciasp();                                      \/\/       paciasp\n+    __ paciaz();                                       \/\/       paciaz\n+    __ pacib1716();                                    \/\/       pacib1716\n+    __ pacibsp();                                      \/\/       pacibsp\n+    __ pacibz();                                       \/\/       pacibz\n@@ -175,0 +191,4 @@\n+\/\/ PostfixExceptionOp\n+    __ wfi();                                          \/\/       wfi\n+    __ xpaclri();                                      \/\/       xpaclri\n+\n@@ -182,0 +202,16 @@\n+    __ paciza(r10);                                    \/\/       paciza  x10\n+    __ pacizb(r27);                                    \/\/       pacizb  x27\n+    __ pacdza(r8);                                     \/\/       pacdza  x8\n+    __ pacdzb(r0);                                     \/\/       pacdzb  x0\n+    __ autiza(r1);                                     \/\/       autiza  x1\n+    __ autizb(r21);                                    \/\/       autizb  x21\n+    __ autdza(r17);                                    \/\/       autdza  x17\n+    __ autdzb(r29);                                    \/\/       autdzb  x29\n+    __ xpacd(r29);                                     \/\/       xpacd   x29\n+    __ braaz(r28);                                     \/\/       braaz   x28\n+    __ brabz(r1);                                      \/\/       brabz   x1\n+    __ blraaz(r23);                                    \/\/       blraaz  x23\n+    __ blrabz(r21);                                    \/\/       blrabz  x21\n+\n+\/\/ PostfixExceptionOneRegOp\n+    __ xpaci(r20);                                     \/\/       xpaci   x20\n@@ -184,6 +220,6 @@\n-    __ stxr(r10, r27, r8);                             \/\/       stxr    w10, x27, [x8]\n-    __ stlxr(r0, r1, r21);                             \/\/       stlxr   w0, x1, [x21]\n-    __ ldxr(r17, r29);                                 \/\/       ldxr    x17, [x29]\n-    __ ldaxr(r29, r28);                                \/\/       ldaxr   x29, [x28]\n-    __ stlr(r1, r23);                                  \/\/       stlr    x1, [x23]\n-    __ ldar(r21, r20);                                 \/\/       ldar    x21, [x20]\n+    __ stxr(r22, r27, r19);                            \/\/       stxr    w22, x27, [x19]\n+    __ stlxr(r11, r16, r6);                            \/\/       stlxr   w11, x16, [x6]\n+    __ ldxr(r17, r0);                                  \/\/       ldxr    x17, [x0]\n+    __ ldaxr(r4, r10);                                 \/\/       ldaxr   x4, [x10]\n+    __ stlr(r24, r22);                                 \/\/       stlr    x24, [x22]\n+    __ ldar(r10, r19);                                 \/\/       ldar    x10, [x19]\n@@ -192,6 +228,6 @@\n-    __ stxrw(r22, r27, r19);                           \/\/       stxr    w22, w27, [x19]\n-    __ stlxrw(r11, r16, r6);                           \/\/       stlxr   w11, w16, [x6]\n-    __ ldxrw(r17, r0);                                 \/\/       ldxr    w17, [x0]\n-    __ ldaxrw(r4, r10);                                \/\/       ldaxr   w4, [x10]\n-    __ stlrw(r24, r22);                                \/\/       stlr    w24, [x22]\n-    __ ldarw(r10, r19);                                \/\/       ldar    w10, [x19]\n+    __ stxrw(r1, r5, r30);                             \/\/       stxr    w1, w5, [x30]\n+    __ stlxrw(r8, r12, r17);                           \/\/       stlxr   w8, w12, [x17]\n+    __ ldxrw(r9, r14);                                 \/\/       ldxr    w9, [x14]\n+    __ ldaxrw(r7, r1);                                 \/\/       ldaxr   w7, [x1]\n+    __ stlrw(r5, r16);                                 \/\/       stlr    w5, [x16]\n+    __ ldarw(r2, r12);                                 \/\/       ldar    w2, [x12]\n@@ -200,6 +236,6 @@\n-    __ stxrh(r1, r5, r30);                             \/\/       stxrh   w1, w5, [x30]\n-    __ stlxrh(r8, r12, r17);                           \/\/       stlxrh  w8, w12, [x17]\n-    __ ldxrh(r9, r14);                                 \/\/       ldxrh   w9, [x14]\n-    __ ldaxrh(r7, r1);                                 \/\/       ldaxrh  w7, [x1]\n-    __ stlrh(r5, r16);                                 \/\/       stlrh   w5, [x16]\n-    __ ldarh(r2, r12);                                 \/\/       ldarh   w2, [x12]\n+    __ stxrh(r10, r12, r3);                            \/\/       stxrh   w10, w12, [x3]\n+    __ stlxrh(r28, r14, r26);                          \/\/       stlxrh  w28, w14, [x26]\n+    __ ldxrh(r30, r10);                                \/\/       ldxrh   w30, [x10]\n+    __ ldaxrh(r14, r21);                               \/\/       ldaxrh  w14, [x21]\n+    __ stlrh(r13, r9);                                 \/\/       stlrh   w13, [x9]\n+    __ ldarh(r22, r27);                                \/\/       ldarh   w22, [x27]\n@@ -208,6 +244,6 @@\n-    __ stxrb(r10, r12, r3);                            \/\/       stxrb   w10, w12, [x3]\n-    __ stlxrb(r28, r14, r26);                          \/\/       stlxrb  w28, w14, [x26]\n-    __ ldxrb(r30, r10);                                \/\/       ldxrb   w30, [x10]\n-    __ ldaxrb(r14, r21);                               \/\/       ldaxrb  w14, [x21]\n-    __ stlrb(r13, r9);                                 \/\/       stlrb   w13, [x9]\n-    __ ldarb(r22, r27);                                \/\/       ldarb   w22, [x27]\n+    __ stxrb(r28, r19, r11);                           \/\/       stxrb   w28, w19, [x11]\n+    __ stlxrb(r30, r19, r2);                           \/\/       stlxrb  w30, w19, [x2]\n+    __ ldxrb(r2, r23);                                 \/\/       ldxrb   w2, [x23]\n+    __ ldaxrb(r1, r0);                                 \/\/       ldaxrb  w1, [x0]\n+    __ stlrb(r12, r16);                                \/\/       stlrb   w12, [x16]\n+    __ ldarb(r13, r15);                                \/\/       ldarb   w13, [x15]\n@@ -216,4 +252,4 @@\n-    __ ldxp(r28, r19, r11);                            \/\/       ldxp    x28, x19, [x11]\n-    __ ldaxp(r30, r19, r2);                            \/\/       ldaxp   x30, x19, [x2]\n-    __ stxp(r2, r23, r1, r0);                          \/\/       stxp    w2, x23, x1, [x0]\n-    __ stlxp(r12, r16, r13, r15);                      \/\/       stlxp   w12, x16, x13, [x15]\n+    __ ldxp(r17, r21, r13);                            \/\/       ldxp    x17, x21, [x13]\n+    __ ldaxp(r11, r30, r8);                            \/\/       ldaxp   x11, x30, [x8]\n+    __ stxp(r24, r13, r11, r1);                        \/\/       stxp    w24, x13, x11, [x1]\n+    __ stlxp(r26, r21, r27, r13);                      \/\/       stlxp   w26, x21, x27, [x13]\n@@ -222,4 +258,4 @@\n-    __ ldxpw(r17, r21, r13);                           \/\/       ldxp    w17, w21, [x13]\n-    __ ldaxpw(r11, r30, r8);                           \/\/       ldaxp   w11, w30, [x8]\n-    __ stxpw(r24, r13, r11, r1);                       \/\/       stxp    w24, w13, w11, [x1]\n-    __ stlxpw(r26, r21, r27, r13);                     \/\/       stlxp   w26, w21, w27, [x13]\n+    __ ldxpw(r20, r3, r12);                            \/\/       ldxp    w20, w3, [x12]\n+    __ ldaxpw(r6, r1, r29);                            \/\/       ldaxp   w6, w1, [x29]\n+    __ stxpw(r6, r4, r11, r16);                        \/\/       stxp    w6, w4, w11, [x16]\n+    __ stlxpw(r4, r30, r12, r21);                      \/\/       stlxp   w4, w30, w12, [x21]\n@@ -229,16 +265,16 @@\n-    __ str(r11, Address(r20, -103));                   \/\/       str     x11, [x20, -103]\n-    __ strw(r28, Address(r16, 62));                    \/\/       str     w28, [x16, 62]\n-    __ strb(r27, Address(r9, -9));                     \/\/       strb    w27, [x9, -9]\n-    __ strh(r2, Address(r25, -50));                    \/\/       strh    w2, [x25, -50]\n-    __ ldr(r4, Address(r2, -241));                     \/\/       ldr     x4, [x2, -241]\n-    __ ldrw(r30, Address(r20, -31));                   \/\/       ldr     w30, [x20, -31]\n-    __ ldrb(r17, Address(r23, -23));                   \/\/       ldrb    w17, [x23, -23]\n-    __ ldrh(r29, Address(r26, -1));                    \/\/       ldrh    w29, [x26, -1]\n-    __ ldrsb(r1, Address(r9, 6));                      \/\/       ldrsb   x1, [x9, 6]\n-    __ ldrsh(r11, Address(r12, 19));                   \/\/       ldrsh   x11, [x12, 19]\n-    __ ldrshw(r11, Address(r1, -50));                  \/\/       ldrsh   w11, [x1, -50]\n-    __ ldrsw(r19, Address(r24, 41));                   \/\/       ldrsw   x19, [x24, 41]\n-    __ ldrd(v24, Address(r24, 95));                    \/\/       ldr     d24, [x24, 95]\n-    __ ldrs(v15, Address(r5, -43));                    \/\/       ldr     s15, [x5, -43]\n-    __ strd(v21, Address(r27, 1));                     \/\/       str     d21, [x27, 1]\n-    __ strs(v23, Address(r13, -107));                  \/\/       str     s23, [x13, -107]\n+    __ str(r6, Address(r27, 97));                      \/\/       str     x6, [x27, 97]\n+    __ strw(r17, Address(r10, 45));                    \/\/       str     w17, [x10, 45]\n+    __ strb(r26, Address(r22, -29));                   \/\/       strb    w26, [x22, -29]\n+    __ strh(r21, Address(r10, -50));                   \/\/       strh    w21, [x10, -50]\n+    __ ldr(r14, Address(r24, 125));                    \/\/       ldr     x14, [x24, 125]\n+    __ ldrw(r7, Address(r24, -16));                    \/\/       ldr     w7, [x24, -16]\n+    __ ldrb(r8, Address(r2, 13));                      \/\/       ldrb    w8, [x2, 13]\n+    __ ldrh(r30, Address(r25, -61));                   \/\/       ldrh    w30, [x25, -61]\n+    __ ldrsb(r3, Address(r12, -14));                   \/\/       ldrsb   x3, [x12, -14]\n+    __ ldrsh(r10, Address(r17, -28));                  \/\/       ldrsh   x10, [x17, -28]\n+    __ ldrshw(r21, Address(r3, -5));                   \/\/       ldrsh   w21, [x3, -5]\n+    __ ldrsw(r2, Address(r25, 23));                    \/\/       ldrsw   x2, [x25, 23]\n+    __ ldrd(v25, Address(r1, -69));                    \/\/       ldr     d25, [x1, -69]\n+    __ ldrs(v29, Address(r27, 6));                     \/\/       ldr     s29, [x27, 6]\n+    __ strd(v29, Address(r12, 41));                    \/\/       str     d29, [x12, 41]\n+    __ strs(v2, Address(r22, -115));                   \/\/       str     s2, [x22, -115]\n@@ -248,16 +284,16 @@\n-    __ str(r10, Address(__ pre(r0, 8)));               \/\/       str     x10, [x0, 8]!\n-    __ strw(r3, Address(__ pre(r0, 29)));              \/\/       str     w3, [x0, 29]!\n-    __ strb(r10, Address(__ pre(r14, 9)));             \/\/       strb    w10, [x14, 9]!\n-    __ strh(r29, Address(__ pre(r25, -3)));            \/\/       strh    w29, [x25, -3]!\n-    __ ldr(r12, Address(__ pre(r16, -144)));           \/\/       ldr     x12, [x16, -144]!\n-    __ ldrw(r12, Address(__ pre(r22, -6)));            \/\/       ldr     w12, [x22, -6]!\n-    __ ldrb(r13, Address(__ pre(r11, -10)));           \/\/       ldrb    w13, [x11, -10]!\n-    __ ldrh(r0, Address(__ pre(r21, -21)));            \/\/       ldrh    w0, [x21, -21]!\n-    __ ldrsb(r23, Address(__ pre(r6, 4)));             \/\/       ldrsb   x23, [x6, 4]!\n-    __ ldrsh(r3, Address(__ pre(r7, -53)));            \/\/       ldrsh   x3, [x7, -53]!\n-    __ ldrshw(r28, Address(__ pre(r4, -7)));           \/\/       ldrsh   w28, [x4, -7]!\n-    __ ldrsw(r24, Address(__ pre(r8, -18)));           \/\/       ldrsw   x24, [x8, -18]!\n-    __ ldrd(v14, Address(__ pre(r11, 12)));            \/\/       ldr     d14, [x11, 12]!\n-    __ ldrs(v19, Address(__ pre(r12, -67)));           \/\/       ldr     s19, [x12, -67]!\n-    __ strd(v20, Address(__ pre(r0, -253)));           \/\/       str     d20, [x0, -253]!\n-    __ strs(v8, Address(__ pre(r0, 64)));              \/\/       str     s8, [x0, 64]!\n+    __ str(r26, Address(__ pre(r5, 3)));               \/\/       str     x26, [x5, 3]!\n+    __ strw(r20, Address(__ pre(r5, -103)));           \/\/       str     w20, [x5, -103]!\n+    __ strb(r8, Address(__ pre(r12, -25)));            \/\/       strb    w8, [x12, -25]!\n+    __ strh(r20, Address(__ pre(r2, -57)));            \/\/       strh    w20, [x2, -57]!\n+    __ ldr(r14, Address(__ pre(r29, -234)));           \/\/       ldr     x14, [x29, -234]!\n+    __ ldrw(r13, Address(__ pre(r29, 4)));             \/\/       ldr     w13, [x29, 4]!\n+    __ ldrb(r24, Address(__ pre(r19, -9)));            \/\/       ldrb    w24, [x19, -9]!\n+    __ ldrh(r3, Address(__ pre(r27, -19)));            \/\/       ldrh    w3, [x27, -19]!\n+    __ ldrsb(r17, Address(__ pre(r1, -5)));            \/\/       ldrsb   x17, [x1, -5]!\n+    __ ldrsh(r17, Address(__ pre(r19, -13)));          \/\/       ldrsh   x17, [x19, -13]!\n+    __ ldrshw(r21, Address(__ pre(r11, -26)));         \/\/       ldrsh   w21, [x11, -26]!\n+    __ ldrsw(r1, Address(__ pre(r9, -60)));            \/\/       ldrsw   x1, [x9, -60]!\n+    __ ldrd(v26, Address(__ pre(r23, -247)));          \/\/       ldr     d26, [x23, -247]!\n+    __ ldrs(v22, Address(__ pre(r21, -127)));          \/\/       ldr     s22, [x21, -127]!\n+    __ strd(v13, Address(__ pre(r7, -216)));           \/\/       str     d13, [x7, -216]!\n+    __ strs(v12, Address(__ pre(r13, -104)));          \/\/       str     s12, [x13, -104]!\n@@ -267,16 +303,16 @@\n-    __ str(r3, Address(__ post(r28, -94)));            \/\/       str     x3, [x28], -94\n-    __ strw(r11, Address(__ post(r7, -54)));           \/\/       str     w11, [x7], -54\n-    __ strb(r27, Address(__ post(r10, -24)));          \/\/       strb    w27, [x10], -24\n-    __ strh(r6, Address(__ post(r7, 27)));             \/\/       strh    w6, [x7], 27\n-    __ ldr(r13, Address(__ post(r10, -202)));          \/\/       ldr     x13, [x10], -202\n-    __ ldrw(r15, Address(__ post(r5, -41)));           \/\/       ldr     w15, [x5], -41\n-    __ ldrb(r2, Address(__ post(r13, 9)));             \/\/       ldrb    w2, [x13], 9\n-    __ ldrh(r28, Address(__ post(r13, -20)));          \/\/       ldrh    w28, [x13], -20\n-    __ ldrsb(r9, Address(__ post(r13, -31)));          \/\/       ldrsb   x9, [x13], -31\n-    __ ldrsh(r3, Address(__ post(r24, -36)));          \/\/       ldrsh   x3, [x24], -36\n-    __ ldrshw(r20, Address(__ post(r3, 6)));           \/\/       ldrsh   w20, [x3], 6\n-    __ ldrsw(r7, Address(__ post(r19, -1)));           \/\/       ldrsw   x7, [x19], -1\n-    __ ldrd(v30, Address(__ post(r8, -130)));          \/\/       ldr     d30, [x8], -130\n-    __ ldrs(v25, Address(__ post(r15, 21)));           \/\/       ldr     s25, [x15], 21\n-    __ strd(v14, Address(__ post(r23, 90)));           \/\/       str     d14, [x23], 90\n-    __ strs(v8, Address(__ post(r0, -33)));            \/\/       str     s8, [x0], -33\n+    __ str(r20, Address(__ post(r5, -237)));           \/\/       str     x20, [x5], -237\n+    __ strw(r29, Address(__ post(r28, -74)));          \/\/       str     w29, [x28], -74\n+    __ strb(r4, Address(__ post(r24, -22)));           \/\/       strb    w4, [x24], -22\n+    __ strh(r13, Address(__ post(r9, -21)));           \/\/       strh    w13, [x9], -21\n+    __ ldr(r26, Address(__ post(r7, -55)));            \/\/       ldr     x26, [x7], -55\n+    __ ldrw(r13, Address(__ post(r3, -115)));          \/\/       ldr     w13, [x3], -115\n+    __ ldrb(r1, Address(__ post(r5, 12)));             \/\/       ldrb    w1, [x5], 12\n+    __ ldrh(r8, Address(__ post(r13, -34)));           \/\/       ldrh    w8, [x13], -34\n+    __ ldrsb(r23, Address(__ post(r20, -27)));         \/\/       ldrsb   x23, [x20], -27\n+    __ ldrsh(r20, Address(__ post(r6, -2)));           \/\/       ldrsh   x20, [x6], -2\n+    __ ldrshw(r9, Address(__ post(r17, -42)));         \/\/       ldrsh   w9, [x17], -42\n+    __ ldrsw(r21, Address(__ post(r6, -30)));          \/\/       ldrsw   x21, [x6], -30\n+    __ ldrd(v16, Address(__ post(r22, -29)));          \/\/       ldr     d16, [x22], -29\n+    __ ldrs(v9, Address(__ post(r11, -3)));            \/\/       ldr     s9, [x11], -3\n+    __ strd(v22, Address(__ post(r26, 60)));           \/\/       str     d22, [x26], 60\n+    __ strs(v16, Address(__ post(r29, -2)));           \/\/       str     s16, [x29], -2\n@@ -286,16 +322,16 @@\n-    __ str(r10, Address(r17, r21, Address::sxtw(3)));  \/\/       str     x10, [x17, w21, sxtw #3]\n-    __ strw(r4, Address(r13, r22, Address::sxtw(2)));  \/\/       str     w4, [x13, w22, sxtw #2]\n-    __ strb(r13, Address(r0, r19, Address::uxtw(0)));  \/\/       strb    w13, [x0, w19, uxtw #0]\n-    __ strh(r12, Address(r27, r6, Address::sxtw(0)));  \/\/       strh    w12, [x27, w6, sxtw #0]\n-    __ ldr(r0, Address(r8, r16, Address::lsl(0)));     \/\/       ldr     x0, [x8, x16, lsl #0]\n-    __ ldrw(r0, Address(r4, r26, Address::sxtx(0)));   \/\/       ldr     w0, [x4, x26, sxtx #0]\n-    __ ldrb(r14, Address(r25, r5, Address::sxtw(0)));  \/\/       ldrb    w14, [x25, w5, sxtw #0]\n-    __ ldrh(r9, Address(r4, r17, Address::uxtw(0)));   \/\/       ldrh    w9, [x4, w17, uxtw #0]\n-    __ ldrsb(r27, Address(r4, r7, Address::lsl(0)));   \/\/       ldrsb   x27, [x4, x7, lsl #0]\n-    __ ldrsh(r15, Address(r17, r30, Address::sxtw(0))); \/\/      ldrsh   x15, [x17, w30, sxtw #0]\n-    __ ldrshw(r16, Address(r0, r22, Address::sxtw(0))); \/\/      ldrsh   w16, [x0, w22, sxtw #0]\n-    __ ldrsw(r22, Address(r10, r30, Address::sxtx(2))); \/\/      ldrsw   x22, [x10, x30, sxtx #2]\n-    __ ldrd(v29, Address(r21, r10, Address::sxtx(3))); \/\/       ldr     d29, [x21, x10, sxtx #3]\n-    __ ldrs(v3, Address(r11, r19, Address::uxtw(0)));  \/\/       ldr     s3, [x11, w19, uxtw #0]\n-    __ strd(v13, Address(r28, r29, Address::uxtw(3))); \/\/       str     d13, [x28, w29, uxtw #3]\n-    __ strs(v23, Address(r29, r5, Address::sxtx(2)));  \/\/       str     s23, [x29, x5, sxtx #2]\n+    __ str(r1, Address(r22, r4, Address::sxtw(0)));    \/\/       str     x1, [x22, w4, sxtw #0]\n+    __ strw(r23, Address(r30, r13, Address::lsl(2)));  \/\/       str     w23, [x30, x13, lsl #2]\n+    __ strb(r12, Address(r11, r12, Address::uxtw(0))); \/\/       strb    w12, [x11, w12, uxtw #0]\n+    __ strh(r25, Address(r12, r0, Address::lsl(1)));   \/\/       strh    w25, [x12, x0, lsl #1]\n+    __ ldr(r17, Address(r7, r0, Address::uxtw(3)));    \/\/       ldr     x17, [x7, w0, uxtw #3]\n+    __ ldrw(r1, Address(r19, r14, Address::uxtw(2)));  \/\/       ldr     w1, [x19, w14, uxtw #2]\n+    __ ldrb(r12, Address(r2, r9, Address::lsl(0)));    \/\/       ldrb    w12, [x2, x9, lsl #0]\n+    __ ldrh(r22, Address(r9, r27, Address::sxtw(0)));  \/\/       ldrh    w22, [x9, w27, sxtw #0]\n+    __ ldrsb(r21, Address(r12, r15, Address::sxtx(0))); \/\/      ldrsb   x21, [x12, x15, sxtx #0]\n+    __ ldrsh(r28, Address(r6, r16, Address::lsl(1)));  \/\/       ldrsh   x28, [x6, x16, lsl #1]\n+    __ ldrshw(r25, Address(r17, r22, Address::sxtw(0))); \/\/     ldrsh   w25, [x17, w22, sxtw #0]\n+    __ ldrsw(r4, Address(r17, r29, Address::sxtx(0))); \/\/       ldrsw   x4, [x17, x29, sxtx #0]\n+    __ ldrd(v5, Address(r1, r3, Address::sxtx(3)));    \/\/       ldr     d5, [x1, x3, sxtx #3]\n+    __ ldrs(v24, Address(r17, r13, Address::uxtw(2))); \/\/       ldr     s24, [x17, w13, uxtw #2]\n+    __ strd(v17, Address(r17, r23, Address::sxtx(3))); \/\/       str     d17, [x17, x23, sxtx #3]\n+    __ strs(v17, Address(r30, r5, Address::sxtw(2)));  \/\/       str     s17, [x30, w5, sxtw #2]\n@@ -305,16 +341,16 @@\n-    __ str(r5, Address(r8, 12600));                    \/\/       str     x5, [x8, 12600]\n-    __ strw(r29, Address(r24, 7880));                  \/\/       str     w29, [x24, 7880]\n-    __ strb(r19, Address(r17, 1566));                  \/\/       strb    w19, [x17, 1566]\n-    __ strh(r13, Address(r19, 3984));                  \/\/       strh    w13, [x19, 3984]\n-    __ ldr(r19, Address(r23, 13632));                  \/\/       ldr     x19, [x23, 13632]\n-    __ ldrw(r23, Address(r29, 6264));                  \/\/       ldr     w23, [x29, 6264]\n-    __ ldrb(r22, Address(r11, 2012));                  \/\/       ldrb    w22, [x11, 2012]\n-    __ ldrh(r3, Address(r10, 3784));                   \/\/       ldrh    w3, [x10, 3784]\n-    __ ldrsb(r8, Address(r16, 1951));                  \/\/       ldrsb   x8, [x16, 1951]\n-    __ ldrsh(r23, Address(r20, 3346));                 \/\/       ldrsh   x23, [x20, 3346]\n-    __ ldrshw(r2, Address(r1, 3994));                  \/\/       ldrsh   w2, [x1, 3994]\n-    __ ldrsw(r4, Address(r17, 7204));                  \/\/       ldrsw   x4, [x17, 7204]\n-    __ ldrd(v20, Address(r27, 14400));                 \/\/       ldr     d20, [x27, 14400]\n-    __ ldrs(v25, Address(r14, 8096));                  \/\/       ldr     s25, [x14, 8096]\n-    __ strd(v26, Address(r10, 15024));                 \/\/       str     d26, [x10, 15024]\n-    __ strs(v9, Address(r3, 6936));                    \/\/       str     s9, [x3, 6936]\n+    __ str(r29, Address(r11, 14160));                  \/\/       str     x29, [x11, 14160]\n+    __ strw(r28, Address(r21, 7752));                  \/\/       str     w28, [x21, 7752]\n+    __ strb(r28, Address(r2, 1746));                   \/\/       strb    w28, [x2, 1746]\n+    __ strh(r0, Address(r28, 3296));                   \/\/       strh    w0, [x28, 3296]\n+    __ ldr(r25, Address(r7, 15408));                   \/\/       ldr     x25, [x7, 15408]\n+    __ ldrw(r0, Address(r3, 6312));                    \/\/       ldr     w0, [x3, 6312]\n+    __ ldrb(r30, Address(r5, 1992));                   \/\/       ldrb    w30, [x5, 1992]\n+    __ ldrh(r14, Address(r23, 3194));                  \/\/       ldrh    w14, [x23, 3194]\n+    __ ldrsb(r10, Address(r19, 1786));                 \/\/       ldrsb   x10, [x19, 1786]\n+    __ ldrsh(r29, Address(r17, 3482));                 \/\/       ldrsh   x29, [x17, 3482]\n+    __ ldrshw(r25, Address(r30, 3362));                \/\/       ldrsh   w25, [x30, 3362]\n+    __ ldrsw(r17, Address(r2, 7512));                  \/\/       ldrsw   x17, [x2, 7512]\n+    __ ldrd(v15, Address(r16, 15176));                 \/\/       ldr     d15, [x16, 15176]\n+    __ ldrs(v12, Address(r30, 6220));                  \/\/       ldr     s12, [x30, 6220]\n+    __ strd(v1, Address(r1, 15216));                   \/\/       str     d1, [x1, 15216]\n+    __ strs(v5, Address(r11, 7832));                   \/\/       str     s5, [x11, 7832]\n@@ -324,2 +360,2 @@\n-    __ ldr(r27, forth);                                \/\/       ldr     x27, forth\n-    __ ldrw(r11, __ pc());                             \/\/       ldr     w11, .\n+    __ ldr(r17, back);                                 \/\/       ldr     x17, back\n+    __ ldrw(r2, back);                                 \/\/       ldr     w2, back\n@@ -328,1 +364,1 @@\n-    __ prfm(Address(r3, -187));                        \/\/       prfm    PLDL1KEEP, [x3, -187]\n+    __ prfm(Address(r25, 111));                        \/\/       prfm    PLDL1KEEP, [x25, 111]\n@@ -331,1 +367,1 @@\n-    __ prfm(__ pc());                                  \/\/       prfm    PLDL1KEEP, .\n+    __ prfm(back);                                     \/\/       prfm    PLDL1KEEP, back\n@@ -334,1 +370,1 @@\n-    __ prfm(Address(r29, r14, Address::lsl(0)));       \/\/       prfm    PLDL1KEEP, [x29, x14, lsl #0]\n+    __ prfm(Address(r14, r27, Address::uxtw(0)));      \/\/       prfm    PLDL1KEEP, [x14, w27, uxtw #0]\n@@ -337,1 +373,1 @@\n-    __ prfm(Address(r4, 13312));                       \/\/       prfm    PLDL1KEEP, [x4, 13312]\n+    __ prfm(Address(r14, 12328));                      \/\/       prfm    PLDL1KEEP, [x14, 12328]\n@@ -340,8 +376,8 @@\n-    __ adcw(r21, r1, r7);                              \/\/       adc     w21, w1, w7\n-    __ adcsw(r8, r5, r7);                              \/\/       adcs    w8, w5, w7\n-    __ sbcw(r7, r27, r14);                             \/\/       sbc     w7, w27, w14\n-    __ sbcsw(r27, r4, r17);                            \/\/       sbcs    w27, w4, w17\n-    __ adc(r0, r28, r0);                               \/\/       adc     x0, x28, x0\n-    __ adcs(r12, r24, r30);                            \/\/       adcs    x12, x24, x30\n-    __ sbc(r0, r25, r15);                              \/\/       sbc     x0, x25, x15\n-    __ sbcs(r1, r24, r3);                              \/\/       sbcs    x1, x24, x3\n+    __ adcw(r0, r25, r15);                             \/\/       adc     w0, w25, w15\n+    __ adcsw(r1, r24, r3);                             \/\/       adcs    w1, w24, w3\n+    __ sbcw(r17, r24, r20);                            \/\/       sbc     w17, w24, w20\n+    __ sbcsw(r11, r0, r13);                            \/\/       sbcs    w11, w0, w13\n+    __ adc(r28, r10, r7);                              \/\/       adc     x28, x10, x7\n+    __ adcs(r4, r15, r16);                             \/\/       adcs    x4, x15, x16\n+    __ sbc(r2, r12, r20);                              \/\/       sbc     x2, x12, x20\n+    __ sbcs(r29, r13, r13);                            \/\/       sbcs    x29, x13, x13\n@@ -350,8 +386,8 @@\n-    __ addw(r17, r24, r20, ext::uxtb, 2);              \/\/       add     w17, w24, w20, uxtb #2\n-    __ addsw(r13, r28, r10, ext::uxth, 1);             \/\/       adds    w13, w28, w10, uxth #1\n-    __ sub(r15, r16, r2, ext::sxth, 2);                \/\/       sub     x15, x16, x2, sxth #2\n-    __ subsw(r29, r13, r13, ext::uxth, 2);             \/\/       subs    w29, w13, w13, uxth #2\n-    __ add(r12, r20, r12, ext::sxtw, 3);               \/\/       add     x12, x20, x12, sxtw #3\n-    __ adds(r30, r27, r11, ext::sxtb, 1);              \/\/       adds    x30, x27, x11, sxtb #1\n-    __ sub(r14, r7, r1, ext::sxtw, 2);                 \/\/       sub     x14, x7, x1, sxtw #2\n-    __ subs(r29, r3, r27, ext::sxth, 1);               \/\/       subs    x29, x3, x27, sxth #1\n+    __ addw(r14, r6, r12, ext::uxtx, 3);               \/\/       add     w14, w6, w12, uxtx #3\n+    __ addsw(r17, r25, r30, ext::uxtw, 4);             \/\/       adds    w17, w25, w30, uxtw #4\n+    __ sub(r0, r17, r14, ext::uxtb, 1);                \/\/       sub     x0, x17, x14, uxtb #1\n+    __ subsw(r9, r24, r29, ext::sxtx, 1);              \/\/       subs    w9, w24, w29, sxtx #1\n+    __ add(r1, r22, r0, ext::sxtw, 2);                 \/\/       add     x1, x22, x0, sxtw #2\n+    __ adds(r12, r28, r22, ext::uxth, 3);              \/\/       adds    x12, x28, x22, uxth #3\n+    __ sub(r10, r12, r17, ext::uxtw, 4);               \/\/       sub     x10, x12, x17, uxtw #4\n+    __ subs(r15, r28, r10, ext::sxtw, 3);              \/\/       subs    x15, x28, x10, sxtw #3\n@@ -360,4 +396,4 @@\n-    __ ccmnw(r0, r13, 14u, Assembler::MI);             \/\/       ccmn    w0, w13, #14, MI\n-    __ ccmpw(r22, r17, 6u, Assembler::CC);             \/\/       ccmp    w22, w17, #6, CC\n-    __ ccmn(r17, r30, 14u, Assembler::VS);             \/\/       ccmn    x17, x30, #14, VS\n-    __ ccmp(r10, r19, 12u, Assembler::HI);             \/\/       ccmp    x10, x19, #12, HI\n+    __ ccmnw(r19, r23, 2u, Assembler::LE);             \/\/       ccmn    w19, w23, #2, LE\n+    __ ccmpw(r17, r9, 6u, Assembler::LO);              \/\/       ccmp    w17, w9, #6, LO\n+    __ ccmn(r21, r8, 2u, Assembler::CC);               \/\/       ccmn    x21, x8, #2, CC\n+    __ ccmp(r19, r5, 1u, Assembler::MI);               \/\/       ccmp    x19, x5, #1, MI\n@@ -366,4 +402,4 @@\n-    __ ccmnw(r6, 18, 2, Assembler::LE);                \/\/       ccmn    w6, #18, #2, LE\n-    __ ccmpw(r9, 13, 4, Assembler::HI);                \/\/       ccmp    w9, #13, #4, HI\n-    __ ccmn(r21, 11, 11, Assembler::LO);               \/\/       ccmn    x21, #11, #11, LO\n-    __ ccmp(r4, 13, 2, Assembler::VC);                 \/\/       ccmp    x4, #13, #2, VC\n+    __ ccmnw(r22, 17, 12, Assembler::HI);              \/\/       ccmn    w22, #17, #12, HI\n+    __ ccmpw(r17, 7, 3, Assembler::HS);                \/\/       ccmp    w17, #7, #3, HS\n+    __ ccmn(r16, 28, 5, Assembler::LT);                \/\/       ccmn    x16, #28, #5, LT\n+    __ ccmp(r22, 3, 5, Assembler::LS);                 \/\/       ccmp    x22, #3, #5, LS\n@@ -372,8 +408,8 @@\n-    __ cselw(r12, r2, r22, Assembler::HI);             \/\/       csel    w12, w2, w22, HI\n-    __ csincw(r24, r16, r17, Assembler::HS);           \/\/       csinc   w24, w16, w17, HS\n-    __ csinvw(r6, r7, r16, Assembler::LT);             \/\/       csinv   w6, w7, w16, LT\n-    __ csnegw(r11, r27, r22, Assembler::LS);           \/\/       csneg   w11, w27, w22, LS\n-    __ csel(r10, r3, r29, Assembler::LT);              \/\/       csel    x10, x3, x29, LT\n-    __ csinc(r12, r26, r27, Assembler::CC);            \/\/       csinc   x12, x26, x27, CC\n-    __ csinv(r15, r10, r21, Assembler::GT);            \/\/       csinv   x15, x10, x21, GT\n-    __ csneg(r30, r23, r9, Assembler::GT);             \/\/       csneg   x30, x23, x9, GT\n+    __ cselw(r29, r26, r12, Assembler::LT);            \/\/       csel    w29, w26, w12, LT\n+    __ csincw(r27, r10, r15, Assembler::CC);           \/\/       csinc   w27, w10, w15, CC\n+    __ csinvw(r21, r28, r30, Assembler::LS);           \/\/       csinv   w21, w28, w30, LS\n+    __ csnegw(r9, r27, r30, Assembler::CC);            \/\/       csneg   w9, w27, w30, CC\n+    __ csel(r29, r15, r29, Assembler::LE);             \/\/       csel    x29, x15, x29, LE\n+    __ csinc(r25, r21, r4, Assembler::EQ);             \/\/       csinc   x25, x21, x4, EQ\n+    __ csinv(r17, r21, r29, Assembler::VS);            \/\/       csinv   x17, x21, x29, VS\n+    __ csneg(r21, r20, r6, Assembler::HI);             \/\/       csneg   x21, x20, x6, HI\n@@ -382,11 +418,23 @@\n-    __ rbitw(r30, r10);                                \/\/       rbit    w30, w10\n-    __ rev16w(r29, r15);                               \/\/       rev16   w29, w15\n-    __ revw(r29, r30);                                 \/\/       rev     w29, w30\n-    __ clzw(r25, r21);                                 \/\/       clz     w25, w21\n-    __ clsw(r4, r0);                                   \/\/       cls     w4, w0\n-    __ rbit(r17, r21);                                 \/\/       rbit    x17, x21\n-    __ rev16(r29, r16);                                \/\/       rev16   x29, x16\n-    __ rev32(r21, r20);                                \/\/       rev32   x21, x20\n-    __ rev(r6, r19);                                   \/\/       rev     x6, x19\n-    __ clz(r30, r3);                                   \/\/       clz     x30, x3\n-    __ cls(r21, r19);                                  \/\/       cls     x21, x19\n+    __ rbitw(r30, r3);                                 \/\/       rbit    w30, w3\n+    __ rev16w(r21, r19);                               \/\/       rev16   w21, w19\n+    __ revw(r11, r24);                                 \/\/       rev     w11, w24\n+    __ clzw(r0, r27);                                  \/\/       clz     w0, w27\n+    __ clsw(r25, r14);                                 \/\/       cls     w25, w14\n+    __ rbit(r3, r14);                                  \/\/       rbit    x3, x14\n+    __ rev16(r17, r7);                                 \/\/       rev16   x17, x7\n+    __ rev32(r15, r24);                                \/\/       rev32   x15, x24\n+    __ rev(r28, r17);                                  \/\/       rev     x28, x17\n+    __ clz(r25, r2);                                   \/\/       clz     x25, x2\n+    __ cls(r26, r28);                                  \/\/       cls     x26, x28\n+    __ pacia(r5, r25);                                 \/\/       pacia   x5, x25\n+    __ pacib(r26, r27);                                \/\/       pacib   x26, x27\n+    __ pacda(r16, r17);                                \/\/       pacda   x16, x17\n+    __ pacdb(r6, r21);                                 \/\/       pacdb   x6, x21\n+    __ autia(r12, r0);                                 \/\/       autia   x12, x0\n+    __ autib(r4, r12);                                 \/\/       autib   x4, x12\n+    __ autda(r27, r17);                                \/\/       autda   x27, x17\n+    __ autdb(r28, r28);                                \/\/       autdb   x28, x28\n+    __ braa(r2, r17);                                  \/\/       braa    x2, x17\n+    __ brab(r10, r15);                                 \/\/       brab    x10, x15\n+    __ blraa(r14, r14);                                \/\/       blraa   x14, x14\n+    __ blrab(r3, r25);                                 \/\/       blrab   x3, x25\n@@ -395,14 +443,14 @@\n-    __ udivw(r11, r24, r0);                            \/\/       udiv    w11, w24, w0\n-    __ sdivw(r27, r25, r14);                           \/\/       sdiv    w27, w25, w14\n-    __ lslvw(r3, r14, r17);                            \/\/       lslv    w3, w14, w17\n-    __ lsrvw(r7, r15, r24);                            \/\/       lsrv    w7, w15, w24\n-    __ asrvw(r28, r17, r25);                           \/\/       asrv    w28, w17, w25\n-    __ rorvw(r2, r26, r28);                            \/\/       rorv    w2, w26, w28\n-    __ udiv(r5, r25, r26);                             \/\/       udiv    x5, x25, x26\n-    __ sdiv(r27, r16, r17);                            \/\/       sdiv    x27, x16, x17\n-    __ lslv(r6, r21, r12);                             \/\/       lslv    x6, x21, x12\n-    __ lsrv(r0, r4, r12);                              \/\/       lsrv    x0, x4, x12\n-    __ asrv(r27, r17, r28);                            \/\/       asrv    x27, x17, x28\n-    __ rorv(r28, r2, r17);                             \/\/       rorv    x28, x2, x17\n-    __ umulh(r10, r15, r14);                           \/\/       umulh   x10, x15, x14\n-    __ smulh(r14, r3, r25);                            \/\/       smulh   x14, x3, x25\n+    __ udivw(r15, r19, r14);                           \/\/       udiv    w15, w19, w14\n+    __ sdivw(r5, r16, r4);                             \/\/       sdiv    w5, w16, w4\n+    __ lslvw(r26, r25, r4);                            \/\/       lslv    w26, w25, w4\n+    __ lsrvw(r2, r2, r12);                             \/\/       lsrv    w2, w2, w12\n+    __ asrvw(r29, r17, r8);                            \/\/       asrv    w29, w17, w8\n+    __ rorvw(r7, r3, r4);                              \/\/       rorv    w7, w3, w4\n+    __ udiv(r25, r4, r26);                             \/\/       udiv    x25, x4, x26\n+    __ sdiv(r25, r4, r17);                             \/\/       sdiv    x25, x4, x17\n+    __ lslv(r0, r26, r17);                             \/\/       lslv    x0, x26, x17\n+    __ lsrv(r23, r15, r21);                            \/\/       lsrv    x23, x15, x21\n+    __ asrv(r28, r17, r27);                            \/\/       asrv    x28, x17, x27\n+    __ rorv(r10, r3, r0);                              \/\/       rorv    x10, x3, x0\n+    __ umulh(r7, r25, r9);                             \/\/       umulh   x7, x25, x9\n+    __ smulh(r6, r15, r29);                            \/\/       smulh   x6, x15, x29\n@@ -411,8 +459,8 @@\n-    __ maddw(r15, r19, r14, r5);                       \/\/       madd    w15, w19, w14, w5\n-    __ msubw(r16, r4, r26, r25);                       \/\/       msub    w16, w4, w26, w25\n-    __ madd(r4, r2, r2, r12);                          \/\/       madd    x4, x2, x2, x12\n-    __ msub(r29, r17, r8, r7);                         \/\/       msub    x29, x17, x8, x7\n-    __ smaddl(r3, r4, r25, r4);                        \/\/       smaddl  x3, w4, w25, x4\n-    __ smsubl(r26, r25, r4, r17);                      \/\/       smsubl  x26, w25, w4, x17\n-    __ umaddl(r0, r26, r17, r23);                      \/\/       umaddl  x0, w26, w17, x23\n-    __ umsubl(r15, r21, r28, r17);                     \/\/       umsubl  x15, w21, w28, x17\n+    __ maddw(r15, r10, r2, r17);                       \/\/       madd    w15, w10, w2, w17\n+    __ msubw(r7, r11, r11, r23);                       \/\/       msub    w7, w11, w11, w23\n+    __ madd(r7, r29, r23, r14);                        \/\/       madd    x7, x29, x23, x14\n+    __ msub(r27, r11, r11, r4);                        \/\/       msub    x27, x11, x11, x4\n+    __ smaddl(r24, r12, r15, r14);                     \/\/       smaddl  x24, w12, w15, x14\n+    __ smsubl(r20, r11, r28, r13);                     \/\/       smsubl  x20, w11, w28, x13\n+    __ umaddl(r11, r12, r23, r30);                     \/\/       umaddl  x11, w12, w23, x30\n+    __ umsubl(r26, r14, r9, r13);                      \/\/       umsubl  x26, w14, w9, x13\n@@ -421,10 +469,10 @@\n-    __ fabds(v27, v10, v3);                            \/\/       fabd    s27, s10, s3\n-    __ fmuls(v0, v7, v25);                             \/\/       fmul    s0, s7, s25\n-    __ fdivs(v9, v6, v15);                             \/\/       fdiv    s9, s6, s15\n-    __ fadds(v29, v15, v10);                           \/\/       fadd    s29, s15, s10\n-    __ fsubs(v2, v17, v7);                             \/\/       fsub    s2, s17, s7\n-    __ fabdd(v11, v11, v23);                           \/\/       fabd    d11, d11, d23\n-    __ fmuld(v7, v29, v23);                            \/\/       fmul    d7, d29, d23\n-    __ fdivd(v14, v27, v11);                           \/\/       fdiv    d14, d27, d11\n-    __ faddd(v11, v4, v24);                            \/\/       fadd    d11, d4, d24\n-    __ fsubd(v12, v15, v14);                           \/\/       fsub    d12, d15, d14\n+    __ fabds(v10, v7, v5);                             \/\/       fabd    s10, s7, s5\n+    __ fmuls(v29, v15, v3);                            \/\/       fmul    s29, s15, s3\n+    __ fdivs(v11, v12, v15);                           \/\/       fdiv    s11, s12, s15\n+    __ fadds(v30, v30, v17);                           \/\/       fadd    s30, s30, s17\n+    __ fsubs(v19, v20, v15);                           \/\/       fsub    s19, s20, s15\n+    __ fabdd(v15, v9, v21);                            \/\/       fabd    d15, d9, d21\n+    __ fmuld(v2, v9, v27);                             \/\/       fmul    d2, d9, d27\n+    __ fdivd(v7, v29, v30);                            \/\/       fdiv    d7, d29, d30\n+    __ faddd(v17, v1, v2);                             \/\/       fadd    d17, d1, d2\n+    __ fsubd(v6, v10, v3);                             \/\/       fsub    d6, d10, d3\n@@ -433,8 +481,8 @@\n-    __ fmadds(v20, v11, v28, v13);                     \/\/       fmadd   s20, s11, s28, s13\n-    __ fmsubs(v11, v12, v23, v30);                     \/\/       fmsub   s11, s12, s23, s30\n-    __ fnmadds(v26, v14, v9, v13);                     \/\/       fnmadd  s26, s14, s9, s13\n-    __ fnmadds(v10, v7, v5, v29);                      \/\/       fnmadd  s10, s7, s5, s29\n-    __ fmaddd(v15, v3, v11, v12);                      \/\/       fmadd   d15, d3, d11, d12\n-    __ fmsubd(v15, v30, v30, v17);                     \/\/       fmsub   d15, d30, d30, d17\n-    __ fnmaddd(v19, v20, v15, v15);                    \/\/       fnmadd  d19, d20, d15, d15\n-    __ fnmaddd(v9, v21, v2, v9);                       \/\/       fnmadd  d9, d21, d2, d9\n+    __ fmadds(v24, v11, v7, v1);                       \/\/       fmadd   s24, s11, s7, s1\n+    __ fmsubs(v11, v0, v3, v17);                       \/\/       fmsub   s11, s0, s3, s17\n+    __ fnmadds(v28, v6, v22, v6);                      \/\/       fnmadd  s28, s6, s22, s6\n+    __ fnmadds(v0, v27, v26, v2);                      \/\/       fnmadd  s0, s27, s26, s2\n+    __ fmaddd(v5, v7, v28, v11);                       \/\/       fmadd   d5, d7, d28, d11\n+    __ fmsubd(v25, v13, v11, v23);                     \/\/       fmsub   d25, d13, d11, d23\n+    __ fnmaddd(v19, v8, v17, v21);                     \/\/       fnmadd  d19, d8, d17, d21\n+    __ fnmaddd(v25, v20, v19, v17);                    \/\/       fnmadd  d25, d20, d19, d17\n@@ -443,10 +491,10 @@\n-    __ fmovs(v27, v7);                                 \/\/       fmov    s27, s7\n-    __ fabss(v29, v30);                                \/\/       fabs    s29, s30\n-    __ fnegs(v17, v1);                                 \/\/       fneg    s17, s1\n-    __ fsqrts(v2, v6);                                 \/\/       fsqrt   s2, s6\n-    __ fcvts(v10, v3);                                 \/\/       fcvt    d10, s3\n-    __ fmovd(v24, v11);                                \/\/       fmov    d24, d11\n-    __ fabsd(v7, v1);                                  \/\/       fabs    d7, d1\n-    __ fnegd(v11, v0);                                 \/\/       fneg    d11, d0\n-    __ fsqrtd(v3, v17);                                \/\/       fsqrt   d3, d17\n-    __ fcvtd(v28, v6);                                 \/\/       fcvt    s28, d6\n+    __ fmovs(v2, v29);                                 \/\/       fmov    s2, s29\n+    __ fabss(v22, v8);                                 \/\/       fabs    s22, s8\n+    __ fnegs(v21, v19);                                \/\/       fneg    s21, s19\n+    __ fsqrts(v20, v11);                               \/\/       fsqrt   s20, s11\n+    __ fcvts(v17, v20);                                \/\/       fcvt    d17, s20\n+    __ fmovd(v6, v15);                                 \/\/       fmov    d6, d15\n+    __ fabsd(v3, v3);                                  \/\/       fabs    d3, d3\n+    __ fnegd(v28, v3);                                 \/\/       fneg    d28, d3\n+    __ fsqrtd(v27, v14);                               \/\/       fsqrt   d27, d14\n+    __ fcvtd(v14, v10);                                \/\/       fcvt    s14, d10\n@@ -455,12 +503,12 @@\n-    __ fcvtzsw(r22, v6);                               \/\/       fcvtzs  w22, s6\n-    __ fcvtzs(r0, v27);                                \/\/       fcvtzs  x0, s27\n-    __ fcvtzdw(r26, v2);                               \/\/       fcvtzs  w26, d2\n-    __ fcvtzd(r5, v7);                                 \/\/       fcvtzs  x5, d7\n-    __ scvtfws(v28, r11);                              \/\/       scvtf   s28, w11\n-    __ scvtfs(v25, r13);                               \/\/       scvtf   s25, x13\n-    __ scvtfwd(v11, r23);                              \/\/       scvtf   d11, w23\n-    __ scvtfd(v19, r8);                                \/\/       scvtf   d19, x8\n-    __ fmovs(r17, v21);                                \/\/       fmov    w17, s21\n-    __ fmovd(r25, v20);                                \/\/       fmov    x25, d20\n-    __ fmovs(v19, r17);                                \/\/       fmov    s19, w17\n-    __ fmovd(v2, r29);                                 \/\/       fmov    d2, x29\n+    __ fcvtzsw(r12, v11);                              \/\/       fcvtzs  w12, s11\n+    __ fcvtzs(r17, v10);                               \/\/       fcvtzs  x17, s10\n+    __ fcvtzdw(r25, v7);                               \/\/       fcvtzs  w25, d7\n+    __ fcvtzd(r7, v14);                                \/\/       fcvtzs  x7, d14\n+    __ scvtfws(v28, r0);                               \/\/       scvtf   s28, w0\n+    __ scvtfs(v22, r0);                                \/\/       scvtf   s22, x0\n+    __ scvtfwd(v12, r23);                              \/\/       scvtf   d12, w23\n+    __ scvtfd(v13, r13);                               \/\/       scvtf   d13, x13\n+    __ fmovs(r7, v14);                                 \/\/       fmov    w7, s14\n+    __ fmovd(r7, v8);                                  \/\/       fmov    x7, d8\n+    __ fmovs(v20, r17);                                \/\/       fmov    s20, w17\n+    __ fmovd(v28, r30);                                \/\/       fmov    d28, x30\n@@ -469,2 +517,2 @@\n-    __ fcmps(v22, v8);                                 \/\/       fcmp    s22, s8\n-    __ fcmpd(v21, v19);                                \/\/       fcmp    d21, d19\n+    __ fcmps(v16, v2);                                 \/\/       fcmp    s16, s2\n+    __ fcmpd(v9, v16);                                 \/\/       fcmp    d9, d16\n@@ -472,1 +520,1 @@\n-    __ fcmpd(v11, 0.0);                                \/\/       fcmp    d11, #0.0\n+    __ fcmpd(v29, 0.0);                                \/\/       fcmp    d29, #0.0\n@@ -475,5 +523,5 @@\n-    __ stpw(r20, r6, Address(r15, -32));               \/\/       stp     w20, w6, [x15, #-32]\n-    __ ldpw(r27, r14, Address(r3, -208));              \/\/       ldp     w27, w14, [x3, #-208]\n-    __ ldpsw(r16, r10, Address(r11, -80));             \/\/       ldpsw   x16, x10, [x11, #-80]\n-    __ stp(r7, r7, Address(r14, 64));                  \/\/       stp     x7, x7, [x14, #64]\n-    __ ldp(r12, r23, Address(r0, 112));                \/\/       ldp     x12, x23, [x0, #112]\n+    __ stpw(r1, r26, Address(r24, -208));              \/\/       stp     w1, w26, [x24, #-208]\n+    __ ldpw(r5, r11, Address(r12, 48));                \/\/       ldp     w5, w11, [x12, #48]\n+    __ ldpsw(r21, r15, Address(r27, 48));              \/\/       ldpsw   x21, x15, [x27, #48]\n+    __ stp(r5, r28, Address(r22, 32));                 \/\/       stp     x5, x28, [x22, #32]\n+    __ ldp(r27, r17, Address(r19, -32));               \/\/       ldp     x27, x17, [x19, #-32]\n@@ -482,5 +530,5 @@\n-    __ stpw(r13, r7, Address(__ pre(r6, -80)));        \/\/       stp     w13, w7, [x6, #-80]!\n-    __ ldpw(r30, r15, Address(__ pre(r2, -144)));      \/\/       ldp     w30, w15, [x2, #-144]!\n-    __ ldpsw(r4, r1, Address(__ pre(r27, -144)));      \/\/       ldpsw   x4, x1, [x27, #-144]!\n-    __ stp(r23, r14, Address(__ pre(r11, 64)));        \/\/       stp     x23, x14, [x11, #64]!\n-    __ ldp(r29, r27, Address(__ pre(r21, -192)));      \/\/       ldp     x29, x27, [x21, #-192]!\n+    __ stpw(r13, r7, Address(__ pre(r26, -176)));      \/\/       stp     w13, w7, [x26, #-176]!\n+    __ ldpw(r13, r21, Address(__ pre(r6, -48)));       \/\/       ldp     w13, w21, [x6, #-48]!\n+    __ ldpsw(r20, r30, Address(__ pre(r27, 16)));      \/\/       ldpsw   x20, x30, [x27, #16]!\n+    __ stp(r21, r5, Address(__ pre(r10, -128)));       \/\/       stp     x21, x5, [x10, #-128]!\n+    __ ldp(r14, r4, Address(__ pre(r23, -96)));        \/\/       ldp     x14, x4, [x23, #-96]!\n@@ -489,5 +537,5 @@\n-    __ stpw(r22, r5, Address(__ post(r21, -48)));      \/\/       stp     w22, w5, [x21], #-48\n-    __ ldpw(r27, r17, Address(__ post(r6, -32)));      \/\/       ldp     w27, w17, [x6], #-32\n-    __ ldpsw(r16, r5, Address(__ post(r1, -80)));      \/\/       ldpsw   x16, x5, [x1], #-80\n-    __ stp(r13, r20, Address(__ post(r22, -208)));     \/\/       stp     x13, x20, [x22], #-208\n-    __ ldp(r30, r27, Address(__ post(r10, 80)));       \/\/       ldp     x30, x27, [x10], #80\n+    __ stpw(r29, r12, Address(__ post(r16, 32)));      \/\/       stp     w29, w12, [x16], #32\n+    __ ldpw(r26, r17, Address(__ post(r27, 96)));      \/\/       ldp     w26, w17, [x27], #96\n+    __ ldpsw(r4, r20, Address(__ post(r14, -96)));     \/\/       ldpsw   x4, x20, [x14], #-96\n+    __ stp(r16, r2, Address(__ post(r14, -112)));      \/\/       stp     x16, x2, [x14], #-112\n+    __ ldp(r23, r24, Address(__ post(r7, -256)));      \/\/       ldp     x23, x24, [x7], #-256\n@@ -496,4 +544,4 @@\n-    __ stnpw(r5, r17, Address(r11, 16));               \/\/       stnp    w5, w17, [x11, #16]\n-    __ ldnpw(r14, r4, Address(r26, -96));              \/\/       ldnp    w14, w4, [x26, #-96]\n-    __ stnp(r23, r29, Address(r12, 32));               \/\/       stnp    x23, x29, [x12, #32]\n-    __ ldnp(r0, r6, Address(r21, -80));                \/\/       ldnp    x0, x6, [x21, #-80]\n+    __ stnpw(r0, r26, Address(r15, 128));              \/\/       stnp    w0, w26, [x15, #128]\n+    __ ldnpw(r26, r6, Address(r8, -208));              \/\/       ldnp    w26, w6, [x8, #-208]\n+    __ stnp(r15, r10, Address(r25, -112));             \/\/       stnp    x15, x10, [x25, #-112]\n+    __ ldnp(r16, r1, Address(r19, -160));              \/\/       ldnp    x16, x1, [x19, #-160]\n@@ -502,22 +550,22 @@\n-    __ ld1(v15, __ T8B, Address(r26));                 \/\/       ld1     {v15.8B}, [x26]\n-    __ ld1(v23, v24, __ T16B, Address(__ post(r11, 32))); \/\/    ld1     {v23.16B, v24.16B}, [x11], 32\n-    __ ld1(v8, v9, v10, __ T1D, Address(__ post(r23, r7))); \/\/  ld1     {v8.1D, v9.1D, v10.1D}, [x23], x7\n-    __ ld1(v19, v20, v21, v22, __ T8H, Address(__ post(r25, 64))); \/\/   ld1     {v19.8H, v20.8H, v21.8H, v22.8H}, [x25], 64\n-    __ ld1r(v29, __ T8B, Address(r17));                \/\/       ld1r    {v29.8B}, [x17]\n-    __ ld1r(v24, __ T4S, Address(__ post(r23, 4)));    \/\/       ld1r    {v24.4S}, [x23], 4\n-    __ ld1r(v10, __ T1D, Address(__ post(r5, r25)));   \/\/       ld1r    {v10.1D}, [x5], x25\n-    __ ld2(v17, v18, __ T2D, Address(r10));            \/\/       ld2     {v17.2D, v18.2D}, [x10]\n-    __ ld2(v12, v13, __ T4H, Address(__ post(r15, 16))); \/\/     ld2     {v12.4H, v13.4H}, [x15], 16\n-    __ ld2r(v25, v26, __ T16B, Address(r17));          \/\/       ld2r    {v25.16B, v26.16B}, [x17]\n-    __ ld2r(v1, v2, __ T2S, Address(__ post(r30, 8))); \/\/       ld2r    {v1.2S, v2.2S}, [x30], 8\n-    __ ld2r(v16, v17, __ T2D, Address(__ post(r17, r9))); \/\/    ld2r    {v16.2D, v17.2D}, [x17], x9\n-    __ ld3(v25, v26, v27, __ T4S, Address(__ post(r12, r2))); \/\/        ld3     {v25.4S, v26.4S, v27.4S}, [x12], x2\n-    __ ld3(v26, v27, v28, __ T2S, Address(r19));       \/\/       ld3     {v26.2S, v27.2S, v28.2S}, [x19]\n-    __ ld3r(v15, v16, v17, __ T8H, Address(r21));      \/\/       ld3r    {v15.8H, v16.8H, v17.8H}, [x21]\n-    __ ld3r(v25, v26, v27, __ T4S, Address(__ post(r13, 12))); \/\/       ld3r    {v25.4S, v26.4S, v27.4S}, [x13], 12\n-    __ ld3r(v14, v15, v16, __ T1D, Address(__ post(r28, r29))); \/\/      ld3r    {v14.1D, v15.1D, v16.1D}, [x28], x29\n-    __ ld4(v17, v18, v19, v20, __ T8H, Address(__ post(r29, 64))); \/\/   ld4     {v17.8H, v18.8H, v19.8H, v20.8H}, [x29], 64\n-    __ ld4(v27, v28, v29, v30, __ T8B, Address(__ post(r7, r0))); \/\/    ld4     {v27.8B, v28.8B, v29.8B, v30.8B}, [x7], x0\n-    __ ld4r(v24, v25, v26, v27, __ T8B, Address(r17)); \/\/       ld4r    {v24.8B, v25.8B, v26.8B, v27.8B}, [x17]\n-    __ ld4r(v0, v1, v2, v3, __ T4H, Address(__ post(r26, 8))); \/\/       ld4r    {v0.4H, v1.4H, v2.4H, v3.4H}, [x26], 8\n-    __ ld4r(v12, v13, v14, v15, __ T2S, Address(__ post(r25, r2))); \/\/  ld4r    {v12.2S, v13.2S, v14.2S, v15.2S}, [x25], x2\n+    __ ld1(v27, __ T8B, Address(r30));                 \/\/       ld1     {v27.8B}, [x30]\n+    __ ld1(v25, v26, __ T16B, Address(__ post(r3, 32))); \/\/     ld1     {v25.16B, v26.16B}, [x3], 32\n+    __ ld1(v30, v31, v0, __ T1D, Address(__ post(r16, r10))); \/\/        ld1     {v30.1D, v31.1D, v0.1D}, [x16], x10\n+    __ ld1(v16, v17, v18, v19, __ T8H, Address(__ post(r19, 64))); \/\/   ld1     {v16.8H, v17.8H, v18.8H, v19.8H}, [x19], 64\n+    __ ld1r(v23, __ T8B, Address(r24));                \/\/       ld1r    {v23.8B}, [x24]\n+    __ ld1r(v8, __ T4S, Address(__ post(r10, 4)));     \/\/       ld1r    {v8.4S}, [x10], 4\n+    __ ld1r(v9, __ T1D, Address(__ post(r20, r23)));   \/\/       ld1r    {v9.1D}, [x20], x23\n+    __ ld2(v2, v3, __ T2D, Address(r3));               \/\/       ld2     {v2.2D, v3.2D}, [x3]\n+    __ ld2(v8, v9, __ T4H, Address(__ post(r30, 16))); \/\/       ld2     {v8.4H, v9.4H}, [x30], 16\n+    __ ld2r(v4, v5, __ T16B, Address(r26));            \/\/       ld2r    {v4.16B, v5.16B}, [x26]\n+    __ ld2r(v3, v4, __ T2S, Address(__ post(r17, 8))); \/\/       ld2r    {v3.2S, v4.2S}, [x17], 8\n+    __ ld2r(v29, v30, __ T2D, Address(__ post(r11, r16))); \/\/   ld2r    {v29.2D, v30.2D}, [x11], x16\n+    __ ld3(v1, v2, v3, __ T4S, Address(__ post(r0, r23))); \/\/   ld3     {v1.4S, v2.4S, v3.4S}, [x0], x23\n+    __ ld3(v0, v1, v2, __ T2S, Address(r21));          \/\/       ld3     {v0.2S, v1.2S, v2.2S}, [x21]\n+    __ ld3r(v5, v6, v7, __ T8H, Address(r7));          \/\/       ld3r    {v5.8H, v6.8H, v7.8H}, [x7]\n+    __ ld3r(v1, v2, v3, __ T4S, Address(__ post(r7, 12))); \/\/   ld3r    {v1.4S, v2.4S, v3.4S}, [x7], 12\n+    __ ld3r(v2, v3, v4, __ T1D, Address(__ post(r5, r15))); \/\/  ld3r    {v2.1D, v3.1D, v4.1D}, [x5], x15\n+    __ ld4(v27, v28, v29, v30, __ T8H, Address(__ post(r29, 64))); \/\/   ld4     {v27.8H, v28.8H, v29.8H, v30.8H}, [x29], 64\n+    __ ld4(v24, v25, v26, v27, __ T8B, Address(__ post(r4, r7))); \/\/    ld4     {v24.8B, v25.8B, v26.8B, v27.8B}, [x4], x7\n+    __ ld4r(v15, v16, v17, v18, __ T8B, Address(r23)); \/\/       ld4r    {v15.8B, v16.8B, v17.8B, v18.8B}, [x23]\n+    __ ld4r(v14, v15, v16, v17, __ T4H, Address(__ post(r21, 8))); \/\/   ld4r    {v14.4H, v15.4H, v16.4H, v17.4H}, [x21], 8\n+    __ ld4r(v20, v21, v22, v23, __ T2S, Address(__ post(r9, r25))); \/\/  ld4r    {v20.2S, v21.2S, v22.2S, v23.2S}, [x9], x25\n@@ -526,26 +574,26 @@\n-    __ addv(v22, __ T8B, v23);                         \/\/       addv    b22, v23.8B\n-    __ addv(v27, __ T16B, v28);                        \/\/       addv    b27, v28.16B\n-    __ addv(v4, __ T4H, v5);                           \/\/       addv    h4, v5.4H\n-    __ addv(v7, __ T8H, v8);                           \/\/       addv    h7, v8.8H\n-    __ addv(v6, __ T4S, v7);                           \/\/       addv    s6, v7.4S\n-    __ smaxv(v1, __ T8B, v2);                          \/\/       smaxv   b1, v2.8B\n-    __ smaxv(v26, __ T16B, v27);                       \/\/       smaxv   b26, v27.16B\n-    __ smaxv(v15, __ T4H, v16);                        \/\/       smaxv   h15, v16.4H\n-    __ smaxv(v2, __ T8H, v3);                          \/\/       smaxv   h2, v3.8H\n-    __ smaxv(v13, __ T4S, v14);                        \/\/       smaxv   s13, v14.4S\n-    __ fmaxv(v13, __ T4S, v14);                        \/\/       fmaxv   s13, v14.4S\n-    __ sminv(v24, __ T8B, v25);                        \/\/       sminv   b24, v25.8B\n-    __ uminv(v23, __ T8B, v24);                        \/\/       uminv   b23, v24.8B\n-    __ sminv(v4, __ T16B, v5);                         \/\/       sminv   b4, v5.16B\n-    __ uminv(v19, __ T16B, v20);                       \/\/       uminv   b19, v20.16B\n-    __ sminv(v15, __ T4H, v16);                        \/\/       sminv   h15, v16.4H\n-    __ uminv(v0, __ T4H, v1);                          \/\/       uminv   h0, v1.4H\n-    __ sminv(v4, __ T8H, v5);                          \/\/       sminv   h4, v5.8H\n-    __ uminv(v20, __ T8H, v21);                        \/\/       uminv   h20, v21.8H\n-    __ sminv(v11, __ T4S, v12);                        \/\/       sminv   s11, v12.4S\n-    __ uminv(v29, __ T4S, v30);                        \/\/       uminv   s29, v30.4S\n-    __ fminv(v15, __ T4S, v16);                        \/\/       fminv   s15, v16.4S\n-    __ fmaxp(v21, v22, __ S);                          \/\/       fmaxp   s21, v22.2S\n-    __ fmaxp(v4, v5, __ D);                            \/\/       fmaxp   d4, v5.2D\n-    __ fminp(v14, v15, __ S);                          \/\/       fminp   s14, v15.2S\n-    __ fminp(v22, v23, __ D);                          \/\/       fminp   d22, v23.2D\n+    __ addv(v23, __ T8B, v24);                         \/\/       addv    b23, v24.8B\n+    __ addv(v26, __ T16B, v27);                        \/\/       addv    b26, v27.16B\n+    __ addv(v5, __ T4H, v6);                           \/\/       addv    h5, v6.4H\n+    __ addv(v6, __ T8H, v7);                           \/\/       addv    h6, v7.8H\n+    __ addv(v15, __ T4S, v16);                         \/\/       addv    s15, v16.4S\n+    __ smaxv(v15, __ T8B, v16);                        \/\/       smaxv   b15, v16.8B\n+    __ smaxv(v25, __ T16B, v26);                       \/\/       smaxv   b25, v26.16B\n+    __ smaxv(v16, __ T4H, v17);                        \/\/       smaxv   h16, v17.4H\n+    __ smaxv(v27, __ T8H, v28);                        \/\/       smaxv   h27, v28.8H\n+    __ smaxv(v24, __ T4S, v25);                        \/\/       smaxv   s24, v25.4S\n+    __ fmaxv(v15, __ T4S, v16);                        \/\/       fmaxv   s15, v16.4S\n+    __ sminv(v25, __ T8B, v26);                        \/\/       sminv   b25, v26.8B\n+    __ uminv(v14, __ T8B, v15);                        \/\/       uminv   b14, v15.8B\n+    __ sminv(v10, __ T16B, v11);                       \/\/       sminv   b10, v11.16B\n+    __ uminv(v13, __ T16B, v14);                       \/\/       uminv   b13, v14.16B\n+    __ sminv(v14, __ T4H, v15);                        \/\/       sminv   h14, v15.4H\n+    __ uminv(v20, __ T4H, v21);                        \/\/       uminv   h20, v21.4H\n+    __ sminv(v1, __ T8H, v2);                          \/\/       sminv   h1, v2.8H\n+    __ uminv(v22, __ T8H, v23);                        \/\/       uminv   h22, v23.8H\n+    __ sminv(v30, __ T4S, v31);                        \/\/       sminv   s30, v31.4S\n+    __ uminv(v14, __ T4S, v15);                        \/\/       uminv   s14, v15.4S\n+    __ fminv(v2, __ T4S, v3);                          \/\/       fminv   s2, v3.4S\n+    __ fmaxp(v6, v7, __ S);                            \/\/       fmaxp   s6, v7.2S\n+    __ fmaxp(v3, v4, __ D);                            \/\/       fmaxp   d3, v4.2D\n+    __ fminp(v7, v8, __ S);                            \/\/       fminp   s7, v8.2S\n+    __ fminp(v24, v25, __ D);                          \/\/       fminp   d24, v25.2D\n@@ -554,7 +602,7 @@\n-    __ absr(v25, __ T8B, v26);                         \/\/       abs     v25.8B, v26.8B\n-    __ absr(v6, __ T16B, v7);                          \/\/       abs     v6.16B, v7.16B\n-    __ absr(v12, __ T4H, v13);                         \/\/       abs     v12.4H, v13.4H\n-    __ absr(v14, __ T8H, v15);                         \/\/       abs     v14.8H, v15.8H\n-    __ absr(v13, __ T2S, v14);                         \/\/       abs     v13.2S, v14.2S\n-    __ absr(v14, __ T4S, v15);                         \/\/       abs     v14.4S, v15.4S\n-    __ absr(v9, __ T2D, v10);                          \/\/       abs     v9.2D, v10.2D\n+    __ absr(v0, __ T8B, v1);                           \/\/       abs     v0.8B, v1.8B\n+    __ absr(v27, __ T16B, v28);                        \/\/       abs     v27.16B, v28.16B\n+    __ absr(v29, __ T4H, v30);                         \/\/       abs     v29.4H, v30.4H\n+    __ absr(v5, __ T8H, v6);                           \/\/       abs     v5.8H, v6.8H\n+    __ absr(v5, __ T2S, v6);                           \/\/       abs     v5.2S, v6.2S\n+    __ absr(v29, __ T4S, v30);                         \/\/       abs     v29.4S, v30.4S\n+    __ absr(v11, __ T2D, v12);                         \/\/       abs     v11.2D, v12.2D\n@@ -562,10 +610,10 @@\n-    __ fabs(v28, __ T4S, v29);                         \/\/       fabs    v28.4S, v29.4S\n-    __ fabs(v10, __ T2D, v11);                         \/\/       fabs    v10.2D, v11.2D\n-    __ fneg(v19, __ T2S, v20);                         \/\/       fneg    v19.2S, v20.2S\n-    __ fneg(v11, __ T4S, v12);                         \/\/       fneg    v11.4S, v12.4S\n-    __ fneg(v17, __ T2D, v18);                         \/\/       fneg    v17.2D, v18.2D\n-    __ fsqrt(v21, __ T2S, v22);                        \/\/       fsqrt   v21.2S, v22.2S\n-    __ fsqrt(v15, __ T4S, v16);                        \/\/       fsqrt   v15.4S, v16.4S\n-    __ fsqrt(v20, __ T2D, v21);                        \/\/       fsqrt   v20.2D, v21.2D\n-    __ notr(v23, __ T8B, v24);                         \/\/       not     v23.8B, v24.8B\n-    __ notr(v26, __ T16B, v27);                        \/\/       not     v26.16B, v27.16B\n+    __ fabs(v0, __ T4S, v1);                           \/\/       fabs    v0.4S, v1.4S\n+    __ fabs(v30, __ T2D, v31);                         \/\/       fabs    v30.2D, v31.2D\n+    __ fneg(v0, __ T2S, v1);                           \/\/       fneg    v0.2S, v1.2S\n+    __ fneg(v17, __ T4S, v18);                         \/\/       fneg    v17.4S, v18.4S\n+    __ fneg(v28, __ T2D, v29);                         \/\/       fneg    v28.2D, v29.2D\n+    __ fsqrt(v25, __ T2S, v26);                        \/\/       fsqrt   v25.2S, v26.2S\n+    __ fsqrt(v9, __ T4S, v10);                         \/\/       fsqrt   v9.4S, v10.4S\n+    __ fsqrt(v25, __ T2D, v26);                        \/\/       fsqrt   v25.2D, v26.2D\n+    __ notr(v12, __ T8B, v13);                         \/\/       not     v12.8B, v13.8B\n+    __ notr(v15, __ T16B, v16);                        \/\/       not     v15.16B, v16.16B\n@@ -574,14 +622,14 @@\n-    __ andr(v5, __ T8B, v6, v7);                       \/\/       and     v5.8B, v6.8B, v7.8B\n-    __ andr(v6, __ T16B, v7, v8);                      \/\/       and     v6.16B, v7.16B, v8.16B\n-    __ orr(v15, __ T8B, v16, v17);                     \/\/       orr     v15.8B, v16.8B, v17.8B\n-    __ orr(v15, __ T16B, v16, v17);                    \/\/       orr     v15.16B, v16.16B, v17.16B\n-    __ eor(v25, __ T8B, v26, v27);                     \/\/       eor     v25.8B, v26.8B, v27.8B\n-    __ eor(v16, __ T16B, v17, v18);                    \/\/       eor     v16.16B, v17.16B, v18.16B\n-    __ addv(v27, __ T8B, v28, v29);                    \/\/       add     v27.8B, v28.8B, v29.8B\n-    __ addv(v24, __ T16B, v25, v26);                   \/\/       add     v24.16B, v25.16B, v26.16B\n-    __ addv(v15, __ T4H, v16, v17);                    \/\/       add     v15.4H, v16.4H, v17.4H\n-    __ addv(v25, __ T8H, v26, v27);                    \/\/       add     v25.8H, v26.8H, v27.8H\n-    __ addv(v14, __ T2S, v15, v16);                    \/\/       add     v14.2S, v15.2S, v16.2S\n-    __ addv(v10, __ T4S, v11, v12);                    \/\/       add     v10.4S, v11.4S, v12.4S\n-    __ addv(v13, __ T2D, v14, v15);                    \/\/       add     v13.2D, v14.2D, v15.2D\n-    __ fadd(v14, __ T2S, v15, v16);                    \/\/       fadd    v14.2S, v15.2S, v16.2S\n+    __ andr(v11, __ T8B, v12, v13);                    \/\/       and     v11.8B, v12.8B, v13.8B\n+    __ andr(v10, __ T16B, v11, v12);                   \/\/       and     v10.16B, v11.16B, v12.16B\n+    __ orr(v17, __ T8B, v18, v19);                     \/\/       orr     v17.8B, v18.8B, v19.8B\n+    __ orr(v24, __ T16B, v25, v26);                    \/\/       orr     v24.16B, v25.16B, v26.16B\n+    __ eor(v21, __ T8B, v22, v23);                     \/\/       eor     v21.8B, v22.8B, v23.8B\n+    __ eor(v23, __ T16B, v24, v25);                    \/\/       eor     v23.16B, v24.16B, v25.16B\n+    __ addv(v0, __ T8B, v1, v2);                       \/\/       add     v0.8B, v1.8B, v2.8B\n+    __ addv(v16, __ T16B, v17, v18);                   \/\/       add     v16.16B, v17.16B, v18.16B\n+    __ addv(v10, __ T4H, v11, v12);                    \/\/       add     v10.4H, v11.4H, v12.4H\n+    __ addv(v6, __ T8H, v7, v8);                       \/\/       add     v6.8H, v7.8H, v8.8H\n+    __ addv(v28, __ T2S, v29, v30);                    \/\/       add     v28.2S, v29.2S, v30.2S\n+    __ addv(v6, __ T4S, v7, v8);                       \/\/       add     v6.4S, v7.4S, v8.4S\n+    __ addv(v5, __ T2D, v6, v7);                       \/\/       add     v5.2D, v6.2D, v7.2D\n+    __ fadd(v5, __ T2S, v6, v7);                       \/\/       fadd    v5.2S, v6.2S, v7.2S\n@@ -589,75 +637,75 @@\n-    __ fadd(v1, __ T2D, v2, v3);                       \/\/       fadd    v1.2D, v2.2D, v3.2D\n-    __ subv(v22, __ T8B, v23, v24);                    \/\/       sub     v22.8B, v23.8B, v24.8B\n-    __ subv(v30, __ T16B, v31, v0);                    \/\/       sub     v30.16B, v31.16B, v0.16B\n-    __ subv(v14, __ T4H, v15, v16);                    \/\/       sub     v14.4H, v15.4H, v16.4H\n-    __ subv(v2, __ T8H, v3, v4);                       \/\/       sub     v2.8H, v3.8H, v4.8H\n-    __ subv(v6, __ T2S, v7, v8);                       \/\/       sub     v6.2S, v7.2S, v8.2S\n-    __ subv(v3, __ T4S, v4, v5);                       \/\/       sub     v3.4S, v4.4S, v5.4S\n-    __ subv(v7, __ T2D, v8, v9);                       \/\/       sub     v7.2D, v8.2D, v9.2D\n-    __ fsub(v24, __ T2S, v25, v26);                    \/\/       fsub    v24.2S, v25.2S, v26.2S\n-    __ fsub(v0, __ T4S, v1, v2);                       \/\/       fsub    v0.4S, v1.4S, v2.4S\n-    __ fsub(v27, __ T2D, v28, v29);                    \/\/       fsub    v27.2D, v28.2D, v29.2D\n-    __ mulv(v29, __ T8B, v30, v31);                    \/\/       mul     v29.8B, v30.8B, v31.8B\n-    __ mulv(v5, __ T16B, v6, v7);                      \/\/       mul     v5.16B, v6.16B, v7.16B\n-    __ mulv(v5, __ T4H, v6, v7);                       \/\/       mul     v5.4H, v6.4H, v7.4H\n-    __ mulv(v29, __ T8H, v30, v31);                    \/\/       mul     v29.8H, v30.8H, v31.8H\n-    __ mulv(v11, __ T2S, v12, v13);                    \/\/       mul     v11.2S, v12.2S, v13.2S\n-    __ mulv(v25, __ T4S, v26, v27);                    \/\/       mul     v25.4S, v26.4S, v27.4S\n-    __ fabd(v0, __ T2S, v1, v2);                       \/\/       fabd    v0.2S, v1.2S, v2.2S\n-    __ fabd(v30, __ T4S, v31, v0);                     \/\/       fabd    v30.4S, v31.4S, v0.4S\n-    __ fabd(v0, __ T2D, v1, v2);                       \/\/       fabd    v0.2D, v1.2D, v2.2D\n-    __ fmul(v17, __ T2S, v18, v19);                    \/\/       fmul    v17.2S, v18.2S, v19.2S\n-    __ fmul(v28, __ T4S, v29, v30);                    \/\/       fmul    v28.4S, v29.4S, v30.4S\n-    __ fmul(v25, __ T2D, v26, v27);                    \/\/       fmul    v25.2D, v26.2D, v27.2D\n-    __ mlav(v9, __ T4H, v10, v11);                     \/\/       mla     v9.4H, v10.4H, v11.4H\n-    __ mlav(v25, __ T8H, v26, v27);                    \/\/       mla     v25.8H, v26.8H, v27.8H\n-    __ mlav(v12, __ T2S, v13, v14);                    \/\/       mla     v12.2S, v13.2S, v14.2S\n-    __ mlav(v15, __ T4S, v16, v17);                    \/\/       mla     v15.4S, v16.4S, v17.4S\n-    __ fmla(v11, __ T2S, v12, v13);                    \/\/       fmla    v11.2S, v12.2S, v13.2S\n-    __ fmla(v10, __ T4S, v11, v12);                    \/\/       fmla    v10.4S, v11.4S, v12.4S\n-    __ fmla(v17, __ T2D, v18, v19);                    \/\/       fmla    v17.2D, v18.2D, v19.2D\n-    __ mlsv(v24, __ T4H, v25, v26);                    \/\/       mls     v24.4H, v25.4H, v26.4H\n-    __ mlsv(v21, __ T8H, v22, v23);                    \/\/       mls     v21.8H, v22.8H, v23.8H\n-    __ mlsv(v23, __ T2S, v24, v25);                    \/\/       mls     v23.2S, v24.2S, v25.2S\n-    __ mlsv(v0, __ T4S, v1, v2);                       \/\/       mls     v0.4S, v1.4S, v2.4S\n-    __ fmls(v16, __ T2S, v17, v18);                    \/\/       fmls    v16.2S, v17.2S, v18.2S\n-    __ fmls(v10, __ T4S, v11, v12);                    \/\/       fmls    v10.4S, v11.4S, v12.4S\n-    __ fmls(v6, __ T2D, v7, v8);                       \/\/       fmls    v6.2D, v7.2D, v8.2D\n-    __ fdiv(v28, __ T2S, v29, v30);                    \/\/       fdiv    v28.2S, v29.2S, v30.2S\n-    __ fdiv(v6, __ T4S, v7, v8);                       \/\/       fdiv    v6.4S, v7.4S, v8.4S\n-    __ fdiv(v5, __ T2D, v6, v7);                       \/\/       fdiv    v5.2D, v6.2D, v7.2D\n-    __ maxv(v5, __ T8B, v6, v7);                       \/\/       smax    v5.8B, v6.8B, v7.8B\n-    __ maxv(v20, __ T16B, v21, v22);                   \/\/       smax    v20.16B, v21.16B, v22.16B\n-    __ maxv(v17, __ T4H, v18, v19);                    \/\/       smax    v17.4H, v18.4H, v19.4H\n-    __ maxv(v15, __ T8H, v16, v17);                    \/\/       smax    v15.8H, v16.8H, v17.8H\n-    __ maxv(v17, __ T2S, v18, v19);                    \/\/       smax    v17.2S, v18.2S, v19.2S\n-    __ maxv(v29, __ T4S, v30, v31);                    \/\/       smax    v29.4S, v30.4S, v31.4S\n-    __ smaxp(v26, __ T8B, v27, v28);                   \/\/       smaxp   v26.8B, v27.8B, v28.8B\n-    __ smaxp(v28, __ T16B, v29, v30);                  \/\/       smaxp   v28.16B, v29.16B, v30.16B\n-    __ smaxp(v1, __ T4H, v2, v3);                      \/\/       smaxp   v1.4H, v2.4H, v3.4H\n-    __ smaxp(v27, __ T8H, v28, v29);                   \/\/       smaxp   v27.8H, v28.8H, v29.8H\n-    __ smaxp(v0, __ T2S, v1, v2);                      \/\/       smaxp   v0.2S, v1.2S, v2.2S\n-    __ smaxp(v20, __ T4S, v21, v22);                   \/\/       smaxp   v20.4S, v21.4S, v22.4S\n-    __ fmax(v28, __ T2S, v29, v30);                    \/\/       fmax    v28.2S, v29.2S, v30.2S\n-    __ fmax(v15, __ T4S, v16, v17);                    \/\/       fmax    v15.4S, v16.4S, v17.4S\n-    __ fmax(v12, __ T2D, v13, v14);                    \/\/       fmax    v12.2D, v13.2D, v14.2D\n-    __ minv(v10, __ T8B, v11, v12);                    \/\/       smin    v10.8B, v11.8B, v12.8B\n-    __ minv(v28, __ T16B, v29, v30);                   \/\/       smin    v28.16B, v29.16B, v30.16B\n-    __ minv(v28, __ T4H, v29, v30);                    \/\/       smin    v28.4H, v29.4H, v30.4H\n-    __ minv(v19, __ T8H, v20, v21);                    \/\/       smin    v19.8H, v20.8H, v21.8H\n-    __ minv(v22, __ T2S, v23, v24);                    \/\/       smin    v22.2S, v23.2S, v24.2S\n-    __ minv(v10, __ T4S, v11, v12);                    \/\/       smin    v10.4S, v11.4S, v12.4S\n-    __ sminp(v4, __ T8B, v5, v6);                      \/\/       sminp   v4.8B, v5.8B, v6.8B\n-    __ sminp(v30, __ T16B, v31, v0);                   \/\/       sminp   v30.16B, v31.16B, v0.16B\n-    __ sminp(v20, __ T4H, v21, v22);                   \/\/       sminp   v20.4H, v21.4H, v22.4H\n-    __ sminp(v8, __ T8H, v9, v10);                     \/\/       sminp   v8.8H, v9.8H, v10.8H\n-    __ sminp(v30, __ T2S, v31, v0);                    \/\/       sminp   v30.2S, v31.2S, v0.2S\n-    __ sminp(v17, __ T4S, v18, v19);                   \/\/       sminp   v17.4S, v18.4S, v19.4S\n-    __ fmin(v10, __ T2S, v11, v12);                    \/\/       fmin    v10.2S, v11.2S, v12.2S\n-    __ fmin(v27, __ T4S, v28, v29);                    \/\/       fmin    v27.4S, v28.4S, v29.4S\n-    __ fmin(v2, __ T2D, v3, v4);                       \/\/       fmin    v2.2D, v3.2D, v4.2D\n-    __ cmeq(v24, __ T8B, v25, v26);                    \/\/       cmeq    v24.8B, v25.8B, v26.8B\n-    __ cmeq(v4, __ T16B, v5, v6);                      \/\/       cmeq    v4.16B, v5.16B, v6.16B\n-    __ cmeq(v3, __ T4H, v4, v5);                       \/\/       cmeq    v3.4H, v4.4H, v5.4H\n-    __ cmeq(v8, __ T8H, v9, v10);                      \/\/       cmeq    v8.8H, v9.8H, v10.8H\n-    __ cmeq(v22, __ T2S, v23, v24);                    \/\/       cmeq    v22.2S, v23.2S, v24.2S\n+    __ fadd(v17, __ T2D, v18, v19);                    \/\/       fadd    v17.2D, v18.2D, v19.2D\n+    __ subv(v15, __ T8B, v16, v17);                    \/\/       sub     v15.8B, v16.8B, v17.8B\n+    __ subv(v17, __ T16B, v18, v19);                   \/\/       sub     v17.16B, v18.16B, v19.16B\n+    __ subv(v29, __ T4H, v30, v31);                    \/\/       sub     v29.4H, v30.4H, v31.4H\n+    __ subv(v26, __ T8H, v27, v28);                    \/\/       sub     v26.8H, v27.8H, v28.8H\n+    __ subv(v28, __ T2S, v29, v30);                    \/\/       sub     v28.2S, v29.2S, v30.2S\n+    __ subv(v1, __ T4S, v2, v3);                       \/\/       sub     v1.4S, v2.4S, v3.4S\n+    __ subv(v27, __ T2D, v28, v29);                    \/\/       sub     v27.2D, v28.2D, v29.2D\n+    __ fsub(v0, __ T2S, v1, v2);                       \/\/       fsub    v0.2S, v1.2S, v2.2S\n+    __ fsub(v20, __ T4S, v21, v22);                    \/\/       fsub    v20.4S, v21.4S, v22.4S\n+    __ fsub(v28, __ T2D, v29, v30);                    \/\/       fsub    v28.2D, v29.2D, v30.2D\n+    __ mulv(v15, __ T8B, v16, v17);                    \/\/       mul     v15.8B, v16.8B, v17.8B\n+    __ mulv(v12, __ T16B, v13, v14);                   \/\/       mul     v12.16B, v13.16B, v14.16B\n+    __ mulv(v10, __ T4H, v11, v12);                    \/\/       mul     v10.4H, v11.4H, v12.4H\n+    __ mulv(v28, __ T8H, v29, v30);                    \/\/       mul     v28.8H, v29.8H, v30.8H\n+    __ mulv(v28, __ T2S, v29, v30);                    \/\/       mul     v28.2S, v29.2S, v30.2S\n+    __ mulv(v19, __ T4S, v20, v21);                    \/\/       mul     v19.4S, v20.4S, v21.4S\n+    __ fabd(v22, __ T2S, v23, v24);                    \/\/       fabd    v22.2S, v23.2S, v24.2S\n+    __ fabd(v10, __ T4S, v11, v12);                    \/\/       fabd    v10.4S, v11.4S, v12.4S\n+    __ fabd(v4, __ T2D, v5, v6);                       \/\/       fabd    v4.2D, v5.2D, v6.2D\n+    __ fmul(v30, __ T2S, v31, v0);                     \/\/       fmul    v30.2S, v31.2S, v0.2S\n+    __ fmul(v20, __ T4S, v21, v22);                    \/\/       fmul    v20.4S, v21.4S, v22.4S\n+    __ fmul(v8, __ T2D, v9, v10);                      \/\/       fmul    v8.2D, v9.2D, v10.2D\n+    __ mlav(v30, __ T4H, v31, v0);                     \/\/       mla     v30.4H, v31.4H, v0.4H\n+    __ mlav(v17, __ T8H, v18, v19);                    \/\/       mla     v17.8H, v18.8H, v19.8H\n+    __ mlav(v10, __ T2S, v11, v12);                    \/\/       mla     v10.2S, v11.2S, v12.2S\n+    __ mlav(v27, __ T4S, v28, v29);                    \/\/       mla     v27.4S, v28.4S, v29.4S\n+    __ fmla(v2, __ T2S, v3, v4);                       \/\/       fmla    v2.2S, v3.2S, v4.2S\n+    __ fmla(v24, __ T4S, v25, v26);                    \/\/       fmla    v24.4S, v25.4S, v26.4S\n+    __ fmla(v4, __ T2D, v5, v6);                       \/\/       fmla    v4.2D, v5.2D, v6.2D\n+    __ mlsv(v3, __ T4H, v4, v5);                       \/\/       mls     v3.4H, v4.4H, v5.4H\n+    __ mlsv(v8, __ T8H, v9, v10);                      \/\/       mls     v8.8H, v9.8H, v10.8H\n+    __ mlsv(v22, __ T2S, v23, v24);                    \/\/       mls     v22.2S, v23.2S, v24.2S\n+    __ mlsv(v17, __ T4S, v18, v19);                    \/\/       mls     v17.4S, v18.4S, v19.4S\n+    __ fmls(v13, __ T2S, v14, v15);                    \/\/       fmls    v13.2S, v14.2S, v15.2S\n+    __ fmls(v4, __ T4S, v5, v6);                       \/\/       fmls    v4.4S, v5.4S, v6.4S\n+    __ fmls(v28, __ T2D, v29, v30);                    \/\/       fmls    v28.2D, v29.2D, v30.2D\n+    __ fdiv(v23, __ T2S, v24, v25);                    \/\/       fdiv    v23.2S, v24.2S, v25.2S\n+    __ fdiv(v21, __ T4S, v22, v23);                    \/\/       fdiv    v21.4S, v22.4S, v23.4S\n+    __ fdiv(v25, __ T2D, v26, v27);                    \/\/       fdiv    v25.2D, v26.2D, v27.2D\n+    __ maxv(v24, __ T8B, v25, v26);                    \/\/       smax    v24.8B, v25.8B, v26.8B\n+    __ maxv(v3, __ T16B, v4, v5);                      \/\/       smax    v3.16B, v4.16B, v5.16B\n+    __ maxv(v23, __ T4H, v24, v25);                    \/\/       smax    v23.4H, v24.4H, v25.4H\n+    __ maxv(v26, __ T8H, v27, v28);                    \/\/       smax    v26.8H, v27.8H, v28.8H\n+    __ maxv(v23, __ T2S, v24, v25);                    \/\/       smax    v23.2S, v24.2S, v25.2S\n+    __ maxv(v14, __ T4S, v15, v16);                    \/\/       smax    v14.4S, v15.4S, v16.4S\n+    __ smaxp(v21, __ T8B, v22, v23);                   \/\/       smaxp   v21.8B, v22.8B, v23.8B\n+    __ smaxp(v3, __ T16B, v4, v5);                     \/\/       smaxp   v3.16B, v4.16B, v5.16B\n+    __ smaxp(v23, __ T4H, v24, v25);                   \/\/       smaxp   v23.4H, v24.4H, v25.4H\n+    __ smaxp(v8, __ T8H, v9, v10);                     \/\/       smaxp   v8.8H, v9.8H, v10.8H\n+    __ smaxp(v24, __ T2S, v25, v26);                   \/\/       smaxp   v24.2S, v25.2S, v26.2S\n+    __ smaxp(v19, __ T4S, v20, v21);                   \/\/       smaxp   v19.4S, v20.4S, v21.4S\n+    __ fmax(v15, __ T2S, v16, v17);                    \/\/       fmax    v15.2S, v16.2S, v17.2S\n+    __ fmax(v16, __ T4S, v17, v18);                    \/\/       fmax    v16.4S, v17.4S, v18.4S\n+    __ fmax(v2, __ T2D, v3, v4);                       \/\/       fmax    v2.2D, v3.2D, v4.2D\n+    __ minv(v1, __ T8B, v2, v3);                       \/\/       smin    v1.8B, v2.8B, v3.8B\n+    __ minv(v0, __ T16B, v1, v2);                      \/\/       smin    v0.16B, v1.16B, v2.16B\n+    __ minv(v24, __ T4H, v25, v26);                    \/\/       smin    v24.4H, v25.4H, v26.4H\n+    __ minv(v4, __ T8H, v5, v6);                       \/\/       smin    v4.8H, v5.8H, v6.8H\n+    __ minv(v3, __ T2S, v4, v5);                       \/\/       smin    v3.2S, v4.2S, v5.2S\n+    __ minv(v11, __ T4S, v12, v13);                    \/\/       smin    v11.4S, v12.4S, v13.4S\n+    __ sminp(v30, __ T8B, v31, v0);                    \/\/       sminp   v30.8B, v31.8B, v0.8B\n+    __ sminp(v27, __ T16B, v28, v29);                  \/\/       sminp   v27.16B, v28.16B, v29.16B\n+    __ sminp(v9, __ T4H, v10, v11);                    \/\/       sminp   v9.4H, v10.4H, v11.4H\n+    __ sminp(v25, __ T8H, v26, v27);                   \/\/       sminp   v25.8H, v26.8H, v27.8H\n+    __ sminp(v2, __ T2S, v3, v4);                      \/\/       sminp   v2.2S, v3.2S, v4.2S\n+    __ sminp(v12, __ T4S, v13, v14);                   \/\/       sminp   v12.4S, v13.4S, v14.4S\n+    __ fmin(v17, __ T2S, v18, v19);                    \/\/       fmin    v17.2S, v18.2S, v19.2S\n+    __ fmin(v30, __ T4S, v31, v0);                     \/\/       fmin    v30.4S, v31.4S, v0.4S\n+    __ fmin(v1, __ T2D, v2, v3);                       \/\/       fmin    v1.2D, v2.2D, v3.2D\n+    __ cmeq(v12, __ T8B, v13, v14);                    \/\/       cmeq    v12.8B, v13.8B, v14.8B\n+    __ cmeq(v28, __ T16B, v29, v30);                   \/\/       cmeq    v28.16B, v29.16B, v30.16B\n+    __ cmeq(v0, __ T4H, v1, v2);                       \/\/       cmeq    v0.4H, v1.4H, v2.4H\n+    __ cmeq(v17, __ T8H, v18, v19);                    \/\/       cmeq    v17.8H, v18.8H, v19.8H\n+    __ cmeq(v12, __ T2S, v13, v14);                    \/\/       cmeq    v12.2S, v13.2S, v14.2S\n@@ -665,15 +713,15 @@\n-    __ cmeq(v13, __ T2D, v14, v15);                    \/\/       cmeq    v13.2D, v14.2D, v15.2D\n-    __ fcmeq(v4, __ T2S, v5, v6);                      \/\/       fcmeq   v4.2S, v5.2S, v6.2S\n-    __ fcmeq(v28, __ T4S, v29, v30);                   \/\/       fcmeq   v28.4S, v29.4S, v30.4S\n-    __ fcmeq(v23, __ T2D, v24, v25);                   \/\/       fcmeq   v23.2D, v24.2D, v25.2D\n-    __ cmgt(v21, __ T8B, v22, v23);                    \/\/       cmgt    v21.8B, v22.8B, v23.8B\n-    __ cmgt(v25, __ T16B, v26, v27);                   \/\/       cmgt    v25.16B, v26.16B, v27.16B\n-    __ cmgt(v24, __ T4H, v25, v26);                    \/\/       cmgt    v24.4H, v25.4H, v26.4H\n-    __ cmgt(v3, __ T8H, v4, v5);                       \/\/       cmgt    v3.8H, v4.8H, v5.8H\n-    __ cmgt(v23, __ T2S, v24, v25);                    \/\/       cmgt    v23.2S, v24.2S, v25.2S\n-    __ cmgt(v26, __ T4S, v27, v28);                    \/\/       cmgt    v26.4S, v27.4S, v28.4S\n-    __ cmgt(v23, __ T2D, v24, v25);                    \/\/       cmgt    v23.2D, v24.2D, v25.2D\n-    __ cmhi(v14, __ T8B, v15, v16);                    \/\/       cmhi    v14.8B, v15.8B, v16.8B\n-    __ cmhi(v21, __ T16B, v22, v23);                   \/\/       cmhi    v21.16B, v22.16B, v23.16B\n-    __ cmhi(v3, __ T4H, v4, v5);                       \/\/       cmhi    v3.4H, v4.4H, v5.4H\n-    __ cmhi(v23, __ T8H, v24, v25);                    \/\/       cmhi    v23.8H, v24.8H, v25.8H\n+    __ cmeq(v21, __ T2D, v22, v23);                    \/\/       cmeq    v21.2D, v22.2D, v23.2D\n+    __ fcmeq(v12, __ T2S, v13, v14);                   \/\/       fcmeq   v12.2S, v13.2S, v14.2S\n+    __ fcmeq(v27, __ T4S, v28, v29);                   \/\/       fcmeq   v27.4S, v28.4S, v29.4S\n+    __ fcmeq(v29, __ T2D, v30, v31);                   \/\/       fcmeq   v29.2D, v30.2D, v31.2D\n+    __ cmgt(v30, __ T8B, v31, v0);                     \/\/       cmgt    v30.8B, v31.8B, v0.8B\n+    __ cmgt(v1, __ T16B, v2, v3);                      \/\/       cmgt    v1.16B, v2.16B, v3.16B\n+    __ cmgt(v25, __ T4H, v26, v27);                    \/\/       cmgt    v25.4H, v26.4H, v27.4H\n+    __ cmgt(v27, __ T8H, v28, v29);                    \/\/       cmgt    v27.8H, v28.8H, v29.8H\n+    __ cmgt(v4, __ T2S, v5, v6);                       \/\/       cmgt    v4.2S, v5.2S, v6.2S\n+    __ cmgt(v29, __ T4S, v30, v31);                    \/\/       cmgt    v29.4S, v30.4S, v31.4S\n+    __ cmgt(v3, __ T2D, v4, v5);                       \/\/       cmgt    v3.2D, v4.2D, v5.2D\n+    __ cmhi(v6, __ T8B, v7, v8);                       \/\/       cmhi    v6.8B, v7.8B, v8.8B\n+    __ cmhi(v29, __ T16B, v30, v31);                   \/\/       cmhi    v29.16B, v30.16B, v31.16B\n+    __ cmhi(v25, __ T4H, v26, v27);                    \/\/       cmhi    v25.4H, v26.4H, v27.4H\n+    __ cmhi(v17, __ T8H, v18, v19);                    \/\/       cmhi    v17.8H, v18.8H, v19.8H\n@@ -681,19 +729,19 @@\n-    __ cmhi(v24, __ T4S, v25, v26);                    \/\/       cmhi    v24.4S, v25.4S, v26.4S\n-    __ cmhi(v19, __ T2D, v20, v21);                    \/\/       cmhi    v19.2D, v20.2D, v21.2D\n-    __ cmhs(v15, __ T8B, v16, v17);                    \/\/       cmhs    v15.8B, v16.8B, v17.8B\n-    __ cmhs(v16, __ T16B, v17, v18);                   \/\/       cmhs    v16.16B, v17.16B, v18.16B\n-    __ cmhs(v2, __ T4H, v3, v4);                       \/\/       cmhs    v2.4H, v3.4H, v4.4H\n-    __ cmhs(v1, __ T8H, v2, v3);                       \/\/       cmhs    v1.8H, v2.8H, v3.8H\n-    __ cmhs(v0, __ T2S, v1, v2);                       \/\/       cmhs    v0.2S, v1.2S, v2.2S\n-    __ cmhs(v24, __ T4S, v25, v26);                    \/\/       cmhs    v24.4S, v25.4S, v26.4S\n-    __ cmhs(v4, __ T2D, v5, v6);                       \/\/       cmhs    v4.2D, v5.2D, v6.2D\n-    __ fcmgt(v3, __ T2S, v4, v5);                      \/\/       fcmgt   v3.2S, v4.2S, v5.2S\n-    __ fcmgt(v11, __ T4S, v12, v13);                   \/\/       fcmgt   v11.4S, v12.4S, v13.4S\n-    __ fcmgt(v30, __ T2D, v31, v0);                    \/\/       fcmgt   v30.2D, v31.2D, v0.2D\n-    __ cmge(v27, __ T8B, v28, v29);                    \/\/       cmge    v27.8B, v28.8B, v29.8B\n-    __ cmge(v9, __ T16B, v10, v11);                    \/\/       cmge    v9.16B, v10.16B, v11.16B\n-    __ cmge(v25, __ T4H, v26, v27);                    \/\/       cmge    v25.4H, v26.4H, v27.4H\n-    __ cmge(v2, __ T8H, v3, v4);                       \/\/       cmge    v2.8H, v3.8H, v4.8H\n-    __ cmge(v12, __ T2S, v13, v14);                    \/\/       cmge    v12.2S, v13.2S, v14.2S\n-    __ cmge(v17, __ T4S, v18, v19);                    \/\/       cmge    v17.4S, v18.4S, v19.4S\n-    __ cmge(v30, __ T2D, v31, v0);                     \/\/       cmge    v30.2D, v31.2D, v0.2D\n+    __ cmhi(v7, __ T4S, v8, v9);                       \/\/       cmhi    v7.4S, v8.4S, v9.4S\n+    __ cmhi(v12, __ T2D, v13, v14);                    \/\/       cmhi    v12.2D, v13.2D, v14.2D\n+    __ cmhs(v0, __ T8B, v1, v2);                       \/\/       cmhs    v0.8B, v1.8B, v2.8B\n+    __ cmhs(v19, __ T16B, v20, v21);                   \/\/       cmhs    v19.16B, v20.16B, v21.16B\n+    __ cmhs(v1, __ T4H, v2, v3);                       \/\/       cmhs    v1.4H, v2.4H, v3.4H\n+    __ cmhs(v23, __ T8H, v24, v25);                    \/\/       cmhs    v23.8H, v24.8H, v25.8H\n+    __ cmhs(v2, __ T2S, v3, v4);                       \/\/       cmhs    v2.2S, v3.2S, v4.2S\n+    __ cmhs(v0, __ T4S, v1, v2);                       \/\/       cmhs    v0.4S, v1.4S, v2.4S\n+    __ cmhs(v8, __ T2D, v9, v10);                      \/\/       cmhs    v8.2D, v9.2D, v10.2D\n+    __ fcmgt(v23, __ T2S, v24, v25);                   \/\/       fcmgt   v23.2S, v24.2S, v25.2S\n+    __ fcmgt(v25, __ T4S, v26, v27);                   \/\/       fcmgt   v25.4S, v26.4S, v27.4S\n+    __ fcmgt(v15, __ T2D, v16, v17);                   \/\/       fcmgt   v15.2D, v16.2D, v17.2D\n+    __ cmge(v29, __ T8B, v30, v31);                    \/\/       cmge    v29.8B, v30.8B, v31.8B\n+    __ cmge(v3, __ T16B, v4, v5);                      \/\/       cmge    v3.16B, v4.16B, v5.16B\n+    __ cmge(v10, __ T4H, v11, v12);                    \/\/       cmge    v10.4H, v11.4H, v12.4H\n+    __ cmge(v22, __ T8H, v23, v24);                    \/\/       cmge    v22.8H, v23.8H, v24.8H\n+    __ cmge(v10, __ T2S, v11, v12);                    \/\/       cmge    v10.2S, v11.2S, v12.2S\n+    __ cmge(v4, __ T4S, v5, v6);                       \/\/       cmge    v4.4S, v5.4S, v6.4S\n+    __ cmge(v17, __ T2D, v18, v19);                    \/\/       cmge    v17.2D, v18.2D, v19.2D\n@@ -701,2 +749,2 @@\n-    __ fcmge(v12, __ T4S, v13, v14);                   \/\/       fcmge   v12.4S, v13.4S, v14.4S\n-    __ fcmge(v28, __ T2D, v29, v30);                   \/\/       fcmge   v28.2D, v29.2D, v30.2D\n+    __ fcmge(v11, __ T4S, v12, v13);                   \/\/       fcmge   v11.4S, v12.4S, v13.4S\n+    __ fcmge(v7, __ T2D, v8, v9);                      \/\/       fcmge   v7.2D, v8.2D, v9.2D\n@@ -930,9 +978,9 @@\n-    __ swp(Assembler::xword, r0, r19, r12);            \/\/       swp     x0, x19, [x12]\n-    __ ldadd(Assembler::xword, r17, r22, r13);         \/\/       ldadd   x17, x22, [x13]\n-    __ ldbic(Assembler::xword, r28, r30, sp);          \/\/       ldclr   x28, x30, [sp]\n-    __ ldeor(Assembler::xword, r1, r26, r28);          \/\/       ldeor   x1, x26, [x28]\n-    __ ldorr(Assembler::xword, r4, r30, r4);           \/\/       ldset   x4, x30, [x4]\n-    __ ldsmin(Assembler::xword, r6, r30, r26);         \/\/       ldsmin  x6, x30, [x26]\n-    __ ldsmax(Assembler::xword, r16, r9, r8);          \/\/       ldsmax  x16, x9, [x8]\n-    __ ldumin(Assembler::xword, r12, r0, r20);         \/\/       ldumin  x12, x0, [x20]\n-    __ ldumax(Assembler::xword, r1, r24, r2);          \/\/       ldumax  x1, x24, [x2]\n+    __ swp(Assembler::xword, r10, r15, r17);           \/\/       swp     x10, x15, [x17]\n+    __ ldadd(Assembler::xword, r2, r10, r12);          \/\/       ldadd   x2, x10, [x12]\n+    __ ldbic(Assembler::xword, r12, r15, r13);         \/\/       ldclr   x12, x15, [x13]\n+    __ ldeor(Assembler::xword, r2, r7, r20);           \/\/       ldeor   x2, x7, [x20]\n+    __ ldorr(Assembler::xword, r26, r16, r4);          \/\/       ldset   x26, x16, [x4]\n+    __ ldsmin(Assembler::xword, r2, r4, r12);          \/\/       ldsmin  x2, x4, [x12]\n+    __ ldsmax(Assembler::xword, r16, r21, r16);        \/\/       ldsmax  x16, x21, [x16]\n+    __ ldumin(Assembler::xword, r16, r11, r21);        \/\/       ldumin  x16, x11, [x21]\n+    __ ldumax(Assembler::xword, r23, r12, r26);        \/\/       ldumax  x23, x12, [x26]\n@@ -941,9 +989,9 @@\n-    __ swpa(Assembler::xword, r0, r9, r24);            \/\/       swpa    x0, x9, [x24]\n-    __ ldadda(Assembler::xword, r26, r16, r30);        \/\/       ldadda  x26, x16, [x30]\n-    __ ldbica(Assembler::xword, r3, r10, r23);         \/\/       ldclra  x3, x10, [x23]\n-    __ ldeora(Assembler::xword, r10, r4, r15);         \/\/       ldeora  x10, x4, [x15]\n-    __ ldorra(Assembler::xword, r2, r11, r8);          \/\/       ldseta  x2, x11, [x8]\n-    __ ldsmina(Assembler::xword, r10, r15, r17);       \/\/       ldsmina x10, x15, [x17]\n-    __ ldsmaxa(Assembler::xword, r2, r10, r12);        \/\/       ldsmaxa x2, x10, [x12]\n-    __ ldumina(Assembler::xword, r12, r15, r13);       \/\/       ldumina x12, x15, [x13]\n-    __ ldumaxa(Assembler::xword, r2, r7, r20);         \/\/       ldumaxa x2, x7, [x20]\n+    __ swpa(Assembler::xword, r23, r28, r14);          \/\/       swpa    x23, x28, [x14]\n+    __ ldadda(Assembler::xword, r11, r24, r1);         \/\/       ldadda  x11, x24, [x1]\n+    __ ldbica(Assembler::xword, r12, zr, r10);         \/\/       ldclra  x12, xzr, [x10]\n+    __ ldeora(Assembler::xword, r16, r7, r2);          \/\/       ldeora  x16, x7, [x2]\n+    __ ldorra(Assembler::xword, r3, r13, r19);         \/\/       ldseta  x3, x13, [x19]\n+    __ ldsmina(Assembler::xword, r17, r16, r3);        \/\/       ldsmina x17, x16, [x3]\n+    __ ldsmaxa(Assembler::xword, r1, r11, r30);        \/\/       ldsmaxa x1, x11, [x30]\n+    __ ldumina(Assembler::xword, r5, r8, r15);         \/\/       ldumina x5, x8, [x15]\n+    __ ldumaxa(Assembler::xword, r29, r30, r0);        \/\/       ldumaxa x29, x30, [x0]\n@@ -952,9 +1000,9 @@\n-    __ swpal(Assembler::xword, r26, r16, r4);          \/\/       swpal   x26, x16, [x4]\n-    __ ldaddal(Assembler::xword, r2, r4, r12);         \/\/       ldaddal x2, x4, [x12]\n-    __ ldbical(Assembler::xword, r16, r21, r16);       \/\/       ldclral x16, x21, [x16]\n-    __ ldeoral(Assembler::xword, r16, r11, r21);       \/\/       ldeoral x16, x11, [x21]\n-    __ ldorral(Assembler::xword, r23, r12, r26);       \/\/       ldsetal x23, x12, [x26]\n-    __ ldsminal(Assembler::xword, r23, r28, r14);      \/\/       ldsminal        x23, x28, [x14]\n-    __ ldsmaxal(Assembler::xword, r11, r24, r1);       \/\/       ldsmaxal        x11, x24, [x1]\n-    __ lduminal(Assembler::xword, r12, zr, r10);       \/\/       lduminal        x12, xzr, [x10]\n-    __ ldumaxal(Assembler::xword, r16, r7, r2);        \/\/       ldumaxal        x16, x7, [x2]\n+    __ swpal(Assembler::xword, r20, r7, r20);          \/\/       swpal   x20, x7, [x20]\n+    __ ldaddal(Assembler::xword, r23, r28, r21);       \/\/       ldaddal x23, x28, [x21]\n+    __ ldbical(Assembler::xword, r27, r25, r5);        \/\/       ldclral x27, x25, [x5]\n+    __ ldeoral(Assembler::xword, r1, r23, r16);        \/\/       ldeoral x1, x23, [x16]\n+    __ ldorral(Assembler::xword, zr, r5, r12);         \/\/       ldsetal xzr, x5, [x12]\n+    __ ldsminal(Assembler::xword, r9, r28, r15);       \/\/       ldsminal        x9, x28, [x15]\n+    __ ldsmaxal(Assembler::xword, r29, r22, sp);       \/\/       ldsmaxal        x29, x22, [sp]\n+    __ lduminal(Assembler::xword, r19, zr, r5);        \/\/       lduminal        x19, xzr, [x5]\n+    __ ldumaxal(Assembler::xword, r14, r16, sp);       \/\/       ldumaxal        x14, x16, [sp]\n@@ -963,9 +1011,9 @@\n-    __ swpl(Assembler::xword, r3, r13, r19);           \/\/       swpl    x3, x13, [x19]\n-    __ ldaddl(Assembler::xword, r17, r16, r3);         \/\/       ldaddl  x17, x16, [x3]\n-    __ ldbicl(Assembler::xword, r1, r11, r30);         \/\/       ldclrl  x1, x11, [x30]\n-    __ ldeorl(Assembler::xword, r5, r8, r15);          \/\/       ldeorl  x5, x8, [x15]\n-    __ ldorrl(Assembler::xword, r29, r30, r0);         \/\/       ldsetl  x29, x30, [x0]\n-    __ ldsminl(Assembler::xword, r20, r7, r20);        \/\/       ldsminl x20, x7, [x20]\n-    __ ldsmaxl(Assembler::xword, r23, r28, r21);       \/\/       ldsmaxl x23, x28, [x21]\n-    __ lduminl(Assembler::xword, r27, r25, r5);        \/\/       lduminl x27, x25, [x5]\n-    __ ldumaxl(Assembler::xword, r1, r23, r16);        \/\/       ldumaxl x1, x23, [x16]\n+    __ swpl(Assembler::xword, r16, r27, r20);          \/\/       swpl    x16, x27, [x20]\n+    __ ldaddl(Assembler::xword, r16, r12, r11);        \/\/       ldaddl  x16, x12, [x11]\n+    __ ldbicl(Assembler::xword, r9, r6, r30);          \/\/       ldclrl  x9, x6, [x30]\n+    __ ldeorl(Assembler::xword, r17, r27, r28);        \/\/       ldeorl  x17, x27, [x28]\n+    __ ldorrl(Assembler::xword, r30, r7, r10);         \/\/       ldsetl  x30, x7, [x10]\n+    __ ldsminl(Assembler::xword, r20, r10, r4);        \/\/       ldsminl x20, x10, [x4]\n+    __ ldsmaxl(Assembler::xword, r24, r17, r17);       \/\/       ldsmaxl x24, x17, [x17]\n+    __ lduminl(Assembler::xword, r22, r3, r29);        \/\/       lduminl x22, x3, [x29]\n+    __ ldumaxl(Assembler::xword, r15, r22, r19);       \/\/       ldumaxl x15, x22, [x19]\n@@ -974,9 +1022,9 @@\n-    __ swp(Assembler::word, zr, r5, r12);              \/\/       swp     wzr, w5, [x12]\n-    __ ldadd(Assembler::word, r9, r28, r15);           \/\/       ldadd   w9, w28, [x15]\n-    __ ldbic(Assembler::word, r29, r22, sp);           \/\/       ldclr   w29, w22, [sp]\n-    __ ldeor(Assembler::word, r19, zr, r5);            \/\/       ldeor   w19, wzr, [x5]\n-    __ ldorr(Assembler::word, r14, r16, sp);           \/\/       ldset   w14, w16, [sp]\n-    __ ldsmin(Assembler::word, r16, r27, r20);         \/\/       ldsmin  w16, w27, [x20]\n-    __ ldsmax(Assembler::word, r16, r12, r11);         \/\/       ldsmax  w16, w12, [x11]\n-    __ ldumin(Assembler::word, r9, r6, r30);           \/\/       ldumin  w9, w6, [x30]\n-    __ ldumax(Assembler::word, r17, r27, r28);         \/\/       ldumax  w17, w27, [x28]\n+    __ swp(Assembler::word, r19, r22, r2);             \/\/       swp     w19, w22, [x2]\n+    __ ldadd(Assembler::word, r15, r6, r12);           \/\/       ldadd   w15, w6, [x12]\n+    __ ldbic(Assembler::word, r16, r11, r13);          \/\/       ldclr   w16, w11, [x13]\n+    __ ldeor(Assembler::word, r23, r1, r30);           \/\/       ldeor   w23, w1, [x30]\n+    __ ldorr(Assembler::word, r19, r5, r17);           \/\/       ldset   w19, w5, [x17]\n+    __ ldsmin(Assembler::word, r2, r16, r22);          \/\/       ldsmin  w2, w16, [x22]\n+    __ ldsmax(Assembler::word, r13, r10, r21);         \/\/       ldsmax  w13, w10, [x21]\n+    __ ldumin(Assembler::word, r29, r27, r12);         \/\/       ldumin  w29, w27, [x12]\n+    __ ldumax(Assembler::word, r27, r3, r1);           \/\/       ldumax  w27, w3, [x1]\n@@ -985,9 +1033,9 @@\n-    __ swpa(Assembler::word, r30, r7, r10);            \/\/       swpa    w30, w7, [x10]\n-    __ ldadda(Assembler::word, r20, r10, r4);          \/\/       ldadda  w20, w10, [x4]\n-    __ ldbica(Assembler::word, r24, r17, r17);         \/\/       ldclra  w24, w17, [x17]\n-    __ ldeora(Assembler::word, r22, r3, r29);          \/\/       ldeora  w22, w3, [x29]\n-    __ ldorra(Assembler::word, r15, r22, r19);         \/\/       ldseta  w15, w22, [x19]\n-    __ ldsmina(Assembler::word, r19, r22, r2);         \/\/       ldsmina w19, w22, [x2]\n-    __ ldsmaxa(Assembler::word, r15, r6, r12);         \/\/       ldsmaxa w15, w6, [x12]\n-    __ ldumina(Assembler::word, r16, r11, r13);        \/\/       ldumina w16, w11, [x13]\n-    __ ldumaxa(Assembler::word, r23, r1, r30);         \/\/       ldumaxa w23, w1, [x30]\n+    __ swpa(Assembler::word, zr, r24, r19);            \/\/       swpa    wzr, w24, [x19]\n+    __ ldadda(Assembler::word, r17, r9, r28);          \/\/       ldadda  w17, w9, [x28]\n+    __ ldbica(Assembler::word, r27, r15, r7);          \/\/       ldclra  w27, w15, [x7]\n+    __ ldeora(Assembler::word, r21, r23, sp);          \/\/       ldeora  w21, w23, [sp]\n+    __ ldorra(Assembler::word, r25, r2, sp);           \/\/       ldseta  w25, w2, [sp]\n+    __ ldsmina(Assembler::word, r27, r16, r10);        \/\/       ldsmina w27, w16, [x10]\n+    __ ldsmaxa(Assembler::word, r23, r19, r3);         \/\/       ldsmaxa w23, w19, [x3]\n+    __ ldumina(Assembler::word, r16, r0, r25);         \/\/       ldumina w16, w0, [x25]\n+    __ ldumaxa(Assembler::word, r26, r23, r2);         \/\/       ldumaxa w26, w23, [x2]\n@@ -996,9 +1044,9 @@\n-    __ swpal(Assembler::word, r19, r5, r17);           \/\/       swpal   w19, w5, [x17]\n-    __ ldaddal(Assembler::word, r2, r16, r22);         \/\/       ldaddal w2, w16, [x22]\n-    __ ldbical(Assembler::word, r13, r10, r21);        \/\/       ldclral w13, w10, [x21]\n-    __ ldeoral(Assembler::word, r29, r27, r12);        \/\/       ldeoral w29, w27, [x12]\n-    __ ldorral(Assembler::word, r27, r3, r1);          \/\/       ldsetal w27, w3, [x1]\n-    __ ldsminal(Assembler::word, zr, r24, r19);        \/\/       ldsminal        wzr, w24, [x19]\n-    __ ldsmaxal(Assembler::word, r17, r9, r28);        \/\/       ldsmaxal        w17, w9, [x28]\n-    __ lduminal(Assembler::word, r27, r15, r7);        \/\/       lduminal        w27, w15, [x7]\n-    __ ldumaxal(Assembler::word, r21, r23, sp);        \/\/       ldumaxal        w21, w23, [sp]\n+    __ swpal(Assembler::word, r16, r12, r4);           \/\/       swpal   w16, w12, [x4]\n+    __ ldaddal(Assembler::word, r28, r30, r29);        \/\/       ldaddal w28, w30, [x29]\n+    __ ldbical(Assembler::word, r16, r27, r6);         \/\/       ldclral w16, w27, [x6]\n+    __ ldeoral(Assembler::word, r9, r29, r15);         \/\/       ldeoral w9, w29, [x15]\n+    __ ldorral(Assembler::word, r7, r4, r7);           \/\/       ldsetal w7, w4, [x7]\n+    __ ldsminal(Assembler::word, r15, r9, r23);        \/\/       ldsminal        w15, w9, [x23]\n+    __ ldsmaxal(Assembler::word, r8, r2, r28);         \/\/       ldsmaxal        w8, w2, [x28]\n+    __ lduminal(Assembler::word, r21, zr, r5);         \/\/       lduminal        w21, wzr, [x5]\n+    __ ldumaxal(Assembler::word, r27, r0, r17);        \/\/       ldumaxal        w27, w0, [x17]\n@@ -1007,9 +1055,9 @@\n-    __ swpl(Assembler::word, r25, r2, sp);             \/\/       swpl    w25, w2, [sp]\n-    __ ldaddl(Assembler::word, r27, r16, r10);         \/\/       ldaddl  w27, w16, [x10]\n-    __ ldbicl(Assembler::word, r23, r19, r3);          \/\/       ldclrl  w23, w19, [x3]\n-    __ ldeorl(Assembler::word, r16, r0, r25);          \/\/       ldeorl  w16, w0, [x25]\n-    __ ldorrl(Assembler::word, r26, r23, r2);          \/\/       ldsetl  w26, w23, [x2]\n-    __ ldsminl(Assembler::word, r16, r12, r4);         \/\/       ldsminl w16, w12, [x4]\n-    __ ldsmaxl(Assembler::word, r28, r30, r29);        \/\/       ldsmaxl w28, w30, [x29]\n-    __ lduminl(Assembler::word, r16, r27, r6);         \/\/       lduminl w16, w27, [x6]\n-    __ ldumaxl(Assembler::word, r9, r29, r15);         \/\/       ldumaxl w9, w29, [x15]\n+    __ swpl(Assembler::word, r15, r4, r26);            \/\/       swpl    w15, w4, [x26]\n+    __ ldaddl(Assembler::word, r8, r28, r22);          \/\/       ldaddl  w8, w28, [x22]\n+    __ ldbicl(Assembler::word, r27, r27, r25);         \/\/       ldclrl  w27, w27, [x25]\n+    __ ldeorl(Assembler::word, r23, r0, r4);           \/\/       ldeorl  w23, w0, [x4]\n+    __ ldorrl(Assembler::word, r6, r16, r0);           \/\/       ldsetl  w6, w16, [x0]\n+    __ ldsminl(Assembler::word, r4, r15, r1);          \/\/       ldsminl w4, w15, [x1]\n+    __ ldsmaxl(Assembler::word, r10, r7, r5);          \/\/       ldsmaxl w10, w7, [x5]\n+    __ lduminl(Assembler::word, r10, r28, r7);         \/\/       lduminl w10, w28, [x7]\n+    __ ldumaxl(Assembler::word, r20, r23, r21);        \/\/       ldumaxl w20, w23, [x21]\n@@ -1018,4 +1066,4 @@\n-    __ bcax(v7, __ T16B, v4, v7, v15);                 \/\/       bcax            v7.16B, v4.16B, v7.16B, v15.16B\n-    __ eor3(v9, __ T16B, v22, v8, v2);                 \/\/       eor3            v9.16B, v22.16B, v8.16B, v2.16B\n-    __ rax1(v27, __ T2D, v20, v30);                    \/\/       rax1            v27.2D, v20.2D, v30.2D\n-    __ xar(v5, __ T2D, v26, v0, 34);                   \/\/       xar             v5.2D, v26.2D, v0.2D, #34\n+    __ bcax(v5, __ T16B, v10, v8, v16);                \/\/       bcax            v5.16B, v10.16B, v8.16B, v16.16B\n+    __ eor3(v30, __ T16B, v6, v17, v2);                \/\/       eor3            v30.16B, v6.16B, v17.16B, v2.16B\n+    __ rax1(v11, __ T2D, v29, v28);                    \/\/       rax1            v11.2D, v29.2D, v28.2D\n+    __ xar(v2, __ T2D, v26, v22, 58);                  \/\/       xar             v2.2D, v26.2D, v22.2D, #58\n@@ -1024,4 +1072,4 @@\n-    __ sha512h(v14, __ T2D, v3, v25);                  \/\/       sha512h         q14, q3, v25.2D\n-    __ sha512h2(v8, __ T2D, v27, v21);                 \/\/       sha512h2                q8, q27, v21.2D\n-    __ sha512su0(v26, __ T2D, v26);                    \/\/       sha512su0               v26.2D, v26.2D\n-    __ sha512su1(v24, __ T2D, v22, v0);                \/\/       sha512su1               v24.2D, v22.2D, v0.2D\n+    __ sha512h(v14, __ T2D, v13, v27);                 \/\/       sha512h         q14, q13, v27.2D\n+    __ sha512h2(v16, __ T2D, v23, v5);                 \/\/       sha512h2                q16, q23, v5.2D\n+    __ sha512su0(v2, __ T2D, v13);                     \/\/       sha512su0               v2.2D, v13.2D\n+    __ sha512su1(v10, __ T2D, v15, v10);               \/\/       sha512su1               v10.2D, v15.2D, v10.2D\n@@ -1030,5 +1078,5 @@\n-    __ sve_add(z4, __ B, 147u);                        \/\/       add     z4.b, z4.b, #0x93\n-    __ sve_sub(z0, __ B, 124u);                        \/\/       sub     z0.b, z0.b, #0x7c\n-    __ sve_and(z1, __ H, 508u);                        \/\/       and     z1.h, z1.h, #0x1fc\n-    __ sve_eor(z9, __ D, 18374686479671656447u);       \/\/       eor     z9.d, z9.d, #0xff00000000007fff\n-    __ sve_orr(z22, __ S, 251662080u);                 \/\/       orr     z22.s, z22.s, #0xf000f00\n+    __ sve_add(z26, __ S, 98u);                        \/\/       add     z26.s, z26.s, #0x62\n+    __ sve_sub(z3, __ S, 138u);                        \/\/       sub     z3.s, z3.s, #0x8a\n+    __ sve_and(z4, __ B, 131u);                        \/\/       and     z4.b, z4.b, #0x83\n+    __ sve_eor(z17, __ H, 16368u);                     \/\/       eor     z17.h, z17.h, #0x3ff0\n+    __ sve_orr(z2, __ S, 4164941887u);                 \/\/       orr     z2.s, z2.s, #0xf83ff83f\n@@ -1037,5 +1085,5 @@\n-    __ sve_add(z8, __ S, 248u);                        \/\/       add     z8.s, z8.s, #0xf8\n-    __ sve_sub(z6, __ S, 16u);                         \/\/       sub     z6.s, z6.s, #0x10\n-    __ sve_and(z11, __ D, 4160749568u);                \/\/       and     z11.d, z11.d, #0xf8000000\n-    __ sve_eor(z26, __ S, 1610637312u);                \/\/       eor     z26.s, z26.s, #0x60006000\n-    __ sve_orr(z13, __ D, 18446181398634037247u);      \/\/       orr     z13.d, z13.d, #0xfffe003fffffffff\n+    __ sve_add(z23, __ B, 51u);                        \/\/       add     z23.b, z23.b, #0x33\n+    __ sve_sub(z7, __ S, 104u);                        \/\/       sub     z7.s, z7.s, #0x68\n+    __ sve_and(z27, __ S, 7864320u);                   \/\/       and     z27.s, z27.s, #0x780000\n+    __ sve_eor(z2, __ D, 68719476224u);                \/\/       eor     z2.d, z2.d, #0xffffffe00\n+    __ sve_orr(z6, __ S, 1056980736u);                 \/\/       orr     z6.s, z6.s, #0x3f003f00\n@@ -1044,5 +1092,5 @@\n-    __ sve_add(z5, __ B, 112u);                        \/\/       add     z5.b, z5.b, #0x70\n-    __ sve_sub(z10, __ S, 88u);                        \/\/       sub     z10.s, z10.s, #0x58\n-    __ sve_and(z26, __ S, 253952u);                    \/\/       and     z26.s, z26.s, #0x3e000\n-    __ sve_eor(z22, __ S, 496u);                       \/\/       eor     z22.s, z22.s, #0x1f0\n-    __ sve_orr(z19, __ S, 536870910u);                 \/\/       orr     z19.s, z19.s, #0x1ffffffe\n+    __ sve_add(z12, __ S, 67u);                        \/\/       add     z12.s, z12.s, #0x43\n+    __ sve_sub(z24, __ S, 154u);                       \/\/       sub     z24.s, z24.s, #0x9a\n+    __ sve_and(z0, __ H, 511u);                        \/\/       and     z0.h, z0.h, #0x1ff\n+    __ sve_eor(z19, __ D, 9241386433220968447u);       \/\/       eor     z19.d, z19.d, #0x803fffff803fffff\n+    __ sve_orr(z6, __ B, 128u);                        \/\/       orr     z6.b, z6.b, #0x80\n@@ -1051,5 +1099,5 @@\n-    __ sve_add(z14, __ H, 22u);                        \/\/       add     z14.h, z14.h, #0x16\n-    __ sve_sub(z16, __ B, 172u);                       \/\/       sub     z16.b, z16.b, #0xac\n-    __ sve_and(z23, __ B, 62u);                        \/\/       and     z23.b, z23.b, #0x3e\n-    __ sve_eor(z17, __ H, 33279u);                     \/\/       eor     z17.h, z17.h, #0x81ff\n-    __ sve_orr(z16, __ B, 254u);                       \/\/       orr     z16.b, z16.b, #0xfe\n+    __ sve_add(z17, __ D, 74u);                        \/\/       add     z17.d, z17.d, #0x4a\n+    __ sve_sub(z10, __ S, 170u);                       \/\/       sub     z10.s, z10.s, #0xaa\n+    __ sve_and(z22, __ D, 17179852800u);               \/\/       and     z22.d, z22.d, #0x3ffffc000\n+    __ sve_eor(z15, __ S, 8388600u);                   \/\/       eor     z15.s, z15.s, #0x7ffff8\n+    __ sve_orr(z4, __ D, 8064u);                       \/\/       orr     z4.d, z4.d, #0x1f80\n@@ -1058,5 +1106,5 @@\n-    __ sve_add(z3, __ B, 49u);                         \/\/       add     z3.b, z3.b, #0x31\n-    __ sve_sub(z17, __ S, 110u);                       \/\/       sub     z17.s, z17.s, #0x6e\n-    __ sve_and(z12, __ S, 4290777087u);                \/\/       and     z12.s, z12.s, #0xffc00fff\n-    __ sve_eor(z19, __ S, 134217216u);                 \/\/       eor     z19.s, z19.s, #0x7fffe00\n-    __ sve_orr(z23, __ B, 254u);                       \/\/       orr     z23.b, z23.b, #0xfe\n+    __ sve_add(z8, __ S, 162u);                        \/\/       add     z8.s, z8.s, #0xa2\n+    __ sve_sub(z22, __ B, 130u);                       \/\/       sub     z22.b, z22.b, #0x82\n+    __ sve_and(z9, __ S, 4292870159u);                 \/\/       and     z9.s, z9.s, #0xffe0000f\n+    __ sve_eor(z5, __ D, 1150687262887383032u);        \/\/       eor     z5.d, z5.d, #0xff80ff80ff80ff8\n+    __ sve_orr(z22, __ H, 32256u);                     \/\/       orr     z22.h, z22.h, #0x7e00\n@@ -1065,5 +1113,5 @@\n-    __ sve_add(z13, __ S, 54u);                        \/\/       add     z13.s, z13.s, #0x36\n-    __ sve_sub(z0, __ B, 120u);                        \/\/       sub     z0.b, z0.b, #0x78\n-    __ sve_and(z17, __ D, 18014398509481728u);         \/\/       and     z17.d, z17.d, #0x3fffffffffff00\n-    __ sve_eor(z22, __ S, 4294709247u);                \/\/       eor     z22.s, z22.s, #0xfffc0fff\n-    __ sve_orr(z2, __ B, 225u);                        \/\/       orr     z2.b, z2.b, #0xe1\n+    __ sve_add(z8, __ S, 134u);                        \/\/       add     z8.s, z8.s, #0x86\n+    __ sve_sub(z25, __ H, 39u);                        \/\/       sub     z25.h, z25.h, #0x27\n+    __ sve_and(z4, __ S, 4186112u);                    \/\/       and     z4.s, z4.s, #0x3fe000\n+    __ sve_eor(z29, __ B, 131u);                       \/\/       eor     z29.b, z29.b, #0x83\n+    __ sve_orr(z29, __ D, 4611685469745315712u);       \/\/       orr     z29.d, z29.d, #0x3fffff803fffff80\n@@ -1072,45 +1120,45 @@\n-    __ sve_add(z20, __ D, z7, z4);                     \/\/       add     z20.d, z7.d, z4.d\n-    __ sve_sub(z7, __ S, z0, z8);                      \/\/       sub     z7.s, z0.s, z8.s\n-    __ sve_fadd(z19, __ D, z22, z4);                   \/\/       fadd    z19.d, z22.d, z4.d\n-    __ sve_fmul(z9, __ D, z22, z11);                   \/\/       fmul    z9.d, z22.d, z11.d\n-    __ sve_fsub(z5, __ S, z30, z16);                   \/\/       fsub    z5.s, z30.s, z16.s\n-    __ sve_abs(z22, __ H, p3, z1);                     \/\/       abs     z22.h, p3\/m, z1.h\n-    __ sve_add(z8, __ D, p5, z16);                     \/\/       add     z8.d, p5\/m, z8.d, z16.d\n-    __ sve_and(z15, __ S, p1, z4);                     \/\/       and     z15.s, p1\/m, z15.s, z4.s\n-    __ sve_asr(z8, __ B, p1, z29);                     \/\/       asr     z8.b, p1\/m, z8.b, z29.b\n-    __ sve_cnt(z28, __ D, p4, z29);                    \/\/       cnt     z28.d, p4\/m, z29.d\n-    __ sve_eor(z9, __ H, p3, z2);                      \/\/       eor     z9.h, p3\/m, z9.h, z2.h\n-    __ sve_lsl(z28, __ B, p0, z7);                     \/\/       lsl     z28.b, p0\/m, z28.b, z7.b\n-    __ sve_lsr(z26, __ H, p5, z17);                    \/\/       lsr     z26.h, p5\/m, z26.h, z17.h\n-    __ sve_mul(z8, __ D, p4, z21);                     \/\/       mul     z8.d, p4\/m, z8.d, z21.d\n-    __ sve_neg(z5, __ S, p5, z21);                     \/\/       neg     z5.s, p5\/m, z21.s\n-    __ sve_not(z22, __ S, p4, z29);                    \/\/       not     z22.s, p4\/m, z29.s\n-    __ sve_orr(z19, __ S, p0, z4);                     \/\/       orr     z19.s, p0\/m, z19.s, z4.s\n-    __ sve_smax(z23, __ B, p1, z19);                   \/\/       smax    z23.b, p1\/m, z23.b, z19.b\n-    __ sve_smin(z23, __ B, p6, z19);                   \/\/       smin    z23.b, p6\/m, z23.b, z19.b\n-    __ sve_sub(z8, __ D, p2, z14);                     \/\/       sub     z8.d, p2\/m, z8.d, z14.d\n-    __ sve_fabs(z17, __ S, p7, z21);                   \/\/       fabs    z17.s, p7\/m, z21.s\n-    __ sve_fadd(z30, __ D, p0, z10);                   \/\/       fadd    z30.d, p0\/m, z30.d, z10.d\n-    __ sve_fdiv(z12, __ S, p0, z9);                    \/\/       fdiv    z12.s, p0\/m, z12.s, z9.s\n-    __ sve_fmax(z24, __ D, p4, z4);                    \/\/       fmax    z24.d, p4\/m, z24.d, z4.d\n-    __ sve_fmin(z6, __ D, p2, z27);                    \/\/       fmin    z6.d, p2\/m, z6.d, z27.d\n-    __ sve_fmul(z13, __ D, p4, z30);                   \/\/       fmul    z13.d, p4\/m, z13.d, z30.d\n-    __ sve_fneg(z22, __ D, p5, z30);                   \/\/       fneg    z22.d, p5\/m, z30.d\n-    __ sve_frintm(z9, __ S, p3, z19);                  \/\/       frintm  z9.s, p3\/m, z19.s\n-    __ sve_frintn(z20, __ S, p7, z9);                  \/\/       frintn  z20.s, p7\/m, z9.s\n-    __ sve_frintp(z13, __ S, p3, z19);                 \/\/       frintp  z13.s, p3\/m, z19.s\n-    __ sve_fsqrt(z24, __ S, p2, z19);                  \/\/       fsqrt   z24.s, p2\/m, z19.s\n-    __ sve_fsub(z17, __ S, p4, z16);                   \/\/       fsub    z17.s, p4\/m, z17.s, z16.s\n-    __ sve_fmad(z0, __ S, p0, z11, z7);                \/\/       fmad    z0.s, p0\/m, z11.s, z7.s\n-    __ sve_fmla(z14, __ D, p4, z4, z15);               \/\/       fmla    z14.d, p4\/m, z4.d, z15.d\n-    __ sve_fmls(z5, __ D, p0, z10, z21);               \/\/       fmls    z5.d, p0\/m, z10.d, z21.d\n-    __ sve_fnmla(z3, __ D, p0, z9, z19);               \/\/       fnmla   z3.d, p0\/m, z9.d, z19.d\n-    __ sve_fnmls(z10, __ S, p6, z3, z19);              \/\/       fnmls   z10.s, p6\/m, z3.s, z19.s\n-    __ sve_mla(z23, __ H, p7, z13, z21);               \/\/       mla     z23.h, p7\/m, z13.h, z21.h\n-    __ sve_mls(z26, __ S, p3, z17, z30);               \/\/       mls     z26.s, p3\/m, z17.s, z30.s\n-    __ sve_and(z14, z2, z29);                          \/\/       and     z14.d, z2.d, z29.d\n-    __ sve_eor(z21, z20, z7);                          \/\/       eor     z21.d, z20.d, z7.d\n-    __ sve_orr(z2, z1, z26);                           \/\/       orr     z2.d, z1.d, z26.d\n-    __ sve_bic(z9, z16, z17);                          \/\/       bic     z9.d, z16.d, z17.d\n-    __ sve_uzp1(z0, __ D, z4, z2);                     \/\/       uzp1    z0.d, z4.d, z2.d\n-    __ sve_uzp2(z14, __ S, z6, z11);                   \/\/       uzp2    z14.s, z6.s, z11.s\n+    __ sve_add(z2, __ B, z11, z28);                    \/\/       add     z2.b, z11.b, z28.b\n+    __ sve_sub(z7, __ S, z1, z26);                     \/\/       sub     z7.s, z1.s, z26.s\n+    __ sve_fadd(z17, __ D, z14, z8);                   \/\/       fadd    z17.d, z14.d, z8.d\n+    __ sve_fmul(z21, __ D, z24, z5);                   \/\/       fmul    z21.d, z24.d, z5.d\n+    __ sve_fsub(z21, __ D, z17, z22);                  \/\/       fsub    z21.d, z17.d, z22.d\n+    __ sve_abs(z29, __ B, p5, z19);                    \/\/       abs     z29.b, p5\/m, z19.b\n+    __ sve_add(z4, __ B, p4, z23);                     \/\/       add     z4.b, p4\/m, z4.b, z23.b\n+    __ sve_and(z19, __ D, p1, z23);                    \/\/       and     z19.d, p1\/m, z19.d, z23.d\n+    __ sve_asr(z19, __ H, p0, z8);                     \/\/       asr     z19.h, p0\/m, z19.h, z8.h\n+    __ sve_cnt(z14, __ D, p6, z17);                    \/\/       cnt     z14.d, p6\/m, z17.d\n+    __ sve_eor(z21, __ B, p1, z30);                    \/\/       eor     z21.b, p1\/m, z21.b, z30.b\n+    __ sve_lsl(z10, __ B, p5, z12);                    \/\/       lsl     z10.b, p5\/m, z10.b, z12.b\n+    __ sve_lsr(z9, __ S, p1, z24);                     \/\/       lsr     z9.s, p1\/m, z9.s, z24.s\n+    __ sve_mul(z4, __ H, p6, z6);                      \/\/       mul     z4.h, p6\/m, z4.h, z6.h\n+    __ sve_neg(z27, __ S, p6, z13);                    \/\/       neg     z27.s, p6\/m, z13.s\n+    __ sve_not(z30, __ S, p5, z22);                    \/\/       not     z30.s, p5\/m, z22.s\n+    __ sve_orr(z30, __ H, p7, z9);                     \/\/       orr     z30.h, p7\/m, z30.h, z9.h\n+    __ sve_smax(z19, __ D, p1, z20);                   \/\/       smax    z19.d, p1\/m, z19.d, z20.d\n+    __ sve_smin(z9, __ H, p2, z13);                    \/\/       smin    z9.h, p2\/m, z9.h, z13.h\n+    __ sve_sub(z19, __ H, p0, z24);                    \/\/       sub     z19.h, p0\/m, z19.h, z24.h\n+    __ sve_fabs(z19, __ D, p3, z17);                   \/\/       fabs    z19.d, p3\/m, z17.d\n+    __ sve_fadd(z16, __ S, p1, z0);                    \/\/       fadd    z16.s, p1\/m, z16.s, z0.s\n+    __ sve_fdiv(z11, __ S, p2, z15);                   \/\/       fdiv    z11.s, p2\/m, z11.s, z15.s\n+    __ sve_fmax(z15, __ D, p1, z15);                   \/\/       fmax    z15.d, p1\/m, z15.d, z15.d\n+    __ sve_fmin(z5, __ D, p0, z10);                    \/\/       fmin    z5.d, p0\/m, z5.d, z10.d\n+    __ sve_fmul(z26, __ S, p0, z0);                    \/\/       fmul    z26.s, p0\/m, z26.s, z0.s\n+    __ sve_fneg(z19, __ D, p7, z10);                   \/\/       fneg    z19.d, p7\/m, z10.d\n+    __ sve_frintm(z3, __ D, p5, z7);                   \/\/       frintm  z3.d, p5\/m, z7.d\n+    __ sve_frintn(z28, __ S, p3, z21);                 \/\/       frintn  z28.s, p3\/m, z21.s\n+    __ sve_frintp(z26, __ D, p3, z17);                 \/\/       frintp  z26.d, p3\/m, z17.d\n+    __ sve_fsqrt(z17, __ D, p3, z2);                   \/\/       fsqrt   z17.d, p3\/m, z2.d\n+    __ sve_fsub(z16, __ S, p5, z20);                   \/\/       fsub    z16.s, p5\/m, z16.s, z20.s\n+    __ sve_fmad(z19, __ D, p0, z1, z26);               \/\/       fmad    z19.d, p0\/m, z1.d, z26.d\n+    __ sve_fmla(z9, __ S, p4, z17, z21);               \/\/       fmla    z9.s, p4\/m, z17.s, z21.s\n+    __ sve_fmls(z4, __ S, p0, z23, z14);               \/\/       fmls    z4.s, p0\/m, z23.s, z14.s\n+    __ sve_fnmla(z11, __ D, p5, z14, z16);             \/\/       fnmla   z11.d, p5\/m, z14.d, z16.d\n+    __ sve_fnmls(z12, __ S, p0, z3, z22);              \/\/       fnmls   z12.s, p0\/m, z3.s, z22.s\n+    __ sve_mla(z3, __ S, p6, z27, z3);                 \/\/       mla     z3.s, p6\/m, z27.s, z3.s\n+    __ sve_mls(z22, __ H, p1, z25, z21);               \/\/       mls     z22.h, p1\/m, z25.h, z21.h\n+    __ sve_and(z5, z7, z25);                           \/\/       and     z5.d, z7.d, z25.d\n+    __ sve_eor(z21, z17, z17);                         \/\/       eor     z21.d, z17.d, z17.d\n+    __ sve_orr(z3, z9, z19);                           \/\/       orr     z3.d, z9.d, z19.d\n+    __ sve_bic(z7, z11, z14);                          \/\/       bic     z7.d, z11.d, z14.d\n+    __ sve_uzp1(z17, __ D, z11, z13);                  \/\/       uzp1    z17.d, z11.d, z13.d\n+    __ sve_uzp2(z17, __ H, z30, z17);                  \/\/       uzp2    z17.h, z30.h, z17.h\n@@ -1119,9 +1167,9 @@\n-    __ sve_andv(v14, __ H, p4, z29);                   \/\/       andv h14, p4, z29.h\n-    __ sve_orv(v3, __ H, p0, z22);                     \/\/       orv h3, p0, z22.h\n-    __ sve_eorv(v3, __ B, p6, z27);                    \/\/       eorv b3, p6, z27.b\n-    __ sve_smaxv(v19, __ D, p5, z7);                   \/\/       smaxv d19, p5, z7.d\n-    __ sve_sminv(v21, __ H, p3, z5);                   \/\/       sminv h21, p3, z5.h\n-    __ sve_fminv(v25, __ D, p1, z21);                  \/\/       fminv d25, p1, z21.d\n-    __ sve_fmaxv(v17, __ S, p0, z3);                   \/\/       fmaxv s17, p0, z3.s\n-    __ sve_fadda(v19, __ S, p3, z7);                   \/\/       fadda s19, p3, s19, z7.s\n-    __ sve_uaddv(v14, __ H, p4, z17);                  \/\/       uaddv d14, p4, z17.h\n+    __ sve_andv(v15, __ S, p3, z26);                   \/\/       andv s15, p3, z26.s\n+    __ sve_orv(v27, __ H, p5, z7);                     \/\/       orv h27, p5, z7.h\n+    __ sve_eorv(v5, __ H, p7, z27);                    \/\/       eorv h5, p7, z27.h\n+    __ sve_smaxv(v0, __ S, p3, z24);                   \/\/       smaxv s0, p3, z24.s\n+    __ sve_sminv(v20, __ S, p0, z3);                   \/\/       sminv s20, p0, z3.s\n+    __ sve_fminv(v25, __ D, p1, z25);                  \/\/       fminv d25, p1, z25.d\n+    __ sve_fmaxv(v17, __ S, p4, z1);                   \/\/       fmaxv s17, p4, z1.s\n+    __ sve_fadda(v14, __ S, p7, z13);                  \/\/       fadda s14, p7, s14, z13.s\n+    __ sve_uaddv(v17, __ S, p0, z30);                  \/\/       uaddv d17, p0, z30.s\n@@ -1146,7 +1194,7 @@\n-    0x14000000,     0x17ffffd7,     0x140003a5,     0x94000000,\n-    0x97ffffd4,     0x940003a2,     0x3400000a,     0x34fffa2a,\n-    0x340073ea,     0x35000008,     0x35fff9c8,     0x35007388,\n-    0xb400000b,     0xb4fff96b,     0xb400732b,     0xb500001d,\n-    0xb5fff91d,     0xb50072dd,     0x10000013,     0x10fff8b3,\n-    0x10007273,     0x90000013,     0x36300016,     0x3637f836,\n-    0x363071f6,     0x3758000c,     0x375ff7cc,     0x3758718c,\n+    0x14000000,     0x17ffffd7,     0x140003d1,     0x94000000,\n+    0x97ffffd4,     0x940003ce,     0x3400000a,     0x34fffa2a,\n+    0x3400796a,     0x35000008,     0x35fff9c8,     0x35007908,\n+    0xb400000b,     0xb4fff96b,     0xb40078ab,     0xb500001d,\n+    0xb5fff91d,     0xb500785d,     0x10000013,     0x10fff8b3,\n+    0x100077f3,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36307776,     0x3758000c,     0x375ff7cc,     0x3758770c,\n@@ -1157,13 +1205,13 @@\n-    0x54006f60,     0x54000001,     0x54fff541,     0x54006f01,\n-    0x54000002,     0x54fff4e2,     0x54006ea2,     0x54000002,\n-    0x54fff482,     0x54006e42,     0x54000003,     0x54fff423,\n-    0x54006de3,     0x54000003,     0x54fff3c3,     0x54006d83,\n-    0x54000004,     0x54fff364,     0x54006d24,     0x54000005,\n-    0x54fff305,     0x54006cc5,     0x54000006,     0x54fff2a6,\n-    0x54006c66,     0x54000007,     0x54fff247,     0x54006c07,\n-    0x54000008,     0x54fff1e8,     0x54006ba8,     0x54000009,\n-    0x54fff189,     0x54006b49,     0x5400000a,     0x54fff12a,\n-    0x54006aea,     0x5400000b,     0x54fff0cb,     0x54006a8b,\n-    0x5400000c,     0x54fff06c,     0x54006a2c,     0x5400000d,\n-    0x54fff00d,     0x540069cd,     0x5400000e,     0x54ffefae,\n-    0x5400696e,     0x5400000f,     0x54ffef4f,     0x5400690f,\n+    0x540074e0,     0x54000001,     0x54fff541,     0x54007481,\n+    0x54000002,     0x54fff4e2,     0x54007422,     0x54000002,\n+    0x54fff482,     0x540073c2,     0x54000003,     0x54fff423,\n+    0x54007363,     0x54000003,     0x54fff3c3,     0x54007303,\n+    0x54000004,     0x54fff364,     0x540072a4,     0x54000005,\n+    0x54fff305,     0x54007245,     0x54000006,     0x54fff2a6,\n+    0x540071e6,     0x54000007,     0x54fff247,     0x54007187,\n+    0x54000008,     0x54fff1e8,     0x54007128,     0x54000009,\n+    0x54fff189,     0x540070c9,     0x5400000a,     0x54fff12a,\n+    0x5400706a,     0x5400000b,     0x54fff0cb,     0x5400700b,\n+    0x5400000c,     0x54fff06c,     0x54006fac,     0x5400000d,\n+    0x54fff00d,     0x54006f4d,     0x5400000e,     0x54ffefae,\n+    0x54006eee,     0x5400000f,     0x54ffef4f,     0x54006e8f,\n@@ -1171,113 +1219,124 @@\n-    0xd44cad80,     0xd503201f,     0xd69f03e0,     0xd6bf03e0,\n-    0xd5033fdf,     0xd5033e9f,     0xd50332bf,     0xd61f0200,\n-    0xd63f0280,     0xc80a7d1b,     0xc800fea1,     0xc85f7fb1,\n-    0xc85fff9d,     0xc89ffee1,     0xc8dffe95,     0x88167e7b,\n-    0x880bfcd0,     0x885f7c11,     0x885ffd44,     0x889ffed8,\n-    0x88dffe6a,     0x48017fc5,     0x4808fe2c,     0x485f7dc9,\n-    0x485ffc27,     0x489ffe05,     0x48dffd82,     0x080a7c6c,\n-    0x081cff4e,     0x085f7d5e,     0x085ffeae,     0x089ffd2d,\n-    0x08dfff76,     0xc87f4d7c,     0xc87fcc5e,     0xc8220417,\n-    0xc82cb5f0,     0x887f55b1,     0x887ff90b,     0x88382c2d,\n-    0x883aedb5,     0xf819928b,     0xb803e21c,     0x381f713b,\n-    0x781ce322,     0xf850f044,     0xb85e129e,     0x385e92f1,\n-    0x785ff35d,     0x39801921,     0x7881318b,     0x78dce02b,\n-    0xb8829313,     0xfc45f318,     0xbc5d50af,     0xfc001375,\n-    0xbc1951b7,     0xf8008c0a,     0xb801dc03,     0x38009dca,\n-    0x781fdf3d,     0xf8570e0c,     0xb85faecc,     0x385f6d6d,\n-    0x785ebea0,     0x38804cd7,     0x789cbce3,     0x78df9c9c,\n-    0xb89eed18,     0xfc40cd6e,     0xbc5bdd93,     0xfc103c14,\n-    0xbc040c08,     0xf81a2783,     0xb81ca4eb,     0x381e855b,\n-    0x7801b4e6,     0xf853654d,     0xb85d74af,     0x384095a2,\n-    0x785ec5bc,     0x389e15a9,     0x789dc703,     0x78c06474,\n-    0xb89ff667,     0xfc57e51e,     0xbc4155f9,     0xfc05a6ee,\n-    0xbc1df408,     0xf835da2a,     0xb836d9a4,     0x3833580d,\n-    0x7826cb6c,     0xf8706900,     0xb87ae880,     0x3865db2e,\n-    0x78714889,     0x38a7789b,     0x78beca2f,     0x78f6c810,\n-    0xb8bef956,     0xfc6afabd,     0xbc734963,     0xfc3d5b8d,\n-    0xbc25fbb7,     0xf9189d05,     0xb91ecb1d,     0x39187a33,\n-    0x791f226d,     0xf95aa2f3,     0xb9587bb7,     0x395f7176,\n-    0x795d9143,     0x399e7e08,     0x799a2697,     0x79df3422,\n-    0xb99c2624,     0xfd5c2374,     0xbd5fa1d9,     0xfd1d595a,\n-    0xbd1b1869,     0x5800595b,     0x1800000b,     0xf8945060,\n-    0xd8000000,     0xf8ae6ba0,     0xf99a0080,     0x1a070035,\n-    0x3a0700a8,     0x5a0e0367,     0x7a11009b,     0x9a000380,\n-    0xba1e030c,     0xda0f0320,     0xfa030301,     0x0b340b11,\n-    0x2b2a278d,     0xcb22aa0f,     0x6b2d29bd,     0x8b2cce8c,\n-    0xab2b877e,     0xcb21c8ee,     0xeb3ba47d,     0x3a4d400e,\n-    0x7a5132c6,     0xba5e622e,     0xfa53814c,     0x3a52d8c2,\n-    0x7a4d8924,     0xba4b3aab,     0xfa4d7882,     0x1a96804c,\n-    0x1a912618,     0x5a90b0e6,     0x5a96976b,     0x9a9db06a,\n-    0x9a9b374c,     0xda95c14f,     0xda89c6fe,     0x5ac0015e,\n-    0x5ac005fd,     0x5ac00bdd,     0x5ac012b9,     0x5ac01404,\n-    0xdac002b1,     0xdac0061d,     0xdac00a95,     0xdac00e66,\n-    0xdac0107e,     0xdac01675,     0x1ac00b0b,     0x1ace0f3b,\n-    0x1ad121c3,     0x1ad825e7,     0x1ad92a3c,     0x1adc2f42,\n-    0x9ada0b25,     0x9ad10e1b,     0x9acc22a6,     0x9acc2480,\n-    0x9adc2a3b,     0x9ad12c5c,     0x9bce7dea,     0x9b597c6e,\n-    0x1b0e166f,     0x1b1ae490,     0x9b023044,     0x9b089e3d,\n-    0x9b391083,     0x9b24c73a,     0x9bb15f40,     0x9bbcc6af,\n-    0x7ea3d55b,     0x1e3908e0,     0x1e2f18c9,     0x1e2a29fd,\n-    0x1e273a22,     0x7ef7d56b,     0x1e770ba7,     0x1e6b1b6e,\n-    0x1e78288b,     0x1e6e39ec,     0x1f1c3574,     0x1f17f98b,\n-    0x1f2935da,     0x1f2574ea,     0x1f4b306f,     0x1f5ec7cf,\n-    0x1f6f3e93,     0x1f6226a9,     0x1e2040fb,     0x1e20c3dd,\n-    0x1e214031,     0x1e21c0c2,     0x1e22c06a,     0x1e604178,\n-    0x1e60c027,     0x1e61400b,     0x1e61c223,     0x1e6240dc,\n-    0x1e3800d6,     0x9e380360,     0x1e78005a,     0x9e7800e5,\n-    0x1e22017c,     0x9e2201b9,     0x1e6202eb,     0x9e620113,\n-    0x1e2602b1,     0x9e660299,     0x1e270233,     0x9e6703a2,\n-    0x1e2822c0,     0x1e7322a0,     0x1e202288,     0x1e602168,\n-    0x293c19f4,     0x2966387b,     0x69762970,     0xa9041dc7,\n-    0xa9475c0c,     0x29b61ccd,     0x29ee3c5e,     0x69ee0764,\n-    0xa9843977,     0xa9f46ebd,     0x28ba16b6,     0x28fc44db,\n-    0x68f61430,     0xa8b352cd,     0xa8c56d5e,     0x28024565,\n-    0x2874134e,     0xa8027597,     0xa87b1aa0,     0x0c40734f,\n-    0x4cdfa177,     0x0cc76ee8,     0x4cdf2733,     0x0d40c23d,\n-    0x4ddfcaf8,     0x0dd9ccaa,     0x4c408d51,     0x0cdf85ec,\n-    0x4d60c239,     0x0dffcbc1,     0x4de9ce30,     0x4cc24999,\n-    0x0c404a7a,     0x4d40e6af,     0x4ddfe9b9,     0x0dddef8e,\n-    0x4cdf07b1,     0x0cc000fb,     0x0d60e238,     0x0dffe740,\n-    0x0de2eb2c,     0x0e31baf6,     0x4e31bb9b,     0x0e71b8a4,\n-    0x4e71b907,     0x4eb1b8e6,     0x0e30a841,     0x4e30ab7a,\n-    0x0e70aa0f,     0x4e70a862,     0x4eb0a9cd,     0x6e30f9cd,\n-    0x0e31ab38,     0x2e31ab17,     0x4e31a8a4,     0x6e31aa93,\n-    0x0e71aa0f,     0x2e71a820,     0x4e71a8a4,     0x6e71aab4,\n-    0x4eb1a98b,     0x6eb1abdd,     0x6eb0fa0f,     0x7e30fad5,\n-    0x7e70f8a4,     0x7eb0f9ee,     0x7ef0faf6,     0x0e20bb59,\n-    0x4e20b8e6,     0x0e60b9ac,     0x4e60b9ee,     0x0ea0b9cd,\n-    0x4ea0b9ee,     0x4ee0b949,     0x0ea0fb59,     0x4ea0fbbc,\n-    0x4ee0f96a,     0x2ea0fa93,     0x6ea0f98b,     0x6ee0fa51,\n-    0x2ea1fad5,     0x6ea1fa0f,     0x6ee1fab4,     0x2e205b17,\n-    0x6e205b7a,     0x0e271cc5,     0x4e281ce6,     0x0eb11e0f,\n-    0x4eb11e0f,     0x2e3b1f59,     0x6e321e30,     0x0e3d879b,\n-    0x4e3a8738,     0x0e71860f,     0x4e7b8759,     0x0eb085ee,\n-    0x4eac856a,     0x4eef85cd,     0x0e30d5ee,     0x4e36d6b4,\n-    0x4e63d441,     0x2e3886f6,     0x6e2087fe,     0x2e7085ee,\n-    0x6e648462,     0x2ea884e6,     0x6ea58483,     0x6ee98507,\n-    0x0ebad738,     0x4ea2d420,     0x4efdd79b,     0x0e3f9fdd,\n-    0x4e279cc5,     0x0e679cc5,     0x4e7f9fdd,     0x0ead9d8b,\n-    0x4ebb9f59,     0x2ea2d420,     0x6ea0d7fe,     0x6ee2d420,\n-    0x2e33de51,     0x6e3edfbc,     0x6e7bdf59,     0x0e6b9549,\n-    0x4e7b9759,     0x0eae95ac,     0x4eb1960f,     0x0e2dcd8b,\n-    0x4e2ccd6a,     0x4e73ce51,     0x2e7a9738,     0x6e7796d5,\n-    0x2eb99717,     0x6ea29420,     0x0eb2ce30,     0x4eaccd6a,\n-    0x4ee8cce6,     0x2e3effbc,     0x6e28fce6,     0x6e67fcc5,\n-    0x0e2764c5,     0x4e3666b4,     0x0e736651,     0x4e71660f,\n-    0x0eb36651,     0x4ebf67dd,     0x0e3ca77a,     0x4e3ea7bc,\n-    0x0e63a441,     0x4e7da79b,     0x0ea2a420,     0x4eb6a6b4,\n-    0x0e3ef7bc,     0x4e31f60f,     0x4e6ef5ac,     0x0e2c6d6a,\n-    0x4e3e6fbc,     0x0e7e6fbc,     0x4e756e93,     0x0eb86ef6,\n-    0x4eac6d6a,     0x0e26aca4,     0x4e20affe,     0x0e76aeb4,\n-    0x4e6aad28,     0x0ea0affe,     0x4eb3ae51,     0x0eacf56a,\n-    0x4ebdf79b,     0x4ee4f462,     0x2e3a8f38,     0x6e268ca4,\n-    0x2e658c83,     0x6e6a8d28,     0x2eb88ef6,     0x6eb38e51,\n-    0x6eef8dcd,     0x0e26e4a4,     0x4e3ee7bc,     0x4e79e717,\n-    0x0e3736d5,     0x4e3b3759,     0x0e7a3738,     0x4e653483,\n-    0x0eb93717,     0x4ebc377a,     0x4ef93717,     0x2e3035ee,\n-    0x6e3736d5,     0x2e653483,     0x6e793717,     0x2eaa3528,\n-    0x6eba3738,     0x6ef53693,     0x2e313e0f,     0x6e323e30,\n-    0x2e643c62,     0x6e633c41,     0x2ea23c20,     0x6eba3f38,\n-    0x6ee63ca4,     0x2ea5e483,     0x6eade58b,     0x6ee0e7fe,\n-    0x0e3d3f9b,     0x4e2b3d49,     0x0e7b3f59,     0x4e643c62,\n-    0x0eae3dac,     0x4eb33e51,     0x4ee03ffe,     0x2e23e441,\n-    0x6e2ee5ac,     0x6e7ee7bc,     0xba5fd3e3,     0x3a5f03e5,\n+    0xd44cad80,     0xd503201f,     0xd503203f,     0xd503205f,\n+    0xd503209f,     0xd50320bf,     0xd503219f,     0xd50323bf,\n+    0xd503239f,     0xd50321df,     0xd50323ff,     0xd50323df,\n+    0xd503211f,     0xd503233f,     0xd503231f,     0xd503215f,\n+    0xd503237f,     0xd503235f,     0xd69f03e0,     0xd6bf03e0,\n+    0xd5033fdf,     0xd503207f,     0xd50320ff,     0xd5033e9f,\n+    0xd50332bf,     0xd61f0200,     0xd63f0280,     0xdac123ea,\n+    0xdac127fb,     0xdac12be8,     0xdac12fe0,     0xdac133e1,\n+    0xdac137f5,     0xdac13bf1,     0xdac13ffd,     0xdac147fd,\n+    0xd61f0b9f,     0xd61f0c3f,     0xd63f0aff,     0xd63f0ebf,\n+    0xdac143f4,     0xc8167e7b,     0xc80bfcd0,     0xc85f7c11,\n+    0xc85ffd44,     0xc89ffed8,     0xc8dffe6a,     0x88017fc5,\n+    0x8808fe2c,     0x885f7dc9,     0x885ffc27,     0x889ffe05,\n+    0x88dffd82,     0x480a7c6c,     0x481cff4e,     0x485f7d5e,\n+    0x485ffeae,     0x489ffd2d,     0x48dfff76,     0x081c7d73,\n+    0x081efc53,     0x085f7ee2,     0x085ffc01,     0x089ffe0c,\n+    0x08dffded,     0xc87f55b1,     0xc87ff90b,     0xc8382c2d,\n+    0xc83aedb5,     0x887f0d94,     0x887f87a6,     0x88262e04,\n+    0x8824b2be,     0xf8061366,     0xb802d151,     0x381e32da,\n+    0x781ce155,     0xf847d30e,     0xb85f0307,     0x39403448,\n+    0x785c333e,     0x389f2183,     0x789e422a,     0x78dfb075,\n+    0xb8817322,     0xfc5bb039,     0xbc40637d,     0xfc02919d,\n+    0xbc18d2c2,     0xf8003cba,     0xb8199cb4,     0x381e7d88,\n+    0x781c7c54,     0xf8516fae,     0xb8404fad,     0x385f7e78,\n+    0x785edf63,     0x389fbc31,     0x789f3e71,     0x78de6d75,\n+    0xb89c4d21,     0xfc509efa,     0xbc581eb6,     0xfc128ced,\n+    0xbc198dac,     0xf81134b4,     0xb81b679d,     0x381ea704,\n+    0x781eb52d,     0xf85c94fa,     0xb858d46d,     0x3840c4a1,\n+    0x785de5a8,     0x389e5697,     0x789fe4d4,     0x78dd6629,\n+    0xb89e24d5,     0xfc5e36d0,     0xbc5fd569,     0xfc03c756,\n+    0xbc1fe7b0,     0xf824cac1,     0xb82d7bd7,     0x382c596c,\n+    0x78207999,     0xf86058f1,     0xb86e5a61,     0x3869784c,\n+    0x787bc936,     0x38aff995,     0x78b078dc,     0x78f6ca39,\n+    0xb8bdea24,     0xfc63f825,     0xbc6d5a38,     0xfc37fa31,\n+    0xbc25dbd1,     0xf91ba97d,     0xb91e4abc,     0x391b485c,\n+    0x7919c380,     0xf95e18f9,     0xb958a860,     0x395f20be,\n+    0x7958f6ee,     0x399bea6a,     0x799b363d,     0x79da47d9,\n+    0xb99d5851,     0xfd5da60f,     0xbd584fcc,     0xfd1db821,\n+    0xbd1e9965,     0x58ffdb71,     0x18ffdb42,     0xf886f320,\n+    0xd8ffdb00,     0xf8bb49c0,     0xf99815c0,     0x1a0f0320,\n+    0x3a030301,     0x5a140311,     0x7a0d000b,     0x9a07015c,\n+    0xba1001e4,     0xda140182,     0xfa0d01bd,     0x0b2c6cce,\n+    0x2b3e5331,     0xcb2e0620,     0x6b3de709,     0x8b20cac1,\n+    0xab362f8c,     0xcb31518a,     0xeb2acf8f,     0x3a57d262,\n+    0x7a493226,     0xba4832a2,     0xfa454261,     0x3a518acc,\n+    0x7a472a23,     0xba5cba05,     0xfa439ac5,     0x1a8cb35d,\n+    0x1a8f355b,     0x5a9e9395,     0x5a9e3769,     0x9a9dd1fd,\n+    0x9a8406b9,     0xda9d62b1,     0xda868695,     0x5ac0007e,\n+    0x5ac00675,     0x5ac00b0b,     0x5ac01360,     0x5ac015d9,\n+    0xdac001c3,     0xdac004f1,     0xdac00b0f,     0xdac00e3c,\n+    0xdac01059,     0xdac0179a,     0xdac10325,     0xdac1077a,\n+    0xdac10a30,     0xdac10ea6,     0xdac1100c,     0xdac11584,\n+    0xdac11a3b,     0xdac11f9c,     0xd71f0851,     0xd71f0d4f,\n+    0xd73f09ce,     0xd73f0c79,     0x1ace0a6f,     0x1ac40e05,\n+    0x1ac4233a,     0x1acc2442,     0x1ac82a3d,     0x1ac42c67,\n+    0x9ada0899,     0x9ad10c99,     0x9ad12340,     0x9ad525f7,\n+    0x9adb2a3c,     0x9ac02c6a,     0x9bc97f27,     0x9b5d7de6,\n+    0x1b02454f,     0x1b0bdd67,     0x9b173ba7,     0x9b0b917b,\n+    0x9b2f3998,     0x9b3cb574,     0x9bb7798b,     0x9ba9b5da,\n+    0x7ea5d4ea,     0x1e2309fd,     0x1e2f198b,     0x1e312bde,\n+    0x1e2f3a93,     0x7ef5d52f,     0x1e7b0922,     0x1e7e1ba7,\n+    0x1e622831,     0x1e633946,     0x1f070578,     0x1f03c40b,\n+    0x1f3618dc,     0x1f3a0b60,     0x1f5c2ce5,     0x1f4bddb9,\n+    0x1f715513,     0x1f734699,     0x1e2043a2,     0x1e20c116,\n+    0x1e214275,     0x1e21c174,     0x1e22c291,     0x1e6041e6,\n+    0x1e60c063,     0x1e61407c,     0x1e61c1db,     0x1e62414e,\n+    0x1e38016c,     0x9e380151,     0x1e7800f9,     0x9e7801c7,\n+    0x1e22001c,     0x9e220016,     0x1e6202ec,     0x9e6201ad,\n+    0x1e2601c7,     0x9e660107,     0x1e270234,     0x9e6703dc,\n+    0x1e222200,     0x1e702120,     0x1e202288,     0x1e6023a8,\n+    0x29266b01,     0x29462d85,     0x69463f75,     0xa90272c5,\n+    0xa97e467b,     0x29aa1f4d,     0x29fa54cd,     0x69c27b74,\n+    0xa9b81555,     0xa9fa12ee,     0x2884321d,     0x28cc477a,\n+    0x68f451c4,     0xa8b909d0,     0xa8f060f7,     0x281069e0,\n+    0x2866191a,     0xa8392b2f,     0xa8760670,     0x0c4073db,\n+    0x4cdfa079,     0x0cca6e1e,     0x4cdf2670,     0x0d40c317,\n+    0x4ddfc948,     0x0dd7ce89,     0x4c408c62,     0x0cdf87c8,\n+    0x4d60c344,     0x0dffca23,     0x4df0cd7d,     0x4cd74801,\n+    0x0c404aa0,     0x4d40e4e5,     0x4ddfe8e1,     0x0dcfeca2,\n+    0x4cdf07bb,     0x0cc70098,     0x0d60e2ef,     0x0dffe6ae,\n+    0x0df9e934,     0x0e31bb17,     0x4e31bb7a,     0x0e71b8c5,\n+    0x4e71b8e6,     0x4eb1ba0f,     0x0e30aa0f,     0x4e30ab59,\n+    0x0e70aa30,     0x4e70ab9b,     0x4eb0ab38,     0x6e30fa0f,\n+    0x0e31ab59,     0x2e31a9ee,     0x4e31a96a,     0x6e31a9cd,\n+    0x0e71a9ee,     0x2e71aab4,     0x4e71a841,     0x6e71aaf6,\n+    0x4eb1abfe,     0x6eb1a9ee,     0x6eb0f862,     0x7e30f8e6,\n+    0x7e70f883,     0x7eb0f907,     0x7ef0fb38,     0x0e20b820,\n+    0x4e20bb9b,     0x0e60bbdd,     0x4e60b8c5,     0x0ea0b8c5,\n+    0x4ea0bbdd,     0x4ee0b98b,     0x0ea0fb59,     0x4ea0f820,\n+    0x4ee0fbfe,     0x2ea0f820,     0x6ea0fa51,     0x6ee0fbbc,\n+    0x2ea1fb59,     0x6ea1f949,     0x6ee1fb59,     0x2e2059ac,\n+    0x6e205a0f,     0x0e2d1d8b,     0x4e2c1d6a,     0x0eb31e51,\n+    0x4eba1f38,     0x2e371ed5,     0x6e391f17,     0x0e228420,\n+    0x4e328630,     0x0e6c856a,     0x4e6884e6,     0x0ebe87bc,\n+    0x4ea884e6,     0x4ee784c5,     0x0e27d4c5,     0x4e36d6b4,\n+    0x4e73d651,     0x2e31860f,     0x6e338651,     0x2e7f87dd,\n+    0x6e7c877a,     0x2ebe87bc,     0x6ea38441,     0x6efd879b,\n+    0x0ea2d420,     0x4eb6d6b4,     0x4efed7bc,     0x0e319e0f,\n+    0x4e2e9dac,     0x0e6c9d6a,     0x4e7e9fbc,     0x0ebe9fbc,\n+    0x4eb59e93,     0x2eb8d6f6,     0x6eacd56a,     0x6ee6d4a4,\n+    0x2e20dffe,     0x6e36deb4,     0x6e6add28,     0x0e6097fe,\n+    0x4e739651,     0x0eac956a,     0x4ebd979b,     0x0e24cc62,\n+    0x4e3acf38,     0x4e66cca4,     0x2e659483,     0x6e6a9528,\n+    0x2eb896f6,     0x6eb39651,     0x0eafcdcd,     0x4ea6cca4,\n+    0x4efecfbc,     0x2e39ff17,     0x6e37fed5,     0x6e7bff59,\n+    0x0e3a6738,     0x4e256483,     0x0e796717,     0x4e7c677a,\n+    0x0eb96717,     0x4eb065ee,     0x0e37a6d5,     0x4e25a483,\n+    0x0e79a717,     0x4e6aa528,     0x0ebaa738,     0x4eb5a693,\n+    0x0e31f60f,     0x4e32f630,     0x4e64f462,     0x0e236c41,\n+    0x4e226c20,     0x0e7a6f38,     0x4e666ca4,     0x0ea56c83,\n+    0x4ead6d8b,     0x0e20affe,     0x4e3daf9b,     0x0e6bad49,\n+    0x4e7baf59,     0x0ea4ac62,     0x4eaeadac,     0x0eb3f651,\n+    0x4ea0f7fe,     0x4ee3f441,     0x2e2e8dac,     0x6e3e8fbc,\n+    0x2e628c20,     0x6e738e51,     0x2eae8dac,     0x6eb38e51,\n+    0x6ef78ed5,     0x0e2ee5ac,     0x4e3de79b,     0x4e7fe7dd,\n+    0x0e2037fe,     0x4e233441,     0x0e7b3759,     0x4e7d379b,\n+    0x0ea634a4,     0x4ebf37dd,     0x4ee53483,     0x2e2834e6,\n+    0x6e3f37dd,     0x2e7b3759,     0x6e733651,     0x2eaa3528,\n+    0x6ea93507,     0x6eee35ac,     0x2e223c20,     0x6e353e93,\n+    0x2e633c41,     0x6e793f17,     0x2ea43c62,     0x6ea23c20,\n+    0x6eea3d28,     0x2eb9e717,     0x6ebbe759,     0x6ef1e60f,\n+    0x0e3f3fdd,     0x4e253c83,     0x0e6c3d6a,     0x4e783ef6,\n+    0x0eac3d6a,     0x4ea63ca4,     0x4ef33e51,     0x2e23e441,\n+    0x6e2de58b,     0x6e69e507,     0xba5fd3e3,     0x3a5f03e5,\n@@ -1338,42 +1397,42 @@\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8208193,\n-    0xf83101b6,     0xf83c13fe,     0xf821239a,     0xf824309e,\n-    0xf826535e,     0xf8304109,     0xf82c7280,     0xf8216058,\n-    0xf8a08309,     0xf8ba03d0,     0xf8a312ea,     0xf8aa21e4,\n-    0xf8a2310b,     0xf8aa522f,     0xf8a2418a,     0xf8ac71af,\n-    0xf8a26287,     0xf8fa8090,     0xf8e20184,     0xf8f01215,\n-    0xf8f022ab,     0xf8f7334c,     0xf8f751dc,     0xf8eb4038,\n-    0xf8ec715f,     0xf8f06047,     0xf863826d,     0xf8710070,\n-    0xf86113cb,     0xf86521e8,     0xf87d301e,     0xf8745287,\n-    0xf87742bc,     0xf87b70b9,     0xf8616217,     0xb83f8185,\n-    0xb82901fc,     0xb83d13f6,     0xb83320bf,     0xb82e33f0,\n-    0xb830529b,     0xb830416c,     0xb82973c6,     0xb831639b,\n-    0xb8be8147,     0xb8b4008a,     0xb8b81231,     0xb8b623a3,\n-    0xb8af3276,     0xb8b35056,     0xb8af4186,     0xb8b071ab,\n-    0xb8b763c1,     0xb8f38225,     0xb8e202d0,     0xb8ed12aa,\n-    0xb8fd219b,     0xb8fb3023,     0xb8ff5278,     0xb8f14389,\n-    0xb8fb70ef,     0xb8f563f7,     0xb87983e2,     0xb87b0150,\n-    0xb8771073,     0xb8702320,     0xb87a3057,     0xb870508c,\n-    0xb87c43be,     0xb87070db,     0xb86961fd,     0xce273c87,\n-    0xce080ac9,     0xce7e8e9b,     0xce808b45,     0xce79806e,\n-    0xce758768,     0xcec0835a,     0xce608ad8,     0x2520d264,\n-    0x2521cf80,     0x058074c1,     0x054242c9,     0x05004476,\n-    0x25a0df08,     0x25a1c206,     0x0583288b,     0x05401c3a,\n-    0x05027e8d,     0x2520ce05,     0x25a1cb0a,     0x0580989a,\n-    0x0540e096,     0x0500fb73,     0x2560c2ce,     0x2521d590,\n-    0x05803e97,     0x05400d31,     0x05003ed0,     0x2520c623,\n-    0x25a1cdd1,     0x058052ac,     0x0540ba33,     0x05003ed7,\n-    0x25a0c6cd,     0x2521cf00,     0x0583c5b1,     0x05407336,\n-    0x05001e62,     0x04e400f4,     0x04a80407,     0x65c402d3,\n-    0x65cb0ac9,     0x659007c5,     0x0456ac36,     0x04c01608,\n-    0x049a048f,     0x041087a8,     0x04dab3bc,     0x04590c49,\n-    0x041380fc,     0x0451963a,     0x04d012a8,     0x0497b6a5,\n-    0x049eb3b6,     0x04980093,     0x04080677,     0x040a1a77,\n-    0x04c109c8,     0x049cbeb1,     0x65c0815e,     0x658d812c,\n-    0x65c69098,     0x65c78b66,     0x65c293cd,     0x04ddb7d6,\n-    0x6582ae69,     0x6580bd34,     0x6581ae6d,     0x658daa78,\n-    0x65819211,     0x65a78160,     0x65ef108e,     0x65f52145,\n-    0x65f34123,     0x65b3786a,     0x04555db7,     0x049e6e3a,\n-    0x043d304e,     0x04a73295,     0x047a3022,     0x04f13209,\n-    0x05e26880,     0x05ab6cce,     0x045a33ae,     0x045822c3,\n-    0x04193b63,     0x04c834f3,     0x044a2cb5,     0x65c726b9,\n-    0x65862071,     0x65982cf3,     0x0441322e,\n+    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf82a822f,\n+    0xf822018a,     0xf82c11af,     0xf8222287,     0xf83a3090,\n+    0xf8225184,     0xf8304215,     0xf83072ab,     0xf837634c,\n+    0xf8b781dc,     0xf8ab0038,     0xf8ac115f,     0xf8b02047,\n+    0xf8a3326d,     0xf8b15070,     0xf8a143cb,     0xf8a571e8,\n+    0xf8bd601e,     0xf8f48287,     0xf8f702bc,     0xf8fb10b9,\n+    0xf8e12217,     0xf8ff3185,     0xf8e951fc,     0xf8fd43f6,\n+    0xf8f370bf,     0xf8ee63f0,     0xf870829b,     0xf870016c,\n+    0xf86913c6,     0xf871239b,     0xf87e3147,     0xf874508a,\n+    0xf8784231,     0xf87673a3,     0xf86f6276,     0xb8338056,\n+    0xb82f0186,     0xb83011ab,     0xb83723c1,     0xb8333225,\n+    0xb82252d0,     0xb82d42aa,     0xb83d719b,     0xb83b6023,\n+    0xb8bf8278,     0xb8b10389,     0xb8bb10ef,     0xb8b523f7,\n+    0xb8b933e2,     0xb8bb5150,     0xb8b74073,     0xb8b07320,\n+    0xb8ba6057,     0xb8f0808c,     0xb8fc03be,     0xb8f010db,\n+    0xb8e921fd,     0xb8e730e4,     0xb8ef52e9,     0xb8e84382,\n+    0xb8f570bf,     0xb8fb6220,     0xb86f8344,     0xb86802dc,\n+    0xb87b133b,     0xb8772080,     0xb8663010,     0xb864502f,\n+    0xb86a40a7,     0xb86a70fc,     0xb87462b7,     0xce284145,\n+    0xce1108de,     0xce7c8fab,     0xce96eb42,     0xce7b81ae,\n+    0xce6586f0,     0xcec081a2,     0xce6a89ea,     0x25a0cc5a,\n+    0x25a1d143,     0x05800e44,     0x05406531,     0x05002d42,\n+    0x2520c677,     0x25a1cd07,     0x0580687b,     0x0543bb42,\n+    0x050044a6,     0x25a0c86c,     0x25a1d358,     0x05800500,\n+    0x05400ad3,     0x05000e06,     0x25e0c951,     0x25a1d54a,\n+    0x05839276,     0x0540ea6f,     0x0503c8a4,     0x25a0d448,\n+    0x2521d056,     0x058059c9,     0x05406d05,     0x05003cb6,\n+    0x25a0d0c8,     0x2561c4f9,     0x05809904,     0x05400e5d,\n+    0x0500cadd,     0x043c0162,     0x04ba0427,     0x65c801d1,\n+    0x65c50b15,     0x65d60635,     0x0416b67d,     0x040012e4,\n+    0x04da06f3,     0x04508113,     0x04daba2e,     0x041907d5,\n+    0x0413958a,     0x04918709,     0x045018c4,     0x0497b9bb,\n+    0x049eb6de,     0x04581d3e,     0x04c80693,     0x044a09a9,\n+    0x04410313,     0x04dcae33,     0x65808410,     0x658d89eb,\n+    0x65c685ef,     0x65c78145,     0x6582801a,     0x04ddbd53,\n+    0x65c2b4e3,     0x6580aebc,     0x65c1ae3a,     0x65cdac51,\n+    0x65819690,     0x65fa8033,     0x65b51229,     0x65ae22e4,\n+    0x65f055cb,     0x65b6606c,     0x04835b63,     0x04556736,\n+    0x043930e5,     0x04b13235,     0x04733123,     0x04ee3167,\n+    0x05ed6971,     0x05716fd1,     0x049a2f4f,     0x045834fb,\n+    0x04593f65,     0x04882f00,     0x048a2074,     0x65c72739,\n+    0x65863031,     0x65983dae,     0x048123d1,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":833,"deletions":774,"binary":false,"changes":1607,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -57,0 +57,1 @@\n+    protected final Architecture arch;\n@@ -64,1 +65,2 @@\n-        config = new TestHotSpotVMConfig(HotSpotJVMCIRuntime.runtime().getConfigStore());\n+        arch = codeCache.getTarget().arch;\n+        config = new TestHotSpotVMConfig(HotSpotJVMCIRuntime.runtime().getConfigStore(), arch);\n@@ -73,1 +75,0 @@\n-        Architecture arch = codeCache.getTarget().arch;\n","filename":"test\/hotspot\/jtreg\/compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/CodeInstallationTest.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,0 +25,2 @@\n+import jdk.vm.ci.aarch64.AArch64;\n+import jdk.vm.ci.code.Architecture;\n@@ -30,1 +32,1 @@\n-    public TestHotSpotVMConfig(HotSpotVMConfigStore config) {\n+    public TestHotSpotVMConfig(HotSpotVMConfigStore config, Architecture arch) {\n@@ -32,0 +34,1 @@\n+        ropProtection = (arch instanceof AArch64) ? getFieldValue(\"VM_Version::_rop_protection\", Boolean.class) : false;\n@@ -51,0 +54,2 @@\n+\n+    public final boolean ropProtection;\n","filename":"test\/hotspot\/jtreg\/compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/TestHotSpotVMConfig.java","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2020, Arm Limited. All rights reserved.\n+ * Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2022, Arm Limited. All rights reserved.\n@@ -257,0 +257,3 @@\n+        if (config.ropProtection) {\n+            code.emitInt(0xdac103be);  \/\/ pacia x30, x29\n+        }\n@@ -472,0 +475,3 @@\n+        if (config.ropProtection) {\n+            code.emitInt(0xdac113be);  \/\/ autia x30, x29\n+        }\n@@ -480,0 +486,3 @@\n+        if (config.ropProtection) {\n+            code.emitInt(0xdac113be);  \/\/ autia x30, x29\n+        }\n","filename":"test\/hotspot\/jtreg\/compiler\/jvmci\/jdk.vm.ci.code.test\/src\/jdk\/vm\/ci\/code\/test\/aarch64\/AArch64TestAssembler.java","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"}]}