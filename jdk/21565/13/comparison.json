{"files":[{"patch":"@@ -122,0 +122,1 @@\n+    inc_held_monitor_count();\n@@ -123,1 +124,0 @@\n-  increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -162,0 +162,1 @@\n+    dec_held_monitor_count();\n@@ -163,1 +164,0 @@\n-  decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -163,1 +163,1 @@\n-  does_not_return, requires_return\n+  does_not_return, requires_return, requires_pop_epilogue_return\n@@ -166,1 +166,0 @@\n-\n@@ -172,1 +171,1 @@\n-  bool _return_state;\n+  return_state_t _return_state;\n@@ -186,2 +185,11 @@\n-void StubAssembler::epilogue() {\n-  leave();\n+void StubAssembler::epilogue(bool use_pop) {\n+  \/\/ Avoid using a leave instruction when this frame may\n+  \/\/ have been frozen, since the current value of rfp\n+  \/\/ restored from the stub would be invalid. We still\n+  \/\/ must restore the rfp value saved on enter though.\n+  if (use_pop) {\n+    ldp(rfp, lr, Address(post(sp, 2 * wordSize)));\n+    authenticate_return_address();\n+  } else {\n+    leave();\n+  }\n@@ -206,3 +214,1 @@\n-  if (_return_state == requires_return) {\n-    __ epilogue();\n-  } else {\n+  if (_return_state == does_not_return) {\n@@ -210,0 +216,2 @@\n+  } else {\n+    __ epilogue(_return_state == requires_pop_epilogue_return);\n@@ -255,1 +263,1 @@\n-    if (i <= 18 && i != rscratch1->encoding() && i != rscratch2->encoding()) {\n+    if (r == rthread || (i <= 18 && i != rscratch1->encoding() && i != rscratch2->encoding())) {\n@@ -340,0 +348,9 @@\n+\/\/ return: offset in 64-bit words.\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+  CodeBlob* cb = f.cb();\n+  assert(cb == Runtime1::blob_for(C1StubId::monitorenter_id) ||\n+         cb == Runtime1::blob_for(C1StubId::monitorenter_nofpu_id), \"must be\");\n+  assert(cb != nullptr && cb->is_runtime_stub(), \"invalid frame\");\n+  int offset = cpu_reg_save_offsets[rthread->encoding()];\n+  return offset \/ 2;   \/\/ SP offsets are in halfwords\n+}\n@@ -865,1 +882,1 @@\n-        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments);\n+        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments, requires_pop_epilogue_return);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":27,"deletions":10,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -60,1 +60,1 @@\n-  assert_different_registers(oop, box, tmp, disp_hdr);\n+  assert_different_registers(oop, box, tmp, disp_hdr, rscratch2);\n@@ -113,4 +113,2 @@\n-  \/\/ The object's monitor m is unlocked iff m->owner == nullptr,\n-  \/\/ otherwise m->owner may contain a thread or a stack address.\n-  \/\/\n-  \/\/ Try to CAS m->owner from null to current thread.\n+  \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+  ldr(rscratch2, Address(rthread, JavaThread::lock_id_offset()));\n@@ -118,1 +116,1 @@\n-  cmpxchg(tmp, zr, rthread, Assembler::xword, \/*acquire*\/ true,\n+  cmpxchg(tmp, zr, rscratch2, Assembler::xword, \/*acquire*\/ true,\n@@ -130,1 +128,1 @@\n-  cmp(tmp3Reg, rthread);\n+  cmp(tmp3Reg, rscratch2);\n@@ -143,1 +141,3 @@\n-  increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n+  if (LockingMode == LM_LEGACY) {\n+    inc_held_monitor_count();\n+  }\n@@ -250,1 +250,3 @@\n-  decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+  if (LockingMode == LM_LEGACY) {\n+    dec_held_monitor_count();\n+  }\n@@ -258,1 +260,1 @@\n-  assert_different_registers(obj, box, t1, t2, t3);\n+  assert_different_registers(obj, box, t1, t2, t3, rscratch2);\n@@ -374,2 +376,3 @@\n-    \/\/ CAS owner (null => current thread).\n-    cmpxchg(t2_owner_addr, zr, rthread, Assembler::xword, \/*acquire*\/ true,\n+    \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+    ldr(rscratch2, Address(rthread, JavaThread::lock_id_offset()));\n+    cmpxchg(t2_owner_addr, zr, rscratch2, Assembler::xword, \/*acquire*\/ true,\n@@ -380,1 +383,1 @@\n-    cmp(t3_owner, rthread);\n+    cmp(t3_owner, rscratch2);\n@@ -393,1 +396,0 @@\n-  increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -562,1 +564,0 @@\n-  decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":16,"deletions":15,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -132,0 +132,5 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  assert(f.interpreter_frame_last_sp() == nullptr, \"should be null for top frame\");\n+  f.interpreter_frame_set_last_sp(f.unextended_sp());\n+}\n+\n@@ -152,0 +157,6 @@\n+  \/\/ The interpreter native wrapper code adds space in the stack equal to size_of_parameters()\n+  \/\/ after the fixed part of the frame. For wait0 this is equal to 3 words (this + long parameter).\n+  \/\/ We adjust by this size since otherwise the saved last sp will be less than the extended_sp.\n+  DEBUG_ONLY(Method* m = hf.interpreter_frame_method();)\n+  DEBUG_ONLY(int extra_space = m->is_object_wait0() ? m->size_of_parameters() : 0;)\n+\n@@ -155,1 +166,1 @@\n-  assert(hf.unextended_sp() >  (intptr_t*)hf.at(frame::interpreter_frame_extended_sp_offset), \"\");\n+  assert(hf.unextended_sp() + extra_space >  (intptr_t*)hf.at(frame::interpreter_frame_extended_sp_offset), \"\");\n@@ -216,1 +227,0 @@\n-    const int locals = hf.interpreter_frame_method()->max_locals();\n@@ -238,1 +248,1 @@\n-      int argsize = hf.compiled_frame_stack_argsize();\n+      int argsize = FKind::stack_argsize(hf);\n@@ -255,2 +265,2 @@\n-      fp = FKind::stub\n-        ? frame_sp + fsize - frame::sender_sp_offset \/\/ on AArch64, this value is used for the safepoint stub\n+      fp = FKind::stub || FKind::native\n+        ? frame_sp + fsize - frame::sender_sp_offset \/\/ fp always points to the address below the pushed return pc. We need correct address.\n@@ -280,0 +290,38 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  intptr_t* fp = caller_sp - frame::sender_sp_offset;\n+  patch_callee_link(f, fp);\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  intptr_t* sp = top.sp();\n+  CodeBlob* cb = top.cb();\n+\n+  if (cb->frame_size() == 2) {\n+    \/\/ C2 runtime stub case. For aarch64 the real size of the c2 runtime stub is 2 words bigger\n+    \/\/ than what we think, i.e. size is 4. This is because the _last_Java_sp is not set to the\n+    \/\/ sp right before making the call to the VM, but rather it is artificially set 2 words above\n+    \/\/ this real sp so that we can store the return address at last_Java_sp[-1], and keep this\n+    \/\/ property where we can retrieve the last_Java_pc from the last_Java_sp. But that means that\n+    \/\/ once we return to the runtime stub, the code will adjust sp according to this real size.\n+    \/\/ So we must adjust the frame size back here and we copy lr\/rfp again.\n+    sp -= 2;\n+    sp[-2] = sp[0];\n+    sp[-1] = sp[1];\n+\n+    log_develop_trace(continuations, preempt)(\"adjusted sp for c2 runtime stub, initial sp: \" INTPTR_FORMAT \" final sp: \" INTPTR_FORMAT\n+                                              \" fp: \" INTPTR_FORMAT, p2i(sp + 2), p2i(sp), sp[-2]);\n+  }\n+  return sp;\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  frame enterSpecial = new_entry_frame();\n+  intptr_t* sp = enterSpecial.sp();\n+\n+  sp[-1] = (intptr_t)ContinuationEntry::cleanup_pc();\n+  sp[-2] = (intptr_t)enterSpecial.fp();\n+\n+  log_develop_trace(continuations, preempt)(\"push_cleanup_continuation initial sp: \" INTPTR_FORMAT \" final sp: \" INTPTR_FORMAT, p2i(sp + 2 * frame::metadata_words), p2i(sp));\n+  return sp;\n+}\n+\n@@ -288,1 +336,3 @@\n-  assert((intptr_t*)f.at_relative(frame::interpreter_frame_extended_sp_offset) < f.unextended_sp(), \"\");\n+  DEBUG_ONLY(Method* m = hf.interpreter_frame_method();)\n+  DEBUG_ONLY(int extra_space = m->is_object_wait0() ? m->size_of_parameters() : 0;) \/\/ see comment in relativize_interpreted_frame_metadata()\n+  assert((intptr_t*)f.at_relative(frame::interpreter_frame_extended_sp_offset) < f.unextended_sp() + extra_space, \"\");\n","filename":"src\/hotspot\/cpu\/aarch64\/continuationFreezeThaw_aarch64.inline.hpp","additions":57,"deletions":7,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,16 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  if (f.is_runtime_frame()) {\n+    \/\/ Unlike x86 we don't know where in the callee frame the return pc is\n+    \/\/ saved so we can't patch the return from the VM call back to Java.\n+    \/\/ Instead, we will patch the return from the runtime stub back to the\n+    \/\/ compiled method so that the target returns to the preempt cleanup stub.\n+    intptr_t* caller_sp = f.sp() + f.cb()->frame_size();\n+    caller_sp[-1] = (intptr_t)StubRoutines::cont_preempt_stub();\n+  } else {\n+    \/\/ The target will check for preemption once it returns to the interpreter\n+    \/\/ or the native wrapper code and will manually jump to the preempt stub.\n+    JavaThread *thread = JavaThread::current();\n+    thread->set_preempt_alternate_return(StubRoutines::cont_preempt_stub());\n+  }\n+}\n+\n@@ -86,1 +102,0 @@\n-#ifdef ASSERT\n@@ -92,0 +107,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/aarch64\/continuationHelper_aarch64.inline.hpp","additions":18,"deletions":2,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -423,0 +423,30 @@\n+#if defined(ASSERT)\n+static address get_register_address_in_stub(const frame& stub_fr, VMReg reg) {\n+  RegisterMap map(nullptr,\n+                  RegisterMap::UpdateMap::include,\n+                  RegisterMap::ProcessFrames::skip,\n+                  RegisterMap::WalkContinuation::skip);\n+  stub_fr.oop_map()->update_register_map(&stub_fr, &map);\n+  return map.location(reg, stub_fr.sp());\n+}\n+#endif\n+\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  CodeBlob* cb = f.cb();\n+  assert(cb != nullptr && cb->is_runtime_stub(), \"invalid frame\");\n+\n+  JavaThread** thread_addr;\n+#ifdef COMPILER1\n+  if (cb == Runtime1::blob_for(C1StubId::monitorenter_id) ||\n+      cb == Runtime1::blob_for(C1StubId::monitorenter_nofpu_id)) {\n+    thread_addr = (JavaThread**)(f.sp() + Runtime1::runtime_blob_current_thread_offset(f));\n+  } else\n+#endif\n+  {\n+    \/\/ c2 only saves rbp in the stub frame so nothing to do.\n+    thread_addr = nullptr;\n+  }\n+  assert(get_register_address_in_stub(f, SharedRuntime::thread_register()) == (address)thread_addr, \"wrong thread address\");\n+  return thread_addr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -76,1 +76,2 @@\n-    interpreter_frame_oop_temp_offset                =  3, \/\/ for native calls only\n+    interpreter_frame_result_handler_offset          =  3, \/\/ for native calls only\n+    interpreter_frame_oop_temp_offset                =  2, \/\/ for native calls only\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -669,1 +669,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -700,1 +700,1 @@\n-      b(count);\n+      b(done);\n@@ -750,1 +750,5 @@\n-      br(Assembler::EQ, count);\n+      br(Assembler::NE, slow_case);\n+\n+      bind(count);\n+      inc_held_monitor_count();\n+      b(done);\n@@ -755,1 +759,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -758,4 +762,0 @@\n-    b(done);\n-\n-    bind(count);\n-    increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -807,0 +807,1 @@\n+    Label slow_case;\n@@ -808,1 +809,0 @@\n-      Label slow_case;\n@@ -810,2 +810,1 @@\n-      b(count);\n-      bind(slow_case);\n+      b(done);\n@@ -821,1 +820,5 @@\n-      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, &slow_case);\n+\n+      bind(count);\n+      dec_held_monitor_count();\n+      b(done);\n@@ -823,0 +826,2 @@\n+\n+    bind(slow_case);\n@@ -826,5 +831,0 @@\n-    b(done);\n-\n-    bind(count);\n-    decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n-\n@@ -1534,0 +1534,49 @@\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result,\n+                                                    address entry_point,\n+                                                    Register arg_1) {\n+  assert(arg_1 == c_rarg1, \"\");\n+  Label resume_pc, not_preempted;\n+\n+#ifdef ASSERT\n+  {\n+    Label L;\n+    ldr(rscratch1, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+    cbz(rscratch1, L);\n+    stop(\"Should not have alternate return address set\");\n+    bind(L);\n+  }\n+#endif \/* ASSERT *\/\n+\n+  \/\/ Force freeze slow path.\n+  push_cont_fastpath();\n+\n+  \/\/ Make VM call. In case of preemption set last_pc to the one we want to resume to.\n+  adr(rscratch1, resume_pc);\n+  str(rscratch1, Address(rthread, JavaThread::last_Java_pc_offset()));\n+  call_VM_base(oop_result, noreg, noreg, entry_point, 1, false \/*check_exceptions*\/);\n+\n+  pop_cont_fastpath();\n+\n+  \/\/ Check if preempted.\n+  ldr(rscratch1, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+  cbz(rscratch1, not_preempted);\n+  str(zr, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+  br(rscratch1);\n+\n+  \/\/ In case of preemption, this is where we will resume once we finally acquire the monitor.\n+  bind(resume_pc);\n+  restore_after_resume(false \/* is_native *\/);\n+\n+  bind(not_preempted);\n+}\n+\n+void InterpreterMacroAssembler::restore_after_resume(bool is_native) {\n+  lea(rscratch1, ExternalAddress(Interpreter::cont_resume_interpreter_adapter()));\n+  blr(rscratch1);\n+  if (is_native) {\n+    \/\/ On resume we need to set up stack as expected\n+    push(dtos);\n+    push(ltos);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":66,"deletions":17,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -61,0 +61,5 @@\n+  void call_VM_preemptable(Register oop_result,\n+                           address entry_point,\n+                           Register arg_1);\n+  void restore_after_resume(bool is_native);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"interpreter\/interpreterRuntime.hpp\"\n@@ -778,0 +779,4 @@\n+static bool is_preemptable(address entry_point) {\n+  return entry_point == CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter);\n+}\n+\n@@ -813,1 +818,6 @@\n-  set_last_Java_frame(last_java_sp, rfp, l, rscratch1);\n+  if (is_preemptable(entry_point)) {\n+    \/\/ skip setting last_pc since we already set it to desired value.\n+    set_last_Java_frame(last_java_sp, rfp, noreg, rscratch1);\n+  } else {\n+    set_last_Java_frame(last_java_sp, rfp, l, rscratch1);\n+  }\n@@ -5330,0 +5340,34 @@\n+\/\/ Clobbers: rscratch1 and rscratch2\n+void MacroAssembler::inc_held_monitor_count() {\n+  Address dst(rthread, JavaThread::held_monitor_count_offset());\n+#ifdef ASSERT\n+  ldr(rscratch2, dst);\n+  increment(rscratch2);\n+  str(rscratch2, dst);\n+  Label ok;\n+  tbz(rscratch2, 63, ok);\n+  STOP(\"assert(held monitor count underflow)\");\n+  should_not_reach_here();\n+  bind(ok);\n+#else\n+  increment(dst);\n+#endif\n+}\n+\n+\/\/ Clobbers: rscratch1 and rscratch2\n+void MacroAssembler::dec_held_monitor_count() {\n+  Address dst(rthread, JavaThread::held_monitor_count_offset());\n+#ifdef ASSERT\n+  ldr(rscratch2, dst);\n+  decrement(rscratch2);\n+  str(rscratch2, dst);\n+  Label ok;\n+  tbz(rscratch2, 63, ok);\n+  STOP(\"assert(held monitor count underflow)\");\n+  should_not_reach_here();\n+  bind(ok);\n+#else\n+  decrement(dst);\n+#endif\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":45,"deletions":1,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -941,2 +941,5 @@\n-  void push_cont_fastpath(Register java_thread);\n-  void pop_cont_fastpath(Register java_thread);\n+  void push_cont_fastpath(Register java_thread = rthread);\n+  void pop_cont_fastpath(Register java_thread = rthread);\n+\n+  void inc_held_monitor_count();\n+  void dec_held_monitor_count();\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1169,0 +1169,1 @@\n+  ContinuationEntry::_thaw_call_pc_offset = __ pc() - start;\n@@ -1175,0 +1176,1 @@\n+  ContinuationEntry::_cleanup_offset = __ pc() - start;\n@@ -1271,0 +1273,4 @@\n+void SharedRuntime::continuation_enter_cleanup(MacroAssembler* masm) {\n+  ::continuation_enter_cleanup(masm);\n+}\n+\n@@ -1737,2 +1743,3 @@\n-  \/\/ be pushed on the stack when we do a stack traversal).\n-  \/\/ We use the same pc\/oopMap repeatedly when we call out\n+  \/\/ be pushed on the stack when we do a stack traversal). It is enough that the pc()\n+  \/\/ points into the right code segment. It does not have to be the correct return pc.\n+  \/\/ We use the same pc\/oopMap repeatedly when we call out.\n@@ -1741,1 +1748,9 @@\n-  __ set_last_Java_frame(sp, noreg, native_return, rscratch1);\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ For convenience we use the pc we want to resume to in case of preemption on Object.wait.\n+    __ set_last_Java_frame(sp, noreg, native_return, rscratch1);\n+  } else {\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ set_last_Java_frame(sp, noreg, __ pc(), rscratch1);\n+  }\n@@ -1819,0 +1834,3 @@\n+\n+      __ bind(count);\n+      __ inc_held_monitor_count();\n@@ -1823,2 +1841,0 @@\n-    __ bind(count);\n-    __ increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -1843,5 +1859,0 @@\n-  __ bind(native_return);\n-\n-  intptr_t return_pc = (intptr_t) __ pc();\n-  oop_maps->add_gc_map(return_pc - start, map);\n-\n@@ -1906,0 +1917,12 @@\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ Check preemption for Object.wait()\n+    __ ldr(rscratch1, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+    __ cbz(rscratch1, native_return);\n+    __ str(zr, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+    __ br(rscratch1);\n+    __ bind(native_return);\n+\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n+  }\n+\n@@ -1929,1 +1952,1 @@\n-      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+      __ dec_held_monitor_count();\n@@ -1952,1 +1975,1 @@\n-      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+      __ dec_held_monitor_count();\n@@ -1956,1 +1979,0 @@\n-      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n@@ -2024,0 +2046,3 @@\n+    \/\/ Force freeze slow path in case we try to preempt. We will pin the\n+    \/\/ vthread to the carrier (see FreezeBase::recurse_freeze_native_frame()).\n+    __ push_cont_fastpath();\n@@ -2025,0 +2050,1 @@\n+    __ pop_cont_fastpath();\n@@ -2565,0 +2591,4 @@\n+VMReg SharedRuntime::thread_register() {\n+  return rthread->as_VMReg();\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":43,"deletions":13,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -119,0 +119,1 @@\n+        + (f.interpreter_frame_method()->is_native() ? 1 : 0) \/\/ temp oop slot\n","filename":"src\/hotspot\/cpu\/aarch64\/stackChunkFrameStream_aarch64.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -7143,0 +7143,31 @@\n+  address generate_cont_preempt_stub() {\n+    if (!Continuations::enabled()) return nullptr;\n+    StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+    address start = __ pc();\n+\n+    __ reset_last_Java_frame(true);\n+\n+    \/\/ Set sp to enterSpecial frame, i.e. remove all frames copied into the heap.\n+    __ ldr(rscratch2, Address(rthread, JavaThread::cont_entry_offset()));\n+    __ mov(sp, rscratch2);\n+\n+    Label preemption_cancelled;\n+    __ ldrb(rscratch1, Address(rthread, JavaThread::preemption_cancelled_offset()));\n+    __ cbnz(rscratch1, preemption_cancelled);\n+\n+    \/\/ Remove enterSpecial frame from the stack and return to Continuation.run() to unmount.\n+    SharedRuntime::continuation_enter_cleanup(_masm);\n+    __ leave();\n+    __ ret(lr);\n+\n+    \/\/ We acquired the monitor after freezing the frames so call thaw to continue execution.\n+    __ bind(preemption_cancelled);\n+    __ strb(zr, Address(rthread, JavaThread::preemption_cancelled_offset()));\n+    __ lea(rfp, Address(sp, checked_cast<int32_t>(ContinuationEntry::size())));\n+    __ lea(rscratch1, ExternalAddress(ContinuationEntry::thaw_call_pc_address()));\n+    __ ldr(rscratch1, Address(rscratch1));\n+    __ br(rscratch1);\n+\n+    return start;\n+  }\n+\n@@ -8225,0 +8256,1 @@\n+    StubRoutines::_cont_preempt_stub = generate_cont_preempt_stub();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -610,0 +610,34 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  if (!Continuations::enabled()) return nullptr;\n+  address start = __ pc();\n+\n+  __ restore_bcp();\n+  __ restore_locals();\n+\n+  \/\/ Restore constant pool cache\n+  __ ldr(rcpool, Address(rfp, frame::interpreter_frame_cache_offset * wordSize));\n+\n+  \/\/ Restore Java expression stack pointer\n+  __ ldr(rscratch1, Address(rfp, frame::interpreter_frame_last_sp_offset * wordSize));\n+  __ lea(esp, Address(rfp, rscratch1, Address::lsl(Interpreter::logStackElementSize)));\n+  \/\/ and NULL it as marker that esp is now tos until next java call\n+  __ str(zr, Address(rfp, frame::interpreter_frame_last_sp_offset * wordSize));\n+\n+  \/\/ Restore machine SP\n+  __ ldr(rscratch1, Address(rfp, frame::interpreter_frame_extended_sp_offset * wordSize));\n+  __ lea(sp, Address(rfp, rscratch1, Address::lsl(LogBytesPerWord)));\n+\n+  \/\/ Restore method\n+  __ ldr(rmethod, Address(rfp, frame::interpreter_frame_method_offset * wordSize));\n+\n+  \/\/ Restore dispatch\n+  uint64_t offset;\n+  __ adrp(rdispatch, ExternalAddress((address)Interpreter::dispatch_table()), offset);\n+  __ add(rdispatch, rdispatch, offset);\n+\n+  __ ret(lr);\n+\n+  return start;\n+}\n+\n+\n@@ -1317,0 +1351,2 @@\n+  __ str(r0, Address(rfp, frame::interpreter_frame_result_handler_offset * wordSize));\n+\n@@ -1352,3 +1388,4 @@\n-  \/\/ Set the last Java PC in the frame anchor to be the return address from\n-  \/\/ the call to the native method: this will allow the debugger to\n-  \/\/ generate an accurate stack trace.\n+  \/\/ It is enough that the pc() points into the right code\n+  \/\/ segment. It does not have to be the correct return pc.\n+  \/\/ For convenience we use the pc we want to resume to in\n+  \/\/ case of preemption on Object.wait.\n@@ -1375,0 +1412,2 @@\n+  __ push_cont_fastpath();\n+\n@@ -1377,1 +1416,3 @@\n-  __ bind(native_return);\n+\n+  __ pop_cont_fastpath();\n+\n@@ -1435,0 +1476,15 @@\n+  if (LockingMode != LM_LEGACY) {\n+    \/\/ Check preemption for Object.wait()\n+    Label not_preempted;\n+    __ ldr(rscratch1, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+    __ cbz(rscratch1, not_preempted);\n+    __ str(zr, Address(rthread, JavaThread::preempt_alternate_return_offset()));\n+    __ br(rscratch1);\n+    __ bind(native_return);\n+    __ restore_after_resume(true \/* is_native *\/);\n+    __ bind(not_preempted);\n+  } else {\n+    \/\/ any pc will do so just use this one for LM_LEGACY to keep code together.\n+    __ bind(native_return);\n+  }\n+\n@@ -1453,0 +1509,1 @@\n+    __ ldr(result_handler, Address(rfp, frame::interpreter_frame_result_handler_offset*wordSize));\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":61,"deletions":4,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -254,0 +254,4 @@\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+  Unimplemented();\n+  return 0;\n+}\n","filename":"src\/hotspot\/cpu\/arm\/c1_Runtime1_arm.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -51,0 +51,4 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -86,0 +90,14 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  Unimplemented();\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/continuationFreezeThaw_arm.inline.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -38,0 +38,4 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -65,1 +69,0 @@\n-#ifdef ASSERT\n@@ -70,0 +73,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/arm\/continuationHelper_arm.inline.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -328,0 +328,5 @@\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/frame_arm.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1361,0 +1361,5 @@\n+VMReg SharedRuntime::thread_register() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -462,0 +462,4 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/templateInterpreterGenerator_arm.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1819,0 +1819,1 @@\n+  inline bool is_branch(address a);\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -457,0 +457,6 @@\n+inline bool Assembler::is_branch(address a) {\n+  int32_t instr = *(int32_t*) a;\n+  int op = inv_op_ppc(instr);\n+  return op == b_op || op == bc_op;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.inline.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -136,1 +136,3 @@\n-  inc_held_monitor_count(Rmark \/*tmp*\/);\n+  if (LockingMode == LM_LEGACY) {\n+    inc_held_monitor_count(Rmark \/*tmp*\/);\n+  }\n@@ -182,1 +184,3 @@\n-  dec_held_monitor_count(Rmark \/*tmp*\/);\n+  if (LockingMode == LM_LEGACY) {\n+    dec_held_monitor_count(Rmark \/*tmp*\/);\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -67,1 +67,2 @@\n-  reset_last_Java_frame();\n+  \/\/ Last java sp can be null when the RT call was preempted\n+  reset_last_Java_frame(false \/* check_last_java_sp *\/);\n@@ -260,0 +261,5 @@\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+  \/\/ On PPC virtual threads don't save the JavaThread* in their context (e.g. C1 stub frames).\n+  ShouldNotCallThis();\n+  return 0;\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_Runtime1_ppc.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -74,0 +74,6 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  \/\/ nothing to do\n+  DEBUG_ONLY( intptr_t* lspp = (intptr_t*) &(f.get_ijava_state()->top_frame_sp); )\n+  assert(*lspp == f.unextended_sp() - f.fp(), \"should be \" INTPTR_FORMAT \" usp:\" INTPTR_FORMAT \" fp:\" INTPTR_FORMAT, *lspp, p2i(f.unextended_sp()), p2i(f.fp()));\n+}\n+\n@@ -353,0 +359,1 @@\n+      assert(!Interpreter::contains(pc), \"sp:\" PTR_FORMAT \" pc:\" PTR_FORMAT, p2i(sp), p2i(pc));\n@@ -483,2 +490,2 @@\n-  assert(is_aligned(caller.fp(), frame::frame_alignment), \"\");\n-  assert(is_aligned(caller.sp(), frame::frame_alignment), \"\");\n+  assert(is_aligned(caller.fp(), frame::frame_alignment), PTR_FORMAT, p2i(caller.fp()));\n+  \/\/ caller.sp() can be unaligned. This is fixed below.\n@@ -513,1 +520,1 @@\n-    int argsize = hf.compiled_frame_stack_argsize();\n+    int argsize = FKind::stack_argsize(hf);\n@@ -546,0 +553,18 @@\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  \/\/ Nothing to do\n+  return top.sp();\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  frame enterSpecial = new_entry_frame();\n+  frame::common_abi* enterSpecial_abi = (frame::common_abi*)enterSpecial.sp();\n+\n+  enterSpecial_abi->lr = (intptr_t)ContinuationEntry::cleanup_pc();\n+\n+  log_develop_trace(continuations, preempt)(\"push_cleanup_continuation enterSpecial sp: \" INTPTR_FORMAT \" cleanup pc: \" INTPTR_FORMAT,\n+                                            p2i(enterSpecial_abi),\n+                                            p2i(ContinuationEntry::cleanup_pc()));\n+\n+  return enterSpecial.sp();\n+}\n+\n@@ -552,0 +577,4 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  assert(f.own_abi()->callers_sp == (uint64_t)caller_sp, \"should have been fixed by patch_caller_links\");\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/continuationFreezeThaw_ppc.inline.hpp","additions":32,"deletions":3,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -30,4 +30,12 @@\n-template<typename FKind>\n-static inline intptr_t** link_address(const frame& f) {\n-  Unimplemented();\n-  return nullptr;\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  if (f.is_runtime_frame()) {\n+    \/\/ Patch the pc of the now old last Java frame (we already set the anchor to enterSpecial)\n+    \/\/ so that when target goes back to Java it will actually return to the preempt cleanup stub.\n+    frame::common_abi* abi = (frame::common_abi*)f.sp();\n+    abi->lr = (uint64_t)StubRoutines::cont_preempt_stub();\n+  } else {\n+    \/\/ The target will check for preemption once it returns to the interpreter\n+    \/\/ or the native wrapper code and will manually jump to the preempt stub.\n+    JavaThread *thread = JavaThread::current();\n+    thread->set_preempt_alternate_return(StubRoutines::cont_preempt_stub());\n+  }\n@@ -62,1 +70,0 @@\n-#ifdef ASSERT\n@@ -67,0 +74,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/ppc\/continuationHelper_ppc.inline.hpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -246,0 +246,5 @@\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  \/\/ The current thread (JavaThread*) is never stored on the stack\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/frame_ppc.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -56,1 +56,4 @@\n-      assert(is_compiled_frame(), \"\");\n+      assert(is_compiled_frame()\n+             || is_native_frame()   \/\/ native wrapper (nmethod) for j.l.Object::wait0\n+             || is_runtime_frame(), \/\/ e.g. Runtime1::monitorenter, SharedRuntime::complete_monitor_locking_C\n+             \"sp:\" PTR_FORMAT \" fp:\" PTR_FORMAT \" name:%s\", p2i(_sp), p2i(_unextended_sp + _cb->frame_size()), _cb->name());\n","filename":"src\/hotspot\/cpu\/ppc\/frame_ppc.inline.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -52,0 +52,8 @@\n+  void call_VM_preemptable(Register oop_result, address entry_point, Register arg_1, bool check_exceptions = true);\n+  void restore_after_resume(Register fp);\n+  \/\/ R22 and R31 are preserved when a vthread gets preempted in the interpreter.\n+  \/\/ The interpreter already assumes that these registers are nonvolatile across native calls.\n+  bool nonvolatile_accross_vthread_preemtion(Register r) const {\n+    return r->is_nonvolatile() && ((r == R22) || (r == R31));\n+  }\n+\n@@ -185,1 +193,1 @@\n-  void call_VM(Register oop_result, address entry_point, bool check_exceptions = true);\n+  void call_VM(Register oop_result, address entry_point, bool check_exceptions = true, Label* last_java_pc = nullptr);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -935,1 +935,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+    call_VM_preemptable(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -956,2 +956,1 @@\n-    Label count_locking, done;\n-    Label cas_failed, slow_case;\n+    Label count_locking, done, slow_case, cas_failed;\n@@ -972,1 +971,1 @@\n-      b(count_locking);\n+      b(done);\n@@ -1038,2 +1037,1 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-    b(done);\n+    call_VM_preemptable(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -1041,3 +1039,7 @@\n-    align(32, 12);\n-    bind(count_locking);\n-    inc_held_monitor_count(current_header \/*tmp*\/);\n+\n+    if (LockingMode == LM_LEGACY) {\n+      b(done);\n+      align(32, 12);\n+      bind(count_locking);\n+      inc_held_monitor_count(current_header \/*tmp*\/);\n+    }\n@@ -1140,1 +1142,3 @@\n-    dec_held_monitor_count(current_header \/*tmp*\/);\n+    if (LockingMode == LM_LEGACY) {\n+      dec_held_monitor_count(current_header \/*tmp*\/);\n+    }\n@@ -2136,1 +2140,1 @@\n-void InterpreterMacroAssembler::call_VM(Register oop_result, address entry_point, bool check_exceptions) {\n+void InterpreterMacroAssembler::call_VM(Register oop_result, address entry_point, bool check_exceptions, Label* last_java_pc) {\n@@ -2139,1 +2143,1 @@\n-  MacroAssembler::call_VM(oop_result, entry_point, false);\n+  MacroAssembler::call_VM(oop_result, entry_point, false \/*check_exceptions*\/, last_java_pc);\n@@ -2158,0 +2162,68 @@\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result, address entry_point,\n+                                        Register arg_1, bool check_exceptions) {\n+  if (!Continuations::enabled()) {\n+    call_VM(oop_result, entry_point, arg_1, check_exceptions);\n+    return;\n+  }\n+\n+  Label resume_pc, not_preempted;\n+\n+  DEBUG_ONLY(ld(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread));\n+  DEBUG_ONLY(cmpdi(CCR0, R0, 0));\n+  asm_assert_eq(\"Should not have alternate return address set\");\n+\n+  \/\/ Preserve 2 registers\n+  assert(nonvolatile_accross_vthread_preemtion(R31) && nonvolatile_accross_vthread_preemtion(R22), \"\");\n+  ld(R3_ARG1, _abi0(callers_sp), R1_SP); \/\/ load FP\n+  std(R31, _ijava_state_neg(lresult), R3_ARG1);\n+  std(R22, _ijava_state_neg(fresult), R3_ARG1);\n+\n+  \/\/ We set resume_pc as last java pc. It will be saved if the vthread gets preempted.\n+  \/\/ Later execution will continue right there.\n+  mr_if_needed(R4_ARG2, arg_1);\n+  push_cont_fastpath();\n+  call_VM(oop_result, entry_point, false \/*check_exceptions*\/, &resume_pc \/* last_java_pc *\/);\n+  pop_cont_fastpath();\n+\n+  \/\/ Jump to handler if the call was preempted\n+  ld(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+  cmpdi(CCR0, R0, 0);\n+  beq(CCR0, not_preempted);\n+  mtlr(R0);\n+  li(R0, 0);\n+  std(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+  blr();\n+\n+  bind(resume_pc); \/\/ Location to resume execution\n+  restore_after_resume(noreg \/* fp *\/);\n+  bind(not_preempted);\n+}\n+\n+void InterpreterMacroAssembler::restore_after_resume(Register fp) {\n+  if (!Continuations::enabled()) return;\n+\n+  const address resume_adapter = TemplateInterpreter::cont_resume_interpreter_adapter();\n+  add_const_optimized(R31, R29_TOC, MacroAssembler::offset_to_global_toc(resume_adapter));\n+  mtctr(R31);\n+  bctrl();\n+  \/\/ Restore registers that are preserved across vthread preemption\n+  assert(nonvolatile_accross_vthread_preemtion(R31) && nonvolatile_accross_vthread_preemtion(R22), \"\");\n+  ld(R3_ARG1, _abi0(callers_sp), R1_SP); \/\/ load FP\n+  ld(R31, _ijava_state_neg(lresult), R3_ARG1);\n+  ld(R22, _ijava_state_neg(fresult), R3_ARG1);\n+#ifdef ASSERT\n+  \/\/ Assert FP is in R11_scratch1 (see generate_cont_resume_interpreter_adapter())\n+  {\n+    Label ok;\n+    ld(R12_scratch2, 0, R1_SP);  \/\/ load fp\n+    cmpd(CCR0, R12_scratch2, R11_scratch1);\n+    beq(CCR0, ok);\n+    stop(FILE_AND_LINE \": FP is expected in R11_scratch1\");\n+    bind(ok);\n+  }\n+#endif\n+  if (fp != noreg && fp != R11_scratch1) {\n+    mr(fp, R11_scratch1);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":84,"deletions":12,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"interpreter\/interpreterRuntime.hpp\"\n@@ -118,1 +119,2 @@\n-                                                       bool add_relocation, bool emit_dummy_addr) {\n+                                                       bool add_relocation, bool emit_dummy_addr,\n+                                                       bool add_addr_to_reloc) {\n@@ -132,1 +134,4 @@\n-      relocate(internal_word_Relocation::spec(addr));\n+      RelocationHolder rh = add_addr_to_reloc ?\n+          internal_word_Relocation::spec(addr) :\n+          internal_word_Relocation::spec_for_immediate();\n+      relocate(rh);\n@@ -717,0 +722,1 @@\n+#ifdef ASSERT\n@@ -732,0 +738,31 @@\n+void MacroAssembler::clobber_nonvolatile_registers() {\n+  BLOCK_COMMENT(\"clobber nonvolatile registers {\");\n+  Register regs[] = {\n+      R14,\n+      R15,\n+      \/\/ don't zap R16_thread\n+      R17,\n+      R18,\n+      R19,\n+      R20,\n+      R21,\n+      R22,\n+      R23,\n+      R24,\n+      R25,\n+      R26,\n+      R27,\n+      R28,\n+      \/\/ don't zap R29_TOC\n+      R30,\n+      R31\n+  };\n+  Register bad = regs[0];\n+  load_const_optimized(bad, 0xbad0101babe11111);\n+  for (uint32_t i = 1; i < (sizeof(regs) \/ sizeof(Register)); i++) {\n+    mr(regs[i], bad);\n+  }\n+  BLOCK_COMMENT(\"} clobber nonvolatile registers\");\n+}\n+#endif \/\/ ASSERT\n+\n@@ -1286,1 +1323,2 @@\n-                                  bool     check_exceptions) {\n+                                  bool     check_exceptions,\n+                                  Label*   last_java_pc) {\n@@ -1292,1 +1330,1 @@\n-  set_top_ijava_frame_at_SP_as_last_Java_frame(last_java_sp, R11_scratch1);\n+  set_top_ijava_frame_at_SP_as_last_Java_frame(last_java_sp, R11_scratch1, last_java_pc);\n@@ -1321,2 +1359,2 @@\n-void MacroAssembler::call_VM(Register oop_result, address entry_point, bool check_exceptions) {\n-  call_VM_base(oop_result, noreg, entry_point, check_exceptions);\n+void MacroAssembler::call_VM(Register oop_result, address entry_point, bool check_exceptions, Label* last_java_pc) {\n+  call_VM_base(oop_result, noreg, entry_point, check_exceptions, last_java_pc);\n@@ -2623,2 +2661,0 @@\n-  \/\/ The object's monitor m is unlocked iff m->owner is null,\n-  \/\/ otherwise m->owner may contain a thread or a stack address.\n@@ -2626,1 +2662,1 @@\n-  \/\/ Try to CAS m->owner from null to current thread.\n+  \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n@@ -2628,0 +2664,2 @@\n+  Register thread_id = displaced_header;\n+  ld(thread_id, in_bytes(JavaThread::lock_id_offset()), R16_thread);\n@@ -2631,1 +2669,1 @@\n-           \/*exchange_value=*\/R16_thread,\n+           \/*exchange_value=*\/thread_id,\n@@ -2641,1 +2679,1 @@\n-  cmpd(flag, current_header, R16_thread);\n+  cmpd(flag, current_header, thread_id);\n@@ -2650,1 +2688,1 @@\n-  \/\/ flag == EQ indicates success, increment held monitor count\n+  \/\/ flag == EQ indicates success, increment held monitor count if LM_LEGACY is enabled\n@@ -2653,1 +2691,3 @@\n-  inc_held_monitor_count(temp);\n+  if (LockingMode == LM_LEGACY) {\n+    inc_held_monitor_count(temp);\n+  }\n@@ -2673,1 +2713,1 @@\n-  Label success, failure, object_has_monitor, notRecursive;\n+  Label success, failure, object_has_monitor, not_recursive;\n@@ -2719,1 +2759,1 @@\n-  blt(CCR0, notRecursive); \/\/ Not recursive if negative after decrement.\n+  blt(CCR0, not_recursive); \/\/ Not recursive if negative after decrement.\n@@ -2728,1 +2768,1 @@\n-  bind(notRecursive);\n+  bind(not_recursive);\n@@ -2758,1 +2798,1 @@\n-  \/\/ flag == EQ indicates success, decrement held monitor count\n+  \/\/ flag == EQ indicates success, decrement held monitor count if LM_LEGACY is enabled\n@@ -2761,1 +2801,3 @@\n-  dec_held_monitor_count(temp);\n+  if (LockingMode == LM_LEGACY) {\n+    dec_held_monitor_count(temp);\n+  }\n@@ -2780,0 +2822,1 @@\n+  assert(UseObjectMonitorTable || tmp3 == noreg, \"tmp3 not needed\");\n@@ -2802,2 +2845,1 @@\n-  const Register mark = tmp1;\n-  const Register t = tmp3; \/\/ Usage of R0 allowed!\n+  Register mark = tmp1;\n@@ -2821,3 +2863,3 @@\n-    subi(t, top, oopSize);\n-    ldx(t, R16_thread, t);\n-    cmpd(CCR0, obj, t);\n+    subi(R0, top, oopSize);\n+    ldx(R0, R16_thread, R0);\n+    cmpd(CCR0, obj, R0);\n@@ -2828,2 +2870,2 @@\n-    andi_(t, mark, markWord::lock_mask_in_place);\n-    cmpldi(CCR0, t, markWord::unlocked_value);\n+    andi_(R0, mark, markWord::lock_mask_in_place);\n+    cmpldi(CCR0, R0, markWord::unlocked_value);\n@@ -2852,1 +2894,1 @@\n-    const Register monitor = mark;\n+    const Register monitor    = UseObjectMonitorTable ? tmp1 : noreg;\n@@ -2854,0 +2896,1 @@\n+    const Register thread_id  = UseObjectMonitorTable ? tmp3 : tmp1;\n@@ -2859,0 +2902,1 @@\n+      mark = noreg;\n@@ -2868,2 +2912,2 @@\n-        ld(tmp3, 0, cache_addr);\n-        cmpd(CCR0, tmp3, obj);\n+        ld(R0, 0, cache_addr);\n+        cmpd(CCR0, R0, obj);\n@@ -2880,2 +2924,2 @@\n-      ld(tmp3, 0, cache_addr);\n-      cmpd(CCR0, tmp3, obj);\n+      ld(R0, 0, cache_addr);\n+      cmpd(CCR0, R0, obj);\n@@ -2886,1 +2930,1 @@\n-      cmpdi(CCR1, tmp3, 0);\n+      cmpdi(CCR1, R0, 0);\n@@ -2898,1 +2942,3 @@\n-    \/\/ CAS owner (null => current thread).\n+    \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+    assert_different_registers(thread_id, monitor, owner_addr, box, R0);\n+    ld(thread_id, in_bytes(JavaThread::lock_id_offset()), R16_thread);\n@@ -2900,1 +2946,1 @@\n-            \/*current_value=*\/t,\n+            \/*current_value=*\/R0,\n@@ -2902,1 +2948,1 @@\n-            \/*exchange_value=*\/R16_thread,\n+            \/*exchange_value=*\/thread_id,\n@@ -2909,1 +2955,1 @@\n-    cmpd(CCR0, t, R16_thread);\n+    cmpd(CCR0, R0, thread_id);\n@@ -2932,1 +2978,0 @@\n-  inc_held_monitor_count(tmp1);\n@@ -3107,1 +3152,0 @@\n-  dec_held_monitor_count(t);\n@@ -3189,3 +3233,5 @@\n-void MacroAssembler::reset_last_Java_frame(void) {\n-  asm_assert_mem8_isnot_zero(in_bytes(JavaThread::last_Java_sp_offset()),\n-                             R16_thread, \"SP was not set, still zero\");\n+void MacroAssembler::reset_last_Java_frame(bool check_last_java_sp) {\n+  if (check_last_java_sp) {\n+    asm_assert_mem8_isnot_zero(in_bytes(JavaThread::last_Java_sp_offset()),\n+                               R16_thread, \"SP was not set, still zero\");\n+  }\n@@ -3204,1 +3250,1 @@\n-void MacroAssembler::set_top_ijava_frame_at_SP_as_last_Java_frame(Register sp, Register tmp1) {\n+void MacroAssembler::set_top_ijava_frame_at_SP_as_last_Java_frame(Register sp, Register tmp1, Label* jpc) {\n@@ -3207,5 +3253,5 @@\n-  \/\/ sp points to a TOP_IJAVA_FRAME, retrieve frame's PC via\n-  \/\/ TOP_IJAVA_FRAME_ABI.\n-  \/\/ FIXME: assert that we really have a TOP_IJAVA_FRAME here!\n-  address entry = pc();\n-  load_const_optimized(tmp1, entry);\n+  if (jpc == nullptr || jpc->is_bound()) {\n+    load_const_optimized(tmp1, jpc == nullptr ? pc() : target(*jpc));\n+  } else {\n+    load_const(tmp1, *jpc, R12_scratch2);\n+  }\n@@ -4481,0 +4527,1 @@\n+#ifdef ASSERT\n@@ -4483,1 +4530,0 @@\n-#ifdef ASSERT\n@@ -4497,1 +4543,0 @@\n-#endif \/\/ ASSERT\n@@ -4499,0 +4544,1 @@\n+#endif \/\/ ASSERT\n@@ -4659,0 +4705,2 @@\n+  if (!Continuations::enabled()) return;\n+\n@@ -4668,0 +4716,2 @@\n+  if (!Continuations::enabled()) return;\n+\n@@ -4679,0 +4729,1 @@\n+  assert(LockingMode == LM_LEGACY, \"\");\n@@ -4694,0 +4745,1 @@\n+  assert(LockingMode == LM_LEGACY, \"\");\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":100,"deletions":48,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -118,1 +118,7 @@\n-                                         bool add_relocation = true, bool emit_dummy_addr = false);\n+                                         bool add_relocation = true, bool emit_dummy_addr = false,\n+                                         bool add_addr_to_reloc = true);\n+  void calculate_address_from_global_toc(Register dst, Label& addr,\n+                                         bool hi16 = true, bool lo16 = true,\n+                                         bool add_relocation = true, bool emit_dummy_addr = false) {\n+    calculate_address_from_global_toc(dst, target(addr), hi16, lo16, add_relocation, emit_dummy_addr, false);\n+  }\n@@ -287,1 +293,4 @@\n-  void clobber_volatile_gprs(Register excluded_register = noreg);\n+  void clobber_volatile_gprs(Register excluded_register = noreg) NOT_DEBUG_RETURN;\n+  \/\/ Load bad values into registers that are nonvolatile according to the ABI except R16_thread and R29_TOC.\n+  \/\/ This is done after vthread preemption and before vthread resume.\n+  void clobber_nonvolatile_registers() NOT_DEBUG_RETURN;\n@@ -401,1 +410,2 @@\n-    bool            check_exception = true\n+    bool            check_exception = true,\n+    Label* last_java_pc = nullptr\n@@ -414,1 +424,1 @@\n-  void call_VM(Register oop_result, address entry_point, bool check_exceptions = true);\n+  void call_VM(Register oop_result, address entry_point, bool check_exceptions = true, Label* last_java_pc = nullptr);\n@@ -698,2 +708,2 @@\n-  void reset_last_Java_frame(void);\n-  void set_top_ijava_frame_at_SP_as_last_Java_frame(Register sp, Register tmp1);\n+  void reset_last_Java_frame(bool check_last_java_sp = true);\n+  void set_top_ijava_frame_at_SP_as_last_Java_frame(Register sp, Register tmp1, Label* jpc = nullptr);\n@@ -912,1 +922,1 @@\n-                            const char* msg);\n+                            const char* msg) NOT_DEBUG_RETURN;\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.hpp","additions":17,"deletions":7,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -194,2 +194,12 @@\n-  jint& stub_inst = *(jint*) branch;\n-  stub_inst = patched_branch(target - branch, stub_inst, 0);\n+  if (is_branch(branch)) {\n+    jint& stub_inst = *(jint*) branch;\n+    stub_inst = patched_branch(target - branch, stub_inst, 0);\n+  } else if (is_calculate_address_from_global_toc_at(branch + BytesPerInstWord, branch)) {\n+    const address inst1_addr = branch;\n+    const address inst2_addr = branch + BytesPerInstWord;\n+    patch_calculate_address_from_global_toc_at(inst2_addr, inst1_addr, target);\n+  } else if (is_load_const_at(branch)) {\n+    patch_const(branch, (long)target);\n+  } else {\n+    assert(false, \"instruction at \" PTR_FORMAT \" not recognized\", p2i(branch));\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.inline.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -208,3 +208,1 @@\n-  } else {\n-    assert(MacroAssembler::is_load_const_from_method_toc_at(addr), \"must be load_const_from_pool\");\n-\n+  } else if (MacroAssembler::is_load_const_from_method_toc_at(addr)) {\n@@ -214,0 +212,4 @@\n+  } else {\n+    assert(MacroAssembler::is_calculate_address_from_global_toc_at(addr, addr - BytesPerInstWord),\n+           \"must be calculate_address_from_global_toc\");\n+    return (intptr_t) MacroAssembler::get_address_of_calculate_address_from_global_toc_at(addr, addr - BytesPerInstWord);\n","filename":"src\/hotspot\/cpu\/ppc\/nativeInst_ppc.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -12096,2 +12096,2 @@\n-instruct cmpFastLockLightweight(flagsRegCR0 crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR1 cr1) %{\n-  predicate(LockingMode == LM_LIGHTWEIGHT);\n+instruct cmpFastLockLightweight(flagsRegCR0 crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2) %{\n+  predicate(LockingMode == LM_LIGHTWEIGHT && !UseObjectMonitorTable);\n@@ -12099,1 +12099,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, KILL cr1);\n+  effect(TEMP tmp1, TEMP tmp2);\n@@ -12104,1 +12104,17 @@\n-                             $tmp1$$Register, $tmp2$$Register, \/*tmp3*\/ R0);\n+                             $tmp1$$Register, $tmp2$$Register, noreg \/*tmp3*\/);\n+    \/\/ If locking was successful, crx should indicate 'EQ'.\n+    \/\/ The compiler generates a branch to the runtime call to\n+    \/\/ _complete_monitor_locking_Java for the case where crx is 'NE'.\n+  %}\n+  ins_pipe(pipe_class_compare);\n+%}\n+\n+instruct cmpFastLockMonitorTable(flagsRegCR0 crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2, iRegPdst tmp3, flagsRegCR1 cr1) %{\n+  predicate(LockingMode == LM_LIGHTWEIGHT && UseObjectMonitorTable);\n+  match(Set crx (FastLock oop box));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr1);\n+\n+  format %{ \"FASTLOCK  $oop, $box, $tmp1, $tmp2, $tmp3\" %}\n+  ins_encode %{\n+    __ fast_lock_lightweight($crx$$CondRegister, $oop$$Register, $box$$Register,\n+                             $tmp1$$Register, $tmp2$$Register, $tmp3$$Register);\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":20,"deletions":4,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1605,0 +1605,1 @@\n+  __ std(tmp2, _abi0(cr), R1_SP);\n@@ -1648,0 +1649,4 @@\n+  __ load_const_optimized(tmp1, ContinuationEntry::cookie_value());\n+  __ ld(tmp2, _abi0(cr), R1_SP);\n+  __ cmpd(CCR0, tmp1, tmp2);\n+  __ asm_assert_eq(FILE_AND_LINE \": cookie not found\");\n@@ -1856,0 +1861,1 @@\n+  ContinuationEntry::_thaw_call_pc_offset = __ pc() - start;\n@@ -1866,0 +1872,1 @@\n+  ContinuationEntry::_cleanup_offset = __ pc() - start;\n@@ -1973,0 +1980,4 @@\n+void SharedRuntime::continuation_enter_cleanup(MacroAssembler* masm) {\n+  ::continuation_enter_cleanup(masm);\n+}\n+\n@@ -2193,1 +2204,0 @@\n-  intptr_t oopmap_pc;\n@@ -2196,0 +2206,1 @@\n+  Label    last_java_pc;\n@@ -2204,1 +2215,1 @@\n-  Register r_return_pc  = R28;\n+  Register r_last_java_pc = R28;\n@@ -2366,9 +2377,3 @@\n-  \/\/ Get current pc for oopmap, and load it patchable relative to global toc.\n-  oopmap_pc = (intptr_t) __ pc();\n-  __ calculate_address_from_global_toc(r_return_pc, (address)oopmap_pc, true, true, true, true);\n-\n-  \/\/ We use the same pc\/oopMap repeatedly when we call out.\n-  oop_maps->add_gc_map(oopmap_pc - start_pc, oop_map);\n-\n-  \/\/ r_return_pc now has the pc loaded that we will use when we finally call\n-  \/\/ to native.\n+  \/\/ The last java pc will also be used as resume pc if this is the wrapper for wait0.\n+  \/\/ For this purpose the precise location matters but not for oopmap lookup.\n+  __ calculate_address_from_global_toc(r_last_java_pc, last_java_pc, true, true, true, true);\n@@ -2402,1 +2407,2 @@\n-      __ compiler_fast_lock_lightweight_object(CCR0, r_oop, r_box, r_temp_1, r_temp_2, r_temp_3);\n+      Register r_temp_3_or_noreg = UseObjectMonitorTable ? r_temp_3 : noreg;\n+      __ compiler_fast_lock_lightweight_object(CCR0, r_oop, r_box, r_temp_1, r_temp_2, r_temp_3_or_noreg);\n@@ -2419,2 +2425,6 @@\n-    __ set_last_Java_frame(R11_scratch1, r_return_pc);\n-    assert(r_return_pc->is_nonvolatile(), \"expecting return pc to be in non-volatile register\");\n+    __ set_last_Java_frame(R11_scratch1, r_last_java_pc);\n+    assert(r_last_java_pc->is_nonvolatile(), \"r_last_java_pc needs to be preserved accross complete_monitor_locking_C call\");\n+    \/\/ The following call will not be preempted.\n+    \/\/ push_cont_fastpath forces freeze slow path in case we try to preempt where we will pin the\n+    \/\/ vthread to the carrier (see FreezeBase::recurse_freeze_native_frame()).\n+    __ push_cont_fastpath();\n@@ -2422,0 +2432,1 @@\n+    __ pop_cont_fastpath();\n@@ -2432,2 +2443,1 @@\n-  \/\/ Use that pc we placed in r_return_pc a while back as the current frame anchor.\n-  __ set_last_Java_frame(R1_SP, r_return_pc);\n+  __ set_last_Java_frame(R1_SP, r_last_java_pc);\n@@ -2493,2 +2503,0 @@\n-  Label after_transition;\n-\n@@ -2569,1 +2577,17 @@\n-    __ bind(after_transition);\n+\n+    \/\/ Check preemption for Object.wait()\n+    if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+      Label not_preempted;\n+      __ ld(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+      __ cmpdi(CCR0, R0, 0);\n+      __ beq(CCR0, not_preempted);\n+      __ mtlr(R0);\n+      __ li(R0, 0);\n+      __ std(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+      __ blr();\n+      __ bind(not_preempted);\n+    }\n+    __ bind(last_java_pc);\n+    \/\/ We use the same pc\/oopMap repeatedly when we call out above.\n+    intptr_t oopmap_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(oopmap_pc - start_pc, oop_map);\n@@ -2651,1 +2675,3 @@\n-  __ reset_last_Java_frame();\n+  \/\/ Last java frame won't be set if we're resuming after preemption\n+  bool maybe_preempted = LockingMode != LM_LEGACY && method->is_object_wait0();\n+  __ reset_last_Java_frame(!maybe_preempted \/* check_last_java_sp *\/);\n@@ -2736,0 +2762,6 @@\n+VMReg SharedRuntime::thread_register() {\n+  \/\/ On PPC virtual threads don't save the JavaThread* in their context (e.g. C1 stub frames).\n+  ShouldNotCallThis();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":52,"deletions":20,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -187,2 +187,3 @@\n-          + ((intptr_t*)f.interpreter_frame_monitor_begin()\n-             - (intptr_t*)f.interpreter_frame_monitor_end())\/BasicObjectLock::size();\n+          + (f.interpreter_frame_method()->is_native() ? 1 : 0) \/\/ temp oop slot\n+          + pointer_delta_as_int((intptr_t*)f.interpreter_frame_monitor_begin(),\n+                                 (intptr_t*)f.interpreter_frame_monitor_end())\/BasicObjectLock::size();\n","filename":"src\/hotspot\/cpu\/ppc\/stackChunkFrameStream_ppc.inline.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4487,0 +4487,4 @@\n+    if (kind == Continuation::thaw_top) {\n+      __ clobber_nonvolatile_registers(); \/\/ Except R16_thread and R29_TOC\n+    }\n+\n@@ -4575,0 +4579,35 @@\n+  address generate_cont_preempt_stub() {\n+    if (!Continuations::enabled()) return nullptr;\n+    StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+    address start = __ pc();\n+\n+    __ clobber_nonvolatile_registers(); \/\/ Except R16_thread and R29_TOC\n+\n+    __ reset_last_Java_frame(false \/*check_last_java_sp*\/);\n+\n+    \/\/ Set sp to enterSpecial frame, i.e. remove all frames copied into the heap.\n+    __ ld_ptr(R1_SP, JavaThread::cont_entry_offset(), R16_thread);\n+\n+    Label preemption_cancelled;\n+    __ lbz(R11_scratch1, in_bytes(JavaThread::preemption_cancelled_offset()), R16_thread);\n+    __ cmpwi(CCR0, R11_scratch1, 0);\n+    __ bne(CCR0, preemption_cancelled);\n+\n+    \/\/ Remove enterSpecial frame from the stack and return to Continuation.run() to unmount.\n+    SharedRuntime::continuation_enter_cleanup(_masm);\n+    __ pop_frame();\n+    __ restore_LR(R11_scratch1);\n+    __ blr();\n+\n+    \/\/ We acquired the monitor after freezing the frames so call thaw to continue execution.\n+    __ bind(preemption_cancelled);\n+    __ li(R11_scratch1, 0); \/\/ false\n+    __ stb(R11_scratch1, in_bytes(JavaThread::preemption_cancelled_offset()), R16_thread);\n+    int simm16_offs = __ load_const_optimized(R11_scratch1, ContinuationEntry::thaw_call_pc_address(), R0, true);\n+    __ ld(R11_scratch1, simm16_offs, R11_scratch1);\n+    __ mtctr(R11_scratch1);\n+    __ bctr();\n+\n+    return start;\n+  }\n+\n@@ -4650,0 +4689,1 @@\n+    StubRoutines::_cont_preempt_stub  = generate_cont_preempt_stub();\n","filename":"src\/hotspot\/cpu\/ppc\/stubGenerator_ppc.cpp","additions":40,"deletions":0,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -699,0 +699,11 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  if (!Continuations::enabled()) return nullptr;\n+  address start = __ pc();\n+\n+  __ load_const_optimized(R25_templateTableBase, (address)Interpreter::dispatch_table((TosState)0), R12_scratch2);\n+  __ restore_interpreter_state(R11_scratch1, false, true \/*restore_top_frame_sp*\/);\n+  __ blr();\n+\n+  return start;\n+}\n+\n@@ -1200,1 +1211,1 @@\n-  const Register native_method_fd     = R11_scratch1;\n+  const Register native_method_fd     = R12_scratch2; \/\/ preferred in MacroAssembler::branch_to\n@@ -1214,4 +1225,0 @@\n-  \/\/ Generate new interpreter state and jump to stack_overflow_return in case of\n-  \/\/ a stack overflow.\n-  \/\/generate_compute_interpreter_state(stack_overflow_return);\n-\n@@ -1256,2 +1263,2 @@\n-  assert(access_flags->is_nonvolatile(),\n-         \"access_flags must be in a non-volatile register\");\n+  assert(__ nonvolatile_accross_vthread_preemtion(access_flags),\n+         \"access_flags not preserved\");\n@@ -1318,0 +1325,2 @@\n+  bool support_vthread_preemption = Continuations::enabled() && LockingMode != LM_LEGACY;\n+\n@@ -1319,1 +1328,3 @@\n-  __ set_top_ijava_frame_at_SP_as_last_Java_frame(R1_SP, R12_scratch2\/*tmp*\/);\n+  Label last_java_pc;\n+  Label *resume_pc = support_vthread_preemption ? &last_java_pc : nullptr;\n+  __ set_top_ijava_frame_at_SP_as_last_Java_frame(R1_SP, R3_ARG1\/*tmp*\/, resume_pc);\n@@ -1338,8 +1349,2 @@\n-  \/\/ Remove the register parameter varargs slots we allocated in\n-  \/\/ compute_interpreter_state. SP+16 ends up pointing to the ABI\n-  \/\/ outgoing argument area.\n-  \/\/\n-  \/\/ Not needed on PPC64.\n-  \/\/__ add(SP, SP, Argument::n_int_register_parameters_c*BytesPerWord);\n-\n-  assert(result_handler_addr->is_nonvolatile(), \"result_handler_addr must be in a non-volatile register\");\n+  assert(__ nonvolatile_accross_vthread_preemtion(result_handler_addr),\n+         \"result_handler_addr not preserved\");\n@@ -1348,0 +1353,1 @@\n+  __ ld(R11_scratch1, _abi0(callers_sp), R1_SP); \/\/ load FP\n@@ -1361,3 +1367,2 @@\n-    __ ld(R11_scratch1, _abi0(callers_sp), R1_SP);\n-    \/\/ Load mirror from interpreter frame.\n-    __ ld(R12_scratch2, _ijava_state_neg(mirror), R11_scratch1);\n+    \/\/ Load mirror from interpreter frame (FP in R11_scratch1)\n+    __ ld(R21_tmp1, _ijava_state_neg(mirror), R11_scratch1);\n@@ -1366,1 +1371,1 @@\n-    __ std(R12_scratch2\/*mirror*\/, _ijava_state_neg(oop_tmp), R11_scratch1);\n+    __ std(R21_tmp1\/*mirror*\/, _ijava_state_neg(oop_tmp), R11_scratch1);\n@@ -1400,0 +1405,10 @@\n+\n+  if (support_vthread_preemption) {\n+    \/\/ result_handler_addr is a nonvolatile register. Its value will be preserved across\n+    \/\/ the native call but only if the call isn't preempted. To preserve its value even\n+    \/\/ in the case of preemption we save it in the lresult slot. It is restored at\n+    \/\/ resume_pc if, and only if the call was preempted. This works because only\n+    \/\/ j.l.Object::wait calls are preempted which don't return a result.\n+    __ std(result_handler_addr, _ijava_state_neg(lresult), R11_scratch1);\n+  }\n+  __ push_cont_fastpath();\n@@ -1401,0 +1416,1 @@\n+  __ pop_cont_fastpath();\n@@ -1498,0 +1514,29 @@\n+  if (support_vthread_preemption) {\n+    \/\/ Check preemption for Object.wait()\n+    Label not_preempted;\n+    __ ld(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+    __ cmpdi(CCR0, R0, 0);\n+    __ beq(CCR0, not_preempted);\n+    __ mtlr(R0);\n+    __ li(R0, 0);\n+    __ std(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread);\n+    __ blr();\n+\n+    \/\/ Execution will be resumed here when the vthread becomes runnable again.\n+    __ bind(*resume_pc);\n+    __ restore_after_resume(R11_scratch1 \/* fp *\/);\n+    \/\/ We saved the result handler before the call\n+    __ ld(result_handler_addr, _ijava_state_neg(lresult), R11_scratch1);\n+#ifdef ASSERT\n+    \/\/ Clobber result slots. Only native methods returning void can be preemted currently.\n+    __ load_const(R3_RET, UCONST64(0xbad01001));\n+    __ std(R3_RET, _ijava_state_neg(lresult), R11_scratch1);\n+    __ std(R3_RET, _ijava_state_neg(fresult), R11_scratch1);\n+    \/\/ reset_last_Java_frame() below asserts that a last java sp is set\n+    __ asm_assert_mem8_is_zero(in_bytes(JavaThread::last_Java_sp_offset()),\n+        R16_thread, FILE_AND_LINE \": Last java sp should not be set when resuming\");\n+    __ std(R3_RET, in_bytes(JavaThread::last_Java_sp_offset()), R16_thread);\n+#endif\n+    __ bind(not_preempted);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/ppc\/templateInterpreterGenerator_ppc.cpp","additions":65,"deletions":20,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -86,1 +86,0 @@\n-    cmpxchgptr(hdr, disp_hdr, temp, t1, done, \/*fallthough*\/nullptr);\n@@ -88,0 +87,1 @@\n+    cmpxchgptr(hdr, disp_hdr, temp, t1, done, \/*fallthough*\/nullptr);\n@@ -109,0 +109,1 @@\n+\n@@ -111,0 +112,1 @@\n+    inc_held_monitor_count();\n@@ -113,1 +115,0 @@\n-  increment(Address(xthread, JavaThread::held_monitor_count_offset()));\n@@ -149,0 +150,1 @@\n+\n@@ -151,0 +153,1 @@\n+    dec_held_monitor_count();\n@@ -152,2 +155,0 @@\n-\n-  decrement(Address(xthread, JavaThread::held_monitor_count_offset()));\n","filename":"src\/hotspot\/cpu\/riscv\/c1_MacroAssembler_riscv.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -168,1 +168,1 @@\n-  does_not_return, requires_return\n+  does_not_return, requires_return, requires_pop_epilogue_return\n@@ -176,1 +176,1 @@\n-  bool _return_state;\n+  return_state_t _return_state;\n@@ -190,2 +190,12 @@\n-void StubAssembler::epilogue() {\n-  leave();\n+void StubAssembler::epilogue(bool use_pop) {\n+  \/\/ Avoid using a leave instruction when this frame may\n+  \/\/ have been frozen, since the current value of fp\n+  \/\/ restored from the stub would be invalid. We still\n+  \/\/ must restore the fp value saved on enter though.\n+  if (use_pop) {\n+    ld(fp, Address(sp));\n+    ld(ra, Address(sp, wordSize));\n+    addi(sp, sp, 2 * wordSize);\n+  } else {\n+    leave();\n+  }\n@@ -211,3 +221,1 @@\n-  if (_return_state == requires_return) {\n-    __ epilogue();\n-  } else {\n+  if (_return_state == does_not_return) {\n@@ -215,0 +223,2 @@\n+  } else {\n+    __ epilogue(_return_state == requires_pop_epilogue_return);\n@@ -269,0 +279,4 @@\n+  int sp_offset = cpu_reg_save_offsets[xthread->encoding()];\n+  oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n+                            xthread->as_VMReg());\n+\n@@ -357,0 +371,10 @@\n+\/\/ return: offset in 64-bit words.\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+  CodeBlob* cb = f.cb();\n+  assert(cb == Runtime1::blob_for(C1StubId::monitorenter_id) ||\n+         cb == Runtime1::blob_for(C1StubId::monitorenter_nofpu_id), \"must be\");\n+  assert(cb != nullptr && cb->is_runtime_stub(), \"invalid frame\");\n+  int offset = cpu_reg_save_offsets[xthread->encoding()];\n+  return offset \/ 2;   \/\/ SP offsets are in halfwords\n+}\n+\n@@ -882,1 +906,1 @@\n-        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments);\n+        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments, requires_pop_epilogue_return);\n","filename":"src\/hotspot\/cpu\/riscv\/c1_Runtime1_riscv.cpp","additions":32,"deletions":8,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-                                  Register tmp1Reg, Register tmp2Reg, Register tmp3Reg) {\n+                                  Register tmp1Reg, Register tmp2Reg, Register tmp3Reg, Register tmp4Reg) {\n@@ -107,3 +107,3 @@\n-    \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto label locked,\n-    \/\/ hence we can store 0 as the displaced header in the box, which indicates that it is a\n-    \/\/ recursive lock.\n+    \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto label\n+    \/\/ locked, hence we can store 0 as the displaced header in the box, which indicates that it\n+    \/\/ is a recursive lock.\n@@ -118,4 +118,2 @@\n-  \/\/ The object's monitor m is unlocked iff m->owner == nullptr,\n-  \/\/ otherwise m->owner may contain a thread or a stack address.\n-  \/\/\n-  \/\/ Try to CAS m->owner from null to current thread.\n+\n+  \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n@@ -123,1 +121,3 @@\n-  cmpxchg(\/*memory address*\/tmp, \/*expected value*\/zr, \/*new value*\/xthread, Assembler::int64,\n+  Register tid = tmp4Reg;\n+  ld(tid, Address(xthread, JavaThread::lock_id_offset()));\n+  cmpxchg(\/*memory address*\/tmp, \/*expected value*\/zr, \/*new value*\/tid, Assembler::int64,\n@@ -135,1 +135,1 @@\n-  bne(tmp3Reg, xthread, slow_path); \/\/ Check for recursive locking\n+  bne(tmp3Reg, tid, slow_path); \/\/ Check for recursive locking\n@@ -142,1 +142,3 @@\n-  increment(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2Reg, tmp3Reg);\n+  if (LockingMode == LM_LEGACY) {\n+    inc_held_monitor_count();\n+  }\n@@ -256,1 +258,3 @@\n-  decrement(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp1Reg, tmp2Reg);\n+  if (LockingMode == LM_LEGACY) {\n+    dec_held_monitor_count();\n+  }\n@@ -276,1 +280,1 @@\n-                                              Register tmp1, Register tmp2, Register tmp3) {\n+                                              Register tmp1, Register tmp2, Register tmp3, Register tmp4) {\n@@ -281,1 +285,1 @@\n-  assert_different_registers(obj, box, tmp1, tmp2, tmp3, flag, t0);\n+  assert_different_registers(obj, box, tmp1, tmp2, tmp3, tmp4, flag, t0);\n@@ -352,0 +356,1 @@\n+\n@@ -398,2 +403,4 @@\n-    \/\/ CAS owner (null => current thread).\n-    cmpxchg(\/*addr*\/ tmp2_owner_addr, \/*expected*\/ zr, \/*new*\/ xthread, Assembler::int64,\n+    \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+    Register tid = tmp4;\n+    ld(tid, Address(xthread, JavaThread::lock_id_offset()));\n+    cmpxchg(\/*addr*\/ tmp2_owner_addr, \/*expected*\/ zr, \/*new*\/ tid, Assembler::int64,\n@@ -404,1 +411,1 @@\n-    bne(tmp3_owner, xthread, slow_path);\n+    bne(tmp3_owner, tid, slow_path);\n@@ -417,1 +424,0 @@\n-  increment(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2, tmp3);\n@@ -589,1 +595,0 @@\n-  decrement(Address(xthread, JavaThread::held_monitor_count_offset()), 1, tmp2, tmp3);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":24,"deletions":19,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -47,1 +47,2 @@\n-  void fast_lock(Register object, Register box, Register tmp1, Register tmp2, Register tmp3);\n+  void fast_lock(Register object, Register box,\n+                 Register tmp1, Register tmp2, Register tmp3, Register tmp4);\n@@ -49,0 +50,1 @@\n+\n@@ -50,2 +52,4 @@\n-  void fast_lock_lightweight(Register object, Register box, Register tmp1, Register tmp2, Register tmp3);\n-  void fast_unlock_lightweight(Register object, Register box, Register tmp1, Register tmp2, Register tmp3);\n+  void fast_lock_lightweight(Register object, Register box,\n+                             Register tmp1, Register tmp2, Register tmp3, Register tmp4);\n+  void fast_unlock_lightweight(Register object, Register box,\n+                               Register tmp1, Register tmp2, Register tmp3);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -130,0 +130,5 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  assert(f.interpreter_frame_last_sp() == nullptr, \"should be null for top frame\");\n+  f.interpreter_frame_set_last_sp(f.unextended_sp());\n+}\n+\n@@ -150,0 +155,6 @@\n+  \/\/ The interpreter native wrapper code adds space in the stack equal to size_of_parameters()\n+  \/\/ after the fixed part of the frame. For wait0 this is equal to 3 words (this + long parameter).\n+  \/\/ We adjust by this size since otherwise the saved last sp will be less than the extended_sp.\n+  DEBUG_ONLY(Method* m = hf.interpreter_frame_method();)\n+  DEBUG_ONLY(int extra_space = m->is_object_wait0() ? m->size_of_parameters() : 0;)\n+\n@@ -153,1 +164,1 @@\n-  assert(hf.unextended_sp() >  (intptr_t*)hf.at(frame::interpreter_frame_extended_sp_offset), \"\");\n+  assert(hf.unextended_sp() + extra_space >  (intptr_t*)hf.at(frame::interpreter_frame_extended_sp_offset), \"\");\n@@ -206,1 +217,2 @@\n-  return frame(sp, sp, _cont.entryFP(), _cont.entryPC()); \/\/ TODO PERF: This finds code blob and computes deopt state\n+  \/\/ TODO PERF: This finds code blob and computes deopt state\n+  return frame(sp, sp, _cont.entryFP(), _cont.entryPC());\n@@ -218,1 +230,0 @@\n-    const int locals = hf.interpreter_frame_method()->max_locals();\n@@ -240,1 +251,1 @@\n-      int argsize = hf.compiled_frame_stack_argsize();\n+      int argsize = FKind::stack_argsize(hf);\n@@ -255,1 +266,1 @@\n-      fp = frame_sp + FKind::size(hf) - 2;\n+      fp = frame_sp + FKind::size(hf) - frame::sender_sp_offset;\n@@ -257,3 +268,5 @@\n-      fp = FKind::stub\n-        ? frame_sp + fsize - 2 \/\/ On RISCV, this value is used for the safepoint stub\n-        : *(intptr_t**)(hf.sp() - 2); \/\/ we need to re-read fp because it may be an oop and we might have fixed the frame.\n+      fp = FKind::stub || FKind::native\n+        \/\/ fp always points to the address above the pushed return pc. We need correct address.\n+        ? frame_sp + fsize - frame::sender_sp_offset\n+        \/\/ we need to re-read fp because it may be an oop and we might have fixed the frame.\n+        : *(intptr_t**)(hf.sp() - 2);\n@@ -261,1 +274,2 @@\n-    return frame(frame_sp, frame_sp, fp, hf.pc(), hf.cb(), hf.oop_map(), false); \/\/ TODO PERF : this computes deopt state; is it necessary?\n+    \/\/ TODO PERF : this computes deopt state; is it necessary?\n+    return frame(frame_sp, frame_sp, fp, hf.pc(), hf.cb(), hf.oop_map(), false);\n@@ -282,0 +296,38 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  intptr_t* fp = caller_sp - frame::sender_sp_offset;\n+  patch_callee_link(f, fp);\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  intptr_t* sp = top.sp();\n+  CodeBlob* cb = top.cb();\n+\n+  if (cb->frame_size() == 2) {\n+    \/\/ C2 runtime stub case. For riscv64 the real size of the c2 runtime stub is 2 words bigger\n+    \/\/ than what we think, i.e. size is 4. This is because the _last_Java_sp is not set to the\n+    \/\/ sp right before making the call to the VM, but rather it is artificially set 2 words above\n+    \/\/ this real sp so that we can store the return address at last_Java_sp[-1], and keep this\n+    \/\/ property where we can retrieve the last_Java_pc from the last_Java_sp. But that means that\n+    \/\/ once we return to the runtime stub, the code will adjust sp according to this real size.\n+    \/\/ So we must adjust the frame size back here and we copy ra\/fp again.\n+    sp -= 2;\n+    sp[-2] = sp[0];\n+    sp[-1] = sp[1];\n+\n+    log_develop_trace(continuations, preempt)(\"adjusted sp for c2 runtime stub, initial sp: \" INTPTR_FORMAT \" final sp: \" INTPTR_FORMAT\n+                                              \" fp: \" INTPTR_FORMAT, p2i(sp + 2), p2i(sp), sp[-2]);\n+  }\n+  return sp;\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  frame enterSpecial = new_entry_frame();\n+  intptr_t* sp = enterSpecial.sp();\n+\n+  sp[-1] = (intptr_t)ContinuationEntry::cleanup_pc();\n+  sp[-2] = (intptr_t)enterSpecial.fp();\n+\n+  log_develop_trace(continuations, preempt)(\"push_cleanup_continuation initial sp: \" INTPTR_FORMAT \" final sp: \" INTPTR_FORMAT, p2i(sp + 2 * frame::metadata_words), p2i(sp));\n+  return sp;\n+}\n+\n@@ -289,0 +341,3 @@\n+  DEBUG_ONLY(Method* m = hf.interpreter_frame_method();)\n+  DEBUG_ONLY(int extra_space = m->is_object_wait0() ? m->size_of_parameters() : 0;) \/\/ see comment in relativize_interpreted_frame_metadata()\n+\n@@ -290,1 +345,1 @@\n-  assert((intptr_t*)f.at_relative(frame::interpreter_frame_extended_sp_offset) < f.unextended_sp(), \"\");\n+  assert((intptr_t*)f.at_relative(frame::interpreter_frame_extended_sp_offset) < f.unextended_sp() + extra_space, \"\");\n","filename":"src\/hotspot\/cpu\/riscv\/continuationFreezeThaw_riscv.inline.hpp","additions":65,"deletions":10,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -43,0 +43,16 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  if (f.is_runtime_frame()) {\n+    \/\/ Unlike x86 we don't know where in the callee frame the return pc is\n+    \/\/ saved so we can't patch the return from the VM call back to Java.\n+    \/\/ Instead, we will patch the return from the runtime stub back to the\n+    \/\/ compiled method so that the target returns to the preempt cleanup stub.\n+    intptr_t* caller_sp = f.sp() + f.cb()->frame_size();\n+    caller_sp[-1] = (intptr_t)StubRoutines::cont_preempt_stub();\n+  } else {\n+    \/\/ The target will check for preemption once it returns to the interpreter\n+    \/\/ or the native wrapper code and will manually jump to the preempt stub.\n+    JavaThread *thread = JavaThread::current();\n+    thread->set_preempt_alternate_return(StubRoutines::cont_preempt_stub());\n+  }\n+}\n+\n@@ -75,1 +91,0 @@\n-#ifdef ASSERT\n@@ -81,0 +96,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/riscv\/continuationHelper_riscv.inline.hpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -396,0 +396,30 @@\n+#if defined(ASSERT)\n+static address get_register_address_in_stub(const frame& stub_fr, VMReg reg) {\n+  RegisterMap map(nullptr,\n+                  RegisterMap::UpdateMap::include,\n+                  RegisterMap::ProcessFrames::skip,\n+                  RegisterMap::WalkContinuation::skip);\n+  stub_fr.oop_map()->update_register_map(&stub_fr, &map);\n+  return map.location(reg, stub_fr.sp());\n+}\n+#endif\n+\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  CodeBlob* cb = f.cb();\n+  assert(cb != nullptr && cb->is_runtime_stub(), \"invalid frame\");\n+\n+  JavaThread** thread_addr;\n+#ifdef COMPILER1\n+  if (cb == Runtime1::blob_for(C1StubId::monitorenter_id) ||\n+      cb == Runtime1::blob_for(C1StubId::monitorenter_nofpu_id)) {\n+    thread_addr = (JavaThread**)(f.sp() + Runtime1::runtime_blob_current_thread_offset(f));\n+  } else\n+#endif\n+  {\n+    \/\/ c2 only saves rbp in the stub frame so nothing to do.\n+    thread_addr = nullptr;\n+  }\n+  assert(get_register_address_in_stub(f, SharedRuntime::thread_register()) == (address)thread_addr, \"wrong thread address\");\n+  return thread_addr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/frame_riscv.cpp","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -114,1 +114,2 @@\n-    interpreter_frame_oop_temp_offset                =  1, \/\/ for native calls only\n+    interpreter_frame_result_handler_offset          =  1, \/\/ for native calls only\n+    interpreter_frame_oop_temp_offset                =  0, \/\/ for native calls only\n","filename":"src\/hotspot\/cpu\/riscv\/frame_riscv.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -729,1 +729,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -760,1 +760,1 @@\n-      j(count);\n+      j(done);\n@@ -789,1 +789,5 @@\n-      beqz(swap_reg, count);\n+      bnez(swap_reg, slow_case);\n+\n+      bind(count);\n+      inc_held_monitor_count();\n+      j(done);\n@@ -795,1 +799,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -798,4 +802,0 @@\n-    j(done);\n-\n-    bind(count);\n-    increment(Address(xthread, JavaThread::held_monitor_count_offset()));\n@@ -847,0 +847,1 @@\n+    Label slow_case;\n@@ -848,1 +849,0 @@\n-      Label slow_case;\n@@ -850,3 +850,1 @@\n-      j(count);\n-\n-      bind(slow_case);\n+      j(done);\n@@ -862,1 +860,5 @@\n-      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, tmp_reg, count, \/*fallthrough*\/nullptr);\n+      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, tmp_reg, count, &slow_case);\n+\n+      bind(count);\n+      dec_held_monitor_count();\n+      j(done);\n@@ -865,0 +867,1 @@\n+    bind(slow_case);\n@@ -869,5 +872,0 @@\n-    j(done);\n-\n-    bind(count);\n-    decrement(Address(xthread, JavaThread::held_monitor_count_offset()));\n-\n@@ -875,1 +873,0 @@\n-\n@@ -1583,0 +1580,49 @@\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result,\n+                                                    address entry_point,\n+                                                    Register arg_1) {\n+  assert(arg_1 == c_rarg1, \"\");\n+  Label resume_pc, not_preempted;\n+\n+#ifdef ASSERT\n+  {\n+    Label L;\n+    ld(t0, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+    beqz(t0, L);\n+    stop(\"Should not have alternate return address set\");\n+    bind(L);\n+  }\n+#endif \/* ASSERT *\/\n+\n+  \/\/ Force freeze slow path.\n+  push_cont_fastpath();\n+\n+  \/\/ Make VM call. In case of preemption set last_pc to the one we want to resume to.\n+  la(t0, resume_pc);\n+  sd(t0, Address(xthread, JavaThread::last_Java_pc_offset()));\n+  call_VM_base(oop_result, noreg, noreg, entry_point, 1, false \/*check_exceptions*\/);\n+\n+  pop_cont_fastpath();\n+\n+  \/\/ Check if preempted.\n+  ld(t1, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+  beqz(t1, not_preempted);\n+  sd(zr, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+  jr(t1);\n+\n+  \/\/ In case of preemption, this is where we will resume once we finally acquire the monitor.\n+  bind(resume_pc);\n+  restore_after_resume(false \/* is_native *\/);\n+\n+  bind(not_preempted);\n+}\n+\n+void InterpreterMacroAssembler::restore_after_resume(bool is_native) {\n+  la(t1, ExternalAddress(Interpreter::cont_resume_interpreter_adapter()));\n+  jalr(t1);\n+  if (is_native) {\n+    \/\/ On resume we need to set up stack as expected\n+    push(dtos);\n+    push(ltos);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":65,"deletions":19,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -62,0 +62,5 @@\n+  void call_VM_preemptable(Register oop_result,\n+                           address entry_point,\n+                           Register arg_1);\n+  void restore_after_resume(bool is_native);\n+\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"interpreter\/interpreterRuntime.hpp\"\n@@ -229,0 +230,30 @@\n+void MacroAssembler::inc_held_monitor_count(Register tmp) {\n+  Address dst(xthread, JavaThread::held_monitor_count_offset());\n+  ld(tmp, dst);\n+  addi(tmp, tmp, 1);\n+  sd(tmp, dst);\n+#ifdef ASSERT\n+  Label ok;\n+  test_bit(tmp, tmp, 63);\n+  beqz(tmp, ok);\n+  STOP(\"assert(held monitor count overflow)\");\n+  should_not_reach_here();\n+  bind(ok);\n+#endif\n+}\n+\n+void MacroAssembler::dec_held_monitor_count(Register tmp) {\n+  Address dst(xthread, JavaThread::held_monitor_count_offset());\n+  ld(tmp, dst);\n+  addi(tmp, tmp, -1);\n+  sd(tmp, dst);\n+#ifdef ASSERT\n+  Label ok;\n+  test_bit(tmp, tmp, 63);\n+  beqz(tmp, ok);\n+  STOP(\"assert(held monitor count underflow)\");\n+  should_not_reach_here();\n+  bind(ok);\n+#endif\n+}\n+\n@@ -410,0 +441,4 @@\n+static bool is_preemptable(address entry_point) {\n+  return entry_point == CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter);\n+}\n+\n@@ -439,1 +474,6 @@\n-  set_last_Java_frame(last_java_sp, fp, l, t0);\n+  if (is_preemptable(entry_point)) {\n+    \/\/ skip setting last_pc since we already set it to desired value.\n+    set_last_Java_frame(last_java_sp, fp, noreg);\n+  } else {\n+    set_last_Java_frame(last_java_sp, fp, l, t0);\n+  }\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":41,"deletions":1,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -789,2 +789,5 @@\n-  void push_cont_fastpath(Register java_thread);\n-  void pop_cont_fastpath(Register java_thread);\n+  void push_cont_fastpath(Register java_thread = xthread);\n+  void pop_cont_fastpath(Register java_thread = xthread);\n+\n+  void inc_held_monitor_count(Register tmp = t0);\n+  void dec_held_monitor_count(Register tmp = t0);\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -10526,1 +10526,2 @@\n-instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box,\n+                     iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, iRegPNoSp tmp4)\n@@ -10530,1 +10531,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4);\n@@ -10533,1 +10534,1 @@\n-  format %{ \"fastlock $object,$box\\t! kills $tmp1,$tmp2,$tmp3, #@cmpFastLock\" %}\n+  format %{ \"fastlock $object,$box\\t! kills $tmp1,$tmp2,$tmp3,$tmp4 #@cmpFastLock\" %}\n@@ -10536,1 +10537,2 @@\n-    __ fast_lock($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register, $tmp3$$Register);\n+    __ fast_lock($object$$Register, $box$$Register,\n+                 $tmp1$$Register, $tmp2$$Register, $tmp3$$Register, $tmp4$$Register);\n@@ -10559,1 +10561,2 @@\n-instruct cmpFastLockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+instruct cmpFastLockLightweight(rFlagsReg cr, iRegP object, iRegP box,\n+                                iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, iRegPNoSp tmp4)\n@@ -10563,1 +10566,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4);\n@@ -10566,1 +10569,1 @@\n-  format %{ \"fastlock $object,$box\\t! kills $tmp1,$tmp2,$tmp3 #@cmpFastLockLightweight\" %}\n+  format %{ \"fastlock $object,$box\\t! kills $tmp1,$tmp2,$tmp3,$tmp4 #@cmpFastLockLightweight\" %}\n@@ -10569,1 +10572,2 @@\n-    __ fast_lock_lightweight($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register, $tmp3$$Register);\n+    __ fast_lock_lightweight($object$$Register, $box$$Register,\n+                             $tmp1$$Register, $tmp2$$Register, $tmp3$$Register, $tmp4$$Register);\n@@ -10575,1 +10579,2 @@\n-instruct cmpFastUnlockLightweight(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+instruct cmpFastUnlockLightweight(rFlagsReg cr, iRegP object, iRegP box,\n+                                  iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3)\n@@ -10585,1 +10590,2 @@\n-    __ fast_unlock_lightweight($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register, $tmp3$$Register);\n+    __ fast_unlock_lightweight($object$$Register, $box$$Register,\n+                               $tmp1$$Register, $tmp2$$Register, $tmp3$$Register);\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":16,"deletions":10,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -1054,0 +1054,1 @@\n+  ContinuationEntry::_thaw_call_pc_offset = __ pc() - start;\n@@ -1060,0 +1061,1 @@\n+  ContinuationEntry::_cleanup_offset = __ pc() - start;\n@@ -1154,0 +1156,4 @@\n+void SharedRuntime::continuation_enter_cleanup(MacroAssembler* masm) {\n+  ::continuation_enter_cleanup(masm);\n+}\n+\n@@ -1636,2 +1642,3 @@\n-  \/\/ be pushed on the stack when we do a stack traversal).\n-  \/\/ We use the same pc\/oopMap repeatedly when we call out\n+  \/\/ be pushed on the stack when we do a stack traversal). It is enough that the pc()\n+  \/\/ points into the right code segment. It does not have to be the correct return pc.\n+  \/\/ We use the same pc\/oopMap repeatedly when we call out.\n@@ -1640,1 +1647,9 @@\n-  __ set_last_Java_frame(sp, noreg, native_return, t0);\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ For convenience we use the pc we want to resume to in case of preemption on Object.wait.\n+    __ set_last_Java_frame(sp, noreg, native_return, t0);\n+  } else {\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n+\n+    __ set_last_Java_frame(sp, noreg, __ pc(), t0);\n+  }\n@@ -1716,0 +1731,3 @@\n+\n+      __ bind(count);\n+      __ inc_held_monitor_count();\n@@ -1721,3 +1739,0 @@\n-    __ bind(count);\n-    __ increment(Address(xthread, JavaThread::held_monitor_count_offset()));\n-\n@@ -1742,5 +1757,0 @@\n-  __ bind(native_return);\n-\n-  intptr_t return_pc = (intptr_t) __ pc();\n-  oop_maps->add_gc_map(return_pc - start, map);\n-\n@@ -1797,0 +1807,12 @@\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ Check preemption for Object.wait()\n+    __ ld(t1, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+    __ beqz(t1, native_return);\n+    __ sd(zr, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+    __ jr(t1);\n+    __ bind(native_return);\n+\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n+  }\n+\n@@ -1820,1 +1842,1 @@\n-      __ decrement(Address(xthread, JavaThread::held_monitor_count_offset()));\n+      __ dec_held_monitor_count();\n@@ -1843,1 +1865,1 @@\n-      __ decrement(Address(xthread, JavaThread::held_monitor_count_offset()));\n+      __ dec_held_monitor_count();\n@@ -1847,1 +1869,0 @@\n-      __ decrement(Address(xthread, JavaThread::held_monitor_count_offset()));\n@@ -1916,0 +1937,3 @@\n+    \/\/ Force freeze slow path in case we try to preempt. We will pin the\n+    \/\/ vthread to the carrier (see FreezeBase::recurse_freeze_native_frame()).\n+    __ push_cont_fastpath();\n@@ -1917,0 +1941,1 @@\n+    __ pop_cont_fastpath();\n@@ -2447,0 +2472,4 @@\n+VMReg SharedRuntime::thread_register() {\n+  return xthread->as_VMReg();\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":43,"deletions":14,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -117,0 +117,1 @@\n+        + (f.interpreter_frame_method()->is_native() ? 1 : 0) \/\/ temp oop slot\n","filename":"src\/hotspot\/cpu\/riscv\/stackChunkFrameStream_riscv.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3876,0 +3876,30 @@\n+  address generate_cont_preempt_stub() {\n+    if (!Continuations::enabled()) return nullptr;\n+    StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+    address start = __ pc();\n+\n+    __ reset_last_Java_frame(true);\n+\n+    \/\/ Set sp to enterSpecial frame, i.e. remove all frames copied into the heap.\n+    __ ld(sp, Address(xthread, JavaThread::cont_entry_offset()));\n+\n+    Label preemption_cancelled;\n+    __ lbu(t0, Address(xthread, JavaThread::preemption_cancelled_offset()));\n+    __ bnez(t0, preemption_cancelled);\n+\n+    \/\/ Remove enterSpecial frame from the stack and return to Continuation.run() to unmount.\n+    SharedRuntime::continuation_enter_cleanup(_masm);\n+    __ leave();\n+    __ ret();\n+\n+    \/\/ We acquired the monitor after freezing the frames so call thaw to continue execution.\n+    __ bind(preemption_cancelled);\n+    __ sb(zr, Address(xthread, JavaThread::preemption_cancelled_offset()));\n+    __ la(fp, Address(sp, checked_cast<int32_t>(ContinuationEntry::size() + 2 * wordSize)));\n+    __ la(t1, ExternalAddress(ContinuationEntry::thaw_call_pc_address()));\n+    __ ld(t1, Address(t1));\n+    __ jr(t1);\n+\n+    return start;\n+  }\n+\n@@ -6238,0 +6268,1 @@\n+    StubRoutines::_cont_preempt_stub     = generate_cont_preempt_stub();\n","filename":"src\/hotspot\/cpu\/riscv\/stubGenerator_riscv.cpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -543,0 +543,32 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  if (!Continuations::enabled()) return nullptr;\n+  address start = __ pc();\n+\n+  __ restore_bcp();\n+  __ restore_locals();\n+\n+  \/\/ Restore constant pool cache\n+  __ ld(xcpool, Address(fp, frame::interpreter_frame_cache_offset * wordSize));\n+\n+  \/\/ Restore Java expression stack pointer\n+  __ ld(t0, Address(fp, frame::interpreter_frame_last_sp_offset * wordSize));\n+  __ shadd(esp, t0, fp, t0, Interpreter::logStackElementSize);\n+  \/\/ and NULL it as marker that esp is now tos until next java call\n+  __ sd(zr, Address(fp, frame::interpreter_frame_last_sp_offset * wordSize));\n+\n+  \/\/ Restore machine SP\n+  __ ld(t0, Address(fp, frame::interpreter_frame_extended_sp_offset * wordSize));\n+  __ shadd(sp, t0, fp, t0, LogBytesPerWord);\n+\n+  \/\/ Restore method\n+  __ ld(xmethod, Address(fp, frame::interpreter_frame_method_offset * wordSize));\n+\n+  \/\/ Restore dispatch\n+  __ la(xdispatch, ExternalAddress((address)Interpreter::dispatch_table()));\n+\n+  __ ret();\n+\n+  return start;\n+}\n+\n+\n@@ -1096,0 +1128,2 @@\n+  __ sd(x10, Address(fp, frame::interpreter_frame_result_handler_offset * wordSize));\n+\n@@ -1134,0 +1168,2 @@\n+  \/\/ For convenience we use the pc we want to resume to in\n+  \/\/ case of preemption on Object.wait.\n@@ -1155,0 +1191,2 @@\n+  __ push_cont_fastpath();\n+\n@@ -1157,1 +1195,3 @@\n-  __ bind(native_return);\n+\n+  __ pop_cont_fastpath();\n+\n@@ -1223,0 +1263,15 @@\n+  if (LockingMode != LM_LEGACY) {\n+    \/\/ Check preemption for Object.wait()\n+    Label not_preempted;\n+    __ ld(t0, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+    __ beqz(t0, not_preempted);\n+    __ sd(zr, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+    __ jr(t0);\n+    __ bind(native_return);\n+    __ restore_after_resume(true \/* is_native *\/);\n+    __ bind(not_preempted);\n+  } else {\n+    \/\/ any pc will do so just use this one for LM_LEGACY to keep code together.\n+    __ bind(native_return);\n+  }\n+\n@@ -1241,0 +1296,1 @@\n+    __ ld(result_handler, Address(fp, frame::interpreter_frame_result_handler_offset * wordSize));\n","filename":"src\/hotspot\/cpu\/riscv\/templateInterpreterGenerator_riscv.cpp","additions":57,"deletions":1,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -211,0 +211,5 @@\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/c1_Runtime1_s390.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -51,0 +51,4 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -86,0 +90,14 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  Unimplemented();\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/continuationFreezeThaw_s390.inline.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -38,0 +38,4 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -65,1 +69,0 @@\n-#ifdef ASSERT\n@@ -70,0 +73,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/s390\/continuationHelper_s390.inline.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -249,0 +249,5 @@\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/frame_s390.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -3564,2 +3564,0 @@\n-  \/\/ The object's monitor m is unlocked iff m->owner is null,\n-  \/\/ otherwise m->owner may contain a thread or a stack address.\n@@ -3567,3 +3565,3 @@\n-  \/\/ Try to CAS m->owner from null to current thread.\n-  \/\/ If m->owner is null, then csg succeeds and sets m->owner=THREAD and CR=EQ.\n-  \/\/ Otherwise, register zero is filled with the current owner.\n+  \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+  \/\/ If csg succeeds then CR=EQ, otherwise, register zero is filled\n+  \/\/ with the current owner.\n@@ -3571,1 +3569,2 @@\n-  z_csg(zero, Z_thread, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), monitor_tagged);\n+  z_l(Z_R1_scratch, Address(Z_thread, JavaThread::lock_id_offset()));\n+  z_csg(zero, Z_R1_scratch, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), monitor_tagged);\n@@ -3580,1 +3579,1 @@\n-  z_cgr(Z_thread, zero); \/\/ owner is stored in zero by \"z_csg\" above\n+  z_cgr(Z_R1_scratch, zero); \/\/ owner is stored in zero by \"z_csg\" above\n@@ -3645,1 +3644,2 @@\n-  z_cg(Z_thread, Address(currentHeader, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  z_l(Z_R1_scratch, Address(Z_thread, JavaThread::lock_id_offset()));\n+  z_cg(Z_R1_scratch, Address(currentHeader, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -6310,3 +6310,3 @@\n-    \/\/ Try to CAS m->owner from null to current thread.\n-    \/\/ If m->owner is null, then csg succeeds and sets m->owner=THREAD and CR=EQ.\n-    \/\/ Otherwise, register zero is filled with the current owner.\n+    \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n+    \/\/ If csg succeeds then CR=EQ, otherwise, register zero is filled\n+    \/\/ with the current owner.\n@@ -6314,1 +6314,2 @@\n-    z_csg(zero, Z_thread, owner_address);\n+    z_l(Z_R1_scratch, Address(Z_thread, JavaThread::lock_id_offset()));\n+    z_csg(zero, Z_R1_scratch, owner_address);\n@@ -6318,1 +6319,1 @@\n-    z_cgr(Z_thread, zero); \/\/ zero contains the owner from z_csg instruction\n+    z_cgr(Z_R1_scratch, zero); \/\/ zero contains the owner from z_csg instruction\n","filename":"src\/hotspot\/cpu\/s390\/macroAssembler_s390.cpp","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2390,0 +2390,5 @@\n+VMReg SharedRuntime::thread_register() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -724,0 +724,5 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  return nullptr;\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/s390\/templateInterpreterGenerator_s390.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2847,0 +2847,20 @@\n+#ifdef _LP64\n+void Assembler::lea(Register dst, Label& L) {\n+  emit_prefix_and_int8(get_prefixq(Address(), dst), (unsigned char)0x8D);\n+  if (!L.is_bound()) {\n+    \/\/ Patch @0x8D opcode\n+    L.add_patch_at(code(), CodeBuffer::locator(offset() - 1, sect()));\n+    \/\/ Register and [rip+disp] operand\n+    emit_modrm(0b00, raw_encode(dst), 0b101);\n+    emit_int32(0);\n+  } else {\n+    \/\/ Register and [rip+disp] operand\n+    emit_modrm(0b00, raw_encode(dst), 0b101);\n+    \/\/ Adjust displacement by sizeof lea instruction\n+    int32_t disp = checked_cast<int32_t>(target(L) - (pc() + sizeof(int32_t)));\n+    assert(is_simm32(disp), \"must be 32bit offset [rip+offset]\");\n+    emit_int32(disp);\n+  }\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1627,0 +1627,4 @@\n+#ifdef _LP64\n+  void lea(Register dst, Label& L);\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -112,0 +112,1 @@\n+    inc_held_monitor_count();\n@@ -114,2 +115,0 @@\n-  inc_held_monitor_count();\n-\n@@ -156,0 +155,2 @@\n+    bind(done);\n+    dec_held_monitor_count();\n@@ -157,2 +158,0 @@\n-  bind(done);\n-  dec_held_monitor_count();\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -209,0 +209,1 @@\n+  bool _use_pop_on_epilog;\n@@ -211,1 +212,1 @@\n-  StubFrame(StubAssembler* sasm, const char* name, bool must_gc_arguments);\n+  StubFrame(StubAssembler* sasm, const char* name, bool must_gc_arguments, bool use_pop_on_epilog = false);\n@@ -222,2 +223,6 @@\n-void StubAssembler::epilogue() {\n-  leave();\n+void StubAssembler::epilogue(bool use_pop) {\n+  \/\/ Avoid using a leave instruction when this frame may\n+  \/\/ have been frozen, since the current value of rbp\n+  \/\/ restored from the stub would be invalid. We still\n+  \/\/ must restore the rbp value saved on enter though.\n+  use_pop ? pop(rbp) : leave();\n@@ -229,1 +234,1 @@\n-StubFrame::StubFrame(StubAssembler* sasm, const char* name, bool must_gc_arguments) {\n+StubFrame::StubFrame(StubAssembler* sasm, const char* name, bool must_gc_arguments, bool use_pop_on_epilog) {\n@@ -231,0 +236,1 @@\n+  _use_pop_on_epilog = use_pop_on_epilog;\n@@ -242,1 +248,1 @@\n-  __ epilogue();\n+  __ epilogue(_use_pop_on_epilog);\n@@ -635,0 +641,8 @@\n+uint Runtime1::runtime_blob_current_thread_offset(frame f) {\n+#ifdef _LP64\n+  return r15_off \/ 2;\n+#else\n+  Unimplemented();\n+  return 0;\n+#endif\n+}\n@@ -1311,1 +1325,1 @@\n-        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments);\n+        StubFrame f(sasm, \"monitorenter\", dont_gc_arguments, true \/* use_pop_on_epilog *\/);\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -314,43 +314,7 @@\n-  \/\/ The object is inflated.\n-\n-  \/\/ boxReg refers to the on-stack BasicLock in the current frame.\n-  \/\/ We'd like to write:\n-  \/\/   set box->_displaced_header = markWord::unused_mark().  Any non-0 value suffices.\n-  \/\/ This is convenient but results a ST-before-CAS penalty.  The following CAS suffers\n-  \/\/ additional latency as we have another ST in the store buffer that must drain.\n-\n-  \/\/ avoid ST-before-CAS\n-  \/\/ register juggle because we need tmpReg for cmpxchgptr below\n-  movptr(scrReg, boxReg);\n-  movptr(boxReg, tmpReg);                   \/\/ consider: LEA box, [tmp-2]\n-\n-  \/\/ Optimistic form: consider XORL tmpReg,tmpReg\n-  movptr(tmpReg, NULL_WORD);\n-\n-  \/\/ Appears unlocked - try to swing _owner from null to non-null.\n-  \/\/ Ideally, I'd manifest \"Self\" with get_thread and then attempt\n-  \/\/ to CAS the register containing Self into m->Owner.\n-  \/\/ But we don't have enough registers, so instead we can either try to CAS\n-  \/\/ rsp or the address of the box (in scr) into &m->owner.  If the CAS succeeds\n-  \/\/ we later store \"Self\" into m->Owner.  Transiently storing a stack address\n-  \/\/ (rsp or the address of the box) into  m->owner is harmless.\n-  \/\/ Invariant: tmpReg == 0.  tmpReg is EAX which is the implicit cmpxchg comparand.\n-  lock();\n-  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  movptr(Address(scrReg, 0), 3);          \/\/ box->_displaced_header = 3\n-  \/\/ If we weren't able to swing _owner from null to the BasicLock\n-  \/\/ then take the slow path.\n-  jccb  (Assembler::notZero, NO_COUNT);\n-  \/\/ update _owner from BasicLock to thread\n-  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n-  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n-\n-  \/\/ If the CAS fails we can either retry or pass control to the slow path.\n-  \/\/ We use the latter tactic.\n-  \/\/ Pass the CAS result in the icc.ZFlag into DONE_LABEL\n-  \/\/ If the CAS was successful ...\n-  \/\/   Self has acquired the lock\n-  \/\/   Invariant: m->_recursions should already be 0, so we don't need to explicitly set it.\n-  \/\/ Intentional fall-through into DONE_LABEL ...\n-#else \/\/ _LP64\n+  \/\/ Just take slow path to avoid dealing with 64 bit atomic instructions here.\n+  orl(boxReg, 1);  \/\/ set ICC.ZF=0 to indicate failure\n+#else\n+  \/\/ Unconditionally set box->_displaced_header = markWord::unused_mark().\n+  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n+  movptr(Address(boxReg, 0), checked_cast<int32_t>(markWord::unused_mark().value()));\n+\n@@ -360,0 +324,1 @@\n+  movptr(boxReg, Address(r15_thread, JavaThread::lock_id_offset()));\n@@ -361,4 +326,2 @@\n-  cmpxchgptr(thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  \/\/ Unconditionally set box->_displaced_header = markWord::unused_mark().\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(boxReg, 0), checked_cast<int32_t>(markWord::unused_mark().value()));\n+  cmpxchgptr(boxReg, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+\n@@ -366,1 +329,1 @@\n-  jccb(Assembler::equal, COUNT);          \/\/ CAS above succeeded; propagate ZF = 1 (success)\n+  jccb(Assembler::equal, COUNT);    \/\/ CAS above succeeded; propagate ZF = 1 (success)\n@@ -368,1 +331,1 @@\n-  cmpptr(thread, rax);                \/\/ Check if we are already the owner (recursive lock)\n+  cmpptr(boxReg, rax);                \/\/ Check if we are already the owner (recursive lock)\n@@ -380,3 +343,6 @@\n-  \/\/ Count monitors in fast path\n-  increment(Address(thread, JavaThread::held_monitor_count_offset()));\n-\n+  if (LockingMode == LM_LEGACY) {\n+#ifdef _LP64\n+    \/\/ Count monitors in fast path\n+    increment(Address(thread, JavaThread::held_monitor_count_offset()));\n+#endif\n+  }\n@@ -444,0 +410,5 @@\n+#ifndef _LP64\n+  \/\/ Just take slow path to avoid dealing with 64 bit atomic instructions here.\n+  orl(boxReg, 1);  \/\/ set ICC.ZF=0 to indicate failure\n+  jmpb(DONE_LABEL);\n+#else\n@@ -492,4 +463,0 @@\n-#ifndef _LP64\n-  get_thread(boxReg);\n-  movptr(Address(boxReg, JavaThread::unlocked_inflated_monitor_offset()), tmpReg);\n-#else \/\/ _LP64\n@@ -497,1 +464,0 @@\n-#endif\n@@ -505,0 +471,1 @@\n+#endif  \/\/ _LP64\n@@ -521,6 +488,5 @@\n-  \/\/ Count monitors in fast path\n-#ifndef _LP64\n-  get_thread(tmpReg);\n-  decrementl(Address(tmpReg, JavaThread::held_monitor_count_offset()));\n-#else \/\/ _LP64\n-  decrementq(Address(r15_thread, JavaThread::held_monitor_count_offset()));\n+\n+  if (LockingMode == LM_LEGACY) {\n+    \/\/ Count monitors in fast path\n+#ifdef _LP64\n+    decrementq(Address(r15_thread, JavaThread::held_monitor_count_offset()));\n@@ -528,0 +494,1 @@\n+  }\n@@ -605,0 +572,5 @@\n+#ifndef _LP64\n+    \/\/ Just take slow path to avoid dealing with 64 bit atomic instructions here.\n+    orl(box, 1);  \/\/ set ICC.ZF=0 to indicate failure\n+    jmpb(slow_path);\n+#else\n@@ -650,1 +622,7 @@\n-    \/\/ CAS owner (null => current thread).\n+    if (UseObjectMonitorTable) {\n+      \/\/ Cache the monitor for unlock before trashing box. On failure to acquire\n+      \/\/ the lock, the slow path will reset the entry accordingly (see CacheSetter).\n+      movptr(Address(box, BasicLock::object_monitor_cache_offset_in_bytes()), monitor);\n+    }\n+\n+    \/\/ Try to CAS owner (no owner => current thread's _lock_id).\n@@ -652,1 +630,2 @@\n-    lock(); cmpxchgptr(thread, owner_address);\n+    movptr(box, Address(thread, JavaThread::lock_id_offset()));\n+    lock(); cmpxchgptr(box, owner_address);\n@@ -656,1 +635,1 @@\n-    cmpptr(thread, rax_reg);\n+    cmpptr(box, rax_reg);\n@@ -663,4 +642,1 @@\n-    if (UseObjectMonitorTable) {\n-      \/\/ Cache the monitor for unlock\n-      movptr(Address(box, BasicLock::object_monitor_cache_offset_in_bytes()), monitor);\n-    }\n+#endif  \/\/ _LP64\n@@ -670,1 +646,0 @@\n-  increment(Address(thread, JavaThread::held_monitor_count_offset()));\n@@ -780,0 +755,5 @@\n+#ifndef _LP64\n+    \/\/ Just take slow path to avoid dealing with 64 bit atomic instructions here.\n+    orl(t, 1);  \/\/ set ICC.ZF=0 to indicate failure\n+    jmpb(slow_path);\n+#else\n@@ -831,0 +811,1 @@\n+#endif  \/\/ _LP64\n@@ -834,1 +815,0 @@\n-  decrement(Address(thread, JavaThread::held_monitor_count_offset()));\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":52,"deletions":72,"binary":false,"changes":124,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -129,0 +129,5 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  assert(f.interpreter_frame_last_sp() == nullptr, \"should be null for top frame\");\n+  f.interpreter_frame_set_last_sp(f.unextended_sp());\n+}\n+\n@@ -139,1 +144,3 @@\n-  assert((*hf.addr_at(frame::interpreter_frame_locals_offset) == frame::sender_sp_offset + f.interpreter_frame_method()->max_locals() - 1), \"\");\n+  DEBUG_ONLY(Method* m = f.interpreter_frame_method();)\n+  DEBUG_ONLY(int max_locals = !m->is_native() ? m->max_locals() : m->size_of_parameters() + 2;)\n+  assert((*hf.addr_at(frame::interpreter_frame_locals_offset) == frame::sender_sp_offset + max_locals - 1), \"\");\n@@ -210,1 +217,0 @@\n-    const int locals = hf.interpreter_frame_method()->max_locals();\n@@ -220,1 +226,3 @@\n-    assert((int)locals_offset == frame::sender_sp_offset + locals - 1, \"\");\n+    DEBUG_ONLY(Method* m = hf.interpreter_frame_method();)\n+    DEBUG_ONLY(const int max_locals = !m->is_native() ? m->max_locals() : m->size_of_parameters() + 2;)\n+    assert((int)locals_offset == frame::sender_sp_offset + max_locals - 1, \"\");\n@@ -228,1 +236,1 @@\n-      int argsize = hf.compiled_frame_stack_argsize();\n+      int argsize = FKind::stack_argsize(hf);\n@@ -245,2 +253,3 @@\n-       \/\/ we need to re-read fp because it may be an oop and we might have fixed the frame.\n-      fp = *(intptr_t**)(hf.sp() - frame::sender_sp_offset);\n+      fp = FKind::stub || FKind::native\n+        ? frame_sp + fsize - frame::sender_sp_offset \/\/ fp always points to the address below the pushed return pc. We need correct address.\n+        : *(intptr_t**)(hf.sp() - frame::sender_sp_offset); \/\/ we need to re-read fp because it may be an oop and we might have fixed the frame.\n@@ -269,0 +278,21 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  intptr_t* fp = caller_sp - frame::sender_sp_offset;\n+  patch_callee_link(f, fp);\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  \/\/ Nothing to do\n+  return top.sp();\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  frame enterSpecial = new_entry_frame();\n+  intptr_t* sp = enterSpecial.sp();\n+\n+  sp[-1] = (intptr_t)ContinuationEntry::cleanup_pc();\n+  sp[-2] = (intptr_t)enterSpecial.fp();\n+\n+  log_develop_trace(continuations, preempt)(\"push_cleanup_continuation initial sp: \" INTPTR_FORMAT \" final sp: \" INTPTR_FORMAT, p2i(sp + 2 * frame::metadata_words), p2i(sp));\n+  return sp;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/continuationFreezeThaw_x86.inline.hpp","additions":37,"deletions":7,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,14 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  if (f.is_runtime_frame()) {\n+    \/\/ Patch the pc of the now old last Java frame (we already set the anchor to enterSpecial)\n+    \/\/ so that when target goes back to Java it will actually return to the preempt cleanup stub.\n+    intptr_t* sp = f.sp();\n+    sp[-1] = (intptr_t)StubRoutines::cont_preempt_stub();\n+  } else {\n+    \/\/ The target will check for preemption once it returns to the interpreter\n+    \/\/ or the native wrapper code and will manually jump to the preempt stub.\n+    JavaThread *thread = JavaThread::current();\n+    thread->set_preempt_alternate_return(StubRoutines::cont_preempt_stub());\n+  }\n+}\n+\n@@ -75,1 +89,0 @@\n-#ifdef ASSERT\n@@ -81,0 +94,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/x86\/continuationHelper_x86.inline.hpp","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -412,0 +412,30 @@\n+#if defined(ASSERT)\n+static address get_register_address_in_stub(const frame& stub_fr, VMReg reg) {\n+  RegisterMap map(nullptr,\n+                  RegisterMap::UpdateMap::include,\n+                  RegisterMap::ProcessFrames::skip,\n+                  RegisterMap::WalkContinuation::skip);\n+  stub_fr.oop_map()->update_register_map(&stub_fr, &map);\n+  return map.location(reg, stub_fr.sp());\n+}\n+#endif\n+\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  CodeBlob* cb = f.cb();\n+  assert(cb != nullptr && cb->is_runtime_stub(), \"invalid frame\");\n+\n+  JavaThread** thread_addr;\n+#ifdef COMPILER1\n+  if (cb == Runtime1::blob_for(C1StubId::monitorenter_id) ||\n+      cb == Runtime1::blob_for(C1StubId::monitorenter_nofpu_id)) {\n+    thread_addr = (JavaThread**)(f.sp() + Runtime1::runtime_blob_current_thread_offset(f));\n+  } else\n+#endif\n+  {\n+    \/\/ c2 only saves rbp in the stub frame so nothing to do.\n+    thread_addr = nullptr;\n+  }\n+  assert(get_register_address_in_stub(f, SharedRuntime::thread_register()) == (address)thread_addr, \"wrong thread address\");\n+  return thread_addr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":30,"deletions":0,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#ifdef _LP64\n@@ -38,0 +39,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/globalDefinitions_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -339,0 +339,59 @@\n+#ifdef _LP64\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result,\n+                                                    address entry_point,\n+                                                    Register arg_1) {\n+  assert(arg_1 == c_rarg1, \"\");\n+  Label resume_pc, not_preempted;\n+\n+#ifdef ASSERT\n+  {\n+    Label L;\n+    cmpptr(Address(r15_thread, JavaThread::preempt_alternate_return_offset()), NULL_WORD);\n+    jcc(Assembler::equal, L);\n+    stop(\"Should not have alternate return address set\");\n+    bind(L);\n+  }\n+#endif \/* ASSERT *\/\n+\n+  \/\/ Force freeze slow path.\n+  push_cont_fastpath();\n+\n+  \/\/ Make VM call. In case of preemption set last_pc to the one we want to resume to.\n+  lea(rscratch1, resume_pc);\n+  push(rscratch1);\n+  MacroAssembler::call_VM_helper(oop_result, entry_point, 1, false \/*check_exceptions*\/);\n+  pop(rscratch1);\n+\n+  pop_cont_fastpath();\n+\n+  \/\/ Check if preempted.\n+  movptr(rscratch1, Address(r15_thread, JavaThread::preempt_alternate_return_offset()));\n+  cmpptr(rscratch1, NULL_WORD);\n+  jccb(Assembler::zero, not_preempted);\n+  movptr(Address(r15_thread, JavaThread::preempt_alternate_return_offset()), NULL_WORD);\n+  jmp(rscratch1);\n+\n+  \/\/ In case of preemption, this is where we will resume once we finally acquire the monitor.\n+  bind(resume_pc);\n+  restore_after_resume(false \/* is_native *\/);\n+\n+  bind(not_preempted);\n+}\n+\n+void InterpreterMacroAssembler::restore_after_resume(bool is_native) {\n+  lea(rscratch1, ExternalAddress(Interpreter::cont_resume_interpreter_adapter()));\n+  call(rscratch1);\n+  if (is_native) {\n+    \/\/ On resume we need to set up stack as expected.\n+    push(dtos);\n+    push(ltos);\n+  }\n+}\n+#else\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result,\n+                         address entry_point,\n+                         Register arg_1) {\n+  MacroAssembler::call_VM(oop_result, entry_point, arg_1);\n+}\n+#endif  \/\/ _LP64\n+\n@@ -1157,1 +1216,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -1244,0 +1303,1 @@\n+      inc_held_monitor_count();\n@@ -1245,1 +1305,0 @@\n-    inc_held_monitor_count();\n@@ -1251,1 +1310,1 @@\n-    call_VM(noreg,\n+    call_VM_preemptable(noreg,\n@@ -1324,0 +1383,1 @@\n+      dec_held_monitor_count();\n@@ -1325,1 +1385,0 @@\n-    dec_held_monitor_count();\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":63,"deletions":4,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -66,0 +66,5 @@\n+  void call_VM_preemptable(Register oop_result,\n+                           address entry_point,\n+                           Register arg_1);\n+  void restore_after_resume(bool is_native);\n+\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"interpreter\/interpreterRuntime.hpp\"\n@@ -531,1 +532,0 @@\n-\n@@ -3036,7 +3036,1 @@\n-#ifndef _LP64\n-  Register thread = rax;\n-  push(thread);\n-  get_thread(thread);\n-  incrementl(Address(thread, JavaThread::held_monitor_count_offset()));\n-  pop(thread);\n-#else \/\/ LP64\n+#ifdef _LP64\n@@ -3048,7 +3042,1 @@\n-#ifndef _LP64\n-  Register thread = rax;\n-  push(thread);\n-  get_thread(thread);\n-  decrementl(Address(thread, JavaThread::held_monitor_count_offset()));\n-  pop(thread);\n-#else \/\/ LP64\n+#ifdef _LP64\n@@ -3151,0 +3139,11 @@\n+#ifdef _LP64\n+void MacroAssembler::set_last_Java_frame(Register last_java_sp,\n+                                         Register last_java_fp,\n+                                         Label &L,\n+                                         Register scratch) {\n+  lea(scratch, L);\n+  movptr(Address(r15_thread, JavaThread::last_Java_pc_offset()), scratch);\n+  set_last_Java_frame(r15_thread, last_java_sp, last_java_fp, nullptr, scratch);\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":14,"deletions":15,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -114,1 +114,2 @@\n-        (op == 0xC7 && branch[1] == 0xF8) \/* xbegin *\/,\n+        (op == 0xC7 && branch[1] == 0xF8) \/* xbegin *\/ ||\n+        (op == 0x8D) \/* lea *\/,\n@@ -125,1 +126,1 @@\n-      int* disp = (int*) &branch[(op == 0x0F || op == 0xC7)? 2: 1];\n+      int* disp = (int*) &branch[(op == 0x0F || op == 0xC7 || op == 0x8D) ? 2 : 1];\n@@ -338,0 +339,7 @@\n+#ifdef _LP64\n+  void set_last_Java_frame(Register last_java_sp,\n+                           Register last_java_fp,\n+                           Label &last_java_pc,\n+                           Register scratch);\n+#endif\n+\n@@ -896,1 +904,1 @@\n-  void lea(Register dst, Address        adr) { Assembler::lea(dst, adr); }\n+  using Assembler::lea;\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2059,0 +2059,5 @@\n+VMReg SharedRuntime::thread_register() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -174,0 +174,1 @@\n+  static int r15_offset_in_bytes(void)    { return BytesPerInt * r15_off; }\n@@ -1423,1 +1424,1 @@\n-void static continuation_enter_cleanup(MacroAssembler* masm) {\n+static void continuation_enter_cleanup(MacroAssembler* masm) {\n@@ -1613,0 +1614,1 @@\n+  ContinuationEntry::_thaw_call_pc_offset = __ pc() - start;\n@@ -1622,1 +1624,1 @@\n-\n+  ContinuationEntry::_cleanup_offset = __ pc() - start;\n@@ -1715,0 +1717,4 @@\n+void SharedRuntime::continuation_enter_cleanup(MacroAssembler* masm) {\n+  ::continuation_enter_cleanup(masm);\n+}\n+\n@@ -2183,4 +2189,7 @@\n-  intptr_t the_pc = (intptr_t) __ pc();\n-  oop_maps->add_gc_map(the_pc - start, map);\n-\n-  __ set_last_Java_frame(rsp, noreg, (address)the_pc, rscratch1);\n+  Label native_return;\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ For convenience we use the pc we want to resume to in case of preemption on Object.wait.\n+    __ set_last_Java_frame(rsp, noreg, native_return, rscratch1);\n+  } else {\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n@@ -2188,0 +2197,2 @@\n+    __ set_last_Java_frame(rsp, noreg, __ pc(), rscratch1);\n+  }\n@@ -2274,0 +2285,3 @@\n+\n+      __ bind(count_mon);\n+      __ inc_held_monitor_count();\n@@ -2278,2 +2292,0 @@\n-    __ bind(count_mon);\n-    __ inc_held_monitor_count();\n@@ -2370,0 +2382,14 @@\n+  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+    \/\/ Check preemption for Object.wait()\n+    __ movptr(rscratch1, Address(r15_thread, JavaThread::preempt_alternate_return_offset()));\n+    __ cmpptr(rscratch1, NULL_WORD);\n+    __ jccb(Assembler::equal, native_return);\n+    __ movptr(Address(r15_thread, JavaThread::preempt_alternate_return_offset()), NULL_WORD);\n+    __ jmp(rscratch1);\n+    __ bind(native_return);\n+\n+    intptr_t the_pc = (intptr_t) __ pc();\n+    oop_maps->add_gc_map(the_pc - start, map);\n+  }\n+\n+\n@@ -2419,1 +2445,0 @@\n-      __ dec_held_monitor_count();\n@@ -2494,0 +2519,3 @@\n+    \/\/ Force freeze slow path in case we try to preempt. We will pin the\n+    \/\/ vthread to the carrier (see FreezeBase::recurse_freeze_native_frame()).\n+    __ push_cont_fastpath();\n@@ -2495,0 +2523,1 @@\n+    __ pop_cont_fastpath();\n@@ -2609,0 +2638,4 @@\n+VMReg SharedRuntime::thread_register() {\n+  return r15_thread->as_VMReg();\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":42,"deletions":9,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -117,0 +117,1 @@\n+        + (f.interpreter_frame_method()->is_native() ? 1 : 0) \/\/ temp oop slot\n","filename":"src\/hotspot\/cpu\/x86\/stackChunkFrameStream_x86.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/continuationEntry.hpp\"\n@@ -3782,0 +3783,30 @@\n+address StubGenerator::generate_cont_preempt_stub() {\n+  if (!Continuations::enabled()) return nullptr;\n+  StubCodeMark mark(this, \"StubRoutines\",\"Continuation preempt stub\");\n+  address start = __ pc();\n+\n+  __ reset_last_Java_frame(true);\n+\n+  \/\/ Set rsp to enterSpecial frame, i.e. remove all frames copied into the heap.\n+  __ movptr(rsp, Address(r15_thread, JavaThread::cont_entry_offset()));\n+\n+  Label preemption_cancelled;\n+  __ movbool(rscratch1, Address(r15_thread, JavaThread::preemption_cancelled_offset()));\n+  __ testbool(rscratch1);\n+  __ jcc(Assembler::notZero, preemption_cancelled);\n+\n+  \/\/ Remove enterSpecial frame from the stack and return to Continuation.run() to unmount.\n+  SharedRuntime::continuation_enter_cleanup(_masm);\n+  __ pop(rbp);\n+  __ ret(0);\n+\n+  \/\/ We acquired the monitor after freezing the frames so call thaw to continue execution.\n+  __ bind(preemption_cancelled);\n+  __ movbool(Address(r15_thread, JavaThread::preemption_cancelled_offset()), false);\n+  __ lea(rbp, Address(rsp, checked_cast<int32_t>(ContinuationEntry::size())));\n+  __ movptr(rscratch1, ExternalAddress(ContinuationEntry::thaw_call_pc_address()));\n+  __ jmp(rscratch1);\n+\n+  return start;\n+}\n+\n@@ -3954,0 +3985,1 @@\n+  StubRoutines::_cont_preempt_stub = generate_cont_preempt_stub();\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -601,0 +601,3 @@\n+  address generate_cont_preempt_stub();\n+  address generate_cont_resume_monitor_operation();\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-  _continuation_stubs_code_size =  1000 LP64_ONLY(+1000),\n+  _continuation_stubs_code_size =  1000 LP64_ONLY(+2000),\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -390,0 +390,20 @@\n+address TemplateInterpreterGenerator::generate_cont_resume_interpreter_adapter() {\n+  if (!Continuations::enabled()) return nullptr;\n+  address start = __ pc();\n+\n+  __ restore_bcp();\n+  __ restore_locals();\n+\n+  \/\/ Get return address before adjusting rsp\n+  __ movptr(rax, Address(rsp, 0));\n+\n+  \/\/ Restore stack bottom\n+  __ movptr(rcx, Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize));\n+  __ lea(rsp, Address(rbp, rcx, Address::times_ptr));\n+  \/\/ and NULL it as marker that esp is now tos until next java call\n+  __ movptr(Address(rbp, frame::interpreter_frame_last_sp_offset * wordSize), NULL_WORD);\n+\n+  __ jmp(rax);\n+\n+  return start;\n+}\n@@ -1032,1 +1052,4 @@\n-   __ set_last_Java_frame(rsp, rbp, (address) __ pc(), rscratch1);\n+   \/\/ For convenience we use the pc we want to resume to in\n+   \/\/ case of preemption on Object.wait.\n+   Label native_return;\n+   __ set_last_Java_frame(rsp, rbp, native_return, rscratch1);\n@@ -1052,0 +1075,2 @@\n+  __ push_cont_fastpath();\n+\n@@ -1057,0 +1082,2 @@\n+  __ pop_cont_fastpath();\n+\n@@ -1080,1 +1107,1 @@\n-    __ cmpptr(Address(rbp, (frame::interpreter_frame_oop_temp_offset + 1)*wordSize),\n+    __ cmpptr(Address(rbp, (frame::interpreter_frame_result_handler_offset)*wordSize),\n@@ -1083,1 +1110,1 @@\n-    __ cmpptr(Address(rbp, (frame::interpreter_frame_oop_temp_offset + 1)*wordSize),\n+    __ cmpptr(Address(rbp, (frame::interpreter_frame_result_handler_offset)*wordSize),\n@@ -1153,0 +1180,18 @@\n+#ifdef _LP64\n+  if (LockingMode != LM_LEGACY) {\n+    \/\/ Check preemption for Object.wait()\n+    Label not_preempted;\n+    __ movptr(rscratch1, Address(r15_thread, JavaThread::preempt_alternate_return_offset()));\n+    __ cmpptr(rscratch1, NULL_WORD);\n+    __ jccb(Assembler::equal, not_preempted);\n+    __ movptr(Address(r15_thread, JavaThread::preempt_alternate_return_offset()), NULL_WORD);\n+    __ jmp(rscratch1);\n+    __ bind(native_return);\n+    __ restore_after_resume(true \/* is_native *\/);\n+    __ bind(not_preempted);\n+  } else {\n+    \/\/ any pc will do so just use this one for LM_LEGACY to keep code together.\n+    __ bind(native_return);\n+  }\n+#endif \/\/ _LP64\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":48,"deletions":3,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -51,0 +51,4 @@\n+inline void FreezeBase::prepare_freeze_interpreted_top_frame(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -86,0 +90,14 @@\n+inline void ThawBase::patch_pd(frame& f, intptr_t* caller_sp) {\n+  Unimplemented();\n+}\n+\n+inline intptr_t* ThawBase::possibly_adjust_frame(frame& top) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n+inline intptr_t* ThawBase::push_cleanup_continuation() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/zero\/continuationFreezeThaw_zero.inline.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -36,0 +36,4 @@\n+static inline void patch_return_pc_with_preempt_stub(frame& f) {\n+  Unimplemented();\n+}\n+\n@@ -63,1 +67,0 @@\n-#ifdef ASSERT\n@@ -68,0 +71,1 @@\n+#ifdef ASSERT\n","filename":"src\/hotspot\/cpu\/zero\/continuationHelper_zero.inline.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -75,0 +75,5 @@\n+JavaThread** frame::saved_thread_address(const frame& f) {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/zero\/frame_zero.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -39,2 +39,0 @@\n-#define SUPPORT_MONITOR_COUNT\n-\n","filename":"src\/hotspot\/cpu\/zero\/globalDefinitions_zero.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -88,0 +88,5 @@\n+VMReg SharedRuntime::thread_register() {\n+  Unimplemented();\n+  return nullptr;\n+}\n+\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -349,3 +349,0 @@\n-      if (success) {\n-        THREAD->inc_held_monitor_count();\n-      }\n@@ -502,3 +499,0 @@\n-      if (success) {\n-        THREAD->dec_held_monitor_count();\n-      }\n","filename":"src\/hotspot\/cpu\/zero\/zeroInterpreter_zero.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -92,1 +92,1 @@\n-  void epilogue();\n+  void epilogue(bool use_pop = false);\n","filename":"src\/hotspot\/share\/c1\/c1_MacroAssembler.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -138,0 +138,2 @@\n+  static uint runtime_blob_current_thread_offset(frame f);\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1689,0 +1689,1 @@\n+  assert(is_in_VTMS_transition(java_thread) != val, \"already %s transition\", val ? \"inside\" : \"outside\");\n@@ -2024,0 +2025,4 @@\n+int java_lang_VirtualThread::_next_offset;\n+int java_lang_VirtualThread::_onWaitingList_offset;\n+int java_lang_VirtualThread::_notified_offset;\n+int java_lang_VirtualThread::_waitTimeout_offset;\n@@ -2029,1 +2034,5 @@\n-  macro(_state_offset,                     k, \"state\",              int_signature,               false)\n+  macro(_state_offset,                     k, \"state\",              int_signature,               false); \\\n+  macro(_next_offset,                      k, \"next\",               vthread_signature,           false); \\\n+  macro(_onWaitingList_offset,             k, \"onWaitingList\",      bool_signature,              false); \\\n+  macro(_notified_offset,                  k, \"notified\",           bool_signature,              false); \\\n+  macro(_waitTimeout_offset,               k, \"waitTimeout\",        long_signature,              false);\n@@ -2055,0 +2064,50 @@\n+void java_lang_VirtualThread::set_state(oop vthread, int state) {\n+  vthread->release_int_field_put(_state_offset, state);\n+}\n+\n+int java_lang_VirtualThread::cmpxchg_state(oop vthread, int old_state, int new_state) {\n+  jint* addr = vthread->field_addr<jint>(_state_offset);\n+  int res = Atomic::cmpxchg(addr, old_state, new_state);\n+  return res;\n+}\n+\n+oop java_lang_VirtualThread::next(oop vthread) {\n+  return vthread->obj_field(_next_offset);\n+}\n+\n+void java_lang_VirtualThread::set_next(oop vthread, oop next_vthread) {\n+  vthread->obj_field_put(_next_offset, next_vthread);\n+}\n+\n+\/\/ Add vthread to the waiting list if it's not already in it. Multiple threads\n+\/\/ could be trying to add vthread to the list at the same time, so we control\n+\/\/ access with a cmpxchg on onWaitingList. The winner adds vthread to the list.\n+\/\/ Method returns true if we added vthread to the list, false otherwise.\n+bool java_lang_VirtualThread::set_onWaitingList(oop vthread, OopHandle& list_head) {\n+  jboolean* addr = vthread->field_addr<jboolean>(_onWaitingList_offset);\n+  jboolean vthread_on_list = Atomic::load(addr);\n+  if (!vthread_on_list) {\n+    vthread_on_list = Atomic::cmpxchg(addr, (jboolean)JNI_FALSE, (jboolean)JNI_TRUE);\n+    if (!vthread_on_list) {\n+      for (;;) {\n+        oop head = list_head.resolve();\n+        java_lang_VirtualThread::set_next(vthread, head);\n+        if (list_head.cmpxchg(head, vthread) == head) return true;\n+      }\n+    }\n+  }\n+  return false; \/\/ already on waiting list\n+}\n+\n+void java_lang_VirtualThread::set_notified(oop vthread, jboolean value) {\n+  vthread->bool_field_put_volatile(_notified_offset, value);\n+}\n+\n+jlong java_lang_VirtualThread::waitTimeout(oop vthread) {\n+  return vthread->long_field(_waitTimeout_offset);\n+}\n+\n+void java_lang_VirtualThread::set_waitTimeout(oop vthread, jlong value) {\n+  vthread->long_field_put(_waitTimeout_offset, value);\n+}\n+\n@@ -2068,0 +2127,3 @@\n+    case UNBLOCKED:\n+    case WAITING:\n+    case TIMED_WAITING:\n@@ -2078,0 +2140,10 @@\n+    case BLOCKING:\n+    case BLOCKED:\n+      status = JavaThreadStatus::BLOCKED_ON_MONITOR_ENTER;\n+      break;\n+    case WAIT:\n+      status = JavaThreadStatus::IN_OBJECT_WAIT;\n+      break;\n+    case TIMED_WAIT:\n+      status = JavaThreadStatus::IN_OBJECT_WAIT_TIMED;\n+      break;\n@@ -2087,0 +2159,7 @@\n+bool java_lang_VirtualThread::is_preempted(oop vthread) {\n+  oop continuation = java_lang_VirtualThread::continuation(vthread);\n+  assert(continuation != nullptr, \"vthread with no continuation\");\n+  stackChunkOop chunk = jdk_internal_vm_Continuation::tail(continuation);\n+  return chunk != nullptr && chunk->preempted();\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":80,"deletions":1,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -533,0 +533,5 @@\n+  static int _next_offset;\n+  static int _onWaitingList_offset;\n+  static int _notified_offset;\n+  static int _recheckInterval_offset;\n+  static int _waitTimeout_offset;\n@@ -548,0 +553,7 @@\n+    BLOCKING      = 12,\n+    BLOCKED       = 13,\n+    UNBLOCKED     = 14,\n+    WAITING       = 15,\n+    WAIT          = 16,  \/\/ waiting in Object.wait\n+    TIMED_WAITING = 17,\n+    TIMED_WAIT    = 18,  \/\/ waiting in timed-Object.wait\n@@ -567,0 +579,9 @@\n+  static void set_state(oop vthread, int state);\n+  static int cmpxchg_state(oop vthread, int old_state, int new_state);\n+  static oop next(oop vthread);\n+  static void set_next(oop vthread, oop next_vthread);\n+  static bool set_onWaitingList(oop vthread, OopHandle& list_head);\n+  static jlong waitTimeout(oop vthread);\n+  static void set_waitTimeout(oop vthread, jlong value);\n+  static void set_notified(oop vthread, jboolean value);\n+  static bool is_preempted(oop vthread);\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -134,0 +134,1 @@\n+  case vmIntrinsics::_setCurrentLockId:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -301,0 +301,2 @@\n+  do_intrinsic(_setCurrentLockId,         java_lang_Thread,       setCurrentLockId_name, long_void_signature,     F_SN) \\\n+   do_name(     setCurrentLockId_name,                           \"setCurrentLockId\")                                    \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -521,0 +521,2 @@\n+  template(lockStackSize_name,                        \"lockStackSize\")                            \\\n+  template(objectWaiter_name,                         \"objectWaiter\")                             \\\n@@ -569,0 +571,1 @@\n+  template(vthread_signature,                         \"Ljava\/lang\/VirtualThread;\")                \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -711,1 +711,2 @@\n-  if (thread->has_last_Java_frame() && fr.sp() == thread->last_Java_sp()) {\n+  if ((thread->has_last_Java_frame() && fr.sp() == thread->last_Java_sp())\n+      JVMTI_ONLY(|| (method()->is_continuation_enter_intrinsic() && thread->on_monitor_waited_event()))) {\n@@ -1301,1 +1302,1 @@\n-    _num_stack_arg_slots     = _method->constMethod()->num_stack_arg_slots();\n+    _num_stack_arg_slots     = 0;\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -292,0 +292,3 @@\n+JNIEXPORT void JNICALL\n+JVM_SetCurrentLockId(JNIEnv* env, jclass threadClass, jlong tid);\n+\n@@ -1151,0 +1154,6 @@\n+JNIEXPORT void JNICALL\n+JVM_VirtualThreadPinnedEvent(jint reasonCode, jstring reasonString);\n+\n+JNIEXPORT jobject JNICALL\n+JVM_TakeVirtualThreadListToUnblock(JNIEnv* env, jclass ignored);\n+\n","filename":"src\/hotspot\/share\/include\/jvm.h","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -738,1 +738,1 @@\n-  current->last_frame().interpreter_frame_verify_monitor(elem);\n+  if (!current->preempting()) current->last_frame().interpreter_frame_verify_monitor(elem);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -237,0 +237,1 @@\n+  int         _num_oops;\n@@ -239,0 +240,1 @@\n+    _num_oops++;\n@@ -256,0 +258,1 @@\n+    _num_oops = 0;\n@@ -264,0 +267,2 @@\n+\n+  int num_oops() { return _num_oops; }\n@@ -322,0 +327,1 @@\n+  _num_oops = mf.num_oops();\n","filename":"src\/hotspot\/share\/interpreter\/oopMapCache.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -215,0 +215,1 @@\n+address    TemplateInterpreter::_cont_resume_interpreter_adapter            = nullptr;\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreter.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -114,0 +114,2 @@\n+  static address    _cont_resume_interpreter_adapter;\n+\n@@ -157,0 +159,2 @@\n+  static address    cont_resume_interpreter_adapter()           { return _cont_resume_interpreter_adapter; }\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreter.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -178,1 +178,3 @@\n-\n+  { CodeletMark cm(_masm, \"preemption resume adapter\");\n+    Interpreter::_cont_resume_interpreter_adapter = generate_cont_resume_interpreter_adapter();\n+  }\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+  address generate_cont_resume_interpreter_adapter();\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -644,3 +644,0 @@\n-          if (success) {\n-            THREAD->inc_held_monitor_count();\n-          }\n@@ -748,3 +745,0 @@\n-        if (success) {\n-          THREAD->inc_held_monitor_count();\n-        }\n@@ -1683,3 +1677,0 @@\n-            if (success) {\n-              THREAD->inc_held_monitor_count();\n-            }\n@@ -1723,3 +1714,0 @@\n-              if (success) {\n-                THREAD->dec_held_monitor_count();\n-              }\n@@ -3166,3 +3154,0 @@\n-            if (success) {\n-              THREAD->dec_held_monitor_count();\n-            }\n@@ -3245,3 +3230,0 @@\n-            if (dec_monitor_count) {\n-              THREAD->dec_held_monitor_count();\n-            }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+  static address cont_resume_interpreter_adapter()  { return nullptr; }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/zeroInterpreter.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -159,0 +159,5 @@\n+  <Event name=\"VirtualThreadPinned\" category=\"Java Virtual Machine, Runtime\" label=\"Virtual Thread Pinned\" thread=\"true\" stackTrace=\"true\" startTime=\"false\">\n+    <Field type=\"string\" name=\"pinnedReason\" label=\"Pinned Reason\" \/>\n+    <Field type=\"Thread\" name=\"carrierThread\" label=\"Carrier Thread\" \/>\n+  <\/Event>\n+\n","filename":"src\/hotspot\/share\/jfr\/metadata\/metadata.xml","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -228,0 +228,1 @@\n+  nonstatic_field(JavaThread,                  _lock_id,                                      int64_t)                               \\\n@@ -328,1 +329,1 @@\n-  unchecked_nonstatic_field(ObjectMonitor,     _owner,                                        sizeof(void *)) \/* NOTE: no type *\/    \\\n+  unchecked_nonstatic_field(ObjectMonitor,     _owner,                                        int64_t)                               \\\n@@ -332,1 +333,2 @@\n-  volatile_nonstatic_field(ObjectMonitor,      _succ,                                         JavaThread*)                           \\\n+  volatile_nonstatic_field(ObjectMonitor,      _succ,                                         int64_t)                               \\\n+  volatile_nonstatic_field(ObjectMonitor,      _stack_locker,                                 BasicLock*)                            \\\n@@ -781,0 +783,1 @@\n+  declare_constant(ObjectMonitor::NO_OWNER)                               \\\n@@ -782,0 +785,1 @@\n+  declare_constant(ObjectMonitor::DEFLATER_MARKER)                        \\\n@@ -810,0 +814,1 @@\n+  declare_constant(markWord::marked_value)                                \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1108,0 +1108,16 @@\n+\n+#if INCLUDE_JFR\n+      ContinuationEntry* ce = jt->last_continuation();\n+      if (ce != nullptr && ce->is_virtual_thread()) {\n+        EventVirtualThreadPinned e;\n+        if (e.should_commit()) {\n+          ResourceMark rm(jt);\n+          char reason[256];\n+          jio_snprintf(reason, sizeof reason, \"Waiting for initialization of klass %s\", external_name());\n+          e.set_pinnedReason(reason);\n+          e.set_carrierThread(JFR_JVM_THREAD_ID(THREAD));\n+          e.commit();\n+        }\n+      }\n+ #endif\n+\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -166,0 +166,17 @@\n+template <typename OopT>\n+void InstanceStackChunkKlass::oop_oop_iterate_lockstack(stackChunkOop chunk, OopIterateClosure* closure, MemRegion mr) {\n+  if (LockingMode != LM_LIGHTWEIGHT) {\n+    return;\n+  }\n+\n+  StackChunkOopIterateFilterClosure<OopIterateClosure> cl(closure, mr);\n+  if (chunk->has_bitmap()) {\n+    chunk->iterate_lockstack<OopT>(&cl);\n+  } else {\n+    chunk->iterate_lockstack<oop>(&cl);\n+  }\n+}\n+\n+template void InstanceStackChunkKlass::oop_oop_iterate_lockstack<oop>(stackChunkOop chunk, OopIterateClosure* closure, MemRegion mr);\n+template void InstanceStackChunkKlass::oop_oop_iterate_lockstack<narrowOop>(stackChunkOop chunk, OopIterateClosure* closure, MemRegion mr);\n+\n@@ -227,1 +244,1 @@\n-                  fs.is_interpreted() ? 0 : f.compiled_frame_stack_argsize());\n+                  fs.is_interpreted() || fs.is_stub() ? 0 : f.compiled_frame_stack_argsize());\n","filename":"src\/hotspot\/share\/oops\/instanceStackChunkKlass.cpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -180,0 +180,3 @@\n+  template <typename OopT>\n+  void oop_oop_iterate_lockstack(stackChunkOop chunk, OopIterateClosure* closure, MemRegion mr);\n+\n","filename":"src\/hotspot\/share\/oops\/instanceStackChunkKlass.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1,1 +1,1 @@\n-\/* Copyright (c) 2019, 2022, Oracle and\/or its affiliates. All rights reserved.\n+\/* Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -68,0 +68,1 @@\n+  oop_oop_iterate_lockstack<T>(chunk, closure, chunk->range());\n@@ -76,0 +77,1 @@\n+  oop_oop_iterate_lockstack<T>(chunk, closure, chunk->range());\n@@ -88,0 +90,1 @@\n+  oop_oop_iterate_lockstack<T>(chunk, closure, mr);\n","filename":"src\/hotspot\/share\/oops\/instanceStackChunkKlass.inline.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -870,0 +870,4 @@\n+bool Method::is_object_wait0() const {\n+  return name() == vmSymbols::wait_name();\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -589,0 +589,3 @@\n+  \/\/ returns true if the method name is wait0\n+  bool is_object_wait0() const;\n+\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+  inline oop cmpxchg(oop old_value, oop new_value);\n","filename":"src\/hotspot\/share\/oops\/oopHandle.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -68,0 +68,4 @@\n+inline oop OopHandle::cmpxchg(oop old_value, oop new_value) {\n+  return NativeAccess<MO_SEQ_CST>::oop_atomic_cmpxchg(_obj, old_value, new_value);\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/oopHandle.inline.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -68,0 +68,15 @@\n+class LockStackOopIterator : public OopIterator {\n+private:\n+  const stackChunkOop _chunk;\n+public:\n+  LockStackOopIterator(const stackChunkOop chunk) : _chunk(chunk) {}\n+\n+  virtual void oops_do(OopClosure* cl) override {\n+    int cnt = _chunk->lockstack_size();\n+    oop* lockstack_start = (oop*)_chunk->start_address();\n+    for (int i = 0; i < cnt; i++) {\n+      cl->do_oop(&lockstack_start[i]);\n+    }\n+  }\n+};\n+\n@@ -227,0 +242,8 @@\n+\n+  bool do_lockstack() {\n+    BarrierSetStackChunk* bs_chunk = BarrierSet::barrier_set()->barrier_set_stack_chunk();\n+    LockStackOopIterator iterator(_chunk);\n+    bs_chunk->encode_gc_mode(_chunk, &iterator);\n+\n+    return true;\n+  }\n@@ -301,0 +324,1 @@\n+  frame_cl.do_lockstack();\n@@ -323,0 +347,8 @@\n+\n+  bool do_lockstack() {\n+    BarrierSetStackChunk* bs_chunk = BarrierSet::barrier_set()->barrier_set_stack_chunk();\n+    LockStackOopIterator iterator(_chunk);\n+    bs_chunk->encode_gc_mode(_chunk, &iterator);\n+\n+    return true;\n+  }\n@@ -335,0 +367,1 @@\n+  closure.do_lockstack();\n@@ -411,0 +444,30 @@\n+void stackChunkOopDesc::transfer_lockstack(oop* dst) {\n+  const bool requires_gc_barriers = is_gc_mode() || requires_barriers();\n+  const bool requires_uncompress = has_bitmap() && UseCompressedOops;\n+  const auto load_and_clear_obj = [&](intptr_t* at) -> oop {\n+    if (requires_gc_barriers) {\n+      if (requires_uncompress) {\n+        oop value = HeapAccess<>::oop_load(reinterpret_cast<narrowOop*>(at));\n+        HeapAccess<>::oop_store(reinterpret_cast<narrowOop*>(at), nullptr);\n+        return value;\n+      } else {\n+        oop value = HeapAccess<>::oop_load(reinterpret_cast<oop*>(at));\n+        HeapAccess<>::oop_store(reinterpret_cast<oop*>(at), nullptr);\n+        return value;\n+      }\n+    } else {\n+      oop value = *reinterpret_cast<oop*>(at);\n+      HeapAccess<>::oop_store(reinterpret_cast<oop*>(at), nullptr);\n+      return value;\n+    }\n+  };\n+\n+  const int cnt = lockstack_size();\n+  intptr_t* lockstack_start = start_address();\n+  for (int i = 0; i < cnt; i++) {\n+    oop mon_owner = load_and_clear_obj(&lockstack_start[i]);\n+    assert(oopDesc::is_oop(mon_owner), \"not an oop\");\n+    dst[i] = mon_owner;\n+  }\n+}\n+\n@@ -459,1 +522,1 @@\n-  VerifyStackChunkFrameClosure(stackChunkOop chunk, int num_frames, int size)\n+  VerifyStackChunkFrameClosure(stackChunkOop chunk)\n@@ -461,1 +524,1 @@\n-      _size(size), _argsize(0), _num_oops(0), _num_frames(num_frames), _num_interpreted_frames(0), _num_i2c(0) {}\n+      _size(0), _argsize(0), _num_oops(0), _num_frames(0), _num_interpreted_frames(0), _num_i2c(0) {}\n@@ -555,1 +618,0 @@\n-  const bool has_safepoint_stub_frame = first.is_stub();\n@@ -557,3 +619,1 @@\n-  VerifyStackChunkFrameClosure closure(this,\n-                                       has_safepoint_stub_frame ? 1 : 0, \/\/ Iterate_stack skips the safepoint stub\n-                                       has_safepoint_stub_frame ? first.frame_size() : 0);\n+  VerifyStackChunkFrameClosure closure(this);\n","filename":"src\/hotspot\/share\/oops\/stackChunkOop.cpp","additions":66,"deletions":6,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,0 +39,2 @@\n+class ObjectMonitor;\n+class ObjectWaiter;\n@@ -61,0 +63,2 @@\n+  static const uint8_t FLAG_HAS_LOCKSTACK = 1 << 5; \/\/ LockStack was copied into stackChunk\n+  static const uint8_t FLAG_PREEMPTED = 1 << 6; \/\/ Continuation was unmounted from inside VM\n@@ -94,0 +98,9 @@\n+  inline uint8_t lockstack_size() const;\n+  inline void set_lockstack_size(uint8_t value);\n+\n+  inline ObjectWaiter* object_waiter() const;\n+  inline void set_object_waiter(ObjectWaiter* obj_waiter);\n+\n+  inline ObjectMonitor* current_pending_monitor() const;\n+  inline ObjectMonitor* current_waiting_monitor() const;\n+\n@@ -130,0 +143,6 @@\n+  inline bool preempted() const;\n+  inline void set_preempted(bool value);\n+\n+  inline bool has_lockstack() const;\n+  inline void set_has_lockstack(bool value);\n+\n@@ -150,0 +169,5 @@\n+  void transfer_lockstack(oop* start);\n+\n+  template <typename OopT, class StackChunkLockStackClosureType>\n+  inline void iterate_lockstack(StackChunkLockStackClosureType* closure);\n+\n","filename":"src\/hotspot\/share\/oops\/stackChunkOop.hpp","additions":25,"deletions":1,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,1 +39,1 @@\n-#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/frame.hpp\"\n@@ -42,0 +42,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -91,0 +92,6 @@\n+inline uint8_t stackChunkOopDesc::lockstack_size() const         { return jdk_internal_vm_StackChunk::lockStackSize(as_oop()); }\n+inline void stackChunkOopDesc::set_lockstack_size(uint8_t value) { jdk_internal_vm_StackChunk::set_lockStackSize(this, value); }\n+\n+inline ObjectWaiter* stackChunkOopDesc::object_waiter() const       { return (ObjectWaiter*)jdk_internal_vm_StackChunk::objectWaiter(as_oop()); }\n+inline void stackChunkOopDesc::set_object_waiter(ObjectWaiter* obj) { jdk_internal_vm_StackChunk::set_objectWaiter(this, (address)obj); }\n+\n@@ -170,1 +177,1 @@\n-  assert((flags() & ~FLAG_HAS_INTERPRETED_FRAMES) == 0, \"other flags should not be set\");\n+  assert((flags() & ~(FLAG_HAS_INTERPRETED_FRAMES | FLAG_PREEMPTED)) == 0, \"other flags should not be set\");\n@@ -174,0 +181,22 @@\n+inline bool stackChunkOopDesc::preempted() const { return is_flag(FLAG_PREEMPTED); }\n+inline void stackChunkOopDesc::set_preempted(bool value) {\n+  assert(preempted() != value, \"\");\n+  set_flag(FLAG_PREEMPTED, value);\n+}\n+\n+inline ObjectMonitor* stackChunkOopDesc::current_pending_monitor() const {\n+  ObjectWaiter* waiter = object_waiter();\n+  if (waiter != nullptr && (waiter->is_monitorenter() || (waiter->is_wait() && (waiter->at_reenter() || waiter->notified())))) {\n+    return waiter->monitor();\n+  }\n+  return nullptr;\n+}\n+\n+inline ObjectMonitor* stackChunkOopDesc::current_waiting_monitor() const {\n+  ObjectWaiter* waiter = object_waiter();\n+  return waiter != nullptr && waiter->is_wait() ? waiter->monitor() : nullptr;\n+}\n+\n+inline bool stackChunkOopDesc::has_lockstack() const         { return is_flag(FLAG_HAS_LOCKSTACK); }\n+inline void stackChunkOopDesc::set_has_lockstack(bool value) { set_flag(FLAG_HAS_LOCKSTACK, value); }\n+\n@@ -196,0 +225,10 @@\n+template <typename OopT, class StackChunkLockStackClosureType>\n+inline void stackChunkOopDesc::iterate_lockstack(StackChunkLockStackClosureType* closure) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n+  int cnt = lockstack_size();\n+  intptr_t* lockstart_addr = start_address();\n+  for (int i = 0; i < cnt; i++) {\n+    closure->do_oop((OopT*)&lockstart_addr[i]);\n+  }\n+}\n+\n@@ -216,0 +255,1 @@\n+    closure->do_frame(f, map);\n@@ -218,1 +258,0 @@\n-\n@@ -224,1 +263,0 @@\n-    f.handle_deopted(); \/\/ the stub caller might be deoptimized (as it's not at a call)\n@@ -285,1 +323,1 @@\n-  assert(fr.is_compiled_frame() || fr.cb()->is_safepoint_stub(), \"\");\n+  assert(fr.is_compiled_frame() || fr.cb()->is_runtime_stub(), \"\");\n","filename":"src\/hotspot\/share\/oops\/stackChunkOop.inline.hpp","additions":44,"deletions":6,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -733,0 +733,1 @@\n+  case vmIntrinsics::_setCurrentLockId:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -482,0 +482,1 @@\n+  case vmIntrinsics::_setCurrentLockId:         return inline_native_setCurrentLockId();\n@@ -3706,0 +3707,6 @@\n+\n+  \/\/ Change the lock_id of the JavaThread\n+  Node* tid = load_field_from_object(arr, \"tid\", \"J\");\n+  Node* thread_id_offset = basic_plus_adr(thread, in_bytes(JavaThread::lock_id_offset()));\n+  Node* tid_memory = store_to_memory(control(), thread_id_offset, tid, T_LONG, Compile::AliasIdxRaw, MemNode::unordered, true);\n+\n@@ -3710,0 +3717,7 @@\n+bool LibraryCallKit::inline_native_setCurrentLockId() {\n+  Node* thread = _gvn.transform(new ThreadLocalNode());\n+  Node* thread_id_offset = basic_plus_adr(thread, in_bytes(JavaThread::lock_id_offset()));\n+  Node* tid_memory = store_to_memory(control(), thread_id_offset, ConvL2X(argument(0)), T_LONG, Compile::AliasIdxRaw, MemNode::unordered, true);\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -241,0 +241,1 @@\n+  bool inline_native_setCurrentLockId();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3092,0 +3092,4 @@\n+\n+  \/\/ Set lock id of new current Thread\n+  thread->set_lock_id(java_lang_Thread::thread_id(threadObj));\n+\n@@ -3095,0 +3099,4 @@\n+JVM_ENTRY_NO_ENV(void, JVM_SetCurrentLockId(JNIEnv* env, jclass threadClass, jlong tid))\n+  thread->set_lock_id(tid);\n+JVM_END\n+\n@@ -3974,0 +3982,33 @@\n+JVM_ENTRY_NO_ENV(void, JVM_VirtualThreadPinnedEvent(jint reasonCode, jstring reasonString))\n+#if INCLUDE_JFR\n+  EventVirtualThreadPinned e;\n+  if (e.should_commit()) {\n+    ResourceMark rm(THREAD);\n+    \/\/ ignore reason code for now\n+    const char *reason = java_lang_String::as_utf8_string(JNIHandles::resolve_non_null(reasonString));\n+    e.set_pinnedReason(reason);\n+    e.set_carrierThread(JFR_JVM_THREAD_ID(THREAD));\n+    e.commit();\n+  }\n+#endif\n+JVM_END\n+\n+JVM_ENTRY(jobject, JVM_TakeVirtualThreadListToUnblock(JNIEnv* env, jclass ignored))\n+  ParkEvent* parkEvent = ObjectMonitor::vthread_unparker_ParkEvent();\n+  assert(parkEvent != nullptr, \"not initialized\");\n+\n+  OopHandle& list_head = ObjectMonitor::vthread_cxq_head();\n+  oop vthread_head = nullptr;\n+  while (true) {\n+    if (list_head.peek() != nullptr) {\n+      for (;;) {\n+        oop head = list_head.resolve();\n+        if (list_head.cmpxchg(head, nullptr) == head) {\n+          return JNIHandles::make_local(THREAD, head);\n+        }\n+      }\n+    }\n+    ThreadBlockInVM tbivm(THREAD);\n+    parkEvent->park();\n+  }\n+JVM_END\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":41,"deletions":0,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -1353,4 +1353,0 @@\n-  \/\/ growable array of jvmti monitors info on the C-heap\n-  GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list =\n-      new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n-\n@@ -1364,1 +1360,0 @@\n-    delete owned_monitors_list;\n@@ -1368,11 +1363,14 @@\n-  if (java_thread != nullptr) {\n-    Handle thread_handle(calling_thread, thread_oop);\n-    EscapeBarrier eb(true, calling_thread, java_thread);\n-    if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n-      delete owned_monitors_list;\n-      return JVMTI_ERROR_OUT_OF_MEMORY;\n-    }\n-    \/\/ get owned monitors info with handshake\n-    GetOwnedMonitorInfoClosure op(this, calling_thread, owned_monitors_list);\n-    JvmtiHandshake::execute(&op, &tlh, java_thread, thread_handle);\n-    err = op.result();\n+  if (LockingMode == LM_LEGACY && java_thread == nullptr) {\n+    *owned_monitor_count_ptr = 0;\n+    return JVMTI_ERROR_NONE;\n+  }\n+\n+  \/\/ growable array of jvmti monitors info on the C-heap\n+  GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list =\n+      new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n+\n+  Handle thread_handle(calling_thread, thread_oop);\n+  EscapeBarrier eb(java_thread != nullptr, calling_thread, java_thread);\n+  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+    delete owned_monitors_list;\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n@@ -1380,0 +1378,4 @@\n+  \/\/ get owned monitors info with handshake\n+  GetOwnedMonitorInfoClosure op(this, calling_thread, owned_monitors_list);\n+  JvmtiHandshake::execute(&op, &tlh, java_thread, thread_handle);\n+  err = op.result();\n@@ -1411,4 +1413,0 @@\n-  \/\/ growable array of jvmti monitors info on the C-heap\n-  GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list =\n-         new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n-\n@@ -1422,1 +1420,0 @@\n-    delete owned_monitors_list;\n@@ -1426,11 +1423,14 @@\n-  if (java_thread != nullptr) {\n-    Handle thread_handle(calling_thread, thread_oop);\n-    EscapeBarrier eb(true, calling_thread, java_thread);\n-    if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n-      delete owned_monitors_list;\n-      return JVMTI_ERROR_OUT_OF_MEMORY;\n-    }\n-    \/\/ get owned monitors info with handshake\n-    GetOwnedMonitorInfoClosure op(this, calling_thread, owned_monitors_list);\n-    JvmtiHandshake::execute(&op, &tlh, java_thread, thread_handle);\n-    err = op.result();\n+  if (LockingMode == LM_LEGACY && java_thread == nullptr) {\n+    *monitor_info_count_ptr = 0;\n+    return JVMTI_ERROR_NONE;\n+  }\n+\n+  \/\/ growable array of jvmti monitors info on the C-heap\n+  GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list =\n+      new (mtServiceability) GrowableArray<jvmtiMonitorStackDepthInfo*>(1, mtServiceability);\n+\n+  Handle thread_handle(calling_thread, thread_oop);\n+  EscapeBarrier eb(java_thread != nullptr, calling_thread, java_thread);\n+  if (!eb.deoptimize_objects(MaxJavaStackTraceDepth)) {\n+    delete owned_monitors_list;\n+    return JVMTI_ERROR_OUT_OF_MEMORY;\n@@ -1438,0 +1438,4 @@\n+  \/\/ get owned monitors info with handshake\n+  GetOwnedMonitorInfoClosure op(this, calling_thread, owned_monitors_list);\n+  JvmtiHandshake::execute(&op, &tlh, java_thread, thread_handle);\n+  err = op.result();\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":36,"deletions":32,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -1019,2 +1019,2 @@\n-JvmtiEnvBase::get_owned_monitors(JavaThread* calling_thread, JavaThread* java_thread, javaVFrame* jvf,\n-                                 GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list) {\n+JvmtiEnvBase::get_owned_monitors(JavaThread* calling_thread, JavaThread* carrier, javaVFrame* jvf,\n+                                 GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list, oop vthread) {\n@@ -1023,1 +1023,1 @@\n-  assert(java_thread->is_handshake_safe_for(current_thread),\n+  assert(carrier == nullptr || carrier->is_handshake_safe_for(current_thread),\n@@ -1030,1 +1030,1 @@\n-      err = get_locked_objects_in_frame(calling_thread, java_thread, jvf, owned_monitors_list, depth - 1);\n+      err = get_locked_objects_in_frame(calling_thread, carrier, jvf, owned_monitors_list, depth - 1, vthread);\n@@ -1039,1 +1039,1 @@\n-  ObjectSynchronizer::owned_monitors_iterate(&jmc, java_thread);\n+  ObjectSynchronizer::owned_monitors_iterate(&jmc, carrier != nullptr ? carrier->threadObj() : vthread);\n@@ -1047,2 +1047,3 @@\n-JvmtiEnvBase::get_locked_objects_in_frame(JavaThread* calling_thread, JavaThread* java_thread,\n-                                 javaVFrame *jvf, GrowableArray<jvmtiMonitorStackDepthInfo*>* owned_monitors_list, jint stack_depth) {\n+JvmtiEnvBase::get_locked_objects_in_frame(JavaThread* calling_thread, JavaThread* target,\n+                                 javaVFrame *jvf, GrowableArray<jvmtiMonitorStackDepthInfo*>* owned_monitors_list,\n+                                 jint stack_depth, oop vthread) {\n@@ -1065,3 +1066,3 @@\n-    ObjectMonitor *mon = java_thread->current_waiting_monitor();\n-    if (mon != nullptr) {\n-      wait_obj = mon->object();\n+    if (target != nullptr) {\n+      ObjectMonitor *mon = target->current_waiting_monitor();\n+      if (mon != nullptr) wait_obj = mon->object();\n@@ -1076,3 +1077,11 @@\n-    ObjectMonitor *mon = java_thread->current_pending_monitor();\n-    if (mon != nullptr) {\n-      pending_obj = mon->object();\n+    if (target != nullptr) {\n+      ObjectMonitor *mon = target->current_pending_monitor();\n+      if (mon != nullptr) pending_obj = mon->object();\n+    } else {\n+      assert(vthread != nullptr, \"no vthread oop\");\n+      oop oopCont = java_lang_VirtualThread::continuation(vthread);\n+      assert(oopCont != nullptr, \"vthread with no continuation\");\n+      stackChunkOop chunk = jdk_internal_vm_Continuation::tail(oopCont);\n+      assert(chunk != nullptr, \"unmounted vthread should have a chunk\");\n+      ObjectMonitor *mon = chunk->current_pending_monitor();\n+      if (mon != nullptr) pending_obj = mon->object();\n@@ -1527,2 +1536,1 @@\n-      oop thread_oop = get_vthread_or_thread_oop(w);\n-      if (thread_oop->is_a(vmClasses::BaseVirtualThread_klass())) {\n+      if (w == nullptr) {\n@@ -1530,0 +1538,5 @@\n+      } else {\n+        oop thread_oop = get_vthread_or_thread_oop(w);\n+        if (thread_oop->is_a(vmClasses::BaseVirtualThread_klass())) {\n+          skipped++;\n+        }\n@@ -1577,3 +1590,7 @@\n-        oop thread_oop = get_vthread_or_thread_oop(w);\n-        bool is_virtual = thread_oop->is_a(vmClasses::BaseVirtualThread_klass());\n-        assert(w != nullptr, \"sanity check\");\n+        bool is_virtual;\n+        if (w == nullptr) {\n+          is_virtual = true;\n+        } else {\n+          oop thread_oop = get_vthread_or_thread_oop(w);\n+          is_virtual = thread_oop->is_a(vmClasses::BaseVirtualThread_klass());\n+        }\n@@ -1585,1 +1602,1 @@\n-          Handle th(current_thread, get_vthread_or_thread_oop(w));\n+          Handle th(current_thread, w->threadObj());\n@@ -2504,1 +2521,0 @@\n-  assert(_target_jt != nullptr, \"sanity check\");\n@@ -2511,1 +2527,1 @@\n-  if (!_target_jt->is_exiting() && _target_jt->threadObj() != nullptr) {\n+  if (_target_jt == nullptr || (!_target_jt->is_exiting() && _target_jt->threadObj() != nullptr)) {\n@@ -2515,1 +2531,2 @@\n-                                                         _owned_monitors_list);\n+                                                         _owned_monitors_list,\n+                                                         target_h());\n@@ -2533,0 +2550,7 @@\n+    oop cont = java_lang_VirtualThread::continuation(target_h());\n+    assert(cont != nullptr, \"vthread with no continuation\");\n+    stackChunkOop chunk = jdk_internal_vm_Continuation::tail(cont);\n+    assert(chunk != nullptr, \"unmounted vthread should have a chunk\");\n+    if (chunk->current_pending_monitor() != nullptr) {\n+      *_owned_monitor_ptr = JNIHandles::make_local(_calling_thread, chunk->current_pending_monitor()->object());\n+    }\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":46,"deletions":22,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -361,1 +361,1 @@\n-                                   jint depth);\n+                                   jint depth, oop vthread = nullptr);\n@@ -425,2 +425,2 @@\n-  jvmtiError get_owned_monitors(JavaThread* calling_thread, JavaThread* java_thread, javaVFrame* jvf,\n-                                GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list);\n+  jvmtiError get_owned_monitors(JavaThread* calling_thread, JavaThread* carrier, javaVFrame* jvf,\n+                                GrowableArray<jvmtiMonitorStackDepthInfo*> *owned_monitors_list, oop vthread);\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1681,2 +1681,3 @@\n-  JvmtiThreadState *state = get_jvmti_thread_state(thread);\n-  if (state == nullptr) {\n+  \/\/ On preemption JVMTI state rebinding has already happened so get it always directly from the oop.\n+  JvmtiThreadState *state = java_lang_Thread::jvmti_thread_state(JNIHandles::resolve(vthread));\n+  if (state == NULL) {\n@@ -1701,1 +1702,1 @@\n-          (*callback)(env->jvmti_external(), jem.jni_env(), jem.jni_thread());\n+          (*callback)(env->jvmti_external(), jem.jni_env(), vthread);\n@@ -2865,0 +2866,15 @@\n+void JvmtiExport::vthread_post_monitor_waited(JavaThread *current, ObjectMonitor *obj_mntr, jboolean timed_out) {\n+  Handle vthread(current, current->vthread());\n+\n+  \/\/ Finish the VTMS transition temporarily to post the event.\n+  current->rebind_to_jvmti_thread_state_of(vthread());\n+  JvmtiVTMSTransitionDisabler::finish_VTMS_transition((jthread)vthread.raw_value(), \/* is_mount *\/ true);\n+\n+  \/\/ Post event.\n+  JvmtiExport::post_monitor_waited(current, obj_mntr, timed_out);\n+\n+  \/\/ Go back to VTMS transition state.\n+  JvmtiVTMSTransitionDisabler::start_VTMS_transition((jthread)vthread.raw_value(), \/* is_mount *\/ true);\n+  current->rebind_to_jvmti_thread_state_of(current->threadObj());\n+}\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":19,"deletions":3,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -400,0 +400,1 @@\n+  static void vthread_post_monitor_waited(JavaThread *current, ObjectMonitor *obj_mntr, jboolean timed_out) NOT_JVMTI_RETURN;\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2309,4 +2309,5 @@\n-    assert(_java_thread != nullptr, \"sanity\");\n-    _java_thread->active_handles()->oops_do(_blk);\n-    if (_blk->stopped()) {\n-      return false;\n+    if (_java_thread != nullptr) {\n+      _java_thread->active_handles()->oops_do(_blk);\n+      if (_blk->stopped()) {\n+        return false;\n+      }\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -498,0 +498,1 @@\n+  assert(!thread->is_in_tmp_VTMS_transition(), \"sanity check\");\n@@ -666,0 +667,6 @@\n+\n+  if (thread->pending_jvmti_unmount_event()) {\n+    assert(java_lang_VirtualThread::is_preempted(JNIHandles::resolve(vthread)), \"should be marked preempted\");\n+    JvmtiExport::post_vthread_unmount(vthread);\n+    thread->set_pending_jvmti_unmount_event(false);\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiThreadState.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -91,0 +91,1 @@\n+  oop*     obj_adr()                                  { return &_obj; }\n","filename":"src\/hotspot\/share\/runtime\/basicLock.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+#include \"oops\/oop.inline.hpp\"\n+#include \"prims\/jvmtiThreadState.inline.hpp\"\n@@ -36,0 +38,1 @@\n+#include \"runtime\/jniHandles.inline.hpp\"\n@@ -57,0 +60,114 @@\n+#if INCLUDE_JVMTI\n+class JvmtiUnmountBeginMark : public StackObj {\n+  Handle _vthread;\n+  JavaThread* _target;\n+  int _preempt_result;\n+  bool _failed;\n+\n+ public:\n+  JvmtiUnmountBeginMark(JavaThread* t) :\n+    _vthread(t, t->vthread()), _target(t), _preempt_result(freeze_pinned_native), _failed(false) {\n+    assert(!_target->is_in_any_VTMS_transition(), \"must be\");\n+\n+    if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+      JvmtiVTMSTransitionDisabler::start_VTMS_transition((jthread)_vthread.raw_value(), \/* is_mount *\/ false);\n+\n+      \/\/ Don't preempt if there is a pending popframe or earlyret operation. This can\n+      \/\/ be installed in start_VTMS_transition() so we need to check it here.\n+      if (JvmtiExport::can_pop_frame() || JvmtiExport::can_force_early_return()) {\n+        JvmtiThreadState* state = _target->jvmti_thread_state();\n+        if (_target->has_pending_popframe() || (state != nullptr && state->is_earlyret_pending())) {\n+          _failed = true;\n+        }\n+      }\n+\n+      \/\/ Don't preempt in case there is an async exception installed since\n+      \/\/ we would incorrectly throw it during the unmount logic in the carrier.\n+      if (_target->has_async_exception_condition()) {\n+        _failed = true;\n+      }\n+    } else {\n+      _target->set_is_in_VTMS_transition(true);\n+      java_lang_Thread::set_is_in_VTMS_transition(_vthread(), true);\n+    }\n+  }\n+  ~JvmtiUnmountBeginMark() {\n+    assert(!_target->is_suspended(), \"must be\");\n+\n+    assert(_target->is_in_VTMS_transition(), \"must be\");\n+    assert(java_lang_Thread::is_in_VTMS_transition(_vthread()), \"must be\");\n+\n+    \/\/ Read it again since for late binding agents the flag could have\n+    \/\/ been set while blocked in the allocation path during freeze.\n+    bool jvmti_present = JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events();\n+\n+    if (_preempt_result != freeze_ok) {\n+      \/\/ Undo transition\n+      if (jvmti_present) {\n+        JvmtiVTMSTransitionDisabler::finish_VTMS_transition((jthread)_vthread.raw_value(), false);\n+      } else {\n+        _target->set_is_in_VTMS_transition(false);\n+        java_lang_Thread::set_is_in_VTMS_transition(_vthread(), false);\n+      }\n+    } else {\n+      if (jvmti_present) {\n+        _target->rebind_to_jvmti_thread_state_of(_target->threadObj());\n+        if (JvmtiExport::should_post_vthread_mount()) {\n+          _target->set_pending_jvmti_unmount_event(true);\n+        }\n+      }\n+    }\n+  }\n+  void set_preempt_result(int res) { _preempt_result = res; }\n+  bool failed() { return _failed; }\n+};\n+\n+static bool is_safe_vthread_to_preempt_for_jvmti(JavaThread* target, oop vthread) {\n+  if (target->is_in_any_VTMS_transition()) {\n+    \/\/ We caught target at the end of a mount transition (is_in_VTMS_transition()) or at the\n+    \/\/ beginning or end of a temporary switch to carrier thread (is_in_tmp_VTMS_transition()).\n+    return false;\n+  }\n+  return true;\n+}\n+#endif \/\/ INCLUDE_JVMTI\n+\n+static bool is_safe_vthread_to_preempt(JavaThread* target, oop vthread) {\n+  if (!java_lang_VirtualThread::is_instance(vthread) ||                               \/\/ inside tmp transition\n+      java_lang_VirtualThread::state(vthread) != java_lang_VirtualThread::RUNNING) {  \/\/ inside transition\n+    return false;\n+  }\n+  return JVMTI_ONLY(is_safe_vthread_to_preempt_for_jvmti(target, vthread)) NOT_JVMTI(true);\n+}\n+\n+typedef int (*FreezeContFnT)(JavaThread*, intptr_t*);\n+\n+static void verify_preempt_preconditions(JavaThread* target, oop continuation) {\n+  assert(target == JavaThread::current(), \"no support for external preemption\");\n+  assert(target->has_last_Java_frame(), \"\");\n+  assert(!target->preempting(), \"\");\n+  assert(target->last_continuation() != nullptr, \"\");\n+  assert(target->last_continuation()->cont_oop(target) == continuation, \"\");\n+  assert(Continuation::continuation_scope(continuation) == java_lang_VirtualThread::vthread_scope(), \"\");\n+  assert(!target->has_pending_exception(), \"\");\n+}\n+\n+int Continuation::try_preempt(JavaThread* target, oop continuation) {\n+  verify_preempt_preconditions(target, continuation);\n+\n+  if (LockingMode == LM_LEGACY) {\n+    return freeze_unsupported;\n+  }\n+\n+  if (!is_safe_vthread_to_preempt(target, target->vthread())) {\n+    return freeze_pinned_native;\n+  }\n+\n+  JVMTI_ONLY(JvmtiUnmountBeginMark jubm(target);)\n+  JVMTI_ONLY(if (jubm.failed()) return freeze_pinned_native;)\n+  int res = CAST_TO_FN_PTR(FreezeContFnT, freeze_preempt_entry())(target, target->last_Java_sp());\n+  log_trace(continuations, preempt)(\"try_preempt: %d\", res);\n+  JVMTI_ONLY(jubm.set_preempt_result(res);)\n+  return res;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/continuation.cpp","additions":117,"deletions":0,"binary":false,"changes":117,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -50,0 +50,12 @@\n+\/\/ should match Continuation.toPreemptStatus() in Continuation.java\n+enum freeze_result {\n+  freeze_ok = 0,\n+  freeze_ok_bottom = 1,\n+  freeze_pinned_cs = 2,\n+  freeze_pinned_native = 3,\n+  freeze_pinned_monitor = 4,\n+  freeze_exception = 5,\n+  freeze_not_mounted = 6,\n+  freeze_unsupported = 7\n+};\n+\n@@ -53,0 +65,5 @@\n+  enum preempt_kind {\n+    freeze_on_monitorenter = 1,\n+    freeze_on_wait         = 2\n+  };\n+\n@@ -72,0 +89,1 @@\n+  static address freeze_preempt_entry();\n@@ -75,0 +93,2 @@\n+  static int try_preempt(JavaThread* target, oop continuation);\n+\n","filename":"src\/hotspot\/share\/runtime\/continuation.hpp","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+int ContinuationEntry::_thaw_call_pc_offset = 0;\n+int ContinuationEntry::_cleanup_offset = 0;\n@@ -40,0 +42,2 @@\n+address ContinuationEntry::_thaw_call_pc = nullptr;\n+address ContinuationEntry::_cleanup_pc = nullptr;\n@@ -46,0 +50,2 @@\n+  _thaw_call_pc = nm->code_begin() + _thaw_call_pc_offset;\n+  _cleanup_pc = nm->code_begin() + _cleanup_offset;\n@@ -49,0 +55,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/continuationEntry.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -60,0 +60,3 @@\n+  static int _thaw_call_pc_offset;\n+  static int _cleanup_offset;\n+\n@@ -65,0 +68,2 @@\n+  static address _thaw_call_pc;\n+  static address _cleanup_pc;\n@@ -104,0 +109,3 @@\n+  static address thaw_call_pc_address() { return (address)&_thaw_call_pc; }\n+  static address cleanup_pc() { return _cleanup_pc; }\n+\n","filename":"src\/hotspot\/share\/runtime\/continuationEntry.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -69,0 +70,1 @@\n+#include \"utilities\/vmError.hpp\"\n@@ -182,0 +184,1 @@\n+static void log_frames_after_thaw(JavaThread* thread, ContinuationWrapper& cont, intptr_t* sp, bool preempted);\n@@ -201,19 +204,0 @@\n-\/\/ should match Continuation.preemptStatus() in Continuation.java\n-enum freeze_result {\n-  freeze_ok = 0,\n-  freeze_ok_bottom = 1,\n-  freeze_pinned_cs = 2,\n-  freeze_pinned_native = 3,\n-  freeze_pinned_monitor = 4,\n-  freeze_exception = 5\n-};\n-\n-const char* freeze_result_names[6] = {\n-  \"freeze_ok\",\n-  \"freeze_ok_bottom\",\n-  \"freeze_pinned_cs\",\n-  \"freeze_pinned_native\",\n-  \"freeze_pinned_monitor\",\n-  \"freeze_exception\"\n-};\n-\n@@ -221,1 +205,1 @@\n-template<typename ConfigT> static inline int freeze_internal(JavaThread* current, intptr_t* const sp);\n+template<typename ConfigT, bool preempt> static inline int freeze_internal(JavaThread* current, intptr_t* const sp);\n@@ -248,0 +232,2 @@\n+  \/\/ Also the preemption case with JVMTI events enabled might safepoint so\n+  \/\/ undo the NoSafepointVerifier here and rely on handling by ContinuationWrapper.\n@@ -250,0 +236,1 @@\n+  DEBUG_ONLY(PauseNoSafepointVerifier pnsv(&__nsv);)\n@@ -272,1 +259,5 @@\n-    return freeze_internal<SelfT>(thread, sp);\n+    return freeze_internal<SelfT, false>(thread, sp);\n+  }\n+\n+  static int freeze_preempt(JavaThread* thread, intptr_t* const sp) {\n+    return freeze_internal<SelfT, true>(thread, sp);\n@@ -315,0 +306,1 @@\n+#endif \/\/ ASSERT\n@@ -320,3 +312,5 @@\n-static void set_anchor(JavaThread* thread, intptr_t* sp) {\n-  address pc = ContinuationHelper::return_address_at(\n-                 sp - frame::sender_sp_ret_address_offset());\n+static void set_anchor(JavaThread* thread, intptr_t* sp, address pc = nullptr) {\n+  if (pc == nullptr) {\n+    pc = ContinuationHelper::return_address_at(\n+           sp - frame::sender_sp_ret_address_offset());\n+  }\n@@ -333,1 +327,0 @@\n-#endif \/\/ ASSERT\n@@ -376,2 +369,0 @@\n-  const bool _preempt; \/\/ used only on the slow path\n-  const intptr_t * const _frame_sp; \/\/ Top frame sp for this freeze\n@@ -381,0 +372,7 @@\n+  \/\/ Used for preemption only\n+  const bool _preempt;\n+  frame _last_frame;\n+\n+  \/\/ Used to support freezing with held monitors\n+  int _monitors_in_lockstack;\n+\n@@ -400,1 +398,1 @@\n-  inline FreezeBase(JavaThread* thread, ContinuationWrapper& cont, intptr_t* sp);\n+  inline FreezeBase(JavaThread* thread, ContinuationWrapper& cont, intptr_t* sp, bool preempt);\n@@ -411,0 +409,2 @@\n+  inline frame& last_frame() { return _last_frame; }\n+\n@@ -432,1 +432,1 @@\n-  frame freeze_start_frame_safepoint_stub(frame f);\n+  frame freeze_start_frame_on_preempt();\n@@ -434,1 +434,1 @@\n-  inline frame freeze_start_frame_yield_stub(frame f);\n+  inline frame freeze_start_frame_yield_stub();\n@@ -444,0 +444,1 @@\n+  NOINLINE freeze_result recurse_freeze_native_frame(frame& f, frame& caller);\n@@ -446,0 +447,2 @@\n+  void freeze_lockstack(stackChunkOop chunk);\n+\n@@ -455,0 +458,1 @@\n+  static inline void prepare_freeze_interpreted_top_frame(frame& f);\n@@ -468,2 +472,2 @@\n-  inline Freeze(JavaThread* thread, ContinuationWrapper& cont, intptr_t* frame_sp)\n-    : FreezeBase(thread, cont, frame_sp) {}\n+  inline Freeze(JavaThread* thread, ContinuationWrapper& cont, intptr_t* frame_sp, bool preempt)\n+    : FreezeBase(thread, cont, frame_sp, preempt) {}\n@@ -477,2 +481,2 @@\n-FreezeBase::FreezeBase(JavaThread* thread, ContinuationWrapper& cont, intptr_t* frame_sp) :\n-    _thread(thread), _cont(cont), _barriers(false), _preempt(false), _frame_sp(frame_sp) {\n+FreezeBase::FreezeBase(JavaThread* thread, ContinuationWrapper& cont, intptr_t* frame_sp, bool preempt) :\n+    _thread(thread), _cont(cont), _barriers(false), _preempt(preempt), _last_frame(false \/* no initialization *\/) {\n@@ -509,1 +513,6 @@\n-  assert(SharedRuntime::cont_doYield_stub()->frame_size() == doYield_stub_frame_size, \"\");\n+  \/\/ With preemption doYield() might not have been resolved yet\n+  assert(_preempt || SharedRuntime::cont_doYield_stub()->frame_size() == doYield_stub_frame_size, \"\");\n+\n+  if (preempt) {\n+    _last_frame = _thread->last_frame();\n+  }\n@@ -512,1 +521,1 @@\n-  _cont_stack_top    = frame_sp + doYield_stub_frame_size; \/\/ we don't freeze the doYield stub frame\n+  _cont_stack_top    = frame_sp + (!preempt ? doYield_stub_frame_size : 0); \/\/ we don't freeze the doYield stub frame\n@@ -519,0 +528,6 @@\n+\n+  if (LockingMode != LM_LIGHTWEIGHT) {\n+    _monitors_in_lockstack = 0;\n+  } else {\n+    _monitors_in_lockstack = _thread->lock_stack().monitor_count();\n+  }\n@@ -527,0 +542,8 @@\n+void FreezeBase::freeze_lockstack(stackChunkOop chunk) {\n+  assert(chunk->sp_address() - chunk->start_address() >= _monitors_in_lockstack, \"no room for lockstack\");\n+\n+  _thread->lock_stack().move_to_address((oop*)chunk->start_address());\n+  chunk->set_lockstack_size(checked_cast<uint8_t>(_monitors_in_lockstack));\n+  chunk->set_has_lockstack(true);\n+}\n+\n@@ -557,1 +580,1 @@\n-  stackChunkOop chunk = allocate_chunk(cont_size() + frame::metadata_words, _cont.argsize() + frame::metadata_words_at_top);\n+  stackChunkOop chunk = allocate_chunk(cont_size() + frame::metadata_words + _monitors_in_lockstack, _cont.argsize() + frame::metadata_words_at_top);\n@@ -590,0 +613,2 @@\n+  total_size_needed += _monitors_in_lockstack;\n+\n@@ -671,1 +696,1 @@\n-  const int chunk_start_sp = cont_size() + frame::metadata_words;\n+  const int chunk_start_sp = cont_size() + frame::metadata_words + _monitors_in_lockstack;\n@@ -700,1 +725,1 @@\n-  assert(!(_fast_freeze_size > 0) || _orig_chunk_sp - (chunk->start_address() + chunk_new_sp) == _fast_freeze_size, \"\");\n+  assert(!(_fast_freeze_size > 0) || (_orig_chunk_sp - (chunk->start_address() + chunk_new_sp)) == (_fast_freeze_size - _monitors_in_lockstack), \"\");\n@@ -737,0 +762,1 @@\n+\n@@ -738,1 +764,10 @@\n-  chunk->set_pc(ContinuationHelper::return_address_at(\n+  if (_preempt) {\n+    \/\/ On aarch64\/riscv64, the return pc of the top frame won't necessarily be at sp[-1].\n+    \/\/ Also, on x64, if the top frame is the native wrapper frame, sp[-1] will not\n+    \/\/ be the pc we used when creating the oopmap. Get the top's frame last pc from\n+    \/\/ the anchor instead.\n+    address last_pc = _last_frame.pc();\n+    ContinuationHelper::patch_return_address_at(chunk_top - frame::sender_sp_ret_address_offset(), last_pc);\n+    chunk->set_pc(last_pc);\n+  } else {\n+    chunk->set_pc(ContinuationHelper::return_address_at(\n@@ -740,0 +775,5 @@\n+  }\n+\n+  if (_monitors_in_lockstack > 0) {\n+    freeze_lockstack(chunk);\n+  }\n@@ -805,1 +845,0 @@\n-  frame f = _thread->last_frame();\n@@ -807,1 +846,1 @@\n-    return freeze_start_frame_yield_stub(f);\n+    return freeze_start_frame_yield_stub();\n@@ -809,1 +848,1 @@\n-    return freeze_start_frame_safepoint_stub(f);\n+    return freeze_start_frame_on_preempt();\n@@ -813,1 +852,2 @@\n-frame FreezeBase::freeze_start_frame_yield_stub(frame f) {\n+frame FreezeBase::freeze_start_frame_yield_stub() {\n+  frame f = _thread->last_frame();\n@@ -820,16 +860,4 @@\n-frame FreezeBase::freeze_start_frame_safepoint_stub(frame f) {\n-#if (defined(X86) || defined(AARCH64) || defined(RISCV64)) && !defined(ZERO)\n-  f.set_fp(f.real_fp()); \/\/ f.set_fp(*Frame::callee_link_address(f)); \/\/ ????\n-#else\n-  Unimplemented();\n-#endif\n-  if (!Interpreter::contains(f.pc())) {\n-    assert(ContinuationHelper::Frame::is_stub(f.cb()), \"must be\");\n-    assert(f.oop_map() != nullptr, \"must be\");\n-\n-    if (Interpreter::contains(ContinuationHelper::StubFrame::return_pc(f))) {\n-      f = sender<ContinuationHelper::StubFrame>(f); \/\/ Safepoint stub in interpreter\n-    }\n-  }\n-  assert(Continuation::is_frame_in_continuation(_thread->last_continuation(), f), \"\");\n-  return f;\n+frame FreezeBase::freeze_start_frame_on_preempt() {\n+  assert(_last_frame.sp() == _thread->last_frame().sp(), \"_last_frame should be already initialized\");\n+  assert(Continuation::is_frame_in_continuation(_thread->last_continuation(), _last_frame), \"\");\n+  return _last_frame;\n@@ -841,1 +869,2 @@\n-  assert(f.is_interpreted_frame() || ((top && _preempt) == ContinuationHelper::Frame::is_stub(f.cb())), \"\");\n+  assert(f.is_interpreted_frame() || ((top && _preempt) == ContinuationHelper::Frame::is_stub(f.cb()))\n+         || ((top && _preempt) == f.is_native_frame()), \"\");\n@@ -854,6 +883,1 @@\n-    assert((_preempt && top) || !f.interpreter_frame_method()->is_native(), \"\");\n-    if (_preempt && top && f.interpreter_frame_method()->is_native()) {\n-      \/\/ int native entry\n-      return freeze_pinned_native;\n-    }\n-\n+    assert(!f.interpreter_frame_method()->is_native() || (top && _preempt), \"\");\n@@ -861,2 +885,3 @@\n-  } else if (_preempt && top && ContinuationHelper::Frame::is_stub(f.cb())) {\n-    return recurse_freeze_stub_frame(f, caller);\n+  } else if (top && _preempt) {\n+    assert(f.is_native_frame() || f.is_runtime_frame(), \"\");\n+    return f.is_native_frame() ? recurse_freeze_native_frame(f, caller) : recurse_freeze_stub_frame(f, caller);\n@@ -923,0 +948,1 @@\n+    || ContinuationHelper::Frame::is_stub(callee.cb())\n@@ -965,0 +991,2 @@\n+  _freeze_size += _monitors_in_lockstack;\n+\n@@ -1019,0 +1047,11 @@\n+  if (_preempt) {\n+    frame f = _thread->last_frame();\n+    if (f.is_interpreted_frame()) {\n+      \/\/ Some platforms do not save the last_sp in the top interpreter frame on VM calls.\n+      \/\/ We need it so that on resume we can restore the sp to the right place, since\n+      \/\/ thawing might add an alignment word to the expression stack (see finish_thaw()).\n+      \/\/ We do it now that we know freezing will be successful.\n+      prepare_freeze_interpreted_top_frame(f);\n+    }\n+  }\n+\n@@ -1024,1 +1063,1 @@\n-  chunk->set_max_thawing_size(chunk->max_thawing_size() + _freeze_size - frame::metadata_words);\n+  chunk->set_max_thawing_size(chunk->max_thawing_size() + _freeze_size - _monitors_in_lockstack - frame::metadata_words);\n@@ -1032,0 +1071,4 @@\n+  if (_monitors_in_lockstack > 0) {\n+    freeze_lockstack(chunk);\n+  }\n+\n@@ -1051,1 +1094,1 @@\n-  assert(Continuation::is_return_barrier_entry(entry.pc()) || Continuation::is_continuation_enterSpecial(entry), \"\");\n+  assert((!empty && Continuation::is_return_barrier_entry(entry.pc())) || (empty && Continuation::is_continuation_enterSpecial(entry)), \"\");\n@@ -1058,0 +1101,1 @@\n+\/\/ After freezing a frame we need to possibly adjust some values related to the caller frame.\n@@ -1116,2 +1160,2 @@\n-  log_develop_trace(continuations)(\"recurse_freeze_interpreted_frame %s _size: %d fsize: %d argsize: %d\",\n-    frame_method->name_and_sig_as_C_string(), _freeze_size, fsize, argsize);\n+  log_develop_trace(continuations)(\"recurse_freeze_interpreted_frame %s _size: %d fsize: %d argsize: %d callee_interpreted: %d\",\n+    frame_method->name_and_sig_as_C_string(), _freeze_size, fsize, argsize, callee_interpreted);\n@@ -1194,1 +1238,2 @@\n-    _total_align_size += frame::align_wiggle; \/\/ See Thaw::align\n+    \/\/ When thawing the frame we might need to add alignment (see Thaw::align)\n+    _total_align_size += frame::align_wiggle;\n@@ -1207,1 +1252,4 @@\n-  intptr_t* const stack_frame_top = ContinuationHelper::StubFrame::frame_top(f, 0, 0);\n+  DEBUG_ONLY(frame fsender = sender(f);)\n+  assert(fsender.is_compiled_frame(), \"sender should be compiled frame\");\n+\n+  intptr_t* const stack_frame_top = ContinuationHelper::StubFrame::frame_top(f);\n@@ -1213,3 +1261,4 @@\n-  \/\/ recurse_freeze_java_frame and freeze inlined here because we need to use a full RegisterMap for lock ownership\n-  NOT_PRODUCT(_frames++;)\n-  _freeze_size += fsize;\n+  freeze_result result = recurse_freeze_java_frame<ContinuationHelper::StubFrame>(f, caller, fsize, 0);\n+  if (UNLIKELY(result > freeze_ok_bottom)) {\n+    return result;\n+  }\n@@ -1217,13 +1266,25 @@\n-  RegisterMap map(_cont.thread(),\n-                  RegisterMap::UpdateMap::include,\n-                  RegisterMap::ProcessFrames::skip,\n-                  RegisterMap::WalkContinuation::skip);\n-  map.set_include_argument_oops(false);\n-  ContinuationHelper::update_register_map<ContinuationHelper::StubFrame>(f, &map);\n-  f.oop_map()->update_register_map(&f, &map); \/\/ we have callee-save registers in this case\n-  frame senderf = sender<ContinuationHelper::StubFrame>(f);\n-  assert(senderf.unextended_sp() < _bottom_address - 1, \"\");\n-  assert(senderf.is_compiled_frame(), \"\");\n-\n-  if (UNLIKELY(senderf.oop_map() == nullptr)) {\n-    \/\/ native frame\n+  assert(result == freeze_ok, \"should have caller\");\n+  DEBUG_ONLY(before_freeze_java_frame(f, caller, fsize, 0, false \/*is_bottom_frame*\/);)\n+\n+  frame hf = new_heap_frame<ContinuationHelper::StubFrame>(f, caller);\n+  intptr_t* heap_frame_top = ContinuationHelper::StubFrame::frame_top(hf);\n+\n+  copy_to_chunk(stack_frame_top, heap_frame_top, fsize);\n+\n+  patch(f, hf, caller, false \/*is_bottom_frame*\/);\n+\n+  DEBUG_ONLY(after_freeze_java_frame(hf, false \/*is_bottom_frame*\/);)\n+\n+  caller = hf;\n+  return freeze_ok;\n+}\n+\n+NOINLINE freeze_result FreezeBase::recurse_freeze_native_frame(frame& f, frame& caller) {\n+  if (!f.cb()->as_nmethod()->method()->is_object_wait0()) {\n+    assert(f.cb()->as_nmethod()->method()->is_synchronized(), \"\");\n+    \/\/ Synchronized native method case. Unlike the interpreter native wrapper, the compiled\n+    \/\/ native wrapper tries to acquire the monitor after marshalling the arguments from the\n+    \/\/ caller into the native convention. This is so that we have a valid oopMap in case of\n+    \/\/ having to block in the slow path. But that would require freezing those registers too\n+    \/\/ and then fixing them back on thaw in case of oops. To avoid complicating things and\n+    \/\/ given that this would be a rare case anyways just pin the vthread to the carrier.\n@@ -1233,1 +1294,9 @@\n-  freeze_result result = recurse_freeze_compiled_frame(senderf, caller, 0, 0); \/\/ This might be deoptimized\n+  intptr_t* const stack_frame_top = ContinuationHelper::NativeFrame::frame_top(f);\n+  \/\/ There are no stackargs but argsize must include the metadata\n+  const int argsize = frame::metadata_words_at_top;\n+  const int fsize = f.cb()->frame_size() + argsize;\n+\n+  log_develop_trace(continuations)(\"recurse_freeze_native_frame %s _size: %d fsize: %d :: \" INTPTR_FORMAT \" - \" INTPTR_FORMAT,\n+    f.cb()->name(), _freeze_size, fsize, p2i(stack_frame_top), p2i(stack_frame_top+fsize));\n+\n+  freeze_result result = recurse_freeze_java_frame<ContinuationHelper::NativeFrame>(f, caller, fsize, argsize);\n@@ -1237,2 +1306,0 @@\n-  assert(result != freeze_ok_bottom, \"\");\n-  assert(!caller.is_interpreted_frame(), \"\");\n@@ -1240,3 +1307,6 @@\n-  DEBUG_ONLY(before_freeze_java_frame(f, caller, fsize, 0, false);)\n-  frame hf = new_heap_frame<ContinuationHelper::StubFrame>(f, caller);\n-  intptr_t* heap_frame_top = ContinuationHelper::StubFrame::frame_top(hf, 0, 0);\n+  assert(result == freeze_ok, \"should have caller frame\");\n+  DEBUG_ONLY(before_freeze_java_frame(f, caller, fsize, argsize, false \/* is_bottom_frame *\/);)\n+\n+  frame hf = new_heap_frame<ContinuationHelper::NativeFrame>(f, caller);\n+  intptr_t* heap_frame_top = ContinuationHelper::NativeFrame::frame_top(hf);\n+\n@@ -1244,1 +1314,9 @@\n-  DEBUG_ONLY(after_freeze_java_frame(hf, false);)\n+\n+  if (caller.is_interpreted_frame()) {\n+    \/\/ When thawing the frame we might need to add alignment (see Thaw::align)\n+    _total_align_size += frame::align_wiggle;\n+  }\n+\n+  patch(f, hf, caller, false \/* is_bottom_frame *\/);\n+\n+  DEBUG_ONLY(after_freeze_java_frame(hf, false \/* is_bottom_frame *\/);)\n@@ -1267,0 +1345,2 @@\n+  assert(chunk->sp_address() - chunk->start_address() >= _monitors_in_lockstack, \"clash with lockstack\");\n+\n@@ -1296,0 +1376,1 @@\n+    DEBUG_ONLY(print_frame_layout(top, false, &ls);)\n@@ -1330,0 +1411,1 @@\n+    oopDesc::set_klass_gap(mem, 0);\n@@ -1438,0 +1520,2 @@\n+  assert(chunk->lockstack_size() == 0, \"\");\n+  assert(chunk->object_waiter() == nullptr, \"\");\n@@ -1510,0 +1594,33 @@\n+\n+static void jvmti_mount_end(JavaThread* current, ContinuationWrapper& cont, frame top) {\n+  assert(current->vthread() != nullptr, \"must be\");\n+\n+  HandleMarkCleaner hm(current);\n+  Handle vth(current, current->vthread());\n+\n+  ContinuationWrapper::SafepointOp so(current, cont);\n+\n+  \/\/ Since we might safepoint set the anchor so that the stack can we walked.\n+  set_anchor(current, top.sp());\n+\n+  JRT_BLOCK\n+    current->rebind_to_jvmti_thread_state_of(vth());\n+    JvmtiVTMSTransitionDisabler::finish_VTMS_transition((jthread)vth.raw_value(), \/* is_mount *\/ true);\n+\n+    \/\/ If pending_jvmti_unmount_event() is true here we are in the preemption\n+    \/\/ cancelled case. Since we never unmounted we don't post the mount event\n+    \/\/ and just clear the pending unmount flag.\n+    if (current->pending_jvmti_unmount_event()) {\n+      current->set_pending_jvmti_unmount_event(false);\n+    } else if (JvmtiExport::should_post_vthread_mount()) {\n+      JvmtiExport::post_vthread_mount((jthread)vth.raw_value());\n+    }\n+\n+    if (current->pending_contended_entered_event()) {\n+      JvmtiExport::post_monitor_contended_entered(current, current->contended_entered_monitor());\n+      current->set_contended_entered_monitor(nullptr);\n+    }\n+  JRT_BLOCK_END\n+\n+  clear_anchor(current);\n+}\n@@ -1522,1 +1639,2 @@\n-        (f.is_compiled_frame() && ContinuationHelper::CompiledFrame::is_owning_locks(map.thread(), &map, f))) {\n+        (f.is_compiled_frame() && ContinuationHelper::CompiledFrame::is_owning_locks(map.thread(), &map, f)) ||\n+        (f.is_native_frame() && ContinuationHelper::NativeFrame::is_owning_locks(map.thread(), f))) {\n@@ -1539,2 +1657,3 @@\n-  for (frame f = freeze_start_frame(); Continuation::is_frame_in_continuation(ce, f); f = f.sender(&map)) {\n-    if (!f.is_compiled_frame() || f.is_deoptimized_frame()) {\n+  int i = 0;\n+  for (frame f = freeze_start_frame(); Continuation::is_frame_in_continuation(ce, f); f = f.sender(&map), i++) {\n+    if (!((f.is_compiled_frame() && !f.is_deoptimized_frame()) || (i == 0 && (f.is_runtime_frame() || f.is_native_frame())))) {\n@@ -1548,1 +1667,1 @@\n-static inline int freeze_epilog(JavaThread* thread, ContinuationWrapper& cont) {\n+static inline int freeze_epilog(ContinuationWrapper& cont) {\n@@ -1551,2 +1670,0 @@\n-  \/\/ This is done for the sake of the enterSpecial frame\n-  StackWatermarkSet::after_unwind(thread);\n@@ -1555,1 +1672,0 @@\n-\n@@ -1567,1 +1683,1 @@\n-  return freeze_epilog(thread, cont);\n+  return freeze_epilog(cont);\n@@ -1570,1 +1686,14 @@\n-template<typename ConfigT>\n+static int preempt_epilog(ContinuationWrapper& cont, freeze_result res, frame& old_last_frame) {\n+  if (UNLIKELY(res != freeze_ok)) {\n+    verify_continuation(cont.continuation());\n+    log_develop_trace(continuations)(\"=== end of freeze (fail %d)\", res);\n+    return res;\n+  }\n+\n+  patch_return_pc_with_preempt_stub(old_last_frame);\n+  cont.tail()->set_preempted(true);\n+\n+  return freeze_epilog(cont);\n+}\n+\n+template<typename ConfigT, bool preempt>\n@@ -1575,1 +1704,1 @@\n-  log_trace(continuations)(\"~~~~ freeze sp: \" INTPTR_FORMAT, p2i(current->last_continuation()->entry_sp()));\n+  log_trace(continuations)(\"~~~~ freeze sp: \" INTPTR_FORMAT \"JavaThread: \" INTPTR_FORMAT, p2i(current->last_continuation()->entry_sp()), p2i(current));\n@@ -1593,1 +1722,1 @@\n-  assert(monitors_on_stack(current) == ((current->held_monitor_count() - current->jni_monitor_count()) > 0),\n+  assert(LockingMode != LM_LEGACY || (monitors_on_stack(current) == ((current->held_monitor_count() - current->jni_monitor_count()) > 0)),\n@@ -1595,0 +1724,2 @@\n+  assert(LockingMode == LM_LEGACY || (current->held_monitor_count() == 0 && current->jni_monitor_count() == 0),\n+         \"Held monitor count should only be used for LM_LEGACY: \" INT64_FORMAT \" JNI: \" INT64_FORMAT, (int64_t)current->held_monitor_count(), (int64_t)current->jni_monitor_count());\n@@ -1602,1 +1733,1 @@\n-    if (SafepointMechanism::should_process(current)) {\n+    if (SafepointMechanism::should_process(current) && !preempt) {\n@@ -1609,1 +1740,1 @@\n-  Freeze<ConfigT> freeze(current, cont, sp);\n+  Freeze<ConfigT> freeze(current, cont, sp, preempt);\n@@ -1616,2 +1747,12 @@\n-    freeze_epilog(current, cont);\n-    return 0;\n+    return !preempt ? freeze_epilog(cont) : preempt_epilog(cont, freeze_ok, freeze.last_frame());\n+  }\n+\n+  if (preempt) {\n+    JvmtiSampledObjectAllocEventCollector jsoaec(false);\n+    freeze.set_jvmti_event_collector(&jsoaec);\n+\n+    freeze_result res = fast ? freeze.try_freeze_fast() : freeze.freeze_slow();\n+\n+    CONT_JFR_ONLY(freeze.jfr_info().post_jfr_event(&event, oopCont, current);)\n+    preempt_epilog(cont, res, freeze.last_frame());\n+    return res;\n@@ -1621,1 +1762,1 @@\n-  assert(current == JavaThread::current(), \"must be current thread except for preempt\");\n+  assert(current == JavaThread::current(), \"must be current thread\");\n@@ -1701,0 +1842,1 @@\n+  size += frame::metadata_words; \/\/ for preemption case (see possibly_adjust_frame)\n@@ -1756,0 +1898,1 @@\n+  bool _preempted_case;\n@@ -1774,0 +1917,1 @@\n+  template<bool check_stub>\n@@ -1777,0 +1921,2 @@\n+  void thaw_lockstack(stackChunkOop chunk);\n+\n@@ -1781,2 +1927,7 @@\n-  \/\/ slow path\n-  NOINLINE intptr_t* thaw_slow(stackChunkOop chunk, bool return_barrier);\n+  intptr_t* handle_preempted_continuation(intptr_t* sp, Continuation::preempt_kind preempt_kind, bool fast_case);\n+  inline intptr_t* possibly_adjust_frame(frame& top);\n+  inline intptr_t* push_cleanup_continuation();\n+  void throw_interrupted_exception(JavaThread* current, frame& top);\n+\n+  void recurse_thaw(const frame& heap_frame, frame& caller, int num_frames, bool top_on_preempt_case);\n+  void finish_thaw(frame& f);\n@@ -1785,1 +1936,0 @@\n-  void recurse_thaw(const frame& heap_frame, frame& caller, int num_frames, bool top);\n@@ -1799,1 +1949,1 @@\n-  void finish_thaw(frame& f);\n+  void recurse_thaw_native_frame(const frame& hf, frame& caller, int num_frames);\n@@ -1805,0 +1955,1 @@\n+  inline void patch_pd(frame& f, intptr_t* caller_sp);\n@@ -1828,0 +1979,1 @@\n+  template<bool check_stub = false>\n@@ -1829,0 +1981,1 @@\n+  NOINLINE intptr_t* thaw_slow(stackChunkOop chunk, Continuation::thaw_kind kind);\n@@ -1844,1 +1997,1 @@\n-                                        : thaw_slow(chunk, kind != Continuation::thaw_top);\n+                                        : thaw_slow(chunk, kind);\n@@ -1877,0 +2030,1 @@\n+template<bool check_stub>\n@@ -1884,1 +2038,1 @@\n-  const int frame_size = f.cb()->frame_size();\n+  int frame_size = f.cb()->frame_size();\n@@ -1887,1 +2041,22 @@\n-  f.next(SmallRegisterMap::instance(), true \/* stop *\/);\n+  assert(!f.is_stub() || check_stub, \"\");\n+  if (check_stub && f.is_stub()) {\n+    \/\/ If we don't thaw the top compiled frame too, after restoring the saved\n+    \/\/ registers back in Java, we would hit the return barrier to thaw one more\n+    \/\/ frame effectively overwritting the restored registers during that call.\n+    f.next(SmallRegisterMap::instance(), true \/* stop *\/);\n+    assert(!f.is_done(), \"\");\n+\n+    f.get_cb();\n+    assert(f.is_compiled(), \"\");\n+    frame_size += f.cb()->frame_size();\n+    argsize = f.stack_argsize();\n+\n+    if (f.cb()->as_nmethod()->is_marked_for_deoptimization()) {\n+      \/\/ The caller of the runtime stub when the continuation is preempted is not at a\n+      \/\/ Java call instruction, and so cannot rely on nmethod patching for deopt.\n+      log_develop_trace(continuations)(\"Deoptimizing runtime stub caller\");\n+      f.to_frame().deoptimize(nullptr); \/\/ the null thread simply avoids the assertion in deoptimize which we're not set up for\n+    }\n+  }\n+\n+  f.next(SmallRegisterMap::instance, true \/* stop *\/);\n@@ -1914,0 +2089,12 @@\n+void ThawBase::thaw_lockstack(stackChunkOop chunk) {\n+  int lockStackSize = chunk->lockstack_size();\n+  assert(lockStackSize > 0 && lockStackSize <= LockStack::CAPACITY, \"\");\n+\n+  oop tmp_lockstack[LockStack::CAPACITY];\n+  chunk->transfer_lockstack(tmp_lockstack);\n+  _thread->lock_stack().move_from_address(tmp_lockstack, lockStackSize);\n+\n+  chunk->set_lockstack_size(0);\n+  chunk->set_has_lockstack(false);\n+}\n+\n@@ -1932,0 +2119,1 @@\n+template<bool check_stub>\n@@ -1965,1 +2153,1 @@\n-    thaw_size = remove_top_compiled_frame_from_chunk(chunk, argsize);\n+    thaw_size = remove_top_compiled_frame_from_chunk<check_stub>(chunk, argsize);\n@@ -2021,1 +2209,60 @@\n-NOINLINE intptr_t* ThawBase::thaw_slow(stackChunkOop chunk, bool return_barrier) {\n+static inline void relativize_chunk_concurrently(stackChunkOop chunk) {\n+#if INCLUDE_ZGC || INCLUDE_SHENANDOAHGC\n+  if (UseZGC || UseShenandoahGC) {\n+    chunk->relativize_derived_pointers_concurrently();\n+  }\n+#endif\n+}\n+\n+template <typename ConfigT>\n+NOINLINE intptr_t* Thaw<ConfigT>::thaw_slow(stackChunkOop chunk, Continuation::thaw_kind kind) {\n+  Continuation::preempt_kind preempt_kind;\n+  bool retry_fast_path = false;\n+\n+  _preempted_case = chunk->preempted();\n+  if (_preempted_case) {\n+    if (chunk->object_waiter() != nullptr) {\n+      \/\/ Mounted again after preemption. Resume the pending monitor operation,\n+      \/\/ which will be either a monitorenter or Object.wait() call.\n+      assert(chunk->current_pending_monitor() != nullptr || chunk->current_waiting_monitor() != nullptr, \"\");\n+      ObjectWaiter* waiter = chunk->object_waiter();\n+      ObjectMonitor* mon = waiter->monitor();\n+      preempt_kind = waiter->is_wait() ? Continuation::freeze_on_wait : Continuation::freeze_on_monitorenter;\n+\n+      bool mon_acquired = mon->resume_operation(_thread, waiter, _cont);\n+      assert(!mon_acquired || mon->has_owner(_thread), \"invariant\");\n+      if (!mon_acquired) {\n+        \/\/ Failed to aquire monitor. Return to enterSpecial to unmount again.\n+        return push_cleanup_continuation();\n+      }\n+      chunk = _cont.tail();  \/\/ reload oop in case of safepoint in resume_operation (if posting JVMTI events).\n+    } else {\n+      \/\/ Preemption cancelled in moniterenter case. We actually acquired\n+      \/\/ the monitor after freezing all frames so nothing to do.\n+      preempt_kind = Continuation::freeze_on_monitorenter;\n+    }\n+    \/\/ Call this first to avoid racing with GC threads later when modifying the chunk flags.\n+    relativize_chunk_concurrently(chunk);\n+    chunk->set_preempted(false);\n+    retry_fast_path = true;\n+  } else {\n+    relativize_chunk_concurrently(chunk);\n+  }\n+\n+  \/\/ On first thaw after freeze restore oops to the lockstack if any.\n+  assert(chunk->lockstack_size() == 0 || kind == Continuation::thaw_top, \"\");\n+  if (kind == Continuation::thaw_top && chunk->lockstack_size() > 0) {\n+    thaw_lockstack(chunk);\n+    retry_fast_path = true;\n+  }\n+\n+  \/\/ Retry the fast path now that we possibly cleared the FLAG_HAS_LOCKSTACK\n+  \/\/ and FLAG_PREEMPTED flags from the stackChunk.\n+  if (retry_fast_path && can_thaw_fast(chunk)) {\n+    intptr_t* sp = thaw_fast<true>(chunk);\n+    if (_preempted_case) {\n+      return handle_preempted_continuation(sp, preempt_kind, true \/* fast_case *\/);\n+    }\n+    return sp;\n+  }\n+\n@@ -2025,1 +2272,1 @@\n-    ls.print_cr(\"thaw slow return_barrier: %d \" INTPTR_FORMAT, return_barrier, p2i(chunk));\n+    ls.print_cr(\"thaw slow return_barrier: %d \" INTPTR_FORMAT, kind, p2i(chunk));\n@@ -2039,1 +2286,1 @@\n-  int num_frames = (return_barrier ? 1 : 2);\n+  int num_frames = kind == Continuation::thaw_top ? 2 : 1;\n@@ -2052,6 +2299,0 @@\n-#if INCLUDE_ZGC || INCLUDE_SHENANDOAHGC\n-  if (UseZGC || UseShenandoahGC) {\n-    _cont.tail()->relativize_derived_pointers_concurrently();\n-  }\n-#endif\n-\n@@ -2059,1 +2300,1 @@\n-  recurse_thaw(heap_frame, caller, num_frames, true);\n+  recurse_thaw(heap_frame, caller, num_frames, _preempted_case);\n@@ -2070,0 +2311,4 @@\n+\n+  if (_preempted_case) {\n+    return handle_preempted_continuation(sp, preempt_kind, false \/* fast_case *\/);\n+  }\n@@ -2073,1 +2318,1 @@\n-void ThawBase::recurse_thaw(const frame& heap_frame, frame& caller, int num_frames, bool top) {\n+void ThawBase::recurse_thaw(const frame& heap_frame, frame& caller, int num_frames, bool top_on_preempt_case) {\n@@ -2079,3 +2324,2 @@\n-  if (top && heap_frame.is_safepoint_blob_frame()) {\n-    assert(ContinuationHelper::Frame::is_stub(heap_frame.cb()), \"cb: %s\", heap_frame.cb()->name());\n-    recurse_thaw_stub_frame(heap_frame, caller, num_frames);\n+  if (top_on_preempt_case && (heap_frame.is_native_frame() || heap_frame.is_runtime_frame())) {\n+    heap_frame.is_native_frame() ? recurse_thaw_native_frame(heap_frame, caller, 2) : recurse_thaw_stub_frame(heap_frame, caller, 2);\n@@ -2111,1 +2355,1 @@\n-    recurse_thaw(_stream.to_frame(), caller, num_frames - 1, false);\n+    recurse_thaw(_stream.to_frame(), caller, num_frames - 1, false \/* top_on_preempt_case *\/);\n@@ -2201,0 +2445,55 @@\n+intptr_t* ThawBase::handle_preempted_continuation(intptr_t* sp, Continuation::preempt_kind preempt_kind, bool fast_case) {\n+  assert(preempt_kind == Continuation::freeze_on_wait || preempt_kind == Continuation::freeze_on_monitorenter, \"\");\n+  frame top(sp);\n+  assert(top.pc() == *(address*)(sp - frame::sender_sp_ret_address_offset()), \"\");\n+\n+#if INCLUDE_JVMTI\n+  \/\/ Finish the VTMS transition.\n+  assert(_thread->is_in_VTMS_transition(), \"must be\");\n+  bool is_vthread = Continuation::continuation_scope(_cont.continuation()) == java_lang_VirtualThread::vthread_scope();\n+  if (is_vthread) {\n+    if (JvmtiVTMSTransitionDisabler::VTMS_notify_jvmti_events()) {\n+      jvmti_mount_end(_thread, _cont, top);\n+    } else {\n+      _thread->set_is_in_VTMS_transition(false);\n+      java_lang_Thread::set_is_in_VTMS_transition(_thread->vthread(), false);\n+    }\n+  }\n+#endif\n+\n+  if (fast_case) {\n+    \/\/ If we thawed in the slow path the runtime stub\/native wrapper frame already\n+    \/\/ has the correct fp (see ThawBase::new_stack_frame). On the fast path though,\n+    \/\/ we copied the original fp at the time of freeze which now will have to be fixed.\n+    assert(top.is_runtime_frame() || top.is_native_frame(), \"\");\n+    int fsize = top.cb()->frame_size();\n+    patch_pd(top, sp + fsize);\n+  }\n+\n+  if (preempt_kind == Continuation::freeze_on_wait) {\n+    \/\/ Check now if we need to throw IE exception.\n+    if (_thread->pending_interrupted_exception()) {\n+      throw_interrupted_exception(_thread, top);\n+      _thread->set_pending_interrupted_exception(false);\n+    }\n+  } else if (top.is_runtime_frame()) {\n+    \/\/ The continuation might now run on a different platform thread than the previous time so\n+    \/\/ we need to adjust the current thread saved in the stub frame before restoring registers.\n+    JavaThread** thread_addr = frame::saved_thread_address(top);\n+    if (thread_addr != nullptr) *thread_addr = _thread;\n+    \/\/ Some platforms require the size of the runtime frame to be adjusted.\n+    sp = possibly_adjust_frame(top);\n+  }\n+  return sp;\n+}\n+\n+void ThawBase::throw_interrupted_exception(JavaThread* current, frame& top) {\n+  ContinuationWrapper::SafepointOp so(current, _cont);\n+  \/\/ Since we might safepoint set the anchor so that the stack can we walked.\n+  set_anchor(current, top.sp());\n+  JRT_BLOCK\n+    THROW(vmSymbols::java_lang_InterruptedException());\n+  JRT_BLOCK_END\n+  clear_anchor(current);\n+}\n+\n@@ -2244,1 +2543,3 @@\n-  const int locals = hf.interpreter_frame_method()->max_locals();\n+  Method* m = hf.interpreter_frame_method();\n+  \/\/ For native frames we need to count parameters, possible alignment, plus the 2 extra words (temp oop\/result handler).\n+  const int locals = !m->is_native() ? m->max_locals() : m->size_of_parameters() + frame::align_wiggle + 2;\n@@ -2261,2 +2562,2 @@\n-  assert(!hf.is_interpreted_frame(), \"\");\n-  assert(_cont.is_preempted() || !stub_caller, \"stub caller not at preemption\");\n+  assert(hf.is_compiled_frame(), \"\");\n+  assert(_preempted_case || !stub_caller, \"stub caller not at preemption\");\n@@ -2275,1 +2576,1 @@\n-    _align_size += frame::align_wiggle; \/\/ we add one whether or not we've aligned because we add it in freeze_interpreted_frame\n+    _align_size += frame::align_wiggle; \/\/ we add one whether or not we've aligned because we add it in recurse_freeze_compiled_frame\n@@ -2308,1 +2609,1 @@\n-              || (_cont.is_preempted() && f.cb()->as_nmethod()->is_marked_for_deoptimization())) {\n+              || (stub_caller && f.cb()->as_nmethod()->is_marked_for_deoptimization())) {\n@@ -2311,1 +2612,0 @@\n-    assert(_thread->is_interp_only_mode() || stub_caller, \"expected a stub-caller\");\n@@ -2339,1 +2639,2 @@\n-  {\n+  if (UNLIKELY(seen_by_gc())) {\n+    \/\/ Process the stub's caller here since we might need the full map.\n@@ -2347,3 +2648,3 @@\n-    if (UNLIKELY(seen_by_gc())) { \/\/ we're now doing this on the stub's caller\n-      _cont.tail()->do_barriers<stackChunkOopDesc::BarrierType::Store>(_stream, &map);\n-    }\n+    _cont.tail()->do_barriers<stackChunkOopDesc::BarrierType::Store>(_stream, &map);\n+  } else {\n+    _stream.next(SmallRegisterMap::instance);\n@@ -2353,3 +2654,1 @@\n-  recurse_thaw_compiled_frame(_stream.to_frame(), caller, num_frames, true); \/\/ this could be deoptimized\n-\n-  DEBUG_ONLY(before_thaw_java_frame(hf, caller, false, num_frames);)\n+  recurse_thaw_compiled_frame(_stream.to_frame(), caller, num_frames, true);\n@@ -2357,1 +2656,1 @@\n-  assert(ContinuationHelper::Frame::is_stub(hf.cb()), \"\");\n+  assert(caller.is_compiled_frame(), \"\");\n@@ -2359,1 +2658,0 @@\n-  assert(!caller.is_interpreted_frame(), \"\");\n@@ -2361,1 +2659,1 @@\n-  int fsize = ContinuationHelper::StubFrame::size(hf);\n+  DEBUG_ONLY(before_thaw_java_frame(hf, caller, false \/*is_bottom_frame*\/, num_frames);)\n@@ -2366,0 +2664,1 @@\n+  int fsize = ContinuationHelper::StubFrame::size(hf);\n@@ -2370,9 +2669,22 @@\n-  { \/\/ can only fix caller once this frame is thawed (due to callee saved regs)\n-    RegisterMap map(nullptr,\n-                    RegisterMap::UpdateMap::include,\n-                    RegisterMap::ProcessFrames::skip,\n-                    RegisterMap::WalkContinuation::skip); \/\/ map.clear();\n-    map.set_include_argument_oops(false);\n-    f.oop_map()->update_register_map(&f, &map);\n-    ContinuationHelper::update_register_map_with_callee(caller, &map);\n-    _cont.tail()->fix_thawed_frame(caller, &map);\n+  patch(f, caller, false \/*is_bottom_frame*\/);\n+\n+  \/\/ can only fix caller once this frame is thawed (due to callee saved regs)\n+  RegisterMap map(nullptr,\n+                  RegisterMap::UpdateMap::include,\n+                  RegisterMap::ProcessFrames::skip,\n+                  RegisterMap::WalkContinuation::skip);\n+  map.set_include_argument_oops(false);\n+  f.oop_map()->update_register_map(&f, &map);\n+  ContinuationHelper::update_register_map_with_callee(caller, &map);\n+  _cont.tail()->fix_thawed_frame(caller, &map);\n+\n+  DEBUG_ONLY(after_thaw_java_frame(f, false \/*is_bottom_frame*\/);)\n+  caller = f;\n+}\n+\n+void ThawBase::recurse_thaw_native_frame(const frame& hf, frame& caller, int num_frames) {\n+  assert(hf.is_native_frame(), \"\");\n+  assert(_preempted_case && hf.cb()->as_nmethod()->method()->is_object_wait0(), \"\");\n+\n+  if (UNLIKELY(seen_by_gc())) { \/\/ recurse_thaw_stub_frame already invoked our barriers with a full regmap\n+    _cont.tail()->do_barriers<stackChunkOopDesc::BarrierType::Store>(_stream, SmallRegisterMap::instance());\n@@ -2381,1 +2693,38 @@\n-  DEBUG_ONLY(after_thaw_java_frame(f, false);)\n+  const bool is_bottom_frame = recurse_thaw_java_frame<ContinuationHelper::NativeFrame>(caller, num_frames);\n+  assert(!is_bottom_frame, \"\");\n+\n+  DEBUG_ONLY(before_thaw_java_frame(hf, caller, is_bottom_frame, num_frames);)\n+\n+  assert(caller.sp() == caller.unextended_sp(), \"\");\n+\n+  if (caller.is_interpreted_frame()) {\n+    _align_size += frame::align_wiggle; \/\/ we add one whether or not we've aligned because we add it in recurse_freeze_native_frame\n+  }\n+\n+  \/\/ new_stack_frame must construct the resulting frame using hf.pc() rather than hf.raw_pc() because the frame is not\n+  \/\/ yet laid out in the stack, and so the original_pc is not stored in it.\n+  \/\/ As a result, f.is_deoptimized_frame() is always false and we must test hf to know if the frame is deoptimized.\n+  frame f = new_stack_frame<ContinuationHelper::NativeFrame>(hf, caller, false \/* bottom *\/);\n+  intptr_t* const stack_frame_top = f.sp();\n+  intptr_t* const heap_frame_top = hf.unextended_sp();\n+\n+  int fsize = ContinuationHelper::NativeFrame::size(hf);\n+  assert(fsize <= (int)(caller.unextended_sp() - f.unextended_sp()), \"\");\n+\n+  intptr_t* from = heap_frame_top - frame::metadata_words_at_bottom;\n+  intptr_t* to   = stack_frame_top - frame::metadata_words_at_bottom;\n+  int sz = fsize + frame::metadata_words_at_bottom;\n+\n+  copy_from_chunk(from, to, sz); \/\/ copying good oops because we invoked barriers above\n+\n+  patch(f, caller, false \/* bottom *\/);\n+\n+  \/\/ f.is_deoptimized_frame() is always false and we must test hf.is_deoptimized_frame() (see comment above)\n+  assert(!f.is_deoptimized_frame(), \"\");\n+  assert(!hf.is_deoptimized_frame(), \"\");\n+  assert(!f.cb()->as_nmethod()->is_marked_for_deoptimization(), \"\");\n+\n+  \/\/ can only fix caller once this frame is thawed (due to callee saved regs); this happens on the stack\n+  _cont.tail()->fix_thawed_frame(caller, SmallRegisterMap::instance());\n+\n+  DEBUG_ONLY(after_thaw_java_frame(f, false \/* bottom *\/);)\n@@ -2468,0 +2817,1 @@\n+  DEBUG_ONLY(bool preempted = cont.tail()->preempted();)\n@@ -2471,21 +2821,1 @@\n-\n-  \/\/ All or part of the frames have been thawed so we know they don't hold any monitors except JNI monitors.\n-  assert(thread->held_monitor_count() == thread->jni_monitor_count(), \"Must be\");\n-\n-#ifdef ASSERT\n-  intptr_t* sp0 = sp;\n-  set_anchor(thread, sp0);\n-  log_frames(thread);\n-  if (LoomVerifyAfterThaw) {\n-    assert(do_verify_after_thaw(thread, cont.tail(), tty), \"\");\n-  }\n-  assert(ContinuationEntry::assert_entry_frame_laid_out(thread), \"\");\n-  clear_anchor(thread);\n-\n-  LogTarget(Trace, continuations) lt;\n-  if (lt.develop_is_enabled()) {\n-    LogStream ls(lt);\n-    ls.print_cr(\"Jumping to frame (thaw):\");\n-    frame(sp).print_value_on(&ls);\n-  }\n-#endif\n+  DEBUG_ONLY(log_frames_after_thaw(thread, cont, sp, preempted);)\n@@ -2596,1 +2926,1 @@\n-  ls.print_cr(\"------- frames ---------\");\n+  ls.print_cr(\"------- frames --------- for thread \" INTPTR_FORMAT, p2i(thread));\n@@ -2620,2 +2950,2 @@\n-    for (frame f = thread->last_frame(); !f.is_entry_frame(); f = f.sender(&map)) {\n-      f.describe(values, i++, &map);\n+    for (frame f = thread->last_frame(); !f.is_first_frame(); f = f.sender(&map), i++) {\n+      f.describe(values, i, &map, i == 0);\n@@ -2632,0 +2962,41 @@\n+\n+static void log_frames_after_thaw(JavaThread* thread, ContinuationWrapper& cont, intptr_t* sp, bool preempted) {\n+  intptr_t* sp0 = sp;\n+  address pc0 = *(address*)(sp - frame::sender_sp_ret_address_offset());\n+  bool use_cont_entry = false;\n+\n+  \/\/ Some preemption cases need to use and adjusted version of sp.\n+  if (preempted) {\n+    if (sp0 == cont.entrySP()) {\n+      \/\/ Still preempted (monitor not acquired) so no frames were thawed.\n+      assert(cont.tail()->preempted(), \"\");\n+      use_cont_entry = true;\n+    }\n+#if defined (AARCH64) || defined (RISCV64)\n+    else {\n+      CodeBlob* cb = CodeCache::find_blob(pc0);\n+      if (cb->frame_size() == 2) {\n+        assert(cb->is_runtime_stub(), \"\");\n+        \/\/ Returning to c2 runtime stub requires extra adjustment on aarch64\n+        \/\/ and riscv64 (see possibly_adjust_frame()).\n+        sp0 += frame::metadata_words;\n+      }\n+    }\n+#endif\n+  }\n+\n+  set_anchor(thread, use_cont_entry ? cont.entrySP() : sp0, use_cont_entry ? cont.entryPC() : nullptr);\n+  log_frames(thread);\n+  if (LoomVerifyAfterThaw) {\n+    assert(do_verify_after_thaw(thread, cont.tail(), tty), \"\");\n+  }\n+  assert(ContinuationEntry::assert_entry_frame_laid_out(thread), \"\");\n+  clear_anchor(thread);\n+\n+  LogTarget(Trace, continuations) lt;\n+  if (lt.develop_is_enabled()) {\n+    LogStream ls(lt);\n+    ls.print_cr(\"Jumping to frame (thaw):\");\n+    frame(sp).print_value_on(&ls);\n+  }\n+}\n@@ -2652,1 +3023,1 @@\n-  const_cast<frame&>(f).describe(values, 0, &map);\n+  const_cast<frame&>(f).describe(values, 0, &map, true);\n@@ -2659,0 +3030,1 @@\n+static address freeze_preempt_entry = nullptr;\n@@ -2668,0 +3040,4 @@\n+address Continuation::freeze_preempt_entry() {\n+  return ::freeze_preempt_entry;\n+}\n+\n@@ -2701,0 +3077,1 @@\n+    freeze_preempt_entry = (address)SelectedConfigT::freeze_preempt;\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":565,"deletions":188,"binary":false,"changes":753,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -61,0 +61,1 @@\n+  class NativeFrame;\n@@ -68,0 +69,1 @@\n+  static const bool native = false;\n@@ -136,0 +138,13 @@\n+class ContinuationHelper::NativeFrame : public ContinuationHelper::NonInterpretedFrame {\n+public:\n+  static const bool native = true;\n+\n+  static bool is_instance(const frame& f);\n+\n+#ifdef ASSERT\n+  static bool is_owning_locks(JavaThread* current, const frame& f);\n+#endif\n+\n+  static int stack_argsize(const frame& f) { return 0; }\n+};\n+\n@@ -141,0 +156,1 @@\n+  static int stack_argsize(const frame& f) { return 0; }\n","filename":"src\/hotspot\/share\/runtime\/continuationHelper.hpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -36,0 +37,1 @@\n+#include \"runtime\/synchronizer.hpp\"\n@@ -56,1 +58,1 @@\n-  return cb != nullptr && (cb->is_safepoint_stub() || cb->is_runtime_stub());\n+  return cb != nullptr && cb->is_runtime_stub();\n@@ -198,0 +200,20 @@\n+inline bool ContinuationHelper::NativeFrame::is_instance(const frame& f) {\n+  return f.is_native_frame();\n+}\n+\n+#ifdef ASSERT\n+inline bool ContinuationHelper::NativeFrame::is_owning_locks(JavaThread* thread, const frame& f) {\n+  assert(NativeFrame::is_instance(f), \"\");\n+\n+  Method* method = f.cb()->as_nmethod()->method();\n+  if (!method->is_synchronized()) {\n+    return false;\n+  } else {\n+    \/\/ Just verify we are actually the owner\n+    oop synced_obj = f.get_native_receiver();\n+    assert(ObjectSynchronizer::current_thread_holds_lock(thread, Handle(thread, synced_obj)), \"must be owner\");\n+    return true;\n+  }\n+}\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/continuationHelper.inline.hpp","additions":23,"deletions":1,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -90,0 +90,2 @@\n+int jdk_internal_vm_StackChunk::_lockStackSize_offset;\n+int jdk_internal_vm_StackChunk::_objectWaiter_offset;\n","filename":"src\/hotspot\/share\/runtime\/continuationJavaClasses.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -74,4 +74,6 @@\n-  macro(jdk_internal_vm_StackChunk, cont,           continuation_signature, false) \\\n-  macro(jdk_internal_vm_StackChunk, flags,          byte_signature,         false) \\\n-  macro(jdk_internal_vm_StackChunk, pc,             intptr_signature,       false) \\\n-  macro(jdk_internal_vm_StackChunk, maxThawingSize, int_signature,          false) \\\n+  macro(jdk_internal_vm_StackChunk, cont,            continuation_signature, false) \\\n+  macro(jdk_internal_vm_StackChunk, flags,           byte_signature,         false) \\\n+  macro(jdk_internal_vm_StackChunk, pc,              intptr_signature,       false) \\\n+  macro(jdk_internal_vm_StackChunk, maxThawingSize,  int_signature,          false) \\\n+  macro(jdk_internal_vm_StackChunk, lockStackSize,   byte_signature,         false) \\\n+  macro(jdk_internal_vm_StackChunk, objectWaiter,    intptr_signature,       false) \\\n@@ -89,0 +91,2 @@\n+  static int _lockStackSize_offset;\n+  static int _objectWaiter_offset;\n@@ -127,0 +131,6 @@\n+  static inline uint8_t lockStackSize(oop chunk);\n+  static inline void set_lockStackSize(oop chunk, uint8_t value);\n+\n+  static inline address objectWaiter(oop chunk);\n+  static inline void set_objectWaiter(oop chunk, address mon);\n+\n","filename":"src\/hotspot\/share\/runtime\/continuationJavaClasses.hpp","additions":15,"deletions":5,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -188,0 +188,16 @@\n+inline uint8_t jdk_internal_vm_StackChunk::lockStackSize(oop chunk) {\n+  return Atomic::load(chunk->field_addr<uint8_t>(_lockStackSize_offset));\n+}\n+\n+inline void jdk_internal_vm_StackChunk::set_lockStackSize(oop chunk, uint8_t value) {\n+  Atomic::store(chunk->field_addr<uint8_t>(_lockStackSize_offset), value);\n+}\n+\n+inline address jdk_internal_vm_StackChunk::objectWaiter(oop chunk) {\n+  return chunk->address_field(_objectWaiter_offset);\n+}\n+\n+inline void jdk_internal_vm_StackChunk::set_objectWaiter(oop chunk, address value) {\n+  chunk->address_field_put(_objectWaiter_offset, value);\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/continuationJavaClasses.inline.hpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -125,0 +125,4 @@\n+  if (!nm->can_be_deoptimized()) {\n+    return;\n+  }\n+\n@@ -1669,1 +1673,1 @@\n-          assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->owner() == deoptee_thread, \"must be\");\n+          assert(ObjectSynchronizer::read_monitor(thread, obj(), obj->mark())->has_owner(deoptee_thread), \"must be\");\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -500,1 +500,0 @@\n-\n@@ -580,1 +579,10 @@\n-    if (current->obj() != nullptr) current->obj()->print_value_on(st);\n+    oop obj = current->obj();\n+    if (obj != nullptr) {\n+      if (!is_heap_frame()) {\n+        obj->print_value_on(st);\n+      } else {\n+        \/\/ Might be an invalid oop. We don't have the\n+        \/\/ stackChunk to correct it so just print address.\n+        st->print(INTPTR_FORMAT, p2i(obj));\n+      }\n+    }\n@@ -583,1 +591,3 @@\n-    current->lock()->print_on(st, current->obj());\n+    if (!is_heap_frame()) {\n+      current->lock()->print_on(st, obj);\n+    }\n@@ -1088,1 +1098,1 @@\n-BasicLock* frame::get_native_monitor() {\n+BasicLock* frame::get_native_monitor() const {\n@@ -1097,1 +1107,1 @@\n-oop frame::get_native_receiver() {\n+oop frame::get_native_receiver() const {\n@@ -1343,1 +1353,1 @@\n-void frame::describe(FrameValues& values, int frame_no, const RegisterMap* reg_map) {\n+void frame::describe(FrameValues& values, int frame_no, const RegisterMap* reg_map, bool top) {\n@@ -1346,0 +1356,5 @@\n+  if (top) {\n+    values.describe(-1, sp() - 1, err_msg(\"sp[-1] for #%d\", frame_no), 0);\n+    values.describe(-1, sp() - 2, err_msg(\"sp[-2] for #%d\", frame_no), 0);\n+  }\n+\n@@ -1417,1 +1432,1 @@\n-  } else if (cb()->is_nmethod()) {\n+  } else if (is_compiled_frame()) {\n@@ -1520,5 +1535,0 @@\n-\n-    if (nm->method()->is_continuation_enter_intrinsic()) {\n-      ContinuationEntry* ce = Continuation::get_continuation_entry_for_entry_frame(reg_map->thread(), *this); \/\/ (ContinuationEntry*)unextended_sp();\n-      ce->describe(values, frame_no);\n-    }\n@@ -1531,0 +1541,4 @@\n+    if (nm->method()->is_continuation_enter_intrinsic()) {\n+      ContinuationEntry* ce = Continuation::get_continuation_entry_for_entry_frame(reg_map->thread(), *this); \/\/ (ContinuationEntry*)unextended_sp();\n+      ce->describe(values, frame_no);\n+    }\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -340,2 +340,2 @@\n-  BasicLock* get_native_monitor();\n-  oop        get_native_receiver();\n+  BasicLock* get_native_monitor() const;\n+  oop        get_native_receiver() const;\n@@ -429,0 +429,2 @@\n+  static JavaThread** saved_thread_address(const frame& f);\n+\n@@ -445,1 +447,1 @@\n-  void describe(FrameValues& values, int frame_no, const RegisterMap* reg_map=nullptr);\n+  void describe(FrameValues& values, int frame_no, const RegisterMap* reg_map=nullptr, bool top = false);\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -86,0 +86,1 @@\n+#include \"runtime\/threadIdentifier.hpp\"\n@@ -238,0 +239,2 @@\n+  \/\/ Set the lock_id to the next thread_id temporarily while initialization runs.\n+  set_lock_id(ThreadIdentifier::next());\n@@ -263,0 +266,3 @@\n+  \/\/ Update the lock_id with the tid value.\n+  set_lock_id(java_lang_Thread::thread_id(thread_oop()));\n+\n@@ -432,0 +438,1 @@\n+  _lock_id(0),\n@@ -452,0 +459,3 @@\n+  _pending_jvmti_unmount_event(false),\n+  _on_monitor_waited_event(false),\n+  _contended_entered_monitor(nullptr),\n@@ -492,0 +502,4 @@\n+  _preempt_alternate_return(nullptr),\n+  _preemption_cancelled(false),\n+  _pending_interrupted_exception(false),\n+\n@@ -1166,0 +1180,1 @@\n+  assert(is_in_VTMS_transition() != val, \"already %s transition\", val ? \"inside\" : \"outside\");\n@@ -1529,3 +1544,9 @@\n-      oop vt = vthread();\n-      assert(vt != nullptr, \"\");\n-      st->print_cr(\"   Carrying virtual thread #\" INT64_FORMAT, (int64_t)java_lang_Thread::thread_id(vt));\n+      st->print(\"   Carrying virtual thread #\");\n+      \/\/ _lock_id is the thread ID of the mounted virtual thread. If it equals\n+      \/\/ the tid of the carrier we caught thread at the start of a temporary\n+      \/\/ transition in VirtualThread.switchToCarrierThread. Ignore that case.\n+      if (lock_id() != java_lang_Thread::thread_id(thread_oop)) {\n+        st->print_cr(INT64_FORMAT, lock_id());\n+      } else {\n+        st->print_cr(\"%s\", \"(Unavailable)\");\n+      }\n@@ -1715,0 +1736,1 @@\n+  set_lock_id(java_lang_Thread::thread_id(thread_oop()));\n@@ -1994,0 +2016,8 @@\n+\n+  if (LockingMode != LM_LEGACY) {\n+    \/\/ Nothing to do. Just do some sanity check.\n+    assert(_held_monitor_count == 0, \"counter should not be used\");\n+    assert(_jni_monitor_count == 0, \"counter should not be used\");\n+    return;\n+  }\n+\n@@ -2002,1 +2032,1 @@\n-#endif\n+#endif \/\/ SUPPORT_MONITOR_COUNT\n@@ -2009,0 +2039,8 @@\n+\n+  if (LockingMode != LM_LEGACY) {\n+    \/\/ Nothing to do. Just do some sanity check.\n+    assert(_held_monitor_count == 0, \"counter should not be used\");\n+    assert(_jni_monitor_count == 0, \"counter should not be used\");\n+    return;\n+  }\n+\n@@ -2010,1 +2048,1 @@\n-  assert(_held_monitor_count >= 0, \"Must always be greater than 0: \" INTX_FORMAT, _held_monitor_count);\n+  assert(_held_monitor_count >= 0, \"Must always be non-negative: \" INTX_FORMAT, _held_monitor_count);\n@@ -2013,1 +2051,1 @@\n-    assert(_jni_monitor_count >= 0, \"Must always be greater than 0: \" INTX_FORMAT, _jni_monitor_count);\n+    assert(_jni_monitor_count >= 0, \"Must always be non-negative: \" INTX_FORMAT, _jni_monitor_count);\n@@ -2021,1 +2059,1 @@\n-#endif\n+#endif \/\/ SUPPORT_MONITOR_COUNT\n@@ -2203,0 +2241,1 @@\n+  target->set_lock_id(java_lang_Thread::thread_id(thread_oop()));\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":46,"deletions":7,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/continuationEntry.hpp\"\n@@ -44,0 +45,1 @@\n+#include \"runtime\/threadIdentifier.hpp\"\n@@ -53,1 +55,0 @@\n-class ContinuationEntry;\n@@ -162,0 +163,8 @@\n+  \/\/ ID used as owner for inflated monitors. Same as the j.l.Thread.tid of the\n+  \/\/ current _vthread object, except during creation of the primordial and JNI\n+  \/\/ attached thread cases where this field can have a temporary value. Also,\n+  \/\/ calls to VirtualThread.switchToCarrierThread will temporarily change _vthread\n+  \/\/ to refer to the carrier while preserving the j.l.Thread.tid of the virtual\n+  \/\/ thread in this field.\n+  int64_t _lock_id;\n+\n@@ -163,0 +172,6 @@\n+  void set_lock_id(int64_t tid) {\n+    assert(tid >= ThreadIdentifier::initial() && tid < ThreadIdentifier::current(), \"invalid tid\");\n+    _lock_id = tid;\n+  }\n+  int64_t lock_id() const { return _lock_id; }\n+\n@@ -317,0 +332,3 @@\n+  bool                  _pending_jvmti_unmount_event;    \/\/ When preempting we post unmount event at unmount end rather than start\n+  bool                  _on_monitor_waited_event;        \/\/ Avoid callee arg processing for enterSpecial when posting waited event\n+  ObjectMonitor*        _contended_entered_monitor;      \/\/ Monitor por pending monitor_contended_entered callback\n@@ -467,0 +485,22 @@\n+  \/\/ This is the field we poke in the interpreter and native\n+  \/\/ wrapper (Object.wait) to check for preemption.\n+  address _preempt_alternate_return;\n+  \/\/ When preempting on monitorenter we could have acquired the\n+  \/\/ monitor after freezing all vthread frames. In that case we\n+  \/\/ set this field so that in the preempt stub we call thaw again\n+  \/\/ instead of unmounting.\n+  bool _preemption_cancelled;\n+  \/\/ For Object.wait() we set this field to know if we need to\n+  \/\/ throw IE at the end of thawing before returning to Java.\n+  bool _pending_interrupted_exception;\n+\n+ public:\n+  bool preemption_cancelled()           { return _preemption_cancelled; }\n+  void set_preemption_cancelled(bool b) { _preemption_cancelled = b; }\n+\n+  bool pending_interrupted_exception()           { return _pending_interrupted_exception; }\n+  void set_pending_interrupted_exception(bool b) { _pending_interrupted_exception = b; }\n+\n+  bool preempting()           { return _preempt_alternate_return != nullptr; }\n+  void set_preempt_alternate_return(address val) { _preempt_alternate_return = val; }\n+\n@@ -631,1 +671,1 @@\n-  void clear_jni_monitor_count() { _jni_monitor_count = 0;   }\n+  void clear_jni_monitor_count() { _jni_monitor_count = 0; }\n@@ -690,0 +730,8 @@\n+  bool pending_jvmti_unmount_event()             { return _pending_jvmti_unmount_event; }\n+  void set_pending_jvmti_unmount_event(bool val) { _pending_jvmti_unmount_event = val; }\n+\n+  bool on_monitor_waited_event()             { return _on_monitor_waited_event; }\n+  void set_on_monitor_waited_event(bool val) { _on_monitor_waited_event = val; }\n+\n+  bool pending_contended_entered_event()         { return _contended_entered_monitor != nullptr; }\n+  ObjectMonitor* contended_entered_monitor()     { return _contended_entered_monitor; }\n@@ -696,0 +744,2 @@\n+  void set_contended_entered_monitor(ObjectMonitor* val) NOT_JVMTI_RETURN JVMTI_ONLY({ _contended_entered_monitor = val; })\n+\n@@ -846,0 +896,2 @@\n+  static ByteSize lock_id_offset()            { return byte_offset_of(JavaThread, _lock_id); }\n+\n@@ -850,0 +902,2 @@\n+  static ByteSize preemption_cancelled_offset()  { return byte_offset_of(JavaThread, _preemption_cancelled); }\n+  static ByteSize preempt_alternate_return_offset() { return byte_offset_of(JavaThread, _preempt_alternate_return); }\n@@ -1270,0 +1324,19 @@\n+class NoPreemptMark {\n+  ContinuationEntry* _ce;\n+  bool _unpin;\n+ public:\n+  NoPreemptMark(JavaThread* thread) : _ce(thread->last_continuation()), _unpin(false) {\n+    if (_ce != nullptr) _unpin = _ce->pin();\n+  }\n+  ~NoPreemptMark() { if (_unpin) _ce->unpin(); }\n+};\n+\n+class ThreadOnMonitorWaitedEvent {\n+  JavaThread* _thread;\n+ public:\n+  ThreadOnMonitorWaitedEvent(JavaThread* thread) : _thread(thread) {\n+    JVMTI_ONLY(_thread->set_on_monitor_waited_event(true);)\n+  }\n+  ~ThreadOnMonitorWaitedEvent() { JVMTI_ONLY(_thread->set_on_monitor_waited_event(false);) }\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":75,"deletions":2,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -247,1 +247,1 @@\n-  assert(this == current() || monitor->owner_raw() == this, \"only add owned monitors for other threads\");\n+  assert(this == current() || monitor->has_owner(this), \"only add owned monitors for other threads\");\n","filename":"src\/hotspot\/share\/runtime\/javaThread.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -347,1 +347,1 @@\n-  alloced_monitor->set_owner_anonymous();\n+  alloced_monitor->set_anonymous_owner();\n@@ -626,2 +626,0 @@\n-  locking_thread->inc_held_monitor_count();\n-\n@@ -657,2 +655,0 @@\n-  current->inc_held_monitor_count();\n-\n@@ -748,1 +744,1 @@\n-  if (monitor->is_owner_anonymous()) {\n+  if (monitor->has_anonymous_owner()) {\n@@ -793,1 +789,1 @@\n-      if (monitor->is_owner_anonymous()) {\n+      if (monitor->has_anonymous_owner()) {\n@@ -811,1 +807,1 @@\n-ObjectMonitor* LightweightSynchronizer::inflate_into_object_header(oop object, ObjectSynchronizer::InflateCause cause, JavaThread* inflating_thread, Thread* current) {\n+ObjectMonitor* LightweightSynchronizer::inflate_into_object_header(oop object, ObjectSynchronizer::InflateCause cause, JavaThread* locking_thread, Thread* current) {\n@@ -813,2 +809,2 @@\n-  \/\/ The JavaThread* inflating_thread parameter is only used by LM_LIGHTWEIGHT and requires\n-  \/\/ that the inflating_thread == Thread::current() or is suspended throughout the call by\n+  \/\/ The JavaThread* locking_thread parameter is only used by LM_LIGHTWEIGHT and requires\n+  \/\/ that the locking_thread == Thread::current() or is suspended throughout the call by\n@@ -829,2 +825,2 @@\n-    \/\/                   is anonymous and the inflating_thread owns the\n-    \/\/                   object lock, then we make the inflating_thread\n+    \/\/                   is anonymous and the locking_thread owns the\n+    \/\/                   object lock, then we make the locking_thread\n@@ -832,1 +828,1 @@\n-    \/\/                   the inflating_thread's lock stack.\n+    \/\/                   the locking_thread's lock stack.\n@@ -841,4 +837,4 @@\n-      if (inf->is_owner_anonymous() &&\n-          inflating_thread != nullptr && inflating_thread->lock_stack().contains(object)) {\n-        inf->set_owner_from_anonymous(inflating_thread);\n-        size_t removed = inflating_thread->lock_stack().remove(object);\n+      if (inf->has_anonymous_owner() &&\n+          locking_thread != nullptr && locking_thread->lock_stack().contains(object)) {\n+        inf->set_owner_from_anonymous(locking_thread);\n+        size_t removed = locking_thread->lock_stack().remove(object);\n@@ -851,1 +847,1 @@\n-    \/\/ Could be fast-locked either by the inflating_thread or by some other thread.\n+    \/\/ Could be fast-locked either by the locking_thread or by some other thread.\n@@ -855,2 +851,2 @@\n-    \/\/ the inflating_thread owns the monitor, then we set the ObjectMonitor's\n-    \/\/ owner to the inflating_thread. Otherwise, we set the ObjectMonitor's owner\n+    \/\/ the locking_thread owns the monitor, then we set the ObjectMonitor's\n+    \/\/ owner to the locking_thread. Otherwise, we set the ObjectMonitor's owner\n@@ -863,1 +859,1 @@\n-      bool own = inflating_thread != nullptr && inflating_thread->lock_stack().contains(object);\n+      bool own = locking_thread != nullptr && locking_thread->lock_stack().contains(object);\n@@ -865,2 +861,2 @@\n-        \/\/ Owned by inflating_thread.\n-        monitor->set_owner_from(nullptr, inflating_thread);\n+        \/\/ Owned by locking_thread.\n+        monitor->set_owner(locking_thread);\n@@ -869,1 +865,1 @@\n-        monitor->set_owner_anonymous();\n+        monitor->set_anonymous_owner();\n@@ -876,1 +872,1 @@\n-          size_t removed = inflating_thread->lock_stack().remove(object);\n+          size_t removed = locking_thread->lock_stack().remove(object);\n@@ -959,1 +955,1 @@\n-    if (monitor->is_owner_anonymous()) {\n+    if (monitor->has_anonymous_owner()) {\n@@ -1080,1 +1076,1 @@\n-      if (monitor->is_owner_anonymous() && lock_stack.contains(object)) {\n+      if (monitor->has_anonymous_owner() && lock_stack.contains(object)) {\n@@ -1192,1 +1188,0 @@\n-    current->inc_held_monitor_count();\n@@ -1201,1 +1196,0 @@\n-      current->inc_held_monitor_count();\n@@ -1219,1 +1213,0 @@\n-      current->inc_held_monitor_count();\n","filename":"src\/hotspot\/share\/runtime\/lightweightSynchronizer.cpp","additions":23,"deletions":30,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-  static ObjectMonitor* inflate_into_object_header(oop object, ObjectSynchronizer::InflateCause cause, JavaThread* inflating_thread, Thread* current);\n+  static ObjectMonitor* inflate_into_object_header(oop object, ObjectSynchronizer::InflateCause cause, JavaThread* locking_thread, Thread* current);\n","filename":"src\/hotspot\/share\/runtime\/lightweightSynchronizer.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -121,0 +121,4 @@\n+  inline int monitor_count() const;\n+  inline void move_to_address(oop* start);\n+  inline void move_from_address(oop* start, int count);\n+\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -218,0 +218,23 @@\n+inline int LockStack::monitor_count() const {\n+  int end = to_index(_top);\n+  assert(end <= CAPACITY, \"invariant\");\n+  return end;\n+}\n+\n+inline void LockStack::move_to_address(oop* start) {\n+  int end = to_index(_top);\n+  for (int i = 0; i < end; i++) {\n+    start[i] = _base[i];\n+    DEBUG_ONLY(_base[i] = nullptr;)\n+  }\n+  _top = lock_stack_base_offset;\n+}\n+\n+inline void LockStack::move_from_address(oop* start, int count) {\n+  assert(to_index(_top) == 0, \"lockstack should be empty\");\n+  for (int i = 0; i < count; i++) {\n+    _base[i] = start[i];\n+    _top += oopSize;\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"runtime\/continuationWrapper.inline.hpp\"\n@@ -56,0 +57,1 @@\n+#include \"runtime\/threads.hpp\"\n@@ -117,0 +119,12 @@\n+OopHandle ObjectMonitor::_vthread_cxq_head;\n+ParkEvent* ObjectMonitor::_vthread_unparker_ParkEvent = nullptr;\n+\n+static void post_virtual_thread_pinned_event(JavaThread* current, const char* reason) {\n+  EventVirtualThreadPinned e;\n+  if (e.should_commit()) {\n+    e.set_pinnedReason(reason);\n+    e.set_carrierThread(JFR_JVM_THREAD_ID(current));\n+    e.commit();\n+  }\n+}\n+\n@@ -240,1 +254,1 @@\n-  _owner(nullptr),\n+  _owner(NO_OWNER),\n@@ -246,1 +260,1 @@\n-  _succ(nullptr),\n+  _succ(NO_OWNER),\n@@ -251,1 +265,2 @@\n-  _WaitSetLock(0)\n+  _WaitSetLock(0),\n+  _stack_locker(nullptr)\n@@ -266,1 +281,1 @@\n-    _om->_succ = nullptr;\n+    _om->clear_successor();\n@@ -277,2 +292,2 @@\n-    if (_om->_succ == current) {\n-      _om->_succ = nullptr;\n+    if (_om->has_successor(current)) {\n+      _om->clear_successor();\n@@ -313,1 +328,1 @@\n-  void* prev_owner = try_set_owner_from(nullptr, locking_thread);\n+  int64_t prev_owner = try_set_owner_from(NO_OWNER, locking_thread);\n@@ -316,1 +331,1 @@\n-  if (prev_owner == nullptr) {\n+  if (prev_owner == NO_OWNER) {\n@@ -319,1 +334,1 @@\n-  } else if (prev_owner == locking_thread) {\n+  } else if (prev_owner == owner_from(locking_thread)) {\n@@ -337,1 +352,1 @@\n-    } else if (prev_owner == nullptr) {\n+    } else if (prev_owner == NO_OWNER) {\n@@ -342,2 +357,2 @@\n-      prev_owner = try_set_owner_from(nullptr, locking_thread);\n-      success = prev_owner == nullptr;\n+      prev_owner = try_set_owner_from(NO_OWNER, locking_thread);\n+      success = prev_owner == NO_OWNER;\n@@ -345,5 +360,0 @@\n-  } else if (LockingMode == LM_LEGACY && locking_thread->is_lock_owned((address)prev_owner)) {\n-    assert(_recursions == 0, \"must be\");\n-    _recursions = 1;\n-    set_owner_from_BasicLock(prev_owner, locking_thread);\n-    success = true;\n@@ -351,1 +361,1 @@\n-  assert(!success || owner_raw() == locking_thread, \"must be\");\n+  assert(!success || has_owner(locking_thread), \"must be\");\n@@ -364,2 +374,2 @@\n-         \", this=\" INTPTR_FORMAT \"{owner=\" INTPTR_FORMAT \"}\",\n-         p2i(locking_thread), p2i(this), p2i(owner_raw()));\n+         \", this=\" INTPTR_FORMAT \"{owner=\" INT64_FORMAT \"}\",\n+         p2i(locking_thread), p2i(this), owner_raw());\n@@ -385,3 +395,3 @@\n-         \", this=\" INTPTR_FORMAT \"{owner=\" INTPTR_FORMAT \"}\",\n-         p2i(locking_thread), p2i(this), p2i(owner_raw()));\n-  assert(owner_raw() == locking_thread, \"must be\");\n+         \", this=\" INTPTR_FORMAT \"{owner=\" INT64_FORMAT \"}\",\n+         p2i(locking_thread), p2i(this), owner_raw());\n+  assert(has_owner(locking_thread), \"must be\");\n@@ -405,1 +415,1 @@\n-  if (r == TryLockResult::HasOwner && owner() == current) {\n+  if (r == TryLockResult::HasOwner && has_owner(current)) {\n@@ -410,7 +420,0 @@\n-  void* cur = owner_raw();\n-  if (LockingMode == LM_LEGACY && current->is_lock_owned((address)cur)) {\n-    assert(_recursions == 0, \"internal state error\");\n-    _recursions = 1;\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    return true;\n-  }\n@@ -439,1 +442,1 @@\n-    assert(owner_raw() == current, \"must be current: owner=\" INTPTR_FORMAT, p2i(owner_raw()));\n+    assert(has_owner(current), \"must be current: owner=\" INT64_FORMAT, owner_raw());\n@@ -455,2 +458,2 @@\n-  assert(owner_raw() != current, \"invariant\");\n-  assert(_succ != current, \"invariant\");\n+  assert(!has_owner(current), \"invariant\");\n+  assert(!has_successor(current), \"invariant\");\n@@ -475,1 +478,1 @@\n-  assert(owner_raw() != current, \"must be\");\n+  assert(!has_owner(current), \"must be\");\n@@ -506,0 +509,29 @@\n+    ContinuationEntry* ce = current->last_continuation();\n+    if (ce != nullptr && ce->is_virtual_thread()) {\n+      int result = Continuation::try_preempt(current, ce->cont_oop(current));\n+      if (result == freeze_ok) {\n+        bool acquired = VThreadMonitorEnter(current);\n+        if (acquired) {\n+          \/\/ We actually acquired the monitor while trying to add the vthread to the\n+          \/\/ _cxq so cancel preemption. We will still go through the preempt stub\n+          \/\/ but instead of unmounting we will call thaw to continue execution.\n+          current->set_preemption_cancelled(true);\n+          if (JvmtiExport::should_post_monitor_contended_entered()) {\n+            \/\/ We are going to call thaw again after this and finish the VMTS\n+            \/\/ transition so no need to do it here. We will post the event there.\n+            current->set_contended_entered_monitor(this);\n+          }\n+        }\n+        current->set_current_pending_monitor(nullptr);\n+        DEBUG_ONLY(int state = java_lang_VirtualThread::state(current->vthread()));\n+        assert((acquired && current->preemption_cancelled() && state == java_lang_VirtualThread::RUNNING) ||\n+               (!acquired && !current->preemption_cancelled() && state == java_lang_VirtualThread::BLOCKING), \"invariant\");\n+        return;\n+      }\n+      if (result == freeze_pinned_native) {\n+        post_virtual_thread_pinned_event(current, \"Native frame or <clinit> on stack\");\n+      } else if (result == freeze_unsupported) {\n+        post_virtual_thread_pinned_event(current, \"Native frame or <clinit> or monitors on stack\");\n+      }\n+    }\n+\n@@ -526,1 +558,1 @@\n-        assert(owner_raw() == current, \"invariant\");\n+        assert(has_owner(current), \"invariant\");\n@@ -539,2 +571,2 @@\n-  assert(owner_raw() == current, \"invariant\");\n-  assert(_succ != current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n+  assert(!has_successor(current), \"invariant\");\n@@ -576,2 +608,2 @@\n-  void* own = owner_raw();\n-  void* first_own = own;\n+  int64_t own = owner_raw();\n+  int64_t first_own = own;\n@@ -596,3 +628,3 @@\n-    } else if (own == nullptr) {\n-      void* prev_own = try_set_owner_from(nullptr, current);\n-      if (prev_own == nullptr) {\n+    } else if (own == NO_OWNER) {\n+      int64_t prev_own = try_set_owner_from(NO_OWNER, current);\n+      if (prev_own == NO_OWNER) {\n@@ -637,1 +669,1 @@\n-    set_owner_from(nullptr, DEFLATER_MARKER);\n+    set_owner_from_raw(NO_OWNER, DEFLATER_MARKER);\n@@ -646,1 +678,1 @@\n-    if (try_set_owner_from(nullptr, DEFLATER_MARKER) != nullptr) {\n+    if (try_set_owner_from_raw(NO_OWNER, DEFLATER_MARKER) != NO_OWNER) {\n@@ -657,1 +689,1 @@\n-      if (try_set_owner_from(DEFLATER_MARKER, nullptr) != DEFLATER_MARKER) {\n+      if (try_set_owner_from_raw(DEFLATER_MARKER, NO_OWNER) != DEFLATER_MARKER) {\n@@ -670,1 +702,1 @@\n-      if (try_set_owner_from(DEFLATER_MARKER, nullptr) != DEFLATER_MARKER) {\n+      if (try_set_owner_from_raw(DEFLATER_MARKER, NO_OWNER) != DEFLATER_MARKER) {\n@@ -771,1 +803,1 @@\n-            \", owner=\" PTR_FORMAT\n+            \", owner=\" INT64_FORMAT\n@@ -779,2 +811,2 @@\n-                ? p2i(nullptr)\n-                : p2i(owner_raw()),\n+                ? NO_OWNER\n+                : owner_raw(),\n@@ -791,2 +823,2 @@\n-    assert(_succ != current, \"invariant\");\n-    assert(owner_raw() == current, \"invariant\");\n+    assert(!has_successor(current), \"invariant\");\n+    assert(has_owner(current), \"invariant\");\n@@ -806,2 +838,2 @@\n-    assert(owner_raw() == current, \"invariant\");\n-    assert(_succ != current, \"invariant\");\n+    assert(has_owner(current), \"invariant\");\n+    assert(!has_successor(current), \"invariant\");\n@@ -812,2 +844,2 @@\n-  assert(_succ != current, \"invariant\");\n-  assert(owner_raw() != current, \"invariant\");\n+  assert(!has_successor(current), \"invariant\");\n+  assert(!has_owner(current), \"invariant\");\n@@ -841,2 +873,2 @@\n-      assert(_succ != current, \"invariant\");\n-      assert(owner_raw() == current, \"invariant\");\n+      assert(!has_successor(current), \"invariant\");\n+      assert(has_owner(current), \"invariant\");\n@@ -858,0 +890,14 @@\n+  \/\/ For virtual threads that are pinned, do a timed-park instead to\n+  \/\/ alleviate some deadlocks cases where the succesor is an unmounted\n+  \/\/ virtual thread that cannot run. This can happen in particular when\n+  \/\/ this virtual thread is currently loading\/initializing a class, and\n+  \/\/ all other carriers have a vthread pinned to it waiting for said class\n+  \/\/ to be loaded\/initialized.\n+  static int MAX_RECHECK_INTERVAL = 1000;\n+  int recheck_interval = 1;\n+  bool do_timed_parked = false;\n+  ContinuationEntry* ce = current->last_continuation();\n+  if (ce != nullptr && ce->is_virtual_thread()) {\n+    do_timed_parked = true;\n+  }\n+\n@@ -863,1 +909,1 @@\n-    assert(owner_raw() != current, \"invariant\");\n+    assert(!has_owner(current), \"invariant\");\n@@ -866,1 +912,10 @@\n-    current->_ParkEvent->park();\n+    if (do_timed_parked) {\n+      current->_ParkEvent->park((jlong) recheck_interval);\n+      \/\/ Increase the recheck_interval, but clamp the value.\n+      recheck_interval *= 8;\n+      if (recheck_interval > MAX_RECHECK_INTERVAL) {\n+        recheck_interval = MAX_RECHECK_INTERVAL;\n+      }\n+    } else {\n+      current->_ParkEvent->park();\n+    }\n@@ -896,1 +951,1 @@\n-    if (_succ == current) _succ = nullptr;\n+    if (has_successor(current)) clear_successor();\n@@ -910,1 +965,1 @@\n-  assert(owner_raw() == current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n@@ -913,2 +968,2 @@\n-  if (_succ == current) {\n-    _succ = nullptr;\n+  if (has_successor(current)) {\n+    clear_successor();\n@@ -961,1 +1016,1 @@\n-    assert(owner_raw() != current, \"invariant\");\n+    assert(!has_owner(current), \"invariant\");\n@@ -997,1 +1052,1 @@\n-    if (_succ == current) _succ = nullptr;\n+    if (has_successor(current)) clear_successor();\n@@ -1020,1 +1075,1 @@\n-  assert(owner_raw() == current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n@@ -1023,2 +1078,2 @@\n-  if (_succ == current) _succ = nullptr;\n-  assert(_succ != current, \"invariant\");\n+  if (has_successor(current)) clear_successor();\n+  assert(!has_successor(current), \"invariant\");\n@@ -1029,0 +1084,130 @@\n+\/\/ This method is called from two places:\n+\/\/ - On monitorenter contention with a null waiter.\n+\/\/ - After Object.wait() times out or the target is interrupted to reenter the\n+\/\/   monitor, with the existing waiter.\n+\/\/ For the Object.wait() case we do not delete the ObjectWaiter in case we\n+\/\/ succesfully acquire the monitor since we are going to need it on return.\n+bool ObjectMonitor::VThreadMonitorEnter(JavaThread* current, ObjectWaiter* waiter) {\n+  if (TryLock(current) == TryLockResult::Success) {\n+    assert(has_owner(current), \"invariant\");\n+    assert(!has_successor(current), \"invariant\");\n+    return true;\n+  }\n+\n+  oop vthread = current->vthread();\n+  ObjectWaiter* node = waiter != nullptr ? waiter : new ObjectWaiter(vthread, this);\n+  node->_prev   = (ObjectWaiter*) 0xBAD;\n+  node->TState  = ObjectWaiter::TS_CXQ;\n+\n+  \/\/ Push node associated with vthread onto the front of the _cxq.\n+  ObjectWaiter* nxt;\n+  for (;;) {\n+    node->_next = nxt = _cxq;\n+    if (Atomic::cmpxchg(&_cxq, nxt, node) == nxt) break;\n+\n+    \/\/ Interference - the CAS failed because _cxq changed.  Just retry.\n+    \/\/ As an optional optimization we retry the lock.\n+    if (TryLock(current) == TryLockResult::Success) {\n+      assert(has_owner(current), \"invariant\");\n+      assert(!has_successor(current), \"invariant\");\n+      if (waiter == nullptr) delete node;  \/\/ for Object.wait() don't delete yet\n+      return true;\n+    }\n+  }\n+\n+  \/\/ We have to try once more since owner could have exited monitor and checked\n+  \/\/ _cxq before we added the node to the queue.\n+  if (TryLock(current) == TryLockResult::Success) {\n+    assert(has_owner(current), \"invariant\");\n+    UnlinkAfterAcquire(current, node);\n+    if (has_successor(current)) clear_successor();\n+    if (waiter == nullptr) delete node;  \/\/ for Object.wait() don't delete yet\n+    return true;\n+  }\n+\n+  assert(java_lang_VirtualThread::state(vthread) == java_lang_VirtualThread::RUNNING, \"wrong state for vthread\");\n+  java_lang_VirtualThread::set_state(vthread, java_lang_VirtualThread::BLOCKING);\n+\n+  \/\/ We didn't succeed in acquiring the monitor so increment _contentions and\n+  \/\/ save ObjectWaiter* in the chunk since we will need it when resuming execution.\n+  add_to_contentions(1);\n+  oop cont = java_lang_VirtualThread::continuation(vthread);\n+  stackChunkOop chunk  = jdk_internal_vm_Continuation::tail(cont);\n+  chunk->set_object_waiter(node);\n+  return false;\n+}\n+\n+\/\/ Called from thaw code to resume the monitor operation that caused the vthread\n+\/\/ to be unmounted. Method returns true if the monitor is successfully acquired,\n+\/\/ which marks the end of the monitor operation, otherwise it returns false.\n+bool ObjectMonitor::resume_operation(JavaThread* current, ObjectWaiter* node, ContinuationWrapper& cont) {\n+  assert(java_lang_VirtualThread::state(current->vthread()) == java_lang_VirtualThread::RUNNING, \"wrong state for vthread\");\n+  assert(!has_owner(current), \"\");\n+\n+  if (node->is_wait() && !node->at_reenter()) {\n+    bool acquired_monitor = VThreadWaitReenter(current, node, cont);\n+    if (acquired_monitor) return true;\n+  }\n+\n+  \/\/ Retry acquiring monitor...\n+\n+  int state = node->TState;\n+  guarantee(state == ObjectWaiter::TS_ENTER || state == ObjectWaiter::TS_CXQ, \"invariant\");\n+\n+  if (TryLock(current) == TryLockResult::Success) {\n+    VThreadEpilog(current, node);\n+    return true;\n+  }\n+\n+  oop vthread = current->vthread();\n+  if (has_successor(current)) clear_successor();\n+\n+  \/\/ Invariant: after clearing _succ a thread *must* retry acquiring the monitor.\n+  OrderAccess::fence();\n+\n+  if (TryLock(current) == TryLockResult::Success) {\n+    VThreadEpilog(current, node);\n+    return true;\n+  }\n+\n+  \/\/ We will return to Continuation.run() and unmount so set the right state.\n+  java_lang_VirtualThread::set_state(vthread, java_lang_VirtualThread::BLOCKING);\n+\n+  return false;\n+}\n+\n+void ObjectMonitor::VThreadEpilog(JavaThread* current, ObjectWaiter* node) {\n+  assert(has_owner(current), \"invariant\");\n+  add_to_contentions(-1);\n+\n+  if (has_successor(current)) clear_successor();\n+\n+  guarantee(_recursions == 0, \"invariant\");\n+\n+  if (node->is_wait()) {\n+    _recursions = node->_recursions;   \/\/ restore the old recursion count\n+    _waiters--;                        \/\/ decrement the number of waiters\n+\n+    if (node->_interrupted) {\n+      \/\/ We will throw at thaw end after finishing the mount transition.\n+      current->set_pending_interrupted_exception(true);\n+    }\n+  }\n+\n+  assert(node->TState == ObjectWaiter::TS_ENTER || node->TState == ObjectWaiter::TS_CXQ, \"\");\n+  UnlinkAfterAcquire(current, node);\n+  delete node;\n+\n+  \/\/ Remove the ObjectWaiter* from the stackChunk.\n+  oop vthread = current->vthread();\n+  oop cont = java_lang_VirtualThread::continuation(vthread);\n+  stackChunkOop chunk  = jdk_internal_vm_Continuation::tail(cont);\n+  chunk->set_object_waiter(nullptr);\n+\n+  if (JvmtiExport::should_post_monitor_contended_entered()) {\n+    \/\/ We are going to call thaw again after this and finish the VMTS\n+    \/\/ transition so no need to do it here. We will post the event there.\n+    current->set_contended_entered_monitor(this);\n+  }\n+}\n+\n@@ -1034,2 +1219,3 @@\n-  assert(owner_raw() == current, \"invariant\");\n-  assert(currentNode->_thread == current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n+  assert((!currentNode->is_vthread() && currentNode->thread() == current) ||\n+         (currentNode->is_vthread() && currentNode->vthread() == current->vthread()), \"invariant\");\n@@ -1146,16 +1332,10 @@\n-  void* cur = owner_raw();\n-  if (current != cur) {\n-    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"invariant\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    } else {\n-      \/\/ Apparent unbalanced locking ...\n-      \/\/ Naively we'd like to throw IllegalMonitorStateException.\n-      \/\/ As a practical matter we can neither allocate nor throw an\n-      \/\/ exception as ::exit() can be called from leaf routines.\n-      \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n-      \/\/ Upon deeper reflection, however, in a properly run JVM the only\n-      \/\/ way we should encounter this situation is in the presence of\n-      \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n-      \/\/ See also: CR4414101\n+  if (!has_owner(current)) {\n+    \/\/ Apparent unbalanced locking ...\n+    \/\/ Naively we'd like to throw IllegalMonitorStateException.\n+    \/\/ As a practical matter we can neither allocate nor throw an\n+    \/\/ exception as ::exit() can be called from leaf routines.\n+    \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n+    \/\/ Upon deeper reflection, however, in a properly run JVM the only\n+    \/\/ way we should encounter this situation is in the presence of\n+    \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n+    \/\/ See also: CR4414101\n@@ -1163,6 +1343,6 @@\n-      LogStreamHandle(Error, monitorinflation) lsh;\n-      lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n-                    \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n-      lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n-      print_debug_style_on(&lsh);\n-      assert(false, \"Non-balanced monitor enter\/exit!\");\n+    LogStreamHandle(Error, monitorinflation) lsh;\n+    lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n+                  \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n+    lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n+    print_debug_style_on(&lsh);\n+    assert(false, \"Non-balanced monitor enter\/exit!\");\n@@ -1170,2 +1350,1 @@\n-      return;\n-    }\n+    return;\n@@ -1188,1 +1367,1 @@\n-    assert(current == owner_raw(), \"invariant\");\n+    assert(has_owner(current), \"invariant\");\n@@ -1194,1 +1373,1 @@\n-    \/\/ successor check. The try_set_owner() below uses cmpxchg() so\n+    \/\/ successor check. The try_set_owner_from() below uses cmpxchg() so\n@@ -1199,1 +1378,1 @@\n-    if ((intptr_t(_EntryList)|intptr_t(_cxq)) == 0 || _succ != nullptr) {\n+    if ((intptr_t(_EntryList)|intptr_t(_cxq)) == 0 || has_successor()) {\n@@ -1241,1 +1420,1 @@\n-    guarantee(owner_raw() == current, \"invariant\");\n+    guarantee(has_owner(current), \"invariant\");\n@@ -1306,1 +1485,1 @@\n-    if (_succ != nullptr) continue;\n+    if (has_successor()) continue;\n@@ -1318,1 +1497,1 @@\n-  assert(owner_raw() == current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n@@ -1326,2 +1505,13 @@\n-  _succ = Wakee->_thread;\n-  ParkEvent * Trigger = Wakee->_event;\n+  oop vthread = nullptr;\n+  ParkEvent * Trigger;\n+  if (!Wakee->is_vthread()) {\n+    JavaThread* t = Wakee->thread();\n+    assert(t != nullptr, \"\");\n+    Trigger = t->_ParkEvent;\n+    set_successor(t);\n+  } else {\n+    vthread = Wakee->vthread();\n+    assert(vthread != nullptr, \"\");\n+    Trigger = ObjectMonitor::vthread_unparker_ParkEvent();\n+    set_successor(vthread);\n+  }\n@@ -1340,1 +1530,8 @@\n-  Trigger->unpark();\n+\n+  if (vthread == nullptr) {\n+    \/\/ Platform thread case.\n+    Trigger->unpark();\n+  } else if (java_lang_VirtualThread::set_onWaitingList(vthread, vthread_cxq_head())) {\n+    \/\/ Virtual thread case.\n+    Trigger->unpark();\n+  }\n@@ -1346,5 +1543,2 @@\n-\/\/ complete_exit exits a lock returning recursion count\n-\/\/ complete_exit requires an inflated monitor\n-\/\/ The _owner field is not always the Thread addr even with an\n-\/\/ inflated monitor, e.g. the monitor can be inflated by a non-owning\n-\/\/ thread due to contention.\n+\/\/ Exits the monitor returning recursion count. _owner should\n+\/\/ be set to current's tid, i.e. no ANONYMOUS_OWNER allowed.\n@@ -1353,0 +1547,1 @@\n+  guarantee(has_owner(current), \"complete_exit not owner\");\n@@ -1354,10 +1549,0 @@\n-  void* cur = owner_raw();\n-  if (current != cur) {\n-    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"internal state error\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    }\n-  }\n-\n-  guarantee(current == owner_raw(), \"complete_exit not owner\");\n@@ -1367,1 +1552,1 @@\n-  guarantee(owner_raw() != current, \"invariant\");\n+  guarantee(!has_owner(current), \"invariant\");\n@@ -1390,8 +1575,2 @@\n-  void* cur = owner_raw();\n-  assert(cur != anon_owner_ptr(), \"no anon owner here\");\n-  if (cur == current) {\n-    return true;\n-  }\n-  if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    _recursions = 0;\n+  int64_t cur = owner_raw();\n+  if (cur == owner_from(current)) {\n@@ -1432,0 +1611,26 @@\n+static void vthread_monitor_waited_event(JavaThread *current, ObjectWaiter* node, ContinuationWrapper& cont, EventJavaMonitorWait* event, jboolean timed_out) {\n+  \/\/ Since we might safepoint set the anchor so that the stack can we walked.\n+  assert(current->last_continuation() != nullptr, \"\");\n+  JavaFrameAnchor* anchor = current->frame_anchor();\n+  anchor->set_last_Java_sp(current->last_continuation()->entry_sp());\n+  anchor->set_last_Java_pc(current->last_continuation()->entry_pc());\n+\n+  ContinuationWrapper::SafepointOp so(current, cont);\n+\n+  JRT_BLOCK\n+    if (event->should_commit()) {\n+      long timeout = java_lang_VirtualThread::waitTimeout(current->vthread());\n+      post_monitor_wait_event(event, node->_monitor, node->_notifier_tid, timeout, timed_out);\n+    }\n+    if (JvmtiExport::should_post_monitor_waited()) {\n+      \/\/ We mark this call in case of an upcall to Java while posting the event.\n+      \/\/ If somebody walks the stack in that case, processing the enterSpecial\n+      \/\/ frame should not include processing callee arguments since there is no\n+      \/\/ actual callee (see nmethod::preserve_callee_argument_oops()).\n+      ThreadOnMonitorWaitedEvent tmwe(current);\n+      JvmtiExport::vthread_post_monitor_waited(current, node->_monitor, timed_out);\n+    }\n+  JRT_BLOCK_END\n+  current->frame_anchor()->clear();\n+}\n+\n@@ -1471,0 +1676,20 @@\n+  ContinuationEntry* ce = current->last_continuation();\n+  if (ce != nullptr && ce->is_virtual_thread()) {\n+    int result = Continuation::try_preempt(current, ce->cont_oop(current));\n+    if (result == freeze_ok) {\n+      VThreadWait(current, millis);\n+      current->set_current_waiting_monitor(nullptr);\n+      return;\n+    }\n+    if (result == freeze_pinned_native || result == freeze_unsupported) {\n+      const Klass* monitor_klass = object()->klass();\n+      if (!is_excluded(monitor_klass)) {\n+        if (result == freeze_pinned_native) {\n+          post_virtual_thread_pinned_event(current,\"Native frame or <clinit> on stack\");\n+        } else if (result == freeze_unsupported) {\n+          post_virtual_thread_pinned_event(current, \"Native frame or <clinit> or monitors on stack\");\n+        }\n+      }\n+    }\n+  }\n+\n@@ -1494,1 +1719,1 @@\n-  guarantee(owner_raw() != current, \"invariant\");\n+  guarantee(!has_owner(current), \"invariant\");\n@@ -1520,1 +1745,1 @@\n-      } else if (node._notified == 0) {\n+      } else if (!node._notified) {\n@@ -1548,1 +1773,1 @@\n-        assert(node._notified == 0, \"invariant\");\n+        assert(!node._notified, \"invariant\");\n@@ -1560,1 +1785,1 @@\n-    if (_succ == current) _succ = nullptr;\n+    if (has_successor(current)) clear_successor();\n@@ -1574,1 +1799,1 @@\n-      if (node._notified != 0 && _succ == current) {\n+      if (node._notified && has_successor(current)) {\n@@ -1590,1 +1815,1 @@\n-        node._event->unpark();\n+        current->_ParkEvent->unpark();\n@@ -1600,1 +1825,1 @@\n-    assert(owner_raw() != current, \"invariant\");\n+    assert(!has_owner(current), \"invariant\");\n@@ -1603,0 +1828,4 @@\n+      \/\/ We use the NoPreemptMark for the very rare case where the previous\n+      \/\/ preempt attempt failed due to OOM. The preempt on monitor contention\n+      \/\/ could succeed but we can't unmount now.\n+      NoPreemptMark npm(current);\n@@ -1615,2 +1844,2 @@\n-    assert(owner_raw() == current, \"invariant\");\n-    assert(_succ != current, \"invariant\");\n+    assert(has_owner(current), \"invariant\");\n+    assert(!has_successor(current), \"invariant\");\n@@ -1629,2 +1858,2 @@\n-  assert(owner_raw() == current, \"invariant\");\n-  assert(_succ != current, \"invariant\");\n+  assert(has_owner(current), \"invariant\");\n+  assert(!has_successor(current), \"invariant\");\n@@ -1646,1 +1875,0 @@\n-\n@@ -1657,1 +1885,1 @@\n-    guarantee(iterator->_notified == 0, \"invariant\");\n+    guarantee(!iterator->_notified, \"invariant\");\n@@ -1664,0 +1892,16 @@\n+    if (iterator->is_vthread()) {\n+      oop vthread = iterator->vthread();\n+      java_lang_VirtualThread::set_notified(vthread, true);\n+      int old_state = java_lang_VirtualThread::state(vthread);\n+      \/\/ If state is not WAIT\/TIMED_WAIT then target could still be on\n+      \/\/ unmount transition, or wait could have already timed-out or target\n+      \/\/ could have been interrupted. In the first case, the target itself\n+      \/\/ will set the state to BLOCKED at the end of the unmount transition.\n+      \/\/ In the other cases the target would have been already unblocked so\n+      \/\/ there is nothing to do.\n+      if (old_state == java_lang_VirtualThread::WAIT ||\n+          old_state == java_lang_VirtualThread::TIMED_WAIT) {\n+        java_lang_VirtualThread::cmpxchg_state(vthread, old_state, java_lang_VirtualThread::BLOCKED);\n+      }\n+    }\n+\n@@ -1666,1 +1910,1 @@\n-    iterator->_notified = 1;\n+    iterator->_notified = true;\n@@ -1699,1 +1943,3 @@\n-    iterator->wait_reenter_begin(this);\n+    if (!iterator->is_vthread()) {\n+      iterator->wait_reenter_begin(this);\n+    }\n@@ -1750,0 +1996,88 @@\n+void ObjectMonitor::VThreadWait(JavaThread* current, jlong millis) {\n+  oop vthread = current->vthread();\n+  ObjectWaiter* node = new ObjectWaiter(vthread, this);\n+  node->_is_wait = true;\n+  node->TState = ObjectWaiter::TS_WAIT;\n+  java_lang_VirtualThread::set_notified(vthread, false);  \/\/ Reset notified flag\n+\n+  \/\/ Enter the waiting queue, which is a circular doubly linked list in this case\n+  \/\/ but it could be a priority queue or any data structure.\n+  \/\/ _WaitSetLock protects the wait queue.  Normally the wait queue is accessed only\n+  \/\/ by the owner of the monitor *except* in the case where park()\n+  \/\/ returns because of a timeout or interrupt.  Contention is exceptionally rare\n+  \/\/ so we use a simple spin-lock instead of a heavier-weight blocking lock.\n+\n+  Thread::SpinAcquire(&_WaitSetLock, \"WaitSet - add\");\n+  AddWaiter(node);\n+  Thread::SpinRelease(&_WaitSetLock);\n+\n+  node->_recursions = _recursions;   \/\/ record the old recursion count\n+  _recursions = 0;                   \/\/ set the recursion level to be 0\n+  _waiters++;                        \/\/ increment the number of waiters\n+  exit(current);                     \/\/ exit the monitor\n+  guarantee(!has_owner(current), \"invariant\");\n+\n+  assert(java_lang_VirtualThread::state(vthread) == java_lang_VirtualThread::RUNNING, \"wrong state for vthread\");\n+  java_lang_VirtualThread::set_state(vthread, millis == 0 ? java_lang_VirtualThread::WAITING : java_lang_VirtualThread::TIMED_WAITING);\n+  java_lang_VirtualThread::set_waitTimeout(vthread, millis);\n+\n+  \/\/ Save the ObjectWaiter* in the chunk since we will need it when resuming execution.\n+  oop cont = java_lang_VirtualThread::continuation(vthread);\n+  stackChunkOop chunk  = jdk_internal_vm_Continuation::tail(cont);\n+  chunk->set_object_waiter(node);\n+}\n+\n+bool ObjectMonitor::VThreadWaitReenter(JavaThread* current, ObjectWaiter* node, ContinuationWrapper& cont) {\n+  \/\/ First time we run after being preempted on Object.wait().\n+  \/\/ Check if we were interrupted or the wait timed-out, and in\n+  \/\/ that case remove ourselves from the _WaitSet queue.\n+  if (node->TState == ObjectWaiter::TS_WAIT) {\n+    Thread::SpinAcquire(&_WaitSetLock, \"WaitSet - unlink\");\n+    if (node->TState == ObjectWaiter::TS_WAIT) {\n+      DequeueSpecificWaiter(node);       \/\/ unlink from WaitSet\n+      assert(!node->_notified, \"invariant\");\n+      node->TState = ObjectWaiter::TS_RUN;\n+    }\n+    Thread::SpinRelease(&_WaitSetLock);\n+  }\n+\n+  \/\/ If this was an interrupted case, set the _interrupted boolean so that\n+  \/\/ once we re-acquire the monitor we know if we need to throw IE or not.\n+  ObjectWaiter::TStates state = node->TState;\n+  bool was_notified = state == ObjectWaiter::TS_ENTER || state == ObjectWaiter::TS_CXQ;\n+  assert(was_notified || state == ObjectWaiter::TS_RUN, \"\");\n+  node->_interrupted = !was_notified && current->is_interrupted(false);\n+\n+  \/\/ Post JFR and JVMTI events.\n+  EventJavaMonitorWait event;\n+  if (event.should_commit() || JvmtiExport::should_post_monitor_waited()) {\n+    vthread_monitor_waited_event(current, node, cont, &event, !was_notified && !node->_interrupted);\n+  }\n+\n+  \/\/ Mark that we are at reenter so that we don't call this method again.\n+  node->_at_reenter = true;\n+\n+  if (!was_notified) {\n+    bool acquired = VThreadMonitorEnter(current, node);\n+    if (acquired) {\n+      guarantee(_recursions == 0, \"invariant\");\n+      _recursions = node->_recursions;   \/\/ restore the old recursion count\n+      _waiters--;                        \/\/ decrement the number of waiters\n+\n+      if (node->_interrupted) {\n+        \/\/ We will throw at thaw end after finishing the mount transition.\n+        current->set_pending_interrupted_exception(true);\n+      }\n+\n+      delete node;\n+      stackChunkOop chunk  = cont.tail();\n+      chunk->set_object_waiter(nullptr);\n+      return true;\n+    }\n+  } else {\n+    \/\/ Already moved to _cxq or _EntryList by notifier, so just add to contentions.\n+    add_to_contentions(1);\n+  }\n+  return false;\n+}\n+\n@@ -1903,2 +2237,2 @@\n-  if (_succ == nullptr) {\n-    _succ = current;\n+  if (!has_successor()) {\n+    set_successor(current);\n@@ -1906,1 +2240,1 @@\n-  Thread* prv = nullptr;\n+  int64_t prv = NO_OWNER;\n@@ -1944,4 +2278,4 @@\n-    JavaThread* ox = static_cast<JavaThread*>(owner_raw());\n-    if (ox == nullptr) {\n-      ox = static_cast<JavaThread*>(try_set_owner_from(nullptr, current));\n-      if (ox == nullptr) {\n+    int64_t ox = owner_raw();\n+    if (ox == NO_OWNER) {\n+      ox = try_set_owner_from(NO_OWNER, current);\n+      if (ox == NO_OWNER) {\n@@ -1950,2 +2284,2 @@\n-        if (_succ == current) {\n-          _succ = nullptr;\n+        if (has_successor(current)) {\n+          clear_successor();\n@@ -1974,1 +2308,1 @@\n-    if (ox != prv && prv != nullptr) {\n+    if (ox != prv && prv != NO_OWNER) {\n@@ -1979,2 +2313,2 @@\n-    if (_succ == nullptr) {\n-      _succ = current;\n+    if (!has_successor()) {\n+      set_successor(current);\n@@ -1989,2 +2323,2 @@\n-  if (_succ == current) {\n-    _succ = nullptr;\n+  if (has_successor(current)) {\n+    clear_successor();\n@@ -2011,1 +2345,2 @@\n-  _notified = 0;\n+  _thread   = current;\n+  _monitor  = nullptr;\n@@ -2013,0 +2348,1 @@\n+  _recursions = 0;\n@@ -2014,2 +2350,4 @@\n-  _thread   = current;\n-  _event    = _thread->_ParkEvent;\n+  _notified = false;\n+  _is_wait  = false;\n+  _at_reenter = false;\n+  _interrupted = false;\n@@ -2017,1 +2355,17 @@\n-  assert(_event != nullptr, \"invariant\");\n+}\n+\n+ObjectWaiter::ObjectWaiter(oop vthread, ObjectMonitor* mon) : ObjectWaiter(nullptr) {\n+  assert(oopDesc::is_oop(vthread), \"\");\n+  _vthread = OopHandle(JavaThread::thread_oop_storage(), vthread);\n+  _monitor = mon;\n+}\n+\n+ObjectWaiter::~ObjectWaiter() {\n+  if (is_vthread()) {\n+    assert(vthread() != nullptr, \"\");\n+    _vthread.release(JavaThread::thread_oop_storage());\n+  }\n+}\n+\n+oop ObjectWaiter::vthread() const {\n+  return _vthread.resolve();\n@@ -2135,0 +2489,6 @@\n+\/\/ We can't call this during Initialize() because BarrierSet needs to be set.\n+void ObjectMonitor::Initialize2() {\n+  _vthread_cxq_head = OopHandle(JavaThread::thread_oop_storage(), nullptr);\n+  _vthread_unparker_ParkEvent = ParkEvent::Allocate(nullptr);\n+}\n+\n@@ -2138,1 +2498,1 @@\n-            \",recursions=\" INTX_FORMAT \",owner=\" INTPTR_FORMAT \"}\",\n+            \",recursions=\" INTX_FORMAT \",owner=\" INT64_FORMAT \"}\",\n@@ -2140,1 +2500,1 @@\n-            p2i(owner()));\n+            owner());\n@@ -2183,1 +2543,1 @@\n-  st->print_cr(\"  _owner = \" INTPTR_FORMAT, p2i(owner_raw()));\n+  st->print_cr(\"  _owner = \" INT64_FORMAT, owner_raw());\n@@ -2194,1 +2554,1 @@\n-  st->print_cr(\"  _succ = \" INTPTR_FORMAT, p2i(_succ));\n+  st->print_cr(\"  _succ = \" INT64_FORMAT, _succ);\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":525,"deletions":165,"binary":false,"changes":690,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"oops\/oopHandle.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -38,0 +40,2 @@\n+class BasicLock;\n+class ContinuationWrapper;\n@@ -39,5 +43,0 @@\n-\/\/ ObjectWaiter serves as a \"proxy\" or surrogate thread.\n-\/\/ TODO-FIXME: Eliminate ObjectWaiter and use the thread-specific\n-\/\/ ParkEvent instead.  Beware, however, that the JVMTI code\n-\/\/ knows about ObjectWaiters, so we'll have to reconcile that code.\n-\/\/ See next_waiter(), first_waiter(), etc.\n@@ -45,1 +44,1 @@\n-class ObjectWaiter : public StackObj {\n+class ObjectWaiter : public CHeapObj<mtThread> {\n@@ -47,1 +46,1 @@\n-  enum TStates { TS_UNDEF, TS_READY, TS_RUN, TS_WAIT, TS_ENTER, TS_CXQ };\n+  enum TStates : uint8_t { TS_UNDEF, TS_READY, TS_RUN, TS_WAIT, TS_ENTER, TS_CXQ };\n@@ -50,4 +49,5 @@\n-  JavaThread*   _thread;\n-  uint64_t      _notifier_tid;\n-  ParkEvent *   _event;\n-  volatile int  _notified;\n+  JavaThread*     _thread;\n+  OopHandle      _vthread;\n+  ObjectMonitor* _monitor;\n+  uint64_t  _notifier_tid;\n+  int         _recursions;\n@@ -55,1 +55,5 @@\n-  bool          _active;           \/\/ Contention monitoring is enabled\n+  volatile bool _notified;\n+  bool           _is_wait;\n+  bool        _at_reenter;\n+  bool       _interrupted;\n+  bool            _active;    \/\/ Contention monitoring is enabled\n@@ -58,1 +62,11 @@\n-\n+  ObjectWaiter(oop vthread, ObjectMonitor* mon);\n+  ~ObjectWaiter();\n+  JavaThread* thread()      const { return _thread; }\n+  bool is_vthread()         const { return _thread == nullptr; }\n+  uint8_t state()           const { return TState; }\n+  ObjectMonitor* monitor()  const { return _monitor; }\n+  bool is_monitorenter()    const { return !_is_wait; }\n+  bool is_wait()            const { return _is_wait; }\n+  bool notified()           const { return _notified; }\n+  bool at_reenter()         const { return _at_reenter; }\n+  oop vthread() const;\n@@ -135,0 +149,5 @@\n+  \/\/ List of j.l.VirtualThread waiting to be unblocked by unblocker thread.\n+  static OopHandle _vthread_cxq_head;\n+  \/\/ ParkEvent of unblocker thread.\n+  static ParkEvent* _vthread_unparker_ParkEvent;\n+\n@@ -149,13 +168,0 @@\n-  \/\/ Used by async deflation as a marker in the _owner field.\n-  \/\/ Note that the choice of the two markers is peculiar:\n-  \/\/ - They need to represent values that cannot be pointers. In particular,\n-  \/\/   we achieve this by using the lowest two bits.\n-  \/\/ - ANONYMOUS_OWNER should be a small value, it is used in generated code\n-  \/\/   and small values encode much better.\n-  \/\/ - We test for anonymous owner by testing for the lowest bit, therefore\n-  \/\/   DEFLATER_MARKER must *not* have that bit set.\n-  static const uintptr_t DEFLATER_MARKER_VALUE = 2;\n-  #define DEFLATER_MARKER reinterpret_cast<void*>(DEFLATER_MARKER_VALUE)\n- public:\n-  \/\/ NOTE: Typed as uintptr_t so that we can pick it up in SA, via vmStructs.\n-  static const uintptr_t ANONYMOUS_OWNER = 1;\n@@ -163,2 +169,3 @@\n- private:\n-  static void* anon_owner_ptr() { return reinterpret_cast<void*>(ANONYMOUS_OWNER); }\n+  static const int64_t NO_OWNER = 0;\n+  static const int64_t ANONYMOUS_OWNER = 1;\n+  static const int64_t DEFLATER_MARKER = 2;\n@@ -166,1 +173,1 @@\n-  void* volatile _owner;            \/\/ pointer to owning thread OR BasicLock\n+  int64_t volatile _owner;  \/\/ Either tid of owner, NO_OWNER, ANONYMOUS_OWNER or DEFLATER_MARKER.\n@@ -181,1 +188,1 @@\n-  JavaThread* volatile _succ;       \/\/ Heir presumptive thread - used for futile wakeup throttling\n+  int64_t volatile _succ;           \/\/ Heir presumptive thread - used for futile wakeup throttling\n@@ -194,0 +201,3 @@\n+  \/\/ Used in LM_LEGACY mode to store BasicLock* in case of inflation by contending thread.\n+  BasicLock* volatile _stack_locker;\n+\n@@ -197,0 +207,4 @@\n+  static void Initialize2();\n+\n+  static OopHandle& vthread_cxq_head() { return _vthread_cxq_head; }\n+  static ParkEvent* vthread_unparker_ParkEvent() { return _vthread_unparker_ParkEvent; }\n@@ -252,1 +266,1 @@\n-    \/\/ TODO-FIXME: assert _owner == null implies _recursions = 0\n+    \/\/ TODO-FIXME: assert _owner == NO_OWNER implies _recursions = 0\n@@ -269,2 +283,8 @@\n-  void*     owner() const;  \/\/ Returns null if DEFLATER_MARKER is observed.\n-  void*     owner_raw() const;\n+  int64_t   owner() const;  \/\/ Returns NO_OWNER if DEFLATER_MARKER is observed.\n+  int64_t   owner_raw() const;\n+\n+  \/\/ These methods return the value we set in _owner when acquiring\n+  \/\/ the monitor with the given thread\/vthread (tid).\n+  static int64_t owner_from(JavaThread* thread);\n+  static int64_t owner_from(oop vthread);\n+\n@@ -275,2 +295,2 @@\n-  \/\/ Clear _owner field; current value must match old_value.\n-  void      release_clear_owner(void* old_value);\n+  \/\/ Clear _owner field; current value must match thread's tid.\n+  void      release_clear_owner(JavaThread* thread);\n@@ -278,3 +298,3 @@\n-  void      set_owner_from(void* old_value, void* new_value);\n-  \/\/ Simply set _owner field to current; current value must match basic_lock_p.\n-  void      set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current);\n+  void      set_owner_from_raw(int64_t old_value, int64_t new_value);\n+  \/\/ Same as above but uses tid of current as new value.\n+  void      set_owner_from(int64_t old_value, JavaThread* current);\n@@ -284,4 +304,21 @@\n-  void*     try_set_owner_from(void* old_value, void* new_value);\n-\n-  void set_owner_anonymous() {\n-    set_owner_from(nullptr, anon_owner_ptr());\n+  int64_t   try_set_owner_from_raw(int64_t old_value, int64_t new_value);\n+  \/\/ Same as above but uses tid of current as new_value.\n+  int64_t   try_set_owner_from(int64_t old_value, JavaThread* current);\n+\n+  \/\/ Methods to check and set _succ. The successor is the thread selected\n+  \/\/ from _cxq\/_EntryList by the current owner when releasing the monitor,\n+  \/\/ to run again and re-try acquiring the monitor. It is used to avoid\n+  \/\/ unnecessary wake-ups if there is already a successor set.\n+  bool      has_successor();\n+  bool      has_successor(JavaThread* thread);\n+  void      set_successor(JavaThread* thread);\n+  void      set_successor(oop vthread);\n+  void      clear_successor();\n+\n+  \/\/ Returns true if _owner field == tid of thread, false otherwise.\n+  bool has_owner(JavaThread* thread) const { return owner() == owner_from(thread); }\n+  \/\/ Set _owner field to tid of thread; current value must be NO_OWNER.\n+  void set_owner(JavaThread* thread) { set_owner_from(NO_OWNER, thread); }\n+  \/\/ Try to set _owner field from NO_OWNER to tid of thread.\n+  bool try_set_owner(JavaThread* thread) {\n+    return try_set_owner_from(NO_OWNER, thread) == NO_OWNER;\n@@ -290,2 +327,3 @@\n-  bool is_owner_anonymous() const {\n-    return owner_raw() == anon_owner_ptr();\n+  bool has_anonymous_owner() const { return owner_raw() == ANONYMOUS_OWNER; }\n+  void set_anonymous_owner() {\n+    set_owner_from_raw(NO_OWNER, ANONYMOUS_OWNER);\n@@ -293,3 +331,2 @@\n-\n-  void set_owner_from_anonymous(Thread* owner) {\n-    set_owner_from(anon_owner_ptr(), owner);\n+  void set_owner_from_anonymous(JavaThread* owner) {\n+    set_owner_from(ANONYMOUS_OWNER, owner);\n@@ -298,0 +335,4 @@\n+  \/\/ Get and set _stack_locker.\n+  BasicLock* stack_locker() const;\n+  void set_stack_locker(BasicLock* locker);\n+\n@@ -303,2 +344,0 @@\n-  int       waiters() const;\n-\n@@ -311,0 +350,1 @@\n+  int waiters() const;\n@@ -354,0 +394,1 @@\n+  bool      resume_operation(JavaThread* current, ObjectWaiter* node, ContinuationWrapper& cont);\n@@ -376,0 +417,4 @@\n+  bool      VThreadMonitorEnter(JavaThread* current, ObjectWaiter* node = nullptr);\n+  void      VThreadWait(JavaThread* current, jlong millis);\n+  bool      VThreadWaitReenter(JavaThread* current, ObjectWaiter* node, ContinuationWrapper& cont);\n+  void      VThreadEpilog(JavaThread* current, ObjectWaiter* node);\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":94,"deletions":49,"binary":false,"changes":143,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"runtime\/threadIdentifier.hpp\"\n@@ -40,0 +42,12 @@\n+inline int64_t ObjectMonitor::owner_from(JavaThread* thread) {\n+  int64_t tid = thread->lock_id();\n+  assert(tid >= 3 && tid < ThreadIdentifier::current(), \"must be reasonable\");\n+  return tid;\n+}\n+\n+inline int64_t ObjectMonitor::owner_from(oop vthread) {\n+  int64_t tid = java_lang_Thread::thread_id(vthread);\n+  assert(tid >= 3 && tid < ThreadIdentifier::current(), \"must be reasonable\");\n+  return tid;\n+}\n+\n@@ -41,2 +55,2 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    if (is_owner_anonymous()) {\n+  if (has_anonymous_owner()) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -45,1 +59,1 @@\n-      return current == owner_raw();\n+      return current->is_lock_owned((address)stack_locker());\n@@ -48,4 +62,1 @@\n-    void* owner = owner_raw();\n-    if (current == owner || current->is_lock_owned((address)owner)) {\n-      return true;\n-    }\n+    return has_owner(current);\n@@ -95,2 +106,2 @@\n-  void* owner = owner_raw();\n-  return owner != nullptr && owner != DEFLATER_MARKER;\n+  int64_t owner = owner_raw();\n+  return owner != NO_OWNER && owner != DEFLATER_MARKER;\n@@ -99,4 +110,4 @@\n-\/\/ Returns null if DEFLATER_MARKER is observed.\n-inline void* ObjectMonitor::owner() const {\n-  void* owner = owner_raw();\n-  return owner != DEFLATER_MARKER ? owner : nullptr;\n+\/\/ Returns NO_OWNER if DEFLATER_MARKER is observed.\n+inline int64_t ObjectMonitor::owner() const {\n+  int64_t owner = owner_raw();\n+  return owner != DEFLATER_MARKER ? owner : NO_OWNER;\n@@ -105,1 +116,1 @@\n-inline void* ObjectMonitor::owner_raw() const {\n+inline int64_t ObjectMonitor::owner_raw() const {\n@@ -109,0 +120,8 @@\n+inline BasicLock* ObjectMonitor::stack_locker() const {\n+  return Atomic::load(&_stack_locker);\n+}\n+\n+inline void ObjectMonitor::set_stack_locker(BasicLock* locker) {\n+  Atomic::store(&_stack_locker, locker);\n+}\n+\n@@ -110,2 +129,0 @@\n-\/\/ This accessor is called when we really need to know if the owner\n-\/\/ field == DEFLATER_MARKER and any non-null value won't do the trick.\n@@ -138,1 +155,2 @@\n-inline void ObjectMonitor::release_clear_owner(void* old_value) {\n+inline void ObjectMonitor::release_clear_owner(JavaThread* old_owner) {\n+  int64_t old_value = owner_from(old_owner);\n@@ -140,3 +158,3 @@\n-  void* prev = Atomic::load(&_owner);\n-  assert(prev == old_value, \"unexpected prev owner=\" INTPTR_FORMAT\n-         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(old_value));\n+  int64_t prev = Atomic::load(&_owner);\n+  assert(prev == old_value, \"unexpected prev owner=\" INT64_FORMAT\n+         \", expected=\" INT64_FORMAT, prev, old_value);\n@@ -144,1 +162,1 @@\n-  Atomic::release_store(&_owner, (void*)nullptr);\n+  Atomic::release_store(&_owner, NO_OWNER);\n@@ -146,2 +164,2 @@\n-                                     INTPTR_FORMAT \", old_value=\" INTPTR_FORMAT,\n-                                     p2i(this), p2i(old_value));\n+                                     INTPTR_FORMAT \", old_value=\" INT64_FORMAT,\n+                                     p2i(this), old_value);\n@@ -152,1 +170,1 @@\n-inline void ObjectMonitor::set_owner_from(void* old_value, void* new_value) {\n+inline void ObjectMonitor::set_owner_from_raw(int64_t old_value, int64_t new_value) {\n@@ -154,3 +172,4 @@\n-  void* prev = Atomic::load(&_owner);\n-  assert(prev == old_value, \"unexpected prev owner=\" INTPTR_FORMAT\n-         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(old_value));\n+  int64_t prev = Atomic::load(&_owner);\n+  assert((int64_t)prev < ThreadIdentifier::current(), \"must be reasonable\");\n+  assert(prev == old_value, \"unexpected prev owner=\" INT64_FORMAT\n+         \", expected=\" INT64_FORMAT, prev, old_value);\n@@ -160,3 +179,3 @@\n-                                     INTPTR_FORMAT \", old_value=\" INTPTR_FORMAT\n-                                     \", new_value=\" INTPTR_FORMAT, p2i(this),\n-                                     p2i(old_value), p2i(new_value));\n+                                     INTPTR_FORMAT \", old_value=\" INT64_FORMAT\n+                                     \", new_value=\" INT64_FORMAT, p2i(this),\n+                                     old_value, new_value);\n@@ -165,14 +184,2 @@\n-\/\/ Simply set _owner field to self; current value must match basic_lock_p.\n-inline void ObjectMonitor::set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current) {\n-#ifdef ASSERT\n-  void* prev = Atomic::load(&_owner);\n-  assert(prev == basic_lock_p, \"unexpected prev owner=\" INTPTR_FORMAT\n-         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(basic_lock_p));\n-#endif\n-  \/\/ Non-null owner field to non-null owner field is safe without\n-  \/\/ cmpxchg() as long as all readers can tolerate either flavor.\n-  Atomic::store(&_owner, current);\n-  log_trace(monitorinflation, owner)(\"set_owner_from_BasicLock(): mid=\"\n-                                     INTPTR_FORMAT \", basic_lock_p=\"\n-                                     INTPTR_FORMAT \", new_value=\" INTPTR_FORMAT,\n-                                     p2i(this), p2i(basic_lock_p), p2i(current));\n+inline void ObjectMonitor::set_owner_from(int64_t old_value, JavaThread* current) {\n+  set_owner_from_raw(old_value, owner_from(current));\n@@ -184,2 +191,3 @@\n-inline void* ObjectMonitor::try_set_owner_from(void* old_value, void* new_value) {\n-  void* prev = Atomic::cmpxchg(&_owner, old_value, new_value);\n+inline int64_t ObjectMonitor::try_set_owner_from_raw(int64_t old_value, int64_t new_value) {\n+  assert((int64_t)new_value < ThreadIdentifier::current(), \"must be reasonable\");\n+  int64_t prev = Atomic::cmpxchg(&_owner, old_value, new_value);\n@@ -188,3 +196,3 @@\n-                                       INTPTR_FORMAT \", prev=\" INTPTR_FORMAT\n-                                       \", new=\" INTPTR_FORMAT, p2i(this),\n-                                       p2i(prev), p2i(new_value));\n+                                       INTPTR_FORMAT \", prev=\" INT64_FORMAT\n+                                       \", new=\" INT64_FORMAT, p2i(this),\n+                                       prev, new_value);\n@@ -195,0 +203,24 @@\n+inline int64_t ObjectMonitor::try_set_owner_from(int64_t old_value, JavaThread* current) {\n+  return try_set_owner_from_raw(old_value, owner_from(current));\n+}\n+\n+inline bool ObjectMonitor::has_successor() {\n+  return Atomic::load(&_succ) != NO_OWNER;\n+}\n+\n+inline bool ObjectMonitor::has_successor(JavaThread* thread) {\n+  return owner_from(thread) == Atomic::load(&_succ);\n+}\n+\n+inline void ObjectMonitor::set_successor(JavaThread* thread) {\n+  Atomic::store(&_succ, owner_from(thread));\n+}\n+\n+inline void ObjectMonitor::set_successor(oop vthread) {\n+  Atomic::store(&_succ, java_lang_Thread::thread_id(vthread));\n+}\n+\n+inline void ObjectMonitor::clear_successor() {\n+  Atomic::store(&_succ, NO_OWNER);\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":81,"deletions":49,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -1974,1 +1974,1 @@\n-    assert(m->owner_raw() != current, \"must be\");\n+    assert(!m->has_owner(current), \"must be\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -515,0 +515,4 @@\n+  static VMReg thread_register();\n+\n+  static void continuation_enter_cleanup(MacroAssembler* masm);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -78,0 +78,1 @@\n+  inline void get_cb();\n@@ -101,1 +102,0 @@\n-  inline void get_cb();\n","filename":"src\/hotspot\/share\/runtime\/stackChunkFrameStream.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -109,1 +109,1 @@\n-  return cb() != nullptr && (_cb->is_safepoint_stub() || _cb->is_runtime_stub());\n+  return cb() != nullptr && _cb->is_runtime_stub();\n@@ -199,1 +199,8 @@\n-  return is_interpreted() ? interpreter_frame_num_oops() : oopmap()->num_oops();\n+  if (is_interpreted()) {\n+    return interpreter_frame_num_oops();\n+  } else if (is_compiled()) {\n+    return oopmap()->num_oops();\n+  } else {\n+    assert(is_stub(), \"invariant\");\n+    return 0;\n+  }\n@@ -211,1 +218,1 @@\n-  bool safepoint = is_stub();\n+  bool is_runtime_stub = is_stub();\n@@ -235,2 +242,3 @@\n-  if (safepoint && cb() != nullptr) { \/\/ there's no post-call nop and no fast oopmap lookup\n-    _oopmap = cb()->oop_map_for_return_address(pc());\n+  if (is_runtime_stub && cb() != nullptr) { \/\/ there's no post-call nop and no fast oopmap lookup\n+    \/\/ caller could have been deoptimized so use orig_pc()\n+    _oopmap = cb()->oop_map_for_return_address(orig_pc());\n@@ -303,3 +311,2 @@\n-  assert(map->in_cont(), \"\");\n-  assert(map->stack_chunk()() == _chunk, \"\");\n-  if (map->update_map()) {\n+  assert(!map->in_cont() || map->stack_chunk() == _chunk, \"\");\n+  if (map->update_map() && is_stub()) {\n","filename":"src\/hotspot\/share\/runtime\/stackChunkFrameStream.inline.hpp","additions":15,"deletions":8,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -296,1 +296,1 @@\n-BasicLock* StackValue::resolve_monitor_lock(const frame* fr, Location location) {\n+BasicLock* StackValue::resolve_monitor_lock(const frame& fr, Location location) {\n@@ -307,1 +307,1 @@\n-  return (BasicLock*) (fr->unextended_sp() + word_offset);\n+  return (BasicLock*) (fr.unextended_sp() + word_offset);\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -126,1 +126,1 @@\n-  static BasicLock*  resolve_monitor_lock(const frame* fr, Location location);\n+  static BasicLock*  resolve_monitor_lock(const frame& fr, Location location);\n","filename":"src\/hotspot\/share\/runtime\/stackValue.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -189,0 +189,1 @@\n+address StubRoutines::_cont_preempt_stub = nullptr;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -295,0 +295,1 @@\n+  static address _cont_preempt_stub;\n@@ -504,0 +505,1 @@\n+  static address cont_preempt_stub()   { return _cont_preempt_stub; }\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -364,1 +364,1 @@\n-    if (mon->owner() != current) return false;  \/\/ slow-path for IMS exception\n+    if (!mon->has_owner(current)) return false;  \/\/ slow-path for IMS exception\n@@ -427,1 +427,0 @@\n-    JavaThread* const owner = static_cast<JavaThread*>(m->owner_raw());\n@@ -434,1 +433,1 @@\n-    if (owner == current) {\n+    if (m->has_owner(current)) {\n@@ -451,1 +450,1 @@\n-    if (owner == nullptr && m->try_set_owner_from(nullptr, current) == nullptr) {\n+    if (!m->has_owner() && m->try_set_owner(current)) {\n@@ -661,1 +660,1 @@\n-  assert(!monitor->is_owner_anonymous(), \"must not be\");\n+  assert(!monitor->has_anonymous_owner(), \"must not be\");\n@@ -669,0 +668,4 @@\n+  \/\/ Top native frames in the stack will not be seen if we attempt\n+  \/\/ preemption, since we start walking from the last Java anchor.\n+  NoPreemptMark npm(current);\n+\n@@ -720,1 +723,1 @@\n-ObjectLocker::ObjectLocker(Handle obj, JavaThread* thread) {\n+ObjectLocker::ObjectLocker(Handle obj, JavaThread* thread) : _npm(thread) {\n@@ -1168,1 +1171,1 @@\n-    return Threads::owning_thread_from_monitor_owner(t_list, (address) mark.locker());\n+    return Threads::owning_thread_from_stacklock(t_list, (address) mark.locker());\n@@ -1232,1 +1235,1 @@\n-    if (monitor->has_owner() && filter(monitor->owner_raw())) {\n+    if (monitor->has_owner() && filter(monitor)) {\n@@ -1243,1 +1246,8 @@\n-  auto thread_filter = [&](void* owner) { return owner == thread; };\n+  int64_t key = ObjectMonitor::owner_from(thread);\n+  auto thread_filter = [&](ObjectMonitor* monitor) { return monitor->owner() == key; };\n+  return owned_monitors_iterate_filtered(closure, thread_filter);\n+}\n+\n+void ObjectSynchronizer::owned_monitors_iterate(MonitorClosure* closure, oop vthread) {\n+  int64_t key = ObjectMonitor::owner_from(vthread);\n+  auto thread_filter = [&](ObjectMonitor* monitor) { return monitor->owner() == key; };\n@@ -1249,1 +1259,1 @@\n-  auto all_filter = [&](void* owner) { return true; };\n+  auto all_filter = [&](ObjectMonitor* monitor) { return true; };\n@@ -1421,1 +1431,1 @@\n-  return inflate_impl(obj, cause);\n+  return inflate_impl(current->is_Java_thread() ? JavaThread::cast(current) : nullptr, obj, cause);\n@@ -1427,1 +1437,1 @@\n-  return inflate_impl(obj, cause);\n+  return inflate_impl(thread, obj, cause);\n@@ -1430,1 +1440,7 @@\n-ObjectMonitor* ObjectSynchronizer::inflate_impl(oop object, const InflateCause cause) {\n+ObjectMonitor* ObjectSynchronizer::inflate_impl(JavaThread* locking_thread, oop object, const InflateCause cause) {\n+  \/\/ The JavaThread* locking_thread requires that the locking_thread == Thread::current() or\n+  \/\/ is suspended throughout the call by some other mechanism.\n+  \/\/ The thread might be nullptr when called from a non JavaThread. (As may still be\n+  \/\/ the case from FastHashCode). However it is only important for correctness that the\n+  \/\/ thread is set when called from ObjectSynchronizer::enter from the owning thread,\n+  \/\/ ObjectSynchronizer::enter_for from any thread, or ObjectSynchronizer::exit.\n@@ -1438,1 +1454,3 @@\n-    \/\/ *  inflated     - Just return it.\n+    \/\/ *  inflated     - If the ObjectMonitor owner is anonymous and the\n+    \/\/                   locking_thread owns the object lock, then we\n+    \/\/                   make the locking_thread the ObjectMonitor owner.\n@@ -1449,0 +1467,7 @@\n+      if (inf->has_anonymous_owner() && locking_thread != nullptr) {\n+        assert(LockingMode == LM_LEGACY, \"invariant\");\n+        if (locking_thread->is_lock_owned((address)inf->stack_locker())) {\n+          inf->set_stack_locker(nullptr);\n+          inf->set_owner_from_anonymous(locking_thread);\n+        }\n+      }\n@@ -1525,2 +1550,0 @@\n-      \/\/ Optimization: if the mark.locker stack address is associated\n-      \/\/ with this thread we could simply set m->_owner = current.\n@@ -1530,1 +1553,8 @@\n-      m->set_owner_from(nullptr, mark.locker());\n+      if (locking_thread != nullptr && locking_thread->is_lock_owned((address)mark.locker())) {\n+        m->set_owner(locking_thread);\n+      } else {\n+        \/\/ Use ANONYMOUS_OWNER to indicate that the owner is the BasicLock on the stack,\n+        \/\/ and set the stack locker field in the monitor.\n+        m->set_stack_locker(mark.locker());\n+        m->set_anonymous_owner();  \/\/ second\n+      }\n@@ -2053,1 +2083,1 @@\n-                   monitor->is_busy(), hash != 0, monitor->owner() != nullptr,\n+                   monitor->is_busy(), hash != 0, monitor->has_owner(),\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":48,"deletions":18,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -140,1 +140,1 @@\n-  static ObjectMonitor* inflate_impl(oop obj, const InflateCause cause);\n+  static ObjectMonitor* inflate_impl(JavaThread* locking_thread, oop obj, const InflateCause cause);\n@@ -171,2 +171,2 @@\n-  \/\/ Iterate ObjectMonitors where the owner == thread; this does NOT include\n-  \/\/ ObjectMonitors where owner is set to a stack lock address in thread.\n+  \/\/ Iterate ObjectMonitors where the owner is thread; this does NOT include\n+  \/\/ ObjectMonitors where the owner is anonymous.\n@@ -175,0 +175,3 @@\n+  \/\/ Iterate ObjectMonitors where the owner is vthread.\n+  static void owned_monitors_iterate(MonitorClosure* m, oop vthread);\n+\n@@ -232,0 +235,3 @@\n+\/\/ When using ObjectLocker the top native frames in the stack will\n+\/\/ not be seen in case we attempt preemption, since we start walking\n+\/\/ from the last Java anchor, so we disable it with NoPreemptMark.\n@@ -237,0 +243,1 @@\n+  NoPreemptMark _npm;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,9 @@\n-static volatile int64_t next_thread_id = 2; \/\/ starting at 2, excluding the primordial thread id\n+\/\/ starting at 3, excluding reserved values defined in ObjectMonitor.hpp\n+static const int64_t INITIAL_TID = 3;\n+static volatile int64_t next_thread_id = INITIAL_TID;\n+\n+#ifdef ASSERT\n+int64_t ThreadIdentifier::initial() {\n+  return INITIAL_TID;\n+}\n+#endif\n@@ -35,0 +43,4 @@\n+int64_t ThreadIdentifier::current() {\n+  return Atomic::load(&next_thread_id);\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/threadIdentifier.cpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,0 +39,1 @@\n+  static int64_t current();\n@@ -40,0 +41,1 @@\n+  DEBUG_ONLY(static int64_t initial();)\n","filename":"src\/hotspot\/share\/runtime\/threadIdentifier.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -169,0 +169,2 @@\n+  assert(thread->lock_id() == ThreadIdentifier::initial(), \"invariant\");\n+\n@@ -535,0 +537,5 @@\n+  \/\/ Set the lock_id now since we will run Java code before the Thread instance\n+  \/\/ is even created. The same value will be assigned to the Thread instance on init.\n+  main_thread->set_lock_id(ThreadIdentifier::next());\n+  assert(main_thread->lock_id() == ThreadIdentifier::initial(), \"invariant\");\n+\n@@ -584,0 +591,2 @@\n+  ObjectMonitor::Initialize2();\n+\n@@ -1229,15 +1238,2 @@\n-JavaThread *Threads::owning_thread_from_monitor_owner(ThreadsList * t_list,\n-                                                      address owner) {\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Not with new lightweight locking\");\n-  \/\/ null owner means not locked so we can skip the search\n-  if (owner == nullptr) return nullptr;\n-\n-  for (JavaThread* p : *t_list) {\n-    \/\/ first, see if owner is the address of a Java thread\n-    if (owner == (address)p) return p;\n-  }\n-\n-  \/\/ Cannot assert on lack of success here since this function may be\n-  \/\/ used by code that is trying to report useful problem information\n-  \/\/ like deadlock detection.\n-  if (LockingMode == LM_MONITOR) return nullptr;\n+JavaThread *Threads::owning_thread_from_stacklock(ThreadsList * t_list, address basicLock) {\n+  assert(LockingMode == LM_LEGACY, \"Not with new lightweight locking\");\n@@ -1245,4 +1241,0 @@\n-  \/\/ If we didn't find a matching Java thread and we didn't force use of\n-  \/\/ heavyweight monitors, then the owner is the stack address of the\n-  \/\/ Lock Word in the owning Java thread's stack.\n-  \/\/\n@@ -1251,1 +1243,1 @@\n-    if (q->is_lock_owned(owner)) {\n+    if (q->is_lock_owned(basicLock)) {\n@@ -1256,2 +1248,0 @@\n-\n-  \/\/ cannot assert on lack of success here; see above comment\n@@ -1278,2 +1268,2 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    if (monitor->is_owner_anonymous()) {\n+  if (monitor->has_anonymous_owner()) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1282,3 +1272,2 @@\n-      Thread* owner = reinterpret_cast<Thread*>(monitor->owner());\n-      assert(owner == nullptr || owner->is_Java_thread(), \"only JavaThreads own monitors\");\n-      return reinterpret_cast<JavaThread*>(owner);\n+      assert(LockingMode == LM_LEGACY, \"invariant\");\n+      return owning_thread_from_stacklock(t_list, (address)monitor->stack_locker());\n@@ -1287,2 +1276,8 @@\n-    address owner = (address)monitor->owner();\n-    return owning_thread_from_monitor_owner(t_list, owner);\n+    JavaThread* the_owner = nullptr;\n+    for (JavaThread* q : *t_list) {\n+      if (monitor->has_owner(q)) {\n+        the_owner = q;\n+        break;\n+      }\n+    }\n+    return the_owner;\n@@ -1340,10 +1335,9 @@\n-        const oop thread_oop = p->threadObj();\n-        if (thread_oop != nullptr) {\n-          if (p->is_vthread_mounted()) {\n-            const oop vt = p->vthread();\n-            assert(vt != nullptr, \"vthread should not be null when vthread is mounted\");\n-            \/\/ JavaThread._vthread can refer to the carrier thread. Print only if _vthread refers to a virtual thread.\n-            if (vt != thread_oop) {\n-              st->print_cr(\"   Mounted virtual thread #\" INT64_FORMAT, (int64_t)java_lang_Thread::thread_id(vt));\n-              p->print_vthread_stack_on(st);\n-            }\n+        if (p->is_vthread_mounted()) {\n+          st->print(\"   Mounted virtual thread #\");\n+          \/\/ _lock_id is the thread ID of the mounted virtual thread. If it equals\n+          \/\/ the tid of the carrier we caught thread at the start of a temporary\n+          \/\/ transition in VirtualThread.switchToCarrierThread. Ignore that case.\n+          if (p->lock_id() != java_lang_Thread::thread_id(p->threadObj())) {\n+            st->print_cr(INT64_FORMAT, p->lock_id());\n+          } else {\n+            st->print_cr(\"%s\", \"(Unavailable)\");\n@@ -1351,0 +1345,1 @@\n+          p->print_vthread_stack_on(st);\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":34,"deletions":39,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -137,3 +137,2 @@\n-  \/\/ Get owning Java thread from the monitor's owner field.\n-  static JavaThread *owning_thread_from_monitor_owner(ThreadsList * t_list,\n-                                                      address owner);\n+  \/\/ Get owning Java thread from the basicLock address.\n+  static JavaThread *owning_thread_from_stacklock(ThreadsList * t_list, address basicLock);\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -283,0 +283,2 @@\n+  bool heap_frame = stack_chunk() != nullptr;\n+  frame f = !heap_frame ? _fr : stack_chunk()->derelativize(_fr);\n@@ -284,6 +286,5 @@\n-  if (stack_chunk() == nullptr) { \/\/ no monitors in continuations\n-    for (BasicObjectLock* current = (fr().previous_monitor_in_interpreter_frame(fr().interpreter_frame_monitor_begin()));\n-        current >= fr().interpreter_frame_monitor_end();\n-        current = fr().previous_monitor_in_interpreter_frame(current)) {\n-      result->push(new MonitorInfo(current->obj(), current->lock(), false, false));\n-    }\n+  for (BasicObjectLock* current = (f.previous_monitor_in_interpreter_frame(f.interpreter_frame_monitor_begin()));\n+      current >= f.interpreter_frame_monitor_end();\n+      current = f.previous_monitor_in_interpreter_frame(current)) {\n+      oop owner = !heap_frame ? current->obj() : StackValue::create_stack_value_from_oop_location(stack_chunk(), (void*)current->obj_adr())->get_obj()();\n+    result->push(new MonitorInfo(owner, current->lock(), false, false));\n","filename":"src\/hotspot\/share\/runtime\/vframe.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -125,0 +125,7 @@\n+    if (Continuation::is_continuation_enterSpecial(_frame)) {\n+      \/\/ This can happen when calling async_get_stack_trace() and catching the target\n+      \/\/ vthread at the JRT_BLOCK_END in freeze_internal() or when posting the Monitor\n+      \/\/ Waited event after target vthread was preempted. Since all continuation frames\n+      \/\/ are freezed we get the top frame from the stackChunk instead.\n+      _frame = Continuation::last_frame(java_lang_VirtualThread::continuation(_thread->vthread()), &_reg_map);\n+    }\n","filename":"src\/hotspot\/share\/runtime\/vframe.inline.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -238,1 +238,1 @@\n-  return StackValue::resolve_monitor_lock(&_fr, location);\n+  return StackValue::resolve_monitor_lock(stack_chunk() == nullptr ? _fr : stack_chunk()->derelativize(_fr), location);\n@@ -287,0 +287,1 @@\n+  if (thread() == nullptr) return result; \/\/ Unmounted continuations have no thread so nothing to do.\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -278,1 +278,1 @@\n-\/\/ Hash table of void* to a list of ObjectMonitor* owned by the JavaThread.\n+\/\/ Hash table of int64_t to a list of ObjectMonitor* owned by the JavaThread.\n@@ -280,1 +280,1 @@\n-\/\/ address in the JavaThread so we use \"void*\".\n+\/\/ address in the JavaThread so we use \"int64_t\".\n@@ -284,1 +284,1 @@\n-  static unsigned int ptr_hash(void* const& s1) {\n+  static unsigned int ptr_hash(int64_t const& s1) {\n@@ -297,1 +297,1 @@\n-  typedef ResourceHashtable<void*, ObjectMonitorLinkedList*, 1031, AnyObj::C_HEAP, mtThread,\n+  typedef ResourceHashtable<int64_t, ObjectMonitorLinkedList*, 1031, AnyObj::C_HEAP, mtThread,\n@@ -303,1 +303,1 @@\n-  void add_list(void* key, ObjectMonitorLinkedList* list) {\n+  void add_list(int64_t key, ObjectMonitorLinkedList* list) {\n@@ -308,1 +308,1 @@\n-  ObjectMonitorLinkedList* get_list(void* key) {\n+  ObjectMonitorLinkedList* get_list(int64_t key) {\n@@ -314,1 +314,1 @@\n-    void* key = monitor->owner();\n+    int64_t key = monitor->owner();\n@@ -338,1 +338,1 @@\n-      bool do_entry(void*& key, ObjectMonitorLinkedList*& list) {\n+      bool do_entry(int64_t& key, ObjectMonitorLinkedList*& list) {\n@@ -353,1 +353,1 @@\n-    if (monitor->is_owner_anonymous()) {\n+    if (monitor->has_anonymous_owner()) {\n@@ -371,1 +371,2 @@\n-    ObjectMonitorLinkedList* list = get_list(thread);\n+    int64_t key = ObjectMonitor::owner_from(thread);\n+    ObjectMonitorLinkedList* list = get_list(key);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":11,"deletions":10,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -668,0 +668,1 @@\n+  nonstatic_field(JavaThread,                  _lock_id,                                      int64_t)                               \\\n@@ -788,1 +789,2 @@\n-  unchecked_nonstatic_field(ObjectMonitor,     _owner,                                        sizeof(void *)) \/* NOTE: no type *\/    \\\n+  unchecked_nonstatic_field(ObjectMonitor,     _owner,                                        int64_t)                               \\\n+  unchecked_nonstatic_field(ObjectMonitor,     _stack_locker,                                 BasicLock*)                            \\\n@@ -2536,0 +2538,1 @@\n+  declare_constant(ObjectMonitor::NO_OWNER)                               \\\n@@ -2537,0 +2540,1 @@\n+  declare_constant(ObjectMonitor::DEFLATER_MARKER)                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -467,17 +467,0 @@\n-          if (currentThread == nullptr) {\n-            \/\/ This function is called at a safepoint so the JavaThread\n-            \/\/ that owns waitingToLockMonitor should be findable, but\n-            \/\/ if it is not findable, then the previous currentThread is\n-            \/\/ blocked permanently. We record this as a deadlock.\n-            num_deadlocks++;\n-\n-            \/\/ add this cycle to the deadlocks list\n-            if (deadlocks == nullptr) {\n-              deadlocks = cycle;\n-            } else {\n-              last->set_next(cycle);\n-            }\n-            last = cycle;\n-            cycle = new DeadlockCycle();\n-            break;\n-          }\n@@ -1056,2 +1039,2 @@\n-        st->print_cr(\"%s UNKNOWN_owner_addr=\" PTR_FORMAT, owner_desc,\n-                  p2i(waitingToLockMonitor->owner()));\n+        st->print_cr(\"%s UNKNOWN_owner_addr=\" INT64_FORMAT, owner_desc,\n+                     waitingToLockMonitor->owner());\n","filename":"src\/hotspot\/share\/services\/threadService.cpp","additions":2,"deletions":19,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-import jdk.internal.misc.Blocker;\n@@ -108,2 +107,0 @@\n-        try {\n-            begin(blocking);\n@@ -111,4 +108,9 @@\n-            do {\n-                long startTime = timedPoll ? System.nanoTime() : 0;\n-                boolean attempted = Blocker.begin(blocking);\n-                try {\n+        if (Thread.currentThread().isVirtual()) {\n+            numEntries = (timedPoll)\n+                    ? timedPoll(TimeUnit.MILLISECONDS.toNanos(to))\n+                    : untimedPoll(blocking);\n+        } else {\n+            try {\n+                begin(blocking);\n+                do {\n+                    long startTime = timedPoll ? System.nanoTime() : 0;\n@@ -116,10 +118,8 @@\n-                } finally {\n-                    Blocker.end(attempted);\n-                }\n-                if (numEntries == IOStatus.INTERRUPTED && timedPoll) {\n-                    \/\/ timed poll interrupted so need to adjust timeout\n-                    long adjust = System.nanoTime() - startTime;\n-                    to -= (int) TimeUnit.NANOSECONDS.toMillis(adjust);\n-                    if (to <= 0) {\n-                        \/\/ timeout expired so no retry\n-                        numEntries = 0;\n+                    if (numEntries == IOStatus.INTERRUPTED && timedPoll) {\n+                        \/\/ timed poll interrupted so need to adjust timeout\n+                        long adjust = System.nanoTime() - startTime;\n+                        to -= (int) TimeUnit.NANOSECONDS.toMillis(adjust);\n+                        if (to <= 0) {\n+                            \/\/ timeout expired so no retry\n+                            numEntries = 0;\n+                        }\n@@ -127,6 +127,4 @@\n-                }\n-            } while (numEntries == IOStatus.INTERRUPTED);\n-            assert IOStatus.check(numEntries);\n-\n-        } finally {\n-            end(blocking);\n+                } while (numEntries == IOStatus.INTERRUPTED);\n+            } finally {\n+                end(blocking);\n+            }\n@@ -134,0 +132,2 @@\n+        assert IOStatus.check(numEntries);\n+\n@@ -138,0 +138,34 @@\n+    \/**\n+     * If blocking, parks the current virtual thread until a file descriptor is polled\n+     * or the thread is interrupted.\n+     *\/\n+    private int untimedPoll(boolean block) throws IOException {\n+        int numEntries = EPoll.wait(epfd, pollArrayAddress, NUM_EPOLLEVENTS, 0);\n+        if (block) {\n+            while (numEntries == 0 && !Thread.currentThread().isInterrupted()) {\n+                Poller.pollSelector(epfd, 0);\n+                numEntries = EPoll.wait(epfd, pollArrayAddress, NUM_EPOLLEVENTS, 0);\n+            }\n+        }\n+        return numEntries;\n+    }\n+\n+    \/**\n+     * Parks the current virtual thread until a file descriptor is polled, or the thread\n+     * is interrupted, for up to the specified waiting time.\n+     *\/\n+    private int timedPoll(long nanos) throws IOException {\n+        long startNanos = System.nanoTime();\n+        int numEntries = EPoll.wait(epfd, pollArrayAddress, NUM_EPOLLEVENTS, 0);\n+        while (numEntries == 0 && !Thread.currentThread().isInterrupted()) {\n+            long remainingNanos = nanos - (System.nanoTime() - startNanos);\n+            if (remainingNanos <= 0) {\n+                \/\/ timeout\n+                break;\n+            }\n+            Poller.pollSelector(epfd, remainingNanos);\n+            numEntries = EPoll.wait(epfd, pollArrayAddress, NUM_EPOLLEVENTS, 0);\n+        }\n+        return numEntries;\n+    }\n+\n","filename":"src\/java.base\/linux\/classes\/sun\/nio\/ch\/EPollSelectorImpl.java","additions":57,"deletions":23,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-import jdk.internal.misc.Blocker;\n@@ -112,2 +111,0 @@\n-        try {\n-            begin(blocking);\n@@ -115,4 +112,9 @@\n-            do {\n-                long startTime = timedPoll ? System.nanoTime() : 0;\n-                boolean attempted = Blocker.begin(blocking);\n-                try {\n+        if (Thread.currentThread().isVirtual()) {\n+            numEntries = (timedPoll)\n+                    ? timedPoll(TimeUnit.MILLISECONDS.toNanos(to))\n+                    : untimedPoll(blocking);\n+        } else {\n+            try {\n+                begin(blocking);\n+                do {\n+                    long startTime = timedPoll ? System.nanoTime() : 0;\n@@ -120,10 +122,8 @@\n-                } finally {\n-                    Blocker.end(attempted);\n-                }\n-                if (numEntries == IOStatus.INTERRUPTED && timedPoll) {\n-                    \/\/ timed poll interrupted so need to adjust timeout\n-                    long adjust = System.nanoTime() - startTime;\n-                    to -= TimeUnit.NANOSECONDS.toMillis(adjust);\n-                    if (to <= 0) {\n-                        \/\/ timeout expired so no retry\n-                        numEntries = 0;\n+                    if (numEntries == IOStatus.INTERRUPTED && timedPoll) {\n+                        \/\/ timed poll interrupted so need to adjust timeout\n+                        long adjust = System.nanoTime() - startTime;\n+                        to -= TimeUnit.NANOSECONDS.toMillis(adjust);\n+                        if (to <= 0) {\n+                            \/\/ timeout expired so no retry\n+                            numEntries = 0;\n+                        }\n@@ -131,6 +131,4 @@\n-                }\n-            } while (numEntries == IOStatus.INTERRUPTED);\n-            assert IOStatus.check(numEntries);\n-\n-        } finally {\n-            end(blocking);\n+                } while (numEntries == IOStatus.INTERRUPTED);\n+            } finally {\n+                end(blocking);\n+            }\n@@ -138,0 +136,2 @@\n+        assert IOStatus.check(numEntries);\n+\n@@ -142,0 +142,34 @@\n+    \/**\n+     * If blocking, parks the current virtual thread until a file descriptor is polled\n+     * or the thread is interrupted.\n+     *\/\n+    private int untimedPoll(boolean block) throws IOException {\n+        int numEntries = KQueue.poll(kqfd, pollArrayAddress, MAX_KEVENTS, 0);\n+        if (block) {\n+            while (numEntries == 0 && !Thread.currentThread().isInterrupted()) {\n+                Poller.pollSelector(kqfd, 0);\n+                numEntries = KQueue.poll(kqfd, pollArrayAddress, MAX_KEVENTS, 0);\n+            }\n+        }\n+        return numEntries;\n+    }\n+\n+    \/**\n+     * Parks the current virtual thread until a file descriptor is polled, or the thread\n+     * is interrupted, for up to the specified waiting time.\n+     *\/\n+    private int timedPoll(long nanos) throws IOException {\n+        long startNanos = System.nanoTime();\n+        int numEntries = KQueue.poll(kqfd, pollArrayAddress, MAX_KEVENTS, 0);\n+        while (numEntries == 0 && !Thread.currentThread().isInterrupted()) {\n+            long remainingNanos = nanos - (System.nanoTime() - startNanos);\n+            if (remainingNanos <= 0) {\n+                \/\/ timeout\n+                break;\n+            }\n+            Poller.pollSelector(kqfd, remainingNanos);\n+            numEntries = KQueue.poll(kqfd, pollArrayAddress, MAX_KEVENTS, 0);\n+        }\n+        return numEntries;\n+    }\n+\n","filename":"src\/java.base\/macosx\/classes\/sun\/nio\/ch\/KQueueSelectorImpl.java","additions":57,"deletions":23,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -162,10 +162,2 @@\n-    public void writeTo(OutputStream out) throws IOException {\n-        if (Thread.currentThread().isVirtual()) {\n-            byte[] bytes;\n-            synchronized (this) {\n-                bytes = Arrays.copyOf(buf, count);\n-            }\n-            out.write(bytes);\n-        } else synchronized (this) {\n-            out.write(buf, 0, count);\n-        }\n+    public synchronized void writeTo(OutputStream out) throws IOException {\n+        out.write(buf, 0, count);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ByteArrayOutputStream.java","additions":2,"deletions":10,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -28,1 +28,0 @@\n-import jdk.internal.misc.Blocker;\n@@ -377,3 +376,2 @@\n-        if (!Thread.currentThread().isVirtual()) {\n-            wait0(timeoutMillis);\n-            return;\n+        if (timeoutMillis < 0) {\n+            throw new IllegalArgumentException(\"timeout value is negative\");\n@@ -382,3 +380,13 @@\n-        \/\/ virtual thread waiting\n-        boolean attempted = Blocker.begin();\n-        try {\n+        if (Thread.currentThread() instanceof VirtualThread vthread) {\n+            try {\n+                wait0(timeoutMillis);\n+            } catch (InterruptedException e) {\n+                \/\/ virtual thread's interrupt status needs to be cleared\n+                vthread.getAndClearInterrupt();\n+                throw e;\n+            } finally {\n+                if (timeoutMillis > 0) {\n+                    vthread.cancelWaitTimeout();\n+                }\n+            }\n+        } else {\n@@ -386,6 +394,0 @@\n-        } catch (InterruptedException e) {\n-            \/\/ virtual thread's interrupt status needs to be cleared\n-            Thread.currentThread().getAndClearInterrupt();\n-            throw e;\n-        } finally {\n-            Blocker.end(attempted);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Object.java","additions":15,"deletions":13,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -1,151 +0,0 @@\n-\/*\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-package java.lang;\n-\n-import java.io.PrintStream;\n-import java.security.AccessController;\n-import java.security.PrivilegedAction;\n-import java.util.LinkedHashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Objects;\n-import java.util.Set;\n-import java.util.stream.Collectors;\n-import static java.lang.StackWalker.Option.*;\n-import jdk.internal.access.JavaIOPrintStreamAccess;\n-import jdk.internal.access.SharedSecrets;\n-import jdk.internal.misc.InternalLock;\n-import jdk.internal.vm.Continuation;\n-\n-\/**\n- * Helper class to print the virtual thread stack trace when pinned.\n- *\n- * The class maintains a ClassValue with the hashes of stack traces that are pinned by\n- * code in that Class. This is used to avoid printing the same stack trace many times.\n- *\/\n-class PinnedThreadPrinter {\n-    private static final JavaIOPrintStreamAccess JIOPSA = SharedSecrets.getJavaIOPrintStreamAccess();\n-    private static final StackWalker STACK_WALKER;\n-    static {\n-        var options = Set.of(SHOW_REFLECT_FRAMES, RETAIN_CLASS_REFERENCE);\n-        PrivilegedAction<StackWalker> pa = () ->\n-            LiveStackFrame.getStackWalker(options, VirtualThread.continuationScope());\n-        @SuppressWarnings(\"removal\")\n-        var stackWalker = AccessController.doPrivileged(pa);\n-        STACK_WALKER = stackWalker;\n-    }\n-\n-    private static final ClassValue<Hashes> HASHES = new ClassValue<>() {\n-        @Override\n-        protected Hashes computeValue(Class<?> type) {\n-            return new Hashes();\n-        }\n-    };\n-\n-    @SuppressWarnings(\"serial\")\n-    private static class Hashes extends LinkedHashMap<Integer, Boolean> {\n-        boolean add(int hash) {\n-            return (putIfAbsent(hash, Boolean.TRUE) == null);\n-        }\n-        @Override\n-        protected boolean removeEldestEntry(Map.Entry<Integer, Boolean> oldest) {\n-            \/\/ limit number of hashes\n-            return size() > 8;\n-        }\n-    }\n-\n-    \/**\n-     * Returns a hash of the given stack trace. The hash is based on the class,\n-     * method and bytecode index.\n-     *\/\n-    private static int hash(List<LiveStackFrame> stack) {\n-        int hash = 0;\n-        for (LiveStackFrame frame : stack) {\n-            hash = (31 * hash) + Objects.hash(frame.getDeclaringClass(),\n-                    frame.getMethodName(),\n-                    frame.getByteCodeIndex());\n-        }\n-        return hash;\n-    }\n-\n-    \/**\n-     * Returns true if the frame is native, a class initializer, or holds monitors.\n-     *\/\n-    private static boolean isInterestingFrame(LiveStackFrame f) {\n-        return f.isNativeMethod()\n-                || \"<clinit>\".equals(f.getMethodName())\n-                || (f.getMonitors().length > 0);\n-    }\n-\n-    \/**\n-     * Prints the current thread's stack trace.\n-     *\n-     * @param printAll true to print all stack frames, false to only print the\n-     *        frames that are native or holding a monitor\n-     *\/\n-    static void printStackTrace(PrintStream out, Continuation.Pinned reason, boolean printAll) {\n-        List<LiveStackFrame> stack = STACK_WALKER.walk(s ->\n-            s.map(f -> (LiveStackFrame) f)\n-                    .filter(f -> f.getDeclaringClass() != PinnedThreadPrinter.class)\n-                    .collect(Collectors.toList())\n-        );\n-        Object lockObj = JIOPSA.lock(out);\n-        if (lockObj instanceof InternalLock lock && lock.tryLock()) {\n-            try {\n-                \/\/ find the closest frame that is causing the thread to be pinned\n-                stack.stream()\n-                    .filter(f -> isInterestingFrame(f))\n-                    .map(LiveStackFrame::getDeclaringClass)\n-                    .findFirst()\n-                    .ifPresentOrElse(klass -> {\n-                        \/\/ print the stack trace if not already seen\n-                        int hash = hash(stack);\n-                        if (HASHES.get(klass).add(hash)) {\n-                            printStackTrace(out, reason, stack, printAll);\n-                        }\n-                    }, () -> printStackTrace(out, reason, stack, true));  \/\/ not found\n-\n-            } finally {\n-                lock.unlock();\n-            }\n-        }\n-    }\n-\n-    private static void printStackTrace(PrintStream out,\n-                                        Continuation.Pinned reason,\n-                                        List<LiveStackFrame> stack,\n-                                        boolean printAll) {\n-        out.format(\"%s reason:%s%n\", Thread.currentThread(), reason);\n-        for (LiveStackFrame frame : stack) {\n-            var ste = frame.toStackTraceElement();\n-            int monitorCount = frame.getMonitors().length;\n-            if (monitorCount > 0) {\n-                out.format(\"    %s <== monitors:%d%n\", ste, monitorCount);\n-            } else if (printAll || isInterestingFrame(frame)) {\n-                out.format(\"    %s%n\", ste);\n-            }\n-        }\n-    }\n-}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/PinnedThreadPrinter.java","additions":0,"deletions":151,"binary":false,"changes":151,"status":"deleted"},{"patch":"@@ -419,0 +419,6 @@\n+    \/**\n+     * Sets the current thread's lock ID.\n+     *\/\n+    @IntrinsicCandidate\n+    static native void setCurrentLockId(long tid);\n+\n@@ -639,0 +645,5 @@\n+    \/**\n+     * Thread identifier assigned to the primordial thread.\n+     *\/\n+    static final long PRIMORDIAL_TID = 3;\n+\n@@ -641,4 +652,4 @@\n-     * 2 as this class cannot be used during early startup to generate the\n-     * identifier for the primordial thread. The counter is off-heap and\n-     * shared with the VM to allow it assign thread identifiers to non-Java\n-     * threads.\n+     * {@link Thread#PRIMORDIAL_TID}&nbsp;+1 as this class cannot be used during\n+     * early startup to generate the identifier for the primordial thread. The\n+     * counter is off-heap and shared with the VM to allow it to assign thread\n+     * identifiers to non-Java threads.\n@@ -725,1 +736,1 @@\n-            this.tid = 1;  \/\/ primordial thread\n+            this.tid = PRIMORDIAL_TID;  \/\/ primordial thread\n@@ -729,0 +740,1 @@\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Thread.java","additions":17,"deletions":5,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-import jdk.internal.event.VirtualThreadPinnedEvent;\n@@ -73,1 +72,0 @@\n-    private static final int TRACE_PINNING_MODE = tracePinningMode();\n@@ -79,0 +77,1 @@\n+    private static final long ON_WAITING_LIST = U.objectFieldOffset(VirtualThread.class, \"onWaitingList\");\n@@ -109,0 +108,15 @@\n+     *   RUNNING -> BLOCKING       \/\/ blocking on monitor enter\n+     *  BLOCKING -> BLOCKED        \/\/ blocked on monitor enter\n+     *   BLOCKED -> UNBLOCKED      \/\/ unblocked, may be scheduled to continue\n+     * UNBLOCKED -> RUNNING        \/\/ continue execution after blocked on monitor enter\n+     *\n+     *   RUNNING -> WAITING        \/\/ transitional state during wait on monitor\n+     *   WAITING -> WAITED         \/\/ waiting on monitor\n+     *    WAITED -> BLOCKED        \/\/ notified, waiting to be unblocked by monitor owner\n+     *    WAITED -> UNBLOCKED      \/\/ timed-out\/interrupted\n+     *\n+     *       RUNNING -> TIMED_WAITING   \/\/ transition state during timed-waiting on monitor\n+     * TIMED_WAITING -> TIMED_WAITED    \/\/ timed-waiting on monitor\n+     *  TIMED_WAITED -> BLOCKED         \/\/ notified, waiting to be unblocked by monitor owner\n+     *  TIMED_WAITED -> UNBLOCKED       \/\/ timed-out\/interrupted\n+     *\n@@ -131,0 +145,11 @@\n+    \/\/ monitor enter\n+    private static final int BLOCKING  = 12;\n+    private static final int BLOCKED   = 13;        \/\/ unmounted\n+    private static final int UNBLOCKED = 14;        \/\/ unmounted but runnable\n+\n+    \/\/ monitor wait\/timed-wait\n+    private static final int WAITING       = 15;\n+    private static final int WAIT          = 16;    \/\/ waiting in Object.wait\n+    private static final int TIMED_WAITING = 17;\n+    private static final int TIMED_WAIT    = 18;    \/\/ waiting in timed-Object.wait\n+\n@@ -136,1 +161,1 @@\n-    \/\/ parking permit\n+    \/\/ parking permit made available by LockSupport.unpark\n@@ -139,0 +164,17 @@\n+    \/\/ blocking permit made available by unblocker thread when another thread exits monitor\n+    private volatile boolean blockPermit;\n+\n+    \/\/ true when on the list of virtual threads waiting to be unblocked\n+    private volatile boolean onWaitingList;\n+\n+    \/\/ next virtual thread on the list of virtual threads waiting to be unblocked\n+    private volatile VirtualThread next;\n+\n+    \/\/ notified by Object.notify\/notifyAll while waiting in Object.wait\n+    private volatile boolean notified;\n+\n+    \/\/ timed-wait support\n+    private long waitTimeout;\n+    private byte timedWaitSeqNo;\n+    private volatile Future<?> waitTimeoutTask;\n+\n@@ -145,1 +187,0 @@\n-\n@@ -200,12 +241,2 @@\n-            if (TRACE_PINNING_MODE > 0) {\n-                boolean printAll = (TRACE_PINNING_MODE == 1);\n-                VirtualThread vthread = (VirtualThread) Thread.currentThread();\n-                int oldState = vthread.state();\n-                try {\n-                    \/\/ avoid printing when in transition states\n-                    vthread.setState(RUNNING);\n-                    PinnedThreadPrinter.printStackTrace(System.out, reason, printAll);\n-                } finally {\n-                    vthread.setState(oldState);\n-                }\n-            }\n+            \/\/ emit JFR event\n+            virtualThreadPinnedEvent(reason.reasonCode(), reason.reasonString());\n@@ -223,0 +254,7 @@\n+    \/**\n+     * jdk.VirtualThreadPinned is emitted by HotSpot VM when pinned. Call into VM to\n+     * emit event to avoid having a JFR event in Java with the same name (but different ID)\n+     * to events emitted by the VM.\n+     *\/\n+    private static native void virtualThreadPinnedEvent(int reason, String reasonString);\n+\n@@ -237,1 +275,2 @@\n-        if (initialState == STARTED || initialState == UNPARKED || initialState == YIELDED) {\n+        if (initialState == STARTED || initialState == UNPARKED\n+                || initialState == UNBLOCKED || initialState == YIELDED) {\n@@ -242,1 +281,1 @@\n-            \/\/ consume parking permit when continuing after parking\n+            \/\/ consume permit when continuing after parking or blocking\n@@ -245,0 +284,2 @@\n+            } if (initialState == UNBLOCKED) {\n+                blockPermit = false;\n@@ -277,8 +318,7 @@\n-                \/\/ The scheduler's execute method is invoked in the context of the\n-                \/\/ carrier thread. For the default scheduler this ensures that the\n-                \/\/ current thread is a ForkJoinWorkerThread so the task will be pushed\n-                \/\/ to the local queue. For other schedulers, it avoids deadlock that\n-                \/\/ would arise due to platform and virtual threads contending for a\n-                \/\/ lock on the scheduler's submission queue.\n-                if (currentThread() instanceof VirtualThread vthread) {\n-                    vthread.switchToCarrierThread();\n+                \/\/ Pin the continuation to prevent the virtual thread from unmounting\n+                \/\/ when submitting a task. For the default scheduler this ensures that\n+                \/\/ the carrier doesn't change when pushing a task. For other schedulers\n+                \/\/ it avoids deadlock that could arise due to carriers and virtual\n+                \/\/ threads contending for a lock.\n+                if (currentThread().isVirtual()) {\n+                    Continuation.pin();\n@@ -288,1 +328,1 @@\n-                        switchToVirtualThread(vthread);\n+                        Continuation.unpin();\n@@ -490,0 +530,1 @@\n+        Thread.setCurrentLockId(this.threadId()); \/\/ keep lock ID of virtual thread\n@@ -577,0 +618,49 @@\n+        \/\/ blocking on monitorenter\n+        if (s == BLOCKING) {\n+            setState(BLOCKED);\n+\n+            \/\/ may have been unblocked while blocking\n+            if (blockPermit && compareAndSetState(BLOCKED, UNBLOCKED)) {\n+                submitRunContinuation();\n+            }\n+            return;\n+        }\n+\n+        \/\/ Object.wait\n+        if (s == WAITING || s == TIMED_WAITING) {\n+            byte seqNo;\n+            int newState;\n+            if (s == WAITING) {\n+                seqNo = 0;  \/\/ not used\n+                setState(newState = WAIT);\n+            } else {\n+                \/\/ synchronize with timeout task (previous timed-wait may be running)\n+                synchronized (timedWaitLock()) {\n+                    seqNo = ++timedWaitSeqNo;\n+                    setState(newState = TIMED_WAIT);\n+                }\n+            }\n+\n+            \/\/ may have been notified while in transition to wait state\n+            if (notified && compareAndSetState(newState, BLOCKED)) {\n+                \/\/ may have even been unblocked already\n+                if (blockPermit && compareAndSetState(BLOCKED, UNBLOCKED)) {\n+                    submitRunContinuation();\n+                }\n+                return;\n+            }\n+\n+            \/\/ may have been interrupted while in transition to wait state\n+            if (interrupted && compareAndSetState(newState, UNBLOCKED)) {\n+                submitRunContinuation();\n+                return;\n+            }\n+\n+            \/\/ schedule wakeup\n+            if (newState == TIMED_WAIT) {\n+                assert waitTimeout > 0;\n+                waitTimeoutTask = schedule(() -> waitTimeoutExpired(seqNo), waitTimeout, MILLISECONDS);\n+            }\n+            return;\n+        }\n+\n@@ -677,1 +767,3 @@\n-            yielded = yieldContinuation();  \/\/ may throw\n+            yielded = yieldContinuation();\n+        } catch (OutOfMemoryError e) {\n+            \/\/ park on carrier\n@@ -713,2 +805,1 @@\n-            Future<?> unparker = scheduleUnpark(nanos);  \/\/ may throw OOME\n-            setState(TIMED_PARKING);\n+            Future<?> unparker = null;\n@@ -716,6 +807,17 @@\n-                yielded = yieldContinuation();  \/\/ may throw\n-            } finally {\n-                assert (Thread.currentThread() == this) && (yielded == (state() == RUNNING));\n-                if (!yielded) {\n-                    assert state() == TIMED_PARKING;\n-                    setState(RUNNING);\n+                 unparker = scheduleUnpark(nanos);\n+            } catch (OutOfMemoryError e) {\n+                \/\/ park on carrier\n+            }\n+            if (unparker != null) {\n+                setState(TIMED_PARKING);\n+                try {\n+                    yielded = yieldContinuation();\n+                } catch (OutOfMemoryError e) {\n+                    \/\/ park on carrier\n+                } finally {\n+                    assert (Thread.currentThread() == this) && (yielded == (state() == RUNNING));\n+                    if (!yielded) {\n+                        assert state() == TIMED_PARKING;\n+                        setState(RUNNING);\n+                    }\n+                    cancel(unparker);\n@@ -723,1 +825,0 @@\n-                cancel(unparker);\n@@ -726,1 +827,1 @@\n-            \/\/ park on carrier thread for remaining time when pinned\n+            \/\/ park on carrier thread for remaining time when pinned (or OOME)\n@@ -744,8 +845,0 @@\n-        VirtualThreadPinnedEvent event;\n-        try {\n-            event = new VirtualThreadPinnedEvent();\n-            event.begin();\n-        } catch (OutOfMemoryError e) {\n-            event = null;\n-        }\n-\n@@ -767,8 +860,0 @@\n-\n-        if (event != null) {\n-            try {\n-                event.commit();\n-            } catch (OutOfMemoryError e) {\n-                \/\/ ignore\n-            }\n-        }\n@@ -778,1 +863,2 @@\n-     * Schedule this virtual thread to be unparked after a given delay.\n+     * Invoked by parkNanos to schedule this virtual thread to be unparked after\n+     * a given delay.\n@@ -793,1 +879,1 @@\n-     * Cancels a task if it has not completed.\n+     * Invoked by parkNanos to cancel the unpark timer.\n@@ -845,0 +931,63 @@\n+    \/**\n+     * Invoked by unblocker thread to unblock this virtual thread.\n+     *\/\n+    private void unblock() {\n+        assert !Thread.currentThread().isVirtual();\n+        blockPermit = true;\n+        if (state() == BLOCKED && compareAndSetState(BLOCKED, UNBLOCKED)) {\n+            submitRunContinuation();\n+        }\n+    }\n+\n+    \/**\n+     * Invoked by timer thread when wait timeout for virtual thread has expired.\n+     * If the virtual thread is in timed-wait then this method will unblock the thread\n+     * and submit its task so that it continues and attempts to reenter the monitor.\n+     * This method does nothing if the thread has been woken by notify or interrupt.\n+     *\/\n+    private void waitTimeoutExpired(byte seqNo) {\n+        assert !Thread.currentThread().isVirtual();\n+        for (;;) {\n+            boolean unblocked = false;\n+            synchronized (timedWaitLock()) {\n+                if (seqNo != timedWaitSeqNo) {\n+                    \/\/ this timeout task is for a past timed-wait\n+                    return;\n+                }\n+                int s = state();\n+                if (s == TIMED_WAIT) {\n+                    unblocked = compareAndSetState(TIMED_WAIT, UNBLOCKED);\n+                } else if (s != (TIMED_WAIT | SUSPENDED)) {\n+                    \/\/ notified or interrupted, no longer waiting\n+                    return;\n+                }\n+            }\n+            if (unblocked) {\n+                submitRunContinuation();\n+                return;\n+            }\n+            \/\/ need to retry when thread is suspended in time-wait\n+            Thread.yield();\n+        }\n+    }\n+\n+    \/**\n+     * Invoked by Object.wait to cancel the wait timer.\n+     *\/\n+    void cancelWaitTimeout() {\n+        assert Thread.currentThread() == this;\n+        Future<?> timeoutTask = this.waitTimeoutTask;\n+        if (timeoutTask != null) {\n+            \/\/ Pin the continuation to prevent the virtual thread from unmounting\n+            \/\/ when there is contention removing the task. This avoids deadlock that\n+            \/\/ could arise due to carriers and virtual threads contending for a\n+            \/\/ lock on the delay queue.\n+            Continuation.pin();\n+            try {\n+                timeoutTask.cancel(false);\n+            } finally {\n+                Continuation.unpin();\n+            }\n+        }\n+    }\n+\n@@ -975,0 +1124,6 @@\n+            \/\/ if thread is waiting in Object.wait then schedule to try to reenter\n+            int s = state();\n+            if ((s == WAIT || s == TIMED_WAIT) && compareAndSetState(s, UNBLOCKED)) {\n+                submitRunContinuation();\n+            }\n+\n@@ -1019,0 +1174,1 @@\n+            case UNBLOCKED:\n@@ -1041,0 +1197,2 @@\n+            case WAITING:\n+            case TIMED_WAITING:\n@@ -1046,1 +1204,2 @@\n-                return State.WAITING;\n+            case WAIT:\n+                return Thread.State.WAITING;\n@@ -1049,1 +1208,5 @@\n-                return State.TIMED_WAITING;\n+            case TIMED_WAIT:\n+                return Thread.State.TIMED_WAITING;\n+            case BLOCKING:\n+            case BLOCKED:\n+                return Thread.State.BLOCKED;\n@@ -1095,1 +1258,1 @@\n-            case PARKED, TIMED_PARKED -> {\n+            case PARKED, TIMED_PARKED, BLOCKED, WAIT, TIMED_WAIT -> {\n@@ -1098,1 +1261,1 @@\n-            case UNPARKED, YIELDED -> {\n+            case UNPARKED, UNBLOCKED, YIELDED -> {\n@@ -1101,1 +1264,1 @@\n-            case PARKING, TIMED_PARKING, YIELDING -> {\n+            case PARKING, TIMED_PARKING, BLOCKING, YIELDING, WAITING, TIMED_WAITING -> {\n@@ -1122,1 +1285,1 @@\n-            case UNPARKED, YIELDED -> {\n+            case UNPARKED, UNBLOCKED, YIELDED -> {\n@@ -1130,0 +1293,9 @@\n+            case BLOCKED -> {\n+                \/\/ resubmit if unblocked while suspended\n+                yield blockPermit && compareAndSetState(BLOCKED, UNBLOCKED);\n+            }\n+            case WAIT, TIMED_WAIT -> {\n+                \/\/ resubmit if notified or interrupted while waiting (Object.wait)\n+                \/\/ waitTimeoutExpired will retry if the timed expired when suspended\n+                yield (notified || interrupted) && compareAndSetState(initialState, UNBLOCKED);\n+            }\n@@ -1224,0 +1396,8 @@\n+    \/**\n+     * Returns a lock object for coordinating timed-wait setup and timeout handling.\n+     *\/\n+    private Object timedWaitLock() {\n+        \/\/ use this object for now to avoid the overhead of introducing another lock\n+        return runContinuation;\n+    }\n+\n@@ -1254,0 +1434,4 @@\n+    private boolean compareAndSetOnWaitingList(boolean expectedValue, boolean newValue) {\n+        return U.compareAndSetBoolean(this, ON_WAITING_LIST, expectedValue, newValue);\n+    }\n+\n@@ -1304,3 +1488,0 @@\n-\n-        \/\/ ensure VirtualThreadPinnedEvent is loaded\/initialized\n-        U.ensureClassInitialized(VirtualThreadPinnedEvent.class);\n@@ -1387,3 +1568,2 @@\n-     * Reads the value of the jdk.tracePinnedThreads property to determine if stack\n-     * traces should be printed when a carrier thread is pinned when a virtual thread\n-     * attempts to park.\n+     * Schedule virtual threads that are ready to be scheduled after they blocked on\n+     * monitor enter.\n@@ -1391,7 +1571,15 @@\n-    private static int tracePinningMode() {\n-        String propValue = GetPropertyAction.privilegedGetProperty(\"jdk.tracePinnedThreads\");\n-        if (propValue != null) {\n-            if (propValue.length() == 0 || \"full\".equalsIgnoreCase(propValue))\n-                return 1;\n-            if (\"short\".equalsIgnoreCase(propValue))\n-                return 2;\n+    private static void unblockVirtualThreads() {\n+        while (true) {\n+            VirtualThread vthread = takeVirtualThreadListToUnblock();\n+            while (vthread != null) {\n+                assert vthread.onWaitingList;\n+                VirtualThread nextThread = vthread.next;\n+\n+                \/\/ remove from list and unblock\n+                vthread.next = null;\n+                boolean changed = vthread.compareAndSetOnWaitingList(true, false);\n+                assert changed;\n+                vthread.unblock();\n+\n+                vthread = nextThread;\n+            }\n@@ -1399,1 +1587,13 @@\n-        return 0;\n+    }\n+\n+    \/**\n+     * Retrieves the list of virtual threads that are waiting to be unblocked, waiting\n+     * if necessary until a list of one or more threads becomes available.\n+     *\/\n+    private static native VirtualThread takeVirtualThreadListToUnblock();\n+\n+    static {\n+        var unblocker = InnocuousThread.newThread(\"VirtualThread-unblocker\",\n+                VirtualThread::unblockVirtualThreads);\n+        unblocker.setDaemon(true);\n+        unblocker.start();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/VirtualThread.java","additions":276,"deletions":76,"binary":false,"changes":352,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2008, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -234,1 +234,1 @@\n-        ReferencedKeySet.create(false, true, new Supplier<>() {\n+        ReferencedKeySet.create(false, new Supplier<>() {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodType.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1137,1 +1137,1 @@\n-                ReferencedKeyMap.create(true, true,\n+                ReferencedKeyMap.create(true,\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/StringConcatFactory.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,1 +38,1 @@\n-    private static ReferenceQueue<Object> queue = new NativeReferenceQueue<>();\n+    private static ReferenceQueue<Object> queue = new ReferenceQueue<>();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Finalizer.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1,92 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package java.lang.ref;\n-\n-\/**\n- * An implementation of a ReferenceQueue that uses native monitors.\n- * The use of java.util.concurrent.lock locks interacts with various mechanisms,\n- * such as virtual threads and ForkJoinPool, that might not be appropriate for some\n- * low-level mechanisms, in particular MethodType's weak intern set.\n- *\/\n-final class NativeReferenceQueue<T> extends ReferenceQueue<T> {\n-    public NativeReferenceQueue() {\n-        super(0);\n-    }\n-\n-    private static class Lock { };\n-    private final Lock lock = new Lock();\n-\n-    @Override\n-    void signal() {\n-        lock.notifyAll();\n-    }\n-    @Override\n-    void await() throws InterruptedException {\n-        lock.wait();\n-    }\n-\n-    @Override\n-    void await(long timeoutMillis) throws InterruptedException {\n-        lock.wait(timeoutMillis);\n-    }\n-\n-    @Override\n-    boolean enqueue(Reference<? extends T> r) {\n-        synchronized(lock) {\n-            return enqueue0(r);\n-        }\n-    }\n-\n-    @Override\n-    public Reference<? extends T> poll() {\n-        if (headIsNull())\n-            return null;\n-\n-        synchronized(lock) {\n-            return poll0();\n-        }\n-    }\n-\n-    @Override\n-    public Reference<? extends T> remove(long timeout)\n-            throws IllegalArgumentException, InterruptedException {\n-        if (timeout < 0)\n-            throw new IllegalArgumentException(\"Negative timeout value\");\n-        if (timeout == 0)\n-            return remove();\n-\n-        synchronized(lock) {\n-            return remove0(timeout);\n-        }\n-    }\n-\n-    @Override\n-    public Reference<? extends T> remove() throws InterruptedException {\n-        synchronized(lock) {\n-            return remove0();\n-        }\n-    }\n-}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/NativeReferenceQueue.java","additions":0,"deletions":92,"binary":false,"changes":92,"status":"deleted"},{"patch":"@@ -333,5 +333,0 @@\n-\n-            @Override\n-            public <T> ReferenceQueue<T> newNativeReferenceQueue() {\n-                return new NativeReferenceQueue<T>();\n-            }\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,3 +28,0 @@\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.locks.Condition;\n-import java.util.concurrent.locks.ReentrantLock;\n@@ -33,0 +30,2 @@\n+import jdk.internal.vm.Continuation;\n+import jdk.internal.vm.ContinuationSupport;\n@@ -53,2 +52,0 @@\n-        public Null() { super(0); }\n-\n@@ -67,14 +64,2 @@\n-    private final ReentrantLock lock;\n-    private final Condition notEmpty;\n-\n-    void signal() {\n-        notEmpty.signalAll();\n-    }\n-\n-    void await() throws InterruptedException {\n-        notEmpty.await();\n-    }\n-\n-    void await(long timeoutMillis) throws InterruptedException {\n-        notEmpty.await(timeoutMillis, TimeUnit.MILLISECONDS);\n-    }\n+    private static class Lock { };\n+    private final Lock lock = new Lock();\n@@ -86,2 +71,0 @@\n-        this.lock = new ReentrantLock();\n-        this.notEmpty = lock.newCondition();\n@@ -90,6 +73,1 @@\n-    ReferenceQueue(int dummy) {\n-        this.lock = null;\n-        this.notEmpty = null;\n-    }\n-\n-    final boolean enqueue0(Reference<? extends T> r) { \/\/ must hold lock\n+    private boolean enqueue0(Reference<? extends T> r) { \/\/ must hold lock\n@@ -114,1 +92,1 @@\n-        signal();\n+        lock.notifyAll();\n@@ -118,5 +96,1 @@\n-    final boolean headIsNull() {\n-        return head == null;\n-    }\n-\n-    final Reference<? extends T> poll0() { \/\/ must hold lock\n+    private Reference<? extends T> poll0() { \/\/ must hold lock\n@@ -145,2 +119,1 @@\n-    final Reference<? extends T> remove0(long timeout)\n-            throws IllegalArgumentException, InterruptedException { \/\/ must hold lock\n+    private Reference<? extends T> remove0(long timeout) throws InterruptedException { \/\/ must hold lock\n@@ -151,1 +124,1 @@\n-            await(timeout);\n+            lock.wait(timeout);\n@@ -154,1 +127,0 @@\n-\n@@ -162,1 +134,1 @@\n-    final Reference<? extends T> remove0() throws InterruptedException { \/\/ must hold lock\n+    private Reference<? extends T> remove0() throws InterruptedException { \/\/ must hold lock\n@@ -166,1 +138,1 @@\n-            await();\n+            lock.wait();\n@@ -171,2 +143,1 @@\n-        lock.lock();\n-        try {\n+        synchronized (lock) {\n@@ -174,2 +145,0 @@\n-        } finally {\n-            lock.unlock();\n@@ -179,0 +148,13 @@\n+    private boolean tryDisablePreempt() {\n+        if (Thread.currentThread().isVirtual() && ContinuationSupport.isSupported()) {\n+            Continuation.pin();\n+            return true;\n+        } else {\n+            return false;\n+        }\n+    }\n+\n+    private void enablePreempt() {\n+        Continuation.unpin();\n+    }\n+\n@@ -189,1 +171,1 @@\n-        if (headIsNull())\n+        if (head == null)\n@@ -191,1 +173,4 @@\n-        lock.lock();\n+\n+        \/\/ Prevent a virtual thread from being preempted as this could potentially\n+        \/\/ deadlock with a carrier that is polling the same reference queue.\n+        boolean disabled = tryDisablePreempt();\n@@ -193,1 +178,3 @@\n-            return poll0();\n+            synchronized (lock) {\n+                return poll0();\n+            }\n@@ -195,1 +182,1 @@\n-            lock.unlock();\n+            if (disabled) enablePreempt();\n@@ -227,2 +214,1 @@\n-        lock.lock();\n-        try {\n+        synchronized (lock) {\n@@ -230,2 +216,0 @@\n-        } finally {\n-            lock.unlock();\n@@ -244,2 +228,1 @@\n-        lock.lock();\n-        try {\n+        synchronized (lock) {\n@@ -247,2 +230,0 @@\n-        } finally {\n-            lock.unlock();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/ReferenceQueue.java","additions":37,"deletions":56,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+import jdk.internal.access.JavaLangAccess;\n@@ -2635,1 +2636,1 @@\n-        if (((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) &&\n+        if (((t = JLA.currentCarrierThread()) instanceof ForkJoinWorkerThread) &&\n@@ -2646,0 +2647,1 @@\n+    private static final JavaLangAccess JLA = SharedSecrets.getJavaLangAccess();\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -53,7 +53,0 @@\n-\n-    \/**\n-     * Constructs a new NativeReferenceQueue.\n-     *\n-     * Invoked by jdk.internal.util.ReferencedKeyMap\n-     *\/\n-    <T> ReferenceQueue<T> newNativeReferenceQueue();\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangRefAccess.java","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1,31 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-package jdk.internal.event;\n-\n-\/**\n- * Event recording that a virtual thread has parked on its carrier thread.\n- *\/\n-public class VirtualThreadPinnedEvent extends Event {\n-}\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/event\/VirtualThreadPinnedEvent.java","additions":0,"deletions":31,"binary":false,"changes":31,"status":"deleted"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,3 +42,1 @@\n-        if (s != null && (s.isEmpty() || s.equals(\"true\"))) {\n-            CAN_USE_INTERNAL_LOCK = false;\n-        } else {\n+        if (s != null && s.equals(\"false\")) {\n@@ -46,0 +44,2 @@\n+        } else {\n+            CAN_USE_INTERNAL_LOCK = false;\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/InternalLock.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -145,23 +145,1 @@\n-        return create(isSoft, false, supplier);\n-    }\n-\n-    \/**\n-     * Create a new {@link ReferencedKeyMap} map.\n-     *\n-     * @param isSoft          true if {@link SoftReference} keys are to\n-     *                        be used, {@link WeakReference} otherwise.\n-     * @param useNativeQueue  true if uses NativeReferenceQueue\n-     *                        otherwise use {@link ReferenceQueue}.\n-     * @param supplier        {@link Supplier} of the backing map\n-     *\n-     * @return a new map with {@link Reference} keys\n-     *\n-     * @param <K> the type of keys maintained by the new map\n-     * @param <V> the type of mapped values\n-     *\/\n-    public static <K, V> ReferencedKeyMap<K, V>\n-    create(boolean isSoft, boolean useNativeQueue, Supplier<Map<ReferenceKey<K>, V>> supplier) {\n-        return new ReferencedKeyMap<K, V>(isSoft, supplier.get(),\n-                useNativeQueue ? SharedSecrets.getJavaLangRefAccess().newNativeReferenceQueue()\n-                               : new ReferenceQueue<>()\n-                );\n+        return new ReferencedKeyMap<K, V>(isSoft, supplier.get(), new ReferenceQueue<>());\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/util\/ReferencedKeyMap.java","additions":1,"deletions":23,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -109,19 +109,1 @@\n-        return create(isSoft, false, supplier);\n-    }\n-\n-    \/**\n-     * Create a new {@link ReferencedKeySet} elements.\n-     *\n-     * @param isSoft          true if {@link SoftReference} elements are to\n-     *                        be used, {@link WeakReference} otherwise.\n-     * @param useNativeQueue  true if uses NativeReferenceQueue\n-     *                        otherwise use {@link ReferenceQueue}.\n-     * @param supplier        {@link Supplier} of the backing map\n-     *\n-     * @return a new set with {@link Reference} elements\n-     *\n-     * @param <E> the type of elements maintained by this set\n-     *\/\n-    public static <E> ReferencedKeySet<E>\n-    create(boolean isSoft, boolean useNativeQueue, Supplier<Map<ReferenceKey<E>, ReferenceKey<E>>> supplier) {\n-         return new ReferencedKeySet<>(ReferencedKeyMap.create(isSoft, useNativeQueue, supplier));\n+        return new ReferencedKeySet<>(ReferencedKeyMap.create(isSoft, supplier));\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/util\/ReferencedKeySet.java","additions":2,"deletions":20,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -59,3 +59,17 @@\n-        \/** Native frame on stack *\/ NATIVE,\n-        \/** Monitor held *\/          MONITOR,\n-        \/** In critical section *\/   CRITICAL_SECTION }\n+        NATIVE(2, \"Native frame or <clinit> on stack\"),\n+        MONITOR(3, \"Monitor held\"),\n+        CRITICAL_SECTION(4, \"In critical section\");\n+\n+        private final int reasonCode;\n+        private final String reasonString;\n+        Pinned(int reasonCode, String reasonString) {\n+            this.reasonCode = reasonCode;\n+            this.reasonString = reasonString;\n+        }\n+        public int reasonCode() {\n+            return reasonCode;\n+        }\n+        public String reasonString() {\n+            return reasonString;\n+        }\n+    }\n@@ -356,2 +370,0 @@\n-        preempted = false;\n-\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/Continuation.java","additions":17,"deletions":5,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+import java.util.List;\n@@ -30,0 +31,1 @@\n+import java.util.Objects;\n@@ -43,1 +45,1 @@\n-abstract class Poller {\n+public abstract class Poller {\n@@ -145,0 +147,14 @@\n+    \/**\n+     * Parks the current thread until a Selector's file descriptor is ready.\n+     * @param fdVal the Selector's file descriptor\n+     * @param nanos the waiting time or 0 to wait indefinitely\n+     *\/\n+    static void pollSelector(int fdVal, long nanos) throws IOException {\n+        assert nanos >= 0L;\n+        Poller poller = POLLERS.masterPoller();\n+        if (poller == null) {\n+            poller = POLLERS.readPoller(fdVal);\n+        }\n+        poller.poll(fdVal, nanos, () -> true);\n+    }\n+\n@@ -261,0 +277,12 @@\n+    \/**\n+     * Returns the number I\/O operations currently registered with this poller.\n+     *\/\n+    public int registered() {\n+        return map.size();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return Objects.toIdentityString(this) + \" [registered = \" + registered() + \"]\";\n+    }\n+\n@@ -347,0 +375,7 @@\n+        \/**\n+         * Returns the master poller, or null if there is no master poller.\n+         *\/\n+        Poller masterPoller() {\n+            return masterPoller;\n+        }\n+\n@@ -363,0 +398,15 @@\n+        \/**\n+         * Return the list of read pollers.\n+         *\/\n+        List<Poller> readPollers() {\n+            return List.of(readPollers);\n+        }\n+\n+        \/**\n+         * Return the list of write pollers.\n+         *\/\n+        List<Poller> writePollers() {\n+            return List.of(writePollers);\n+        }\n+\n+\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/Poller.java","additions":51,"deletions":1,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import java.lang.invoke.MethodHandles;\n@@ -54,0 +55,8 @@\n+    static {\n+        try {\n+            MethodHandles.lookup().ensureInitialized(AnchorCertificates.class);\n+        } catch (IllegalAccessException e) {\n+            throw new ExceptionInInitializerError(e);\n+        }\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/sun\/security\/ssl\/X509TrustManagerImpl.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1994, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1994, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,0 +46,1 @@\n+    {\"setCurrentLockId\", \"(J)V\",       (void *)&JVM_SetCurrentLockId},\n","filename":"src\/java.base\/share\/native\/libjava\/Thread.c","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,0 +41,1 @@\n+    { \"takeVirtualThreadListToUnblock\", \"()\" VIRTUAL_THREAD, (void *)&JVM_TakeVirtualThreadListToUnblock},\n@@ -47,0 +48,7 @@\n+\n+JNIEXPORT void JNICALL\n+Java_java_lang_VirtualThread_virtualThreadPinnedEvent(JNIEnv *env, jclass ignored,\n+                                                      jint reasonCode, jstring reasonString)\n+{\n+    JVM_VirtualThreadPinnedEvent(reasonCode, reasonString);\n+}\n","filename":"src\/java.base\/share\/native\/libjava\/VirtualThread.c","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -58,0 +58,1 @@\n+  private static CIntegerField lockIdField;\n@@ -104,0 +105,1 @@\n+    lockIdField        = type.getCIntegerField(\"_lock_id\");\n@@ -379,0 +381,4 @@\n+  public Address getLockId() {\n+    return lockIdField.getAddress(addr);\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -54,0 +54,2 @@\n+    f = type.getField(\"_stack_locker\");\n+    stackLockerFieldOffset = f.getOffset();\n@@ -90,0 +92,1 @@\n+  public Address stackLocker() { return addr.getAddressAt(stackLockerFieldOffset); }\n@@ -120,0 +123,1 @@\n+  private static long          stackLockerFieldOffset;\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -215,3 +215,1 @@\n-    \/\/ refer to Threads::owning_thread_from_monitor_owner\n-    public JavaThread owningThreadFromMonitor(Address o) {\n-        assert(VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() != LockingMode.getLightweight());\n+    private JavaThread owningThreadFromMonitor(Address o) {\n@@ -221,1 +219,1 @@\n-            if (o.equals(thread.threadObjectAddress())) {\n+            if (o.equals(thread.getLockId())) {\n@@ -225,6 +223,0 @@\n-\n-        for (int i = 0; i < getNumberOfThreads(); i++) {\n-            JavaThread thread = getJavaThreadAt(i);\n-            if (thread.isLockOwned(o))\n-                return thread;\n-        }\n@@ -235,2 +227,2 @@\n-        if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLightweight()) {\n-            if (monitor.isOwnedAnonymous()) {\n+        if (monitor.isOwnedAnonymous()) {\n+            if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLightweight()) {\n@@ -249,0 +241,9 @@\n+            } else {\n+                assert(VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLegacy());\n+                Address o = (Address)monitor.stackLocker();\n+                for (int i = 0; i < getNumberOfThreads(); i++) {\n+                    JavaThread thread = getJavaThreadAt(i);\n+                    if (thread.isLockOwned(o))\n+                        return thread;\n+                }\n+                return null;\n@@ -250,4 +251,0 @@\n-            \/\/ Owner can only be threads at this point.\n-            Address o = monitor.owner();\n-            if (o == null) return null;\n-            return new JavaThread(o);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":14,"deletions":17,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1,37 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package jdk.jfr.events;\n-\n-import jdk.jfr.Category;\n-import jdk.jfr.Label;\n-import jdk.jfr.Name;\n-import jdk.jfr.internal.MirrorEvent;\n-\n-@Category(\"Java Application\")\n-@Label(\"Virtual Thread Pinned\")\n-@Name(\"jdk.VirtualThreadPinned\")\n-public final class VirtualThreadPinnedEvent extends MirrorEvent {\n-}\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/events\/VirtualThreadPinnedEvent.java","additions":0,"deletions":37,"binary":false,"changes":37,"status":"deleted"},{"patch":"@@ -71,1 +71,0 @@\n-        jdk.internal.event.VirtualThreadPinnedEvent.class,\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/JDKEvents.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -46,1 +46,0 @@\n-import jdk.jfr.events.VirtualThreadPinnedEvent;\n@@ -75,1 +74,0 @@\n-        register(\"jdk.internal.event.VirtualThreadPinnedEvent\", VirtualThreadPinnedEvent.class);\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/MirrorEvents.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -78,1 +78,0 @@\n-      <setting name=\"threshold\">20 ms<\/setting>\n","filename":"src\/jdk.jfr\/share\/conf\/jfr\/default.jfc","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -78,1 +78,0 @@\n-      <setting name=\"threshold\">20 ms<\/setting>\n","filename":"src\/jdk.jfr\/share\/conf\/jfr\/profile.jfc","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-using Node = Tree::TreapNode;\n+using TNode = Tree::TreapNode;\n@@ -80,1 +80,1 @@\n-    treap(tree).visit_in_order([&](Node* x) {\n+    treap(tree).visit_in_order([&](TNode* x) {\n@@ -133,1 +133,1 @@\n-    treap(tree).visit_in_order([&](Node* x) {\n+    treap(tree).visit_in_order([&](TNode* x) {\n@@ -158,1 +158,1 @@\n-    treap(tree).visit_in_order([&](Node* x) {\n+    treap(tree).visit_in_order([&](TNode* x) {\n@@ -190,1 +190,1 @@\n-  tree.visit_in_order([&](Node* node) {\n+  tree.visit_in_order([&](TNode* node) {\n@@ -230,1 +230,1 @@\n-    treap(tree).visit_in_order([&](Node* x) {\n+    treap(tree).visit_in_order([&](TNode* x) {\n@@ -267,1 +267,1 @@\n-    treap(tree).visit_range_in_order(0, 99999, [&](Node* x) {\n+    treap(tree).visit_range_in_order(0, 99999, [&](TNode* x) {\n","filename":"test\/hotspot\/gtest\/nmt\/test_vmatree.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -89,0 +89,14 @@\n+###\n+# The test first suspends a vthread and all the carriers and then it resumes the vthread expecting it\n+# to run to completion. In mainline it only works because the suspension step happens while the vthread is\n+# pinned to the carrier blocked on synchronized. So the carrier only actually suspends on the next unmount\n+# transition which in this test happens once the vthread has finished executing the expected code.\n+\n+vmTestbase\/nsk\/jdi\/ThreadReference\/isSuspended\/issuspended002\/TestDescription.java 8338713 generic-all\n+\n+###\n+# The test sends a StopThread to a vthread expecting that is currently pinned to the carrier blocked on\n+# synchronized. Since the vthread is now unmounted StopThread returns JVMTI_ERROR_OPAQUE_FRAME error.\n+\n+vmTestbase\/nsk\/jdb\/kill\/kill001\/kill001.java 8338714 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList-Virtual.txt","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,1 @@\n+ *                   -XX:CompileCommand=exclude,java.util.concurrent.TimeUnit::toNanos\n@@ -55,0 +56,1 @@\n+ *                   -XX:CompileCommand=exclude,java.util.concurrent.TimeUnit::toNanos\n","filename":"test\/hotspot\/jtreg\/compiler\/codecache\/stress\/OverloadCompileQueueTest.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -122,0 +122,2 @@\n+            \/\/ We only count monitors in LM_LEGACY mode\n+            \"-XX:LockingMode=1\",\n@@ -222,1 +224,4 @@\n-            final Object monitor = new Object();\n+            final Object[] monitors = new Object[nThreads];\n+            for (int i = 0; i < nThreads; i++) {\n+                monitors[i] = new Object();\n+            }\n@@ -228,0 +233,1 @@\n+                Object monitor = skipUnlock ? monitors[i] : monitors[0];\n","filename":"test\/hotspot\/jtreg\/runtime\/vthread\/JNIMonitor\/JNIMonitor.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-static JNIEnv *jni = nullptr;\n@@ -74,1 +73,1 @@\n-static int prepare() {\n+static int prepare(JNIEnv* jni) {\n@@ -95,2 +94,1 @@\n-agentProc(jvmtiEnv *jvmti, JNIEnv *agentJNI, void *arg) {\n-  jni = agentJNI;\n+agentProc(jvmtiEnv *jvmti, JNIEnv *jni, void *arg) {\n@@ -103,1 +101,1 @@\n-  if (!prepare()) {\n+  if (!prepare(jni)) {\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/events\/MonitorContendedEnter\/mcontenter01\/libmcontenter01.cpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-static JNIEnv *jni = nullptr;\n@@ -130,1 +129,0 @@\n-  jni = agentJNI;\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/events\/MonitorContendedEntered\/mcontentered01\/libmcontentered01.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+const int MAX_COUNT = 50;\n+\n@@ -34,1 +36,0 @@\n-static JNIEnv *jni = nullptr;\n@@ -43,0 +44,2 @@\n+static void check_stack_trace(JNIEnv* env, jthread thr);\n+\n@@ -68,0 +71,4 @@\n+\n+  if (jni->IsVirtualThread(thr)) {\n+    check_stack_trace(jni, thr);\n+  }\n@@ -72,0 +79,35 @@\n+static void check_stack_trace(JNIEnv* jni, jthread thr) {\n+  jvmtiError err;\n+  jint count = 0;\n+  jint skipped = 0;\n+\n+  print_stack_trace(jvmti, jni, nullptr);\n+\n+  jvmtiFrameInfo frameInfo[MAX_COUNT];\n+\n+  err = jvmti->GetStackTrace(thr, 0, MAX_COUNT, frameInfo, &count);\n+  check_jvmti_status(jni, err, \"event handler: error in JVMTI GetStackTrace call\");\n+\n+  const int expected_count = 8;\n+  const char* expected_methods[expected_count] = {\"wait0\", \"wait\", \"run\", \"runWith\", \"run\", \"run\", \"enter0\", \"enter\"};\n+\n+  if (count != expected_count) {\n+    LOG(\"Expected 8 methods in the stack but found %d\", count);\n+    jni->FatalError(\"Unexpected method count\");\n+  }\n+\n+  for (int idx = 0; idx < count; idx++) {\n+    jclass declaringClass = nullptr;\n+    char *clasSignature = nullptr;\n+    char *methodName = nullptr;\n+\n+    err = jvmti->GetMethodName(frameInfo[idx].method, &methodName, nullptr, nullptr);\n+    check_jvmti_status(jni, err, \"event handler: error in JVMTI GetMethodName call\");\n+\n+    if (strcmp(methodName, expected_methods[idx]) != 0) {\n+      LOG(\"Expected method %s but found %s\", expected_methods[idx], methodName);\n+      jni->FatalError(\"Unexpected method found\");\n+    }\n+  }\n+}\n+\n@@ -93,1 +135,0 @@\n-  jni = agentJNI;\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/events\/MonitorWaited\/monitorwaited01\/libmonitorwaited01.cpp","additions":43,"deletions":2,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -43,0 +43,1 @@\n+ * @requires vm.continuations\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/events\/MonitorWaited\/monitorwaited01\/monitorwaited01.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -254,0 +254,2 @@\n+    private static native void runFromNative(Runnable runnable);\n+\n@@ -255,6 +257,5 @@\n-        final Object syncObj = new Object();\n-        return Thread.ofVirtual().unstarted(() -> {\n-            synchronized (syncObj) {\n-                runnable.run();\n-            }\n-        });\n+        return Thread.ofVirtual().unstarted(() -> runFromNative(runnable));\n+    }\n+\n+    private static void runUpcall(Runnable runnable) {\n+        runnable.run();\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/GetThreadStateMountedTest\/GetThreadStateMountedTest.java","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -194,0 +194,10 @@\n+extern \"C\" JNIEXPORT void JNICALL\n+Java_GetThreadStateMountedTest_runFromNative(JNIEnv* jni, jclass clazz, jobject runnable) {\n+  jmethodID mid = jni->GetStaticMethodID(clazz, \"runUpcall\", \"(Ljava\/lang\/Runnable;)V\");\n+  if (mid == nullptr) {\n+    jni->FatalError(\"failed to get runUpcall method\");\n+    return;\n+  }\n+  jni->CallStaticVoidMethod(clazz, mid, runnable);\n+}\n+\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/GetThreadStateMountedTest\/libGetThreadStateMountedTest.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+ * @library \/test\/lib\n@@ -34,1 +35,2 @@\n- * @run main\/othervm\/native -agentlib:StopThreadTest -XX:+UnlockExperimentalVMOptions -XX:-VMContinuations StopThreadTest\n+ * @library \/test\/lib\n+ * @run main\/othervm\/native -agentlib:StopThreadTest -XX:+UnlockExperimentalVMOptions -XX:-VMContinuations -DboundVThread=true StopThreadTest\n@@ -40,0 +42,1 @@\n+ * @library \/test\/lib\n@@ -43,0 +46,1 @@\n+import jdk.test.lib.Platform;\n@@ -45,0 +49,3 @@\n+import com.sun.management.HotSpotDiagnosticMXBean;\n+import java.lang.management.ManagementFactory;\n+\n@@ -56,0 +63,1 @@\n+    static final boolean isBoundVThread = Boolean.getBoolean(\"boundVThread\");\n@@ -57,0 +65,1 @@\n+    static final int JVMTI_ERROR_OPAQUE_FRAME = 32;\n@@ -107,1 +116,1 @@\n-            TestTask.ensureAtPointA();\n+            TestTask.ensureAtPointA(testTaskThread);\n@@ -122,2 +131,4 @@\n-            if (retCode != JVMTI_ERROR_NONE) {\n-                throwFailed(\"Main #A.2: expected JVMTI_ERROR_NONE instead of: \" + retCode);\n+            int expectedRetCode = preemptableVirtualThread() ? JVMTI_ERROR_OPAQUE_FRAME : JVMTI_ERROR_NONE;\n+            String expectedRetCodeName = preemptableVirtualThread() ? \"JVMTI_ERROR_OPAQUE_FRAME\" : \"JVMTI_ERROR_NONE\";\n+            if (retCode != expectedRetCode) {\n+                throwFailed(\"Main #A.2: expected \" + expectedRetCodeName + \" instead of: \" + retCode);\n@@ -125,1 +136,1 @@\n-                log(\"Main #A.2: got expected JVMTI_ERROR_NONE\");\n+                log(\"Main #A.2: got expected \" + expectedRetCodeName);\n@@ -182,2 +193,3 @@\n-        static void ensureAtPointA() {\n-            while (!atPointA) {\n+        static void ensureAtPointA(Thread vt) {\n+            \/\/ wait while the thread state is not the expected one\n+            while (!atPointA && vt.getState() != Thread.State.BLOCKED) {\n@@ -206,1 +218,1 @@\n-            if (!seenExceptionFromA) {\n+            if (!seenExceptionFromA && !preemptableVirtualThread()) {\n@@ -266,0 +278,6 @@\n+\n+    static boolean preemptableVirtualThread() {\n+        boolean legacyLockingMode = ManagementFactory.getPlatformMXBean(HotSpotDiagnosticMXBean.class)\n+                                        .getVMOption(\"LockingMode\").getValue().equals(\"1\");\n+        return is_virtual && !isBoundVThread && !legacyLockingMode;\n+    }\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/StopThreadTest\/StopThreadTest.java","additions":27,"deletions":9,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+ * @requires vm.debug != true\n@@ -37,0 +38,13 @@\n+\/*\n+ * @test id=debug\n+ * @requires vm.debug == true\n+ * @library \/test\/lib\n+ * @compile SuspendResume1.java\n+ * @run driver jdk.test.lib.FileInstaller . .\n+ * @run main\/othervm\/native\/timeout=600\n+ *      -Djdk.virtualThreadScheduler.maxPoolSize=1\n+ *      -agentlib:SuspendResume1\n+ *      -XX:-VerifyContinuations\n+ *      SuspendResume1\n+ *\/\n+\n@@ -171,1 +185,1 @@\n-                sleep(1000);\n+                sleep(100);\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/SuspendResume1\/SuspendResume1.java","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+ * @requires vm.debug != true\n@@ -36,0 +37,13 @@\n+\/*\n+ * @test id=debug\n+ * @requires vm.debug == true\n+ * @library \/test\/lib\n+ * @compile SuspendResume2.java\n+ * @run driver jdk.test.lib.FileInstaller . .\n+ * @run main\/othervm\/native\n+ *      -Djdk.virtualThreadScheduler.maxPoolSize=1\n+ *      -agentlib:SuspendResume2\n+ *      -XX:-VerifyContinuations\n+ *      SuspendResume2\n+ *\/\n+\n@@ -151,1 +165,1 @@\n-                SuspendResume2.sleep(1);\n+                SuspendResume2.sleep(10);\n@@ -165,1 +179,1 @@\n-                sleep(1);\n+                sleep(100);\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/SuspendResume2\/SuspendResume2.java","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,2 +35,1 @@\n- * @summary Do not suspend virtual threads in a critical section.\n- * @bug 8311218\n+ * @requires vm.debug != true\n@@ -42,0 +41,8 @@\n+\/**\n+ * @test id=xint-debug\n+ * @requires vm.debug == true\n+ * @requires vm.continuations\n+ * @library \/testlibrary\n+ * @run main\/othervm -Xint -XX:-VerifyContinuations SuspendWithInterruptLock\n+ *\/\n+\n","filename":"test\/hotspot\/jtreg\/serviceability\/jvmti\/vthread\/SuspendWithInterruptLock\/SuspendWithInterruptLock.java","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,2 +65,2 @@\n-            tokensMap.put(\"(a java\/util\/concurrent\/locks\/AbstractQueuedSynchronizer$ConditionObject)\",\n-                          \"instance of Oop for java\/util\/concurrent\/locks\/AbstractQueuedSynchronizer\\\\$ConditionObject\");\n+            tokensMap.put(\"(a java.lang.ref.ReferenceQueue$Lock)\",\n+                          \"instance of Oop for java\/lang\/ref\/ReferenceQueue\\\\$Lock\");\n","filename":"test\/hotspot\/jtreg\/serviceability\/sa\/ClhsdbInspect.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-import jdk.internal.misc.Blocker;\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n@@ -30,2 +30,2 @@\n- * Class <code>Object<\/code> is the root of the class hierarchy.\n- * Every class has <code>Object<\/code> as a superclass. All objects,\n+ * Class {@code Object} is the root of the class hierarchy.\n+ * Every class has {@code Object} as a superclass. All objects,\n@@ -34,2 +34,0 @@\n- * @author  unascribed\n- * @version 1.67, 02\/03\/04\n@@ -37,1 +35,1 @@\n- * @since   JDK1.0\n+ * @since   1.0\n@@ -42,3 +40,14 @@\n-     * Returns the runtime class of an object. That <tt>Class<\/tt>\n-     * object is the object that is locked by <tt>static synchronized<\/tt>\n-     * methods of the represented class.\n+     * Constructs a new object.\n+     *\/\n+    @IntrinsicCandidate\n+    public Object() {}\n+\n+    \/**\n+     * Returns the runtime class of this {@code Object}. The returned\n+     * {@code Class} object is the object that is locked by {@code\n+     * static synchronized} methods of the represented class.\n+     *\n+     * <p><b>The actual result type is {@code Class<? extends |X|>}\n+     * where {@code |X|} is the erasure of the static type of the\n+     * expression on which {@code getClass} is called.<\/b> For\n+     * example, no cast is required in this code fragment:<\/p>\n@@ -46,5 +55,8 @@\n-     * @return The <code>java.lang.Class<\/code> object that represents\n-     *         the runtime class of the object.  The result is of type\n-     *         {@code Class<? extends X>} where X is the\n-     *         static type of the expression on which\n-     *         <code>getClass<\/code> is called.\n+     * <p>\n+     * {@code Number n = 0;                             }<br>\n+     * {@code Class<? extends Number> c = n.getClass(); }\n+     * <\/p>\n+     *\n+     * @return The {@code Class} object that represents the runtime\n+     *         class of this object.\n+     * @jls 15.8.2 Class Literals\n@@ -52,1 +64,2 @@\n-    public final native Class<? extends Object> getClass();\n+    @IntrinsicCandidate\n+    public final native Class<?> getClass();\n@@ -55,3 +68,3 @@\n-     * Returns a hash code value for the object. This method is\n-     * supported for the benefit of hashtables such as those provided by\n-     * <code>java.util.Hashtable<\/code>.\n+     * {@return a hash code value for this object} This method is\n+     * supported for the benefit of hash tables such as those provided by\n+     * {@link java.util.HashMap}.\n@@ -59,1 +72,1 @@\n-     * The general contract of <code>hashCode<\/code> is:\n+     * The general contract of {@code hashCode} is:\n@@ -62,1 +75,1 @@\n-     *     an execution of a Java application, the <tt>hashCode<\/tt> method\n+     *     an execution of a Java application, the {@code hashCode} method\n@@ -64,1 +77,1 @@\n-     *     used in <tt>equals<\/tt> comparisons on the object is modified.\n+     *     used in {@code equals} comparisons on the object is modified.\n@@ -67,3 +80,4 @@\n-     * <li>If two objects are equal according to the <tt>equals(Object)<\/tt>\n-     *     method, then calling the <code>hashCode<\/code> method on each of\n-     *     the two objects must produce the same integer result.\n+     * <li>If two objects are equal according to the {@link\n+     *     #equals(Object) equals} method, then calling the {@code\n+     *     hashCode} method on each of the two objects must produce the\n+     *     same integer result.\n@@ -71,5 +85,5 @@\n-     *     according to the {@link java.lang.Object#equals(java.lang.Object)}\n-     *     method, then calling the <tt>hashCode<\/tt> method on each of the\n-     *     two objects must produce distinct integer results.  However, the\n-     *     programmer should be aware that producing distinct integer results\n-     *     for unequal objects may improve the performance of hashtables.\n+     *     according to the {@link #equals(Object) equals} method, then\n+     *     calling the {@code hashCode} method on each of the two objects\n+     *     must produce distinct integer results.  However, the programmer\n+     *     should be aware that producing distinct integer results for\n+     *     unequal objects may improve the performance of hash tables.\n@@ -77,7 +91,0 @@\n-     * <p>\n-     * As much as is reasonably practical, the hashCode method defined by\n-     * class <tt>Object<\/tt> does return distinct integers for distinct\n-     * objects. (This is typically implemented by converting the internal\n-     * address of the object into an integer, but this implementation\n-     * technique is not required by the\n-     * Java<font size=\"-2\"><sup>TM<\/sup><\/font> programming language.)\n@@ -85,1 +92,9 @@\n-     * @return  a hash code value for this object.\n+     * @implSpec\n+     * As far as is reasonably practical, the {@code hashCode} method defined\n+     * by class {@code Object} returns distinct integers for distinct objects.\n+     *\n+     * @apiNote\n+     * The {@link java.util.Objects#hash(Object...) hash} and {@link\n+     * java.util.Objects#hashCode(Object) hashCode} methods of {@link\n+     * java.util.Objects} can be used to help construct simple hash codes.\n+     *\n@@ -87,1 +102,1 @@\n-     * @see     java.util.Hashtable\n+     * @see     java.lang.System#identityHashCode\n@@ -89,0 +104,1 @@\n+    @IntrinsicCandidate\n@@ -94,1 +110,1 @@\n-     * The <code>equals<\/code> method implements an equivalence relation\n+     * The {@code equals} method implements an equivalence relation\n@@ -98,2 +114,2 @@\n-     *     <code>x<\/code>, <code>x.equals(x)<\/code> should return\n-     *     <code>true<\/code>.\n+     *     {@code x}, {@code x.equals(x)} should return\n+     *     {@code true}.\n@@ -101,3 +117,3 @@\n-     *     <code>x<\/code> and <code>y<\/code>, <code>x.equals(y)<\/code>\n-     *     should return <code>true<\/code> if and only if\n-     *     <code>y.equals(x)<\/code> returns <code>true<\/code>.\n+     *     {@code x} and {@code y}, {@code x.equals(y)}\n+     *     should return {@code true} if and only if\n+     *     {@code y.equals(x)} returns {@code true}.\n@@ -105,4 +121,4 @@\n-     *     <code>x<\/code>, <code>y<\/code>, and <code>z<\/code>, if\n-     *     <code>x.equals(y)<\/code> returns <code>true<\/code> and\n-     *     <code>y.equals(z)<\/code> returns <code>true<\/code>, then\n-     *     <code>x.equals(z)<\/code> should return <code>true<\/code>.\n+     *     {@code x}, {@code y}, and {@code z}, if\n+     *     {@code x.equals(y)} returns {@code true} and\n+     *     {@code y.equals(z)} returns {@code true}, then\n+     *     {@code x.equals(z)} should return {@code true}.\n@@ -110,4 +126,4 @@\n-     *     <code>x<\/code> and <code>y<\/code>, multiple invocations of\n-     *     <tt>x.equals(y)<\/tt> consistently return <code>true<\/code>\n-     *     or consistently return <code>false<\/code>, provided no\n-     *     information used in <code>equals<\/code> comparisons on the\n+     *     {@code x} and {@code y}, multiple invocations of\n+     *     {@code x.equals(y)} consistently return {@code true}\n+     *     or consistently return {@code false}, provided no\n+     *     information used in {@code equals} comparisons on the\n@@ -115,2 +131,2 @@\n-     * <li>For any non-null reference value <code>x<\/code>,\n-     *     <code>x.equals(null)<\/code> should return <code>false<\/code>.\n+     * <li>For any non-null reference value {@code x},\n+     *     {@code x.equals(null)} should return {@code false}.\n@@ -118,0 +134,1 @@\n+     *\n@@ -119,1 +136,8 @@\n-     * The <tt>equals<\/tt> method for class <code>Object<\/code> implements\n+     * An equivalence relation partitions the elements it operates on\n+     * into <i>equivalence classes<\/i>; all the members of an\n+     * equivalence class are equal to each other. Members of an\n+     * equivalence class are substitutable for each other, at least\n+     * for some purposes.\n+     *\n+     * @implSpec\n+     * The {@code equals} method for class {@code Object} implements\n@@ -121,6 +145,10 @@\n-     * that is, for any non-null reference values <code>x<\/code> and\n-     * <code>y<\/code>, this method returns <code>true<\/code> if and only\n-     * if <code>x<\/code> and <code>y<\/code> refer to the same object\n-     * (<code>x == y<\/code> has the value <code>true<\/code>).\n-     * <p>\n-     * Note that it is generally necessary to override the <tt>hashCode<\/tt>\n+     * that is, for any non-null reference values {@code x} and\n+     * {@code y}, this method returns {@code true} if and only\n+     * if {@code x} and {@code y} refer to the same object\n+     * ({@code x == y} has the value {@code true}).\n+     *\n+     * In other words, under the reference equality equivalence\n+     * relation, each equivalence class only has a single element.\n+     *\n+     * @apiNote\n+     * It is generally necessary to override the {@link #hashCode() hashCode}\n@@ -128,1 +156,1 @@\n-     * general contract for the <tt>hashCode<\/tt> method, which states\n+     * general contract for the {@code hashCode} method, which states\n@@ -130,0 +158,3 @@\n+     * <p>The two-argument {@link java.util.Objects#equals(Object,\n+     * Object) Objects.equals} method implements an equivalence relation\n+     * on two possibly-null object references.\n@@ -132,2 +163,2 @@\n-     * @return  <code>true<\/code> if this object is the same as the obj\n-     *          argument; <code>false<\/code> otherwise.\n+     * @return  {@code true} if this object is the same as the obj\n+     *          argument; {@code false} otherwise.\n@@ -135,1 +166,1 @@\n-     * @see     java.util.Hashtable\n+     * @see     java.util.HashMap\n@@ -145,1 +176,1 @@\n-     * intent is that, for any object <tt>x<\/tt>, the expression:\n+     * intent is that, for any object {@code x}, the expression:\n@@ -153,1 +184,1 @@\n-     * will be <tt>true<\/tt>, but these are not absolute requirements.\n+     * will be {@code true}, but these are not absolute requirements.\n@@ -158,1 +189,1 @@\n-     * will be <tt>true<\/tt>, this is not an absolute requirement.\n+     * will be {@code true}, this is not an absolute requirement.\n@@ -161,3 +192,3 @@\n-     * <tt>super.clone<\/tt>.  If a class and all of its superclasses (except\n-     * <tt>Object<\/tt>) obey this convention, it will be the case that\n-     * <tt>x.clone().getClass() == x.getClass()<\/tt>.\n+     * {@code super.clone}.  If a class and all of its superclasses (except\n+     * {@code Object}) obey this convention, it will be the case that\n+     * {@code x.clone().getClass() == x.getClass()}.\n@@ -168,1 +199,1 @@\n-     * by <tt>super.clone<\/tt> before returning it.  Typically, this means\n+     * by {@code super.clone} before returning it.  Typically, this means\n@@ -173,1 +204,1 @@\n-     * the case that no fields in the object returned by <tt>super.clone<\/tt>\n+     * the case that no fields in the object returned by {@code super.clone}\n@@ -175,2 +206,3 @@\n-     * <p>\n-     * The method <tt>clone<\/tt> for class <tt>Object<\/tt> performs a\n+     *\n+     * @implSpec\n+     * The method {@code clone} for class {@code Object} performs a\n@@ -178,3 +210,5 @@\n-     * not implement the interface <tt>Cloneable<\/tt>, then a\n-     * <tt>CloneNotSupportedException<\/tt> is thrown. Note that all arrays\n-     * are considered to implement the interface <tt>Cloneable<\/tt>.\n+     * not implement the interface {@code Cloneable}, then a\n+     * {@code CloneNotSupportedException} is thrown. Note that all arrays\n+     * are considered to implement the interface {@code Cloneable} and that\n+     * the return type of the {@code clone} method of an array type {@code T[]}\n+     * is {@code T[]} where T is any reference or primitive type.\n@@ -187,3 +221,3 @@\n-     * The class <tt>Object<\/tt> does not itself implement the interface\n-     * <tt>Cloneable<\/tt>, so calling the <tt>clone<\/tt> method on an object\n-     * whose class is <tt>Object<\/tt> will result in throwing an\n+     * The class {@code Object} does not itself implement the interface\n+     * {@code Cloneable}, so calling the {@code clone} method on an object\n+     * whose class is {@code Object} will result in throwing an\n@@ -193,3 +227,3 @@\n-     * @exception  CloneNotSupportedException  if the object's class does not\n-     *               support the <code>Cloneable<\/code> interface. Subclasses\n-     *               that override the <code>clone<\/code> method can also\n+     * @throws  CloneNotSupportedException  if the object's class does not\n+     *               support the {@code Cloneable} interface. Subclasses\n+     *               that override the {@code clone} method can also\n@@ -200,0 +234,1 @@\n+    @IntrinsicCandidate\n@@ -203,2 +238,8 @@\n-     * Returns a string representation of the object. In general, the\n-     * <code>toString<\/code> method returns a string that\n+     * {@return a string representation of the object}\n+     *\n+     * Satisfying this method's contract implies a non-{@code null}\n+     * result must be returned.\n+     *\n+     * @apiNote\n+     * In general, the\n+     * {@code toString} method returns a string that\n@@ -209,2 +250,4 @@\n-     * <p>\n-     * The <code>toString<\/code> method for class <code>Object<\/code>\n+     * The string output is not necessarily stable over time or across\n+     * JVM invocations.\n+     * @implSpec\n+     * The {@code toString} method for class {@code Object}\n@@ -212,1 +255,1 @@\n-     * object is an instance, the at-sign character `<code>@<\/code>', and\n+     * object is an instance, the at-sign character `{@code @}', and\n@@ -216,2 +259,1 @@\n-     * <blockquote>\n-     * <pre>\n+     * {@snippet lang=java :\n@@ -219,3 +261,6 @@\n-     * <\/pre><\/blockquote>\n-     *\n-     * @return  a string representation of the object.\n+     * }\n+     * The {@link java.util.Objects#toIdentityString(Object)\n+     * Objects.toIdentityString} method returns the string for an\n+     * object equal to the string that would be returned if neither\n+     * the {@code toString} nor {@code hashCode} methods were\n+     * overridden by the object's class.\n@@ -233,1 +278,1 @@\n-     * monitor by calling one of the <code>wait<\/code> methods.\n+     * monitor by calling one of the {@code wait} methods.\n@@ -247,1 +292,1 @@\n-     * <li>By executing the body of a <code>synchronized<\/code> statement\n+     * <li>By executing the body of a {@code synchronized} statement\n@@ -249,2 +294,2 @@\n-     * <li>For objects of type <code>Class,<\/code> by executing a\n-     *     synchronized static method of that class.\n+     * <li>For objects of type {@code Class,} by executing a\n+     *     static synchronized method of that class.\n@@ -255,1 +300,1 @@\n-     * @exception  IllegalMonitorStateException  if the current thread is not\n+     * @throws  IllegalMonitorStateException  if the current thread is not\n@@ -260,0 +305,1 @@\n+    @IntrinsicCandidate\n@@ -265,1 +311,1 @@\n-     * <code>wait<\/code> methods.\n+     * {@code wait} methods.\n@@ -275,1 +321,1 @@\n-     * of this object's monitor. See the <code>notify<\/code> method for a\n+     * of this object's monitor. See the {@code notify} method for a\n@@ -279,1 +325,1 @@\n-     * @exception  IllegalMonitorStateException  if the current thread is not\n+     * @throws  IllegalMonitorStateException  if the current thread is not\n@@ -284,0 +330,1 @@\n+    @IntrinsicCandidate\n@@ -287,35 +334,2 @@\n-     * Causes current thread to wait until either another thread invokes the\n-     * {@link java.lang.Object#notify()} method or the\n-     * {@link java.lang.Object#notifyAll()} method for this object, or a\n-     * specified amount of time has elapsed.\n-     * <p>\n-     * The current thread must own this object's monitor.\n-     * <p>\n-     * This method causes the current thread (call it <var>T<\/var>) to\n-     * place itself in the wait set for this object and then to relinquish\n-     * any and all synchronization claims on this object. Thread <var>T<\/var>\n-     * becomes disabled for thread scheduling purposes and lies dormant\n-     * until one of four things happens:\n-     * <ul>\n-     * <li>Some other thread invokes the <tt>notify<\/tt> method for this\n-     * object and thread <var>T<\/var> happens to be arbitrarily chosen as\n-     * the thread to be awakened.\n-     * <li>Some other thread invokes the <tt>notifyAll<\/tt> method for this\n-     * object.\n-     * <li>Some other thread {@link java.lang.Thread#interrupt() interrupts}\n-     * thread <var>T<\/var>.\n-     * <li>The specified amount of real time has elapsed, more or less.  If\n-     * <tt>timeout<\/tt> is zero, however, then real time is not taken into\n-     * consideration and the thread simply waits until notified.\n-     * <\/ul>\n-     * The thread <var>T<\/var> is then removed from the wait set for this\n-     * object and re-enabled for thread scheduling. It then competes in the\n-     * usual manner with other threads for the right to synchronize on the\n-     * object; once it has gained control of the object, all its\n-     * synchronization claims on the object are restored to the status quo\n-     * ante - that is, to the situation as of the time that the <tt>wait<\/tt>\n-     * method was invoked. Thread <var>T<\/var> then returns from the\n-     * invocation of the <tt>wait<\/tt> method. Thus, on return from the\n-     * <tt>wait<\/tt> method, the synchronization state of the object and of\n-     * thread <tt>T<\/tt> is exactly as it was when the <tt>wait<\/tt> method\n-     * was invoked.\n+     * Causes the current thread to wait until it is awakened, typically\n+     * by being <em>notified<\/em> or <em>interrupted<\/em>.\n@@ -323,28 +337,23 @@\n-     * A thread can also wake up without being notified, interrupted, or\n-     * timing out, a so-called <i>spurious wakeup<\/i>.  While this will rarely\n-     * occur in practice, applications must guard against it by testing for\n-     * the condition that should have caused the thread to be awakened, and\n-     * continuing to wait if the condition is not satisfied.  In other words,\n-     * waits should always occur in loops, like this one:\n-     * <pre>\n-     *     synchronized (obj) {\n-     *         while (&lt;condition does not hold&gt;)\n-     *             obj.wait(timeout);\n-     *         ... \/\/ Perform action appropriate to condition\n-     *     }\n-     * <\/pre>\n-     * (For more information on this topic, see Section 3.2.3 in Doug Lea's\n-     * \"Concurrent Programming in Java (Second Edition)\" (Addison-Wesley,\n-     * 2000), or Item 50 in Joshua Bloch's \"Effective Java Programming\n-     * Language Guide\" (Addison-Wesley, 2001).\n-     * <p>\n-     * If the current thread is\n-     * {@link java.lang.Thread#interrupt() interrupted} by another thread\n-     * while it is waiting, then an <tt>InterruptedException<\/tt> is thrown.\n-     * This exception is not thrown until the lock status of this object has\n-     * been restored as described above.\n-     * <p>\n-     * Note that the <tt>wait<\/tt> method, as it places the current thread\n-     * into the wait set for this object, unlocks only this object; any\n-     * other objects on which the current thread may be synchronized remain\n-     * locked while the thread waits.\n+     * In all respects, this method behaves as if {@code wait(0L, 0)}\n+     * had been called. See the specification of the {@link #wait(long, int)} method\n+     * for details.\n+     *\n+     * @throws IllegalMonitorStateException if the current thread is not\n+     *         the owner of the object's monitor\n+     * @throws InterruptedException if any thread interrupted the current thread before or\n+     *         while the current thread was waiting. The <em>interrupted status<\/em> of the\n+     *         current thread is cleared when this exception is thrown.\n+     * @see    #notify()\n+     * @see    #notifyAll()\n+     * @see    #wait(long)\n+     * @see    #wait(long, int)\n+     *\/\n+    public final void wait() throws InterruptedException {\n+        bi04t002a.instrInvoke(bi04t002a.INSTR_WAIT);\n+        wait(0L);\n+    }\n+\n+    \/**\n+     * Causes the current thread to wait until it is awakened, typically\n+     * by being <em>notified<\/em> or <em>interrupted<\/em>, or until a\n+     * certain amount of real time has elapsed.\n@@ -352,4 +361,3 @@\n-     * This method should only be called by a thread that is the owner\n-     * of this object's monitor. See the <code>notify<\/code> method for a\n-     * description of the ways in which a thread can become the owner of\n-     * a monitor.\n+     * In all respects, this method behaves as if {@code wait(timeoutMillis, 0)}\n+     * had been called. See the specification of the {@link #wait(long, int)} method\n+     * for details.\n@@ -357,12 +365,11 @@\n-     * @param      timeout   the maximum time to wait in milliseconds.\n-     * @exception  IllegalArgumentException      if the value of timeout is\n-     *               negative.\n-     * @exception  IllegalMonitorStateException  if the current thread is not\n-     *               the owner of the object's monitor.\n-     * @exception  InterruptedException if another thread interrupted the\n-     *             current thread before or while the current thread\n-     *             was waiting for a notification.  The <i>interrupted\n-     *             status<\/i> of the current thread is cleared when\n-     *             this exception is thrown.\n-     * @see        java.lang.Object#notify()\n-     * @see        java.lang.Object#notifyAll()\n+     * @param  timeoutMillis the maximum time to wait, in milliseconds\n+     * @throws IllegalArgumentException if {@code timeoutMillis} is negative\n+     * @throws IllegalMonitorStateException if the current thread is not\n+     *         the owner of the object's monitor\n+     * @throws InterruptedException if any thread interrupted the current thread before or\n+     *         while the current thread was waiting. The <em>interrupted status<\/em> of the\n+     *         current thread is cleared when this exception is thrown.\n+     * @see    #notify()\n+     * @see    #notifyAll()\n+     * @see    #wait()\n+     * @see    #wait(long, int)\n@@ -371,3 +378,2 @@\n-        if (!Thread.currentThread().isVirtual()) {\n-            wait0(timeoutMillis);\n-            return;\n+        if (timeoutMillis < 0) {\n+            throw new IllegalArgumentException(\"timeout value is negative\");\n@@ -376,3 +382,13 @@\n-        \/\/ virtual thread waiting\n-        boolean attempted = Blocker.begin();\n-        try {\n+        if (Thread.currentThread() instanceof VirtualThread vthread) {\n+            try {\n+                wait0(timeoutMillis);\n+            } catch (InterruptedException e) {\n+                \/\/ virtual thread's interrupt status needs to be cleared\n+                vthread.getAndClearInterrupt();\n+                throw e;\n+            } finally {\n+                if (timeoutMillis > 0) {\n+                    vthread.cancelWaitTimeout();\n+                }\n+            }\n+        } else {\n@@ -380,6 +396,0 @@\n-        } catch (InterruptedException e) {\n-            \/\/ virtual thread's interrupt status needs to be cleared\n-            Thread.currentThread().getAndClearInterrupt();\n-            throw e;\n-        } finally {\n-            Blocker.end(attempted);\n@@ -389,0 +399,3 @@\n+    \/\/ final modifier so method not in vtable\n+    private final native void wait0(long timeoutMillis) throws InterruptedException;\n+\n@@ -390,21 +403,16 @@\n-     * Causes current thread to wait until another thread invokes the\n-     * {@link java.lang.Object#notify()} method or the\n-     * {@link java.lang.Object#notifyAll()} method for this object, or\n-     * some other thread interrupts the current thread, or a certain\n-     * amount of real time has elapsed.\n-     * <p>\n-     * This method is similar to the <code>wait<\/code> method of one\n-     * argument, but it allows finer control over the amount of time to\n-     * wait for a notification before giving up. The amount of real time,\n-     * measured in nanoseconds, is given by:\n-     * <blockquote>\n-     * <pre>\n-     * 1000000*timeout+nanos<\/pre><\/blockquote>\n-     * <p>\n-     * In all other respects, this method does the same thing as the\n-     * method {@link #wait(long)} of one argument. In particular,\n-     * <tt>wait(0, 0)<\/tt> means the same thing as <tt>wait(0)<\/tt>.\n-     * <p>\n-     * The current thread must own this object's monitor. The thread\n-     * releases ownership of this monitor and waits until either of the\n-     * following two conditions has occurred:\n+     * Causes the current thread to wait until it is awakened, typically\n+     * by being <em>notified<\/em> or <em>interrupted<\/em>, or until a\n+     * certain amount of real time has elapsed.\n+     * <p>\n+     * The current thread must own this object's monitor lock. See the\n+     * {@link #notify notify} method for a description of the ways in which\n+     * a thread can become the owner of a monitor lock.\n+     * <p>\n+     * This method causes the current thread (referred to here as <var>T<\/var>) to\n+     * place itself in the wait set for this object and then to relinquish any\n+     * and all synchronization claims on this object. Note that only the locks\n+     * on this object are relinquished; any other objects on which the current\n+     * thread may be synchronized remain locked while the thread waits.\n+     * <p>\n+     * Thread <var>T<\/var> then becomes disabled for thread scheduling purposes\n+     * and lies dormant until one of the following occurs:\n@@ -412,6 +420,13 @@\n-     * <li>Another thread notifies threads waiting on this object's monitor\n-     *     to wake up either through a call to the <code>notify<\/code> method\n-     *     or the <code>notifyAll<\/code> method.\n-     * <li>The timeout period, specified by <code>timeout<\/code>\n-     *     milliseconds plus <code>nanos<\/code> nanoseconds arguments, has\n-     *     elapsed.\n+     * <li>Some other thread invokes the {@code notify} method for this\n+     * object and thread <var>T<\/var> happens to be arbitrarily chosen as\n+     * the thread to be awakened.\n+     * <li>Some other thread invokes the {@code notifyAll} method for this\n+     * object.\n+     * <li>Some other thread {@linkplain Thread#interrupt() interrupts}\n+     * thread <var>T<\/var>.\n+     * <li>The specified amount of real time has elapsed, more or less.\n+     * The amount of real time, in nanoseconds, is given by the expression\n+     * {@code 1000000 * timeoutMillis + nanos}. If {@code timeoutMillis} and {@code nanos}\n+     * are both zero, then real time is not taken into consideration and the\n+     * thread waits until awakened by one of the other causes.\n+     * <li>Thread <var>T<\/var> is awakened spuriously. (See below.)\n@@ -420,2 +435,11 @@\n-     * The thread then waits until it can re-obtain ownership of the\n-     * monitor and resumes execution.\n+     * The thread <var>T<\/var> is then removed from the wait set for this\n+     * object and re-enabled for thread scheduling. It competes in the\n+     * usual manner with other threads for the right to synchronize on the\n+     * object; once it has regained control of the object, all its\n+     * synchronization claims on the object are restored to the status quo\n+     * ante - that is, to the situation as of the time that the {@code wait}\n+     * method was invoked. Thread <var>T<\/var> then returns from the\n+     * invocation of the {@code wait} method. Thus, on return from the\n+     * {@code wait} method, the synchronization state of the object and of\n+     * thread {@code T} is exactly as it was when the {@code wait} method\n+     * was invoked.\n@@ -423,3 +447,25 @@\n-     * As in the one argument version, interrupts and spurious wakeups are\n-     * possible, and this method should always be used in a loop:\n-     * <pre>\n+     * A thread can wake up without being notified, interrupted, or timing out, a\n+     * so-called <em>spurious wakeup<\/em>.  While this will rarely occur in practice,\n+     * applications must guard against it by testing for the condition that should\n+     * have caused the thread to be awakened, and continuing to wait if the condition\n+     * is not satisfied. See the example below.\n+     * <p>\n+     * For more information on this topic, see section 14.2,\n+     * \"Condition Queues,\" in Brian Goetz and others' <cite>Java Concurrency\n+     * in Practice<\/cite> (Addison-Wesley, 2006) or Item 81 in Joshua\n+     * Bloch's <cite>Effective Java, Third Edition<\/cite> (Addison-Wesley,\n+     * 2018).\n+     * <p>\n+     * If the current thread is {@linkplain java.lang.Thread#interrupt() interrupted}\n+     * by any thread before or while it is waiting, then an {@code InterruptedException}\n+     * is thrown.  The <em>interrupted status<\/em> of the current thread is cleared when\n+     * this exception is thrown. This exception is not thrown until the lock status of\n+     * this object has been restored as described above.\n+     *\n+     * @apiNote\n+     * The recommended approach to waiting is to check the condition being awaited in\n+     * a {@code while} loop around the call to {@code wait}, as shown in the example\n+     * below. Among other things, this approach avoids problems that can be caused\n+     * by spurious wakeups.\n+     *\n+     * {@snippet lang=java :\n@@ -427,3 +473,6 @@\n-     *         while (&lt;condition does not hold&gt;)\n-     *             obj.wait(timeout, nanos);\n-     *         ... \/\/ Perform action appropriate to condition\n+     *         while ( <condition does not hold and timeout not exceeded> ) {\n+     *             long timeoutMillis = ... ; \/\/ recompute timeout values\n+     *             int nanos = ... ;\n+     *             obj.wait(timeoutMillis, nanos);\n+     *         }\n+     *         ... \/\/ Perform action appropriate to condition or timeout\n@@ -431,5 +480,1 @@\n-     * <\/pre>\n-     * This method should only be called by a thread that is the owner\n-     * of this object's monitor. See the <code>notify<\/code> method for a\n-     * description of the ways in which a thread can become the owner of\n-     * a monitor.\n+     * }\n@@ -437,13 +482,13 @@\n-     * @param      timeout   the maximum time to wait in milliseconds.\n-     * @param      nanos      additional time, in nanoseconds range\n-     *                       0-999999.\n-     * @exception  IllegalArgumentException      if the value of timeout is\n-     *                      negative or the value of nanos is\n-     *                      not in the range 0-999999.\n-     * @exception  IllegalMonitorStateException  if the current thread is not\n-     *               the owner of this object's monitor.\n-     * @exception  InterruptedException if another thread interrupted the\n-     *             current thread before or while the current thread\n-     *             was waiting for a notification.  The <i>interrupted\n-     *             status<\/i> of the current thread is cleared when\n-     *             this exception is thrown.\n+     * @param  timeoutMillis the maximum time to wait, in milliseconds\n+     * @param  nanos   additional time, in nanoseconds, in the range 0-999999 inclusive\n+     * @throws IllegalArgumentException if {@code timeoutMillis} is negative,\n+     *         or if the value of {@code nanos} is out of range\n+     * @throws IllegalMonitorStateException if the current thread is not\n+     *         the owner of the object's monitor\n+     * @throws InterruptedException if any thread interrupted the current thread before or\n+     *         while the current thread was waiting. The <em>interrupted status<\/em> of the\n+     *         current thread is cleared when this exception is thrown.\n+     * @see    #notify()\n+     * @see    #notifyAll()\n+     * @see    #wait()\n+     * @see    #wait(long)\n@@ -451,1 +496,1 @@\n-    public final void wait(long timeout, int nanos) throws InterruptedException {\n+    public final void wait(long timeoutMillis, int nanos) throws InterruptedException {\n@@ -455,2 +500,2 @@\n-        if (timeout < 0) {\n-            throw new IllegalArgumentException(\"timeout value is negative\");\n+        if (timeoutMillis < 0) {\n+            throw new IllegalArgumentException(\"timeoutMillis value is negative\");\n@@ -464,9 +509,3 @@\n-            if (nanos >= 500000 || (nanos != 0 && timeout == 0)) {\n-                timeout++;\n-            }\n-\n-            wait(timeout);\n-    }\n-\n-    \/\/ final modifier so method not in vtable\n-    private final native void wait0(long timeoutMillis) throws InterruptedException;\n+        if (nanos > 0 && timeoutMillis < Long.MAX_VALUE) {\n+            timeoutMillis++;\n+        }\n@@ -474,41 +513,1 @@\n-    \/**\n-     * Causes current thread to wait until another thread invokes the\n-     * {@link java.lang.Object#notify()} method or the\n-     * {@link java.lang.Object#notifyAll()} method for this object.\n-     * In other words, this method behaves exactly as if it simply\n-     * performs the call <tt>wait(0)<\/tt>.\n-     * <p>\n-     * The current thread must own this object's monitor. The thread\n-     * releases ownership of this monitor and waits until another thread\n-     * notifies threads waiting on this object's monitor to wake up\n-     * either through a call to the <code>notify<\/code> method or the\n-     * <code>notifyAll<\/code> method. The thread then waits until it can\n-     * re-obtain ownership of the monitor and resumes execution.\n-     * <p>\n-     * As in the one argument version, interrupts and spurious wakeups are\n-     * possible, and this method should always be used in a loop:\n-     * <pre>\n-     *     synchronized (obj) {\n-     *         while (&lt;condition does not hold&gt;)\n-     *             obj.wait();\n-     *         ... \/\/ Perform action appropriate to condition\n-     *     }\n-     * <\/pre>\n-     * This method should only be called by a thread that is the owner\n-     * of this object's monitor. See the <code>notify<\/code> method for a\n-     * description of the ways in which a thread can become the owner of\n-     * a monitor.\n-     *\n-     * @exception  IllegalMonitorStateException  if the current thread is not\n-     *               the owner of the object's monitor.\n-     * @exception  InterruptedException if another thread interrupted the\n-     *             current thread before or while the current thread\n-     *             was waiting for a notification.  The <i>interrupted\n-     *             status<\/i> of the current thread is cleared when\n-     *             this exception is thrown.\n-     * @see        java.lang.Object#notify()\n-     * @see        java.lang.Object#notifyAll()\n-     *\/\n-    public final void wait() throws InterruptedException {\n-        bi04t002a.instrInvoke(bi04t002a.INSTR_WAIT);\n-        wait(0);\n+        wait(timeoutMillis);\n@@ -520,1 +519,1 @@\n-     * A subclass overrides the <code>finalize<\/code> method to dispose of\n+     * A subclass overrides the {@code finalize} method to dispose of\n@@ -523,2 +522,8 @@\n-     * The general contract of <tt>finalize<\/tt> is that it is invoked\n-     * if and when the Java<font size=\"-2\"><sup>TM<\/sup><\/font> virtual\n+     * <b>When running in a Java virtual machine in which finalization has been\n+     * disabled or removed, the garbage collector will never call\n+     * {@code finalize()}. In a Java virtual machine in which finalization is\n+     * enabled, the garbage collector might call {@code finalize} only after an\n+     * indefinite delay.<\/b>\n+     * <p>\n+     * The general contract of {@code finalize} is that it is invoked\n+     * if and when the Java virtual\n@@ -529,1 +534,1 @@\n-     * finalized. The <tt>finalize<\/tt> method may take any action, including\n+     * finalized. The {@code finalize} method may take any action, including\n@@ -531,1 +536,1 @@\n-     * of <tt>finalize<\/tt>, however, is to perform cleanup actions before\n+     * of {@code finalize}, however, is to perform cleanup actions before\n@@ -537,1 +542,1 @@\n-     * The <tt>finalize<\/tt> method of class <tt>Object<\/tt> performs no\n+     * The {@code finalize} method of class {@code Object} performs no\n@@ -539,1 +544,1 @@\n-     * <tt>Object<\/tt> may override this definition.\n+     * {@code Object} may override this definition.\n@@ -542,1 +547,1 @@\n-     * invoke the <tt>finalize<\/tt> method for any given object. It is\n+     * invoke the {@code finalize} method for any given object. It is\n@@ -548,1 +553,1 @@\n-     * After the <tt>finalize<\/tt> method has been invoked for an object, no\n+     * After the {@code finalize} method has been invoked for an object, no\n@@ -555,1 +560,1 @@\n-     * The <tt>finalize<\/tt> method is never invoked more than once by a Java\n+     * The {@code finalize} method is never invoked more than once by a Java\n@@ -558,1 +563,1 @@\n-     * Any exception thrown by the <code>finalize<\/code> method causes\n+     * Any exception thrown by the {@code finalize} method causes\n@@ -562,1 +567,49 @@\n-     * @throws Throwable the <code>Exception<\/code> raised by this method\n+     * @apiNote\n+     * Classes that embed non-heap resources have many options\n+     * for cleanup of those resources. The class must ensure that the\n+     * lifetime of each instance is longer than that of any resource it embeds.\n+     * {@link java.lang.ref.Reference#reachabilityFence} can be used to ensure that\n+     * objects remain reachable while resources embedded in the object are in use.\n+     * <p>\n+     * A subclass should avoid overriding the {@code finalize} method\n+     * unless the subclass embeds non-heap resources that must be cleaned up\n+     * before the instance is collected.\n+     * Finalizer invocations are not automatically chained, unlike constructors.\n+     * If a subclass overrides {@code finalize} it must invoke the superclass\n+     * finalizer explicitly.\n+     * To guard against exceptions prematurely terminating the finalize chain,\n+     * the subclass should use a {@code try-finally} block to ensure\n+     * {@code super.finalize()} is always invoked. For example,\n+     * {@snippet lang=\"java\":\n+     *     @Override\n+     *     protected void finalize() throws Throwable {\n+     *         try {\n+     *             ... \/\/ cleanup subclass state\n+     *         } finally {\n+     *             super.finalize();\n+     *         }\n+     *     }\n+     * }\n+     *\n+     * @deprecated Finalization is deprecated and subject to removal in a future\n+     * release. The use of finalization can lead to problems with security,\n+     * performance, and reliability.\n+     * See <a href=\"https:\/\/openjdk.org\/jeps\/421\">JEP 421<\/a> for\n+     * discussion and alternatives.\n+     * <p>\n+     * Subclasses that override {@code finalize} to perform cleanup should use\n+     * alternative cleanup mechanisms and remove the {@code finalize} method.\n+     * Use {@link java.lang.ref.Cleaner} and\n+     * {@link java.lang.ref.PhantomReference} as safer ways to release resources\n+     * when an object becomes unreachable. Alternatively, add a {@code close}\n+     * method to explicitly release resources, and implement\n+     * {@code AutoCloseable} to enable use of the {@code try}-with-resources\n+     * statement.\n+     * <p>\n+     * This method will remain in place until finalizers have been removed from\n+     * most existing code.\n+     *\n+     * @throws Throwable the {@code Exception} raised by this method\n+     * @see java.lang.ref.WeakReference\n+     * @see java.lang.ref.PhantomReference\n+     * @jls 12.6 Finalization of Class Instances\n@@ -564,0 +617,1 @@\n+    @Deprecated(since=\"9\", forRemoval=true)\n@@ -565,1 +619,0 @@\n-\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/bcinstr\/BI04\/bi04t002\/newclass02\/java.base\/java\/lang\/Object.java","additions":365,"deletions":312,"binary":false,"changes":677,"status":"modified"},{"patch":"@@ -1,147 +0,0 @@\n-\/*\n- * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-\/**\n- * @test\n- * @bug 8292240\n- * @summary Test the scenario where a blocking operation pins a virtual thread to its\n- *   carrier thread (cT1) and doesn't activate a spare. Subsequent blocking operations\n- *   that pin a virtual thread to cT1 should attempt to activate a spare.\n- * @requires vm.continuations\n- * @run main\/othervm\n- *     -Djdk.virtualThreadScheduler.parallelism=1\n- *     -Djdk.virtualThreadScheduler.maxPoolSize=2 ActivateSpareCarrier 100\n- *\/\n-\n-import java.time.Duration;\n-import java.util.Comparator;\n-import java.util.List;\n-import java.util.concurrent.ForkJoinWorkerThread;\n-import java.util.stream.Collectors;\n-\n-public class ActivateSpareCarrier {\n-\n-    private static final int DEFAULT_ITERTAIONS = 10_000;\n-\n-    private static final Object LOCK = new Object();\n-\n-    public static void main(String[] args) throws Exception {\n-        int iterations;\n-        if (args.length == 0) {\n-            iterations = DEFAULT_ITERTAIONS;\n-        } else {\n-            iterations = Integer.parseInt(args[0]);\n-        }\n-        for (int i = 0; i < iterations; i++) {\n-            test(i);\n-        }\n-    }\n-\n-    \/**\n-     * This method creates 3 virtual threads:\n-     * - thread1 blocks in Object.wait, activating a spare carrier thread\n-     * - thread2 is started and runs on the spare carrier thread\n-     * - thread1 is notified causing it to re-adjust the release count and terminate\n-     * - thread3 is started and should run on the one active thread\n-     *\n-     * This method need invoked at least twice in the same VM.\n-     *\/\n-    private static void test(int i) throws Exception {\n-        System.out.printf(\"---- %d ----%n\", i);\n-\n-        \/\/ thread1 blocks in wait, this triggers a tryCompensate to activate a spare thread\n-        Thread thread1 = Thread.ofVirtual().unstarted(() -> {\n-            System.out.println(Thread.currentThread());\n-            synchronized (LOCK) {\n-                try {\n-                    LOCK.wait();\n-                } catch (InterruptedException e) { }\n-            }\n-        });\n-        System.out.printf(\"starting waiter thread #%d%n\", thread1.threadId());\n-        thread1.start();\n-\n-        \/\/ wait for thread1 to block in Object.wait\n-        while (thread1.getState() != Thread.State.WAITING) {\n-            Thread.sleep(10);\n-        }\n-\n-        \/\/ start another virtual thread, it should run on the spare carrier thread\n-        startAndJoinVirtualThread();\n-\n-        \/\/ notify thread1, this releases the blocker\n-        synchronized (LOCK) {\n-            LOCK.notifyAll();\n-        }\n-        joinThread(thread1);\n-\n-        \/\/ start another virtual thread after counts have been re-adjusted\n-        startAndJoinVirtualThread();\n-    }\n-\n-    \/**\n-     * Start a virtual thread and wait for it to terminate.\n-     *\/\n-    private static void startAndJoinVirtualThread() throws InterruptedException {\n-        Thread thread = Thread.ofVirtual().unstarted(() -> {\n-            System.out.println(Thread.currentThread());\n-        });\n-        System.out.format(\"starting #%d%n\", thread.threadId());\n-        thread.start();\n-        joinThread(thread);\n-    }\n-\n-    \/**\n-     * Wait for the give thread to terminate with diagnostic output if the thread does\n-     * not terminate quickly.\n-     *\/\n-    private static void joinThread(Thread thread) throws InterruptedException {\n-        long tid = thread.threadId();\n-        System.out.printf(\"Waiting for #%d to terminate%n\", tid);\n-        boolean terminated = thread.join(Duration.ofSeconds(2));\n-        if (!terminated) {\n-            System.out.printf(\"#%d did not terminate quickly, continue to wait...%n\", tid);\n-            printForkJoinWorkerThreads();\n-            thread.join();\n-        }\n-        System.out.printf(\"#%d terminated%n\", tid);\n-    }\n-\n-    \/**\n-     * Print the list of ForkJoinWorkerThreads and their stack traces.\n-     *\/\n-    private static void printForkJoinWorkerThreads() {\n-        List<Thread> threads = Thread.getAllStackTraces().keySet().stream()\n-                .filter(t -> t instanceof ForkJoinWorkerThread)\n-                .sorted(Comparator.comparingLong(Thread::threadId))\n-                .collect(Collectors.toList());\n-        System.out.println(\"ForkJoinWorkerThreads:\");\n-        for (Thread t : threads) {\n-            System.out.printf(\"    %s%n\", t);\n-            StackTraceElement[] stack = t.getStackTrace();\n-            for (StackTraceElement e : stack) {\n-                System.out.printf(\"      %s%n\", e);\n-            }\n-        }\n-    }\n-}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/ActivateSpareCarrier.java","additions":0,"deletions":147,"binary":false,"changes":147,"status":"deleted"},{"patch":"@@ -0,0 +1,102 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Test cancelling a timeout task for Object.wait(millis) when there is\n+ *     contention on the timer queue\n+ * @key randomness\n+ * @run main\/othervm\n+ *     -Djdk.virtualThreadScheduler.parallelism=2\n+ *     -Djdk.virtualThreadScheduler.timerQueues=1\n+ *     CancelTimerWithContention\n+ *\/\n+\n+import java.time.Instant;\n+import java.util.Random;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CancelTimerWithContention {\n+\n+    \/\/ number of threads\n+    private static final int MIN_THREADS = 100;\n+    private static final int MAX_THREADS = 10_000;\n+\n+    \/\/ number of monitors to enter\n+    private static final int MIN_MONITORS = 2;\n+    private static final int MAX_MONITORS = 8;\n+\n+    private static final Random RAND = new Random();\n+\n+    public static void main(String[] args) {\n+        for (int threadCount = MIN_THREADS; threadCount <= MAX_THREADS; threadCount += 100) {\n+            System.out.format(\"%s #threads = %d%n\", Instant.now(), threadCount);\n+            for (int lockCount = MIN_MONITORS; lockCount <= MAX_MONITORS;  lockCount += 2) {\n+                test(threadCount, lockCount);\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test threads entering monitors and using Object.wait(millis) to wait. This\n+     * testing scenario leads to a mix of contention (with responsible threads using\n+     * short timeouts), timed-wait, and cancellation of timer tasks. This scenario\n+     * can result in contention of the timer queue.\n+     *\/\n+    static void test(int threadCount, int monitorCount) {\n+        var locks = new Object[monitorCount];\n+        for (int i = 0; i < monitorCount; i++) {\n+            locks[i] = new Object();\n+        }\n+\n+        try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n+            var finished = new AtomicInteger();\n+\n+            for (int i = 0; i < threadCount; i++) {\n+                Object lock = locks[RAND.nextInt(monitorCount)];    \/\/ random lock\n+\n+                executor.submit(() -> {\n+                    synchronized (lock) {\n+                        lock.wait(Long.MAX_VALUE);\n+                    }\n+                    finished.incrementAndGet();\n+                    return null;\n+                });\n+\n+                synchronized (lock) {\n+                    lock.notify();\n+                }\n+            }\n+\n+            \/\/ notify at most one thread until all threads are finished\n+            while (finished.get() < threadCount) {\n+                for (Object lock : locks) {\n+                    synchronized (lock) {\n+                        lock.notify();\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/CancelTimerWithContention.java","additions":102,"deletions":0,"binary":false,"changes":102,"status":"added"},{"patch":"@@ -65,5 +65,2 @@\n-        int minParallelism = 2;\n-        if (Thread.currentThread().isVirtual()) {\n-            minParallelism++;\n-        }\n-        VThreadRunner.ensureParallelism(minParallelism);\n+        \/\/ need at least two carriers to test pinning\n+        VThreadRunner.ensureParallelism(2);\n@@ -143,0 +140,217 @@\n+    \/**\n+     * Test jdk.VirtualThreadPinned event when blocking on monitor while pinned.\n+     *\/\n+    @Test\n+    void testBlockWhenPinned() throws Exception {\n+        try (Recording recording = new Recording()) {\n+            recording.enable(\"jdk.VirtualThreadPinned\");\n+            recording.start();\n+\n+            Object lock = new Object();\n+\n+            var started = new AtomicBoolean();\n+            var vthread = Thread.ofVirtual().unstarted(() -> {\n+                VThreadPinner.runPinned(() -> {\n+                    started.set(true);\n+                    synchronized (lock) { }\n+                });\n+            });\n+\n+            try {\n+                synchronized (lock) {\n+                    vthread.start();\n+                    \/\/ wait for thread to start and block\n+                    awaitTrue(started);\n+                    await(vthread, Thread.State.BLOCKED);\n+                }\n+            } finally {\n+                vthread.join();\n+                recording.stop();\n+            }\n+\n+            assertContainsPinnedEvent(recording, vthread);\n+        }\n+    }\n+\n+    \/**\n+     * Test jdk.VirtualThreadPinned event when waiting with Object.wait while pinned.\n+     *\/\n+    @ParameterizedTest\n+    @ValueSource(booleans = { true, false })\n+    void testObjectWaitWhenPinned(boolean timed) throws Exception {\n+        try (Recording recording = new Recording()) {\n+            recording.enable(\"jdk.VirtualThreadPinned\");\n+            recording.start();\n+\n+            Object lock = new Object();\n+\n+            var started = new AtomicBoolean();\n+            var vthread = Thread.startVirtualThread(() -> {\n+                VThreadPinner.runPinned(() -> {\n+                    started.set(true);\n+                    synchronized (lock) {\n+                        try {\n+                            if (timed) {\n+                                lock.wait(Long.MAX_VALUE);\n+                            } else {\n+                                lock.wait();\n+                            }\n+                        } catch (InterruptedException e) {\n+                            fail();\n+                        }\n+                    }\n+                });\n+            });\n+\n+            try {\n+                \/\/ wait for thread to start and wait\n+                awaitTrue(started);\n+                await(vthread, timed ? Thread.State.TIMED_WAITING : Thread.State.WAITING);\n+            } finally {\n+                synchronized (lock) {\n+                    lock.notifyAll();\n+                }\n+                vthread.join();\n+                recording.stop();\n+            }\n+\n+            assertContainsPinnedEvent(recording, vthread);\n+        }\n+    }\n+\n+    \/**\n+     * Test jdk.VirtualThreadPinned event when parking in a class initializer.\n+     *\/\n+    @Test\n+    void testParkInClassInitializer() throws Exception {\n+        class TestClass {\n+            static {\n+                LockSupport.park();\n+            }\n+            static void m() {\n+                \/\/ do nothing\n+            }\n+        }\n+\n+        try (Recording recording = new Recording()) {\n+            recording.enable(\"jdk.VirtualThreadPinned\");\n+            recording.start();\n+\n+            var started = new AtomicBoolean();\n+            Thread vthread = Thread.startVirtualThread(() -> {\n+                started.set(true);\n+                TestClass.m();\n+            });\n+\n+            try {\n+                \/\/ wait for it to start and park\n+                awaitTrue(started);\n+                await(vthread, Thread.State.WAITING);\n+            } finally {\n+                LockSupport.unpark(vthread);\n+                vthread.join();\n+                recording.stop();\n+            }\n+\n+            assertContainsPinnedEvent(recording, vthread);\n+        }\n+    }\n+\n+    \/**\n+     * Test jdk.VirtualThreadPinned event when blocking on monitor in a class initializer.\n+     *\/\n+    @Test\n+    void testBlockInClassInitializer() throws Exception {\n+        class LockHolder {\n+            static final Object lock = new Object();\n+        }\n+        class TestClass {\n+            static {\n+                synchronized (LockHolder.lock) { }\n+            }\n+            static void m() {\n+                \/\/ no nothing\n+            }\n+        }\n+\n+        try (Recording recording = new Recording()) {\n+            recording.enable(\"jdk.VirtualThreadPinned\");\n+            recording.start();\n+\n+            var started = new AtomicBoolean();\n+            Thread vthread = Thread.ofVirtual().unstarted(() -> {\n+                started.set(true);\n+                TestClass.m();\n+            });\n+\n+            try {\n+                synchronized (LockHolder.lock) {\n+                    vthread.start();\n+                    \/\/ wait for thread to start and block\n+                    awaitTrue(started);\n+                    await(vthread, Thread.State.BLOCKED);\n+                }\n+            } finally {\n+                vthread.join();\n+                recording.stop();\n+            }\n+\n+            assertContainsPinnedEvent(recording, vthread);\n+        }\n+    }\n+\n+    \/**\n+     * Test jdk.VirtualThreadPinned event when waiting for a class initializer.\n+     *\/\n+    @Test\n+    void testWaitingForClassInitializer() throws Exception {\n+        class TestClass {\n+            static {\n+                LockSupport.park();\n+            }\n+            static void m() {\n+                \/\/ do nothing\n+            }\n+        }\n+\n+        try (Recording recording = new Recording()) {\n+            recording.enable(\"jdk.VirtualThreadPinned\");\n+            recording.start();\n+\n+            var started1 = new AtomicBoolean();\n+            var started2 = new AtomicBoolean();\n+\n+            Thread vthread1 = Thread.ofVirtual().unstarted(() -> {\n+                started1.set(true);\n+                TestClass.m();\n+            });\n+            Thread vthread2 = Thread.ofVirtual().unstarted(() -> {\n+                started2.set(true);\n+                TestClass.m();\n+            });\n+\n+            try {\n+                \/\/ start first virtual thread and wait for it to start + park\n+                vthread1.start();\n+                awaitTrue(started1);\n+                await(vthread1, Thread.State.WAITING);\n+\n+                \/\/ start second virtual thread and wait for it to start\n+                vthread2.start();\n+                awaitTrue(started2);\n+\n+                \/\/ give time for second virtual thread to wait on the MutexLocker\n+                Thread.sleep(3000);\n+\n+            } finally {\n+                LockSupport.unpark(vthread1);\n+                vthread1.join();\n+                vthread2.join();\n+                recording.stop();\n+            }\n+\n+            \/\/ the recording should have a pinned event for vthread2\n+            assertContainsPinnedEvent(recording, vthread2);\n+        }\n+    }\n+\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/JfrEvents.java","additions":219,"deletions":5,"binary":false,"changes":224,"status":"modified"},{"patch":"@@ -0,0 +1,39 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+import java.lang.management.ManagementFactory;\n+import com.sun.management.HotSpotDiagnosticMXBean;\n+\n+class LockingMode {\n+    private LockingMode() { }\n+\n+    \/**\n+     * Returns true if using legacy locking mode.\n+     *\/\n+    static boolean isLegacy() {\n+        return ManagementFactory.getPlatformMXBean(HotSpotDiagnosticMXBean.class)\n+                .getVMOption(\"LockingMode\")\n+                .getValue()\n+                .equals(\"1\");\n+    }\n+}\n\\ No newline at end of file\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/LockingMode.java","additions":39,"deletions":0,"binary":false,"changes":39,"status":"added"},{"patch":"@@ -0,0 +1,509 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=default\n+ * @summary Tests for object monitors that have been useful to find bugs\n+ * @library \/test\/lib\n+ * @requires vm.continuations & vm.opt.LockingMode != 1\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm MiscMonitorTests\n+ *\/\n+\n+\/*\n+ * @test id=Xint\n+ * @library \/test\/lib\n+ * @requires vm.continuations & vm.opt.LockingMode != 1\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm -Xint MiscMonitorTests\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp\n+ * @library \/test\/lib\n+ * @requires vm.continuations & vm.opt.LockingMode != 1\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm -Xcomp MiscMonitorTests\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel3\n+ * @library \/test\/lib\n+ * @requires vm.continuations & vm.opt.LockingMode != 1\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=3 MiscMonitorTests\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation\n+ * @summary Test virtual threads using synchronized\n+ * @library \/test\/lib\n+ * @requires vm.continuations & vm.opt.LockingMode != 1\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation MiscMonitorTests\n+ *\/\n+\n+\/*\n+ * @test id=gc\n+ * @requires vm.debug == true & vm.continuations & vm.opt.LockingMode != 1\n+ * @library \/test\/lib\n+ * @modules java.base\/java.lang:+open\n+ * @run junit\/othervm -XX:+UnlockDiagnosticVMOptions -XX:+FullGCALot -XX:FullGCALotInterval=1000 MiscMonitorTests\n+ *\/\n+\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.*;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import jdk.test.lib.thread.VThreadScheduler;\n+import org.junit.jupiter.api.Test;\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+class MiscMonitorTests {\n+    static final int CARRIER_COUNT = Runtime.getRuntime().availableProcessors();\n+\n+    \/**\n+     * Test that yielding while holding monitors releases carrier.\n+     *\/\n+    @Test\n+    void testReleaseOnYield() throws Exception {\n+        try (var test = new TestReleaseOnYield()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestReleaseOnYield extends TestBase {\n+        final Object lock = new Object();\n+        volatile boolean finish;\n+        volatile int counter;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT;\n+\n+            startVThreads(() -> foo(), vthreadCount, \"Batch1\");\n+            sleep(500);  \/\/ Give time for threads to reach Thread.yield\n+            startVThreads(() -> bar(), vthreadCount, \"Batch2\");\n+\n+            while (counter != vthreadCount) {\n+                Thread.onSpinWait();\n+            }\n+            finish = true;\n+            joinVThreads();\n+        }\n+\n+        void foo() {\n+            Object lock = new Object();\n+            synchronized (lock) {\n+                while (!finish) {\n+                    Thread.yield();\n+                }\n+            }\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        }\n+\n+        void bar() {\n+            synchronized (lock) {\n+                counter++;\n+            }\n+            System.err.println(\"Exiting bar from thread \" + Thread.currentThread().getName());\n+        }\n+    }\n+\n+    \/**\n+     * Test yielding while holding monitors with recursive locking releases carrier.\n+     *\/\n+    @Test\n+    void testReleaseOnYieldRecursive() throws Exception {\n+        try (var test = new TestReleaseOnYieldRecursive()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestReleaseOnYieldRecursive extends TestBase {\n+        final Object lock = new Object();\n+        volatile boolean finish;\n+        volatile int counter;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT;\n+\n+            startVThreads(() -> foo(), vthreadCount, \"Batch1\");\n+            sleep(500);  \/\/ Give time for threads to reach Thread.yield\n+            startVThreads(() -> bar(), vthreadCount, \"Batch2\");\n+\n+            while (counter != 2 * vthreadCount) {\n+                Thread.onSpinWait();\n+            }\n+            finish = true;\n+            joinVThreads();\n+        }\n+\n+        void foo() {\n+           Object lock = new Object();\n+            synchronized (lock) {\n+                while (!finish) {\n+                    Thread.yield();\n+                }\n+            }\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        }\n+\n+        void bar() {\n+            synchronized (lock) {\n+                counter++;\n+            }\n+            recursive(10);\n+            System.err.println(\"Exiting bar from thread \" + Thread.currentThread().getName());\n+        };\n+\n+        void recursive(int count) {\n+            synchronized (Thread.currentThread()) {\n+                if (count > 0) {\n+                    recursive(count - 1);\n+                } else {\n+                    synchronized (lock) {\n+                        counter++;\n+                        Thread.yield();\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test that contention on monitorenter releases carrier.\n+     *\/\n+    @Test\n+    void testReleaseOnContention() throws Exception {\n+        try (var test = new TestReleaseOnContention()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestReleaseOnContention extends TestBase {\n+        final Object lock = new Object();\n+        volatile boolean finish;\n+        volatile int counter;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT * 8;\n+\n+            startVThreads(() -> foo(), vthreadCount, \"VThread\");\n+            sleep(500);  \/\/ Give time for threads to reach synchronized (lock)\n+\n+            finish = true;\n+            joinVThreads();\n+        }\n+\n+        void foo() {\n+            synchronized (lock) {\n+                while (!finish) {\n+                    Thread.yield();\n+                }\n+            }\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        }\n+    }\n+\n+    \/**\n+     * Test contention on monitorenter with extra monitors on stack shared by all threads.\n+     *\/\n+    @Test\n+    void testContentionMultipleMonitors() throws Exception {\n+        try (var test = new TestContentionMultipleMonitors()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestContentionMultipleMonitors extends TestBase {\n+        static int MONITOR_COUNT = 12;\n+        final Object[] lockArray = new Object[MONITOR_COUNT];\n+        final AtomicInteger workerCount = new AtomicInteger(0);\n+        volatile boolean finish;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT * 8;\n+            for (int i = 0; i < MONITOR_COUNT; i++) {\n+                lockArray[i] = new Object();\n+            }\n+\n+            startVThreads(() -> foo(), vthreadCount, \"VThread\");\n+\n+            sleep(5000);\n+            finish = true;\n+            joinVThreads();\n+            assertEquals(vthreadCount, workerCount.get());\n+        }\n+\n+        void foo() {\n+            while (!finish) {\n+                int lockNumber = ThreadLocalRandom.current().nextInt(0, MONITOR_COUNT - 1);\n+                synchronized (lockArray[lockNumber]) {\n+                    recursive1(lockNumber, lockNumber);\n+                }\n+            }\n+            workerCount.getAndIncrement();\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        }\n+\n+        public void recursive1(int depth, int lockNumber) {\n+            if (depth > 0) {\n+                recursive1(depth - 1, lockNumber);\n+            } else {\n+                if (Math.random() < 0.5) {\n+                    Thread.yield();\n+                }\n+                recursive2(lockNumber);\n+            }\n+        }\n+\n+        public void recursive2(int lockNumber) {\n+            if (lockNumber + 2 <= MONITOR_COUNT - 1) {\n+                lockNumber += 2;\n+                synchronized (lockArray[lockNumber]) {\n+                    Thread.yield();\n+                    recursive2(lockNumber);\n+                }\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test contention on monitorenter with extra monitors on stack both local only and shared by all threads.\n+     *\/\n+    @Test\n+    void testContentionMultipleMonitors2() throws Exception {\n+        try (var test = new TestContentionMultipleMonitors2()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestContentionMultipleMonitors2 extends TestBase {\n+        int MONITOR_COUNT = 12;\n+        final Object[] lockArray = new Object[MONITOR_COUNT];\n+        final AtomicInteger workerCount = new AtomicInteger(0);\n+        volatile boolean finish;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT * 8;\n+            for (int i = 0; i < MONITOR_COUNT; i++) {\n+                lockArray[i] = new Object();\n+            }\n+\n+            startVThreads(() -> foo(), vthreadCount, \"VThread\");\n+\n+            sleep(5000);\n+            finish = true;\n+            joinVThreads();\n+            assertEquals(vthreadCount, workerCount.get());\n+        }\n+\n+        void foo() {\n+            Object[] myLockArray = new Object[MONITOR_COUNT];\n+            for (int i = 0; i < MONITOR_COUNT; i++) {\n+                myLockArray[i] = new Object();\n+            }\n+\n+            while (!finish) {\n+                int lockNumber = ThreadLocalRandom.current().nextInt(0, MONITOR_COUNT - 1);\n+                synchronized (myLockArray[lockNumber]) {\n+                    synchronized (lockArray[lockNumber]) {\n+                        recursive1(lockNumber, lockNumber, myLockArray);\n+                    }\n+                }\n+            }\n+            workerCount.getAndIncrement();\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        }\n+\n+        public void recursive1(int depth, int lockNumber, Object[] myLockArray) {\n+            if (depth > 0) {\n+                recursive1(depth - 1, lockNumber, myLockArray);\n+            } else {\n+                if (Math.random() < 0.5) {\n+                    Thread.yield();\n+                }\n+                recursive2(lockNumber, myLockArray);\n+            }\n+        }\n+\n+        public void recursive2(int lockNumber, Object[] myLockArray) {\n+            if (lockNumber + 2 <= MONITOR_COUNT - 1) {\n+                lockNumber += 2;\n+                synchronized (myLockArray[lockNumber]) {\n+                    if (Math.random() < 0.5) {\n+                        Thread.yield();\n+                    }\n+                    synchronized (lockArray[lockNumber]) {\n+                        Thread.yield();\n+                        recursive2(lockNumber, myLockArray);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+\n+    \/**\n+     * Test contention on monitorenter with synchronized methods.\n+     *\/\n+    @Test\n+    void testContentionWithSyncMethods() throws Exception {\n+        try (var test = new TestContentionWithSyncMethods()) {\n+            test.runTest();\n+        }\n+    }\n+\n+    private static class TestContentionWithSyncMethods extends TestBase {\n+        static final int MONITOR_COUNT = 12;\n+        final Object[] lockArray = new Object[MONITOR_COUNT];\n+        final AtomicInteger workerCount = new AtomicInteger(0);\n+        volatile boolean finish;\n+\n+        @Override\n+        void runTest() throws Exception {\n+            int vthreadCount = CARRIER_COUNT * 8;\n+            for (int i = 0; i < MONITOR_COUNT; i++) {\n+                lockArray[i] = new Object();\n+            }\n+\n+            startVThreads(() -> foo(), vthreadCount, \"VThread\");\n+\n+            sleep(5000);\n+            finish = true;\n+            joinVThreads();\n+            assertEquals(vthreadCount, workerCount.get());\n+        }\n+\n+        void foo() {\n+            Object myLock = new Object();\n+\n+            while (!finish) {\n+                int lockNumber = ThreadLocalRandom.current().nextInt(0, MONITOR_COUNT - 1);\n+                synchronized (myLock) {\n+                    synchronized (lockArray[lockNumber]) {\n+                        recursive(lockNumber, myLock);\n+                    }\n+                }\n+            }\n+            workerCount.getAndIncrement();\n+            System.err.println(\"Exiting foo from thread \" + Thread.currentThread().getName());\n+        };\n+\n+        synchronized void recursive(int depth, Object myLock) {\n+            if (depth > 0) {\n+                recursive(depth - 1, myLock);\n+            } else {\n+                if (Math.random() < 0.5) {\n+                    Thread.yield();\n+                } else {\n+                    synchronized (myLock) {\n+                        Thread.yield();\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test wait\/notify mechanism.\n+     *\/\n+    @Test\n+    void waitNotifyTest() throws Exception {\n+        int threadCount = 1000;\n+        int waitTime = 50;\n+        Thread[] vthread = new Thread[threadCount];\n+        long start = System.currentTimeMillis();\n+\n+        while (System.currentTimeMillis() - start < 5000) {\n+            CountDownLatch latchStart = new CountDownLatch(threadCount);\n+            CountDownLatch latchFinish = new CountDownLatch(threadCount);\n+            Object object = new Object();\n+\n+            for (int i = 0; i < threadCount; i++) {\n+                vthread[i] = Thread.ofVirtual().start(() -> {\n+                    synchronized (object) {\n+                        try {\n+                            latchStart.countDown();\n+                            object.wait(waitTime);\n+                        } catch (InterruptedException e) {\n+                            \/\/do nothing;\n+                        }\n+                    }\n+                    latchFinish.countDown();\n+                });\n+            }\n+\n+            try {\n+                latchStart.await();\n+                synchronized (object) {\n+                    object.notifyAll();\n+                }\n+                latchFinish.await();\n+                for (int i = 0; i < threadCount; i++) {\n+                    vthread[i].join();\n+                }\n+            } catch (InterruptedException e) {\n+                \/\/do nothing;\n+            }\n+        }\n+    }\n+\n+    private static abstract class TestBase implements AutoCloseable {\n+        final ExecutorService scheduler = Executors.newFixedThreadPool(CARRIER_COUNT);\n+        final List<Thread[]> vthreadList = new ArrayList<>();\n+\n+        abstract void runTest() throws Exception;\n+\n+        void startVThreads(Runnable r, int count, String name) {\n+            Thread vthreads[] = new Thread[count];\n+            for (int i = 0; i < count; i++) {\n+                vthreads[i] = VThreadScheduler.virtualThreadBuilder(scheduler).name(name + \"-\" + i).start(r);\n+            }\n+            vthreadList.add(vthreads);\n+        }\n+\n+        void joinVThreads() throws Exception {\n+            for (Thread[] vthreads : vthreadList) {\n+                for (Thread vthread : vthreads) {\n+                    vthread.join();\n+                }\n+            }\n+        }\n+\n+        void sleep(long ms) throws Exception {\n+            Thread.sleep(ms);\n+        }\n+\n+        @Override\n+        public void close() {\n+            scheduler.close();\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/MiscMonitorTests.java","additions":509,"deletions":0,"binary":false,"changes":509,"status":"added"},{"patch":"@@ -29,0 +29,1 @@\n+ * @build LockingMode\n@@ -32,0 +33,80 @@\n+\/*\n+ * @test id=LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xint-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xint -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xint-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xint -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel1-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=1 -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel1-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=1 -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorEnterExit\n+ *\/\n+\n@@ -51,0 +132,1 @@\n+import org.junit.jupiter.api.condition.DisabledIf;\n@@ -55,1 +137,0 @@\n-import org.junit.jupiter.api.condition.*;\n@@ -60,0 +141,1 @@\n+    static final int MAX_VTHREAD_COUNT = 4 * Runtime.getRuntime().availableProcessors();\n@@ -64,4 +146,2 @@\n-        \/\/ need >=2 carriers for testing pinning when main thread is a virtual thread\n-        if (Thread.currentThread().isVirtual()) {\n-            VThreadRunner.ensureParallelism(2);\n-        }\n+        \/\/ need >=2 carriers for tests that pin\n+        VThreadRunner.ensureParallelism(2);\n@@ -153,0 +233,47 @@\n+    \/**\n+     * Test monitor reenter when there are other threads blocked trying to enter.\n+     *\/\n+    @Test\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testReenterWithContention() throws Exception {\n+        var lock = new Object();\n+        VThreadRunner.run(() -> {\n+            List<Thread> threads = new ArrayList<>();\n+            testReenter(lock, 0, threads);\n+\n+            \/\/ wait for threads to terminate\n+            for (Thread vthread : threads) {\n+                vthread.join();\n+            }\n+        });\n+    }\n+\n+    private void testReenter(Object lock, int depth, List<Thread> threads) throws Exception {\n+        if (depth < MAX_ENTER_DEPTH) {\n+            synchronized (lock) {\n+                assertTrue(Thread.holdsLock(lock));\n+\n+                \/\/ start platform or virtual thread that blocks waiting to enter\n+                var started = new CountDownLatch(1);\n+                ThreadFactory factory = ThreadLocalRandom.current().nextBoolean()\n+                        ? Thread.ofPlatform().factory()\n+                        : Thread.ofVirtual().factory();\n+                var thread = factory.newThread(() -> {\n+                    started.countDown();\n+                    synchronized (lock) {\n+                        \/* do nothing *\/\n+                    }\n+                });\n+                thread.start();\n+\n+                \/\/ wait for thread to start and block\n+                started.await();\n+                await(thread, Thread.State.BLOCKED);\n+                threads.add(thread);\n+\n+                \/\/ test reenter\n+                testReenter(lock, depth + 1, threads);\n+            }\n+        }\n+    }\n+\n@@ -200,7 +327,1 @@\n-        \/\/ need at least two carrier threads\n-        int previousParallelism = VThreadRunner.ensureParallelism(2);\n-        try {\n-            VThreadRunner.run(this::testEnterWithContentionWhenPinned);\n-        } finally {\n-            VThreadRunner.setParallelism(previousParallelism);\n-        }\n+        VThreadRunner.run(this::testEnterWithContentionWhenPinned);\n@@ -237,0 +358,73 @@\n+    \/**\n+     * Test that blocking waiting to enter a monitor releases the carrier.\n+     *\/\n+    @Test\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testReleaseWhenBlocked() throws Exception {\n+        assumeTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+        try (ExecutorService scheduler = Executors.newFixedThreadPool(1)) {\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+\n+            var lock = new Object();\n+\n+            \/\/ thread enters monitor\n+            var started = new CountDownLatch(1);\n+            var vthread1 = factory.newThread(() -> {\n+                started.countDown();\n+                synchronized (lock) {\n+                }\n+            });\n+\n+            try {\n+                synchronized (lock) {\n+                    \/\/ start thread and wait for it to block\n+                    vthread1.start();\n+                    started.await();\n+                    await(vthread1, Thread.State.BLOCKED);\n+\n+                    \/\/ carrier should be released, use it for another thread\n+                    var executed = new AtomicBoolean();\n+                    var vthread2 = factory.newThread(() -> {\n+                        executed.set(true);\n+                    });\n+                    vthread2.start();\n+                    vthread2.join();\n+                    assertTrue(executed.get());\n+                }\n+            } finally {\n+                vthread1.join();\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test lots of virtual threads blocked waiting to enter a monitor. If the number\n+     * of virtual threads exceeds the number of carrier threads this test will hang if\n+     * carriers aren't released.\n+     *\/\n+    @Test\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testManyBlockedThreads() throws Exception {\n+        Thread[] vthreads = new Thread[MAX_VTHREAD_COUNT];\n+        var lock = new Object();\n+        synchronized (lock) {\n+            for (int i = 0; i < MAX_VTHREAD_COUNT; i++) {\n+                var started = new CountDownLatch(1);\n+                var vthread = Thread.ofVirtual().start(() -> {\n+                    started.countDown();\n+                    synchronized (lock) {\n+                    }\n+                });\n+                \/\/ wait for thread to start and block\n+                started.await();\n+                await(vthread, Thread.State.BLOCKED);\n+                vthreads[i] = vthread;\n+            }\n+        }\n+\n+        \/\/ cleanup\n+        for (int i = 0; i < MAX_VTHREAD_COUNT; i++) {\n+            vthreads[i].join();\n+        }\n+    }\n+\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/MonitorEnterExit.java","additions":206,"deletions":12,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+ * @build LockingMode\n@@ -32,0 +33,80 @@\n+\/*\n+ * @test id=LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xint-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xint -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xint-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xint -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel1-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=1 -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel1-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=1 -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation-LM_LEGACY\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation -XX:LockingMode=1 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation-LM_LIGHTWEIGHT\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation -XX:LockingMode=2 --enable-native-access=ALL-UNNAMED MonitorWaitNotify\n+ *\/\n+\n@@ -53,0 +134,2 @@\n+import org.junit.jupiter.api.condition.DisabledIf;\n+import org.junit.jupiter.params.provider.Arguments;\n@@ -54,0 +137,1 @@\n+import org.junit.jupiter.params.provider.MethodSource;\n@@ -206,0 +290,123 @@\n+\n+    \/**\n+     * Returns a stream of elements that are ordered pairs of platform and virtual thread\n+     * counts. 0,2,4,..8 platform threads. 2,4,6,..16 virtual threads.\n+     *\/\n+    static Stream<Arguments> threadCounts() {\n+        return IntStream.range(0, 9)\n+                .filter(i -> i % 2 == 0)\n+                .mapToObj(i -> i)\n+                .flatMap(np -> IntStream.range(2, 17)\n+                        .filter(i -> i % 2 == 0)\n+                        .mapToObj(vp -> Arguments.of(np, vp)));\n+    }\n+\n+    \/**\n+     * Test notify wakes only one thread when platform and virtual threads are waiting.\n+     *\/\n+    @ParameterizedTest\n+    @MethodSource(\"threadCounts\")\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testNotifyOneThread(int nPlatformThreads, int nVirtualThreads) throws Exception {\n+        int nThreads = nPlatformThreads + nVirtualThreads;\n+\n+        var lock = new Object();\n+        var ready = new CountDownLatch(nThreads);\n+        var notified = new AtomicInteger();\n+\n+        Runnable waitTask = () -> {\n+            synchronized (lock) {\n+                try {\n+                    ready.countDown();\n+                    lock.wait();\n+                    notified.incrementAndGet();\n+                } catch (InterruptedException e) { }\n+            }\n+        };\n+\n+        var threads = new ArrayList<Thread>();\n+        try {\n+            for (int i = 0; i < nPlatformThreads; i++) {\n+                threads.add(Thread.ofPlatform().start(waitTask));\n+            }\n+            for (int i = 0; i < nVirtualThreads; i++) {\n+                threads.add(Thread.ofVirtual().start(waitTask));\n+            }\n+\n+            \/\/ wait for all threads to wait\n+            ready.await();\n+\n+            \/\/ wake threads, one by one\n+            for (int i = 0; i < threads.size(); i++) {\n+\n+                \/\/ wake one thread\n+                synchronized (lock) {\n+                    lock.notify();\n+                }\n+\n+                \/\/ one thread should have awoken\n+                int expectedWakeups = i + 1;\n+                while (notified.get() < expectedWakeups) {\n+                    Thread.sleep(10);\n+                }\n+                assertEquals(expectedWakeups, notified.get());\n+            }\n+        } finally {\n+            for (Thread t : threads) {\n+                t.interrupt();\n+                t.join();\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test notifyAll wakes all threads.\n+     *\/\n+    @ParameterizedTest\n+    @MethodSource(\"threadCounts\")\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testNotifyAllThreads(int nPlatformThreads, int nVirtualThreads) throws Exception {\n+        int nThreads = nPlatformThreads + nVirtualThreads;\n+\n+        var lock = new Object();\n+        var ready = new CountDownLatch(nThreads);\n+        var notified = new CountDownLatch(nThreads);\n+\n+        Runnable waitTask = () -> {\n+            synchronized (lock) {\n+                try {\n+                    ready.countDown();\n+                    lock.wait();\n+                    notified.countDown();\n+                } catch (InterruptedException e) { }\n+            }\n+        };\n+\n+        var threads = new ArrayList<Thread>();\n+        try {\n+            for (int i = 0; i < nPlatformThreads; i++) {\n+                threads.add(Thread.ofPlatform().start(waitTask));\n+            }\n+            for (int i = 0; i < nVirtualThreads; i++) {\n+                threads.add(Thread.ofVirtual().start(waitTask));\n+            }\n+\n+            \/\/ wait for all threads to wait\n+            ready.await();\n+\n+            \/\/ wakeup all threads\n+            synchronized (lock) {\n+                lock.notifyAll();\n+            }\n+\n+            \/\/ wait for all threads to have awoken\n+            notified.await();\n+\n+        } finally {\n+            for (Thread t : threads) {\n+                t.interrupt();\n+                t.join();\n+            }\n+        }\n+    }\n+\n@@ -492,0 +699,91 @@\n+    \/**\n+     * Test that Object.wait releases the carrier. This test uses a custom scheduler\n+     * with one carrier thread.\n+     *\/\n+    @ParameterizedTest\n+    @ValueSource(ints = { 0, 30000, Integer.MAX_VALUE })\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testReleaseWhenWaiting1(int timeout) throws Exception {\n+        assumeTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+        try (ExecutorService scheduler = Executors.newFixedThreadPool(1)) {\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+\n+            var lock = new Object();\n+            var ready = new AtomicBoolean();\n+            var completed = new AtomicBoolean();\n+\n+            var vthread1 = factory.newThread(() -> {\n+                synchronized (lock) {\n+                    try {\n+                        ready.set(true);\n+                        if (timeout > 0) {\n+                            lock.wait(timeout);\n+                        } else {\n+                            lock.wait();\n+                        }\n+                    } catch (InterruptedException e) {\n+                        fail(\"wait interrupted\");\n+                    }\n+                }\n+                completed.set(true);\n+            });\n+            vthread1.start();\n+\n+            \/\/ wait for vthread1 to start and wait\n+            awaitTrue(ready);\n+            await(vthread1, timeout > 0 ? Thread.State.TIMED_WAITING : Thread.State.WAITING);\n+\n+            \/\/ carrier should be released, use it for another thread\n+            var executed = new AtomicBoolean();\n+            var vthread2 = factory.newThread(() -> {\n+                executed.set(true);\n+            });\n+            vthread2.start();\n+            vthread2.join();\n+            assertTrue(executed.get());\n+\n+            \/\/ wakeup vthread1\n+            synchronized (lock) {\n+                lock.notifyAll();\n+            }\n+\n+            vthread1.join();\n+            assertTrue(completed.get());\n+        }\n+    }\n+\n+    \/**\n+     * Test that Object.wait releases the carrier. This test arranges for 4*ncores - 1\n+     * virtual threads to wait. For long timeout and no timeout cases, all virtual threads\n+     * will wait until they are notified.\n+     *\/\n+    @ParameterizedTest\n+    @ValueSource(ints = { 0, 10, 20, 100, 500, 30000, Integer.MAX_VALUE })\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testReleaseWhenWaiting2(int timeout) throws Exception {\n+        int VTHREAD_COUNT = 4 * Runtime.getRuntime().availableProcessors();\n+        CountDownLatch latch = new CountDownLatch(VTHREAD_COUNT);\n+        Object lock = new Object();\n+        AtomicInteger counter = new AtomicInteger(0);\n+\n+        for (int i = 0; i < VTHREAD_COUNT; i++) {\n+            Thread.ofVirtual().name(\"vthread-\" + i).start(() -> {\n+                synchronized (lock) {\n+                    if (counter.incrementAndGet() == VTHREAD_COUNT) {\n+                        lock.notifyAll();\n+                    } else {\n+                        try {\n+                            if (timeout > 0) {\n+                                lock.wait(timeout);\n+                            } else {\n+                                lock.wait();\n+                            }\n+                        } catch (InterruptedException e) {}\n+                    }\n+                }\n+                latch.countDown();\n+            });\n+        }\n+        latch.await();\n+    }\n+\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/MonitorWaitNotify.java","additions":298,"deletions":0,"binary":false,"changes":298,"status":"modified"},{"patch":"@@ -33,2 +33,4 @@\n-import java.util.concurrent.*;\n-import java.util.concurrent.atomic.*;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n@@ -40,1 +42,1 @@\n-        try (ExecutorService scheduler = Executors.newFixedThreadPool(8)) {\n+        try (var scheduler = new Scheduler(8)) {\n@@ -77,0 +79,23 @@\n+\n+    static class Scheduler implements Executor, AutoCloseable {\n+        private final ExecutorService pool;\n+\n+        Scheduler(int poolSize) {\n+            pool = Executors.newFixedThreadPool(poolSize);\n+        }\n+\n+        @Override\n+        public void execute(Runnable task) {\n+            try {\n+                pool.execute(task);\n+            } finally {\n+                \/\/ ExecutorService::execute may consume parking permit\n+                LockSupport.unpark(Thread.currentThread());\n+            }\n+        }\n+\n+        @Override\n+        public void close() {\n+            pool.close();\n+        }\n+    }\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/ParkWithFixedThreadPool.java","additions":28,"deletions":3,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,2 +24,2 @@\n-\/**\n- * @test\n+\/*\n+ * @test id=default\n@@ -27,0 +27,1 @@\n+ * @modules java.base\/java.lang:+open jdk.management\n@@ -28,0 +29,1 @@\n+ * @build LockingMode\n@@ -31,0 +33,24 @@\n+\/*\n+ * @test id=Xint\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xint Parking\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp Parking\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @build LockingMode\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation Parking\n+ *\/\n+\n@@ -32,0 +58,4 @@\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ThreadFactory;\n@@ -33,0 +63,1 @@\n+import java.util.concurrent.atomic.AtomicBoolean;\n@@ -36,0 +67,1 @@\n+import jdk.test.lib.thread.VThreadScheduler;\n@@ -37,0 +69,3 @@\n+import org.junit.jupiter.api.condition.DisabledIf;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.ValueSource;\n@@ -38,0 +73,1 @@\n+import static org.junit.jupiter.api.Assumptions.*;\n@@ -40,1 +76,2 @@\n-    private static final Object lock = new Object();\n+    static final int MAX_VTHREAD_COUNT = 4 * Runtime.getRuntime().availableProcessors();\n+    static final Object lock = new Object();\n@@ -346,0 +383,85 @@\n+    \/**\n+     * Test that parking while holding a monitor releases the carrier.\n+     *\/\n+    @ParameterizedTest\n+    @ValueSource(booleans = { true, false })\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testParkWhenHoldingMonitor(boolean reenter) throws Exception {\n+        assumeTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+        try (ExecutorService scheduler = Executors.newFixedThreadPool(1)) {\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+\n+            var lock = new Object();\n+\n+            \/\/ thread enters (and maybe reenters) a monitor and parks\n+            var started = new CountDownLatch(1);\n+            var vthread1 = factory.newThread(() -> {\n+                started.countDown();\n+                synchronized (lock) {\n+                    if (reenter) {\n+                        synchronized (lock) {\n+                            LockSupport.park();\n+                        }\n+                    } else {\n+                        LockSupport.park();\n+                    }\n+                }\n+            });\n+\n+            vthread1.start();\n+            try {\n+                \/\/ wait for thread to start and park\n+                started.await();\n+                await(vthread1, Thread.State.WAITING);\n+\n+                \/\/ carrier should be released, use it for another thread\n+                var executed = new AtomicBoolean();\n+                var vthread2 = factory.newThread(() -> {\n+                    executed.set(true);\n+                });\n+                vthread2.start();\n+                vthread2.join();\n+                assertTrue(executed.get());\n+            } finally {\n+                LockSupport.unpark(vthread1);\n+                vthread1.join();\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Test lots of virtual threads parked while holding a monitor. If the number of\n+     * virtual threads exceeds the number of carrier threads then this test will hang if\n+     * parking doesn't release the carrier.\n+     *\/\n+    @Test\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testManyParkedWhenHoldingMonitor() throws Exception {\n+        Thread[] vthreads = new Thread[MAX_VTHREAD_COUNT];\n+        var done = new AtomicBoolean();\n+        for (int i = 0; i < MAX_VTHREAD_COUNT; i++) {\n+            var lock = new Object();\n+            var started = new CountDownLatch(1);\n+            var vthread = Thread.ofVirtual().start(() -> {\n+                started.countDown();\n+                synchronized (lock) {\n+                    while (!done.get()) {\n+                        LockSupport.park();\n+                    }\n+                }\n+            });\n+            \/\/ wait for thread to start and park\n+            started.await();\n+            await(vthread, Thread.State.WAITING);\n+            vthreads[i] = vthread;\n+        }\n+\n+        \/\/ cleanup\n+        done.set(true);\n+        for (int i = 0; i < MAX_VTHREAD_COUNT; i++) {\n+            var vthread = vthreads[i];\n+            LockSupport.unpark(vthread);\n+            vthread.join();\n+        }\n+    }\n+\n@@ -360,0 +482,12 @@\n+\n+    \/**\n+     * Waits for the given thread to reach a given state.\n+     *\/\n+    private void await(Thread thread, Thread.State expectedState) throws InterruptedException {\n+        Thread.State state = thread.getState();\n+        while (state != expectedState) {\n+            assertTrue(state != Thread.State.TERMINATED, \"Thread has terminated\");\n+            Thread.sleep(10);\n+            state = thread.getState();\n+        }\n+    }\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/Parking.java","additions":138,"deletions":4,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -0,0 +1,142 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Test that a virtual thread waiting to enter a monitor, while pinning its\n+ *   carrier, will retry until it enters the monitor. This avoids starvation when the\n+ *   monitor is exited, an unmounted thread is the chosen successor, and the successor\n+ *   can't continue because there are no carriers available.\n+ * @modules java.base\/java.lang:+open\n+ * @library \/test\/lib\n+ * @requires vm.opt.LockingMode != 1\n+ * @run main\/othervm --enable-native-access=ALL-UNNAMED RetryMonitorEnterWhenPinned\n+ *\/\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import jdk.test.lib.thread.VThreadPinner;\n+\n+public class RetryMonitorEnterWhenPinned {\n+    public static void main(String[] args) throws Exception {\n+        int iterations = (args.length > 0) ? Integer.parseInt(args[0]) : 10;\n+        for (int i = 1; i <= iterations; i++) {\n+            System.out.printf(\"%s -- iteration %d --%n\", Instant.now(), i);\n+            run();\n+            System.out.println();\n+        }\n+    }\n+\n+    static void run() throws Exception {\n+        var threads = new ArrayList<Thread>();\n+\n+        Object lock = new Object();\n+        synchronized (lock) {\n+\n+            \/\/ start virtual threads that block on monitorenter\n+            for (int i = 0; i < 100; i++) {\n+                var started = new CountDownLatch(1);\n+                Thread thread = Thread.startVirtualThread(() -> {\n+                    started.countDown();\n+                    synchronized (lock) {\n+                        spin(20);\n+                    }\n+                });\n+\n+                \/\/ wait for thread to start and block\n+                started.await();\n+                await(thread, Thread.State.BLOCKED);\n+                threads.add(thread);\n+            }\n+\n+            \/\/ start virtual threads that block on monitorenter while pinned\n+            int carriersAvailable = Runtime.getRuntime().availableProcessors();\n+            if (Thread.currentThread().isVirtual()) {\n+                carriersAvailable--;\n+            }\n+            for (int i = 0; i < 100; i++) {\n+                var started = new CountDownLatch(1);\n+                Thread thread = Thread.startVirtualThread(() -> {\n+                    started.countDown();\n+                    VThreadPinner.runPinned(() -> {\n+                        synchronized (lock) {\n+                            spin(20);\n+                        }\n+                    });\n+                });\n+\n+                \/\/ if there are carriers available when wait until the thread blocks.\n+                if (carriersAvailable > 0) {\n+                    System.out.printf(\"%s waiting for thread #%d to block%n\",\n+                            Instant.now(), thread.threadId());\n+                    started.await();\n+                    await(thread, Thread.State.BLOCKED);\n+                    carriersAvailable--;\n+                }\n+                threads.add(thread);\n+            }\n+\n+        } \/\/ exit monitor\n+\n+        \/\/ wait for all threads to terminate\n+        int threadsRemaining = threads.size();\n+        while (threadsRemaining > 0) {\n+            System.out.printf(\"%s waiting for %d threads to terminate%n\",\n+                    Instant.now(), threadsRemaining);\n+            int terminated = 0;\n+            for (Thread t : threads) {\n+                if (t.join(Duration.ofSeconds(1))) {\n+                    terminated++;\n+                }\n+            }\n+            threadsRemaining = threads.size() - terminated;\n+        }\n+        System.out.printf(\"%s done%n\", Instant.now());\n+    }\n+\n+    \/**\n+     * Spin for the given number of milliseconds.\n+     *\/\n+    static void spin(long millis) {\n+        long nanos = TimeUnit.MILLISECONDS.toNanos(millis);\n+        long start = System.nanoTime();\n+        while ((System.nanoTime() - start) < nanos) {\n+            Thread.onSpinWait();\n+        }\n+    }\n+\n+    \/**\n+     * Wait for a thread to reach the expected state.\n+     *\/\n+    static void await(Thread thread, Thread.State expectedState) throws InterruptedException {\n+        Thread.State state = thread.getState();\n+        while (state != expectedState) {\n+            assert state != Thread.State.TERMINATED : \"Thread has terminated\";\n+            Thread.sleep(10);\n+            state = thread.getState();\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/RetryMonitorEnterWhenPinned.java","additions":142,"deletions":0,"binary":false,"changes":142,"status":"added"},{"patch":"@@ -0,0 +1,511 @@\n+\/*\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=default\n+ * @summary Test virtual threads with a synchronized native method and a native method\n+ *      that enter\/exits a monitor with JNI MonitorEnter\/MonitorExit\n+ * @requires vm.continuations\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @run junit\/othervm SynchronizedNative\n+ *\/\n+\n+\/*\n+ * @test id=Xint\n+ * @requires vm.continuations\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @run junit\/othervm -Xint SynchronizedNative\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-TieredStopAtLevel1\n+ * @requires vm.continuations\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @run junit\/othervm -Xcomp -XX:TieredStopAtLevel=1 SynchronizedNative\n+ *\/\n+\n+\/*\n+ * @test id=Xcomp-noTieredCompilation\n+ * @requires vm.continuations\n+ * @modules java.base\/java.lang:+open jdk.management\n+ * @library \/test\/lib\n+ * @run junit\/othervm -Xcomp -XX:-TieredCompilation SynchronizedNative\n+ *\/\n+\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Phaser;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.locks.LockSupport;\n+import java.util.stream.IntStream;\n+import java.util.stream.Stream;\n+\n+import jdk.test.lib.thread.VThreadPinner;\n+import jdk.test.lib.thread.VThreadRunner;   \/\/ ensureParallelism requires jdk.management\n+import jdk.test.lib.thread.VThreadScheduler;\n+\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.BeforeAll;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.Arguments;\n+import org.junit.jupiter.params.provider.MethodSource;\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+class SynchronizedNative {\n+\n+    @BeforeAll\n+    static void setup() throws Exception {\n+        \/\/ need at least two carriers to test pinning\n+        VThreadRunner.ensureParallelism(2);\n+        System.loadLibrary(\"SynchronizedNative\");\n+    }\n+\n+    \/**\n+     * Test entering a monitor with a synchronized native method, no contention.\n+     *\/\n+    @Test\n+    void testEnter() throws Exception {\n+        Object lock = this;\n+        VThreadRunner.run(() -> {\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+        });\n+    }\n+\n+    \/**\n+     * Test reentering a monitor with synchronized native method, no contention.\n+     *\/\n+    @Test\n+    void testReenter() throws Exception {\n+        Object lock = this;\n+        VThreadRunner.run(() -> {\n+\n+            \/\/ enter, reenter with a synchronized native method\n+            synchronized (lock) {\n+                runWithSynchronizedNative(() -> {\n+                    assertTrue(Thread.holdsLock(lock));\n+                });\n+                assertTrue(Thread.holdsLock(lock));\n+            }\n+            assertFalse(Thread.holdsLock(lock));\n+\n+            \/\/ enter with synchronized native method, renter with synchronized statement\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                synchronized (lock) {\n+                    assertTrue(Thread.holdsLock(lock));\n+                }\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+\n+            \/\/ enter with synchronized native method, reenter with synchronized native method\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                runWithSynchronizedNative(() -> {\n+                    assertTrue(Thread.holdsLock(lock));\n+                });\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+        });\n+    }\n+\n+    \/**\n+     * Test entering a monitor with a synchronized native method and with contention.\n+     *\/\n+    @Test\n+    void testEnterWithContention() throws Exception {\n+        var lock = this;\n+        var started = new CountDownLatch(1);\n+        var entered = new AtomicBoolean();\n+        var vthread = Thread.ofVirtual().unstarted(() -> {\n+            started.countDown();\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                entered.set(true);\n+            });\n+        });\n+        try {\n+            synchronized (lock) {\n+                vthread.start();\n+\n+                \/\/ wait for thread to start and block\n+                started.await();\n+                await(vthread, Thread.State.BLOCKED);\n+\n+                assertFalse(entered.get());\n+            }\n+        } finally {\n+            vthread.join();\n+        }\n+        assertTrue(entered.get());\n+    }\n+\n+    \/**\n+     * Returns a stream of elements that are ordered pairs of platform and virtual thread\n+     * counts. 0,2,4 platform threads. 2,4,6,8 virtual threads.\n+     *\/\n+    static Stream<Arguments> threadCounts() {\n+        return IntStream.range(0, 5)\n+                .filter(i -> i % 2 == 0)\n+                .mapToObj(i -> i)\n+                .flatMap(np -> IntStream.range(2, 9)\n+                        .filter(i -> i % 2 == 0)\n+                        .mapToObj(vp -> Arguments.of(np, vp)));\n+    }\n+\n+    \/**\n+     * Execute a task concurrently from both platform and virtual threads.\n+     *\/\n+    private void executeConcurrently(int nPlatformThreads,\n+                                     int nVirtualThreads,\n+                                     Runnable task) throws Exception {\n+        int parallism = nVirtualThreads;\n+        if (Thread.currentThread().isVirtual()) {\n+            parallism++;\n+        }\n+        int previousParallelism = VThreadRunner.ensureParallelism(parallism);\n+        try {\n+            int nthreads = nPlatformThreads + nVirtualThreads;\n+            var phaser = new Phaser(nthreads + 1);\n+\n+            \/\/ start all threads\n+            var threads = new Thread[nthreads];\n+            int index = 0;\n+            for (int i = 0; i < nPlatformThreads; i++) {\n+                threads[index++] = Thread.ofPlatform().start(() -> {\n+                    phaser.arriveAndAwaitAdvance();\n+                    task.run();\n+                });\n+            }\n+            for (int i = 0; i < nVirtualThreads; i++) {\n+                threads[index++] = Thread.ofVirtual().start(() -> {\n+                    phaser.arriveAndAwaitAdvance();\n+                    task.run();\n+                });\n+            }\n+\n+            \/\/ wait for all threads to start\n+            phaser.arriveAndAwaitAdvance();\n+            System.err.printf(\"  %d threads started%n\", nthreads);\n+\n+            \/\/ wait for all threads to terminate\n+            for (Thread thread : threads) {\n+                if (thread != null) {\n+                    System.err.printf(\"  join %s ...%n\", thread);\n+                    thread.join();\n+                }\n+            }\n+        } finally {\n+            \/\/ reset parallelism\n+            VThreadRunner.setParallelism(previousParallelism);\n+        }\n+    }\n+\n+\n+    \/**\n+     * Test entering a monitor with a synchronized native method from many threads\n+     * at the same time.\n+     *\/\n+    @ParameterizedTest\n+    @MethodSource(\"threadCounts\")\n+    void testEnterConcurrently(int nPlatformThreads, int nVirtualThreads) throws Exception {\n+        var counter = new Object() {\n+            int value;\n+            int value() { return value; }\n+            void increment() { value++; }\n+        };\n+        var lock = this;\n+        executeConcurrently(nPlatformThreads, nVirtualThreads, () -> {\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                counter.increment();\n+                LockSupport.parkNanos(100_000_000);  \/\/ 100ms\n+            });\n+        });\n+        synchronized (lock) {\n+            assertEquals(nPlatformThreads + nVirtualThreads, counter.value());\n+        }\n+    }\n+\n+    \/**\n+     * Test entering a monitor with JNI MonitorEnter.\n+     *\/\n+    @Test\n+    void testEnterInNative() throws Exception {\n+        Object lock = new Object();\n+        VThreadRunner.run(() -> {\n+            runWithMonitorEnteredInNative(lock, () -> {\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+        });\n+    }\n+\n+    \/**\n+     * Test reentering a monitor with JNI MonitorEnter.\n+     *\/\n+    @Test\n+    void testReenterInNative() throws Exception {\n+        Object lock = new Object();\n+        VThreadRunner.run(() -> {\n+\n+            \/\/ enter, reenter with JNI MonitorEnter\n+            synchronized (lock) {\n+                runWithMonitorEnteredInNative(lock, () -> {\n+                    assertTrue(Thread.holdsLock(lock));\n+                });\n+                assertTrue(Thread.holdsLock(lock));\n+            }\n+            assertFalse(Thread.holdsLock(lock));\n+\n+            \/\/ enter with JNI MonitorEnter, renter with synchronized statement\n+            runWithMonitorEnteredInNative(lock, () -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                synchronized (lock) {\n+                    assertTrue(Thread.holdsLock(lock));\n+                }\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+\n+            \/\/ enter with JNI MonitorEnter, renter with JNI MonitorEnter\n+            runWithMonitorEnteredInNative(lock, () -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                runWithMonitorEnteredInNative(lock, () -> {\n+                    assertTrue(Thread.holdsLock(lock));\n+                });\n+                assertTrue(Thread.holdsLock(lock));\n+            });\n+            assertFalse(Thread.holdsLock(lock));\n+        });\n+    }\n+\n+    \/**\n+     * Test entering a monitor with JNI MonitorEnter and with contention.\n+     *\/\n+    @Test\n+    void testEnterInNativeWithContention() throws Exception {\n+        var lock = new Object();\n+        var started = new CountDownLatch(1);\n+        var entered = new AtomicBoolean();\n+        var vthread = Thread.ofVirtual().unstarted(() -> {\n+            started.countDown();\n+            runWithMonitorEnteredInNative(lock, () -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                entered.set(true);\n+            });\n+        });\n+        try {\n+            synchronized (lock) {\n+                vthread.start();\n+\n+                \/\/ wait for thread to start and block\n+                started.await();\n+                await(vthread, Thread.State.BLOCKED);\n+\n+                assertFalse(entered.get());\n+            }\n+        } finally {\n+            vthread.join();\n+        }\n+        assertTrue(entered.get());\n+    }\n+\n+    \/**\n+     * Test entering a monitor with JNI MonitorEnter from many threads at the same time.\n+     *\/\n+    @ParameterizedTest\n+    @MethodSource(\"threadCounts\")\n+    void testEnterInNativeConcurrently(int nPlatformThreads, int nVirtualThreads) throws Exception {\n+        var counter = new Object() {\n+            int value;\n+            int value() { return value; }\n+            void increment() { value++; }\n+        };\n+        var lock = counter;\n+        executeConcurrently(nPlatformThreads, nVirtualThreads, () -> {\n+            runWithMonitorEnteredInNative(lock, () -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                counter.increment();\n+                LockSupport.parkNanos(100_000_000);  \/\/ 100ms\n+            });\n+        });\n+        synchronized (lock) {\n+            assertEquals(nPlatformThreads + nVirtualThreads, counter.value());\n+        }\n+    }\n+\n+    \/**\n+     * Test parking with synchronized native method on stack.\n+     *\/\n+    @Test\n+    void testParkingWhenPinned() throws Exception {\n+        var lock = this;\n+        var started = new CountDownLatch(1);\n+        var entered = new AtomicBoolean();\n+        var done = new AtomicBoolean();\n+        var vthread = Thread.ofVirtual().start(() -> {\n+            started.countDown();\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock));\n+                entered.set(true);\n+                while (!done.get()) {\n+                    LockSupport.park();\n+                }\n+            });\n+        });\n+        try {\n+            \/\/ wait for thread to start and block\n+            started.await();\n+            await(vthread, Thread.State.WAITING);\n+        } finally {\n+            done.set(true);\n+            LockSupport.unpark(vthread);\n+            vthread.join();\n+        }\n+        assertTrue(entered.get());\n+    }\n+\n+    \/**\n+     * Test blocking with synchronized native method on stack.\n+     *\/\n+    @Test\n+    void testBlockingWhenPinned() throws Exception {\n+        var lock1 = this;\n+        var lock2 = new Object();\n+\n+        var started = new CountDownLatch(1);\n+        var entered1 = new AtomicBoolean();   \/\/ set to true when vthread enters lock1\n+        var entered2 = new AtomicBoolean();   \/\/ set to true when vthread enters lock2\n+\n+        var vthread = Thread.ofVirtual().unstarted(() -> {\n+            started.countDown();\n+            runWithSynchronizedNative(() -> {\n+                assertTrue(Thread.holdsLock(lock1));\n+                entered1.set(true);\n+                synchronized (lock2) {   \/\/ should block\n+                    assertTrue(Thread.holdsLock(lock2));\n+                    entered2.set(true);\n+                }\n+            });\n+        });\n+        try {\n+            synchronized (lock2) {\n+                \/\/ start thread and wait for it to block trying to enter lock2\n+                vthread.start();\n+                started.await();\n+                await(vthread, Thread.State.BLOCKED);\n+\n+                assertTrue(entered1.get());\n+                assertFalse(entered2.get());\n+            }\n+        } finally {\n+            vthread.join();\n+        }\n+        assertTrue(entered2.get());\n+    }\n+\n+    \/**\n+     * Test that blocking on synchronized native method releases the carrier.\n+     *\/\n+    \/\/@Test\n+    void testReleaseWhenBlocked() throws Exception {\n+        assertTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+        try (ExecutorService scheduler = Executors.newFixedThreadPool(1)) {\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+\n+            var lock = this;\n+            var started = new CountDownLatch(1);\n+            var entered = new AtomicBoolean();   \/\/ set to true when vthread enters lock\n+\n+            var vthread1 = factory.newThread(() -> {\n+                started.countDown();\n+                runWithSynchronizedNative(() -> {\n+                    assertTrue(Thread.holdsLock(lock));\n+                    entered.set(true);\n+                });\n+                assertFalse(Thread.holdsLock(lock));\n+            });\n+\n+            vthread1.start();\n+            try {\n+                synchronized (this) {\n+                    \/\/ start thread and wait for it to block\n+                    vthread1.start();\n+                    started.await();\n+                    await(vthread1, Thread.State.BLOCKED);\n+\n+                    \/\/ carrier should be released, use it for another thread\n+                    var executed = new AtomicBoolean();\n+                    var vthread2 = factory.newThread(() -> {\n+                        executed.set(true);\n+                    });\n+                    vthread2.start();\n+                    vthread2.join();\n+                    assertTrue(executed.get());\n+                }\n+            } finally {\n+                vthread1.join();\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Invokes the given task's run method while holding the monitor for \"this\".\n+     *\/\n+    private synchronized native void runWithSynchronizedNative(Runnable task);\n+\n+    \/**\n+     * Invokes the given task's run method while holding the monitor for the given\n+     * object. The monitor is entered with JNI MonitorEnter, and exited with JNI MonitorExit.\n+     *\/\n+    private native void runWithMonitorEnteredInNative(Object lock, Runnable task);\n+\n+    \/**\n+     * Called from native methods to run the given task.\n+     *\/\n+    private void run(Runnable task) {\n+        task.run();\n+    }\n+\n+    \/**\n+     * Waits for the given thread to reach a given state.\n+     *\/\n+    private void await(Thread thread, Thread.State expectedState) throws InterruptedException {\n+        Thread.State state = thread.getState();\n+        while (state != expectedState) {\n+            assertTrue(state != Thread.State.TERMINATED, \"Thread has terminated\");\n+            Thread.sleep(10);\n+            state = thread.getState();\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/SynchronizedNative.java","additions":511,"deletions":0,"binary":false,"changes":511,"status":"added"},{"patch":"@@ -30,0 +30,1 @@\n+ * @build LockingMode\n@@ -38,0 +39,1 @@\n+ * @build LockingMode\n@@ -71,0 +73,1 @@\n+import org.junit.jupiter.api.condition.DisabledIf;\n@@ -1085,1 +1088,1 @@\n-    void testYield1() throws Exception {\n+    void testYieldReleasesCarrier() throws Exception {\n@@ -1109,1 +1112,1 @@\n-     * Test Thread.yield when thread is pinned by native frame.\n+     * Test Thread.yield releases carrier thread when virtual thread holds a monitor.\n@@ -1112,1 +1115,32 @@\n-    void testYield2() throws Exception {\n+    @DisabledIf(\"LockingMode#isLegacy\")\n+    void testYieldReleasesCarrierWhenHoldingMonitor() throws Exception {\n+        assumeTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+        var list = new CopyOnWriteArrayList<String>();\n+        try (ExecutorService scheduler = Executors.newFixedThreadPool(1)) {\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+            var lock = new Object();\n+            var thread = factory.newThread(() -> {\n+                list.add(\"A\");\n+                var child = factory.newThread(() -> {\n+                    list.add(\"B\");\n+                    synchronized (lock) {\n+                        Thread.yield();\n+                    }\n+                    list.add(\"B\");\n+                });\n+                child.start();\n+                Thread.yield();\n+                list.add(\"A\");\n+                try { child.join(); } catch (InterruptedException e) { }\n+            });\n+            thread.start();\n+            thread.join();\n+        }\n+        assertEquals(List.of(\"A\", \"B\", \"A\", \"B\"), list);\n+    }\n+\n+    \/**\n+     * Test Thread.yield when thread is pinned.\n+     *\/\n+    @Test\n+    void testYieldWhenPinned() throws Exception {\n@@ -1139,1 +1173,1 @@\n-    void testYield3() throws Exception {\n+    void testYieldDoesNotConsumParkingPermit() throws Exception {\n@@ -1152,1 +1186,1 @@\n-    void testYield4() throws Exception {\n+    void testYieldDoesNotOfferParkingPermit() throws Exception {\n@@ -1974,0 +2008,32 @@\n+    \/**\n+     * Test Thread.holdsLock when lock held by carrier thread.\n+     *\/\n+    @Disabled\n+    @Test\n+    void testHoldsLock3() throws Exception {\n+        assumeTrue(VThreadScheduler.supportsCustomScheduler(), \"No support for custom schedulers\");\n+\n+        Object lock = new Object();\n+\n+        \/\/ carrier thread runs all tasks while holding the lock\n+        ThreadFactory carrierThreadFactory = task -> Thread.ofPlatform().unstarted(() -> {\n+            synchronized (lock) {\n+                task.run();\n+            }\n+        });\n+        try (ExecutorService pool = Executors.newSingleThreadExecutor(carrierThreadFactory)) {\n+            Executor scheduler = task -> pool.submit(task::run);\n+            ThreadFactory factory = VThreadScheduler.virtualThreadFactory(scheduler);\n+\n+            \/\/ start virtual that tests if it holds the lock\n+            var result = new AtomicReference<Boolean>();\n+            Thread vthread = factory.newThread(() -> {\n+                result.set(Thread.holdsLock(lock));\n+            });\n+            vthread.start();\n+            vthread.join();\n+            boolean holdsLock = result.get();\n+            assertFalse(holdsLock, \"Thread.holdsLock should return false\");\n+        }\n+    }\n+\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/ThreadAPI.java","additions":71,"deletions":5,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -1,177 +0,0 @@\n-\/*\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-\/**\n- * @test\n- * @bug 8284161 8289284 8322846\n- * @summary Basic test of debugging option to trace pinned threads\n- * @requires vm.continuations\n- * @library \/test\/lib\n- * @run junit\/othervm -Djdk.tracePinnedThreads=full TracePinnedThreads\n- * @run junit\/othervm -Djdk.tracePinnedThreads=short TracePinnedThreads\n- *\/\n-\n-import java.io.ByteArrayOutputStream;\n-import java.io.PrintStream;\n-import java.time.Duration;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.locks.LockSupport;\n-\n-import jdk.test.lib.thread.VThreadRunner;\n-import org.junit.jupiter.api.Test;\n-import static org.junit.jupiter.api.Assertions.*;\n-\n-class TracePinnedThreads {\n-    static final Object lock = new Object();\n-\n-    \/**\n-     * Parks current thread for 1 second.\n-     *\/\n-    private static void park() {\n-        long nanos = Duration.ofSeconds(1).toNanos();\n-        LockSupport.parkNanos(nanos);\n-    }\n-\n-    \/**\n-     * Invokes the park method through a native frame to park the current\n-     * thread for 1 second.\n-     *\/\n-    private static native void invokePark();\n-\n-    \/**\n-     * Test parking inside synchronized block.\n-     *\/\n-    @Test\n-    void testPinnedCausedBySynchronizedBlock() throws Exception {\n-        String output = run(() -> {\n-            synchronized (lock) {\n-                park();\n-            }\n-        });\n-        assertContains(output, \"reason:MONITOR\");\n-        assertContains(output, \"<== monitors:1\");\n-    }\n-\n-    \/**\n-     * Test parking with native frame on stack.\n-     *\/\n-    @Test\n-    void testPinnedCausedByNativeMethod() throws Exception {\n-        System.loadLibrary(\"TracePinnedThreads\");\n-        String output = run(() -> invokePark());\n-        assertContains(output, \"reason:NATIVE\");\n-        assertContains(output, \"(Native Method)\");\n-    }\n-\n-    \/**\n-     * Test parking in class initializer.\n-     *\/\n-    @Test\n-    void testPinnedCausedByClassInitializer() throws Exception {\n-        class C {\n-            static {\n-                park();\n-            }\n-        }\n-        String output = run(C::new);\n-        assertContains(output, \"reason:NATIVE\");\n-        assertContains(output, \"<clinit>\");\n-    }\n-\n-    \/**\n-     * Test contention writing to System.out when pinned. The test creates four threads\n-     * that write to System.out when pinned, this is enough to potentially deadlock\n-     * without the changes in JDK-8322846.\n-     *\/\n-    @Test\n-    void testContention() throws Exception {\n-        \/\/ use several classes to avoid duplicate stack traces\n-        class C1 {\n-            synchronized void print() {\n-                System.out.println(\"hello\");\n-            }\n-        }\n-        class C2 {\n-            synchronized void print() {\n-                System.out.println(\"hello\");\n-            }\n-        }\n-        class C3 {\n-            synchronized void print() {\n-                System.out.println(\"hello\");\n-            }\n-        }\n-        class C4 {\n-            synchronized void print() {\n-                System.out.println(\"hello\");\n-            }\n-        }\n-\n-        try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n-            executor.submit(() -> {\n-                new C1().print();\n-            });\n-            executor.submit(() -> {\n-                new C2().print();\n-            });\n-            executor.submit(() -> {\n-                new C3().print();\n-            });\n-            executor.submit(() -> {\n-                new C4().print();\n-            });\n-        }\n-    }\n-\n-    \/**\n-     * Run a task in a virtual thread, returning a String with any output printed\n-     * to standard output.\n-     *\/\n-    private static String run(Runnable task) throws Exception {\n-        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n-        PrintStream original = System.out;\n-        System.setOut(new PrintStream(baos, true));\n-        try {\n-            VThreadRunner.run(task::run);\n-        } finally {\n-            System.setOut(original);\n-        }\n-        String output = new String(baos.toByteArray());\n-        System.out.println(output);\n-        return output;\n-    }\n-\n-    \/**\n-     * Tests that s1 contains s2.\n-     *\/\n-    private static void assertContains(String s1, String s2) {\n-        assertTrue(s1.contains(s2), s2 + \" not found!!!\");\n-    }\n-\n-    \/**\n-     * Tests that s1 does not contain s2.\n-     *\/\n-    private static void assertDoesNotContain(String s1, String s2) {\n-        assertFalse(s1.contains(s2), s2 + \" found!!\");\n-    }\n-}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/TracePinnedThreads.java","additions":0,"deletions":177,"binary":false,"changes":177,"status":"deleted"},{"patch":"@@ -27,1 +27,1 @@\n- * @modules java.base\/java.lang:+open java.base\/jdk.internal.event jdk.management\n+ * @modules java.base\/jdk.internal.event jdk.management\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/VirtualThreadPinnedEventThrows.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -0,0 +1,43 @@\n+\/*\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"jni.h\"\n+\n+JNIEXPORT void JNICALL\n+Java_SynchronizedNative_runWithSynchronizedNative(JNIEnv *env, jobject obj, jobject task) {\n+    jclass clazz = (*env)->GetObjectClass(env, obj);\n+    jmethodID mid = (*env)->GetMethodID(env, clazz, \"run\", \"(Ljava\/lang\/Runnable;)V\");\n+    if (mid != NULL) {\n+        (*env)->CallVoidMethod(env, obj, mid, task);\n+    }\n+}\n+\n+JNIEXPORT void JNICALL\n+Java_SynchronizedNative_runWithMonitorEnteredInNative(JNIEnv *env, jobject obj, jobject lock, jobject task) {\n+    jclass clazz = (*env)->GetObjectClass(env, obj);\n+    jmethodID mid = (*env)->GetMethodID(env, clazz, \"run\", \"(Ljava\/lang\/Runnable;)V\");\n+    if (mid != NULL && (*env)->MonitorEnter(env, lock) == 0) {\n+        (*env)->CallVoidMethod(env, obj, mid, task);\n+        (*env)->MonitorExit(env, lock);  \/\/ can be called with pending exception\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/libSynchronizedNative.c","additions":43,"deletions":0,"binary":false,"changes":43,"status":"added"},{"patch":"@@ -1,31 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"jni.h\"\n-\n-JNIEXPORT void JNICALL Java_TracePinnedThreads_invokePark(JNIEnv *env, jclass clazz) {\n-    jmethodID mid = (*env)->GetStaticMethodID(env, clazz, \"park\", \"()V\");\n-    if (mid != NULL) {\n-        (*env)->CallStaticVoidMethod(env, clazz, mid);\n-    }\n-}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/libTracePinnedThreads.c","additions":0,"deletions":31,"binary":false,"changes":31,"status":"deleted"},{"patch":"@@ -0,0 +1,91 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Stress test Thread.getStackTrace on a virtual thread in timed-Object.wait\n+ * @requires vm.debug != true\n+ * @run main\/othervm GetStackTraceALotWithTimedWait 100000\n+ *\/\n+\n+\/*\n+ * @test\n+ * @requires vm.debug == true\n+ * @run main\/othervm GetStackTraceALotWithTimedWait 50000\n+ *\/\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+public class GetStackTraceALotWithTimedWait {\n+\n+    public static void main(String[] args) throws Exception {\n+        int iterations = args.length > 0 ? Integer.parseInt(args[0]) : 100_000;\n+\n+        try (var executor = Executors.newVirtualThreadPerTaskExecutor()) {\n+            var done = new AtomicBoolean();\n+            var threads = new ArrayList<Thread>();\n+\n+            \/\/ start threads that invoke Object.wait with a short timeout\n+            int nthreads = Runtime.getRuntime().availableProcessors();\n+            for (int i = 0; i < nthreads; i++) {\n+                var ref = new AtomicReference<Thread>();\n+                var lock = new Object();\n+                executor.submit(() -> {\n+                    ref.set(Thread.currentThread());\n+                    while (!done.get()) {\n+                        synchronized (lock) {\n+                            int delay = 1 + ThreadLocalRandom.current().nextInt(20);\n+                            lock.wait(delay);\n+                        }\n+                    }\n+                    return null;\n+                });\n+                Thread thread;\n+                while ((thread = ref.get()) == null) {\n+                    Thread.sleep(20);\n+                }\n+                threads.add(thread);\n+            }\n+\n+            \/\/ hammer on Thread.getStackTrace\n+            try {\n+                for (int i = 1; i <= iterations; i++) {\n+                    if ((i % 1000) == 0) {\n+                        System.out.println(Instant.now() + \" => \" + i + \" of \" + iterations);\n+                    }\n+                    for (Thread thread : threads) {\n+                        thread.getStackTrace();\n+                    }\n+                }\n+            } finally {\n+                done.set(true);\n+            }\n+        }\n+    }\n+}\n+\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/stress\/GetStackTraceALotWithTimedWait.java","additions":91,"deletions":0,"binary":false,"changes":91,"status":"added"},{"patch":"@@ -0,0 +1,111 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=default\n+ * @summary Test virtual threads entering a lot of monitors with contention\n+ * @requires vm.opt.LockingMode != 1\n+ * @library \/test\/lib\n+ * @run main\/othervm LotsOfContendedMonitorEnter\n+ *\/\n+\n+\/*\n+ * @test id=LM_LIGHTWEIGHT\n+ * @requires vm.opt.LockingMode != 1\n+ * @library \/test\/lib\n+ * @run main\/othervm -XX:LockingMode=2 LotsOfContendedMonitorEnter\n+ *\/\n+\n+import java.util.concurrent.CountDownLatch;\n+import jdk.test.lib.thread.VThreadRunner;\n+\n+public class LotsOfContendedMonitorEnter {\n+\n+    public static void main(String[] args) throws Exception {\n+        int depth;\n+        if (args.length > 0) {\n+            depth = Integer.parseInt(args[0]);\n+        } else {\n+            depth = 1024;\n+        }\n+        VThreadRunner.run(() -> testContendedEnter(depth));\n+    }\n+\n+    \/**\n+     * Enter the monitor for a new object, racing with another virtual thread that\n+     * attempts to enter around the same time, then repeat to the given depth.\n+     *\/\n+    private static void testContendedEnter(int depthRemaining) throws Exception {\n+        if (depthRemaining > 0) {\n+            var lock = new Object();\n+\n+            \/\/ start thread to enter monitor for brief period, then enters again when signalled\n+            var started = new CountDownLatch(1);\n+            var signal = new CountDownLatch(1);\n+            var thread = Thread.ofVirtual().start(() -> {\n+                started.countDown();\n+\n+                \/\/ enter, may be contended\n+                synchronized (lock) {\n+                    Thread.onSpinWait();\n+                }\n+\n+                \/\/ wait to be signalled\n+                try {\n+                    signal.await();\n+                } catch (InterruptedException e) { }\n+\n+                \/\/ enter again, this will block until the main thread releases\n+                synchronized (lock) {\n+                    \/\/ do nothing\n+                }\n+            });\n+            try {\n+                \/\/ wait for thread to start\n+                started.await();\n+\n+                \/\/ enter, may be contended\n+                synchronized (lock) {\n+                    \/\/ signal thread to enter monitor again, it should block\n+                    signal.countDown();\n+                    await(thread, Thread.State.BLOCKED);\n+                    testContendedEnter(depthRemaining - 1);\n+                }\n+            } finally {\n+                thread.join();\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Waits for the given thread to reach a given state.\n+     *\/\n+    private static void await(Thread thread, Thread.State expectedState) {\n+        Thread.State state = thread.getState();\n+        while (state != expectedState) {\n+            assert state != Thread.State.TERMINATED : \"Thread has terminated\";\n+            Thread.yield();\n+            state = thread.getState();\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/stress\/LotsOfContendedMonitorEnter.java","additions":111,"deletions":0,"binary":false,"changes":111,"status":"added"},{"patch":"@@ -0,0 +1,93 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=default\n+ * @summary Test virtual thread entering (and reentering) a lot of monitors with no contention\n+ * @library \/test\/lib\n+ * @run main\/othervm LotsOfUncontendedMonitorEnter\n+ *\/\n+\n+\/*\n+ * @test id=LM_LEGACY\n+ * @library \/test\/lib\n+ * @run main\/othervm -XX:LockingMode=1 LotsOfUncontendedMonitorEnter\n+ *\/\n+\n+\/*\n+ * @test id=LM_LIGHTWEIGHT\n+ * @library \/test\/lib\n+ * @run main\/othervm -XX:LockingMode=2 LotsOfUncontendedMonitorEnter\n+ *\/\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.ThreadLocalRandom;\n+import jdk.test.lib.thread.VThreadRunner;\n+\n+public class LotsOfUncontendedMonitorEnter {\n+\n+    public static void main(String[] args) throws Exception {\n+        int depth;\n+        if (args.length > 0) {\n+            depth = Integer.parseInt(args[0]);\n+        } else {\n+            depth = 24; \/\/ 33554430 enters\n+        }\n+        VThreadRunner.run(() -> {\n+            testEnter(List.of(), depth);\n+        });\n+    }\n+\n+    \/**\n+     * Enter the monitor for a new object, reenter a monitor that is already held, and\n+     * repeat to the given depth.\n+     *\/\n+    private static void testEnter(List<Object> ownedMonitors, int depthRemaining) {\n+        if (depthRemaining > 0) {\n+            var lock = new Object();\n+            synchronized (lock) {\n+                \/\/ new list of owned monitors\n+                var monitors = concat(ownedMonitors, lock);\n+                testEnter(monitors, depthRemaining - 1);\n+\n+                \/\/ reenter a monitor that is already owned\n+                int index = ThreadLocalRandom.current().nextInt(monitors.size());\n+                var otherLock = monitors.get(index);\n+\n+                synchronized (otherLock) {\n+                    testEnter(monitors, depthRemaining - 1);\n+                }\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Adds an element to a list, returning a new list.\n+     *\/\n+    private static <T> List<T> concat(List<T> list, T object) {\n+        var newList = new ArrayList<>(list);\n+        newList.add(object);\n+        return newList;\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/stress\/LotsOfUncontendedMonitorEnter.java","additions":93,"deletions":0,"binary":false,"changes":93,"status":"added"},{"patch":"@@ -0,0 +1,121 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Stress test virtual threads with a variation of the Skynet 1M benchmark that uses\n+ *   a channel implementation based on object monitors. This variant uses a reduced number of\n+ *   100k virtual threads at the final level.\n+ * @requires vm.debug != true & vm.continuations & vm.opt.LockingMode != 1\n+ * @run main\/othervm\/timeout=300 Skynet100kWithMonitors 50\n+ *\/\n+\n+\/*\n+ * @test\n+ * @requires vm.debug == true & vm.continuations & vm.opt.LockingMode != 1\n+ * @run main\/othervm\/timeout=300 Skynet100kWithMonitors 10\n+ *\/\n+\n+public class Skynet100kWithMonitors {\n+\n+    public static void main(String[] args) {\n+        int iterations = (args.length) > 0 ? Integer.parseInt(args[0]) : 10;\n+        for (int i = 0; i < iterations; i++) {\n+            skynet(100_000, 4999950000L);\n+        }\n+    }\n+\n+    static void skynet(int num, long expected) {\n+        long start = System.currentTimeMillis();\n+        var chan = new Channel<Long>();\n+\n+        Thread.startVirtualThread(() -> skynet(chan, 0, num, 10));\n+\n+        long sum = chan.receive();\n+        long end = System.currentTimeMillis();\n+        System.out.format(\"Result: %d in %s ms%n\", sum, (end-start));\n+        if (sum != expected)\n+            throw new RuntimeException(\"Expected \" + expected);\n+    }\n+\n+    static void skynet(Channel<Long> result, int num, int size, int div) {\n+        if (size == 1) {\n+            result.send((long)num);\n+        } else {\n+            var chan = new Channel<Long>();\n+            for (int i = 0; i < div; i++) {\n+                int subNum = num + i * (size \/ div);\n+                Thread.startVirtualThread(() -> skynet(chan, subNum, size \/ div, div));\n+            }\n+            long sum = 0;\n+            for (int i = 0; i < div; i++) {\n+                sum += chan.receive();\n+            }\n+            result.send(sum);\n+        }\n+    }\n+\n+    static class Channel<T> {\n+        private final Object lock = new Object();\n+        private T element;\n+\n+        Channel() {\n+        }\n+\n+        void send(T e) {\n+            boolean interrupted = false;\n+            synchronized (lock) {\n+                while (element != null) {\n+                    try {\n+                        lock.wait();\n+                    } catch (InterruptedException x) {\n+                        interrupted = true;\n+                    }\n+                }\n+                element = e;\n+                lock.notifyAll();\n+            }\n+            if (interrupted)\n+                Thread.currentThread().interrupt();\n+        }\n+\n+        T receive() {\n+            T e;\n+            boolean interrupted = false;\n+            synchronized (lock) {\n+                while ((e = element) == null) {\n+                    try {\n+                        lock.wait();\n+                    } catch (InterruptedException x) {\n+                        interrupted = true;\n+                    }\n+                }\n+                element = null;\n+                lock.notifyAll();\n+            }\n+            if (interrupted)\n+                Thread.currentThread().interrupt();\n+            return e;\n+        }\n+    }\n+}\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/stress\/Skynet100kWithMonitors.java","additions":121,"deletions":0,"binary":false,"changes":121,"status":"added"},{"patch":"@@ -1,24 +0,0 @@\n-#\n-# Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n-# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n-#\n-# This code is free software; you can redistribute it and\/or modify it\n-# under the terms of the GNU General Public License version 2 only, as\n-# published by the Free Software Foundation.\n-#\n-# This code is distributed in the hope that it will be useful, but WITHOUT\n-# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n-# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n-# version 2 for more details (a copy is included in the LICENSE file that\n-# accompanied this code).\n-#\n-# You should have received a copy of the GNU General Public License version\n-# 2 along with this work; if not, write to the Free Software Foundation,\n-# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n-#\n-# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n-# or visit www.oracle.com if you need additional information or have any\n-# questions.\n-#\n-\n-exclusiveAccess.dirs=.\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/stress\/TEST.properties","additions":0,"deletions":24,"binary":false,"changes":24,"status":"deleted"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+ * @requires vm.compMode != \"Xcomp\"\n","filename":"test\/jdk\/java\/lang\/reflect\/callerCache\/ReflectionCallerCacheTest.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,0 +31,8 @@\n+\/*\n+ * @test id=poller-modes\n+ * @requires (os.family == \"linux\") | (os.family == \"mac\")\n+ * @library \/test\/lib\n+ * @run junit\/othervm -Djdk.pollerMode=1 --enable-native-access=ALL-UNNAMED SelectorOps\n+ * @run junit\/othervm -Djdk.pollerMode=2 --enable-native-access=ALL-UNNAMED SelectorOps\n+ *\/\n+\n","filename":"test\/jdk\/java\/nio\/channels\/vthread\/SelectorOps.java","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-* Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+* Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+* @library \/test\/lib\n@@ -47,0 +48,1 @@\n+* @library \/test\/lib\n@@ -57,0 +59,2 @@\n+import jdk.test.lib.Platform;\n+\n@@ -63,0 +67,3 @@\n+import com.sun.management.HotSpotDiagnosticMXBean;\n+import java.lang.management.ManagementFactory;\n+\n@@ -279,0 +286,2 @@\n+        if (!legacyLockingMode()) return;\n+\n@@ -413,0 +422,5 @@\n+\n+    static boolean legacyLockingMode() {\n+        return ManagementFactory.getPlatformMXBean(HotSpotDiagnosticMXBean.class)\n+                    .getVMOption(\"LockingMode\").getValue().equals(\"1\");\n+    }\n","filename":"test\/jdk\/jdk\/internal\/vm\/Continuation\/Basic.java","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-* Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+* Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -78,0 +78,3 @@\n+import com.sun.management.HotSpotDiagnosticMXBean;\n+import java.lang.management.ManagementFactory;\n+\n@@ -473,1 +476,1 @@\n-        return traceHas(Op.PIN::contains);\n+        return traceHas(Op.PIN::contains) && legacyLockingMode();\n@@ -1032,0 +1035,5 @@\n+\n+    static boolean legacyLockingMode() {\n+        return ManagementFactory.getPlatformMXBean(HotSpotDiagnosticMXBean.class)\n+                    .getVMOption(\"LockingMode\").getValue().equals(\"1\");\n+    }\n","filename":"test\/jdk\/jdk\/internal\/vm\/Continuation\/Fuzz.java","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"}]}