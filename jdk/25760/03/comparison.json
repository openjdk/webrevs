{"files":[{"patch":"@@ -921,1 +921,1 @@\n-void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {\n+void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) const {\n@@ -1306,0 +1306,51 @@\n+bool CallLeafPureNode::is_unused() const {\n+  return proj_out_or_null(TypeFunc::Parms) == nullptr;\n+}\n+\n+bool CallLeafPureNode::is_dead() const {\n+  return proj_out_or_null(TypeFunc::Control) == nullptr;\n+}\n+\n+\/* We make a tuple of the global input state + TOP for the output values.\n+ * We use this to delete a pure function that is not used: by replacing the call with\n+ * such a tuple, we let output Proj's idealization pick the corresponding input of the\n+ * pure call, so jumping over it, and effectively, removing the call from the graph.\n+ * This avoids doing the graph surgery manually, but leaves that to IGVN\n+ * that is specialized for doing that right. We need also tuple components for output\n+ * values of the function to respect the return arity, and in case there is a projection\n+ * that would pick an output (which shouldn't happen at the moment).\n+ *\/\n+TupleNode* CallLeafPureNode::make_tuple_of_input_state_and_top_return_values(const Compile* C) const {\n+  \/\/ Transparently propagate input state but parameters\n+  TupleNode* tuple = TupleNode::make(\n+      tf()->range(),\n+      in(TypeFunc::Control),\n+      in(TypeFunc::I_O),\n+      in(TypeFunc::Memory),\n+      in(TypeFunc::FramePtr),\n+      in(TypeFunc::ReturnAdr));\n+\n+  \/\/ And add TOPs for the return values\n+  for (uint i = TypeFunc::Parms; i < tf()->range()->cnt(); i++) {\n+    tuple->set_req(i, C->top());\n+  }\n+\n+  return tuple;\n+}\n+\n+Node* CallLeafPureNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (is_dead()) {\n+    return nullptr;\n+  }\n+\n+  \/\/ We need to wait until IGVN because during parsing, usages might still be missing\n+  \/\/ and we would remove the call immediately.\n+  if (can_reshape && is_unused()) {\n+    \/\/ The result is not used. We remove the call by replacing it with a tuple, that\n+    \/\/ is later disintegrated by the projections.\n+    return make_tuple_of_input_state_and_top_return_values(phase->C);\n+  }\n+\n+  return CallRuntimeNode::Ideal(phase, can_reshape);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":52,"deletions":1,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -740,1 +740,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true) const;\n@@ -916,0 +916,27 @@\n+\/* A pure function call, they are assumed not to be safepoints, not to read or write memory,\n+ * have no exception... They just take parameters, return a value without side effect. It is\n+ * always correct to create some, or remove them, if the result is not used.\n+ *\n+ * They still have control input to allow easy lowering into other kind of calls that require\n+ * a control, but this is more a technical than a moral constraint.\n+ *\n+ * Pure calls must have only control and data input and output: I\/O, Memory and so on must be top.\n+ * Nevertheless, pure calls can typically be expensive math operations so care must be taken\n+ * when letting the node float.\n+ *\/\n+class CallLeafPureNode : public CallLeafNode {\n+protected:\n+  bool is_unused() const;\n+  bool is_dead() const;\n+  TupleNode* make_tuple_of_input_state_and_top_return_values(const Compile* C) const;\n+\n+public:\n+  CallLeafPureNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type)\n+      : CallLeafNode(tf, addr, name, adr_type) {\n+    init_class_id(Class_CallLeafPure);\n+  }\n+  int Opcode() const override;\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape) override;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":28,"deletions":1,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -64,0 +64,1 @@\n+macro(CallLeafPure)\n@@ -375,0 +376,1 @@\n+macro(Tuple)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3301,0 +3301,19 @@\n+  case Op_CallLeafPure: {\n+    \/\/ If the pure call is not supported, then lower to a CallLeaf.\n+    if (!Matcher::match_rule_supported(Op_CallLeafPure)) {\n+      CallNode* call = n->as_Call();\n+      CallNode* new_call = new CallLeafNode(call->tf(), call->entry_point(),\n+                                            call->_name, TypeRawPtr::BOTTOM);\n+      new_call->init_req(TypeFunc::Control, call->in(TypeFunc::Control));\n+      new_call->init_req(TypeFunc::I_O, C->top());\n+      new_call->init_req(TypeFunc::Memory, C->top());\n+      new_call->init_req(TypeFunc::ReturnAdr, C->top());\n+      new_call->init_req(TypeFunc::FramePtr, C->top());\n+      for (unsigned int i = TypeFunc::Parms; i < call->tf()->domain()->cnt(); i++) {\n+        new_call->init_req(i, call->in(i));\n+      }\n+      n->subsume_by(new_call, this);\n+    }\n+    frc.inc_call_count();\n+    break;\n+  }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, const char* name) : CallLeafNode(tf, nullptr, name, TypeRawPtr::BOTTOM) {\n+ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name) : CallLeafPureNode(tf, addr, name, TypeRawPtr::BOTTOM) {\n@@ -50,1 +50,1 @@\n-ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), \"drem\") {\n+ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::drem), \"drem\") {\n@@ -57,1 +57,1 @@\n-ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), \"frem\") {\n+ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::frem), \"frem\") {\n@@ -1520,0 +1520,5 @@\n+  Node* super = CallLeafPureNode::Ideal(phase, can_reshape);\n+  if (super != nullptr) {\n+    return super;\n+  }\n+\n@@ -1523,1 +1528,0 @@\n-  PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -1525,5 +1529,1 @@\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeF::make(0.));\n-  }\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -1572,0 +1572,5 @@\n+  Node* super = CallLeafPureNode::Ideal(phase, can_reshape);\n+  if (super != nullptr) {\n+    return super;\n+  }\n+\n@@ -1575,1 +1580,0 @@\n-  PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -1577,5 +1581,1 @@\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeD::make(0.));\n-  }\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -1629,14 +1629,0 @@\n-  if (projs.fallthrough_catchproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_catchproj, in(TypeFunc::Control));\n-  }\n-  if (projs.fallthrough_memproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_memproj, in(TypeFunc::Memory));\n-  }\n-  if (projs.catchall_memproj != nullptr) {\n-    phase->replace_node(projs.catchall_memproj, C->top());\n-  }\n-  if (projs.fallthrough_ioproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_ioproj, in(TypeFunc::I_O));\n-  }\n-  assert(projs.catchall_ioproj == nullptr, \"no exceptions from floating mod\");\n-  assert(projs.catchall_catchproj == nullptr, \"no exceptions from floating mod\");\n","filename":"src\/hotspot\/share\/opto\/divnode.cpp","additions":15,"deletions":29,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -159,1 +159,1 @@\n-class ModFloatingNode : public CallLeafNode {\n+class ModFloatingNode : public CallLeafPureNode {\n@@ -164,1 +164,1 @@\n-  ModFloatingNode(Compile* C, const TypeFunc* tf, const char *name);\n+  ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name);\n","filename":"src\/hotspot\/share\/opto\/divnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1883,8 +1883,14 @@\n-  Node* memory = reset_memory();\n-  Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n-  call->init_req( TypeFunc::Control,   control()  );\n-  call->init_req( TypeFunc::I_O,       top()      ); \/\/ does no i\/o\n-  call->init_req( TypeFunc::Memory,    m          ); \/\/ may gc ptrs\n-  call->init_req( TypeFunc::FramePtr,  frameptr() );\n-  call->init_req( TypeFunc::ReturnAdr, top()      );\n-  return memory;\n+  call->init_req(TypeFunc::Control, control());\n+  call->init_req(TypeFunc::I_O, top()); \/\/ does no i\/o\n+  call->init_req(TypeFunc::ReturnAdr, top());\n+  if (call->is_CallLeafPure()) {\n+    call->init_req(TypeFunc::Memory, top());\n+    call->init_req(TypeFunc::FramePtr, top());\n+    return nullptr;\n+  } else {\n+    Node* memory = reset_memory();\n+    Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n+    call->init_req(TypeFunc::Memory, m); \/\/ may gc ptrs\n+    call->init_req(TypeFunc::FramePtr, frameptr());\n+    return memory;\n+  }\n@@ -1908,0 +1914,5 @@\n+  if (call->is_CallLeafPure()) {\n+    \/\/ Pure function have only control (for now) and data output, in particular\n+    \/\/ they don't touch the memory, so we don't want a memory proj that is set after.\n+    return;\n+  }\n@@ -2494,0 +2505,2 @@\n+  } else if (flags & RC_PURE) {\n+    call = new CallLeafPureNode(call_type, call_addr, call_name, adr_type);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":21,"deletions":8,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -787,0 +787,1 @@\n+    RC_PURE = 128,              \/\/ CallLeaf is pure\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1800,1 +1800,1 @@\n-  Node* trig = make_runtime_call(RC_LEAF, call_type, funcAddr, funcName,\n+  Node* trig = make_runtime_call(RC_LEAF | RC_PURE, call_type, funcAddr, funcName,\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2600,1 +2600,0 @@\n-        bool is_drem = n->Opcode() == Op_ModD;\n@@ -2602,4 +2601,2 @@\n-        CallNode* call = new CallLeafNode(mod_macro->tf(),\n-                                          is_drem ? CAST_FROM_FN_PTR(address, SharedRuntime::drem)\n-                                                  : CAST_FROM_FN_PTR(address, SharedRuntime::frem),\n-                                          is_drem ? \"drem\" : \"frem\", TypeRawPtr::BOTTOM);\n+        CallNode* call = new CallLeafPureNode(mod_macro->tf(), mod_macro->entry_point(),\n+                                              mod_macro->_name, TypeRawPtr::BOTTOM);\n@@ -2607,4 +2604,4 @@\n-        call->init_req(TypeFunc::I_O, mod_macro->in(TypeFunc::I_O));\n-        call->init_req(TypeFunc::Memory, mod_macro->in(TypeFunc::Memory));\n-        call->init_req(TypeFunc::ReturnAdr, mod_macro->in(TypeFunc::ReturnAdr));\n-        call->init_req(TypeFunc::FramePtr, mod_macro->in(TypeFunc::FramePtr));\n+        call->init_req(TypeFunc::I_O, C->top());\n+        call->init_req(TypeFunc::Memory, C->top());\n+        call->init_req(TypeFunc::ReturnAdr, C->top());\n+        call->init_req(TypeFunc::FramePtr, C->top());\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -123,0 +123,4 @@\n+    if (ctrl->Opcode() == Op_Tuple) {\n+      \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+      ctrl = ctrl->in(_con);\n+    }\n@@ -166,0 +170,9 @@\n+\/\/------------------------------Identity---------------------------------------\n+Node* ProjNode::Identity(PhaseGVN* phase) {\n+  if (in(0) != nullptr && in(0)->Opcode() == Op_Tuple) {\n+    \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+    return in(0)->in(_con);\n+  }\n+  return this;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+  virtual Node* Identity(PhaseGVN* phase);\n@@ -108,0 +109,45 @@\n+\/* Tuples are used to avoid manual graph surgery. When a node with Proj outputs (such as a call)\n+ * must be removed and its ouputs replaced by its input, or some other value, we can make its\n+ * ::Ideal return a tuple of what we want for each output: the ::Identity of output Proj will\n+ * take care to jump over the Tuple and directly pick up the right input of the Tuple.\n+ *\n+ * For instance, if a function call is proven to have no side effect and return the constant 0,\n+ * we can replace it with the 6-tuple:\n+ * (control input, IO input, memory input, frame ptr input, return addr input, Con:0)\n+ * all the output projections will pick up the input of the now gone call, except for the result\n+ * projection that is replaced by 0.\n+ *\n+ * Using TupleNode avoid manual graph surgery and leave that to our expert surgeon: IGVN.\n+ * Since the user of a Tuple are expected to be Proj, when creating a tuple during idealization,\n+ * the output Proj should be enqueued for IGVN immediately after, and the tuple should not survive\n+ * after the current IGVN.\n+ *\/\n+class TupleNode : public MultiNode {\n+  const TypeTuple* _tf;\n+\n+  template <typename... NN>\n+  static void make_helper(TupleNode* tn, uint i, Node* node, NN... nn) {\n+    tn->set_req(i, node);\n+    make_helper(tn, i + 1, nn...);\n+  }\n+\n+  static void make_helper(TupleNode*, uint) {}\n+\n+public:\n+  TupleNode(const TypeTuple* tf) : MultiNode(tf->cnt()), _tf(tf) {}\n+\n+  int Opcode() const override;\n+  const Type* bottom_type() const override { return _tf; }\n+\n+  \/* Give as many `Node*` as you want in the `nn` pack:\n+   * TupleNode::make(tf, input1)\n+   * TupleNode::make(tf, input1, input2, input3, input4)\n+   *\/\n+  template <typename... NN>\n+  static TupleNode* make(const TypeTuple* tf, NN... nn) {\n+    TupleNode* tn = new TupleNode(tf);\n+    make_helper(tn, 0, nn...);\n+    return tn;\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.hpp","additions":46,"deletions":0,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2950,10 +2950,0 @@\n-bool Node::is_pure_function() const {\n-  switch (Opcode()) {\n-  case Op_ModD:\n-  case Op_ModF:\n-    return true;\n-  default:\n-    return false;\n-  }\n-}\n-\n@@ -2966,1 +2956,1 @@\n-  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_pure_function();\n+  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_CallLeafPure();\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+class CallLeafPureNode;\n@@ -676,0 +677,1 @@\n+              DEFINE_CLASS_ID(CallLeafPure,     CallLeaf, 1)\n@@ -910,0 +912,1 @@\n+  DEFINE_CLASS_QUERY(CallLeafPure)\n@@ -1292,2 +1295,0 @@\n-  bool is_pure_function() const;\n-\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1100,1 +1100,1 @@\n-  CallNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n+  CallLeafPureNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallLeafPureNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n@@ -1102,3 +1102,3 @@\n-  Node* prev_mem = set_predefined_input_for_runtime_call(mod);\n-  mod = _gvn.transform(mod)->as_Call();\n-  set_predefined_output_for_runtime_call(mod, prev_mem, TypeRawPtr::BOTTOM);\n+  set_predefined_input_for_runtime_call(mod);\n+  mod = _gvn.transform(mod)->as_CallLeafPure();\n+  set_predefined_output_for_runtime_call(mod);\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}