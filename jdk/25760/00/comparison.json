{"files":[{"patch":"@@ -921,1 +921,1 @@\n-void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {\n+void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) const {\n@@ -1306,0 +1306,34 @@\n+bool CallLeafPureNode::is_unused() const {\n+  return proj_out_or_null(TypeFunc::Parms) == nullptr;\n+}\n+\/\/ We make a tuple of the global input state + TOP for the output values.\n+TupleNode* CallLeafPureNode::make_tuple_of_input_state_and_top_return_values(const Compile* C) const {\n+  \/\/ Transparently propagate input state but parameters\n+  TupleNode* tuple = TupleNode::make(\n+      tf()->range(),\n+      in(TypeFunc::Control),\n+      in(TypeFunc::I_O),\n+      in(TypeFunc::Memory),\n+      in(TypeFunc::FramePtr),\n+      in(TypeFunc::ReturnAdr));\n+\n+  \/\/ And add TOPs for the return values\n+  for (uint i = TypeFunc::Parms; i < tf()->range()->cnt(); i++) {\n+    tuple->set_req(i, C->top());\n+  }\n+\n+  return tuple;\n+}\n+\n+Node* CallLeafPureNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (proj_out_or_null(TypeFunc::Control) == nullptr) { \/\/ dead node\n+    return nullptr;\n+  }\n+\n+  if (can_reshape && is_unused()) {\n+    return make_tuple_of_input_state_and_top_return_values(phase->C);\n+  }\n+\n+  return CallRuntimeNode::Ideal(phase, can_reshape);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":35,"deletions":1,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -740,1 +740,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true) const;\n@@ -916,0 +916,15 @@\n+class CallLeafPureNode : public CallLeafNode {\n+protected:\n+  bool is_unused() const;\n+  TupleNode* make_tuple_of_input_state_and_top_return_values(const Compile* C) const;\n+\n+public:\n+  CallLeafPureNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type)\n+      : CallLeafNode(tf, addr, name, adr_type) {\n+    init_class_id(Class_CallLeafPure);\n+  }\n+  int Opcode() const override;\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape) override;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":16,"deletions":1,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -64,0 +64,1 @@\n+macro(CallLeafPure)\n@@ -375,0 +376,1 @@\n+macro(Tuple)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3301,0 +3301,18 @@\n+  case Op_CallLeafPure: {\n+    if (!Matcher::match_rule_supported(Op_CallLeafPure)) {\n+      CallNode* call = n->as_Call();\n+      CallNode* new_call = new CallLeafNode(call->tf(), call->entry_point(),\n+                                            call->_name, TypeRawPtr::BOTTOM);\n+      new_call->init_req(TypeFunc::Control, call->in(TypeFunc::Control));\n+      new_call->init_req(TypeFunc::I_O, C->top());\n+      new_call->init_req(TypeFunc::Memory, C->top());\n+      new_call->init_req(TypeFunc::ReturnAdr, C->top());\n+      new_call->init_req(TypeFunc::FramePtr, C->top());\n+      for (unsigned int i = 0; i < call->tf()->domain()->cnt() - TypeFunc::Parms; i++) {\n+        new_call->init_req(TypeFunc::Parms + i, call->in(TypeFunc::Parms + i));\n+      }\n+      n->subsume_by(new_call, this);\n+    }\n+    frc.inc_call_count();\n+    break;\n+  }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, const char* name) : CallLeafNode(tf, nullptr, name, TypeRawPtr::BOTTOM) {\n+ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name) : CallLeafPureNode(tf, addr, name, TypeRawPtr::BOTTOM) {\n@@ -50,1 +50,1 @@\n-ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), \"drem\") {\n+ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::drem), \"drem\") {\n@@ -57,1 +57,1 @@\n-ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), \"frem\") {\n+ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::frem), \"frem\") {\n@@ -1523,0 +1523,4 @@\n+  if (proj_out_or_null(TypeFunc::Control) == nullptr) { \/\/ dead node\n+    return nullptr;\n+  }\n+\n@@ -1525,4 +1529,2 @@\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeF::make(0.));\n+  if (is_unused()) {\n+    return make_tuple_of_input_state_and_top_return_values(igvn->C);\n@@ -1575,0 +1577,4 @@\n+  if (proj_out_or_null(TypeFunc::Control) == nullptr) { \/\/ dead node\n+    return nullptr;\n+  }\n+\n@@ -1577,4 +1583,2 @@\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeD::make(0.));\n+  if (is_unused()) {\n+    return make_tuple_of_input_state_and_top_return_values(igvn->C);\n@@ -1629,14 +1633,0 @@\n-  if (projs.fallthrough_catchproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_catchproj, in(TypeFunc::Control));\n-  }\n-  if (projs.fallthrough_memproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_memproj, in(TypeFunc::Memory));\n-  }\n-  if (projs.catchall_memproj != nullptr) {\n-    phase->replace_node(projs.catchall_memproj, C->top());\n-  }\n-  if (projs.fallthrough_ioproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_ioproj, in(TypeFunc::I_O));\n-  }\n-  assert(projs.catchall_ioproj == nullptr, \"no exceptions from floating mod\");\n-  assert(projs.catchall_catchproj == nullptr, \"no exceptions from floating mod\");\n","filename":"src\/hotspot\/share\/opto\/divnode.cpp","additions":15,"deletions":25,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -159,1 +159,1 @@\n-class ModFloatingNode : public CallLeafNode {\n+class ModFloatingNode : public CallLeafPureNode {\n@@ -164,1 +164,1 @@\n-  ModFloatingNode(Compile* C, const TypeFunc* tf, const char *name);\n+  ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name);\n","filename":"src\/hotspot\/share\/opto\/divnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1883,8 +1883,14 @@\n-  Node* memory = reset_memory();\n-  Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n-  call->init_req( TypeFunc::Control,   control()  );\n-  call->init_req( TypeFunc::I_O,       top()      ); \/\/ does no i\/o\n-  call->init_req( TypeFunc::Memory,    m          ); \/\/ may gc ptrs\n-  call->init_req( TypeFunc::FramePtr,  frameptr() );\n-  call->init_req( TypeFunc::ReturnAdr, top()      );\n-  return memory;\n+  call->init_req(TypeFunc::Control, control());\n+  call->init_req(TypeFunc::I_O, top()); \/\/ does no i\/o\n+  call->init_req(TypeFunc::ReturnAdr, top());\n+  if (call->is_CallLeafPure()) {\n+    call->init_req(TypeFunc::Memory, top());\n+    call->init_req(TypeFunc::FramePtr, top());\n+    return nullptr;\n+  } else {\n+    Node* memory = reset_memory();\n+    Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n+    call->init_req(TypeFunc::Memory, m); \/\/ may gc ptrs\n+    call->init_req(TypeFunc::FramePtr, frameptr());\n+    return memory;\n+  }\n@@ -1908,0 +1914,3 @@\n+  if (call->is_CallLeafPure()) {\n+    return;\n+  }\n@@ -2494,0 +2503,2 @@\n+  } else if (flags & RC_PURE) {\n+    call = new CallLeafPureNode(call_type, call_addr, call_name, adr_type);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":19,"deletions":8,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -787,0 +787,1 @@\n+    RC_PURE = 128,              \/\/ CallLeaf is pure\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1800,1 +1800,1 @@\n-  Node* trig = make_runtime_call(RC_LEAF, call_type, funcAddr, funcName,\n+  Node* trig = make_runtime_call(RC_LEAF | RC_PURE, call_type, funcAddr, funcName,\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2600,1 +2600,0 @@\n-        bool is_drem = n->Opcode() == Op_ModD;\n@@ -2602,4 +2601,2 @@\n-        CallNode* call = new CallLeafNode(mod_macro->tf(),\n-                                          is_drem ? CAST_FROM_FN_PTR(address, SharedRuntime::drem)\n-                                                  : CAST_FROM_FN_PTR(address, SharedRuntime::frem),\n-                                          is_drem ? \"drem\" : \"frem\", TypeRawPtr::BOTTOM);\n+        CallNode* call = new CallLeafPureNode(mod_macro->tf(), mod_macro->entry_point(),\n+                                              mod_macro->_name, TypeRawPtr::BOTTOM);\n@@ -2607,4 +2604,4 @@\n-        call->init_req(TypeFunc::I_O, mod_macro->in(TypeFunc::I_O));\n-        call->init_req(TypeFunc::Memory, mod_macro->in(TypeFunc::Memory));\n-        call->init_req(TypeFunc::ReturnAdr, mod_macro->in(TypeFunc::ReturnAdr));\n-        call->init_req(TypeFunc::FramePtr, mod_macro->in(TypeFunc::FramePtr));\n+        call->init_req(TypeFunc::I_O, C->top());\n+        call->init_req(TypeFunc::Memory, C->top());\n+        call->init_req(TypeFunc::ReturnAdr, C->top());\n+        call->init_req(TypeFunc::FramePtr, C->top());\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -123,0 +123,4 @@\n+    if (ctrl->Opcode() == Op_Tuple) {\n+      \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+      ctrl = ctrl->in(_con);\n+    }\n@@ -166,0 +170,9 @@\n+\/\/------------------------------Identity---------------------------------------\n+Node* ProjNode::Identity(PhaseGVN* phase) {\n+  if (in(0) != nullptr && in(0)->Opcode() == Op_Tuple) {\n+    \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+    return in(0)->in(_con);\n+  }\n+  return this;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+  virtual Node* Identity(PhaseGVN* phase);\n@@ -108,0 +109,26 @@\n+\/\/------------------------------TupleNode---------------------------------------\n+class TupleNode : public MultiNode {\n+  const TypeTuple* _tf;\n+\n+  template <typename... NN>\n+  static void make_helper(TupleNode* tn, uint i, Node* node, NN... nn) {\n+    tn->set_req(i, node);\n+    make_helper(tn, i + 1, nn...);\n+  }\n+\n+  static void make_helper(TupleNode*, uint) {}\n+\n+public:\n+  TupleNode(const TypeTuple* tf) : MultiNode(tf->cnt()), _tf(tf) {}\n+\n+  int Opcode() const override;\n+  const Type* bottom_type() const override { return _tf; }\n+\n+  template <typename... NN>\n+  static TupleNode* make(const TypeTuple* tf, NN... nn) {\n+    TupleNode* tn = new TupleNode(tf);\n+    make_helper(tn, 0, nn...);\n+    return tn;\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.hpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2950,10 +2950,0 @@\n-bool Node::is_pure_function() const {\n-  switch (Opcode()) {\n-  case Op_ModD:\n-  case Op_ModF:\n-    return true;\n-  default:\n-    return false;\n-  }\n-}\n-\n@@ -2966,1 +2956,1 @@\n-  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_pure_function();\n+  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_CallLeafPure();\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+class CallLeafPureNode;\n@@ -676,0 +677,1 @@\n+              DEFINE_CLASS_ID(CallLeafPure,     CallLeaf, 1)\n@@ -910,0 +912,1 @@\n+  DEFINE_CLASS_QUERY(CallLeafPure)\n@@ -1292,2 +1295,0 @@\n-  bool is_pure_function() const;\n-\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1100,1 +1100,1 @@\n-  CallNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n+  CallLeafPureNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallLeafPureNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n@@ -1102,3 +1102,3 @@\n-  Node* prev_mem = set_predefined_input_for_runtime_call(mod);\n-  mod = _gvn.transform(mod)->as_Call();\n-  set_predefined_output_for_runtime_call(mod, prev_mem, TypeRawPtr::BOTTOM);\n+  set_predefined_input_for_runtime_call(mod);\n+  mod = _gvn.transform(mod)->as_CallLeafPure();\n+  set_predefined_output_for_runtime_call(mod);\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}