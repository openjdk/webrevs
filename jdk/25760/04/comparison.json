{"files":[{"patch":"@@ -921,1 +921,1 @@\n-void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {\n+void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) const {\n@@ -1306,0 +1306,51 @@\n+bool CallLeafPureNode::is_unused() const {\n+  return proj_out_or_null(TypeFunc::Parms) == nullptr;\n+}\n+\n+bool CallLeafPureNode::is_dead() const {\n+  return proj_out_or_null(TypeFunc::Control) == nullptr;\n+}\n+\n+\/* We make a tuple of the global input state + TOP for the output values.\n+ * We use this to delete a pure function that is not used: by replacing the call with\n+ * such a tuple, we let output Proj's idealization pick the corresponding input of the\n+ * pure call, so jumping over it, and effectively, removing the call from the graph.\n+ * This avoids doing the graph surgery manually, but leaves that to IGVN\n+ * that is specialized for doing that right. We need also tuple components for output\n+ * values of the function to respect the return arity, and in case there is a projection\n+ * that would pick an output (which shouldn't happen at the moment).\n+ *\/\n+TupleNode* CallLeafPureNode::make_tuple_of_input_state_and_top_return_values(const Compile* C) const {\n+  \/\/ Transparently propagate input state but parameters\n+  TupleNode* tuple = TupleNode::make(\n+      tf()->range(),\n+      in(TypeFunc::Control),\n+      in(TypeFunc::I_O),\n+      in(TypeFunc::Memory),\n+      in(TypeFunc::FramePtr),\n+      in(TypeFunc::ReturnAdr));\n+\n+  \/\/ And add TOPs for the return values\n+  for (uint i = TypeFunc::Parms; i < tf()->range()->cnt(); i++) {\n+    tuple->set_req(i, C->top());\n+  }\n+\n+  return tuple;\n+}\n+\n+Node* CallLeafPureNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (is_dead()) {\n+    return nullptr;\n+  }\n+\n+  \/\/ We need to wait until IGVN because during parsing, usages might still be missing\n+  \/\/ and we would remove the call immediately.\n+  if (can_reshape && is_unused()) {\n+    \/\/ The result is not used. We remove the call by replacing it with a tuple, that\n+    \/\/ is later disintegrated by the projections.\n+    return make_tuple_of_input_state_and_top_return_values(phase->C);\n+  }\n+\n+  return CallRuntimeNode::Ideal(phase, can_reshape);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":52,"deletions":1,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -740,1 +740,1 @@\n-  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true);\n+  void extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts = true) const;\n@@ -916,0 +916,27 @@\n+\/* A pure function call, they are assumed not to be safepoints, not to read or write memory,\n+ * have no exception... They just take parameters, return a value without side effect. It is\n+ * always correct to create some, or remove them, if the result is not used.\n+ *\n+ * They still have control input to allow easy lowering into other kind of calls that require\n+ * a control, but this is more a technical than a moral constraint.\n+ *\n+ * Pure calls must have only control and data input and output: I\/O, Memory and so on must be top.\n+ * Nevertheless, pure calls can typically be expensive math operations so care must be taken\n+ * when letting the node float.\n+ *\/\n+class CallLeafPureNode : public CallLeafNode {\n+protected:\n+  bool is_unused() const;\n+  bool is_dead() const;\n+  TupleNode* make_tuple_of_input_state_and_top_return_values(const Compile* C) const;\n+\n+public:\n+  CallLeafPureNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type)\n+      : CallLeafNode(tf, addr, name, adr_type) {\n+    init_class_id(Class_CallLeafPure);\n+  }\n+  int Opcode() const override;\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape) override;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":28,"deletions":1,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -64,0 +64,1 @@\n+macro(CallLeafPure)\n@@ -375,0 +376,1 @@\n+macro(Tuple)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3301,0 +3301,19 @@\n+  case Op_CallLeafPure: {\n+    \/\/ If the pure call is not supported, then lower to a CallLeaf.\n+    if (!Matcher::match_rule_supported(Op_CallLeafPure)) {\n+      CallNode* call = n->as_Call();\n+      CallNode* new_call = new CallLeafNode(call->tf(), call->entry_point(),\n+                                            call->_name, TypeRawPtr::BOTTOM);\n+      new_call->init_req(TypeFunc::Control, call->in(TypeFunc::Control));\n+      new_call->init_req(TypeFunc::I_O, C->top());\n+      new_call->init_req(TypeFunc::Memory, C->top());\n+      new_call->init_req(TypeFunc::ReturnAdr, C->top());\n+      new_call->init_req(TypeFunc::FramePtr, C->top());\n+      for (unsigned int i = TypeFunc::Parms; i < call->tf()->domain()->cnt(); i++) {\n+        new_call->init_req(i, call->in(i));\n+      }\n+      n->subsume_by(new_call, this);\n+    }\n+    frc.inc_call_count();\n+    break;\n+  }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, const char* name) : CallLeafNode(tf, nullptr, name, TypeRawPtr::BOTTOM) {\n+ModFloatingNode::ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name) : CallLeafPureNode(tf, addr, name, TypeRawPtr::BOTTOM) {\n@@ -50,1 +50,1 @@\n-ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), \"drem\") {\n+ModDNode::ModDNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::Math_DD_D_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::drem), \"drem\") {\n@@ -57,1 +57,1 @@\n-ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), \"frem\") {\n+ModFNode::ModFNode(Compile* C, Node* a, Node* b) : ModFloatingNode(C, OptoRuntime::modf_Type(), CAST_FROM_FN_PTR(address, SharedRuntime::frem), \"frem\") {\n@@ -1519,19 +1519,1 @@\n-Node* ModFNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  if (!can_reshape) {\n-    return nullptr;\n-  }\n-  PhaseIterGVN* igvn = phase->is_IterGVN();\n-\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeF::make(0.));\n-  }\n-\n-  \/\/ Either input is TOP ==> the result is TOP\n-  const Type* t1 = phase->type(dividend());\n-  const Type* t2 = phase->type(divisor());\n-  if (t1 == Type::TOP || t2 == Type::TOP) {\n-    return phase->C->top();\n-  }\n-\n+const Type* ModFNode::get_result_if_constant(const Type* dividend, const Type* divisor) const {\n@@ -1539,1 +1521,1 @@\n-  if ((t1->base() != Type::FloatCon) || (t2->base() != Type::FloatCon)) {\n+  if ((dividend->base() != Type::FloatCon) || (divisor->base() != Type::FloatCon)) {\n@@ -1543,4 +1525,4 @@\n-  float f1 = t1->getf();\n-  float f2 = t2->getf();\n-  jint x1 = jint_cast(f1); \/\/ note:  *(int*)&f1, not just (int)f1\n-  jint x2 = jint_cast(f2);\n+  float dividend_f = dividend->getf();\n+  float divisor_f = divisor->getf();\n+  jint dividend_i = jint_cast(dividend_f); \/\/ note:  *(int*)&f1, not just (int)f1\n+  jint divisor_i = jint_cast(divisor_f);\n@@ -1549,2 +1531,2 @@\n-  if (g_isnan(f1)) {\n-    return replace_with_con(igvn, t1);\n+  if (g_isnan(dividend_f)) {\n+    return dividend;\n@@ -1552,2 +1534,2 @@\n-  if (g_isnan(f2)) {\n-    return replace_with_con(igvn, t2);\n+  if (g_isnan(divisor_f)) {\n+    return divisor;\n@@ -1557,1 +1539,1 @@\n-  if (!g_isfinite(f1) || !g_isfinite(f2) || x2 == 0 || x2 == min_jint) {\n+  if (!g_isfinite(dividend_f) || !g_isfinite(divisor_f) || divisor_i == 0 || divisor_i == min_jint) {\n@@ -1563,2 +1545,2 @@\n-  jint xr = jint_cast(fmod(f1, f2));\n-  if ((x1 ^ xr) < 0) {\n+  jint xr = jint_cast(fmod(dividend_f, divisor_f));\n+  if ((dividend_i ^ xr) < 0) {\n@@ -1568,1 +1550,1 @@\n-  return replace_with_con(igvn, TypeF::make(jfloat_cast(xr)));\n+  return TypeF::make(jfloat_cast(xr));\n@@ -1571,19 +1553,1 @@\n-Node* ModDNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  if (!can_reshape) {\n-    return nullptr;\n-  }\n-  PhaseIterGVN* igvn = phase->is_IterGVN();\n-\n-  bool result_is_unused = proj_out_or_null(TypeFunc::Parms) == nullptr;\n-  bool not_dead = proj_out_or_null(TypeFunc::Control) != nullptr;\n-  if (result_is_unused && not_dead) {\n-    return replace_with_con(igvn, TypeD::make(0.));\n-  }\n-\n-  \/\/ Either input is TOP ==> the result is TOP\n-  const Type* t1 = phase->type(dividend());\n-  const Type* t2 = phase->type(divisor());\n-  if (t1 == Type::TOP || t2 == Type::TOP) {\n-    return nullptr;\n-  }\n-\n+const Type* ModDNode::get_result_if_constant(const Type* dividend, const Type* divisor) const {\n@@ -1591,1 +1555,1 @@\n-  if ((t1->base() != Type::DoubleCon) || (t2->base() != Type::DoubleCon)) {\n+  if ((dividend->base() != Type::DoubleCon) || (divisor->base() != Type::DoubleCon)) {\n@@ -1595,4 +1559,4 @@\n-  double f1 = t1->getd();\n-  double f2 = t2->getd();\n-  jlong x1 = jlong_cast(f1); \/\/ note:  *(long*)&f1, not just (long)f1\n-  jlong x2 = jlong_cast(f2);\n+  double dividend_d = dividend->getd();\n+  double divisor_d = divisor->getd();\n+  jlong dividend_l = jlong_cast(dividend_d); \/\/ note:  *(long*)&f1, not just (long)f1\n+  jlong divisor_l = jlong_cast(divisor_d);\n@@ -1601,2 +1565,2 @@\n-  if (g_isnan(f1)) {\n-    return replace_with_con(igvn, t1);\n+  if (g_isnan(dividend_d)) {\n+    return dividend;\n@@ -1604,2 +1568,2 @@\n-  if (g_isnan(f2)) {\n-    return replace_with_con(igvn, t2);\n+  if (g_isnan(divisor_d)) {\n+    return divisor;\n@@ -1609,1 +1573,1 @@\n-  if (!g_isfinite(f1) || !g_isfinite(f2) || x2 == 0 || x2 == min_jlong) {\n+  if (!g_isfinite(dividend_d) || !g_isfinite(divisor_d) || divisor_l == 0 || divisor_l == min_jlong) {\n@@ -1615,2 +1579,2 @@\n-  jlong xr = jlong_cast(fmod(f1, f2));\n-  if ((x1 ^ xr) < 0) {\n+  jlong xr = jlong_cast(fmod(dividend_d, divisor_d));\n+  if ((dividend_l ^ xr) < 0) {\n@@ -1620,1 +1584,1 @@\n-  return replace_with_con(igvn, TypeD::make(jdouble_cast(xr)));\n+  return TypeD::make(jdouble_cast(xr));\n@@ -1623,22 +1587,14 @@\n-Node* ModFloatingNode::replace_with_con(PhaseIterGVN* phase, const Type* con) {\n-  Compile* C = phase->C;\n-  Node* con_node = phase->makecon(con);\n-  CallProjections projs;\n-  extract_projections(&projs, false, false);\n-  phase->replace_node(projs.fallthrough_proj, in(TypeFunc::Control));\n-  if (projs.fallthrough_catchproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_catchproj, in(TypeFunc::Control));\n-  }\n-  if (projs.fallthrough_memproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_memproj, in(TypeFunc::Memory));\n-  }\n-  if (projs.catchall_memproj != nullptr) {\n-    phase->replace_node(projs.catchall_memproj, C->top());\n-  }\n-  if (projs.fallthrough_ioproj != nullptr) {\n-    phase->replace_node(projs.fallthrough_ioproj, in(TypeFunc::I_O));\n-  }\n-  assert(projs.catchall_ioproj == nullptr, \"no exceptions from floating mod\");\n-  assert(projs.catchall_catchproj == nullptr, \"no exceptions from floating mod\");\n-  if (projs.resproj != nullptr) {\n-    phase->replace_node(projs.resproj, con_node);\n+Node* ModFloatingNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (can_reshape) {\n+    PhaseIterGVN* igvn = phase->is_IterGVN();\n+\n+    \/\/ Either input is TOP ==> the result is TOP\n+    const Type* dividend_type = phase->type(dividend());\n+    const Type* divisor_type = phase->type(divisor());\n+    if (dividend_type == Type::TOP || divisor_type == Type::TOP) {\n+      return phase->C->top();\n+    }\n+    const Type* constant_result = get_result_if_constant(dividend_type, divisor_type);\n+    if (constant_result != nullptr) {\n+      return make_tuple_of_input_state_and_constant_result(igvn, constant_result);\n+    }\n@@ -1646,4 +1602,20 @@\n-  phase->replace_node(this, C->top());\n-  C->remove_macro_node(this);\n-  disconnect_inputs(C);\n-  return nullptr;\n+\n+  return CallLeafPureNode::Ideal(phase, can_reshape);\n+}\n+\n+\/* Give a tuple node for ::Ideal to return, made of the input state (control to return addr)\n+ * and the given constant result. Idealization of projections will make sure to transparently\n+ * propagate the input state and replace the result by the said constant.\n+ *\/\n+TupleNode* ModFloatingNode::make_tuple_of_input_state_and_constant_result(PhaseIterGVN* phase, const Type* con) const {\n+  Node* con_node = phase->makecon(con);\n+  TupleNode* tuple = TupleNode::make(\n+      tf()->range(),\n+      in(TypeFunc::Control),\n+      in(TypeFunc::I_O),\n+      in(TypeFunc::Memory),\n+      in(TypeFunc::FramePtr),\n+      in(TypeFunc::ReturnAdr),\n+      con_node);\n+\n+  return tuple;\n","filename":"src\/hotspot\/share\/opto\/divnode.cpp","additions":65,"deletions":93,"binary":false,"changes":158,"status":"modified"},{"patch":"@@ -159,1 +159,3 @@\n-class ModFloatingNode : public CallLeafNode {\n+class ModFloatingNode : public CallLeafPureNode {\n+  TupleNode* make_tuple_of_input_state_and_constant_result(PhaseIterGVN* phase, const Type* con) const;\n+\n@@ -161,1 +163,3 @@\n-  Node* replace_with_con(PhaseIterGVN* phase, const Type* con);\n+  virtual Node* dividend() const = 0;\n+  virtual Node* divisor() const = 0;\n+  virtual const Type* get_result_if_constant(const Type* dividend, const Type* divisor) const = 0;\n@@ -164,1 +168,2 @@\n-  ModFloatingNode(Compile* C, const TypeFunc* tf, const char *name);\n+  ModFloatingNode(Compile* C, const TypeFunc* tf, address addr, const char* name);\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape) override;\n@@ -170,2 +175,3 @@\n-  Node* dividend() const { return in(TypeFunc::Parms + 0); }\n-  Node* divisor() const { return in(TypeFunc::Parms + 1); }\n+  Node* dividend() const override { return in(TypeFunc::Parms + 0); }\n+  Node* divisor() const override { return in(TypeFunc::Parms + 1); }\n+  const Type* get_result_if_constant(const Type* dividend, const Type* divisor) const override;\n@@ -175,4 +181,3 @@\n-  virtual int Opcode() const;\n-  virtual uint ideal_reg() const { return Op_RegF; }\n-  virtual uint size_of() const { return sizeof(*this); }\n-  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  int Opcode() const override;\n+  uint ideal_reg() const override { return Op_RegF; }\n+  uint size_of() const override { return sizeof(*this); }\n@@ -184,2 +189,3 @@\n-  Node* dividend() const { return in(TypeFunc::Parms + 0); }\n-  Node* divisor() const { return in(TypeFunc::Parms + 2); }\n+  Node* dividend() const override { return in(TypeFunc::Parms + 0); }\n+  Node* divisor() const override { return in(TypeFunc::Parms + 2); }\n+  const Type* get_result_if_constant(const Type* dividend, const Type* divisor) const override;\n@@ -189,4 +195,3 @@\n-  virtual int Opcode() const;\n-  virtual uint ideal_reg() const { return Op_RegD; }\n-  virtual uint size_of() const { return sizeof(*this); }\n-  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  int Opcode() const override;\n+  uint ideal_reg() const override { return Op_RegD; }\n+  uint size_of() const override { return sizeof(*this); }\n","filename":"src\/hotspot\/share\/opto\/divnode.hpp","additions":20,"deletions":15,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -1883,8 +1883,14 @@\n-  Node* memory = reset_memory();\n-  Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n-  call->init_req( TypeFunc::Control,   control()  );\n-  call->init_req( TypeFunc::I_O,       top()      ); \/\/ does no i\/o\n-  call->init_req( TypeFunc::Memory,    m          ); \/\/ may gc ptrs\n-  call->init_req( TypeFunc::FramePtr,  frameptr() );\n-  call->init_req( TypeFunc::ReturnAdr, top()      );\n-  return memory;\n+  call->init_req(TypeFunc::Control, control());\n+  call->init_req(TypeFunc::I_O, top()); \/\/ does no i\/o\n+  call->init_req(TypeFunc::ReturnAdr, top());\n+  if (call->is_CallLeafPure()) {\n+    call->init_req(TypeFunc::Memory, top());\n+    call->init_req(TypeFunc::FramePtr, top());\n+    return nullptr;\n+  } else {\n+    Node* memory = reset_memory();\n+    Node* m = narrow_mem == nullptr ? memory : narrow_mem;\n+    call->init_req(TypeFunc::Memory, m); \/\/ may gc ptrs\n+    call->init_req(TypeFunc::FramePtr, frameptr());\n+    return memory;\n+  }\n@@ -1908,0 +1914,5 @@\n+  if (call->is_CallLeafPure()) {\n+    \/\/ Pure function have only control (for now) and data output, in particular\n+    \/\/ they don't touch the memory, so we don't want a memory proj that is set after.\n+    return;\n+  }\n@@ -2494,0 +2505,2 @@\n+  } else if (flags & RC_PURE) {\n+    call = new CallLeafPureNode(call_type, call_addr, call_name, adr_type);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":21,"deletions":8,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -787,0 +787,1 @@\n+    RC_PURE = 128,              \/\/ CallLeaf is pure\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1800,1 +1800,1 @@\n-  Node* trig = make_runtime_call(RC_LEAF, call_type, funcAddr, funcName,\n+  Node* trig = make_runtime_call(RC_LEAF | RC_PURE, call_type, funcAddr, funcName,\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2600,1 +2600,0 @@\n-        bool is_drem = n->Opcode() == Op_ModD;\n@@ -2602,4 +2601,2 @@\n-        CallNode* call = new CallLeafNode(mod_macro->tf(),\n-                                          is_drem ? CAST_FROM_FN_PTR(address, SharedRuntime::drem)\n-                                                  : CAST_FROM_FN_PTR(address, SharedRuntime::frem),\n-                                          is_drem ? \"drem\" : \"frem\", TypeRawPtr::BOTTOM);\n+        CallNode* call = new CallLeafPureNode(mod_macro->tf(), mod_macro->entry_point(),\n+                                              mod_macro->_name, TypeRawPtr::BOTTOM);\n@@ -2607,4 +2604,4 @@\n-        call->init_req(TypeFunc::I_O, mod_macro->in(TypeFunc::I_O));\n-        call->init_req(TypeFunc::Memory, mod_macro->in(TypeFunc::Memory));\n-        call->init_req(TypeFunc::ReturnAdr, mod_macro->in(TypeFunc::ReturnAdr));\n-        call->init_req(TypeFunc::FramePtr, mod_macro->in(TypeFunc::FramePtr));\n+        call->init_req(TypeFunc::I_O, C->top());\n+        call->init_req(TypeFunc::Memory, C->top());\n+        call->init_req(TypeFunc::ReturnAdr, C->top());\n+        call->init_req(TypeFunc::FramePtr, C->top());\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -123,0 +123,4 @@\n+    if (ctrl->Opcode() == Op_Tuple) {\n+      \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+      ctrl = ctrl->in(_con);\n+    }\n@@ -166,0 +170,9 @@\n+\/\/------------------------------Identity---------------------------------------\n+Node* ProjNode::Identity(PhaseGVN* phase) {\n+  if (in(0) != nullptr && in(0)->Opcode() == Op_Tuple) {\n+    \/\/ Jumping over Tuples: the i-th projection of a Tuple is the i-th input of the Tuple.\n+    return in(0)->in(_con);\n+  }\n+  return this;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+  virtual Node* Identity(PhaseGVN* phase);\n@@ -108,0 +109,45 @@\n+\/* Tuples are used to avoid manual graph surgery. When a node with Proj outputs (such as a call)\n+ * must be removed and its ouputs replaced by its input, or some other value, we can make its\n+ * ::Ideal return a tuple of what we want for each output: the ::Identity of output Proj will\n+ * take care to jump over the Tuple and directly pick up the right input of the Tuple.\n+ *\n+ * For instance, if a function call is proven to have no side effect and return the constant 0,\n+ * we can replace it with the 6-tuple:\n+ * (control input, IO input, memory input, frame ptr input, return addr input, Con:0)\n+ * all the output projections will pick up the input of the now gone call, except for the result\n+ * projection that is replaced by 0.\n+ *\n+ * Using TupleNode avoid manual graph surgery and leave that to our expert surgeon: IGVN.\n+ * Since the user of a Tuple are expected to be Proj, when creating a tuple during idealization,\n+ * the output Proj should be enqueued for IGVN immediately after, and the tuple should not survive\n+ * after the current IGVN.\n+ *\/\n+class TupleNode : public MultiNode {\n+  const TypeTuple* _tf;\n+\n+  template <typename... NN>\n+  static void make_helper(TupleNode* tn, uint i, Node* node, NN... nn) {\n+    tn->set_req(i, node);\n+    make_helper(tn, i + 1, nn...);\n+  }\n+\n+  static void make_helper(TupleNode*, uint) {}\n+\n+public:\n+  TupleNode(const TypeTuple* tf) : MultiNode(tf->cnt()), _tf(tf) {}\n+\n+  int Opcode() const override;\n+  const Type* bottom_type() const override { return _tf; }\n+\n+  \/* Give as many `Node*` as you want in the `nn` pack:\n+   * TupleNode::make(tf, input1)\n+   * TupleNode::make(tf, input1, input2, input3, input4)\n+   *\/\n+  template <typename... NN>\n+  static TupleNode* make(const TypeTuple* tf, NN... nn) {\n+    TupleNode* tn = new TupleNode(tf);\n+    make_helper(tn, 0, nn...);\n+    return tn;\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/multnode.hpp","additions":46,"deletions":0,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2950,10 +2950,0 @@\n-bool Node::is_pure_function() const {\n-  switch (Opcode()) {\n-  case Op_ModD:\n-  case Op_ModF:\n-    return true;\n-  default:\n-    return false;\n-  }\n-}\n-\n@@ -2966,1 +2956,1 @@\n-  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_pure_function();\n+  return Opcode() == Op_Proj && as_Proj()->_con == TypeFunc::Parms && maybe_pure_function->is_CallLeafPure();\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+class CallLeafPureNode;\n@@ -676,0 +677,1 @@\n+              DEFINE_CLASS_ID(CallLeafPure,     CallLeaf, 1)\n@@ -910,0 +912,1 @@\n+  DEFINE_CLASS_QUERY(CallLeafPure)\n@@ -1292,2 +1295,0 @@\n-  bool is_pure_function() const;\n-\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1100,1 +1100,1 @@\n-  CallNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n+  CallLeafPureNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallLeafPureNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n@@ -1102,3 +1102,3 @@\n-  Node* prev_mem = set_predefined_input_for_runtime_call(mod);\n-  mod = _gvn.transform(mod)->as_Call();\n-  set_predefined_output_for_runtime_call(mod, prev_mem, TypeRawPtr::BOTTOM);\n+  set_predefined_input_for_runtime_call(mod);\n+  mod = _gvn.transform(mod)->as_CallLeafPure();\n+  set_predefined_output_for_runtime_call(mod);\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}