{"files":[{"patch":"@@ -416,1 +416,1 @@\n-instruct vaddI_vi(vReg dst, vReg src1, immI5 con) %{\n+instruct vadd_immI(vReg dst, vReg src1, immI5 con) %{\n@@ -420,1 +420,1 @@\n-  format %{ \"vaddI_vi $dst, $src1, $con\" %}\n+  format %{ \"vadd_immI $dst, $src1, $con\" %}\n@@ -431,1 +431,1 @@\n-instruct vaddL_vi(vReg dst, vReg src1, immL5 con) %{\n+instruct vadd_immL(vReg dst, vReg src1, immL5 con) %{\n@@ -433,1 +433,1 @@\n-  format %{ \"vaddL_vi $dst, $src1, $con\" %}\n+  format %{ \"vadd_immL $dst, $src1, $con\" %}\n@@ -445,1 +445,1 @@\n-instruct vaddI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vadd_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -449,1 +449,1 @@\n-  format %{ \"vaddI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vadd_regI $dst, $src1, $src2\" %}\n@@ -460,1 +460,1 @@\n-instruct vaddL_vx(vReg dst, vReg src1, iRegL src2) %{\n+instruct vadd_regL(vReg dst, vReg src1, iRegL src2) %{\n@@ -462,1 +462,1 @@\n-  format %{ \"vaddL_vx $dst, $src1, $src2\" %}\n+  format %{ \"vadd_regL $dst, $src1, $src2\" %}\n@@ -474,1 +474,1 @@\n-instruct vaddI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vadd_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -478,1 +478,1 @@\n-  format %{ \"vaddI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vadd_immI_masked $dst_src, $dst_src, $con\" %}\n@@ -489,1 +489,1 @@\n-instruct vaddL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vadd_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -491,1 +491,1 @@\n-  format %{ \"vaddL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vadd_immL_masked $dst_src, $dst_src, $con\" %}\n@@ -503,1 +503,1 @@\n-instruct vaddI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vadd_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -507,1 +507,1 @@\n-  format %{ \"vaddI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vadd_regI_masked $dst_src, $dst_src, $src2\" %}\n@@ -518,1 +518,1 @@\n-instruct vaddL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vadd_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -520,1 +520,1 @@\n-  format %{ \"vaddL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vadd_regL_masked $dst_src, $dst_src, $src2\" %}\n@@ -596,1 +596,1 @@\n-instruct vsubI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vsub_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -600,1 +600,1 @@\n-  format %{ \"vsubI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vsub_regI $dst, $src1, $src2\" %}\n@@ -611,1 +611,1 @@\n-instruct vsubL_vx(vReg dst, vReg src1, iRegL src2) %{\n+instruct vsub_regL(vReg dst, vReg src1, iRegL src2) %{\n@@ -613,1 +613,1 @@\n-  format %{ \"vsubL_vx $dst, $src1, $src2\" %}\n+  format %{ \"vsub_regL $dst, $src1, $src2\" %}\n@@ -625,1 +625,1 @@\n-instruct vsubI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vsub_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -629,1 +629,1 @@\n-  format %{ \"vsubI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vsub_regI_masked $dst_src, $dst_src, $src2\" %}\n@@ -640,1 +640,1 @@\n-instruct vsubL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vsub_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -642,1 +642,1 @@\n-  format %{ \"vsub_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vsub_regL_masked $dst_src, $dst_src, $src2\" %}\n@@ -686,1 +686,1 @@\n-instruct vandI_vi(vReg dst_src, immI5 con) %{\n+instruct vand_immI(vReg dst_src, immI5 con) %{\n@@ -691,1 +691,1 @@\n-  format %{ \"vandI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vand_immI $dst_src, $dst_src, $con\" %}\n@@ -702,1 +702,1 @@\n-instruct vandL_vi(vReg dst_src, immL5 con) %{\n+instruct vand_immL(vReg dst_src, immL5 con) %{\n@@ -705,1 +705,1 @@\n-  format %{ \"vandL_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vand_immL $dst_src, $dst_src, $con\" %}\n@@ -717,1 +717,1 @@\n-instruct vandI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vand_regI(vReg dst_src, iRegIorL2I src) %{\n@@ -722,1 +722,1 @@\n-  format %{ \"vandI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vand_regI $dst_src, $dst_src, $src\" %}\n@@ -733,1 +733,1 @@\n-instruct vandL_vx(vReg dst_src, iRegL src) %{\n+instruct vand_regL(vReg dst_src, iRegL src) %{\n@@ -736,1 +736,1 @@\n-  format %{ \"vandL_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vand_regL $dst_src, $dst_src, $src\" %}\n@@ -748,1 +748,1 @@\n-instruct vandI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vand_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -753,1 +753,1 @@\n-  format %{ \"vandI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vand_immI_masked $dst_src, $dst_src, $con\" %}\n@@ -764,1 +764,1 @@\n-instruct vandL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vand_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -767,1 +767,1 @@\n-  format %{ \"vandL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vand_immL_masked $dst_src, $dst_src, $con\" %}\n@@ -779,1 +779,1 @@\n-instruct vandI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vand_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -784,1 +784,1 @@\n-  format %{ \"vandI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vand_regI_masked $dst_src, $dst_src, $src\" %}\n@@ -795,1 +795,1 @@\n-instruct vandL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vand_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -798,1 +798,1 @@\n-  format %{ \"vandL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vand_regL_masked $dst_src, $dst_src, $src\" %}\n@@ -842,1 +842,1 @@\n-instruct vorI_vi(vReg dst_src, immI5 con) %{\n+instruct vor_immI(vReg dst_src, immI5 con) %{\n@@ -847,1 +847,1 @@\n-  format %{ \"vorI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vor_immI $dst_src, $dst_src, $con\" %}\n@@ -858,1 +858,1 @@\n-instruct vorL_vi(vReg dst_src, immL5 con) %{\n+instruct vor_immL(vReg dst_src, immL5 con) %{\n@@ -861,1 +861,1 @@\n-  format %{ \"vorL_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vor_immL $dst_src, $dst_src, $con\" %}\n@@ -873,1 +873,1 @@\n-instruct vorI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vor_regI(vReg dst_src, iRegIorL2I src) %{\n@@ -878,1 +878,1 @@\n-  format %{ \"vorI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vor_regI $dst_src, $dst_src, $src\" %}\n@@ -889,1 +889,1 @@\n-instruct vorL_vx(vReg dst_src, iRegL src) %{\n+instruct vor_regL(vReg dst_src, iRegL src) %{\n@@ -892,1 +892,1 @@\n-  format %{ \"vorL_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vor_regL $dst_src, $dst_src, $src\" %}\n@@ -904,1 +904,1 @@\n-instruct vorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -909,1 +909,1 @@\n-  format %{ \"vorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vor_immI_masked $dst_src, $dst_src, $con\" %}\n@@ -920,1 +920,1 @@\n-instruct vorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -923,1 +923,1 @@\n-  format %{ \"vorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vor_immL_masked $dst_src, $dst_src, $con\" %}\n@@ -935,1 +935,1 @@\n-instruct vorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -940,1 +940,1 @@\n-  format %{ \"vorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vor_regI_masked $dst_src, $dst_src, $src\" %}\n@@ -951,1 +951,1 @@\n-instruct vorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -954,1 +954,1 @@\n-  format %{ \"vorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vor_regL_masked $dst_src, $dst_src, $src\" %}\n@@ -998,1 +998,1 @@\n-instruct vxorI_vi(vReg dst_src, immI5 con) %{\n+instruct vxor_immI(vReg dst_src, immI5 con) %{\n@@ -1003,1 +1003,1 @@\n-  format %{ \"vxorI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxor_immI $dst_src, $dst_src, $con\" %}\n@@ -1014,1 +1014,1 @@\n-instruct vxorL_vi(vReg dst_src, immL5 con) %{\n+instruct vxor_immL(vReg dst_src, immL5 con) %{\n@@ -1017,1 +1017,1 @@\n-  format %{ \"vxorL_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxor_immL $dst_src, $dst_src, $con\" %}\n@@ -1029,1 +1029,1 @@\n-instruct vxorI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vxor_regI(vReg dst_src, iRegIorL2I src) %{\n@@ -1034,1 +1034,1 @@\n-  format %{ \"vxorI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxor_regI $dst_src, $dst_src, $src\" %}\n@@ -1045,1 +1045,1 @@\n-instruct vxorL_vx(vReg dst_src, iRegL src) %{\n+instruct vxor_regL(vReg dst_src, iRegL src) %{\n@@ -1048,1 +1048,1 @@\n-  format %{ \"vxorL_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxor_regL $dst_src, $dst_src, $src\" %}\n@@ -1060,1 +1060,1 @@\n-instruct vxorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vxor_immI_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -1065,1 +1065,1 @@\n-  format %{ \"vxorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vxor_immI_masked $dst_src, $dst_src, $con\" %}\n@@ -1076,1 +1076,1 @@\n-instruct vxorL_vi_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n+instruct vxor_immL_masked(vReg dst_src, immL5 con, vRegMask_V0 v0) %{\n@@ -1079,1 +1079,1 @@\n-  format %{ \"vxorL_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vxor_immL_masked $dst_src, $dst_src, $con\" %}\n@@ -1091,1 +1091,1 @@\n-instruct vxorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vxor_regI_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -1096,1 +1096,1 @@\n-  format %{ \"vxorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vxor_regI_masked $dst_src, $dst_src, $src\" %}\n@@ -1107,1 +1107,1 @@\n-instruct vxorL_vx_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n+instruct vxor_regL_masked(vReg dst_src, iRegL src, vRegMask_V0 v0) %{\n@@ -1110,1 +1110,1 @@\n-  format %{ \"vxorL_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vxor_regL_masked $dst_src, $dst_src, $src\" %}\n@@ -1802,1 +1802,1 @@\n-instruct vmulI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vmul_regI(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -1806,1 +1806,1 @@\n-  format %{ \"vmulI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vmul_regI $dst, $src1, $src2\" %}\n@@ -1817,1 +1817,1 @@\n-instruct vmulL_vx(vReg dst, vReg src1, iRegL src2) %{\n+instruct vmul_regL(vReg dst, vReg src1, iRegL src2) %{\n@@ -1819,1 +1819,1 @@\n-  format %{ \"vmulL_vx $dst, $src1, $src2\" %}\n+  format %{ \"vmul_regL $dst, $src1, $src2\" %}\n@@ -1831,1 +1831,1 @@\n-instruct vmulI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vmul_regI_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -1835,1 +1835,1 @@\n-  format %{ \"vmulI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vmul_regI_masked $dst_src, $dst_src, $src2\" %}\n@@ -1846,1 +1846,1 @@\n-instruct vmulL_vx_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n+instruct vmul_regL_masked(vReg dst_src, iRegL src2, vRegMask_V0 v0) %{\n@@ -1848,1 +1848,1 @@\n-  format %{ \"vmulL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vmul_regL_masked $dst_src, $dst_src, $src2\" %}\n@@ -3123,1 +3123,1 @@\n-instruct vasrB_vi(vReg dst, vReg src, immI shift) %{\n+instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n@@ -3126,1 +3126,1 @@\n-  format %{ \"vasrB_vi $dst, $src, $shift\" %}\n+  format %{ \"vasrB_imm $dst, $src, $shift\" %}\n@@ -3141,1 +3141,1 @@\n-instruct vasrS_vi(vReg dst, vReg src, immI shift) %{\n+instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n@@ -3144,1 +3144,1 @@\n-  format %{ \"vasrS_vi $dst, $src, $shift\" %}\n+  format %{ \"vasrS_imm $dst, $src, $shift\" %}\n@@ -3159,1 +3159,1 @@\n-instruct vasrI_vi(vReg dst, vReg src, immI shift) %{\n+instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n@@ -3162,1 +3162,1 @@\n-  format %{ \"vasrI_vi $dst, $src, $shift\" %}\n+  format %{ \"vasrI_imm $dst, $src, $shift\" %}\n@@ -3176,1 +3176,1 @@\n-instruct vasrL_vi(vReg dst, vReg src, immI shift) %{\n+instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n@@ -3180,1 +3180,1 @@\n-  format %{ \"vasrL_vi $dst, $src, $shift\" %}\n+  format %{ \"vasrL_imm $dst, $src, $shift\" %}\n@@ -3194,1 +3194,1 @@\n-instruct vasrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3197,1 +3197,1 @@\n-  format %{ \"vasrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3211,1 +3211,1 @@\n-instruct vasrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3214,1 +3214,1 @@\n-  format %{ \"vasrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3228,1 +3228,1 @@\n-instruct vasrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3231,1 +3231,1 @@\n-  format %{ \"vasrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3244,1 +3244,1 @@\n-instruct vasrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vasrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3248,1 +3248,1 @@\n-  format %{ \"vasrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vasrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3261,1 +3261,1 @@\n-instruct vlsrB_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n@@ -3264,1 +3264,1 @@\n-  format %{ \"vlsrB_vi $dst, $src, $shift\" %}\n+  format %{ \"vlsrB_imm $dst, $src, $shift\" %}\n@@ -3283,1 +3283,1 @@\n-instruct vlsrS_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n@@ -3286,1 +3286,1 @@\n-  format %{ \"vlsrS_vi $dst, $src, $shift\" %}\n+  format %{ \"vlsrS_imm $dst, $src, $shift\" %}\n@@ -3305,1 +3305,1 @@\n-instruct vlsrI_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n@@ -3308,1 +3308,1 @@\n-  format %{ \"vlsrI_vi $dst, $src, $shift\" %}\n+  format %{ \"vlsrI_imm $dst, $src, $shift\" %}\n@@ -3322,1 +3322,1 @@\n-instruct vlsrL_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n@@ -3326,1 +3326,1 @@\n-  format %{ \"vlsrL_vi $dst, $src, $shift\" %}\n+  format %{ \"vlsrL_imm $dst, $src, $shift\" %}\n@@ -3340,1 +3340,1 @@\n-instruct vlsrB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3343,1 +3343,1 @@\n-  format %{ \"vlsrB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3361,1 +3361,1 @@\n-instruct vlsrS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3364,1 +3364,1 @@\n-  format %{ \"vlsrS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3382,1 +3382,1 @@\n-instruct vlsrI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3385,1 +3385,1 @@\n-  format %{ \"vlsrI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3398,1 +3398,1 @@\n-instruct vlsrL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlsrL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3402,1 +3402,1 @@\n-  format %{ \"vlsrL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlsrL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3415,1 +3415,1 @@\n-instruct vlslB_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n@@ -3418,1 +3418,1 @@\n-  format %{ \"vlslB_vi $dst, $src, $shift\" %}\n+  format %{ \"vlslB_imm $dst, $src, $shift\" %}\n@@ -3432,1 +3432,1 @@\n-instruct vlslS_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n@@ -3435,1 +3435,1 @@\n-  format %{ \"vlslS_vi $dst, $src, $shift\" %}\n+  format %{ \"vlslS_imm $dst, $src, $shift\" %}\n@@ -3449,1 +3449,1 @@\n-instruct vlslI_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n@@ -3452,1 +3452,1 @@\n-  format %{ \"vlslI_vi $dst, $src, $shift\" %}\n+  format %{ \"vlslI_imm $dst, $src, $shift\" %}\n@@ -3461,1 +3461,1 @@\n-instruct vlslL_vi(vReg dst, vReg src, immI shift) %{\n+instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n@@ -3465,1 +3465,1 @@\n-  format %{ \"vlslL_vi $dst, $src, $shift\" %}\n+  format %{ \"vlslL_imm $dst, $src, $shift\" %}\n@@ -3474,1 +3474,1 @@\n-instruct vlslB_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslB_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3477,1 +3477,1 @@\n-  format %{ \"vlslB_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslB_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3492,1 +3492,1 @@\n-instruct vlslS_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslS_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3495,1 +3495,1 @@\n-  format %{ \"vlslS_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslS_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3510,1 +3510,1 @@\n-instruct vlslI_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslI_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3513,1 +3513,1 @@\n-  format %{ \"vlslI_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslI_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3523,1 +3523,1 @@\n-instruct vlslL_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vlslL_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3527,1 +3527,1 @@\n-  format %{ \"vlslL_vi_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  format %{ \"vlslL_imm_masked $dst_src, $dst_src, $shift, $v0\" %}\n@@ -3567,1 +3567,1 @@\n-instruct vrotate_right_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_right_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3569,1 +3569,1 @@\n-  format %{ \"vrotate_right_vx $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_reg $dst, $src, $shift\\t\" %}\n@@ -3579,1 +3579,1 @@\n-instruct vrotate_right_vi(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_right_imm(vReg dst, vReg src, immI shift) %{\n@@ -3581,1 +3581,1 @@\n-  format %{ \"vrotate_right_vi $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_right_imm $dst, $src, $shift\\t\" %}\n@@ -3599,1 +3599,1 @@\n-  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_right_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n@@ -3610,1 +3610,1 @@\n-instruct vrotate_right_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3612,1 +3612,1 @@\n-  format %{ \"vrotate_right_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_right_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n@@ -3622,1 +3622,1 @@\n-instruct vrotate_right_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_right_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3624,1 +3624,1 @@\n-  format %{ \"vrotate_right_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_right_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n@@ -3654,1 +3654,1 @@\n-instruct vrotate_left_vx(vReg dst, vReg src, iRegIorL2I shift) %{\n+instruct vrotate_left_reg(vReg dst, vReg src, iRegIorL2I shift) %{\n@@ -3656,1 +3656,1 @@\n-  format %{ \"vrotate_left_vx $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_reg $dst, $src, $shift\\t\" %}\n@@ -3666,1 +3666,1 @@\n-instruct vrotate_left_vi(vReg dst, vReg src, immI shift) %{\n+instruct vrotate_left_imm(vReg dst, vReg src, immI shift) %{\n@@ -3668,1 +3668,1 @@\n-  format %{ \"vrotate_left_vi $dst, $src, $shift\\t\" %}\n+  format %{ \"vrotate_left_imm $dst, $src, $shift\\t\" %}\n@@ -3687,1 +3687,1 @@\n-  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_left_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n@@ -3698,1 +3698,1 @@\n-instruct vrotate_left_vx_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_reg_masked(vReg dst_src, iRegIorL2I shift, vRegMask_V0 v0) %{\n@@ -3700,1 +3700,1 @@\n-  format %{ \"vrotate_left_vx_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_left_reg_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n@@ -3710,1 +3710,1 @@\n-instruct vrotate_left_vi_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n+instruct vrotate_left_imm_masked(vReg dst_src, immI shift, vRegMask_V0 v0) %{\n@@ -3712,1 +3712,1 @@\n-  format %{ \"vrotate_left_vi_masked $dst_src, $dst_src, $shift, $v0\\t\" %}\n+  format %{ \"vrotate_left_imm_masked $dst_src, $dst_src, $shift, v0.t\\t\" %}\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":146,"deletions":146,"binary":false,"changes":292,"status":"modified"}]}