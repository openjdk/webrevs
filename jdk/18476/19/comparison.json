{"files":[{"patch":"@@ -79,1 +79,2 @@\n-  0,  0,  0    \/\/ EVEX_NTUP\n+  1,   1,  1,  \/\/ EVEX_NOSCALE(0)\n+  0,  0,  0    \/\/ EVEX_ETUP\n@@ -297,5 +298,1 @@\n-  int enc = r->encoding();\n-  if (enc >= 8) {\n-    enc -= 8;\n-  }\n-  return enc;\n+  return r->encoding() & 7;\n@@ -441,0 +438,3 @@\n+    case EVEX_NOSCALE:\n+      break;\n+\n@@ -528,0 +528,3 @@\n+    case EVEX_NOSCALE:\n+      break;\n+\n@@ -549,0 +552,14 @@\n+bool Assembler::needs_rex2(Register reg1, Register reg2, Register reg3) {\n+  return (reg1->is_valid() && reg1->encoding() >= 16) ||\n+         (reg2->is_valid() && reg2->encoding() >= 16) ||\n+         (reg3->is_valid() && reg3->encoding() >= 16);\n+}\n+\n+bool Assembler::needs_eevex(Register reg1, Register reg2, Register reg3) {\n+  return needs_rex2(reg1, reg2, reg3);\n+}\n+\n+bool Assembler::needs_eevex(int enc1, int enc2, int enc3) {\n+  return enc1 >= 16 || enc2 >= 16 || enc3 >=16;\n+}\n+\n@@ -619,2 +636,1 @@\n-      if (disp == 0 && no_relocation &&\n-          base_enc != rbp->encoding() LP64_ONLY(&& base_enc != r13->encoding())) {\n+      if (disp == 0 && no_relocation && ((base_enc & 0x7) != 5)) {\n@@ -622,0 +638,1 @@\n+        \/\/ !(rbp | r13 | r21 | r29)\n@@ -638,1 +655,2 @@\n-    } else if (base_enc == rsp->encoding() LP64_ONLY(|| base_enc == r12->encoding())) {\n+    } else if ((base_enc & 0x7) == 4) {\n+      \/\/ rsp | r12 | r20 | r28\n@@ -660,3 +678,3 @@\n-      assert(base_enc != rsp->encoding() LP64_ONLY(&& base_enc != r12->encoding()), \"illegal addressing mode\");\n-      if (disp == 0 && no_relocation &&\n-          base_enc != rbp->encoding() LP64_ONLY(&& base_enc != r13->encoding())) {\n+      \/\/ !(rsp | r12 | r20 | r28) were handled above\n+      assert(((base_enc & 0x7) != 4), \"illegal addressing mode\");\n+      if (disp == 0 && no_relocation &&  ((base_enc & 0x7) != 5)) {\n@@ -664,0 +682,1 @@\n+        \/\/ !(rbp | r13 | r21 | r29)\n@@ -820,0 +839,7 @@\n+  case REX2:\n+    NOT_LP64(assert(false, \"64bit prefixes\"));\n+    if ((0xFF & *ip++) & REXBIT_W) {\n+      is_64bit = true;\n+    }\n+    goto again_after_prefix;\n+\n@@ -869,0 +895,8 @@\n+\n+    case REX2:\n+      NOT_LP64(assert(false, \"64bit prefix found\"));\n+      if ((0xFF & *ip++) & REXBIT_W) {\n+        is_64bit = true;\n+      }\n+      goto again_after_size_prefix2;\n+\n@@ -1158,0 +1192,1 @@\n+    case REX2:\n@@ -1284,0 +1319,27 @@\n+void Assembler::emit_opcode_prefix_and_encoding(int byte1, int byte2, int ocp_and_encoding, int byte3) {\n+  int opcode_prefix = (ocp_and_encoding & 0xFF00) >> 8;\n+  if (opcode_prefix != 0) {\n+    emit_int32(opcode_prefix, (unsigned char)byte1, byte2 | (ocp_and_encoding & 0xFF), byte3);\n+  } else {\n+    emit_int24((unsigned char)byte1, byte2 | (ocp_and_encoding & 0xFF), byte3);\n+  }\n+}\n+\n+void Assembler::emit_opcode_prefix_and_encoding(int byte1, int byte2, int ocp_and_encoding) {\n+  int opcode_prefix = (ocp_and_encoding & 0xFF00) >> 8;\n+  if (opcode_prefix != 0) {\n+    emit_int24(opcode_prefix, (unsigned char)byte1, byte2 | (ocp_and_encoding & 0xFF));\n+  } else {\n+    emit_int16((unsigned char)byte1, byte2 | (ocp_and_encoding & 0xFF));\n+  }\n+}\n+\n+void Assembler::emit_opcode_prefix_and_encoding(int byte1, int ocp_and_encoding) {\n+  int opcode_prefix = (ocp_and_encoding & 0xFF00) >> 8;\n+  if (opcode_prefix != 0) {\n+    emit_int16(opcode_prefix, (unsigned char)byte1 | (ocp_and_encoding & 0xFF));\n+  } else {\n+    emit_int8((unsigned char)byte1 | (ocp_and_encoding & 0xFF));\n+  }\n+}\n+\n@@ -1606,2 +1668,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -1613,0 +1676,1 @@\n+  assert((!needs_eevex(dst, src1) && needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -1614,1 +1678,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -1621,4 +1686,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F,\n-             (unsigned char)0xBC,\n-             0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBC, 0xC0, encode);\n@@ -1628,4 +1691,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F,\n-             (unsigned char)0xBD,\n-             0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBD, 0xC0, encode);\n@@ -1635,2 +1696,2 @@\n-  int encode = prefix_and_encode(reg->encoding());\n-  emit_int16(0x0F, (0xC8 | encode));\n+  int encode = prefix_and_encode(reg->encoding(), false, true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xC8, encode);\n@@ -1641,2 +1702,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rbx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rbx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -1648,0 +1710,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -1649,1 +1712,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -1657,2 +1721,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rdx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rdx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -1665,0 +1730,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -1666,1 +1732,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -1674,2 +1741,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rcx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rcx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -1681,0 +1749,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -1682,1 +1751,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -1746,4 +1816,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F,\n-             0x40 | cc,\n-             0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding(0x40 | cc, 0xC0, encode);\n@@ -1752,1 +1820,0 @@\n-\n@@ -1756,2 +1823,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (0x40 | cc));\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((0x40 | cc));\n@@ -1843,2 +1910,2 @@\n-  prefix(adr, reg);\n-  emit_int16(0x0F, (unsigned char)0xB1);\n+  prefix(adr, reg, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB1);\n@@ -1851,2 +1918,2 @@\n-  prefix(adr, reg);\n-  emit_int16(0x0F, (unsigned char)0xB1);\n+  prefix(adr, reg, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB1);\n@@ -1861,2 +1928,2 @@\n-  prefix(adr, reg, true);\n-  emit_int16(0x0F, (unsigned char)0xB0);\n+  prefix(adr, reg, true, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB0);\n@@ -1920,2 +1987,8 @@\n-  int8_t w = 0x01;\n-  Prefix p = Prefix_EMPTY;\n+  if (needs_eevex(crc, v)) {\n+    assert(UseAPX && UseAVX > 2, \"extended gpr use requires UseAPX and UseAVX > 2\");\n+    InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ sizeInBytes == 8, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+    int encode = vex_prefix_and_encode(crc->encoding(), 0, v->encoding(), sizeInBytes == 2 ? VEX_SIMD_66 : VEX_SIMD_NONE, VEX_OPCODE_0F_3C, &attributes, true);\n+    emit_int16(sizeInBytes == 1 ? (unsigned char)0xF0 : (unsigned char)0xF1, (0xC0 | encode));\n+  } else {\n+    int8_t w = 0x01;\n+    Prefix p = Prefix_EMPTY;\n@@ -1923,27 +1996,33 @@\n-  emit_int8((unsigned char)0xF2);\n-  switch (sizeInBytes) {\n-  case 1:\n-    w = 0;\n-    break;\n-  case 2:\n-  case 4:\n-    break;\n-  LP64_ONLY(case 8:)\n-    \/\/ This instruction is not valid in 32 bits\n-    \/\/ Note:\n-    \/\/ http:\/\/www.intel.com\/content\/dam\/www\/public\/us\/en\/documents\/manuals\/64-ia-32-architectures-software-developer-instruction-set-reference-manual-325383.pdf\n-    \/\/\n-    \/\/ Page B - 72   Vol. 2C says\n-    \/\/ qwreg2 to qwreg            1111 0010 : 0100 1R0B : 0000 1111 : 0011 1000 : 1111 0000 : 11 qwreg1 qwreg2\n-    \/\/ mem64 to qwreg             1111 0010 : 0100 1R0B : 0000 1111 : 0011 1000 : 1111 0000 : mod qwreg r \/ m\n-    \/\/                                                                            F0!!!\n-    \/\/ while 3 - 208 Vol. 2A\n-    \/\/ F2 REX.W 0F 38 F1 \/ r       CRC32 r64, r \/ m64             RM         Valid      N.E.Accumulate CRC32 on r \/ m64.\n-    \/\/\n-    \/\/ the 0 on a last bit is reserved for a different flavor of this instruction :\n-    \/\/ F2 REX.W 0F 38 F0 \/ r       CRC32 r64, r \/ m8              RM         Valid      N.E.Accumulate CRC32 on r \/ m8.\n-    p = REX_W;\n-    break;\n-  default:\n-    assert(0, \"Unsupported value for a sizeInBytes argument\");\n-    break;\n+    emit_int8((unsigned char)0xF2);\n+    switch (sizeInBytes) {\n+    case 1:\n+      w = 0;\n+      break;\n+    case 2:\n+    case 4:\n+      break;\n+    LP64_ONLY(case 8:)\n+      \/\/ This instruction is not valid in 32 bits\n+      \/\/ Note:\n+      \/\/ http:\/\/www.intel.com\/content\/dam\/www\/public\/us\/en\/documents\/manuals\/64-ia-32-architectures-software-developer-instruction-set-reference-manual-325383.pdf\n+      \/\/\n+      \/\/ Page B - 72   Vol. 2C says\n+      \/\/ qwreg2 to qwreg            1111 0010 : 0100 1R0B : 0000 1111 : 0011 1000 : 1111 0000 : 11 qwreg1 qwreg2\n+      \/\/ mem64 to qwreg             1111 0010 : 0100 1R0B : 0000 1111 : 0011 1000 : 1111 0000 : mod qwreg r \/ m\n+      \/\/                                                                            F0!!!\n+      \/\/ while 3 - 208 Vol. 2A\n+      \/\/ F2 REX.W 0F 38 F1 \/ r       CRC32 r64, r \/ m64             RM         Valid      N.E.Accumulate CRC32 on r \/ m64.\n+      \/\/\n+      \/\/ the 0 on a last bit is reserved for a different flavor of this instruction :\n+      \/\/ F2 REX.W 0F 38 F0 \/ r       CRC32 r64, r \/ m8              RM         Valid      N.E.Accumulate CRC32 on r \/ m8.\n+      p = REX_W;\n+      break;\n+    default:\n+      assert(0, \"Unsupported value for a sizeInBytes argument\");\n+      break;\n+    }\n+    LP64_ONLY(prefix(crc, v, p);)\n+    emit_int32(0x0F,\n+               0x38,\n+               0xF0 | w,\n+               0xC0 | ((crc->encoding() & 0x7) << 3) | (v->encoding() & 7));\n@@ -1951,5 +2030,0 @@\n-  LP64_ONLY(prefix(crc, v, p);)\n-  emit_int32(0x0F,\n-             0x38,\n-             0xF0 | w,\n-             0xC0 | ((crc->encoding() & 0x7) << 3) | (v->encoding() & 7));\n@@ -1961,2 +2035,10 @@\n-  int8_t w = 0x01;\n-  Prefix p = Prefix_EMPTY;\n+  if (needs_eevex(crc, adr.base(), adr.index())) {\n+    assert(UseAPX && UseAVX > 2, \"extended gpr use requires UseAPX and UseAVX > 2\");\n+    InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ sizeInBytes == 8, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+    attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n+    vex_prefix(adr, 0, crc->encoding(), sizeInBytes == 2 ? VEX_SIMD_66 : VEX_SIMD_NONE, VEX_OPCODE_0F_3C, &attributes);\n+    emit_int8(sizeInBytes == 1 ? (unsigned char)0xF0 : (unsigned char)0xF1);\n+    emit_operand(crc, adr, 0);\n+  } else {\n+    int8_t w = 0x01;\n+    Prefix p = Prefix_EMPTY;\n@@ -1964,15 +2046,19 @@\n-  emit_int8((uint8_t)0xF2);\n-  switch (sizeInBytes) {\n-  case 1:\n-    w = 0;\n-    break;\n-  case 2:\n-  case 4:\n-    break;\n-  LP64_ONLY(case 8:)\n-    \/\/ This instruction is not valid in 32 bits\n-    p = REX_W;\n-    break;\n-  default:\n-    assert(0, \"Unsupported value for a sizeInBytes argument\");\n-    break;\n+    emit_int8((uint8_t)0xF2);\n+    switch (sizeInBytes) {\n+    case 1:\n+      w = 0;\n+      break;\n+    case 2:\n+    case 4:\n+      break;\n+    LP64_ONLY(case 8:)\n+      \/\/ This instruction is not valid in 32 bits\n+      p = REX_W;\n+      break;\n+    default:\n+      assert(0, \"Unsupported value for a sizeInBytes argument\");\n+      break;\n+    }\n+    LP64_ONLY(prefix(crc, adr, p);)\n+    emit_int24(0x0F, 0x38, (0xF0 | w));\n+    emit_operand(crc, adr, 0);\n@@ -1980,3 +2066,0 @@\n-  LP64_ONLY(prefix(crc, adr, p);)\n-  emit_int24(0x0F, 0x38, (0xF0 | w));\n-  emit_operand(crc, adr, 0);\n@@ -2084,1 +2167,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes, true);\n@@ -2101,1 +2184,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F3, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F3, VEX_OPCODE_0F, &attributes, true);\n@@ -2118,1 +2201,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F3, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F3, VEX_OPCODE_0F, &attributes, true);\n@@ -2421,4 +2504,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F,\n-             (unsigned char)0xAF,\n-             (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xAF, 0xC0, encode);\n@@ -2453,2 +2534,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xAF);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xAF);\n@@ -2590,1 +2671,1 @@\n-  if (UseAVX > 0 ) {\n+  if (UseAVX > 0 && !UseAPX ) {\n@@ -2599,2 +2680,2 @@\n-    prefix(src);\n-    emit_int16(0x0F, (unsigned char)0xAE);\n+    prefix(src, true \/* is_map1 *\/);\n+    emit_int8((unsigned char)0xAE);\n@@ -2627,2 +2708,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBD, (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBD, 0xC0, encode);\n@@ -2635,2 +2716,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBD);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBD);\n@@ -2728,2 +2809,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -2735,1 +2816,1 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -2742,2 +2823,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F, &attributes);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F, &attributes, true);\n@@ -2749,1 +2830,1 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -2757,1 +2838,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -2766,1 +2848,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -2781,2 +2864,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes, true);\n@@ -2788,1 +2871,1 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -2803,1 +2886,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -2812,1 +2896,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -2820,2 +2905,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes, true);\n@@ -2827,1 +2912,1 @@\n-  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -3108,1 +3193,1 @@\n-  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -3116,1 +3201,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -3585,1 +3670,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -3592,1 +3677,1 @@\n-  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -3598,2 +3683,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBE);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBE);\n@@ -3605,2 +3690,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), false, src->encoding(), true);\n-  emit_int24(0x0F, (unsigned char)0xBE, (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), false, src->encoding(), true, true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBE, 0xC0, encode);\n@@ -3678,2 +3763,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBF);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBF);\n@@ -3684,2 +3769,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBF, (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBF, 0xC0, encode);\n@@ -3756,2 +3841,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xB6);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB6);\n@@ -3763,2 +3848,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), false, src->encoding(), true);\n-  emit_int24(0x0F, (unsigned char)0xB6, 0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), false, src->encoding(), true, true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB6, 0xC0, encode);\n@@ -3769,2 +3854,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xB7);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB7);\n@@ -3775,2 +3860,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xB7, 0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB7, 0xC0, encode);\n@@ -4419,0 +4504,1 @@\n+  assert(!needs_eevex(src.base(), src.index()), \"does not support extended gprs\");\n@@ -4746,1 +4832,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4764,1 +4850,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4800,1 +4886,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4818,1 +4904,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4836,1 +4922,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4843,1 +4929,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4861,1 +4947,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(),  nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4868,1 +4954,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -4886,1 +4972,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -4904,1 +4990,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -4911,1 +4997,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -5314,2 +5400,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xB8);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xB8);\n@@ -5322,2 +5408,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xB8, (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB8, 0xC0, encode);\n@@ -5395,2 +5481,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x18);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x18);\n@@ -5403,2 +5489,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x0D);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x0D);\n@@ -5411,2 +5497,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x18);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x18);\n@@ -5419,2 +5505,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x18);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x18);\n@@ -5427,2 +5513,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x18);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x18);\n@@ -5435,2 +5521,2 @@\n-  prefix(src);\n-  emit_int16(0x0F, 0x0D);\n+  prefix(src, true \/* is_map1 *\/);\n+  emit_int8(0x0D);\n@@ -5444,0 +5530,6 @@\n+void Assembler::prefix16(int prefix) {\n+  assert(UseAPX, \"APX features not enabled\");\n+  emit_int8((prefix & 0xff00) >> 8);\n+  emit_int8(prefix & 0xff);\n+}\n+\n@@ -5651,0 +5743,1 @@\n+  assert(!needs_eevex(src.base(), src.index()), \"does not support extended gprs\");\n@@ -5668,0 +5761,1 @@\n+  assert(!needs_eevex(src.base(), src.index()), \"does not support extended gprs\");\n@@ -6081,2 +6175,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), true);\n-  emit_int24(0x0F, (unsigned char)0x90 | cc, (0xC0 | encode));\n+  int encode = prefix_and_encode(dst->encoding(), true, true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0x90 | cc, 0xC0, encode);\n@@ -6215,2 +6309,2 @@\n-  int encode = prefix_and_encode(src->encoding(), dst->encoding());\n-  emit_int24(0x0F, (unsigned char)0xA5, (0xC0 | encode));\n+  int encode = prefix_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xA5, 0xC0, encode);\n@@ -6220,2 +6314,2 @@\n-  int encode = prefix_and_encode(src->encoding(), dst->encoding());\n-  emit_int32(0x0F, (unsigned char)0xA4, (0xC0 | encode), imm8);\n+  int encode = prefix_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xA4, 0xC0, encode, imm8);\n@@ -6225,2 +6319,2 @@\n-  int encode = prefix_and_encode(src->encoding(), dst->encoding());\n-  emit_int24(0x0F, (unsigned char)0xAD, (0xC0 | encode));\n+  int encode = prefix_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xAD, 0xC0, encode);\n@@ -6230,2 +6324,2 @@\n-  int encode = prefix_and_encode(src->encoding(), dst->encoding());\n-  emit_int32(0x0F, (unsigned char)0xAC, (0xC0 | encode), imm8);\n+  int encode = prefix_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xAC, 0xC0, encode, imm8);\n@@ -6236,2 +6330,2 @@\n-  int encode = prefixq_and_encode(src->encoding(), dst->encoding());\n-  emit_int32(0x0F, (unsigned char)0xA4, (0xC0 | encode), imm8);\n+  int encode = prefixq_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xA4, 0xC0, encode, imm8);\n@@ -6241,2 +6335,2 @@\n-  int encode = prefixq_and_encode(src->encoding(), dst->encoding());\n-  emit_int32(0x0F, (unsigned char)0xAC, (0xC0 | encode), imm8);\n+  int encode = prefixq_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xAC, 0xC0, encode, imm8);\n@@ -6308,2 +6402,2 @@\n-void Assembler::stmxcsr( Address dst) {\n-  if (UseAVX > 0 ) {\n+void Assembler::stmxcsr(Address dst) {\n+  if (UseAVX > 0 && !UseAPX  ) {\n@@ -6319,2 +6413,2 @@\n-    prefix(dst);\n-    emit_int16(0x0F, (unsigned char)0xAE);\n+    prefix(dst, true \/* is_map1 *\/);\n+    emit_int8((unsigned char)0xAE);\n@@ -6460,4 +6554,2 @@\n-  int encode = prefix_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F,\n-             (unsigned char)0xBC,\n-             0xC0 | encode);\n+  int encode = prefix_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBC, 0xC0, encode);\n@@ -6470,2 +6562,2 @@\n-  prefix(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBC);\n+  prefix(src, dst, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBC);\n@@ -6478,2 +6570,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBC, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBC, 0xC0, encode);\n@@ -6486,2 +6578,2 @@\n-  prefixq(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBC);\n+  prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBC);\n@@ -6533,2 +6625,2 @@\n-  prefix(dst, src, true);\n-  emit_int16(0x0F, (unsigned char)0xC0);\n+  prefix(dst, src, true, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xC0);\n@@ -6541,2 +6633,2 @@\n-  prefix(dst, src);\n-  emit_int16(0x0F, (unsigned char)0xC1);\n+  prefix(dst, src, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xC1);\n@@ -6548,2 +6640,2 @@\n-  prefix(dst, src);\n-  emit_int16(0x0F, (unsigned char)0xC1);\n+  prefix(dst, src, false, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xC1);\n@@ -9119,1 +9211,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -10889,1 +10981,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes, true);\n@@ -10898,1 +10990,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes , true);\n@@ -10907,1 +10999,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes, true);\n@@ -10916,1 +11008,1 @@\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes, true);\n@@ -11676,1 +11768,2 @@\n-void Assembler::evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v, int nds_enc, VexSimdPrefix pre, VexOpcode opc){\n+void Assembler::evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool eevex_b, bool evex_v,\n+                       bool eevex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc) {\n@@ -11685,1 +11778,1 @@\n-  \/\/ P0: byte 2, initialized to RXBR`00mm\n+  \/\/ P0: byte 2, initialized to RXBR'0mmm\n@@ -11689,0 +11782,1 @@\n+  byte2 |= eevex_b ? EEVEX_B : 0;\n@@ -11690,1 +11784,1 @@\n-  \/\/ of form {0F, 0F_38, 0F_3A}\n+  \/\/ of form {0F, 0F_38, 0F_3A, 0F_3C}\n@@ -11695,2 +11789,1 @@\n-  \/\/ p[10] is always 1\n-  byte3 |= EVEX_F;\n+  byte3 |= (eevex_x ? 0 : EEVEX_X);\n@@ -11723,0 +11816,4 @@\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    assert(UseAPX, \"APX features not enabled\");\n+  }\n+  bool is_extended = adr.base_needs_rex2() || adr.index_needs_rex2() || nds_enc >= 16 || xreg_enc >= 16;\n@@ -11732,1 +11829,0 @@\n-\n@@ -11738,1 +11834,1 @@\n-      if ((attributes->get_vector_len() != AVX_512bit) && (nds_enc < 16) && (xreg_enc < 16)) {\n+      if ((attributes->get_vector_len() != AVX_512bit) && !is_extended) {\n@@ -11749,1 +11845,1 @@\n-    assert(((nds_enc < 16 && xreg_enc < 16) || (!attributes->is_legacy_mode())),\"XMM register should be 0-15\");\n+    assert((!is_extended || (!attributes->is_legacy_mode())),\"XMM register should be 0-15\");\n@@ -11763,0 +11859,2 @@\n+    bool eevex_x = adr.index_needs_rex2();\n+    bool eevex_b = adr.base_needs_rex2();\n@@ -11764,1 +11862,1 @@\n-    evex_prefix(vex_r, vex_b, vex_x, evex_r, evex_v, nds_enc, pre, opc);\n+    evex_prefix(vex_r, vex_b, vex_x, evex_r, eevex_b, evex_v, eevex_x, nds_enc, pre, opc);\n@@ -11773,1 +11871,5 @@\n-int Assembler::vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc, VexSimdPrefix pre, VexOpcode opc, InstructionAttr *attributes) {\n+int Assembler::vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc, VexSimdPrefix pre, VexOpcode opc, InstructionAttr *attributes, bool src_is_gpr) {\n+  if (src_is_gpr && src_enc >= 16) {\n+    assert(UseAPX, \"APX features not enabled\");\n+  }\n+  bool is_extended = dst_enc >= 16 || nds_enc >= 16 || src_enc >=16;\n@@ -11785,1 +11887,1 @@\n-          (dst_enc < 16) && (nds_enc < 16) && (src_enc < 16)) {\n+           !is_extended) {\n@@ -11802,1 +11904,1 @@\n-    assert(((dst_enc < 16 && nds_enc < 16 && src_enc < 16) || (!attributes->is_legacy_mode())),\"XMM register should be 0-15\");\n+    assert(((!is_extended) || (!attributes->is_legacy_mode())),\"XMM register should be 0-15\");\n@@ -11810,0 +11912,1 @@\n+    bool evex_b = (src_enc >= 16) && src_is_gpr;\n@@ -11811,1 +11914,1 @@\n-    vex_x = (src_enc >= 16);\n+    vex_x = (src_enc >= 16) && !src_is_gpr;\n@@ -11813,1 +11916,1 @@\n-    evex_prefix(vex_r, vex_b, vex_x, evex_r, evex_v, nds_enc, pre, opc);\n+    evex_prefix(vex_r, vex_b, vex_x, evex_r, evex_b, evex_v, false \/*eevex_x*\/, nds_enc, pre, opc);\n@@ -11825,1 +11928,0 @@\n-\n@@ -11839,1 +11941,1 @@\n-                                      VexOpcode opc, InstructionAttr *attributes) {\n+                                      VexOpcode opc, InstructionAttr *attributes, bool src_is_gpr) {\n@@ -11844,1 +11946,1 @@\n-    return vex_prefix_and_encode(dst_enc, nds_enc, src_enc, pre, opc, attributes);\n+    return vex_prefix_and_encode(dst_enc, nds_enc, src_enc, pre, opc, attributes, src_is_gpr);\n@@ -12339,2 +12441,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12346,2 +12449,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12353,2 +12456,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12360,2 +12464,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12367,2 +12472,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12374,2 +12480,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12381,0 +12488,1 @@\n+  assert((!needs_eevex(dst, src1) && !needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12382,1 +12490,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -12390,0 +12499,1 @@\n+  assert((!needs_eevex(dst, src1) && !needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12391,1 +12501,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -12399,0 +12510,1 @@\n+  assert((!needs_eevex(dst, src1) && !needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12400,1 +12512,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -12408,0 +12521,1 @@\n+  assert((!needs_eevex(dst, src1) && !needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12409,1 +12523,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -12417,2 +12532,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12424,0 +12540,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12425,1 +12542,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -12433,2 +12551,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12440,0 +12559,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12441,1 +12561,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -12449,2 +12570,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12456,0 +12578,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12457,1 +12580,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -12465,2 +12589,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12472,0 +12597,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12473,1 +12599,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -12481,2 +12608,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12488,0 +12616,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12489,1 +12618,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -12497,2 +12627,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes, true);\n@@ -12504,0 +12635,1 @@\n+  assert((!needs_eevex(dst, src1.base(), src1.index()) && !needs_eevex(src2)) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -12505,1 +12637,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -12809,0 +12942,29 @@\n+int Assembler::get_base_prefix_bits(int enc) {\n+  int bits = 0;\n+  if (enc & 16) bits |= REX2BIT_B4;\n+  if (enc & 8) bits |= REXBIT_B;\n+  return bits;\n+}\n+\n+int Assembler::get_index_prefix_bits(int enc) {\n+  int bits = 0;\n+  if (enc & 16) bits |= REX2BIT_X4;\n+  if (enc & 8) bits |= REXBIT_X;\n+  return bits;\n+}\n+\n+int Assembler::get_base_prefix_bits(Register base) {\n+  return base->is_valid() ? get_base_prefix_bits(base->encoding()) : 0;\n+}\n+\n+int Assembler::get_index_prefix_bits(Register index) {\n+  return index->is_valid() ? get_index_prefix_bits(index->encoding()) : 0;\n+}\n+\n+int Assembler::get_reg_prefix_bits(int enc) {\n+  int bits = 0;\n+  if (enc & 16) bits |= REX2BIT_R4;\n+  if (enc & 8) bits |= REXBIT_R;\n+  return bits;\n+}\n+\n@@ -12810,1 +12972,3 @@\n-  if (reg->encoding() >= 8) {\n+  if (reg->encoding() >= 16) {\n+    prefix16(WREX2 | get_base_prefix_bits(reg->encoding()));\n+  } else if (reg->encoding() >= 8) {\n@@ -12816,0 +12980,4 @@\n+  if ((p & WREX2) || src->encoding() >= 16 || dst->encoding() >= 16) {\n+    prefix_rex2(dst, src);\n+    return;\n+  }\n@@ -12828,0 +12996,7 @@\n+void Assembler::prefix_rex2(Register dst, Register src) {\n+  int bits = 0;\n+  bits |= get_base_prefix_bits(src->encoding());\n+  bits |= get_reg_prefix_bits(dst->encoding());\n+  prefix16(WREX2 | bits);\n+}\n+\n@@ -12829,0 +13004,3 @@\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2() || dst->encoding() >= 16) {\n+    prefix_rex2(dst, adr);\n+  }\n@@ -12849,1 +13027,13 @@\n-void Assembler::prefix(Address adr) {\n+void Assembler::prefix_rex2(Register dst, Address adr) {\n+  assert(!adr.index_needs_rex2(), \"prefix(Register dst, Address adr) does not support handling of an X\");\n+  int bits = 0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_reg_prefix_bits(dst->encoding());\n+  prefix16(WREX2 | bits);\n+}\n+\n+void Assembler::prefix(Address adr, bool is_map1) {\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    prefix_rex2(adr, is_map1);\n+    return;\n+  }\n@@ -12861,0 +13051,8 @@\n+  if (is_map1) emit_int8(0x0F);\n+}\n+\n+void Assembler::prefix_rex2(Address adr, bool is_map1) {\n+  int bits = is_map1 ? REX2BIT_M0 : 0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  prefix16(WREX2 | bits);\n@@ -12863,1 +13061,5 @@\n-void Assembler::prefix(Address adr, Register reg, bool byteinst) {\n+void Assembler::prefix(Address adr, Register reg, bool byteinst, bool is_map1) {\n+  if (reg->encoding() >= 16 || adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    prefix_rex2(adr, reg, byteinst, is_map1);\n+    return;\n+  }\n@@ -12893,0 +13095,9 @@\n+  if (is_map1) emit_int8(0x0F);\n+}\n+\n+void Assembler::prefix_rex2(Address adr, Register reg, bool byteinst, bool is_map1) {\n+  int bits = is_map1 ? REX2BIT_M0 : 0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  bits |= get_reg_prefix_bits(reg->encoding());\n+  prefix16(WREX2 | bits);\n@@ -12896,0 +13107,4 @@\n+  if (reg->encoding() >= 16 || adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    prefixq_rex2(adr, reg);\n+    return;\n+  }\n@@ -12925,1 +13140,12 @@\n-int Assembler::prefix_and_encode(int reg_enc, bool byteinst) {\n+void Assembler::prefix_rex2(Address adr, XMMRegister src) {\n+  int bits = 0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  bits |= get_reg_prefix_bits(src->encoding());\n+  prefix16(WREX2 | bits);\n+}\n+\n+int Assembler::prefix_and_encode(int reg_enc, bool byteinst, bool is_map1) {\n+  if (reg_enc >= 16) {\n+    return prefix_and_encode_rex2(reg_enc, is_map1);\n+  }\n@@ -12932,1 +13158,2 @@\n-  return reg_enc;\n+  int opc_prefix = is_map1 ? 0x0F00 : 0;\n+  return opc_prefix | reg_enc;\n@@ -12935,1 +13162,9 @@\n-int Assembler::prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte) {\n+int Assembler::prefix_and_encode_rex2(int reg_enc, bool is_map1) {\n+  prefix16(WREX2 | (is_map1 ? REX2BIT_M0 : 0) | get_base_prefix_bits(reg_enc));\n+  return reg_enc & 0x7;\n+}\n+\n+int Assembler::prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte, bool is_map1) {\n+  if (src_enc >= 16 || dst_enc >= 16) {\n+    return prefix_and_encode_rex2(dst_enc, src_enc, is_map1 ? REX2BIT_M0 : 0);\n+  }\n@@ -12952,0 +13187,11 @@\n+  int opcode_prefix = is_map1 ? 0x0F00 : 0;\n+  return opcode_prefix | (dst_enc << 3 | src_enc);\n+}\n+\n+int Assembler::prefix_and_encode_rex2(int dst_enc, int src_enc, int init_bits) {\n+  int bits = init_bits;\n+  bits |= get_reg_prefix_bits(dst_enc);\n+  bits |= get_base_prefix_bits(src_enc);\n+  dst_enc &= 0x7;\n+  src_enc &= 0x7;\n+  prefix16(WREX2 | bits);\n@@ -12955,1 +13201,8 @@\n-int8_t Assembler::get_prefixq(Address adr) {\n+bool Assembler::prefix_is_rex2(int prefix) {\n+  return (prefix & 0xFF00) == WREX2;\n+}\n+\n+int Assembler::get_prefixq(Address adr, bool is_map1) {\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    return get_prefixq_rex2(adr, is_map1);\n+  }\n@@ -12958,1 +13211,10 @@\n-  return prfx;\n+  return is_map1 ? (((int16_t)prfx) << 8) | 0x0F : (int16_t)prfx;\n+}\n+\n+int Assembler::get_prefixq_rex2(Address adr, bool is_map1) {\n+  assert(UseAPX, \"APX features not enabled\");\n+  int bits = REXBIT_W;\n+  if (is_map1) bits |= REX2BIT_M0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  return WREX2 | bits;\n@@ -12961,1 +13223,4 @@\n-int8_t Assembler::get_prefixq(Address adr, Register src) {\n+int Assembler::get_prefixq(Address adr, Register src, bool is_map1) {\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2() || src->encoding() >= 16) {\n+    return get_prefixq_rex2(adr, src, is_map1);\n+  }\n@@ -12997,1 +13262,11 @@\n-  return prfx;\n+  return is_map1 ? (((int16_t)prfx) << 8) | 0x0F : (int16_t)prfx;\n+}\n+\n+int Assembler::get_prefixq_rex2(Address adr, Register src, bool is_map1) {\n+  assert(UseAPX, \"APX features not enabled\");\n+  int bits = REXBIT_W;\n+  if (is_map1) bits |= REX2BIT_M0;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  bits |= get_reg_prefix_bits(src->encoding());\n+  return WREX2 | bits;\n@@ -13001,1 +13276,5 @@\n-  emit_int8(get_prefixq(adr));\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    prefix16(get_prefixq_rex2(adr));\n+  } else {\n+    emit_int8(get_prefixq(adr));\n+  }\n@@ -13004,2 +13283,7 @@\n-void Assembler::prefixq(Address adr, Register src) {\n-  emit_int8(get_prefixq(adr, src));\n+void Assembler::prefixq(Address adr, Register src, bool is_map1) {\n+  if (adr.base_needs_rex2() || adr.index_needs_rex2() || src->encoding() >= 16) {\n+    prefix16(get_prefixq_rex2(adr, src, is_map1));\n+  } else {\n+    emit_int8(get_prefixq(adr, src));\n+    if (is_map1) emit_int8(0x0F);\n+  }\n@@ -13008,0 +13292,1 @@\n+\n@@ -13009,0 +13294,4 @@\n+  if (src->encoding() >= 16 || adr.base_needs_rex2() || adr.index_needs_rex2()) {\n+    prefixq_rex2(adr, src);\n+    return;\n+  }\n@@ -13040,1 +13329,12 @@\n-int Assembler::prefixq_and_encode(int reg_enc) {\n+void Assembler::prefixq_rex2(Address adr, XMMRegister src) {\n+  int bits = REXBIT_W;\n+  bits |= get_base_prefix_bits(adr.base());\n+  bits |= get_index_prefix_bits(adr.index());\n+  bits |= get_reg_prefix_bits(src->encoding());\n+  prefix16(WREX2 | bits);\n+}\n+\n+int Assembler::prefixq_and_encode(int reg_enc, bool is_map1) {\n+  if (reg_enc >= 16) {\n+    return prefixq_and_encode_rex2(reg_enc, is_map1);\n+  }\n@@ -13047,1 +13347,2 @@\n-  return reg_enc;\n+  int opcode_prefix = is_map1 ? 0x0F00 : 0;\n+  return opcode_prefix | reg_enc;\n@@ -13050,1 +13351,10 @@\n-int Assembler::prefixq_and_encode(int dst_enc, int src_enc) {\n+\n+int Assembler::prefixq_and_encode_rex2(int reg_enc, bool is_map1) {\n+  prefix16(WREX2 | REXBIT_W | (is_map1 ? REX2BIT_M0: 0) | get_base_prefix_bits(reg_enc));\n+  return reg_enc & 0x7;\n+}\n+\n+int Assembler::prefixq_and_encode(int dst_enc, int src_enc, bool is_map1) {\n+  if (dst_enc >= 16 || src_enc >= 16) {\n+    return prefixq_and_encode_rex2(dst_enc, src_enc, is_map1);\n+  }\n@@ -13067,1 +13377,16 @@\n-  return dst_enc << 3 | src_enc;\n+  int opcode_prefix = is_map1 ? 0x0F00 : 0;\n+  return opcode_prefix | (dst_enc << 3 | src_enc);\n+}\n+\n+int Assembler::prefixq_and_encode_rex2(int dst_enc, int src_enc, bool is_map1) {\n+  int init_bits = REXBIT_W | (is_map1 ? REX2BIT_M0 : 0);\n+  return prefix_and_encode_rex2(dst_enc, src_enc, init_bits);\n+}\n+\n+void Assembler::emit_prefix_and_int8(int prefix, int b1) {\n+  if ((prefix & 0xFF00) == 0) {\n+    emit_int16(prefix, b1);\n+  } else {\n+    assert((prefix & 0xFF00) != WREX2 || UseAPX, \"APX features not enabled\");\n+    emit_int24((prefix & 0xFF00) >> 8, prefix & 0x00FF, b1);\n+  }\n@@ -13077,1 +13402,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x13);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x13);\n@@ -13094,1 +13419,1 @@\n-  emit_int16(get_prefixq(dst, src), 0x01);\n+  emit_prefix_and_int8(get_prefixq(dst, src), 0x01);\n@@ -13105,1 +13430,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x03);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x03);\n@@ -13116,6 +13441,13 @@\n-  emit_int8(0x66);\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int32(0x0F,\n-             0x38,\n-             (unsigned char)0xF6,\n-             (0xC0 | encode));\n+  if (needs_rex2(dst, src)) {\n+    assert(UseAPX && UseAVX > 2, \"extended gpr use requires UseAPX and UseAVX > 2\");\n+    InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+    int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3C, &attributes, true);\n+    emit_int16((unsigned char)0x66, (0xC0 | encode));\n+  } else {\n+    emit_int8(0x66);\n+    int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n+    emit_int32(0x0F,\n+               0x38,\n+               (unsigned char)0xF6,\n+               (0xC0 | encode));\n+  }\n@@ -13126,6 +13458,13 @@\n-  emit_int8((unsigned char)0xF3);\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int32(0x0F,\n-             0x38,\n-             (unsigned char)0xF6,\n-             (0xC0 | encode));\n+  if (needs_rex2(dst, src)) {\n+    assert(UseAPX && UseAVX > 2, \"extended gpr use requires UseAPX and UseAVX > 2\");\n+    InstructionAttr attributes(AVX_128bit, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+    int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_3C, &attributes, true);\n+    emit_int16((unsigned char)0x66, (0xC0 | encode));\n+  } else {\n+    emit_int8((unsigned char)0xF3);\n+    int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n+    emit_int32(0x0F,\n+               0x38,\n+               (unsigned char)0xF6,\n+               (0xC0 | encode));\n+  }\n@@ -13133,1 +13472,0 @@\n-\n@@ -13147,1 +13485,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x23);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x23);\n@@ -13158,1 +13496,1 @@\n-  emit_int16(get_prefixq(dst, src), 0x21);\n+  emit_prefix_and_int8(get_prefixq(dst, src), 0x21);\n@@ -13164,2 +13502,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src1, src2) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -13171,0 +13510,1 @@\n+  assert((!needs_eevex(dst, src1) && needs_eevex(src2.base(), src2.index())) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -13172,1 +13512,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -13179,2 +13520,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBC, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBC, 0xC0, encode);\n@@ -13184,2 +13525,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBD, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBD, 0xC0, encode);\n@@ -13189,2 +13530,2 @@\n-  int encode = prefixq_and_encode(reg->encoding());\n-  emit_int16(0x0F, (0xC8 | encode));\n+  int encode = prefixq_and_encode(reg->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xC8, encode);\n@@ -13195,2 +13536,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rbx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rbx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -13202,0 +13544,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -13203,1 +13546,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -13211,2 +13555,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rdx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rdx->encoding(),  dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -13218,0 +13563,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -13219,1 +13565,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -13227,2 +13574,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(rcx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(rcx->encoding(), dst->encoding(), src->encoding(), VEX_SIMD_NONE, VEX_OPCODE_0F_38, &attributes, true);\n@@ -13234,0 +13582,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -13235,1 +13584,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -13251,2 +13601,2 @@\n-  prefix(adr);\n-  emit_int16(0x0F, (unsigned char)0xAE);\n+  prefix(adr, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xAE);\n@@ -13264,1 +13614,1 @@\n-  prefix(adr);\n+  prefix(adr, true \/* is_map1 *\/);\n@@ -13266,1 +13616,1 @@\n-  emit_int16(0x0F, (unsigned char)0xAE);\n+  emit_int8((unsigned char)0xAE);\n@@ -13279,1 +13629,1 @@\n-  prefix(adr);\n+  prefix(adr, true \/* is_map1 *\/);\n@@ -13281,1 +13631,1 @@\n-  emit_int16(0x0F, (unsigned char)0xAE);\n+  emit_int8((unsigned char)0xAE);\n@@ -13287,2 +13637,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (0x40 | cc), (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((0x40 | cc), 0xC0, encode);\n@@ -13293,1 +13643,2 @@\n-  emit_int24(get_prefixq(src, dst), 0x0F, (0x40 | cc));\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (0x40 | cc));\n@@ -13310,1 +13661,1 @@\n-  emit_int16(get_prefixq(dst, src), 0x39);\n+  emit_prefix_and_int8(get_prefixq(dst, src), 0x39);\n@@ -13321,1 +13672,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x3B);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x3B);\n@@ -13327,1 +13678,2 @@\n-  emit_int24(get_prefixq(adr, reg), 0x0F, (unsigned char)0xB1);\n+  int prefix = get_prefixq(adr, reg, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xB1);\n@@ -13334,1 +13686,1 @@\n-  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, dst, as_XMMRegister(src->encoding()), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes, true);\n@@ -13363,1 +13715,3 @@\n-  emit_int32((unsigned char)0xF2, REX_W, 0x0F, 0x2C);\n+  emit_int8((unsigned char)0xF2);\n+  prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0x2C);\n@@ -13405,1 +13759,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xFF);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xFF);\n@@ -13409,0 +13763,1 @@\n+\/\/ can't use REX2\n@@ -13415,0 +13770,1 @@\n+\/\/ can't use REX2\n@@ -13421,0 +13777,1 @@\n+\/\/ can't use REX2\n@@ -13427,0 +13784,1 @@\n+\/\/ cant use REX2\n@@ -13444,2 +13802,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xAF, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xAF, 0xC0, encode);\n@@ -13479,1 +13837,2 @@\n-  emit_int24(get_prefixq(src, dst), 0x0F, (unsigned char)0xAF);\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xAF);\n@@ -13500,1 +13859,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xFF);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xFF);\n@@ -13510,1 +13869,1 @@\n-  emit_int16(get_prefixq(src, dst), (unsigned char)0x8D);\n+  emit_prefix_and_int8(get_prefixq(src, dst), (unsigned char)0x8D);\n@@ -13568,2 +13927,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBD, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBD, 0xC0, encode);\n@@ -13576,2 +13935,2 @@\n-  prefixq(src, dst);\n-  emit_int16(0x0F, (unsigned char)0xBD);\n+  prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_int8((unsigned char)0xBD);\n@@ -13585,1 +13944,1 @@\n-  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(dst, xnoreg, as_XMMRegister(src->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -13594,1 +13953,1 @@\n-  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  int encode = simd_prefix_and_encode(src, xnoreg, as_XMMRegister(dst->encoding()), VEX_SIMD_66, VEX_OPCODE_0F, &attributes, true);\n@@ -13607,1 +13966,1 @@\n-  emit_int16(get_prefixq(src, dst), (unsigned char)0x8B);\n+  emit_prefix_and_int8(get_prefixq(src, dst), (unsigned char)0x8B);\n@@ -13613,1 +13972,1 @@\n-  emit_int16(get_prefixq(dst, src), (unsigned char)0x89);\n+  emit_prefix_and_int8(get_prefixq(dst, src), (unsigned char)0x89);\n@@ -13619,1 +13978,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xC7);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xC7);\n@@ -13632,3 +13991,2 @@\n-  emit_int24(get_prefixq(src, dst),\n-             0x0F,\n-             (unsigned char)0xBE);\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xBE);\n@@ -13639,2 +13997,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBE, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBE, 0xC0, encode);\n@@ -13646,1 +14004,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xC7);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xC7);\n@@ -13653,1 +14011,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x63);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x63);\n@@ -13664,3 +14022,2 @@\n-  emit_int24(get_prefixq(src, dst),\n-             0x0F,\n-             (unsigned char)0xBF);\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xBF);\n@@ -13671,2 +14028,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xBF, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBF, 0xC0, encode);\n@@ -13677,3 +14034,2 @@\n-  emit_int24(get_prefixq(src, dst),\n-             0x0F,\n-             (unsigned char)0xB6);\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xB6);\n@@ -13684,2 +14040,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xB6, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB6, 0xC0, encode);\n@@ -13690,3 +14046,2 @@\n-  emit_int24(get_prefixq(src, dst),\n-             0x0F,\n-             (unsigned char)0xB7);\n+  int prefix = get_prefixq(src, dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xB7);\n@@ -13697,2 +14052,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xB7, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB7, 0xC0, encode);\n@@ -13703,1 +14058,1 @@\n-  emit_int16(get_prefixq(src), (unsigned char)0xF7);\n+  emit_prefix_and_int8(get_prefixq(src), (unsigned char)0xF7);\n@@ -13714,2 +14069,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst1->encoding(), dst2->encoding(), src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  assert(!needs_eevex(dst1, dst2, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst1->encoding(), dst2->encoding(), src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes, true);\n@@ -13726,1 +14082,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xF7);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xF7);\n@@ -13736,2 +14092,2 @@\n-  int encode = prefixq_and_encode(src->encoding(), dst->encoding());\n-  emit_int24(0x0F, (unsigned char)0xA3, (encode | 0xC0));\n+  int encode = prefixq_and_encode(src->encoding(), dst->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xA3, 0xC0, encode);\n@@ -13742,3 +14098,2 @@\n-  int encode = prefixq_and_encode(src->encoding());\n-  emit_int16(0x0f, 0xba);\n-  emit_int8(0xe0|encode);\n+  int encode = prefixq_and_encode(src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xBA, 0xE0, encode);\n@@ -13751,3 +14106,2 @@\n-  emit_int24(get_prefixq(dst),\n-             0x0F,\n-             (unsigned char)0xBA);\n+  int prefix = get_prefixq(dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xBA);\n@@ -13761,3 +14115,2 @@\n-  emit_int24(get_prefixq(dst),\n-             0x0F,\n-             (unsigned char)0xBA);\n+  int prefix = get_prefixq(dst, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xBA);\n@@ -13776,1 +14129,1 @@\n-  emit_int16(get_prefixq(dst, src), (unsigned char)0x09);\n+  emit_prefix_and_int8(get_prefixq(dst, src), (unsigned char)0x09);\n@@ -13792,1 +14145,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x0B);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x0B);\n@@ -13804,4 +14157,2 @@\n-  emit_int32((unsigned char)0xF3,\n-             get_prefixq(src, dst),\n-             0x0F,\n-             (unsigned char)0xB8);\n+  emit_int8((unsigned char)0xF3);\n+  emit_prefix_and_int8(get_prefixq(src, dst, true \/* is_map1 *\/), (unsigned char) 0xB8);\n@@ -13814,2 +14165,2 @@\n-  int encode = prefixq_and_encode(dst->encoding(), src->encoding());\n-  emit_int24(0x0F, (unsigned char)0xB8, (0xC0 | encode));\n+  int encode = prefixq_and_encode(dst->encoding(), src->encoding(), true \/* is_map1 *\/);\n+  emit_opcode_prefix_and_encoding((unsigned char)0xB8, 0xC0, encode);\n@@ -13820,1 +14171,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0x8F);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0x8F);\n@@ -13825,1 +14176,2 @@\n-  emit_int8((unsigned char)0x58 | dst->encoding());\n+  int encode = prefix_and_encode(dst->encoding());\n+  emit_int8((unsigned char)0x58 | encode);\n@@ -13965,1 +14317,1 @@\n-  emit_int16(get_prefixq(src), (unsigned char)0xFF);\n+  emit_prefix_and_int8(get_prefixq(src), (unsigned char)0xFF);\n@@ -13991,2 +14343,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -13998,0 +14351,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -13999,1 +14353,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_32bit);\n@@ -14008,2 +14363,3 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n-  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes);\n+  assert(!needs_eevex(dst, src) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0,  src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes, true);\n@@ -14015,0 +14371,1 @@\n+  assert(!needs_eevex(dst, src.base(), src.index()) || (UseAPX && UseAVX > 2), \"extended gpr use requires UseAPX and UseAVX > 2\");\n@@ -14016,1 +14373,2 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_NOSCALE, \/* input_size_in_bits *\/ EVEX_64bit);\n@@ -14028,1 +14386,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD1);\n@@ -14032,1 +14390,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xC1);\n@@ -14040,1 +14398,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD3);\n@@ -14063,1 +14421,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD1);\n@@ -14067,1 +14425,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xC1);\n@@ -14075,1 +14433,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD3);\n@@ -14108,1 +14466,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x1B);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x1B);\n@@ -14150,1 +14508,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD3);\n@@ -14158,1 +14516,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xD1);\n@@ -14162,1 +14520,1 @@\n-    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xC1);\n@@ -14176,1 +14534,1 @@\n-  emit_int16(get_prefixq(dst, src), 0x29);\n+  emit_prefix_and_int8(get_prefixq(dst, src), 0x29);\n@@ -14193,1 +14551,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x2B);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x2B);\n@@ -14204,1 +14562,1 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0xF7);\n+  emit_prefix_and_int8(get_prefixq(dst), (unsigned char)0xF7);\n@@ -14232,1 +14590,1 @@\n-  emit_int16(get_prefixq(src, dst), (unsigned char)0x85);\n+  emit_prefix_and_int8(get_prefixq(src, dst), (unsigned char)0x85);\n@@ -14238,1 +14596,2 @@\n-  emit_int24(get_prefixq(dst, src), 0x0F, (unsigned char)0xC1);\n+  int prefix = get_prefixq(dst, src, true \/* is_map1 *\/);\n+  emit_prefix_and_int8(prefix, (unsigned char)0xC1);\n@@ -14244,1 +14603,1 @@\n-  emit_int16(get_prefixq(src, dst), (unsigned char)0x87);\n+  emit_prefix_and_int8(get_prefixq(src, dst), (unsigned char)0x87);\n@@ -14260,1 +14619,1 @@\n-  emit_int16(get_prefixq(src, dst), 0x33);\n+  emit_prefix_and_int8(get_prefixq(src, dst), 0x33);\n@@ -14277,1 +14636,1 @@\n-  emit_int16(get_prefixq(dst, src), 0x31);\n+  emit_prefix_and_int8(get_prefixq(dst, src), 0x31);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":783,"deletions":424,"binary":false,"changes":1207,"status":"modified"},{"patch":"@@ -311,1 +311,5 @@\n-    return _base->is_valid() && _base->encoding() >= 8;\n+    return _base->is_valid() && ((_base->encoding() & 8) == 8);\n+  }\n+\n+  bool base_needs_rex2() const {\n+    return _base->is_valid() && _base->encoding() >= 16;\n@@ -315,1 +319,5 @@\n-    return _index->is_valid() &&_index->encoding() >= 8;\n+    return _index->is_valid() && ((_index->encoding() & 8) == 8);\n+  }\n+\n+  bool index_needs_rex2() const {\n+    return _index->is_valid() &&_index->encoding() >= 16;\n@@ -322,0 +330,4 @@\n+  bool xmmindex_needs_rex2() const {\n+    return _xmmindex->is_valid() && _xmmindex->encoding() >= 16;\n+  }\n+\n@@ -511,0 +523,3 @@\n+    REX2       = 0xd5,\n+    WREX2      = REX2 << 8,\n+\n@@ -517,0 +532,11 @@\n+  enum PrefixBits {\n+    REXBIT_B  = 0x01,\n+    REXBIT_X  = 0x02,\n+    REXBIT_R  = 0x04,\n+    REXBIT_W  = 0x08,\n+    REX2BIT_B4 = 0x10,\n+    REX2BIT_X4 = 0x20,\n+    REX2BIT_R4 = 0x40,\n+    REX2BIT_M0 = 0x80\n+  };\n+\n@@ -528,0 +554,1 @@\n+    EVEX_B  = 0x20,\n@@ -532,0 +559,7 @@\n+  enum ExtEvexPrefix {\n+    EEVEX_R = 0x10,\n+    EEVEX_B = 0x08,\n+    EEVEX_X = 0x04,\n+    EEVEX_V = 0x08\n+  };\n+\n@@ -543,1 +577,1 @@\n-    VEX_SIMD_F2   = 0x3\n+    VEX_SIMD_F2   = 0x3,\n@@ -551,0 +585,1 @@\n+    VEX_OPCODE_0F_3C = 0x4,\n@@ -575,1 +610,2 @@\n-    EVEX_ETUP = 23\n+    EVEX_NOSCALE = 23,\n+    EVEX_ETUP = 24\n@@ -689,0 +725,6 @@\n+  int get_base_prefix_bits(int enc);\n+  int get_index_prefix_bits(int enc);\n+  int get_base_prefix_bits(Register base);\n+  int get_index_prefix_bits(Register index);\n+  int get_reg_prefix_bits(int enc);\n+\n@@ -692,0 +734,1 @@\n+  void prefix_rex2(Register dst, Register src);\n@@ -693,0 +736,1 @@\n+  void prefix_rex2(Register dst, Address adr);\n@@ -694,2 +738,4 @@\n-  void prefix(Address adr);\n-  void prefix(Address adr, Register reg,  bool byteinst = false);\n+  void prefix(Address adr, bool is_map1 = false);\n+  void prefix_rex2(Address adr, bool is_map1 = false);\n+  void prefix(Address adr, Register reg,  bool byteinst = false, bool is_map1 = false);\n+  void prefix_rex2(Address adr, Register reg,  bool byteinst = false, bool is_map1 = false);\n@@ -697,0 +743,1 @@\n+  void prefix_rex2(Address adr, XMMRegister reg);\n@@ -698,3 +745,4 @@\n-  int prefix_and_encode(int reg_enc, bool byteinst = false);\n-  int prefix_and_encode(int dst_enc, int src_enc) {\n-    return prefix_and_encode(dst_enc, false, src_enc, false);\n+  int prefix_and_encode(int reg_enc, bool byteinst = false, bool is_map1 = false);\n+  int prefix_and_encode_rex2(int reg_enc, bool is_map1 = false);\n+  int prefix_and_encode(int dst_enc, int src_enc, bool is_map1 = false) {\n+    return prefix_and_encode(dst_enc, false, src_enc, false, is_map1);\n@@ -702,1 +750,1 @@\n-  int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte);\n+  int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte, bool is_map1 = false);\n@@ -704,0 +752,1 @@\n+  int prefix_and_encode_rex2(int dst_enc, int src_enc, int init_bits = 0);\n@@ -707,2 +756,4 @@\n-  int8_t get_prefixq(Address adr);\n-  int8_t get_prefixq(Address adr, Register reg);\n+  int get_prefixq(Address adr, bool is_map1 = false);\n+  int get_prefixq_rex2(Address adr, bool is_map1 = false);\n+  int get_prefixq(Address adr, Register reg, bool is_map1 = false);\n+  int get_prefixq_rex2(Address adr, Register reg, bool ismap1 = false);\n@@ -711,1 +762,1 @@\n-  void prefixq(Address adr, Register reg);\n+  void prefixq(Address adr, Register reg, bool is_map1 = false);\n@@ -713,0 +764,1 @@\n+  void prefixq_rex2(Address adr, XMMRegister src);\n@@ -714,2 +766,11 @@\n-  int prefixq_and_encode(int reg_enc);\n-  int prefixq_and_encode(int dst_enc, int src_enc);\n+  bool prefix_is_rex2(int prefix);\n+\n+  int prefixq_and_encode(int reg_enc, bool is_map1 = false);\n+  int prefixq_and_encode_rex2(int reg_enc, bool is_map1 = false);\n+  int prefixq_and_encode(int dst_enc, int src_enc, bool is_map1 = false);\n+  int prefixq_and_encode_rex2(int dst_enc, int src_enc, bool is_map1 = false);\n+\n+  bool needs_rex2(Register reg1, Register reg2 = noreg, Register reg3 = noreg);\n+\n+  bool needs_eevex(Register reg1, Register reg2 = noreg, Register reg3 = noreg);\n+  bool needs_eevex(int enc1, int enc2 = -1, int enc3 = -1);\n@@ -724,2 +785,2 @@\n-  void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v,\n-                   int nds_enc, VexSimdPrefix pre, VexOpcode opc);\n+  void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_v, bool evex_r, bool evex_b,\n+                       bool eevex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc);\n@@ -727,2 +788,1 @@\n-  void vex_prefix(Address adr, int nds_enc, int xreg_enc,\n-                  VexSimdPrefix pre, VexOpcode opc,\n+  void vex_prefix(Address adr, int nds_enc, int xreg_enc, VexSimdPrefix pre, VexOpcode opc,\n@@ -733,1 +793,1 @@\n-                             InstructionAttr *attributes);\n+                             InstructionAttr *attributes, bool src_is_gpr = false);\n@@ -739,1 +799,1 @@\n-                             VexOpcode opc, InstructionAttr *attributes);\n+                             VexOpcode opc, InstructionAttr *attributes, bool src_is_gpr = false);\n@@ -824,0 +884,4 @@\n+  void emit_prefix_and_int8(int prefix, int b1);\n+  void emit_opcode_prefix_and_encoding(int byte1, int ocp_and_encoding);\n+  void emit_opcode_prefix_and_encoding(int byte1, int byte2, int ocp_and_encoding);\n+  void emit_opcode_prefix_and_encoding(int byte1, int byte2, int ocp_and_encoding, int byte3);\n@@ -910,0 +974,2 @@\n+  void prefix16(int p);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":87,"deletions":21,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -33,2 +33,5 @@\n-inline int Assembler::prefix_and_encode(int reg_enc, bool byteinst) { return reg_enc; }\n-inline int Assembler::prefixq_and_encode(int reg_enc) { return reg_enc; }\n+inline int Assembler::prefix_and_encode(int reg_enc, bool byteinst, bool is_map1)\n+{\n+    int opc_prefix = is_map1 ? 0x0F00 : 0;\n+    return opc_prefix | reg_enc;\n+}\n@@ -36,2 +39,14 @@\n-inline int Assembler::prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte) { return dst_enc << 3 | src_enc; }\n-inline int Assembler::prefixq_and_encode(int dst_enc, int src_enc) { return dst_enc << 3 | src_enc; }\n+inline int Assembler::prefixq_and_encode(int reg_enc, bool is_map1) {\n+    int opc_prefix = is_map1 ? 0xF00 : 0;\n+    return opc_prefix | reg_enc;\n+}\n+\n+inline int Assembler::prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte, bool is_map1) {\n+    int opc_prefix = is_map1 ? 0xF00 : 0;\n+    return opc_prefix | (dst_enc << 3 | src_enc);\n+}\n+\n+inline int Assembler::prefixq_and_encode(int dst_enc, int src_enc, bool is_map1) {\n+    int opc_prefix = is_map1 ? 0xF00 : 0;\n+    return opc_prefix | dst_enc << 3 | src_enc;\n+}\n@@ -42,1 +57,7 @@\n-inline void Assembler::prefix(Address adr) {}\n+\n+inline void Assembler::prefix(Address adr, bool is_map1) {\n+    if (is_map1) {\n+        emit_int8(0x0F);\n+    }\n+}\n+\n@@ -45,2 +66,10 @@\n-inline void Assembler::prefix(Address adr, Register reg,  bool byteinst) {}\n-inline void Assembler::prefixq(Address adr, Register reg) {}\n+inline void Assembler::prefix(Address adr, Register reg,  bool byteinst, bool is_map1) {\n+    if (is_map1) {\n+        emit_int8(0x0F);\n+    }\n+}\n+inline void Assembler::prefixq(Address adr, Register reg, bool is_map1) {\n+    if (is_map1) {\n+        emit_int8(0x0F);\n+    }\n+}\n@@ -50,0 +79,1 @@\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.inline.hpp","additions":37,"deletions":7,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -235,2 +235,4 @@\n-             \"mitigations for the Intel JCC erratum\")\n-\n+             \"mitigations for the Intel JCC erratum\")                       \\\n+                                                                            \\\n+  product(bool, UseAPX, false, EXPERIMENTAL,                                \\\n+          \"Use Advanced Performance Extensions on x86\")                     \\\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1005,0 +1005,7 @@\n+  if (UseAPX && (UseAVX < 3)) {\n+    if (!FLAG_IS_DEFAULT(UseAPX)) {\n+        warning(\"UseAPX is only available when UseAVX > 2\");\n+    }\n+    FLAG_SET_DEFAULT(UseAPX, false);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"}]}