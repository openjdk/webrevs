{"files":[{"patch":"@@ -47,0 +47,3 @@\n+  \/\/ Young collections can never unload classes\n+  bool can_unload_classes() override { return false; }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahYoungHeuristics.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -673,1 +673,1 @@\n-      heap->old_generation()->cancel_gc();\n+      heap->old_generation()->abandon_gc();\n@@ -699,9 +699,1 @@\n-  if (_do_old_gc_bootstrap) {\n-    shenandoah_assert_generational();\n-    \/\/ Update region state for both young and old regions\n-    ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_region_states);\n-    ShenandoahInitMarkUpdateRegionStateClosure cl;\n-    heap->parallel_heap_region_iterate(&cl);\n-    heap->old_generation()->ref_processor()->reset_thread_locals();\n-  } else {\n-    \/\/ Update region state for only young regions\n+  {\n@@ -710,1 +702,8 @@\n-    _generation->parallel_heap_region_iterate(&cl);\n+    if (_do_old_gc_bootstrap) {\n+      \/\/ Update region state for both young and old regions\n+      shenandoah_assert_generational();\n+      heap->parallel_heap_region_iterate(&cl);\n+    } else {\n+      \/\/ Update region state for only current generation regions\n+      _generation->parallel_heap_region_iterate(&cl);\n+    }\n@@ -1101,1 +1100,1 @@\n-void ShenandoahConcurrentGC::op_update_refs() {\n+void ShenandoahConcurrentGC::op_update_refs() const {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.cpp","additions":11,"deletions":12,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -121,1 +121,1 @@\n-  void op_update_refs();\n+  void op_update_refs() const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentGC.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -165,1 +165,1 @@\n-          \/\/ (even if they have degenerated). If this is a global cycle, we'd have cancelled\n+          \/\/ (even if they have degenerated). If this is a global cycle, we'd have abandoned\n@@ -167,2 +167,3 @@\n-          \/\/ the generation does NOT abandon incomplete SATB buffers as cancel_concurrent_mark does.\n-          \/\/ We need to separate out the old pointers which is done below.\n+          \/\/ the young generation does NOT abandon incomplete SATB buffers in the old generation\n+          \/\/ as cancel_concurrent_mark does. We need to separate out the old pointers which\n+          \/\/ is done below.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahDegeneratedGC.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -107,1 +107,1 @@\n-  ShenandoahReferenceProcessor* ref_processor() { return _ref_processor; }\n+  ShenandoahReferenceProcessor* ref_processor() const { return _ref_processor; }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -173,4 +173,3 @@\n-  ShenandoahHeuristics* global_heuristics = _heap->global_generation()->heuristics();\n-  request.generation = _heap->global_generation();\n-  global_heuristics->log_trigger(\"GC request (%s)\", GCCause::to_string(request.cause));\n-  global_heuristics->record_requested_gc();\n+  ShenandoahHeuristics* heuristics = request.generation->heuristics();\n+  heuristics->log_trigger(\"GC request (%s)\", GCCause::to_string(request.cause));\n+  heuristics->record_requested_gc();\n@@ -179,6 +178,1 @@\n-    return stw_full;;\n-  } else {\n-    \/\/ Unload and clean up everything. Note that this is an _explicit_ request and so does not use\n-    \/\/ the same `should_unload_classes` call as the regulator's concurrent gc request.\n-    _heap->set_unload_classes(global_heuristics->can_unload_classes());\n-    return concurrent_normal;\n+    return stw_full;\n@@ -186,0 +180,5 @@\n+\n+  \/\/ Unload and clean up everything. Note that this is an _explicit_ request and so does not use\n+  \/\/ the same `should_unload_classes` call as the regulator's concurrent gc request.\n+  _heap->set_unload_classes(heuristics->can_unload_classes());\n+  return concurrent_normal;\n@@ -410,0 +409,2 @@\n+      \/\/ Configure the young generation for bootstrapping the old mark\n+      young_generation->prepare_for_bootstrap(old_generation);\n@@ -412,5 +413,0 @@\n-      \/\/ Configure the young generation's concurrent mark to put objects in\n-      \/\/ old regions into the concurrent mark queues associated with the old\n-      \/\/ generation. The young cycle will run as normal except that rather than\n-      \/\/ ignore old references it will mark and enqueue them in the old concurrent\n-      \/\/ task queues but it will not traverse them.\n@@ -418,1 +414,0 @@\n-      young_generation->set_old_gen_task_queues(old_generation->task_queues());\n@@ -564,2 +559,2 @@\n-    assert(generation->is_global(), \"If not young, must be GLOBAL\");\n-    assert(!do_old_gc_bootstrap, \"Do not bootstrap with GLOBAL GC\");\n+    assert(generation->is_global(), \"If not young, must be Global\");\n+    assert(!do_old_gc_bootstrap, \"Do not bootstrap with Global GC\");\n@@ -567,1 +562,1 @@\n-      msg = \"At end of Interrupted Concurrent GLOBAL GC\";\n+      msg = \"At end of Interrupted Concurrent Global GC\";\n@@ -719,10 +714,1 @@\n-void ShenandoahGenerationalControlThread::handle_requested_gc(GCCause::Cause cause) {\n-  \/\/ For normal requested GCs (System.gc) we want to block the caller. However,\n-  \/\/ for whitebox requested GC, we want to initiate the GC and return immediately.\n-  \/\/ The whitebox caller thread will arrange for itself to wait until the GC notifies\n-  \/\/ it that has reached the requested breakpoint (phase in the GC).\n-  if (cause == GCCause::_wb_breakpoint) {\n-    notify_control_thread(cause, ShenandoahHeap::heap()->global_generation());\n-    return;\n-  }\n-\n+void ShenandoahGenerationalControlThread::wait_for_gc_cycle(GCCause::Cause cause, ShenandoahGeneration* generation) {\n@@ -743,1 +729,1 @@\n-    notify_control_thread(cause, ShenandoahHeap::heap()->global_generation());\n+    notify_control_thread(cause, generation);\n@@ -749,0 +735,15 @@\n+void ShenandoahGenerationalControlThread::handle_requested_gc(GCCause::Cause cause) {\n+  \/\/ For normal requested GCs (System.gc) we want to block the caller. However,\n+  \/\/ for whitebox requested GC, we want to initiate the GC and return immediately.\n+  \/\/ The whitebox caller thread will arrange for itself to wait until the GC notifies\n+  \/\/ it that has reached the requested breakpoint (phase in the GC).\n+  if (cause == GCCause::_wb_breakpoint) {\n+    notify_control_thread(cause, ShenandoahHeap::heap()->global_generation());\n+    return;\n+  }\n+  ShenandoahGeneration* generation = cause == GCCause::_wb_young_gc\n+                                   ? ShenandoahHeap::heap()->young_generation()\n+                                   : ShenandoahHeap::heap()->global_generation();\n+  wait_for_gc_cycle(cause, generation);\n+}\n+\n@@ -774,2 +775,3 @@\n-    log_debug(gc, thread)(\"Transition from: %s to: %s\", gc_mode_name(_gc_mode), gc_mode_name(new_mode));\n-    EventMark event(\"Control thread transition from: %s, to %s\", gc_mode_name(_gc_mode), gc_mode_name(new_mode));\n+    FormatBuffer<> msg(\"Transition from: %s to: %s\", gc_mode_name(_gc_mode), gc_mode_name(new_mode));\n+    log_debug(gc, thread)(\"%s\", msg.buffer());\n+    Events::log(this, \"%s\", msg.buffer());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalControlThread.cpp","additions":34,"deletions":32,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -101,0 +101,3 @@\n+  \/\/ Visible for white box API to start an old cycle\n+  void wait_for_gc_cycle(GCCause::Cause cause, ShenandoahGeneration* generation);\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalControlThread.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -61,0 +61,3 @@\n+  \/\/ If we were bootstrapping, we don't need that configuration anymore\n+  heap->young_generation()->clear_bootstrap_configuration();\n+\n@@ -62,1 +65,1 @@\n-  heap->old_generation()->cancel_gc();\n+  heap->old_generation()->abandon_gc();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalFullGC.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -130,0 +130,5 @@\n+bool ShenandoahGenerationalHeap::start_old_collection() {\n+  static_cast<ShenandoahGenerationalControlThread*>(_control_thread)->wait_for_gc_cycle(GCCause::_shenandoah_concurrent_gc, old_generation());\n+  return true;\n+}\n+\n@@ -941,0 +946,10 @@\n+\n+  if (is_concurrent_old_mark_in_progress()) {\n+    \/\/ Discovered lists may have young references with old referents. These references will be\n+    \/\/ processed at the end of old marking. We need to update them.\n+    ShenandoahReferenceProcessor* old_ref_processor = old_generation()->ref_processor();\n+    assert(old_ref_processor != nullptr, \"Must have old ref processor if old marking is in progress\");\n+    ShenandoahPhaseTimings::Phase phase = concurrent ? ShenandoahPhaseTimings::conc_weak_refs : ShenandoahPhaseTimings::degen_gc_weakrefs;\n+    old_ref_processor->heal_discovered_lists(phase, workers(), concurrent);\n+  }\n+\n@@ -1029,3 +1044,2 @@\n-  \/\/ In case degeneration interrupted concurrent evacuation or update references, we need to clean up\n-  \/\/ transient state. Otherwise, these actions have no effect.\n-  reset_generation_reserves();\n+\n+  complete_cycle();\n@@ -1040,0 +1054,2 @@\n+  complete_cycle();\n+\n@@ -1050,0 +1066,11 @@\n+\n+}\n+\n+void ShenandoahGenerationalHeap::complete_cycle() {\n+  if (young_generation()->is_bootstrap_cycle()) {\n+    \/\/ Once the bootstrap cycle is completed, the young generation is no longer obliged to mark old\n+    young_generation()->clear_bootstrap_configuration();\n+  }\n+\n+  \/\/ In case degeneration interrupted concurrent evacuation or update references, we need to clean up\n+  \/\/ transient state. Otherwise, these actions have no effect.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":30,"deletions":3,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -46,0 +46,2 @@\n+  bool start_old_collection();\n+\n@@ -145,0 +147,1 @@\n+  void complete_cycle();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -60,4 +60,0 @@\n-    \/\/ Old collection is complete, the young generation no longer needs this\n-    \/\/ reference to the old concurrent mark so clean it up.\n-    heap->young_generation()->set_old_gen_task_queues(nullptr);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGC.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -296,1 +296,1 @@\n-void ShenandoahOldGeneration::cancel_gc() {\n+void ShenandoahOldGeneration::abandon_gc() {\n@@ -308,2 +308,0 @@\n-    \/\/ Remove old generation access to young generation mark queues\n-    ShenandoahHeap::heap()->young_generation()->set_old_gen_task_queues(nullptr);\n@@ -449,2 +447,3 @@\n-    log_debug(gc, thread)(\"Old generation transition from %s to %s\", state_name(_state), state_name(new_state));\n-    EventMark event(\"Old was %s, now is %s\", state_name(_state), state_name(new_state));\n+    FormatBuffer<> msg(\"Old was %s, now is %s\", state_name(_state), state_name(new_state));\n+    log_debug(gc, thread)(\"%s\", msg.buffer());\n+    Events::log(Thread::current(), \"%s\", msg.buffer());\n@@ -534,0 +533,1 @@\n+      assert(heap->young_generation()->is_bootstrap_cycle(), \"Young generation needs old mark queues.\");\n@@ -537,1 +537,1 @@\n-      assert(heap->young_generation()->old_gen_task_queues() != nullptr, \"Young generation needs old mark queues.\");\n+      assert(!heap->young_generation()->is_bootstrap_cycle(), \"Young generation is done with bootstrapping\");\n@@ -555,1 +555,0 @@\n-  assert(heap->young_generation()->old_gen_task_queues() == nullptr, \"Cannot become ready for bootstrap when still setup for bootstrapping.\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -228,2 +228,2 @@\n-  \/\/ Cancels old gc and transitions to the idle state\n-  void cancel_gc();\n+  \/\/ Abandons all old gc state and transitions to the idle state\n+  void abandon_gc();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -182,0 +182,43 @@\n+template <typename CallbackT>\n+class ShenandoahReferenceProcessorTask : public WorkerTask {\n+private:\n+  bool const                          _concurrent;\n+  ShenandoahPhaseTimings::Phase const _phase;\n+  ShenandoahRefProcThreadLocal* const _ref_proc_thread_locals;\n+  CallbackT _callback;\n+  volatile uint _iterate_discovered_list_id;\n+\n+public:\n+  ShenandoahReferenceProcessorTask(ShenandoahPhaseTimings::Phase phase, bool concurrent,\n+                                   ShenandoahRefProcThreadLocal* ref_proc_thread_locals, CallbackT callback) :\n+    WorkerTask(\"ShenandoahReferenceProcessorTask\"),\n+    _concurrent(concurrent),\n+    _phase(phase),\n+    _ref_proc_thread_locals(ref_proc_thread_locals),\n+    _callback(callback),\n+    _iterate_discovered_list_id(0) {\n+  }\n+\n+  virtual void work(uint worker_id) {\n+    if (_concurrent) {\n+      ShenandoahConcurrentWorkerSession worker_session(worker_id);\n+      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::WeakRefProc, worker_id, true);\n+      do_work();\n+    } else {\n+      ShenandoahParallelWorkerSession worker_session(worker_id);\n+      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::WeakRefProc, worker_id, true);\n+      do_work();\n+    }\n+  }\n+\n+  void do_work() {\n+    const uint max_workers = ShenandoahHeap::heap()->max_workers();\n+    uint worker_id = AtomicAccess::add(&_iterate_discovered_list_id, 1U, memory_order_relaxed) - 1;\n+    while (worker_id < max_workers) {\n+      ShenandoahRefProcThreadLocal& ref_proc_data = _ref_proc_thread_locals[worker_id];\n+      _callback(ref_proc_data, worker_id);\n+      worker_id = AtomicAccess::add(&_iterate_discovered_list_id, 1U, memory_order_relaxed) - 1;\n+    }\n+  }\n+};\n+\n@@ -199,0 +242,24 @@\n+template <typename T>\n+void ShenandoahRefProcThreadLocal::heal_discovered_list() {\n+  if (_discovered_list == nullptr) {\n+    return;\n+  }\n+\n+  T* list = reinterpret_cast<T*>(&_discovered_list);\n+  while (list != nullptr) {\n+    const oop discovered_ref = CompressedOops::decode(*list);\n+    const oop reference = lrb(discovered_ref);\n+    if (discovered_ref != reference) {\n+      \/\/ Update our list with the forwarded object\n+      set_oop_field(list, reference);\n+    }\n+\n+    \/\/ Discovered list terminates with a self-loop\n+    const oop discovered = lrb(reference_discovered<T>(reference));\n+    if (reference == discovered) {\n+      break;\n+    }\n+    list = reference_discovered_addr<T>(reference);\n+  }\n+}\n+\n@@ -231,2 +298,2 @@\n-  _iterate_discovered_list_id(0U),\n-  _generation(generation) {\n+  _generation(generation),\n+  _old_generation_ref_processor(nullptr) {\n@@ -247,0 +314,3 @@\n+  if (_old_generation_ref_processor != nullptr) {\n+    _old_generation_ref_processor->set_mark_closure(worker_id, mark_closure);\n+  }\n@@ -262,0 +332,14 @@\n+void ShenandoahReferenceProcessor::heal_discovered_lists(ShenandoahPhaseTimings::Phase phase, WorkerThreads* workers, bool concurrent) {\n+    ShenandoahReferenceProcessorTask heal_lists_task(phase, concurrent, _ref_proc_thread_locals,\n+[&](ShenandoahRefProcThreadLocal& ref_proc_data, uint worker_id) {\n+         if (UseCompressedOops) {\n+           ref_proc_data.heal_discovered_list<narrowOop>();\n+         } else {\n+           ref_proc_data.heal_discovered_list<oop>();\n+         }\n+       }\n+    );\n+  workers->run_task(&heal_lists_task);\n+}\n+\n+\n@@ -297,1 +381,0 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -315,0 +398,6 @@\n+    if (_old_generation_ref_processor != nullptr) {\n+      log_trace(gc,ref)(\"Discovered reference for old: \" PTR_FORMAT, p2i(reference));\n+      _old_generation_ref_processor->discover_reference(reference, type);\n+      return true;\n+    }\n+\n@@ -456,1 +545,1 @@\n-T* ShenandoahReferenceProcessor::keep(oop reference, ReferenceType type, uint worker_id) {\n+T* ShenandoahReferenceProcessor::keep(oop reference, ReferenceType type) {\n@@ -459,3 +548,0 @@\n-  \/\/ Update statistics\n-  _ref_proc_thread_locals[worker_id].inc_enqueued(type);\n-\n@@ -491,1 +577,5 @@\n-      p = keep<T>(reference, type, worker_id);\n+      \/\/ Update statistics\n+      refproc_data.inc_enqueued(type);\n+\n+      \/\/ Keep this reference on the list and make it inactive\n+      p = keep<T>(reference, type);\n@@ -519,27 +609,1 @@\n-void ShenandoahReferenceProcessor::work() {\n-  \/\/ Process discovered references\n-  uint max_workers = ShenandoahHeap::heap()->max_workers();\n-  uint worker_id = AtomicAccess::add(&_iterate_discovered_list_id, 1U, memory_order_relaxed) - 1;\n-  while (worker_id < max_workers) {\n-    if (UseCompressedOops) {\n-      process_references<narrowOop>(_ref_proc_thread_locals[worker_id], worker_id);\n-    } else {\n-      process_references<oop>(_ref_proc_thread_locals[worker_id], worker_id);\n-    }\n-    worker_id = AtomicAccess::add(&_iterate_discovered_list_id, 1U, memory_order_relaxed) - 1;\n-  }\n-}\n-\n-class ShenandoahReferenceProcessorTask : public WorkerTask {\n-private:\n-  bool const                          _concurrent;\n-  ShenandoahPhaseTimings::Phase const _phase;\n-  ShenandoahReferenceProcessor* const _reference_processor;\n-\n-public:\n-  ShenandoahReferenceProcessorTask(ShenandoahPhaseTimings::Phase phase, bool concurrent, ShenandoahReferenceProcessor* reference_processor) :\n-    WorkerTask(\"ShenandoahReferenceProcessorTask\"),\n-    _concurrent(concurrent),\n-    _phase(phase),\n-    _reference_processor(reference_processor) {\n-  }\n+void ShenandoahReferenceProcessor::process_references(ShenandoahPhaseTimings::Phase phase, WorkerThreads* workers, bool concurrent) {\n@@ -547,5 +611,3 @@\n-  virtual void work(uint worker_id) {\n-    if (_concurrent) {\n-      ShenandoahConcurrentWorkerSession worker_session(worker_id);\n-      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::WeakRefProc, worker_id);\n-      _reference_processor->work();\n+  auto process_refs = [&](ShenandoahRefProcThreadLocal& ref_proc_data, uint worker_id) {\n+    if (UseCompressedOops) {\n+      process_references<narrowOop>(ref_proc_data, worker_id);\n@@ -553,3 +615,1 @@\n-      ShenandoahParallelWorkerSession worker_session(worker_id);\n-      ShenandoahWorkerTimingsTracker x(_phase, ShenandoahPhaseTimings::WeakRefProc, worker_id);\n-      _reference_processor->work();\n+      process_references<oop>(ref_proc_data, worker_id);\n@@ -557,6 +617,1 @@\n-  }\n-};\n-\n-void ShenandoahReferenceProcessor::process_references(ShenandoahPhaseTimings::Phase phase, WorkerThreads* workers, bool concurrent) {\n-\n-  AtomicAccess::release_store_fence(&_iterate_discovered_list_id, 0U);\n+  };\n@@ -565,1 +620,1 @@\n-  ShenandoahReferenceProcessorTask task(phase, concurrent, this);\n+  ShenandoahReferenceProcessorTask task(phase, concurrent, _ref_proc_thread_locals, process_refs);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReferenceProcessor.cpp","additions":105,"deletions":50,"binary":false,"changes":155,"status":"modified"},{"patch":"@@ -100,0 +100,3 @@\n+  template<typename T>\n+  void heal_discovered_list();\n+\n@@ -139,2 +142,0 @@\n-  volatile uint _iterate_discovered_list_id;\n-\n@@ -145,0 +146,2 @@\n+  ShenandoahReferenceProcessor* _old_generation_ref_processor;\n+\n@@ -164,1 +167,1 @@\n-  T* keep(oop reference, ReferenceType type, uint worker_id);\n+  T* keep(oop reference, ReferenceType type);\n@@ -184,0 +187,33 @@\n+  void set_old_generation_ref_processor(ShenandoahReferenceProcessor* ref_processor) {\n+    _old_generation_ref_processor = ref_processor;\n+  }\n+\n+  void clear_old_generation_ref_processor() {\n+    _old_generation_ref_processor = nullptr;\n+  }\n+\n+  ShenandoahReferenceProcessor* get_old_generation_ref_processor() const {\n+    return _old_generation_ref_processor;\n+  }\n+\n+  \/\/ The generational mode for Shenandoah will collect _referents_ for the generation\n+  \/\/ being collected. For example, if we have a young reference pointing to an old\n+  \/\/ referent, that young reference will be processed after we finish marking the old\n+  \/\/ generation. This presents a problem for discovery.\n+  \/\/\n+  \/\/ When the young mark _encounters_ a young reference with an old referent, it\n+  \/\/ cannot \"discover\" it because old marking hasn't finished. However, if it does not\n+  \/\/ discover it, the old referent will be strongly marked. This will prevent the\n+  \/\/ old generation from clearing the referent (if it even reaches it again during\n+  \/\/ old marking).\n+  \/\/\n+  \/\/ To solve this, we let young reference processing discover the old reference\n+  \/\/ by having it use the old generation reference processor to discover it. This means\n+  \/\/ the old reference processor can have a discovered list that contains young\n+  \/\/ weak references. If any of these young references reside in a region that is collected,\n+  \/\/ old reference processing will crash when it processes this young reference. Therefore,\n+  \/\/ we have this method to traverse the discovered lists after young evacuation is\n+  \/\/ complete. It will replace any forwarded entries in the discovered list with the\n+  \/\/ forwardee.\n+  void heal_discovered_lists(ShenandoahPhaseTimings::Phase phase, WorkerThreads* workers, bool concurrent);\n+\n@@ -188,3 +224,1 @@\n-  const ReferenceProcessorStats& reference_process_stats() { return _stats; }\n-\n-  void work();\n+  const ReferenceProcessorStats& reference_process_stats() const { return _stats; }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReferenceProcessor.hpp","additions":40,"deletions":6,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n@@ -42,6 +43,4 @@\n-  if (is_bootstrap_cycle() && in_progress && !heap->is_prepare_for_old_mark_in_progress()) {\n-    \/\/ This is not a bug. When the bootstrapping marking phase is complete,\n-    \/\/ the old generation marking is still in progress, unless it's not.\n-    \/\/ In the case that old-gen preparation for mixed evacuation has been\n-    \/\/ preempted, we do not want to set concurrent old mark to be in progress.\n-    heap->set_concurrent_old_mark_in_progress(in_progress);\n+  if (is_bootstrap_cycle() && in_progress) {\n+    \/\/ The start of concurrent mark for young is also the start of the concurrent mark for old\n+    assert(!heap->is_prepare_for_old_mark_in_progress(), \"Filling old regions must be complete before bootstrap\");\n+    heap->set_concurrent_old_mark_in_progress(true);\n@@ -51,0 +50,18 @@\n+\/\/ A bootstrap cycle will run as normal young cycle except that rather than\n+\/\/ ignore old references it will mark and enqueue them in the old concurrent\n+\/\/ task queues, but it will not traverse them. Similarly, we must configure\n+\/\/ the young ref processor to have the old ref processor discover old weak\n+\/\/ references.\n+void ShenandoahYoungGeneration::prepare_for_bootstrap(ShenandoahGeneration* generation) {\n+  assert(generation->is_old(), \"Need old generation to prepare for bootstrap\");\n+  ShenandoahReferenceProcessor* old_ref_processor = generation->ref_processor();\n+  _old_gen_task_queues = generation->task_queues();\n+  ref_processor()->set_old_generation_ref_processor(old_ref_processor);\n+  old_ref_processor->reset_thread_locals();\n+}\n+\n+void ShenandoahYoungGeneration::clear_bootstrap_configuration() {\n+  _old_gen_task_queues = nullptr;\n+  ref_processor()->clear_old_generation_ref_processor();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahYoungGeneration.cpp","additions":23,"deletions":6,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -63,3 +63,1 @@\n-  void set_old_gen_task_queues(ShenandoahObjToScanQueueSet* old_gen_queues) {\n-    _old_gen_task_queues = old_gen_queues;\n-  }\n+\n@@ -72,1 +70,1 @@\n-  bool is_bootstrap_cycle() {\n+  bool is_bootstrap_cycle() const {\n@@ -76,0 +74,6 @@\n+  \/\/ Take a reference to the old task queues and reference processor\n+  void prepare_for_bootstrap(ShenandoahGeneration* generation);\n+\n+  \/\/ Clear references to old gen marking\n+  void clear_bootstrap_configuration();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahYoungGeneration.hpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -121,0 +121,4 @@\n+#if INCLUDE_SHENANDOAHGC\n+#include \"gc\/shenandoah\/shenandoahGenerationalHeap.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.hpp\"\n+#endif \/\/ INCLUDE_SHENANDOAHGC\n@@ -704,0 +708,40 @@\n+#if INCLUDE_SHENANDOAHGC\n+\n+WB_ENTRY(jint, WB_ShenandoahRegionSize(JNIEnv* env, jobject o))\n+  if (UseShenandoahGC) {\n+    return ShenandoahHeapRegion::region_size_bytes_jint();\n+  }\n+THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_ShenandoahRegionSize: Shenandoah GC is not enabled\");\n+WB_END\n+\n+WB_ENTRY(jint, WB_ShenandoahRegionCount(JNIEnv* env, jobject o))\n+  if (UseShenandoahGC) {\n+    return static_cast<jint>(ShenandoahHeap::heap()->num_regions());\n+  }\n+THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_ShenandoahRegionSize: Shenandoah GC is not enabled\");\n+WB_END\n+\n+WB_ENTRY(jint, WB_ShenandoahRegionIndex(JNIEnv* env, jobject o, jobject obj))\n+  if (UseShenandoahGC) {\n+    oop resolved = JNIHandles::resolve(obj);\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    if (heap->is_in(resolved)) {\n+      return static_cast<jint>(heap->heap_region_containing(resolved)->index());\n+    }\n+    return -1;\n+  }\n+THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_ShenandoahRegionSize: Shenandoah GC is not enabled\");\n+WB_END\n+\n+WB_ENTRY(jboolean, WB_ShenandoahOldGC(JNIEnv* env, jobject o))\n+  if (UseShenandoahGC) {\n+    if (ShenandoahHeap::heap()->mode()->is_generational()) {\n+      return ShenandoahGenerationalHeap::heap()->start_old_collection();\n+    }\n+    return false;\n+  }\n+THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_ShenandoahRegionSize: Shenandoah GC is not enabled\");\n+WB_END\n+\n+#endif \/\/ INCLUDE_SHENANDOAHGC\n+\n@@ -2893,0 +2937,6 @@\n+#if INCLUDE_SHENANDOAHGC\n+  {CC\"shenandoahRegionSize\",   CC\"()I\",                   (void*)&WB_ShenandoahRegionSize  },\n+  {CC\"shenandoahRegionCount\",  CC\"()I\",                   (void*)&WB_ShenandoahRegionCount },\n+  {CC\"shenandoahRegionIndex\",  CC\"(Ljava\/lang\/Object;)I\", (void*)&WB_ShenandoahRegionIndex },\n+  {CC\"shenandoahOldGC\",        CC\"()Z\",                   (void*)&WB_ShenandoahOldGC },\n+#endif\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -0,0 +1,250 @@\n+package gc.shenandoah.generational;\n+\n+import java.lang.ref.Reference;\n+import java.lang.ref.WeakReference;\n+import java.lang.ref.ReferenceQueue;\n+import java.util.*;\n+import java.util.function.Supplier;\n+\n+import jdk.test.whitebox.WhiteBox;\n+\n+\/*\n+ * @test id=young\n+ * @requires vm.gc.Shenandoah\n+ * @summary Confirm that young non-strong references are collected.\n+ * @library \/testlibrary \/test\/lib \/\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:.\n+ *      -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *      -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      -XX:ShenandoahGenerationalMinTenuringAge=1 -XX:ShenandoahGenerationalMaxTenuringAge=1\n+ *      -XX:ShenandoahLearningSteps=0 -XX:ShenandoahIgnoreOldGrowthBelowPercentage=100\n+ *      -XX:-UseCompressedOops\n+ *      -Xmx128M -Xms128M -ea\n+ *      gc.shenandoah.generational.TestGenerationalReferenceProcessing young\n+ *\/\n+\n+\/*\n+ * @test id=old\n+ * @requires vm.gc.Shenandoah\n+ * @summary Confirm that young non-strong references are collected.\n+ * @library \/testlibrary \/test\/lib \/\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:.\n+ *      -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *      -XX:+UnlockExperimentalVMOptions\n+ *      -XX:+UseShenandoahGC -XX:ShenandoahGCMode=generational\n+ *      -XX:ShenandoahGenerationalMinTenuringAge=1 -XX:ShenandoahGenerationalMaxTenuringAge=1\n+ *      -XX:ShenandoahLearningSteps=0 -XX:ShenandoahIgnoreOldGrowthBelowPercentage=100\n+ *      -XX:-UseCompressedOops\n+ *      -Xmx128M -Xms128M -ea\n+ *      gc.shenandoah.generational.TestGenerationalReferenceProcessing old\n+ *\/\n+public class TestGenerationalReferenceProcessing {\n+    static final int OLD = 0;\n+    static final int YOUNG = 1;\n+\n+    private static final WhiteBox WB = WhiteBox.getWhiteBox();\n+\n+    private static class LeakedObject {}\n+\n+    private static final int REGION_SIZE = WB.shenandoahRegionSize();\n+    private static final int REGION_COUNT = WB.shenandoahRegionCount();\n+    private static final int OBJECT_SIZE = (int)WB.getObjectSize(new LeakedObject());\n+\n+    \/\/ We don't want to fill too much of the heap, or the heuristics will trigger GCs instead of our test\n+    private static final int REGIONS_TO_FILL = REGION_COUNT \/ 12;\n+    private static final int OBJECTS_PER_REGION = REGION_SIZE \/ OBJECT_SIZE \/ 2;\n+    private static final int OBJECT_COUNT = OBJECTS_PER_REGION * REGIONS_TO_FILL;\n+\n+    private static final List<WeakReference<?>> WEAK_REFS = new ArrayList<>(OBJECT_COUNT);\n+    private static final List<LeakedObject> REFERENTS = new ArrayList<>(OBJECT_COUNT);\n+    private static final ReferenceQueue<LeakedObject> refQueue = new ReferenceQueue<>();\n+\n+    private static final int MINIMUM_CROSS_GENERATIONAL_REFERENCE_COUNT = 50;\n+\n+    static class ReferenceClassifier {\n+        private final Object[][] references;\n+\n+        ReferenceClassifier() {\n+            references = new Object[][]{\n+                    {new HashSet<WeakReference<?>>(), new HashSet<WeakReference<?>>()},\n+                    {new HashSet<WeakReference<?>>(), new HashSet<WeakReference<?>>()}\n+            };\n+        }\n+\n+        void classify() {\n+            clear();\n+\n+            for (int j = 0; j < TestGenerationalReferenceProcessing.WEAK_REFS.size(); ++j) {\n+                var weakRef = TestGenerationalReferenceProcessing.WEAK_REFS.get(j);\n+                var referent = weakRef.get();\n+                if (referent != null) {\n+                    int row = WB.isObjectInOldGen(weakRef) ? OLD : YOUNG;\n+                    int column = WB.isObjectInOldGen(referent) ? OLD : YOUNG;\n+                    getReferences(row, column).add(weakRef);\n+                }\n+            }\n+        }\n+\n+        private void clear() {\n+            getReferences(OLD, OLD).clear();\n+            getReferences(OLD, YOUNG).clear();\n+            getReferences(YOUNG, OLD).clear();\n+            getReferences(YOUNG, YOUNG).clear();\n+        }\n+\n+        HashSet<WeakReference<?>> getReferences(int reference, int referent) {\n+            assert(reference == OLD || reference == YOUNG);\n+            assert(referent == OLD || referent == YOUNG);\n+            return (HashSet<WeakReference<?>>)references[reference][referent];\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return String.format(\"OO: %d, OY: %d, YO: %d, YY: %d\",\n+                    getReferences(OLD, OLD).size(), getReferences(OLD, YOUNG).size(),\n+                    getReferences(YOUNG, OLD).size(), getReferences(YOUNG, YOUNG).size());\n+        }\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        if (args.length != 1) {\n+            System.out.println(\"Call with generation to test: young|old\");\n+            return;\n+        }\n+\n+        if (\"young\".equals(args[0])) {\n+            testCollectCrossGenerationalReferents(OLD, YOUNG);\n+        } else if (\"old\".equals(args[0])) {\n+            testCollectCrossGenerationalReferents(YOUNG, OLD);\n+        }\n+    }\n+\n+    private static String name(int generation) {\n+        return generation == OLD ? \"old\" : \"young\";\n+    }\n+\n+    private static void testCollectCrossGenerationalReferents(int referenceGen, int referentGen) {\n+        ReferenceClassifier classifier = new ReferenceClassifier();\n+\n+        useMemoryUntil(() -> {\n+                classifier.classify();\n+                return classifier.getReferences(referenceGen, referentGen).size() > MINIMUM_CROSS_GENERATIONAL_REFERENCE_COUNT;\n+        });\n+\n+        assert !classifier.getReferences(referenceGen, referentGen).isEmpty() : \"Conditions for test not met: \" + classifier;\n+\n+        System.out.println(\"Before clearing all referents: \" + classifier);\n+        drainReferenceQueueAndClearReferents();\n+\n+        if (referentGen == YOUNG) {\n+            WB.youngGC();\n+        } else {\n+            \/\/ Print address of old references before old GC.\n+            var oldToOld = classifier.getReferences(referentGen, referentGen);\n+            printReferences(OLD, OLD, oldToOld);\n+            WB.shenandoahOldGC();\n+        }\n+\n+        int cleared = removeClearedWeakReferences();\n+        classifier.classify();\n+        System.out.println(\"After \" + name(referentGen) + \" GC, cleared: \" + cleared + \", referents: \" + classifier);\n+\n+        assertReferencesCleared(referentGen, referentGen, classifier);\n+        assertReferencesCleared(referenceGen, referentGen, classifier);\n+    }\n+\n+    private static void assertReferencesCleared(int referenceGen, int referentGen, ReferenceClassifier classifier) {\n+        var references = classifier.getReferences(referenceGen, referentGen);\n+        if (references.isEmpty()) {\n+            return;\n+        }\n+\n+        \/\/ Addresses here could be relocated and may not match logs from old gen collection\n+        printReferences(referenceGen, referentGen, references);\n+        throw new AssertionError(name(referenceGen) + \" to \" + name(referentGen) + \" referents should have been cleared\");\n+    }\n+\n+    private static void printReferences(int referenceGen, int referentGen, HashSet<WeakReference<?>> references) {\n+        final int max_references = 10;\n+        int references_shown = 0;\n+        for (var reference : references) {\n+            if (references_shown > max_references) {\n+                break;\n+            }\n+\n+            ++references_shown;\n+            System.out.printf(\"reference: 0x%x in %s refers to 0x%x in %s\\n\",\n+                    WB.getObjectAddress(reference), name(referenceGen),\n+                    WB.getObjectAddress(reference.get()), name(referentGen));\n+        }\n+    }\n+\n+    private static int removeClearedWeakReferences() {\n+        int cleared = 0;\n+        Reference<?> weak;\n+        while ((weak = refQueue.poll()) != null) {\n+            WEAK_REFS.remove(weak);\n+            ++cleared;\n+        }\n+        return cleared;\n+    }\n+\n+    private static void drainReferenceQueueAndClearReferents() {\n+        \/\/ Drain the reference queue of any incidental weak references from outside the test\n+        while (refQueue.poll() != null);\n+\n+        \/\/ Make all our referents unreachable now\n+        REFERENTS.clear();\n+    }\n+\n+    private static void useMemoryUntil(Supplier<Boolean> exitCondition) {\n+        \/\/ This is not an exact science here. We want to create weak references\n+        \/\/ with referents in a different region. We also don't want to allocate\n+        \/\/ everything up front, or else they will all end up in old together, and\n+        \/\/ we won't get a good mix of cross generational pointers.\n+        for (int i = 0; i < REGIONS_TO_FILL; i += 4) {\n+            allocateReferents(2);\n+            allocateReferences(2);\n+\n+            WB.youngGC();\n+            if (exitCondition.get()) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private static void allocateReferents(int regions) {\n+        for (int j = 0; j < regions; j++) {\n+            for (int i = 0; i < OBJECTS_PER_REGION; ++i) {\n+                var leakedObject = new LeakedObject();\n+                REFERENTS.add(leakedObject);\n+                byte[] garbage = new byte[OBJECT_SIZE];\n+                garbage[i % garbage.length] = (byte) i;\n+            }\n+        }\n+    }\n+\n+    private static void allocateReferences(int regions) {\n+\n+        \/\/ Fill up regions that are equal parts garbage and references\n+        \/\/ We want to create cross region references to increase the chances\n+        \/\/ of cross generational references.\n+        int referentCount = REFERENTS.size() - 1;\n+        for (int j = 0; j < regions; j++) {\n+            for (int i = 0; i < OBJECTS_PER_REGION; ++i) {\n+                var leakedObject = REFERENTS.get(referentCount - i);\n+                var ref = new WeakReference<>(leakedObject, refQueue);\n+                WEAK_REFS.add(ref);\n+                byte[] garbage = new byte[OBJECT_SIZE];\n+                garbage[i % garbage.length] = (byte) i;\n+            }\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/gc\/shenandoah\/generational\/TestGenerationalReferenceProcessing.java","additions":250,"deletions":0,"binary":false,"changes":250,"status":"added"},{"patch":"@@ -318,0 +318,7 @@\n+  \/\/ Shenandoah\n+\n+  public native int shenandoahRegionSize();\n+  public native int shenandoahRegionCount();\n+  public native int shenandoahRegionIndex(Object o);\n+  public native boolean shenandoahOldGC();\n+\n","filename":"test\/lib\/jdk\/test\/whitebox\/WhiteBox.java","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"}]}