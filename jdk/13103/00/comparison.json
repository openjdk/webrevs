{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"metaprogramming\/enableIf.hpp\"\n@@ -31,11 +32,16 @@\n-\/\/ uint32_t count_leading_zeros(T x)\n-\n-\/\/ Return the number of leading zeros in x, e.g. the zero-based index\n-\/\/ of the most significant set bit in x.  Undefined for 0.\n-\n-\/\/ We implement and support variants for 8, 16, 32 and 64 bit integral types.\n-template <typename T, size_t n> struct CountLeadingZerosImpl;\n-\n-template <typename T> unsigned count_leading_zeros(T v) {\n-  assert(v != 0, \"precondition\");\n-  return CountLeadingZerosImpl<T, sizeof(T)>::doit(v);\n+#include <type_traits>\n+\n+template <typename T>\n+struct CountLeadingZerosImpl;\n+\n+\/\/ unsigned count_leading_zeros<T>(T)\n+\/\/\n+\/\/ Precondition: x != 0.\n+\/\/\n+\/\/ Count the number of leading (starting from the MSB) zero bits in an unsigned integer. Also known\n+\/\/ as the zero-based index of the first set most significant bit.\n+template <typename T, ENABLE_IF(std::is_integral<T>::value)>\n+inline unsigned count_leading_zeros(T x) {\n+  precond(x != 0);\n+  using U = std::make_unsigned_t<T>;\n+  return CountLeadingZerosImpl<U>{}(static_cast<U>(x));\n@@ -47,1 +53,1 @@\n-#if defined(TARGET_COMPILER_gcc)\n+#if defined(TARGET_COMPILER_gcc) || defined(TARGET_COMPILER_xlc)\n@@ -49,5 +55,3 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 1> {\n-  static unsigned doit(T v) {\n-    return __builtin_clz((uint32_t)v & 0xFF) - 24u;\n-  }\n-};\n+template <typename T>\n+struct CountLeadingZerosImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned int.\n@@ -55,3 +59,2 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 2> {\n-  static unsigned doit(T v) {\n-    return __builtin_clz((uint32_t)v & 0xFFFF) - 16u;\n+  inline unsigned operator()(unsigned int x) const {\n+    return __builtin_clz(x) - ((sizeof(unsigned int) - sizeof(T)) * 8);\n@@ -59,1 +62,0 @@\n-};\n@@ -61,3 +63,2 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 4> {\n-  static unsigned doit(T v) {\n-    return __builtin_clz(v);\n+  inline unsigned operator()(unsigned long x) const {\n+    return __builtin_clzl(x);\n@@ -65,1 +66,0 @@\n-};\n@@ -67,3 +67,2 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 8> {\n-  static unsigned doit(T v) {\n-    return __builtin_clzll(v);\n+  inline unsigned operator()(unsigned long long x) const {\n+    return __builtin_clzll(x);\n@@ -79,1 +78,0 @@\n-#pragma intrinsic(_BitScanReverse)\n@@ -81,3 +79,1 @@\n-#ifdef _LP64\n-#pragma intrinsic(_BitScanReverse64)\n-#endif\n+#if defined(AARCH64)\n@@ -85,5 +81,9 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 1> {\n-  static unsigned doit(T v) {\n-    unsigned long index;\n-    _BitScanReverse(&index, (uint32_t)v & 0xFF);\n-    return 7u - index;\n+#pragma intrinsic(_CountLeadingZeros)\n+#pragma intrinsic(_CountLeadingZeros64)\n+\n+template <typename T>\n+struct CountLeadingZerosImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned long.\n+\n+  inline unsigned operator()(unsigned long x) const {\n+    return _CountLeadingZeros(x) - ((sizeof(unsigned long) - sizeof(T)) * 8);\n@@ -91,1 +91,0 @@\n-};\n@@ -93,5 +92,2 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 2> {\n-  static unsigned doit(T v) {\n-    unsigned long index;\n-    _BitScanReverse(&index, (uint32_t)v & 0xFFFF);\n-    return 15u - index;\n+  inline unsigned operator()(unsigned __int64 x) const {\n+    return _CountLeadingZeros64(x);\n@@ -101,2 +97,12 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 4> {\n-  static unsigned doit(T v) {\n+#else\n+\n+#pragma intrinsic(_BitScanReverse)\n+#ifdef _LP64\n+#pragma intrinsic(_BitScanReverse64)\n+#endif\n+\n+template <typename T>\n+struct CountLeadingZerosImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned long.\n+\n+  inline unsigned operator()(unsigned long x) const {\n@@ -104,2 +110,3 @@\n-    _BitScanReverse(&index, v);\n-    return 31u - index;\n+    unsigned char result = _BitScanReverse(&index, x);\n+    postcond(result != 0);\n+    return static_cast<unsigned>((sizeof(T) * 8 - 1) - index);\n@@ -107,1 +114,0 @@\n-};\n@@ -109,2 +115,1 @@\n-template <typename T> struct CountLeadingZerosImpl<T, 8> {\n-  static unsigned doit(T v) {\n+  inline unsigned operator()(unsigned __int64 x) const {\n@@ -113,2 +118,3 @@\n-    _BitScanReverse64(&index, v);\n-    return 63u - index;\n+    unsigned char result = _BitScanReverse64(&index, x);\n+    postcond(result != 0);\n+    return static_cast<unsigned>(63ul - index);\n@@ -116,3 +122,6 @@\n-    uint64_t high = ((uint64_t)v) >> 32ULL;\n-    if (high != 0) {\n-      return count_leading_zeros((uint32_t)high);\n+    unsigned long index;\n+    unsigned long high = static_cast<unsigned long>(x >> 32);\n+    if (high != 0ul) {\n+      unsigned char result = _BitScanReverse(&index, high);\n+      postcond(result != 0);\n+      index += 31ul;\n@@ -120,1 +129,2 @@\n-      return count_leading_zeros((uint32_t)v) + 32;\n+      unsigned char result = _BitScanReverse(&index, static_cast<unsigned long>(x));\n+      postcond(result != 0);\n@@ -122,0 +132,1 @@\n+    return static_cast<unsigned>(63ul - index);\n@@ -126,30 +137,1 @@\n-\/*****************************************************************************\n- * IBM XL C\/C++\n- *****************************************************************************\/\n-#elif defined(TARGET_COMPILER_xlc)\n-\n-#include <builtins.h>\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 1> {\n-  static unsigned doit(T v) {\n-    return __cntlz4((uint32_t)v & 0xFF) - 24u;\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 2> {\n-  static unsigned doit(T v) {\n-    return __cntlz4((uint32_t)v & 0xFFFF) - 16u;\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 4> {\n-  static unsigned doit(T v) {\n-    return __cntlz4(v);\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 8> {\n-  static unsigned doit(T v) {\n-    return __cntlz8(v);\n-  }\n-};\n+#endif\n@@ -158,1 +140,1 @@\n- * Fallback\n+ * Unknown toolchain\n@@ -162,51 +144,1 @@\n-inline uint32_t count_leading_zeros_32(uint32_t x) {\n-  assert(x != 0, \"precondition\");\n-\n-  \/\/ Efficient and portable fallback implementation:\n-  \/\/ http:\/\/graphics.stanford.edu\/~seander\/bithacks.html#IntegerLogDeBruijn\n-  \/\/ - with positions xor'd by 31 to get number of leading zeros\n-  \/\/ rather than position of highest bit.\n-  static const uint32_t MultiplyDeBruijnBitPosition[32] = {\n-      31, 22, 30, 21, 18, 10, 29,  2, 20, 17, 15, 13, 9,  6, 28,  1,\n-      23, 19, 11,  3, 16, 14,  7, 24, 12,  4,  8, 25, 5, 26, 27,  0\n-  };\n-\n-  \/\/ First round down to one less than a power of 2\n-  x |= x >> 1;\n-  x |= x >> 2;\n-  x |= x >> 4;\n-  x |= x >> 8;\n-  x |= x >> 16;\n-  \/\/ Multiply by a magic constant which ensure the highest 5 bits point to\n-  \/\/ the right index in the lookup table\n-  return MultiplyDeBruijnBitPosition[(x * 0x07c4acddu) >> 27u];\n-}\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 1> {\n-  static unsigned doit(T v) {\n-    return count_leading_zeros_32((uint32_t)v & 0xFF) - 24u;\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 2> {\n-  static unsigned doit(T v) {\n-    return count_leading_zeros_32((uint32_t)v & 0xFFFF) - 16u;\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 4> {\n-  static unsigned doit(T v) {\n-    return count_leading_zeros_32(v);\n-  }\n-};\n-\n-template <typename T> struct CountLeadingZerosImpl<T, 8> {\n-  static unsigned doit(T v) {\n-    uint64_t high = ((uint64_t)v) >> 32ULL;\n-    if (high != 0) {\n-      return count_leading_zeros_32((uint32_t)high);\n-    } else {\n-      return count_leading_zeros_32((uint32_t)v) + 32u;\n-    }\n-  }\n-};\n+#error Unknown compiler.\n","filename":"src\/hotspot\/share\/utilities\/count_leading_zeros.hpp","additions":71,"deletions":139,"binary":false,"changes":210,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,1 +32,1 @@\n-\/\/ unsigned count_trailing_zeros(T x)\n+#include <type_traits>\n@@ -34,5 +34,2 @@\n-\/\/ Return the number of trailing zeros in x, e.g. the zero-based index\n-\/\/ of the least significant set bit in x.\n-\/\/ Precondition: x != 0.\n-\n-\/\/ We implement and support variants for 8, 16, 32 and 64 bit integral types.\n+template <typename T>\n+struct CountTrailingZerosImpl;\n@@ -40,1 +37,12 @@\n-\/\/ Dispatch on toolchain to select implementation.\n+\/\/ unsigned count_trailing_zeros<T>(T)\n+\/\/\n+\/\/ Precondition: x != 0.\n+\/\/\n+\/\/ Count the number of trailing (starting from the LSB) zero bits in an unsigned integer. Also known\n+\/\/ as the zero-based index of the first set least significant bit.\n+template <typename T, ENABLE_IF(std::is_integral<T>::value)>\n+inline unsigned count_trailing_zeros(T x) {\n+  precond(x != 0);\n+  using U = std::make_unsigned_t<T>;\n+  return CountTrailingZerosImpl<U>{}(static_cast<U>(x));\n+}\n@@ -45,1 +53,1 @@\n-#if defined(TARGET_COMPILER_gcc)\n+#if defined(TARGET_COMPILER_gcc) || defined(TARGET_COMPILER_xlc)\n@@ -47,3 +55,3 @@\n-inline unsigned count_trailing_zeros_32(uint32_t x) {\n-  return __builtin_ctz(x);\n-}\n+template <typename T>\n+struct CountTrailingZerosImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned int.\n@@ -51,3 +59,12 @@\n-inline unsigned count_trailing_zeros_64(uint64_t x) {\n-  return __builtin_ctzll(x);\n-}\n+  inline unsigned operator()(unsigned int x) const {\n+    return __builtin_ctz(x);\n+  }\n+\n+  inline unsigned operator()(unsigned long x) const {\n+    return __builtin_ctzl(x);\n+  }\n+\n+  inline unsigned operator()(unsigned long long x) const {\n+    return __builtin_ctzll(x);\n+  }\n+};\n@@ -67,5 +84,10 @@\n-inline unsigned count_trailing_zeros_32(uint32_t x) {\n-  unsigned long index;\n-  _BitScanForward(&index, x);\n-  return index;\n-}\n+template <typename T>\n+struct CountTrailingZerosImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned long.\n+\n+  inline unsigned operator()(unsigned long x) const {\n+    unsigned long index;\n+    unsigned char result = _BitScanForward(&index, x);\n+    postcond(result != 0);\n+    return static_cast<unsigned>(index);\n+  }\n@@ -73,2 +95,1 @@\n-inline unsigned count_trailing_zeros_64(uint64_t x) {\n-  unsigned long index;\n+  inline unsigned operator()(unsigned __int64 x) const {\n@@ -76,1 +97,4 @@\n-  _BitScanForward64(&index, x);\n+    unsigned long index;\n+    unsigned char result = _BitScanForward64(&index, x);\n+    postcond(result != 0);\n+    return static_cast<unsigned>(index);\n@@ -78,5 +102,11 @@\n-  if (_BitScanForward(&index, static_cast<uint32_t>(x)) == 0) {\n-    \/\/ no bit found? If so, try the upper dword. Otherwise index already contains the result\n-    _BitScanForward(&index, static_cast<uint32_t>(x >> 32));\n-    index += 32;\n-  }\n+    unsigned long index;\n+    unsigned long low = static_cast<unsigned long>(x);\n+    if (low != 0ul) {\n+      unsigned char result = _BitScanForward(&index, low);\n+      postcond(result != 0);\n+    } else {\n+      unsigned char result = _BitScanForward(&index, static_cast<unsigned long>(x >> 32));\n+      postcond(result != 0);\n+      index += 32ul;\n+    }\n+    return static_cast<unsigned>(index);\n@@ -84,17 +114,2 @@\n-  return index;\n-}\n-\n-\/*****************************************************************************\n- * IBM XL C\/C++\n- *****************************************************************************\/\n-#elif defined(TARGET_COMPILER_xlc)\n-\n-#include <builtins.h>\n-\n-inline unsigned count_trailing_zeros_32(uint32_t x) {\n-  return __cnttz4(x);\n-}\n-\n-inline unsigned count_trailing_zeros_64(uint64_t x) {\n-  return __cnttz8(x);\n-}\n+  }\n+};\n@@ -106,1 +121,0 @@\n-#error Unknown TARGET_COMPILER\n@@ -108,11 +122,1 @@\n-#endif \/\/ Toolchain dispatch\n-\n-template<typename T,\n-         ENABLE_IF(std::is_integral<T>::value),\n-         ENABLE_IF(sizeof(T) <= sizeof(uint64_t))>\n-inline unsigned count_trailing_zeros(T x) {\n-  assert(x != 0, \"precondition\");\n-  return (sizeof(x) <= sizeof(uint32_t)) ?\n-         count_trailing_zeros_32(static_cast<uint32_t>(x)) :\n-         count_trailing_zeros_64(x);\n-}\n+#error Unknown toolchain.\n@@ -120,0 +124,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/utilities\/count_trailing_zeros.hpp","additions":62,"deletions":57,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,11 +34,0 @@\n-\/\/ Returns the population count of x, i.e., the number of bits set in x.\n-\/\/\n-\/\/ Adapted from Hacker's Delight, 2nd Edition, Figure 5-2 and the text that\n-\/\/ follows.\n-\/\/\n-\/\/ Ideally this should be dispatched per platform to use optimized\n-\/\/ instructions when available, such as POPCNT on modern x86\/AMD. Our builds\n-\/\/ still target and support older architectures that might lack support for\n-\/\/ these. For example, with current build configurations, __builtin_popcount(x)\n-\/\/ generate a call to a similar but slower 64-bit version when calling with\n-\/\/ a 32-bit integer type.\n@@ -46,0 +35,6 @@\n+struct PopulationCountImpl;\n+\n+\/\/ unsigned population_count<T>(T)\n+\/\/\n+\/\/ Counts the number of set bits in the value of unsigned integer type T.\n+template <typename T, ENABLE_IF(std::is_integral<T>::value)>\n@@ -47,21 +42,2 @@\n-  STATIC_ASSERT(BitsPerWord <= 128);\n-  STATIC_ASSERT(BitsPerByte == 8);\n-  STATIC_ASSERT(std::is_integral<T>::value);\n-  STATIC_ASSERT(!std::is_signed<T>::value);\n-  \/\/ We need to take care with implicit integer promotion when dealing with\n-  \/\/ integers < 32-bit. We chose to do this by explicitly widening constants\n-  \/\/ to unsigned\n-  using P = std::conditional_t<(sizeof(T) < sizeof(unsigned)), unsigned, T>;\n-  const T all = ~T(0);           \/\/ 0xFF..FF\n-  const P fives = all\/3;         \/\/ 0x55..55\n-  const P threes = (all\/15) * 3; \/\/ 0x33..33\n-  const P z_ones = all\/255;      \/\/ 0x0101..01\n-  const P z_effs = z_ones * 15;  \/\/ 0x0F0F..0F\n-  P r = x;\n-  r -= ((r >> 1) & fives);\n-  r = (r & threes) + ((r >> 2) & threes);\n-  r = ((r + (r >> 4)) & z_effs) * z_ones;\n-  \/\/ The preceding multiply by z_ones is the only place where the intermediate\n-  \/\/ calculations can exceed the range of T. We need to discard any such excess\n-  \/\/ before the right-shift, hence the conversion back to T.\n-  return static_cast<T>(r) >> (((sizeof(T) - 1) * BitsPerByte));\n+  using U = std::make_unsigned_t<T>;\n+  return PopulationCountImpl<U>{}(static_cast<U>(x));\n@@ -70,0 +46,116 @@\n+\/*****************************************************************************\n+ * Fallback\n+ *****************************************************************************\/\n+\n+template <typename T>\n+struct PopulationCountFallbackImpl {\n+  \/\/ Adapted from Hacker's Delight, 2nd Edition, Figure 5-2 and the text that\n+  \/\/ follows.\n+  inline unsigned operator()(T x) const {\n+    \/\/ We need to take care with implicit integer promotion when dealing with\n+    \/\/ integers < 32-bit. We chose to do this by explicitly widening constants\n+    \/\/ to unsigned\n+    using P = std::conditional_t<(sizeof(T) < sizeof(unsigned)), unsigned, T>;\n+    constexpr T all = ~T(0);           \/\/ 0xFF..FF\n+    constexpr P fives = all\/3;         \/\/ 0x55..55\n+    constexpr P threes = (all\/15) * 3; \/\/ 0x33..33\n+    constexpr P z_ones = all\/255;      \/\/ 0x0101..01\n+    constexpr P z_effs = z_ones * 15;  \/\/ 0x0F0F..0F\n+    P r = x;\n+    r -= ((r >> 1) & fives);\n+    r = (r & threes) + ((r >> 2) & threes);\n+    r = ((r + (r >> 4)) & z_effs) * z_ones;\n+    \/\/ The preceding multiply by z_ones is the only place where the intermediate\n+    \/\/ calculations can exceed the range of T. We need to discard any such excess\n+    \/\/ before the right-shift, hence the conversion back to T.\n+    return static_cast<T>(r) >> (((sizeof(T) - 1) * 8));\n+  }\n+};\n+\n+\/*****************************************************************************\n+ * GCC and compatible (including Clang)\n+ *****************************************************************************\/\n+#if defined(TARGET_COMPILER_gcc) || defined(TARGET_TOOLCHAIN_xlc)\n+\n+#if defined(__clang__) || defined(ASSERT)\n+\n+\/\/ Unlike GCC, Clang is willing to inline the generic implementation of __builtin_popcount when\n+\/\/ architecture support is unavailable in -O2. This ensures we avoid the function call to libgcc.\n+\/\/ Clang is able to recognize the fallback implementation as byteswapping, but not on every\n+\/\/ architecture unlike GCC. This suggests the optimization pass for GCC that recognizes byteswapping\n+\/\/ is architecture agnostic, while for Clang it is not.\n+\n+template <typename T>\n+struct PopulationCountImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned int.\n+\n+  inline unsigned operator()(unsigned int x) const {\n+    return __builtin_popcount(x);\n+  }\n+\n+  inline unsigned operator()(unsigned long x) const {\n+    return __builtin_popcountl(x);\n+  }\n+\n+  inline unsigned operator()(unsigned long long x) const {\n+    return __builtin_popcountll(x);\n+  }\n+};\n+\n+#else\n+\n+\/\/ We do not use __builtin_popcount and friends for GCC in release builds. Unfortunately on\n+\/\/ architectures that do not have a popcount instruction, GCC emits a function call to libgcc\n+\/\/ regardless of optimization options, even when the generic implementation is, for example, less\n+\/\/ than 20 instructions. GCC is however able to recognize the fallback as popcount regardless of\n+\/\/ architecture and appropriately replaces the code in -O2 with the appropriate\n+\/\/ architecture-specific byteswap instruction, if available. If it is not available, GCC emits the\n+\/\/ exact same implementation that underpins its __builtin_bswap in libgcc as there is really only\n+\/\/ one way to implement it, as we have in fallback.\n+\n+template <typename T>\n+struct PopulationCountImpl : public PopulationCountFallbackImpl<T> {};\n+\n+#endif\n+\n+\/*****************************************************************************\n+ * Microsoft Visual Studio\n+ *****************************************************************************\/\n+#elif defined(TARGET_COMPILER_visCPP)\n+\n+#if defined(AARCH64)\n+\n+#include <intrin.h>\n+\n+#pragma intrinsic(_CountOneBits)\n+#pragma intrinsic(_CountOneBits64)\n+\n+template <typename T>\n+struct PopulationCountImpl {\n+  \/\/ Smaller integer types will be handled via integer promotion to unsigned long.\n+\n+  inline unsigned operator()(unsigned long x) const {\n+    return _CountOneBits(x);\n+  }\n+\n+  inline unsigned operator()(unsigned __int64 x) const {\n+    return _CountOneBits64(x);\n+  }\n+};\n+\n+#else\n+\n+template <typename T>\n+struct PopulationCountImpl : public PopulationCountFallbackImpl<T> {};\n+\n+#endif\n+\n+\/*****************************************************************************\n+ * Unknown toolchain\n+ *****************************************************************************\/\n+#else\n+\n+#error Unknown toolchain.\n+\n+#endif\n+\n","filename":"src\/hotspot\/share\/utilities\/population_count.hpp","additions":125,"deletions":33,"binary":false,"changes":158,"status":"modified"}]}