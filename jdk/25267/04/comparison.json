{"files":[{"patch":"@@ -68,0 +68,1 @@\n+#include \"oops\/jmethodIDTable.hpp\"\n@@ -581,0 +582,26 @@\n+void ClassLoaderData::add_jmethod_id(jmethodID mid) {\n+  MutexLocker m1(metaspace_lock(), Mutex::_no_safepoint_check_flag);\n+  if (_jmethod_ids == nullptr) {\n+    _jmethod_ids = new (mtClass) GrowableArray<jmethodID>(32, mtClass);\n+  }\n+  _jmethod_ids->push(mid);\n+}\n+\n+\/\/ Method::remove_jmethod_ids removes jmethodID entries from the table which\n+\/\/ releases memory.\n+\/\/ Because native code (e.g., JVMTI agent) holding jmethod_ids may access them\n+\/\/ after the associated classes and class loader are unloaded, subsequent lookups\n+\/\/ for these ids will return null since they are no longer found in the table.\n+\/\/ The Java Native Interface Specification says \"method ID\n+\/\/ does not prevent the VM from unloading the class from which the ID has\n+\/\/ been derived. After the class is unloaded, the method or field ID becomes\n+\/\/ invalid\".\n+void ClassLoaderData::remove_jmethod_ids() {\n+  MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+  for (int i = 0; i < _jmethod_ids->length(); i++) {\n+    jmethodID mid = _jmethod_ids->at(i);\n+    JmethodIDTable::remove(mid);\n+  }\n+  delete _jmethod_ids;\n+}\n+\n@@ -602,11 +629,0 @@\n-  \/\/ Method::clear_jmethod_ids only sets the jmethod_ids to null without\n-  \/\/ releasing the memory for related JNIMethodBlocks and JNIMethodBlockNodes.\n-  \/\/ This is done intentionally because native code (e.g. JVMTI agent) holding\n-  \/\/ jmethod_ids may access them after the associated classes and class loader\n-  \/\/ are unloaded. The Java Native Interface Specification says \"method ID\n-  \/\/ does not prevent the VM from unloading the class from which the ID has\n-  \/\/ been derived. After the class is unloaded, the method or field ID becomes\n-  \/\/ invalid\". In real world usages, the native code may rely on jmethod_ids\n-  \/\/ being null after class unloading. Hence, it is unsafe to free the memory\n-  \/\/ from the VM side without knowing when native code is going to stop using\n-  \/\/ them.\n@@ -614,1 +630,1 @@\n-    Method::clear_jmethod_ids(this);\n+    remove_jmethod_ids();\n@@ -1040,3 +1056,1 @@\n-    out->print   (\" - jmethod count       \");\n-    Method::print_jmethod_ids_count(this, out);\n-    out->print_cr(\"\");\n+    out->print_cr(\" - jmethod count       %d\", _jmethod_ids->length());\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":29,"deletions":15,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,1 +56,0 @@\n-class JNIMethodBlock;\n@@ -146,4 +145,3 @@\n-  \/\/ These method IDs are created for the class loader and set to null when the\n-  \/\/ class loader is unloaded.  They are rarely freed, only for redefine classes\n-  \/\/ and if they lose a data race in InstanceKlass.\n-  JNIMethodBlock*                  _jmethod_ids;\n+  \/\/ These method IDs are created for the class loader and removed when the\n+  \/\/ class loader is unloaded.\n+  GrowableArray<jmethodID>*        _jmethod_ids;\n@@ -319,2 +317,3 @@\n-  JNIMethodBlock* jmethod_ids() const              { return _jmethod_ids; }\n-  void set_jmethod_ids(JNIMethodBlock* new_block)  { _jmethod_ids = new_block; }\n+  void add_jmethod_id(jmethodID id);\n+  void remove_jmethod_ids();\n+  GrowableArray<jmethodID>* jmethod_ids() const { return _jmethod_ids; }\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.hpp","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+#include \"oops\/jmethodIDTable.hpp\"\n@@ -439,0 +440,3 @@\n+    \/\/ Initialize table for matching jmethodID, before SystemDictionary\n+    JmethodIDTable::initialize();\n+\n@@ -447,1 +451,0 @@\n-\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -61,0 +61,1 @@\n+  f(mtJNI,            \"JNI\")                                                         \\\n","filename":"src\/hotspot\/share\/nmt\/memTag.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2394,0 +2394,18 @@\n+\/\/ Allocate the jmethodID cache.\n+static jmethodID* create_jmethod_id_cache(size_t size) {\n+  jmethodID* jmeths = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n+  memset(jmeths, 0, (size + 1) * sizeof(jmethodID));\n+  \/\/ cache size is stored in element[0], other elements offset by one\n+  jmeths[0] = (jmethodID)size;\n+  return jmeths;\n+}\n+\n+\/\/ When reading outside a lock, use this.\n+jmethodID* InstanceKlass::methods_jmethod_ids_acquire() const {\n+  return Atomic::load_acquire(&_methods_jmethod_ids);\n+}\n+\n+void InstanceKlass::release_set_methods_jmethod_ids(jmethodID* jmeths) {\n+  Atomic::release_store(&_methods_jmethod_ids, jmeths);\n+}\n+\n@@ -2395,6 +2413,1 @@\n-\/\/ This code is called by the VMThread and JavaThreads so the\n-\/\/ locking has to be done very carefully to avoid deadlocks\n-\/\/ and\/or other cache consistency problems.\n-\/\/\n-jmethodID InstanceKlass::get_jmethod_id(const methodHandle& method_h) {\n-  Method* method = method_h();\n+jmethodID InstanceKlass::get_jmethod_id(Method* method) {\n@@ -2421,1 +2434,1 @@\n-    jmeths = methods_jmethod_ids_acquire();\n+    jmeths = _methods_jmethod_ids;\n@@ -2459,4 +2472,1 @@\n-      jmethodID* new_cache = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n-      memset(new_cache, 0, (size + 1) * sizeof(jmethodID));\n-      \/\/ The cache size is stored in element[0]; the other elements are offset by one.\n-      new_cache[0] = (jmethodID)size;\n+      jmethodID* new_cache = create_jmethod_id_cache(size);\n@@ -2473,3 +2483,2 @@\n-\/\/ Figure out how many jmethodIDs haven't been allocated, and make\n-\/\/ sure space for them is pre-allocated.  This makes getting all\n-\/\/ method ids much, much faster with classes with more than 8\n+\/\/ Make a jmethodID for all methods in this class.\n+\/\/ This makes getting all method ids much, much faster with classes with more than 8\n@@ -2478,2 +2487,8 @@\n-void InstanceKlass::ensure_space_for_methodids(int start_offset) {\n-  int new_jmeths = 0;\n+void InstanceKlass::make_methods_jmethod_ids() {\n+  MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+  jmethodID* jmeths = _methods_jmethod_ids;\n+  if (jmeths == nullptr) {\n+    jmeths = create_jmethod_id_cache(idnum_allocated_count());\n+    release_set_methods_jmethod_ids(jmeths);\n+  }\n+\n@@ -2481,1 +2496,1 @@\n-  for (int index = start_offset; index < length; index++) {\n+  for (int index = 0; index < length; index++) {\n@@ -2483,3 +2498,7 @@\n-    jmethodID id = m->find_jmethod_id_or_null();\n-    if (id == nullptr) {\n-      new_jmeths++;\n+    int idnum = m->method_idnum();\n+    assert(!m->is_old(), \"should not have old methods or I'm confused\");\n+    jmethodID id = Atomic::load_acquire(&jmeths[idnum + 1]);\n+    if (!m->is_overpass() &&  \/\/ skip overpasses\n+        id == nullptr) {\n+      id = Method::make_jmethod_id(class_loader_data(), m);\n+      Atomic::release_store(&jmeths[idnum + 1], id);\n@@ -2488,3 +2507,0 @@\n-  if (new_jmeths != 0) {\n-    Method::ensure_jmethod_ids(class_loader_data(), new_jmeths);\n-  }\n@@ -2917,1 +2933,1 @@\n-  jmethodID* jmeths = methods_jmethod_ids_acquire();\n+  jmethodID* jmeths = _methods_jmethod_ids;\n@@ -4264,8 +4280,4 @@\n-\/\/ This nulls out jmethodIDs for all methods in 'klass'\n-\/\/ It needs to be called explicitly for all previous versions of a class because these may not be cleaned up\n-\/\/ during class unloading.\n-\/\/ We can not use the jmethodID cache associated with klass directly because the 'previous' versions\n-\/\/ do not have the jmethodID cache filled in. Instead, we need to lookup jmethodID for each method and this\n-\/\/ is expensive - O(n) for one jmethodID lookup. For all contained methods it is O(n^2).\n-\/\/ The reason for expensive jmethodID lookup for each method is that there is no direct link between method and jmethodID.\n-void InstanceKlass::clear_jmethod_ids(InstanceKlass* klass) {\n+\/\/ This nulls out jmethodIDs for all obsolete methods in the previous version of the 'klass'\n+\/\/ These obsolete methods only exist in the previous version and we're about to delete the memory for them.\n+\/\/ The jmethodID for these are deallocated when we unload the class, so this doesn't remove them from the table.\n+void InstanceKlass::clear_obsolete_jmethod_ids(InstanceKlass* klass) {\n@@ -4275,0 +4287,1 @@\n+    \/\/ Only need to clear obsolete methods.\n@@ -4324,1 +4337,1 @@\n-      clear_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n+      clear_obsolete_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":46,"deletions":33,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -780,2 +780,2 @@\n-  jmethodID get_jmethod_id(const methodHandle& method_h);\n-  void ensure_space_for_methodids(int start_offset = 0);\n+  jmethodID get_jmethod_id(Method* method);\n+  void make_methods_jmethod_ids();\n@@ -1055,4 +1055,4 @@\n-  inline jmethodID* methods_jmethod_ids_acquire() const;\n-  inline void release_set_methods_jmethod_ids(jmethodID* jmeths);\n-  \/\/ This nulls out jmethodIDs for all methods in 'klass'\n-  static void clear_jmethod_ids(InstanceKlass* klass);\n+  jmethodID* methods_jmethod_ids_acquire() const;\n+  void release_set_methods_jmethod_ids(jmethodID* jmeths);\n+  \/\/ This nulls out obsolete jmethodIDs for all methods in 'klass'.\n+  static void clear_obsolete_jmethod_ids(InstanceKlass* klass);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -74,8 +74,0 @@\n-inline jmethodID* InstanceKlass::methods_jmethod_ids_acquire() const {\n-  return Atomic::load_acquire(&_methods_jmethod_ids);\n-}\n-\n-inline void InstanceKlass::release_set_methods_jmethod_ids(jmethodID* jmeths) {\n-  Atomic::release_store(&_methods_jmethod_ids, jmeths);\n-}\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.inline.hpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,186 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"logging\/log.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"oops\/jmethodIDTable.hpp\"\n+#include \"oops\/method.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"utilities\/concurrentHashTable.inline.hpp\"\n+#include \"utilities\/concurrentHashTableTasks.inline.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+\/\/ Save (jmethod, Method*) in a hashtable to lookup Method.\n+\/\/ The CHT is for performance because it has lock free lookup.\n+\n+static uint64_t _jmethodID_counter = 0;\n+\n+class JmethodEntry {\n+ public:\n+  uint64_t _id;\n+  Method*  _method;\n+\n+  JmethodEntry(uint64_t id, Method* method) : _id(id), _method(method) {}\n+};\n+\n+class JmethodIDTableConfig : public AllStatic {\n+ public:\n+  typedef JmethodEntry Value;\n+  static void* allocate_node(void* context, size_t size, Value const& value) {\n+    return AllocateHeap(size, mtJNI);\n+  }\n+  static void free_node(void* context, void* memory, Value const& value) {\n+    FreeHeap(memory);\n+  }\n+  static uintx get_hash(Value const& value, bool* is_dead) {\n+    *is_dead = false;\n+    return value._id;\n+  }\n+  static bool is_dead(Value const& value) {\n+    return false;\n+  }\n+};\n+\n+using MethodIdTable = ConcurrentHashTable<JmethodIDTableConfig, mtJNI>;\n+static MethodIdTable* _jmethod_id_table = nullptr;\n+\n+void JmethodIDTable::initialize() {\n+  const size_t start_size = 10;\n+  \/\/ 2^24 is max size\n+  const size_t end_size = 24;\n+  \/\/ If a chain gets to 32 something might be wrong.\n+  const size_t grow_hint = 32;\n+\n+  _jmethod_id_table  = new MethodIdTable(start_size, end_size, grow_hint);\n+}\n+\n+class JmethodIDLookup : StackObj {\n+ private:\n+  uint64_t _mid;\n+\n+ public:\n+  JmethodIDLookup(const uint64_t mid) : _mid(mid) {}\n+  uintx get_hash() const {\n+    return _mid;\n+  }\n+  bool equals(JmethodEntry* value) {\n+    return _mid == value->_id;\n+  }\n+\n+  bool is_dead(JmethodEntry* value) {\n+    return false;\n+  }\n+};\n+\n+static JmethodEntry* get_jmethod_entry(jmethodID mid) {\n+  assert(mid != nullptr, \"JNI method id should not be null\");\n+\n+  Thread* current = Thread::current();\n+  JmethodIDLookup lookup((uint64_t)mid);\n+  JmethodEntry* result = nullptr;\n+  auto get = [&] (JmethodEntry* value) {\n+    \/\/ function called if value is found so is never null\n+    result = value;\n+  };\n+  bool needs_rehashing = false;\n+  _jmethod_id_table->get(current, lookup, get, &needs_rehashing);\n+  assert(!needs_rehashing, \"should never need rehashing\");\n+  return result;\n+}\n+\n+Method* JmethodIDTable::resolve_jmethod_id(jmethodID mid) {\n+  JmethodEntry* result = get_jmethod_entry(mid);\n+  return result == nullptr ? nullptr : result->_method;\n+}\n+\n+const unsigned _resize_load_trigger = 5;       \/\/ load factor that will trigger the resize\n+\n+static unsigned table_size(Thread* current) {\n+  return 1 << _jmethod_id_table->get_size_log2(current);\n+}\n+\n+static bool needs_resize(Thread* current) {\n+  return ((_jmethodID_counter > (_resize_load_trigger * table_size(current))) &&\n+         !_jmethod_id_table->is_max_size_reached());\n+}\n+\n+\/\/ Add a method id to the jmethod_ids.\n+jmethodID JmethodIDTable::make_jmethod_id(Method* m) {\n+  bool grow_hint, clean_hint;\n+\n+  assert_locked_or_safepoint(JmethodIdCreation_lock);\n+  \/\/ Update jmethodID global counter.\n+  _jmethodID_counter++;\n+  guarantee(_jmethodID_counter != 0, \"must never go back to zero\");\n+\n+  JmethodEntry new_entry(_jmethodID_counter, m);\n+  Thread* current = Thread::current();\n+  JmethodIDLookup lookup(_jmethodID_counter);\n+  bool created = _jmethod_id_table->insert(current, lookup, new_entry, &grow_hint, &clean_hint);\n+  assert(created, \"must be\");\n+  log_debug(jmethod)(\"Inserted jmethod id \" UINT64_FORMAT_X, _jmethodID_counter);\n+\n+  \/\/ Resize table if it needs to grow.  The _jmethod_id_table has a good distribution.\n+  if (needs_resize(current)) {\n+    _jmethod_id_table->grow(current);\n+    log_info(jmethod)(\"Growing table to %d for \" UINT64_FORMAT \" entries\", table_size(current), _jmethodID_counter);\n+  }\n+  return (jmethodID)_jmethodID_counter;\n+}\n+\n+void JmethodIDTable::remove(jmethodID jmid) {\n+  assert_locked_or_safepoint(JmethodIdCreation_lock);\n+  JmethodIDLookup lookup((uint64_t)jmid);\n+  Thread* current = Thread::current();\n+  JmethodEntry* result;\n+  auto get = [&] (JmethodEntry* value) {\n+    \/\/ The function that is called if value is found, so is never null.\n+    result = value;\n+  };\n+  bool removed = _jmethod_id_table->remove(current, lookup, get);\n+  assert(removed, \"must be\");\n+  log_debug(jmethod)(\"Removed jmethod id \" UINT64_FORMAT_X, (uint64_t)jmid);\n+}\n+\n+void JmethodIDTable::change_method_associated_with_jmethod_id(jmethodID jmid, Method* new_method) {\n+  assert_locked_or_safepoint(JmethodIdCreation_lock);\n+  JmethodEntry* result = get_jmethod_entry(jmid);\n+  \/\/ Change table entry to point to the new method.\n+  log_debug(jmethod)(\"Changed jmethod id \" UINT64_FORMAT_X \" from \" PTR_FORMAT \" to \" PTR_FORMAT, (uint64_t)jmid,\n+                     p2i(result->_method), p2i(new_method));\n+  result->_method = new_method;\n+}\n+\n+void JmethodIDTable::clear_jmethod_id(jmethodID jmid, Method* obsolete_method) {\n+  assert_locked_or_safepoint(JmethodIdCreation_lock);\n+  JmethodEntry* result = get_jmethod_entry(jmid);\n+  \/\/ We need to make sure that jmethodID actually resolves to this method\n+  \/\/ - multiple redefined versions may share jmethodID slots and if a method\n+  \/\/   has already been rewired to a newer version we could be clearing reference\n+  \/\/   to a still existing method instance.\n+  if (result->_method == obsolete_method) {\n+    result->_method = nullptr;\n+  }\n+}\n","filename":"src\/hotspot\/share\/oops\/jmethodIDTable.cpp","additions":186,"deletions":0,"binary":false,"changes":186,"status":"added"},{"patch":"@@ -0,0 +1,53 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_OOPS_JMETHODIDTABLE_HPP\n+#define SHARE_OOPS_JMETHODIDTABLE_HPP\n+\n+#include \"jni.h\"\n+#include \"memory\/allocation.hpp\"\n+\n+\/\/ Class for associating Method with jmethodID\n+class Method;\n+\n+class JmethodIDTable : public AllStatic {\n+ public:\n+  static void initialize();\n+\n+  \/\/ Given a Method return a jmethodID.\n+  static jmethodID make_jmethod_id(Method* m);\n+\n+  \/\/ Given a jmethodID, return a Method.\n+  static Method* resolve_jmethod_id(jmethodID mid);\n+\n+  \/\/ Class unloading support, remove the associations from the tables.  Stale jmethodID will\n+  \/\/ not be found and return null.\n+  static void remove(jmethodID mid);\n+\n+  \/\/ RedefineClasses support\n+  static void change_method_associated_with_jmethod_id(jmethodID jmid, Method* new_method);\n+  static void clear_jmethod_id(jmethodID jmid, Method* m);\n+};\n+\n+#endif \/\/ SHARE_OOPS_JMETHODIDTABLE_HPP\n","filename":"src\/hotspot\/share\/oops\/jmethodIDTable.hpp","additions":53,"deletions":0,"binary":false,"changes":53,"status":"added"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"oops\/jmethodIDTable.hpp\"\n@@ -2062,146 +2063,3 @@\n-\n-\/\/ This is a block allocating object, sort of like JNIHandleBlock, only a\n-\/\/ lot simpler.\n-\/\/ It's allocated on the CHeap because once we allocate a jmethodID, we can\n-\/\/ never get rid of it.\n-\n-static const int min_block_size = 8;\n-\n-class JNIMethodBlockNode : public CHeapObj<mtClass> {\n-  friend class JNIMethodBlock;\n-  Method**        _methods;\n-  int             _number_of_methods;\n-  int             _top;\n-  JNIMethodBlockNode* _next;\n-\n- public:\n-\n-  JNIMethodBlockNode(int num_methods = min_block_size);\n-\n-  ~JNIMethodBlockNode() { FREE_C_HEAP_ARRAY(Method*, _methods); }\n-\n-  void ensure_methods(int num_addl_methods) {\n-    if (_top < _number_of_methods) {\n-      num_addl_methods -= _number_of_methods - _top;\n-      if (num_addl_methods <= 0) {\n-        return;\n-      }\n-    }\n-    if (_next == nullptr) {\n-      _next = new JNIMethodBlockNode(MAX2(num_addl_methods, min_block_size));\n-    } else {\n-      _next->ensure_methods(num_addl_methods);\n-    }\n-  }\n-};\n-\n-class JNIMethodBlock : public CHeapObj<mtClass> {\n-  JNIMethodBlockNode _head;\n-  JNIMethodBlockNode *_last_free;\n- public:\n-  static Method* const _free_method;\n-\n-  JNIMethodBlock(int initial_capacity = min_block_size)\n-      : _head(initial_capacity), _last_free(&_head) {}\n-\n-  void ensure_methods(int num_addl_methods) {\n-    _last_free->ensure_methods(num_addl_methods);\n-  }\n-\n-  Method** add_method(Method* m) {\n-    for (JNIMethodBlockNode* b = _last_free; b != nullptr; b = b->_next) {\n-      if (b->_top < b->_number_of_methods) {\n-        \/\/ top points to the next free entry.\n-        int i = b->_top;\n-        b->_methods[i] = m;\n-        b->_top++;\n-        _last_free = b;\n-        return &(b->_methods[i]);\n-      } else if (b->_top == b->_number_of_methods) {\n-        \/\/ if the next free entry ran off the block see if there's a free entry\n-        for (int i = 0; i < b->_number_of_methods; i++) {\n-          if (b->_methods[i] == _free_method) {\n-            b->_methods[i] = m;\n-            _last_free = b;\n-            return &(b->_methods[i]);\n-          }\n-        }\n-        \/\/ Only check each block once for frees.  They're very unlikely.\n-        \/\/ Increment top past the end of the block.\n-        b->_top++;\n-      }\n-      \/\/ need to allocate a next block.\n-      if (b->_next == nullptr) {\n-        b->_next = _last_free = new JNIMethodBlockNode();\n-      }\n-    }\n-    guarantee(false, \"Should always allocate a free block\");\n-    return nullptr;\n-  }\n-\n-  bool contains(Method** m) {\n-    if (m == nullptr) return false;\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      if (b->_methods <= m && m < b->_methods + b->_number_of_methods) {\n-        \/\/ This is a bit of extra checking, for two reasons.  One is\n-        \/\/ that contains() deals with pointers that are passed in by\n-        \/\/ JNI code, so making sure that the pointer is aligned\n-        \/\/ correctly is valuable.  The other is that <= and > are\n-        \/\/ technically not defined on pointers, so the if guard can\n-        \/\/ pass spuriously; no modern compiler is likely to make that\n-        \/\/ a problem, though (and if one did, the guard could also\n-        \/\/ fail spuriously, which would be bad).\n-        ptrdiff_t idx = m - b->_methods;\n-        if (b->_methods + idx == m) {\n-          return true;\n-        }\n-      }\n-    }\n-    return false;  \/\/ not found\n-  }\n-\n-  \/\/ During class unloading the methods are cleared, which is different\n-  \/\/ than freed.\n-  void clear_all_methods() {\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      for (int i = 0; i< b->_number_of_methods; i++) {\n-        b->_methods[i] = nullptr;\n-      }\n-    }\n-  }\n-#ifndef PRODUCT\n-  int count_methods() {\n-    \/\/ count all allocated methods\n-    int count = 0;\n-    for (JNIMethodBlockNode* b = &_head; b != nullptr; b = b->_next) {\n-      for (int i = 0; i< b->_number_of_methods; i++) {\n-        if (b->_methods[i] != _free_method) count++;\n-      }\n-    }\n-    return count;\n-  }\n-#endif \/\/ PRODUCT\n-};\n-\n-\/\/ Something that can't be mistaken for an address or a markWord\n-Method* const JNIMethodBlock::_free_method = (Method*)55;\n-\n-JNIMethodBlockNode::JNIMethodBlockNode(int num_methods) : _top(0), _next(nullptr) {\n-  _number_of_methods = MAX2(num_methods, min_block_size);\n-  _methods = NEW_C_HEAP_ARRAY(Method*, _number_of_methods, mtInternal);\n-  for (int i = 0; i < _number_of_methods; i++) {\n-    _methods[i] = JNIMethodBlock::_free_method;\n-  }\n-}\n-\n-void Method::ensure_jmethod_ids(ClassLoaderData* cld, int capacity) {\n-  \/\/ Have to add jmethod_ids() to class loader data thread-safely.\n-  \/\/ Also have to add the method to the list safely, which the lock\n-  \/\/ protects as well.\n-  MutexLocker ml(JmethodIdCreation_lock,  Mutex::_no_safepoint_check_flag);\n-  if (cld->jmethod_ids() == nullptr) {\n-    cld->set_jmethod_ids(new JNIMethodBlock(capacity));\n-  } else {\n-    cld->jmethod_ids()->ensure_methods(capacity);\n-  }\n-}\n+\/\/ jmethodIDs are 64-bit integers that will never run out and are mapped in a table\n+\/\/ to their Method and vice versa.  If JNI code has access to stale jmethodID, this\n+\/\/ wastes no memory but the Method* returned is null.\n@@ -2212,1 +2070,1 @@\n-  \/\/ Also have to add the method to the list safely, which the lock\n+  \/\/ Also have to add the method to the InstanceKlass list safely, which the lock\n@@ -2215,0 +2073,2 @@\n+  jmethodID jmid = JmethodIDTable::make_jmethod_id(m);\n+  assert(jmid != nullptr, \"must be created\");\n@@ -2216,7 +2076,3 @@\n-  ResourceMark rm;\n-  log_debug(jmethod)(\"Creating jmethodID for Method %s\", m->external_name());\n-  if (cld->jmethod_ids() == nullptr) {\n-    cld->set_jmethod_ids(new JNIMethodBlock());\n-  }\n-  \/\/ jmethodID is a pointer to Method*\n-  return (jmethodID)cld->jmethod_ids()->add_method(m);\n+  \/\/ Add to growable array in CLD.\n+  cld->add_jmethod_id(jmid);\n+  return jmid;\n@@ -2225,0 +2081,1 @@\n+\/\/ This looks in the InstanceKlass cache, then calls back to make_jmethod_id if not found.\n@@ -2226,2 +2083,7 @@\n-  methodHandle mh(Thread::current(), this);\n-  return method_holder()->get_jmethod_id(mh);\n+  return method_holder()->get_jmethod_id(this);\n+}\n+\n+\/\/ Get the Method out of the table given the method id.\n+Method* Method::resolve_jmethod_id(jmethodID mid) {\n+  assert(mid != nullptr, \"JNI method id should not be null\");\n+  return JmethodIDTable::resolve_jmethod_id(mid);\n@@ -2235,1 +2097,1 @@\n-           new_method->method_holder()->class_loader() == nullptr, \/\/ allow Unsafe substitution\n+         new_method->method_holder()->class_loader() == nullptr, \/\/ allow substitution to Unsafe method\n@@ -2237,2 +2099,1 @@\n-  \/\/ Just change the method in place, jmethodID pointer doesn't change.\n-  *((Method**)jmid) = new_method;\n+  JmethodIDTable::change_method_associated_with_jmethod_id(jmid, new_method);\n@@ -2241,1 +2102,11 @@\n-bool Method::is_method_id(jmethodID mid) {\n+\/\/ If there's a jmethodID for this method, clear the Method\n+\/\/ but leave jmethodID for this method in the table.\n+\/\/ It's deallocated with class unloading.\n+void Method::clear_jmethod_id() {\n+  jmethodID mid = method_holder()->jmethod_id_or_null(this);\n+  if (mid != nullptr) {\n+    JmethodIDTable::clear_jmethod_id(mid, this);\n+  }\n+}\n+\n+bool Method::validate_jmethod_id(jmethodID mid) {\n@@ -2247,1 +2118,1 @@\n-  return (cld->jmethod_ids()->contains((Method**)mid));\n+  return (cld->jmethod_ids()->contains(mid));\n@@ -2253,1 +2124,1 @@\n-  if (o == nullptr || o == JNIMethodBlock::_free_method) {\n+  if (o == nullptr) {\n@@ -2262,1 +2133,1 @@\n-};\n+}\n@@ -2283,19 +2154,0 @@\n-\/\/ Called when the class loader is unloaded to make all methods weak.\n-void Method::clear_jmethod_ids(ClassLoaderData* loader_data) {\n-  loader_data->jmethod_ids()->clear_all_methods();\n-}\n-\n-void Method::clear_jmethod_id() {\n-  \/\/ Being at a safepoint prevents racing against other class redefinitions\n-  assert(SafepointSynchronize::is_at_safepoint(), \"should be at safepoint\");\n-  \/\/ The jmethodID is not stored in the Method instance, we need to look it up first\n-  jmethodID methodid = find_jmethod_id_or_null();\n-  \/\/ We need to make sure that jmethodID actually resolves to this method\n-  \/\/ - multiple redefined versions may share jmethodID slots and if a method\n-  \/\/   has already been rewired to a newer version we could be removing reference\n-  \/\/   to a still existing method instance\n-  if (methodid != nullptr && *((Method**)methodid) == this) {\n-    *((Method**)methodid) = nullptr;\n-  }\n-}\n-\n@@ -2326,7 +2178,0 @@\n-#ifndef PRODUCT\n-void Method::print_jmethod_ids_count(const ClassLoaderData* loader_data, outputStream* out) {\n-  out->print(\"%d\", loader_data->jmethod_ids()->count_methods());\n-}\n-#endif \/\/ PRODUCT\n-\n-\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":34,"deletions":189,"binary":false,"changes":223,"status":"modified"},{"patch":"@@ -707,5 +707,0 @@\n-  \/\/ Ensure there is enough capacity in the internal tracking data\n-  \/\/ structures to hold the number of jmethodIDs you plan to generate.\n-  \/\/ This saves substantial time doing allocations.\n-  static void ensure_jmethod_ids(ClassLoaderData* cld, int capacity);\n-\n@@ -715,4 +710,1 @@\n-  inline static Method* resolve_jmethod_id(jmethodID mid) {\n-    assert(mid != nullptr, \"JNI method id should not be null\");\n-    return *((Method**)mid);\n-  }\n+  static Method* resolve_jmethod_id(jmethodID mid);\n@@ -726,1 +718,1 @@\n-  static bool is_method_id(jmethodID mid);\n+  static bool validate_jmethod_id(jmethodID mid);\n@@ -728,2 +720,1 @@\n-  \/\/ Clear methods\n-  static void clear_jmethod_ids(ClassLoaderData* loader_data);\n+  \/\/ Clear jmethodID\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":12,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -442,1 +442,1 @@\n-  else if (!Method::is_method_id(method_id)) {\n+  else if (!Method::validate_jmethod_id(method_id)) {\n","filename":"src\/hotspot\/share\/prims\/jniCheck.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2771,1 +2771,0 @@\n-  bool jmethodids_found = true;\n@@ -2774,0 +2773,3 @@\n+  \/\/ Make jmethodIDs for all non-overpass methods.\n+  ik->make_methods_jmethod_ids();\n+\n@@ -2786,14 +2788,2 @@\n-    jmethodID id;\n-    if (jmethodids_found) {\n-      id = m->find_jmethod_id_or_null();\n-      if (id == nullptr) {\n-        \/\/ If we find an uninitialized value, make sure there is\n-        \/\/ enough space for all the uninitialized values we might\n-        \/\/ find.\n-        ik->ensure_space_for_methodids(index);\n-        jmethodids_found = false;\n-        id = m->jmethod_id();\n-      }\n-    } else {\n-      id = m->jmethod_id();\n-    }\n+    jmethodID id = m->find_jmethod_id_or_null();\n+    assert(id != nullptr, \"should be created above\");\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnv.cpp","additions":5,"deletions":15,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -3779,0 +3779,7 @@\n+    \/\/ The method_idnum should be within the range of 1..number-of-methods\n+    \/\/ until incremented later for obsolete methods.\n+    \/\/ The increment is so if a jmethodID is created for an old obsolete method\n+    \/\/ it gets a new jmethodID cache slot in the InstanceKlass.\n+    \/\/ They're cleaned out later when all methods of the previous version are purged.\n+    assert(old_method->method_idnum() <= _old_methods->length(),\n+           \"shouldn't be incremented yet for obsolete methods\");\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -236,1 +236,1 @@\n-  MUTEX_DEFN(JmethodIdCreation_lock          , PaddedMutex  , nosafepoint-2); \/\/ used for creating jmethodIDs.\n+  MUTEX_DEFN(JmethodIdCreation_lock          , PaddedMutex  , nosafepoint-1);    \/\/ used for creating jmethodIDs locks HandshakeState_lock\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}