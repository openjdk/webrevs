{"files":[{"patch":"@@ -418,1 +418,1 @@\n-instruct vaddI_vi(vReg dst, vReg src1, immI5 con) %{\n+instruct vadd_vi(vReg dst, vReg src1, immI5 con) %{\n@@ -422,1 +422,1 @@\n-  format %{ \"vaddI_vi $dst, $src1, $con\" %}\n+  format %{ \"vadd_vi $dst, $src1, $con\" %}\n@@ -447,1 +447,1 @@\n-instruct vaddI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vadd_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -451,1 +451,1 @@\n-  format %{ \"vaddI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vadd_vx $dst, $src1, $src2\" %}\n@@ -476,1 +476,1 @@\n-instruct vaddI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vadd_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -480,1 +480,1 @@\n-  format %{ \"vaddI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vadd_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -505,1 +505,1 @@\n-instruct vaddI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vadd_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -509,1 +509,1 @@\n-  format %{ \"vaddI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vadd_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -598,1 +598,1 @@\n-instruct vsubI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vsub_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -602,1 +602,1 @@\n-  format %{ \"vsubI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vsub_vx $dst, $src1, $src2\" %}\n@@ -627,1 +627,1 @@\n-instruct vsubI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vsub_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -631,1 +631,1 @@\n-  format %{ \"vsubI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vsub_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -644,1 +644,1 @@\n-  format %{ \"vsub_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vsubL_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -688,1 +688,1 @@\n-instruct vandI_vi(vReg dst_src, immI5 con) %{\n+instruct vand_vi(vReg dst_src, immI5 con) %{\n@@ -693,1 +693,1 @@\n-  format %{ \"vandI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vand_vi $dst_src, $dst_src, $con\" %}\n@@ -719,1 +719,1 @@\n-instruct vandI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vand_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -724,1 +724,1 @@\n-  format %{ \"vandI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vand_vx $dst_src, $dst_src, $src\" %}\n@@ -750,1 +750,1 @@\n-instruct vandI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vand_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -755,1 +755,1 @@\n-  format %{ \"vandI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vand_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -781,1 +781,1 @@\n-instruct vandI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vand_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -786,1 +786,1 @@\n-  format %{ \"vandI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vand_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -844,1 +844,1 @@\n-instruct vorI_vi(vReg dst_src, immI5 con) %{\n+instruct vor_vi(vReg dst_src, immI5 con) %{\n@@ -849,1 +849,1 @@\n-  format %{ \"vorI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vor_vi $dst_src, $dst_src, $con\" %}\n@@ -875,1 +875,1 @@\n-instruct vorI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vor_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -880,1 +880,1 @@\n-  format %{ \"vorI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vor_vx $dst_src, $dst_src, $src\" %}\n@@ -906,1 +906,1 @@\n-instruct vorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vor_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -911,1 +911,1 @@\n-  format %{ \"vorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vor_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -937,1 +937,1 @@\n-instruct vorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vor_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -942,1 +942,1 @@\n-  format %{ \"vorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vor_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1000,1 +1000,1 @@\n-instruct vxorI_vi(vReg dst_src, immI5 con) %{\n+instruct vxor_vi(vReg dst_src, immI5 con) %{\n@@ -1005,1 +1005,1 @@\n-  format %{ \"vxorI_vi $dst_src, $dst_src, $con\" %}\n+  format %{ \"vxor_vi $dst_src, $dst_src, $con\" %}\n@@ -1031,1 +1031,1 @@\n-instruct vxorI_vx(vReg dst_src, iRegIorL2I src) %{\n+instruct vxor_vx(vReg dst_src, iRegIorL2I src) %{\n@@ -1036,1 +1036,1 @@\n-  format %{ \"vxorI_vx $dst_src, $dst_src, $src\" %}\n+  format %{ \"vxor_vx $dst_src, $dst_src, $src\" %}\n@@ -1062,1 +1062,1 @@\n-instruct vxorI_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n+instruct vxor_vi_masked(vReg dst_src, immI5 con, vRegMask_V0 v0) %{\n@@ -1067,1 +1067,1 @@\n-  format %{ \"vxorI_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n+  format %{ \"vxor_vi_masked $dst_src, $dst_src, $con, $v0\" %}\n@@ -1093,1 +1093,1 @@\n-instruct vxorI_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n+instruct vxor_vx_masked(vReg dst_src, iRegIorL2I src, vRegMask_V0 v0) %{\n@@ -1098,1 +1098,1 @@\n-  format %{ \"vxorI_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n+  format %{ \"vxor_vx_masked $dst_src, $dst_src, $src, $v0\" %}\n@@ -1126,1 +1126,1 @@\n-instruct vand_notI(vReg dst, vReg src1, vReg src2, immI_M1 m1) %{\n+instruct vand_not(vReg dst, vReg src1, vReg src2, immI_M1 m1) %{\n@@ -1132,1 +1132,1 @@\n-  format %{ \"vand_notI $dst, $src1, $src2\" %}\n+  format %{ \"vand_not $dst, $src1, $src2\" %}\n@@ -1157,1 +1157,1 @@\n-instruct vand_notI_masked(vReg dst_src1, vReg src2, immI_M1 m1, vRegMask_V0 v0) %{\n+instruct vand_not_masked(vReg dst_src1, vReg src2, immI_M1 m1, vRegMask_V0 v0) %{\n@@ -1163,1 +1163,1 @@\n-  format %{ \"vand_notI_masked $dst_src1, $dst_src1, $src2, $v0\" %}\n+  format %{ \"vand_not_masked $dst_src1, $dst_src1, $src2, $v0\" %}\n@@ -1190,1 +1190,1 @@\n-instruct vand_notI_vx(vReg dst, vReg src1, iRegIorL2I src2, immI_M1 m1) %{\n+instruct vand_not_vx(vReg dst, vReg src1, iRegIorL2I src2, immI_M1 m1) %{\n@@ -1196,1 +1196,1 @@\n-  format %{ \"vand_notI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vand_not_vx $dst, $src1, $src2\" %}\n@@ -1221,1 +1221,1 @@\n-instruct vand_notI_vx_masked(vReg dst_src1, iRegIorL2I src2, immI_M1 m1, vRegMask_V0 v0) %{\n+instruct vand_not_vx_masked(vReg dst_src1, iRegIorL2I src2, immI_M1 m1, vRegMask_V0 v0) %{\n@@ -1227,1 +1227,1 @@\n-  format %{ \"vand_notI_vx_masked $dst_src1, $dst_src1, $src2, $v0\" %}\n+  format %{ \"vand_not_vx_masked $dst_src1, $dst_src1, $src2, $v0\" %}\n@@ -1258,1 +1258,1 @@\n-instruct vnotI(vReg dst, vReg src, immI_M1 m1) %{\n+instruct vnot(vReg dst, vReg src, immI_M1 m1) %{\n@@ -1263,1 +1263,1 @@\n-  format %{ \"vnotI $dst, $src\" %}\n+  format %{ \"vnot $dst, $src\" %}\n@@ -1289,1 +1289,1 @@\n-instruct vnotI_masked(vReg dst_src, immI_M1 m1, vRegMask_V0 v0) %{\n+instruct vnot_masked(vReg dst_src, immI_M1 m1, vRegMask_V0 v0) %{\n@@ -1294,1 +1294,1 @@\n-  format %{ \"vnotI_masked $dst_src, $dst_src, $v0\" %}\n+  format %{ \"vnot_masked $dst_src, $dst_src, $v0\" %}\n@@ -1804,1 +1804,1 @@\n-instruct vmulI_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n+instruct vmul_vx(vReg dst, vReg src1, iRegIorL2I src2) %{\n@@ -1808,1 +1808,1 @@\n-  format %{ \"vmulI_vx $dst, $src1, $src2\" %}\n+  format %{ \"vmul_vx $dst, $src1, $src2\" %}\n@@ -1833,1 +1833,1 @@\n-instruct vmulI_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n+instruct vmul_vx_masked(vReg dst_src, iRegIorL2I src2, vRegMask_V0 v0) %{\n@@ -1837,1 +1837,1 @@\n-  format %{ \"vmulI_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n+  format %{ \"vmul_vx_masked $dst_src, $dst_src, $src2, $v0\" %}\n@@ -1924,1 +1924,1 @@\n-instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct reduce_and(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -1931,1 +1931,1 @@\n-  format %{ \"reduce_andI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"reduce_and $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -1958,1 +1958,1 @@\n-instruct reduce_andI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct reduce_and_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -1965,1 +1965,1 @@\n-  format %{ \"reduce_andI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"reduce_and_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -1994,1 +1994,1 @@\n-instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct reduce_or(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -2001,1 +2001,1 @@\n-  format %{ \"reduce_orI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"reduce_or $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -2028,1 +2028,1 @@\n-instruct reduce_orI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct reduce_or_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -2035,1 +2035,1 @@\n-  format %{ \"reduce_orI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"reduce_or_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -2064,1 +2064,1 @@\n-instruct reduce_xorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct reduce_xor(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -2071,1 +2071,1 @@\n-  format %{ \"reduce_xorI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"reduce_xor $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -2098,1 +2098,1 @@\n-instruct reduce_xorI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct reduce_xor_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -2105,1 +2105,1 @@\n-  format %{ \"reduce_xorI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"reduce_xor_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -2134,1 +2134,1 @@\n-instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct reduce_add(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -2141,1 +2141,1 @@\n-  format %{ \"reduce_addI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"reduce_add $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -2240,1 +2240,1 @@\n-instruct reduce_addI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct reduce_add_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -2247,1 +2247,1 @@\n-  format %{ \"reduce_addI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"reduce_add_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -2306,1 +2306,1 @@\n-instruct vreduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct vreduce_max(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -2313,1 +2313,1 @@\n-  format %{ \"vreduce_maxI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"vreduce_max $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -2340,1 +2340,1 @@\n-instruct vreduce_maxI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct vreduce_max_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -2347,1 +2347,1 @@\n-  format %{ \"vreduce_maxI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"vreduce_max_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -2376,1 +2376,1 @@\n-instruct vreduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n+instruct vreduce_min(iRegINoSp dst, iRegIorL2I src1, vReg src2, vReg tmp) %{\n@@ -2383,1 +2383,1 @@\n-  format %{ \"vreduce_minI $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  format %{ \"vreduce_min $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -2410,1 +2410,1 @@\n-instruct vreduce_minI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n+instruct vreduce_min_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegMask_V0 v0, vReg tmp) %{\n@@ -2417,1 +2417,1 @@\n-  format %{ \"vreduce_minI_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n+  format %{ \"vreduce_min_masked $dst, $src1, $src2, $v0\\t# KILL $tmp\" %}\n@@ -5160,1 +5160,1 @@\n-instruct insertI_index_lt32(vReg dst, vReg src, iRegIorL2I val, immI idx, vRegMask_V0 v0) %{\n+instruct insert_index_lt32(vReg dst, vReg src, iRegIorL2I val, immI idx, vRegMask_V0 v0) %{\n@@ -5167,1 +5167,1 @@\n-  format %{ \"insertI_index_lt32 $dst, $src, $val, $idx\" %}\n+  format %{ \"insert_index_lt32 $dst, $src, $val, $idx\" %}\n@@ -5179,1 +5179,1 @@\n-instruct insertI_index(vReg dst, vReg src, iRegIorL2I val, iRegIorL2I idx, vReg tmp, vRegMask_V0 v0) %{\n+instruct insert_index(vReg dst, vReg src, iRegIorL2I val, iRegIorL2I idx, vReg tmp, vRegMask_V0 v0) %{\n@@ -5186,1 +5186,1 @@\n-  format %{ \"insertI_index $dst, $src, $val, $idx\\t# KILL $tmp\" %}\n+  format %{ \"insert_index $dst, $src, $val, $idx\\t# KILL $tmp\" %}\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":81,"deletions":81,"binary":false,"changes":162,"status":"modified"}]}