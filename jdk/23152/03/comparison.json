{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -44,0 +44,1 @@\n+  pd_nof_available_regs = 32,\n@@ -47,1 +48,1 @@\n-  pd_nof_caller_save_cpu_regs_frame_map = 19 - 2 \/* rscratch1 and rscratch2 *\/ R18_RESERVED_ONLY(- 1),  \/\/ number of registers killed by calls\n+  pd_nof_caller_save_cpu_regs_frame_map = pd_nof_available_regs,  \/\/ number of registers killed by calls\n@@ -50,2 +51,2 @@\n-  pd_first_callee_saved_reg = 19 - 2 \/* rscratch1 and rscratch2 *\/ R18_RESERVED_ONLY(- 1),\n-  pd_last_callee_saved_reg = 26 - 2 \/* rscratch1 and rscratch2 *\/ R18_RESERVED_ONLY(- 1),\n+  pd_first_callee_saved_reg = pd_nof_available_regs - 1,\n+  pd_last_callee_saved_reg = pd_first_callee_saved_reg - 1, \/\/ in fact, no callee saved regs\n@@ -53,1 +54,1 @@\n-  pd_last_allocatable_cpu_reg = 16 R18_RESERVED_ONLY(- 1),\n+  pd_last_allocatable_cpu_reg = pd_nof_available_regs - 1,\n@@ -63,1 +64,1 @@\n-  pd_last_cpu_reg = 16 R18_RESERVED_ONLY(- 1),\n+  pd_last_cpu_reg = pd_nof_available_regs - 1,\n@@ -65,1 +66,1 @@\n-  pd_last_byte_reg = 16 R18_RESERVED_ONLY(- 1),\n+  pd_last_byte_reg = pd_last_cpu_reg,\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Defs_aarch64.hpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -197,1 +197,16 @@\n-  map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n+  \/\/ r27 is allocated conditionally. With compressed oops it holds\n+  \/\/ the heapbase value and is not visible to the allocator.\n+  bool preserve_rheapbase = i >= nof_caller_save_cpu_regs();\n+  if (!preserve_rheapbase) {\n+    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n+  }\n+\n+  if(!PreserveFramePointer) {\n+    map_register(i, r29); r29_opr = LIR_OprFact::single_cpu(i); i++;\n+  }\n+\n+  \/\/ The unallocatable registers are at the end\n+\n+  if (preserve_rheapbase) {\n+    map_register(i, r27); r27_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rheapbase\n+  }\n@@ -199,1 +214,3 @@\n-  map_register(i, r29); r29_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rfp\n+  if(PreserveFramePointer) {\n+    map_register(i, r29); r29_opr = LIR_OprFact::single_cpu(i); i++; \/\/ rfp\n+  }\n@@ -243,0 +260,13 @@\n+  _caller_save_cpu_regs[17 R18_RESERVED_ONLY(-1)] = r19_opr;\n+  _caller_save_cpu_regs[18 R18_RESERVED_ONLY(-1)] = r20_opr;\n+  _caller_save_cpu_regs[19 R18_RESERVED_ONLY(-1)] = r21_opr;\n+  _caller_save_cpu_regs[20 R18_RESERVED_ONLY(-1)] = r22_opr;\n+  _caller_save_cpu_regs[21 R18_RESERVED_ONLY(-1)] = r23_opr;\n+  _caller_save_cpu_regs[22 R18_RESERVED_ONLY(-1)] = r24_opr;\n+  _caller_save_cpu_regs[23 R18_RESERVED_ONLY(-1)] = r25_opr;\n+  _caller_save_cpu_regs[24 R18_RESERVED_ONLY(-1)] = r26_opr;\n+\n+  if (nof_caller_save_cpu_regs() > 25 R18_RESERVED_ONLY(-1)) {\n+    _caller_save_cpu_regs[25 R18_RESERVED_ONLY(-1)] = r27_opr;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.cpp","additions":33,"deletions":3,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -143,3 +143,22 @@\n-  static int nof_caller_save_cpu_regs() { return pd_nof_caller_save_cpu_regs_frame_map; }\n-  static int last_cpu_reg()             { return pd_last_cpu_reg;  }\n-  static int last_byte_reg()            { return pd_last_byte_reg; }\n+  static int adjust_reg_range(int range, bool exclude_fp = true) {\n+    \/\/ r27 is not allocatable when compressed oops is on and heapbase is not\n+    \/\/ zero, compressed klass pointers doesn't use r27 after JDK-8234794\n+    if (UseCompressedOops && (CompressedOops::base() != nullptr)) {\n+      range -= 1;\n+    }\n+\n+    \/\/ r29 is not allocatable when PreserveFramePointer is on,\n+    \/\/ but fp saving is handled in MacroAssembler::build_frame()\/remove_frame()\n+    if (exclude_fp) {\n+      range -= 1;\n+    }\n+\n+    \/\/ rscratch registers r8, r9\n+    \/\/ r28=rthread, r30=lr, r31=sp\n+    \/\/ r18 on masOS\/Windows\n+    return range - 5 R18_RESERVED_ONLY(-1);\n+  }\n+\n+  static int nof_caller_save_cpu_regs() { return adjust_reg_range(pd_nof_caller_save_cpu_regs_frame_map);  }\n+  static int last_cpu_reg()             { return adjust_reg_range(pd_last_cpu_reg, PreserveFramePointer);  }\n+  static int last_byte_reg()            { return adjust_reg_range(pd_last_byte_reg, PreserveFramePointer); }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_FrameMap_aarch64.hpp","additions":23,"deletions":4,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -44,1 +44,1 @@\n-  if (assigned_reg < pd_first_callee_saved_reg)\n+  if (assigned_reg < FrameMap::nof_caller_save_cpu_regs())\n@@ -46,1 +46,1 @@\n-  if (assigned_reg > pd_last_callee_saved_reg && assigned_reg < pd_first_callee_saved_fpu_reg)\n+  if (assigned_reg >= pd_first_fpu_reg && assigned_reg < pd_first_callee_saved_fpu_reg)\n@@ -69,1 +69,1 @@\n-    _last_reg = pd_last_allocatable_cpu_reg;\n+    _last_reg = FrameMap::last_cpu_reg();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LinearScan_aarch64.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -261,7 +261,6 @@\n-  for (int i = 0; i < FrameMap::nof_cpu_regs; i++) {\n-    Register r = as_Register(i);\n-    if (r == rthread || (i <= 18 && i != rscratch1->encoding() && i != rscratch2->encoding())) {\n-      int sp_offset = cpu_reg_save_offsets[i];\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n-                                r->as_VMReg());\n-    }\n+  for (int i = 0; i < FrameMap::nof_caller_save_cpu_regs(); i++) {\n+    LIR_Opr opr = FrameMap::caller_save_cpu_reg_at(i);\n+    Register r = opr->as_register();\n+    int reg_num = r->encoding();\n+    int sp_offset = cpu_reg_save_offsets[reg_num];\n+    oop_map->set_callee_saved(VMRegImpl::stack2reg(cpu_reg_save_offsets[reg_num]), r->as_VMReg());\n@@ -270,0 +269,4 @@\n+  Register r = rthread;\n+  int reg_num = r->encoding();\n+  oop_map->set_callee_saved(VMRegImpl::stack2reg(cpu_reg_save_offsets[reg_num]), r->as_VMReg());\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -53,1 +53,0 @@\n-  Runtime1::initialize(buffer_blob);\n@@ -55,0 +54,1 @@\n+  Runtime1::initialize(buffer_blob);\n","filename":"src\/hotspot\/share\/c1\/c1_Compiler.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"oops\/compressedOops.hpp\"\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"}]}