{"files":[{"patch":"@@ -27,0 +27,1 @@\n+#include \"opto\/addnode.hpp\"\n@@ -238,0 +239,137 @@\n+\/\/ This function removes redundant lea instructions that result from chained dereferences that\n+\/\/ match to leaPCompressedOopOffset, leaP8Narrow, or leaP32Narrow. This happens for ideal graphs\n+\/\/ of the form LoadN -> DecodeN -> AddP. Matching with any leaP* rule consumes both the AddP and\n+\/\/ the DecodeN. However, after matching the DecodeN is added back as the base for the leaP*,\n+\/\/ which is necessary if the oop derived by the leaP* gets added to an OopMap, because OopMaps\n+\/\/ cannot contain derived oops with narrow oops as a base.\n+\/\/ This results in the following graph after matching:\n+\/\/  LoadN\n+\/\/  |   \\\n+\/\/  | decodeHeapOop_not_null\n+\/\/  |   \/       \\\n+\/\/  leaP*    MachProj (leaf)\n+\/\/ The decode_heap_oop_not_null will emit a lea with an unused result if the derived oop does\n+\/\/ not end up in an OopMap.\n+\/\/ This peephole recognizes graphs of the shape as shown above, ensures that the result of the\n+\/\/ decode is only used by the derived oop and removes that decode if this is the case. Further,\n+\/\/ multiple leaP*s can have the same decode as their base. This peephole will remove the decode\n+\/\/ if all leaP*s and the decode share the same parent.\n+\/\/ Additionally, if the register allocator spills the result of the LoadN we can get such a graph:\n+\/\/               LoadN\n+\/\/                 |\n+\/\/        DefinitionSpillCopy\n+\/\/           \/           \\\n+\/\/ MemToRegSpillCopy   MemToRegSpillCopy\n+\/\/           |           \/\n+\/\/           | decodeHeapOop_not_null\n+\/\/           |   \/              \\\n+\/\/           leaP*          MachProj (leaf)\n+\/\/ In this case where the common parent of the leaP* and the decode is one MemToRegSpillCopy\n+\/\/ away, this peephole can also recognize the decode as redundant and also remove the spill copy\n+\/\/ if that is only used by the decode.\n+bool Peephole::lea_remove_redundant(Block* block, int block_index, PhaseCFG* cfg_, PhaseRegAlloc* ra_,\n+                                    MachNode* (*new_root)(), uint inst0_rule) {\n+  MachNode* lea_derived_oop = block->get_node(block_index)->as_Mach();\n+  assert(lea_derived_oop->rule() == inst0_rule, \"sanity\");\n+  assert(lea_derived_oop->ideal_Opcode() == Op_AddP, \"sanity\");\n+\n+  MachNode* decode = lea_derived_oop->in(AddPNode::Base)->isa_Mach();\n+  if (decode == nullptr || decode->ideal_Opcode() != Op_DecodeN) {\n+    return false;\n+  }\n+\n+  \/\/ Check that the lea and the decode live in the same block.\n+  if (!block->contains(decode)) {\n+    return false;\n+  }\n+\n+  Node* lea_address = lea_derived_oop->in(AddPNode::Address);\n+  Node* decode_address = decode->in(1);\n+\n+  bool is_spill = lea_address != decode_address &&\n+                  lea_address->is_SpillCopy() &&\n+                  decode_address->is_SpillCopy();\n+\n+  \/\/ If this is a spill, move lea_address and decode_address one node further up to the\n+  \/\/ grandparents of lea_derived_oop and decode respectively. This lets us look through\n+  \/\/ the indirection of the spill.\n+  MachNode* decode_spill;\n+  if (is_spill) {\n+    decode_spill = decode_address->as_Mach();\n+    decode_address = decode_address->in(1);\n+    lea_address = lea_address->in(1);\n+  }\n+\n+  \/\/ The leaP* and the decode must have the same parent. If we have a spill, they must have\n+  \/\/ the same grandparent.\n+  if (lea_address != decode_address) {\n+    return false;\n+  }\n+\n+  \/\/ Ensure the decode only has the leaP*s (with the same (grand)parent) and a MachProj leaf as children.\n+  MachProjNode* proj = nullptr;\n+  for (DUIterator_Fast imax, i = decode->fast_outs(imax); i < imax; i++) {\n+    Node* out = decode->fast_out(i);\n+    if (out == lea_derived_oop) {\n+      continue;\n+    }\n+    if (out->is_MachProj() && out->outcnt() == 0) {\n+      proj = out->as_MachProj();\n+      continue;\n+    }\n+    if (out->is_Mach()) {\n+      MachNode* other_lea = out->as_Mach();\n+      if ((other_lea->rule() == leaP32Narrow_rule ||\n+           other_lea->rule() == leaP8Narrow_rule ||\n+           other_lea->rule() == leaPCompressedOopOffset_rule) &&\n+           other_lea->in(AddPNode::Base) == decode &&\n+          (is_spill ? other_lea->in(AddPNode::Address)->in(1)\n+                    : other_lea->in(AddPNode::Address)) == decode_address) {\n+        continue;\n+      }\n+    }\n+    \/\/ There is other stuff we do not expect...\n+    return false;\n+  }\n+\n+  \/\/ Ensure the MachProj is in the same block as the decode and the lea.\n+  if (proj == nullptr || !block->contains(proj)) {\n+    \/\/ This should only fail if we are stressing scheduling.\n+    assert(StressGCM, \"should be scheduled contiguously otherwise\");\n+    return false;\n+  }\n+\n+  \/\/ We now have verified that the decode is redundant and can be removed with a peephole.\n+  \/\/ Remove the projection\n+  block->find_remove(proj);\n+  cfg_->map_node_to_block(proj, nullptr);\n+\n+  \/\/ Rewire the base of all leas currently depending on the decode we are removing.\n+  for (DUIterator_Fast imax, i = decode->fast_outs(imax); i < imax; i++) {\n+    Node* dependant_lea = decode->fast_out(i);\n+    if (dependant_lea->is_Mach() && dependant_lea->as_Mach()->ideal_Opcode() == Op_AddP) {\n+\n+      dependant_lea->set_req(AddPNode::Base, decode_address);\n+      \/\/ This deleted something in the out array, hence adjust i, imax.\n+      --i;\n+      --imax;\n+    }\n+  }\n+\n+  \/\/ Remove spill for the decode if the spill node does not have any other uses.\n+  if (is_spill && decode_spill->outcnt() == 1 && block->contains(decode_spill)) {\n+    decode_spill->set_removed();\n+    block->find_remove(decode_spill);\n+    cfg_->map_node_to_block(decode_spill, nullptr);\n+    decode_spill->del_req(1);\n+  }\n+\n+  \/\/ Remove the decode\n+  decode->set_removed();\n+  block->find_remove(decode);\n+  cfg_->map_node_to_block(decode, nullptr);\n+  decode->del_req(1);\n+\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/peephole_x86_64.cpp","additions":138,"deletions":0,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+  static bool lea_remove_redundant(Block* block, int block_index, PhaseCFG* cfg_, PhaseRegAlloc* ra_,\n+                                   MachNode* (*new_root)(), uint inst0_rule);\n","filename":"src\/hotspot\/cpu\/x86\/peephole_x86_64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -14596,0 +14596,18 @@\n+peephole\n+%{\n+  peepmatch (leaPCompressedOopOffset);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n+peephole\n+%{\n+  peepmatch (leaP8Narrow);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n+peephole\n+%{\n+  peepmatch (leaP32Narrow);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -0,0 +1,393 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=GetAndSet\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 for AtomicReference.getAndSet.\n+ * @requires os.simpleArch == \"x64\" & vm.opt.TieredCompilation != false\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea GetAndSet\n+ *\/\n+\n+\/*\n+ * @test id=StringEquals\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 for String.Equals.\n+ * @requires os.simpleArch == \"x64\" & vm.opt.TieredCompilation != false\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea StringEquals\n+ *\/\n+\n+\/*\n+ * @test id=StringInflate\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 for StringConcat intrinsics.\n+ * @requires os.simpleArch == \"x64\" & vm.opt.TieredCompilation != false\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea StringInflate\n+ *\/\n+\n+\/*\n+ * @test id=RegexFind\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 when performing regex matching.\n+ * @requires os.simpleArch == \"x64\" & vm.opt.TieredCompilation != false & vm.opt.UseAvx == 3\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea RegexFind\n+ *\/\n+\n+\/*\n+ * @test id=StoreNSerial\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 when storing narrow oops to object arrays.\n+ * @requires os.simpleArch == \"x64\" & vm.gc.Serial\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea StoreNSerial\n+ *\/\n+\n+\/*\n+ * @test id=StoreNParallel\n+ * @bug 8020282\n+ * @summary Test that we do not generate redundant leas on x86 when storing narrow oops to object arrays.\n+ * @requires os.simpleArch == \"x64\" & vm.gc.Parallel\n+ * @modules jdk.compiler\/com.sun.tools.javac.util\n+ * @library \/test\/lib \/\n+ * @run driver compiler.codegen.TestRedundantLea StoreNParallel\n+ *\/\n+\n+\n+package compiler.codegen;\n+\n+import java.util.concurrent.atomic.*;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import com.sun.tools.javac.util.*;\n+\n+import compiler.lib.ir_framework.*;\n+\n+\/\/ The following tests ensure that we do not generate a redundant lea instruction on x86.\n+\/\/ These get generated on chained dereferences for the rules leaPCompressedOopOffset,\n+\/\/ leaP8Narrow, and leaP32Narrow and stem from a decodeHeapOopNotNull that is not needed\n+\/\/ unless the derived oop is added to an oop map. The redundant lea is removed with an\n+\/\/ opto assembly peephole optimization. Hence, all tests below feature a negative test\n+\/\/ run with -XX:-OptoPeephole to detect changes that obsolete that peephole.\n+\/\/ Further, all tests are run with different max heap sizes to trigger the generation of\n+\/\/ different lea match rules: -XX:MaxHeapSize=32m generates leaP(8|32)Narrow and\n+\/\/ -XX:MaxHeapSize=4g generates leaPCompressedOopOffset, since the address computation\n+\/\/ needs to shift left by 3.\n+public class TestRedundantLea {\n+    public static void main(String[] args) {\n+        String testName = args[0];\n+        TestFramework framework;\n+        switch (testName) {\n+            case \"GetAndSet\" -> {\n+                framework = new TestFramework(GetAndSetTest.class);\n+            }\n+            case \"StringEquals\" -> {\n+                framework = new TestFramework(StringEqualsTest.class);\n+                framework.addHelperClasses(StringEqualsTestHelper.class);\n+            }\n+            case \"StringInflate\" -> {\n+                framework = new TestFramework(StringInflateTest.class);\n+                framework.addFlags(\"--add-exports=jdk.compiler\/com.sun.tools.javac.util=ALL-UNNAMED\");\n+            }\n+            case \"RegexFind\" -> {\n+                framework = new TestFramework(RegexFindTest.class);\n+            }\n+            case \"StoreNSerial\" -> {\n+                framework = new TestFramework(StoreNTest.class);\n+                framework.addFlags(\"-XX:+UseSerialGC\");\n+            }\n+            case \"StoreNParallel\" -> {\n+                framework = new TestFramework(StoreNTest.class);\n+                framework.addFlags(\"-XX:+UseParallelGC\");\n+            }\n+            default -> {\n+                throw new IllegalArgumentException(\"Unknown test name \\\"\" + testName +\"\\\"\");\n+            }\n+        }\n+\n+        int i = 0;\n+        Scenario[] scenarios = new Scenario[2];\n+        for (boolean negativeTest : new boolean[] {false, true}) {\n+            if (negativeTest) {\n+                scenarios[i] = new Scenario(i, \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-OptoPeephole\");\n+            } else {\n+                scenarios[i] = new Scenario(i, \"-XX:+OptoPeephole\");\n+            }\n+            i += 1;\n+        }\n+\n+        framework.addScenarios(scenarios).start();\n+    }\n+}\n+\n+\/\/ This generates a leaP* rule for the chained dereference of obj.value that\n+\/\/ gets passed to the get and set VM intrinsic.\n+class GetAndSetTest {\n+    private static final Object CURRENT = new Object();\n+    private final AtomicReference<Object> obj = new AtomicReference<Object>();\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    \/\/ Test that the peephole worked for leaP(8|32)Narrow\n+    @IR(failOn = {IRNode.DECODE_HEAP_OOP_NOT_NULL},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    public void testGetAndSet() {\n+        obj.getAndSet(CURRENT);\n+    }\n+}\n+\n+\/\/ This generates leaP* rules for the chained dereferences of the String.value\n+\/\/ fields that are used in the string_equals VM intrinsic.\n+class StringEqualsTest {\n+    final StringEqualsTestHelper strEqHelper = new StringEqualsTestHelper(\"I am the string that is tested against\");\n+\n+    @Setup\n+    private static Object[] setup() {\n+        return new Object[]{\"I will be compared!\"};\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=3\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    \/\/ Test that the peephole worked for leaPCompressedOopOffset\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    @Arguments(setup = \"setup\")\n+    public boolean test(String str) {\n+        return strEqHelper.doEquals(str);\n+    }\n+}\n+\n+class StringEqualsTestHelper {\n+    private String str;\n+\n+    public StringEqualsTestHelper(String str) {\n+        this.str = str;\n+    }\n+\n+    @ForceInline\n+    public boolean doEquals(String other) {\n+        return this.str.equals(other);\n+    }\n+}\n+\n+\/\/ With all VM instrinsics disabled, this test only generates a leaP* rule\n+\/\/ before the string_inflate intrinsic (with -XX:-OptimizeStringConcat no\n+\/\/ leaP* rule is generated). With VM intrinsics enabled (this is the case\n+\/\/ here) leaP* rules are also generated for the string_equals and arrays_hashcode\n+\/\/ VM instrinsics.\n+\/\/ This generates a larger number of decodes for -XX:UseAVX={0,1} than for\n+\/\/ other flags.\n+class StringInflateTest {\n+    @Setup\n+    private static Object[] setup() {\n+        Names names = new Names(new Context());\n+        Name n1 = names.fromString(\"one\");\n+        Name n2 = names.fromString(\"two\");\n+        return new Object[] {n1, n2};\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=5\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"false\", \"UseAVX\", \">=2\"})\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=13\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"false\", \"UseAVX\", \"<2\"})\n+    \/\/ 2 decodes get removed\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=3\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"true\", \"UseAVX\", \">=2\"})\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=11\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"true\", \"UseAVX\", \"<2\"})\n+    @Arguments(setup = \"setup\")\n+    public static Name test(Name n1, Name n2) {\n+        return n1.append(n2);\n+    }\n+}\n+\n+\/\/ This test case generates leaP* rules before arrayof_jint_fill intrinsics,\n+\/\/ but only with -XX:+UseAVX3.\n+class RegexFindTest {\n+    @Setup\n+    private static Object[] setup() {\n+        Pattern pat = Pattern.compile(\"27\");\n+        Matcher m = pat.matcher(\" 274  leaPCompressedOopOffset  === _ 275 277  [[ 2246 165 294 ]] #16\/0x0000000000000010byte[int:>=0]\");\n+        return new Object[] { m };\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P_8_NARROW, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"MaxHeapSize\", \"<1073741824\", \"UseAVX\", \"=3\"},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    @IR(counts = {IRNode.LEA_P_COMPRESSED_OOP_OFFSET, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"MaxHeapSize\", \">1073741824\", \"UseAVX\", \"=3\"},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Due to unpredictable code generation, we cannot match the exact number of decodes below.\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \">=7\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"false\", \"UseAVX\", \"=3\"})\n+    \/\/ Test that the peephole worked for leaPCompressedOopOffset\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \">=6\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd = {\"OptoPeephole\", \"true\", \"UseAVX\", \"=3\"})\n+    @Arguments(setup = \"setup\")\n+    public boolean test(Matcher m) {\n+        return m.find();\n+    }\n+}\n+\n+\/\/ The matcher generates leaP* rules for storing an object in an array of objects\n+\/\/ at a constant offset, but only when using the Serial or Parallel GC.\n+\/\/ Here, we can also manipulate the offset such that we get a leaP32Narrow rule\n+\/\/ and we can demonstrate that the peephole also removes simple cases of unneeded\n+\/\/ spills.\n+class StoreNTest {\n+    private static final int SOME_SIZE = 42;\n+    private static final int OFFSET8BIT_IDX = 3;\n+    private static final int OFFSET32BIT_IDX = 33;\n+\n+    private static final Object CURRENT = new Object();\n+    private static final Object OTHER = new Object();\n+\n+    private StoreNTestHelper[] classArr8bit = new StoreNTestHelper[SOME_SIZE];\n+    private StoreNTestHelper[] classArr32bit = new StoreNTestHelper[SOME_SIZE];\n+    private Object[] objArr8bit = new Object[SOME_SIZE];\n+    private Object[] objArr32bit = new Object[SOME_SIZE];\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    \/\/ Test that the peephole worked for leaPCompressedOopOffset\n+    @IR(failOn = {IRNode.DECODE_HEAP_OOP_NOT_NULL},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    \/\/ Test that the peephole removes a spill.\n+    @IR(counts = {IRNode.MEM_TO_REG_SPILL_COPY, \"=4\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd ={\"OptoPeephole\", \"false\", \"UseCompactObjectHeaders\", \"false\"})\n+    @IR(counts = {IRNode.MEM_TO_REG_SPILL_COPY, \"=3\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfAnd ={\"OptoPeephole\", \"true\", \"UseCompactObjectHeaders\", \"false\"})\n+    public void testRemoveSpill() {\n+        this.classArr8bit[OFFSET8BIT_IDX] = new StoreNTestHelper(CURRENT, OTHER);\n+        this.classArr32bit[OFFSET32BIT_IDX] = new StoreNTestHelper(OTHER, CURRENT);\n+    }\n+\n+    \/\/ This variation of the test above generates a split spill register path.\n+    \/\/ Due to the complicated graph structure with the phis, the peephole\n+    \/\/ cannot remove the redundant decode shared by both leaP*s.\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    public void testPhiSpill() {\n+        this.classArr8bit[OFFSET8BIT_IDX] = new StoreNTestHelper(CURRENT, OTHER);\n+        this.classArr8bit[OFFSET32BIT_IDX] = new StoreNTestHelper(CURRENT, OTHER);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    \/\/ Test that the peephole worked for leaPCompressedOopOffset\n+    @IR(failOn = {IRNode.DECODE_HEAP_OOP_NOT_NULL},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    public void testNoAlloc() {\n+        this.objArr8bit[OFFSET8BIT_IDX] = CURRENT;\n+        this.objArr32bit[OFFSET32BIT_IDX] = OTHER;\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.LEA_P, \"=2\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIfPlatform = {\"mac\", \"false\"})\n+    \/\/ Negative test\n+    @IR(counts = {IRNode.DECODE_HEAP_OOP_NOT_NULL, \"=1\"},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"false\"})\n+    \/\/ Test that the peephole worked for leaPCompressedOopOffset\n+    @IR(failOn = {IRNode.DECODE_HEAP_OOP_NOT_NULL},\n+        phase = {CompilePhase.FINAL_CODE},\n+        applyIf = {\"OptoPeephole\", \"true\"})\n+    public void testNoAllocSameArray() {\n+        this.objArr8bit[OFFSET8BIT_IDX] = CURRENT;\n+        this.objArr8bit[OFFSET32BIT_IDX] = OTHER;\n+    }\n+}\n+\n+class StoreNTestHelper {\n+    Object o1;\n+    Object o2;\n+\n+    public StoreNTestHelper(Object o1, Object o2) {\n+        this.o1 = o1;\n+        this.o2 = o2;\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/codegen\/TestRedundantLea.java","additions":393,"deletions":0,"binary":false,"changes":393,"status":"added"},{"patch":"@@ -652,0 +652,5 @@\n+    public static final String DECODE_HEAP_OOP_NOT_NULL = PREFIX + \"DECODE_HEAP_OOP_NOT_NULL\" + POSTFIX;\n+    static {\n+        machOnly(DECODE_HEAP_OOP_NOT_NULL, \"decodeHeapOop_not_null\");\n+    }\n+\n@@ -873,0 +878,24 @@\n+    \/\/ Only supported on x86.\n+    public static final String LEA_P_COMPRESSED_OOP_OFFSET = PREFIX + \"LEA_P_COMPRESSED_OOP_OFFSET\" + POSTFIX;\n+    static {\n+        machOnly(LEA_P_COMPRESSED_OOP_OFFSET, \"leaPCompressedOopOffset\");\n+    }\n+\n+    \/\/ Only supported on x86.\n+    public static final String LEA_P_8_NARROW = PREFIX + \"LEA_P_8_NARROW\" + POSTFIX;\n+    static {\n+        machOnly(LEA_P_8_NARROW, \"leaP8Narrow\");\n+    }\n+\n+    \/\/ Only supported on x86.\n+    public static final String LEA_P_32_NARROW = PREFIX + \"LEA_P_32_NARROW\" + POSTFIX;\n+    static {\n+        machOnly(LEA_P_32_NARROW, \"leaP32Narrow\");\n+    }\n+\n+    \/\/ Only supported on x86.\n+    public static final String LEA_P = PREFIX + \"LEA_P\" + POSTFIX;\n+    static {\n+        machOnly(LEA_P, \"leaP(CompressedOopOffset|(8|32)Narrow)\");\n+    }\n+\n@@ -1211,0 +1240,5 @@\n+    public static final String MEM_TO_REG_SPILL_COPY = PREFIX + \"MEM_TO_REG_SPILL_COPY\" + POSTFIX;\n+    static {\n+        machOnly(MEM_TO_REG_SPILL_COPY, \"MemToRegSpillCopy\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":34,"deletions":0,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -0,0 +1,112 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.bench.vm.compiler.x86;\n+\n+import org.openjdk.jmh.annotations.*;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@Warmup(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)\n+@Measurement(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)\n+\/\/ Fix heap size since the StoreN benchmarks are allocating a lot and dependent on GC selection and compressed oop mode.\n+@Fork(value = 3, jvmArgsAppend = {\"-Xms1g\", \"-Xmx1g\"})\n+@State(Scope.Thread)\n+public class RedundantLeaPeephole {\n+    @State(Scope.Thread)\n+    public class StoreNHelper {\n+        Object o1;\n+        Object o2;\n+\n+        public StoreNHelper(Object o1, Object o2) {\n+            this.o1 = o1;\n+            this.o2 = o2;\n+        }\n+    }\n+\n+    @State(Scope.Thread)\n+    public class StringEqualsHelper {\n+        private String str;\n+\n+        public StringEqualsHelper(String str) {\n+            this.str = str;\n+        }\n+\n+        @CompilerControl(CompilerControl.Mode.INLINE)\n+        public boolean doEquals(String other) {\n+            return this.str.equals(other);\n+        }\n+    }\n+\n+    private static final int SIZE = 42;\n+    private static final int SMALL_IDX = 3;\n+    private static final int BIG_IDX = 33;\n+\n+    private static final Object O1 = new Object();\n+    private static final Object O2 = new Object();\n+\n+    private Object[] arr1 = new Object[SIZE];\n+    private Object[] arr2 = new Object[SIZE];\n+    private StoreNHelper[] arrH1 = new StoreNHelper[SIZE];\n+    private StoreNHelper[] arrH2 = new StoreNHelper[SIZE];\n+\n+    private StringEqualsHelper strEqHelper = new StringEqualsHelper(\"foo\");\n+\n+    @Benchmark\n+    @Fork(jvmArgsAppend = {\"-XX:+UseSerialGC\"})\n+    public void benchStoreNRemoveSpillSerial() {\n+        this.arrH1[SMALL_IDX] = new StoreNHelper(O1, O2);\n+        this.arrH2[BIG_IDX] = new StoreNHelper(O2, O1);\n+    }\n+\n+    @Benchmark\n+    @Fork(jvmArgsAppend = {\"-XX:+UseParallelGC\"})\n+    public void benchStoreNRemoveSpillParallel() {\n+        this.arrH1[SMALL_IDX] = new StoreNHelper(O1, O2);\n+        this.arrH2[BIG_IDX] = new StoreNHelper(O2, O1);\n+    }\n+\n+    @Benchmark\n+    @Fork(jvmArgsAppend = {\"-XX:+UseSerialGC\"})\n+    public void benchStoreNNoAllocSerial() {\n+        this.arr1[SMALL_IDX] = O1;\n+        this.arr1[BIG_IDX] = O2;\n+        this.arr2[SMALL_IDX] = O1;\n+        this.arr2[BIG_IDX] = O2;\n+    }\n+\n+    @Benchmark\n+    @Fork(jvmArgsAppend = {\"-XX:+UseParallelGC\"})\n+    public void benchStoreNNoAllocParallel() {\n+        this.arr1[SMALL_IDX] = O1;\n+        this.arr1[BIG_IDX] = O2;\n+        this.arr2[SMALL_IDX] = O1;\n+        this.arr2[BIG_IDX] = O2;\n+    }\n+\n+    @Benchmark\n+    public boolean benchStringEquals() {\n+        return this.strEqHelper.doEquals(\"bar\");\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/compiler\/x86\/RedundantLeaPeephole.java","additions":112,"deletions":0,"binary":false,"changes":112,"status":"added"}]}