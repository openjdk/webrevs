{"files":[{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -73,2 +74,49 @@\n-  lightweight_lock(disp_hdr, obj, hdr, temp, rscratch2, slow_case);\n-\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    lightweight_lock(disp_hdr, obj, hdr, temp, rscratch2, slow_case);\n+  } else if (LockingMode == LM_LEGACY) {\n+\n+    if (DiagnoseSyncOnValueBasedClasses != 0) {\n+      load_klass(hdr, obj);\n+      ldrb(hdr, Address(hdr, Klass::misc_flags_offset()));\n+      tst(hdr, KlassFlags::_misc_is_value_based_class);\n+      br(Assembler::NE, slow_case);\n+    }\n+\n+    Label done;\n+    \/\/ Load object header\n+    ldr(hdr, Address(obj, hdr_offset));\n+    \/\/ and mark it as unlocked\n+    orr(hdr, hdr, markWord::unlocked_value);\n+    \/\/ save unlocked object header into the displaced header location on the stack\n+    str(hdr, Address(disp_hdr, 0));\n+    \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+    \/\/ displaced header address in the object header - if it is not the same, get the\n+    \/\/ object header instead\n+    lea(rscratch2, Address(obj, hdr_offset));\n+    cmpxchgptr_barrier(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/nullptr);\n+    \/\/ if the object header was the same, we're done\n+    \/\/ if the object header was not the same, it is now in the hdr register\n+    \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+    \/\/\n+    \/\/ 1) (hdr & aligned_mask) == 0\n+    \/\/ 2) sp <= hdr\n+    \/\/ 3) hdr <= sp + page_size\n+    \/\/\n+    \/\/ these 3 tests can be done by evaluating the following expression:\n+    \/\/\n+    \/\/ (hdr - sp) & (aligned_mask - page_size)\n+    \/\/\n+    \/\/ assuming both the stack pointer and page_size have their least\n+    \/\/ significant 2 bits cleared and page_size is a power of 2\n+    mov(rscratch1, sp);\n+    sub(hdr, hdr, rscratch1);\n+    ands(hdr, hdr, aligned_mask - (int)os::vm_page_size());\n+    \/\/ for recursive locking, the result is zero => save it in the displaced header\n+    \/\/ location (null in the displaced hdr location indicates recursive locking)\n+    str(hdr, Address(disp_hdr, 0));\n+    \/\/ otherwise we don't care about the result and handle locking via runtime call\n+    cbnz(hdr, slow_case);\n+    \/\/ done\n+    bind(done);\n+    inc_held_monitor_count(rscratch1);\n+  }\n@@ -86,1 +134,18 @@\n-  lightweight_unlock(obj, hdr, temp, rscratch2, slow_case);\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    lightweight_unlock(obj, hdr, temp, rscratch2, slow_case);\n+  } else if (LockingMode == LM_LEGACY) {\n+    \/\/ test if object header is pointing to the displaced header, and if so, restore\n+    \/\/ the displaced header in the object - if the object header is not pointing to\n+    \/\/ the displaced header, get the object header instead\n+    \/\/ if the object header was not pointing to the displaced header,\n+    \/\/ we do unlocking via runtime call\n+    if (hdr_offset) {\n+      lea(rscratch1, Address(obj, hdr_offset));\n+      cmpxchgptr_barrier(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n+    } else {\n+      cmpxchgptr_barrier(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n+    }\n+    \/\/ done\n+    bind(done);\n+    dec_held_monitor_count(rscratch1);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":68,"deletions":3,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -3370,1 +3371,1 @@\n-void MacroAssembler::cmpxchgptr(Register oldv, Register newv, Register addr, Register tmp,\n+void MacroAssembler::cmpxchgptr_barrier(Register oldv, Register newv, Register addr, Register tmp,\n@@ -3380,1 +3381,0 @@\n-    membar(AnyAny);\n@@ -3408,37 +3408,1 @@\n-  cmpxchgptr(oldv, newv, obj, tmp, succeed, fail);\n-}\n-\n-void MacroAssembler::cmpxchgw(Register oldv, Register newv, Register addr, Register tmp,\n-                                Label &succeed, Label *fail) {\n-  \/\/ oldv holds comparison value\n-  \/\/ newv holds value to write in exchange\n-  \/\/ addr identifies memory word to compare against\/update\n-  \/\/ tmp returns 0\/1 for success\/failure\n-  if (UseLSE) {\n-    mov(tmp, oldv);\n-    casal(Assembler::word, oldv, newv, addr);\n-    cmp(tmp, oldv);\n-    br(Assembler::EQ, succeed);\n-    membar(AnyAny);\n-  } else {\n-    Label retry_load, nope;\n-    prfm(Address(addr), PSTL1STRM);\n-    bind(retry_load);\n-    \/\/ flush and load exclusive from the memory location\n-    \/\/ and fail if it is not what we expect\n-    ldaxrw(tmp, addr);\n-    cmp(tmp, oldv);\n-    br(Assembler::NE, nope);\n-    \/\/ if we store+flush with no intervening write tmp will be zero\n-    stlxrw(tmp, newv, addr);\n-    cbzw(tmp, succeed);\n-    \/\/ retry so we only ever return after a load fails to compare\n-    \/\/ ensures we don't return a stale value after a failed write.\n-    b(retry_load);\n-    \/\/ if the memory word differs we return it in oldv and signal a fail\n-    bind(nope);\n-    membar(AnyAny);\n-    mov(oldv, tmp);\n-  }\n-  if (fail)\n-    b(*fail);\n+  cmpxchgptr_barrier(oldv, newv, obj, tmp, succeed, fail);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":3,"deletions":39,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -1217,4 +1218,1 @@\n-  void cmpxchgptr(Register oldv, Register newv, Register addr, Register tmp,\n-                  Label &succeed, Label *fail);\n-\n-  void cmpxchgw(Register oldv, Register newv, Register addr, Register tmp,\n+  void cmpxchgptr_barrier(Register oldv, Register newv, Register addr, Register tmp,\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"}]}