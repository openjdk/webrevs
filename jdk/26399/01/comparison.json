{"files":[{"patch":"@@ -120,2 +120,16 @@\n-  void set_value(int value) {\n-    Atomic::release_store(guard_addr(), value);\n+  void set_value(int value, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      Atomic::release_store(guard_addr(), value);\n+      return;\n+    }\n+    assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    value &= bit_mask;\n+    int old_value = Atomic::load(guard_addr());\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      int new_value = value | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      int v = Atomic::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n@@ -184,1 +198,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -201,1 +215,1 @@\n-  barrier.set_value(value);\n+  barrier.set_value(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetNMethod_aarch64.cpp","additions":18,"deletions":4,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -54,2 +54,16 @@\n-  void set_value(int value) {\n-    Atomic::release_store(guard_addr(), value);\n+  void set_value(int value, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      Atomic::release_store(guard_addr(), value);\n+      return;\n+    }\n+    assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    value &= bit_mask;\n+    int old_value = Atomic::load(guard_addr());\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      int new_value = value | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      int v = Atomic::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n@@ -118,1 +132,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -126,1 +140,1 @@\n-  barrier->set_value(value);\n+  barrier->set_value(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/arm\/gc\/shared\/barrierSetNMethod_arm.cpp","additions":18,"deletions":4,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -195,0 +195,1 @@\n+  __ align(8); \/\/ align for atomic update\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/shared\/barrierSetAssembler_ppc.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-  void release_set_guard_value(int value) {\n+  void release_set_guard_value(int value, int bit_mask) {\n@@ -58,2 +58,31 @@\n-    \/\/ Set the guard value (naming of 'offset' function is misleading).\n-    get_patchable_instruction_handle()->set_offset(value);\n+    if (bit_mask == ~0) {\n+      \/\/ Set the guard value (naming of 'offset' function is misleading).\n+      get_patchable_instruction_handle()->set_offset(value);\n+      return;\n+    }\n+\n+    assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    value &= bit_mask;\n+\n+    NativeMovRegMem* mov = get_patchable_instruction_handle();\n+    assert(align_up(mov->instruction_address(), sizeof(uint64_t)) ==\n+           align_down(mov->instruction_address(), sizeof(uint64_t)), \"instruction not aligned\");\n+    uint64_t *instr = (uint64_t*)mov->instruction_address();\n+    assert(NativeMovRegMem::instruction_size == sizeof(*instr), \"must be\");\n+    union {\n+      u_char buf[NativeMovRegMem::instruction_size];\n+      uint64_t u64;\n+    } new_mov_instr, old_mov_instr;\n+    new_mov_instr.u64 = old_mov_instr.u64 = Atomic::load(instr);\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      int old_value = nativeMovRegMem_at(old_mov_instr.buf)->offset();\n+      int new_value = value | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      nativeMovRegMem_at(new_mov_instr.buf)->set_offset(new_value, false \/* no icache flush *\/);\n+      \/\/ Swap in the new value\n+      uint64_t v = Atomic::cmpxchg(instr, old_mov_instr.u64, new_mov_instr.u64, memory_order_release);\n+      if (v == old_mov_instr.u64) break;\n+      old_mov_instr.u64 = v;\n+    }\n+    ICache::ppc64_flush_icache_bytes(addr_at(0), NativeMovRegMem::instruction_size);\n@@ -120,1 +149,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -126,1 +155,1 @@\n-  barrier->release_set_guard_value(value);\n+  barrier->release_set_guard_value(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/shared\/barrierSetNMethod_ppc.cpp","additions":34,"deletions":5,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -465,1 +465,1 @@\n-  void set_offset(intptr_t x) {\n+  void set_offset(intptr_t x, bool flush_icache = true) {\n@@ -475,1 +475,3 @@\n-    ICache::ppc64_flush_icache_bytes(addr_at(0), NativeMovRegMem::instruction_size);\n+    if (flush_icache) {\n+      ICache::ppc64_flush_icache_bytes(addr_at(0), NativeMovRegMem::instruction_size);\n+    }\n","filename":"src\/hotspot\/cpu\/ppc\/nativeInst_ppc.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -114,2 +114,16 @@\n-  void set_value(int value) {\n-    Atomic::release_store(guard_addr(), value);\n+  void set_value(int value, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      Atomic::release_store(guard_addr(), value);\n+      return;\n+    }\n+    assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    value &= bit_mask;\n+    int old_value = Atomic::load(guard_addr());\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      int new_value = value | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      int v = Atomic::cmpxchg(guard_addr(), old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n@@ -197,1 +211,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -214,1 +228,1 @@\n-  barrier.set_value(value);\n+  barrier.set_value(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/shared\/barrierSetNMethod_riscv.cpp","additions":18,"deletions":4,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -56,2 +56,3 @@\n-    void set_guard_value(int value) {\n-      int32_t* data_addr = (int32_t*)get_patchable_data_address();\n+    void set_guard_value(int value, int bit_mask) {\n+      if (bit_mask == ~0) {\n+        int32_t* data_addr = (int32_t*)get_patchable_data_address();\n@@ -59,2 +60,16 @@\n-      \/\/ Set guard instruction value\n-      *data_addr = value;\n+        \/\/ Set guard instruction value\n+        *data_addr = value;\n+        return;\n+      }\n+      assert((value & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+      value &= bit_mask;\n+      int32_t* data_addr = (int32_t*)get_patchable_data_address();\n+      int old_value = Atomic::load(data_addr);\n+      while (true) {\n+        \/\/ Only bits in the mask are changed\n+        int new_value = value | (old_value & ~bit_mask);\n+        if (new_value == old_value) break;\n+        int v = Atomic::cmpxchg(data_addr, old_value, new_value, memory_order_release);\n+        if (v == old_value) break;\n+        old_value = v;\n+      }\n@@ -103,1 +118,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -109,1 +124,1 @@\n-  barrier->set_guard_value(value);\n+  barrier->set_guard_value(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/s390\/gc\/shared\/barrierSetNMethod_s390.cpp","additions":21,"deletions":6,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+  NativeNMethodCmpBarrier* nativeNMethodCmpBarrier_at(address a) { return (NativeNMethodCmpBarrier*)a; }\n+\n@@ -54,1 +56,22 @@\n-  void set_immediate(jint imm) { set_int_at(imm_offset, imm); }\n+  void set_immediate(jint imm, int bit_mask) {\n+    if (bit_mask == ~0) {\n+      set_int_at(imm_offset, imm);\n+      return;\n+    }\n+\n+    assert((imm & ~bit_mask) == 0, \"trying to set bits outside the mask\");\n+    imm &= bit_mask;\n+\n+    assert(align_up(immediate_address(), sizeof(jint)) ==\n+           align_down(immediate_address(), sizeof(jint)), \"immediate not aligned\");\n+    jint* data_addr = (jint*)immediate_address();\n+    jint old_value = Atomic::load(data_addr);\n+    while (true) {\n+      \/\/ Only bits in the mask are changed\n+      jint new_value = imm | (old_value & ~bit_mask);\n+      if (new_value == old_value) break;\n+      jint v = Atomic::cmpxchg(data_addr, old_value, new_value, memory_order_release);\n+      if (v == old_value) break;\n+      old_value = v;\n+    }\n+  }\n@@ -162,1 +185,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n@@ -168,1 +191,1 @@\n-  cmp->set_immediate(value);\n+  cmp->set_immediate(value, bit_mask);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetNMethod_x86.cpp","additions":26,"deletions":3,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-void BarrierSetNMethod::set_guard_value(nmethod* nm, int value) {\n+void BarrierSetNMethod::set_guard_value(nmethod* nm, int value, int bit_mask) {\n","filename":"src\/hotspot\/cpu\/zero\/gc\/shared\/barrierSetNMethod_zero.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-  guard_with(nm, disarmed_guard_value());\n+  set_guard_value(nm, disarmed_guard_value());\n@@ -80,10 +80,1 @@\n-  \/\/ Enter critical section.  Does not block for safepoint.\n-  ConditionalMutexLocker ml(NMethodEntryBarrier_lock, !NMethodEntryBarrier_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n-  \/\/ Do not undo sticky bit\n-  if (is_not_entrant(nm)) {\n-    value |= not_entrant;\n-  }\n-  if (guard_value(nm) != value) {\n-    \/\/ Patch the code only if needed.\n-    set_guard_value(nm, value);\n-  }\n+  set_guard_value(nm, value);\n@@ -122,0 +113,2 @@\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, Thread::current()));\n+\n@@ -182,4 +175,0 @@\n-  \/\/ Enable WXWrite: the function is called directly from nmethod_entry_barrier\n-  \/\/ stub.\n-  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, Thread::current()));\n-\n@@ -246,7 +235,1 @@\n-  \/\/ Enter critical section.  Does not block for safepoint.\n-  ConditionalMutexLocker ml(NMethodEntryBarrier_lock, !NMethodEntryBarrier_lock->owned_by_self(), Mutex::_no_safepoint_check_flag);\n-  int value = guard_value(nm) | not_entrant;\n-  if (guard_value(nm) != value) {\n-    \/\/ Patch the code only if needed.\n-    set_guard_value(nm, value);\n-  }\n+  set_guard_value(nm, not_entrant, not_entrant);\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.cpp","additions":5,"deletions":22,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -39,0 +39,4 @@\n+\n+  void deoptimize(nmethod* nm, address* return_addr_ptr);\n+\n+protected:\n@@ -45,5 +49,2 @@\n-  void deoptimize(nmethod* nm, address* return_addr_ptr);\n-\n-protected:\n-  virtual int guard_value(nmethod* nm);\n-  void set_guard_value(nmethod* nm, int value);\n+  int guard_value(nmethod* nm);\n+  void set_guard_value(nmethod* nm, int value, int bit_mask = ~not_entrant);\n@@ -63,1 +64,1 @@\n-  virtual bool is_armed(nmethod* nm);\n+  bool is_armed(nmethod* nm);\n@@ -66,2 +67,2 @@\n-  virtual void make_not_entrant(nmethod* nm);\n-  virtual bool is_not_entrant(nmethod* nm);\n+  void make_not_entrant(nmethod* nm);\n+  bool is_not_entrant(nmethod* nm);\n@@ -69,1 +70,1 @@\n-  virtual void guard_with(nmethod* nm, int value);\n+  void guard_with(nmethod* nm, int value);\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.hpp","additions":10,"deletions":9,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -109,28 +109,0 @@\n-void ZBarrierSetNMethod::guard_with(nmethod* nm, int value) {\n-  assert((value & not_entrant) == 0, \"not_entrant bit is reserved\");\n-  ZLocker<ZReentrantLock> locker(ZNMethod::lock_for_nmethod(nm));\n-  \/\/ Preserve the sticky bit\n-  if (is_not_entrant(nm)) {\n-    value |= not_entrant;\n-  }\n-  if (guard_value(nm) != value) {\n-    \/\/ Patch the code only if needed.\n-    set_guard_value(nm, value);\n-  }\n-}\n-\n-bool ZBarrierSetNMethod::is_armed(nmethod* nm) {\n-  int value = guard_value(nm) & ~not_entrant;\n-  return value != disarmed_guard_value();\n-}\n-\n-void ZBarrierSetNMethod::make_not_entrant(nmethod* nm) {\n-  ZLocker<ZReentrantLock> locker(ZNMethod::lock_for_nmethod(nm));\n-  int value = guard_value(nm) | not_entrant; \/\/ permanent sticky value\n-  set_guard_value(nm, value);\n-}\n-\n-bool ZBarrierSetNMethod::is_not_entrant(nmethod* nm) {\n-  return (guard_value(nm) & not_entrant) != 0;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSetNMethod.cpp","additions":0,"deletions":28,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -33,4 +33,0 @@\n-  enum : int {\n-    not_entrant = 1 << 31, \/\/ armed sticky bit, see make_not_entrant\n-  };\n-\n@@ -49,4 +45,0 @@\n-  virtual void make_not_entrant(nmethod* nm);\n-  virtual bool is_not_entrant(nmethod* nm);\n-  virtual void guard_with(nmethod* nm, int value);\n-  virtual bool is_armed(nmethod* nm);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSetNMethod.hpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-Mutex*   NMethodEntryBarrier_lock     = nullptr;\n@@ -209,2 +208,0 @@\n-  MUTEX_DEFN(NMethodEntryBarrier_lock        , PaddedMutex  , service-1);\n-\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-extern Mutex*   NMethodEntryBarrier_lock;        \/\/ protects nmethod entry barrier\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}