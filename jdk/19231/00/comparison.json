{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -151,5 +151,0 @@\n-    return false;\n-  }\n-\n-  \/\/ Walk simple thread stacks\n-  if (!ThreadStackTracker::walk_simple_thread_stack_site(&malloc_walker)) {\n","filename":"src\/hotspot\/share\/nmt\/memBaseline.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -196,11 +196,4 @@\n-    if (ThreadStackTracker::track_as_vm()) {\n-      const VirtualMemory* thread_stack_usage =\n-        (const VirtualMemory*)_vm_snapshot->by_type(mtThreadStack);\n-      reserved_amount  += thread_stack_usage->reserved();\n-      committed_amount += thread_stack_usage->committed();\n-    } else {\n-      const MallocMemory* thread_stack_usage =\n-        (const MallocMemory*)_malloc_snapshot->by_type(mtThreadStack);\n-      reserved_amount += thread_stack_usage->malloc_size();\n-      committed_amount += thread_stack_usage->malloc_size();\n-    }\n+    const VirtualMemory* thread_stack_usage =\n+      (const VirtualMemory*)_vm_snapshot->by_type(mtThreadStack);\n+    reserved_amount  += thread_stack_usage->reserved();\n+    committed_amount += thread_stack_usage->committed();\n@@ -243,15 +236,6 @@\n-    if (ThreadStackTracker::track_as_vm()) {\n-      const VirtualMemory* thread_stack_usage =\n-       _vm_snapshot->by_type(mtThreadStack);\n-      \/\/ report thread count\n-      out->print_cr(\"%27s (threads #\" SIZE_FORMAT \")\", \" \", ThreadStackTracker::thread_count());\n-      out->print(\"%27s (stack: \", \" \");\n-      print_total(thread_stack_usage->reserved(), thread_stack_usage->committed(), thread_stack_usage->peak_size());\n-    } else {\n-      MallocMemory* thread_stack_memory = _malloc_snapshot->by_type(mtThreadStack);\n-      const char* scale = current_scale();\n-      \/\/ report thread count\n-      out->print_cr(\"%27s (threads #\" SIZE_FORMAT \")\", \" \", thread_stack_memory->malloc_count());\n-      out->print(\"%27s (Stack: \" SIZE_FORMAT \"%s\", \" \",\n-        amount_in_current_scale(thread_stack_memory->malloc_size()), scale);\n-    }\n+    const VirtualMemory* thread_stack_usage =\n+     _vm_snapshot->by_type(mtThreadStack);\n+    \/\/ report thread count\n+    out->print_cr(\"%27s (threads #\" SIZE_FORMAT \")\", \" \", ThreadStackTracker::thread_count());\n+    out->print(\"%27s (stack: \", \" \");\n+    print_total(thread_stack_usage->reserved(), thread_stack_usage->committed(), thread_stack_usage->peak_size());\n@@ -630,18 +614,9 @@\n-      if (ThreadStackTracker::track_as_vm()) {\n-        \/\/ report thread stack\n-        const VirtualMemory* current_thread_stack =\n-          _current_baseline.virtual_memory(mtThreadStack);\n-        const VirtualMemory* early_thread_stack =\n-          _early_baseline.virtual_memory(mtThreadStack);\n-\n-        print_virtual_memory_diff(current_thread_stack->reserved(), current_thread_stack->committed(),\n-          early_thread_stack->reserved(), early_thread_stack->committed());\n-      } else {\n-        const MallocMemory* current_thread_stack =\n-          _current_baseline.malloc_memory(mtThreadStack);\n-        const MallocMemory* early_thread_stack =\n-          _early_baseline.malloc_memory(mtThreadStack);\n-\n-        print_malloc_diff(current_thread_stack->malloc_size(), current_thread_stack->malloc_count(),\n-          early_thread_stack->malloc_size(), early_thread_stack->malloc_count(), flag);\n-      }\n+      \/\/ report thread stack\n+      const VirtualMemory* current_thread_stack =\n+        _current_baseline.virtual_memory(mtThreadStack);\n+      const VirtualMemory* early_thread_stack =\n+        _early_baseline.virtual_memory(mtThreadStack);\n+\n+      print_virtual_memory_diff(current_thread_stack->reserved(), current_thread_stack->committed(),\n+        early_thread_stack->reserved(), early_thread_stack->committed());\n+\n","filename":"src\/hotspot\/share\/nmt\/memReporter.cpp","additions":19,"deletions":44,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -70,2 +70,1 @@\n-        !VirtualMemoryTracker::initialize(level) ||\n-        !ThreadStackTracker::initialize(level)) {\n+        !VirtualMemoryTracker::initialize(level)) {\n","filename":"src\/hotspot\/share\/nmt\/memTracker.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,7 +46,5 @@\n-  \/\/ If backed by virtual memory, snapping the thread stacks involves walking\n-  \/\/ them to to figure out how much memory is committed if they are backed by\n-  \/\/ virtual memory. This needs ot happen before we take the snapshot of the\n-  \/\/ virtual memory since it will update this information.\n-  if (ThreadStackTracker::track_as_vm()) {\n-    VirtualMemoryTracker::snapshot_thread_stacks();\n-  }\n+  \/\/ Snapping the thread stacks involves walking the areas to figure out how\n+  \/\/ much memory had been committed if they are backed by virtual memory. This\n+  \/\/ needs to happen before we take the snapshot of the virtual memory since it\n+  \/\/ will update this information.\n+  VirtualMemoryTracker::snapshot_thread_stacks();\n","filename":"src\/hotspot\/share\/nmt\/nmtUsage.cpp","additions":6,"deletions":8,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2019, 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2019, 2024, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +28,0 @@\n-#include \"nmt\/mallocTracker.hpp\"\n@@ -31,0 +31,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -32,0 +33,3 @@\n+#include \"utilities\/align.hpp\"\n+#include \"utilities\/debug.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -34,1 +38,0 @@\n-SortedLinkedList<SimpleThreadStackSite, ThreadStackTracker::compare_thread_stack_base>* ThreadStackTracker::_simple_thread_stacks = nullptr;\n@@ -36,11 +39,10 @@\n-bool ThreadStackTracker::initialize(NMT_TrackingLevel level) {\n-  if (level == NMT_detail && !track_as_vm()) {\n-    _simple_thread_stacks = new (std::nothrow, mtNMT)\n-      SortedLinkedList<SimpleThreadStackSite, ThreadStackTracker::compare_thread_stack_base>();\n-    return (_simple_thread_stacks != nullptr);\n-  }\n-  return true;\n-}\n-\n-int ThreadStackTracker::compare_thread_stack_base(const SimpleThreadStackSite& s1, const SimpleThreadStackSite& s2) {\n-  return primitive_compare(s1.base(), s2.base());\n+static void align_thread_stack_boundaries_inward(void*& base, size_t& size) {\n+  \/\/ Thread stack boundaries don't have to be aligned to page boundaries. For cases where they\n+  \/\/ are not aligned (e.g. AIX, Alpine), this function corrects boundaries inward to the next\n+  \/\/ page boundaries. This ensures that we can track thread stacks piggybacking on the virtual\n+  \/\/ memory tracker.\n+  void* const base_aligned = align_up(base, os::vm_page_size());\n+  const size_t size_aligned = align_down(size, os::vm_page_size());\n+  assert(size_aligned > 0, \"stack size less than a page?\");\n+  base = base_aligned;\n+  size = size_aligned;\n@@ -50,1 +52,1 @@\n-  assert(MemTracker::tracking_level() >= NMT_summary, \"Must be\");\n+  assert(MemTracker::enabled(), \"Must be\");\n@@ -52,0 +54,2 @@\n+  align_thread_stack_boundaries_inward(base, size);\n+\n@@ -53,11 +57,1 @@\n-  if (track_as_vm()) {\n-    VirtualMemoryTracker::add_reserved_region((address)base, size, stack, mtThreadStack);\n-  } else {\n-    \/\/ Use a slot in mallocMemorySummary for thread stack bookkeeping\n-    MallocMemorySummary::record_malloc(size, mtThreadStack);\n-    if (MemTracker::tracking_level() == NMT_detail) {\n-      assert(_simple_thread_stacks != nullptr, \"Must be initialized\");\n-      SimpleThreadStackSite site((address)base, size, stack);\n-      _simple_thread_stacks->add(site);\n-    }\n-  }\n+  VirtualMemoryTracker::add_reserved_region((address)base, size, stack, mtThreadStack);\n@@ -68,1 +62,1 @@\n-  assert(MemTracker::tracking_level() >= NMT_summary, \"Must be\");\n+  assert(MemTracker::enabled(), \"Must be\");\n@@ -70,0 +64,2 @@\n+  align_thread_stack_boundaries_inward(base, size);\n+\n@@ -71,12 +67,1 @@\n-  if(track_as_vm()) {\n-    VirtualMemoryTracker::remove_released_region((address)base, size);\n-  } else {\n-    \/\/ Use a slot in mallocMemorySummary for thread stack bookkeeping\n-    MallocMemorySummary::record_free(size, mtThreadStack);\n-    if (MemTracker::tracking_level() == NMT_detail) {\n-      assert(_simple_thread_stacks != nullptr, \"Must be initialized\");\n-      SimpleThreadStackSite site((address)base, size, NativeCallStack::empty_stack()); \/\/ Fake object just to serve as compare target for delete\n-      bool removed = _simple_thread_stacks->remove(site);\n-      assert(removed, \"Must exist\");\n-    }\n-  }\n+  VirtualMemoryTracker::remove_released_region((address)base, size);\n@@ -86,33 +71,0 @@\n-bool ThreadStackTracker::walk_simple_thread_stack_site(MallocSiteWalker* walker) {\n-  if (!track_as_vm()) {\n-    LinkedListImpl<MallocSite> _sites;\n-    {\n-      ThreadCritical tc;\n-      assert(_simple_thread_stacks != nullptr, \"Must be initialized\");\n-      LinkedListIterator<SimpleThreadStackSite> itr(_simple_thread_stacks->head());\n-      const SimpleThreadStackSite* ts = itr.next();\n-      \/\/ Consolidate sites and convert to MallocSites, so we can piggyback into\n-      \/\/ malloc snapshot\n-      while (ts != nullptr) {\n-        MallocSite site(*ts->call_stack(), mtThreadStack);\n-        MallocSite* exist = _sites.find(site);\n-        if (exist != nullptr) {\n-          exist->allocate(ts->size());\n-        } else {\n-          site.allocate(ts->size());\n-          _sites.add(site);\n-        }\n-        ts = itr.next();\n-      }\n-    }\n-\n-    \/\/ Piggyback to malloc snapshot\n-    LinkedListIterator<MallocSite> site_itr(_sites.head());\n-    const MallocSite* s = site_itr.next();\n-    while (s != nullptr) {\n-      walker->do_malloc_site(s);\n-      s = site_itr.next();\n-    }\n-  }\n-  return true;\n-}\n","filename":"src\/hotspot\/share\/nmt\/threadStackTracker.cpp","additions":24,"deletions":72,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2019, 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2019, 2024, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,4 +29,2 @@\n-#include \"nmt\/allocationSite.hpp\"\n-#include \"nmt\/mallocSiteTable.hpp\"\n-#include \"nmt\/nmtCommon.hpp\"\n-#include \"utilities\/linkedlist.hpp\"\n+#include \"memory\/allStatic.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -34,31 +33,0 @@\n-class SimpleThreadStackSite : public AllocationSite {\n-  const address _base;\n-  const size_t  _size;\n-public:\n-  SimpleThreadStackSite(address base, size_t size, const NativeCallStack& stack) :\n-    AllocationSite(stack, mtThreadStack),\n-    _base(base),\n-    _size(size) {}\n-\n-  bool equals(const SimpleThreadStackSite& mts) const {\n-    bool eq = base() == mts.base();\n-    assert(!eq || size() == mts.size(), \"Must match\");\n-    return eq;\n-  }\n-\n-  size_t  size() const { return _size; }\n-  address base() const { return _base; }\n-};\n-\n-  \/*\n-   * Most of platforms, that hotspot support, have their thread stacks backed by\n-   * virtual memory by default. For these cases, thread stack tracker simply\n-   * delegates tracking to virtual memory tracker.\n-   * However, there are exceptions, (e.g. AIX), that platforms can provide stacks\n-   * that are not page aligned. A hypothetical VM implementation, it can provide\n-   * it own stacks. In these case, track_as_vm() should return false and manage\n-   * stack tracking by this tracker internally.\n-   * During memory snapshot, tracked thread stacks memory data is walked and stored\n-   * along with malloc'd data inside baseline. The regions are not scanned and assumed\n-   * all committed for now. Can add scanning phase when there is a need.\n-   *\/\n@@ -68,3 +36,0 @@\n-\n-  static int compare_thread_stack_base(const SimpleThreadStackSite& s1, const SimpleThreadStackSite& s2);\n-  static SortedLinkedList<SimpleThreadStackSite, compare_thread_stack_base>* _simple_thread_stacks;\n@@ -72,2 +37,0 @@\n-  static bool initialize(NMT_TrackingLevel level);\n-\n@@ -76,2 +39,0 @@\n-\n-  static bool   track_as_vm()  { return AIX_ONLY(false) NOT_AIX(true); }\n@@ -79,4 +40,0 @@\n-\n-  \/\/ Snapshot support. Piggyback thread stack data in malloc slot, NMT always handles\n-  \/\/ thread stack slot specially since beginning.\n-  static bool walk_simple_thread_stack_site(MallocSiteWalker* walker);\n","filename":"src\/hotspot\/share\/nmt\/threadStackTracker.hpp","additions":4,"deletions":47,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -50,5 +50,2 @@\n-  \/\/ Only if thread stack is backed by virtual memory\n-  if (ThreadStackTracker::track_as_vm()) {\n-    \/\/ Snapshot current thread stacks\n-    VirtualMemoryTracker::snapshot_thread_stacks();\n-  }\n+  \/\/ Snapshot current thread stacks\n+  VirtualMemoryTracker::snapshot_thread_stacks();\n","filename":"src\/hotspot\/share\/nmt\/virtualMemoryTracker.cpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"}]}