{"files":[{"patch":"@@ -142,7 +142,1 @@\n-     * contention. We approach this by defining the Nodes that we need\n-     * anyway as ThreadLocals, and include in them per-thread index\n-     * and related bookkeeping state. (We can safely reuse per-thread\n-     * nodes rather than creating them fresh each time because slots\n-     * alternate between pointing to a node vs null, so cannot\n-     * encounter ABA problems. However, we do need some care in\n-     * resetting them between uses.)\n+     * contention.\n@@ -150,13 +144,22 @@\n-     * Implementing an effective arena requires allocating a bunch of\n-     * space, so we only do so upon detecting contention (except on\n-     * uniprocessors, where they wouldn't help, so aren't used).\n-     * Otherwise, exchanges use the single-slot slotExchange method.\n-     * On contention, not only must the slots be in different\n-     * locations, but the locations must not encounter memory\n-     * contention due to being on the same cache line (or more\n-     * generally, the same coherence unit).  Because, as of this\n-     * writing, there is no way to determine cacheline size, we define\n-     * a value that is enough for common platforms.  Additionally,\n-     * extra care elsewhere is taken to avoid other false\/unintended\n-     * sharing and to enhance locality, including adding padding (via\n-     * @Contended) to Nodes, embedding \"bound\" as an Exchanger field.\n+     * We approach this by defining the Nodes holding references to\n+     * transfered items as ThreadLocals, and include in them\n+     * per-thread index and related bookkeeping state. We can safely\n+     * reuse per-thread nodes rather than creating them fresh each\n+     * time because slots alternate between pointing to a node vs\n+     * null, so cannot encounter ABA problems. However, we must ensure\n+     * that object transfer fields are reset between uses. Given this,\n+     * Participant nodes can be defined as static ThreadLocals. As\n+     * seen for example in class Striped64, using indices established\n+     * in one instance across others usually improves overall\n+     * performance.  Nodes also include a participant-local random\n+     * number generator.\n+     *\n+     * Spreading out contention requires that the memory locations\n+     * used by the arena slots don't share a cache line -- otherwise,\n+     * the arena would have almost no benefit. We arrange this by\n+     * adding another level of indirection: The arena elements point\n+     * to \"Slots\", each of which is padded using @Contended. We only\n+     * create a single Slot on intialization, adding more when\n+     * needed. The per-thread Participant Nodes may also be subject to\n+     * false-sharing contention, but tend to be more scattered in\n+     * memory, so are unpadded, with some occasional performance impact.\n@@ -166,13 +169,6 @@\n-     * while trying to exchange. By nature of the above algorithm, the\n-     * only kinds of collision that reliably indicate contention are\n-     * when two attempted releases collide -- one of two attempted\n-     * offers can legitimately fail to CAS without indicating\n-     * contention by more than one other thread. (Note: it is possible\n-     * but not worthwhile to more precisely detect contention by\n-     * reading slot values after CAS failures.)  When a thread has\n-     * collided at each slot within the current arena bound, it tries\n-     * to expand the arena size by one. We track collisions within\n-     * bounds by using a version (sequence) number on the \"bound\"\n-     * field, and conservatively reset collision counts when a\n-     * participant notices that bound has been updated (in either\n-     * direction).\n+     * while trying to exchange. And shrink it via \"spinouts\" in which\n+     * threads give up waiting at a slot.  By nature of the above\n+     * algorithm, the only kinds of collision that reliably indicate\n+     * contention are when two attempted releases collide -- one of\n+     * two attempted offers can legitimately fail to CAS without\n+     * indicating contention by more than one other thread.\n@@ -180,25 +176,15 @@\n-     * The effective arena size is reduced (when there is more than\n-     * one slot) by giving up on waiting after a while and trying to\n-     * decrement the arena size on expiration. The value of \"a while\"\n-     * is an empirical matter.  We implement by piggybacking on the\n-     * use of spin->yield->block that is essential for reasonable\n-     * waiting performance anyway -- in a busy exchanger, offers are\n-     * usually almost immediately released, in which case context\n-     * switching on multiprocessors is extremely slow\/wasteful.  Arena\n-     * waits just omit the blocking part, and instead cancel. The spin\n-     * count is empirically chosen to be a value that avoids blocking\n-     * 99% of the time under maximum sustained exchange rates on a\n-     * range of test machines. Spins and yields entail some limited\n-     * randomness (using a cheap xorshift) to avoid regular patterns\n-     * that can induce unproductive grow\/shrink cycles. (Using a\n-     * pseudorandom also helps regularize spin cycle duration by\n-     * making branches unpredictable.)  Also, during an offer, a\n-     * waiter can \"know\" that it will be released when its slot has\n-     * changed, but cannot yet proceed until match is set.  In the\n-     * mean time it cannot cancel the offer, so instead spins\/yields.\n-     * Note: It is possible to avoid this secondary check by changing\n-     * the linearization point to be a CAS of the match field (as done\n-     * in one case in the Scott & Scherer DISC paper), which also\n-     * increases asynchrony a bit, at the expense of poorer collision\n-     * detection and inability to always reuse per-thread nodes. So\n-     * the current scheme is typically a better tradeoff.\n+     * Arena size (the value of field \"bound\") is controlled by random\n+     * sampling. On each miss (collision or spinout), a thread chooses\n+     * a new random index within the arena.  Upon the third collision\n+     * with the same current bound, it tries to grow the arena. And\n+     * upon the second spinout, it tries to shrink. The asymmetry in\n+     * part reflects relative costs, and reduces flailing. Because\n+     * they cannot be changed without also changing the sampling\n+     * strategy, these rules are directly incorporated into uses of\n+     * the xchg \"misses\" variable.  The bound field is tagged with\n+     * sequence numbers to reduce stale decisions. Uniform random\n+     * indices are generated using XorShift with enough bits so that\n+     * bias (See Knuth TAoCP vol 2) is negligible for moduli used here\n+     * (at most 256) without requiring rejection tests. Using\n+     * nonuniform randoms with greater weight to higher indices is\n+     * also possible but does not seem worthwhile in practice.\n@@ -206,11 +192,15 @@\n-     * On collisions, indices traverse the arena cyclically in reverse\n-     * order, restarting at the maximum index (which will tend to be\n-     * sparsest) when bounds change. (On expirations, indices instead\n-     * are halved until reaching 0.) It is possible (and has been\n-     * tried) to use randomized, prime-value-stepped, or double-hash\n-     * style traversal instead of simple cyclic traversal to reduce\n-     * bunching.  But empirically, whatever benefits these may have\n-     * don't overcome their added overhead: We are managing operations\n-     * that occur very quickly unless there is sustained contention,\n-     * so simpler\/faster control policies work better than more\n-     * accurate but slower ones.\n+     * These mechanics rely on a reasonable choice of constant SPINS.\n+     * The time cost of SPINS * Thread.onSpinWait() should be at least\n+     * the expected cost of a park\/unpark context switch, and larger\n+     * than that of two failed CASes, but still small enough to avoid\n+     * excessive delays during arena shrinkage.  We also deal with the\n+     * possibility that when an offering thread waits for a release,\n+     * spin-waiting would be useless because the releasing thread is\n+     * descheduled. On multiprocessors, we cannot know this in\n+     * general. But when Virtual Threads are used, method\n+     * ForkJoinWorkerThread.hasKnownQueuedWork serves as a guide to\n+     * whether to spin or immediately block, allowing a context switch\n+     * that may enable a releaser.  Note also that when many threads\n+     * are being run on few cores, enountering enough collisions to\n+     * trigger arena growth is rare, and soon followed by shrinkage,\n+     * so this doesn't require special handling.\n@@ -218,5 +208,5 @@\n-     * Because we use expiration for arena size control, we cannot\n-     * throw TimeoutExceptions in the timed version of the public\n-     * exchange method until the arena size has shrunken to zero (or\n-     * the arena isn't enabled). This may delay response to timeout\n-     * but is still within spec.\n+     * The basic exchange mechanics rely on checks that Node item\n+     * fields are not null, which doesn't work when offered items are\n+     * null. We trap this case by translating nulls to the\n+     * (un-Exchangeable) value of the static Participant\n+     * reference.\n@@ -224,10 +214,8 @@\n-     * Essentially all of the implementation is in methods\n-     * slotExchange and arenaExchange. These have similar overall\n-     * structure, but differ in too many details to combine. The\n-     * slotExchange method uses the single Exchanger field \"slot\"\n-     * rather than arena array elements. However, it still needs\n-     * minimal collision detection to trigger arena construction.\n-     * (The messiest part is making sure interrupt status and\n-     * InterruptedExceptions come out right during transitions when\n-     * both methods may be called. This is done by using null return\n-     * as a sentinel to recheck interrupt status.)\n+     * Essentially all of the implementation is in method xchg.  As is\n+     * too common in this sort of code, most of the logic relies on\n+     * reads of fields that are maintained as local variables so can't\n+     * be nicely factored. It is structured as a main loop with a\n+     * leading volatile read (of field bound), that causes others to\n+     * be freshly read even though declared in plain mode.  We don't\n+     * use compareAndExchange that would otherwise save some re-reads\n+     * because of the need to recheck indices and bounds on failures.\n@@ -235,18 +223,15 @@\n-     * As is too common in this sort of code, methods are monolithic\n-     * because most of the logic relies on reads of fields that are\n-     * maintained as local variables so can't be nicely factored --\n-     * mainly, here, bulky spin->yield->block\/cancel code.  Note that\n-     * field Node.item is not declared as volatile even though it is\n-     * read by releasing threads, because they only do so after CAS\n-     * operations that must precede access, and all uses by the owning\n-     * thread are otherwise acceptably ordered by other operations.\n-     * (Because the actual points of atomicity are slot CASes, it\n-     * would also be legal for the write to Node.match in a release to\n-     * be weaker than a full volatile write. However, this is not done\n-     * because it could allow further postponement of the write,\n-     * delaying progress.)\n-     *\/\n-\n-    \/**\n-     * The index distance (as a shift value) between any two used slots\n-     * in the arena, spacing them out to avoid false sharing.\n+     * Support for optional timeouts in a single method adds further\n+     * complexity. Note that for the sake of arena bounds control,\n+     * time bounds must be ignored during spinouts, which may delay\n+     * TimeoutExceptions (but no more so than would excessive context\n+     * switching that could occur otherwise).  Responses to\n+     * interruption are handled similarly, postponing commitment to\n+     * throw InterruptedException until successfully cancelled.\n+     *\n+     * Design differences from previous releases include:\n+     * * Accommodation of VirtualThreads.\n+     * * Use of Slots vs spaced indices for the arena and static\n+     *   ThreadLocals, avoiding separate arena vs non-arena modes.\n+     * * Use of random sampling for grow\/shrink decisions, with typically\n+     *   faster and more stable adaptation (as was mentioned as a\n+     *   possible improvement in previous version).\n@@ -254,1 +239,0 @@\n-    private static final int ASHIFT = 5;\n@@ -258,3 +242,3 @@\n-     * arena size is MMASK + 1. Must be a power of two minus one, less\n-     * than (1<<(31-ASHIFT)). The cap of 255 (0xff) more than suffices\n-     * for the expected scaling limits of the main algorithms.\n+     * arena size is MMASK + 1. Must be a power of two minus one. The\n+     * cap of 255 (0xff) more than suffices for the expected scaling\n+     * limits of the main algorithms.\n@@ -270,3 +254,0 @@\n-    \/** The number of CPUs, for sizing and spin control *\/\n-    private static final int NCPU = Runtime.getRuntime().availableProcessors();\n-\n@@ -274,10 +255,2 @@\n-     * The maximum slot index of the arena: The number of slots that\n-     * can in principle hold all threads without contention, or at\n-     * most the maximum indexable value.\n-     *\/\n-    static final int FULL = (NCPU >= (MMASK << 1)) ? MMASK : NCPU >>> 1;\n-\n-    \/**\n-     * The bound for spins while waiting for a match. The actual\n-     * number of iterations will on average be about twice this value\n-     * due to randomization. Note: Spinning is disabled when NCPU==1.\n+     * The bound for spins while waiting for a match before either\n+     * blocking or possibly shrinking arena.\n@@ -288,10 +261,1 @@\n-     * Value representing null arguments\/returns from public\n-     * methods. Needed because the API originally didn't disallow null\n-     * arguments, which it should have.\n-     *\/\n-    private static final Object NULL_ITEM = new Object();\n-\n-    \/**\n-     * Sentinel value returned by internal exchange methods upon\n-     * timeout, to avoid need for separate timed versions of these\n-     * methods.\n+     * Padded arena cells to avoid false-sharing memory contention\n@@ -299,1 +263,4 @@\n-    private static final Object TIMED_OUT = new Object();\n+    @jdk.internal.vm.annotation.Contended\n+    static final class Slot {\n+        Node entry;\n+    }\n@@ -303,1 +270,1 @@\n-     * bookkeeping. Padded via @Contended to reduce memory contention.\n+     * bookkeeping.\n@@ -305,1 +272,2 @@\n-    @jdk.internal.vm.annotation.Contended static final class Node {\n+    static final class Node {\n+        long seed;              \/\/ Random seed\n@@ -307,3 +275,0 @@\n-        int bound;              \/\/ Last recorded value of Exchanger.bound\n-        int collides;           \/\/ Number of CAS failures at current bound\n-        int hash;               \/\/ Pseudo-random for spins\n@@ -313,0 +278,4 @@\n+        Node() {\n+            index = -1;         \/\/ initialize on first use\n+            seed = Thread.currentThread().threadId();\n+        }\n@@ -321,1 +290,4 @@\n-     * Per-thread state.\n+     * The participant thread-locals. Because it is impossible to\n+     * exchange, we also use this reference for dealing with null user\n+     * arguments that are translated in and out of this value\n+     * surrounding use.\n@@ -323,1 +295,1 @@\n-    private final Participant participant;\n+    private static final Participant participant = new Participant();\n@@ -326,2 +298,2 @@\n-     * Elimination array; null until enabled (within slotExchange).\n-     * Element accesses use emulation of volatile gets and CAS.\n+     * Elimination array; element accesses use emulation of volatile\n+     * gets and CAS.\n@@ -329,1 +301,1 @@\n-    private volatile Node[] arena;\n+    private final Slot[] arena;\n@@ -332,1 +304,2 @@\n-     * Slot used until contention detected.\n+     * Number of cores, for sizing and spin control. Computed only\n+     * upon construction.\n@@ -334,1 +307,1 @@\n-    private volatile Node slot;\n+    private final int ncpu;\n@@ -337,4 +310,1 @@\n-     * The index of the largest valid arena position, OR'ed with SEQ\n-     * number in high bits, incremented on each update.  The initial\n-     * update from 0 to SEQ is used to ensure that the arena array is\n-     * constructed only once.\n+     * The index of the largest valid arena position.\n@@ -345,1 +315,1 @@\n-     * Exchange function when arenas enabled. See above for explanation.\n+     * Exchange function. See above for explanation.\n@@ -347,5 +317,5 @@\n-     * @param item the (non-null) item to exchange\n-     * @param timed true if the wait is timed\n-     * @param ns if timed, the maximum wait time, else 0L\n-     * @return the other thread's item; or null if interrupted; or\n-     * TIMED_OUT if timed and timed out\n+     * @param x the item to exchange\n+     * @param deadline if zero, untimed, else timeout deadline\n+     * @return the other thread's item\n+     * @throws InterruptedException if interrupted while waiting\n+     * @throws TimeoutException if deadline nonzero and timed out\n@@ -353,2 +323,3 @@\n-    private final Object arenaExchange(Object item, boolean timed, long ns) {\n-        Node[] a = arena;\n+    private final V xchg(V x, long deadline)\n+        throws InterruptedException, TimeoutException {\n+        Slot[] a = arena;\n@@ -356,14 +327,39 @@\n-        Node p = participant.get();\n-        for (int i = p.index;;) {                      \/\/ access slot at i\n-            int b, m, c;\n-            int j = (i << ASHIFT) + ((1 << ASHIFT) - 1);\n-            if (j < 0 || j >= alen)\n-                j = alen - 1;\n-            Node q = (Node)AA.getAcquire(a, j);\n-            if (q != null && AA.compareAndSet(a, j, q, null)) {\n-                Object v = q.item;                     \/\/ release\n-                q.match = item;\n-                Thread w = q.parked;\n-                if (w != null)\n-                    LockSupport.unpark(w);\n-                return v;\n+        Participant ps = participant;\n+        Object item = (x == null) ? ps : x;      \/\/ translate nulls\n+        Node p = ps.get();\n+        int i = p.index;                         \/\/ if < 0, move\n+        int misses = 0;                          \/\/ ++ on collide, -- on spinout\n+        Object offered = null;                   \/\/ for cleanup\n+        Object v = null;\n+        outer: for (;;) {\n+            int b, m; Slot s; Node q;\n+            if ((m = (b = bound) & MMASK) == 0)  \/\/ volatile read\n+                i = 0;\n+            if (i < 0 || i > m || i >= alen || (s = a[i]) == null) {\n+                long r = p.seed;                 \/\/ randomly move\n+                r ^= r << 13; r ^= r >>> 7; r ^= r << 17; \/\/ xorShift\n+                i = p.index = (int)((p.seed = r) % (m + 1));\n+            }\n+            else if ((q = s.entry) != null) {    \/\/ try release\n+                if (ENTRY.compareAndSet(s, q, null)) {\n+                    Thread w;\n+                    v = q.item;\n+                    q.match = item;\n+                    if (i == 0 && (w = q.parked) != null)\n+                        LockSupport.unpark(w);\n+                    break;\n+                }\n+                else {                           \/\/ collision\n+                    int nb;\n+                    i = -1;                      \/\/ move index\n+                    if (b != bound)              \/\/ stale\n+                        misses = 0;\n+                    else if (misses <= 2)        \/\/ continue sampling\n+                        ++misses;\n+                    else if ((nb = (b + 1) & MMASK) < alen) {\n+                        misses = 0;              \/\/ try to grow\n+                        if (BOUND.compareAndSet(this, b, b + 1 + SEQ) &&\n+                            a[i = p.index = nb] == null)\n+                            AA.compareAndSet(a, nb, null, new Slot());\n+                    }\n+                }\n@@ -371,12 +367,15 @@\n-            else if (i <= (m = (b = bound) & MMASK) && q == null) {\n-                p.item = item;                         \/\/ offer\n-                if (AA.compareAndSet(a, j, null, p)) {\n-                    long end = (timed && m == 0) ? System.nanoTime() + ns : 0L;\n-                    Thread t = Thread.currentThread(); \/\/ wait\n-                    for (int h = p.hash, spins = SPINS;;) {\n-                        Object v = p.match;\n-                        if (v != null) {\n-                            MATCH.setRelease(p, null);\n-                            p.item = null;             \/\/ clear for next use\n-                            p.hash = h;\n-                            return v;\n+            else {                               \/\/ try offer\n+                if (offered == null)\n+                    offered = p.item = item;\n+                if (ENTRY.compareAndSet(s, null, p)) {\n+                    boolean tryCancel;           \/\/ true if interrupted\n+                    Thread t = Thread.currentThread();\n+                    if (!(tryCancel = t.isInterrupted()) && ncpu > 1 &&\n+                        (i != 0 ||               \/\/ check for busy VTs\n+                         (!ForkJoinWorkerThread.hasKnownQueuedWork()))) {\n+                        for (int j = SPINS; j > 0; --j) {\n+                            if ((v = p.match) != null) {\n+                                MATCH.set(p, null);\n+                                break outer;     \/\/ spin wait\n+                            }\n+                            Thread.onSpinWait();\n@@ -384,7 +383,5 @@\n-                        else if (spins > 0) {\n-                            h ^= h << 1; h ^= h >>> 3; h ^= h << 10; \/\/ xorshift\n-                            if (h == 0)                \/\/ initialize hash\n-                                h = SPINS | (int)t.threadId();\n-                            else if (h < 0 &&          \/\/ approx 50% true\n-                                     (--spins & ((SPINS >>> 1) - 1)) == 0)\n-                                Thread.yield();        \/\/ two yields per wait\n+                    }\n+                    for (long ns = 1L;;) {       \/\/ block or cancel offer\n+                        if ((v = p.match) != null) {\n+                            MATCH.set(p, null);\n+                            break outer;\n@@ -392,8 +389,6 @@\n-                        else if (AA.getAcquire(a, j) != p)\n-                            spins = SPINS;       \/\/ releaser hasn't set match yet\n-                        else if (!t.isInterrupted() && m == 0 &&\n-                                 (!timed ||\n-                                  (ns = end - System.nanoTime()) > 0L)) {\n-                            p.parked = t;              \/\/ minimize window\n-                            if (AA.getAcquire(a, j) == p) {\n-                                if (ns == 0L)\n+                        if (i == 0 && !tryCancel &&\n+                            (deadline == 0L ||\n+                             ((ns = deadline - System.nanoTime()) > 0L))) {\n+                            p.parked = t;        \/\/ emable unpark and recheck\n+                            if (p.match == null) {\n+                                if (deadline == 0L)\n@@ -403,0 +398,1 @@\n+                                tryCancel = t.isInterrupted();\n@@ -406,7 +402,2 @@\n-                        else if (AA.getAcquire(a, j) == p &&\n-                                 AA.compareAndSet(a, j, p, null)) {\n-                            if (m != 0)                \/\/ try to shrink\n-                                BOUND.compareAndSet(this, b, b + SEQ - 1);\n-                            p.item = null;\n-                            p.hash = h;\n-                            i = p.index >>>= 1;        \/\/ descend\n+                        else if (ENTRY.compareAndSet(s, p, null)) { \/\/ cancel\n+                            offered = p.item = null;\n@@ -414,4 +405,13 @@\n-                                return null;\n-                            if (timed && m == 0 && ns <= 0L)\n-                                return TIMED_OUT;\n-                            break;                     \/\/ expired; restart\n+                                throw new InterruptedException();\n+                            if (deadline != 0L && ns <= 0L)\n+                                throw new TimeoutException();\n+                            i = -1;              \/\/ move and restart\n+                            if (bound != b)\n+                                misses = 0;      \/\/ stale\n+                            else if (misses >= 0)\n+                                --misses;        \/\/ continue sampling\n+                            else if ((b & MMASK) != 0) {\n+                                misses = 0;      \/\/ try to shrink\n+                                BOUND.compareAndSet(this, b, b - 1 + SEQ);\n+                            }\n+                            continue outer;\n@@ -421,91 +421,0 @@\n-                else\n-                    p.item = null;                     \/\/ clear offer\n-            }\n-            else {\n-                if (p.bound != b) {                    \/\/ stale; reset\n-                    p.bound = b;\n-                    p.collides = 0;\n-                    i = (i != m || m == 0) ? m : m - 1;\n-                }\n-                else if ((c = p.collides) < m || m == FULL ||\n-                         !BOUND.compareAndSet(this, b, b + SEQ + 1)) {\n-                    p.collides = c + 1;\n-                    i = (i == 0) ? m : i - 1;          \/\/ cyclically traverse\n-                }\n-                else\n-                    i = m + 1;                         \/\/ grow\n-                p.index = i;\n-            }\n-        }\n-    }\n-\n-    \/**\n-     * Exchange function used until arenas enabled. See above for explanation.\n-     *\n-     * @param item the item to exchange\n-     * @param timed true if the wait is timed\n-     * @param ns if timed, the maximum wait time, else 0L\n-     * @return the other thread's item; or null if either the arena\n-     * was enabled or the thread was interrupted before completion; or\n-     * TIMED_OUT if timed and timed out\n-     *\/\n-    private final Object slotExchange(Object item, boolean timed, long ns) {\n-        Node p = participant.get();\n-        Thread t = Thread.currentThread();\n-        if (t.isInterrupted()) \/\/ preserve interrupt status so caller can recheck\n-            return null;\n-\n-        for (Node q;;) {\n-            if ((q = slot) != null) {\n-                if (SLOT.compareAndSet(this, q, null)) {\n-                    Object v = q.item;\n-                    q.match = item;\n-                    Thread w = q.parked;\n-                    if (w != null)\n-                        LockSupport.unpark(w);\n-                    return v;\n-                }\n-                \/\/ create arena on contention, but continue until slot null\n-                if (NCPU > 1 && bound == 0 &&\n-                    BOUND.compareAndSet(this, 0, SEQ))\n-                    arena = new Node[(FULL + 2) << ASHIFT];\n-            }\n-            else if (arena != null)\n-                return null; \/\/ caller must reroute to arenaExchange\n-            else {\n-                p.item = item;\n-                if (SLOT.compareAndSet(this, null, p))\n-                    break;\n-                p.item = null;\n-            }\n-        }\n-\n-        \/\/ await release\n-        int h = p.hash;\n-        long end = timed ? System.nanoTime() + ns : 0L;\n-        int spins = (NCPU > 1) ? SPINS : 1;\n-        Object v;\n-        while ((v = p.match) == null) {\n-            if (spins > 0) {\n-                h ^= h << 1; h ^= h >>> 3; h ^= h << 10;\n-                if (h == 0)\n-                    h = SPINS | (int)t.threadId();\n-                else if (h < 0 && (--spins & ((SPINS >>> 1) - 1)) == 0)\n-                    Thread.yield();\n-            }\n-            else if (slot != p)\n-                spins = SPINS;\n-            else if (!t.isInterrupted() && arena == null &&\n-                     (!timed || (ns = end - System.nanoTime()) > 0L)) {\n-                p.parked = t;\n-                if (slot == p) {\n-                    if (ns == 0L)\n-                        LockSupport.park(this);\n-                    else\n-                        LockSupport.parkNanos(this, ns);\n-                }\n-                p.parked = null;\n-            }\n-            else if (SLOT.compareAndSet(this, p, null)) {\n-                v = timed && ns <= 0L && !t.isInterrupted() ? TIMED_OUT : null;\n-                break;\n@@ -514,4 +423,4 @@\n-        MATCH.setRelease(p, null);\n-        p.item = null;\n-        p.hash = h;\n-        return v;\n+        if (offered != null)                     \/\/ cleanup\n+            p.item = null;\n+        @SuppressWarnings(\"unchecked\") V ret = (v == participant) ? null : (V)v;\n+        return ret;\n@@ -524,1 +433,3 @@\n-        participant = new Participant();\n+        int h = (ncpu = Runtime.getRuntime().availableProcessors()) >>> 1;\n+        int size = (h == 0) ? 1 : (h > MMASK) ? MMASK + 1 : h;\n+        (arena = new Slot[size])[0] = new Slot();\n@@ -560,1 +471,0 @@\n-    @SuppressWarnings(\"unchecked\")\n@@ -562,9 +472,5 @@\n-        Object v;\n-        Node[] a;\n-        Object item = (x == null) ? NULL_ITEM : x; \/\/ translate null args\n-        if (((a = arena) != null ||\n-             (v = slotExchange(item, false, 0L)) == null) &&\n-            (Thread.interrupted() || \/\/ disambiguates null return\n-             (v = arenaExchange(item, false, 0L)) == null))\n-            throw new InterruptedException();\n-        return (v == NULL_ITEM) ? null : (V)v;\n+        try {\n+            return xchg(x, 0L);\n+        } catch (TimeoutException cannotHappen) {\n+            return null; \/\/ not reached\n+        }\n@@ -615,1 +521,0 @@\n-    @SuppressWarnings(\"unchecked\")\n@@ -618,11 +523,2 @@\n-        Object v;\n-        Object item = (x == null) ? NULL_ITEM : x;\n-        long ns = unit.toNanos(timeout);\n-        if ((arena != null ||\n-             (v = slotExchange(item, true, ns)) == null) &&\n-            (Thread.interrupted() ||\n-             (v = arenaExchange(item, true, ns)) == null))\n-            throw new InterruptedException();\n-        if (v == TIMED_OUT)\n-            throw new TimeoutException();\n-        return (v == NULL_ITEM) ? null : (V)v;\n+        long d = unit.toNanos(timeout) + System.nanoTime();\n+        return xchg(x, (d == 0L) ? 1L : d); \/\/ avoid zero deadline\n@@ -633,1 +529,0 @@\n-    private static final VarHandle SLOT;\n@@ -635,0 +530,1 @@\n+    private static final VarHandle ENTRY;\n@@ -640,1 +536,0 @@\n-            SLOT = l.findVarHandle(Exchanger.class, \"slot\", Node.class);\n@@ -642,1 +537,2 @@\n-            AA = MethodHandles.arrayElementVarHandle(Node[].class);\n+            ENTRY = l.findVarHandle(Slot.class, \"entry\", Node.class);\n+            AA = MethodHandles.arrayElementVarHandle(Slot[].class);\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/Exchanger.java","additions":223,"deletions":327,"binary":false,"changes":550,"status":"modified"},{"patch":"@@ -42,0 +42,2 @@\n+import jdk.internal.access.JavaLangAccess;\n+import jdk.internal.access.SharedSecrets;\n@@ -205,0 +207,24 @@\n+    \/**\n+     * Returns true if the current task is being executed by a\n+     * ForkJoinWorkerThread that is momentarily known to have one or\n+     * more queued tasks that it could execute immediately. This\n+     * method is approximate and useful only as a heuristic indicator\n+     * within a running task.\n+     *\n+     * @return true if the current task is being executed by a worker\n+     * that has queued work\n+     *\/\n+    static boolean hasKnownQueuedWork() {\n+        ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue q, sq;\n+        ForkJoinPool p; ForkJoinPool.WorkQueue[] qs; int i;\n+        Thread c = JLA.currentCarrierThread();\n+        return ((c instanceof ForkJoinWorkerThread) &&\n+                (p = (wt = (ForkJoinWorkerThread)c).pool) != null &&\n+                (q = wt.workQueue) != null &&\n+                (i = q.source) >= 0 && \/\/ check local and current source queues\n+                (((qs = p.queues) != null && qs.length > i &&\n+                  (sq = qs[i]) != null && sq.top - sq.base > 0) ||\n+                 q.top - q.base > 0));\n+    }\n+    private static final JavaLangAccess JLA = SharedSecrets.getJavaLangAccess();\n+\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinWorkerThread.java","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -429,2 +429,2 @@\n-            if (w.isVirtual())             \/\/ don't spin\n-                spin = false;\n+            if (spin && ForkJoinWorkerThread.hasKnownQueuedWork())\n+                spin = false;              \/\/ don't spin\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/LinkedTransferQueue.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}