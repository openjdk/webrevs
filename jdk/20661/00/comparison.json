{"files":[{"patch":"@@ -268,1 +268,1 @@\n-        \/\/ If we patch code we need both a code patching and a loadload\n+        \/\/ If we patch code we need both a cmodx fence and a loadload\n@@ -276,0 +276,1 @@\n+\n@@ -277,4 +278,10 @@\n-        \/\/ Embed an artificial data dependency to order the guard load\n-        \/\/ before the epoch load.\n-        __ srli(ra, t0, 32);\n-        __ orr(t1, t1, ra);\n+        if (!UseZtso) {\n+          \/\/ Embed an synthetic data dependency to order the guard load\n+          \/\/ before the epoch load. (xor + add is standard way)\n+          \/\/ Note: This may be slower than using a membar(load|load) (fence r,r).\n+          \/\/ Because processors will not start the second load until the first comes back.\n+          \/\/ This means you canâ€™t overlap the two loads,\n+          \/\/ which is stronger than needed for ordering (stronger than TSO).\n+          __ srli(ra, t0, 32);\n+          __ orr(t1, t1, ra);\n+        }\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/shared\/barrierSetAssembler_riscv.cpp","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"}]}