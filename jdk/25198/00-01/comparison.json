{"files":[{"patch":"@@ -306,1 +306,1 @@\n-  _min_last_uncommit_cycle = MIN2(_size, _min_last_uncommit_cycle);\n+  _min_size_watermark = MIN2(_size, _min_size_watermark);\n@@ -455,1 +455,1 @@\n-    _min_last_uncommit_cycle(_size),\n+    _min_size_watermark(_size),\n@@ -555,3 +555,1 @@\n-size_t ZMappedCache::reset_uncommit_cycle() {\n-  const size_t old_min = _min_last_uncommit_cycle;\n-\n+void ZMappedCache::reset_uncommit_cycle() {\n@@ -559,1 +557,2 @@\n-  _min_last_uncommit_cycle = _size;\n+  _min_size_watermark = _size;\n+}\n@@ -561,1 +560,2 @@\n-  return old_min;\n+size_t ZMappedCache::uncommit_watermark() {\n+  return _min_size_watermark;\n@@ -566,1 +566,1 @@\n-      _min_last_uncommit_cycle < _removed_last_uncommit_cycle\n+      _min_size_watermark < _removed_last_uncommit_cycle\n@@ -568,1 +568,1 @@\n-          : _min_last_uncommit_cycle - _removed_last_uncommit_cycle;\n+          : _min_size_watermark - _removed_last_uncommit_cycle;\n","filename":"src\/hotspot\/share\/gc\/z\/zMappedCache.cpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-  size_t        _min_last_uncommit_cycle;\n+  size_t        _min_size_watermark;\n@@ -106,1 +106,2 @@\n-  size_t reset_uncommit_cycle();\n+  void reset_uncommit_cycle();\n+  size_t uncommit_watermark();\n","filename":"src\/hotspot\/share\/gc\/z\/zMappedCache.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -629,1 +629,1 @@\n-    _uncommitter.cancel_uncommit_cycle(&_cache);\n+    _uncommitter.cancel_uncommit_cycle();\n@@ -738,80 +738,0 @@\n-size_t ZPartition::uncommit() {\n-  ZArray<ZVirtualMemory> flushed_vmems;\n-  size_t flushed = 0;\n-\n-  {\n-    \/\/ We need to join the suspendible thread set while manipulating capacity\n-    \/\/ and used, to make sure GC safepoints will have a consistent view.\n-    SuspendibleThreadSetJoiner sts_joiner;\n-    ZLocker<ZLock> locker(&_page_allocator->_lock);\n-\n-    if (_uncommitter.uncommit_cycle_is_canceled()) {\n-      \/\/ We have committed within the delay, stop uncommitting.\n-      return 0;\n-    }\n-\n-    \/\/ We flush out and uncommit chunks at a time (~0.8% of the max capacity,\n-    \/\/ but at least one granule and at most 256M), in case demand for memory\n-    \/\/ increases while we are uncommitting.\n-    const size_t limit_upper_bound = MAX2(ZGranuleSize, align_down(256 * M \/ ZNUMA::count(), ZGranuleSize));\n-    const size_t limit = MIN2(align_up(_current_max_capacity >> 7, ZGranuleSize), limit_upper_bound);\n-\n-    if (limit == 0) {\n-      \/\/ This may occur if the current max capacity for this partition is 0\n-\n-      _uncommitter.cancel_uncommit_cycle(&_cache);\n-      return 0;\n-    }\n-\n-    if (!_uncommitter.uncommit_cycle_is_active()) {\n-      \/\/ We are activating a new cycle\n-      const size_t uncommit_limit = _capacity - _min_capacity;\n-      _uncommitter.activate_uncommit_cycle(&_cache, uncommit_limit);\n-    }\n-\n-    const size_t to_uncommit = _uncommitter.to_uncommit();\n-\n-    \/\/ Never uncommit below min capacity.\n-    const size_t retain = MAX2(_used, _min_capacity);\n-    const size_t release = _capacity - retain;\n-    const size_t flush = MIN3(release, limit, to_uncommit);\n-\n-    if (flush == 0) {\n-      \/\/ Nothing to flush\n-      _uncommitter.cancel_uncommit_cycle(&_cache);\n-      return 0;\n-    }\n-\n-    \/\/ Flush memory from the mapped cache to uncommit\n-    flushed = _cache.remove_for_uncommit(flush, &flushed_vmems);\n-    if (flushed == 0) {\n-      \/\/ Nothing flushed\n-      _uncommitter.cancel_uncommit_cycle(&_cache);\n-      return 0;\n-    }\n-\n-    \/\/ Record flushed memory as claimed and how much we've flushed for this partition\n-    Atomic::add(&_claimed, flushed);\n-  }\n-\n-  \/\/ Unmap and uncommit flushed memory\n-  for (const ZVirtualMemory vmem : flushed_vmems) {\n-    unmap_virtual(vmem);\n-    uncommit_physical(vmem);\n-    free_physical(vmem);\n-    free_virtual(vmem);\n-  }\n-\n-  {\n-    SuspendibleThreadSetJoiner sts_joiner;\n-    ZLocker<ZLock> locker(&_page_allocator->_lock);\n-\n-    \/\/ Adjust claimed and capacity to reflect the uncommit\n-    Atomic::sub(&_claimed, flushed);\n-    decrease_capacity(flushed, false \/* set_max_capacity *\/);\n-    _uncommitter.register_uncommit(flushed);\n-  }\n-\n-  return flushed;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.cpp","additions":1,"deletions":81,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+  friend class ZUncommitter;\n@@ -102,4 +103,0 @@\n-  template <typename Fn>\n-  void evaluate_under_lock(Fn function) const;\n-  size_t uncommit();\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -29,6 +29,0 @@\n-template <typename Fn>\n-void ZPartition::evaluate_under_lock(Fn function) const {\n-  ZLocker<ZLock> locker(&_page_allocator->_lock);\n-  function();\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.inline.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/z\/zNUMA.inline.hpp\"\n@@ -103,0 +104,1 @@\n+    Tickspan accumulated_time;\n@@ -106,1 +108,1 @@\n-      const size_t uncommitted = _partition->uncommit();\n+      const size_t uncommitted = uncommit();\n@@ -120,0 +122,2 @@\n+        Ticks end = Ticks::now();\n+\n@@ -121,1 +125,4 @@\n-        EventZUncommit::commit(start, Ticks::now(), uncommitted_since_last_timeout);\n+        EventZUncommit::commit(start, end, uncommitted_since_last_timeout);\n+\n+        \/\/ Track accumulated time\n+        accumulated_time += end - start;\n@@ -133,3 +140,0 @@\n-      log_info(gc, heap)(\"Uncommitter (%u) Uncommitted: %zuM(%.0f%%)\",\n-                         _id, _uncommitted \/ M, percent_of(_uncommitted, ZHeap::heap()->max_capacity()));\n-\n@@ -140,0 +144,2 @@\n+        Ticks end = Ticks::now();\n+\n@@ -141,1 +147,4 @@\n-        EventZUncommit::commit(start, Ticks::now(), uncommitted_since_last_timeout);\n+        EventZUncommit::commit(start, end, uncommitted_since_last_timeout);\n+\n+        \/\/ Track accumulated time\n+        accumulated_time += end - start;\n@@ -143,0 +152,4 @@\n+\n+      log_info(gc, heap)(\"Uncommitter (%u) Uncommitted: %zuM(%.0f%%) in %fs\",\n+                         _id, _uncommitted \/ M, percent_of(_uncommitted, ZHeap::heap()->max_capacity()),\n+                         accumulated_time.seconds());\n@@ -161,3 +174,1 @@\n-  _partition->evaluate_under_lock([&]() {\n-    precond(uncommit_cycle_is_active() || uncommit_cycle_is_canceled());\n-    precond(uncommit_cycle_is_finished() || uncommit_cycle_is_canceled());\n+  ZLocker<ZLock> locker(&_partition->_page_allocator->_lock);\n@@ -165,6 +176,2 @@\n-    \/\/ Update the next timeout\n-    if (uncommit_cycle_is_canceled()) {\n-      update_next_cycle_timeout_on_cancel();\n-    } else {\n-      update_next_cycle_timeout_on_finish();\n-    }\n+  precond(uncommit_cycle_is_active() || uncommit_cycle_is_canceled());\n+  precond(uncommit_cycle_is_finished() || uncommit_cycle_is_canceled());\n@@ -172,5 +179,6 @@\n-    \/\/ Reset the cycle\n-    _to_uncommit = 0;\n-    _uncommitted = 0;\n-    _cycle_start = 0.0;\n-    _cancel_time = 0.0;\n+  \/\/ Update the next timeout\n+  if (uncommit_cycle_is_canceled()) {\n+    update_next_cycle_timeout_on_cancel();\n+  } else {\n+    update_next_cycle_timeout_on_finish();\n+  }\n@@ -178,4 +186,9 @@\n-    postcond(uncommit_cycle_is_finished());\n-    postcond(!uncommit_cycle_is_canceled());\n-    postcond(!uncommit_cycle_is_active());\n-  });\n+  \/\/ Reset the cycle\n+  _to_uncommit = 0;\n+  _uncommitted = 0;\n+  _cycle_start = 0.0;\n+  _cancel_time = 0.0;\n+\n+  postcond(uncommit_cycle_is_finished());\n+  postcond(!uncommit_cycle_is_canceled());\n+  postcond(!uncommit_cycle_is_active());\n@@ -184,1 +197,1 @@\n-void ZUncommitter::activate_uncommit_cycle(ZMappedCache* cache, size_t uncommit_limit) {\n+void ZUncommitter::activate_uncommit_cycle() {\n@@ -188,1 +201,2 @@\n-  precond(is_aligned(uncommit_limit, ZGranuleSize));\n+\n+  ZMappedCache* const cache = &_partition->_cache;\n@@ -192,1 +206,11 @@\n-  _to_uncommit = MIN2(uncommit_limit, cache->reset_uncommit_cycle());\n+\n+  \/\/ Read watermark from cache\n+  const size_t uncommit_watermark = cache->uncommit_watermark();\n+\n+  \/\/ Keep 10% as a headroom\n+  const size_t to_uncommit = align_up(size_t(double(uncommit_watermark) * 0.9), ZGranuleSize);\n+\n+  \/\/ Never uncommit below min capacity\n+  const size_t uncommit_limit = _partition->_capacity - _partition->_min_capacity;\n+\n+  _to_uncommit = MIN2(uncommit_limit, to_uncommit);\n@@ -195,2 +219,2 @@\n-  postcond(is_aligned(_to_uncommit, ZGranuleSize));\n-}\n+  \/\/ Reset cache for next uncommit cycle\n+  cache->reset_uncommit_cycle();\n@@ -198,2 +222,1 @@\n-size_t ZUncommitter::to_uncommit() const {\n-  return _to_uncommit;\n+  postcond(is_aligned(_to_uncommit, ZGranuleSize));\n@@ -236,1 +259,1 @@\n-void ZUncommitter::cancel_uncommit_cycle(ZMappedCache* cache) {\n+void ZUncommitter::cancel_uncommit_cycle() {\n@@ -238,1 +261,1 @@\n-  cache->reset_uncommit_cycle();\n+  _partition->_cache.reset_uncommit_cycle();\n@@ -271,1 +294,1 @@\n-  const double time_to_compleat = double(_to_uncommit) \/ uncommit_rate;\n+  const double time_to_complete = double(_to_uncommit) \/ uncommit_rate;\n@@ -274,2 +297,2 @@\n-  if (time_left < time_to_compleat) {\n-    \/\/ To slow, work as fast as we can.\n+  if (time_left < time_to_complete) {\n+    \/\/ Too slow, work as fast as we can.\n@@ -290,1 +313,1 @@\n-  const double extra_time = time_left - time_to_compleat;\n+  const double extra_time = time_left - time_to_complete;\n@@ -307,0 +330,72 @@\n+\n+size_t ZUncommitter::uncommit() {\n+  ZArray<ZVirtualMemory> flushed_vmems;\n+  size_t flushed = 0;\n+\n+  {\n+    \/\/ We need to join the suspendible thread set while manipulating capacity\n+    \/\/ and used, to make sure GC safepoints will have a consistent view.\n+    SuspendibleThreadSetJoiner sts_joiner;\n+    ZLocker<ZLock> locker(&_partition->_page_allocator->_lock);\n+\n+    if (uncommit_cycle_is_canceled()) {\n+      \/\/ We have committed within the delay, stop uncommitting.\n+      return 0;\n+    }\n+\n+    \/\/ We flush out and uncommit chunks at a time (~0.8% of the max capacity,\n+    \/\/ but at least one granule and at most 256M), in case demand for memory\n+    \/\/ increases while we are uncommitting.\n+    const size_t current_max_capacity = _partition->_current_max_capacity;\n+    const size_t limit_upper_bound = MAX2(ZGranuleSize, align_down(256 * M \/ ZNUMA::count(), ZGranuleSize));\n+    const size_t limit = MIN2(align_up(current_max_capacity >> 7, ZGranuleSize), limit_upper_bound);\n+\n+    if (limit == 0) {\n+      \/\/ This may occur if the current max capacity for this partition is 0\n+\n+      cancel_uncommit_cycle();\n+      return 0;\n+    }\n+\n+    if (!uncommit_cycle_is_active()) {\n+      \/\/ We are activating a new cycle\n+      activate_uncommit_cycle();\n+    }\n+\n+    \/\/ Never uncommit below min capacity.\n+    const size_t retain = MAX2(_partition->_used, _partition->_min_capacity);\n+    const size_t release = _partition->_capacity - retain;\n+    const size_t flush = MIN3(release, limit, _to_uncommit);\n+\n+    \/\/ Flush memory from the mapped cache for uncommit\n+    flushed = _partition->_cache.remove_for_uncommit(flush, &flushed_vmems);\n+    if (flushed == 0) {\n+      \/\/ Nothing flushed\n+      cancel_uncommit_cycle();\n+      return 0;\n+    }\n+\n+    \/\/ Record flushed memory as claimed and how much we've flushed for this partition\n+    Atomic::add(&_partition->_claimed, flushed);\n+  }\n+\n+  \/\/ Unmap and uncommit flushed memory\n+  for (const ZVirtualMemory vmem : flushed_vmems) {\n+    _partition->unmap_virtual(vmem);\n+    _partition->uncommit_physical(vmem);\n+    _partition->free_physical(vmem);\n+    _partition->free_virtual(vmem);\n+  }\n+\n+  {\n+    SuspendibleThreadSetJoiner sts_joiner;\n+    ZLocker<ZLock> locker(&_partition->_page_allocator->_lock);\n+\n+    \/\/ Adjust claimed and capacity to reflect the uncommit\n+    Atomic::sub(&_partition->_claimed, flushed);\n+    _partition->decrease_capacity(flushed, false \/* set_max_capacity *\/);\n+    register_uncommit(flushed);\n+  }\n+\n+  return flushed;\n+}\n","filename":"src\/hotspot\/share\/gc\/z\/zUncommitter.cpp","additions":132,"deletions":37,"binary":false,"changes":169,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-class ZMappedCache;\n@@ -56,0 +55,8 @@\n+  void activate_uncommit_cycle();\n+  void register_uncommit(size_t size);\n+\n+  bool uncommit_cycle_is_finished() const;\n+  bool uncommit_cycle_is_active() const;\n+  bool uncommit_cycle_is_canceled() const;\n+\n+  size_t uncommit();\n@@ -64,8 +71,1 @@\n-  void activate_uncommit_cycle(ZMappedCache* cache, size_t uncommit_limit);\n-  size_t to_uncommit() const;\n-  void cancel_uncommit_cycle(ZMappedCache* cache);\n-  void register_uncommit(size_t size);\n-\n-  bool uncommit_cycle_is_finished() const;\n-  bool uncommit_cycle_is_active() const;\n-  bool uncommit_cycle_is_canceled() const;\n+  void cancel_uncommit_cycle();\n","filename":"src\/hotspot\/share\/gc\/z\/zUncommitter.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"}]}