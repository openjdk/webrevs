{"files":[{"patch":"@@ -149,2 +149,0 @@\n-  if (!InlineIntrinsics) return NULL; \/\/ Generate a vanilla entry\n-\n@@ -304,6 +302,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16)) {\n-    return nullptr;\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -326,6 +319,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16)) {\n-    return nullptr;\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -966,2 +954,2 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -969,3 +957,3 @@\n-    \/\/ rmethod: Method*\n-    \/\/ r19_sender_sp: senderSP must preserved for slow path\n-    \/\/ esp: args\n+  \/\/ rmethod: Method*\n+  \/\/ r19_sender_sp: senderSP must preserved for slow path\n+  \/\/ esp: args\n@@ -973,3 +961,3 @@\n-    Label slow_path;\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+  Label slow_path;\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -977,2 +965,2 @@\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n@@ -980,4 +968,4 @@\n-    \/\/ Load parameters\n-    const Register crc = c_rarg0;  \/\/ crc\n-    const Register val = c_rarg1;  \/\/ source java byte value\n-    const Register tbl = c_rarg2;  \/\/ scratch\n+  \/\/ Load parameters\n+  const Register crc = c_rarg0;  \/\/ crc\n+  const Register val = c_rarg1;  \/\/ source java byte value\n+  const Register tbl = c_rarg2;  \/\/ scratch\n@@ -985,3 +973,3 @@\n-    \/\/ Arguments are reversed on java expression stack\n-    __ ldrw(val, Address(esp, 0));              \/\/ byte value\n-    __ ldrw(crc, Address(esp, wordSize));       \/\/ Initial CRC\n+  \/\/ Arguments are reversed on java expression stack\n+  __ ldrw(val, Address(esp, 0));              \/\/ byte value\n+  __ ldrw(crc, Address(esp, wordSize));       \/\/ Initial CRC\n@@ -989,3 +977,3 @@\n-    uint64_t offset;\n-    __ adrp(tbl, ExternalAddress(StubRoutines::crc_table_addr()), offset);\n-    __ add(tbl, tbl, offset);\n+  uint64_t offset;\n+  __ adrp(tbl, ExternalAddress(StubRoutines::crc_table_addr()), offset);\n+  __ add(tbl, tbl, offset);\n@@ -993,3 +981,3 @@\n-    __ mvnw(crc, crc); \/\/ ~crc\n-    __ update_byte_crc32(crc, val, tbl);\n-    __ mvnw(crc, crc); \/\/ ~crc\n+  __ mvnw(crc, crc); \/\/ ~crc\n+  __ update_byte_crc32(crc, val, tbl);\n+  __ mvnw(crc, crc); \/\/ ~crc\n@@ -997,1 +985,1 @@\n-    \/\/ result in c_rarg0\n+  \/\/ result in c_rarg0\n@@ -999,2 +987,2 @@\n-    __ andr(sp, r19_sender_sp, -16);\n-    __ ret(lr);\n+  __ andr(sp, r19_sender_sp, -16);\n+  __ ret(lr);\n@@ -1002,6 +990,4 @@\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -1016,2 +1002,2 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -1019,32 +1005,32 @@\n-    \/\/ rmethod,: Method*\n-    \/\/ r19_sender_sp: senderSP must preserved for slow path\n-\n-    Label slow_path;\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters\n-    const Register crc = c_rarg0;  \/\/ crc\n-    const Register buf = c_rarg1;  \/\/ source java byte array address\n-    const Register len = c_rarg2;  \/\/ length\n-    const Register off = len;      \/\/ offset (never overlaps with 'len')\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    \/\/ Calculate address of start element\n-    if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n-      __ ldr(buf, Address(esp, 2*wordSize)); \/\/ long buf\n-      __ ldrw(off, Address(esp, wordSize)); \/\/ offset\n-      __ add(buf, buf, off); \/\/ + offset\n-      __ ldrw(crc,   Address(esp, 4*wordSize)); \/\/ Initial CRC\n-    } else {\n-      __ ldr(buf, Address(esp, 2*wordSize)); \/\/ byte[] array\n-      __ add(buf, buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ ldrw(off, Address(esp, wordSize)); \/\/ offset\n-      __ add(buf, buf, off); \/\/ + offset\n-      __ ldrw(crc,   Address(esp, 3*wordSize)); \/\/ Initial CRC\n-    }\n-    \/\/ Can now load 'len' since we're finished with 'off'\n-    __ ldrw(len, Address(esp, 0x0)); \/\/ Length\n+  \/\/ rmethod,: Method*\n+  \/\/ r19_sender_sp: senderSP must preserved for slow path\n+\n+  Label slow_path;\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ safepoint_poll(slow_path, false \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n+\n+  \/\/ Load parameters\n+  const Register crc = c_rarg0;  \/\/ crc\n+  const Register buf = c_rarg1;  \/\/ source java byte array address\n+  const Register len = c_rarg2;  \/\/ length\n+  const Register off = len;      \/\/ offset (never overlaps with 'len')\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  \/\/ Calculate address of start element\n+  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n+    __ ldr(buf, Address(esp, 2*wordSize)); \/\/ long buf\n+    __ ldrw(off, Address(esp, wordSize)); \/\/ offset\n+    __ add(buf, buf, off); \/\/ + offset\n+    __ ldrw(crc,   Address(esp, 4*wordSize)); \/\/ Initial CRC\n+  } else {\n+    __ ldr(buf, Address(esp, 2*wordSize)); \/\/ byte[] array\n+    __ add(buf, buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ ldrw(off, Address(esp, wordSize)); \/\/ offset\n+    __ add(buf, buf, off); \/\/ + offset\n+    __ ldrw(crc,   Address(esp, 3*wordSize)); \/\/ Initial CRC\n+  }\n+  \/\/ Can now load 'len' since we're finished with 'off'\n+  __ ldrw(len, Address(esp, 0x0)); \/\/ Length\n@@ -1052,1 +1038,1 @@\n-    __ andr(sp, r19_sender_sp, -16); \/\/ Restore the caller's SP\n+  __ andr(sp, r19_sender_sp, -16); \/\/ Restore the caller's SP\n@@ -1054,2 +1040,2 @@\n-    \/\/ We are frameless so we can just jump to the stub.\n-    __ b(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()));\n+  \/\/ We are frameless so we can just jump to the stub.\n+  __ b(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()));\n@@ -1057,6 +1043,4 @@\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -1073,10 +1057,2 @@\n-  if (UseCRC32CIntrinsics) {\n-    address entry = __ pc();\n-\n-    \/\/ Prepare jump to stub using parameters from the stack\n-    const Register crc = c_rarg0; \/\/ initial crc\n-    const Register buf = c_rarg1; \/\/ source java byte array address\n-    const Register len = c_rarg2; \/\/ len argument to the kernel\n-\n-    const Register end = len; \/\/ index of last element to process\n-    const Register off = crc; \/\/ offset\n+  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -1084,11 +1060,19 @@\n-    __ ldrw(end, Address(esp)); \/\/ int end\n-    __ ldrw(off, Address(esp, wordSize)); \/\/ int offset\n-    __ sub(len, end, off);\n-    __ ldr(buf, Address(esp, 2*wordSize)); \/\/ byte[] buf | long buf\n-    __ add(buf, buf, off); \/\/ + offset\n-    if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n-      __ ldrw(crc, Address(esp, 4*wordSize)); \/\/ long crc\n-    } else {\n-      __ add(buf, buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ ldrw(crc, Address(esp, 3*wordSize)); \/\/ long crc\n-    }\n+  \/\/ Prepare jump to stub using parameters from the stack\n+  const Register crc = c_rarg0; \/\/ initial crc\n+  const Register buf = c_rarg1; \/\/ source java byte array address\n+  const Register len = c_rarg2; \/\/ len argument to the kernel\n+\n+  const Register end = len; \/\/ index of last element to process\n+  const Register off = crc; \/\/ offset\n+\n+  __ ldrw(end, Address(esp)); \/\/ int end\n+  __ ldrw(off, Address(esp, wordSize)); \/\/ int offset\n+  __ sub(len, end, off);\n+  __ ldr(buf, Address(esp, 2*wordSize)); \/\/ byte[] buf | long buf\n+  __ add(buf, buf, off); \/\/ + offset\n+  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n+    __ ldrw(crc, Address(esp, 4*wordSize)); \/\/ long crc\n+  } else {\n+    __ add(buf, buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ ldrw(crc, Address(esp, 3*wordSize)); \/\/ long crc\n+  }\n@@ -1096,1 +1080,1 @@\n-    __ andr(sp, r19_sender_sp, -16); \/\/ Restore the caller's SP\n+  __ andr(sp, r19_sender_sp, -16); \/\/ Restore the caller's SP\n@@ -1098,2 +1082,2 @@\n-    \/\/ Jump to the stub.\n-    __ b(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()));\n+  \/\/ Jump to the stub.\n+  __ b(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()));\n@@ -1101,3 +1085,1 @@\n-    return entry;\n-  }\n-  return NULL;\n+  return entry;\n@@ -1745,0 +1727,5 @@\n+\/\/ Not supported\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":103,"deletions":116,"binary":false,"changes":219,"status":"modified"},{"patch":"@@ -125,2 +125,0 @@\n-  if (!InlineIntrinsics) return nullptr; \/\/ Generate a vanilla entry\n-\n@@ -783,0 +781,1 @@\n+address TemplateInterpreterGenerator::generate_currentThread() { return nullptr; }\n@@ -786,0 +785,4 @@\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n","filename":"src\/hotspot\/cpu\/arm\/templateInterpreterGenerator_arm.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1749,3 +1749,3 @@\n-  if (UseCRC32Intrinsics) {\n-    address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n-    Label slow_path;\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n+  Label slow_path;\n@@ -1753,3 +1753,3 @@\n-    \/\/ Safepoint check\n-    const Register sync_state = R11_scratch1;\n-    __ safepoint_poll(slow_path, sync_state, false \/* at_return *\/, false \/* in_nmethod *\/);\n+  \/\/ Safepoint check\n+  const Register sync_state = R11_scratch1;\n+  __ safepoint_poll(slow_path, sync_state, false \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -1757,3 +1757,3 @@\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we not even call stub code (we generate the code inline)\n-    \/\/ and there is no safepoint on this path.\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we not even call stub code (we generate the code inline)\n+  \/\/ and there is no safepoint on this path.\n@@ -1761,6 +1761,6 @@\n-    \/\/ Load java parameters.\n-    \/\/ R15_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = R15_esp;\n-    const Register crc     = R3_ARG1;  \/\/ crc value\n-    const Register data    = R4_ARG2;\n-    const Register table   = R5_ARG3;  \/\/ address of crc32 table\n+  \/\/ Load java parameters.\n+  \/\/ R15_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = R15_esp;\n+  const Register crc     = R3_ARG1;  \/\/ crc value\n+  const Register data    = R4_ARG2;\n+  const Register table   = R5_ARG3;  \/\/ address of crc32 table\n@@ -1768,1 +1768,1 @@\n-    BLOCK_COMMENT(\"CRC32_update {\");\n+  BLOCK_COMMENT(\"CRC32_update {\");\n@@ -1770,1 +1770,1 @@\n-    \/\/ Arguments are reversed on java expression stack\n+  \/\/ Arguments are reversed on java expression stack\n@@ -1772,2 +1772,2 @@\n-    int data_offs = 0+1*wordSize;      \/\/ (stack) address of byte value. Emitter expects address, not value.\n-                                       \/\/ Being passed as an int, the single byte is at offset +0.\n+  int data_offs = 0+1*wordSize;      \/\/ (stack) address of byte value. Emitter expects address, not value.\n+                                     \/\/ Being passed as an int, the single byte is at offset +0.\n@@ -1775,2 +1775,2 @@\n-    int data_offs = 3+1*wordSize;      \/\/ (stack) address of byte value. Emitter expects address, not value.\n-                                       \/\/ Being passed from java as an int, the single byte is at offset +3.\n+  int data_offs = 3+1*wordSize;      \/\/ (stack) address of byte value. Emitter expects address, not value.\n+                                     \/\/ Being passed from java as an int, the single byte is at offset +3.\n@@ -1778,15 +1778,8 @@\n-    __ lwz(crc, 2*wordSize, argP);     \/\/ Current crc state, zero extend to 64 bit to have a clean register.\n-    __ lbz(data, data_offs, argP);     \/\/ Byte from buffer, zero-extended.\n-    __ load_const_optimized(table, StubRoutines::crc_table_addr(), R0);\n-    __ kernel_crc32_singleByteReg(crc, data, table, true);\n-\n-    \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n-    __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n-    __ blr();\n-\n-    \/\/ Generate a vanilla native entry as the slow path.\n-    BLOCK_COMMENT(\"} CRC32_update\");\n-    BIND(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), R11_scratch1);\n-    return start;\n-  }\n+  __ lwz(crc, 2*wordSize, argP);     \/\/ Current crc state, zero extend to 64 bit to have a clean register.\n+  __ lbz(data, data_offs, argP);     \/\/ Byte from buffer, zero-extended.\n+  __ load_const_optimized(table, StubRoutines::crc_table_addr(), R0);\n+  __ kernel_crc32_singleByteReg(crc, data, table, true);\n+\n+  \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n+  __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n+  __ blr();\n@@ -1794,1 +1787,5 @@\n-  return NULL;\n+  \/\/ Generate a vanilla native entry as the slow path.\n+  BLOCK_COMMENT(\"} CRC32_update\");\n+  BIND(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), R11_scratch1);\n+  return start;\n@@ -1803,48 +1800,3 @@\n-  if (UseCRC32Intrinsics) {\n-    address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n-    Label slow_path;\n-\n-    \/\/ Safepoint check\n-    const Register sync_state = R11_scratch1;\n-    __ safepoint_poll(slow_path, sync_state, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we not even call stub code (we generate the code inline)\n-    \/\/ and there is no safepoint on this path.\n-\n-    \/\/ Load parameters.\n-    \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = R15_esp;\n-    const Register crc     = R3_ARG1;  \/\/ crc value\n-    const Register data    = R4_ARG2;  \/\/ address of java byte array\n-    const Register dataLen = R5_ARG3;  \/\/ source data len\n-    const Register tmp     = R11_scratch1;\n-\n-    \/\/ Arguments are reversed on java expression stack.\n-    \/\/ Calculate address of start element.\n-    if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n-      BLOCK_COMMENT(\"CRC32_updateByteBuffer {\");\n-      \/\/ crc     @ (SP + 5W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off\n-      __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n-      __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n-      __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-      __ lwz( crc,     5*wordSize, argP);  \/\/ current crc state\n-      __ add( data, data, tmp);            \/\/ Add byte buffer offset.\n-    } else {                                                         \/\/ Used for \"updateBytes update\".\n-      BLOCK_COMMENT(\"CRC32_updateBytes {\");\n-      \/\/ crc     @ (SP + 4W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off + base_offset\n-      __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n-      __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n-      __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-      __ add( data, data, tmp);            \/\/ add byte buffer offset\n-      __ lwz( crc,     4*wordSize, argP);  \/\/ current crc state\n-      __ addi(data, data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n-    }\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n+  Label slow_path;\n@@ -1852,1 +1804,44 @@\n-    __ crc32(crc, data, dataLen, R2, R6, R7, R8, R9, R10, R11, R12, false);\n+  \/\/ Safepoint check\n+  const Register sync_state = R11_scratch1;\n+  __ safepoint_poll(slow_path, sync_state, false \/* at_return *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we not even call stub code (we generate the code inline)\n+  \/\/ and there is no safepoint on this path.\n+\n+  \/\/ Load parameters.\n+  \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = R15_esp;\n+  const Register crc     = R3_ARG1;  \/\/ crc value\n+  const Register data    = R4_ARG2;  \/\/ address of java byte array\n+  const Register dataLen = R5_ARG3;  \/\/ source data len\n+  const Register tmp     = R11_scratch1;\n+\n+  \/\/ Arguments are reversed on java expression stack.\n+  \/\/ Calculate address of start element.\n+  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n+    BLOCK_COMMENT(\"CRC32_updateByteBuffer {\");\n+    \/\/ crc     @ (SP + 5W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off\n+    __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n+    __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n+    __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+    __ lwz( crc,     5*wordSize, argP);  \/\/ current crc state\n+    __ add( data, data, tmp);            \/\/ Add byte buffer offset.\n+  } else {                                                         \/\/ Used for \"updateBytes update\".\n+    BLOCK_COMMENT(\"CRC32_updateBytes {\");\n+    \/\/ crc     @ (SP + 4W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off + base_offset\n+    __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n+    __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n+    __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+    __ add( data, data, tmp);            \/\/ add byte buffer offset\n+    __ lwz( crc,     4*wordSize, argP);  \/\/ current crc state\n+    __ addi(data, data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  }\n@@ -1854,3 +1849,1 @@\n-    \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n-    __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n-    __ blr();\n+  __ crc32(crc, data, dataLen, R2, R6, R7, R8, R9, R10, R11, R12, false);\n@@ -1858,6 +1851,3 @@\n-    \/\/ Generate a vanilla native entry as the slow path.\n-    BLOCK_COMMENT(\"} CRC32_updateBytes(Buffer)\");\n-    BIND(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), R11_scratch1);\n-    return start;\n-  }\n+  \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n+  __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n+  __ blr();\n@@ -1865,1 +1855,5 @@\n-  return NULL;\n+  \/\/ Generate a vanilla native entry as the slow path.\n+  BLOCK_COMMENT(\"} CRC32_updateBytes(Buffer)\");\n+  BIND(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), R11_scratch1);\n+  return start;\n@@ -1877,47 +1871,45 @@\n-  if (UseCRC32CIntrinsics) {\n-    address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we not even call stub code (we generate the code inline)\n-    \/\/ and there is no safepoint on this path.\n-\n-    \/\/ Load parameters.\n-    \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = R15_esp;\n-    const Register crc     = R3_ARG1;  \/\/ crc value\n-    const Register data    = R4_ARG2;  \/\/ address of java byte array\n-    const Register dataLen = R5_ARG3;  \/\/ source data len\n-    const Register tmp     = R11_scratch1;\n-\n-    \/\/ Arguments are reversed on java expression stack.\n-    \/\/ Calculate address of start element.\n-    if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) { \/\/ Used for \"updateDirectByteBuffer\".\n-      BLOCK_COMMENT(\"CRC32C_updateDirectByteBuffer {\");\n-      \/\/ crc     @ (SP + 5W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off\n-      __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n-      __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n-      __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-      __ lwz( crc,     5*wordSize, argP);  \/\/ current crc state\n-      __ add( data, data, tmp);            \/\/ Add byte buffer offset.\n-      __ sub( dataLen, dataLen, tmp);      \/\/ (end_index - offset)\n-    } else {                                                         \/\/ Used for \"updateBytes update\".\n-      BLOCK_COMMENT(\"CRC32C_updateBytes {\");\n-      \/\/ crc     @ (SP + 4W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off + base_offset\n-      __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n-      __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n-      __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-      __ add( data, data, tmp);            \/\/ add byte buffer offset\n-      __ sub( dataLen, dataLen, tmp);      \/\/ (end_index - offset)\n-      __ lwz( crc,     4*wordSize, argP);  \/\/ current crc state\n-      __ addi(data, data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n-    }\n-\n-    __ crc32(crc, data, dataLen, R2, R6, R7, R8, R9, R10, R11, R12, true);\n+  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n+  address start = __ pc();  \/\/ Remember stub start address (is rtn value).\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we not even call stub code (we generate the code inline)\n+  \/\/ and there is no safepoint on this path.\n+\n+  \/\/ Load parameters.\n+  \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = R15_esp;\n+  const Register crc     = R3_ARG1;  \/\/ crc value\n+  const Register data    = R4_ARG2;  \/\/ address of java byte array\n+  const Register dataLen = R5_ARG3;  \/\/ source data len\n+  const Register tmp     = R11_scratch1;\n+\n+  \/\/ Arguments are reversed on java expression stack.\n+  \/\/ Calculate address of start element.\n+  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) { \/\/ Used for \"updateDirectByteBuffer\".\n+    BLOCK_COMMENT(\"CRC32C_updateDirectByteBuffer {\");\n+    \/\/ crc     @ (SP + 5W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off\n+    __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n+    __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n+    __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+    __ lwz( crc,     5*wordSize, argP);  \/\/ current crc state\n+    __ add( data, data, tmp);            \/\/ Add byte buffer offset.\n+    __ sub( dataLen, dataLen, tmp);      \/\/ (end_index - offset)\n+  } else {                                                         \/\/ Used for \"updateBytes update\".\n+    BLOCK_COMMENT(\"CRC32C_updateBytes {\");\n+    \/\/ crc     @ (SP + 4W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off + base_offset\n+    __ ld(  data,    3*wordSize, argP);  \/\/ start of byte buffer\n+    __ lwa( tmp,     2*wordSize, argP);  \/\/ byte buffer offset\n+    __ lwa( dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+    __ add( data, data, tmp);            \/\/ add byte buffer offset\n+    __ sub( dataLen, dataLen, tmp);      \/\/ (end_index - offset)\n+    __ lwz( crc,     4*wordSize, argP);  \/\/ current crc state\n+    __ addi(data, data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  }\n@@ -1925,3 +1917,1 @@\n-    \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n-    __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n-    __ blr();\n+  __ crc32(crc, data, dataLen, R2, R6, R7, R8, R9, R10, R11, R12, true);\n@@ -1929,3 +1919,3 @@\n-    BLOCK_COMMENT(\"} CRC32C_update{Bytes|DirectByteBuffer}\");\n-    return start;\n-  }\n+  \/\/ Restore caller sp for c2i case (from compiled) and for resized sender frame (from interpreted).\n+  __ resize_frame_absolute(R21_sender_SP, R11_scratch1, R0);\n+  __ blr();\n@@ -1933,1 +1923,2 @@\n-  return NULL;\n+  BLOCK_COMMENT(\"} CRC32C_update{Bytes|DirectByteBuffer}\");\n+  return start;\n@@ -1937,0 +1928,5 @@\n+address TemplateInterpreterGenerator::generate_currentThread() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n","filename":"src\/hotspot\/cpu\/ppc\/templateInterpreterGenerator_ppc.cpp","additions":146,"deletions":150,"binary":false,"changes":296,"status":"modified"},{"patch":"@@ -146,4 +146,0 @@\n-  if (!InlineIntrinsics) {\n-    return NULL; \/\/ Generate a vanilla entry\n-  }\n-\n@@ -304,4 +300,0 @@\n-\/\/ Not supported\n-address TemplateInterpreterGenerator::generate_Float_float16ToFloat_entry() { return nullptr; }\n-address TemplateInterpreterGenerator::generate_Float_floatToFloat16_entry() { return nullptr; }\n-\n@@ -867,1 +859,1 @@\n-  return 0;\n+  return nullptr;\n@@ -877,1 +869,1 @@\n-  return 0;\n+  return nullptr;\n@@ -889,1 +881,1 @@\n-  return 0;\n+  return nullptr;\n@@ -892,0 +884,8 @@\n+\/\/ Not supported\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_float16ToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToFloat16_entry() { return nullptr; }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/templateInterpreterGenerator_riscv.cpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1804,0 +1804,3 @@\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  uint64_t entry_off = __ offset();\n+  Label    slow_path;\n@@ -1805,3 +1808,2 @@\n-  if (UseCRC32Intrinsics) {\n-    uint64_t entry_off = __ offset();\n-    Label    slow_path;\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ safepoint_poll(slow_path, Z_R1);\n@@ -1809,2 +1811,1 @@\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ safepoint_poll(slow_path, Z_R1);\n+  BLOCK_COMMENT(\"CRC32_update {\");\n@@ -1812,1 +1813,3 @@\n-    BLOCK_COMMENT(\"CRC32_update {\");\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we not even call stub code (we generate the code inline)\n+  \/\/ and there is no safepoint on this path.\n@@ -1814,14 +1817,10 @@\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we not even call stub code (we generate the code inline)\n-    \/\/ and there is no safepoint on this path.\n-\n-    \/\/ Load java parameters.\n-    \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = Z_esp;\n-    const Register crc     = Z_ARG1;  \/\/ crc value\n-    const Register data    = Z_ARG2;  \/\/ address of java byte value (kernel_crc32 needs address)\n-    const Register dataLen = Z_ARG3;  \/\/ source data len (1 byte). Not used because calling the single-byte emitter.\n-    const Register table   = Z_ARG4;  \/\/ address of crc32 table\n-\n-    \/\/ Arguments are reversed on java expression stack.\n-    __ z_la(data, 3+1*wordSize, argP);  \/\/ byte value (stack address).\n+  \/\/ Load java parameters.\n+  \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = Z_esp;\n+  const Register crc     = Z_ARG1;  \/\/ crc value\n+  const Register data    = Z_ARG2;  \/\/ address of java byte value (kernel_crc32 needs address)\n+  const Register dataLen = Z_ARG3;  \/\/ source data len (1 byte). Not used because calling the single-byte emitter.\n+  const Register table   = Z_ARG4;  \/\/ address of crc32 table\n+\n+  \/\/ Arguments are reversed on java expression stack.\n+  __ z_la(data, 3+1*wordSize, argP);  \/\/ byte value (stack address).\n@@ -1829,1 +1828,1 @@\n-    __ z_llgf(crc, 2 * wordSize, argP); \/\/ Current crc state, zero extend to 64 bit to have a clean register.\n+  __ z_llgf(crc, 2 * wordSize, argP); \/\/ Current crc state, zero extend to 64 bit to have a clean register.\n@@ -1831,2 +1830,2 @@\n-    StubRoutines::zarch::generate_load_crc_table_addr(_masm, table);\n-    __ kernel_crc32_singleByte(crc, data, dataLen, table, Z_R1, true);\n+  StubRoutines::zarch::generate_load_crc_table_addr(_masm, table);\n+  __ kernel_crc32_singleByte(crc, data, dataLen, table, Z_R1, true);\n@@ -1834,4 +1833,2 @@\n-    \/\/ Restore caller sp for c2i case.\n-    __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n-\n-    __ z_br(Z_R14);\n+  \/\/ Restore caller sp for c2i case.\n+  __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n@@ -1839,1 +1836,1 @@\n-    BLOCK_COMMENT(\"} CRC32_update\");\n+  __ z_br(Z_R14);\n@@ -1841,5 +1838,1 @@\n-    \/\/ Use a previously generated vanilla native entry as the slow path.\n-    BIND(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), Z_R1);\n-    return __ addr_at(entry_off);\n-  }\n+  BLOCK_COMMENT(\"} CRC32_update\");\n@@ -1847,1 +1840,4 @@\n-  return NULL;\n+  \/\/ Use a previously generated vanilla native entry as the slow path.\n+  BIND(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), Z_R1);\n+  return __ addr_at(entry_off);\n@@ -1857,0 +1853,3 @@\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  uint64_t entry_off = __ offset();\n+  Label    slow_path;\n@@ -1858,48 +1857,2 @@\n-  if (UseCRC32Intrinsics) {\n-    uint64_t entry_off = __ offset();\n-    Label    slow_path;\n-\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ safepoint_poll(slow_path, Z_R1);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters.\n-    \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = Z_esp;\n-    const Register crc     = Z_ARG1;  \/\/ crc value\n-    const Register data    = Z_ARG2;  \/\/ address of java byte array\n-    const Register dataLen = Z_ARG3;  \/\/ source data len\n-    const Register table   = Z_ARG4;  \/\/ address of crc32 table\n-    const Register t0      = Z_R10;   \/\/ work reg for kernel* emitters\n-    const Register t1      = Z_R11;   \/\/ work reg for kernel* emitters\n-    const Register t2      = Z_R12;   \/\/ work reg for kernel* emitters\n-    const Register t3      = Z_R13;   \/\/ work reg for kernel* emitters\n-\n-    \/\/ Arguments are reversed on java expression stack.\n-    \/\/ Calculate address of start element.\n-    if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n-      \/\/ crc     @ (SP + 5W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off\n-      BLOCK_COMMENT(\"CRC32_updateByteBuffer {\");\n-      __ z_llgf(crc,    5*wordSize, argP);  \/\/ current crc state\n-      __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n-      __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n-      __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-    } else {                                                         \/\/ Used for \"updateBytes update\".\n-      \/\/ crc     @ (SP + 4W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off + base_offset\n-      BLOCK_COMMENT(\"CRC32_updateBytes {\");\n-      __ z_llgf(crc,    4*wordSize, argP);  \/\/ current crc state\n-      __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n-      __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n-      __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n-      __ z_aghi(data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n-    }\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ safepoint_poll(slow_path, Z_R1);\n@@ -1907,1 +1860,2 @@\n-    StubRoutines::zarch::generate_load_crc_table_addr(_masm, table);\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n@@ -1909,4 +1863,38 @@\n-    __ resize_frame(-(6*8), Z_R0, true); \/\/ Resize frame to provide add'l space to spill 5 registers.\n-    __ z_stmg(t0, t3, 1*8, Z_SP);        \/\/ Spill regs 10..13 to make them available as work registers.\n-    __ kernel_crc32_1word(crc, data, dataLen, table, t0, t1, t2, t3, true);\n-    __ z_lmg(t0, t3, 1*8, Z_SP);         \/\/ Spill regs 10..13 back from stack.\n+  \/\/ Load parameters.\n+  \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = Z_esp;\n+  const Register crc     = Z_ARG1;  \/\/ crc value\n+  const Register data    = Z_ARG2;  \/\/ address of java byte array\n+  const Register dataLen = Z_ARG3;  \/\/ source data len\n+  const Register table   = Z_ARG4;  \/\/ address of crc32 table\n+  const Register t0      = Z_R10;   \/\/ work reg for kernel* emitters\n+  const Register t1      = Z_R11;   \/\/ work reg for kernel* emitters\n+  const Register t2      = Z_R12;   \/\/ work reg for kernel* emitters\n+  const Register t3      = Z_R13;   \/\/ work reg for kernel* emitters\n+\n+  \/\/ Arguments are reversed on java expression stack.\n+  \/\/ Calculate address of start element.\n+  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n+    \/\/ crc     @ (SP + 5W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off\n+    BLOCK_COMMENT(\"CRC32_updateByteBuffer {\");\n+    __ z_llgf(crc,    5*wordSize, argP);  \/\/ current crc state\n+    __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n+    __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n+    __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+  } else {                                                         \/\/ Used for \"updateBytes update\".\n+    \/\/ crc     @ (SP + 4W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off + base_offset\n+    BLOCK_COMMENT(\"CRC32_updateBytes {\");\n+    __ z_llgf(crc,    4*wordSize, argP);  \/\/ current crc state\n+    __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n+    __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n+    __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process\n+    __ z_aghi(data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  }\n@@ -1914,2 +1902,1 @@\n-    \/\/ Restore caller sp for c2i case.\n-    __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n+  StubRoutines::zarch::generate_load_crc_table_addr(_masm, table);\n@@ -1917,1 +1904,4 @@\n-    __ z_br(Z_R14);\n+  __ resize_frame(-(6*8), Z_R0, true); \/\/ Resize frame to provide add'l space to spill 5 registers.\n+  __ z_stmg(t0, t3, 1*8, Z_SP);        \/\/ Spill regs 10..13 to make them available as work registers.\n+  __ kernel_crc32_1word(crc, data, dataLen, table, t0, t1, t2, t3, true);\n+  __ z_lmg(t0, t3, 1*8, Z_SP);         \/\/ Spill regs 10..13 back from stack.\n@@ -1919,1 +1909,2 @@\n-    BLOCK_COMMENT(\"} CRC32_update{Bytes|ByteBuffer}\");\n+  \/\/ Restore caller sp for c2i case.\n+  __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n@@ -1921,5 +1912,1 @@\n-    \/\/ Use a previously generated vanilla native entry as the slow path.\n-    BIND(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), Z_R1);\n-    return __ addr_at(entry_off);\n-  }\n+  __ z_br(Z_R14);\n@@ -1927,1 +1914,6 @@\n-  return NULL;\n+  BLOCK_COMMENT(\"} CRC32_update{Bytes|ByteBuffer}\");\n+\n+  \/\/ Use a previously generated vanilla native entry as the slow path.\n+  BIND(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native), Z_R1);\n+  return __ addr_at(entry_off);\n@@ -1939,0 +1931,2 @@\n+  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n+  uint64_t entry_off = __ offset();\n@@ -1940,46 +1934,2 @@\n-  if (UseCRC32CIntrinsics) {\n-    uint64_t entry_off = __ offset();\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters.\n-    \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n-    const Register argP    = Z_esp;\n-    const Register crc     = Z_ARG1;  \/\/ crc value\n-    const Register data    = Z_ARG2;  \/\/ address of java byte array\n-    const Register dataLen = Z_ARG3;  \/\/ source data len\n-    const Register table   = Z_ARG4;  \/\/ address of crc32 table\n-    const Register t0      = Z_R10;   \/\/ work reg for kernel* emitters\n-    const Register t1      = Z_R11;   \/\/ work reg for kernel* emitters\n-    const Register t2      = Z_R12;   \/\/ work reg for kernel* emitters\n-    const Register t3      = Z_R13;   \/\/ work reg for kernel* emitters\n-\n-    \/\/ Arguments are reversed on java expression stack.\n-    \/\/ Calculate address of start element.\n-    if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n-      \/\/ crc     @ (SP + 5W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off\n-      BLOCK_COMMENT(\"CRC32C_updateDirectByteBuffer {\");\n-      __ z_llgf(crc,    5*wordSize, argP);  \/\/ current crc state\n-      __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n-      __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n-      __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process, calculated as\n-      __ z_sgf(dataLen, Address(argP, 2*wordSize));  \/\/ (end_index - offset)\n-    } else {                                                                \/\/ Used for \"updateBytes update\".\n-      \/\/ crc     @ (SP + 4W) (32bit)\n-      \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n-      \/\/ off     @ (SP + 2W) (32bit)\n-      \/\/ dataLen @ (SP + 1W) (32bit)\n-      \/\/ data = buf + off + base_offset\n-      BLOCK_COMMENT(\"CRC32C_updateBytes {\");\n-      __ z_llgf(crc,    4*wordSize, argP);  \/\/ current crc state\n-      __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n-      __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n-      __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process, calculated as\n-      __ z_sgf(dataLen, Address(argP, 2*wordSize));  \/\/ (end_index - offset)\n-      __ z_aghi(data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n-    }\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n@@ -1987,1 +1937,40 @@\n-    StubRoutines::zarch::generate_load_crc32c_table_addr(_masm, table);\n+  \/\/ Load parameters.\n+  \/\/ Z_esp is callers operand stack pointer, i.e. it points to the parameters.\n+  const Register argP    = Z_esp;\n+  const Register crc     = Z_ARG1;  \/\/ crc value\n+  const Register data    = Z_ARG2;  \/\/ address of java byte array\n+  const Register dataLen = Z_ARG3;  \/\/ source data len\n+  const Register table   = Z_ARG4;  \/\/ address of crc32 table\n+  const Register t0      = Z_R10;   \/\/ work reg for kernel* emitters\n+  const Register t1      = Z_R11;   \/\/ work reg for kernel* emitters\n+  const Register t2      = Z_R12;   \/\/ work reg for kernel* emitters\n+  const Register t3      = Z_R13;   \/\/ work reg for kernel* emitters\n+\n+  \/\/ Arguments are reversed on java expression stack.\n+  \/\/ Calculate address of start element.\n+  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) { \/\/ Used for \"updateByteBuffer direct\".\n+    \/\/ crc     @ (SP + 5W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to long array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off\n+    BLOCK_COMMENT(\"CRC32C_updateDirectByteBuffer {\");\n+    __ z_llgf(crc,    5*wordSize, argP);  \/\/ current crc state\n+    __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n+    __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n+    __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process, calculated as\n+    __ z_sgf(dataLen, Address(argP, 2*wordSize));  \/\/ (end_index - offset)\n+  } else {                                                                \/\/ Used for \"updateBytes update\".\n+    \/\/ crc     @ (SP + 4W) (32bit)\n+    \/\/ buf     @ (SP + 3W) (64bit ptr to byte array)\n+    \/\/ off     @ (SP + 2W) (32bit)\n+    \/\/ dataLen @ (SP + 1W) (32bit)\n+    \/\/ data = buf + off + base_offset\n+    BLOCK_COMMENT(\"CRC32C_updateBytes {\");\n+    __ z_llgf(crc,    4*wordSize, argP);  \/\/ current crc state\n+    __ z_lg(data,     3*wordSize, argP);  \/\/ start of byte buffer\n+    __ z_agf(data,    2*wordSize, argP);  \/\/ Add byte buffer offset.\n+    __ z_lgf(dataLen, 1*wordSize, argP);  \/\/ #bytes to process, calculated as\n+    __ z_sgf(dataLen, Address(argP, 2*wordSize));  \/\/ (end_index - offset)\n+    __ z_aghi(data, arrayOopDesc::base_offset_in_bytes(T_BYTE));\n+  }\n@@ -1989,4 +1978,1 @@\n-    __ resize_frame(-(6*8), Z_R0, true); \/\/ Resize frame to provide add'l space to spill 5 registers.\n-    __ z_stmg(t0, t3, 1*8, Z_SP);        \/\/ Spill regs 10..13 to make them available as work registers.\n-    __ kernel_crc32_1word(crc, data, dataLen, table, t0, t1, t2, t3, false);\n-    __ z_lmg(t0, t3, 1*8, Z_SP);         \/\/ Spill regs 10..13 back from stack.\n+  StubRoutines::zarch::generate_load_crc32c_table_addr(_masm, table);\n@@ -1994,2 +1980,4 @@\n-    \/\/ Restore caller sp for c2i case.\n-    __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n+  __ resize_frame(-(6*8), Z_R0, true); \/\/ Resize frame to provide add'l space to spill 5 registers.\n+  __ z_stmg(t0, t3, 1*8, Z_SP);        \/\/ Spill regs 10..13 to make them available as work registers.\n+  __ kernel_crc32_1word(crc, data, dataLen, table, t0, t1, t2, t3, false);\n+  __ z_lmg(t0, t3, 1*8, Z_SP);         \/\/ Spill regs 10..13 back from stack.\n@@ -1997,1 +1985,2 @@\n-    __ z_br(Z_R14);\n+  \/\/ Restore caller sp for c2i case.\n+  __ resize_frame_absolute(Z_R10, Z_R0, true); \/\/ Cut the stack back to where the caller started.\n@@ -1999,3 +1988,1 @@\n-    BLOCK_COMMENT(\"} CRC32C_update{Bytes|DirectByteBuffer}\");\n-    return __ addr_at(entry_off);\n-  }\n+  __ z_br(Z_R14);\n@@ -2003,1 +1990,2 @@\n-  return NULL;\n+  BLOCK_COMMENT(\"} CRC32C_update{Bytes|DirectByteBuffer}\");\n+  return __ addr_at(entry_off);\n@@ -2007,0 +1995,5 @@\n+address TemplateInterpreterGenerator::generate_currentThread() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n","filename":"src\/hotspot\/cpu\/s390\/templateInterpreterGenerator_s390.cpp","additions":148,"deletions":155,"binary":false,"changes":303,"status":"modified"},{"patch":"@@ -56,2 +56,2 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -59,32 +59,32 @@\n-    \/\/ rbx: Method*\n-    \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n-    \/\/ rdx: scratch\n-    \/\/ rdi: scratch\n-\n-    Label slow_path;\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ get_thread(rdi);\n-    __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters\n-    const Register crc = rax;  \/\/ crc\n-    const Register val = rdx;  \/\/ source java byte value\n-    const Register tbl = rdi;  \/\/ scratch\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    __ movl(val, Address(rsp,   wordSize)); \/\/ byte value\n-    __ movl(crc, Address(rsp, 2*wordSize)); \/\/ Initial CRC\n-\n-    __ lea(tbl, ExternalAddress(StubRoutines::crc_table_addr()));\n-    __ notl(crc); \/\/ ~crc\n-    __ update_byte_crc32(crc, val, tbl);\n-    __ notl(crc); \/\/ ~crc\n-    \/\/ result in rax\n-\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n+  \/\/ rbx: Method*\n+  \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n+  \/\/ rdx: scratch\n+  \/\/ rdi: scratch\n+\n+  Label slow_path;\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ get_thread(rdi);\n+  __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n+\n+  \/\/ Load parameters\n+  const Register crc = rax;  \/\/ crc\n+  const Register val = rdx;  \/\/ source java byte value\n+  const Register tbl = rdi;  \/\/ scratch\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  __ movl(val, Address(rsp,   wordSize)); \/\/ byte value\n+  __ movl(crc, Address(rsp, 2*wordSize)); \/\/ Initial CRC\n+\n+  __ lea(tbl, ExternalAddress(StubRoutines::crc_table_addr()));\n+  __ notl(crc); \/\/ ~crc\n+  __ update_byte_crc32(crc, val, tbl);\n+  __ notl(crc); \/\/ ~crc\n+  \/\/ result in rax\n+\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n@@ -92,6 +92,4 @@\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -106,2 +104,2 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -109,38 +107,38 @@\n-    \/\/ rbx,: Method*\n-    \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n-    \/\/ rdx: scratch\n-    \/\/ rdi: scratch\n-\n-    Label slow_path;\n-    \/\/ If we need a safepoint check, generate full interpreter entry.\n-    __ get_thread(rdi);\n-    __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters\n-    const Register crc = rax;  \/\/ crc\n-    const Register buf = rdx;  \/\/ source java byte array address\n-    const Register len = rdi;  \/\/ length\n-\n-    \/\/ value              x86_32\n-    \/\/ interp. arg ptr    ESP + 4\n-    \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int len)\n-    \/\/                                         3           2      1        0\n-    \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long buf, int off, int len)\n-    \/\/                                              4         2,3      1        0\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    __ movl(len,   Address(rsp,   4 + 0)); \/\/ Length\n-    \/\/ Calculate address of start element\n-    if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n-      __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long buf\n-      __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-      __ movl(crc,   Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n-    } else {\n-      __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n-      __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-      __ movl(crc,   Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n-    }\n+  \/\/ rbx,: Method*\n+  \/\/ rsi: senderSP must preserved for slow path, set SP to it on fast path\n+  \/\/ rdx: scratch\n+  \/\/ rdi: scratch\n+\n+  Label slow_path;\n+  \/\/ If we need a safepoint check, generate full interpreter entry.\n+  __ get_thread(rdi);\n+  __ safepoint_poll(slow_path, rdi, false \/* at_return *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n+\n+  \/\/ Load parameters\n+  const Register crc = rax;  \/\/ crc\n+  const Register buf = rdx;  \/\/ source java byte array address\n+  const Register len = rdi;  \/\/ length\n+\n+  \/\/ value              x86_32\n+  \/\/ interp. arg ptr    ESP + 4\n+  \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int len)\n+  \/\/                                         3           2      1        0\n+  \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long buf, int off, int len)\n+  \/\/                                              4         2,3      1        0\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  __ movl(len,   Address(rsp,   4 + 0)); \/\/ Length\n+  \/\/ Calculate address of start element\n+  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n+    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long buf\n+    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n+    __ movl(crc,   Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n+  } else {\n+    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n+    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n+    __ movl(crc,   Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n+  }\n@@ -148,2 +146,2 @@\n-    __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()), crc, buf, len);\n-    \/\/ result in rax\n+  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()), crc, buf, len);\n+  \/\/ result in rax\n@@ -151,4 +149,4 @@\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n@@ -156,6 +154,4 @@\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -170,37 +166,28 @@\n-  if (UseCRC32CIntrinsics) {\n-    address entry = __ pc();\n-    \/\/ Load parameters\n-    const Register crc = rax;  \/\/ crc\n-    const Register buf = rcx;  \/\/ source java byte array address\n-    const Register len = rdx;  \/\/ length\n-    const Register end = len;\n-\n-    \/\/ value              x86_32\n-    \/\/ interp. arg ptr    ESP + 4\n-    \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int end)\n-    \/\/                                         3           2      1        0\n-    \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long address, int off, int end)\n-    \/\/                                              4         2,3          1        0\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    __ movl(end, Address(rsp, 4 + 0)); \/\/ end\n-    __ subl(len, Address(rsp, 4 + 1 * wordSize));  \/\/ end - offset == length\n-    \/\/ Calculate address of start element\n-    if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n-      __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long address\n-      __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-      __ movl(crc, Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n-    } else {\n-      __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n-      __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n-      __ movl(crc, Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n-    }\n-    __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()), crc, buf, len);\n-    \/\/ result in rax\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, rsi);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n-\n-    return entry;\n+  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n+  \/\/ Load parameters\n+  const Register crc = rax;  \/\/ crc\n+  const Register buf = rcx;  \/\/ source java byte array address\n+  const Register len = rdx;  \/\/ length\n+  const Register end = len;\n+\n+  \/\/ value              x86_32\n+  \/\/ interp. arg ptr    ESP + 4\n+  \/\/ int java.util.zip.CRC32.updateBytes(int crc, byte[] b, int off, int end)\n+  \/\/                                         3           2      1        0\n+  \/\/ int java.util.zip.CRC32.updateByteBuffer(int crc, long address, int off, int end)\n+  \/\/                                              4         2,3          1        0\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  __ movl(end, Address(rsp, 4 + 0)); \/\/ end\n+  __ subl(len, Address(rsp, 4 + 1 * wordSize));  \/\/ end - offset == length\n+  \/\/ Calculate address of start element\n+  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n+    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ long address\n+    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n+    __ movl(crc, Address(rsp, 4 + 4 * wordSize)); \/\/ Initial CRC\n+  } else {\n+    __ movptr(buf, Address(rsp, 4 + 2 * wordSize)); \/\/ byte[] array\n+    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ addptr(buf, Address(rsp, 4 + 1 * wordSize)); \/\/ + offset\n+    __ movl(crc, Address(rsp, 4 + 3 * wordSize)); \/\/ Initial CRC\n@@ -208,1 +195,8 @@\n-  return NULL;\n+  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()), crc, buf, len);\n+  \/\/ result in rax\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, rsi);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n+\n+  return entry;\n@@ -322,6 +316,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16)) {\n-    return nullptr; \/\/ Generate a vanilla entry\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -348,6 +337,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat)) {\n-    return nullptr; \/\/ Generate a vanilla entry\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -375,2 +359,0 @@\n-  if (!InlineIntrinsics) return NULL; \/\/ Generate a vanilla entry\n-\n@@ -521,0 +503,4 @@\n+\n+\/\/ Not supported\n+address TemplateInterpreterGenerator::generate_currentThread() { return nullptr; }\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86_32.cpp","additions":130,"deletions":144,"binary":false,"changes":274,"status":"modified"},{"patch":"@@ -185,40 +185,38 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n-\n-    \/\/ rbx,: Method*\n-    \/\/ r13: senderSP must preserved for slow path, set SP to it on fast path\n-    \/\/ c_rarg0: scratch (rdi on non-Win64, rcx on Win64)\n-    \/\/ c_rarg1: scratch (rsi on non-Win64, rdx on Win64)\n-\n-    Label slow_path;\n-    __ safepoint_poll(slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters\n-    const Register crc = rax;  \/\/ crc\n-    const Register val = c_rarg0;  \/\/ source java byte value\n-    const Register tbl = c_rarg1;  \/\/ scratch\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    __ movl(val, Address(rsp,   wordSize)); \/\/ byte value\n-    __ movl(crc, Address(rsp, 2*wordSize)); \/\/ Initial CRC\n-\n-    __ lea(tbl, ExternalAddress(StubRoutines::crc_table_addr()));\n-    __ notl(crc); \/\/ ~crc\n-    __ update_byte_crc32(crc, val, tbl);\n-    __ notl(crc); \/\/ ~crc\n-    \/\/ result in rax\n-\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, r13);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n-\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n+\n+  \/\/ rbx,: Method*\n+  \/\/ r13: senderSP must preserved for slow path, set SP to it on fast path\n+  \/\/ c_rarg0: scratch (rdi on non-Win64, rcx on Win64)\n+  \/\/ c_rarg1: scratch (rsi on non-Win64, rdx on Win64)\n+\n+  Label slow_path;\n+  __ safepoint_poll(slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n+\n+  \/\/ Load parameters\n+  const Register crc = rax;  \/\/ crc\n+  const Register val = c_rarg0;  \/\/ source java byte value\n+  const Register tbl = c_rarg1;  \/\/ scratch\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  __ movl(val, Address(rsp,   wordSize)); \/\/ byte value\n+  __ movl(crc, Address(rsp, 2*wordSize)); \/\/ Initial CRC\n+\n+  __ lea(tbl, ExternalAddress(StubRoutines::crc_table_addr()));\n+  __ notl(crc); \/\/ ~crc\n+  __ update_byte_crc32(crc, val, tbl);\n+  __ notl(crc); \/\/ ~crc\n+  \/\/ result in rax\n+\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, r13);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n+\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -233,34 +231,2 @@\n-  if (UseCRC32Intrinsics) {\n-    address entry = __ pc();\n-\n-    \/\/ rbx,: Method*\n-    \/\/ r13: senderSP must preserved for slow path, set SP to it on fast path\n-\n-    Label slow_path;\n-    __ safepoint_poll(slow_path, r15_thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n-\n-    \/\/ We don't generate local frame and don't align stack because\n-    \/\/ we call stub code and there is no safepoint on this path.\n-\n-    \/\/ Load parameters\n-    const Register crc = c_rarg0;  \/\/ crc\n-    const Register buf = c_rarg1;  \/\/ source java byte array address\n-    const Register len = c_rarg2;  \/\/ length\n-    const Register off = len;      \/\/ offset (never overlaps with 'len')\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    \/\/ Calculate address of start element\n-    if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n-      __ movptr(buf, Address(rsp, 3*wordSize)); \/\/ long buf\n-      __ movl2ptr(off, Address(rsp, 2*wordSize)); \/\/ offset\n-      __ addq(buf, off); \/\/ + offset\n-      __ movl(crc,   Address(rsp, 5*wordSize)); \/\/ Initial CRC\n-    } else {\n-      __ movptr(buf, Address(rsp, 3*wordSize)); \/\/ byte[] array\n-      __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ movl2ptr(off, Address(rsp, 2*wordSize)); \/\/ offset\n-      __ addq(buf, off); \/\/ + offset\n-      __ movl(crc,   Address(rsp, 4*wordSize)); \/\/ Initial CRC\n-    }\n-    \/\/ Can now load 'len' since we're finished with 'off'\n-    __ movl(len, Address(rsp, wordSize)); \/\/ Length\n+  assert(UseCRC32Intrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n@@ -268,2 +234,31 @@\n-    __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()), crc, buf, len);\n-    \/\/ result in rax\n+  \/\/ rbx,: Method*\n+  \/\/ r13: senderSP must preserved for slow path, set SP to it on fast path\n+\n+  Label slow_path;\n+  __ safepoint_poll(slow_path, r15_thread, false \/* at_return *\/, false \/* in_nmethod *\/);\n+\n+  \/\/ We don't generate local frame and don't align stack because\n+  \/\/ we call stub code and there is no safepoint on this path.\n+\n+  \/\/ Load parameters\n+  const Register crc = c_rarg0;  \/\/ crc\n+  const Register buf = c_rarg1;  \/\/ source java byte array address\n+  const Register len = c_rarg2;  \/\/ length\n+  const Register off = len;      \/\/ offset (never overlaps with 'len')\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  \/\/ Calculate address of start element\n+  if (kind == Interpreter::java_util_zip_CRC32_updateByteBuffer) {\n+    __ movptr(buf, Address(rsp, 3*wordSize)); \/\/ long buf\n+    __ movl2ptr(off, Address(rsp, 2*wordSize)); \/\/ offset\n+    __ addq(buf, off); \/\/ + offset\n+    __ movl(crc,   Address(rsp, 5*wordSize)); \/\/ Initial CRC\n+  } else {\n+    __ movptr(buf, Address(rsp, 3*wordSize)); \/\/ byte[] array\n+    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ movl2ptr(off, Address(rsp, 2*wordSize)); \/\/ offset\n+    __ addq(buf, off); \/\/ + offset\n+    __ movl(crc,   Address(rsp, 4*wordSize)); \/\/ Initial CRC\n+  }\n+  \/\/ Can now load 'len' since we're finished with 'off'\n+  __ movl(len, Address(rsp, wordSize)); \/\/ Length\n@@ -271,4 +266,2 @@\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, r13);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n+  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32()), crc, buf, len);\n+  \/\/ result in rax\n@@ -276,6 +269,9 @@\n-    \/\/ generate a vanilla native entry as the slow path\n-    __ bind(slow_path);\n-    __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n-    return entry;\n-  }\n-  return NULL;\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, r13);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n+\n+  \/\/ generate a vanilla native entry as the slow path\n+  __ bind(slow_path);\n+  __ jump_to_entry(Interpreter::entry_for_kind(Interpreter::native));\n+  return entry;\n@@ -290,40 +286,29 @@\n-  if (UseCRC32CIntrinsics) {\n-    address entry = __ pc();\n-    \/\/ Load parameters\n-    const Register crc = c_rarg0;  \/\/ crc\n-    const Register buf = c_rarg1;  \/\/ source java byte array address\n-    const Register len = c_rarg2;\n-    const Register off = c_rarg3;  \/\/ offset\n-    const Register end = len;\n-\n-    \/\/ Arguments are reversed on java expression stack\n-    \/\/ Calculate address of start element\n-    if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n-      __ movptr(buf, Address(rsp, 3 * wordSize)); \/\/ long address\n-      __ movl2ptr(off, Address(rsp, 2 * wordSize)); \/\/ offset\n-      __ addq(buf, off); \/\/ + offset\n-      __ movl(crc, Address(rsp, 5 * wordSize)); \/\/ Initial CRC\n-      \/\/ Note on 5 * wordSize vs. 4 * wordSize:\n-      \/\/ *   int java.util.zip.CRC32C.updateByteBuffer(int crc, long address, int off, int end)\n-      \/\/                                                   4         2,3          1        0\n-      \/\/ end starts at SP + 8\n-      \/\/ The Java(R) Virtual Machine Specification Java SE 7 Edition\n-      \/\/ 4.10.2.3. Values of Types long and double\n-      \/\/    \"When calculating operand stack length, values of type long and double have length two.\"\n-    } else {\n-      __ movptr(buf, Address(rsp, 3 * wordSize)); \/\/ byte[] array\n-      __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n-      __ movl2ptr(off, Address(rsp, 2 * wordSize)); \/\/ offset\n-      __ addq(buf, off); \/\/ + offset\n-      __ movl(crc, Address(rsp, 4 * wordSize)); \/\/ Initial CRC\n-    }\n-    __ movl(end, Address(rsp, wordSize)); \/\/ end\n-    __ subl(end, off); \/\/ end - off\n-    __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()), crc, buf, len);\n-    \/\/ result in rax\n-    \/\/ _areturn\n-    __ pop(rdi);                \/\/ get return address\n-    __ mov(rsp, r13);           \/\/ set sp to sender sp\n-    __ jmp(rdi);\n-\n-    return entry;\n+  assert(UseCRC32CIntrinsics, \"this intrinsic is not supported\");\n+  address entry = __ pc();\n+  \/\/ Load parameters\n+  const Register crc = c_rarg0;  \/\/ crc\n+  const Register buf = c_rarg1;  \/\/ source java byte array address\n+  const Register len = c_rarg2;\n+  const Register off = c_rarg3;  \/\/ offset\n+  const Register end = len;\n+\n+  \/\/ Arguments are reversed on java expression stack\n+  \/\/ Calculate address of start element\n+  if (kind == Interpreter::java_util_zip_CRC32C_updateDirectByteBuffer) {\n+    __ movptr(buf, Address(rsp, 3 * wordSize)); \/\/ long address\n+    __ movl2ptr(off, Address(rsp, 2 * wordSize)); \/\/ offset\n+    __ addq(buf, off); \/\/ + offset\n+    __ movl(crc, Address(rsp, 5 * wordSize)); \/\/ Initial CRC\n+    \/\/ Note on 5 * wordSize vs. 4 * wordSize:\n+    \/\/ *   int java.util.zip.CRC32C.updateByteBuffer(int crc, long address, int off, int end)\n+    \/\/                                                   4         2,3          1        0\n+    \/\/ end starts at SP + 8\n+    \/\/ The Java(R) Virtual Machine Specification Java SE 7 Edition\n+    \/\/ 4.10.2.3. Values of Types long and double\n+    \/\/    \"When calculating operand stack length, values of type long and double have length two.\"\n+  } else {\n+    __ movptr(buf, Address(rsp, 3 * wordSize)); \/\/ byte[] array\n+    __ addptr(buf, arrayOopDesc::base_offset_in_bytes(T_BYTE)); \/\/ + header size\n+    __ movl2ptr(off, Address(rsp, 2 * wordSize)); \/\/ offset\n+    __ addq(buf, off); \/\/ + offset\n+    __ movl(crc, Address(rsp, 4 * wordSize)); \/\/ Initial CRC\n@@ -331,0 +316,8 @@\n+  __ movl(end, Address(rsp, wordSize)); \/\/ end\n+  __ subl(end, off); \/\/ end - off\n+  __ super_call_VM_leaf(CAST_FROM_FN_PTR(address, StubRoutines::updateBytesCRC32C()), crc, buf, len);\n+  \/\/ result in rax\n+  \/\/ _areturn\n+  __ pop(rdi);                \/\/ get return address\n+  __ mov(rsp, r13);           \/\/ set sp to sender sp\n+  __ jmp(rdi);\n@@ -332,1 +325,1 @@\n-  return NULL;\n+  return entry;\n@@ -340,6 +333,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16)) {\n-    return nullptr; \/\/ Generate a vanilla entry\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -367,6 +355,1 @@\n-  \/\/ vmIntrinsics checks InlineIntrinsics flag, no need to check it here.\n-  if (!VM_Version::supports_float16() ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_floatToFloat16) ||\n-      vmIntrinsics::is_disabled_by_flags(vmIntrinsics::_float16ToFloat)) {\n-    return nullptr; \/\/ Generate a vanilla entry\n-  }\n+  assert(VM_Version::supports_float16(), \"this intrinsic is not supported\");\n@@ -399,2 +382,0 @@\n-  if (!InlineIntrinsics) return NULL; \/\/ Generate a vanilla entry\n-\n@@ -517,0 +498,6 @@\n+\/\/ Not supported\n+address TemplateInterpreterGenerator::generate_Float_intBitsToFloat_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Float_floatToRawIntBits_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_longBitsToDouble_entry() { return nullptr; }\n+address TemplateInterpreterGenerator::generate_Double_doubleToRawLongBits_entry() { return nullptr; }\n+\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86_64.cpp","additions":128,"deletions":141,"binary":false,"changes":269,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"classfile\/vmIntrinsics.hpp\"\n@@ -3223,0 +3224,16 @@\n+\n+bool VM_Version::is_intrinsic_supported(vmIntrinsicID id) {\n+  assert(id != vmIntrinsics::_none, \"must be a VM intrinsic\");\n+  switch (id) {\n+  case vmIntrinsics::_floatToFloat16:\n+  case vmIntrinsics::_float16ToFloat:\n+    if (!supports_float16()) {\n+      return false;\n+    }\n+    break;\n+  default:\n+    break;\n+  }\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -767,0 +767,3 @@\n+  \/\/ Check intrinsic support\n+  static bool is_intrinsic_supported(vmIntrinsicID id);\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/vm_version.hpp\"\n@@ -652,3 +653,2 @@\n-bool vmIntrinsics::is_disabled_by_flags(const methodHandle& method) {\n-  vmIntrinsics::ID id = method->intrinsic_id();\n-  return is_disabled_by_flags(id);\n+bool vmIntrinsics::is_intrinsic_available(vmIntrinsics::ID id) {\n+  return VM_Version::is_intrinsic_supported(id) && !is_disabled_by_flags(id);\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1527,4 +1527,1 @@\n-  static bool is_disabled_by_flags(const methodHandle& method);\n-  static bool is_intrinsic_available(vmIntrinsics::ID id) {\n-    return !is_disabled_by_flags(id);\n-  }\n+  static bool is_intrinsic_available(vmIntrinsics::ID id);\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -129,0 +129,2 @@\n+    vmIntrinsics::ID id = method->intrinsic_id();\n+    assert(id != vmIntrinsics::_none, \"must be a VM intrinsic\");\n@@ -130,2 +132,2 @@\n-           !directive->is_intrinsic_disabled(method) &&\n-           !vmIntrinsics::is_disabled_by_flags(method);\n+           vmIntrinsics::is_intrinsic_available(id) &&\n+           !directive->is_intrinsic_disabled(id);\n","filename":"src\/hotspot\/share\/compiler\/abstractCompiler.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -552,2 +552,1 @@\n-bool DirectiveSet::is_intrinsic_disabled(const methodHandle& method) {\n-  vmIntrinsics::ID id = method->intrinsic_id();\n+bool DirectiveSet::is_intrinsic_disabled(vmIntrinsics::ID id) {\n","filename":"src\/hotspot\/share\/compiler\/compilerDirectives.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -129,1 +129,1 @@\n-  bool is_intrinsic_disabled(const methodHandle& method);\n+  bool is_intrinsic_disabled(vmIntrinsicID id);\n","filename":"src\/hotspot\/share\/compiler\/compilerDirectives.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -90,2 +90,0 @@\n-address    AbstractInterpreter::_native_entry_begin                         = nullptr;\n-address    AbstractInterpreter::_native_entry_end                           = nullptr;\n@@ -138,1 +136,0 @@\n-#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n@@ -140,1 +137,0 @@\n-#endif\n@@ -153,1 +149,1 @@\n-      case vmIntrinsics::_dsqrt_strict:      return java_lang_math_sqrt;\n+      case vmIntrinsics::_dsqrt_strict:      return java_lang_math_sqrt_strict;\n@@ -200,1 +196,47 @@\n-void AbstractInterpreter::set_entry_for_kind(AbstractInterpreter::MethodKind kind, address entry) {\n+vmIntrinsics::ID AbstractInterpreter::method_intrinsic(MethodKind kind) {\n+  switch (kind) {\n+  case java_lang_math_sin         : return vmIntrinsics::_dsin;\n+  case java_lang_math_cos         : return vmIntrinsics::_dcos;\n+  case java_lang_math_tan         : return vmIntrinsics::_dtan;\n+  case java_lang_math_abs         : return vmIntrinsics::_dabs;\n+  case java_lang_math_log         : return vmIntrinsics::_dlog;\n+  case java_lang_math_log10       : return vmIntrinsics::_dlog10;\n+  case java_lang_math_sqrt        : return vmIntrinsics::_dsqrt;\n+  case java_lang_math_sqrt_strict : return vmIntrinsics::_dsqrt_strict;\n+  case java_lang_math_pow         : return vmIntrinsics::_dpow;\n+  case java_lang_math_exp         : return vmIntrinsics::_dexp;\n+  case java_lang_math_fmaD        : return vmIntrinsics::_fmaD;\n+  case java_lang_math_fmaF        : return vmIntrinsics::_fmaF;\n+  case java_lang_ref_reference_get: return vmIntrinsics::_Reference_get;\n+  case java_util_zip_CRC32_update : return vmIntrinsics::_updateCRC32;\n+  case java_util_zip_CRC32_updateBytes\n+                                  : return vmIntrinsics::_updateBytesCRC32;\n+  case java_util_zip_CRC32_updateByteBuffer\n+                                  : return vmIntrinsics::_updateByteBufferCRC32;\n+  case java_util_zip_CRC32C_updateBytes\n+                                  : return vmIntrinsics::_updateBytesCRC32C;\n+  case java_util_zip_CRC32C_updateDirectByteBuffer\n+                                  : return vmIntrinsics::_updateDirectByteBufferCRC32C;\n+  case java_lang_Thread_currentThread\n+                                  : return vmIntrinsics::_currentThread;\n+  case java_lang_Float_intBitsToFloat\n+                                  : return vmIntrinsics::_intBitsToFloat;\n+  case java_lang_Float_floatToRawIntBits\n+                                  : return vmIntrinsics::_floatToRawIntBits;\n+  case java_lang_Double_longBitsToDouble\n+                                  : return vmIntrinsics::_longBitsToDouble;\n+  case java_lang_Double_doubleToRawLongBits\n+                                  : return vmIntrinsics::_doubleToRawLongBits;\n+  case java_lang_Float_float16ToFloat\n+                                  : return vmIntrinsics::_float16ToFloat;\n+  case java_lang_Float_floatToFloat16\n+                                  : return vmIntrinsics::_floatToFloat16;\n+\n+  default:\n+    fatal(\"unexpected method intrinsic kind: %d\", kind);\n+    break;\n+  }\n+  return vmIntrinsics::_none;\n+}\n+\n+void AbstractInterpreter::set_entry_for_kind(MethodKind kind, address entry) {\n@@ -271,1 +313,0 @@\n-    case java_lang_math_sqrt    : tty->print(\"java_lang_math_sqrt\"    ); break;\n@@ -274,0 +315,2 @@\n+    case java_lang_math_pow     : tty->print(\"java_lang_math_pow\"     ); break;\n+    case java_lang_math_exp     : tty->print(\"java_lang_math_exp\"     ); break;\n@@ -276,0 +319,2 @@\n+    case java_lang_math_sqrt    : tty->print(\"java_lang_math_sqrt\"    ); break;\n+    case java_lang_math_sqrt_strict           : tty->print(\"java_lang_math_sqrt_strict\"); break;\n@@ -281,0 +326,8 @@\n+    case java_lang_ref_reference_get          : tty->print(\"java_lang_ref_reference_get\"); break;\n+    case java_lang_Thread_currentThread       : tty->print(\"java_lang_Thread_currentThread\"); break;\n+    case java_lang_Float_intBitsToFloat       : tty->print(\"java_lang_Float_intBitsToFloat\"); break;\n+    case java_lang_Float_floatToRawIntBits    : tty->print(\"java_lang_Float_floatToRawIntBits\"); break;\n+    case java_lang_Double_longBitsToDouble    : tty->print(\"java_lang_Double_longBitsToDouble\"); break;\n+    case java_lang_Double_doubleToRawLongBits : tty->print(\"java_lang_Double_doubleToRawLongBits\"); break;\n+    case java_lang_Float_float16ToFloat       : tty->print(\"java_lang_Float_float16ToFloat\"); break;\n+    case java_lang_Float_floatToFloat16       : tty->print(\"java_lang_Float_floatToFloat16\"); break;\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.cpp","additions":60,"deletions":7,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+    java_lang_math_sqrt_strict,                                 \/\/ implementation of java.lang.StrictMath.sqrt(x)\n@@ -108,0 +109,3 @@\n+  \/\/ Conversion from the above enum to vmIntrinsics::ID\n+  static vmIntrinsics::ID method_intrinsic(MethodKind kind);\n+\n@@ -117,3 +121,0 @@\n-  static address    _native_entry_begin;                        \/\/ Region for native entry code\n-  static address    _native_entry_end;\n-\n@@ -226,1 +227,0 @@\n-  static bool       in_native_entry(address pc)                 { return _native_entry_begin <= pc && pc < _native_entry_end; }\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -180,3 +180,3 @@\n-#define method_entry(kind)                                                                   \\\n-  { CodeletMark cm(_masm, \"method entry point (kind = \" #kind \")\");                          \\\n-    Interpreter::_entry_table[Interpreter::kind] = generate_method_entry(Interpreter::kind); \\\n+#define method_entry(kind)                                                                          \\\n+  { CodeletMark cm(_masm, \"method entry point (kind = \" #kind \")\");                                 \\\n+    Interpreter::_entry_table[Interpreter::kind] = generate_method_entry(Interpreter::kind, false); \\\n@@ -197,0 +197,1 @@\n+  method_entry(java_lang_math_sqrt_strict)\n@@ -204,3 +205,0 @@\n-#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n-  method_entry(java_lang_Thread_currentThread)\n-#endif\n@@ -209,9 +207,0 @@\n-  \/\/ all native method kinds (must be one contiguous block)\n-  Interpreter::_native_entry_begin = Interpreter::code()->code_end();\n-  method_entry(native)\n-  method_entry(native_synchronized)\n-  Interpreter::_native_entry_end = Interpreter::code()->code_end();\n-\n-  method_entry(java_util_zip_CRC32_update)\n-  method_entry(java_util_zip_CRC32_updateBytes)\n-  method_entry(java_util_zip_CRC32_updateByteBuffer)\n@@ -221,5 +210,0 @@\n-  method_entry(java_lang_Float_intBitsToFloat);\n-  method_entry(java_lang_Float_floatToRawIntBits);\n-  method_entry(java_lang_Double_longBitsToDouble);\n-  method_entry(java_lang_Double_doubleToRawLongBits);\n-\n@@ -231,0 +215,25 @@\n+  \/\/ all native method kinds\n+#define native_method_entry(kind)                                                                  \\\n+  { CodeletMark cm(_masm, \"native method entry point (kind = \" #kind \")\");                         \\\n+    Interpreter::_entry_table[Interpreter::kind] = generate_method_entry(Interpreter::kind, true); \\\n+  }\n+\n+  native_method_entry(native)\n+  native_method_entry(native_synchronized)\n+\n+  \/\/ Entries to intrinsics for native methods should follow\n+  \/\/ entries for `native` methods to use the same address in case\n+  \/\/ intrinsic is disabled.\n+  native_method_entry(java_lang_Thread_currentThread)\n+\n+  native_method_entry(java_util_zip_CRC32_update)\n+  native_method_entry(java_util_zip_CRC32_updateBytes)\n+  native_method_entry(java_util_zip_CRC32_updateByteBuffer)\n+\n+  native_method_entry(java_lang_Float_intBitsToFloat)\n+  native_method_entry(java_lang_Float_floatToRawIntBits)\n+  native_method_entry(java_lang_Double_longBitsToDouble)\n+  native_method_entry(java_lang_Double_doubleToRawLongBits)\n+\n+#undef native_method_entry\n+\n@@ -400,1 +409,1 @@\n-                                        AbstractInterpreter::MethodKind kind) {\n+                                        AbstractInterpreter::MethodKind kind, bool native) {\n@@ -402,1 +411,0 @@\n-  bool native = false;\n@@ -407,4 +415,4 @@\n-  case Interpreter::zerolocals             :                                          break;\n-  case Interpreter::zerolocals_synchronized:                synchronized = true;      break;\n-  case Interpreter::native                 : native = true;                           break;\n-  case Interpreter::native_synchronized    : native = true; synchronized = true;      break;\n+  case Interpreter::zerolocals             :                           break;\n+  case Interpreter::zerolocals_synchronized: synchronized = true;      break;\n+  case Interpreter::native                 :                           break;\n+  case Interpreter::native_synchronized    : synchronized = true;      break;\n@@ -415,0 +423,21 @@\n+  default:\n+    entry_point = generate_intrinsic_entry(kind); \/\/ process the rest\n+    break;\n+  }\n+\n+  if (entry_point) {\n+    return entry_point;\n+  }\n+\n+  \/\/ We expect the normal and native entry points to be generated first so we can reuse them.\n+  if (native) {\n+    entry_point = Interpreter::entry_for_kind(synchronized ? Interpreter::native_synchronized : Interpreter::native);\n+    if (entry_point == nullptr) {\n+      entry_point = generate_native_entry(synchronized);\n+    }\n+  } else {\n+    entry_point = Interpreter::entry_for_kind(synchronized ? Interpreter::zerolocals_synchronized : Interpreter::zerolocals);\n+    if (entry_point == nullptr) {\n+      entry_point = generate_normal_entry(synchronized);\n+    }\n+  }\n@@ -416,0 +445,12 @@\n+  return entry_point;\n+}\n+\n+\/\/ Generate intrinsic method entries\n+address TemplateInterpreterGenerator::generate_intrinsic_entry(AbstractInterpreter::MethodKind kind) {\n+  if (!InlineIntrinsics || !vmIntrinsics::is_intrinsic_available(AbstractInterpreter::method_intrinsic(kind))) {\n+    return nullptr;\n+  }\n+\n+  address entry_point = nullptr;\n+\n+  switch (kind) {\n@@ -427,0 +468,2 @@\n+  case Interpreter::java_lang_math_sqrt_strict\n+                                           : entry_point = generate_math_entry(Interpreter::java_lang_math_sqrt); break;\n@@ -430,1 +473,1 @@\n-                                           : native = true; entry_point = generate_CRC32_update_entry();  break;\n+                                           : entry_point = generate_CRC32_update_entry();  break;\n@@ -434,1 +477,1 @@\n-                                           : native = true; entry_point = generate_CRC32_updateBytes_entry(kind); break;\n+                                           : entry_point = generate_CRC32_updateBytes_entry(kind); break;\n@@ -439,1 +482,0 @@\n-#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n@@ -442,1 +484,0 @@\n-#endif\n@@ -447,1 +488,1 @@\n-#ifdef IA32\n+\n@@ -449,1 +490,1 @@\n-  \/\/ On other platforms the normal entry is used to enter these methods.\n+  \/\/ On other platforms the native entry is used to enter these methods.\n@@ -451,1 +492,1 @@\n-                                           : native = true; entry_point = generate_Float_intBitsToFloat_entry(); break;\n+                                           : entry_point = generate_Float_intBitsToFloat_entry(); break;\n@@ -453,1 +494,1 @@\n-                                           : native = true; entry_point = generate_Float_floatToRawIntBits_entry(); break;\n+                                           : entry_point = generate_Float_floatToRawIntBits_entry(); break;\n@@ -455,1 +496,1 @@\n-                                           : native = true; entry_point = generate_Double_longBitsToDouble_entry(); break;\n+                                           : entry_point = generate_Double_longBitsToDouble_entry(); break;\n@@ -457,9 +498,1 @@\n-                                           : native = true; entry_point = generate_Double_doubleToRawLongBits_entry(); break;\n-#else\n-  case Interpreter::java_lang_Float_intBitsToFloat:\n-  case Interpreter::java_lang_Float_floatToRawIntBits:\n-  case Interpreter::java_lang_Double_longBitsToDouble:\n-  case Interpreter::java_lang_Double_doubleToRawLongBits:\n-    native = true;\n-    break;\n-#endif \/\/ !IA32\n+                                           : entry_point = generate_Double_doubleToRawLongBits_entry(); break;\n@@ -467,1 +500,1 @@\n-    fatal(\"unexpected method kind: %d\", kind);\n+    fatal(\"unexpected intrinsic method kind: %d\", kind);\n@@ -470,18 +503,0 @@\n-\n-  if (entry_point) {\n-    return entry_point;\n-  }\n-\n-  \/\/ We expect the normal and native entry points to be generated first so we can reuse them.\n-  if (native) {\n-    entry_point = Interpreter::entry_for_kind(synchronized ? Interpreter::native_synchronized : Interpreter::native);\n-    if (entry_point == nullptr) {\n-      entry_point = generate_native_entry(synchronized);\n-    }\n-  } else {\n-    entry_point = Interpreter::entry_for_kind(synchronized ? Interpreter::zerolocals_synchronized : Interpreter::zerolocals);\n-    if (entry_point == nullptr) {\n-      entry_point = generate_normal_entry(synchronized);\n-    }\n-  }\n-\n@@ -490,0 +505,1 @@\n+\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.cpp","additions":79,"deletions":63,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -87,1 +87,4 @@\n-  address generate_method_entry(AbstractInterpreter::MethodKind kind);\n+  address generate_method_entry(AbstractInterpreter::MethodKind kind, bool native);\n+\n+  \/\/ generate intrinsic method entries\n+  address generate_intrinsic_entry(AbstractInterpreter::MethodKind kind);\n@@ -97,1 +100,0 @@\n-#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n@@ -99,2 +101,0 @@\n-#endif\n-#ifdef IA32\n@@ -105,1 +105,0 @@\n-#endif \/\/ IA32\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.hpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -69,1 +69,0 @@\n-    Interpreter::_native_entry_begin = Interpreter::code()->code_end();\n@@ -72,1 +71,0 @@\n-    Interpreter::_native_entry_end = Interpreter::code()->code_end();\n","filename":"src\/hotspot\/share\/interpreter\/zero\/zeroInterpreterGenerator.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -183,1 +183,1 @@\n-bool C2Compiler::is_intrinsic_supported(const methodHandle& method, bool is_virtual) {\n+bool C2Compiler::is_intrinsic_supported(const methodHandle& method) {\n@@ -191,14 +191,0 @@\n-  \/\/ Only Object.hashCode and Object.clone intrinsics implement also a virtual\n-  \/\/ dispatch because calling both methods is expensive but both methods are\n-  \/\/ frequently overridden. All other intrinsics implement only a non-virtual\n-  \/\/ dispatch.\n-  if (is_virtual) {\n-    switch (id) {\n-    case vmIntrinsics::_hashCode:\n-    case vmIntrinsics::_clone:\n-      break;\n-    default:\n-      return false;\n-    }\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":15,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -64,7 +64,1 @@\n-  virtual bool is_intrinsic_supported(const methodHandle& method) {\n-    return is_intrinsic_supported(method, false);\n-  }\n-\n-  \/\/ Check if the compiler supports an intrinsic for 'method' given the\n-  \/\/ the dispatch mode specified by the 'is_virtual' parameter.\n-  bool is_intrinsic_supported(const methodHandle& method, bool is_virtual);\n+  virtual bool is_intrinsic_supported(const methodHandle& method);\n","filename":"src\/hotspot\/share\/opto\/c2compiler.hpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -80,4 +80,4 @@\n-    is_available = compiler != nullptr && compiler->is_intrinsic_supported(mh, is_virtual) &&\n-                   !C->directive()->is_intrinsic_disabled(mh) &&\n-                   !vmIntrinsics::is_disabled_by_flags(mh);\n-\n+    is_available = compiler != nullptr && compiler->is_intrinsic_available(mh, C->directive());\n+    if (is_available && is_virtual) {\n+      is_available = vmIntrinsics::does_virtual_dispatch(id);\n+    }\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+enum class vmIntrinsicID;\n@@ -184,0 +185,4 @@\n+\n+  \/\/ Does this CPU support this intrinsic?\n+  static bool is_intrinsic_supported(vmIntrinsicID id) { return true; }\n+\n","filename":"src\/hotspot\/share\/runtime\/abstract_vm_version.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1197,1 +1197,1 @@\n-          \"Inline intrinsics that can be statically resolved\")              \\\n+          \"Use intrinsics in Interpreter that can be statically resolved\")  \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -86,2 +86,3 @@\n-            expectStableFloats = (sse >= 1);\n-            expectStableDoubles = (sse >= 2);\n+            boolean stubsPresent = WHITE_BOX.getBooleanVMFlag(\"InlineIntrinsics\");\n+            expectStableFloats = (sse >= 1) && stubsPresent;\n+            expectStableDoubles = (sse >= 2) && stubsPresent;\n","filename":"test\/hotspot\/jtreg\/compiler\/floatingpoint\/NaNTest.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}