{"files":[{"patch":"@@ -30,2 +30,1 @@\n-#include \"runtime\/javaThread.hpp\"\n-#include \"runtime\/safepoint.hpp\"\n+#include \"nmt\/regionsTree.inline.hpp\"\n@@ -107,32 +106,0 @@\n-\/\/ Walk all virtual memory regions for baselining\n-class VirtualMemoryAllocationWalker : public VirtualMemoryWalker {\n- private:\n-  typedef LinkedListImpl<ReservedMemoryRegion, AnyObj::C_HEAP, mtNMT,\n-                         AllocFailStrategy::RETURN_NULL> EntryList;\n-  EntryList _virtual_memory_regions;\n-  DEBUG_ONLY(address _last_base;)\n- public:\n-  VirtualMemoryAllocationWalker() {\n-    DEBUG_ONLY(_last_base = nullptr);\n-  }\n-\n-  bool do_allocation_site(const ReservedMemoryRegion* rgn)  {\n-    assert(rgn->base() >= _last_base, \"region unordered?\");\n-    DEBUG_ONLY(_last_base = rgn->base());\n-    if (rgn->size() > 0) {\n-      if (_virtual_memory_regions.add(*rgn) != nullptr) {\n-        return true;\n-      } else {\n-        return false;\n-      }\n-    } else {\n-      \/\/ Ignore empty sites.\n-      return true;\n-    }\n-  }\n-\n-  LinkedList<ReservedMemoryRegion>* virtual_memory_allocations() {\n-    return &_virtual_memory_regions;\n-  }\n-};\n-\n@@ -161,5 +128,1 @@\n-  \/\/ Virtual memory allocation sites\n-  VirtualMemoryAllocationWalker virtual_memory_walker;\n-  if (!VirtualMemoryTracker::Instance::walk_virtual_memory(&virtual_memory_walker)) {\n-    return false;\n-  }\n+  assert(_vma_allocs_replacement == nullptr, \"must\");\n@@ -167,2 +130,7 @@\n-  \/\/ Virtual memory allocations are collected in call stack order\n-  _virtual_memory_allocations.move(virtual_memory_walker.virtual_memory_allocations());\n+  {\n+    MemTracker::NmtVirtualMemoryLocker locker;\n+    _vma_allocs_replacement = new (mtNMT, std::nothrow) RegionsTree(*VirtualMemoryTracker::Instance::tree());\n+    if (_vma_allocs_replacement == nullptr)  {\n+      return false;\n+    }\n+  }\n@@ -205,2 +173,0 @@\n-  VirtualMemoryAllocationIterator itr = virtual_memory_allocations();\n-  const ReservedMemoryRegion* rgn;\n@@ -208,2 +174,3 @@\n-  while ((rgn = itr.next()) != nullptr) {\n-    VirtualMemoryAllocationSite tmp(*rgn->call_stack(), rgn->mem_tag());\n+  bool failed_oom = false;\n+  _vma_allocs_replacement->visit_reserved_regions([&](ReservedMemoryRegion& rgn) {\n+    VirtualMemoryAllocationSite tmp(*rgn.call_stack(), rgn.mem_tag());\n@@ -214,1 +181,4 @@\n-      if (node == nullptr) return false;\n+      if (node == nullptr) {\n+        failed_oom = true;\n+        return false;\n+      }\n@@ -217,2 +187,8 @@\n-    site->reserve_memory(rgn->size());\n-    site->commit_memory(VirtualMemoryTracker::Instance::committed_size(rgn));\n+    site->reserve_memory(rgn.size());\n+\n+    site->commit_memory(_vma_allocs_replacement->committed_size(rgn));\n+    return true;\n+  });\n+\n+  if (failed_oom) {\n+    return false;\n","filename":"src\/hotspot\/share\/nmt\/memBaseline.cpp","additions":24,"deletions":48,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-typedef LinkedListIterator<ReservedMemoryRegion>         VirtualMemoryAllocationIterator;\n@@ -74,1 +73,1 @@\n-  LinkedListImpl<ReservedMemoryRegion>        _virtual_memory_allocations;\n+  RegionsTree* _vma_allocs_replacement;\n@@ -89,0 +88,1 @@\n+    _vma_allocs_replacement(nullptr),\n@@ -113,3 +113,3 @@\n-  VirtualMemoryAllocationIterator virtual_memory_allocations() {\n-    assert(!_virtual_memory_allocations.is_empty(), \"Not detail baseline\");\n-    return VirtualMemoryAllocationIterator(_virtual_memory_allocations.head());\n+  RegionsTree* virtual_memory_allocations() {\n+    assert(_vma_allocs_replacement != nullptr, \"Not detail baseline\");\n+    return _vma_allocs_replacement;\n@@ -188,1 +188,2 @@\n-    _virtual_memory_allocations.clear();\n+    delete _vma_allocs_replacement;\n+    _vma_allocs_replacement = nullptr;\n","filename":"src\/hotspot\/share\/nmt\/memBaseline.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -398,3 +398,0 @@\n-  VirtualMemoryAllocationIterator itr = _baseline.virtual_memory_allocations();\n-  const ReservedMemoryRegion* rgn;\n-\n@@ -402,3 +399,4 @@\n-  while ((rgn = itr.next()) != nullptr) {\n-    report_virtual_memory_region(rgn);\n-  }\n+  _baseline.virtual_memory_allocations()->visit_reserved_regions([&](ReservedMemoryRegion& rgn) {\n+    report_virtual_memory_region(&rgn);\n+    return true;\n+  });\n","filename":"src\/hotspot\/share\/nmt\/memReporter.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -60,0 +60,18 @@\n+\n+NativeCallStackStorage::NativeCallStackStorage(const NativeCallStackStorage& other)\n+  : _table_size(other._table_size),\n+    _table(nullptr),\n+    _stacks(),\n+    _is_detailed_mode(other._is_detailed_mode),\n+    _fake_stack(other._fake_stack) {\n+  if (_is_detailed_mode) {\n+    _table = NEW_C_HEAP_ARRAY(TableEntryIndex, _table_size, mtNMT);\n+    for (int i = 0; i < _table_size; i++) {\n+      _table[i] = other._table[i];\n+    }\n+  }\n+  _stacks.reserve(other._stacks.length());\n+  for (int i = 0; i < other._stacks.length(); i++) {\n+    _stacks.at_grow(i) = other._stacks.at(i);\n+  }\n+}\n","filename":"src\/hotspot\/share\/nmt\/nmtNativeCallStackStorage.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -97,1 +97,2 @@\n-\n+  NativeCallStackStorage(const NativeCallStackStorage& other);\n+  NativeCallStackStorage& operator=(const NativeCallStackStorage& other) = delete;\n","filename":"src\/hotspot\/share\/nmt\/nmtNativeCallStackStorage.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+#include \"nmt\/regionsTree.inline.hpp\"\n+#include \"nmt\/virtualMemoryTracker.hpp\"\n@@ -57,1 +59,10 @@\n-#endif\n\\ No newline at end of file\n+#endif\n+\n+size_t RegionsTree::committed_size(ReservedMemoryRegion& rgn) {\n+  size_t result = 0;\n+  visit_committed_regions(rgn, [&](CommittedMemoryRegion& crgn) {\n+    result += crgn.size();\n+    return true;\n+  });\n+  return result;\n+}\n","filename":"src\/hotspot\/share\/nmt\/regionsTree.cpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -43,0 +43,6 @@\n+  RegionsTree(const RegionsTree& other)\n+  : VMATree(other),\n+    _ncs_storage(other._ncs_storage),\n+    _with_storage(other._with_storage) {}\n+  RegionsTree& operator=(const RegionsTree& other) = delete;\n+\n@@ -94,0 +100,2 @@\n+\n+  size_t committed_size(ReservedMemoryRegion& rgn);\n@@ -96,1 +104,1 @@\n-#endif \/\/ NMT_REGIONSTREE_HPP\n\\ No newline at end of file\n+#endif \/\/ NMT_REGIONSTREE_HPP\n","filename":"src\/hotspot\/share\/nmt\/regionsTree.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -747,0 +747,7 @@\n+\n+void VMATree::clear() {\n+  _tree.remove_all();\n+};\n+bool VMATree::is_empty() {\n+  return _tree.size() == 0;\n+};\n","filename":"src\/hotspot\/share\/nmt\/vmatree.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-class VMATree {\n+class VMATree : public CHeapObjBase {\n@@ -69,1 +69,0 @@\n-  NONCOPYABLE(VMATree);\n@@ -230,0 +229,2 @@\n+  VMATree(const VMATree& other) : _tree(other._tree) {}\n+  VMATree& operator=(VMATree const&) = delete;\n@@ -333,0 +334,3 @@\n+\n+  void clear();\n+  bool is_empty();\n","filename":"src\/hotspot\/share\/nmt\/vmatree.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -454,0 +454,9 @@\n+  RBTree(const RBTree& other) : BaseType(), _allocator() {\n+    static_assert(std::is_copy_constructible<K>::value, \"Key type must be copy-constructible when copying a RBTree\");\n+    static_assert(std::is_copy_constructible<V>::value, \"Value type must be copy-constructible when copying a RBTree\");\n+    other.visit_in_order([&](auto node) {\n+      this->upsert(node->key(), node->val());\n+      return true;\n+    });\n+  }\n+  RBTree& operator=(const RBTree& other) = delete;\n","filename":"src\/hotspot\/share\/utilities\/rbTree.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"}]}