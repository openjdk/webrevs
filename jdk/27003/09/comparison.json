{"files":[{"patch":"@@ -30,2 +30,1 @@\n-#include \"runtime\/javaThread.hpp\"\n-#include \"runtime\/safepoint.hpp\"\n+#include \"nmt\/regionsTree.inline.hpp\"\n@@ -107,32 +106,0 @@\n-\/\/ Walk all virtual memory regions for baselining\n-class VirtualMemoryAllocationWalker : public VirtualMemoryWalker {\n- private:\n-  typedef LinkedListImpl<ReservedMemoryRegion, AnyObj::C_HEAP, mtNMT,\n-                         AllocFailStrategy::RETURN_NULL> EntryList;\n-  EntryList _virtual_memory_regions;\n-  DEBUG_ONLY(address _last_base;)\n- public:\n-  VirtualMemoryAllocationWalker() {\n-    DEBUG_ONLY(_last_base = nullptr);\n-  }\n-\n-  bool do_allocation_site(const ReservedMemoryRegion* rgn)  {\n-    assert(rgn->base() >= _last_base, \"region unordered?\");\n-    DEBUG_ONLY(_last_base = rgn->base());\n-    if (rgn->size() > 0) {\n-      if (_virtual_memory_regions.add(*rgn) != nullptr) {\n-        return true;\n-      } else {\n-        return false;\n-      }\n-    } else {\n-      \/\/ Ignore empty sites.\n-      return true;\n-    }\n-  }\n-\n-  LinkedList<ReservedMemoryRegion>* virtual_memory_allocations() {\n-    return &_virtual_memory_regions;\n-  }\n-};\n-\n@@ -161,5 +128,1 @@\n-  \/\/ Virtual memory allocation sites\n-  VirtualMemoryAllocationWalker virtual_memory_walker;\n-  if (!VirtualMemoryTracker::Instance::walk_virtual_memory(&virtual_memory_walker)) {\n-    return false;\n-  }\n+  assert(_vma_allocs_replacement == nullptr, \"must\");\n@@ -167,2 +130,7 @@\n-  \/\/ Virtual memory allocations are collected in call stack order\n-  _virtual_memory_allocations.move(virtual_memory_walker.virtual_memory_allocations());\n+  {\n+    MemTracker::NmtVirtualMemoryLocker locker;\n+    _vma_allocs_replacement = new (mtNMT, std::nothrow) RegionsTree(*VirtualMemoryTracker::Instance::tree());\n+    if (_vma_allocs_replacement == nullptr)  {\n+      return false;\n+    }\n+  }\n@@ -205,2 +173,0 @@\n-  VirtualMemoryAllocationIterator itr = virtual_memory_allocations();\n-  const ReservedMemoryRegion* rgn;\n@@ -208,2 +174,3 @@\n-  while ((rgn = itr.next()) != nullptr) {\n-    VirtualMemoryAllocationSite tmp(*rgn->call_stack(), rgn->mem_tag());\n+  bool failed_oom = false;\n+  _vma_allocs_replacement->visit_reserved_regions([&](ReservedMemoryRegion& rgn) {\n+    VirtualMemoryAllocationSite tmp(*rgn.call_stack(), rgn.mem_tag());\n@@ -214,1 +181,4 @@\n-      if (node == nullptr) return false;\n+      if (node == nullptr) {\n+        failed_oom = true;\n+        return false;\n+      }\n@@ -217,2 +187,8 @@\n-    site->reserve_memory(rgn->size());\n-    site->commit_memory(VirtualMemoryTracker::Instance::committed_size(rgn));\n+    site->reserve_memory(rgn.size());\n+\n+    site->commit_memory(_vma_allocs_replacement->committed_size(rgn));\n+    return true;\n+  });\n+\n+  if (failed_oom) {\n+    return false;\n","filename":"src\/hotspot\/share\/nmt\/memBaseline.cpp","additions":24,"deletions":48,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -38,1 +38,0 @@\n-typedef LinkedListIterator<ReservedMemoryRegion>         VirtualMemoryAllocationIterator;\n@@ -74,1 +73,1 @@\n-  LinkedListImpl<ReservedMemoryRegion>        _virtual_memory_allocations;\n+  RegionsTree* _vma_allocs_replacement;\n@@ -89,0 +88,1 @@\n+    _vma_allocs_replacement(nullptr),\n@@ -113,3 +113,3 @@\n-  VirtualMemoryAllocationIterator virtual_memory_allocations() {\n-    assert(!_virtual_memory_allocations.is_empty(), \"Not detail baseline\");\n-    return VirtualMemoryAllocationIterator(_virtual_memory_allocations.head());\n+  RegionsTree* virtual_memory_allocations() {\n+    assert(_vma_allocs_replacement != nullptr, \"Not detail baseline\");\n+    return _vma_allocs_replacement;\n@@ -188,1 +188,2 @@\n-    _virtual_memory_allocations.clear();\n+    delete _vma_allocs_replacement;\n+    _vma_allocs_replacement = nullptr;\n","filename":"src\/hotspot\/share\/nmt\/memBaseline.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -398,3 +398,0 @@\n-  VirtualMemoryAllocationIterator itr = _baseline.virtual_memory_allocations();\n-  const ReservedMemoryRegion* rgn;\n-\n@@ -402,3 +399,4 @@\n-  while ((rgn = itr.next()) != nullptr) {\n-    report_virtual_memory_region(rgn);\n-  }\n+  _baseline.virtual_memory_allocations()->visit_reserved_regions([&](ReservedMemoryRegion& rgn) {\n+    report_virtual_memory_region(&rgn);\n+    return true;\n+  });\n","filename":"src\/hotspot\/share\/nmt\/memReporter.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -60,0 +60,18 @@\n+\n+NativeCallStackStorage::NativeCallStackStorage(const NativeCallStackStorage& other)\n+  : _table_size(other._table_size),\n+    _table(nullptr),\n+    _stacks(),\n+    _is_detailed_mode(other._is_detailed_mode),\n+    _fake_stack(other._fake_stack) {\n+  if (_is_detailed_mode) {\n+    _table = NEW_C_HEAP_ARRAY(TableEntryIndex, _table_size, mtNMT);\n+    for (int i = 0; i < _table_size; i++) {\n+      _table[i] = other._table[i];\n+    }\n+  }\n+  _stacks.reserve(other._stacks.length());\n+  for (int i = 0; i < other._stacks.length(); i++) {\n+    _stacks.at_grow(i) = other._stacks.at(i);\n+  }\n+}\n","filename":"src\/hotspot\/share\/nmt\/nmtNativeCallStackStorage.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -97,1 +97,2 @@\n-\n+  NativeCallStackStorage(const NativeCallStackStorage& other);\n+  NativeCallStackStorage& operator=(const NativeCallStackStorage& other) = delete;\n","filename":"src\/hotspot\/share\/nmt\/nmtNativeCallStackStorage.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+#include \"nmt\/regionsTree.inline.hpp\"\n+#include \"nmt\/virtualMemoryTracker.hpp\"\n@@ -57,1 +59,10 @@\n-#endif\n\\ No newline at end of file\n+#endif\n+\n+size_t RegionsTree::committed_size(ReservedMemoryRegion& rgn) {\n+  size_t result = 0;\n+  visit_committed_regions(rgn, [&](CommittedMemoryRegion& crgn) {\n+    result += crgn.size();\n+    return true;\n+  });\n+  return result;\n+}\n","filename":"src\/hotspot\/share\/nmt\/regionsTree.cpp","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -43,0 +43,6 @@\n+  RegionsTree(const RegionsTree& other)\n+  : VMATree(other),\n+    _ncs_storage(other._ncs_storage),\n+    _with_storage(other._with_storage) {}\n+  RegionsTree& operator=(const RegionsTree& other) = delete;\n+\n@@ -94,0 +100,2 @@\n+\n+  size_t committed_size(ReservedMemoryRegion& rgn);\n@@ -96,1 +104,1 @@\n-#endif \/\/ NMT_REGIONSTREE_HPP\n\\ No newline at end of file\n+#endif \/\/ NMT_REGIONSTREE_HPP\n","filename":"src\/hotspot\/share\/nmt\/regionsTree.hpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -747,0 +747,7 @@\n+\n+void VMATree::clear() {\n+  _tree.remove_all();\n+};\n+bool VMATree::is_empty() {\n+  return _tree.size() == 0;\n+};\n","filename":"src\/hotspot\/share\/nmt\/vmatree.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"utilities\/rbTree.hpp\"\n@@ -42,1 +43,1 @@\n-class VMATree {\n+class VMATree : public CHeapObjBase {\n@@ -69,1 +70,0 @@\n-  NONCOPYABLE(VMATree);\n@@ -230,0 +230,4 @@\n+  VMATree(const VMATree& other) : _tree() {\n+    assert(other._tree.copy_into(_tree), \"VMATree dies on OOM\");\n+  }\n+  VMATree& operator=(VMATree const&) = delete;\n@@ -333,0 +337,3 @@\n+\n+  void clear();\n+  bool is_empty();\n","filename":"src\/hotspot\/share\/nmt\/vmatree.hpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -415,0 +415,1 @@\n+\n@@ -454,0 +455,1 @@\n+  NONCOPYABLE(RBTree);\n@@ -456,0 +458,48 @@\n+  bool copy_into(RBTree& other) const {\n+    assert(other.size() == 0, \"You can only copy into an empty RBTree\");\n+    assert(std::is_copy_constructible<K>::value, \"Key type must be copy-constructible when copying a RBTree\");\n+    assert(std::is_copy_constructible<V>::value, \"Value type must be copy-constructible when copying a RBTree\");\n+    enum class Dir { Left, Right };\n+    struct node_pair { const IntrusiveRBNode* current; IntrusiveRBNode* other_parent; Dir dir; };\n+    struct stack {\n+      node_pair s[64];\n+      int idx = 0;\n+      stack() : idx(0) {}\n+      node_pair pop() { idx--; return s[idx]; };\n+      void push(node_pair n) { s[idx] = n; idx++; };\n+      bool is_empty() { return idx == 0; };\n+    };\n+\n+    stack visit_stack;\n+    if (this->_root == nullptr)  {\n+      return true;\n+    }\n+    RBNode<K, V>* root = static_cast<RBNode<K, V>*>(this->_root);\n+    other._root = other.allocate_node(root->key(), root->val());\n+    if (other._root == nullptr) return false;\n+\n+    visit_stack.push({this->_root->_left, other._root, Dir::Left});\n+    visit_stack.push({this->_root->_right, other._root, Dir::Right});\n+    while (!visit_stack.is_empty()) {\n+      node_pair n = visit_stack.pop();\n+      const RBNode<K, V>* current = static_cast<const RBNode<K, V>*>(n.current);\n+      if (current == nullptr) continue;\n+      RBNode<K, V>* new_node = other.allocate_node(current->key(), current->val());\n+      if (new_node == nullptr) {\n+        return false;\n+      }\n+      if (n.dir == Dir::Left) {\n+        n.other_parent->_left = new_node;\n+      } else {\n+        n.other_parent->_right = new_node;\n+      }\n+      new_node->set_parent(n.other_parent);\n+      new_node->_parent |= n.current->_parent & 0x1;\n+      visit_stack.push({n.current->_left, new_node, Dir::Left});\n+      visit_stack.push({n.current->_right, new_node, Dir::Right});\n+    }\n+    other._num_nodes = this->_num_nodes;\n+    DEBUG_ONLY(other._expected_visited = this->_expected_visited);\n+    return true;\n+  }\n+\n","filename":"src\/hotspot\/share\/utilities\/rbTree.hpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -1082,0 +1082,39 @@\n+TEST_VM_F(RBTreeTest, TestCopyInto) {\n+  {\n+    RBTreeInt rbtree1;\n+    RBTreeInt rbtree2;\n+\n+    rbtree1.copy_into(rbtree2);\n+    rbtree2.verify_self();\n+  }\n+\n+  RBTreeInt rbtree1;\n+  RBTreeInt rbtree2;\n+\n+  int size = 1000;\n+  for (int i = 0; i < size; i++) {\n+    rbtree1.upsert(i, i);\n+  }\n+\n+  rbtree1.copy_into(rbtree2);\n+  rbtree2.verify_self();\n+\n+  ResourceMark rm;\n+  GrowableArray<int> allocations(size);\n+  int size1 = 0;\n+  rbtree1.visit_in_order([&](RBTreeIntNode* node) {\n+    size1++;\n+    allocations.append(node->key());\n+    return true;\n+  });\n+\n+  int size2 = 0;\n+  rbtree2.visit_in_order([&](RBTreeIntNode* node) {\n+    EXPECT_EQ(node->key(), allocations.at(size2++));\n+    return true;\n+  });\n+\n+  EXPECT_EQ(size1, size2);\n+  EXPECT_EQ(rbtree1.size(), rbtree2.size());\n+  EXPECT_EQ(size2, static_cast<int>(rbtree2.size()));\n+}\n","filename":"test\/hotspot\/gtest\/utilities\/test_rbtree.cpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"}]}