{"files":[{"patch":"@@ -1,136 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n-#define SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n-\n-#include \"memory\/padded.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/pair.hpp\"\n-\n-\/\/ The NonblockingQueue template provides a non-blocking FIFO.\n-\/\/ It has inner padding of one cache line between its two internal pointers.\n-\/\/\n-\/\/ The queue is internally represented by a linked list of elements, with\n-\/\/ the link to the next element provided by a member of each element.\n-\/\/ Access to this member is provided by the next_ptr function.\n-\/\/\n-\/\/ The queue has a special pseudo-element that marks the end of the list.\n-\/\/ Each queue has its own unique special element.  A pointer to this element\n-\/\/ can be recognized using the is_end() function.  Such a pointer must never\n-\/\/ be dereferenced.  This end marker is the value of the next member of the\n-\/\/ last element in the queue, and possibly other elements while modifying\n-\/\/ the queue.\n-\/\/\n-\/\/ A queue may temporarily appear to be empty even though elements have been\n-\/\/ added and not removed.  For example, after running the following program,\n-\/\/ the value of r may be null.\n-\/\/\n-\/\/ thread1: q.push(a); r = q.pop();\n-\/\/ thread2: q.push(b);\n-\/\/\n-\/\/ This can occur if the push of b started before the push of a, but didn't\n-\/\/ complete until after the pop.\n-\/\/\n-\/\/ \\tparam T is the class of the elements in the queue.\n-\/\/\n-\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n-\/\/ an object of type T must return a pointer to the list entry member\n-\/\/ of the object associated with the NonblockingQueue type.\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-class NonblockingQueue {\n-  T* volatile _head;\n-  \/\/ Padding of one cache line to avoid false sharing.\n-  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_PADDING_SIZE, sizeof(T*));\n-  T* volatile _tail;\n-\n-  NONCOPYABLE(NonblockingQueue);\n-\n-  \/\/ Return the entry following node in the list used by the\n-  \/\/ specialized NonblockingQueue class.\n-  static inline T* next(const T& node);\n-\n-  \/\/ Set the entry following node to new_next in the list used by the\n-  \/\/ specialized NonblockingQueue class. Not thread-safe, as it cannot\n-  \/\/ concurrently run with push or try_pop operations that modify this\n-  \/\/ node.\n-  static inline void set_next(T& node, T* new_next);\n-\n-  \/\/ A unique pseudo-object pointer associated with this specific queue.\n-  \/\/ The resulting pointer must not be dereferenced.\n-  inline T* end_marker() const;\n-\n-public:\n-  inline NonblockingQueue();\n-  inline ~NonblockingQueue() NOT_DEBUG(= default);\n-\n-  \/\/ Return true if the queue is empty.\n-  \/\/ Not thread-safe.  There must be no concurrent modification while the\n-  \/\/ queue is being tested.\n-  inline bool empty() const;\n-\n-  \/\/ Return the number of objects in the queue.\n-  \/\/ Not thread-safe. There must be no concurrent modification while the\n-  \/\/ length is being determined.\n-  inline size_t length() const;\n-\n-  \/\/ Thread-safe add the object to the end of the queue.\n-  \/\/ Subject to ABA behavior; callers must ensure usage is safe.\n-  inline void push(T& node) { append(node, node); }\n-\n-  \/\/ Thread-safe add the objects from first to last to the end of the queue.\n-  \/\/ Subject to ABA behavior; callers must ensure usage is safe.\n-  inline void append(T& first, T& last);\n-\n-  \/\/ Thread-safe attempt to remove and return the first object in the queue.\n-  \/\/ Returns true if successful.  If successful then *node_ptr is the former\n-  \/\/ first object, or null if the queue was empty.  If unsuccessful, because\n-  \/\/ of contention with a concurrent modification, then returns false with\n-  \/\/ the value of *node_ptr unspecified.  Subject to ABA behavior; callers\n-  \/\/ must ensure usage is safe.\n-  inline bool try_pop(T** node_ptr);\n-\n-  \/\/ Thread-safe remove and return the first object in the queue, or null\n-  \/\/ if the queue was empty.  This just iterates on try_pop() until it\n-  \/\/ succeeds, returning the (possibly null) element obtained from that.\n-  \/\/ Subject to ABA behavior; callers must ensure usage is safe.\n-  inline T* pop();\n-\n-  \/\/ Take all the objects from the queue, leaving the queue empty.\n-  \/\/ Not thread-safe.  There must be no concurrent operations.\n-  \/\/ Returns a pair of <head, tail> pointers to the current queue.\n-  inline Pair<T*, T*> take_all();\n-\n-  \/\/ Iteration support is provided by first() and is_end().  The queue must\n-  \/\/ not be modified while iterating over its elements.\n-\n-  \/\/ Return the first object in the queue, or an end marker (a pointer p for\n-  \/\/ which is_end(p) is true) if the queue is empty.\n-  inline T* first() const;\n-\n-  \/\/ Test whether entry is an end marker for this queue.\n-  inline bool is_end(const T* entry) const;\n-};\n-\n-#endif \/\/ SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.hpp","additions":0,"deletions":136,"binary":false,"changes":136,"status":"deleted"},{"patch":"@@ -1,248 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n-#define SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n-\n-#include \"utilities\/nonblockingQueue.hpp\"\n-\n-#include \"runtime\/atomicAccess.hpp\"\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* NonblockingQueue<T, next_ptr>::next(const T& node) {\n-  return AtomicAccess::load(next_ptr(const_cast<T&>(node)));\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-void NonblockingQueue<T, next_ptr>::set_next(T& node, T* new_next) {\n-  AtomicAccess::store(next_ptr(node), new_next);\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-NonblockingQueue<T, next_ptr>::NonblockingQueue() : _head(nullptr), _tail(nullptr) {}\n-\n-#ifdef ASSERT\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-NonblockingQueue<T, next_ptr>::~NonblockingQueue() {\n-  assert(_head == nullptr, \"precondition\");\n-  assert(_tail == nullptr, \"precondition\");\n-}\n-#endif\n-\n-\/\/ The end_marker must be uniquely associated with the specific queue, in\n-\/\/ case queue elements can make their way through multiple queues.  A\n-\/\/ pointer to the queue itself (after casting) satisfies that requirement.\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* NonblockingQueue<T, next_ptr>::end_marker() const {\n-  return const_cast<T*>(reinterpret_cast<const T*>(this));\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* NonblockingQueue<T, next_ptr>::first() const {\n-  T* head = AtomicAccess::load(&_head);\n-  return head == nullptr ? end_marker() : head;\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-bool NonblockingQueue<T, next_ptr>::is_end(const T* entry) const {\n-  return entry == end_marker();\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-bool NonblockingQueue<T, next_ptr>::empty() const {\n-  return AtomicAccess::load(&_head) == nullptr;\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-size_t NonblockingQueue<T, next_ptr>::length() const {\n-  size_t result = 0;\n-  for (T* cur = first(); !is_end(cur); cur = next(*cur)) {\n-    ++result;\n-  }\n-  return result;\n-}\n-\n-\/\/ An append operation atomically exchanges the new tail with the queue tail.\n-\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n-\/\/ appended. If the old tail is null then the queue was empty, then the\n-\/\/ head of the list being appended is instead stored in the queue head.\n-\/\/\n-\/\/ This means there is a period between the exchange and the old tail update\n-\/\/ where the queue sequence is split into two parts, the list from the queue\n-\/\/ head to the old tail, and the list being appended.  If there are concurrent\n-\/\/ push\/append operations, each may introduce another such segment.  But they\n-\/\/ all eventually get resolved by their respective updates of their old tail's\n-\/\/ \"next\" value.  This also means that try_pop operation must handle an object\n-\/\/ differently depending on its \"next\" value.\n-\/\/\n-\/\/ A push operation is just a degenerate append, where the object being pushed\n-\/\/ is both the head and the tail of the list being appended.\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-void NonblockingQueue<T, next_ptr>::append(T& first, T& last) {\n-  assert(next(last) == nullptr, \"precondition\");\n-  \/\/ Make last the new end of the queue.  Any further push\/appends will\n-  \/\/ extend after last.  We will try to extend from the previous end of\n-  \/\/ queue.\n-  set_next(last, end_marker());\n-  T* old_tail = AtomicAccess::xchg(&_tail, &last);\n-  if (old_tail == nullptr) {\n-    \/\/ If old_tail is null then the queue was empty, and _head must also be\n-    \/\/ null. The correctness of this assertion depends on try_pop clearing\n-    \/\/ first _head then _tail when taking the last entry.\n-    assert(AtomicAccess::load(&_head) == nullptr, \"invariant\");\n-    \/\/ Fall through to common update of _head.\n-  } else if (is_end(AtomicAccess::cmpxchg(next_ptr(*old_tail), end_marker(), &first))) {\n-    \/\/ Successfully extended the queue list from old_tail to first.  No\n-    \/\/ other push\/append could have competed with us, because we claimed\n-    \/\/ old_tail for extension.  We won any races with try_pop by changing\n-    \/\/ away from end-marker.  So we're done.\n-    \/\/\n-    \/\/ Note that ABA is possible here.  A concurrent try_pop could take\n-    \/\/ old_tail before our update of old_tail's next_ptr, old_tail gets\n-    \/\/ recycled and re-added to the end of this queue, and then we\n-    \/\/ successfully cmpxchg, making the list in _tail circular.  Callers\n-    \/\/ must ensure this can't happen.\n-    return;\n-  } else {\n-    \/\/ A concurrent try_pop has claimed old_tail, so it is no longer in the\n-    \/\/ list. The queue was logically empty.  _head is either null or\n-    \/\/ old_tail, depending on how far try_pop operations have progressed.\n-    DEBUG_ONLY(T* old_head = AtomicAccess::load(&_head);)\n-    assert((old_head == nullptr) || (old_head == old_tail), \"invariant\");\n-    \/\/ Fall through to common update of _head.\n-  }\n-  \/\/ The queue was empty, and first should become the new _head.  The queue\n-  \/\/ will appear to be empty to any further try_pops until done.\n-  AtomicAccess::store(&_head, &first);\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-bool NonblockingQueue<T, next_ptr>::try_pop(T** node_ptr) {\n-  \/\/ We only need memory_order_consume. Upgrade it to \"load_acquire\"\n-  \/\/ as the memory_order_consume API is not ready for use yet.\n-  T* old_head = AtomicAccess::load_acquire(&_head);\n-  if (old_head == nullptr) {\n-    *node_ptr = nullptr;\n-    return true;                \/\/ Queue is empty.\n-  }\n-\n-  T* next_node = AtomicAccess::load_acquire(next_ptr(*old_head));\n-  if (!is_end(next_node)) {\n-    \/\/ [Clause 1]\n-    \/\/ There are several cases for next_node.\n-    \/\/ (1) next_node is the extension of the queue's list.\n-    \/\/ (2) next_node is null, because a competing try_pop took old_head.\n-    \/\/ (3) next_node is the extension of some unrelated list, because a\n-    \/\/ competing try_pop took old_head and put it in some other list.\n-    \/\/\n-    \/\/ Attempt to advance the list, replacing old_head with next_node in\n-    \/\/ _head.  The success or failure of that attempt, along with the value\n-    \/\/ of next_node, are used to partially determine which case we're in and\n-    \/\/ how to proceed.  In particular, advancement will fail for case (3).\n-    if (old_head != AtomicAccess::cmpxchg(&_head, old_head, next_node)) {\n-      \/\/ [Clause 1a]\n-      \/\/ The cmpxchg to advance the list failed; a concurrent try_pop won\n-      \/\/ the race and claimed old_head.  This can happen for any of the\n-      \/\/ next_node cases.\n-      return false;\n-    } else if (next_node == nullptr) {\n-      \/\/ [Clause 1b]\n-      \/\/ The cmpxchg to advance the list succeeded, but a concurrent try_pop\n-      \/\/ has already claimed old_head (see [Clause 2] - old_head was the last\n-      \/\/ entry in the list) by nulling old_head's next field.  The advance set\n-      \/\/ _head to null, \"helping\" the competing try_pop.  _head will remain\n-      \/\/ nullptr until a subsequent push\/append.  This is a lost race, and we\n-      \/\/ report it as such for consistency, though we could report the queue\n-      \/\/ was empty.  We don't attempt to further help [Clause 2] by also\n-      \/\/ trying to set _tail to nullptr, as that would just ensure that one or\n-      \/\/ the other cmpxchg is a wasted failure.\n-      return false;\n-    } else {\n-      \/\/ [Clause 1c]\n-      \/\/ Successfully advanced the list and claimed old_head.  next_node was\n-      \/\/ in the extension of the queue's list.  Return old_head after\n-      \/\/ unlinking it from next_node.\n-      set_next(*old_head, nullptr);\n-      *node_ptr = old_head;\n-      return true;\n-    }\n-\n-  } else if (is_end(AtomicAccess::cmpxchg(next_ptr(*old_head), next_node, (T*)nullptr))) {\n-    \/\/ [Clause 2]\n-    \/\/ Old_head was the last entry and we've claimed it by setting its next\n-    \/\/ value to null.  However, this leaves the queue in disarray.  Fix up\n-    \/\/ the queue, possibly in conjunction with other concurrent operations.\n-    \/\/ Any further try_pops will consider the queue empty until a\n-    \/\/ push\/append completes by installing a new head.\n-\n-    \/\/ The order of the two cmpxchgs doesn't matter algorithmically, but\n-    \/\/ dealing with _head first gives a stronger invariant in append, and is\n-    \/\/ also consistent with [Clause 1b].\n-\n-    \/\/ Attempt to change the queue head from old_head to null.  Failure of\n-    \/\/ the cmpxchg indicates a concurrent operation updated _head first.  That\n-    \/\/ could be either a push\/append or a try_pop in [Clause 1b].\n-    AtomicAccess::cmpxchg(&_head, old_head, (T*)nullptr);\n-\n-    \/\/ Attempt to change the queue tail from old_head to null.  Failure of\n-    \/\/ the cmpxchg indicates that a concurrent push\/append updated _tail first.\n-    \/\/ That operation will eventually recognize the old tail (our old_head) is\n-    \/\/ no longer in the list and update _head from the list being appended.\n-    AtomicAccess::cmpxchg(&_tail, old_head, (T*)nullptr);\n-\n-    \/\/ The queue has been restored to order, and we can return old_head.\n-    *node_ptr = old_head;\n-    return true;\n-\n-  } else {\n-    \/\/ [Clause 3]\n-    \/\/ Old_head was the last entry in the list, but either a concurrent\n-    \/\/ try_pop claimed it first or a concurrent push\/append extended the\n-    \/\/ list from it.  Either way, we lost the race to claim it.\n-    return false;\n-  }\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* NonblockingQueue<T, next_ptr>::pop() {\n-  T* result = nullptr;\n-  \/\/ Typically try_pop() will succeed without retrying many times, thus we\n-  \/\/ omit SpinPause in the loop body.  SpinPause or yield may be worthwhile\n-  \/\/ in rare, highly contended cases, and client code could implement such\n-  \/\/ with try_pop().\n-  while (!try_pop(&result)) {}\n-  return result;\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-Pair<T*, T*> NonblockingQueue<T, next_ptr>::take_all() {\n-  T* tail = AtomicAccess::load(&_tail);\n-  if (tail != nullptr) set_next(*tail, nullptr); \/\/ Clear end marker.\n-  Pair<T*, T*> result(AtomicAccess::load(&_head), tail);\n-  AtomicAccess::store(&_head, (T*)nullptr);\n-  AtomicAccess::store(&_tail, (T*)nullptr);\n-  return result;\n-}\n-\n-#endif \/\/ SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.inline.hpp","additions":0,"deletions":248,"binary":false,"changes":248,"status":"deleted"},{"patch":"@@ -1,283 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"memory\/allocation.inline.hpp\"\n-#include \"runtime\/atomicAccess.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/nonblockingQueue.inline.hpp\"\n-#include \"utilities\/pair.hpp\"\n-#include \"threadHelper.inline.hpp\"\n-#include \"unittest.hpp\"\n-\n-#include <new>\n-\n-class NonblockingQueueTestElement {\n-  typedef NonblockingQueueTestElement Element;\n-\n-  Element* volatile _entry;\n-  Element* volatile _entry1;\n-  size_t _id;\n-\n-  static Element* volatile* entry_ptr(Element& e) { return &e._entry; }\n-  static Element* volatile* entry1_ptr(Element& e) { return &e._entry1; }\n-\n-public:\n-  using TestQueue = NonblockingQueue<Element, &entry_ptr>;\n-  using TestQueue1 = NonblockingQueue<Element, &entry1_ptr>;\n-\n-  NonblockingQueueTestElement(size_t id = 0) : _entry(), _entry1(), _id(id) {}\n-  size_t id() const { return _id; }\n-  void set_id(size_t value) { _id = value; }\n-  Element* next() { return _entry; }\n-  Element* next1() { return _entry1; }\n-};\n-\n-typedef NonblockingQueueTestElement Element;\n-typedef Element::TestQueue TestQueue;\n-typedef Element::TestQueue1 TestQueue1;\n-\n-static void initialize(Element* elements, size_t size, TestQueue* queue) {\n-  for (size_t i = 0; i < size; ++i) {\n-    elements[i].set_id(i);\n-  }\n-  ASSERT_TRUE(queue->empty());\n-  ASSERT_EQ(0u, queue->length());\n-  ASSERT_TRUE(queue->is_end(queue->first()));\n-  ASSERT_TRUE(queue->pop() == nullptr);\n-\n-  for (size_t id = 0; id < size; ++id) {\n-    ASSERT_EQ(id, queue->length());\n-    Element* e = &elements[id];\n-    ASSERT_EQ(id, e->id());\n-    queue->push(*e);\n-    ASSERT_FALSE(queue->empty());\n-    \/\/ first() is always the oldest element.\n-    ASSERT_EQ(&elements[0], queue->first());\n-  }\n-}\n-\n-class NonblockingQueueTestBasics : public ::testing::Test {\n-public:\n-  NonblockingQueueTestBasics();\n-\n-  static const size_t nelements = 10;\n-  Element elements[nelements];\n-  TestQueue queue;\n-};\n-\n-const size_t NonblockingQueueTestBasics::nelements;\n-\n-NonblockingQueueTestBasics::NonblockingQueueTestBasics() : queue() {\n-  initialize(elements, nelements, &queue);\n-}\n-\n-TEST_F(NonblockingQueueTestBasics, pop) {\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_FALSE(queue.empty());\n-    ASSERT_EQ(nelements - i, queue.length());\n-    Element* e = queue.pop();\n-    ASSERT_TRUE(e != nullptr);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-  }\n-  ASSERT_TRUE(queue.empty());\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_TRUE(queue.pop() == nullptr);\n-}\n-\n-TEST_F(NonblockingQueueTestBasics, append) {\n-  TestQueue other_queue;\n-  ASSERT_TRUE(other_queue.empty());\n-  ASSERT_EQ(0u, other_queue.length());\n-  ASSERT_TRUE(other_queue.is_end(other_queue.first()));\n-  ASSERT_TRUE(other_queue.pop() == nullptr);\n-\n-  Pair<Element*, Element*> pair = queue.take_all();\n-  other_queue.append(*pair.first, *pair.second);\n-  ASSERT_EQ(nelements, other_queue.length());\n-  ASSERT_TRUE(queue.empty());\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_TRUE(queue.is_end(queue.first()));\n-  ASSERT_TRUE(queue.pop() == nullptr);\n-\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_EQ(nelements - i, other_queue.length());\n-    Element* e = other_queue.pop();\n-    ASSERT_TRUE(e != nullptr);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-  }\n-  ASSERT_EQ(0u, other_queue.length());\n-  ASSERT_TRUE(other_queue.pop() == nullptr);\n-}\n-\n-TEST_F(NonblockingQueueTestBasics, two_queues) {\n-  TestQueue1 queue1;\n-  ASSERT_TRUE(queue1.pop() == nullptr);\n-\n-  for (size_t id = 0; id < nelements; ++id) {\n-    queue1.push(elements[id]);\n-  }\n-  ASSERT_EQ(nelements, queue1.length());\n-  Element* e0 = queue.first();\n-  Element* e1 = queue1.first();\n-  ASSERT_TRUE(e0 != nullptr);\n-  ASSERT_TRUE(e1 != nullptr);\n-  ASSERT_FALSE(queue.is_end(e0));\n-  ASSERT_FALSE(queue1.is_end(e1));\n-  while (!queue.is_end(e0) && !queue1.is_end(e1)) {\n-    ASSERT_EQ(e0, e1);\n-    e0 = e0->next();\n-    e1 = e1->next1();\n-  }\n-  ASSERT_TRUE(queue.is_end(e0));\n-  ASSERT_TRUE(queue1.is_end(e1));\n-\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_EQ(nelements - i, queue.length());\n-    ASSERT_EQ(nelements - i, queue1.length());\n-\n-    Element* e = queue.pop();\n-    ASSERT_TRUE(e != nullptr);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-\n-    Element* e1 = queue1.pop();\n-    ASSERT_TRUE(e1 != nullptr);\n-    ASSERT_EQ(&elements[i], e1);\n-    ASSERT_EQ(i, e1->id());\n-\n-    ASSERT_EQ(e, e1);\n-  }\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_EQ(0u, queue1.length());\n-  ASSERT_TRUE(queue.pop() == nullptr);\n-  ASSERT_TRUE(queue1.pop() == nullptr);\n-}\n-\n-class NonblockingQueueTestThread : public JavaTestThread {\n-  uint _id;\n-  TestQueue* _from;\n-  TestQueue* _to;\n-  volatile size_t* _processed;\n-  size_t _process_limit;\n-  size_t _local_processed;\n-  volatile bool _ready;\n-\n-public:\n-  NonblockingQueueTestThread(Semaphore* post,\n-                             uint id,\n-                             TestQueue* from,\n-                             TestQueue* to,\n-                             volatile size_t* processed,\n-                             size_t process_limit) :\n-    JavaTestThread(post),\n-    _id(id),\n-    _from(from),\n-    _to(to),\n-    _processed(processed),\n-    _process_limit(process_limit),\n-    _local_processed(0),\n-    _ready(false)\n-  {}\n-\n-  virtual void main_run() {\n-    AtomicAccess::release_store_fence(&_ready, true);\n-    while (true) {\n-      Element* e = _from->pop();\n-      if (e != nullptr) {\n-        _to->push(*e);\n-        AtomicAccess::inc(_processed);\n-        ++_local_processed;\n-      } else if (AtomicAccess::load_acquire(_processed) == _process_limit) {\n-        tty->print_cr(\"thread %u processed %zu\", _id, _local_processed);\n-        return;\n-      }\n-    }\n-  }\n-\n-  bool ready() const { return AtomicAccess::load_acquire(&_ready); }\n-};\n-\n-TEST_VM(NonblockingQueueTest, stress) {\n-  Semaphore post;\n-  TestQueue initial_queue;\n-  TestQueue start_queue;\n-  TestQueue middle_queue;\n-  TestQueue final_queue;\n-  volatile size_t stage1_processed = 0;\n-  volatile size_t stage2_processed = 0;\n-\n-  const size_t nelements = 10000;\n-  Element* elements = NEW_C_HEAP_ARRAY(Element, nelements, mtOther);\n-  for (size_t id = 0; id < nelements; ++id) {\n-    ::new (&elements[id]) Element(id);\n-    initial_queue.push(elements[id]);\n-  }\n-  ASSERT_EQ(nelements, initial_queue.length());\n-\n-  \/\/ - stage1 threads pop from start_queue and push to middle_queue.\n-  \/\/ - stage2 threads pop from middle_queue and push to final_queue.\n-  \/\/ - all threads in a stage count the number of elements processed in\n-  \/\/   their corresponding stageN_processed counter.\n-\n-  const uint stage1_threads = 2;\n-  const uint stage2_threads = 2;\n-  const uint nthreads = stage1_threads + stage2_threads;\n-  NonblockingQueueTestThread* threads[nthreads] = {};\n-\n-  for (uint i = 0; i < ARRAY_SIZE(threads); ++i) {\n-    TestQueue* from = &start_queue;\n-    TestQueue* to = &middle_queue;\n-    volatile size_t* processed = &stage1_processed;\n-    if (i >= stage1_threads) {\n-      from = &middle_queue;\n-      to = &final_queue;\n-      processed = &stage2_processed;\n-    }\n-    threads[i] =\n-      new NonblockingQueueTestThread(&post, i, from, to, processed, nelements);\n-    threads[i]->doit();\n-    while (!threads[i]->ready()) {} \/\/ Wait until ready to start test.\n-  }\n-\n-  \/\/ Transfer elements to start_queue to start test.\n-  Pair<Element*, Element*> pair = initial_queue.take_all();\n-  start_queue.append(*pair.first, *pair.second);\n-\n-  \/\/ Wait for all threads to complete.\n-  for (uint i = 0; i < nthreads; ++i) {\n-    post.wait();\n-  }\n-\n-  \/\/ Verify expected state.\n-  ASSERT_EQ(nelements, stage1_processed);\n-  ASSERT_EQ(nelements, stage2_processed);\n-  ASSERT_EQ(0u, initial_queue.length());\n-  ASSERT_EQ(0u, start_queue.length());\n-  ASSERT_EQ(0u, middle_queue.length());\n-  ASSERT_EQ(nelements, final_queue.length());\n-  while (final_queue.pop() != nullptr) {}\n-\n-  FREE_C_HEAP_ARRAY(Element, elements);\n-}\n","filename":"test\/hotspot\/gtest\/utilities\/test_nonblockingQueue.cpp","additions":0,"deletions":283,"binary":false,"changes":283,"status":"deleted"}]}