{"files":[{"patch":"@@ -258,0 +258,13 @@\n+inline uint VtableStubs::unsafe_hash(address entry_point) {\n+  \/\/ The entrypoint may or may not be a VtableStub. Generate a hash as if it was.\n+  address vtable_stub_addr = entry_point - VtableStub::entry_offset();\n+  assert(CodeCache::contains(vtable_stub_addr), \"assumed to always be the case\");\n+  address vtable_type_addr = vtable_stub_addr + offset_of(VtableStub, _type);\n+  address vtable_index_addr = vtable_stub_addr + offset_of(VtableStub, _index);\n+  bool is_vtable_stub = *vtable_type_addr == static_cast<uint8_t>(VtableStub::Type::vtable_stub);\n+  int vtable_index;\n+  memcpy(&vtable_index, vtable_index_addr, sizeof(vtable_index));\n+  return hash(is_vtable_stub, vtable_index);\n+}\n+\n+\n@@ -278,0 +291,4 @@\n+  \/\/ The pc may or may not be the entry point for a VtableStub. Use unsafe_hash\n+  \/\/ to generate the hash that would have been used if it was. The lookup in the\n+  \/\/ _table will only succeed if there is a VtableStub with an entry point at\n+  \/\/ the pc.\n@@ -279,2 +296,1 @@\n-  VtableStub* stub = (VtableStub*)(pc - VtableStub::entry_offset());\n-  uint hash = VtableStubs::hash(stub->is_vtable_stub(), stub->index());\n+  uint hash = VtableStubs::unsafe_hash(pc);\n@@ -282,2 +298,2 @@\n-  for (s = Atomic::load(&_table[hash]); s != nullptr && s != stub; s = s->next()) {}\n-  return (s == stub) ? s : nullptr;\n+  for (s = Atomic::load(&_table[hash]); s != nullptr && s->entry_point() != pc; s = s->next()) {}\n+  return (s != nullptr && s->entry_point() == pc) ? s : nullptr;\n","filename":"src\/hotspot\/share\/code\/vtableStubs.cpp","additions":20,"deletions":4,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"sanitizers\/ub.hpp\"\n@@ -97,0 +96,1 @@\n+  static inline uint unsafe_hash       (address entry_point);\n@@ -122,0 +122,6 @@\n+  enum class Type : uint8_t {\n+    itable_stub,\n+    vtable_stub,\n+  };\n+\n+\n@@ -130,1 +136,1 @@\n-  bool           _is_vtable_stub;    \/\/ True if vtable stub, false, is itable stub\n+  Type           _type;              \/\/ Type, either vtable stub or itable stub\n@@ -137,1 +143,1 @@\n-          _is_vtable_stub(is_vtable_stub) {}\n+          _type(is_vtable_stub ? Type::vtable_stub : Type::itable_stub) {}\n@@ -145,1 +151,1 @@\n-  address code_end() const                       { return code_begin() + VtableStubs::code_size_limit(_is_vtable_stub); }\n+  address code_end() const                       { return code_begin() + VtableStubs::code_size_limit(is_vtable_stub()); }\n@@ -150,1 +156,1 @@\n-    return _index == index && _is_vtable_stub == is_vtable_stub;\n+    return _index == index && this->is_vtable_stub() == is_vtable_stub;\n@@ -176,5 +182,2 @@\n-  bool is_itable_stub()                          { return !_is_vtable_stub; }\n-  \/\/ We reinterpret arbitrary memory as VtableStub. This does not cause failures because the lookup\/equality\n-  \/\/ check will reject false objects. Disabling UBSan is a temporary workaround until JDK-8331725 is fixed.\n-  ATTRIBUTE_NO_UBSAN\n-  bool is_vtable_stub()                          { return  _is_vtable_stub; }\n+  bool is_itable_stub() const                    { return _type == Type::itable_stub; }\n+  bool is_vtable_stub() const                    { return _type == Type::vtable_stub; }\n","filename":"src\/hotspot\/share\/code\/vtableStubs.hpp","additions":13,"deletions":10,"binary":false,"changes":23,"status":"modified"}]}