{"files":[{"patch":"@@ -243,0 +243,3 @@\n+  \/\/ Track allocation rate even if we decide to start a cycle for other reasons.\n+  double rate = _allocation_rate.sample(allocated);\n+\n@@ -248,2 +251,0 @@\n-  \/\/ Track allocation rate even if we decide to start a cycle for other reasons.\n-  double rate = _allocation_rate.sample(allocated);\n@@ -363,0 +364,19 @@\n+double ShenandoahAllocationRate::force_sample(size_t allocated, size_t &unaccounted_bytes_allocated) {\n+  const double MinSampleTime = 0.002;    \/\/ Do not sample if time since last update is less than 2 ms\n+  double now = os::elapsedTime();\n+  double time_since_last_update = now -_last_sample_time;\n+  if (time_since_last_update < MinSampleTime) {\n+    unaccounted_bytes_allocated = allocated - _last_sample_value;\n+    _last_sample_value = 0;\n+    return 0.0;\n+  } else {\n+    double rate = instantaneous_rate(now, allocated);\n+    _rate.add(rate);\n+    _rate_avg.add(_rate.avg());\n+    _last_sample_time = now;\n+    _last_sample_value = allocated;\n+    unaccounted_bytes_allocated = 0;\n+    return rate;\n+  }\n+}\n+\n@@ -367,6 +387,3 @@\n-    if (allocated >= _last_sample_value) {\n-      rate = instantaneous_rate(now, allocated);\n-      _rate.add(rate);\n-      _rate_avg.add(_rate.avg());\n-    }\n-\n+    rate = instantaneous_rate(now, allocated);\n+    _rate.add(rate);\n+    _rate_avg.add(_rate.avg());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.cpp","additions":25,"deletions":8,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+  double force_sample(size_t allocated, size_t &unaccounted_bytes_allocated);\n@@ -44,0 +45,1 @@\n+\n@@ -74,1 +76,1 @@\n-                                                     size_t actual_free);\n+                                                     size_t actual_free) override;\n@@ -76,1 +78,1 @@\n-  void record_cycle_start();\n+  virtual void record_cycle_start() override;\n@@ -153,0 +155,7 @@\n+\n+public:\n+  virtual size_t force_alloc_rate_sample(size_t bytes_allocated) override {\n+    size_t unaccounted_bytes;\n+    _allocation_rate.force_sample(bytes_allocated, unaccounted_bytes);\n+    return unaccounted_bytes;\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahAdaptiveHeuristics.hpp","additions":11,"deletions":2,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -244,0 +244,5 @@\n+  virtual size_t force_alloc_rate_sample(size_t bytes_allocated) {\n+    \/\/ do nothing\n+    return 0;\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahHeuristics.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -44,0 +44,4 @@\n+\n+  \/\/ Return an approximation of the bytes allocated since GC start.  The value returned is monotonically non-decreasing\n+  \/\/ in time within each GC cycle.  For certain GC cycles, the value returned may include some bytes allocated before\n+  \/\/ the start of the current GC cycle.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahSpaceInfo.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -154,2 +154,2 @@\n-void ShenandoahGeneration::reset_bytes_allocated_since_gc_start() {\n-  AtomicAccess::store(&_bytes_allocated_since_gc_start, (size_t)0);\n+void ShenandoahGeneration::reset_bytes_allocated_since_gc_start(size_t initial_bytes_allocated) {\n+  AtomicAccess::store(&_bytes_allocated_since_gc_start, initial_bytes_allocated);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -145,1 +145,1 @@\n-  void reset_bytes_allocated_since_gc_start();\n+  void reset_bytes_allocated_since_gc_start(size_t initial_bytes_allocated);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2322,0 +2322,9 @@\n+  \/\/ It is important to force_alloc_rate_sample() before the associated generation's bytes_allocated has been reset.\n+  \/\/ Note that there is no lock to prevent additional alloations between sampling bytes_allocated_since_gc_start() and\n+  \/\/ reset_bytes_allocated_since_gc_start().  If additional allocations happen, they will be ignored in the average\n+  \/\/ allocation rate computations.  This effect is considered to be be negligible.\n+\n+  \/\/ unaccounted_bytes is the bytes not accounted for by our forced sample.  If the sample interval is too short,\n+  \/\/ the \"forced sample\" will not happen, and any recently allocated bytes are \"unaccounted for\".  We pretend these\n+  \/\/ bytes are allocated after the start of subsequent gc.\n+  size_t unaccounted_bytes;\n@@ -2323,2 +2332,9 @@\n-    young_generation()->reset_bytes_allocated_since_gc_start();\n-    old_generation()->reset_bytes_allocated_since_gc_start();\n+    size_t bytes_allocated = young_generation()->bytes_allocated_since_gc_start();\n+    unaccounted_bytes = young_generation()->heuristics()->force_alloc_rate_sample(bytes_allocated);\n+    young_generation()->reset_bytes_allocated_since_gc_start(unaccounted_bytes);\n+    unaccounted_bytes = 0;\n+    old_generation()->reset_bytes_allocated_since_gc_start(unaccounted_bytes);\n+  } else {\n+    size_t bytes_allocated = global_generation()->bytes_allocated_since_gc_start();\n+    \/\/ Single-gen Shenandoah uses global heuristics.\n+    unaccounted_bytes = heuristics()->force_alloc_rate_sample(bytes_allocated);\n@@ -2326,2 +2342,1 @@\n-\n-  global_generation()->reset_bytes_allocated_since_gc_start();\n+  global_generation()->reset_bytes_allocated_since_gc_start(unaccounted_bytes);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":19,"deletions":4,"binary":false,"changes":23,"status":"modified"}]}