{"files":[{"patch":"@@ -75,3 +75,10 @@\n-  \/\/ nothing to do\n-  DEBUG_ONLY( intptr_t* lspp = (intptr_t*) &(f.get_ijava_state()->top_frame_sp); )\n-  assert(*lspp == f.unextended_sp() - f.fp(), \"should be \" INTPTR_FORMAT \" usp:\" INTPTR_FORMAT \" fp:\" INTPTR_FORMAT, *lspp, p2i(f.unextended_sp()), p2i(f.fp()));\n+  \/\/ Nothing to do. We don't save a last sp since we cannot use sp as esp.\n+  \/\/ Instead the top frame is trimmed when making an i2i call. The original\n+  \/\/ top_frame_sp is set when the frame is pushed (see generate_fixed_frame()).\n+  \/\/ An interpreter top frame that was just thawed is resized to top_frame_sp by the\n+  \/\/ resume adapter (see generate_cont_resume_interpreter_adapter()). So the assertion is\n+  \/\/ false, if we freeze again right after thawing as we do when redoing a vm call wasn't\n+  \/\/ successful.\n+  assert(_thread->interp_redoing_vm_call() ||\n+         ((intptr_t*)f.at_relative(ijava_idx(top_frame_sp)) == f.unextended_sp()),\n+         \"top_frame_sp:\" PTR_FORMAT \" usp:\" PTR_FORMAT, f.at_relative(ijava_idx(top_frame_sp)), p2i(f.unextended_sp()));\n@@ -341,0 +348,2 @@\n+  \/\/ Nothing to do on PPC because the interpreter does not use SP as expression stack pointer.\n+  \/\/ Instead there is a dedicated register R15_esp which is not affected by VM calls.\n@@ -577,2 +586,10 @@\n-  Unimplemented();\n-  return nullptr;\n+  frame enterSpecial = new_entry_frame();\n+  frame::common_abi* enterSpecial_abi = (frame::common_abi*)enterSpecial.sp();\n+\n+  enterSpecial_abi->lr = (intptr_t)StubRoutines::cont_preempt_stub();\n+\n+  log_develop_trace(continuations, preempt)(\"push_preempt_adapter enterSpecial sp: \" INTPTR_FORMAT \" adapter pc: \" INTPTR_FORMAT,\n+                                            p2i(enterSpecial_abi),\n+                                            p2i(StubRoutines::cont_preempt_stub()));\n+\n+  return enterSpecial.sp();\n","filename":"src\/hotspot\/cpu\/ppc\/continuationFreezeThaw_ppc.inline.hpp","additions":22,"deletions":5,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -40,0 +40,3 @@\n+    DEBUG_ONLY(Method* m = f.is_interpreted_frame() ? f.interpreter_frame_method() : f.cb()->as_nmethod()->method();)\n+    assert(m->is_object_wait0() || thread->interp_at_preemptable_vmcall_cnt() > 0,\n+           \"preemptable VM call not using call_VM_preemptable\");\n","filename":"src\/hotspot\/cpu\/ppc\/continuationHelper_ppc.inline.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -218,1 +218,1 @@\n-    uint64_t top_frame_sp; \/\/ Maybe define parent_frame_abi and move there.\n+    uint64_t top_frame_sp; \/\/ Original sp to be restored when returning from an i2i call\n","filename":"src\/hotspot\/cpu\/ppc\/frame_ppc.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+  \/\/ Use for vthread preemption\n@@ -53,0 +54,1 @@\n+  void call_VM_preemptable(Register oop_result, address entry_point, Register arg_1, Register arg_2, bool check_exceptions = true);\n@@ -57,1 +59,1 @@\n-    return r->is_nonvolatile() && ((r == R22) || (r == R31));\n+    return r->is_nonvolatile() && ((r == R24) || (r == R31));\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -111,0 +111,2 @@\n+  assert(nonvolatile_accross_vthread_preemtion(R24_dispatch_addr),\n+         \"Requirement of field accesses (e.g. putstatic)\");\n@@ -865,0 +867,3 @@\n+  asm_assert_mem8_is_zero(in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread,\n+                          \"remove_activation: should not have alternate return address set\");\n+\n@@ -2017,1 +2022,2 @@\n-                                        Register arg_1, bool check_exceptions) {\n+                                                    Register arg_1,\n+                                                    bool check_exceptions) {\n@@ -2022,0 +2028,10 @@\n+  call_VM_preemptable(oop_result, entry_point, arg_1, noreg \/* arg_2 *\/, check_exceptions);\n+}\n+\n+void InterpreterMacroAssembler::call_VM_preemptable(Register oop_result, address entry_point,\n+                                                    Register arg_1, Register arg_2,\n+                                                    bool check_exceptions) {\n+  if (!Continuations::enabled()) {\n+    call_VM(oop_result, entry_point, arg_1, arg_2, check_exceptions);\n+    return;\n+  }\n@@ -2024,0 +2040,3 @@\n+  Register tmp = R11_scratch1;\n+  assert_different_registers(arg_1, tmp);\n+  assert_different_registers(arg_2, tmp);\n@@ -2025,3 +2044,10 @@\n-  DEBUG_ONLY(ld(R0, in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread));\n-  DEBUG_ONLY(cmpdi(CR0, R0, 0));\n-  asm_assert_eq(\"Should not have alternate return address set\");\n+#ifdef ASSERT\n+  asm_assert_mem8_is_zero(in_bytes(JavaThread::preempt_alternate_return_offset()), R16_thread,\n+                          \"Should not have alternate return address set\");\n+  \/\/ We check this counter in patch_return_pc_with_preempt_stub() during freeze.\n+  lwa(tmp, in_bytes(JavaThread::interp_at_preemptable_vmcall_cnt_offset()), R16_thread);\n+  addi(tmp, tmp, 1);\n+  cmpwi(CR0, tmp, 0);\n+  stw(tmp, in_bytes(JavaThread::interp_at_preemptable_vmcall_cnt_offset()), R16_thread);\n+  asm_assert(gt, \"call_VM_preemptable: should be > 0\");\n+#endif \/\/ ASSERT\n@@ -2030,1 +2056,1 @@\n-  assert(nonvolatile_accross_vthread_preemtion(R31) && nonvolatile_accross_vthread_preemtion(R22), \"\");\n+  assert(nonvolatile_accross_vthread_preemtion(R31) && nonvolatile_accross_vthread_preemtion(R24), \"\");\n@@ -2033,1 +2059,1 @@\n-  std(R22, _ijava_state_neg(fresult), R3_ARG1);\n+  std(R24, _ijava_state_neg(fresult), R3_ARG1);\n@@ -2038,0 +2064,2 @@\n+  assert(arg_2 != R4_ARG2, \"smashed argument\");\n+  mr_if_needed(R5_ARG3, arg_2, true \/* allow_noreg *\/);\n@@ -2039,1 +2067,1 @@\n-  call_VM(oop_result, entry_point, false \/*check_exceptions*\/, &resume_pc \/* last_java_pc *\/);\n+  call_VM(noreg \/* oop_result *\/, entry_point, false \/*check_exceptions*\/, &resume_pc \/* last_java_pc *\/);\n@@ -2042,0 +2070,8 @@\n+#ifdef ASSERT\n+  lwa(tmp, in_bytes(JavaThread::interp_at_preemptable_vmcall_cnt_offset()), R16_thread);\n+  addi(tmp, tmp, -1);\n+  cmpwi(CR0, tmp, 0);\n+  stw(tmp, in_bytes(JavaThread::interp_at_preemptable_vmcall_cnt_offset()), R16_thread);\n+  asm_assert(ge, \"call_VM_preemptable: should be >= 0\");\n+#endif \/\/ ASSERT\n+\n@@ -2046,0 +2082,1 @@\n+  \/\/ Preempted. Frames are already frozen on heap.\n@@ -2053,0 +2090,1 @@\n+\n@@ -2054,0 +2092,6 @@\n+  if (check_exceptions) {\n+    check_and_forward_exception(R11_scratch1, R12_scratch2);\n+  }\n+  if (oop_result->is_valid()) {\n+    get_vm_result_oop(oop_result);\n+  }\n@@ -2057,2 +2101,0 @@\n-  if (!Continuations::enabled()) return;\n-\n@@ -2063,5 +2105,0 @@\n-  \/\/ Restore registers that are preserved across vthread preemption\n-  assert(nonvolatile_accross_vthread_preemtion(R31) && nonvolatile_accross_vthread_preemtion(R22), \"\");\n-  ld(R3_ARG1, _abi0(callers_sp), R1_SP); \/\/ load FP\n-  ld(R31, _ijava_state_neg(lresult), R3_ARG1);\n-  ld(R22, _ijava_state_neg(fresult), R3_ARG1);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":51,"deletions":14,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -760,1 +760,1 @@\n-  load_const_optimized(bad, 0xbad0101babe11111);\n+  load_const_optimized(bad, 0xbad0101babe00000);\n@@ -762,1 +762,1 @@\n-    mr(regs[i], bad);\n+    addi(regs[i], regs[0], regs[i]->encoding());\n@@ -764,0 +764,1 @@\n+  addi(regs[0], regs[0], regs[0]->encoding());\n@@ -4344,1 +4345,0 @@\n-void MacroAssembler::asm_assert(bool check_equal, const char *msg) {\n@@ -4346,0 +4346,1 @@\n+void MacroAssembler::asm_assert(AsmAssertCond cond, const char *msg) {\n@@ -4347,1 +4348,2 @@\n-  if (check_equal) {\n+  switch (cond) {\n+  case eq:\n@@ -4349,1 +4351,2 @@\n-  } else {\n+    break;\n+  case ne:\n@@ -4351,0 +4354,15 @@\n+    break;\n+  case ge:\n+    bge(CR0, ok);\n+    break;\n+  case gt:\n+    bgt(CR0, ok);\n+    break;\n+  case lt:\n+    blt(CR0, ok);\n+    break;\n+  case le:\n+    ble(CR0, ok);\n+    break;\n+  default:\n+    assert(false, \"unknown cond:%d\", cond);\n@@ -4354,1 +4372,0 @@\n-#endif\n@@ -4357,2 +4374,1 @@\n-#ifdef ASSERT\n-void MacroAssembler::asm_assert_mems_zero(bool check_equal, int size, int mem_offset,\n+void MacroAssembler::asm_assert_mems_zero(AsmAssertCond cond, int size, int mem_offset,\n@@ -4372,1 +4388,1 @@\n-  asm_assert(check_equal, msg);\n+  asm_assert(cond, msg);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":25,"deletions":9,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-  inline void mr_if_needed(Register rd, Register rs);\n+  inline void mr_if_needed(Register rd, Register rs, bool allow_invalid = false);\n@@ -945,3 +945,11 @@\n-  void asm_assert(bool check_equal, const char* msg);\n-  void asm_assert_eq(const char* msg) { asm_assert(true, msg); }\n-  void asm_assert_ne(const char* msg) { asm_assert(false, msg); }\n+  enum AsmAssertCond {\n+    eq,\n+    ne,\n+    ge,\n+    gt,\n+    lt,\n+    le\n+  };\n+  void asm_assert(AsmAssertCond cond, const char* msg) PRODUCT_RETURN;\n+  void asm_assert_eq(const char* msg) { asm_assert(eq, msg); }\n+  void asm_assert_ne(const char* msg) { asm_assert(ne, msg); }\n@@ -950,1 +958,1 @@\n-  void asm_assert_mems_zero(bool check_equal, int size, int mem_offset, Register mem_base,\n+  void asm_assert_mems_zero(AsmAssertCond cond, int size, int mem_offset, Register mem_base,\n@@ -956,1 +964,1 @@\n-    asm_assert_mems_zero(true,  8, mem_offset, mem_base, msg);\n+    asm_assert_mems_zero(eq,  8, mem_offset, mem_base, msg);\n@@ -959,1 +967,1 @@\n-    asm_assert_mems_zero(false, 8, mem_offset, mem_base, msg);\n+    asm_assert_mems_zero(ne, 8, mem_offset, mem_base, msg);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.hpp","additions":15,"deletions":7,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -68,1 +68,2 @@\n-inline void MacroAssembler::mr_if_needed(Register rd, Register rs) {\n+inline void MacroAssembler::mr_if_needed(Register rd, Register rs, bool allow_noreg) {\n+  if (allow_noreg && (rs == noreg)) return;\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -64,1 +64,1 @@\n-    guarantee (false, \"\");\n+    guarantee (false, \"unreachable\");\n@@ -71,1 +71,1 @@\n-  bool include_argument_oops() const { return false; }\n+  bool include_argument_oops() const { return IncludeArgs; }\n@@ -79,1 +79,1 @@\n-    Unimplemented();\n+    assert(false, \"Shouldn't reach here! p:\" PTR_FORMAT \" sp:\" PTR_FORMAT, p2i(p), p2i(p));\n","filename":"src\/hotspot\/cpu\/ppc\/smallRegisterMap_ppc.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -183,1 +183,0 @@\n-  InterpreterOopMap mask;\n@@ -185,6 +184,3 @@\n-  f.interpreted_frame_oop_map(&mask);\n-  return  mask.num_oops()\n-          + 1 \/\/ for the mirror oop\n-          + (f.interpreter_frame_method()->is_native() ? 1 : 0) \/\/ temp oop slot\n-          + pointer_delta_as_int((intptr_t*)f.interpreter_frame_monitor_begin(),\n-                                 (intptr_t*)f.interpreter_frame_monitor_end())\/BasicObjectLock::size();\n+  InterpreterOopCount closure;\n+  f.oops_interpreted_do(&closure, map);\n+  return closure.count();\n","filename":"src\/hotspot\/cpu\/ppc\/stackChunkFrameStream_ppc.inline.hpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -705,0 +705,5 @@\n+  \/\/ Restore registers that are preserved across vthread preemption\n+  assert(__ nonvolatile_accross_vthread_preemtion(R31) && __ nonvolatile_accross_vthread_preemtion(R24), \"\");\n+  __ ld(R3_ARG1, _abi0(callers_sp), R1_SP); \/\/ load FP\n+  __ ld(R31, _ijava_state_neg(lresult), R3_ARG1);\n+  __ ld(R24, _ijava_state_neg(fresult), R3_ARG1);\n@@ -1252,1 +1257,1 @@\n-  const Register access_flags         = R22_tmp2;\n+  const Register access_flags         = R24_tmp4;\n","filename":"src\/hotspot\/cpu\/ppc\/templateInterpreterGenerator_ppc.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2214,1 +2214,1 @@\n-  __ call_VM(noreg, entry, R4_ARG2);\n+  __ call_VM_preemptable(noreg, entry, R4_ARG2);\n@@ -2262,1 +2262,1 @@\n-  __ call_VM(noreg, entry, R4_ARG2);\n+  __ call_VM_preemptable(noreg, entry, R4_ARG2);\n@@ -3864,1 +3864,1 @@\n-  call_VM(R17_tos, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), Rcpool, Rindex);\n+  __ call_VM_preemptable(R17_tos, CAST_FROM_FN_PTR(address, InterpreterRuntime::_new), Rcpool, Rindex);\n","filename":"src\/hotspot\/cpu\/ppc\/templateTable_ppc_64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -477,1 +477,1 @@\n-  static inline void prepare_freeze_interpreted_top_frame(frame& f);\n+  inline void prepare_freeze_interpreted_top_frame(frame& f);\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -499,0 +499,1 @@\n+  DEBUG_ONLY(_interp_redoing_vm_call(false) COMMA)\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -519,0 +519,3 @@\n+  bool _interp_redoing_vm_call;\n+  bool interp_redoing_vm_call() const { return _interp_redoing_vm_call; };\n+\n@@ -523,0 +526,2 @@\n+      assert(!_thread->_interp_redoing_vm_call, \"\");\n+      _thread->_interp_redoing_vm_call = true;\n@@ -528,0 +533,2 @@\n+      assert(_thread->_interp_redoing_vm_call, \"\");\n+      _thread->_interp_redoing_vm_call = false;\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -646,1 +646,1 @@\n-#if defined(AARCH64) || defined(AMD64) || defined(RISCV64)\n+#if defined(AARCH64) || defined(AMD64) || defined(RISCV64) || defined(PPC64)\n","filename":"src\/hotspot\/share\/utilities\/macros.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,1 +28,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n@@ -36,1 +35,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n@@ -44,1 +42,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n@@ -52,1 +49,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n@@ -60,1 +56,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n@@ -68,1 +63,0 @@\n- * @requires os.arch==\"amd64\" | os.arch==\"x86_64\" | os.arch==\"aarch64\" | os.arch==\"riscv64\"\n","filename":"test\/jdk\/java\/lang\/Thread\/virtual\/KlassInit.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"}]}