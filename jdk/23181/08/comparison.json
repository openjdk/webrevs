{"files":[{"patch":"@@ -130,0 +130,11 @@\n+    \/\/ Do not auto-vectorize these FP operations, neither NEON or SVE\/SVE2 support them directly:\n+    \/\/   1. The non_strict_order SVE implementation for 256-bit wide vectors does recursive folding\n+    \/\/      and doesn't conform to the JLS, Section Evaluation Order.\n+    \/\/   2. A strictly ordered SVE implementation for 256-bit wide vectors isn't currently\n+    \/\/      profitable performance-wise.\n+    \/\/   3. The strictly ordered NEON implementation for 64-bit and 128-bit wide vectors isn't\n+    \/\/      profitable performance-wise.\n+    if (opcode == Op_MulReductionVD || opcode == Op_MulReductionVF) {\n+      return false;\n+    }\n+\n@@ -142,1 +153,0 @@\n-          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF ||\n@@ -196,3 +206,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For 256-bit vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8 || length_in_bytes > 32) {\n@@ -3451,2 +3461,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -3457,1 +3467,17 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulI_256b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                          vReg tmp1, vReg tmp2, vReg tmp3) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3);\n+  format %{ \"reduce_mulI_256b $dst, $isrc, $vsrc\\t# vector (256 bits). KILL $tmp1, $tmp2, $tmp3\" %}\n@@ -3459,0 +3485,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -3461,1 +3488,2 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_mul_integral_256b($dst$$Register, bt, $isrc$$Register,\n@@ -3463,1 +3491,1 @@\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+                                $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister);\n@@ -3468,1 +3496,1 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulL_128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -3472,1 +3500,1 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_128b $dst, $isrc, $vsrc\\t# 2L\" %}\n@@ -3474,2 +3502,2 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register, $vsrc$$FloatRegister, 16,\n+                                  fnoreg, fnoreg);\n@@ -3480,1 +3508,17 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulL_256b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1);\n+  format %{ \"reduce_mulL_256b $dst, $isrc, $vsrc\\t# 4L. KILL $tmp1\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_mul_integral_256b($dst$$Register, T_LONG, $isrc$$Register,\n+                                $vsrc$$FloatRegister, length_in_bytes,\n+                                $tmp1$$FloatRegister, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -3484,1 +3528,1 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n@@ -3487,2 +3531,18 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_non_strict_order_mulF_256b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32 && !n->as_Reduction()->requires_strict_order());\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_non_strict_order_mulF_256b $dst, $fsrc, $vsrc\\t# 8F. KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_non_strict_order_mul_fp_256b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                                           $vsrc$$FloatRegister, length_in_bytes, $tmp1$$FloatRegister,\n+                                           $tmp2$$FloatRegister);\n@@ -3493,1 +3553,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -3497,1 +3557,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -3499,2 +3559,18 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_non_strict_order_mulD_256b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32 && !n->as_Reduction()->requires_strict_order());\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_non_strict_order_mulD_256b $dst, $dsrc, $vsrc\\t# 4D. KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_non_strict_order_mul_fp_256b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                                           $vsrc$$FloatRegister, length_in_bytes, $tmp1$$FloatRegister,\n+                                           $tmp2$$FloatRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":97,"deletions":21,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -120,0 +120,11 @@\n+    \/\/ Do not auto-vectorize these FP operations, neither NEON or SVE\/SVE2 support them directly:\n+    \/\/   1. The non_strict_order SVE implementation for 256-bit wide vectors does recursive folding\n+    \/\/      and doesn't conform to the JLS, Section Evaluation Order.\n+    \/\/   2. A strictly ordered SVE implementation for 256-bit wide vectors isn't currently\n+    \/\/      profitable performance-wise.\n+    \/\/   3. The strictly ordered NEON implementation for 64-bit and 128-bit wide vectors isn't\n+    \/\/      profitable performance-wise.\n+    if (opcode == Op_MulReductionVD || opcode == Op_MulReductionVF) {\n+      return false;\n+    }\n+\n@@ -132,1 +143,0 @@\n-          opcode == Op_MulReductionVD || opcode == Op_MulReductionVF ||\n@@ -186,3 +196,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For 256-bit vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8 || length_in_bytes > 32) {\n@@ -2078,2 +2088,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -2084,1 +2094,17 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulI_256b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                          vReg tmp1, vReg tmp2, vReg tmp3) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3);\n+  format %{ \"reduce_mulI_256b $dst, $isrc, $vsrc\\t# vector (256 bits). KILL $tmp1, $tmp2, $tmp3\" %}\n@@ -2086,0 +2112,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -2088,1 +2115,2 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_mul_integral_256b($dst$$Register, bt, $isrc$$Register,\n@@ -2090,1 +2118,1 @@\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+                                $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister);\n@@ -2095,1 +2123,1 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulL_128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -2099,1 +2127,1 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_128b $dst, $isrc, $vsrc\\t# 2L\" %}\n@@ -2101,2 +2129,2 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register, $vsrc$$FloatRegister, 16,\n+                                  fnoreg, fnoreg);\n@@ -2107,1 +2135,17 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulL_256b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1);\n+  format %{ \"reduce_mulL_256b $dst, $isrc, $vsrc\\t# 4L. KILL $tmp1\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_mul_integral_256b($dst$$Register, T_LONG, $isrc$$Register,\n+                                $vsrc$$FloatRegister, length_in_bytes,\n+                                $tmp1$$FloatRegister, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -2111,1 +2155,1 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n@@ -2114,2 +2158,18 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_non_strict_order_mulF_256b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32 && !n->as_Reduction()->requires_strict_order());\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_non_strict_order_mulF_256b $dst, $fsrc, $vsrc\\t# 8F. KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_non_strict_order_mul_fp_256b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                                           $vsrc$$FloatRegister, length_in_bytes, $tmp1$$FloatRegister,\n+                                           $tmp2$$FloatRegister);\n@@ -2120,1 +2180,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -2124,1 +2184,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -2126,2 +2186,18 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_non_strict_order_mulD_256b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 32 && !n->as_Reduction()->requires_strict_order());\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_non_strict_order_mulD_256b $dst, $dsrc, $vsrc\\t# 4D. KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ reduce_non_strict_order_mul_fp_256b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                                           $vsrc$$FloatRegister, length_in_bytes, $tmp1$$FloatRegister,\n+                                           $tmp2$$FloatRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":97,"deletions":21,"binary":false,"changes":118,"status":"modified"},{"patch":"@@ -4067,0 +4067,7 @@\n+  \/\/ SVE move prefix (unpredicated)\n+  void sve_movprfx(FloatRegister Zd, FloatRegister Zn) {\n+    starti;\n+    f(0b00000100, 31, 24), f(0b00, 23, 22), f(0b1, 21), f(0b00000, 20, 16);\n+    f(0b101111, 15, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1996,4 +1996,4 @@\n-void C2_MacroAssembler::neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                                 Register isrc, FloatRegister vsrc,\n-                                                 unsigned vector_length_in_bytes,\n-                                                 FloatRegister vtmp1, FloatRegister vtmp2) {\n+void C2_MacroAssembler::reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc,\n+                                                   FloatRegister vsrc,\n+                                                   unsigned vector_length_in_bytes,\n+                                                   FloatRegister vtmp1, FloatRegister vtmp2) {\n@@ -2001,0 +2001,3 @@\n+  if (bt != T_LONG) {\n+    assert_different_registers(vsrc, vtmp1, vtmp2);\n+  }\n@@ -2003,1 +2006,1 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_integral {\");\n+  BLOCK_COMMENT(\"reduce_mul_integral_le128b {\");\n@@ -2071,1 +2074,42 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_integral\");\n+  BLOCK_COMMENT(\"} reduce_mul_integral_le128b\");\n+}\n+\n+\/\/ Vector reduction multiply for integral type with SVE instructions. Multiplies halves of the\n+\/\/ source vector to get to a 128b vector that fits into a SIMD&FP register. After that point ASIMD\n+\/\/ instructions are used. Note: temporary registers vtmp2 and vtmp3 are not used in some cases.\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::reduce_mul_integral_256b(Register dst, BasicType bt, Register isrc,\n+                                                 FloatRegister vsrc,\n+                                                 unsigned vector_length_in_bytes,\n+                                                 FloatRegister vtmp1, FloatRegister vtmp2,\n+                                                 FloatRegister vtmp3) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+  if (bt == T_LONG) {\n+    assert_different_registers(vsrc, vtmp1);\n+  } else {\n+    assert_different_registers(vsrc, vtmp1, vtmp2, vtmp3);\n+  }\n+\n+  BLOCK_COMMENT(\"reduce_mul_integral_256b {\");\n+  unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+\n+  \/\/ Handle the first iteration separately to preserve the original values in vsrc\n+  sve_movprfx(vtmp1, vsrc);                                \/\/ copy\n+  sve_ext(vtmp1, vtmp1, vector_length_in_bytes \/ 2);       \/\/ swap halves\n+  sve_mul(vtmp1, elemType_to_regVariant(bt), ptrue, vsrc); \/\/ multiply halves\n+  vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+  vector_length = vector_length \/ 2;\n+\n+  switch (bt) {\n+  case T_BYTE:\n+  case T_SHORT:\n+  case T_INT:\n+  case T_LONG:\n+    reduce_mul_integral_le128b(dst, bt, isrc, vtmp1, FloatRegister::neon_vl, vtmp2, vtmp3);\n+    break;\n+  default:\n+    assert(false, \"unsupported\");\n+    ShouldNotReachHere();\n+  }\n+  BLOCK_COMMENT(\"} reduce_mul_integral_256b\");\n@@ -2075,4 +2119,4 @@\n-void C2_MacroAssembler::neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                                           FloatRegister fsrc, FloatRegister vsrc,\n-                                           unsigned vector_length_in_bytes,\n-                                           FloatRegister vtmp) {\n+\/\/ Strictly-ordered, used for both strictly-ordered and unordered operations.\n+void C2_MacroAssembler::reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                             FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                             FloatRegister vtmp) {\n@@ -2082,1 +2126,1 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_fp {\");\n+  BLOCK_COMMENT(\"reduce_mul_fp_le128b {\");\n@@ -2105,1 +2149,23 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_fp\");\n+  BLOCK_COMMENT(\"} reduce_mul_fp_le128b\");\n+}\n+\n+\/\/ Unordered vector reduction multiply for floating-point type with SVE instructions. Multiplies\n+\/\/ halves of the source vector to get to a 128b vector that fits into a SIMD&FP register. After that\n+\/\/ point ASIMD instructions are used.\n+void C2_MacroAssembler::reduce_non_strict_order_mul_fp_256b(FloatRegister dst, BasicType bt,\n+                                                            FloatRegister fsrc, FloatRegister vsrc,\n+                                                            unsigned vector_length_in_bytes,\n+                                                            FloatRegister vtmp1,\n+                                                            FloatRegister vtmp2) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+\n+  \/\/ Handle the first iteration separately to preserve the original values in vsrc\n+  unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+  sve_movprfx(vtmp1, vsrc);                                 \/\/ copy\n+  sve_ext(vtmp1, vtmp1, vector_length_in_bytes \/ 2);        \/\/ swap halves\n+  sve_fmul(vtmp1, elemType_to_regVariant(bt), ptrue, vsrc); \/\/ multiply halves\n+  vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+\n+  reduce_mul_fp_le128b(dst, bt, fsrc, vtmp1, FloatRegister::neon_vl, vtmp2);\n+  BLOCK_COMMENT(\"} reduce_non_strict_order_mul_fp_gt128b\");\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":78,"deletions":12,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -128,4 +128,10 @@\n-  void neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                Register isrc, FloatRegister vsrc,\n-                                unsigned vector_length_in_bytes,\n-                                FloatRegister vtmp1, FloatRegister vtmp2);\n+  void reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                  unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                  FloatRegister vtmp2);\n+\n+  void reduce_mul_integral_256b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                FloatRegister vtmp2, FloatRegister vtmp3);\n+\n+  void reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp);\n@@ -133,3 +139,3 @@\n-  void neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                          FloatRegister fsrc, FloatRegister vsrc,\n-                          unsigned vector_length_in_bytes, FloatRegister vtmp);\n+  void reduce_non_strict_order_mul_fp_256b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                           FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                           FloatRegister vtmp1, FloatRegister vtmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -4717,1 +4717,2 @@\n-    Node* post_loop_reduction = ReductionNode::make(sopc, nullptr, init, last_accumulator, bt);\n+    Node* post_loop_reduction = ReductionNode::make(sopc, nullptr, init, last_accumulator, bt,\n+                                                    \/* requires_strict_order *\/ false);\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2132,0 +2132,1 @@\n+                        [\"movprfx\",  \"__ sve_movprfx(z17, z15);\",                          \"movprfx\\tz17, z15\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1145,0 +1145,1 @@\n+    __ sve_movprfx(z17, z15);                          \/\/       movprfx z17, z15\n@@ -1441,7 +1442,7 @@\n-    0x14000000,     0x17ffffd7,     0x140004b0,     0x94000000,\n-    0x97ffffd4,     0x940004ad,     0x3400000a,     0x34fffa2a,\n-    0x3400954a,     0x35000008,     0x35fff9c8,     0x350094e8,\n-    0xb400000b,     0xb4fff96b,     0xb400948b,     0xb500001d,\n-    0xb5fff91d,     0xb500943d,     0x10000013,     0x10fff8b3,\n-    0x100093d3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36309356,     0x3758000c,     0x375ff7cc,     0x375892ec,\n+    0x14000000,     0x17ffffd7,     0x140004b1,     0x94000000,\n+    0x97ffffd4,     0x940004ae,     0x3400000a,     0x34fffa2a,\n+    0x3400956a,     0x35000008,     0x35fff9c8,     0x35009508,\n+    0xb400000b,     0xb4fff96b,     0xb40094ab,     0xb500001d,\n+    0xb5fff91d,     0xb500945d,     0x10000013,     0x10fff8b3,\n+    0x100093f3,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36309376,     0x3758000c,     0x375ff7cc,     0x3758930c,\n@@ -1452,13 +1453,13 @@\n-    0x540090c0,     0x54000001,     0x54fff541,     0x54009061,\n-    0x54000002,     0x54fff4e2,     0x54009002,     0x54000002,\n-    0x54fff482,     0x54008fa2,     0x54000003,     0x54fff423,\n-    0x54008f43,     0x54000003,     0x54fff3c3,     0x54008ee3,\n-    0x54000004,     0x54fff364,     0x54008e84,     0x54000005,\n-    0x54fff305,     0x54008e25,     0x54000006,     0x54fff2a6,\n-    0x54008dc6,     0x54000007,     0x54fff247,     0x54008d67,\n-    0x54000008,     0x54fff1e8,     0x54008d08,     0x54000009,\n-    0x54fff189,     0x54008ca9,     0x5400000a,     0x54fff12a,\n-    0x54008c4a,     0x5400000b,     0x54fff0cb,     0x54008beb,\n-    0x5400000c,     0x54fff06c,     0x54008b8c,     0x5400000d,\n-    0x54fff00d,     0x54008b2d,     0x5400000e,     0x54ffefae,\n-    0x54008ace,     0x5400000f,     0x54ffef4f,     0x54008a6f,\n+    0x540090e0,     0x54000001,     0x54fff541,     0x54009081,\n+    0x54000002,     0x54fff4e2,     0x54009022,     0x54000002,\n+    0x54fff482,     0x54008fc2,     0x54000003,     0x54fff423,\n+    0x54008f63,     0x54000003,     0x54fff3c3,     0x54008f03,\n+    0x54000004,     0x54fff364,     0x54008ea4,     0x54000005,\n+    0x54fff305,     0x54008e45,     0x54000006,     0x54fff2a6,\n+    0x54008de6,     0x54000007,     0x54fff247,     0x54008d87,\n+    0x54000008,     0x54fff1e8,     0x54008d28,     0x54000009,\n+    0x54fff189,     0x54008cc9,     0x5400000a,     0x54fff12a,\n+    0x54008c6a,     0x5400000b,     0x54fff0cb,     0x54008c0b,\n+    0x5400000c,     0x54fff06c,     0x54008bac,     0x5400000d,\n+    0x54fff00d,     0x54008b4d,     0x5400000e,     0x54ffefae,\n+    0x54008aee,     0x5400000f,     0x54ffef4f,     0x54008a8f,\n@@ -1682,60 +1683,60 @@\n-    0x05271e11,     0x6545e891,     0x6585e891,     0x65c5e891,\n-    0x6545c891,     0x6585c891,     0x65c5c891,     0x45b0c210,\n-    0x45f1c231,     0x1e601000,     0x1e603000,     0x1e621000,\n-    0x1e623000,     0x1e641000,     0x1e643000,     0x1e661000,\n-    0x1e663000,     0x1e681000,     0x1e683000,     0x1e6a1000,\n-    0x1e6a3000,     0x1e6c1000,     0x1e6c3000,     0x1e6e1000,\n-    0x1e6e3000,     0x1e701000,     0x1e703000,     0x1e721000,\n-    0x1e723000,     0x1e741000,     0x1e743000,     0x1e761000,\n-    0x1e763000,     0x1e781000,     0x1e783000,     0x1e7a1000,\n-    0x1e7a3000,     0x1e7c1000,     0x1e7c3000,     0x1e7e1000,\n-    0x1e7e3000,     0xf8268267,     0xf82d023c,     0xf8301046,\n-    0xf83d2083,     0xf8263290,     0xf82d528c,     0xf8284299,\n-    0xf8337160,     0xf8386286,     0xf8bf820e,     0xf8a600e0,\n-    0xf8af1353,     0xf8a922ea,     0xf8b53396,     0xf8a251e3,\n-    0xf8b340f4,     0xf8a470fd,     0xf8a06209,     0xf8f48097,\n-    0xf8f002ea,     0xf8eb10d9,     0xf8ff21b0,     0xf8f7302c,\n-    0xf8ee52a9,     0xf8f041fa,     0xf8e471e4,     0xf8e863c6,\n-    0xf864823d,     0xf87d013a,     0xf86f1162,     0xf87d20e3,\n-    0xf86132bb,     0xf870510e,     0xf8704336,     0xf86572b4,\n-    0xf8706217,     0xb83e8294,     0xb8200264,     0xb8381284,\n-    0xb8242358,     0xb8333102,     0xb828530e,     0xb83042df,\n-    0xb824703f,     0xb82a6194,     0xb8a080e9,     0xb8b80090,\n-    0xb8bb1146,     0xb8bb21b8,     0xb8b032df,     0xb8b653f4,\n-    0xb8bd41c9,     0xb8b47287,     0xb8bc6169,     0xb8ee828c,\n-    0xb8e10138,     0xb8f3126d,     0xb8f020b0,     0xb8e03183,\n-    0xb8e851ef,     0xb8f041e4,     0xb8fe7005,     0xb8ea6376,\n-    0xb8638120,     0xb873015d,     0xb8781284,     0xb86723b8,\n-    0xb86e3175,     0xb87b51ed,     0xb87f41d1,     0xb863721e,\n-    0xb87660f4,     0xce216874,     0xce104533,     0xce648c15,\n-    0xce8e3302,     0xce6e82ab,     0xce6c87d1,     0xcec08063,\n-    0xce638937,     0x25e0c358,     0x25a1c7d3,     0x0580785a,\n-    0x05426328,     0x05009892,     0x25a0cc29,     0x2561cec8,\n-    0x058044b3,     0x05401c99,     0x05006b49,     0x25e0d6f7,\n-    0x2561c528,     0x0583c8bc,     0x0542522f,     0x05001ec0,\n-    0x25e0de65,     0x25a1c113,     0x05803cad,     0x0540f3c0,\n-    0x0500ab15,     0x2560c28c,     0x2561d7c0,     0x05801ed7,\n-    0x0542633b,     0x05003696,     0x2560d4b4,     0x25e1c918,\n-    0x058021ff,     0x05400e15,     0x0500f3de,     0x0473025a,\n-    0x04bd05ab,     0x658e0025,     0x658a08e2,     0x659a0493,\n-    0x043e1062,     0x04f418b4,     0x046d15bd,     0x04611fce,\n-    0x04d6a07c,     0x04001929,     0x041a09da,     0x04d098f4,\n-    0x04db10d4,     0x0459a3ad,     0x041aa029,     0x041919fb,\n-    0x04d39e24,     0x04118302,     0x04101dba,     0x04d7ae16,\n-    0x04dea571,     0x04180210,     0x05e786fc,     0x05e4915c,\n-    0x04881cf1,     0x044a0f04,     0x04090969,     0x048b16c4,\n-    0x044101e4,     0x04dcbf44,     0x65809745,     0x658d833f,\n-    0x65c68468,     0x65c79b07,     0x65829e38,     0x049dafca,\n-    0x6582bba8,     0x65c0b7ff,     0x65c1b4e0,     0x658dbadd,\n-    0x65819a9d,     0x65ed9246,     0x65b30815,     0x65e6263c,\n-    0x65eebb94,     0x65bad14e,     0x65efe178,     0x65fc5697,\n-    0x65e07f14,     0x040c55a6,     0x04977f4d,     0x043d3046,\n-    0x04b733a0,     0x046830a4,     0x04ed322d,     0x05686948,\n-    0x05bd6c13,     0x65c88ef0,     0x450db3d7,     0x4540b6d9,\n-    0x043e3979,     0x445896ce,     0x445a9005,     0x44d98069,\n-    0x445b87ae,     0x04da348e,     0x04982edb,     0x0499397f,\n-    0x0408338c,     0x04ca309c,     0x65c721e6,     0x65c63641,\n-    0x65982882,     0x04812b8b,     0x0e251083,     0x4e3712d5,\n-    0x0e61101f,     0x4e6d118b,     0x0eba1338,     0x4eb712d5,\n-    0x2e31120f,     0x6e2e11ac,     0x2e6810e6,     0x6e6f11cd,\n-    0x2eaa1128,     0x6eb1120f,\n+    0x0420bdf1,     0x05271e11,     0x6545e891,     0x6585e891,\n+    0x65c5e891,     0x6545c891,     0x6585c891,     0x65c5c891,\n+    0x45b0c210,     0x45f1c231,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf8268267,     0xf82d023c,\n+    0xf8301046,     0xf83d2083,     0xf8263290,     0xf82d528c,\n+    0xf8284299,     0xf8337160,     0xf8386286,     0xf8bf820e,\n+    0xf8a600e0,     0xf8af1353,     0xf8a922ea,     0xf8b53396,\n+    0xf8a251e3,     0xf8b340f4,     0xf8a470fd,     0xf8a06209,\n+    0xf8f48097,     0xf8f002ea,     0xf8eb10d9,     0xf8ff21b0,\n+    0xf8f7302c,     0xf8ee52a9,     0xf8f041fa,     0xf8e471e4,\n+    0xf8e863c6,     0xf864823d,     0xf87d013a,     0xf86f1162,\n+    0xf87d20e3,     0xf86132bb,     0xf870510e,     0xf8704336,\n+    0xf86572b4,     0xf8706217,     0xb83e8294,     0xb8200264,\n+    0xb8381284,     0xb8242358,     0xb8333102,     0xb828530e,\n+    0xb83042df,     0xb824703f,     0xb82a6194,     0xb8a080e9,\n+    0xb8b80090,     0xb8bb1146,     0xb8bb21b8,     0xb8b032df,\n+    0xb8b653f4,     0xb8bd41c9,     0xb8b47287,     0xb8bc6169,\n+    0xb8ee828c,     0xb8e10138,     0xb8f3126d,     0xb8f020b0,\n+    0xb8e03183,     0xb8e851ef,     0xb8f041e4,     0xb8fe7005,\n+    0xb8ea6376,     0xb8638120,     0xb873015d,     0xb8781284,\n+    0xb86723b8,     0xb86e3175,     0xb87b51ed,     0xb87f41d1,\n+    0xb863721e,     0xb87660f4,     0xce216874,     0xce104533,\n+    0xce648c15,     0xce8e3302,     0xce6e82ab,     0xce6c87d1,\n+    0xcec08063,     0xce638937,     0x25e0c358,     0x25a1c7d3,\n+    0x0580785a,     0x05426328,     0x05009892,     0x25a0cc29,\n+    0x2561cec8,     0x058044b3,     0x05401c99,     0x05006b49,\n+    0x25e0d6f7,     0x2561c528,     0x0583c8bc,     0x0542522f,\n+    0x05001ec0,     0x25e0de65,     0x25a1c113,     0x05803cad,\n+    0x0540f3c0,     0x0500ab15,     0x2560c28c,     0x2561d7c0,\n+    0x05801ed7,     0x0542633b,     0x05003696,     0x2560d4b4,\n+    0x25e1c918,     0x058021ff,     0x05400e15,     0x0500f3de,\n+    0x0473025a,     0x04bd05ab,     0x658e0025,     0x658a08e2,\n+    0x659a0493,     0x043e1062,     0x04f418b4,     0x046d15bd,\n+    0x04611fce,     0x04d6a07c,     0x04001929,     0x041a09da,\n+    0x04d098f4,     0x04db10d4,     0x0459a3ad,     0x041aa029,\n+    0x041919fb,     0x04d39e24,     0x04118302,     0x04101dba,\n+    0x04d7ae16,     0x04dea571,     0x04180210,     0x05e786fc,\n+    0x05e4915c,     0x04881cf1,     0x044a0f04,     0x04090969,\n+    0x048b16c4,     0x044101e4,     0x04dcbf44,     0x65809745,\n+    0x658d833f,     0x65c68468,     0x65c79b07,     0x65829e38,\n+    0x049dafca,     0x6582bba8,     0x65c0b7ff,     0x65c1b4e0,\n+    0x658dbadd,     0x65819a9d,     0x65ed9246,     0x65b30815,\n+    0x65e6263c,     0x65eebb94,     0x65bad14e,     0x65efe178,\n+    0x65fc5697,     0x65e07f14,     0x040c55a6,     0x04977f4d,\n+    0x043d3046,     0x04b733a0,     0x046830a4,     0x04ed322d,\n+    0x05686948,     0x05bd6c13,     0x65c88ef0,     0x450db3d7,\n+    0x4540b6d9,     0x043e3979,     0x445896ce,     0x445a9005,\n+    0x44d98069,     0x445b87ae,     0x04da348e,     0x04982edb,\n+    0x0499397f,     0x0408338c,     0x04ca309c,     0x65c721e6,\n+    0x65c63641,     0x65982882,     0x04812b8b,     0x0e251083,\n+    0x4e3712d5,     0x0e61101f,     0x4e6d118b,     0x0eba1338,\n+    0x4eb712d5,     0x2e31120f,     0x6e2e11ac,     0x2e6810e6,\n+    0x6e6f11cd,     0x2eaa1128,     0x6eb1120f,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":81,"deletions":80,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Arm Limited. All rights reserved.\n+ * Copyright (c) 2025, Arm Limited. All rights reserved.\n@@ -84,1 +84,1 @@\n-        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+        applyIfCPUFeature = {\"asimd\", \"true\"})\n@@ -87,1 +87,1 @@\n-        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        applyIfCPUFeature = {\"sse2\", \"true\"},\n@@ -99,1 +99,1 @@\n-        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+        applyIfCPUFeature = {\"asimd\", \"true\"})\n@@ -102,1 +102,1 @@\n-        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        applyIfCPUFeatureOr = {\"sse2\", \"true\"},\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestVectorFPReduction.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"}]}