{"files":[{"patch":"@@ -2,2 +2,2 @@\n-\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n-\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Arm Limited. All rights reserved.\n@@ -196,3 +196,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For wider vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8) {\n@@ -3009,2 +3009,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -3015,1 +3015,1 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n@@ -3019,3 +3019,3 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n-                                $vsrc$$FloatRegister, length_in_bytes,\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n@@ -3026,1 +3026,18 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulI_gt128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2, pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp);\n+  format %{ \"reduce_mulI_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $tmp2, $pgtmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                                  $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_le128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -3030,1 +3047,14 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_le128b $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_gt128b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pgtmp);\n+  format %{ \"reduce_mulL_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $pgtmp\" %}\n@@ -3032,2 +3062,5 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, fnoreg,\n+                                  $pgtmp$$PRegister);\n@@ -3038,1 +3071,1 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -3042,1 +3075,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_gt128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp);\n+  format %{ \"reduce_mulF_gt128b $dst, $fsrc, $vsrc\\t# (> 128 bits). KILL $tmp, $pgtmp\" %}\n@@ -3045,2 +3092,3 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp$$PRegister);\n@@ -3051,1 +3099,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_le128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -3055,1 +3103,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_le128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -3057,2 +3105,17 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD_gt128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp);\n+  format %{ \"reduce_mulD_gt128b $dst, $dsrc, $vsrc\\t# (> 16 bits). KILL $tmp, $pgtmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp$$PRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":86,"deletions":23,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n-\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n-\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Arm Limited. All rights reserved.\n@@ -186,3 +186,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For wider vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8) {\n@@ -1873,2 +1873,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -1879,1 +1879,1 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n@@ -1883,3 +1883,3 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n-                                $vsrc$$FloatRegister, length_in_bytes,\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n@@ -1890,1 +1890,18 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulI_gt128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2, pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp);\n+  format %{ \"reduce_mulI_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $tmp2, $pgtmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                                  $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_le128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -1894,1 +1911,14 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_le128b $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_gt128b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pgtmp);\n+  format %{ \"reduce_mulL_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $pgtmp\" %}\n@@ -1896,2 +1926,5 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, fnoreg,\n+                                  $pgtmp$$PRegister);\n@@ -1902,1 +1935,1 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -1906,1 +1939,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_gt128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp);\n+  format %{ \"reduce_mulF_gt128b $dst, $fsrc, $vsrc\\t# (> 128 bits). KILL $tmp, $pgtmp\" %}\n@@ -1909,2 +1956,3 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp$$PRegister);\n@@ -1915,1 +1963,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_le128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -1919,1 +1967,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_le128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -1921,2 +1969,17 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD_gt128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp);\n+  format %{ \"reduce_mulD_gt128b $dst, $dsrc, $vsrc\\t# (> 16 bits). KILL $tmp, $pgtmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp$$PRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":86,"deletions":23,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2024, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Red Hat Inc. All rights reserved.\n@@ -3666,0 +3666,12 @@\n+\/\/ SVE aliases\n+#define INSN(ALIAS, REFERENT)                            \\\n+  void ALIAS(PRegister Pd, PRegister Pg, PRegister Pn) { \\\n+    REFERENT(Pd, Pg, Pn, Pg);                            \\\n+  }\n+\n+  INSN(sve_mov,  sve_and);  \/\/ Move predicates (zeroing); an alias of sve_and\n+  INSN(sve_movs, sve_ands); \/\/ Move predicates (zeroing), setting the condition flags; an alias of sve_ands\n+  INSN(sve_not,  sve_eor);  \/\/ Bitwise invert predicate; an alias of sve_eor\n+  INSN(sve_nots, sve_eors); \/\/ Bitwise invert predicate, setting the condition flags; an alias of sve_eors\n+#undef INSN\n+\n@@ -4004,0 +4016,7 @@\n+  \/\/ SVE move prefix (unpredicated)\n+  void sve_movprfx(FloatRegister Zd, FloatRegister Zn) {\n+    starti;\n+    f(0b00000100, 31, 24), f(0b00, 23, 22), f(0b1, 21), f(0b00000, 20, 16);\n+    f(0b101111, 15, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":21,"deletions":2,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -1994,0 +1994,1 @@\n+\/\/ Note: vsrc and vtmp2 may match.\n@@ -1995,4 +1996,4 @@\n-void C2_MacroAssembler::neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                                 Register isrc, FloatRegister vsrc,\n-                                                 unsigned vector_length_in_bytes,\n-                                                 FloatRegister vtmp1, FloatRegister vtmp2) {\n+void C2_MacroAssembler::reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc,\n+                                                   FloatRegister vsrc,\n+                                                   unsigned vector_length_in_bytes,\n+                                                   FloatRegister vtmp1, FloatRegister vtmp2) {\n@@ -2000,0 +2001,2 @@\n+  assert_different_registers(vtmp1, vsrc);\n+  assert_different_registers(vtmp1, vtmp2);\n@@ -2002,1 +2005,1 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_integral {\");\n+  BLOCK_COMMENT(\"reduce_mul_integral_le128b {\");\n@@ -2033,3 +2036,3 @@\n-          ins(vtmp2, D, vsrc, 0, 1);\n-          mulv(vtmp2, T4H, vtmp2, vsrc);\n-          ins(vtmp1, S, vtmp2, 0, 1);\n+          ins(vtmp1, D, vsrc, 0, 1);\n+          mulv(vtmp1, T4H, vtmp1, vsrc);\n+          ins(vtmp2, S, vtmp1, 0, 1);\n@@ -2070,1 +2073,44 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_integral\");\n+  BLOCK_COMMENT(\"} reduce_mul_integral_le128b\");\n+}\n+\n+\/\/ Vector reduction multiply for integral type with SVE instructions. Multiplies halves of the\n+\/\/ source vector to get to a 128b vector that fits into a SIMD&FP register. After that point ASIMD\n+\/\/ instructions are used. Note: temporary registers vtmp1 and vtmp2 are not used in some cases.\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::reduce_mul_integral_gt128b(Register dst, BasicType bt, Register isrc,\n+                                                   FloatRegister vsrc,\n+                                                   unsigned vector_length_in_bytes,\n+                                                   FloatRegister vtmp1, FloatRegister vtmp2,\n+                                                   PRegister pgtmp) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(vector_length_in_bytes <= FloatRegister::sve_vl_max, \"unsupported vector length\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+\n+  BLOCK_COMMENT(\"reduce_mul_integral_gt128b {\");\n+  unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+\n+  auto do_recursive_folding_iteration =\n+      [&](FloatRegister vdst, FloatRegister vsrc, FloatRegister vtmp) {\n+        assert(vdst == vtmp || vdst == vsrc, \"unsupported combination of registers\");\n+        sve_gen_mask_imm(pgtmp, bt, vector_length \/ 2);\n+        \/\/ Shuffle the upper half elements of the register to the right.\n+        sve_movprfx(vtmp1, vsrc);\n+        sve_ext(vtmp1, vsrc, vector_length_in_bytes \/ 2);\n+        if (vdst == vtmp) {\n+          sve_mul(vdst, elemType_to_regVariant(bt), pgtmp, vsrc);\n+        } else if (vdst == vsrc) {\n+          sve_mul(vdst, elemType_to_regVariant(bt), pgtmp, vtmp);\n+        } else {\n+          ShouldNotReachHere();\n+        }\n+        vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+        vector_length = vector_length \/ 2;\n+      };\n+\n+  do_recursive_folding_iteration(vtmp1, vsrc, vtmp1);\n+  while (vector_length_in_bytes > FloatRegister::neon_vl) {\n+    do_recursive_folding_iteration(vtmp1, vtmp1, vtmp2);\n+  }\n+\n+  reduce_mul_integral_le128b(dst, bt, isrc, vtmp1, FloatRegister::neon_vl, vtmp2, vtmp1);\n+  BLOCK_COMMENT(\"} reduce_mul_integral_gt128b\");\n@@ -2074,4 +2120,3 @@\n-void C2_MacroAssembler::neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                                           FloatRegister fsrc, FloatRegister vsrc,\n-                                           unsigned vector_length_in_bytes,\n-                                           FloatRegister vtmp) {\n+void C2_MacroAssembler::reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                             FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                             FloatRegister vtmp) {\n@@ -2081,1 +2126,1 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_fp {\");\n+  BLOCK_COMMENT(\"reduce_mul_fp_le128b {\");\n@@ -2104,1 +2149,26 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_fp\");\n+  BLOCK_COMMENT(\"} reduce_mul_fp_le128b\");\n+}\n+\n+\/\/ Vector reduction multiply for floating-point type with SVE instructions. Multiplies halves of the\n+\/\/ source vector to get to a 128b vector that fits into a SIMD&FP register. After that point ASIMD\n+\/\/ instructions are used.\n+void C2_MacroAssembler::reduce_mul_fp_gt128b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                             FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                             FloatRegister vtmp, PRegister pgtmp) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(vector_length_in_bytes <= FloatRegister::sve_vl_max, \"unsupported vector length\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+\n+  BLOCK_COMMENT(\"reduce_mul_fp_gt128b {\");\n+  while (vector_length_in_bytes > FloatRegister::neon_vl) {\n+    unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+    \/\/ Shuffle the upper half elements of the register to the right.\n+    sve_gen_mask_imm(pgtmp, bt, vector_length \/ 2);\n+    sve_movprfx(vtmp, vsrc);\n+    sve_ext(vtmp, vsrc, vector_length_in_bytes \/ 2);\n+    sve_fmul(vsrc, elemType_to_regVariant(bt), pgtmp, vtmp);\n+    vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+  }\n+\n+  reduce_mul_fp_le128b(dst, bt, fsrc, vsrc, FloatRegister::neon_vl, vtmp);\n+  BLOCK_COMMENT(\"} reduce_mul_fp_gt128b\");\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":86,"deletions":16,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -128,4 +128,10 @@\n-  void neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                Register isrc, FloatRegister vsrc,\n-                                unsigned vector_length_in_bytes,\n-                                FloatRegister vtmp1, FloatRegister vtmp2);\n+  void reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                  unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                  FloatRegister vtmp2);\n+\n+  void reduce_mul_integral_gt128b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                  unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                  FloatRegister vtmp2, PRegister pgtmp1);\n+\n+  void reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp);\n@@ -133,3 +139,2 @@\n-  void neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                          FloatRegister fsrc, FloatRegister vsrc,\n-                          unsigned vector_length_in_bytes, FloatRegister vtmp);\n+  void reduce_mul_fp_gt128b(FloatRegister dst, BasicType bt, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp, PRegister pgtmp);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2050,0 +2050,4 @@\n+                        [\"mov\",      \"__ sve_mov(p3, p1, p7);\",                            \"and\\tp3.b, p1\/z, p7.b, p1.b\"],\n+                        [\"movs\",     \"__ sve_movs(p4, p12, p5);\",                          \"ands\\tp4.b, p12\/z, p5.b, p12.b\"],\n+                        [\"not\",      \"__ sve_not(p3, p1, p7);\",                            \"eor\\tp3.b, p1\/z, p7.b, p1.b\"],\n+                        [\"nots\",     \"__ sve_nots(p4, p12, p5);\",                          \"eors\\tp4.b, p12\/z, p5.b, p12.b\"],\n@@ -2081,0 +2085,1 @@\n+                        [\"movprfx\",  \"__ sve_movprfx(z17, z15);\",                          \"movprfx\\tz17, z15\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1013,0 +1013,4 @@\n+    __ sve_mov(p3, p1, p7);                            \/\/       and     p3.b, p1\/z, p7.b, p1.b\n+    __ sve_movs(p4, p12, p5);                          \/\/       ands    p4.b, p12\/z, p5.b, p12.b\n+    __ sve_not(p3, p1, p7);                            \/\/       eor     p3.b, p1\/z, p7.b, p1.b\n+    __ sve_nots(p4, p12, p5);                          \/\/       eors    p4.b, p12\/z, p5.b, p12.b\n@@ -1044,0 +1048,1 @@\n+    __ sve_movprfx(z17, z15);                          \/\/       movprfx z17, z15\n@@ -1330,7 +1335,7 @@\n-    0x14000000,     0x17ffffd7,     0x14000441,     0x94000000,\n-    0x97ffffd4,     0x9400043e,     0x3400000a,     0x34fffa2a,\n-    0x3400876a,     0x35000008,     0x35fff9c8,     0x35008708,\n-    0xb400000b,     0xb4fff96b,     0xb40086ab,     0xb500001d,\n-    0xb5fff91d,     0xb500865d,     0x10000013,     0x10fff8b3,\n-    0x100085f3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36308576,     0x3758000c,     0x375ff7cc,     0x3758850c,\n+    0x14000000,     0x17ffffd7,     0x14000446,     0x94000000,\n+    0x97ffffd4,     0x94000443,     0x3400000a,     0x34fffa2a,\n+    0x3400880a,     0x35000008,     0x35fff9c8,     0x350087a8,\n+    0xb400000b,     0xb4fff96b,     0xb400874b,     0xb500001d,\n+    0xb5fff91d,     0xb50086fd,     0x10000013,     0x10fff8b3,\n+    0x10008693,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36308616,     0x3758000c,     0x375ff7cc,     0x375885ac,\n@@ -1341,13 +1346,13 @@\n-    0x540082e0,     0x54000001,     0x54fff541,     0x54008281,\n-    0x54000002,     0x54fff4e2,     0x54008222,     0x54000002,\n-    0x54fff482,     0x540081c2,     0x54000003,     0x54fff423,\n-    0x54008163,     0x54000003,     0x54fff3c3,     0x54008103,\n-    0x54000004,     0x54fff364,     0x540080a4,     0x54000005,\n-    0x54fff305,     0x54008045,     0x54000006,     0x54fff2a6,\n-    0x54007fe6,     0x54000007,     0x54fff247,     0x54007f87,\n-    0x54000008,     0x54fff1e8,     0x54007f28,     0x54000009,\n-    0x54fff189,     0x54007ec9,     0x5400000a,     0x54fff12a,\n-    0x54007e6a,     0x5400000b,     0x54fff0cb,     0x54007e0b,\n-    0x5400000c,     0x54fff06c,     0x54007dac,     0x5400000d,\n-    0x54fff00d,     0x54007d4d,     0x5400000e,     0x54ffefae,\n-    0x54007cee,     0x5400000f,     0x54ffef4f,     0x54007c8f,\n+    0x54008380,     0x54000001,     0x54fff541,     0x54008321,\n+    0x54000002,     0x54fff4e2,     0x540082c2,     0x54000002,\n+    0x54fff482,     0x54008262,     0x54000003,     0x54fff423,\n+    0x54008203,     0x54000003,     0x54fff3c3,     0x540081a3,\n+    0x54000004,     0x54fff364,     0x54008144,     0x54000005,\n+    0x54fff305,     0x540080e5,     0x54000006,     0x54fff2a6,\n+    0x54008086,     0x54000007,     0x54fff247,     0x54008027,\n+    0x54000008,     0x54fff1e8,     0x54007fc8,     0x54000009,\n+    0x54fff189,     0x54007f69,     0x5400000a,     0x54fff12a,\n+    0x54007f0a,     0x5400000b,     0x54fff0cb,     0x54007eab,\n+    0x5400000c,     0x54fff06c,     0x54007e4c,     0x5400000d,\n+    0x54fff00d,     0x54007ded,     0x5400000e,     0x54ffefae,\n+    0x54007d8e,     0x5400000f,     0x54ffef4f,     0x54007d2f,\n@@ -1538,0 +1543,1 @@\n+    0x250144e3,     0x254c70a4,     0x250146e3,     0x254c72a4,\n@@ -1545,58 +1551,59 @@\n-    0x05314001,     0x05a18610,     0x05e18610,     0x05271e11,\n-    0x6545e891,     0x6585e891,     0x65c5e891,     0x6545c891,\n-    0x6585c891,     0x65c5c891,     0x45b0c210,     0x45f1c231,\n-    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,\n-    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,\n-    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,\n-    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,\n-    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,\n-    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,\n-    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,\n-    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,\n-    0xf8338131,     0xf83c01fb,     0xf82712f5,     0xf83f2059,\n-    0xf83f31fb,     0xf82a5277,     0xf8234010,     0xf83972fa,\n-    0xf8226190,     0xf8a483dc,     0xf8bd0370,     0xf8a613a9,\n-    0xf8b02087,     0xf8a7312f,     0xf8b75048,     0xf8bc43f5,\n-    0xf8a5701b,     0xf8b1608f,     0xf8fa8388,     0xf8f6037b,\n-    0xf8f91017,     0xf8e421e6,     0xf8e031e4,     0xf8e150ea,\n-    0xf8e5438a,     0xf8e772f4,     0xf8f56166,     0xf86883f1,\n-    0xf8660051,     0xf86c13be,     0xf86322db,     0xf87d31ae,\n-    0xf87c5311,     0xf86541c2,     0xf86a7170,     0xf87b6197,\n-    0xb8248236,     0xb8240261,     0xb83011b0,     0xb82e204c,\n-    0xb83132a3,     0xb83750c5,     0xb82741b3,     0xb83c7211,\n-    0xb82663a2,     0xb8a380c4,     0xb8b001b4,     0xb8ac1114,\n-    0xb8b92274,     0xb8a0330b,     0xb8a653f4,     0xb8ae40d0,\n-    0xb8a071e7,     0xb8b3613a,     0xb8ea82b7,     0xb8f6005c,\n-    0xb8e3126f,     0xb8f42087,     0xb8fd3007,     0xb8e95290,\n-    0xb8f74204,     0xb8ea7177,     0xb8f963e6,     0xb87082ed,\n-    0xb86c01c1,     0xb8691215,     0xb87a208f,     0xb8643110,\n-    0xb866509e,     0xb87d43b1,     0xb87a71e9,     0xb86263ab,\n-    0xce216ce3,     0xce0e2255,     0xce798ed2,     0xce959685,\n-    0xce7e8217,     0xce608694,     0xcec08264,     0xce748898,\n-    0x25e0da44,     0x2521c8f3,     0x05801548,     0x0540cbdf,\n-    0x05006521,     0x2560c7a0,     0x25a1c498,     0x058026bb,\n-    0x05407dd8,     0x0500f3d6,     0x2560ce3d,     0x2521d4b4,\n-    0x05803cbc,     0x05404d6c,     0x05001b89,     0x25a0c532,\n-    0x2521cc40,     0x05800c08,     0x054074c4,     0x050034a0,\n-    0x2520c9e3,     0x25e1ca93,     0x05803e98,     0x05425238,\n-    0x050024cb,     0x25a0ce7f,     0x25e1d0c3,     0x05802676,\n-    0x05401e63,     0x05002d49,     0x04e20080,     0x04ab04ce,\n-    0x659e022e,     0x65970863,     0x659c0703,     0x04d6b4f3,\n-    0x04400cb5,     0x049a06da,     0x04508071,     0x045b0d14,\n-    0x0459b22e,     0x04daba4d,     0x04590a13,     0x0493979b,\n-    0x04d188a8,     0x0450081c,     0x0417b6b9,     0x041eb743,\n-    0x04981e7a,     0x05e78dc1,     0x0564824e,     0x048816ff,\n-    0x040a0d1e,     0x04810ee0,     0x04dcb340,     0x65c08ed8,\n-    0x65cd8162,     0x65c6970c,     0x65c79e29,     0x65c29494,\n-    0x04ddbecd,     0x65c2ba5f,     0x65c0a9af,     0x6581a434,\n-    0x658da0ee,     0x65c1908c,     0x65be806f,     0x65ff0694,\n-    0x65ee2d2d,     0x65a3af81,     0x65a9cb3a,     0x65e1e9da,\n-    0x65f447ba,     0x65e17da6,     0x0401482b,     0x040279fb,\n-    0x0439323e,     0x04a33302,     0x046331bd,     0x04fc320e,\n-    0x05bb6964,     0x05e16e02,     0x65c897e7,     0x4596b150,\n-    0x4516b4fd,     0x0438396c,     0x041a280b,     0x04183697,\n-    0x04192de3,     0x04083b7e,     0x04ca3955,     0x65873883,\n-    0x658622a6,     0x65d83bd9,     0x0441303f,     0x0e2e11ac,\n-    0x4e2013fe,     0x0e6f11cd,     0x4e6a1128,     0x0ebb1359,\n-    0x4ebf13dd,     0x2e231041,     0x6e21101f,     0x2e791317,\n-    0x6e61101f,     0x2eb612b4,     0x6ea21020,\n+    0x05314001,     0x05a18610,     0x05e18610,     0x0420bdf1,\n+    0x05271e11,     0x6545e891,     0x6585e891,     0x65c5e891,\n+    0x6545c891,     0x6585c891,     0x65c5c891,     0x45b0c210,\n+    0x45f1c231,     0x1e601000,     0x1e603000,     0x1e621000,\n+    0x1e623000,     0x1e641000,     0x1e643000,     0x1e661000,\n+    0x1e663000,     0x1e681000,     0x1e683000,     0x1e6a1000,\n+    0x1e6a3000,     0x1e6c1000,     0x1e6c3000,     0x1e6e1000,\n+    0x1e6e3000,     0x1e701000,     0x1e703000,     0x1e721000,\n+    0x1e723000,     0x1e741000,     0x1e743000,     0x1e761000,\n+    0x1e763000,     0x1e781000,     0x1e783000,     0x1e7a1000,\n+    0x1e7a3000,     0x1e7c1000,     0x1e7c3000,     0x1e7e1000,\n+    0x1e7e3000,     0xf8338131,     0xf83c01fb,     0xf82712f5,\n+    0xf83f2059,     0xf83f31fb,     0xf82a5277,     0xf8234010,\n+    0xf83972fa,     0xf8226190,     0xf8a483dc,     0xf8bd0370,\n+    0xf8a613a9,     0xf8b02087,     0xf8a7312f,     0xf8b75048,\n+    0xf8bc43f5,     0xf8a5701b,     0xf8b1608f,     0xf8fa8388,\n+    0xf8f6037b,     0xf8f91017,     0xf8e421e6,     0xf8e031e4,\n+    0xf8e150ea,     0xf8e5438a,     0xf8e772f4,     0xf8f56166,\n+    0xf86883f1,     0xf8660051,     0xf86c13be,     0xf86322db,\n+    0xf87d31ae,     0xf87c5311,     0xf86541c2,     0xf86a7170,\n+    0xf87b6197,     0xb8248236,     0xb8240261,     0xb83011b0,\n+    0xb82e204c,     0xb83132a3,     0xb83750c5,     0xb82741b3,\n+    0xb83c7211,     0xb82663a2,     0xb8a380c4,     0xb8b001b4,\n+    0xb8ac1114,     0xb8b92274,     0xb8a0330b,     0xb8a653f4,\n+    0xb8ae40d0,     0xb8a071e7,     0xb8b3613a,     0xb8ea82b7,\n+    0xb8f6005c,     0xb8e3126f,     0xb8f42087,     0xb8fd3007,\n+    0xb8e95290,     0xb8f74204,     0xb8ea7177,     0xb8f963e6,\n+    0xb87082ed,     0xb86c01c1,     0xb8691215,     0xb87a208f,\n+    0xb8643110,     0xb866509e,     0xb87d43b1,     0xb87a71e9,\n+    0xb86263ab,     0xce216ce3,     0xce0e2255,     0xce798ed2,\n+    0xce959685,     0xce7e8217,     0xce608694,     0xcec08264,\n+    0xce748898,     0x25e0da44,     0x2521c8f3,     0x05801548,\n+    0x0540cbdf,     0x05006521,     0x2560c7a0,     0x25a1c498,\n+    0x058026bb,     0x05407dd8,     0x0500f3d6,     0x2560ce3d,\n+    0x2521d4b4,     0x05803cbc,     0x05404d6c,     0x05001b89,\n+    0x25a0c532,     0x2521cc40,     0x05800c08,     0x054074c4,\n+    0x050034a0,     0x2520c9e3,     0x25e1ca93,     0x05803e98,\n+    0x05425238,     0x050024cb,     0x25a0ce7f,     0x25e1d0c3,\n+    0x05802676,     0x05401e63,     0x05002d49,     0x04e20080,\n+    0x04ab04ce,     0x659e022e,     0x65970863,     0x659c0703,\n+    0x04d6b4f3,     0x04400cb5,     0x049a06da,     0x04508071,\n+    0x045b0d14,     0x0459b22e,     0x04daba4d,     0x04590a13,\n+    0x0493979b,     0x04d188a8,     0x0450081c,     0x0417b6b9,\n+    0x041eb743,     0x04981e7a,     0x05e78dc1,     0x0564824e,\n+    0x048816ff,     0x040a0d1e,     0x04810ee0,     0x04dcb340,\n+    0x65c08ed8,     0x65cd8162,     0x65c6970c,     0x65c79e29,\n+    0x65c29494,     0x04ddbecd,     0x65c2ba5f,     0x65c0a9af,\n+    0x6581a434,     0x658da0ee,     0x65c1908c,     0x65be806f,\n+    0x65ff0694,     0x65ee2d2d,     0x65a3af81,     0x65a9cb3a,\n+    0x65e1e9da,     0x65f447ba,     0x65e17da6,     0x0401482b,\n+    0x040279fb,     0x0439323e,     0x04a33302,     0x046331bd,\n+    0x04fc320e,     0x05bb6964,     0x05e16e02,     0x65c897e7,\n+    0x4596b150,     0x4516b4fd,     0x0438396c,     0x041a280b,\n+    0x04183697,     0x04192de3,     0x04083b7e,     0x04ca3955,\n+    0x65873883,     0x658622a6,     0x65d83bd9,     0x0441303f,\n+    0x0e2e11ac,     0x4e2013fe,     0x0e6f11cd,     0x4e6a1128,\n+    0x0ebb1359,     0x4ebf13dd,     0x2e231041,     0x6e21101f,\n+    0x2e791317,     0x6e61101f,     0x2eb612b4,     0x6ea21020,\n+\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":85,"deletions":78,"binary":false,"changes":163,"status":"modified"}]}