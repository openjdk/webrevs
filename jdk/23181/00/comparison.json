{"files":[{"patch":"@@ -2,2 +2,2 @@\n-\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n-\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Arm Limited. All rights reserved.\n@@ -196,3 +196,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For wider vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8) {\n@@ -3009,2 +3009,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -3015,1 +3015,1 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n@@ -3019,3 +3019,3 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n-                                $vsrc$$FloatRegister, length_in_bytes,\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n@@ -3026,1 +3026,18 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulI_gt128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2, pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulI_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $tmp2, $pgtmp1, $pgtmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                                  $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_le128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -3030,1 +3047,14 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_le128b $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_gt128b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulL_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $pgtmp1, $pgtmp2\" %}\n@@ -3032,2 +3062,5 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, fnoreg,\n+                                  $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n@@ -3038,1 +3071,1 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -3042,1 +3075,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_gt128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulF_gt128b $dst, $fsrc, $vsrc\\t# (> 128 bits). KILL $tmp, $pgtmp1, $pgtmp2\" %}\n@@ -3045,2 +3092,3 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n@@ -3051,1 +3099,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_le128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -3055,1 +3103,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_le128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -3057,2 +3105,17 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD_gt128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulD_gt128b $dst, $dsrc, $vsrc\\t# (> 16 bits). KILL $tmp, $pgtmp1, $pgtmp2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":86,"deletions":23,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n-\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n-\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2025, Arm Limited. All rights reserved.\n@@ -186,3 +186,3 @@\n-        \/\/ No vector multiply reduction instructions, but we do\n-        \/\/ emit scalar instructions for 64\/128-bit vectors.\n-        if (length_in_bytes != 8 && length_in_bytes != 16) {\n+        \/\/ No vector multiply reduction instructions, but we do emit ASIMD instructions for\n+        \/\/ 64\/128-bit vectors. For wider vectors it's a combination of SVE and ASIMD instructions.\n+        if (length_in_bytes < 8) {\n@@ -1873,2 +1873,2 @@\n-instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n-                     vReg tmp1, vReg tmp2) %{\n+instruct reduce_mulI_le128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2) %{\n@@ -1879,1 +1879,1 @@\n-  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  format %{ \"reduce_mulI_le128b $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n@@ -1883,3 +1883,3 @@\n-    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n-                                $vsrc$$FloatRegister, length_in_bytes,\n-                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    __ reduce_mul_integral_le128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n@@ -1890,1 +1890,18 @@\n-instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+instruct reduce_mulI_gt128b(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                            vReg tmp1, vReg tmp2, pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulI_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $tmp2, $pgtmp1, $pgtmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, bt, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                                  $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_le128b(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n@@ -1894,1 +1911,14 @@\n-  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  format %{ \"reduce_mulL_le128b $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ reduce_mul_integral_le128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL_gt128b(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp1,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulL_gt128b $dst, $isrc, $vsrc\\t# vector (> 128 bits). KILL $tmp1, $pgtmp1, $pgtmp2\" %}\n@@ -1896,2 +1926,5 @@\n-    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n-                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_integral_gt128b($dst$$Register, T_LONG, $isrc$$Register,\n+                                  $vsrc$$FloatRegister, length_in_bytes,\n+                                  $tmp1$$FloatRegister, fnoreg,\n+                                  $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n@@ -1902,1 +1935,1 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulF_le128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -1906,1 +1939,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulF_le128b $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF_gt128b(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulF_gt128b $dst, $fsrc, $vsrc\\t# (> 128 bits). KILL $tmp, $pgtmp1, $pgtmp2\" %}\n@@ -1909,2 +1956,3 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n@@ -1915,1 +1963,1 @@\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+instruct reduce_mulD_le128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n@@ -1919,1 +1967,1 @@\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  format %{ \"reduce_mulD_le128b $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n@@ -1921,2 +1969,17 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+    __ reduce_mul_fp_le128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD_gt128b(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp,\n+                            pRegGov pgtmp1, pRegGov pgtmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) > 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp1, TEMP pgtmp2);\n+  format %{ \"reduce_mulD_gt128b $dst, $dsrc, $vsrc\\t# (> 16 bits). KILL $tmp, $pgtmp1, $pgtmp2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ reduce_mul_fp_gt128b($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister,\n+                            $pgtmp1$$PRegister, $pgtmp2$$PRegister);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":86,"deletions":23,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2024, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Red Hat Inc. All rights reserved.\n@@ -3666,0 +3666,12 @@\n+\/\/ SVE aliases\n+#define INSN(ALIAS, REFERENT)                            \\\n+  void ALIAS(PRegister Pd, PRegister Pg, PRegister Pn) { \\\n+    REFERENT(Pd, Pg, Pn, Pg);                            \\\n+  }\n+\n+  INSN(sve_mov,  sve_and);  \/\/ Move predicates (zeroing); an alias of sve_and\n+  INSN(sve_movs, sve_ands); \/\/ Move predicates (zeroing), setting the condition flags; an alias of sve_ands\n+  INSN(sve_not,  sve_eor);  \/\/ Bitwise invert predicate; an alias of sve_eor\n+  INSN(sve_nots, sve_eors); \/\/ Bitwise invert predicate, setting the condition flags; an alias of sve_eors\n+#undef INSN\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -1995,4 +1995,4 @@\n-void C2_MacroAssembler::neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                                 Register isrc, FloatRegister vsrc,\n-                                                 unsigned vector_length_in_bytes,\n-                                                 FloatRegister vtmp1, FloatRegister vtmp2) {\n+void C2_MacroAssembler::reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc,\n+                                                   FloatRegister vsrc,\n+                                                   unsigned vector_length_in_bytes,\n+                                                   FloatRegister vtmp1, FloatRegister vtmp2) {\n@@ -2002,1 +2002,1 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_integral {\");\n+  BLOCK_COMMENT(\"reduce_mul_integral_le128b {\");\n@@ -2070,1 +2070,31 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_integral\");\n+  BLOCK_COMMENT(\"} reduce_mul_integral_le128b\");\n+}\n+\n+\/\/ Vector reduction multiply for integral type with SVE instructions. Multiplies halves of the\n+\/\/ source vector to get to a 128b vector that fits into a SIMD&FP register. After that point ASIMD\n+\/\/ instructions are used. Note: temporary registers vtmp1 and vtmp2 are not used in some cases.\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::reduce_mul_integral_gt128b(Register dst, BasicType bt, Register isrc,\n+                                                   FloatRegister vsrc,\n+                                                   unsigned vector_length_in_bytes,\n+                                                   FloatRegister vtmp1, FloatRegister vtmp2,\n+                                                   PRegister pgtmp1, PRegister pgtmp2) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(vector_length_in_bytes <= FloatRegister::sve_vl_max, \"unsupported vector length\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+\n+  BLOCK_COMMENT(\"reduce_mul_integral_gt128b {\");\n+  while (vector_length_in_bytes > FloatRegister::neon_vl) {\n+    unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+    sve_gen_mask_imm(pgtmp1, bt, vector_length);\n+    sve_gen_mask_imm(pgtmp2, bt, vector_length \/ 2);\n+    sve_not(pgtmp1, pgtmp1, pgtmp2);\n+    \/\/ Shuffle the upper half elements of the register to the right. The actual data type does not\n+    \/\/ matter: a contiguous set of elements is moved and its size is a multiple of D RegVariant.\n+    sve_compact(vtmp1, D, vsrc, pgtmp1);\n+    sve_mul(vsrc, elemType_to_regVariant(bt), pgtmp2, vtmp1);\n+    vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+  }\n+\n+  reduce_mul_integral_le128b(dst, bt, isrc, vsrc, FloatRegister::neon_vl, vtmp1, vtmp2);\n+  BLOCK_COMMENT(\"} reduce_mul_integral_gt128b\");\n@@ -2074,4 +2104,3 @@\n-void C2_MacroAssembler::neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                                           FloatRegister fsrc, FloatRegister vsrc,\n-                                           unsigned vector_length_in_bytes,\n-                                           FloatRegister vtmp) {\n+void C2_MacroAssembler::reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                             FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                             FloatRegister vtmp) {\n@@ -2081,22 +2110,11 @@\n-  BLOCK_COMMENT(\"neon_reduce_mul_fp {\");\n-    switch(bt) {\n-      case T_FLOAT:\n-        fmuls(dst, fsrc, vsrc);\n-        ins(vtmp, S, vsrc, 0, 1);\n-        fmuls(dst, dst, vtmp);\n-        if (isQ) {\n-          ins(vtmp, S, vsrc, 0, 2);\n-          fmuls(dst, dst, vtmp);\n-          ins(vtmp, S, vsrc, 0, 3);\n-          fmuls(dst, dst, vtmp);\n-         }\n-        break;\n-      case T_DOUBLE:\n-        assert(isQ, \"unsupported\");\n-        fmuld(dst, fsrc, vsrc);\n-        ins(vtmp, D, vsrc, 0, 1);\n-        fmuld(dst, dst, vtmp);\n-        break;\n-      default:\n-        assert(false, \"unsupported\");\n-        ShouldNotReachHere();\n+  BLOCK_COMMENT(\"reduce_mul_fp_le128b {\");\n+  switch (bt) {\n+  case T_FLOAT:\n+    fmuls(dst, fsrc, vsrc);\n+    ins(vtmp, S, vsrc, 0, 1);\n+    fmuls(dst, dst, vtmp);\n+    if (isQ) {\n+      ins(vtmp, S, vsrc, 0, 2);\n+      fmuls(dst, dst, vtmp);\n+      ins(vtmp, S, vsrc, 0, 3);\n+      fmuls(dst, dst, vtmp);\n@@ -2104,1 +2122,40 @@\n-  BLOCK_COMMENT(\"} neon_reduce_mul_fp\");\n+    break;\n+  case T_DOUBLE:\n+    assert(isQ, \"unsupported\");\n+    fmuld(dst, fsrc, vsrc);\n+    ins(vtmp, D, vsrc, 0, 1);\n+    fmuld(dst, dst, vtmp);\n+    break;\n+  default:\n+    assert(false, \"unsupported\");\n+    ShouldNotReachHere();\n+  }\n+  BLOCK_COMMENT(\"} reduce_mul_fp_le128b\");\n+}\n+\n+\/\/ Vector reduction multiply for floating-point type with SVE instructions. Multiplies halves of the\n+\/\/ source vector to get to a 128b vector that fits into a SIMD&FP register. After that point ASIMD\n+\/\/ instructions are used.\n+void C2_MacroAssembler::reduce_mul_fp_gt128b(FloatRegister dst, BasicType bt, FloatRegister fsrc,\n+                                             FloatRegister vsrc, unsigned vector_length_in_bytes,\n+                                             FloatRegister vtmp, PRegister pgtmp1,\n+                                             PRegister pgtmp2) {\n+  assert(vector_length_in_bytes > FloatRegister::neon_vl, \"ASIMD impl should be used instead\");\n+  assert(vector_length_in_bytes <= FloatRegister::sve_vl_max, \"unsupported vector length\");\n+  assert(is_power_of_2(vector_length_in_bytes), \"unsupported vector length\");\n+\n+  BLOCK_COMMENT(\"reduce_mul_fp_gt128b {\");\n+  while (vector_length_in_bytes > FloatRegister::neon_vl) {\n+    unsigned vector_length = vector_length_in_bytes \/ type2aelembytes(bt);\n+    sve_gen_mask_imm(pgtmp1, bt, vector_length);\n+    sve_gen_mask_imm(pgtmp2, bt, vector_length \/ 2);\n+    sve_not(pgtmp1, pgtmp1, pgtmp2);\n+    \/\/ Shuffle the upper half elements of the register to the right. The actual data type does not\n+    \/\/ matter: a contiguous set of elements is moved and its size is a multiple of D RegVariant.\n+    sve_compact(vtmp, D, vsrc, pgtmp1);\n+    sve_fmul(vsrc, elemType_to_regVariant(bt), pgtmp2, vtmp);\n+    vector_length_in_bytes = vector_length_in_bytes \/ 2;\n+  }\n+\n+  reduce_mul_fp_le128b(dst, bt, fsrc, vsrc, FloatRegister::neon_vl, vtmp);\n+  BLOCK_COMMENT(\"} reduce_mul_fp_gt128b\");\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":91,"deletions":34,"binary":false,"changes":125,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -128,4 +128,10 @@\n-  void neon_reduce_mul_integral(Register dst, BasicType bt,\n-                                Register isrc, FloatRegister vsrc,\n-                                unsigned vector_length_in_bytes,\n-                                FloatRegister vtmp1, FloatRegister vtmp2);\n+  void reduce_mul_integral_le128b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                  unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                  FloatRegister vtmp2);\n+\n+  void reduce_mul_integral_gt128b(Register dst, BasicType bt, Register isrc, FloatRegister vsrc,\n+                                  unsigned vector_length_in_bytes, FloatRegister vtmp1,\n+                                  FloatRegister vtmp2, PRegister pgtmp1, PRegister pgtmp2);\n+\n+  void reduce_mul_fp_le128b(FloatRegister dst, BasicType bt, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp);\n@@ -133,3 +139,3 @@\n-  void neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n-                          FloatRegister fsrc, FloatRegister vsrc,\n-                          unsigned vector_length_in_bytes, FloatRegister vtmp);\n+  void reduce_mul_fp_gt128b(FloatRegister dst, BasicType bt, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp, PRegister pgtmp1,\n+                            PRegister pgtmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":14,"deletions":8,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2050,0 +2050,4 @@\n+                        [\"mov\",      \"__ sve_mov(p3, p1, p7);\",                            \"and\\tp3.b, p1\/z, p7.b, p1.b\"],\n+                        [\"movs\",     \"__ sve_movs(p4, p12, p5);\",                          \"ands\\tp4.b, p12\/z, p5.b, p12.b\"],\n+                        [\"not\",      \"__ sve_not(p3, p1, p7);\",                            \"eor\\tp3.b, p1\/z, p7.b, p1.b\"],\n+                        [\"nots\",     \"__ sve_nots(p4, p12, p5);\",                          \"eors\\tp4.b, p12\/z, p5.b, p12.b\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1013,0 +1013,4 @@\n+    __ sve_mov(p3, p1, p7);                            \/\/       and     p3.b, p1\/z, p7.b, p1.b\n+    __ sve_movs(p4, p12, p5);                          \/\/       ands    p4.b, p12\/z, p5.b, p12.b\n+    __ sve_not(p3, p1, p7);                            \/\/       eor     p3.b, p1\/z, p7.b, p1.b\n+    __ sve_nots(p4, p12, p5);                          \/\/       eors    p4.b, p12\/z, p5.b, p12.b\n@@ -1330,7 +1334,7 @@\n-    0x14000000,     0x17ffffd7,     0x14000441,     0x94000000,\n-    0x97ffffd4,     0x9400043e,     0x3400000a,     0x34fffa2a,\n-    0x3400876a,     0x35000008,     0x35fff9c8,     0x35008708,\n-    0xb400000b,     0xb4fff96b,     0xb40086ab,     0xb500001d,\n-    0xb5fff91d,     0xb500865d,     0x10000013,     0x10fff8b3,\n-    0x100085f3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36308576,     0x3758000c,     0x375ff7cc,     0x3758850c,\n+    0x14000000,     0x17ffffd7,     0x14000445,     0x94000000,\n+    0x97ffffd4,     0x94000442,     0x3400000a,     0x34fffa2a,\n+    0x340087ea,     0x35000008,     0x35fff9c8,     0x35008788,\n+    0xb400000b,     0xb4fff96b,     0xb400872b,     0xb500001d,\n+    0xb5fff91d,     0xb50086dd,     0x10000013,     0x10fff8b3,\n+    0x10008673,     0x90000013,     0x36300016,     0x3637f836,\n+    0x363085f6,     0x3758000c,     0x375ff7cc,     0x3758858c,\n@@ -1341,13 +1345,13 @@\n-    0x540082e0,     0x54000001,     0x54fff541,     0x54008281,\n-    0x54000002,     0x54fff4e2,     0x54008222,     0x54000002,\n-    0x54fff482,     0x540081c2,     0x54000003,     0x54fff423,\n-    0x54008163,     0x54000003,     0x54fff3c3,     0x54008103,\n-    0x54000004,     0x54fff364,     0x540080a4,     0x54000005,\n-    0x54fff305,     0x54008045,     0x54000006,     0x54fff2a6,\n-    0x54007fe6,     0x54000007,     0x54fff247,     0x54007f87,\n-    0x54000008,     0x54fff1e8,     0x54007f28,     0x54000009,\n-    0x54fff189,     0x54007ec9,     0x5400000a,     0x54fff12a,\n-    0x54007e6a,     0x5400000b,     0x54fff0cb,     0x54007e0b,\n-    0x5400000c,     0x54fff06c,     0x54007dac,     0x5400000d,\n-    0x54fff00d,     0x54007d4d,     0x5400000e,     0x54ffefae,\n-    0x54007cee,     0x5400000f,     0x54ffef4f,     0x54007c8f,\n+    0x54008360,     0x54000001,     0x54fff541,     0x54008301,\n+    0x54000002,     0x54fff4e2,     0x540082a2,     0x54000002,\n+    0x54fff482,     0x54008242,     0x54000003,     0x54fff423,\n+    0x540081e3,     0x54000003,     0x54fff3c3,     0x54008183,\n+    0x54000004,     0x54fff364,     0x54008124,     0x54000005,\n+    0x54fff305,     0x540080c5,     0x54000006,     0x54fff2a6,\n+    0x54008066,     0x54000007,     0x54fff247,     0x54008007,\n+    0x54000008,     0x54fff1e8,     0x54007fa8,     0x54000009,\n+    0x54fff189,     0x54007f49,     0x5400000a,     0x54fff12a,\n+    0x54007eea,     0x5400000b,     0x54fff0cb,     0x54007e8b,\n+    0x5400000c,     0x54fff06c,     0x54007e2c,     0x5400000d,\n+    0x54fff00d,     0x54007dcd,     0x5400000e,     0x54ffefae,\n+    0x54007d6e,     0x5400000f,     0x54ffef4f,     0x54007d0f,\n@@ -1538,0 +1542,1 @@\n+    0x250144e3,     0x254c70a4,     0x250146e3,     0x254c72a4,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":25,"deletions":20,"binary":false,"changes":45,"status":"modified"}]}