{"files":[{"patch":"@@ -831,1 +831,0 @@\n-  vmassert(last_Java_pc() == nullptr, \"already walkable\");\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"runtime\/continuationEntry.hpp\"\n@@ -459,0 +460,32 @@\n+void InterpreterMacroAssembler::call_VM_with_sender_Java_fp_entry(address entry_point) {\n+  mov(c_rarg0, rthread);\n+  MacroAssembler::call_VM_leaf_base(entry_point, 0);\n+}\n+\n+void InterpreterMacroAssembler::set_last_Java_frame_with_sender_fp(Register last_java_sp,\n+                                                                   Register last_java_fp,\n+                                                                   address last_java_pc,\n+                                                                   Register scratch) {\n+  assert_different_registers(last_java_fp, rfp);\n+\n+#if INCLUDE_JFR\n+  Label L_ljf, L_valid_rfp;\n+  cbnz(rfp, L_valid_rfp);\n+  mov(scratch, 1);\n+  str(scratch, Address(rthread, JavaThread::last_sender_Java_fp_offset()));\n+  b(L_ljf);\n+  bind(L_valid_rfp);\n+  str(rfp, Address(rthread, JavaThread::last_sender_Java_fp_offset()));\n+  bind(L_ljf);\n+#endif\n+\n+  set_last_Java_frame(last_java_sp, last_java_fp, last_java_pc, scratch);\n+}\n+\n+void InterpreterMacroAssembler::reset_last_Java_frame_with_sender_fp(Register fp_reg) {\n+  \/\/ Restore the fp_reg.\n+  ldr(fp_reg, Address(rthread, JavaThread::last_Java_fp_offset()));\n+  reset_last_Java_frame(true);\n+  JFR_ONLY(str(zr, Address(rthread, JavaThread::last_sender_Java_fp_offset()));)\n+}\n+\n@@ -461,1 +494,0 @@\n-\/\/ Apply stack watermark barrier.\n@@ -464,0 +496,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -473,5 +506,4 @@\n-void InterpreterMacroAssembler::remove_activation(\n-        TosState state,\n-        bool throw_monitor_exception,\n-        bool install_monitor_exception,\n-        bool notify_jvmdi) {\n+void InterpreterMacroAssembler::remove_activation(TosState state,\n+                                                  bool throw_monitor_exception,\n+                                                  bool install_monitor_exception,\n+                                                  bool notify_jvmdi) {\n@@ -482,15 +514,0 @@\n-  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n-  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n-  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n-  Label slow_path;\n-  Label fast_path;\n-  safepoint_poll(slow_path, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n-  br(Assembler::AL, fast_path);\n-  bind(slow_path);\n-  push(state);\n-  set_last_Java_frame(esp, rfp, (address)pc(), rscratch1);\n-  super_call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind), rthread);\n-  reset_last_Java_frame(true);\n-  pop(state);\n-  bind(fast_path);\n-\n@@ -650,4 +667,36 @@\n-  \/\/ restore sender esp\n-  mov(esp, rscratch2);\n-  \/\/ remove frame anchor\n-  leave();\n+  \/\/ For asynchronous profiling to work correctly, we must remove the\n+  \/\/ activation frame _before_ we test the method return safepoint poll.\n+  \/\/ This is equivalent to how it is done for compiled frames.\n+  \/\/ Removing an interpreter activation frame from a sampling perspective means\n+  \/\/ updating the frame link. But since we are unwinding the current frame,\n+  \/\/ we must save the current rfp in a temporary register, this_fp, for use\n+  \/\/ as the last java fp should we decide to unwind.\n+  \/\/ The asynchronous profiler will only see the updated rfp, either using the\n+  \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+  const Register this_fp = rscratch2;\n+  make_sender_fp_current(this_fp, rscratch1);\n+\n+  \/\/ The interpreter frame is now unwound from a sampling perspective,\n+  \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, this_fp, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+  br(Assembler::AL, fast_path);\n+  bind(slow_path);\n+  save_bcp(this_fp); \/\/ need to save bcp but not restore it.\n+  push(state);\n+  set_last_Java_frame_with_sender_fp(esp, this_fp, (address)pc(), rscratch1);\n+  call_VM_with_sender_Java_fp_entry(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind));\n+  reset_last_Java_frame_with_sender_fp(this_fp);\n+  pop(state);\n+  bind(fast_path);\n+\n+  ldr(esp, Address(this_fp, frame::interpreter_frame_sender_sp_offset * wordSize));\n+  ldr(lr, Address(this_fp, wordSize));\n+  authenticate_return_address();\n+  lea(sp, Address(this_fp, 2 * wordSize));\n+\n@@ -661,0 +710,21 @@\n+void InterpreterMacroAssembler::make_sender_fp_current(Register save_this_fp, Register tmp) {\n+  const Register return_addr = save_this_fp;\n+  const Register continuation_return_pc = tmp;\n+  const Register sender_sp = tmp;\n+  ldr(return_addr, Address(rfp, wordSize)); \/\/ return address\n+  \/\/ Load address of ContinuationEntry return pc\n+  lea(continuation_return_pc, ExternalAddress(ContinuationEntry::return_pc_address()));\n+  \/\/ Load the ContinuationEntry return pc\n+  ldr(continuation_return_pc, Address(continuation_return_pc));\n+  Label L_continuation, L_end;\n+  cmp(continuation_return_pc, return_addr);\n+  mov(save_this_fp, rfp); \/\/ Save current fp in temporary register.\n+  br(Assembler::EQ, L_continuation);\n+  ldr(rfp, Address(rfp)); \/\/ Update the frame link.\n+  b(L_end);\n+  bind(L_continuation);\n+  lea(sender_sp, Address(rfp, frame::sender_sp_offset * wordSize));\n+  ldr(rfp, Address(sender_sp, (int)(ContinuationEntry::size()))); \/\/ Update the frame link.\n+  bind(L_end);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":95,"deletions":25,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -66,0 +66,9 @@\n+  void call_VM_with_sender_Java_fp_entry(address entry_point);\n+\n+  void set_last_Java_frame_with_sender_fp(Register last_java_sp,\n+                                          Register last_java_fp,\n+                                          address last_java_pc,\n+                                          Register scratch);\n+\n+  void reset_last_Java_frame_with_sender_fp(Register fp_reg);\n+\n@@ -73,1 +82,5 @@\n-    str(rbcp, Address(rfp, frame::interpreter_frame_bcp_offset * wordSize));\n+    save_bcp(rfp);\n+  }\n+\n+  void save_bcp(Register fp_register) {\n+    str(rbcp, Address(fp_register, frame::interpreter_frame_bcp_offset * wordSize));\n@@ -228,0 +241,2 @@\n+  void make_sender_fp_current(Register save_this_fp, Register tmp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.hpp","additions":17,"deletions":2,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n-private:\n+ private:\n@@ -33,0 +33,1 @@\n+  JFR_ONLY(intptr_t* volatile _last_sender_Java_fp;) \/\/ specialized field for when JFR samples an interpreter frame\n@@ -34,1 +35,1 @@\n-public:\n+ public:\n@@ -47,0 +48,1 @@\n+    JFR_ONLY(_last_sender_Java_fp = nullptr;)\n@@ -62,0 +64,1 @@\n+    JFR_ONLY(_last_sender_Java_fp = src->_last_sender_Java_fp;)\n@@ -75,5 +78,1 @@\n-private:\n-\n-  static ByteSize last_Java_fp_offset()          { return byte_offset_of(JavaFrameAnchor, _last_Java_fp); }\n-\n-public:\n+ public:\n@@ -83,1 +82,1 @@\n-  intptr_t*   last_Java_fp(void)                 { return _last_Java_fp; }\n+  intptr_t*   last_Java_fp() const               { return _last_Java_fp; }\n@@ -87,0 +86,6 @@\n+  JFR_ONLY(intptr_t* last_sender_Java_fp() const { return _last_sender_Java_fp; })\n+\n+  static ByteSize last_Java_fp_offset() { return byte_offset_of(JavaFrameAnchor, _last_Java_fp); }\n+\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() { return byte_offset_of(JavaFrameAnchor, _last_sender_Java_fp); })\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/javaFrameAnchor_aarch64.hpp","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -557,0 +557,5 @@\n+  safepoint_poll(slow_path, rfp, at_return, acquire, in_nmethod, tmp);\n+}\n+\n+void MacroAssembler::safepoint_poll(Label& slow_path, Register fp_reg, bool at_return, bool acquire, bool in_nmethod, Register tmp) {\n+  assert(fp_reg != tmp, \"invariant\");\n@@ -566,1 +571,1 @@\n-    cmp(in_nmethod ? sp : rfp, tmp);\n+    cmp(in_nmethod ? sp : fp_reg, tmp);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -123,0 +123,2 @@\n+  void safepoint_poll(Label& slow_path, Register fp_reg, bool at_return, bool acquire, bool in_nmethod, Register tmp = rscratch1);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1612,5 +1612,0 @@\n-  __ ldr(esp, Address(rfp,\n-                    frame::interpreter_frame_sender_sp_offset *\n-                    wordSize)); \/\/ get sender sp\n-  \/\/ remove frame anchor\n-  __ leave();\n@@ -1618,0 +1613,35 @@\n+  \/\/ For asynchronous profiling to work correctly, we must remove the\n+  \/\/ activation frame _before_ we test the method return safepoint poll.\n+  \/\/ This is equivalent to how it is done for compiled frames.\n+  \/\/ Removing an interpreter activation frame from a sampling perspective means\n+  \/\/ updating the frame link (fp). But since we are unwinding the current frame,\n+  \/\/ we must save the current rfp in a temporary register, this_fp, for use\n+  \/\/ as the last java fp should we decide to unwind.\n+  \/\/ The asynchronous profiler will only see the updated rfp, either using the\n+  \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+  const Register this_fp = rscratch2;\n+  __ make_sender_fp_current(this_fp, rscratch1);\n+\n+  \/\/ The interpreter frame is now unwound from a sampling perspective,\n+  \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  __ safepoint_poll(slow_path, this_fp, true \/* at_return *\/, false \/* acquire *\/, false \/* in_nmethod *\/);\n+  __ br(Assembler::AL, fast_path);\n+  __ bind(slow_path);\n+  __ push(dtos);\n+  __ push(ltos);\n+  __ set_last_Java_frame_with_sender_fp(esp, this_fp, (address)__ pc(), rscratch1);\n+  __ call_VM_with_sender_Java_fp_entry(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind));\n+  __ reset_last_Java_frame_with_sender_fp(this_fp);\n+  __ pop(ltos);\n+  __ pop(dtos);\n+  __ bind(fast_path);\n+\n+  __ ldr(esp, Address(this_fp, frame::interpreter_frame_sender_sp_offset* wordSize));\n+  __ ldr(lr, Address(this_fp, wordSize));\n+  __ authenticate_return_address();\n@@ -1890,0 +1920,1 @@\n+    __ restore_bcp();\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":36,"deletions":5,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -1893,2 +1893,18 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n-\n+    \/\/ For asynchronous profiling to work correctly, we must remove the\n+    \/\/ activation frame _before_ we test the method return safepoint poll.\n+    \/\/ This is equivalent to how it is done for compiled frames.\n+    \/\/ Removing an interpreter activation frame from a sampling perspective means\n+    \/\/ updating the frame link (fp). But since we are unwinding the current frame,\n+    \/\/ we must save the current rfp in a temporary register, this_fp, for use\n+    \/\/ as the last java fp should we decide to unwind.\n+    \/\/ The asynchronous profiler will only see the updated rfp, either using the\n+    \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+    const Register this_fp = rscratch2;\n+    __ make_sender_fp_current(this_fp, rscratch1);\n+\n+    \/\/ The interpreter frame is now unwound from a sampling perspective,\n+    \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+\n+    __ save_bcp(this_fp); \/\/ need to save bcp but not restore it.\n+    __ set_last_Java_frame_with_sender_fp(esp, this_fp, (address)__ pc(), rscratch1);\n+    __ call_VM_with_sender_Java_fp_entry(CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n@@ -1897,0 +1913,1 @@\n+    __ reset_last_Java_frame_with_sender_fp(this_fp);\n@@ -1900,4 +1917,4 @@\n-    __ ldr(esp,\n-        Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));\n-    \/\/ remove frame anchor\n-    __ leave();\n+    __ ldr(esp, Address(this_fp, frame::interpreter_frame_sender_sp_offset* wordSize));\n+    __ ldr(lr, Address(this_fp, wordSize));\n+    __ authenticate_return_address();\n+    __ lea(sp, Address(this_fp, 2 * wordSize));\n@@ -1913,1 +1930,0 @@\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":23,"deletions":7,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -704,1 +704,0 @@\n-  vmassert(last_Java_pc() == nullptr, \"already walkable\");\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include \"runtime\/continuationEntry.hpp\"\n@@ -779,0 +780,45 @@\n+void InterpreterMacroAssembler::call_VM_with_sender_Java_fp(Register fp_reg, Register tmp, address entry_point, bool store_bcp) {\n+  if (store_bcp) {\n+    save_bcp(fp_reg); \/\/ We must save the bcp, but need not restore it. This is because we have already popped the fp.\n+  }\n+  \/\/ Adjust sp as we now have a return address on stack.\n+  \/\/ We've pushed one address, correct last_Java_sp\n+  Register last_java_sp = tmp;\n+  lea(last_java_sp, Address(rsp, wordSize));\n+\n+  \/\/ Thread argument\n+  movptr(c_rarg0, r15_thread);\n+\n+#if INCLUDE_JFR\n+  Label L_ljf, L_valid_rbp;\n+  testptr(rbp, rbp);\n+  jccb(Assembler::notZero, L_valid_rbp);\n+  Address last_sender_Java_fp_offset(r15_thread, JavaThread::frame_anchor_offset() + JavaFrameAnchor::last_sender_Java_fp_offset());\n+  movptr(last_sender_Java_fp_offset, 1);\n+  jmpb(L_ljf);\n+  bind(L_valid_rbp);\n+  movptr(last_sender_Java_fp_offset, rbp);\n+  bind(L_ljf);\n+#endif\n+\n+  movptr(Address(r15_thread, JavaThread::last_Java_fp_offset()), fp_reg);\n+  movptr(fp_reg, Address(rsp, 0)); \/\/ last_java_pc\n+  movptr(Address(r15_thread, JavaThread::last_Java_pc_offset()), fp_reg);\n+  movptr(Address(r15_thread, JavaThread::last_Java_sp_offset()), last_java_sp);\n+  MacroAssembler::call_VM_leaf_base(entry_point, 0);\n+  Address last_java_fp_offset(r15_thread, JavaThread::last_Java_fp_offset());\n+  movptr(fp_reg, last_java_fp_offset); \/\/ restore fp_reg\n+  reset_last_Java_frame(true);\n+  JFR_ONLY(movptr(last_sender_Java_fp_offset, NULL_WORD);)\n+}\n+\n+void InterpreterMacroAssembler::call_VM_with_sender_Java_fp_entry(Register fp_reg, Register tmp, address entry_point, bool store_bcp \/* true *\/) {\n+  Label C, E;\n+  call(C, relocInfo::none);\n+  jmp(E);\n+  bind(C);\n+  call_VM_with_sender_Java_fp(fp_reg, tmp, entry_point, store_bcp);\n+  ret(0);\n+  bind(E);\n+}\n+\n@@ -781,1 +827,0 @@\n-\/\/ Apply stack watermark barrier.\n@@ -784,0 +829,1 @@\n+\/\/ Apply stack watermark barrier.\n@@ -793,6 +839,5 @@\n-void InterpreterMacroAssembler::remove_activation(\n-        TosState state,\n-        Register ret_addr,\n-        bool throw_monitor_exception,\n-        bool install_monitor_exception,\n-        bool notify_jvmdi) {\n+void InterpreterMacroAssembler::remove_activation(TosState state,\n+                                                  Register ret_addr,\n+                                                  bool throw_monitor_exception,\n+                                                  bool install_monitor_exception,\n+                                                  bool notify_jvmdi) {\n@@ -807,15 +852,0 @@\n-  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n-  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n-  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n-  Label slow_path;\n-  Label fast_path;\n-  safepoint_poll(slow_path, true \/* at_return *\/, false \/* in_nmethod *\/);\n-  jmp(fast_path);\n-  bind(slow_path);\n-  push(state);\n-  set_last_Java_frame(noreg, rbp, (address)pc(), rscratch1);\n-  super_call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind), rthread);\n-  reset_last_Java_frame(true);\n-  pop(state);\n-  bind(fast_path);\n-\n@@ -975,3 +1005,34 @@\n-  leave();                           \/\/ remove frame anchor\n-  pop(ret_addr);                     \/\/ get return address\n-  mov(rsp, rbx);                     \/\/ set sp to sender sp\n+\n+  \/\/ For asynchronous profiling to work correctly, we must remove the\n+  \/\/ activation frame _before_ we test the method return safepoint poll.\n+  \/\/ This is equivalent to how it is done for compiled frames.\n+  \/\/ Removing an interpreter activation frame from a sampling perspective means\n+  \/\/ updating the frame link (fp). But since we are unwinding the current frame,\n+  \/\/ we must save the current rbp in a temporary register, this_fp, for use\n+  \/\/ as the last java fp should we decide to unwind.\n+  \/\/ The asynchronous profiler will only see the updated rbp, either using the\n+  \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+  const Register this_fp = rscratch2;\n+  make_sender_fp_current(this_fp, rscratch1);\n+\n+  \/\/ The interpreter frame is now unwound from a sampling perspective,\n+  \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  safepoint_poll(slow_path, this_fp, true \/* at_return *\/, false \/* in_nmethod *\/);\n+  jmp(fast_path);\n+  bind(slow_path);\n+  push(state);\n+  \/\/ Special call to save also the sender fp (the now updated rbp) and using the temporary this_fp register as the last_java_fp.\n+  call_VM_with_sender_Java_fp_entry(this_fp, rscratch1, CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind));\n+  pop(state);\n+  bind(fast_path);\n+\n+  \/\/ Finalize remove activation by getting the return address and the caller sp.\n+  movptr(ret_addr, Address(this_fp, wordSize)); \/\/ return address\n+  movptr(rsp, rbx); \/\/ sender sp\n+\n@@ -981,0 +1042,21 @@\n+void InterpreterMacroAssembler::make_sender_fp_current(Register save_this_fp, Register tmp) {\n+  const Register return_addr = save_this_fp;\n+  const Register continuation_return_pc = tmp;\n+  const Register sender_sp = tmp;\n+  movptr(return_addr, Address(rbp, wordSize)); \/\/ return address\n+  \/\/ Load address of ContinuationEntry return pc\n+  lea(continuation_return_pc, ExternalAddress(ContinuationEntry::return_pc_address()));\n+  \/\/ Load the ContinuationEntry return pc\n+  movptr(continuation_return_pc, Address(continuation_return_pc));\n+  Label L_continuation, L_end;\n+  cmpptr(continuation_return_pc, return_addr);\n+  movptr(save_this_fp, rbp); \/\/ Save current fp in temporary register.\n+  jccb(Assembler::equal, L_continuation);\n+  movptr(rbp, Address(rbp, frame::link_offset)); \/\/ Update the frame link.\n+  jmpb(L_end);\n+  bind(L_continuation);\n+  lea(sender_sp, Address(rbp, frame::sender_sp_offset * wordSize));\n+  movptr(rbp, Address(sender_sp, (int)(ContinuationEntry::size()))); \/\/ Update the frame link.\n+  bind(L_end);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":107,"deletions":25,"binary":false,"changes":132,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,5 @@\n+  void call_VM_with_sender_Java_fp_entry(Register fp_reg,\n+                                         Register tmp,\n+                                         address entry_point,\n+                                         bool store_bcp = true);\n+\n@@ -72,1 +77,5 @@\n-    movptr(Address(rbp, frame::interpreter_frame_bcp_offset * wordSize), _bcp_register);\n+    save_bcp(rbp);\n+  }\n+\n+  void save_bcp(Register fp_register) {\n+    movptr(Address(fp_register, frame::interpreter_frame_bcp_offset * wordSize), _bcp_register);\n@@ -203,0 +212,3 @@\n+\n+  void make_sender_fp_current(Register save_this_fp, Register tmp);\n+\n@@ -273,0 +285,5 @@\n+  void call_VM_with_sender_Java_fp(Register fp_reg,\n+                                   Register tmp,\n+                                   address entry_point,\n+                                   bool store_bcp);\n+\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.hpp","additions":19,"deletions":2,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,1 @@\n-private:\n+ private:\n@@ -32,0 +32,1 @@\n+  JFR_ONLY(intptr_t* volatile _last_sender_Java_fp;) \/\/ specialized field for when JFR samples an interpreter frame\n@@ -33,1 +34,1 @@\n-public:\n+ public:\n@@ -46,0 +47,1 @@\n+    JFR_ONLY(_last_sender_Java_fp = nullptr;)\n@@ -60,0 +62,1 @@\n+    JFR_ONLY(_last_sender_Java_fp = src->_last_sender_Java_fp;)\n@@ -72,3 +75,1 @@\n-  static ByteSize last_Java_fp_offset()          { return byte_offset_of(JavaFrameAnchor, _last_Java_fp); }\n-\n-public:\n+ public:\n@@ -78,1 +79,1 @@\n-  intptr_t*   last_Java_fp(void)                 { return _last_Java_fp; }\n+  intptr_t*   last_Java_fp() const               { return _last_Java_fp; }\n@@ -82,0 +83,6 @@\n+  JFR_ONLY(intptr_t* last_sender_Java_fp() const { return _last_sender_Java_fp;})\n+\n+  static ByteSize last_Java_fp_offset()          { return byte_offset_of(JavaFrameAnchor, _last_Java_fp); }\n+\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset()   { return byte_offset_of(JavaFrameAnchor, _last_sender_Java_fp); })\n+\n","filename":"src\/hotspot\/cpu\/x86\/javaFrameAnchor_x86.hpp","additions":14,"deletions":7,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2456,0 +2456,4 @@\n+  return safepoint_poll(slow_path, rbp, at_return, in_nmethod);\n+}\n+\n+void MacroAssembler::safepoint_poll(Label& slow_path, Register fp_reg, bool at_return, bool in_nmethod) {\n@@ -2459,1 +2463,1 @@\n-    cmpptr(in_nmethod ? rsp : rbp, Address(r15_thread, JavaThread::polling_word_offset()));\n+    cmpptr(in_nmethod ? rsp : fp_reg, Address(r15_thread, JavaThread::polling_word_offset()));\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -746,0 +746,2 @@\n+  void safepoint_poll(Label& slow_path, Register fp_reg, bool at_return, bool in_nmethod);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1167,0 +1167,32 @@\n+  \/\/ Remove activation\n+\n+  \/\/ For asynchronous profiling to work correctly, we must remove the\n+  \/\/ activation frame _before_ we test the method return safepoint poll.\n+  \/\/ This is equivalent to how it is done for compiled frames.\n+  \/\/ Removing an interpreter activation frame from a sampling perspective means\n+  \/\/ updating the frame link (fp). But since we are unwinding the current frame,\n+  \/\/ we must save the current rbp in a temporary register, this_fp, for use\n+  \/\/ as the last java fp should we decide to unwind.\n+  \/\/ The asynchronous profiler will only see the updated rfp, either using the\n+  \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+  const Register this_fp = rscratch2;\n+  __ make_sender_fp_current(this_fp, rscratch1);\n+\n+  \/\/ The interpreter frame is now unwound from a sampling perspective,\n+  \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+\n+  \/\/ The below poll is for the stack watermark barrier. It allows fixing up frames lazily,\n+  \/\/ that would normally not be safe to use. Such bad returns into unsafe territory of\n+  \/\/ the stack, will call InterpreterRuntime::at_unwind.\n+  Label slow_path;\n+  Label fast_path;\n+  __ safepoint_poll(slow_path, this_fp, true, false);\n+  __ jmp(fast_path);\n+  __ bind(slow_path);\n+  __ push(dtos);\n+  __ push(ltos);\n+  __ call_VM_with_sender_Java_fp_entry(this_fp, rscratch1, CAST_FROM_FN_PTR(address, InterpreterRuntime::at_unwind), false \/* save_bcp *\/);\n+  __ pop(ltos);\n+  __ pop(dtos);\n+  __ bind(fast_path);\n+\n@@ -1168,6 +1200,2 @@\n-  __ movptr(t, Address(rbp,\n-                       frame::interpreter_frame_sender_sp_offset *\n-                       wordSize)); \/\/ get sender sp\n-  __ leave();                                \/\/ remove frame anchor\n-  __ pop(rdi);                               \/\/ get return address\n-  __ mov(rsp, t);                            \/\/ set sp to sender sp\n+  __ movptr(rdi, Address(this_fp, wordSize)); \/\/ get return address\n+  __ movptr(rsp, Address(this_fp, frame::interpreter_frame_sender_sp_offset* wordSize)); \/\/ get sender sp\n@@ -1440,0 +1468,1 @@\n+    __ restore_bcp();\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":35,"deletions":6,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -1828,1 +1828,15 @@\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n+      \/\/ For asynchronous profiling to work correctly, we must remove the\n+      \/\/ activation frame _before_ we test the method return safepoint poll.\n+      \/\/ This is equivalent to how it is done for compiled frames.\n+      \/\/ Removing an interpreter activation frame from a sampling perspective means\n+      \/\/ updating the frame link (fp). But since we are unwinding the current frame,\n+      \/\/ we must save the current rbp in a temporary register, this_fp, for use\n+      \/\/ as the last java fp should we decide to unwind.\n+      \/\/ The asynchronous profiler will only see the updated rbp, either using the\n+      \/\/ CPU context or by reading the saved_Java_fp() field as part of the ljf.\n+      const Register this_fp = rscratch2;\n+      __ make_sender_fp_current(this_fp, rax);\n+\n+      \/\/ The interpreter frame is now unwound from a sampling perspective,\n+      \/\/ meaning it sees the sender frame as the current frame from this point onwards.\n+      __ call_VM_with_sender_Java_fp_entry(this_fp, rax, CAST_FROM_FN_PTR(address, SharedRuntime::OSR_migration_begin));\n@@ -1837,1 +1851,0 @@\n-      const Register sender_sp = j_rarg1;\n@@ -1839,5 +1852,3 @@\n-      \/\/ pop the interpreter frame\n-      __ movptr(sender_sp, Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize)); \/\/ get sender sp\n-      __ leave();                                \/\/ remove frame anchor\n-      __ pop(retaddr);                           \/\/ get return address\n-      __ mov(rsp, sender_sp);                   \/\/ set sp to sender sp\n+      \/\/ pop the rest of the interpreter frame\n+      __ movptr(retaddr, Address(this_fp, frame::return_addr_offset * wordSize)); \/\/ get return address\n+      __ movptr(rsp, Address(this_fp, frame::interpreter_frame_sender_sp_offset* wordSize)); \/\/ get sender sp\n@@ -1847,3 +1858,0 @@\n-      \/\/ unlike x86 we need no specialized return from compiled code\n-      \/\/ to the interpreter or the call stub.\n-\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":18,"deletions":10,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-  ZeroFrame* volatile _last_Java_fp;\n+  intptr_t* volatile _last_Java_fp;\n@@ -53,1 +53,1 @@\n-  void set(intptr_t* sp, address pc, ZeroFrame* fp) {\n+  void set(intptr_t* sp, address pc, intptr_t* fp) {\n@@ -84,1 +84,1 @@\n-  ZeroFrame* last_Java_fp() const {\n+  intptr_t* last_Java_fp() const {\n","filename":"src\/hotspot\/cpu\/zero\/javaFrameAnchor_zero.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -5734,18 +5734,4 @@\n-\/\/ returns true if thread could be suspended,\n-\/\/ false otherwise\n-static bool do_suspend(HANDLE* h) {\n-  if (h != nullptr) {\n-    if (SuspendThread(*h) != ~0) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-\/\/ resume the thread\n-\/\/ calling resume on an active thread is a no-op\n-static void do_resume(HANDLE* h) {\n-  if (h != nullptr) {\n-    ResumeThread(*h);\n-  }\n-}\n+\/\/ WINDOWS CONTEXT Flags for THREAD_SAMPLING\n+#if defined(AMD64) || defined(_M_ARM64)\n+  #define sampling_context_flags (CONTEXT_FULL | CONTEXT_FLOATING_POINT)\n+#endif\n@@ -5753,7 +5739,4 @@\n-\/\/ retrieve a suspend\/resume context capable handle\n-\/\/ from the tid. Caller validates handle return value.\n-void get_thread_handle_for_extended_context(HANDLE* h,\n-                                            DWORD tid) {\n-  if (h != nullptr) {\n-    *h = OpenThread(THREAD_SUSPEND_RESUME | THREAD_GET_CONTEXT | THREAD_QUERY_INFORMATION, FALSE, tid);\n-  }\n+\/\/ Retrieve a suspend\/resume context capable handle for the tid.\n+\/\/ Caller validates handle return value.\n+static inline HANDLE get_thread_handle_for_extended_context(DWORD tid) {\n+  return OpenThread(THREAD_SUSPEND_RESUME | THREAD_GET_CONTEXT | THREAD_QUERY_INFORMATION, FALSE, tid);\n@@ -5765,8 +5748,2 @@\n-  CONTEXT    ctxt;\n-  HANDLE     h = nullptr;\n-\n-  \/\/ get context capable handle for thread\n-  get_thread_handle_for_extended_context(&h, _thread->osthread()->thread_id());\n-\n-  \/\/ sanity\n-  if (h == nullptr || h == INVALID_HANDLE_VALUE) {\n+  const HANDLE h = get_thread_handle_for_extended_context(_thread->osthread()->thread_id());\n+  if (h == nullptr) {\n@@ -5775,11 +5752,9 @@\n-\n-  \/\/ suspend the thread\n-  if (do_suspend(&h)) {\n-    ctxt.ContextFlags = (CONTEXT_FULL | CONTEXT_FLOATING_POINT);\n-    \/\/ get thread context\n-    GetThreadContext(h, &ctxt);\n-    SuspendedThreadTaskContext context(_thread, &ctxt);\n-    \/\/ pass context to Thread Sampling impl\n-    do_task(context);\n-    \/\/ resume thread\n-    do_resume(&h);\n+  CONTEXT ctxt;\n+  ctxt.ContextFlags = sampling_context_flags;\n+  if (SuspendThread(h) != OS_ERR) {\n+    if (GetThreadContext(h, &ctxt)) {\n+      const SuspendedThreadTaskContext context(_thread, &ctxt);\n+      \/\/ Pass context to Thread Sampling implementation.\n+      do_task(context);\n+    }\n+    ResumeThread(h);\n@@ -5787,2 +5762,0 @@\n-\n-  \/\/ close handle\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":19,"deletions":46,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,4 @@\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() {\n+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_sender_Java_fp_offset();\n+  })\n+\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/javaThread_bsd_aarch64.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,4 @@\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() {\n+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_sender_Java_fp_offset();\n+  })\n+\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/javaThread_linux_aarch64.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,0 +40,4 @@\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() {\n+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_sender_Java_fp_offset();\n+  })\n+\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/javaThread_linux_x86.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-    frame_anchor()->set(sp, nullptr, fp);\n+    frame_anchor()->set(sp, nullptr, (intptr_t*)fp);\n@@ -76,1 +76,1 @@\n-    return frame_anchor()->last_Java_fp();\n+    return (ZeroFrame*)(frame_anchor()->last_Java_fp());\n","filename":"src\/hotspot\/os_cpu\/linux_zero\/javaThread_linux_zero.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -41,0 +41,4 @@\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() {\n+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_sender_Java_fp_offset();\n+  })\n+\n","filename":"src\/hotspot\/os_cpu\/windows_aarch64\/javaThread_windows_aarch64.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -47,0 +47,3 @@\n+  JFR_ONLY(static ByteSize last_sender_Java_fp_offset() {\n+    return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_sender_Java_fp_offset(); })\n+\n","filename":"src\/hotspot\/os_cpu\/windows_x86\/javaThread_windows_x86.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -79,0 +79,3 @@\n+#if INCLUDE_JFR\n+#include \"jfr\/jfr.hpp\"\n+#endif\n@@ -1171,0 +1174,1 @@\n+  JFR_ONLY(Jfr::check_and_process_sample_request(current);)\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampling.hpp\"\n@@ -37,0 +38,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -151,0 +153,11 @@\n+\n+bool Jfr::has_sample_request(JavaThread* jt) {\n+  return jt->jfr_thread_local()->has_sample_request();\n+}\n+\n+void Jfr::check_and_process_sample_request(JavaThread* jt) {\n+  assert(jt != nullptr, \"invariant\");\n+  if (has_sample_request(jt)) {\n+    JfrThreadSampling::process_sample_request(jt);\n+  }\n+}\n","filename":"src\/hotspot\/share\/jfr\/jfr.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -75,0 +75,2 @@\n+  static bool has_sample_request(JavaThread* jt);\n+  static void check_and_process_sample_request(JavaThread* jt);\n","filename":"src\/hotspot\/share\/jfr\/jfr.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -280,1 +280,1 @@\n-    JfrThreadSampling::set_java_sample_period(periodMillis);\n+    JfrThreadSampler::set_java_sample_period(periodMillis);\n@@ -282,1 +282,1 @@\n-    JfrThreadSampling::set_native_sample_period(periodMillis);\n+    JfrThreadSampler::set_native_sample_period(periodMillis);\n","filename":"src\/hotspot\/share\/jfr\/jni\/jfrJniMethod.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -337,1 +337,2 @@\n-  writer.write(trace->_nr_of_frames);\n+  const int number_of_frames = trace->number_of_frames();\n+  writer.write<u4>(number_of_frames);\n@@ -339,2 +340,2 @@\n-  for (u4 i = 0; i < trace->_nr_of_frames; ++i) {\n-    const JfrStackFrame& frame = trace->_frames[i];\n+  for (int i = 0; i < number_of_frames; ++i) {\n+    const JfrStackFrame& frame = trace->_frames->at(i);\n","filename":"src\/hotspot\/share\/jfr\/leakprofiler\/checkpoint\/objectSampleCheckpoint.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -713,0 +713,5 @@\n+  <Event name=\"SafepointLatency\" category=\"Java Virtual Machine, Runtime, Safepoint\" label=\"Safepoint Latency\"\n+    description=\"The delay for a thread to reach its next safepoint poll instruction after receiving an asynchronous sampling interrupt\" thread=\"true\" stackTrace=\"true\" throttle=\"true\">\n+    <Field type=\"VMThreadState\" name=\"threadState\" label=\"VM Thread State\" \/>\n+  <\/Event>\n+\n@@ -1298,0 +1303,4 @@\n+  <Type name=\"VMThreadState\" label=\"JVM Thread State\">\n+    <Field type=\"string\" name=\"state\" label=\"State\" \/>\n+  <\/Type>\n+\n","filename":"src\/hotspot\/share\/jfr\/metadata\/metadata.xml","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1,120 +0,0 @@\n-\/*\n- * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"code\/debugInfoRec.hpp\"\n-#include \"code\/nmethod.hpp\"\n-#include \"code\/pcDesc.hpp\"\n-#include \"jfr\/periodic\/sampling\/jfrCallTrace.hpp\"\n-#include \"jfr\/utilities\/jfrTypes.hpp\"\n-#include \"oops\/method.hpp\"\n-#include \"runtime\/javaCalls.hpp\"\n-#include \"runtime\/javaThread.inline.hpp\"\n-#include \"runtime\/frame.inline.hpp\"\n-#include \"runtime\/registerMap.hpp\"\n-\n-bool JfrGetCallTrace::find_top_frame(frame& top_frame, Method** method, frame& first_frame) {\n-  assert(top_frame.cb() != nullptr, \"invariant\");\n-  RegisterMap map(_thread,\n-                  RegisterMap::UpdateMap::skip,\n-                  RegisterMap::ProcessFrames::skip,\n-                  RegisterMap::WalkContinuation::skip);\n-  frame candidate = top_frame;\n-  for (u4 i = 0; i < MAX_STACK_DEPTH * 2; ++i) {\n-    if (candidate.is_entry_frame()) {\n-      JavaCallWrapper *jcw = candidate.entry_frame_call_wrapper_if_safe(_thread);\n-      if (jcw == nullptr || jcw->is_first_frame()) {\n-        return false;\n-      }\n-    }\n-\n-    if (candidate.is_interpreted_frame()) {\n-      JavaThreadState state = _thread->thread_state();\n-      const bool known_valid = (state == _thread_in_native || state == _thread_in_vm || state == _thread_blocked);\n-      if (known_valid || candidate.is_interpreted_frame_valid(_thread)) {\n-        Method* im = candidate.interpreter_frame_method();\n-        if (known_valid && !Method::is_valid_method(im)) {\n-          return false;\n-        }\n-        *method = im;\n-        first_frame = candidate;\n-        return true;\n-      }\n-    }\n-\n-    if (candidate.cb()->is_nmethod()) {\n-      \/\/ first check to make sure that we have a sane stack,\n-      \/\/ the PC is actually inside the code part of the codeBlob,\n-      \/\/ and we are past is_frame_complete_at (stack has been setup)\n-      if (!candidate.safe_for_sender(_thread)) {\n-        return false;\n-      }\n-      nmethod* nm = (nmethod*)candidate.cb();\n-      *method = nm->method();\n-\n-      if (_in_java) {\n-        PcDesc* pc_desc = nm->pc_desc_near(candidate.pc() + 1);\n-        if (pc_desc == nullptr || pc_desc->scope_decode_offset() == DebugInformationRecorder::serialized_null) {\n-          return false;\n-        }\n-        candidate.set_pc(pc_desc->real_pc(nm));\n-        assert(nm->pc_desc_at(candidate.pc()) != nullptr, \"invalid pc\");\n-      }\n-      first_frame = candidate;\n-      return true;\n-    }\n-\n-    if (!candidate.safe_for_sender(_thread) ||\n-      candidate.is_stub_frame() ||\n-      candidate.cb()->frame_size() <= 0) {\n-      return false;\n-    }\n-\n-    candidate = candidate.sender(&map);\n-    if (candidate.cb() == nullptr) {\n-      return false;\n-    }\n-  }\n-  return false;\n-}\n-\n-bool JfrGetCallTrace::get_topframe(void* ucontext, frame& topframe) {\n-  if (!_thread->pd_get_top_frame_for_profiling(&topframe, ucontext, _in_java)) {\n-    return false;\n-  }\n-\n-  if (topframe.cb() == nullptr) {\n-    return false;\n-  }\n-\n-  frame first_java_frame;\n-  Method* method = nullptr;\n-  if (find_top_frame(topframe, &method, first_java_frame)) {\n-    if (method == nullptr) {\n-      return false;\n-    }\n-    topframe = first_java_frame;\n-    return true;\n-  }\n-  return false;\n-}\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCallTrace.cpp","additions":0,"deletions":120,"binary":false,"changes":120,"status":"deleted"},{"patch":"@@ -1,45 +0,0 @@\n-\/*\n- * Copyright (c) 2012, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_JFR_PERIODIC_SAMPLING_JFRCALLTRACE_HPP\n-#define SHARE_JFR_PERIODIC_SAMPLING_JFRCALLTRACE_HPP\n-\n-#include \"memory\/allocation.hpp\"\n-\n-class frame;\n-class Method;\n-class JavaThread;\n-\n-class JfrGetCallTrace : public StackObj {\n- private:\n-  JavaThread* _thread;\n-  bool _in_java;\n-\n- public:\n-  JfrGetCallTrace(bool in_java, JavaThread* thread) : _thread(thread), _in_java(in_java) {}\n-  bool find_top_frame(frame& topframe, Method** method, frame& first_frame);\n-  bool get_topframe(void* ucontext, frame& top);\n-};\n-\n-#endif \/\/ SHARE_JFR_PERIODIC_SAMPLING_JFRCALLTRACE_HPP\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCallTrace.hpp","additions":0,"deletions":45,"binary":false,"changes":45,"status":"deleted"},{"patch":"@@ -0,0 +1,384 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+#include \"asm\/codeBuffer.hpp\"\n+#include \"interpreter\/interpreter.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrSampleRequest.hpp\"\n+#include \"runtime\/continuationEntry.hpp\"\n+#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/javaThread.inline.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"runtime\/safepointMechanism.inline.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n+#include \"runtime\/suspendedThreadTask.hpp\"\n+\n+static inline bool is_entry_frame(address pc) {\n+  return StubRoutines::returns_to_call_stub(pc);\n+}\n+\n+static inline bool is_entry_frame(const JfrSampleRequest& request) {\n+  return is_entry_frame(static_cast<address>(request._sample_pc));\n+}\n+\n+static inline bool is_interpreter(address pc) {\n+  return Interpreter::contains(pc);\n+}\n+\n+static inline bool is_interpreter(const JfrSampleRequest& request) {\n+  return is_interpreter(static_cast<address>(request._sample_pc));\n+}\n+\n+static inline Method* interpreter_frame_method(const intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return reinterpret_cast<Method*>(fp[frame::interpreter_frame_method_offset]);\n+}\n+\n+static inline Method* interpreter_frame_method(const JfrSampleRequest& request) {\n+  return interpreter_frame_method(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline address interpreter_frame_bcp(const intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return reinterpret_cast<address>(fp[frame::interpreter_frame_bcp_offset]);\n+}\n+\n+static inline address interpreter_frame_bcp(const JfrSampleRequest& request) {\n+  assert(is_interpreter(request), \"invariant\");\n+  return interpreter_frame_bcp(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline bool in_stack(intptr_t* ptr, JavaThread* jt) {\n+  assert(jt != nullptr, \"invariant\");\n+  return jt->is_in_full_stack_checked(reinterpret_cast<address>(ptr));\n+}\n+\n+static inline bool sp_in_stack(const JfrSampleRequest& request, JavaThread* jt) {\n+  return in_stack(static_cast<intptr_t*>(request._sample_sp), jt);\n+}\n+\n+static inline bool fp_in_stack(const JfrSampleRequest& request, JavaThread* jt) {\n+  return in_stack(static_cast<intptr_t*>(request._sample_bcp), jt);\n+}\n+\n+static inline address interpreter_frame_return_address(const intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return reinterpret_cast<address>(fp[frame::return_addr_offset]);\n+}\n+\n+static inline void update_interpeter_frame_sender_pc(JfrSampleRequest& request, intptr_t* fp) {\n+  request._sample_pc = interpreter_frame_return_address(fp);\n+}\n+\n+static inline void update_interpreter_frame_pc(JfrSampleRequest& request, JavaThread* jt) {\n+  assert(fp_in_stack(request, jt), \"invariant\");\n+  assert(is_interpreter(request), \"invariant\");\n+  request._sample_pc = interpreter_frame_return_address(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline address interpreter_frame_return_address(const JfrSampleRequest& request) {\n+  assert(is_interpreter(request), \"invariant\");\n+  return interpreter_frame_return_address(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline intptr_t* interpreter_frame_sender_sp(const intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return reinterpret_cast<intptr_t*>(fp[frame::interpreter_frame_sender_sp_offset]);\n+}\n+\n+static inline intptr_t* continuation_frame_sender_fp(void* sp) {\n+  assert(sp != nullptr, \"invariant\");\n+  return reinterpret_cast<intptr_t*>(static_cast<address>(sp) + (ContinuationEntry::size()));\n+}\n+\n+static inline address continuation_frame_sender_pc(void* sp) {\n+  assert(sp != nullptr, \"invariant\");\n+  return static_cast<address>(sp) + (ContinuationEntry::size() + wordSize);\n+}\n+\n+static inline void update_continuation_frame_sender_pc(JfrSampleRequest& request) {\n+  request._sample_pc = continuation_frame_sender_pc(request._sample_sp);\n+}\n+\n+static inline void update_continuation_frame_sender_sp(JfrSampleRequest& request) {\n+  request._sample_sp = static_cast<address>(request._sample_sp) + (ContinuationEntry::size() + 2 * wordSize);\n+}\n+\n+static inline intptr_t* frame_sender_sp(intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return fp + frame::sender_sp_offset;\n+}\n+\n+static inline intptr_t* frame_sender_sp(const JfrSampleRequest& request, JavaThread* jt) {\n+  assert(fp_in_stack(request, jt), \"invariant\");\n+  return frame_sender_sp(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline void update_frame_sender_sp(JfrSampleRequest& request, JavaThread* jt) {\n+  request._sample_sp = frame_sender_sp(request, jt);\n+}\n+\n+static inline void update_frame_sender_sp(JfrSampleRequest& request, intptr_t* fp) {\n+  request._sample_sp = frame_sender_sp(fp);\n+}\n+\n+static inline intptr_t* frame_link(const intptr_t* fp) {\n+  assert(fp != nullptr, \"invariant\");\n+  return reinterpret_cast<intptr_t*>(fp[frame::link_offset]);\n+}\n+\n+static inline intptr_t* frame_link(const JfrSampleRequest& request) {\n+  return frame_link(static_cast<intptr_t*>(request._sample_bcp));\n+}\n+\n+static inline void update_sp(JfrSampleRequest& request, int frame_size) {\n+  assert(frame_size >= 0, \"invariant\");\n+  request._sample_sp = static_cast<intptr_t*>(request._sample_sp) + frame_size;\n+}\n+\n+static inline void update_pc(JfrSampleRequest& request) {\n+  assert(request._sample_sp != nullptr, \"invariant\");\n+  request._sample_pc = address(static_cast<intptr_t**>(request._sample_sp)[-1]);\n+}\n+\n+static inline void update_fp(JfrSampleRequest& request) {\n+  assert(request._sample_sp != nullptr, \"invariant\");\n+  request._sample_bcp = is_interpreter(request) ? static_cast<intptr_t**>(request._sample_sp)[-2] : nullptr;\n+}\n+\n+static inline const intptr_t* frame_complete_offset(const JfrSampleRequest& request) {\n+  return static_cast<intptr_t*>(request._sample_bcp) + frame::interpreter_frame_initial_sp_offset;\n+}\n+\n+static inline bool is_interpreter_frame_setup(const JfrSampleRequest& request) {\n+  return frame_complete_offset(request) >= static_cast<intptr_t*>(request._sample_sp);\n+}\n+\n+\/\/ Less extensive sanity checks for an interpreter frame.\n+static bool is_valid_interpreter_frame(const JfrSampleRequest& request, JavaThread* jt) {\n+  assert(sp_in_stack(request, jt), \"invariant\");\n+  assert(fp_in_stack(request, jt), \"invariant\");\n+  \/\/ word alignment.\n+  if ((reinterpret_cast<intptr_t>(request._sample_bcp) & (wordSize - 1)) != 0) {\n+    return false;\n+  }\n+  return is_interpreter_frame_setup(request) && Method::is_valid_method(interpreter_frame_method(request));\n+}\n+\n+static inline bool is_continuation_frame(address pc) {\n+  return ContinuationEntry::return_pc() == pc;\n+}\n+\n+static inline bool is_continuation_frame(const JfrSampleRequest& request) {\n+  return is_continuation_frame(static_cast<address>(request._sample_pc));\n+}\n+\n+static void update_continuation_frame_sender(JfrSampleRequest& request, intptr_t* last_fp) {\n+  assert(last_fp != nullptr, \"invariant\");\n+  update_frame_sender_sp(request, last_fp);\n+  update_continuation_frame_sender_pc(request);\n+  update_continuation_frame_sender_sp(request);\n+}\n+\n+static intptr_t* update_continuation_frame_sender(JfrSampleRequest& request) {\n+  update_continuation_frame_sender(request, static_cast<intptr_t*>(request._sample_bcp));\n+  request._sample_bcp = nullptr;\n+  return continuation_frame_sender_fp(request._sample_sp);\n+}\n+\n+static intptr_t* sender_for_interpreter_frame(JfrSampleRequest& request, JavaThread* jt) {\n+  update_interpreter_frame_pc(request, jt); \/\/ pick up return address\n+  if (is_continuation_frame(request)) {\n+    return update_continuation_frame_sender(request);\n+  }\n+  update_frame_sender_sp(request, jt);\n+  intptr_t* fp = nullptr;\n+  if (is_interpreter(request) || is_entry_frame(request)) {\n+    fp = frame_link(request);\n+  }\n+  request._sample_bcp = nullptr;\n+  return fp;\n+}\n+\n+static bool build(JfrSampleRequest& request, intptr_t* fp, JavaThread* jt);\n+\n+static bool build_for_interpreter(JfrSampleRequest& request, JavaThread* jt) {\n+  assert(is_interpreter(request), \"invariant\");\n+  if (!fp_in_stack(request, jt)) {\n+    return false;\n+  }\n+  if (is_valid_interpreter_frame(request, jt)) {\n+    \/\/ Set fp as sp for interpreter frames.\n+    request._sample_sp = request._sample_bcp;\n+    \/\/ Get real bcp.\n+    void* const bcp = interpreter_frame_bcp(request);\n+    \/\/ Set Method* as the sample_pc for interpreter frames.\n+    request._sample_pc = interpreter_frame_method(request);\n+    \/\/ Setting bcp = 1 marks the sample request to represent a native method.\n+    request._sample_bcp = bcp != nullptr ? bcp : reinterpret_cast<address>(1);\n+    return true;\n+  }\n+  intptr_t* fp = sender_for_interpreter_frame(request, jt);\n+  if (request._sample_pc == nullptr || request._sample_sp == nullptr) {\n+    return false;\n+  }\n+  return build(request, fp, jt);\n+}\n+\n+\/\/ Attempt to build a Jfr sample request.\n+static bool build(JfrSampleRequest& request, intptr_t* fp, JavaThread* jt) {\n+  assert(request._sample_sp != nullptr, \"invariant\");\n+  assert(request._sample_pc != nullptr, \"invariant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(jt->thread_state() == _thread_in_Java, \"invariant\");\n+\n+  \/\/ 1. Interpreter frame?\n+  if (is_interpreter(request)) {\n+    request._sample_bcp = fp;\n+    return build_for_interpreter(request, jt);\n+  }\n+  const CodeBlob* const cb = CodeCache::find_blob(request._sample_pc);\n+  if (cb != nullptr) {\n+    \/\/ 2. Is nmethod?\n+    if (cb->is_nmethod()) {\n+      return true;\n+    }\n+    \/\/ 3. What kind of CodeBlob or Stub?\n+    \/\/ Longer plan is to make stubs and blobs parsable,\n+    \/\/ and we will have a list of cases here for each blob type\n+    \/\/ describing how to locate the sender. We can't get to the\n+    \/\/ sender of a blob or stub until they have a standardized\n+    \/\/ layout and proper metadata descriptions.\n+  }\n+  return false;\n+}\n+\n+\/\/ We have logically unwound the interpreter frame at the sensitive safepoint poll site,\n+\/\/ by updating the fp link, and the sender frame is represented by sender_Java_fp.\n+\/\/ We need to use sender_Java_fp as the last fp in these contexts, else we would\n+\/\/ re-sample an interpreter frame whose poll return check we are currently processing, causing a race.\n+static inline intptr_t* process_sender_Java_fp(JfrSampleRequest& request, intptr_t* sender_Java_fp, intptr_t* last_fp, JavaThread* jt) {\n+  assert(sender_Java_fp != nullptr, \"invariant\");\n+  assert(last_fp != nullptr, \"invariant\");\n+  assert(in_stack(last_fp, jt), \"invariant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(jt->has_last_Java_frame(), \"invariant\");\n+  if (p2i(sender_Java_fp) == 1) {\n+    \/\/ A marker that the fp of the sender is undetermined, which implies\n+    \/\/ the sender is a compiled frame to be used instead.\n+    update_interpeter_frame_sender_pc(request, last_fp); \/\/ pick up return address\n+    update_frame_sender_sp(request, last_fp); \/\/ sender sp\n+    return nullptr;\n+  }\n+  if (JfrThreadLocal::is_vthread(jt)) {\n+    if (is_continuation_frame(interpreter_frame_return_address(last_fp))) {\n+      update_continuation_frame_sender(request, last_fp);\n+    }\n+  }\n+  return sender_Java_fp;\n+}\n+\n+static bool build_from_ljf(JfrSampleRequest& request,\n+                           const SuspendedThreadTaskContext& context,\n+                           JavaThread* jt) {\n+  assert(sp_in_stack(request, jt), \"invariant\");\n+\n+  \/\/ Last Java frame is available, but might not be walkable, fix it.\n+  address last_pc = jt->last_Java_pc();\n+  if (last_pc == nullptr) {\n+    last_pc = address(static_cast<intptr_t**>(request._sample_sp)[-1]);\n+    if (last_pc == nullptr) {\n+      return false;\n+    }\n+  }\n+  assert(last_pc != nullptr, \"invariant\");\n+  request._sample_pc = last_pc;\n+\n+  intptr_t* last_fp = jt->last_Java_fp();\n+  if (last_fp == nullptr) {\n+    if (is_interpreter(request)) {\n+      intptr_t* unused_sp;\n+      os::fetch_frame_from_context(context.ucontext(), &unused_sp, &last_fp);\n+    }\n+    return build(request, last_fp, jt);\n+  }\n+\n+  \/\/ last fp indicates an interpreter frame. If sender_Java_fp exists,\n+  \/\/ this ljf represents a sensitive method return safepoint poll site in the interpreter.\n+  intptr_t* const sender_Java_fp = jt->sender_Java_fp();\n+  if (sender_Java_fp != nullptr) {\n+    last_fp = process_sender_Java_fp(request, sender_Java_fp, last_fp, jt);\n+  }\n+  return build(request, last_fp, jt);\n+}\n+\n+static inline JfrSampleResult set_request_and_arm_local_poll(JfrSampleRequest& request, JfrThreadLocal* tl, JavaThread* jt) {\n+  assert(tl != nullptr, \"invariant\");\n+  assert(jt->jfr_thread_local() == tl, \"invariant\");\n+  tl->set_sample_state(JAVA_SAMPLE);\n+  SafepointMechanism::arm_local_poll_release(jt);\n+  \/\/ For a Java sample, request._sample_ticks is also the start time for the SafepointLatency event.\n+  request._sample_ticks = JfrTicks::now();\n+  tl->set_sample_request(request);\n+  return SAMPLE_JAVA;\n+}\n+\n+\/\/ A biased sample request is denoted by an empty bcp and an empty pc.\n+static inline JfrSampleResult set_biased_java_sample(JfrSampleRequest& request, JfrThreadLocal* tl, JavaThread* jt) {\n+  if (request._sample_bcp != nullptr) {\n+    request._sample_bcp = nullptr;\n+  }\n+  assert(request._sample_bcp == nullptr, \"invariant\");\n+  request._sample_pc = nullptr;\n+  return set_request_and_arm_local_poll(request, tl, jt);\n+}\n+\n+static inline JfrSampleResult set_unbiased_java_sample(JfrSampleRequest& request, JfrThreadLocal* tl, JavaThread* jt) {\n+  assert(request._sample_sp != nullptr, \"invariant\");\n+  assert(sp_in_stack(request, jt), \"invariant\");\n+  assert(request._sample_pc != nullptr, \"invariant\");\n+  assert(request._sample_bcp != nullptr || !is_interpreter(request), \"invariant\");\n+  return set_request_and_arm_local_poll(request, tl, jt);\n+}\n+\n+JfrSampleResult JfrSampleRequestBuilder::build_java_sample_request(const SuspendedThreadTaskContext& context,\n+                                                                   JfrThreadLocal* tl,\n+                                                                   JavaThread* jt) {\n+  assert(tl != nullptr, \"invariant\");\n+  assert(tl->sample_state() == NO_SAMPLE, \"invariant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(jt->thread_state() == _thread_in_Java, \"invariant\");\n+\n+  JfrSampleRequest request;\n+\n+  \/\/ Prioritize the ljf, if one exists.\n+  request._sample_sp = jt->last_Java_sp();\n+  if (request._sample_sp == nullptr || !build_from_ljf(request, context, jt)) {\n+    intptr_t* fp;\n+    request._sample_pc = os::fetch_frame_from_context(context.ucontext(), reinterpret_cast<intptr_t**>(&request._sample_sp), &fp);\n+    assert(sp_in_stack(request, jt), \"invariant\");\n+    if (!build(request, fp, jt)) {\n+      return set_biased_java_sample(request, tl, jt);\n+    }\n+  }\n+  return set_unbiased_java_sample(request, tl, jt);\n+}\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrSampleRequest.cpp","additions":384,"deletions":0,"binary":false,"changes":384,"status":"added"},{"patch":"@@ -0,0 +1,86 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_JFR_PERIODIC_SAMPLING_JFRSAMPLEREQUEST_HPP\n+#define SHARE_JFR_PERIODIC_SAMPLING_JFRSAMPLEREQUEST_HPP\n+\n+#include \"jfr\/utilities\/jfrTime.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+\n+class JavaThread;\n+class JfrThreadLocal;\n+class SuspendedThreadTaskContext;\n+\n+enum JfrSampleResult {\n+  THREAD_SUSPENSION_ERROR,\n+  WRONG_THREAD_STATE,\n+  UNPARSABLE_TOP_FRAME,\n+  INVALID_STACK_TRACE,\n+  CRASH,\n+  NO_LAST_JAVA_FRAME,\n+  UNKNOWN,\n+  FAIL,\n+  SKIP,\n+  SAMPLE_NATIVE,\n+  SAMPLE_JAVA,\n+  NOF_SAMPLING_RESULTS\n+};\n+\n+enum JfrSampleRequestType {\n+  NO_SAMPLE = 0,\n+  NATIVE_SAMPLE = 1,\n+  JAVA_SAMPLE = 2,\n+  NOF_SAMPLE_TYPES\n+};\n+\n+struct JfrSampleRequest {\n+  void* _sample_sp;\n+  void* _sample_pc;\n+  void* _sample_bcp;\n+  JfrTicks _sample_ticks;\n+\n+  JfrSampleRequest() :\n+    _sample_sp(nullptr),\n+    _sample_pc(nullptr),\n+    _sample_bcp(nullptr),\n+    _sample_ticks() {}\n+\n+  JfrSampleRequest(const JfrTicks& ticks) :\n+    _sample_sp(nullptr),\n+    _sample_pc(nullptr),\n+    _sample_bcp(nullptr),\n+    _sample_ticks(ticks) {}\n+};\n+\n+typedef GrowableArrayCHeap<JfrSampleRequest, mtTracing> JfrSampleRequestQueue;\n+\n+class JfrSampleRequestBuilder : AllStatic {\n+ public:\n+  static JfrSampleResult build_java_sample_request(const SuspendedThreadTaskContext& context,\n+                                                   JfrThreadLocal* tl,\n+                                                   JavaThread* jt);\n+};\n+\n+#endif \/\/ SHARE_JFR_PERIODIC_SAMPLING_JFRSAMPLEREQUEST_HPP\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrSampleRequest.hpp","additions":86,"deletions":0,"binary":false,"changes":86,"status":"added"},{"patch":"@@ -25,6 +25,1 @@\n-#include \"classfile\/javaThreadStatus.hpp\"\n-#include \"jfr\/jfrEvents.hpp\"\n-#include \"jfr\/recorder\/jfrRecorder.hpp\"\n-#include \"jfr\/periodic\/sampling\/jfrCallTrace.hpp\"\n-#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n-#include \"jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.inline.hpp\"\n+#include \"jfr\/metadata\/jfrSerializer.hpp\"\n@@ -32,3 +27,3 @@\n-#include \"jfr\/recorder\/stacktrace\/jfrStackTraceRepository.hpp\"\n-#include \"jfr\/recorder\/storage\/jfrBuffer.hpp\"\n-#include \"jfr\/support\/jfrThreadLocal.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrSampleRequest.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampling.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n@@ -36,1 +31,2 @@\n-#include \"jfrfiles\/jfrEventClasses.hpp\"\n+#include \"jfr\/utilities\/jfrTryLock.hpp\"\n+#include \"jfr\/utilities\/jfrTypes.hpp\"\n@@ -39,1 +35,0 @@\n-#include \"runtime\/frame.inline.hpp\"\n@@ -42,0 +37,2 @@\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"runtime\/orderAccess.hpp\"\n@@ -43,0 +40,1 @@\n+#include \"runtime\/safepointMechanism.inline.hpp\"\n@@ -44,1 +42,0 @@\n-#include \"runtime\/stackWatermark.hpp\"\n@@ -46,2 +43,1 @@\n-#include \"runtime\/threadCrashProtection.hpp\"\n-#include \"runtime\/threadSMR.hpp\"\n+#include \"runtime\/threadSMR.inline.hpp\"\n@@ -50,289 +46,8 @@\n-enum JfrSampleType {\n-  NO_SAMPLE = 0,\n-  JAVA_SAMPLE = 1,\n-  NATIVE_SAMPLE = 2\n-};\n-\n-static bool thread_state_in_java(JavaThread* thread) {\n-  assert(thread != nullptr, \"invariant\");\n-  switch(thread->thread_state()) {\n-    case _thread_new:\n-    case _thread_uninitialized:\n-    case _thread_new_trans:\n-    case _thread_in_vm_trans:\n-    case _thread_blocked_trans:\n-    case _thread_in_native_trans:\n-    case _thread_blocked:\n-    case _thread_in_vm:\n-    case _thread_in_native:\n-    case _thread_in_Java_trans:\n-      break;\n-    case _thread_in_Java:\n-      return true;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-  }\n-  return false;\n-}\n-\n-static bool thread_state_in_native(JavaThread* thread) {\n-  assert(thread != nullptr, \"invariant\");\n-  switch(thread->thread_state()) {\n-    case _thread_new:\n-    case _thread_uninitialized:\n-    case _thread_new_trans:\n-    case _thread_blocked_trans:\n-    case _thread_blocked:\n-    case _thread_in_vm:\n-    case _thread_in_vm_trans:\n-    case _thread_in_Java_trans:\n-    case _thread_in_Java:\n-    case _thread_in_native_trans:\n-      break;\n-    case _thread_in_native:\n-      return true;\n-    default:\n-      ShouldNotReachHere();\n-      break;\n-  }\n-  return false;\n-}\n-\n-class JfrThreadSampleClosure {\n- public:\n-  JfrThreadSampleClosure(EventExecutionSample* events, EventNativeMethodSample* events_native);\n-  ~JfrThreadSampleClosure() {}\n-  EventExecutionSample* next_event() { return &_events[_added_java++]; }\n-  EventNativeMethodSample* next_event_native() { return &_events_native[_added_native++]; }\n-  void commit_events(JfrSampleType type);\n-  bool do_sample_thread(JavaThread* thread, JfrStackFrame* frames, u4 max_frames, JfrSampleType type);\n-  uint java_entries() { return _added_java; }\n-  uint native_entries() { return _added_native; }\n-\n- private:\n-  bool sample_thread_in_java(JavaThread* thread, JfrStackFrame* frames, u4 max_frames);\n-  bool sample_thread_in_native(JavaThread* thread, JfrStackFrame* frames, u4 max_frames);\n-  EventExecutionSample* _events;\n-  EventNativeMethodSample* _events_native;\n-  Thread* _self;\n-  uint _added_java;\n-  uint _added_native;\n-};\n-\n-class OSThreadSampler : public SuspendedThreadTask {\n- public:\n-  OSThreadSampler(JavaThread* thread,\n-                  JfrThreadSampleClosure& closure,\n-                  JfrStackFrame *frames,\n-                  u4 max_frames) : SuspendedThreadTask((Thread*)thread),\n-    _success(false),\n-    _thread_oop(thread->threadObj()),\n-    _stacktrace(frames, max_frames),\n-    _closure(closure),\n-    _suspend_time() {}\n-\n-  void take_sample();\n-  void do_task(const SuspendedThreadTaskContext& context);\n-  void protected_task(const SuspendedThreadTaskContext& context);\n-  bool success() const { return _success; }\n-  const JfrStackTrace& stacktrace() const { return _stacktrace; }\n-\n- private:\n-  bool _success;\n-  oop _thread_oop;\n-  JfrStackTrace _stacktrace;\n-  JfrThreadSampleClosure& _closure;\n-  JfrTicks _suspend_time;\n-};\n-\n-class OSThreadSamplerCallback : public CrashProtectionCallback {\n- public:\n-  OSThreadSamplerCallback(OSThreadSampler& sampler, const SuspendedThreadTaskContext &context) :\n-    _sampler(sampler), _context(context) {\n-  }\n-  virtual void call() {\n-    _sampler.protected_task(_context);\n-  }\n- private:\n-  OSThreadSampler& _sampler;\n-  const SuspendedThreadTaskContext& _context;\n-};\n-\n-void OSThreadSampler::do_task(const SuspendedThreadTaskContext& context) {\n-#ifndef ASSERT\n-  guarantee(JfrOptionSet::sample_protection(), \"Sample Protection should be on in product builds\");\n-#endif\n-  assert(_suspend_time.value() == 0, \"already timestamped!\");\n-  _suspend_time = JfrTicks::now();\n-\n-  if (JfrOptionSet::sample_protection()) {\n-    OSThreadSamplerCallback cb(*this, context);\n-    ThreadCrashProtection crash_protection;\n-    if (!crash_protection.call(cb)) {\n-      log_error(jfr)(\"Thread method sampler crashed\");\n-    }\n-  } else {\n-    protected_task(context);\n-  }\n-}\n-\n-\/*\n-* From this method and down the call tree we attempt to protect against crashes\n-* using a signal handler \/ __try block. Don't take locks, rely on destructors or\n-* leave memory (in case of signal \/ exception) in an inconsistent state. *\/\n-void OSThreadSampler::protected_task(const SuspendedThreadTaskContext& context) {\n-  JavaThread* const jt = JavaThread::cast(context.thread());\n-  \/\/ Skip sample if we signaled a thread that moved to other state\n-  if (!thread_state_in_java(jt)) {\n-    return;\n-  }\n-  JfrGetCallTrace trace(true, jt);\n-  frame topframe;\n-  if (trace.get_topframe(context.ucontext(), topframe)) {\n-    if (_stacktrace.record_async(jt, topframe)) {\n-      \/* If we managed to get a topframe and a stacktrace, create an event\n-      * and put it into our array. We can't call Jfr::_stacktraces.add()\n-      * here since it would allocate memory using malloc. Doing so while\n-      * the stopped thread is inside malloc would deadlock. *\/\n-      _success = true;\n-      EventExecutionSample *ev = _closure.next_event();\n-      ev->set_starttime(_suspend_time);\n-      ev->set_endtime(_suspend_time); \/\/ fake to not take an end time\n-      ev->set_sampledThread(JfrThreadLocal::thread_id(jt));\n-      ev->set_state(static_cast<u8>(JavaThreadStatus::RUNNABLE));\n-    }\n-  }\n-}\n-\n-void OSThreadSampler::take_sample() {\n-  run();\n-}\n-\n-class JfrNativeSamplerCallback : public CrashProtectionCallback {\n- public:\n-  JfrNativeSamplerCallback(JfrThreadSampleClosure& closure, JavaThread* jt, JfrStackFrame* frames, u4 max_frames) :\n-    _closure(closure), _jt(jt), _thread_oop(jt->threadObj()), _stacktrace(frames, max_frames), _success(false) {\n-  }\n-  virtual void call();\n-  bool success() { return _success; }\n-  JfrStackTrace& stacktrace() { return _stacktrace; }\n-\n- private:\n-  JfrThreadSampleClosure& _closure;\n-  JavaThread* _jt;\n-  oop _thread_oop;\n-  JfrStackTrace _stacktrace;\n-  bool _success;\n-};\n-\n-static void write_native_event(JfrThreadSampleClosure& closure, JavaThread* jt, oop thread_oop) {\n-  EventNativeMethodSample *ev = closure.next_event_native();\n-  ev->set_starttime(JfrTicks::now());\n-  ev->set_sampledThread(JfrThreadLocal::thread_id(jt));\n-  ev->set_state(static_cast<u8>(JavaThreadStatus::RUNNABLE));\n-}\n-\n-void JfrNativeSamplerCallback::call() {\n-  \/\/ When a thread is only attach it will be native without a last java frame\n-  if (!_jt->has_last_Java_frame()) {\n-    return;\n-  }\n-\n-  frame topframe = _jt->last_frame();\n-  frame first_java_frame;\n-  Method* method = nullptr;\n-  JfrGetCallTrace gct(false, _jt);\n-  if (!gct.find_top_frame(topframe, &method, first_java_frame)) {\n-    return;\n-  }\n-  if (method == nullptr) {\n-    return;\n-  }\n-  topframe = first_java_frame;\n-  _success = _stacktrace.record_async(_jt, topframe);\n-  if (_success) {\n-    write_native_event(_closure, _jt, _thread_oop);\n-  }\n-}\n-\n-bool JfrThreadSampleClosure::sample_thread_in_java(JavaThread* thread, JfrStackFrame* frames, u4 max_frames) {\n-  \/\/ Process the oops in the thread head before calling into code that wants to\n-  \/\/ stack walk over Loom continuations. The stack walking code will otherwise\n-  \/\/ skip frames in stack chunks on the Java heap.\n-  StackWatermarkSet::start_processing(thread, StackWatermarkKind::gc);\n-\n-  OSThreadSampler sampler(thread, *this, frames, max_frames);\n-  sampler.take_sample();\n-  \/* We don't want to allocate any memory using malloc\/etc while the thread\n-  * is stopped, so everything is stored in stack allocated memory until this\n-  * point where the thread has been resumed again, if the sampling was a success\n-  * we need to store the stacktrace in the stacktrace repository and update\n-  * the event with the id that was returned. *\/\n-  if (!sampler.success()) {\n-    return false;\n-  }\n-  EventExecutionSample *event = &_events[_added_java - 1];\n-  traceid id = JfrStackTraceRepository::add(sampler.stacktrace());\n-  assert(id != 0, \"Stacktrace id should not be 0\");\n-  event->set_stackTrace(id);\n-  return true;\n-}\n-\n-bool JfrThreadSampleClosure::sample_thread_in_native(JavaThread* thread, JfrStackFrame* frames, u4 max_frames) {\n-  \/\/ Process the oops in the thread head before calling into code that wants to\n-  \/\/ stack walk over Loom continuations. The stack walking code will otherwise\n-  \/\/ skip frames in stack chunks on the Java heap.\n-  StackWatermarkSet::start_processing(thread, StackWatermarkKind::gc);\n-\n-  JfrNativeSamplerCallback cb(*this, thread, frames, max_frames);\n-  if (JfrOptionSet::sample_protection()) {\n-    ThreadCrashProtection crash_protection;\n-    if (!crash_protection.call(cb)) {\n-      log_error(jfr)(\"Thread method sampler crashed for native\");\n-    }\n-  } else {\n-    cb.call();\n-  }\n-  if (!cb.success()) {\n-    return false;\n-  }\n-  EventNativeMethodSample *event = &_events_native[_added_native - 1];\n-  traceid id = JfrStackTraceRepository::add(cb.stacktrace());\n-  assert(id != 0, \"Stacktrace id should not be 0\");\n-  event->set_stackTrace(id);\n-  return true;\n-}\n-\n-static const uint MAX_NR_OF_JAVA_SAMPLES = 5;\n-static const uint MAX_NR_OF_NATIVE_SAMPLES = 1;\n-\n-void JfrThreadSampleClosure::commit_events(JfrSampleType type) {\n-  if (JAVA_SAMPLE == type) {\n-    assert(_added_java > 0 && _added_java <= MAX_NR_OF_JAVA_SAMPLES, \"invariant\");\n-    if (EventExecutionSample::is_enabled()) {\n-      for (uint i = 0; i < _added_java; ++i) {\n-        _events[i].commit();\n-      }\n-    }\n-  } else {\n-    assert(NATIVE_SAMPLE == type, \"invariant\");\n-    assert(_added_native > 0 && _added_native <= MAX_NR_OF_NATIVE_SAMPLES, \"invariant\");\n-    if (EventNativeMethodSample::is_enabled()) {\n-      for (uint i = 0; i < _added_native; ++i) {\n-        _events_native[i].commit();\n-      }\n-    }\n-  }\n-}\n-\n-JfrThreadSampleClosure::JfrThreadSampleClosure(EventExecutionSample* events, EventNativeMethodSample* events_native) :\n-  _events(events),\n-  _events_native(events_native),\n-  _self(Thread::current()),\n-  _added_java(0),\n-  _added_native(0) {\n-}\n-\n-class JfrThreadSampler : public NonJavaThread {\n-  friend class JfrThreadSampling;\n+\/\/ The JfrSamplerThread suspends, if necessary, JavaThreads for sampling.\n+\/\/ It creates a sample description of the top Java frame, called a Jfr Sample Request.\n+\/\/ The request is installed into a thread-local queue associated with the sampled thread.\n+\/\/ Before resuming the sampled thread, its thread-local poll page is armed.\n+\/\/ This mechanism lets the sampled thread discover and process the installed\n+\/\/ sample request at its next safepoint poll instruction.\n+class JfrSamplerThread : public NonJavaThread {\n+  friend class JfrThreadSampler;\n@@ -341,2 +56,0 @@\n-  Thread* _sampler_thread;\n-  JfrStackFrame* const _frames;\n@@ -347,1 +60,0 @@\n-  const size_t _min_size; \/\/ for enqueue buffer monitoring\n@@ -352,3 +64,0 @@\n-  const JfrBuffer* get_enqueue_buffer();\n-  const JfrBuffer* renew_if_full(const JfrBuffer* enqueue_buffer);\n-\n@@ -356,3 +65,2 @@\n-  void task_stacktrace(JfrSampleType type, JavaThread** last_thread);\n-  JfrThreadSampler(int64_t java_period_millis, int64_t native_period_millis, u4 max_frames);\n-  ~JfrThreadSampler();\n+  void task_stacktrace(JfrSampleRequestType type, JavaThread** last_thread);\n+  JfrSamplerThread(int64_t java_period_millis, int64_t native_period_millis, u4 max_frames);\n@@ -366,0 +74,3 @@\n+  bool sample_java_thread(JavaThread* jt);\n+  bool sample_native_thread(JavaThread* jt);\n+\n@@ -367,0 +78,1 @@\n+  void run();\n@@ -368,0 +80,1 @@\n+\n@@ -369,2 +82,2 @@\n-  virtual const char* name() const { return \"JFR Thread Sampler\"; }\n-  virtual const char* type_name() const { return \"JfrThreadSampler\"; }\n+  virtual const char* name() const { return \"JFR Sampler Thread\"; }\n+  virtual const char* type_name() const { return \"JfrSamplerThread\"; }\n@@ -372,5 +85,2 @@\n-  void run();\n-  static Monitor* transition_block() { return JfrThreadSampler_lock; }\n-  static void on_javathread_suspend(JavaThread* thread);\n-  int64_t get_java_period() const { return Atomic::load(&_java_period_millis); };\n-  int64_t get_native_period() const { return Atomic::load(&_native_period_millis); };\n+  int64_t java_period() const { return Atomic::load(&_java_period_millis); };\n+  int64_t native_period() const { return Atomic::load(&_native_period_millis); };\n@@ -379,41 +89,1 @@\n-static void clear_transition_block(JavaThread* jt) {\n-  assert(Threads_lock->owned_by_self(), \"Holding the thread table lock.\");\n-  jt->clear_trace_flag();\n-  JfrThreadLocal* const tl = jt->jfr_thread_local();\n-  MutexLocker ml(JfrThreadSampler::transition_block(), Mutex::_no_safepoint_check_flag);\n-  if (tl->is_trace_block()) {\n-    JfrThreadSampler::transition_block()->notify();\n-  }\n-}\n-\n-static bool is_excluded(JavaThread* thread) {\n-  assert(thread != nullptr, \"invariant\");\n-  return thread->is_hidden_from_external_view() || thread->in_deopt_handler() || thread->jfr_thread_local()->is_excluded();\n-}\n-\n-bool JfrThreadSampleClosure::do_sample_thread(JavaThread* thread, JfrStackFrame* frames, u4 max_frames, JfrSampleType type) {\n-  assert(Threads_lock->owned_by_self(), \"Holding the thread table lock.\");\n-  if (is_excluded(thread)) {\n-    return false;\n-  }\n-\n-  bool ret = false;\n-  thread->set_trace_flag();  \/\/ Provides StoreLoad, needed to keep read of thread state from floating up.\n-  if (UseSystemMemoryBarrier) {\n-    SystemMemoryBarrier::emit();\n-  }\n-  if (JAVA_SAMPLE == type) {\n-    if (thread_state_in_java(thread)) {\n-      ret = sample_thread_in_java(thread, frames, max_frames);\n-    }\n-  } else {\n-    assert(NATIVE_SAMPLE == type, \"invariant\");\n-    if (thread_state_in_native(thread)) {\n-      ret = sample_thread_in_native(thread, frames, max_frames);\n-    }\n-  }\n-  clear_transition_block(thread);\n-  return ret;\n-}\n-\n-JfrThreadSampler::JfrThreadSampler(int64_t java_period_millis, int64_t native_period_millis, u4 max_frames) :\n+JfrSamplerThread::JfrSamplerThread(int64_t java_period_millis, int64_t native_period_millis, u4 max_frames) :\n@@ -421,2 +91,0 @@\n-  _sampler_thread(nullptr),\n-  _frames(JfrCHeapObj::new_array<JfrStackFrame>(max_frames)),\n@@ -427,1 +95,0 @@\n-  _min_size(max_frames * 2 * wordSize), \/\/ each frame tags at most 2 words, min size is a full stacktrace\n@@ -435,45 +102,3 @@\n-JfrThreadSampler::~JfrThreadSampler() {\n-  JfrCHeapObj::free(_frames, sizeof(JfrStackFrame) * _max_frames);\n-}\n-\n-void JfrThreadSampler::set_java_period(int64_t period_millis) {\n-  assert(period_millis >= 0, \"invariant\");\n-  Atomic::store(&_java_period_millis, period_millis);\n-}\n-\n-void JfrThreadSampler::set_native_period(int64_t period_millis) {\n-  assert(period_millis >= 0, \"invariant\");\n-  Atomic::store(&_native_period_millis, period_millis);\n-}\n-\n-static inline bool is_released(JavaThread* jt) {\n-  return !jt->is_trace_suspend();\n-}\n-\n-void JfrThreadSampler::on_javathread_suspend(JavaThread* thread) {\n-  if (is_released(thread)) {\n-    return;\n-  }\n-  JfrThreadLocal* const tl = thread->jfr_thread_local();\n-  MonitorLocker ml(transition_block(), Mutex::_no_safepoint_check_flag);\n-  tl->set_trace_block();\n-  while (!is_released(thread)) {\n-    ml.wait();\n-  }\n-  tl->clear_trace_block();\n-}\n-\n-JavaThread* JfrThreadSampler::next_thread(ThreadsList* t_list, JavaThread* first_sampled, JavaThread* current) {\n-  assert(t_list != nullptr, \"invariant\");\n-  assert(Threads_lock->owned_by_self(), \"Holding the thread table lock.\");\n-  assert(_cur_index >= -1 && (uint)_cur_index + 1 <= t_list->length(), \"invariant\");\n-  assert((current == nullptr && -1 == _cur_index) || (t_list->find_index_of_JavaThread(current) == _cur_index), \"invariant\");\n-  if ((uint)_cur_index + 1 == t_list->length()) {\n-    \/\/ wrap\n-    _cur_index = 0;\n-  } else {\n-    _cur_index++;\n-  }\n-  assert(_cur_index >= 0 && (uint)_cur_index < t_list->length(), \"invariant\");\n-  JavaThread* const next = t_list->thread_at(_cur_index);\n-  return next != first_sampled ? next : nullptr;\n+void JfrSamplerThread::post_run() {\n+  this->NonJavaThread::post_run();\n+  delete this;\n@@ -482,1 +107,1 @@\n-void JfrThreadSampler::start_thread() {\n+void JfrSamplerThread::start_thread() {\n@@ -490,1 +115,1 @@\n-void JfrThreadSampler::enroll() {\n+void JfrSamplerThread::enroll() {\n@@ -498,1 +123,1 @@\n-void JfrThreadSampler::disenroll() {\n+void JfrSamplerThread::disenroll() {\n@@ -506,1 +131,12 @@\n-static int64_t get_monotonic_ms() {\n+\/\/ Currently we only need to serialize a single thread state\n+\/\/ _thread_in_Java for the SafepointLatency event.\n+class VMThreadStateSerializer : public JfrSerializer {\n+ public:\n+  void serialize(JfrCheckpointWriter& writer) {\n+    writer.write_count(1);\n+    writer.write_key(_thread_in_Java);\n+    writer.write(\"_thread_in_Java\");\n+  }\n+};\n+\n+static inline int64_t get_monotonic_ms() {\n@@ -510,4 +146,2 @@\n-void JfrThreadSampler::run() {\n-  assert(_sampler_thread == nullptr, \"invariant\");\n-\n-  _sampler_thread = this;\n+void JfrSamplerThread::run() {\n+  JfrSerializer::register_serializer(TYPE_VMTHREADSTATE, true, new VMThreadStateSerializer());\n@@ -526,1 +160,1 @@\n-    int64_t java_period_millis = get_java_period();\n+    int64_t java_period_millis = java_period();\n@@ -528,1 +162,1 @@\n-    int64_t native_period_millis = get_native_period();\n+    int64_t native_period_millis = native_period();\n@@ -570,8 +204,13 @@\n-void JfrThreadSampler::post_run() {\n-  this->NonJavaThread::post_run();\n-  delete this;\n-}\n-\n-const JfrBuffer* JfrThreadSampler::get_enqueue_buffer() {\n-  const JfrBuffer* buffer = JfrTraceIdLoadBarrier::get_sampler_enqueue_buffer(this);\n-  return buffer != nullptr ? renew_if_full(buffer) : JfrTraceIdLoadBarrier::renew_sampler_enqueue_buffer(this);\n+JavaThread* JfrSamplerThread::next_thread(ThreadsList* t_list, JavaThread* first_sampled, JavaThread* current) {\n+  assert(t_list != nullptr, \"invariant\");\n+  assert(_cur_index >= -1 && (uint)_cur_index + 1 <= t_list->length(), \"invariant\");\n+  assert((current == nullptr && -1 == _cur_index) || (t_list->find_index_of_JavaThread(current) == _cur_index), \"invariant\");\n+  if ((uint)_cur_index + 1 == t_list->length()) {\n+    \/\/ wrap\n+    _cur_index = 0;\n+  } else {\n+    _cur_index++;\n+  }\n+  assert(_cur_index >= 0 && (uint)_cur_index < t_list->length(), \"invariant\");\n+  JavaThread* const next = t_list->thread_at(_cur_index);\n+  return next != first_sampled ? next : nullptr;\n@@ -580,3 +219,3 @@\n-const JfrBuffer* JfrThreadSampler::renew_if_full(const JfrBuffer* enqueue_buffer) {\n-  assert(enqueue_buffer != nullptr, \"invariant\");\n-  return enqueue_buffer->free_size() < _min_size ? JfrTraceIdLoadBarrier::renew_sampler_enqueue_buffer(this) : enqueue_buffer;\n+static inline bool is_excluded(JavaThread* jt) {\n+  assert(jt != nullptr, \"invariant\");\n+  return jt->is_Compiler_thread() || jt->is_hidden_from_external_view() || jt->is_JfrRecorder_thread() || jt->jfr_thread_local()->is_excluded();\n@@ -585,7 +224,2 @@\n-void JfrThreadSampler::task_stacktrace(JfrSampleType type, JavaThread** last_thread) {\n-  ResourceMark rm;\n-  EventExecutionSample samples[MAX_NR_OF_JAVA_SAMPLES];\n-  EventNativeMethodSample samples_native[MAX_NR_OF_NATIVE_SAMPLES];\n-  JfrThreadSampleClosure sample_task(samples, samples_native);\n-\n-  const uint sample_limit = JAVA_SAMPLE == type ? MAX_NR_OF_JAVA_SAMPLES : MAX_NR_OF_NATIVE_SAMPLES;\n+void JfrSamplerThread::task_stacktrace(JfrSampleRequestType type, JavaThread** last_thread) {\n+  const uint sample_limit = JAVA_SAMPLE == type ? 5 : 1;\n@@ -594,0 +228,2 @@\n+  elapsedTimer sample_time;\n+  sample_time.start();\n@@ -595,35 +231,28 @@\n-    elapsedTimer sample_time;\n-    sample_time.start();\n-    {\n-      MutexLocker tlock(Threads_lock);\n-      ThreadsListHandle tlh;\n-      \/\/ Resolve a sample session relative start position index into the thread list array.\n-      \/\/ In cases where the last sampled thread is null or not-null but stale, find_index() returns -1.\n-      _cur_index = tlh.list()->find_index_of_JavaThread(*last_thread);\n-      JavaThread* current = _cur_index != -1 ? *last_thread : nullptr;\n-\n-      \/\/ Explicitly monitor the available space of the thread-local buffer used by the load barrier\n-      \/\/ for enqueuing klasses as part of tagging methods. We do this because if space becomes sparse,\n-      \/\/ we cannot rely on the implicit allocation of a new buffer as part of the regular tag mechanism.\n-      \/\/ If the free list is empty, a malloc could result, and the problem with that is that the thread\n-      \/\/ we have suspended could be the holder of the malloc lock. Instead, the buffer is pre-emptively\n-      \/\/ renewed before thread suspension.\n-      const JfrBuffer* enqueue_buffer = get_enqueue_buffer();\n-      assert(enqueue_buffer != nullptr, \"invariant\");\n-\n-      while (num_samples < sample_limit) {\n-        current = next_thread(tlh.list(), start, current);\n-        if (current == nullptr) {\n-          break;\n-        }\n-        if (start == nullptr) {\n-          start = current;  \/\/ remember the thread where we started to attempt sampling\n-        }\n-        if (current->is_Compiler_thread()) {\n-          continue;\n-        }\n-        assert(enqueue_buffer->free_size() >= _min_size, \"invariant\");\n-        if (sample_task.do_sample_thread(current, _frames, _max_frames, type)) {\n-          num_samples++;\n-        }\n-        enqueue_buffer = renew_if_full(enqueue_buffer);\n+    MutexLocker tlock(Threads_lock);\n+    ThreadsListHandle tlh;\n+    \/\/ Resolve a sample session relative start position index into the thread list array.\n+    \/\/ In cases where the last sampled thread is null or not-null but stale, find_index() returns -1.\n+    _cur_index = tlh.list()->find_index_of_JavaThread(*last_thread);\n+    JavaThread* current = _cur_index != -1 ? *last_thread : nullptr;\n+\n+    \/\/ while (num_samples < sample_limit) {\n+    while (true) {\n+      current = next_thread(tlh.list(), start, current);\n+      if (current == nullptr) {\n+        break;\n+      }\n+      if (is_excluded(current)) {\n+        continue;\n+      }\n+      if (start == nullptr) {\n+        start = current; \/\/ remember the thread where we started to attempt sampling\n+      }\n+      bool success;\n+      if (JAVA_SAMPLE == type) {\n+        success = sample_java_thread(current);\n+      } else {\n+        assert(type == NATIVE_SAMPLE, \"invariant\");\n+        success = sample_native_thread(current);\n+      }\n+      if (success) {\n+        num_samples++;\n@@ -631,1 +260,0 @@\n-      *last_thread = current;  \/\/ remember the thread we last attempted to sample\n@@ -633,3 +261,1 @@\n-    sample_time.stop();\n-    log_trace(jfr)(\"JFR thread sampling done in %3.7f secs with %d java %d native samples\",\n-                   sample_time.seconds(), sample_task.java_entries(), sample_task.native_entries());\n+    *last_thread = current; \/\/ remember the thread we last attempted to sample\n@@ -637,2 +263,88 @@\n-  if (num_samples > 0) {\n-    sample_task.commit_events(type);\n+  sample_time.stop();\n+  log_trace(jfr)(\"JFR thread sampling done in %3.7f secs with %d java %d native samples\",\n+    sample_time.seconds(), type == JAVA_SAMPLE ? num_samples : 0, type == NATIVE_SAMPLE ? num_samples : 0);\n+}\n+\n+\/\/ Platform-specific thread suspension and CPU context retrieval.\n+class OSThreadSampler : public SuspendedThreadTask {\n+ private:\n+  JfrSampleResult _result;\n+ public:\n+  OSThreadSampler(JavaThread* jt) : SuspendedThreadTask(jt),\n+                                    _result(THREAD_SUSPENSION_ERROR) {}\n+  void request_sample() { run(); }\n+  JfrSampleResult result() const { return _result; }\n+\n+  void do_task(const SuspendedThreadTaskContext& context) {\n+    JavaThread* const jt = JavaThread::cast(context.thread());\n+    assert(jt != nullptr, \"invariant\");\n+    if (jt->thread_state() == _thread_in_Java) {\n+      JfrThreadLocal* const tl = jt->jfr_thread_local();\n+      if (tl->sample_state() == NO_SAMPLE) {\n+        _result = JfrSampleRequestBuilder::build_java_sample_request(context, tl, jt);\n+      }\n+    }\n+  }\n+};\n+\n+\/\/ Sampling a thread in state _thread_in_Java\n+\/\/ involves a platform-specific thread suspend and CPU context retrieval.\n+bool JfrSamplerThread::sample_java_thread(JavaThread* jt) {\n+  if (jt->thread_state() != _thread_in_Java) {\n+    return false;\n+  }\n+\n+  OSThreadSampler sampler(jt);\n+  sampler.request_sample();\n+\n+  if (sampler.result() != SAMPLE_JAVA) {\n+    \/\/ Wrong thread state or suspension error.\n+    return false;\n+  }\n+\n+  \/\/ If we get to do it before the sampled thread, we install\n+  \/\/ the new Jfr Sample Request into the thread-local queue\n+  \/\/ associated with the sampled thread. This makes the just\n+  \/\/ sampled thread eligible for yet another sample.\n+  JfrThreadLocal* const tl = jt->jfr_thread_local();\n+  JfrMutexTryLock lock(tl->sample_monitor());\n+  if (lock.acquired() && tl->sample_state() == JAVA_SAMPLE) {\n+    tl->enqueue_request();\n+    assert(tl->sample_state() == NO_SAMPLE, \"invariant\");\n+  }\n+  return true;\n+}\n+\n+static JfrSamplerThread* _sampler_thread = nullptr;\n+\n+\/\/ We can sample a JavaThread running in state _thread_in_native\n+\/\/ without thread suspension and CPU context retrieval,\n+\/\/ if we carefully order the loads of the thread state.\n+bool JfrSamplerThread::sample_native_thread(JavaThread* jt) {\n+  if (jt->thread_state() != _thread_in_native) {\n+    return false;\n+  }\n+\n+  JfrThreadLocal* const tl = jt->jfr_thread_local();\n+  assert(tl != nullptr, \"invariant\");\n+\n+  if (tl->sample_state() != NO_SAMPLE) {\n+    return false;\n+  }\n+\n+  tl->set_sample_state(NATIVE_SAMPLE);\n+\n+  SafepointMechanism::arm_local_poll_release(jt);\n+\n+  \/\/ Barriers needed to keep the next read of thread state from floating up.\n+  if (UseSystemMemoryBarrier) {\n+    SystemMemoryBarrier::emit();\n+  } else {\n+    OrderAccess::storeload();\n+  }\n+\n+  if (jt->thread_state() != _thread_in_native || !jt->has_last_Java_frame()) {\n+    MonitorLocker lock(tl->sample_monitor(), Monitor::_no_safepoint_check_flag);\n+    tl->set_sample_state(NO_SAMPLE);\n+    lock.notify_all();\n+    return false;\n@@ -640,0 +352,12 @@\n+\n+  return JfrThreadSampling::process_native_sample_request(tl, jt, _sampler_thread);\n+}\n+\n+void JfrSamplerThread::set_java_period(int64_t period_millis) {\n+  assert(period_millis >= 0, \"invariant\");\n+  Atomic::store(&_java_period_millis, period_millis);\n+}\n+\n+void JfrSamplerThread::set_native_period(int64_t period_millis) {\n+  assert(period_millis >= 0, \"invariant\");\n+  Atomic::store(&_native_period_millis, period_millis);\n@@ -642,1 +366,2 @@\n-static JfrThreadSampling* _instance = nullptr;\n+\/\/ JfrThreadSampler;\n+static JfrThreadSampler* _instance = nullptr;\n@@ -644,1 +369,1 @@\n-JfrThreadSampling& JfrThreadSampling::instance() {\n+JfrThreadSampler& JfrThreadSampler::instance() {\n@@ -648,1 +373,9 @@\n-JfrThreadSampling* JfrThreadSampling::create() {\n+JfrThreadSampler::JfrThreadSampler() {}\n+\n+JfrThreadSampler::~JfrThreadSampler() {\n+  if (_sampler_thread != nullptr) {\n+    _sampler_thread->disenroll();\n+  }\n+}\n+\n+JfrThreadSampler* JfrThreadSampler::create() {\n@@ -650,1 +383,1 @@\n-  _instance = new JfrThreadSampling();\n+  _instance = new JfrThreadSampler();\n@@ -654,1 +387,1 @@\n-void JfrThreadSampling::destroy() {\n+void JfrThreadSampler::destroy() {\n@@ -661,8 +394,0 @@\n-JfrThreadSampling::JfrThreadSampling() : _sampler(nullptr) {}\n-\n-JfrThreadSampling::~JfrThreadSampling() {\n-  if (_sampler != nullptr) {\n-    _sampler->disenroll();\n-  }\n-}\n-\n@@ -670,4 +395,4 @@\n-static void assert_periods(const JfrThreadSampler* sampler, int64_t java_period_millis, int64_t native_period_millis) {\n-  assert(sampler != nullptr, \"invariant\");\n-  assert(sampler->get_java_period() == java_period_millis, \"invariant\");\n-  assert(sampler->get_native_period() == native_period_millis, \"invariant\");\n+static void assert_periods(const JfrSamplerThread* sampler_thread, int64_t java_period_millis, int64_t native_period_millis) {\n+  assert(sampler_thread != nullptr, \"invariant\");\n+  assert(sampler_thread->java_period() == java_period_millis, \"invariant\");\n+  assert(sampler_thread->native_period() == native_period_millis, \"invariant\");\n@@ -681,2 +406,2 @@\n-void JfrThreadSampling::create_sampler(int64_t java_period_millis, int64_t native_period_millis) {\n-  assert(_sampler == nullptr, \"invariant\");\n+void JfrThreadSampler::create_sampler(int64_t java_period_millis, int64_t native_period_millis) {\n+  assert(_sampler_thread == nullptr, \"invariant\");\n@@ -684,3 +409,3 @@\n-  _sampler = new JfrThreadSampler(java_period_millis, native_period_millis, JfrOptionSet::stackdepth());\n-  _sampler->start_thread();\n-  _sampler->enroll();\n+  _sampler_thread = new JfrSamplerThread(java_period_millis, native_period_millis, JfrOptionSet::stackdepth());\n+  _sampler_thread->start_thread();\n+  _sampler_thread->enroll();\n@@ -689,1 +414,1 @@\n-void JfrThreadSampling::update_run_state(int64_t java_period_millis, int64_t native_period_millis) {\n+void JfrThreadSampler::update_run_state(int64_t java_period_millis, int64_t native_period_millis) {\n@@ -691,1 +416,1 @@\n-    if (_sampler == nullptr) {\n+    if (_sampler_thread == nullptr) {\n@@ -694,1 +419,1 @@\n-      _sampler->enroll();\n+      _sampler_thread->enroll();\n@@ -696,1 +421,1 @@\n-    DEBUG_ONLY(assert_periods(_sampler, java_period_millis, native_period_millis);)\n+    DEBUG_ONLY(assert_periods(_sampler_thread, java_period_millis, native_period_millis);)\n@@ -700,3 +425,3 @@\n-  if (_sampler != nullptr) {\n-    DEBUG_ONLY(assert_periods(_sampler, java_period_millis, native_period_millis);)\n-    _sampler->disenroll();\n+  if (_sampler_thread != nullptr) {\n+    DEBUG_ONLY(assert_periods(_sampler_thread, java_period_millis, native_period_millis);)\n+    _sampler_thread->disenroll();\n@@ -706,1 +431,1 @@\n-void JfrThreadSampling::set_sampling_period(bool is_java_period, int64_t period_millis) {\n+void JfrThreadSampler::set_period(bool is_java_period, int64_t period_millis) {\n@@ -711,3 +436,3 @@\n-    if (_sampler != nullptr) {\n-      _sampler->set_java_period(java_period_millis);\n-      native_period_millis = _sampler->get_native_period();\n+    if (_sampler_thread != nullptr) {\n+      _sampler_thread->set_java_period(java_period_millis);\n+      native_period_millis = _sampler_thread->native_period();\n@@ -717,3 +442,3 @@\n-    if (_sampler != nullptr) {\n-      _sampler->set_native_period(native_period_millis);\n-      java_period_millis = _sampler->get_java_period();\n+    if (_sampler_thread != nullptr) {\n+      _sampler_thread->set_native_period(native_period_millis);\n+      java_period_millis = _sampler_thread->java_period();\n@@ -725,1 +450,1 @@\n-void JfrThreadSampling::set_java_sample_period(int64_t period_millis) {\n+void JfrThreadSampler::set_java_sample_period(int64_t period_millis) {\n@@ -730,1 +455,1 @@\n-  instance().set_sampling_period(true, period_millis);\n+  instance().set_period(true, period_millis);\n@@ -733,1 +458,1 @@\n-void JfrThreadSampling::set_native_sample_period(int64_t period_millis) {\n+void JfrThreadSampler::set_native_sample_period(int64_t period_millis) {\n@@ -738,5 +463,1 @@\n-  instance().set_sampling_period(false, period_millis);\n-}\n-\n-void JfrThreadSampling::on_javathread_suspend(JavaThread* thread) {\n-  JfrThreadSampler::on_javathread_suspend(thread);\n+  instance().set_period(false, period_millis);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampler.cpp","additions":242,"deletions":521,"binary":false,"changes":763,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,4 +30,1 @@\n-class JavaThread;\n-class JfrThreadSampler;\n-\n-class JfrThreadSampling : public JfrCHeapObj {\n+class JfrThreadSampler : public JfrCHeapObj {\n@@ -36,1 +33,0 @@\n-  JfrThreadSampler* _sampler;\n@@ -39,1 +35,1 @@\n-  void set_sampling_period(bool is_java_period, int64_t period_millis);\n+  void set_period(bool is_java_period, int64_t period_millis);\n@@ -41,2 +37,2 @@\n-  JfrThreadSampling();\n-  ~JfrThreadSampling();\n+  JfrThreadSampler();\n+  ~JfrThreadSampler();\n@@ -44,2 +40,2 @@\n-  static JfrThreadSampling& instance();\n-  static JfrThreadSampling* create();\n+  static JfrThreadSampler& instance();\n+  static JfrThreadSampler* create();\n@@ -51,1 +47,0 @@\n-  static void on_javathread_suspend(JavaThread* thread);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampler.hpp","additions":7,"deletions":12,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -0,0 +1,351 @@\n+\/*\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"classfile\/javaThreadStatus.hpp\"\n+#include \"code\/codeCache.inline.hpp\"\n+#include \"code\/debugInfoRec.hpp\"\n+#include \"code\/nmethod.hpp\"\n+#include \"interpreter\/interpreter.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"jfr\/jfrEvents.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrSampleRequest.hpp\"\n+#include \"jfr\/periodic\/sampling\/jfrThreadSampling.hpp\"\n+#include \"jfr\/recorder\/stacktrace\/jfrStackTrace.hpp\"\n+#include \"jfr\/utilities\/jfrTypes.hpp\"\n+#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/javaThread.inline.hpp\"\n+#include \"runtime\/stackFrameStream.inline.hpp\"\n+\n+template <typename EventType>\n+static inline void send_sample_event(const JfrTicks& start_time, const JfrTicks& end_time, traceid sid, traceid tid) {\n+  EventType event(UNTIMED);\n+  event.set_starttime(start_time);\n+  event.set_endtime(end_time);\n+  event.set_sampledThread(tid);\n+  event.set_state(static_cast<u8>(JavaThreadStatus::RUNNABLE));\n+  event.set_stackTrace(sid);\n+  event.commit();\n+}\n+\n+static inline void send_safepoint_latency_event(const JfrSampleRequest& request, const JfrTicks& end_time, traceid sid, const JavaThread* jt) {\n+  assert(jt != nullptr, \"invariant\");\n+  assert(!jt->jfr_thread_local()->has_cached_stack_trace(), \"invariant\");\n+  EventSafepointLatency event(UNTIMED);\n+  event.set_starttime(request._sample_ticks);\n+  event.set_endtime(end_time);\n+  if (event.should_commit()) {\n+    event.set_threadState(_thread_in_Java);\n+    jt->jfr_thread_local()->set_cached_stack_trace_id(sid);\n+    event.commit();\n+    jt->jfr_thread_local()->clear_cached_stack_trace();\n+  }\n+}\n+\n+static inline bool is_interpreter(address pc) {\n+  return Interpreter::contains(pc);\n+}\n+\n+static inline bool is_interpreter(const JfrSampleRequest& request) {\n+  return request._sample_bcp != nullptr;\n+}\n+\n+\/\/ A sampled interpreter frame is handled differently compared to a sampled compiler frame.\n+\/\/ The JfrSampleRequest description already holds the top java frame saved by the sampler thread.\n+\/\/ The 'top_frame' that is filled by this routine is instead the sender frame of the interpreter\n+\/\/ top frame already described in the sample request.\n+static bool compute_sender_frame(const JfrSampleRequest& request, frame& sender_frame, JavaThread* jt) {\n+  assert(is_interpreter(request), \"invariant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(jt->has_last_Java_frame(), \"invariant\");\n+\n+  \/\/ For a request representing an interpreter frame, request._sample_sp is actually the frame pointer, fp.\n+  const void* const sampled_fp = request._sample_sp;\n+\n+  StackFrameStream stream(jt, false, false);\n+  if (stream.current()->is_safepoint_blob_frame()) {\n+    stream.next();\n+  }\n+  assert(!stream.current()->is_safepoint_blob_frame(), \"invariant\");\n+\n+  \/\/ Search the first frame that is above the sampled fp. This is the sender frame to return.\n+  for (; !stream.is_done(); stream.next()) {\n+    frame* const current = stream.current();\n+    if (current->real_fp() <= sampled_fp) {\n+      continue;\n+    }\n+    sender_frame = *current;\n+    return true;\n+  }\n+  \/\/ There is only a single interpreter frame on stack- leave sender_frame empty.\n+  return true;\n+}\n+\n+static inline const PcDesc* get_pc_desc(nmethod* nm, void* pc) {\n+  assert(nm != nullptr, \"invariant\");\n+  assert(pc != nullptr, \"invariant\");\n+  return nm->pc_desc_near(static_cast<address>(pc));\n+}\n+\n+static inline bool is_valid(const PcDesc* pc_desc) {\n+  return pc_desc != nullptr && pc_desc->scope_decode_offset() != DebugInformationRecorder::serialized_null;\n+}\n+\n+static bool compute_top_frame(const JfrSampleRequest& request, frame& top_frame, JavaThread* jt) {\n+  assert(jt != nullptr, \"invariant\");\n+\n+  if (!jt->has_last_Java_frame()) {\n+    return false;\n+  }\n+\n+  if (is_interpreter(request)) {\n+    return compute_sender_frame(request, top_frame, jt);\n+  }\n+\n+  void* const sampled_pc = request._sample_pc;\n+  if (sampled_pc == nullptr) {\n+    \/\/ A biased sample is requested.\n+    top_frame = jt->last_frame();\n+    return true;\n+  }\n+\n+  CodeBlob* const sampled_cb = CodeCache::find_blob(sampled_pc);\n+  if (sampled_cb == nullptr) {\n+    \/\/ No code blob... probably native code. Perform a biased sample.\n+    top_frame = jt->last_frame();\n+    return true;\n+  }\n+\n+  \/\/ We will never describe a sample request that represents an unparsable stub or blob.\n+  assert(sampled_cb->frame_complete_offset() != CodeOffsets::frame_never_safe, \"invariant\");\n+\n+  const void* const sampled_sp = request._sample_sp;\n+  assert(sampled_sp != nullptr, \"invariant\");\n+\n+  nmethod* const sampled_nm = sampled_cb->as_nmethod_or_null();\n+\n+  StackFrameStream stream(jt, false \/* update registers *\/, false \/* process frames *\/);\n+\n+  if (stream.current()->is_safepoint_blob_frame()) {\n+    if (sampled_nm != nullptr) {\n+      \/\/ Move to the physical sender frame of the SafepointBlob stub frame using the frame size, not the logical iterator.\n+      const int safepoint_blob_stub_frame_size = stream.current()->cb()->frame_size();\n+      intptr_t* const sender_sp = stream.current()->unextended_sp() + safepoint_blob_stub_frame_size;\n+      if (sender_sp > sampled_sp) {\n+        const address saved_exception_pc = jt->saved_exception_pc();\n+        assert(saved_exception_pc != nullptr, \"invariant\");\n+        const nmethod* const exception_nm = CodeCache::find_blob(saved_exception_pc)->as_nmethod();\n+        assert(exception_nm != nullptr, \"invariant\");\n+        if (exception_nm == sampled_nm && sampled_nm->is_at_poll_return(saved_exception_pc)) {\n+          \/\/ We sit at the poll return site in the sampled compiled nmethod with only the return address on the stack.\n+          \/\/ The sampled_nm compiled frame is no longer extant, but we might be able to reconstruct a synthetic\n+          \/\/ compiled frame at this location. We do this by overlaying a reconstructed frame on top of\n+          \/\/ the huge SafepointBlob stub frame. Of course, the synthetic frame only contains random stack memory,\n+          \/\/ but it is safe because stack walking cares only about the form of the frame (i.e., an sp and a pc).\n+          \/\/ We also do not have to worry about stackbanging because we currently have a huge SafepointBlob stub frame\n+          \/\/ on the stack. For extra assurance, we know that we can create this frame size at this\n+          \/\/ very location because we just popped such a frame before we hit the return poll site.\n+          \/\/\n+          \/\/ Let's attempt to correct for the safepoint bias.\n+          const PcDesc* pc_desc = get_pc_desc(sampled_nm, sampled_pc);\n+          if (is_valid(pc_desc)) {\n+            assert(CodeCache::find_blob(pc_desc->real_pc(sampled_nm)) == sampled_nm, \"invariant\");\n+            intptr_t* const synthetic_sp = sender_sp - sampled_nm->frame_size();\n+            top_frame = frame(synthetic_sp, synthetic_sp, sender_sp, pc_desc->real_pc(sampled_nm), sampled_nm);\n+            return true;\n+          }\n+        }\n+      }\n+    }\n+    stream.next(); \/\/ skip the SafepointBlob stub frame\n+  }\n+\n+  assert(!stream.current()->is_safepoint_blob_frame(), \"invariant\");\n+\n+  \/\/ Search the first frame that is above the sampled sp.\n+  for (; !stream.is_done(); stream.next()) {\n+    frame* const current = stream.current();\n+\n+    if (current->real_fp() <= sampled_sp) {\n+      \/\/ Continue searching for a matching frame.\n+      continue;\n+    }\n+\n+    if (sampled_nm == nullptr) {\n+      \/\/ The sample didn't have an nmethod; we decide to trace from its sender.\n+      \/\/ Another instance of safepoint bias.\n+      top_frame = *current;\n+      return true;\n+    }\n+\n+    \/\/ Check for a matching compiled method.\n+    if (current->cb()->as_nmethod_or_null() == sampled_nm) {\n+      if (current->pc() != sampled_pc) {\n+        \/\/ Let's adjust for the safepoint bias if we can.\n+        const PcDesc* const pc_desc = get_pc_desc(sampled_nm, sampled_pc);\n+        if (is_valid(pc_desc)) {\n+          current->adjust_pc(pc_desc->real_pc(sampled_nm));\n+        }\n+      }\n+      top_frame = *current;\n+      return true;\n+    }\n+    \/\/ A mismatched sample in which case we trace from the sender.\n+    \/\/ Yet another instance of safepoint bias,to be addressed with\n+    \/\/ more exact and stricter versions when parsable blobs become available.\n+    top_frame = *current;\n+    return true;\n+  }\n+\n+  assert(false, \"Should not reach here\");\n+  return false;\n+}\n+\n+static void record_thread_in_java(const JfrSampleRequest& request, const JfrTicks& now, JavaThread* jt, Thread* current) {\n+  assert(jt != nullptr, \"invariant\");\n+  assert(current != nullptr, \"invariant\");\n+  frame top_frame;\n+  if (!compute_top_frame(request, top_frame, jt)) {\n+    return;\n+  }\n+  traceid sid;\n+  {\n+    ResourceMark rm(current);\n+    JfrStackTrace stacktrace;\n+    if (!stacktrace.record(jt, top_frame, request)) {\n+      \/\/ Unable to record stacktrace. Fail.\n+      return;\n+    }\n+    sid = JfrStackTraceRepository::add(stacktrace);\n+  }\n+  assert(sid != 0, \"invariant\");\n+  const traceid tid = JfrThreadLocal::thread_id(jt);\n+  send_sample_event<EventExecutionSample>(request._sample_ticks, now, sid, tid);\n+  if (current == jt) {\n+    send_safepoint_latency_event(request, now, sid, jt);\n+  }\n+}\n+\n+static void drain_enqueued_requests(const JfrTicks& now, JfrThreadLocal* tl, JavaThread* jt, Thread* current) {\n+  assert(tl != nullptr, \"invariant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(current != nullptr, \"invariant\");\n+  assert(jt->jfr_thread_local() == tl, \"invariant\");\n+  assert_lock_strong(tl->sample_monitor());\n+  if (tl->has_enqueued_requests()) {\n+    for (const JfrSampleRequest& request : *tl->sample_requests()) {\n+      record_thread_in_java(request, now, jt, current);\n+    }\n+    tl->clear_enqueued_requests();\n+  }\n+  assert(!tl->has_enqueued_requests(), \"invariant\");\n+}\n+\n+class SampleMonitor : public StackObj {\n+ private:\n+  JfrThreadLocal* const _tl;\n+  Monitor* const _sample_monitor;\n+ public:\n+  SampleMonitor(JfrThreadLocal* tl) : _tl(tl), _sample_monitor(tl->sample_monitor()) {\n+    assert(tl != nullptr, \"invariant\");\n+    assert(_sample_monitor != nullptr, \"invariant\");\n+    _sample_monitor->lock_without_safepoint_check();\n+  }\n+  ~SampleMonitor() {\n+    assert_lock_strong(_sample_monitor);\n+    _tl->set_sample_state(NO_SAMPLE);\n+    _sample_monitor->notify_all();\n+    _sample_monitor->unlock();\n+  }\n+};\n+\n+\/\/ Only entered by the JfrSampler thread.\n+bool JfrThreadSampling::process_native_sample_request(JfrThreadLocal* tl, JavaThread* jt, Thread* sampler_thread) {\n+  assert(tl != nullptr, \"invairant\");\n+  assert(jt != nullptr, \"invariant\");\n+  assert(sampler_thread != nullptr, \"invariant\");\n+  assert(sampler_thread->is_JfrSampler_thread(), \"invariant\");\n+  assert(tl == jt->jfr_thread_local(), \"invariant\");\n+  assert(jt != sampler_thread, \"only asynchronous processing of native samples\");\n+  assert(jt->has_last_Java_frame(), \"invariant\");\n+  assert(tl->sample_state() == NATIVE_SAMPLE, \"invariant\");\n+\n+  const JfrTicks start_time = JfrTicks::now();\n+\n+  traceid tid;\n+  traceid sid;\n+\n+  {\n+    SampleMonitor sm(tl);\n+\n+    \/\/ Because the thread was in native, it is in a walkable state, because\n+    \/\/ it will hit a safepoint poll on the way back from native. To ensure timely\n+    \/\/ progress, any requests in the queue can be safely processed now.\n+    drain_enqueued_requests(start_time, tl, jt, sampler_thread);\n+    \/\/ Process the current stacktrace using the ljf.\n+    {\n+      ResourceMark rm(sampler_thread);\n+      JfrStackTrace stacktrace;\n+      const frame top_frame = jt->last_frame();\n+      if (!stacktrace.record_inner(jt, top_frame, 0 \/* skip level *\/)) {\n+        \/\/ Unable to record stacktrace. Fail.\n+        return false;\n+      }\n+      sid = JfrStackTraceRepository::add(stacktrace);\n+    }\n+    \/\/ Read the tid under the monitor to ensure that if its a virtual thread,\n+    \/\/ it is not unmounted until we are done with it.\n+    tid = JfrThreadLocal::thread_id(jt);\n+  }\n+\n+  assert(tl->sample_state() == NO_SAMPLE, \"invariant\");\n+  send_sample_event<EventNativeMethodSample>(start_time, start_time, sid, tid);\n+  return true;\n+}\n+\n+\/\/ Entry point for a sampled thread that discovered pending Jfr Sample Requests as part of a safepoint poll.\n+void JfrThreadSampling::process_sample_request(JavaThread* jt) {\n+  assert(JavaThread::current() == jt, \"should be current thread\");\n+  assert(jt->thread_state() == _thread_in_vm || jt->thread_state() == _thread_in_Java, \"invariant\");\n+\n+  const JfrTicks now = JfrTicks::now();\n+\n+  JfrThreadLocal* const tl = jt->jfr_thread_local();\n+  assert(tl != nullptr, \"invariant\");\n+\n+  MonitorLocker ml(tl->sample_monitor(), Monitor::_no_safepoint_check_flag);\n+\n+  for (;;) {\n+    const int sample_state = tl->sample_state();\n+    if (sample_state == NATIVE_SAMPLE) {\n+      \/\/ Wait until stack trace is processed.\n+      ml.wait();\n+    } else if (sample_state == JAVA_SAMPLE) {\n+      tl->enqueue_request();\n+    } else {\n+      \/\/ State has been processed.\n+      break;\n+    }\n+  }\n+  drain_enqueued_requests(now, tl, jt, jt);\n+}\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampling.cpp","additions":351,"deletions":0,"binary":false,"changes":351,"status":"added"},{"patch":"@@ -0,0 +1,42 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_JFR_PERIODIC_SAMPLING_JFRTHREADSAMPLING_HPP\n+#define SHARE_JFR_PERIODIC_SAMPLING_JFRTHREADSAMPLING_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+\n+class JavaThread;\n+class JfrThreadLocal;\n+class Thread;\n+\n+class JfrThreadSampling : AllStatic {\n+  friend class JfrSamplerThread;\n+ private:\n+  static bool process_native_sample_request(JfrThreadLocal* tl, JavaThread* jt, Thread* sampler_thread);\n+ public:\n+  static void process_sample_request(JavaThread* jt);\n+};\n+\n+#endif \/\/ SHARE_JFR_PERIODIC_SAMPLING_JFRTHREADSAMPLING_HPP\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampling.hpp","additions":42,"deletions":0,"binary":false,"changes":42,"status":"added"},{"patch":"@@ -304,1 +304,1 @@\n-  if (!create_thread_sampling()) {\n+  if (!create_thread_sampler()) {\n@@ -320,1 +320,1 @@\n-static JfrThreadSampling* _thread_sampling = nullptr;\n+static JfrThreadSampler* _thread_sampler = nullptr;\n@@ -387,4 +387,4 @@\n-bool JfrRecorder::create_thread_sampling() {\n-  assert(_thread_sampling == nullptr, \"invariant\");\n-  _thread_sampling = JfrThreadSampling::create();\n-  return _thread_sampling != nullptr;\n+bool JfrRecorder::create_thread_sampler() {\n+  assert(_thread_sampler == nullptr, \"invariant\");\n+  _thread_sampler = JfrThreadSampler::create();\n+  return _thread_sampler != nullptr;\n@@ -427,3 +427,3 @@\n-  if (_thread_sampling != nullptr) {\n-    JfrThreadSampling::destroy();\n-    _thread_sampling = nullptr;\n+  if (_thread_sampler != nullptr) {\n+    JfrThreadSampler::destroy();\n+    _thread_sampler = nullptr;\n@@ -435,1 +435,1 @@\n-  return JfrRecorderThread::start(_checkpoint_manager, _post_box, JavaThread::current());\n+  return JfrRecorderThreadEntry::start(_checkpoint_manager, _post_box, JavaThread::current());\n","filename":"src\/hotspot\/share\/jfr\/recorder\/jfrRecorder.cpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,1 +56,1 @@\n-  static bool create_thread_sampling();\n+  static bool create_thread_sampler();\n","filename":"src\/hotspot\/share\/jfr\/recorder\/jfrRecorder.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -37,1 +37,2 @@\n-static JfrEventThrottler* _throttler = nullptr;\n+static JfrEventThrottler* _object_allocation_throttler = nullptr;\n+static JfrEventThrottler* _safepoint_latency_throttler = nullptr;\n@@ -50,3 +51,8 @@\n-  assert(_throttler == nullptr, \"invariant\");\n-  _throttler = new JfrEventThrottler(JfrObjectAllocationSampleEvent);\n-  return _throttler != nullptr && _throttler->initialize();\n+  assert(_object_allocation_throttler == nullptr, \"invariant\");\n+  _object_allocation_throttler = new JfrEventThrottler(JfrObjectAllocationSampleEvent);\n+  if (_object_allocation_throttler == nullptr || !_object_allocation_throttler->initialize()) {\n+    return false;\n+  }\n+  assert(_safepoint_latency_throttler == nullptr, \"invariant\");\n+  _safepoint_latency_throttler = new JfrEventThrottler(JfrSafepointLatencyEvent);\n+  return _safepoint_latency_throttler != nullptr && _safepoint_latency_throttler->initialize();\n@@ -56,2 +62,4 @@\n-  delete _throttler;\n-  _throttler = nullptr;\n+  delete _object_allocation_throttler;\n+  _object_allocation_throttler = nullptr;\n+  delete _safepoint_latency_throttler;\n+  _safepoint_latency_throttler = nullptr;\n@@ -60,2 +68,3 @@\n-\/\/ There is currently only one throttler instance, for the jdk.ObjectAllocationSample event.\n-\/\/ When introducing additional throttlers, also add a lookup map keyed by event id.\n+\/\/ There is currently only two throttler instances, one for the jdk.ObjectAllocationSample event\n+\/\/ and another for the SamplingLatency event.\n+\/\/ When introducing many more throttlers, consider adding a lookup map keyed by event id.\n@@ -63,3 +72,10 @@\n-  assert(_throttler != nullptr, \"JfrEventThrottler has not been properly initialized\");\n-  assert(event_id == JfrObjectAllocationSampleEvent, \"Event type has an unconfigured throttler\");\n-  return event_id == JfrObjectAllocationSampleEvent ? _throttler : nullptr;\n+  assert(_object_allocation_throttler != nullptr, \"ObjectAllocation throttler has not been properly initialized\");\n+  assert(_safepoint_latency_throttler != nullptr, \"SafepointLatency throttler has not been properly initialized\");\n+  assert(event_id == JfrObjectAllocationSampleEvent || event_id == JfrSafepointLatencyEvent, \"Event type has an unconfigured throttler\");\n+  if (event_id == JfrObjectAllocationSampleEvent) {\n+    return _object_allocation_throttler;\n+  }\n+  if (event_id == JfrSafepointLatencyEvent) {\n+    return _safepoint_latency_throttler;\n+  }\n+  return nullptr;\n@@ -69,1 +85,3 @@\n-  if (event_id != JfrObjectAllocationSampleEvent) {\n+  if (event_id == JfrObjectAllocationSampleEvent) {\n+    assert(_object_allocation_throttler != nullptr, \"ObjectAllocation throttler has not been properly initialized\");\n+    _object_allocation_throttler->configure(sample_size, period_ms);\n@@ -72,2 +90,4 @@\n-  assert(_throttler != nullptr, \"JfrEventThrottler has not been properly initialized\");\n-  _throttler->configure(sample_size, period_ms);\n+  if (event_id == JfrSafepointLatencyEvent) {\n+    assert(_safepoint_latency_throttler != nullptr, \"SafepointLatency throttler has not been properly initialized\");\n+    _safepoint_latency_throttler->configure(sample_size, period_ms);\n+  }\n@@ -95,2 +115,2 @@\n-  if (throttler == nullptr) return true;\n-  return _throttler->_disabled ? true : _throttler->sample(timestamp);\n+  assert(throttler != nullptr, \"invariant\");\n+  return throttler->_disabled ? true : throttler->sample(timestamp);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/service\/jfrEventThrottler.cpp","additions":36,"deletions":16,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -39,0 +39,8 @@\n+class JfrRecorderThread : public JavaThread {\n+ public:\n+  JfrRecorderThread(ThreadFunction entry_point) : JavaThread(entry_point) {}\n+  virtual ~JfrRecorderThread() {}\n+\n+  virtual bool is_JfrRecorder_thread() const { return true; }\n+};\n+\n@@ -43,1 +51,1 @@\n-  JavaThread* new_thread = new JavaThread(proc);\n+  JfrRecorderThread* new_thread = new JfrRecorderThread(proc);\n@@ -57,1 +65,1 @@\n-JfrPostBox* JfrRecorderThread::_post_box = nullptr;\n+JfrPostBox* JfrRecorderThreadEntry::_post_box = nullptr;\n@@ -59,1 +67,1 @@\n-JfrPostBox& JfrRecorderThread::post_box() {\n+JfrPostBox& JfrRecorderThreadEntry::post_box() {\n@@ -66,1 +74,1 @@\n-bool JfrRecorderThread::start(JfrCheckpointManager* cp_manager, JfrPostBox* post_box, TRAPS) {\n+bool JfrRecorderThreadEntry::start(JfrCheckpointManager* cp_manager, JfrPostBox* post_box, TRAPS) {\n","filename":"src\/hotspot\/share\/jfr\/recorder\/service\/jfrRecorderThread.cpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,1 +36,1 @@\n-class JfrRecorderThread : AllStatic {\n+class JfrRecorderThreadEntry : AllStatic {\n","filename":"src\/hotspot\/share\/jfr\/recorder\/service\/jfrRecorderThread.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-  JfrPostBox& post_box = JfrRecorderThread::post_box();\n+  JfrPostBox& post_box = JfrRecorderThreadEntry::post_box();\n","filename":"src\/hotspot\/share\/jfr\/recorder\/service\/jfrRecorderThreadLoop.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -80,3 +80,1 @@\n-  if (id < 0) {\n-    return nullptr;\n-  }\n+  assert(id >= 0, \"invariant\");\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackFilterRegistry.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,66 @@\n+\/*\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"jfr\/recorder\/checkpoint\/jfrCheckpointWriter.hpp\"\n+#include \"jfr\/recorder\/repository\/jfrChunkWriter.hpp\"\n+#include \"jfr\/recorder\/stacktrace\/jfrStackFrame.hpp\"\n+#include \"jfr\/support\/jfrMethodLookup.hpp\"\n+#include \"oops\/method.inline.hpp\"\n+\n+JfrStackFrame::JfrStackFrame() : _klass(nullptr), _methodid(0), _line(0), _bci(0), _type(0) {}\n+\n+JfrStackFrame::JfrStackFrame(const traceid& id, int bci, u1 type, const InstanceKlass* ik) :\n+  _klass(ik), _methodid(id), _line(0), _bci(bci), _type(type) {}\n+\n+JfrStackFrame::JfrStackFrame(const traceid& id, int bci, u1 type, int lineno, const InstanceKlass* ik) :\n+  _klass(ik), _methodid(id), _line(lineno), _bci(bci), _type(type) {}\n+\n+template <typename Writer>\n+static void write_frame(Writer& w, traceid methodid, int line, int bci, u1 type) {\n+  w.write(methodid);\n+  w.write(static_cast<u4>(line));\n+  w.write(static_cast<u4>(bci));\n+  w.write(static_cast<u8>(type));\n+}\n+\n+void JfrStackFrame::write(JfrChunkWriter& cw) const {\n+  write_frame(cw, _methodid, _line, _bci, _type);\n+}\n+\n+void JfrStackFrame::write(JfrCheckpointWriter& cpw) const {\n+  write_frame(cpw, _methodid, _line, _bci, _type);\n+}\n+\n+bool JfrStackFrame::equals(const JfrStackFrame& rhs) const {\n+  return _methodid == rhs._methodid && _bci == rhs._bci && _type == rhs._type;\n+}\n+\n+void JfrStackFrame::resolve_lineno() const {\n+  assert(_klass, \"no klass pointer\");\n+  assert(_line == 0, \"already have linenumber\");\n+  const Method* const method = JfrMethodLookup::lookup(_klass, _methodid);\n+  assert(method != nullptr, \"invariant\");\n+  assert(method->method_holder() == _klass, \"invariant\");\n+  _line = method->line_number_from_bci(_bci);\n+}\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackFrame.cpp","additions":66,"deletions":0,"binary":false,"changes":66,"status":"added"},{"patch":"@@ -0,0 +1,67 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_JFR_RECORDER_STACKTRACE_JFRSTACKFRAME_HPP\n+#define SHARE_JFR_RECORDER_STACKTRACE_JFRSTACKFRAME_HPP\n+\n+#include \"jfr\/utilities\/jfrTypes.hpp\"\n+\n+class JfrCheckpointWriter;\n+class JfrChunkWriter;\n+class InstanceKlass;\n+\n+class JfrStackFrame {\n+  friend class ObjectSampleCheckpoint;\n+ private:\n+  const InstanceKlass* _klass;\n+  traceid _methodid;\n+  mutable int _line;\n+  int _bci;\n+  u1 _type;\n+\n+ public:\n+  JfrStackFrame();\n+  JfrStackFrame(const traceid& id, int bci, u1 type, const InstanceKlass* klass);\n+  JfrStackFrame(const traceid& id, int bci, u1 type, int lineno, const InstanceKlass* klass);\n+\n+  bool equals(const JfrStackFrame& rhs) const;\n+  void write(JfrChunkWriter& cw) const;\n+  void write(JfrCheckpointWriter& cpw) const;\n+  void resolve_lineno() const;\n+\n+  enum : u1 {\n+    FRAME_INTERPRETER = 0,\n+    FRAME_JIT,\n+    FRAME_INLINE,\n+    FRAME_NATIVE,\n+    NUM_FRAME_TYPES\n+  };\n+};\n+\n+template <typename>\n+class GrowableArray;\n+\n+typedef GrowableArray<JfrStackFrame> JfrStackFrames;\n+\n+#endif \/\/ SHARE_JFR_RECORDER_STACKTRACE_JFRSTACKFRAME_HPP\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackFrame.hpp","additions":67,"deletions":0,"binary":false,"changes":67,"status":"added"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"jfr\/recorder\/stacktrace\/jfrVframeStream.inline.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"jfr\/support\/jfrMethodLookup.hpp\"\n@@ -35,0 +35,1 @@\n+#include \"nmt\/memTag.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -41,1 +43,1 @@\n-static void copy_frames(JfrStackFrame** lhs_frames, u4 length, const JfrStackFrame* rhs_frames) {\n+static void copy_frames(JfrStackFrames* lhs_frames, const JfrStackFrames* rhs_frames) {\n@@ -44,4 +46,6 @@\n-  if (length > 0) {\n-    *lhs_frames = NEW_C_HEAP_ARRAY(JfrStackFrame, length, mtTracing);\n-    memcpy(*lhs_frames, rhs_frames, length * sizeof(JfrStackFrame));\n-  }\n+  assert(rhs_frames->length() > 0, \"invariant\");\n+  assert(lhs_frames->capacity() == rhs_frames->length(), \"invariant\");\n+  assert(lhs_frames->length() == 0, \"invariant\");\n+  lhs_frames->set_length(rhs_frames->length());\n+  assert(lhs_frames->length() == rhs_frames->length(), \"invariant\");\n+  memcpy(&lhs_frames->first(), &rhs_frames->first(), rhs_frames->length() * sizeof(JfrStackFrame));\n@@ -50,7 +54,1 @@\n-JfrStackFrame::JfrStackFrame(const traceid& id, int bci, u1 type, const InstanceKlass* ik) :\n-  _klass(ik), _methodid(id), _line(0), _bci(bci), _type(type) {}\n-\n-JfrStackFrame::JfrStackFrame(const traceid& id, int bci, u1 type, int lineno, const InstanceKlass* ik) :\n-  _klass(ik), _methodid(id), _line(lineno), _bci(bci), _type(type) {}\n-\n-JfrStackTrace::JfrStackTrace(JfrStackFrame* frames, u4 max_frames) :\n+JfrStackTrace::JfrStackTrace() :\n@@ -58,1 +56,1 @@\n-  _frames(frames),\n+  _frames(new JfrStackFrames(JfrOptionSet::stackdepth())), \/\/ ResourceArea\n@@ -61,2 +59,2 @@\n-  _nr_of_frames(0),\n-  _max_frames(max_frames),\n+  _count(0),\n+  _max_frames(JfrOptionSet::stackdepth()),\n@@ -70,1 +68,1 @@\n-  _frames(nullptr),\n+  _frames(new (mtInternal) JfrStackFrames(trace.number_of_frames(), mtInternal)), \/\/ CHeap\n@@ -73,1 +71,1 @@\n-  _nr_of_frames(trace._nr_of_frames),\n+  _count(trace._count),\n@@ -79,1 +77,1 @@\n-  copy_frames(&_frames, trace._nr_of_frames, trace._frames);\n+  copy_frames(_frames, trace._frames);\n@@ -84,1 +82,2 @@\n-    FREE_C_HEAP_ARRAY(JfrStackFrame, _frames);\n+    delete _frames;\n+    return;\n@@ -88,0 +87,5 @@\n+int JfrStackTrace::number_of_frames() const {\n+  assert(_frames != nullptr, \"invariant\");\n+  return _frames->length();\n+}\n+\n@@ -89,6 +93,7 @@\n-static void write_stacktrace(Writer& w, traceid id, bool reached_root, u4 nr_of_frames, const JfrStackFrame* frames) {\n-  w.write((u8)id);\n-  w.write((u1)!reached_root);\n-  w.write(nr_of_frames);\n-  for (u4 i = 0; i < nr_of_frames; ++i) {\n-    frames[i].write(w);\n+static void write_stacktrace(Writer& w, traceid id, bool reached_root, const JfrStackFrames* frames) {\n+  w.write(static_cast<u8>(id));\n+  w.write(static_cast<u1>(!reached_root));\n+  const int nr_of_frames = frames->length();\n+  w.write(static_cast<u4>(nr_of_frames));\n+  for (int i = 0; i < nr_of_frames; ++i) {\n+    frames->at(i).write(w);\n@@ -100,1 +105,1 @@\n-  write_stacktrace(sw, _id, _reached_root, _nr_of_frames, _frames);\n+  write_stacktrace(sw, _id, _reached_root, _frames);\n@@ -106,1 +111,1 @@\n-  write_stacktrace(cpw, _id, _reached_root, _nr_of_frames, _frames);\n+  write_stacktrace(cpw, _id, _reached_root, _frames);\n@@ -110,4 +115,0 @@\n-bool JfrStackFrame::equals(const JfrStackFrame& rhs) const {\n-  return _methodid == rhs._methodid && _bci == rhs._bci && _type == rhs._type;\n-}\n-\n@@ -115,1 +116,1 @@\n-  if (_reached_root != rhs._reached_root || _nr_of_frames != rhs._nr_of_frames || _hash != rhs._hash) {\n+  if (_reached_root != rhs._reached_root || _frames->length() != rhs.number_of_frames() || _hash != rhs._hash) {\n@@ -118,2 +119,2 @@\n-  for (u4 i = 0; i < _nr_of_frames; ++i) {\n-    if (!_frames[i].equals(rhs._frames[i])) {\n+  for (int i = 0; i < _frames->length(); ++i) {\n+    if (!_frames->at(i).equals(rhs._frames->at(i))) {\n@@ -126,38 +127,2 @@\n-template <typename Writer>\n-static void write_frame(Writer& w, traceid methodid, int line, int bci, u1 type) {\n-  w.write((u8)methodid);\n-  w.write((u4)line);\n-  w.write((u4)bci);\n-  w.write((u8)type);\n-}\n-\n-void JfrStackFrame::write(JfrChunkWriter& cw) const {\n-  write_frame(cw, _methodid, _line, _bci, _type);\n-}\n-\n-void JfrStackFrame::write(JfrCheckpointWriter& cpw) const {\n-  write_frame(cpw, _methodid, _line, _bci, _type);\n-}\n-\n-class JfrVframeStream : public vframeStreamCommon {\n- private:\n-  bool _vthread;\n-  const ContinuationEntry* _cont_entry;\n-  bool _async_mode;\n-  bool step_to_sender();\n-  void next_frame();\n- public:\n-  JfrVframeStream(JavaThread* jt, const frame& fr, bool stop_at_java_call_stub, bool async_mode);\n-  void next_vframe();\n-};\n-\n-static RegisterMap::WalkContinuation walk_continuation(JavaThread* jt) {\n-  \/\/ NOTE: WalkContinuation::skip, because of interactions with ZGC relocation\n-  \/\/       and load barriers. This code is run while generating stack traces for\n-  \/\/       the ZPage allocation event, even when ZGC is relocating  objects.\n-  \/\/       When ZGC is relocating, it is forbidden to run code that performs\n-  \/\/       load barriers. With WalkContinuation::include, we visit heap stack\n-  \/\/       chunks and could be using load barriers.\n-  return (UseZGC && !StackWatermarkSet::processing_started(jt))\n-      ? RegisterMap::WalkContinuation::skip\n-      : RegisterMap::WalkContinuation::include;\n+static inline bool is_interpreter(const JfrSampleRequest& request) {\n+  return request._sample_bcp != nullptr;\n@@ -166,14 +131,21 @@\n-JfrVframeStream::JfrVframeStream(JavaThread* jt, const frame& fr, bool stop_at_java_call_stub, bool async_mode) :\n-  vframeStreamCommon(jt,\n-                     RegisterMap::UpdateMap::skip,\n-                     RegisterMap::ProcessFrames::skip,\n-                     walk_continuation(jt)),\n-    _vthread(JfrThreadLocal::is_vthread(jt)),\n-    _cont_entry(_vthread ? jt->last_continuation() : nullptr),\n-    _async_mode(async_mode) {\n-  assert(!_vthread || _cont_entry != nullptr, \"invariant\");\n-  _reg_map.set_async(async_mode);\n-  _frame = fr;\n-  _stop_at_java_call_stub = stop_at_java_call_stub;\n-  while (!fill_from_frame()) {\n-    step_to_sender();\n+void JfrStackTrace::record_interpreter_top_frame(const JfrSampleRequest& request) {\n+  assert(_hash == 0, \"invariant\");\n+  assert(_count == 0, \"invariant\");\n+  assert(_frames != nullptr, \"invariant\");\n+  assert(_frames->length() == 0, \"invariant\");\n+  _hash = 1;\n+  const Method* method = reinterpret_cast<Method*>(request._sample_pc);\n+  assert(method != nullptr, \"invariant\");\n+  const traceid mid = JfrTraceId::load(method);\n+  const int bci = method->is_native() ? 0 : method->validate_bci_from_bcp(reinterpret_cast<address>(request._sample_bcp));\n+  const u1 type = method->is_native() ? JfrStackFrame::FRAME_NATIVE : JfrStackFrame::FRAME_INTERPRETER;\n+  _hash = (_hash * 31) + mid;\n+  _hash = (_hash * 31) + bci;\n+  _hash = (_hash * 31) + type;\n+  _frames->append(JfrStackFrame(mid, bci, type, method->method_holder()));\n+  _count++;\n+}\n+\n+static inline bool interpreter_top_frame_has_no_sender(const JfrSampleRequest& request, const frame& fr, JavaThread* jt) {\n+  if (fr.pc() == nullptr) {\n+    return true;\n@@ -181,6 +153,7 @@\n-}\n-\n-inline bool JfrVframeStream::step_to_sender() {\n-  if (_async_mode && !_frame.safe_for_sender(_thread)) {\n-    _mode = at_end_mode;\n-    return false;\n+  const Method* method = reinterpret_cast<Method*>(request._sample_pc);\n+  assert(method != nullptr, \"invariant\");\n+  if (method->intrinsic_id() == vmIntrinsicID::_Continuation_enterSpecial) {\n+    assert(JfrThreadLocal::is_vthread(jt), \"invariant\");\n+    const ContinuationEntry* const cont_entry = jt->last_continuation();\n+    assert(cont_entry != nullptr, \"invariant\");\n+    return cont_entry->is_virtual_thread();\n@@ -188,2 +161,1 @@\n-  _frame = _frame.sender(&_reg_map);\n-  return true;\n+  return false;\n@@ -192,18 +164,5 @@\n-inline void JfrVframeStream::next_frame() {\n-  static constexpr const u4 loop_max = MAX_STACK_DEPTH * 2;\n-  u4 loop_count = 0;\n-  do {\n-    if (_vthread && Continuation::is_continuation_enterSpecial(_frame)) {\n-      if (_cont_entry->is_virtual_thread()) {\n-        \/\/ An entry of a vthread continuation is a termination point.\n-        _mode = at_end_mode;\n-        break;\n-      }\n-      _cont_entry = _cont_entry->parent();\n-    }\n-    if (_async_mode) {\n-      ++loop_count;\n-      if (loop_count > loop_max) {\n-        _mode = at_end_mode;\n-        break;\n-      }\n+bool JfrStackTrace::record(JavaThread* jt, const frame& frame, const JfrSampleRequest& request) {\n+  if (is_interpreter(request)) {\n+    record_interpreter_top_frame(request);\n+    if (interpreter_top_frame_has_no_sender(request, frame, jt)) {\n+      return true;\n@@ -211,15 +170,0 @@\n-  } while (step_to_sender() && !fill_from_frame());\n-}\n-\n-\/\/ Solaris SPARC Compiler1 needs an additional check on the grandparent\n-\/\/ of the top_frame when the parent of the top_frame is interpreted and\n-\/\/ the grandparent is compiled. However, in this method we do not know\n-\/\/ the relationship of the current _frame relative to the top_frame so\n-\/\/ we implement a more broad sanity check. When the previous callee is\n-\/\/ interpreted and the current sender is compiled, we verify that the\n-\/\/ current sender is also walkable. If it is not walkable, then we mark\n-\/\/ the current vframeStream as at the end.\n-void JfrVframeStream::next_vframe() {\n-  \/\/ handle frames with inlining\n-  if (_mode == compiled_mode && fill_in_compiled_inlined_sender()) {\n-    return;\n@@ -227,7 +171,1 @@\n-  next_frame();\n-}\n-\n-static const size_t min_valid_free_size_bytes = 16;\n-\n-static inline bool is_full(const JfrBuffer* enqueue_buffer) {\n-  return enqueue_buffer->free_size() < min_valid_free_size_bytes;\n+  return record(jt, frame, 0);\n@@ -236,1 +174,1 @@\n-bool JfrStackTrace::record_async(JavaThread* jt, const frame& frame) {\n+bool JfrStackTrace::record(JavaThread* jt, int skip, int64_t stack_filter_id) {\n@@ -238,50 +176,2 @@\n-  assert(!_lineno, \"invariant\");\n-  Thread* current_thread = Thread::current();\n-  assert(current_thread->is_JfrSampler_thread(), \"invariant\");\n-  assert(jt != current_thread, \"invariant\");\n-  \/\/ Explicitly monitor the available space of the thread-local buffer used for enqueuing klasses as part of tagging methods.\n-  \/\/ We do this because if space becomes sparse, we cannot rely on the implicit allocation of a new buffer as part of the\n-  \/\/ regular tag mechanism. If the free list is empty, a malloc could result, and the problem with that is that the thread\n-  \/\/ we have suspended could be the holder of the malloc lock. If there is no more available space, the attempt is aborted.\n-  const JfrBuffer* const enqueue_buffer = JfrTraceIdLoadBarrier::get_sampler_enqueue_buffer(current_thread);\n-  HandleMark hm(current_thread); \/\/ RegisterMap uses Handles to support continuations.\n-  JfrVframeStream vfs(jt, frame, false, true);\n-  u4 count = 0;\n-  _reached_root = true;\n-  _hash = 1;\n-  while (!vfs.at_end()) {\n-    if (count >= _max_frames) {\n-      _reached_root = false;\n-      break;\n-    }\n-    const Method* method = vfs.method();\n-    if (!Method::is_valid_method(method) || is_full(enqueue_buffer)) {\n-      \/\/ we throw away everything we've gathered in this sample since\n-      \/\/ none of it is safe\n-      return false;\n-    }\n-    const traceid mid = JfrTraceId::load(method);\n-    u1 type = vfs.is_interpreted_frame() ? JfrStackFrame::FRAME_INTERPRETER : JfrStackFrame::FRAME_JIT;\n-    int bci = 0;\n-    if (method->is_native()) {\n-      type = JfrStackFrame::FRAME_NATIVE;\n-    } else {\n-      bci = vfs.bci();\n-    }\n-\n-    intptr_t* frame_id = vfs.frame_id();\n-    vfs.next_vframe();\n-    if (type == JfrStackFrame::FRAME_JIT && !vfs.at_end() && frame_id == vfs.frame_id()) {\n-      \/\/ This frame and the caller frame are both the same physical\n-      \/\/ frame, so this frame is inlined into the caller.\n-      type = JfrStackFrame::FRAME_INLINE;\n-    }\n-    _hash = (_hash * 31) + mid;\n-    _hash = (_hash * 31) + bci;\n-    _hash = (_hash * 31) + type;\n-    _frames[count] = JfrStackFrame(mid, bci, type, method->line_number_from_bci(bci), method->method_holder());\n-    count++;\n-  }\n-  _lineno = true;\n-  _nr_of_frames = count;\n-  return count > 0;\n+  assert(jt == JavaThread::current(), \"invariant\");\n+  return jt->has_last_Java_frame() ? record(jt, jt->last_frame(), skip, stack_filter_id) : false;\n@@ -290,5 +180,1 @@\n-bool JfrStackTrace::record(JavaThread* jt, const frame& frame, int skip, int64_t stack_filter_id) {\n-  assert(jt != nullptr, \"invariant\");\n-  assert(jt == Thread::current(), \"invariant\");\n-  assert(jt->thread_state() != _thread_in_native, \"invariant\");\n-  assert(!_lineno, \"invariant\");\n+bool JfrStackTrace::record(JavaThread* jt, const frame& frame, int skip, int64_t stack_filter_id \/* -1 *\/) {\n@@ -298,3 +184,11 @@\n-  HandleMark hm(jt);\n-  JfrVframeStream vfs(jt, frame, false, false);\n-  u4 count = 0;\n+  return record_inner(jt, frame, skip, stack_filter_id);\n+}\n+\n+bool JfrStackTrace::record_inner(JavaThread* jt, const frame& frame, int skip, int64_t stack_filter_id \/* -1 *\/) {\n+  assert(jt != nullptr, \"invariant\");\n+  assert(!_lineno, \"invariant\");\n+  assert(_frames != nullptr, \"invariant\");\n+  assert(_frames->length() == 0 || _frames->length() == 1, \"invariant\");\n+  Thread* const current_thread = Thread::current();\n+  HandleMark hm(current_thread); \/\/ RegisterMap uses Handles to support continuations.\n+  JfrVframeStream vfs(jt, frame, false);\n@@ -308,2 +202,4 @@\n-  const JfrStackFilter* stack_filter = JfrStackFilterRegistry::lookup(stack_filter_id);\n-  _hash = 1;\n+  const JfrStackFilter* stack_filter = stack_filter_id < 0 ? nullptr : JfrStackFilterRegistry::lookup(stack_filter_id);\n+  if (_hash == 0) {\n+    _hash = 1;\n+  }\n@@ -311,1 +207,1 @@\n-    if (count >= _max_frames) {\n+    if (_count >= _max_frames) {\n@@ -341,12 +237,2 @@\n-    _frames[count] = JfrStackFrame(mid, bci, type, method->method_holder());\n-    count++;\n-  }\n-  _nr_of_frames = count;\n-  return count > 0;\n-}\n-\n-bool JfrStackTrace::record(JavaThread* current_thread, int skip, int64_t stack_filter_id) {\n-  assert(current_thread != nullptr, \"invariant\");\n-  assert(current_thread == Thread::current(), \"invariant\");\n-  if (!current_thread->has_last_Java_frame()) {\n-    return false;\n+    _frames->append(JfrStackFrame(mid, bci, type, method->method_holder()));\n+    _count++;\n@@ -354,10 +240,1 @@\n-  return record(current_thread, current_thread->last_frame(), skip, stack_filter_id);\n-}\n-\n-void JfrStackFrame::resolve_lineno() const {\n-  assert(_klass, \"no klass pointer\");\n-  assert(_line == 0, \"already have linenumber\");\n-  const Method* const method = JfrMethodLookup::lookup(_klass, _methodid);\n-  assert(method != nullptr, \"invariant\");\n-  assert(method->method_holder() == _klass, \"invariant\");\n-  _line = method->line_number_from_bci(_bci);\n+  return _count > 0;\n@@ -368,2 +245,2 @@\n-  for (unsigned int i = 0; i < _nr_of_frames; i++) {\n-    _frames[i].resolve_lineno();\n+  for (int i = 0; i < _frames->length(); i++) {\n+    _frames->at(i).resolve_lineno();\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackTrace.cpp","additions":98,"deletions":221,"binary":false,"changes":319,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"jfr\/recorder\/stacktrace\/jfrStackFrame.hpp\"\n@@ -36,27 +37,1 @@\n-\n-class JfrStackFrame {\n-  friend class ObjectSampleCheckpoint;\n- private:\n-  const InstanceKlass* _klass;\n-  traceid _methodid;\n-  mutable int _line;\n-  int _bci;\n-  u1 _type;\n-\n- public:\n-  JfrStackFrame(const traceid& id, int bci, u1 type, const InstanceKlass* klass);\n-  JfrStackFrame(const traceid& id, int bci, u1 type, int lineno, const InstanceKlass* klass);\n-\n-  bool equals(const JfrStackFrame& rhs) const;\n-  void write(JfrChunkWriter& cw) const;\n-  void write(JfrCheckpointWriter& cpw) const;\n-  void resolve_lineno() const;\n-\n-  enum : u1 {\n-    FRAME_INTERPRETER = 0,\n-    FRAME_JIT,\n-    FRAME_INLINE,\n-    FRAME_NATIVE,\n-    NUM_FRAME_TYPES\n-  };\n-};\n+struct JfrSampleRequest;\n@@ -68,0 +43,1 @@\n+  friend class JfrThreadSampling;\n@@ -70,1 +46,0 @@\n-  friend class OSThreadSampler;\n@@ -74,1 +49,1 @@\n-  JfrStackFrame* _frames;\n+  JfrStackFrames* _frames;\n@@ -77,1 +52,1 @@\n-  u4 _nr_of_frames;\n+  u4 _count;\n@@ -91,1 +66,0 @@\n-  void set_nr_of_frames(u4 nr_of_frames) { _nr_of_frames = nr_of_frames; }\n@@ -96,4 +70,1 @@\n-  bool record(JavaThread* current_thread, int skip, int64_t stack_frame_id);\n-  bool record(JavaThread* current_thread, const frame& frame, int skip, int64_t stack_frame_id);\n-  bool record_async(JavaThread* other_thread, const frame& frame);\n-\n+  int number_of_frames() const;\n@@ -102,0 +73,3 @@\n+  bool record_inner(JavaThread* jt, const frame& frame, int skip, int64_t stack_filter_id = -1);\n+  bool record(JavaThread* jt, const frame& frame, int skip, int64_t stack_filter_id = -1);\n+  void record_interpreter_top_frame(const JfrSampleRequest& request);\n@@ -104,2 +78,0 @@\n-  JfrStackTrace(JfrStackFrame* frames, u4 max_frames);\n-  ~JfrStackTrace();\n@@ -108,0 +80,4 @@\n+  \/\/ ResourceArea allocation, remember ResourceMark.\n+  JfrStackTrace();\n+  ~JfrStackTrace();\n+\n@@ -110,0 +86,3 @@\n+\n+  bool record(JavaThread* current_thread, int skip, int64_t stack_filter_id);\n+  bool record(JavaThread* jt, const frame& frame, const JfrSampleRequest& request);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackTrace.hpp","additions":16,"deletions":37,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"jfr\/recorder\/service\/jfrOptionSet.hpp\"\n@@ -68,1 +69,1 @@\n-class JfrFrameType : public JfrSerializer {\n+class JfrFrameTypeSerializer : public JfrSerializer {\n@@ -84,1 +85,1 @@\n-  return JfrSerializer::register_serializer(TYPE_FRAMETYPE, true, new JfrFrameType());\n+  return JfrSerializer::register_serializer(TYPE_FRAMETYPE, true, new JfrFrameTypeSerializer());\n@@ -153,13 +154,3 @@\n-  JfrStackFrame* frames = tl->stackframes();\n-  if (frames == nullptr) {\n-    \/\/ pending oom\n-    return 0;\n-  }\n-  assert(frames != nullptr, \"invariant\");\n-  assert(tl->stackframes() == frames, \"invariant\");\n-  return instance().record(JavaThread::cast(current_thread), skip, stack_filter_id, frames, tl->stackdepth());\n-}\n-\n-traceid JfrStackTraceRepository::record(JavaThread* current_thread, int skip, int64_t stack_filter_id, JfrStackFrame *frames, u4 max_frames) {\n-  JfrStackTrace stacktrace(frames, max_frames);\n-  return stacktrace.record(current_thread, skip, stack_filter_id) ? add(instance(), stacktrace) : 0;\n+  ResourceMark rm(current_thread);\n+  JfrStackTrace stacktrace;\n+  return stacktrace.record(JavaThread::cast(current_thread), skip, stack_filter_id) ? add(instance(), stacktrace) : 0;\n@@ -188,1 +179,2 @@\n-  JfrStackTrace stacktrace(tl->stackframes(), tl->stackdepth());\n+  ResourceMark rm(current_thread);\n+  JfrStackTrace stacktrace;\n@@ -198,1 +190,1 @@\n-  assert(stacktrace._nr_of_frames > 0, \"invariant\");\n+  assert(stacktrace.number_of_frames() > 0, \"invariant\");\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackTraceRepository.cpp","additions":9,"deletions":17,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+class JfrStackTrace;\n@@ -40,0 +41,1 @@\n+  friend class JfrThreadSampler;\n@@ -71,2 +73,0 @@\n-\n-  traceid add_trace(const JfrStackTrace& stacktrace);\n@@ -74,2 +74,1 @@\n-  static traceid add(const JfrStackTrace& stacktrace);\n-  traceid record(JavaThread* current_thread, int skip, int64_t stack_filter_id, JfrStackFrame* frames, u4 max_frames);\n+  traceid add_trace(const JfrStackTrace& stacktrace);\n@@ -78,0 +77,1 @@\n+  static traceid add(const JfrStackTrace& stacktrace);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackTraceRepository.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -0,0 +1,54 @@\n+\/*\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"jfr\/recorder\/stacktrace\/jfrVframeStream.inline.hpp\"\n+#include \"runtime\/javaThread.inline.hpp\"\n+#include \"runtime\/registerMap.hpp\"\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n+\n+static inline RegisterMap::WalkContinuation walk_continuation(JavaThread* jt) {\n+  \/\/ NOTE: WalkContinuation::skip, because of interactions with ZGC relocation\n+  \/\/       and load barriers. This code is run while generating stack traces for\n+  \/\/       the ZPage allocation event, even when ZGC is relocating  objects.\n+  \/\/       When ZGC is relocating, it is forbidden to run code that performs\n+  \/\/       load barriers. With WalkContinuation::include, we visit heap stack\n+  \/\/       chunks and could be using load barriers.\n+  \/\/\n+  \/\/ NOTE: Shenandoah GC also seems to require this check - actual details as to why\n+  \/\/       is unknown but to be filled in by others.\n+  return ((UseZGC || UseShenandoahGC) && !StackWatermarkSet::processing_started(jt))\n+    ? RegisterMap::WalkContinuation::skip\n+    : RegisterMap::WalkContinuation::include;\n+}\n+\n+JfrVframeStream::JfrVframeStream(JavaThread* jt, const frame& fr, bool stop_at_java_call_stub) :\n+  vframeStreamCommon(jt, RegisterMap::UpdateMap::skip, RegisterMap::ProcessFrames::skip, walk_continuation(jt)),\n+  _vthread(JfrThreadLocal::is_vthread(jt)), _cont_entry(_vthread ? jt->last_continuation() : nullptr) {\n+  assert(!_vthread || _cont_entry != nullptr, \"invariant\");\n+  _frame = fr;\n+  _stop_at_java_call_stub = stop_at_java_call_stub;\n+  while (!fill_from_frame()) {\n+    _frame = _frame.sender(&_reg_map);\n+  }\n+}\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrVframeStream.cpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"added"},{"patch":"@@ -0,0 +1,41 @@\n+\/*\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_HPP\n+#define SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_HPP\n+\n+#include \"runtime\/vframe.hpp\"\n+\n+class JfrVframeStream : public vframeStreamCommon {\n+ private:\n+  bool _vthread;\n+  const ContinuationEntry* _cont_entry;\n+  void step_to_sender();\n+  void next_frame();\n+ public:\n+  JfrVframeStream(JavaThread* jt, const frame& fr, bool stop_at_java_call_stub);\n+  void next_vframe();\n+};\n+\n+#endif \/\/ SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_HPP\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrVframeStream.hpp","additions":41,"deletions":0,"binary":false,"changes":41,"status":"added"},{"patch":"@@ -0,0 +1,56 @@\n+\/*\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_INLINE_HPP\n+#define SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_INLINE_HPP\n+\n+#include \"jfr\/recorder\/stacktrace\/jfrVframeStream.hpp\"\n+#include \"runtime\/continuationEntry.inline.hpp\"\n+#include \"runtime\/vframe.inline.hpp\"\n+\n+inline void JfrVframeStream::next_frame() {\n+  do {\n+    if (_vthread && Continuation::is_continuation_enterSpecial(_frame)) {\n+      if (_cont_entry->is_virtual_thread()) {\n+        \/\/ An entry of a vthread continuation is a termination point.\n+        _mode = at_end_mode;\n+        break;\n+      }\n+      _cont_entry = _cont_entry->parent();\n+    }\n+\n+    _frame = _frame.sender(&_reg_map);\n+\n+  } while (!fill_from_frame());\n+}\n+\n+inline void JfrVframeStream::next_vframe() {\n+  \/\/ handle frames with inlining\n+  if (_mode == compiled_mode && fill_in_compiled_inlined_sender()) {\n+    return;\n+  }\n+  next_frame();\n+}\n+\n+#endif \/\/ SHARE_JFR_RECORDER_STACKTRACE_JFRVFRAMESTREAM_INLINE_HPP\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrVframeStream.inline.hpp","additions":56,"deletions":0,"binary":false,"changes":56,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n-* Copyright (c) 2012, 2023, Oracle and\/or its affiliates. All rights reserved.\n+* Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,1 +28,0 @@\n-#include \"jfr\/periodic\/sampling\/jfrThreadSampler.hpp\"\n@@ -68,1 +67,2 @@\n-#define SUSPEND_THREAD_CONDITIONAL(thread) if ((thread)->is_trace_suspend()) JfrThreadSampling::on_javathread_suspend(thread)\n+#define SAMPLE_STATE_OFFSET_JFR \\\n+  JfrThreadLocal::sample_state_offset() + THREAD_LOCAL_OFFSET_JFR\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadExtension.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -49,0 +49,3 @@\n+  _sample_request(),\n+  _sample_request_queue(8),\n+  _sample_monitor(Monitor::nosafepoint, \"jfr thread sample monitor\"),\n@@ -57,1 +60,2 @@\n-  _stackframes(nullptr),\n+  _sample_state(0),\n+  _sample_thread_state(_thread_uninitialized),\n@@ -71,2 +75,0 @@\n-  _stackdepth(0),\n-  _entering_suspend_flag(0),\n@@ -77,0 +79,1 @@\n+  _enqueued_requests(false),\n@@ -168,4 +171,0 @@\n-  if (_stackframes != nullptr) {\n-    FREE_C_HEAP_ARRAY(JfrStackFrame, _stackframes);\n-    _stackframes = nullptr;\n-  }\n@@ -248,6 +247,0 @@\n-JfrStackFrame* JfrThreadLocal::install_stackframes() const {\n-  assert(_stackframes == nullptr, \"invariant\");\n-  _stackframes = NEW_C_HEAP_ARRAY(JfrStackFrame, stackdepth(), mtTracing);\n-  return _stackframes;\n-}\n-\n@@ -282,0 +275,4 @@\n+ByteSize JfrThreadLocal::sample_state_offset() {\n+  return byte_offset_of(JfrThreadLocal, _sample_state);\n+}\n+\n@@ -340,4 +337,0 @@\n-u4 JfrThreadLocal::stackdepth() const {\n-  return _stackdepth != 0 ? _stackdepth : (u4)JfrOptionSet::stackdepth();\n-}\n-\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadLocal.cpp","additions":10,"deletions":17,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -28,0 +28,2 @@\n+#include \"jfr\/periodic\/sampling\/jfrSampleRequest.hpp\"\n+#include \"jfr\/utilities\/jfrAllocation.hpp\"\n@@ -29,0 +31,1 @@\n+#include \"jfr\/utilities\/jfrTime.hpp\"\n@@ -30,0 +33,2 @@\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n@@ -34,1 +39,0 @@\n-class JfrStackFrame;\n@@ -43,0 +47,3 @@\n+  mutable JfrSampleRequest _sample_request;\n+  JfrSampleRequestQueue _sample_request_queue;\n+  Monitor _sample_monitor;\n@@ -51,1 +58,2 @@\n-  mutable JfrStackFrame* _stackframes;\n+  volatile int _sample_state;\n+  JavaThreadState _sample_thread_state;\n@@ -65,2 +73,0 @@\n-  mutable u4 _stackdepth;\n-  volatile jint _entering_suspend_flag;\n@@ -71,0 +77,1 @@\n+  volatile bool _enqueued_requests;\n@@ -77,1 +84,0 @@\n-  JfrStackFrame* install_stackframes() const;\n@@ -143,2 +149,64 @@\n-  JfrStackFrame* stackframes() const {\n-    return _stackframes != nullptr ? _stackframes : install_stackframes();\n+\n+  int sample_state() const {\n+    return Atomic::load_acquire(&_sample_state);\n+  }\n+\n+  void set_sample_state(int state) {\n+    Atomic::release_store(&_sample_state, state);\n+  }\n+\n+  Monitor* sample_monitor() {\n+    return &_sample_monitor;\n+  }\n+\n+  JfrSampleRequestQueue* sample_requests() {\n+    return &_sample_request_queue;\n+  }\n+\n+  JfrSampleRequest sample_request() const {\n+    return _sample_request;\n+  }\n+\n+  void set_sample_request(JfrSampleRequest request) {\n+    _sample_request = request;\n+  }\n+\n+  void set_sample_ticks() {\n+    _sample_request._sample_ticks = JfrTicks::now();\n+  }\n+\n+  void set_sample_ticks(const JfrTicks& ticks) {\n+    _sample_request._sample_ticks = ticks;\n+  }\n+\n+  bool has_sample_ticks() const {\n+    return _sample_request._sample_ticks.value() != 0;\n+  }\n+\n+  const JfrTicks& sample_ticks() const {\n+    return _sample_request._sample_ticks;\n+  }\n+\n+  bool has_enqueued_requests() const {\n+    return Atomic::load_acquire(&_enqueued_requests);\n+  }\n+\n+  void enqueue_request() {\n+    assert_lock_strong(sample_monitor());\n+    assert(sample_state() == JAVA_SAMPLE, \"invariant\");\n+    if (_sample_request_queue.append(_sample_request) == 0) {\n+      Atomic::release_store(&_enqueued_requests, true);\n+    }\n+    set_sample_state(NO_SAMPLE);\n+  }\n+\n+  void clear_enqueued_requests() {\n+    assert_lock_strong(sample_monitor());\n+    assert(has_enqueued_requests(), \"invariant\");\n+    assert(_sample_request_queue.is_nonempty(), \"invariant\");\n+    _sample_request_queue.clear();\n+    Atomic::release_store(&_enqueued_requests, false);\n+  }\n+\n+  bool has_native_sample_request() const {\n+    return sample_state() == NATIVE_SAMPLE;\n@@ -147,2 +215,2 @@\n-  void set_stackframes(JfrStackFrame* frames) {\n-    _stackframes = frames;\n+  bool has_java_sample_request() const {\n+    return sample_state() == JAVA_SAMPLE || has_enqueued_requests();\n@@ -151,1 +219,7 @@\n-  u4 stackdepth() const;\n+  bool has_sample_request() const {\n+    return sample_state() != NO_SAMPLE || has_enqueued_requests();\n+  }\n+\n+  void set_sample_thread_state(JavaThreadState state) {\n+    _sample_thread_state = state;\n+  }\n@@ -153,2 +227,2 @@\n-  void set_stackdepth(u4 depth) {\n-    _stackdepth = depth;\n+  JavaThreadState sample_thread_state() const {\n+    return _sample_thread_state;\n@@ -214,12 +288,0 @@\n-  void set_trace_block() {\n-    _entering_suspend_flag = 1;\n-  }\n-\n-  void clear_trace_block() {\n-    _entering_suspend_flag = 0;\n-  }\n-\n-  bool is_trace_block() const {\n-    return _entering_suspend_flag != 0;\n-  }\n-\n@@ -300,0 +362,1 @@\n+  static ByteSize sample_state_offset();\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadLocal.hpp","additions":87,"deletions":24,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -59,0 +59,1 @@\n+  JFR_LOG_TAG(jfr, system, sampling) \\\n","filename":"src\/hotspot\/share\/jfr\/utilities\/jfrLogTagSets.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -45,1 +45,1 @@\n-private:\n+ private:\n@@ -49,1 +49,1 @@\n-public:\n+ public:\n@@ -58,1 +58,1 @@\n-public:\n+ public:\n@@ -66,1 +66,1 @@\n-private:\n+ private:\n@@ -73,1 +73,1 @@\n-private:\n+ private:\n@@ -89,1 +89,1 @@\n-public:\n+ public:\n@@ -99,1 +99,4 @@\n-public:\n+  static address return_pc() { return _return_pc; }\n+  static address return_pc_address() { return (address)&_return_pc; }\n+\n+ public:\n","filename":"src\/hotspot\/share\/runtime\/continuationEntry.hpp","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -104,0 +104,1 @@\n+#include \"jfr\/jfr.hpp\"\n@@ -476,0 +477,1 @@\n+  JFR_ONLY(Jfr::check_and_process_sample_request(current);)\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -232,0 +232,1 @@\n+}\n@@ -233,0 +234,7 @@\n+\/\/ This is optimized for intra-blob pc adjustments only.\n+void frame::adjust_pc(address newpc) {\n+  assert(_cb != nullptr, \"invariant\");\n+  assert(_cb == CodeCache::find_blob(newpc), \"invariant\");\n+  \/\/ Unsafe to use the is_deoptimized tester after changing pc\n+  _deopt_state = unknown;\n+  _pc = newpc;\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -130,0 +130,1 @@\n+  void adjust_pc(address newpc);\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1082,1 +1082,0 @@\n-  JFR_ONLY(SUSPEND_THREAD_CONDITIONAL(this);)\n@@ -1085,1 +1084,0 @@\n-\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -230,2 +230,0 @@\n-  inline void set_trace_flag();\n-  inline void clear_trace_flag();\n@@ -602,1 +600,5 @@\n-  \/\/ last_Java_pc\n+  \/\/ last Java fp\n+  intptr_t* last_Java_fp() const                 { return _anchor.last_Java_fp(); }\n+\n+  \/\/ This is used by JFR when sampling interpreter frames.\n+  JFR_ONLY(intptr_t* sender_Java_fp() const      { return _anchor.last_sender_Java_fp(); })\n@@ -604,0 +606,1 @@\n+  \/\/ last_Java_pc\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -60,6 +60,0 @@\n-inline void JavaThread::set_trace_flag() {\n-  set_suspend_flag(_trace_flag);\n-}\n-inline void JavaThread::clear_trace_flag() {\n-  clear_suspend_flag(_trace_flag);\n-}\n","filename":"src\/hotspot\/share\/runtime\/javaThread.inline.hpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -119,1 +119,0 @@\n-Monitor* JfrThreadSampler_lock        = nullptr;\n@@ -281,1 +280,0 @@\n-  MUTEX_DEFN(JfrThreadSampler_lock           , PaddedMonitor, nosafepoint);\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -138,1 +138,0 @@\n-extern Monitor* JfrThreadSampler_lock;           \/\/ used to suspend\/resume JFR thread sampler\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -35,0 +35,3 @@\n+#ifdef INCLUDE_JFR\n+#include \"jfr\/jfr.hpp\"\n+#endif\n@@ -97,1 +100,1 @@\n-    bool armed = global_poll() || thread->handshake_state()->has_operation();\n+    bool armed = has_pending_safepoint(thread);\n@@ -123,1 +126,1 @@\n-    if (!armed && (global_poll() || thread->handshake_state()->has_operation())) {\n+    if (!armed && has_pending_safepoint(thread)) {\n@@ -132,0 +135,4 @@\n+static inline bool has_handshake_operation(JavaThread* jt, bool allow_suspend, bool check_async) {\n+  return jt->handshake_state()->has_operation() && jt->handshake_state()->process_by_self(allow_suspend, check_async);\n+}\n+\n@@ -138,1 +145,0 @@\n-  bool need_rechecking;\n@@ -142,0 +148,1 @@\n+    JFR_ONLY(Jfr::check_and_process_sample_request(thread);)\n@@ -156,3 +163,1 @@\n-\n-    need_rechecking = thread->handshake_state()->has_operation() && thread->handshake_state()->process_by_self(allow_suspend, check_async_exception);\n-  } while (need_rechecking);\n+  } while (has_handshake_operation(thread, allow_suspend, check_async_exception));\n","filename":"src\/hotspot\/share\/runtime\/safepointMechanism.cpp","additions":11,"deletions":6,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,0 +52,2 @@\n+  static inline bool has_pending_safepoint(JavaThread* thread);\n+\n","filename":"src\/hotspot\/share\/runtime\/safepointMechanism.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,3 @@\n+#if INCLUDE_JFR\n+#include \"jfr\/jfr.hpp\"\n+#endif\n@@ -59,0 +62,4 @@\n+inline bool SafepointMechanism::has_pending_safepoint(JavaThread* thread) {\n+  return global_poll() || thread->handshake_state()->has_operation() JFR_ONLY(|| Jfr::has_sample_request(thread));\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/safepointMechanism.inline.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2960,1 +2960,1 @@\n-\n+  JFR_ONLY(Jfr::check_and_process_sample_request(current);)\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,31 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/suspendedThreadTask.hpp\"\n-\n-void SuspendedThreadTask::run() {\n-  internal_do_task();\n-  _done = true;\n-}\n","filename":"src\/hotspot\/share\/runtime\/suspendedThreadTask.cpp","additions":0,"deletions":31,"binary":false,"changes":31,"status":"deleted"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,5 +31,1 @@\n-public:\n-  SuspendedThreadTaskContext(Thread* thread, void *ucontext) : _thread(thread), _ucontext(ucontext) {}\n-  Thread* thread() const { return _thread; }\n-  void* ucontext() const { return _ucontext; }\n-private:\n+ private:\n@@ -38,0 +34,4 @@\n+ public:\n+  SuspendedThreadTaskContext(Thread* thread, void* ucontext) : _thread(thread), _ucontext(ucontext) {}\n+  Thread* thread() const { return _thread; }\n+  void* ucontext() const { return _ucontext; }\n@@ -41,8 +41,1 @@\n-public:\n-  SuspendedThreadTask(Thread* thread) : _thread(thread), _done(false) {}\n-  void run();\n-  virtual void do_task(const SuspendedThreadTaskContext& context) = 0;\n-protected:\n-  ~SuspendedThreadTask() {}\n-private:\n-  void internal_do_task();\n+ private:\n@@ -50,1 +43,7 @@\n-  bool _done;\n+  void internal_do_task();\n+ protected:\n+  ~SuspendedThreadTask() {}\n+ public:\n+  SuspendedThreadTask(Thread* thread) : _thread(thread) {}\n+  void run() { internal_do_task(); }\n+  virtual void do_task(const SuspendedThreadTaskContext& context) = 0;\n","filename":"src\/hotspot\/share\/runtime\/suspendedThreadTask.hpp","additions":14,"deletions":15,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -314,0 +314,1 @@\n+  virtual bool is_JfrRecorder_thread() const         { return false; }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -91,0 +91,2 @@\n+  void  set_length(int len)     { _len = len; }\n+\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -77,0 +77,4 @@\n+    \/**\n+     *  Covers sampling work (for Hotspot developer)\n+     *\/\n+    JFR_SYSTEM_SAMPLING(10),\n@@ -80,1 +84,1 @@\n-    JFR_PERIODIC(10),\n+    JFR_PERIODIC(11),\n@@ -84,1 +88,1 @@\n-    JFR_METADATA(11),\n+    JFR_METADATA(12),\n@@ -88,1 +92,1 @@\n-    JFR_EVENT(12),\n+    JFR_EVENT(13),\n@@ -92,1 +96,1 @@\n-    JFR_SETTING(13),\n+    JFR_SETTING(14),\n@@ -96,1 +100,1 @@\n-    JFR_DCMD(14),\n+    JFR_DCMD(15),\n@@ -100,1 +104,1 @@\n-    JFR_START(15);\n+    JFR_START(16);\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/LogTag.java","additions":11,"deletions":7,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -209,0 +209,7 @@\n+    <event name=\"jdk.SafepointLatency\">\n+      <setting name=\"enabled\" control=\"method-sampling-enabled\">false<\/setting>\n+      <setting name=\"stackTrace\">true<\/setting>\n+      <setting name=\"threshold\">0 ms<\/setting>\n+      <setting name=\"throttle\">off<\/setting>\n+    <\/event>\n+\n","filename":"src\/jdk.jfr\/share\/conf\/jfr\/default.jfc","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -209,0 +209,7 @@\n+    <event name=\"jdk.SafepointLatency\">\n+      <setting name=\"enabled\" control=\"method-sampling-enabled\">false<\/setting>\n+      <setting name=\"stackTrace\">false<\/setting>\n+      <setting name=\"threshold\">0 ms<\/setting>\n+      <setting name=\"throttle\">off<\/setting>\n+    <\/event>\n+\n","filename":"src\/jdk.jfr\/share\/conf\/jfr\/profile.jfc","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-            \"UnsignedIntFlag\", \"UnsignedIntFlagChanged\", \"DoubleFlagChanged\")\n+            \"UnsignedIntFlag\", \"UnsignedIntFlagChanged\", \"DoubleFlagChanged\", \"SafepointLatency\")\n","filename":"test\/jdk\/jdk\/jfr\/event\/metadata\/TestLookForUntestedEvents.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+    public static final String SafepointLatency = PREFIX + \"SafepointLatency\";\n","filename":"test\/lib\/jdk\/test\/lib\/jfr\/EventNames.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}