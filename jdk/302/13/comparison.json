{"files":[{"patch":"@@ -2709,16 +2709,1 @@\n-void Assembler::evmovdqu(XMMRegister dst, KRegister mask, Address src, int vector_len, int type) {\n-  assert(VM_Version::supports_avx512vlbw(), \"\");\n-  assert(type == T_BYTE || type == T_SHORT || type == T_CHAR || type == T_INT || type == T_LONG, \"\");\n-  InstructionMark im(this);\n-  bool wide = type == T_SHORT || type == T_CHAR || type == T_LONG;\n-  int prefix = (type == T_BYTE ||  type == T_SHORT || type == T_CHAR) ? VEX_SIMD_F2 : VEX_SIMD_F3;\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ wide, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n-  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n-  attributes.set_embedded_opmask_register_specifier(mask);\n-  attributes.set_is_evex_instruction();\n-  vex_prefix(src, 0, dst->encoding(), (Assembler::VexSimdPrefix)prefix, VEX_OPCODE_0F, &attributes);\n-  emit_int8(0x6F);\n-  emit_operand(dst, src);\n-}\n-\n-void Assembler::evmovdqu(Address dst, KRegister mask, XMMRegister src, int vector_len, int type) {\n+void Assembler::evmovdqub(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len) {\n@@ -2727,1 +2712,0 @@\n-  assert(type == T_BYTE || type == T_SHORT || type == T_CHAR || type == T_INT || type == T_LONG, \"\");\n@@ -2729,3 +2713,1 @@\n-  bool wide = type == T_SHORT || type == T_CHAR || type == T_LONG;\n-  int prefix = (type == T_BYTE ||  type == T_SHORT || type == T_CHAR) ? VEX_SIMD_F2 : VEX_SIMD_F3;\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ wide, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n@@ -2733,1 +2715,0 @@\n-  attributes.reset_is_clear_context();\n@@ -2736,1 +2717,4 @@\n-  vex_prefix(dst, 0, src->encoding(), (Assembler::VexSimdPrefix)prefix, VEX_OPCODE_0F, &attributes);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  vex_prefix(dst, 0, src->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":6,"deletions":22,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -1547,0 +1547,1 @@\n+  void evmovdqub(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len);\n@@ -1564,4 +1565,0 @@\n-  \/\/ Generic move instructions.\n-  void evmovdqu(Address dst, KRegister mask, XMMRegister src, int vector_len, int type);\n-  void evmovdqu(XMMRegister dst, KRegister mask, Address src, int vector_len, int type);\n-\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1894,0 +1894,14 @@\n+\n+void C2_MacroAssembler::genmask(Register dst, Register len, Register temp) {\n+  if (ArrayCopyPartialInlineSize <= 32) {\n+    mov64(dst, 1);\n+    shlxq(dst, dst, len);\n+    decq(dst);\n+  } else {\n+    mov64(dst, -1);\n+    movq(temp, len);\n+    negptr(temp);\n+    addptr(temp, 64);\n+    shrxq(dst, dst, temp);\n+  }\n+}\n@@ -1940,0 +1954,9 @@\n+void C2_MacroAssembler::evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len) {\n+  MacroAssembler::evmovdqu(type, kmask, dst, src, vector_len);\n+}\n+\n+void C2_MacroAssembler::evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len) {\n+  MacroAssembler::evmovdqu(type, kmask, dst, src, vector_len);\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -123,0 +123,3 @@\n+  void evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len);\n+  void evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len);\n+\n@@ -142,0 +145,1 @@\n+  void genmask(Register dst, Register len, Register temp);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -8012,0 +8012,50 @@\n+\n+void MacroAssembler::evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evmovdqub(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evmovdquw(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evmovdqul(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evmovdquq(dst, kmask, src, false, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evmovdqub(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evmovdquw(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evmovdqul(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evmovdquq(dst, kmask, src, true, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -1096,0 +1096,3 @@\n+  void evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len);\n+  void evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len);\n+\n@@ -1100,0 +1103,1 @@\n+  void evmovdqub(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len) { Assembler::evmovdqub(dst, mask, src, merge, vector_len); }\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -203,2 +203,2 @@\n-    evmovdqu(xmm, mask, Address(src, index, scale, offset), Assembler::AVX_512bit, type[shift]);\n-    evmovdqu(Address(dst, index, scale, offset), mask, xmm, Assembler::AVX_512bit, type[shift]);\n+    evmovdqu(type[shift], mask, xmm, Address(src, index, scale, offset), Assembler::AVX_512bit);\n+    evmovdqu(type[shift], mask, Address(dst, index, scale, offset), xmm, Assembler::AVX_512bit);\n@@ -219,2 +219,2 @@\n-  evmovdqu(xmm, mask, Address(src, index, scale, offset), Assembler::AVX_256bit, type[shift]);\n-  evmovdqu(Address(dst, index, scale, offset), mask, xmm, Assembler::AVX_256bit, type[shift]);\n+  evmovdqu(type[shift], mask, xmm, Address(src, index, scale, offset), Assembler::AVX_256bit);\n+  evmovdqu(type[shift], mask, Address(dst, index, scale, offset), xmm, Assembler::AVX_256bit);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_arrayCopy_avx3.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1365,0 +1365,1 @@\n+\n@@ -1402,0 +1403,32 @@\n+#ifdef COMPILER2\n+    if (UseAVX > 2) {\n+      if (FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize) ||\n+          (!FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize) &&\n+           ArrayCopyPartialInlineSize != 0 &&\n+           ArrayCopyPartialInlineSize != 32 &&\n+           ArrayCopyPartialInlineSize != 16 &&\n+           ArrayCopyPartialInlineSize != 64)) {\n+        int inline_size = 0;\n+        if (MaxVectorSize >= 64 && AVX3Threshold == 0) {\n+          inline_size = 64;\n+        } else if (MaxVectorSize >= 32) {\n+          inline_size = 32;\n+        } else if (MaxVectorSize >= 16) {\n+          inline_size = 16;\n+        }\n+        if(!FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize)) {\n+          warning(\"Setting ArrayCopyPartialInlineSize as %d\", inline_size);\n+        }\n+        ArrayCopyPartialInlineSize = inline_size;\n+      }\n+\n+      if (ArrayCopyPartialInlineSize > MaxVectorSize) {\n+        ArrayCopyPartialInlineSize = MaxVectorSize >= 16 ? MaxVectorSize : 0;\n+        if (ArrayCopyPartialInlineSize) {\n+          warning(\"Setting ArrayCopyPartialInlineSize as MaxVectorSize\" INTX_FORMAT \")\", MaxVectorSize);\n+        } else {\n+          warning(\"Setting ArrayCopyPartialInlineSize as \" INTX_FORMAT, ArrayCopyPartialInlineSize);\n+        }\n+      }\n+    }\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -1524,0 +1524,7 @@\n+    case Op_VectorMaskGen:\n+    case Op_LoadVectorMasked:\n+    case Op_StoreVectorMasked:\n+      if (UseAVX < 3) {\n+        return false;\n+      }\n+      break;\n@@ -1597,0 +1604,10 @@\n+    case Op_VectorMaskGen:\n+    case Op_LoadVectorMasked:\n+    case Op_StoreVectorMasked:\n+      if (!VM_Version::supports_avx512bw()) {\n+        return false;\n+      }\n+      if ((size_in_bits != 512) && !VM_Version::supports_avx512vl()) {\n+        return false;\n+      }\n+      break;\n@@ -7897,0 +7914,47 @@\n+#ifdef _LP64\n+\/\/ ---------------------------------- Masked Block Copy ------------------------------------\n+\n+instruct vmasked_load64(vec dst, memory mem, rRegL mask) %{\n+  match(Set dst (LoadVectorMasked mem mask));\n+  format %{ \"vector_masked_load $dst, $mem, $mask \\t! vector masked copy\" %}\n+  ins_encode %{\n+    BasicType elmType =  this->bottom_type()->is_vect()->element_basic_type();\n+    int vector_len = vector_length_encoding(this);\n+    __ kmovql(k2, $mask$$Register);\n+    __ evmovdqu(elmType, k2, $dst$$XMMRegister, $mem$$Address, vector_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_gen(rRegL dst, rRegL len, rRegL tempLen) %{\n+  match(Set dst (VectorMaskGen len));\n+  effect(TEMP_DEF dst, TEMP tempLen);\n+  format %{ \"vector_mask_gen $len \\t! vector mask generator\" %}\n+  ins_encode %{\n+    __ genmask($dst$$Register, $len$$Register, $tempLen$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmask_gen_imm(rRegL dst, immL len) %{\n+  match(Set dst (VectorMaskGen len));\n+  format %{ \"vector_mask_gen $len \\t! vector mask generator\" %}\n+  ins_encode %{\n+    __ mov64($dst$$Register, (1L << ($len$$constant & 63)) -1);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmasked_store64(memory mem, vec src, rRegL mask) %{\n+  match(Set mem (StoreVectorMasked mem (Binary src mask)));\n+  format %{ \"vector_masked_store $mem, $src, $mask \\t! vector masked store\" %}\n+  ins_encode %{\n+    const MachNode* src_node = static_cast<const MachNode*>(this->in(this->operand_index($src)));\n+    BasicType elmType =  src_node->bottom_type()->is_vect()->element_basic_type();\n+    int vector_len = vector_length_encoding(src_node);\n+    __ kmovql(k2, $mask$$Register);\n+    __ evmovdqu(elmType, k2, $mem$$Address, $src$$XMMRegister, vector_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":64,"deletions":0,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -272,0 +272,1 @@\n+  if( strcmp(opType,\"LoadVectorMasked\")==0 )  return Form::idealV;\n@@ -289,0 +290,1 @@\n+  if( strcmp(opType,\"StoreVectorMasked\")==0 )  return Form::idealV;\n","filename":"src\/hotspot\/share\/adlc\/forms.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -782,0 +782,1 @@\n+       !strcmp(_matrule->_rChild->_opType,\"VectorMaskGen\")||\n@@ -3487,1 +3488,1 @@\n-    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\",\n+    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n@@ -4179,1 +4180,1 @@\n-    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\n+    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\"LoadVectorMasked\",\"StoreVectorMasked\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -687,0 +687,2 @@\n+  } else if (mb->trailing_partial_array_copy()) {\n+    return true;\n@@ -733,0 +735,13 @@\n+\n+\/\/ As an optimization, choose optimum vector size for copy length known at compile time.\n+int ArrayCopyNode::get_partial_inline_vector_lane_count(BasicType type, int const_len) {\n+  int lane_count = ArrayCopyPartialInlineSize\/type2aelembytes(type);\n+  if (const_len > 0) {\n+    int size_in_bytes = const_len * type2aelembytes(type);\n+    if (size_in_bytes <= 16)\n+      lane_count = 16\/type2aelembytes(type);\n+    else if (size_in_bytes > 16 && size_in_bytes <= 32)\n+      lane_count = 32\/type2aelembytes(type);\n+  }\n+  return lane_count;\n+}\n","filename":"src\/hotspot\/share\/opto\/arraycopynode.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -183,0 +183,3 @@\n+\n+  static int get_partial_inline_vector_lane_count(BasicType type, int const_len);\n+\n","filename":"src\/hotspot\/share\/opto\/arraycopynode.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -83,0 +83,4 @@\n+  product(intx, ArrayCopyPartialInlineSize, -1, DIAGNOSTIC,                 \\\n+          \"Partial inline size used for array copy acceleration.\")          \\\n+          range(-1, 64)                                                     \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -408,0 +408,3 @@\n+macro(LoadVectorMasked)\n+macro(StoreVectorMasked)\n+macro(VectorMaskGen)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -3355,0 +3355,3 @@\n+  case Op_VectorMaskGen:\n+  case Op_LoadVectorMasked:\n+  case Op_StoreVectorMasked:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -690,0 +690,1 @@\n+        case Op_StoreVectorMasked:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -246,2 +246,4 @@\n-          assert(ac != NULL && ac->is_clonebasic(), \"Only basic clone is a non escaping clone\");\n-          return ac;\n+          if (ac != NULL) {\n+            assert(ac->is_clonebasic(), \"Only basic clone is a non escaping clone\");\n+            return ac;\n+          }\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -129,0 +129,5 @@\n+\n+  bool generate_partial_inlining_block(Node** ctrl, MergeMemNode** mem, const TypePtr* adr_type,\n+                                       RegionNode** exit_block, Node** result_memory, Node* length,\n+                                       Node* src_start, Node* dst_start, BasicType type);\n+\n@@ -177,1 +182,1 @@\n-  void generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n+  bool generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"opto\/vectornode.hpp\"\n@@ -172,0 +173,124 @@\n+\/\/\n+\/\/ Partial in-lining handling for smaller conjoint\/disjoint array copies having\n+\/\/ length(in bytes) less than ArrayCopyPartialInlineSize.\n+\/\/  if (length <= ArrayCopyPartialInlineSize) {\n+\/\/    partial_inlining_block:\n+\/\/      mask = Mask_Gen\n+\/\/      vload = LoadVectorMasked src , mask\n+\/\/      StoreVectorMasked dst, mask, vload\n+\/\/  } else {\n+\/\/    stub_block:\n+\/\/      callstub array_copy\n+\/\/  }\n+\/\/  exit_block:\n+\/\/    Phi = label partial_inlining_block:mem , label stub_block:mem (filled by caller)\n+\/\/    mem = MergeMem (Phi)\n+\/\/    control = stub_block\n+\/\/\n+\/\/  Exit_block and associated phi(memory) are partially initialized for partial_in-lining_block\n+\/\/  edges. Remaining edges for exit_block coming from stub_block are connected by the caller\n+\/\/  post stub nodes creation.\n+\/\/\n+\/\/  Constant copy length operation having size less than ArrayCopyPartialInlineSize prevents\n+\/\/  creation of additional control flow for stub_block and exit_block.\n+\/\/\n+\/\/  Return true to emit subsequent stub calling code.\n+\/\/\n+\n+bool PhaseMacroExpand::generate_partial_inlining_block(Node** ctrl, MergeMemNode** mem, const TypePtr* adr_type,\n+                                                       RegionNode** exit_block, Node** result_memory, Node* length,\n+                                                       Node* src_start, Node* dst_start, BasicType type) {\n+  const TypePtr *src_adr_type = _igvn.type(src_start)->isa_ptr();\n+\n+  Node* orig_mem = *mem;\n+  Node* is_lt64bytes_tp = NULL;\n+  Node* is_lt64bytes_fp = NULL;\n+\n+  int const_len = -1;\n+  const TypeInt* lty = NULL;\n+  uint shift  = exact_log2(type2aelembytes(type));\n+  if (length->Opcode() == Op_ConvI2L && (lty = _igvn.type(length->in(1))->isa_int()) && lty->is_con()) {\n+    const_len = lty->get_con() << shift;\n+  } else if ((lty = _igvn.type(length)->isa_int()) && lty->is_con()) {\n+    const_len = lty->get_con() << shift;\n+  }\n+\n+  \/\/ Return if copy length is greater than partial inline size limit or\n+  \/\/ target does not supports masked load\/stores.\n+  int lane_count = ArrayCopyNode::get_partial_inline_vector_lane_count(type, const_len);\n+  if ( const_len > ArrayCopyPartialInlineSize ||\n+      !Matcher::match_rule_supported_vector(Op_LoadVectorMasked, lane_count, type)  ||\n+      !Matcher::match_rule_supported_vector(Op_StoreVectorMasked, lane_count, type) ||\n+      !Matcher::match_rule_supported_vector(Op_VectorMaskGen, lane_count, type)) {\n+    return true;\n+  }\n+\n+  Node* inline_block = NULL;\n+  \/\/ Emit length comparison check for non-constant length.\n+  if (const_len < 0) {\n+    Node* copy_bytes = new LShiftXNode(length, intcon(shift));\n+    transform_later(copy_bytes);\n+\n+    Node* cmp_le = new CmpULNode(copy_bytes, longcon(ArrayCopyPartialInlineSize));\n+    transform_later(cmp_le);\n+    Node* bol_le = new BoolNode(cmp_le, BoolTest::le);\n+    transform_later(bol_le);\n+    is_lt64bytes_tp  = generate_guard(ctrl, bol_le, NULL, PROB_FAIR);\n+    is_lt64bytes_fp = *ctrl;\n+\n+    inline_block = is_lt64bytes_tp;\n+  } else {\n+    inline_block = *ctrl;\n+  }\n+\n+  Node* mask_gen =  new VectorMaskGenNode(length, TypeLong::LONG, Type::get_const_basic_type(type));\n+  transform_later(mask_gen);\n+\n+  unsigned vec_size = lane_count *  type2aelembytes(type);\n+  if (C->max_vector_size() < vec_size) {\n+    C->set_max_vector_size(vec_size);\n+  }\n+\n+  int alias_idx = C->get_alias_index(src_adr_type);\n+  Node* mm = (*mem)->memory_at(alias_idx);\n+  const TypeVect * vt = TypeVect::make(type, lane_count);\n+  Node* masked_load = new LoadVectorMaskedNode(inline_block, mm, src_start,\n+                                               src_adr_type, vt, mask_gen);\n+  transform_later(masked_load);\n+\n+  mm = (*mem)->memory_at(C->get_alias_index(adr_type));\n+  Node* masked_store = new StoreVectorMaskedNode(inline_block, mm, dst_start,\n+                                                 masked_load, adr_type, mask_gen);\n+  transform_later(masked_store);\n+\n+  \/\/ Stub region is created for non-constant copy length.\n+  if (const_len < 0) {\n+    \/\/ Region containing stub calling node.\n+    Node* stub_block = is_lt64bytes_fp;\n+\n+    \/\/ Convergence region for inline_block and stub_block.\n+    *exit_block = new RegionNode(3);\n+    transform_later(*exit_block);\n+    (*exit_block)->init_req(1, is_lt64bytes_tp);\n+    *result_memory = new PhiNode(*exit_block, Type::MEMORY, adr_type);\n+    transform_later(*result_memory);\n+    (*result_memory)->init_req(1, masked_store);\n+\n+    *ctrl = stub_block;\n+    return true;\n+  } else {\n+    \/\/ Prevent stub call generation for constant length less\n+    \/\/ than partial inline size.\n+    uint alias_idx = C->get_alias_index(adr_type);\n+    if (alias_idx != Compile::AliasIdxBot) {\n+      *mem = MergeMemNode::make(*mem);\n+      (*mem)->set_memory_at(alias_idx, masked_store);\n+    } else {\n+      *mem = MergeMemNode::make(masked_store);\n+    }\n+    transform_later(*mem);\n+    return false;\n+  }\n+}\n+\n+\n@@ -562,0 +687,1 @@\n+  bool is_partial_array_copy = false;\n@@ -568,4 +694,4 @@\n-    generate_unchecked_arraycopy(&local_ctrl, &local_mem,\n-                                 adr_type, copy_type, disjoint_bases,\n-                                 src, src_offset, dest, dest_offset,\n-                                 ConvI2X(copy_length), dest_uninitialized);\n+    is_partial_array_copy = generate_unchecked_arraycopy(&local_ctrl, &local_mem,\n+                                                         adr_type, copy_type, disjoint_bases,\n+                                                         src, src_offset, dest, dest_offset,\n+                                                         ConvI2X(copy_length), dest_uninitialized);\n@@ -718,0 +844,6 @@\n+  if (is_partial_array_copy) {\n+    assert((*ctrl)->is_Proj(), \"MemBar control projection\");\n+    assert((*ctrl)->in(0)->isa_MemBar(), \"MemBar node\");\n+    (*ctrl)->in(0)->isa_MemBar()->set_trailing_partial_array_copy();\n+  }\n+\n@@ -724,1 +856,1 @@\n-  if (dest_t->is_known_instance()) {\n+  if (dest_t->is_known_instance() && !is_partial_array_copy) {\n@@ -1056,1 +1188,1 @@\n-void PhaseMacroExpand::generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n+bool PhaseMacroExpand::generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n@@ -1063,1 +1195,1 @@\n-  if ((*ctrl)->is_top()) return;\n+  if ((*ctrl)->is_top()) return false;\n@@ -1078,3 +1210,8 @@\n-  const TypeFunc* call_type = OptoRuntime::fast_arraycopy_Type();\n-  Node* call = make_leaf_call(*ctrl, *mem, call_type, copyfunc_addr, copyfunc_name, adr_type,\n-                              src_start, dest_start, copy_length XTOP);\n+  Node* result_memory = NULL;\n+  RegionNode* exit_block = NULL;\n+  bool gen_stub_call = true;\n+  if (ArrayCopyPartialInlineSize > 0 && is_subword_type(basic_elem_type) &&\n+    Matcher::vector_width_in_bytes(basic_elem_type) >= 16) {\n+    gen_stub_call = generate_partial_inlining_block(ctrl, mem, adr_type, &exit_block, &result_memory,\n+                                                    copy_length, src_start, dest_start, basic_elem_type);\n+  }\n@@ -1082,1 +1219,27 @@\n-  finish_arraycopy_call(call, ctrl, mem, adr_type);\n+  if (gen_stub_call) {\n+    const TypeFunc* call_type = OptoRuntime::fast_arraycopy_Type();\n+    Node* call = make_leaf_call(*ctrl, *mem, call_type, copyfunc_addr, copyfunc_name, adr_type,\n+                                src_start, dest_start, copy_length XTOP);\n+\n+    finish_arraycopy_call(call, ctrl, mem, adr_type);\n+  }\n+\n+  \/\/ Connecting remaining edges for exit_block coming from stub_block.\n+  if (exit_block) {\n+    exit_block->init_req(2, *ctrl);\n+\n+    \/\/ Memory edge corresponding to stub_region.\n+    result_memory->init_req(2, *mem);\n+\n+    uint alias_idx = C->get_alias_index(adr_type);\n+    if (alias_idx != Compile::AliasIdxBot) {\n+      *mem = MergeMemNode::make(*mem);\n+      (*mem)->set_memory_at(alias_idx, result_memory);\n+    } else {\n+      *mem = MergeMemNode::make(result_memory);\n+    }\n+    transform_later(*mem);\n+    *ctrl = exit_block;\n+    return true;\n+  }\n+  return false;\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":174,"deletions":11,"binary":false,"changes":185,"status":"modified"},{"patch":"@@ -2204,0 +2204,1 @@\n+    case Op_LoadVectorMasked:\n@@ -2306,0 +2307,6 @@\n+    case Op_StoreVectorMasked: {\n+      Node* pair = new BinaryNode(n->in(3), n->in(4));\n+      n->set_req(3, pair);\n+      n->del_req(4);\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1193,1 +1193,2 @@\n-    LeadingLoadStore\n+    LeadingLoadStore,\n+    TrailingPartialArrayCopy\n@@ -1230,0 +1231,2 @@\n+  void set_trailing_partial_array_copy() { _kind = TrailingPartialArrayCopy; }\n+  bool trailing_partial_array_copy() const { return _kind == TrailingPartialArrayCopy; }\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -156,0 +156,2 @@\n+class LoadVectorMaskedNode;\n+class StoreVectorMaskedNode;\n@@ -692,2 +694,2 @@\n-    DEFINE_CLASS_ID(Mem,   Node, 4)\n-      DEFINE_CLASS_ID(Load,  Mem, 0)\n+    DEFINE_CLASS_ID(Mem, Node, 4)\n+      DEFINE_CLASS_ID(Load, Mem, 0)\n@@ -696,0 +698,1 @@\n+          DEFINE_CLASS_ID(LoadVectorMasked, LoadVector, 1)\n@@ -699,0 +702,1 @@\n+          DEFINE_CLASS_ID(StoreVectorMasked, StoreVector, 1)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -762,0 +762,35 @@\n+Node* LoadVectorMaskedNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* mask_len = in(3)->in(1);\n+  const TypeLong* ty = phase->type(mask_len)->isa_long();\n+  if (ty && ty->is_con()) {\n+    BasicType mask_bt = ((VectorMaskGenNode*)in(3))->get_elem_type()->array_element_basic_type();\n+    uint load_sz      = type2aelembytes(mask_bt) * ty->get_con();\n+    if ( load_sz == 32 || load_sz == 64) {\n+      assert(load_sz == 32 || MaxVectorSize > 32, \"Unexpected load size\");\n+      Node* ctr = in(MemNode::Control);\n+      Node* mem = in(MemNode::Memory);\n+      Node* adr = in(MemNode::Address);\n+      return phase->transform(new LoadVectorNode(ctr, mem, adr, adr_type(), vect_type()));\n+    }\n+  }\n+  return NULL;\n+}\n+\n+Node* StoreVectorMaskedNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* mask_len = in(4)->in(1);\n+  const TypeLong* ty = phase->type(mask_len)->isa_long();\n+  if (ty && ty->is_con()) {\n+    BasicType mask_bt = ((VectorMaskGenNode*)in(4))->get_elem_type()->array_element_basic_type();\n+    uint load_sz      = type2aelembytes(mask_bt) * ty->get_con();\n+    if ( load_sz == 32 || load_sz == 64) {\n+      assert(load_sz == 32 || MaxVectorSize > 32, \"Unexpected store size\");\n+      Node* ctr = in(MemNode::Control);\n+      Node* mem = in(MemNode::Memory);\n+      Node* adr = in(MemNode::Address);\n+      Node* val = in(MemNode::ValueIn);\n+      return phase->transform(new StoreVectorNode(ctr, mem, adr, adr_type(), val));\n+    }\n+  }\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":35,"deletions":0,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -781,0 +781,50 @@\n+class StoreVectorMaskedNode : public StoreVectorNode {\n+ public:\n+  StoreVectorMaskedNode(Node* c, Node* mem, Node* dst, Node* src, const TypePtr* at, Node* mask)\n+   : StoreVectorNode(c, mem, dst, at, src) {\n+    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    init_class_id(Class_StoreVector);\n+    set_mismatched_access();\n+    add_req(mask);\n+  }\n+\n+  virtual int Opcode() const;\n+\n+  virtual uint match_edge(uint idx) const {\n+    return idx > 1;\n+  }\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+};\n+\n+class LoadVectorMaskedNode : public LoadVectorNode {\n+ public:\n+  LoadVectorMaskedNode(Node* c, Node* mem, Node* src, const TypePtr* at, const TypeVect* vt, Node* mask)\n+   : LoadVectorNode(c, mem, src, at, vt) {\n+    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    init_class_id(Class_LoadVector);\n+    set_mismatched_access();\n+    add_req(mask);\n+  }\n+\n+  virtual int Opcode() const;\n+\n+  virtual uint match_edge(uint idx) const {\n+    return idx > 1;\n+  }\n+  Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+};\n+\n+class VectorMaskGenNode : public TypeNode {\n+ public:\n+  VectorMaskGenNode(Node* length, const Type* ty, const Type* ety): TypeNode(ty, 2), _elemType(ety) {\n+    init_req(1, length);\n+  }\n+\n+  virtual int Opcode() const;\n+  const Type* get_elem_type()  { return _elemType;}\n+  virtual  uint  size_of() const { return sizeof(VectorMaskGenNode); }\n+\n+  private:\n+   const Type* _elemType;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"}]}