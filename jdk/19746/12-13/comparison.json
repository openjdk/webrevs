{"files":[{"patch":"@@ -44,1 +44,4 @@\n-#endif\n+#endif \/\/ COMPILER1\n+#ifdef COMPILER2\n+#include \"gc\/g1\/c2\/g1BarrierSetC2.hpp\"\n+#endif \/\/ COMPILER2\n@@ -48,0 +51,7 @@\n+static void generate_marking_inactive_test(MacroAssembler* masm) {\n+  int active_offset = in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset());\n+  assert(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, \"Assumption\");\n+  __ lbz(R0, active_offset, R16_thread);  \/\/ tmp1 := *(mark queue active address)\n+  __ cmpwi(CCR0, R0, 0);\n+}\n+\n@@ -61,7 +71,1 @@\n-    if (in_bytes(SATBMarkQueue::byte_width_of_active()) == 4) {\n-      __ lwz(R0, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()), R16_thread);\n-    } else {\n-      guarantee(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, \"Assumption\");\n-      __ lbz(R0, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()), R16_thread);\n-    }\n-    __ cmpdi(CCR0, R0, 0);\n+    generate_marking_inactive_test(masm);\n@@ -112,0 +116,15 @@\n+static void generate_queue_insertion(MacroAssembler* masm, ByteSize index_offset, ByteSize buffer_offset, Label& runtime,\n+                                     const Register value, const Register temp) {\n+  assert_different_registers(value, temp);\n+  \/\/ Can we store a value in the given thread's buffer?\n+  \/\/ (The index field is typed as size_t.)\n+  __ ld(temp, in_bytes(index_offset), R16_thread);  \/\/ temp := *(index address)\n+  __ cmpdi(CCR0, temp, 0);                          \/\/ jump to runtime if index == 0 (full buffer)\n+  __ beq(CCR0, runtime);\n+  \/\/ The buffer is not full, store value into it.\n+  __ ld(R0, in_bytes(buffer_offset), R16_thread);   \/\/ R0 := buffer address\n+  __ addi(temp, temp, -wordSize);                   \/\/ temp := next index\n+  __ std(temp, in_bytes(index_offset), R16_thread); \/\/ *(index address) := next index\n+  __ stdx(value, temp, R0);                         \/\/ *(buffer address + next index) := value\n+}\n+\n@@ -116,0 +135,2 @@\n+  assert_different_registers(pre_val, tmp1, tmp2);\n+\n@@ -120,1 +141,7 @@\n-  if (preloaded) {\n+  \/\/ Determine necessary runtime invocation preservation measures\n+  const bool needs_frame = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR;\n+  const bool preserve_gp_registers = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR_GP_REGS;\n+  const bool preserve_fp_registers = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR_GP_FP_REGS;\n+  int nbytes_save = 0;\n+\n+  if (pre_val->is_volatile() && preloaded && !preserve_gp_registers) {\n@@ -124,5 +151,2 @@\n-    assert_different_registers(pre_val, tmp1, tmp2);\n-    if (pre_val->is_volatile()) {\n-      nv_save = !tmp1->is_volatile() ? tmp1 : tmp2;\n-      assert(!nv_save->is_volatile(), \"need one nv temp register if pre_val lives in volatile register\");\n-    }\n+    nv_save = !tmp1->is_volatile() ? tmp1 : tmp2;\n+    assert(!nv_save->is_volatile(), \"need one nv temp register if pre_val lives in volatile register\");\n@@ -133,8 +157,1 @@\n-  \/\/ Is marking active?\n-  if (in_bytes(SATBMarkQueue::byte_width_of_active()) == 4) {\n-    __ lwz(tmp1, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()), R16_thread);\n-  } else {\n-    guarantee(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, \"Assumption\");\n-    __ lbz(tmp1, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()), R16_thread);\n-  }\n-  __ cmpdi(CCR0, tmp1, 0);\n+  generate_marking_inactive_test(masm);\n@@ -178,12 +195,2 @@\n-  const Register Rbuffer = tmp1, Rindex = tmp2;\n-\n-  __ ld(Rindex, in_bytes(G1ThreadLocalData::satb_mark_queue_index_offset()), R16_thread);\n-  __ cmpdi(CCR0, Rindex, 0);\n-  __ beq(CCR0, runtime); \/\/ If index == 0, goto runtime.\n-  __ ld(Rbuffer, in_bytes(G1ThreadLocalData::satb_mark_queue_buffer_offset()), R16_thread);\n-\n-  __ addi(Rindex, Rindex, -wordSize); \/\/ Decrement index.\n-  __ std(Rindex, in_bytes(G1ThreadLocalData::satb_mark_queue_index_offset()), R16_thread);\n-\n-  \/\/ Record the previous value.\n-  __ stdx(pre_val, Rbuffer, Rindex);\n+  generate_queue_insertion(masm, G1ThreadLocalData::satb_mark_queue_index_offset(), G1ThreadLocalData::satb_mark_queue_buffer_offset(),\n+                           runtime, pre_val, tmp1);\n@@ -194,6 +201,0 @@\n-  \/\/ Determine necessary runtime invocation preservation measures\n-  const bool needs_frame = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR;\n-  const bool preserve_gp_registers = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR_GP_REGS;\n-  const bool preserve_fp_registers = preservation_level >= MacroAssembler::PRESERVATION_FRAME_LR_GP_FP_REGS;\n-  int nbytes_save = 0;\n-\n@@ -213,1 +214,1 @@\n-  if (pre_val->is_volatile() && preloaded && !preserve_gp_registers) {\n+  if (nv_save != noreg) {\n@@ -217,1 +218,1 @@\n-  if (pre_val->is_volatile() && preloaded && !preserve_gp_registers) {\n+  if (nv_save != noreg) {\n@@ -233,0 +234,20 @@\n+static void generate_region_crossing_test(MacroAssembler* masm, const Register store_addr, const Register new_val) {\n+  __ xorr(R0, store_addr, new_val);                  \/\/ tmp1 := store address ^ new value\n+  __ srdi_(R0, R0, G1HeapRegion::LogOfHRGrainBytes); \/\/ tmp1 := ((store address ^ new value) >> LogOfHRGrainBytes)\n+}\n+\n+static Address generate_card_young_test(MacroAssembler* masm, const Register store_addr, const Register tmp1, const Register tmp2) {\n+  CardTableBarrierSet* ct = barrier_set_cast<CardTableBarrierSet>(BarrierSet::barrier_set());\n+  __ load_const_optimized(tmp1, (address)(ct->card_table()->byte_map_base()), tmp2);\n+  __ srdi(tmp2, store_addr, CardTable::card_shift());        \/\/ tmp1 := card address relative to card table base\n+  __ lbzx(R0, tmp1, tmp2);                                   \/\/ tmp1 := card address\n+  __ cmpwi(CCR0, R0, (int)G1CardTable::g1_young_card_val());\n+  return Address(tmp1, tmp2); \/\/ return card address\n+}\n+\n+static void generate_card_dirty_test(MacroAssembler* masm, Address card_addr) {\n+  __ membar(Assembler::StoreLoad);                        \/\/ Must reload after StoreLoad membar due to concurrent refinement\n+  __ lbzx(R0, card_addr.base(), card_addr.index());       \/\/ tmp2 := card\n+  __ cmpwi(CCR0, R0, (int)G1CardTable::dirty_card_val()); \/\/ tmp2 := card == dirty_card_val?\n+}\n+\n@@ -244,3 +265,1 @@\n-  \/\/ Does store cross heap regions?\n-  __ xorr(tmp1, store_addr, new_val);\n-  __ srdi_(tmp1, tmp1, G1HeapRegion::LogOfHRGrainBytes);\n+  generate_region_crossing_test(masm, store_addr, new_val);\n@@ -260,10 +279,1 @@\n-  \/\/ Storing region crossing non-null, is card already dirty?\n-  const Register Rcard_addr = tmp1;\n-  Register Rbase = tmp2;\n-  __ load_const_optimized(Rbase, (address)(ct->card_table()->byte_map_base()), \/*temp*\/ tmp3);\n-\n-  __ srdi(Rcard_addr, store_addr, CardTable::card_shift());\n-\n-  \/\/ Get the address of the card.\n-  __ lbzx(\/*card value*\/ tmp3, Rbase, Rcard_addr);\n-  __ cmpwi(CCR0, tmp3, (int)G1CardTable::g1_young_card_val());\n+  Address card_addr = generate_card_young_test(masm, store_addr, tmp1, tmp2);\n@@ -272,3 +282,1 @@\n-  __ membar(Assembler::StoreLoad);\n-  __ lbzx(\/*card value*\/ tmp3, Rbase, Rcard_addr);  \/\/ Reload after membar.\n-  __ cmpwi(CCR0, tmp3 \/* card value *\/, (int)G1CardTable::dirty_card_val());\n+  generate_card_dirty_test(masm, card_addr);\n@@ -277,15 +285,2 @@\n-  \/\/ Storing a region crossing, non-null oop, card is clean.\n-  \/\/ Dirty card and log.\n-  __ li(tmp3, (int)G1CardTable::dirty_card_val());\n-  \/\/release(); \/\/ G1: oops are allowed to get visible after dirty marking.\n-  __ stbx(tmp3, Rbase, Rcard_addr);\n-\n-  __ add(Rcard_addr, Rbase, Rcard_addr); \/\/ This is the address which needs to get enqueued.\n-  Rbase = noreg; \/\/ end of lifetime\n-\n-  const Register Rqueue_index = tmp2,\n-                 Rqueue_buf   = tmp3;\n-  __ ld(Rqueue_index, in_bytes(G1ThreadLocalData::dirty_card_queue_index_offset()), R16_thread);\n-  __ cmpdi(CCR0, Rqueue_index, 0);\n-  __ beq(CCR0, runtime); \/\/ index == 0 then jump to runtime\n-  __ ld(Rqueue_buf, in_bytes(G1ThreadLocalData::dirty_card_queue_buffer_offset()), R16_thread);\n+  __ li(R0, (int)G1CardTable::dirty_card_val());\n+  __ stbx(R0, card_addr.base(), card_addr.index()); \/\/ *(card address) := dirty_card_val\n@@ -293,2 +288,2 @@\n-  __ addi(Rqueue_index, Rqueue_index, -wordSize); \/\/ decrement index\n-  __ std(Rqueue_index, in_bytes(G1ThreadLocalData::dirty_card_queue_index_offset()), R16_thread);\n+  Register Rcard_addr = tmp3;\n+  __ add(Rcard_addr, card_addr.base(), card_addr.index()); \/\/ This is the address which needs to get enqueued.\n@@ -296,1 +291,4 @@\n-  __ stdx(Rcard_addr, Rqueue_buf, Rqueue_index); \/\/ store card\n+  generate_queue_insertion(masm,\n+                           G1ThreadLocalData::dirty_card_queue_index_offset(),\n+                           G1ThreadLocalData::dirty_card_queue_buffer_offset(),\n+                           runtime, Rcard_addr, tmp1);\n@@ -395,0 +393,136 @@\n+#ifdef COMPILER2\n+\n+static void generate_c2_barrier_runtime_call(MacroAssembler* masm, G1BarrierStubC2* stub, const Register arg, const address runtime_path) {\n+  SaveLiveRegisters save_registers(masm, stub);\n+  __ call_VM_leaf(runtime_path, arg, R16_thread);\n+}\n+\n+void G1BarrierSetAssembler::g1_write_barrier_pre_c2(MacroAssembler* masm,\n+                                                    Register obj,\n+                                                    Register pre_val,\n+                                                    Register tmp1,\n+                                                    Register tmp2,\n+                                                    G1PreBarrierStubC2* stub) {\n+  assert_different_registers(obj, tmp1, tmp2, R0);\n+  assert_different_registers(pre_val, tmp1, R0);\n+  assert(!UseCompressedOops || tmp2 != noreg, \"tmp2 needed with CompressedOops\");\n+\n+  stub->initialize_registers(obj, pre_val, R16_thread, tmp1, tmp2);\n+\n+  generate_marking_inactive_test(masm);\n+  __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CCR0, Assembler::equal), *stub->entry());\n+\n+  __ bind(*stub->continuation());\n+}\n+\n+void G1BarrierSetAssembler::generate_c2_pre_barrier_stub(MacroAssembler* masm,\n+                                                         G1PreBarrierStubC2* stub) const {\n+  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n+  Label runtime;\n+  Register obj = stub->obj();\n+  Register pre_val = stub->pre_val();\n+  Register tmp1 = stub->tmp1();\n+\n+  __ bind(*stub->entry());\n+\n+  if (obj != noreg) {\n+    \/\/ Note: C2 currently doesn't use implicit null checks with barriers.\n+    \/\/ Otherwise, obj could be null and the following instruction would raise a SIGSEGV.\n+    if (UseCompressedOops) {\n+      __ lwz(pre_val, 0, obj);\n+    } else {\n+      __ ld(pre_val, 0, obj);\n+    }\n+  }\n+  __ cmpdi(CCR0, pre_val, 0);\n+  __ bc_far_optimized(Assembler::bcondCRbiIs1, __ bi0(CCR0, Assembler::equal), *stub->continuation());\n+\n+  Register pre_val_decoded = pre_val;\n+  if (UseCompressedOops) {\n+    pre_val_decoded = __ decode_heap_oop_not_null(stub->tmp2(), pre_val);\n+  }\n+\n+  generate_queue_insertion(masm,\n+                           G1ThreadLocalData::satb_mark_queue_index_offset(),\n+                           G1ThreadLocalData::satb_mark_queue_buffer_offset(),\n+                           runtime, pre_val_decoded, tmp1);\n+  __ b(*stub->continuation());\n+\n+  __ bind(runtime);\n+  generate_c2_barrier_runtime_call(masm, stub, pre_val_decoded, CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_pre_entry));\n+  __ b(*stub->continuation());\n+}\n+\n+void G1BarrierSetAssembler::g1_write_barrier_post_c2(MacroAssembler* masm,\n+                                                     Register store_addr,\n+                                                     Register new_val,\n+                                                     Register tmp1,\n+                                                     Register tmp2,\n+                                                     G1PostBarrierStubC2* stub,\n+                                                     bool decode_new_val) {\n+  assert_different_registers(store_addr, new_val, tmp1, R0);\n+  assert_different_registers(store_addr, tmp1, tmp2, R0);\n+\n+  stub->initialize_registers(R16_thread, tmp1, tmp2);\n+\n+  bool null_check_required = (stub->barrier_data() & G1C2BarrierPostNotNull) == 0;\n+  Register new_val_decoded = new_val;\n+\n+  if (decode_new_val) {\n+    assert(UseCompressedOops, \"or should not be here\");\n+    if (null_check_required && CompressedOops::base() != nullptr) {\n+      \/\/ We prefer doing the null check after the region crossing check.\n+      \/\/ Only compressed oop modes with base != null require a null check here.\n+      __ cmpwi(CCR0, new_val, 0);\n+      __ beq(CCR0, *stub->continuation());\n+      null_check_required = false;\n+    }\n+    new_val_decoded = __ decode_heap_oop_not_null(tmp2, new_val);\n+  }\n+\n+  generate_region_crossing_test(masm, store_addr, new_val_decoded);\n+  __ beq(CCR0, *stub->continuation());\n+\n+  \/\/ crosses regions, storing null?\n+  if (null_check_required) {\n+    __ cmpdi(CCR0, new_val_decoded, 0);\n+    __ beq(CCR0, *stub->continuation());\n+  }\n+\n+  Address card_addr = generate_card_young_test(masm, store_addr, tmp1, tmp2);\n+  assert(card_addr.base() == tmp1 && card_addr.index() == tmp2, \"needed by post barrier stub\");\n+  __ bc_far_optimized(Assembler::bcondCRbiIs0, __ bi0(CCR0, Assembler::equal), *stub->entry());\n+\n+  __ bind(*stub->continuation());\n+}\n+\n+void G1BarrierSetAssembler::generate_c2_post_barrier_stub(MacroAssembler* masm,\n+                                                          G1PostBarrierStubC2* stub) const {\n+  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n+  Label runtime;\n+  Address card_addr(stub->tmp1(), stub->tmp2()); \/\/ See above.\n+\n+  __ bind(*stub->entry());\n+\n+  generate_card_dirty_test(masm, card_addr);\n+  __ bc_far_optimized(Assembler::bcondCRbiIs1, __ bi0(CCR0, Assembler::equal), *stub->continuation());\n+\n+  __ li(R0, (int)G1CardTable::dirty_card_val());\n+  __ stbx(R0, card_addr.base(), card_addr.index()); \/\/ *(card address) := dirty_card_val\n+\n+  Register Rcard_addr = stub->tmp1();\n+  __ add(Rcard_addr, card_addr.base(), card_addr.index()); \/\/ This is the address which needs to get enqueued.\n+\n+  generate_queue_insertion(masm,\n+                           G1ThreadLocalData::dirty_card_queue_index_offset(),\n+                           G1ThreadLocalData::dirty_card_queue_buffer_offset(),\n+                           runtime, Rcard_addr, stub->tmp2());\n+  __ b(*stub->continuation());\n+\n+  __ bind(runtime);\n+  generate_c2_barrier_runtime_call(masm, stub, Rcard_addr, CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_field_post_entry));\n+  __ b(*stub->continuation());\n+}\n+\n+#endif \/\/ COMPILER2\n+\n@@ -473,7 +607,1 @@\n-  if (in_bytes(SATBMarkQueue::byte_width_of_active()) == 4) {\n-    __ lwz(tmp, satb_q_active_byte_offset, R16_thread);\n-  } else {\n-    assert(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, \"Assumption\");\n-    __ lbz(tmp, satb_q_active_byte_offset, R16_thread);\n-  }\n-  __ cmpdi(CCR0, tmp, 0);\n+  generate_marking_inactive_test(sasm);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/g1\/g1BarrierSetAssembler_ppc.cpp","additions":211,"deletions":83,"binary":false,"changes":294,"status":"modified"},{"patch":"@@ -33,0 +33,4 @@\n+#ifdef COMPILER2\n+#include \"gc\/g1\/c2\/g1BarrierSetC2.hpp\"\n+#endif\n+\n@@ -37,0 +41,2 @@\n+class G1PreBarrierStubC2;\n+class G1PostBarrierStubC2;\n@@ -62,0 +68,19 @@\n+#ifdef COMPILER2\n+  void g1_write_barrier_pre_c2(MacroAssembler* masm,\n+                               Register obj,\n+                               Register pre_val,\n+                               Register tmp1,\n+                               Register tmp2,\n+                               G1PreBarrierStubC2* c2_stub);\n+  void generate_c2_pre_barrier_stub(MacroAssembler* masm,\n+                                    G1PreBarrierStubC2* stub) const;\n+  void g1_write_barrier_post_c2(MacroAssembler* masm,\n+                                Register store_addr,\n+                                Register new_val,\n+                                Register tmp1,\n+                                Register tmp2,\n+                                G1PostBarrierStubC2* c2_stub,\n+                                bool decode_new_val);\n+  void generate_c2_post_barrier_stub(MacroAssembler* masm,\n+                                     G1PostBarrierStubC2* stub) const;\n+#endif\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/g1\/g1BarrierSetAssembler_ppc.hpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -0,0 +1,713 @@\n+\/\/\n+\/\/ Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2024 SAP SE. All rights reserved.\n+\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+\/\/\n+\/\/ This code is free software; you can redistribute it and\/or modify it\n+\/\/ under the terms of the GNU General Public License version 2 only, as\n+\/\/ published by the Free Software Foundation.\n+\/\/\n+\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n+\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+\/\/ version 2 for more details (a copy is included in the LICENSE file that\n+\/\/ accompanied this code).\n+\/\/\n+\/\/ You should have received a copy of the GNU General Public License version\n+\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n+\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+\/\/\n+\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+\/\/ or visit www.oracle.com if you need additional information or have any\n+\/\/ questions.\n+\/\/\n+\n+source_hpp %{\n+\n+#include \"gc\/g1\/c2\/g1BarrierSetC2.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+\n+%}\n+\n+source %{\n+\n+#include \"gc\/g1\/g1BarrierSetAssembler_ppc.hpp\"\n+#include \"gc\/g1\/g1BarrierSetRuntime.hpp\"\n+\n+static void pre_write_barrier(MacroAssembler* masm,\n+                              const MachNode* node,\n+                              Register obj,\n+                              Register pre_val,\n+                              Register tmp1,\n+                              Register tmp2 = noreg, \/\/ only needed with CompressedOops when pre_val needs to be preserved\n+                              RegSet preserve = RegSet(),\n+                              RegSet no_preserve = RegSet()) {\n+  if (!G1PreBarrierStubC2::needs_barrier(node)) {\n+    return;\n+  }\n+  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n+  G1BarrierSetAssembler* g1_asm = static_cast<G1BarrierSetAssembler*>(BarrierSet::barrier_set()->barrier_set_assembler());\n+  G1PreBarrierStubC2* const stub = G1PreBarrierStubC2::create(node);\n+  for (RegSetIterator<Register> reg = preserve.begin(); *reg != noreg; ++reg) {\n+    stub->preserve(*reg);\n+  }\n+  for (RegSetIterator<Register> reg = no_preserve.begin(); *reg != noreg; ++reg) {\n+    stub->dont_preserve(*reg);\n+  }\n+  g1_asm->g1_write_barrier_pre_c2(masm, obj, pre_val, tmp1, (tmp2 != noreg) ? tmp2 : pre_val, stub);\n+}\n+\n+static void post_write_barrier(MacroAssembler* masm,\n+                               const MachNode* node,\n+                               Register store_addr,\n+                               Register new_val,\n+                               Register tmp1,\n+                               Register tmp2,\n+                               bool decode_new_val = false) {\n+  if (!G1PostBarrierStubC2::needs_barrier(node)) {\n+    return;\n+  }\n+  Assembler::InlineSkippedInstructionsCounter skip_counter(masm);\n+  G1BarrierSetAssembler* g1_asm = static_cast<G1BarrierSetAssembler*>(BarrierSet::barrier_set()->barrier_set_assembler());\n+  G1PostBarrierStubC2* const stub = G1PostBarrierStubC2::create(node);\n+  g1_asm->g1_write_barrier_post_c2(masm, store_addr, new_val, tmp1, tmp2, stub, decode_new_val);\n+}\n+\n+%}\n+\n+instruct g1StoreP(indirect mem, iRegPsrc src, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_Store()->barrier_data() != 0);\n+  match(Set mem (StoreP mem src));\n+  effect(TEMP tmp1, TEMP tmp2, KILL cr0);\n+  ins_cost(2 * MEMORY_REF_COST);\n+  format %{ \"std    $mem, $src\\t# ptr\" %}\n+  ins_encode %{\n+    pre_write_barrier(masm, this,\n+                      $mem$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      noreg,\n+                      RegSet::of($mem$$Register, $src$$Register) \/* preserve *\/);\n+    __ std($src$$Register, 0, $mem$$Register);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1StoreN(indirect mem, iRegNsrc src, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_Store()->barrier_data() != 0);\n+  match(Set mem (StoreN mem src));\n+  effect(TEMP tmp1, TEMP tmp2, KILL cr0);\n+  ins_cost(2 * MEMORY_REF_COST);\n+  format %{ \"stw    $mem, $src\\t# ptr\" %}\n+  ins_encode %{\n+    assert(!in(operand_index(2))->is_Mach() ||\n+           (in(operand_index(2))->as_Mach()->ideal_Opcode() != Op_EncodeP),\n+           \"EncodeP src nodes should be matched with their corresponding StoreN nodes\");\n+    pre_write_barrier(masm, this,\n+                      $mem$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      noreg,\n+                      RegSet::of($mem$$Register, $src$$Register) \/* preserve *\/);\n+    __ stw($src$$Register, 0, $mem$$Register);\n+    if ((barrier_data() & G1C2BarrierPost) != 0) {\n+      post_write_barrier(masm, this,\n+                         $mem$$Register,\n+                         $src$$Register \/* new_val *\/,\n+                         $tmp1$$Register,\n+                         $tmp2$$Register,\n+                         true \/* decode_new_val *\/);\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1EncodePAndStoreN(indirect mem, iRegPsrc src, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_Store()->barrier_data() != 0);\n+  match(Set mem (StoreN mem (EncodeP src)));\n+  effect(TEMP tmp1, TEMP tmp2, KILL cr0);\n+  ins_cost(2 * MEMORY_REF_COST);\n+  format %{ \"encode_heap_oop $src\\n\\t\"\n+            \"stw   $mem, $src\\t# ptr\" %}\n+  ins_encode %{\n+    pre_write_barrier(masm, this,\n+                      $mem$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      noreg,\n+                      RegSet::of($mem$$Register, $src$$Register) \/* preserve *\/);\n+    Register encoded_oop = noreg;\n+    if ((barrier_data() & G1C2BarrierPostNotNull) == 0) {\n+      encoded_oop = __ encode_heap_oop($tmp2$$Register, $src$$Register);\n+    } else {\n+      encoded_oop = __ encode_heap_oop_not_null($tmp2$$Register, $src$$Register);\n+    }\n+    __ stw(encoded_oop, 0, $mem$$Register);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $src$$Register \/* new_val *\/,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndExchangeP(iRegPdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndExchangeNode*)n)->order() != MemNode::acquire && ((CompareAndExchangeNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (CompareAndExchangeP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"cmpxchgd $newval, $mem\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ cmpxchgd(CCR0, $res$$Register, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndExchangeP_acq(iRegPdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndExchangeNode*)n)->order() == MemNode::acquire || ((CompareAndExchangeNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (CompareAndExchangeP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"cmpxchgd acq $newval, $mem\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ cmpxchgd(CCR0, $res$$Register, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register);\n+    __ bind(no_update);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndExchangeN(iRegNdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndExchangeNode*)n)->order() != MemNode::acquire && ((CompareAndExchangeNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (CompareAndExchangeN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"cmpxchgw $newval, $mem\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ cmpxchgw(CCR0, $res$$Register, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register,\n+                       true \/* decode_new_val *\/);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndExchangeN_acq(iRegNdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndExchangeNode*)n)->order() == MemNode::acquire || ((CompareAndExchangeNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (CompareAndExchangeN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"cmpxchgw acq $newval, $mem\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ cmpxchgw(CCR0, $res$$Register, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register,\n+                       true \/* decode_new_val *\/);\n+    __ bind(no_update);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndSwapP(iRegIdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (CompareAndSwapP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"CMPXCHGD $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgd(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndSwapP_acq(iRegIdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (CompareAndSwapP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"CMPXCHGD acq $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgd(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndSwapN(iRegIdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (CompareAndSwapN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"CMPXCHGW $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgw(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/,\n+                       true \/* decode_new_val *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1CompareAndSwapN_acq(iRegIdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (CompareAndSwapN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"CMPXCHGW acq $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgw(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/,\n+                       true \/* decode_new_val *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct weakG1CompareAndSwapP(iRegIdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"weak CMPXCHGD $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgd(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct weakG1CompareAndSwapP_acq(iRegIdst res, indirect mem, iRegPsrc oldval, iRegPsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"weak CMPXCHGD acq $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgd(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/);\n+    __ li($res$$Register, 1);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+    __ bind(no_update); \/\/ weak version requires no memory barrier on failure\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct weakG1CompareAndSwapN(iRegIdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst));\n+  match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"weak CMPXCHGW $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgw(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/,\n+                       true \/* decode_new_val *\/);\n+    __ li($res$$Register, 1);\n+    __ bind(no_update);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct weakG1CompareAndSwapN_acq(iRegIdst res, indirect mem, iRegNsrc oldval, iRegNsrc newval, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0 &&\n+            (((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst));\n+  match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));\n+  effect(TEMP_DEF res, TEMP tmp, KILL cr0);\n+  format %{ \"weak CMPXCHGW acq $res, $mem, $oldval, $newval; as bool; ptr\" %}\n+  ins_encode %{\n+    Label no_update;\n+    __ li($res$$Register, 0);\n+    __ cmpxchgw(CCR0, R0, $oldval$$Register, $newval$$Register, $mem$$Register,\n+                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n+                noreg, &no_update, true, true);\n+    \/\/ Pass oldval to SATB which is the only value which can get overwritten.\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg,\n+                      $oldval$$Register \/* pre_val *\/,\n+                      $tmp$$Register,\n+                      $res$$Register \/* temp *\/,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/,\n+                      RegSet::of($res$$Register) \/* no_preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp$$Register,\n+                       $res$$Register \/* temp *\/,\n+                       true \/* decode_new_val *\/);\n+    __ li($res$$Register, 1);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n+      __ sync();\n+    }\n+    __ bind(no_update); \/\/ weak version requires no memory barrier on failure\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1GetAndSetP(iRegPdst res, indirect mem, iRegPsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0);\n+  match(Set res (GetAndSetP mem newval));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"GetAndSetP    $newval, $mem\" %}\n+  ins_encode %{\n+    assert_different_registers($mem$$Register, $newval$$Register);\n+    __ getandsetd($res$$Register, $newval$$Register, $mem$$Register,\n+                  MacroAssembler::cmpxchgx_hint_atomic_update());\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg \/* obj *\/,\n+                      $res$$Register \/* res *\/,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1GetAndSetN(iRegNdst res, indirect mem, iRegNsrc newval, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_LoadStore()->barrier_data() != 0);\n+  match(Set res (GetAndSetN mem newval));\n+  effect(TEMP_DEF res, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  format %{ \"GetAndSetN    $newval, $mem\" %}\n+  ins_encode %{\n+    assert_different_registers($mem$$Register, $newval$$Register);\n+    __ getandsetw($res$$Register, $newval$$Register, $mem$$Register,\n+                  MacroAssembler::cmpxchgx_hint_atomic_update());\n+    \/\/ Can be done after cmpxchg because there's no safepoint here.\n+    pre_write_barrier(masm, this,\n+                      noreg \/* obj *\/,\n+                      $res$$Register \/* res *\/,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register,\n+                      RegSet::of($mem$$Register, $newval$$Register) \/* preserve *\/);\n+    post_write_barrier(masm, this,\n+                       $mem$$Register,\n+                       $newval$$Register,\n+                       $tmp1$$Register,\n+                       $tmp2$$Register,\n+                       true \/* decode_new_val *\/);\n+    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n+      __ isync();\n+    } else {\n+      __ sync();\n+    }\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1LoadP(iRegPdst dst, memoryAlg4 mem, iRegPdst tmp, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_Load()->is_unordered() && n->as_Load()->barrier_data() != 0);\n+  match(Set dst (LoadP mem));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr0);\n+  ins_cost(2 * MEMORY_REF_COST);\n+  format %{ \"ld    $dst, $mem\\t# ptr\" %}\n+  ins_encode %{\n+    __ ld($dst$$Register, $mem$$disp, $mem$$base$$Register);\n+    pre_write_barrier(masm, this,\n+                      noreg \/* obj *\/,\n+                      $dst$$Register \/* pre_val *\/,\n+                      $tmp$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1LoadP_acq(iRegPdst dst, memoryAlg4 mem)\n+%{\n+  predicate(UseG1GC && n->as_Load()->barrier_data() != 0);\n+  match(Set dst (LoadP mem));\n+  ins_cost(3 * MEMORY_REF_COST);\n+  format %{ \"ld    $dst, $mem\\t# ptr\" %}\n+  ins_encode %{\n+    \/\/ Note: The combination of SATB barrier and acquire should never be needed,\n+    \/\/ because Reference.get() doesn't use acquire.\n+    ShouldNotReachHere();\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1LoadN(iRegNdst dst, memoryAlg4 mem, iRegPdst tmp1, iRegPdst tmp2, flagsRegCR0 cr0)\n+%{\n+  predicate(UseG1GC && n->as_Load()->is_unordered() && n->as_Load()->barrier_data() != 0);\n+  match(Set dst (LoadN mem));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, KILL cr0);\n+  ins_cost(2 * MEMORY_REF_COST);\n+  format %{ \"lwz    $dst, $mem\\t# ptr\" %}\n+  ins_encode %{\n+    __ lwz($dst$$Register, $mem$$disp, $mem$$base$$Register);\n+    pre_write_barrier(masm, this,\n+                      noreg \/* obj *\/,\n+                      $dst$$Register,\n+                      $tmp1$$Register,\n+                      $tmp2$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct g1LoadN_acq(iRegNdst dst, memoryAlg4 mem)\n+%{\n+  predicate(UseG1GC && n->as_Load()->barrier_data() != 0);\n+  match(Set dst (LoadN mem));\n+  ins_cost(3 * MEMORY_REF_COST);\n+  format %{ \"lwz    $dst, $mem\\t# ptr\" %}\n+  ins_encode %{\n+    \/\/ Note: The combination of SATB barrier and acquire should never be needed,\n+    \/\/ because Reference.get() doesn't use acquire.\n+    ShouldNotReachHere();\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/g1\/g1_ppc.ad","additions":713,"deletions":0,"binary":false,"changes":713,"status":"added"},{"patch":"@@ -1003,0 +1003,4 @@\n+  if (is_encode_and_store_pattern(n, m)) {\n+    mstack.push(m, Visit);\n+    return true;\n+  }\n@@ -5410,1 +5414,1 @@\n-  predicate(n->as_Load()->is_unordered() || followed_by_acquire(n));\n+  predicate((n->as_Load()->is_unordered() || followed_by_acquire(n)) && n->as_Load()->barrier_data() == 0);\n@@ -5422,0 +5426,1 @@\n+  predicate(n->as_Load()->barrier_data() == 0);\n@@ -5435,1 +5440,1 @@\n-  predicate(_kids[0]->_leaf->as_Load()->is_unordered() && CompressedOops::shift() == 0);\n+  predicate(_kids[0]->_leaf->as_Load()->is_unordered() && CompressedOops::shift() == 0 && _kids[0]->_leaf->as_Load()->barrier_data() == 0);\n@@ -6426,0 +6431,1 @@\n+  predicate(n->as_Store()->barrier_data() == 0);\n@@ -7480,0 +7486,1 @@\n+  predicate(n->as_LoadStore()->barrier_data() == 0);\n@@ -7679,1 +7686,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && n->as_LoadStore()->barrier_data() == 0);\n@@ -7693,1 +7700,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst);\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && n->as_LoadStore()->barrier_data() == 0);\n@@ -7942,1 +7949,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && n->as_LoadStore()->barrier_data() == 0);\n@@ -7956,1 +7963,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst);\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && n->as_LoadStore()->barrier_data() == 0);\n@@ -8265,0 +8272,1 @@\n+  predicate(n->as_LoadStore()->barrier_data() == 0);\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":14,"deletions":6,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"utilities\/count_trailing_zeros.hpp\"\n@@ -558,0 +559,8 @@\n+template <>\n+inline Register AbstractRegSet<Register>::first() {\n+  if (_bitset == 0) { return noreg; }\n+  return as_Register(count_trailing_zeros(_bitset));\n+}\n+\n+typedef AbstractRegSet<Register> RegSet;\n+\n","filename":"src\/hotspot\/cpu\/ppc\/register_ppc.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"}]}