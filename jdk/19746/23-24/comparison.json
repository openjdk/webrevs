{"files":[{"patch":"@@ -166,0 +166,33 @@\n+\/\/ This pattern is generated automatically from g1_aarch64.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct g1StoreNVolatile(indirect mem, iRegN src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, rFlagsReg cr)\n+%{\n+  predicate(UseG1GC && needs_releasing_store(n) && n->as_Store()->barrier_data() != 0);\n+  match(Set mem (StoreN mem src));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);\n+  ins_cost(VOLATILE_REF_COST);\n+  format %{ \"stlrw  $src, $mem\\t# compressed ptr\" %}\n+  ins_encode %{\n+    write_barrier_pre(masm, this,\n+                      $mem$$Register \/* obj *\/,\n+                      $tmp1$$Register \/* pre_val *\/,\n+                      $tmp2$$Register \/* tmp1 *\/,\n+                      $tmp3$$Register \/* tmp2 *\/,\n+                      RegSet::of($mem$$Register, $src$$Register) \/* preserve *\/);\n+    __ stlrw($src$$Register, $mem$$Register);\n+    if ((barrier_data() & G1C2BarrierPost) != 0) {\n+      if ((barrier_data() & G1C2BarrierPostNotNull) == 0) {\n+        __ decode_heap_oop($tmp1$$Register, $src$$Register);\n+      } else {\n+        __ decode_heap_oop_not_null($tmp1$$Register, $src$$Register);\n+      }\n+    }\n+    write_barrier_post(masm, this,\n+                       $mem$$Register \/* store_addr *\/,\n+                       $tmp1$$Register \/* new_val *\/,\n+                       $tmp2$$Register \/* tmp1 *\/,\n+                       $tmp3$$Register \/* tmp2 *\/);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -198,3 +231,0 @@\n-\/\/ Very few of the total executed stores are volatile (less than 1% across\n-\/\/ multiple benchmark suites), no need to define an encode-and-store version.\n-\n@@ -203,1 +233,1 @@\n-instruct g1StoreNVolatile(indirect mem, iRegN src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, rFlagsReg cr)\n+instruct g1EncodePAndStoreNVolatile(indirect mem, iRegP src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, rFlagsReg cr)\n@@ -206,1 +236,1 @@\n-  match(Set mem (StoreN mem src));\n+  match(Set mem (StoreN mem (EncodeP src)));\n@@ -209,1 +239,2 @@\n-  format %{ \"stlrw  $src, $mem\\t# compressed ptr\" %}\n+  format %{ \"encode_heap_oop $tmp1, $src\\n\\t\"\n+            \"stlrw  $tmp1, $mem\\t# compressed ptr\" %}\n@@ -217,7 +248,4 @@\n-    __ stlrw($src$$Register, $mem$$Register);\n-    if ((barrier_data() & G1C2BarrierPost) != 0) {\n-      if ((barrier_data() & G1C2BarrierPostNotNull) == 0) {\n-        __ decode_heap_oop($tmp1$$Register, $src$$Register);\n-      } else {\n-        __ decode_heap_oop_not_null($tmp1$$Register, $src$$Register);\n-      }\n+    if ((barrier_data() & G1C2BarrierPostNotNull) == 0) {\n+      __ encode_heap_oop($tmp1$$Register, $src$$Register);\n+    } else {\n+      __ encode_heap_oop_not_null($tmp1$$Register, $src$$Register);\n@@ -225,0 +253,1 @@\n+    __ stlrw($tmp1$$Register, $mem$$Register);\n@@ -227,1 +256,1 @@\n-                       $tmp1$$Register \/* new_val *\/,\n+                       $src$$Register \/* new_val *\/,\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1_aarch64.ad","additions":43,"deletions":14,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -91,1 +91,4 @@\n-\n+STOREN_INSN(Volatile,stlrw)\n+dnl\n+define(`ENCODESTOREN_INSN',\n+`\n@@ -94,1 +97,1 @@\n-instruct g1EncodePAndStoreN(indirect mem, iRegP src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, rFlagsReg cr)\n+instruct g1EncodePAndStoreN$1(indirect mem, iRegP src, iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, rFlagsReg cr)\n@@ -96,1 +99,1 @@\n-  predicate(UseG1GC && !needs_releasing_store(n) && n->as_Store()->barrier_data() != 0);\n+  predicate(UseG1GC && ifelse($1,Volatile,'needs_releasing_store(n)`,'!needs_releasing_store(n)`) && n->as_Store()->barrier_data() != 0);\n@@ -99,1 +102,1 @@\n-  ins_cost(INSN_COST);\n+  ins_cost(ifelse($1,Volatile,VOLATILE_REF_COST,INSN_COST));\n@@ -101,1 +104,1 @@\n-            \"strw  $tmp1, $mem\\t# compressed ptr\" %}\n+            \"$2  $tmp1, $mem\\t# compressed ptr\" %}\n@@ -114,1 +117,1 @@\n-    __ strw($tmp1$$Register, $mem$$Register);\n+    __ $2($tmp1$$Register, $mem$$Register);\n@@ -121,6 +124,4 @@\n-  ins_pipe(istore_reg_mem);\n-%}\n-\n-\/\/ Very few of the total executed stores are volatile (less than 1% across\n-\/\/ multiple benchmark suites), no need to define an encode-and-store version.\n-STOREN_INSN(Volatile,stlrw)\n+  ins_pipe(ifelse($1,Volatile,pipe_class_memory,istore_reg_mem));\n+%}')dnl\n+ENCODESTOREN_INSN(,strw)\n+ENCODESTOREN_INSN(Volatile,stlrw)\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1_aarch64.m4","additions":13,"deletions":12,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2844,1 +2844,2 @@\n-      !m->is_EncodeP()) {\n+      !m->is_EncodeP() ||\n+      n->as_Store()->barrier_data() == 0) {\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+import java.util.concurrent.ThreadLocalRandom;\n@@ -54,0 +55,4 @@\n+    static class OuterWithVolatileField {\n+        volatile Object f;\n+    }\n+\n@@ -173,0 +178,11 @@\n+    @Test\n+    @IR(applyIf = {\"UseCompressedOops\", \"false\"},\n+        counts = {IRNode.G1_STORE_P_WITH_BARRIER_FLAG, PRE_AND_POST, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    @IR(applyIf = {\"UseCompressedOops\", \"true\"},\n+        counts = {IRNode.G1_ENCODE_P_AND_STORE_N_WITH_BARRIER_FLAG, PRE_AND_POST, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    public static void testStoreVolatile(OuterWithVolatileField o, Object o1) {\n+        o.f = o1;\n+    }\n+\n@@ -223,0 +239,25 @@\n+    @Test\n+    @IR(applyIfAnd = {\"UseCompressedOops\", \"false\", \"ReduceInitialCardMarks\", \"false\"},\n+        counts = {IRNode.G1_STORE_P_WITH_BARRIER_FLAG, POST_ONLY, \"2\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    @IR(applyIfAnd = {\"UseCompressedOops\", \"true\", \"ReduceInitialCardMarks\", \"false\"},\n+        counts = {IRNode.G1_ENCODE_P_AND_STORE_N_WITH_BARRIER_FLAG, POST_ONLY, \"2\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    @IR(applyIfAnd = {\"UseCompressedOops\", \"false\", \"ReduceInitialCardMarks\", \"true\"},\n+        failOn = {IRNode.G1_STORE_P},\n+        phase = CompilePhase.FINAL_CODE)\n+    @IR(applyIfAnd = {\"UseCompressedOops\", \"true\", \"ReduceInitialCardMarks\", \"true\"},\n+        failOn = {IRNode.G1_STORE_N, IRNode.G1_ENCODE_P_AND_STORE_N},\n+        phase = CompilePhase.FINAL_CODE)\n+    public static Outer testStoreOnNewObjectInTwoPaths(Object o1, boolean c) {\n+        Outer o;\n+        if (c) {\n+            o = new Outer();\n+            o.f = o1;\n+        } else {\n+            o = new Outer();\n+            o.f = o1;\n+        }\n+        return o;\n+    }\n+\n@@ -228,0 +269,1 @@\n+                 \"testStoreVolatile\",\n@@ -230,1 +272,2 @@\n-                 \"testStoreNotNullOnNewObject\"})\n+                 \"testStoreNotNullOnNewObject\",\n+                 \"testStoreOnNewObjectInTwoPaths\"})\n@@ -263,0 +306,6 @@\n+        {\n+            OuterWithVolatileField o = new OuterWithVolatileField();\n+            Object o1 = new Object();\n+            testStoreVolatile(o, o1);\n+            Asserts.assertEquals(o1, o.f);\n+        }\n@@ -277,0 +326,5 @@\n+        {\n+            Object o1 = new Object();\n+            Outer o = testStoreOnNewObjectInTwoPaths(o1, ThreadLocalRandom.current().nextBoolean());\n+            Asserts.assertEquals(o1, o.f);\n+        }\n","filename":"test\/hotspot\/jtreg\/compiler\/gcbarriers\/TestG1BarrierGeneration.java","additions":55,"deletions":1,"binary":false,"changes":56,"status":"modified"}]}