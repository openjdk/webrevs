{"files":[{"patch":"@@ -3,1 +3,1 @@\n-\/\/ Copyright (c) 2020, 2023, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n@@ -138,3 +138,3 @@\n-          \/\/ The vector implementation of Op_AddReductionVD\/F is for the Vector API only.\n-          \/\/ It is not suitable for auto-vectorization because it does not add the elements\n-          \/\/ in the same order as sequential code, and FP addition is non-associative.\n+          \/\/ The implementations of Op_AddReductionVD\/F in Neon are for the Vector API only.\n+          \/\/ They are not suitable for auto-vectorization because the result would not conform\n+          \/\/ to the JLS, Section Evaluation Order.\n@@ -2861,5 +2861,5 @@\n-\/\/ Floating-point addition is not associative, so the rules for AddReductionVF\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVF is only generated by Vector API.\n-instruct reduce_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 2);\n+\n+instruct reduce_non_strict_order_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for a 64-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 2 && !n->as_Reduction()->requires_strict_order());\n@@ -2868,1 +2868,1 @@\n-  format %{ \"reduce_add2F_neon $dst, $fsrc, $vsrc\" %}\n+  format %{ \"reduce_non_strict_order_add2F_neon $dst, $fsrc, $vsrc\" %}\n@@ -2876,2 +2876,4 @@\n-instruct reduce_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 4);\n+instruct reduce_non_strict_order_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for 128-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 4 && !n->as_Reduction()->requires_strict_order());\n@@ -2880,1 +2882,1 @@\n-  format %{ \"reduce_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  format %{ \"reduce_non_strict_order_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n@@ -2889,0 +2891,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionVF when vector size > 128-bits. For example -\n+\/\/    AddReductionVF generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionVF. For example - AddReductionVF generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -2890,1 +2900,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -2894,0 +2905,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -2902,5 +2914,5 @@\n-\/\/ Floating-point addition is not associative, so the rule for AddReductionVD\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVD is only generated by Vector API.\n-instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0);\n+\n+instruct reduce_non_strict_order_add2D_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(!n->as_Reduction()->requires_strict_order());\n@@ -2909,1 +2921,1 @@\n-  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n+  format %{ \"reduce_non_strict_order_add2D_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n@@ -2917,0 +2929,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionVD when vector size > 128-bits. For example -\n+\/\/    AddReductionVD generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionVD. For example - AddReductionVD generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -2918,1 +2938,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -2922,0 +2943,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":43,"deletions":21,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-\/\/ Copyright (c) 2020, 2023, Arm Limited. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Arm Limited. All rights reserved.\n@@ -128,3 +128,3 @@\n-          \/\/ The vector implementation of Op_AddReductionVD\/F is for the Vector API only.\n-          \/\/ It is not suitable for auto-vectorization because it does not add the elements\n-          \/\/ in the same order as sequential code, and FP addition is non-associative.\n+          \/\/ The implementations of Op_AddReductionVD\/F in Neon are for the Vector API only.\n+          \/\/ They are not suitable for auto-vectorization because the result would not conform\n+          \/\/ to the JLS, Section Evaluation Order.\n@@ -1751,5 +1751,5 @@\n-\/\/ Floating-point addition is not associative, so the rules for AddReductionVF\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVF is only generated by Vector API.\n-instruct reduce_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 2);\n+\n+instruct reduce_non_strict_order_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for a 64-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 2 && !n->as_Reduction()->requires_strict_order());\n@@ -1758,1 +1758,1 @@\n-  format %{ \"reduce_add2F_neon $dst, $fsrc, $vsrc\" %}\n+  format %{ \"reduce_non_strict_order_add2F_neon $dst, $fsrc, $vsrc\" %}\n@@ -1766,2 +1766,4 @@\n-instruct reduce_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 4);\n+instruct reduce_non_strict_order_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for 128-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 4 && !n->as_Reduction()->requires_strict_order());\n@@ -1770,1 +1772,1 @@\n-  format %{ \"reduce_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  format %{ \"reduce_non_strict_order_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n@@ -1782,0 +1784,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionV$1 when vector size > 128-bits. For example -\n+\/\/    AddReductionV$1 generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionV$1. For example - AddReductionV$1 generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -1783,1 +1793,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -1787,0 +1798,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -1797,5 +1809,5 @@\n-\/\/ Floating-point addition is not associative, so the rule for AddReductionVD\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVD is only generated by Vector API.\n-instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0);\n+\n+instruct reduce_non_strict_order_add2D_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(!n->as_Reduction()->requires_strict_order());\n@@ -1804,1 +1816,1 @@\n-  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n+  format %{ \"reduce_non_strict_order_add2D_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":32,"deletions":20,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1462,1 +1462,1 @@\n-  \/\/ Move UnorderedReduction out of loop if possible\n+  \/\/ Move an unordered Reduction out of loop if possible\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4306,0 +4306,5 @@\n+\/\/ Returns true if the Reduction node is unordered.\n+static bool is_unordered_reduction(Node* n) {\n+  return n->is_Reduction() && !n->as_Reduction()->requires_strict_order();\n+}\n+\n@@ -4311,0 +4316,3 @@\n+\/\/ Note: UnorderedReduction represents a ReductionNode which does not require\n+\/\/ calculating in strict order.\n+\/\/\n@@ -4350,0 +4358,1 @@\n+\/\/\n@@ -4351,1 +4360,2 @@\n-\/\/ reordering of operations (for example float addition).\n+\/\/ reordering of operations (for example float addition\/multiplication require\n+\/\/ strict order).\n@@ -4355,1 +4365,1 @@\n-  \/\/ Find all Phi nodes with UnorderedReduction on backedge.\n+  \/\/ Find all Phi nodes with an unordered Reduction on backedge.\n@@ -4359,2 +4369,2 @@\n-    \/\/ We have a phi with a single use, and a UnorderedReduction on the backedge.\n-    if (!phi->is_Phi() || phi->outcnt() != 1 || !phi->in(2)->is_UnorderedReduction()) {\n+    \/\/ We have a phi with a single use, and an unordered Reduction on the backedge.\n+    if (!phi->is_Phi() || phi->outcnt() != 1 || !is_unordered_reduction(phi->in(2))) {\n@@ -4364,1 +4374,2 @@\n-    UnorderedReductionNode* last_ur = phi->in(2)->as_UnorderedReduction();\n+    ReductionNode* last_ur = phi->in(2)->as_Reduction();\n+    assert(!last_ur->requires_strict_order(), \"must be\");\n@@ -4381,2 +4392,2 @@\n-    \/\/ Traverse up the chain of UnorderedReductions, checking that it loops back to\n-    \/\/ the phi. Check that all UnorderedReductions only have a single use, except for\n+    \/\/ Traverse up the chain of unordered Reductions, checking that it loops back to\n+    \/\/ the phi. Check that all unordered Reductions only have a single use, except for\n@@ -4385,2 +4396,2 @@\n-    UnorderedReductionNode* current = last_ur;\n-    UnorderedReductionNode* first_ur = nullptr;\n+    ReductionNode* current = last_ur;\n+    ReductionNode* first_ur = nullptr;\n@@ -4388,1 +4399,1 @@\n-      assert(current->is_UnorderedReduction(), \"sanity\");\n+      assert(!current->requires_strict_order(), \"sanity\");\n@@ -4405,1 +4416,1 @@\n-      \/\/ Expect single use of UnorderedReduction, except for last_ur.\n+      \/\/ Expect single use of an unordered Reduction, except for last_ur.\n@@ -4423,1 +4434,1 @@\n-      \/\/ Expect another UnorderedReduction or phi as the scalar input.\n+      \/\/ Expect another unordered Reduction or phi as the scalar input.\n@@ -4425,1 +4436,1 @@\n-      if (scalar_input->is_UnorderedReduction() &&\n+      if (is_unordered_reduction(scalar_input) &&\n@@ -4427,2 +4438,3 @@\n-        \/\/ Move up the UnorderedReduction chain.\n-        current = scalar_input->as_UnorderedReduction();\n+        \/\/ Move up the unordered Reduction chain.\n+        current = scalar_input->as_Reduction();\n+        assert(!current->requires_strict_order(), \"must be\");\n@@ -4452,1 +4464,1 @@\n-    VectorNode::trace_new_vector(identity_vector, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(identity_vector, \"Unordered Reduction\");\n@@ -4461,1 +4473,1 @@\n-    \/\/ Traverse down the chain of UnorderedReductions, and replace them with vector_accumulators.\n+    \/\/ Traverse down the chain of unordered Reductions, and replace them with vector_accumulators.\n@@ -4470,1 +4482,1 @@\n-      VectorNode::trace_new_vector(vector_accumulator, \"UnorderedReduction\");\n+      VectorNode::trace_new_vector(vector_accumulator, \"Unordered Reduction\");\n@@ -4474,1 +4486,2 @@\n-      current = vector_accumulator->unique_out()->as_UnorderedReduction();\n+      current = vector_accumulator->unique_out()->as_Reduction();\n+      assert(!current->requires_strict_order(), \"must be\");\n@@ -4491,1 +4504,1 @@\n-    VectorNode::trace_new_vector(post_loop_reduction, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(post_loop_reduction, \"Unordered Reduction\");\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":33,"deletions":20,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -177,1 +177,0 @@\n-class UnorderedReductionNode;\n@@ -739,1 +738,0 @@\n-          DEFINE_CLASS_ID(UnorderedReduction, Reduction, 0)\n@@ -989,1 +987,0 @@\n-  DEFINE_CLASS_QUERY(UnorderedReduction)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1768,14 +1768,6 @@\n-  Node* value = nullptr;\n-  if (mask == nullptr) {\n-    assert(!is_masked_op, \"Masked op needs the mask value never null\");\n-    value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n-  } else {\n-    if (use_predicate) {\n-      value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n-      value->add_req(mask);\n-      value->add_flag(Node::Flag_is_predicated_vector);\n-    } else {\n-      Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n-      value = gvn().transform(new VectorBlendNode(reduce_identity, opd, mask));\n-      value = ReductionNode::make(opc, nullptr, init, value, elem_bt);\n-    }\n+  Node* value = opd;\n+\n+  assert(mask != nullptr || !is_masked_op, \"Masked op needs the mask value never null\");\n+  if (mask != nullptr && !use_predicate) {\n+    Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n+    value = gvn().transform(new VectorBlendNode(reduce_identity, value, mask));\n@@ -1783,0 +1775,10 @@\n+\n+  \/\/ Make an unordered Reduction node. This affects only AddReductionVF\/VD and MulReductionVF\/VD,\n+  \/\/ as these operations are allowed to be associative (not requiring strict order) in VectorAPI.\n+  value = ReductionNode::make(opc, nullptr, init, value, elem_bt, \/* requires_strict_order *\/ false);\n+\n+  if (mask != nullptr && use_predicate) {\n+    value->add_req(mask);\n+    value->add_flag(Node::Flag_is_predicated_vector);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":17,"deletions":15,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2007, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2007, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1320,1 +1320,2 @@\n-ReductionNode* ReductionNode::make(int opc, Node *ctrl, Node* n1, Node* n2, BasicType bt) {\n+ReductionNode* ReductionNode::make(int opc, Node* ctrl, Node* n1, Node* n2, BasicType bt,\n+                                   bool requires_strict_order) {\n@@ -1330,2 +1331,2 @@\n-  case Op_AddReductionVF: return new AddReductionVFNode(ctrl, n1, n2);\n-  case Op_AddReductionVD: return new AddReductionVDNode(ctrl, n1, n2);\n+  case Op_AddReductionVF: return new AddReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_AddReductionVD: return new AddReductionVDNode(ctrl, n1, n2, requires_strict_order);\n@@ -1334,7 +1335,7 @@\n-  case Op_MulReductionVF: return new MulReductionVFNode(ctrl, n1, n2);\n-  case Op_MulReductionVD: return new MulReductionVDNode(ctrl, n1, n2);\n-  case Op_MinReductionV:  return new MinReductionVNode(ctrl, n1, n2);\n-  case Op_MaxReductionV:  return new MaxReductionVNode(ctrl, n1, n2);\n-  case Op_AndReductionV:  return new AndReductionVNode(ctrl, n1, n2);\n-  case Op_OrReductionV:   return new OrReductionVNode(ctrl, n1, n2);\n-  case Op_XorReductionV:  return new XorReductionVNode(ctrl, n1, n2);\n+  case Op_MulReductionVF: return new MulReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MulReductionVD: return new MulReductionVDNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MinReductionV:  return new MinReductionVNode (ctrl, n1, n2);\n+  case Op_MaxReductionV:  return new MaxReductionVNode (ctrl, n1, n2);\n+  case Op_AndReductionV:  return new AndReductionVNode (ctrl, n1, n2);\n+  case Op_OrReductionV:   return new OrReductionVNode  (ctrl, n1, n2);\n+  case Op_XorReductionV:  return new XorReductionVNode (ctrl, n1, n2);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":12,"deletions":11,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -208,1 +208,3 @@\n-  static ReductionNode* make(int opc, Node* ctrl, Node* in1, Node* in2, BasicType bt);\n+  static ReductionNode* make(int opc, Node* ctrl, Node* in1, Node* in2, BasicType bt,\n+                             \/\/ This only effects floating-point add and mul reductions.\n+                             bool requires_strict_order = true);\n@@ -230,1 +232,0 @@\n-};\n@@ -232,6 +233,18 @@\n-\/\/---------------------------UnorderedReductionNode-------------------------------------\n-\/\/ Order of reduction does not matter. Example int add. Not true for float add.\n-class UnorderedReductionNode : public ReductionNode {\n-public:\n-  UnorderedReductionNode(Node * ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {\n-    init_class_id(Class_UnorderedReduction);\n+  \/\/ Floating-point addition and multiplication are non-associative, so\n+  \/\/ AddReductionVF\/D and MulReductionVF\/D require strict ordering\n+  \/\/ in auto-vectorization. Vector API can generate AddReductionVF\/D\n+  \/\/ and MulReductionVF\/VD without strict ordering, which can benefit\n+  \/\/ some platforms.\n+  \/\/\n+  \/\/ Other reductions don't need strict ordering.\n+  virtual bool requires_strict_order() const {\n+    return false;\n+  }\n+\n+#ifndef PRODUCT\n+  void dump_spec(outputStream* st) const {\n+    if (requires_strict_order()) {\n+      st->print(\"requires_strict_order\");\n+    } else {\n+      st->print(\"no_strict_order\");\n+    }\n@@ -239,0 +252,1 @@\n+#endif\n@@ -243,1 +257,1 @@\n-class AddReductionVINode : public UnorderedReductionNode {\n+class AddReductionVINode : public ReductionNode {\n@@ -245,1 +259,1 @@\n-  AddReductionVINode(Node * ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AddReductionVINode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -251,1 +265,1 @@\n-class AddReductionVLNode : public UnorderedReductionNode {\n+class AddReductionVLNode : public ReductionNode {\n@@ -253,1 +267,1 @@\n-  AddReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AddReductionVLNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -260,0 +274,6 @@\n+private:\n+  \/\/ True if add reduction operation for floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -261,1 +281,4 @@\n-  AddReductionVFNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -263,0 +286,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -268,0 +301,6 @@\n+private:\n+  \/\/ True if add reduction operation for doubles requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for doubles is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -269,1 +308,4 @@\n-  AddReductionVDNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVDNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -271,0 +313,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -405,1 +457,1 @@\n-class MulReductionVINode : public UnorderedReductionNode {\n+class MulReductionVINode : public ReductionNode {\n@@ -407,1 +459,1 @@\n-  MulReductionVINode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MulReductionVINode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -413,1 +465,1 @@\n-class MulReductionVLNode : public UnorderedReductionNode {\n+class MulReductionVLNode : public ReductionNode {\n@@ -415,1 +467,1 @@\n-  MulReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MulReductionVLNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -422,0 +474,5 @@\n+  \/\/ True if mul reduction operation for floats requires strict ordering.\n+  \/\/ As an example - The value is true when mul reduction for floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -423,1 +480,4 @@\n-  MulReductionVFNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -425,0 +485,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -430,0 +500,5 @@\n+  \/\/ True if mul reduction operation for doubles requires strict ordering.\n+  \/\/ As an example - The value is true when mul reduction for doubles is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -431,1 +506,4 @@\n-  MulReductionVDNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVDNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -433,0 +511,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -758,1 +846,1 @@\n-class AndReductionVNode : public UnorderedReductionNode {\n+class AndReductionVNode : public ReductionNode {\n@@ -760,1 +848,1 @@\n-  AndReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AndReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -775,1 +863,1 @@\n-class OrReductionVNode : public UnorderedReductionNode {\n+class OrReductionVNode : public ReductionNode {\n@@ -777,1 +865,1 @@\n-  OrReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  OrReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -792,1 +880,1 @@\n-class XorReductionVNode : public UnorderedReductionNode {\n+class XorReductionVNode : public ReductionNode {\n@@ -794,1 +882,1 @@\n-  XorReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  XorReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -800,1 +888,1 @@\n-class MinReductionVNode : public UnorderedReductionNode {\n+class MinReductionVNode : public ReductionNode {\n@@ -802,1 +890,1 @@\n-  MinReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MinReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -808,1 +896,1 @@\n-class MaxReductionVNode : public UnorderedReductionNode {\n+class MaxReductionVNode : public ReductionNode {\n@@ -810,1 +898,1 @@\n-  MaxReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MaxReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":118,"deletions":30,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -0,0 +1,99 @@\n+\/*\n+ * Copyright (c) 2024, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.c2.irTests;\n+\n+import compiler.lib.ir_framework.*;\n+\n+\/*\n+ * @test\n+ * @bug 8320725\n+ * @summary Ensure strictly ordered AddReductionVF\/VD nodes are generated on SVE machines\n+ * while being disabled on Neon\n+ * @library \/test\/lib \/\n+ * @run driver compiler.c2.irTests.TestVectorFPReduction\n+ *\/\n+\n+public class TestVectorFPReduction {\n+\n+    final private static int SIZE = 1024;\n+\n+    private static double[] da = new double[SIZE];\n+    private static double[] db = new double[SIZE];\n+    private static float[] fa = new float[SIZE];\n+    private static float[] fb = new float[SIZE];\n+    private static float fresult;\n+    private static double dresult;\n+\n+    public static void main(String[] args) {\n+        TestFramework.run();\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"}, failOn = {IRNode.ADD_REDUCTION_VF})\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"}, counts = {\"requires_strict_order\", \">=1\", IRNode.ADD_REDUCTION_VF, \">=1\"},\n+        failOn = {\"no_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    private static void testAddReductionVF() {\n+        float result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result += (fa[i] + fb[i]);\n+        }\n+        fresult += result;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"}, failOn = {IRNode.ADD_REDUCTION_VD})\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"}, counts = {\"requires_strict_order\", \">=1\", IRNode.ADD_REDUCTION_VD, \">=1\"},\n+        failOn = {\"no_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    private static void testAddReductionVD() {\n+        double result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result += (da[i] + db[i]);\n+        }\n+        dresult += result;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"}, failOn = {IRNode.MUL_REDUCTION_VF})\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"}, counts = {\"requires_strict_order\", \">=1\", IRNode.MUL_REDUCTION_VF, \">=1\"},\n+        failOn = {\"no_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    private static void testMulReductionVF() {\n+        float result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result *= (fa[i] + fb[i]);\n+        }\n+        fresult += result;\n+    }\n+\n+    @Test\n+    @IR(applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"}, failOn = {IRNode.MUL_REDUCTION_VD})\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"}, counts = {\"requires_strict_order\", \">=1\", IRNode.MUL_REDUCTION_VD, \">=1\"},\n+        failOn = {\"no_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    private static void testMulReductionVD() {\n+        double result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result *= (da[i] + db[i]);\n+        }\n+        dresult += result;\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestVectorFPReduction.java","additions":99,"deletions":0,"binary":false,"changes":99,"status":"added"},{"patch":"@@ -0,0 +1,184 @@\n+\/*\n+ * Copyright (c) 2024, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.vectorapi;\n+\n+import compiler.lib.ir_framework.*;\n+\n+import jdk.incubator.vector.DoubleVector;\n+import jdk.incubator.vector.FloatVector;\n+import jdk.incubator.vector.VectorOperators;\n+import jdk.incubator.vector.VectorSpecies;\n+\n+import java.util.Random;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Utils;\n+\n+\/**\n+ * @test\n+ * @bug 8320725\n+ * @library \/test\/lib \/\n+ * @requires os.arch == \"aarch64\"\n+ * @summary Verify non-strictly ordered AddReductionVF\/VD and MulReductionVF\/VD\n+ * nodes are generated for float and double types in VectorAPI\n+ * @modules jdk.incubator.vector\n+ *\n+ * @run driver compiler.vectorapi.TestVectorAddMulReduction\n+ *\/\n+\n+public class TestVectorAddMulReduction {\n+\n+    private static final int SIZE = 1024;\n+    private static final Random RD = Utils.getRandomInstance();\n+\n+    private static float[] fa;\n+    private static float fres;\n+    private static double[] da;\n+    private static double dres;\n+\n+    static {\n+        fa = new float[SIZE];\n+        da = new double[SIZE];\n+        fres = 1;\n+        dres = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            fa[i] = RD.nextFloat();\n+            da[i] = RD.nextDouble();\n+        }\n+    }\n+\n+    \/\/ Test add reduction operation for floats\n+    @ForceInline\n+    public static void testFloatAddKernel(VectorSpecies SPECIES, float[] f) {\n+        for (int i = 0; i < SPECIES.loopBound(f.length); i += SPECIES.length()) {\n+            var av = FloatVector.fromArray(SPECIES, f, i);\n+            fres += av.reduceLanes(VectorOperators.ADD);\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=8\"}, counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_64() {\n+        testFloatAddKernel(FloatVector.SPECIES_64, fa);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=16\"}, counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_128() {\n+        testFloatAddKernel(FloatVector.SPECIES_128, fa);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=32\"}, counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_256() {\n+        testFloatAddKernel(FloatVector.SPECIES_256, fa);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=64\"}, counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_512() {\n+        testFloatAddKernel(FloatVector.SPECIES_512, fa);\n+    }\n+\n+    \/\/ Test add reduction operation for doubles\n+    @ForceInline\n+    public static void testDoubleAddKernel(VectorSpecies SPECIES, double[] d) {\n+        for (int i = 0; i < SPECIES.loopBound(d.length); i += SPECIES.length()) {\n+            var av = DoubleVector.fromArray(SPECIES, d, i);\n+            dres += av.reduceLanes(VectorOperators.ADD);\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=16\"}, counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_128() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_128, da);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=32\"}, counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_256() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_256, da);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=64\"}, counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_512() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_512, da);\n+    }\n+\n+    \/\/ Test mul reduction operation for floats\n+    \/\/ On aarch64, there are no direct vector mul reduction instructions for float\/double mul reduction\n+    \/\/ and scalar instructions are emitted for 64-bit\/128-bit vectors. Thus MulReductionVF\/VD nodes are generated\n+    \/\/ only for vector length of 8B\/16B on vectorAPI.\n+    @ForceInline\n+    public static void testFloatMulKernel(VectorSpecies SPECIES, float[] f) {\n+        for (int i = 0; i < SPECIES.loopBound(f.length); i += SPECIES.length()) {\n+            var av = FloatVector.fromArray(SPECIES, f, i);\n+            fres += av.reduceLanes(VectorOperators.MUL);\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=8\"}, counts = {IRNode.MUL_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatMul_64() {\n+        testFloatMulKernel(FloatVector.SPECIES_64, fa);\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=16\"}, counts = {IRNode.MUL_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatMul_128() {\n+        testFloatMulKernel(FloatVector.SPECIES_128, fa);\n+    }\n+\n+    \/\/ Test mul reduction operation for doubles\n+    @ForceInline\n+    public static void testDoubleMulKernel(VectorSpecies SPECIES, double[] d) {\n+        for (int i = 0; i < SPECIES.loopBound(d.length); i += SPECIES.length()) {\n+            var av = DoubleVector.fromArray(SPECIES, d, i);\n+            dres += av.reduceLanes(VectorOperators.MUL);\n+        }\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"MaxVectorSize\", \">=16\"}, counts = {IRNode.MUL_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"}, phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleMul_128() {\n+        testDoubleMulKernel(DoubleVector.SPECIES_128, da);\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFramework.runWithFlags(\"-XX:-TieredCompilation\",\n+                                   \"--add-modules=jdk.incubator.vector\");\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/TestVectorAddMulReduction.java","additions":184,"deletions":0,"binary":false,"changes":184,"status":"added"}]}