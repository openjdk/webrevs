{"files":[{"patch":"@@ -138,3 +138,3 @@\n-          \/\/ The vector implementation of Op_AddReductionVD\/F is for the Vector API only.\n-          \/\/ It is not suitable for auto-vectorization because it does not add the elements\n-          \/\/ in the same order as sequential code, and FP addition is non-associative.\n+          \/\/ The implementations of Op_AddReductionVD\/F in Neon are for the Vector API only.\n+          \/\/ They are not suitable for auto-vectorization because the result would not conform\n+          \/\/ to the JLS, Section Evaluation Order.\n@@ -2861,5 +2861,5 @@\n-\/\/ Floating-point addition is not associative, so the rules for AddReductionVF\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVF is only generated by Vector API.\n-instruct reduce_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 2);\n+\n+instruct reduce_non_strict_order_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for a 64-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 2 && !n->as_Reduction()->requires_strict_order());\n@@ -2868,1 +2868,1 @@\n-  format %{ \"reduce_add2F_neon $dst, $fsrc, $vsrc\" %}\n+  format %{ \"reduce_non_strict_order_add2F_neon $dst, $fsrc, $vsrc\" %}\n@@ -2876,2 +2876,4 @@\n-instruct reduce_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 4);\n+instruct reduce_non_strict_order_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for 128-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 4 && !n->as_Reduction()->requires_strict_order());\n@@ -2880,1 +2882,1 @@\n-  format %{ \"reduce_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  format %{ \"reduce_non_strict_order_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n@@ -2889,0 +2891,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionVF when vector size > 128-bits. For example -\n+\/\/    AddReductionVF generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionVF. For example - AddReductionVF generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -2890,1 +2900,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -2894,0 +2905,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -2902,5 +2914,5 @@\n-\/\/ Floating-point addition is not associative, so the rule for AddReductionVD\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVD is only generated by Vector API.\n-instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0);\n+\n+instruct reduce_non_strict_order_add2D_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(!n->as_Reduction()->requires_strict_order());\n@@ -2909,1 +2921,1 @@\n-  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n+  format %{ \"reduce_non_strict_order_add2D_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n@@ -2917,0 +2929,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionVD when vector size > 128-bits. For example -\n+\/\/    AddReductionVD generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionVD. For example - AddReductionVD generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -2918,1 +2938,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -2922,0 +2943,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":42,"deletions":20,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -128,3 +128,3 @@\n-          \/\/ The vector implementation of Op_AddReductionVD\/F is for the Vector API only.\n-          \/\/ It is not suitable for auto-vectorization because it does not add the elements\n-          \/\/ in the same order as sequential code, and FP addition is non-associative.\n+          \/\/ The implementations of Op_AddReductionVD\/F in Neon are for the Vector API only.\n+          \/\/ They are not suitable for auto-vectorization because the result would not conform\n+          \/\/ to the JLS, Section Evaluation Order.\n@@ -1755,5 +1755,5 @@\n-\/\/ Floating-point addition is not associative, so the rules for AddReductionVF\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVF is only generated by Vector API.\n-instruct reduce_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 2);\n+\n+instruct reduce_non_strict_order_add2F_neon(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for a 64-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 2 && !n->as_Reduction()->requires_strict_order());\n@@ -1762,1 +1762,1 @@\n-  format %{ \"reduce_add2F_neon $dst, $fsrc, $vsrc\" %}\n+  format %{ \"reduce_non_strict_order_add2F_neon $dst, $fsrc, $vsrc\" %}\n@@ -1770,2 +1770,4 @@\n-instruct reduce_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(UseSVE == 0 && Matcher::vector_length(n->in(2)) == 4);\n+instruct reduce_non_strict_order_add4F_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for 128-bits-long vector. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(Matcher::vector_length(n->in(2)) == 4 && !n->as_Reduction()->requires_strict_order());\n@@ -1774,1 +1776,1 @@\n-  format %{ \"reduce_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  format %{ \"reduce_non_strict_order_add4F_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n@@ -1786,0 +1788,8 @@\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionV$1 when vector size > 128-bits. For example -\n+\/\/    AddReductionV$1 generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionV$1. For example - AddReductionV$1 generated by\n+\/\/    auto-vectorization on SVE machine.\n@@ -1787,1 +1797,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());\n@@ -1791,0 +1802,1 @@\n+    assert(UseSVE > 0, \"must be sve\");\n@@ -1801,5 +1813,5 @@\n-\/\/ Floating-point addition is not associative, so the rule for AddReductionVD\n-\/\/ on NEON can't be used to auto-vectorize floating-point reduce-add.\n-\/\/ Currently, on NEON, AddReductionVD is only generated by Vector API.\n-instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n-  predicate(UseSVE == 0);\n+\n+instruct reduce_non_strict_order_add2D_neon(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  \/\/ Non-strictly ordered floating-point add reduction for doubles. This rule is\n+  \/\/ intended for the VectorAPI (which allows for non-strictly ordered add reduction).\n+  predicate(!n->as_Reduction()->requires_strict_order());\n@@ -1808,1 +1820,1 @@\n-  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n+  format %{ \"reduce_non_strict_order_add2D_neon $dst, $dsrc, $vsrc\\t# 2D\" %}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":31,"deletions":19,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1463,1 +1463,1 @@\n-  \/\/ Move UnorderedReduction out of loop if possible\n+  \/\/ Move an unordered Reduction out of loop if possible\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4313,0 +4313,5 @@\n+\/\/ Returns true if the Reduction node is unordered.\n+static bool is_unordered_reduction(Node* n) {\n+  return n->is_Reduction() && !n->as_Reduction()->requires_strict_order();\n+}\n+\n@@ -4318,0 +4323,3 @@\n+\/\/ Note: UnorderedReduction represents a ReductionNode which does not require\n+\/\/ calculating in strict order.\n+\/\/\n@@ -4357,0 +4365,1 @@\n+\/\/\n@@ -4358,1 +4367,2 @@\n-\/\/ reordering of operations (for example float addition).\n+\/\/ reordering of operations (for example float addition\/multiplication require\n+\/\/ strict order).\n@@ -4362,1 +4372,1 @@\n-  \/\/ Find all Phi nodes with UnorderedReduction on backedge.\n+  \/\/ Find all Phi nodes with an unordered Reduction on backedge.\n@@ -4366,2 +4376,2 @@\n-    \/\/ We have a phi with a single use, and a UnorderedReduction on the backedge.\n-    if (!phi->is_Phi() || phi->outcnt() != 1 || !phi->in(2)->is_UnorderedReduction()) {\n+    \/\/ We have a phi with a single use, and an unordered Reduction on the backedge.\n+    if (!phi->is_Phi() || phi->outcnt() != 1 || !is_unordered_reduction(phi->in(2))) {\n@@ -4371,1 +4381,2 @@\n-    UnorderedReductionNode* last_ur = phi->in(2)->as_UnorderedReduction();\n+    ReductionNode* last_ur = phi->in(2)->as_Reduction();\n+    assert(!last_ur->requires_strict_order(), \"must be\");\n@@ -4388,2 +4399,2 @@\n-    \/\/ Traverse up the chain of UnorderedReductions, checking that it loops back to\n-    \/\/ the phi. Check that all UnorderedReductions only have a single use, except for\n+    \/\/ Traverse up the chain of unordered Reductions, checking that it loops back to\n+    \/\/ the phi. Check that all unordered Reductions only have a single use, except for\n@@ -4392,2 +4403,2 @@\n-    UnorderedReductionNode* current = last_ur;\n-    UnorderedReductionNode* first_ur = nullptr;\n+    ReductionNode* current = last_ur;\n+    ReductionNode* first_ur = nullptr;\n@@ -4395,1 +4406,1 @@\n-      assert(current->is_UnorderedReduction(), \"sanity\");\n+      assert(!current->requires_strict_order(), \"sanity\");\n@@ -4412,1 +4423,1 @@\n-      \/\/ Expect single use of UnorderedReduction, except for last_ur.\n+      \/\/ Expect single use of an unordered Reduction, except for last_ur.\n@@ -4430,1 +4441,1 @@\n-      \/\/ Expect another UnorderedReduction or phi as the scalar input.\n+      \/\/ Expect another unordered Reduction or phi as the scalar input.\n@@ -4432,1 +4443,1 @@\n-      if (scalar_input->is_UnorderedReduction() &&\n+      if (is_unordered_reduction(scalar_input) &&\n@@ -4434,2 +4445,3 @@\n-        \/\/ Move up the UnorderedReduction chain.\n-        current = scalar_input->as_UnorderedReduction();\n+        \/\/ Move up the unordered Reduction chain.\n+        current = scalar_input->as_Reduction();\n+        assert(!current->requires_strict_order(), \"must be\");\n@@ -4459,1 +4471,1 @@\n-    VectorNode::trace_new_vector(identity_vector, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(identity_vector, \"Unordered Reduction\");\n@@ -4468,1 +4480,1 @@\n-    \/\/ Traverse down the chain of UnorderedReductions, and replace them with vector_accumulators.\n+    \/\/ Traverse down the chain of unordered Reductions, and replace them with vector_accumulators.\n@@ -4477,1 +4489,1 @@\n-      VectorNode::trace_new_vector(vector_accumulator, \"UnorderedReduction\");\n+      VectorNode::trace_new_vector(vector_accumulator, \"Unordered Reduction\");\n@@ -4481,1 +4493,2 @@\n-      current = vector_accumulator->unique_out()->as_UnorderedReduction();\n+      current = vector_accumulator->unique_out()->as_Reduction();\n+      assert(!current->requires_strict_order(), \"must be\");\n@@ -4498,1 +4511,1 @@\n-    VectorNode::trace_new_vector(post_loop_reduction, \"UnorderedReduction\");\n+    VectorNode::trace_new_vector(post_loop_reduction, \"Unordered Reduction\");\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":33,"deletions":20,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -178,1 +178,0 @@\n-class UnorderedReductionNode;\n@@ -742,1 +741,0 @@\n-          DEFINE_CLASS_ID(UnorderedReduction, Reduction, 0)\n@@ -994,1 +992,0 @@\n-  DEFINE_CLASS_QUERY(UnorderedReduction)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1619,14 +1619,6 @@\n-  Node* value = nullptr;\n-  if (mask == nullptr) {\n-    assert(!is_masked_op, \"Masked op needs the mask value never null\");\n-    value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n-  } else {\n-    if (use_predicate) {\n-      value = ReductionNode::make(opc, nullptr, init, opd, elem_bt);\n-      value->add_req(mask);\n-      value->add_flag(Node::Flag_is_predicated_vector);\n-    } else {\n-      Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n-      value = gvn().transform(new VectorBlendNode(reduce_identity, opd, mask));\n-      value = ReductionNode::make(opc, nullptr, init, value, elem_bt);\n-    }\n+  Node* value = opd;\n+\n+  assert(mask != nullptr || !is_masked_op, \"Masked op needs the mask value never null\");\n+  if (mask != nullptr && !use_predicate) {\n+    Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n+    value = gvn().transform(new VectorBlendNode(reduce_identity, value, mask));\n@@ -1634,0 +1626,10 @@\n+\n+  \/\/ Make an unordered Reduction node. This affects only AddReductionVF\/VD and MulReductionVF\/VD,\n+  \/\/ as these operations are allowed to be associative (not requiring strict order) in VectorAPI.\n+  value = ReductionNode::make(opc, nullptr, init, value, elem_bt, \/* requires_strict_order *\/ false);\n+\n+  if (mask != nullptr && use_predicate) {\n+    value->add_req(mask);\n+    value->add_flag(Node::Flag_is_predicated_vector);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":16,"deletions":14,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -1299,1 +1299,2 @@\n-ReductionNode* ReductionNode::make(int opc, Node *ctrl, Node* n1, Node* n2, BasicType bt) {\n+ReductionNode* ReductionNode::make(int opc, Node* ctrl, Node* n1, Node* n2, BasicType bt,\n+                                   bool requires_strict_order) {\n@@ -1309,2 +1310,2 @@\n-  case Op_AddReductionVF: return new AddReductionVFNode(ctrl, n1, n2);\n-  case Op_AddReductionVD: return new AddReductionVDNode(ctrl, n1, n2);\n+  case Op_AddReductionVF: return new AddReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_AddReductionVD: return new AddReductionVDNode(ctrl, n1, n2, requires_strict_order);\n@@ -1313,7 +1314,7 @@\n-  case Op_MulReductionVF: return new MulReductionVFNode(ctrl, n1, n2);\n-  case Op_MulReductionVD: return new MulReductionVDNode(ctrl, n1, n2);\n-  case Op_MinReductionV:  return new MinReductionVNode(ctrl, n1, n2);\n-  case Op_MaxReductionV:  return new MaxReductionVNode(ctrl, n1, n2);\n-  case Op_AndReductionV:  return new AndReductionVNode(ctrl, n1, n2);\n-  case Op_OrReductionV:   return new OrReductionVNode(ctrl, n1, n2);\n-  case Op_XorReductionV:  return new XorReductionVNode(ctrl, n1, n2);\n+  case Op_MulReductionVF: return new MulReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MulReductionVD: return new MulReductionVDNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MinReductionV:  return new MinReductionVNode (ctrl, n1, n2);\n+  case Op_MaxReductionV:  return new MaxReductionVNode (ctrl, n1, n2);\n+  case Op_AndReductionV:  return new AndReductionVNode (ctrl, n1, n2);\n+  case Op_OrReductionV:   return new OrReductionVNode  (ctrl, n1, n2);\n+  case Op_XorReductionV:  return new XorReductionVNode (ctrl, n1, n2);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":11,"deletions":10,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -206,1 +206,3 @@\n-  static ReductionNode* make(int opc, Node* ctrl, Node* in1, Node* in2, BasicType bt);\n+  static ReductionNode* make(int opc, Node* ctrl, Node* in1, Node* in2, BasicType bt,\n+                             \/\/ This only effects floating-point add and mul reductions.\n+                             bool requires_strict_order = true);\n@@ -228,1 +230,0 @@\n-};\n@@ -230,6 +231,18 @@\n-\/\/---------------------------UnorderedReductionNode-------------------------------------\n-\/\/ Order of reduction does not matter. Example int add. Not true for float add.\n-class UnorderedReductionNode : public ReductionNode {\n-public:\n-  UnorderedReductionNode(Node * ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {\n-    init_class_id(Class_UnorderedReduction);\n+  \/\/ Floating-point addition and multiplication are non-associative, so\n+  \/\/ AddReductionVF\/D and MulReductionVF\/D require strict ordering\n+  \/\/ in auto-vectorization. Vector API can generate AddReductionVF\/D\n+  \/\/ and MulReductionVF\/VD without strict ordering, which can benefit\n+  \/\/ some platforms.\n+  \/\/\n+  \/\/ Other reductions don't need strict ordering.\n+  virtual bool requires_strict_order() const {\n+    return false;\n+  }\n+\n+#ifndef PRODUCT\n+  void dump_spec(outputStream* st) const {\n+    if (requires_strict_order()) {\n+      st->print(\"requires_strict_order\");\n+    } else {\n+      st->print(\"no_strict_order\");\n+    }\n@@ -237,0 +250,1 @@\n+#endif\n@@ -241,1 +255,1 @@\n-class AddReductionVINode : public UnorderedReductionNode {\n+class AddReductionVINode : public ReductionNode {\n@@ -243,1 +257,1 @@\n-  AddReductionVINode(Node * ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AddReductionVINode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -249,1 +263,1 @@\n-class AddReductionVLNode : public UnorderedReductionNode {\n+class AddReductionVLNode : public ReductionNode {\n@@ -251,1 +265,1 @@\n-  AddReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AddReductionVLNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -258,0 +272,6 @@\n+private:\n+  \/\/ True if add reduction operation for floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -259,1 +279,4 @@\n-  AddReductionVFNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -261,0 +284,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -266,0 +299,6 @@\n+private:\n+  \/\/ True if add reduction operation for doubles requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for doubles is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -267,1 +306,4 @@\n-  AddReductionVDNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVDNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -269,0 +311,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -403,1 +455,1 @@\n-class MulReductionVINode : public UnorderedReductionNode {\n+class MulReductionVINode : public ReductionNode {\n@@ -405,1 +457,1 @@\n-  MulReductionVINode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MulReductionVINode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -411,1 +463,1 @@\n-class MulReductionVLNode : public UnorderedReductionNode {\n+class MulReductionVLNode : public ReductionNode {\n@@ -413,1 +465,1 @@\n-  MulReductionVLNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MulReductionVLNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -420,0 +472,5 @@\n+  \/\/ True if mul reduction operation for floats requires strict ordering.\n+  \/\/ As an example - The value is true when mul reduction for floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -421,1 +478,4 @@\n-  MulReductionVFNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -423,0 +483,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -428,0 +498,5 @@\n+  \/\/ True if mul reduction operation for doubles requires strict ordering.\n+  \/\/ As an example - The value is true when mul reduction for doubles is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n@@ -429,1 +504,4 @@\n-  MulReductionVDNode(Node *ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n+  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVDNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n@@ -431,0 +509,10 @@\n+\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -756,1 +844,1 @@\n-class AndReductionVNode : public UnorderedReductionNode {\n+class AndReductionVNode : public ReductionNode {\n@@ -758,1 +846,1 @@\n-  AndReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  AndReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -773,1 +861,1 @@\n-class OrReductionVNode : public UnorderedReductionNode {\n+class OrReductionVNode : public ReductionNode {\n@@ -775,1 +863,1 @@\n-  OrReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  OrReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -790,1 +878,1 @@\n-class XorReductionVNode : public UnorderedReductionNode {\n+class XorReductionVNode : public ReductionNode {\n@@ -792,1 +880,1 @@\n-  XorReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  XorReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -798,1 +886,1 @@\n-class MinReductionVNode : public UnorderedReductionNode {\n+class MinReductionVNode : public ReductionNode {\n@@ -800,1 +888,1 @@\n-  MinReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MinReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n@@ -806,1 +894,1 @@\n-class MaxReductionVNode : public UnorderedReductionNode {\n+class MaxReductionVNode : public ReductionNode {\n@@ -808,1 +896,1 @@\n-  MaxReductionVNode(Node *ctrl, Node* in1, Node* in2) : UnorderedReductionNode(ctrl, in1, in2) {}\n+  MaxReductionVNode(Node* ctrl, Node* in1, Node* in2) : ReductionNode(ctrl, in1, in2) {}\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":118,"deletions":30,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -0,0 +1,111 @@\n+\/*\n+ * Copyright (c) 2024, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.loopopts.superword;\n+\n+import compiler.lib.ir_framework.*;\n+\n+\/*\n+ * @test\n+ * @bug 8320725\n+ * @summary Ensure strictly ordered AddReductionVF\/VD and MulReductionVF\/VD nodes\n+            are generated when these operations are auto-vectorized\n+ * @library \/test\/lib \/\n+ * @run driver compiler.loopopts.superword.TestVectorFPReduction\n+ *\/\n+\n+public class TestVectorFPReduction {\n+\n+    final private static int SIZE = 1024;\n+\n+    private static double[] da = new double[SIZE];\n+    private static double[] db = new double[SIZE];\n+    private static float[] fa = new float[SIZE];\n+    private static float[] fb = new float[SIZE];\n+    private static float fresult;\n+    private static double dresult;\n+\n+    public static void main(String[] args) {\n+        TestFramework.run();\n+    }\n+\n+    @Test\n+    @IR(failOn = {IRNode.ADD_REDUCTION_VF},\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+    @IR(counts = {\"requires_strict_order\", \">=1\", IRNode.ADD_REDUCTION_VF, \">=1\"},\n+        failOn = {\"no_strict_order\"},\n+        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    private static void testAddReductionVF() {\n+        float result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result += (fa[i] + fb[i]);\n+        }\n+        fresult += result;\n+    }\n+\n+    @Test\n+    @IR(failOn = {IRNode.ADD_REDUCTION_VD},\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+    @IR(counts = {\"requires_strict_order\", \">=1\", IRNode.ADD_REDUCTION_VD, \">=1\"},\n+        failOn = {\"no_strict_order\"},\n+        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    private static void testAddReductionVD() {\n+        double result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result += (da[i] + db[i]);\n+        }\n+        dresult += result;\n+    }\n+\n+    @Test\n+    @IR(failOn = {IRNode.MUL_REDUCTION_VF},\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+    @IR(counts = {\"requires_strict_order\", \">=1\", IRNode.MUL_REDUCTION_VF, \">=1\"},\n+        failOn = {\"no_strict_order\"},\n+        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    private static void testMulReductionVF() {\n+        float result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result *= (fa[i] + fb[i]);\n+        }\n+        fresult += result;\n+    }\n+\n+    @Test\n+    @IR(failOn = {IRNode.MUL_REDUCTION_VD},\n+        applyIfCPUFeatureAnd = {\"asimd\", \"true\", \"sve\", \"false\"})\n+    @IR(counts = {\"requires_strict_order\", \">=1\", IRNode.MUL_REDUCTION_VD, \">=1\"},\n+        failOn = {\"no_strict_order\"},\n+        applyIfCPUFeatureOr = {\"sve\", \"true\", \"sse2\", \"true\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    private static void testMulReductionVD() {\n+        double result = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            result *= (da[i] + db[i]);\n+        }\n+        dresult += result;\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestVectorFPReduction.java","additions":111,"deletions":0,"binary":false,"changes":111,"status":"added"},{"patch":"@@ -0,0 +1,211 @@\n+\/*\n+ * Copyright (c) 2024, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.vectorapi;\n+\n+import compiler.lib.ir_framework.*;\n+\n+import jdk.incubator.vector.DoubleVector;\n+import jdk.incubator.vector.FloatVector;\n+import jdk.incubator.vector.VectorOperators;\n+import jdk.incubator.vector.VectorSpecies;\n+\n+import java.util.Random;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Utils;\n+\n+\/**\n+ * @test\n+ * @bug 8320725\n+ * @library \/test\/lib \/\n+ * @summary Verify non-strictly ordered AddReductionVF\/VD and MulReductionVF\/VD\n+ *          nodes are generated in VectorAPI\n+ * @modules jdk.incubator.vector\n+ * @run driver compiler.vectorapi.TestVectorAddMulReduction\n+ *\/\n+\n+public class TestVectorAddMulReduction {\n+\n+    private static final int SIZE = 1024;\n+    private static final Random RD = Utils.getRandomInstance();\n+\n+    private static float[] fa;\n+    private static float fres;\n+    private static double[] da;\n+    private static double dres;\n+\n+    static {\n+        fa = new float[SIZE];\n+        da = new double[SIZE];\n+        fres = 1;\n+        dres = 1;\n+        for (int i = 0; i < SIZE; i++) {\n+            fa[i] = RD.nextFloat();\n+            da[i] = RD.nextDouble();\n+        }\n+    }\n+\n+    \/\/ Test add reduction operation for floats\n+    @ForceInline\n+    public static void testFloatAddKernel(VectorSpecies SPECIES, float[] f) {\n+        for (int i = 0; i < SPECIES.loopBound(f.length); i += SPECIES.length()) {\n+            var av = FloatVector.fromArray(SPECIES, f, i);\n+            fres += av.reduceLanes(VectorOperators.ADD);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=8\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_64() {\n+        testFloatAddKernel(FloatVector.SPECIES_64, fa);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=16\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_128() {\n+        testFloatAddKernel(FloatVector.SPECIES_128, fa);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=32\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_256() {\n+        testFloatAddKernel(FloatVector.SPECIES_256, fa);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=64\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatAdd_512() {\n+        testFloatAddKernel(FloatVector.SPECIES_512, fa);\n+    }\n+\n+    \/\/ Test add reduction operation for doubles\n+    @ForceInline\n+    public static void testDoubleAddKernel(VectorSpecies SPECIES, double[] d) {\n+        for (int i = 0; i < SPECIES.loopBound(d.length); i += SPECIES.length()) {\n+            var av = DoubleVector.fromArray(SPECIES, d, i);\n+            dres += av.reduceLanes(VectorOperators.ADD);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=16\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_128() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_128, da);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=32\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_256() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_256, da);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.ADD_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=64\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleAdd_512() {\n+        testDoubleAddKernel(DoubleVector.SPECIES_512, da);\n+    }\n+\n+    \/\/ Test mul reduction operation for floats\n+    \/\/ On aarch64, there are no direct vector mul reduction instructions for float\/double mul reduction\n+    \/\/ and scalar instructions are emitted for 64-bit\/128-bit vectors. Thus MulReductionVF\/VD nodes are generated\n+    \/\/ only for vector length of 8B\/16B on vectorAPI.\n+    @ForceInline\n+    public static void testFloatMulKernel(VectorSpecies SPECIES, float[] f) {\n+        for (int i = 0; i < SPECIES.loopBound(f.length); i += SPECIES.length()) {\n+            var av = FloatVector.fromArray(SPECIES, f, i);\n+            fres += av.reduceLanes(VectorOperators.MUL);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.MUL_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=8\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatMul_64() {\n+        testFloatMulKernel(FloatVector.SPECIES_64, fa);\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.MUL_REDUCTION_VF, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=16\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testFloatMul_128() {\n+        testFloatMulKernel(FloatVector.SPECIES_128, fa);\n+    }\n+\n+    \/\/ Test mul reduction operation for doubles\n+    @ForceInline\n+    public static void testDoubleMulKernel(VectorSpecies SPECIES, double[] d) {\n+        for (int i = 0; i < SPECIES.loopBound(d.length); i += SPECIES.length()) {\n+            var av = DoubleVector.fromArray(SPECIES, d, i);\n+            dres += av.reduceLanes(VectorOperators.MUL);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {IRNode.MUL_REDUCTION_VD, \">=1\", \"no_strict_order\", \">=1\"},\n+        failOn = {\"requires_strict_order\"},\n+        applyIfCPUFeatureOr = {\"asimd\", \"true\", \"sse2\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \">=16\"},\n+        phase = CompilePhase.PRINT_IDEAL)\n+    public static void testDoubleMul_128() {\n+        testDoubleMulKernel(DoubleVector.SPECIES_128, da);\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFramework.runWithFlags(\"--add-modules=jdk.incubator.vector\");\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/TestVectorAddMulReduction.java","additions":211,"deletions":0,"binary":false,"changes":211,"status":"added"}]}