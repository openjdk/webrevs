{"files":[{"patch":"@@ -44,1 +44,1 @@\n-  FreeNode* old_head = _head.fetch_then_set(node);\n+  FreeNode* old_head = AtomicAccess::xchg(&_head, node);\n@@ -51,1 +51,1 @@\n-  return _count.add_then_fetch(1u);\n+  return AtomicAccess::add(&_count, size_t(1));\n@@ -55,2 +55,2 @@\n-  NodeList result{_head.load_relaxed(), _tail, _count.load_relaxed()};\n-  _head.store_relaxed(nullptr);\n+  NodeList result{AtomicAccess::load(&_head), _tail, AtomicAccess::load(&_count)};\n+  AtomicAccess::store(&_head, (FreeNode*)nullptr);\n@@ -58,1 +58,1 @@\n-  _count.store_relaxed(0u);\n+  AtomicAccess::store(&_count, size_t(0));\n@@ -63,1 +63,1 @@\n-  return _count.load_relaxed();\n+  return  AtomicAccess::load(&_count);\n@@ -88,1 +88,1 @@\n-  uint index = _active_pending_list.load_relaxed();\n+  uint index = AtomicAccess::load(&_active_pending_list);\n@@ -96,1 +96,1 @@\n-  uint index = _active_pending_list.load_relaxed();\n+  uint index = AtomicAccess::load(&_active_pending_list);\n@@ -99,1 +99,1 @@\n-  _free_count.store_relaxed(0u);\n+  _free_count = 0;\n@@ -103,1 +103,1 @@\n-  return _free_count.load_relaxed();\n+  return AtomicAccess::load(&_free_count);\n@@ -107,1 +107,1 @@\n-  uint index = _active_pending_list.load_relaxed();\n+  uint index = AtomicAccess::load(&_active_pending_list);\n@@ -127,1 +127,1 @@\n-    size_t count = _free_count.sub_then_fetch(1u);\n+    size_t count = AtomicAccess::sub(&_free_count, 1u);\n@@ -152,1 +152,1 @@\n-    uint index = _active_pending_list.load_acquire();\n+    uint index = AtomicAccess::load_acquire(&_active_pending_list);\n@@ -167,2 +167,2 @@\n-  if (_transfer_lock.load_relaxed() || \/\/ Skip CAS if likely to fail.\n-      _transfer_lock.cmpxchg(false, true)) {\n+  if (AtomicAccess::load(&_transfer_lock) || \/\/ Skip CAS if likely to fail.\n+      AtomicAccess::cmpxchg(&_transfer_lock, false, true)) {\n@@ -175,1 +175,1 @@\n-  uint index = _active_pending_list.load_relaxed();\n+  uint index = AtomicAccess::load(&_active_pending_list);\n@@ -177,1 +177,1 @@\n-  _active_pending_list.release_store(new_active);\n+  AtomicAccess::release_store(&_active_pending_list, new_active);\n@@ -189,1 +189,1 @@\n-    _free_count.add_then_fetch(count);\n+    AtomicAccess::add(&_free_count, count);\n@@ -194,1 +194,1 @@\n-  _transfer_lock.release_store(false);\n+  AtomicAccess::release_store(&_transfer_lock, false);\n","filename":"src\/hotspot\/share\/gc\/shared\/freeListAllocator.cpp","additions":19,"deletions":19,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -65,1 +65,1 @@\n-    Atomic<FreeNode*> _next;\n+    FreeNode* volatile _next;\n@@ -69,1 +69,1 @@\n-    FreeNode* next() { return _next.load_relaxed(); }\n+    FreeNode* next() { return AtomicAccess::load(&_next); }\n@@ -71,1 +71,1 @@\n-    Atomic<FreeNode*>* next_addr() { return &_next; }\n+    FreeNode* volatile* next_addr() { return &_next; }\n@@ -73,1 +73,1 @@\n-    void set_next(FreeNode* next) { _next.store_relaxed(next); }\n+    void set_next(FreeNode* next) { AtomicAccess::store(&_next, next); }\n@@ -88,2 +88,2 @@\n-    Atomic<FreeNode*> _head;\n-    Atomic<size_t> _count;\n+    FreeNode* volatile _head;\n+    volatile size_t _count;\n@@ -108,1 +108,1 @@\n-  static Atomic<FreeNode*>* next_ptr(FreeNode& node) { return node.next_addr(); }\n+  static FreeNode* volatile* next_ptr(FreeNode& node) { return node.next_addr(); }\n@@ -116,1 +116,1 @@\n-  DECLARE_PADDED_MEMBER(1, Atomic<size_t>, _free_count);\n+  DECLARE_PADDED_MEMBER(1, volatile size_t, _free_count);\n@@ -118,1 +118,1 @@\n-  DECLARE_PADDED_MEMBER(3, Atomic<bool>, _transfer_lock);\n+  DECLARE_PADDED_MEMBER(3, volatile bool, _transfer_lock);\n@@ -121,1 +121,1 @@\n-  Atomic<uint> _active_pending_list;\n+  volatile uint _active_pending_list;\n","filename":"src\/hotspot\/share\/gc\/shared\/freeListAllocator.hpp","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cppstdlib\/type_traits.hpp\"\n@@ -33,2 +34,0 @@\n-#include <type_traits>\n-\n@@ -78,1 +77,1 @@\n-\/\/     v.cmpxchg(x, y [, o]) -> T\n+\/\/     v.compare_exchange(x, y [, o]) -> T\n@@ -96,1 +95,1 @@\n-\/\/     v.fetch_then_set(x [, o]) -> T\n+\/\/     v.exchange(x [, o]) -> T\n@@ -101,2 +100,0 @@\n-\/\/     v.atomic_inc([o]) -> void\n-\/\/     v.atomic_dec([o]) -> void\n@@ -108,1 +105,1 @@\n-\/\/ (4) An atomic translated type additionally provides the fetch_then_set\n+\/\/ (4) An atomic translated type additionally provides the exchange\n@@ -126,4 +123,0 @@\n-\/\/   member functions:\n-\/\/     v.replace_if_null(x [, o]) -> bool\n-\/\/     v.clear_if_equal(x [, o]) -> bool\n-\/\/\n@@ -137,1 +130,1 @@\n-\/\/ Atomic bytes don't provide fetch_then_set. This is because that operation\n+\/\/ Atomic bytes don't provide exchange(). This is because that operation\n@@ -194,1 +187,1 @@\n-  template<typename T> class SupportsFetchThenSet;\n+  template<typename T> class SupportsExchange;\n@@ -197,5 +190,5 @@\n-  \/\/ Support conditional fetch_then_set() for atomic translated types.\n-  template<typename T> class HasFetchThenSet;\n-  template<typename T> class DecayedHasFetchThenSet;\n-  template<typename Derived, typename T, bool = DecayedHasFetchThenSet<T>::value>\n-  class TranslatedFetchThenSet;\n+  \/\/ Support conditional exchange() for atomic translated types.\n+  template<typename T> class HasExchange;\n+  template<typename T> class DecayedHasExchange;\n+  template<typename Derived, typename T, bool = DecayedHasExchange<T>::value>\n+  class TranslatedExchange;\n@@ -281,2 +274,2 @@\n-  T cmpxchg(T compare_value, T new_value,\n-            atomic_memory_order order = memory_order_conservative) {\n+  T compare_exchange(T compare_value, T new_value,\n+                     atomic_memory_order order = memory_order_conservative) {\n@@ -288,1 +281,1 @@\n-class AtomicImpl::SupportsFetchThenSet : public CommonCore<T> {\n+class AtomicImpl::SupportsExchange : public CommonCore<T> {\n@@ -292,2 +285,2 @@\n-  explicit SupportsFetchThenSet(T value) : Base(value) {}\n-  ~SupportsFetchThenSet() = default;\n+  explicit SupportsExchange(T value) : Base(value) {}\n+  ~SupportsExchange() = default;\n@@ -296,2 +289,2 @@\n-  T fetch_then_set(T new_value,\n-                   atomic_memory_order order = memory_order_conservative) {\n+  T exchange(T new_value,\n+             atomic_memory_order order = memory_order_conservative) {\n@@ -303,2 +296,2 @@\n-class AtomicImpl::SupportsArithmetic : public SupportsFetchThenSet<T> {\n-  using Base = SupportsFetchThenSet<T>;\n+class AtomicImpl::SupportsArithmetic : public SupportsExchange<T> {\n+  using Base = SupportsExchange<T>;\n@@ -358,8 +351,0 @@\n-\n-  void atomic_inc(atomic_memory_order order = memory_order_conservative) {\n-    AtomicAccess::inc(this->value_ptr(), order);\n-  }\n-\n-  void atomic_dec(atomic_memory_order order = memory_order_conservative) {\n-    AtomicAccess::dec(this->value_ptr(), order);\n-  }\n@@ -445,10 +430,0 @@\n-\n-  bool replace_if_null(T new_value,\n-                       atomic_memory_order order = memory_order_conservative) {\n-    return nullptr == this->cmpxchg(nullptr, new_value, order);\n-  }\n-\n-  bool clear_if_equal(T compare_value,\n-                      atomic_memory_order order = memory_order_conservative) {\n-    return compare_value == this->cmpxchg(compare_value, nullptr, order);\n-  }\n@@ -459,1 +434,1 @@\n-\/\/ Test whether Atomic<T> has fetch_then_set().\n+\/\/ Test whether Atomic<T> has exchange().\n@@ -461,2 +436,2 @@\n-class AtomicImpl::HasFetchThenSet {\n-  template<typename Check> static char* test(decltype(&Check::fetch_then_set));\n+class AtomicImpl::HasExchange {\n+  template<typename Check> static char* test(decltype(&Check::exchange));\n@@ -469,1 +444,1 @@\n-\/\/ Test whether the atomic decayed type associated with T has fetch_then_set().\n+\/\/ Test whether the atomic decayed type associated with T has exchange().\n@@ -471,1 +446,1 @@\n-class AtomicImpl::DecayedHasFetchThenSet {\n+class AtomicImpl::DecayedHasExchange {\n@@ -475,4 +450,4 @@\n-  \/\/ \"Unit test\" HasFetchThenSet<>.\n-  static_assert(HasFetchThenSet<int>::value);\n-  static_assert(HasFetchThenSet<int*>::value);\n-  static_assert(!HasFetchThenSet<char>::value);\n+  \/\/ \"Unit test\" HasExchange<>.\n+  static_assert(HasExchange<int>::value);\n+  static_assert(HasExchange<int*>::value);\n+  static_assert(!HasExchange<char>::value);\n@@ -481,1 +456,1 @@\n-  static constexpr bool value = HasFetchThenSet<Decayed>::value;\n+  static constexpr bool value = HasExchange<Decayed>::value;\n@@ -485,1 +460,1 @@\n-\/\/ fetch_then_set().\n+\/\/ exchange().\n@@ -487,1 +462,1 @@\n-class AtomicImpl::TranslatedFetchThenSet {};\n+class AtomicImpl::TranslatedExchange {};\n@@ -490,1 +465,1 @@\n-\/\/ fetch_then_set().\n+\/\/ exchange().\n@@ -492,1 +467,1 @@\n-class AtomicImpl::TranslatedFetchThenSet<Derived, T, true> {\n+class AtomicImpl::TranslatedExchange<Derived, T, true> {\n@@ -494,3 +469,3 @@\n-  T fetch_then_set(T new_value,\n-                   atomic_memory_order order = memory_order_conservative) {\n-    return static_cast<Derived*>(this)->fetch_then_set_impl(new_value, order);\n+  T exchange(T new_value,\n+             atomic_memory_order order = memory_order_conservative) {\n+    return static_cast<Derived*>(this)->exchange_impl(new_value, order);\n@@ -502,1 +477,1 @@\n-  : public TranslatedFetchThenSet<Atomic<T>, T>\n+  : public TranslatedExchange<Atomic<T>, T>\n@@ -504,2 +479,2 @@\n-  \/\/ Give TranslatedFetchThenSet<> access to fetch_then_set_impl() if needed.\n-  friend class TranslatedFetchThenSet<Atomic<T>, T>;\n+  \/\/ Give TranslatedExchange<> access to exchange_impl() if needed.\n+  friend class TranslatedExchange<Atomic<T>, T>;\n@@ -561,5 +536,5 @@\n-  T cmpxchg(T compare_value, T new_value,\n-            atomic_memory_order order = memory_order_conservative) {\n-    return recover(_value.cmpxchg(decay(compare_value),\n-                                  decay(new_value),\n-                                  order));\n+  T compare_exchange(T compare_value, T new_value,\n+                     atomic_memory_order order = memory_order_conservative) {\n+    return recover(_value.compare_exchange(decay(compare_value),\n+                                           decay(new_value),\n+                                           order));\n@@ -569,1 +544,1 @@\n-  \/\/ Implementation of fetch_then_set() if needed.\n+  \/\/ Implementation of exchange() if needed.\n@@ -572,3 +547,3 @@\n-  template<typename Dep = Decayed, ENABLE_IF(HasFetchThenSet<Dep>::value)>\n-  T fetch_then_set_impl(T new_value, atomic_memory_order order) {\n-    return recover(_value.fetch_then_set(decay(new_value), order));\n+  template<typename Dep = Decayed, ENABLE_IF(HasExchange<Dep>::value)>\n+  T exchange_impl(T new_value, atomic_memory_order order) {\n+    return recover(_value.exchange(decay(new_value), order));\n","filename":"src\/hotspot\/share\/runtime\/atomic.hpp","additions":49,"deletions":74,"binary":false,"changes":123,"status":"modified"},{"patch":"@@ -1,83 +0,0 @@\n-\/*\n- * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_UTILITIES_ATOMICNEXTACCESS_HPP\n-#define SHARE_UTILITIES_ATOMICNEXTACCESS_HPP\n-\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/atomicAccess.hpp\"\n-\n-\/\/ A helper class for LockFreeStack and similar intrusive-list style data\n-\/\/ structures that involve atomicity.  These classes require the list element\n-\/\/ provide a function pointer template parameter for getting the \"next\" field\n-\/\/ from an element object.  That function pointer may take one of two forms,\n-\/\/ where T is the element type:\n-\/\/\n-\/\/ - T* volatile* (*)(T&)\n-\/\/ - Atomic<T>* (*)(T&)\n-\/\/\n-\/\/ Specializations of this class provide functions that manipulate the next\n-\/\/ field according to the access mechanism.\n-template<typename T, auto next_access>\n-struct AtomicNextAccess;\n-\n-template<typename T, T* volatile* (*next_access)(T&)>\n-struct AtomicNextAccess<T, next_access> {\n-  static T* next(const T& value) {\n-    return AtomicAccess::load(next_access(const_cast<T&>(value)));\n-  }\n-\n-  static T* next_acquire(const T& value) {\n-    return AtomicAccess::load_acquire(next_access(const_cast<T&>(value)));\n-  }\n-\n-  static void set_next(T& value, T* new_next) {\n-    AtomicAccess::store(next_access(value), new_next);\n-  }\n-\n-  static T* cmpxchg(T& value, const T* compare, T* exchange) {\n-    return AtomicAccess::cmpxchg(next_access(value), compare, exchange);\n-  }\n-};\n-\n-template<typename T, Atomic<T*>* (*next_access)(T&)>\n-struct AtomicNextAccess<T, next_access> {\n-  static T* next(const T& value) {\n-    return next_access(const_cast<T&>(value))->load_relaxed();\n-  }\n-\n-  static T* next_acquire(const T& value) {\n-    return next_access(const_cast<T&>(value))->load_acquire();\n-  }\n-\n-  static void set_next(T& value, T* new_next) {\n-    next_access(value)->store_relaxed(new_next);\n-  }\n-\n-  static T* cmpxchg(T& value, const T* compare, T* exchange) {\n-    return next_access(value)->cmpxchg(compare, exchange);\n-  }\n-};\n-\n-#endif \/\/ SHARE_UTILITIES_ATOMICNEXTACCESS_HPP\n","filename":"src\/hotspot\/share\/utilities\/atomicNextAccess.hpp","additions":0,"deletions":83,"binary":false,"changes":83,"status":"deleted"},{"patch":"@@ -28,2 +28,1 @@\n-#include \"runtime\/atomic.hpp\"\n-#include \"utilities\/atomicNextAccess.hpp\"\n+#include \"runtime\/atomicAccess.hpp\"\n@@ -38,8 +37,5 @@\n-\/\/ To be used in a LockFreeStack of objects of type T, an object of type T\n-\/\/ must have a list entry member. A list entry member is a data member whose\n-\/\/ type is either (1) Atomic<T*>, or (2) T* volatile. There must be a\n-\/\/ non-member or static member function returning a pointer to that member,\n-\/\/ which is used to provide access to it by a LockFreeStack.  A LockFreeStack\n-\/\/ is associated with the class of its elements and an entry member from that\n-\/\/ class by being specialized on the element class and a pointer to the\n-\/\/ function for accessing that entry member.\n+\/\/ To be used in a LockFreeStack of objects of type T, an object of\n+\/\/ type T must have a list entry member of type T* volatile, with an\n+\/\/ non-member accessor function returning a pointer to that member.  A\n+\/\/ LockFreeStack is associated with the class of its elements and an\n+\/\/ entry member from that class.\n@@ -59,1 +55,1 @@\n-\/\/ \\tparam next_access is a function pointer.  Applying this function to\n+\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n@@ -62,1 +58,1 @@\n-template<typename T, auto next_access>\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n@@ -64,1 +60,1 @@\n-  Atomic<T*> _top;\n+  T* volatile _top;\n@@ -72,1 +68,1 @@\n-      cur = _top.cmpxchg(cur, first);\n+      cur = AtomicAccess::cmpxchg(&_top, cur, first);\n@@ -96,1 +92,1 @@\n-      result = _top.cmpxchg(result, new_top);\n+      result = AtomicAccess::cmpxchg(&_top, result, new_top);\n@@ -108,1 +104,1 @@\n-    return _top.fetch_then_set(nullptr);\n+    return AtomicAccess::xchg(&_top, (T*)nullptr);\n@@ -152,1 +148,1 @@\n-  T* top() const { return _top.load_relaxed(); }\n+  T* top() const { return AtomicAccess::load(&_top); }\n@@ -167,1 +163,1 @@\n-    return AtomicNextAccess<T, next_access>::next(value);\n+    return AtomicAccess::load(next_ptr(const_cast<T&>(value)));\n@@ -175,1 +171,1 @@\n-    AtomicNextAccess<T, next_access>::set_next(value, new_next);\n+    AtomicAccess::store(next_ptr(value), new_next);\n","filename":"src\/hotspot\/share\/utilities\/lockFreeStack.hpp","additions":15,"deletions":19,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,2 +29,0 @@\n-#include \"runtime\/atomic.hpp\"\n-#include \"utilities\/atomicNextAccess.hpp\"\n@@ -38,3 +36,2 @@\n-\/\/ the link to the next element provided by a member of each element. The\n-\/\/ type of this list entry member must be either (1) Atomic<T*>, or\n-\/\/ (2) T* volatile. The next_access template parameter provides access to it.\n+\/\/ the link to the next element provided by a member of each element.\n+\/\/ Access to this member is provided by the next_ptr function.\n@@ -61,1 +58,1 @@\n-\/\/ \\tparam next_access is a function pointer.  Applying this function to\n+\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n@@ -64,1 +61,1 @@\n-template<typename T, auto next_access>\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n@@ -66,1 +63,1 @@\n-  Atomic<T*> _head;\n+  T* volatile _head;\n@@ -69,1 +66,1 @@\n-  Atomic<T*> _tail;\n+  T* volatile _tail;\n@@ -73,2 +70,0 @@\n-  using NextAccess = AtomicNextAccess<T, next_access>;\n-\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.hpp","additions":7,"deletions":12,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -30,1 +30,0 @@\n-#include \"runtime\/atomic.hpp\"\n@@ -32,1 +31,0 @@\n-#include \"utilities\/atomicNextAccess.hpp\"\n@@ -34,3 +32,3 @@\n-template<typename T, auto next_access>\n-T* NonblockingQueue<T, next_access>::next(const T& node) {\n-  return NextAccess::next(node);\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::next(const T& node) {\n+  return AtomicAccess::load(next_ptr(const_cast<T&>(node)));\n@@ -39,3 +37,3 @@\n-template<typename T, auto next_access>\n-void NonblockingQueue<T, next_access>::set_next(T& node, T* new_next) {\n-  NextAccess::set_next(node, new_next);\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void NonblockingQueue<T, next_ptr>::set_next(T& node, T* new_next) {\n+  AtomicAccess::store(next_ptr(node), new_next);\n@@ -44,3 +42,2 @@\n-template<typename T, auto next_access>\n-NonblockingQueue<T, next_access>::NonblockingQueue()\n-  : _head(nullptr), _tail(nullptr) {}\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+NonblockingQueue<T, next_ptr>::NonblockingQueue() : _head(nullptr), _tail(nullptr) {}\n@@ -49,4 +46,4 @@\n-template<typename T, auto next_access>\n-NonblockingQueue<T, next_access>::~NonblockingQueue() {\n-  assert(_head.load_relaxed() == nullptr, \"precondition\");\n-  assert(_tail.load_relaxed() == nullptr, \"precondition\");\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+NonblockingQueue<T, next_ptr>::~NonblockingQueue() {\n+  assert(_head == nullptr, \"precondition\");\n+  assert(_tail == nullptr, \"precondition\");\n@@ -59,2 +56,2 @@\n-template<typename T, auto next_access>\n-T* NonblockingQueue<T, next_access>::end_marker() const {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::end_marker() const {\n@@ -64,3 +61,3 @@\n-template<typename T, auto next_access>\n-T* NonblockingQueue<T, next_access>::first() const {\n-  T* head = _head.load_relaxed();\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::first() const {\n+  T* head = AtomicAccess::load(&_head);\n@@ -70,2 +67,2 @@\n-template<typename T, auto next_access>\n-bool NonblockingQueue<T, next_access>::is_end(const T* entry) const {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::is_end(const T* entry) const {\n@@ -75,3 +72,3 @@\n-template<typename T, auto next_access>\n-bool NonblockingQueue<T, next_access>::empty() const {\n-  return _head.load_relaxed() == nullptr;\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::empty() const {\n+  return AtomicAccess::load(&_head) == nullptr;\n@@ -80,2 +77,2 @@\n-template<typename T, auto next_access>\n-size_t NonblockingQueue<T, next_access>::length() const {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+size_t NonblockingQueue<T, next_ptr>::length() const {\n@@ -104,2 +101,2 @@\n-template<typename T, auto next_access>\n-void NonblockingQueue<T, next_access>::append(T& first, T& last) {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void NonblockingQueue<T, next_ptr>::append(T& first, T& last) {\n@@ -111,1 +108,1 @@\n-  T* old_tail = _tail.fetch_then_set(&last);\n+  T* old_tail = AtomicAccess::xchg(&_tail, &last);\n@@ -116,1 +113,1 @@\n-    assert(_head.load_relaxed() == nullptr, \"invariant\");\n+    assert(AtomicAccess::load(&_head) == nullptr, \"invariant\");\n@@ -118,1 +115,1 @@\n-  } else if (is_end(NextAccess::cmpxchg(*old_tail, end_marker(), &first))) {\n+  } else if (is_end(AtomicAccess::cmpxchg(next_ptr(*old_tail), end_marker(), &first))) {\n@@ -134,1 +131,1 @@\n-    DEBUG_ONLY(T* old_head = _head.load_relaxed();)\n+    DEBUG_ONLY(T* old_head = AtomicAccess::load(&_head);)\n@@ -140,1 +137,1 @@\n-  _head.store_relaxed(&first);\n+  AtomicAccess::store(&_head, &first);\n@@ -143,2 +140,2 @@\n-template<typename T, auto next_access>\n-bool NonblockingQueue<T, next_access>::try_pop(T** node_ptr) {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::try_pop(T** node_ptr) {\n@@ -147,1 +144,1 @@\n-  T* old_head = _head.load_acquire();\n+  T* old_head = AtomicAccess::load_acquire(&_head);\n@@ -153,1 +150,1 @@\n-  T* next_node = NextAccess::next_acquire(*old_head);\n+  T* next_node = AtomicAccess::load_acquire(next_ptr(*old_head));\n@@ -166,1 +163,1 @@\n-    if (old_head != _head.cmpxchg(old_head, next_node)) {\n+    if (old_head != AtomicAccess::cmpxchg(&_head, old_head, next_node)) {\n@@ -194,1 +191,1 @@\n-  } else if (is_end(NextAccess::cmpxchg(*old_head, next_node, nullptr))) {\n+  } else if (is_end(AtomicAccess::cmpxchg(next_ptr(*old_head), next_node, (T*)nullptr))) {\n@@ -209,1 +206,1 @@\n-    _head.cmpxchg(old_head, nullptr);\n+    AtomicAccess::cmpxchg(&_head, old_head, (T*)nullptr);\n@@ -215,1 +212,1 @@\n-    _tail.cmpxchg(old_head, nullptr);\n+    AtomicAccess::cmpxchg(&_tail, old_head, (T*)nullptr);\n@@ -230,2 +227,2 @@\n-template<typename T, auto next_access>\n-T* NonblockingQueue<T, next_access>::pop() {\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::pop() {\n@@ -241,3 +238,3 @@\n-template<typename T, auto next_access>\n-Pair<T*, T*> NonblockingQueue<T, next_access>::take_all() {\n-  T* tail = _tail.load_relaxed();\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+Pair<T*, T*> NonblockingQueue<T, next_ptr>::take_all() {\n+  T* tail = AtomicAccess::load(&_tail);\n@@ -245,3 +242,3 @@\n-  Pair<T*, T*> result(_head.load_relaxed(), tail);\n-  _head.store_relaxed(nullptr);\n-  _tail.store_relaxed(nullptr);\n+  Pair<T*, T*> result(AtomicAccess::load(&_head), tail);\n+  AtomicAccess::store(&_head, (T*)nullptr);\n+  AtomicAccess::store(&_tail, (T*)nullptr);\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.inline.hpp","additions":47,"deletions":50,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-    value = _enter.cmpxchg(old, value);\n+    value = _enter.compare_exchange(old, value);\n@@ -98,1 +98,1 @@\n-  DEBUG_ONLY(_writers.atomic_dec();)\n+  assert(_writers.sub_then_fetch(1u) == 0u, \"invariant\");\n","filename":"src\/hotspot\/share\/utilities\/singleWriterSynchronizer.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cppstdlib\/type_traits.hpp\"\n@@ -28,2 +29,0 @@\n-#include <type_traits>\n-\n@@ -76,14 +75,0 @@\n-  void atomic_inc() {\n-    _test_value.store_relaxed(_old_value);\n-    T expected = _old_value + 1;\n-    _test_value.atomic_inc();\n-    EXPECT_EQ(expected, _test_value.load_relaxed());\n-  }\n-\n-  void atomic_dec() {\n-    _test_value.store_relaxed(_old_value);\n-    T expected = _old_value - 1;\n-    _test_value.atomic_dec();\n-    EXPECT_EQ(expected, _test_value.load_relaxed());\n-  }\n-\n@@ -97,2 +82,0 @@\n-    TEST_ARITHMETIC(atomic_inc)\n-    TEST_ARITHMETIC(atomic_dec)\n@@ -130,1 +113,1 @@\n-    T res = _test_value.fetch_then_set(five);\n+    T res = _test_value.exchange(five);\n@@ -157,1 +140,1 @@\n-    T res = _test_value.cmpxchg(five, ten);\n+    T res = _test_value.compare_exchange(five, ten);\n@@ -160,1 +143,1 @@\n-    res = _test_value.cmpxchg(zero, ten);\n+    res = _test_value.compare_exchange(zero, ten);\n@@ -204,1 +187,1 @@\n-    _array[index].cmpxchg(_default_val, one);\n+    _array[index].compare_exchange(_default_val, one);\n@@ -207,1 +190,1 @@\n-    _array[index].cmpxchg(one, _default_val);\n+    _array[index].compare_exchange(one, _default_val);\n@@ -241,1 +224,1 @@\n-    EXPECT_EQ(value1, _test_value.cmpxchg(value2, value2));\n+    EXPECT_EQ(value1, _test_value.compare_exchange(value2, value2));\n@@ -243,1 +226,1 @@\n-    EXPECT_EQ(value1, _test_value.cmpxchg(value1, value2));\n+    EXPECT_EQ(value1, _test_value.compare_exchange(value1, value2));\n@@ -250,1 +233,1 @@\n-    EXPECT_EQ(value1, _test_value.fetch_then_set(value2));\n+    EXPECT_EQ(value1, _test_value.exchange(value2));\n@@ -415,15 +398,1 @@\n-  void atomic_inc() {\n-    _test_value.store_relaxed(_initial_ptr);\n-    T* expected = _initial_ptr + 1;\n-    _test_value.atomic_inc();\n-    EXPECT_EQ(expected, _test_value.load_relaxed());\n-  }\n-\n-  void atomic_dec() {\n-    _test_value.store_relaxed(_initial_ptr);\n-    T* expected = _initial_ptr - 1;\n-    _test_value.atomic_dec();\n-    EXPECT_EQ(expected, _test_value.load_relaxed());\n-  }\n-\n-  void fetch_then_set() {\n+  void exchange() {\n@@ -432,1 +401,1 @@\n-    T* result = _test_value.fetch_then_set(replace);\n+    T* result = _test_value.exchange(replace);\n@@ -437,1 +406,1 @@\n-  void cmpxchg() {\n+  void compare_exchange() {\n@@ -442,1 +411,1 @@\n-    T* result = _test_value.cmpxchg(not_initial_ptr, replace);\n+    T* result = _test_value.compare_exchange(not_initial_ptr, replace);\n@@ -446,1 +415,1 @@\n-    result = _test_value.cmpxchg(_initial_ptr, replace);\n+    result = _test_value.compare_exchange(_initial_ptr, replace);\n@@ -451,20 +420,0 @@\n-  void replace_if_null() {\n-    _test_value.store_relaxed(nullptr);\n-    EXPECT_TRUE(_test_value.replace_if_null(_initial_ptr));\n-    EXPECT_EQ(_initial_ptr, _test_value.load_relaxed());\n-\n-    T* replace = _initial_ptr + 3;\n-    EXPECT_FALSE(_test_value.replace_if_null(replace));\n-    EXPECT_EQ(_initial_ptr, _test_value.load_relaxed());\n-  }\n-\n-  void clear_if_equal() {\n-    _test_value.store_relaxed(_initial_ptr);\n-    T* compare = _initial_ptr + 3;\n-    EXPECT_FALSE(_test_value.clear_if_equal(compare));\n-    EXPECT_EQ(_initial_ptr, _test_value.load_relaxed());\n-\n-    EXPECT_TRUE(_test_value.clear_if_equal(_initial_ptr));\n-    EXPECT_EQ(nullptr, _test_value.load_relaxed());\n-  }\n-\n@@ -478,6 +427,2 @@\n-    TEST_OP(atomic_inc)\n-    TEST_OP(atomic_dec)\n-    TEST_OP(fetch_then_set)\n-    TEST_OP(cmpxchg)\n-    TEST_OP(replace_if_null)\n-    TEST_OP(clear_if_equal)\n+    TEST_OP(exchange)\n+    TEST_OP(compare_exchange)\n@@ -572,1 +517,1 @@\n-\/\/ Test whether Atomic<T> has fetch_then_set().\n+\/\/ Test whether Atomic<T> has exchange().\n@@ -574,1 +519,1 @@\n-\/\/ by the atomic translated type to decide whether to provide fetch_then_set().\n+\/\/ by the atomic translated type to decide whether to provide exchange().\n@@ -578,1 +523,1 @@\n-class AtomicTypeHasFetchThenSet {\n+class AtomicTypeHasExchange {\n@@ -581,1 +526,1 @@\n-           typename = decltype(declval<AU>().fetch_then_set(declval<U>()))>\n+           typename = decltype(declval<AU>().exchange(declval<U>()))>\n@@ -592,6 +537,6 @@\n-\/\/ Unit tests for AtomicTypeHasFetchThenSet.\n-static_assert(AtomicTypeHasFetchThenSet<int>::value);\n-static_assert(AtomicTypeHasFetchThenSet<int*>::value);\n-static_assert(AtomicTypeHasFetchThenSet<TranslatedAtomicTestObject1>::value);\n-static_assert(AtomicTypeHasFetchThenSet<TranslatedAtomicTestObject2>::value);\n-static_assert(!AtomicTypeHasFetchThenSet<uint8_t>::value);\n+\/\/ Unit tests for AtomicTypeHasExchange.\n+static_assert(AtomicTypeHasExchange<int>::value);\n+static_assert(AtomicTypeHasExchange<int*>::value);\n+static_assert(AtomicTypeHasExchange<TranslatedAtomicTestObject1>::value);\n+static_assert(AtomicTypeHasExchange<TranslatedAtomicTestObject2>::value);\n+static_assert(!AtomicTypeHasExchange<uint8_t>::value);\n@@ -599,2 +544,2 @@\n-\/\/ Verify translated byte type *doesn't* have fetch_then_set.\n-static_assert(!AtomicTypeHasFetchThenSet<TranslatedAtomicByteObject>::value);\n+\/\/ Verify translated byte type *doesn't* have exchange.\n+static_assert(!AtomicTypeHasExchange<TranslatedAtomicByteObject>::value);\n@@ -603,1 +548,1 @@\n-\/\/ non-existent fetch_then_set of the atomic decayed type.\n+\/\/ non-existent exchange of the atomic decayed type.\n@@ -616,2 +561,2 @@\n-  EXPECT_EQ(5, Translated::decay(_test_value.cmpxchg(Translated::recover(5),\n-                                                     Translated::recover(10))));\n+  EXPECT_EQ(5, Translated::decay(_test_value.compare_exchange(Translated::recover(5),\n+                                                              Translated::recover(10))));\n@@ -620,2 +565,2 @@\n-  if constexpr (AtomicTypeHasFetchThenSet<T>::value) {\n-    EXPECT_EQ(10, Translated::decay(_test_value.fetch_then_set(Translated::recover(20))));\n+  if constexpr (AtomicTypeHasExchange<T>::value) {\n+    EXPECT_EQ(10, Translated::decay(_test_value.exchange(Translated::recover(20))));\n@@ -652,1 +597,1 @@\n-  EXPECT_EQ(5, resolve(_test_value.cmpxchg(construct(5), construct(10))));\n+  EXPECT_EQ(5, resolve(_test_value.compare_exchange(construct(5), construct(10))));\n@@ -654,1 +599,1 @@\n-  EXPECT_EQ(10, resolve(_test_value.fetch_then_set(construct(20))));\n+  EXPECT_EQ(10, resolve(_test_value.exchange(construct(20))));\n","filename":"test\/hotspot\/gtest\/runtime\/test_atomic.cpp","additions":35,"deletions":90,"binary":false,"changes":125,"status":"modified"}]}