{"files":[{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023 SAP SE. All rights reserved.\n@@ -846,0 +846,4 @@\n+\/\/ MI, signed\n+#define CHHSI_ZOPC  (unsigned long)(0xe5L << 40 | 0x54L << 32)\n+#define CHSI_ZOPC   (unsigned long)(0xe5L << 40 | 0x5cL << 32)\n+#define CGHSI_ZOPC  (unsigned long)(0xe5L << 40 | 0x58L << 32)\n@@ -858,0 +862,4 @@\n+\/\/ MI, unsigned\n+#define CLHHSI_ZOPC (unsigned long)(0xe5L << 40 | 0x55L << 32)\n+#define CLFHSI_ZOPC (unsigned long)(0xe5L << 40 | 0x5dL << 32)\n+#define CLGHSI_ZOPC (unsigned long)(0xe5L << 40 | 0x59L << 32)\n@@ -1063,0 +1071,1 @@\n+#define MVCIN_ZOPC  (unsigned long)(0xe8L << 40)\n@@ -1711,1 +1720,1 @@\n-    assert(Immediate::is_uimm(x, nbits), \"unsigned constant out of range\");\n+    assert(Immediate::is_uimm(x, nbits), \"unsigned immediate \" INTPTR_FORMAT \" out of range (%d bits)\", x, nbits);\n@@ -1718,1 +1727,1 @@\n-    assert(Immediate::is_simm(x, nbits), \"value out of range\");\n+    assert(Immediate::is_simm(x, nbits), \"signed immediate \" INTPTR_FORMAT \" out of range (%d bits)\", x, nbits);\n@@ -1725,1 +1734,1 @@\n-    assert((x >> nbits) == 0 || (x >> nbits) == -1, \"value out of range\");\n+    assert((x >> nbits) == 0 || (x >> nbits) == -1, \"signed immediate \" INTPTR_FORMAT \" out of range (%d bits)\", x, nbits);\n@@ -1737,1 +1746,1 @@\n-    assert(Immediate::is_simm(ui20, 20), \"value out of range\");\n+    assert(Immediate::is_simm(ui20, 20), \"signed displacement (disp20) \" INTPTR_FORMAT \" out of range\", ui20);\n@@ -1850,0 +1859,4 @@\n+   \/\/ compare memory - immediate\n+  inline void z_chhsi(int64_t d1, Register b1, int64_t i2);              \/\/ compare (*d1(b1), i2_imm16)      ; int16\n+  inline void z_chsi( int64_t d1, Register b1, int64_t i2);              \/\/ compare (*d1(b1), i2_imm16)      ; int32\n+  inline void z_cghsi(int64_t d1, Register b1, int64_t i2);              \/\/ compare (*d1(b1), i2_imm16)      ; int64\n@@ -1865,0 +1878,4 @@\n+   \/\/ compare memory - immediate\n+  inline void z_clhhsi(int64_t d1, Register b1, int64_t i2);             \/\/ compare (*d1(b1), i2_imm16)      ; uint16\n+  inline void z_clfhsi(int64_t d1, Register b1, int64_t i2);             \/\/ compare (*d1(b1), i2_imm16)      ; uint32\n+  inline void z_clghsi(int64_t d1, Register b1, int64_t i2);             \/\/ compare (*d1(b1), i2_imm16)      ; uint64\n@@ -2438,0 +2455,1 @@\n+  inline void z_mvcin(int64_t d1, int64_t l, Register b1, int64_t d2, Register b2); \/\/ move l+1 bytes\n","filename":"src\/hotspot\/cpu\/s390\/assembler_s390.hpp","additions":24,"deletions":6,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023 SAP SE. All rights reserved.\n@@ -280,1 +280,2 @@\n-inline void Assembler::z_mvc(int64_t d1, int64_t l, Register b1, int64_t d2, Register b2) { emit_48( MVC_ZOPC | uimm8(l, 8, 48) | rsmask_48(d1, b1) | rsmask_SS(d2, b2)); }\n+inline void Assembler::z_mvc(int64_t d1, int64_t l, Register b1, int64_t d2, Register b2) { emit_48( MVC_ZOPC   | uimm8(l, 8, 48) | rsmask_48(d1, b1) | rsmask_SS(d2, b2)); }\n+inline void Assembler::z_mvcin(int64_t d1, int64_t l, Register b1, int64_t d2, Register b2) { emit_48( MVCIN_ZOPC | uimm8(l, 8, 48) | rsmask_48(d1, b1) | rsmask_SS(d2, b2)); }\n@@ -650,0 +651,3 @@\n+inline void Assembler::z_chhsi(int64_t d1, Register b1, int64_t i2) { emit_48( CHHSI_ZOPC  | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n+inline void Assembler::z_chsi( int64_t d1, Register b1, int64_t i2) { emit_48( CHSI_ZOPC   | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n+inline void Assembler::z_cghsi(int64_t d1, Register b1, int64_t i2) { emit_48( CGHSI_ZOPC  | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n@@ -660,0 +664,3 @@\n+inline void Assembler::z_clhhsi(int64_t d1, Register b1, int64_t i2) { emit_48( CLHHSI_ZOPC  | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n+inline void Assembler::z_clfhsi(int64_t d1, Register b1, int64_t i2) { emit_48( CLFHSI_ZOPC  | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n+inline void Assembler::z_clghsi(int64_t d1, Register b1, int64_t i2) { emit_48( CLGHSI_ZOPC  | rsmask_48(d1, b1) | simm16(i2, 32, 48)); }\n@@ -775,1 +782,0 @@\n-\n@@ -1381,1 +1387,1 @@\n-inline void Assembler::z_brnp(  Label& L) { z_brc( bcondNotPositive, target( L)); }\n+inline void Assembler::z_brnp(  Label& L) { z_brc(bcondNotPositive, target( L)); }\n","filename":"src\/hotspot\/cpu\/s390\/assembler_s390.inline.hpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2023 SAP SE. All rights reserved.\n@@ -1055,1 +1055,1 @@\n-\/\/ addr: Address descriptor of memory to clear index register will not be used !\n+\/\/ addr: Address descriptor of memory to clear. Index register will not be used!\n@@ -1057,0 +1057,1 @@\n+\/\/ condition code will not be preserved.\n@@ -1059,7 +1060,2 @@\n-void MacroAssembler::clear_mem(const Address& addr, unsigned size) {\n-  guarantee(size <= 256, \"MacroAssembler::clear_mem: size too large\");\n-\n-  if (size == 1) {\n-    z_mvi(addr, 0);\n-    return;\n-  }\n+void MacroAssembler::clear_mem(const Address& addr, unsigned int size) {\n+  guarantee((addr.disp() + size) <= 4096, \"MacroAssembler::clear_mem: size too large\");\n@@ -1068,1 +1064,1 @@\n-    case 2: z_mvhhi(addr, 0);\n+    case 0:\n@@ -1070,1 +1066,2 @@\n-    case 4: z_mvhi(addr, 0);\n+    case 1:\n+      z_mvi(addr, 0);\n@@ -1072,1 +1069,8 @@\n-    case 8: z_mvghi(addr, 0);\n+    case 2:\n+      z_mvhhi(addr, 0);\n+      return;\n+    case 4:\n+      z_mvhi(addr, 0);\n+      return;\n+    case 8:\n+      z_mvghi(addr, 0);\n@@ -1077,1 +1081,15 @@\n-  z_xc(addr, size, addr);\n+  \/\/ Caution: the emitter with Address operands does implicitly decrement the length\n+  if (size <= 256) {\n+    z_xc(addr, size, addr);\n+  } else {\n+    unsigned int offset = addr.disp();\n+    unsigned int incr   = 256;\n+    for (unsigned int i = 0; i <= size-incr; i += incr) {\n+      z_xc(offset, incr - 1, addr.base(), offset, addr.base());\n+      offset += incr;\n+    }\n+    unsigned int rest = size - (offset - addr.disp());\n+    if (size > 0) {\n+      z_xc(offset, rest-1, addr.base(), offset, addr.base());\n+    }\n+  }\n","filename":"src\/hotspot\/cpu\/s390\/macroAssembler_s390.cpp","additions":31,"deletions":13,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2022 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023 SAP SE. All rights reserved.\n@@ -63,2 +63,0 @@\n-\/\/ These static, partially const, variables are for the AES intrinsics.\n-\/\/ They are declared\/initialized here to make them available across function bodies.\n@@ -66,26 +64,33 @@\n-#if defined(JIT_TIMER)\n-    static const int JIT_TIMER_space      = 8;                   \/\/ extra space for JIT_TIMER data\n-#else\n-    static const int JIT_TIMER_space      = 0;\n-#endif\n-    static const int AES_parmBlk_align    = 32;                  \/\/ octoword alignment.\n-\n-    static int AES_ctrVal_len  = 0;                              \/\/ ctr init value len (in bytes), expected: length of dataBlk (16)\n-    static int AES_ctrVec_len  = 0;                              \/\/ # of ctr vector elements. That many block can be ciphered with one instruction execution\n-    static int AES_ctrArea_len = 0;                              \/\/ reserved stack space (in bytes) for ctr (= ctrVal_len * ctrVec_len)\n-\n-    static int AES_parmBlk_addspace = 0;  \/\/ Must be multiple of AES_parmblk_align.\n-                                          \/\/ Will be set by stub generator to stub specific value.\n-    static int AES_dataBlk_space    = 0;  \/\/ Must be multiple of AES_parmblk_align.\n-                                          \/\/ Will be set by stub generator to stub specific value.\n-\n-    static const int keylen_offset     =  -1;\n-    static const int fCode_offset      =  -2;\n-    static const int ctrVal_len_offset =  -4;\n-    static const int msglen_offset     =  -8;\n-    static const int unextSP_offset    = -16;\n-    static const int remmsg_len_offset = -20;\n-    static const int argsave_offset    = -2*AES_parmBlk_align;\n-    static const int localSpill_offset = argsave_offset + 24;  \/\/ arg2..arg4 are saved\n-\n-\/\/ -----------------------------------------------------------------------\n+  \/\/ These static, partially const, variables are for the AES intrinsics.\n+  \/\/ They are declared\/initialized here to make them available across function bodies.\n+\n+      static const int AES_parmBlk_align    = 32;                  \/\/ octoword alignment.\n+      static const int AES_stackSpace_incr  = AES_parmBlk_align;   \/\/ add'l stack space is allocated in such increments.\n+                                                                   \/\/ Must be multiple of AES_parmBlk_align.\n+\n+      static int AES_ctrVal_len  = 0;                              \/\/ ctr init value len (in bytes), expected: length of dataBlk (16)\n+      static int AES_ctrVec_len  = 0;                              \/\/ # of ctr vector elements. That many block can be ciphered with one instruction execution\n+      static int AES_ctrArea_len = 0;                              \/\/ reserved stack space (in bytes) for ctr (= ctrVal_len * ctrVec_len)\n+\n+      static int AES_parmBlk_addspace = 0;  \/\/ Must be multiple of AES_parmblk_align.\n+                                            \/\/ Will be set by stub generator to stub specific value.\n+      static int AES_dataBlk_space    = 0;  \/\/ Must be multiple of AES_parmblk_align.\n+                                            \/\/ Will be set by stub generator to stub specific value.\n+      static int AES_dataBlk_offset   = 0;  \/\/ offset of the local src and dst dataBlk buffers\n+                                            \/\/ Will be set by stub generator to stub specific value.\n+\n+      \/\/ These offsets are relative to the parameter block address (Register parmBlk = Z_R1)\n+      static const int keylen_offset     =  -1;\n+      static const int fCode_offset      =  -2;\n+      static const int ctrVal_len_offset =  -4;\n+      static const int msglen_offset     =  -8;\n+      static const int unextSP_offset    = -16;\n+      static const int rem_msgblk_offset = -20;\n+      static const int argsave_offset    = -2*AES_parmBlk_align;\n+      static const int regsave_offset    = -4*AES_parmBlk_align; \/\/ save space for work regs (Z_R10..13)\n+      static const int msglen_red_offset = regsave_offset + AES_parmBlk_align; \/\/ reduced len after preLoop;\n+      static const int counter_offset    = msglen_red_offset+8;  \/\/ current counter vector position.\n+      static const int localSpill_offset = argsave_offset + 24;  \/\/ arg2..arg4 are saved\n+\n+\n+      \/\/ -----------------------------------------------------------------------\n@@ -1862,1 +1867,2 @@\n-\/\/ *****************************************************************************\n+\n+  \/\/ *****************************************************************************\n@@ -1870,2 +1876,0 @@\n-  \/\/   |        | JIT_TIMER timestamp buffer, only if JIT_TIMER is defined.\n-  \/\/   +--------+\n@@ -1880,1 +1884,2 @@\n-  \/\/   |        |         Each counter is a 128bit int. Vector element i is formed by incrementing element (i-1).\n+  \/\/   |        |         Each counter is a 128bit int. Vector element [0] is a copy of iv.\n+  \/\/   |        |         Vector element [i] is formed by incrementing element [i-1].\n@@ -1923,1 +1928,11 @@\n-  \/\/    parmBlk-48 ARG4(counter value) ptr spill slot\n+  \/\/    parmBlk-48 ARG4(icv value) ptr spill slot\n+  \/\/\n+  \/\/    parmBlk-72\n+  \/\/    parmBlk-80\n+  \/\/    parmBlk-88 counter vector current position\n+  \/\/    parmBlk-96 reduced msg len (after preLoop processing)\n+  \/\/\n+  \/\/    parmBlk-104 Z_R13 spill slot (preLoop only)\n+  \/\/    parmBlk-112 Z_R12 spill slot (preLoop only)\n+  \/\/    parmBlk-120 Z_R11 spill slot (preLoop only)\n+  \/\/    parmBlk-128 Z_R10 spill slot (preLoop only)\n@@ -1994,2 +2009,3 @@\n-    for (int j = 0; j < AES_ctrVec_len; j++) {\n-      int offset = j * AES_ctrVal_len;\n+\n+    if (v0_only) {\n+      int offset = 0;\n@@ -1997,1 +2013,14 @@\n-      if (v0_only) break;\n+    } else {\n+      int j = 0;\n+      if (VM_Version::has_VectorFacility()) {\n+        bool first_call = true;\n+        for (; j < (AES_ctrVec_len - 3); j+=4) {                       \/\/ increment blocks of 4 iv elements\n+          int offset = j * AES_ctrVal_len;\n+          generate_increment128x4(counter, offset, AES_ctrVec_len, first_call);\n+          first_call = false;\n+        }\n+      }\n+      for (; j < AES_ctrVec_len; j++) {\n+        int offset = j * AES_ctrVal_len;\n+        generate_increment128(counter, offset, AES_ctrVec_len, scratch); \/\/ increment iv by # vector elements\n+      }\n@@ -2017,1 +2046,33 @@\n-  void generate_counterMode_push_Block(int dataBlk_len, int parmBlk_len, int crypto_fCode,\n+  void generate_increment128(Register counter, int offset, Register increment, Register scratch) {\n+    __ clear_reg(scratch);                                 \/\/ prepare to add carry to high-order DW\n+    __ z_alg(increment, Address(counter, offset + 8));     \/\/ increment low order DW\n+    __ z_stg(increment, Address(counter, offset + 8));     \/\/ store back\n+    __ z_alcg(scratch, Address(counter, offset));          \/\/ add carry to high-order DW\n+    __ z_stg(scratch, Address(counter, offset));           \/\/ store back\n+  }\n+\n+  \/\/ This is the vector variant of increment128, incrementing 4 ctr vector elements per call.\n+  void generate_increment128x4(Register counter, int offset, int increment, bool init) {\n+    VectorRegister Vincr      = Z_V16;\n+    VectorRegister Vctr0      = Z_V20;\n+    VectorRegister Vctr1      = Z_V21;\n+    VectorRegister Vctr2      = Z_V22;\n+    VectorRegister Vctr3      = Z_V23;\n+\n+    \/\/ Initialize the increment value only once for a series of increments.\n+    \/\/ It must be assured that the non-initializing generator calls are\n+    \/\/ immediately subsequent. Otherwise, there is no guarantee for Vincr to be unchanged.\n+    if (init) {\n+      __ z_vzero(Vincr);                                   \/\/ preset VReg with constant increment\n+      __ z_vleih(Vincr, increment, 7);                     \/\/ rightmost HW has ix = 7\n+    }\n+\n+    __ z_vlm(Vctr0, Vctr3, offset, counter);               \/\/ get the counter values\n+    __ z_vaq(Vctr0, Vctr0, Vincr);                         \/\/ increment them\n+    __ z_vaq(Vctr1, Vctr1, Vincr);\n+    __ z_vaq(Vctr2, Vctr2, Vincr);\n+    __ z_vaq(Vctr3, Vctr3, Vincr);\n+    __ z_vstm(Vctr0, Vctr3, offset, counter);              \/\/ store the counter values\n+  }\n+\n+  unsigned int generate_counterMode_push_Block(int dataBlk_len, int parmBlk_len, int crypto_fCode,\n@@ -2021,3 +2082,3 @@\n-    AES_dataBlk_space    = roundup(2*dataBlk_len, AES_parmBlk_align);\n-    AES_parmBlk_addspace = AES_parmBlk_align    \/\/ spill space (temp data)\n-                         + AES_parmBlk_align    \/\/ for argument save\/restore\n+    AES_parmBlk_addspace = AES_stackSpace_incr             \/\/ spill space (temp data)\n+                         + AES_stackSpace_incr             \/\/ for argument save\/restore\n+                         + AES_stackSpace_incr*2           \/\/ for work reg save\/restore\n@@ -2025,1 +2086,3 @@\n-    const int key_len    = parmBlk_len;         \/\/ The length of the unextended key (16, 24, 32)\n+    AES_dataBlk_space    = roundup(2*dataBlk_len, AES_parmBlk_align);\n+    AES_dataBlk_offset   = -(AES_parmBlk_addspace+AES_dataBlk_space);\n+    const int key_len    = parmBlk_len;                    \/\/ The length of the unextended key (16, 24, 32)\n@@ -2028,2 +2091,2 @@\n-    AES_ctrVal_len  = dataBlk_len;               \/\/ ctr init value len (in bytes)\n-    AES_ctrArea_len = AES_ctrVec_len * AES_ctrVal_len; \/\/ space required on stack for ctr vector\n+    AES_ctrVal_len  = dataBlk_len;                         \/\/ ctr init value len (in bytes)\n+    AES_ctrArea_len = AES_ctrVec_len * AES_ctrVal_len;     \/\/ space required on stack for ctr vector\n@@ -2033,5 +2096,4 @@\n-    const int resize_len = JIT_TIMER_space       \/\/ timestamp storage for JIT_TIMER\n-                         + AES_parmBlk_align     \/\/ room for alignment of parmBlk\n-                         + AES_parmBlk_align     \/\/ extra room for alignment\n-                         + AES_dataBlk_space     \/\/ one src and one dst data blk\n-                         + AES_parmBlk_addspace  \/\/ spill space for local data\n+    const int resize_len = AES_parmBlk_align               \/\/ room for alignment of parmBlk\n+                         + AES_parmBlk_align               \/\/ extra room for alignment\n+                         + AES_dataBlk_space               \/\/ one src and one dst data blk\n+                         + AES_parmBlk_addspace            \/\/ spill space for local data\n@@ -2039,1 +2101,1 @@\n-                         + AES_ctrArea_len       \/\/ stack space for ctr vector\n+                         + AES_ctrArea_len                 \/\/ stack space for ctr vector\n@@ -2053,0 +2115,3 @@\n+#ifdef ASSERT\n+    __ clear_mem(Address(Z_SP, (intptr_t)8), resize_len - 8);\n+#endif\n@@ -2055,1 +2120,1 @@\n-    __ add2reg(parmBlk, AES_parmBlk_addspace + (AES_parmBlk_align-1), Z_SP);\n+    __ add2reg(parmBlk, AES_parmBlk_addspace + AES_dataBlk_space + (2*AES_parmBlk_align-1), Z_SP);\n@@ -2062,0 +2127,1 @@\n+    __ z_sty(msglen, msglen_red_offset, parmBlk);          \/\/ save for main loop, may get updated in preLoop.\n@@ -2063,1 +2129,1 @@\n-    __ z_sty(msglen, remmsg_len_offset, parmBlk);\n+    __ z_sty(msglen, rem_msgblk_offset, parmBlk);\n@@ -2067,0 +2133,1 @@\n+    __ z_stmg(Z_R10, Z_R13, regsave_offset, parmBlk);      \/\/ make some regs available as work registers\n@@ -2071,0 +2138,1 @@\n+    return resize_len;\n@@ -2077,1 +2145,1 @@\n-    assert_different_registers(scratch, Z_R0);            \/\/ can't use Z_R0 for exrl.\n+    assert_different_registers(scratch, Z_R0);             \/\/ can't use Z_R0 for exrl.\n@@ -2080,2 +2148,2 @@\n-    __ z_llgc(scratch, keylen_offset, parmBlk);           \/\/ get saved (key_len-1) value (we saved just one byte!)\n-    __ z_exrl(scratch, eraser);                           \/\/ template relies on parmBlk still pointing to key on stack\n+    __ z_llgc(scratch, keylen_offset, parmBlk);            \/\/ get saved (key_len-1) value (we saved just one byte!)\n+    __ z_exrl(scratch, eraser);                            \/\/ template relies on parmBlk still pointing to key on stack\n@@ -2088,2 +2156,42 @@\n-    __ z_lgf(msglen, msglen_offset,  parmBlk);            \/\/ Restore msglen, only low order FW is valid\n-    __ z_lg(Z_SP,    unextSP_offset, parmBlk);            \/\/ trim stack back to unextended size\n+    \/\/ restore work registers\n+    __ z_lmg(Z_R10, Z_R13, regsave_offset, parmBlk);       \/\/ make some regs available as work registers\n+\n+    __ z_lgf(msglen, msglen_offset,  parmBlk);             \/\/ Restore msglen, only low order FW is valid\n+#ifdef ASSERT\n+    {\n+      Label skip2last, skip2done;\n+      \/\/ Z_RET (aka Z_R2) can be used as scratch as well. It will be set from msglen before return.\n+      __ z_lgr(Z_RET, Z_SP);                                 \/\/ save extended SP\n+      __ z_lg(Z_SP,    unextSP_offset, parmBlk);             \/\/ trim stack back to unextended size\n+      __ z_sgrk(Z_R1, Z_SP, Z_RET);\n+\n+      __ z_cghi(Z_R1, 256);\n+      __ z_brl(skip2last);\n+      __ z_xc(0, 255, Z_RET, 0, Z_RET);\n+      __ z_aghi(Z_RET, 256);\n+      __ z_aghi(Z_R1, -256);\n+\n+      __ z_cghi(Z_R1, 256);\n+      __ z_brl(skip2last);\n+      __ z_xc(0, 255, Z_RET, 0, Z_RET);\n+      __ z_aghi(Z_RET, 256);\n+      __ z_aghi(Z_R1, -256);\n+\n+      __ z_cghi(Z_R1, 256);\n+      __ z_brl(skip2last);\n+      __ z_xc(0, 255, Z_RET, 0, Z_RET);\n+      __ z_aghi(Z_RET, 256);\n+      __ z_aghi(Z_R1, -256);\n+\n+      __ bind(skip2last);\n+      __ z_lgr(Z_R0, Z_RET);\n+      __ z_aghik(Z_RET, Z_R1, -1);  \/\/ decrement for exrl\n+      __ z_brl(skip2done);\n+      __ z_lgr(parmBlk, Z_R0);      \/\/ parmBlk == Z_R1, used in eraser template\n+      __ z_exrl(Z_RET, eraser);\n+\n+      __ bind(skip2done);\n+    }\n+#else\n+    __ z_lg(Z_SP,    unextSP_offset, parmBlk);             \/\/ trim stack back to unextended size\n+#endif\n@@ -2093,1 +2201,2 @@\n-  void generate_counterMode_push_parmBlk(Register parmBlk, Register msglen, Register fCode, Register key, bool is_decipher) {\n+  int generate_counterMode_push_parmBlk(Register parmBlk, Register msglen, Register fCode, Register key, bool is_decipher) {\n+    int       resize_len = 0;\n@@ -2111,1 +2220,1 @@\n-      generate_counterMode_push_Block(VM_Version::Cipher::_AES128_dataBlk,\n+      resize_len = generate_counterMode_push_Block(VM_Version::Cipher::_AES128_dataBlk,\n@@ -2122,1 +2231,1 @@\n-      generate_counterMode_push_Block(VM_Version::Cipher::_AES192_dataBlk,\n+      resize_len = generate_counterMode_push_Block(VM_Version::Cipher::_AES192_dataBlk,\n@@ -2133,1 +2242,1 @@\n-      generate_counterMode_push_Block(VM_Version::Cipher::_AES256_dataBlk,\n+      resize_len = generate_counterMode_push_Block(VM_Version::Cipher::_AES256_dataBlk,\n@@ -2141,0 +2250,1 @@\n+    return resize_len;\n@@ -2153,29 +2263,0 @@\n-  \/\/ Resize current stack frame to make room for some register data which needs\n-  \/\/ to be spilled temporarily. All registers in the range [from..to] are spilled\n-  \/\/ automatically. The actual length of the allocated aux block is returned.\n-  \/\/ The extra spill space (if requested) is located at\n-  \/\/   [Z_SP+stackSpace-spillSpace, Z_SP+stackSpace)\n-  \/\/ Kills Z__R0 (contains fp afterwards) and Z_R1 (contains old SP afterwards).\n-  \/\/ All space in the range [SP..SP+regSpace) is reserved.\n-  \/\/ As always (here): 0(SP) - stack linkage, 8(SP) - SP before resize for easy pop.\n-  int generate_push_aux_block(Register from, Register to, unsigned int spillSpace) {\n-    int n_regs     = to->encoding() - from->encoding() + 1;\n-    int linkSpace  = 2*wordSize;\n-    int regSpace   = n_regs*wordSize;\n-    int stackSpace = roundup(linkSpace + regSpace + spillSpace, AES_parmBlk_align);\n-    BLOCK_COMMENT(err_msg(\"push aux_block (%d bytes) counterMode_AESCrypt {\", stackSpace));\n-    __ z_lgr(Z_R1, Z_SP);\n-    __ resize_frame(-stackSpace, Z_R0, true);\n-    __ z_stg(Z_R1, 8, Z_SP);\n-    __ z_stmg(from, to, linkSpace, Z_SP);\n-    BLOCK_COMMENT(err_msg(\"} push aux_block (%d bytes) counterMode_AESCrypt\", stackSpace));\n-    return stackSpace;\n-  }\n-  \/\/ Reverts everything done by generate_push_aux_block().\n-  void generate_pop_aux_block(Register from, Register to) {\n-    BLOCK_COMMENT(\"pop aux_block counterMode_AESCrypt {\");\n-    __ z_lmg(from, to, 16, Z_SP);\n-    __ z_lg(Z_SP, 8, Z_SP);\n-    BLOCK_COMMENT(\"} pop aux_block counterMode_AESCrypt\");\n-  }\n-\n@@ -2186,0 +2267,17 @@\n+    \/\/ On entry:\n+    \/\/ if there was a previous call to update(), and this previous call did not fully use\n+    \/\/ the current encrypted counter, that counter is available at arg6_Offset(Z_SP).\n+    \/\/ The index of the first unused bayte in the encrypted counter is available at arg7_Offset(Z_SP).\n+    \/\/ The index is in the range [1..AES_ctrVal_len] ([1..16]), where index == 16 indicates a fully\n+    \/\/ used previous encrypted counter.\n+    \/\/ The unencrypted counter has already been incremented and is ready to be used for the next\n+    \/\/ data block, after the unused bytes from the previous call have been consumed.\n+    \/\/ The unencrypted counter follows the \"increment-after use\" principle.\n+\n+    \/\/ On exit:\n+    \/\/ The index of the first unused byte of the encrypted counter is written back to arg7_Offset(Z_SP).\n+    \/\/ A value of AES_ctrVal_len (16) indicates there is no leftover byte.\n+    \/\/ If there is at least one leftover byte (1 <= index < AES_ctrVal_len), the encrypted counter value\n+    \/\/ is written back to arg6_Offset(Z_SP). If there is no leftover, nothing is written back.\n+    \/\/ The unencrypted counter value is written back after having been incremented.\n+\n@@ -2194,0 +2292,5 @@\n+               \/\/ encCtr   = Z_ARG6  - encrypted counter (byte array),\n+               \/\/                      address passed on stack at _z_abi(remaining_cargs) + 0 * WordSize\n+               \/\/ cvIndex  = Z_ARG7  - # used (consumed) bytes of encrypted counter,\n+               \/\/                      passed on stack at _z_abi(remaining_cargs) + 1 * WordSize\n+               \/\/                      Caution:4-byte value, right-justified in 8-byte stack word\n@@ -2197,1 +2300,1 @@\n-    const Register src     = Z_ARG1; \/\/ is Z_R2\n+    const Register src     = Z_ARG1; \/\/ is Z_R2, forms even\/odd pair with srclen\n@@ -2203,1 +2306,2 @@\n-    Label CryptoLoop, CryptoLoop_doit, CryptoLoop_end, CryptoLoop_setupAndDoLast, CryptoLoop_ctrVal_inc, allDone, Exit;\n+    Label CryptoLoop, CryptoLoop_doit, CryptoLoop_end, CryptoLoop_setupAndDoLast, CryptoLoop_ctrVal_inc;\n+    Label allDone, allDone_noInc, popAndExit, Exit;\n@@ -2205,11 +2309,3 @@\n-    \/\/ Check if there is a leftover, partially used encrypted counter from last invocation.\n-    \/\/ If so, use those leftover counter bytes first before starting the \"normal\" encryption.\n-    {\n-      Register cvIndex   = Z_R10;  \/\/ # unused bytes of last encrypted counter value\n-      Register cvUnused  = Z_R11;  \/\/ # unused bytes of last encrypted counter value\n-      Register encCtr    = Z_R12;  \/\/ encrypted counter value, points to first ununsed byte.\n-      Label no_preLoop, preLoop_end;\n-\n-      \/\/ Before pushing an aux block, check if it's necessary at all (saves some cycles).\n-      __ z_lt(Z_R0, _z_abi(remaining_cargs) + 8 + 4, Z_R0, Z_SP); \/\/ arg7: # unused bytes in encCTR.\n-      __ z_brnp(no_preLoop);                                      \/\/ no unused bytes, nothing special to do.\n+    int    arg6_Offset = _z_abi(remaining_cargs) + 0 * HeapWordSize;\n+    int    arg7_Offset = _z_abi(remaining_cargs) + 1 * HeapWordSize; \/\/ stack slot holds ptr to int value\n+    int   oldSP_Offset = 0;\n@@ -2217,3 +2313,3 @@\n-      int   oldSP_Offset  = generate_push_aux_block(Z_R10, Z_R12, 16);\n-      int   arg6_Offset   = oldSP_Offset + _z_abi(remaining_cargs);\n-      int   arg7_Offset   = oldSP_Offset + _z_abi(remaining_cargs) + 8;\n+    \/\/ Is there anything to do at all? Protect against negative len as well.\n+    __ z_ltr(msglen, msglen);\n+    __ z_brnh(Exit);\n@@ -2221,5 +2317,4 @@\n-      __ z_ltgf(cvUnused, arg7_Offset+4, Z_R0, Z_SP); \/\/ arg7: # unused bytes in encCTR. (16-arg7) is index of first unused byte.\n-      __ z_brnp(preLoop_end);                  \/\/ \"not positive\" means no unused bytes left\n-      __ z_aghik(cvIndex, cvUnused, -16);      \/\/ calculate index of first unused byte. AES_ctrVal_len undefined at this point.\n-      __ z_brnl(preLoop_end);                  \/\/ NotLow(=NotNegative): unused bytes >= 16? How that?\n-      __ z_lcgr(cvIndex, cvIndex);\n+    \/\/ Expand stack, load parm block address into parmBlk (== Z_R1), copy crypto key to parm block.\n+    oldSP_Offset = generate_counterMode_push_parmBlk(parmBlk, msglen, fCode, key, is_decipher);\n+    arg6_Offset += oldSP_Offset;\n+    arg7_Offset += oldSP_Offset;\n@@ -2227,2 +2322,2 @@\n-      __ z_lg(encCtr, arg6_Offset, Z_SP);      \/\/ arg6: encrypted counter byte array.\n-      __ z_agr(encCtr, cvIndex);               \/\/ first unused byte of encrypted ctr. Used in ctrXOR.\n+    \/\/ Check if there is a leftover, partially used encrypted counter from last invocation.\n+    \/\/ If so, use those leftover counter bytes first before starting the \"normal\" encryption.\n@@ -2230,2 +2325,9 @@\n-      __ z_cr(cvUnused, msglen);               \/\/ check if msg is long enough\n-      __ z_locr(cvUnused, msglen, Assembler::bcondHigh); \/\/ take the shorter length\n+    \/\/ We do not have access to the encrypted counter value. It is generated and used only\n+    \/\/ internally within the previous kmctr instruction. But, at the end of call to this stub,\n+    \/\/ the last encrypted couner is extracted by ciphering a 0x00 byte stream. The result is\n+    \/\/ stored at the arg6 location for use with the subsequent call.\n+    \/\/\n+    \/\/ The #used bytes of the encrypted counter (from a previous call) is provided via arg7.\n+    \/\/ It is used as index into the encrypted counter to access the first byte availabla for ciphering.\n+    \/\/ To cipher the input text, we move the number of remaining bytes in the encrypted counter from\n+    \/\/ input to output. Then we simply XOR the output bytes with the associated encrypted counter bytes.\n@@ -2233,2 +2335,2 @@\n-      __ z_aghi(cvUnused, -1);                 \/\/ decrement # unused bytes by 1 for exrl instruction\n-      __ z_brl(preLoop_end);                   \/\/ negative result means nothing to do (msglen is zero)\n+    Register cvIxAddr  = Z_R10;                  \/\/ Address of index into encCtr. Preserved for use @CryptoLoop_end.\n+    __ z_lg(cvIxAddr, arg7_Offset, Z_SP);        \/\/ arg7: addr of field encCTR_index.\n@@ -2236,0 +2338,27 @@\n+    {\n+      Register cvUnused  = Z_R11;                \/\/ # unused bytes of encrypted counter value (= 16 - cvIndex)\n+      Register encCtr    = Z_R12;                \/\/ encrypted counter value, points to first ununsed byte.\n+      Register cvIndex   = Z_R13;                \/\/ # index of first unused byte of encrypted counter value\n+      Label    preLoop_end;\n+\n+      \/\/ preLoop is necessary only if there is a partially used encrypted counter (encCtr).\n+      \/\/ Partially used means cvIndex is in [1, dataBlk_len-1].\n+      \/\/ cvIndex == 0:           encCtr is set up but not used at all. Should not occur.\n+      \/\/ cvIndex == dataBlk_len: encCtr is exhausted, all bytes used.\n+      \/\/ Using unsigned compare protects against cases where (cvIndex < 0).\n+      __ z_clfhsi(0, cvIxAddr, AES_ctrVal_len);  \/\/ check #used bytes in encCtr against ctr len.\n+      __ z_brnl(preLoop_end);                    \/\/ if encCtr is fully used, skip to normal processing.\n+      __ z_ltgf(cvIndex, 0, Z_R0, cvIxAddr);     \/\/ # used bytes in encCTR.\n+      __ z_brz(preLoop_end);                     \/\/ if encCtr has no used bytes, skip to normal processing.\n+\n+      __ z_lg(encCtr, arg6_Offset, Z_SP);        \/\/ encrypted counter from last call to update()\n+      __ z_agr(encCtr, cvIndex);                 \/\/ now points to first unused byte\n+\n+      __ add2reg(cvUnused, -AES_ctrVal_len, cvIndex); \/\/ calculate #unused bytes in encCtr.\n+      __ z_lcgr(cvUnused, cvUnused);             \/\/ previous checks ensure cvUnused in range [1, dataBlk_len-1]\n+\n+      __ z_lgf(msglen, msglen_offset, parmBlk);  \/\/ Restore msglen (jint value)\n+      __ z_cr(cvUnused, msglen);                 \/\/ check if msg can consume all unused encCtr bytes\n+      __ z_locr(cvUnused, msglen, Assembler::bcondHigh); \/\/ take the shorter length\n+      __ z_aghi(cvUnused, -1);                   \/\/ decrement # unused bytes by 1 for exrl instruction\n+                                                 \/\/ preceding checks ensure cvUnused in range [1, dataBlk_len-1]\n@@ -2239,1 +2368,5 @@\n-      __ add2reg(cvUnused, 1, cvUnused);\n+      __ z_aghi(cvUnused, 1);                    \/\/ revert decrement from above\n+      __ z_agr(cvIndex, cvUnused);               \/\/ update index into encCtr (first unused byte)\n+      __ z_st(cvIndex, 0, cvIxAddr);             \/\/ write back arg7, cvIxAddr is still valid\n+\n+      \/\/ update pointers and counters to prepare for main loop\n@@ -2242,15 +2375,4 @@\n-      __ z_sr(msglen, cvUnused);\n-      __ z_brnz(preLoop_end);                  \/\/ there is still work to do\n-\n-      \/\/ Remaining msglen is zero, i.e. all msg bytes were processed in preLoop.\n-      \/\/ Take an early exit.\n-      generate_pop_aux_block(Z_R10, Z_R12);\n-      __ z_bru(Exit);\n-\n-      \/\/-------------------------------------------\n-      \/\/---<  execution templates for preLoop  >---\n-      \/\/-------------------------------------------\n-      __ bind(fromMover);\n-      __ z_mvc(0, 0, to, 0, from);         \/\/ Template instruction to move input data to dst.\n-      __ bind(ctrXOR);\n-      __ z_xc(0,  0, to, 0, encCtr);       \/\/ Template instruction to XOR input data (now in to) with encrypted counter.\n+      __ z_sr(msglen, cvUnused);                 \/\/ #bytes not yet processed\n+      __ z_sty(msglen, msglen_red_offset, parmBlk); \/\/ save for calculations in main loop\n+      __ z_srak(Z_R0, msglen, exact_log2(AES_ctrVal_len));\/\/ # full cipher blocks that can be formed from input text.\n+      __ z_sty(Z_R0, rem_msgblk_offset, parmBlk);\n@@ -2258,2 +2380,3 @@\n-      __ bind(preLoop_end);\n-      generate_pop_aux_block(Z_R10, Z_R12);\n+      \/\/ check remaining msglen. If zero, all msg bytes were processed in preLoop.\n+      __ z_ltr(msglen, msglen);\n+      __ z_brnh(popAndExit);\n@@ -2261,1 +2384,1 @@\n-      __ bind(no_preLoop);\n+      __ bind(preLoop_end);\n@@ -2264,2 +2387,0 @@\n-    \/\/ Expand stack, load parm block address into parmBlk (== Z_R1), copy crypto key to parm block.\n-    generate_counterMode_push_parmBlk(parmBlk, msglen, fCode, key, is_decipher);\n@@ -2276,2 +2397,2 @@\n-      __ z_asi(remmsg_len_offset, parmBlk, -AES_ctrVec_len);  \/\/ decrement #remaining blocks (16 bytes each). Range: [+127..-128]\n-      __ z_brl(CryptoLoop_setupAndDoLast);                    \/\/ Handling the last iteration out-of-line\n+      __ z_asi(rem_msgblk_offset, parmBlk, -AES_ctrVec_len);  \/\/ decrement #remaining blocks (16 bytes each). Range: [+127..-128]\n+      __ z_brl(CryptoLoop_setupAndDoLast);                    \/\/ Handling the last iteration (using less than max #blocks) out-of-line\n@@ -2282,1 +2403,1 @@\n-      __ z_lt(srclen, remmsg_len_offset, Z_R0, parmBlk);      \/\/ check if this was the last iteration\n+      __ z_lt(srclen, rem_msgblk_offset, Z_R0, parmBlk);      \/\/ check if this was the last iteration\n@@ -2286,0 +2407,1 @@\n+                                                              \/\/  > 0: this is the fallthru case, need another iteration\n@@ -2293,5 +2415,11 @@\n-    \/\/ except for the last few [0..dataBlk_len) bytes. To encrypt these few bytes\n-    \/\/ we need to form an extra src and dst data block of dataBlk_len each. This\n-    \/\/ is because we can only process full blocks but we must not read or write\n-    \/\/ beyond the boundaries of the argument arrays. Here is what we do:\n-    \/\/  - The src data block is filled with the remaining \"from\" bytes, padded with 0x00's.\n+    \/\/ except for the last few [0..dataBlk_len) bytes. In addition, we know that\n+    \/\/ there are no more unused bytes in the previously generated encrypted counter.\n+    \/\/ The (unencrypted) counter, however, is ready to use (it was incremented before).\n+\n+    \/\/ To encrypt the few remaining bytes, we need to form an extra src and dst\n+    \/\/ data block of dataBlk_len each. This is because we can only process full\n+    \/\/ blocks but we must not read or write beyond the boundaries of the argument\n+    \/\/ arrays. Here is what we do:\n+    \/\/  - The ctrVector has at least one unused element. This is ensured by CryptoLoop code.\n+    \/\/  - The (first) unused element is pointed at by the counter register.\n+    \/\/  - The src data block is filled with the remaining \"from\" bytes, remainder of block undefined.\n@@ -2301,29 +2429,35 @@\n-    \/\/  - The counter value to be used is is pointed at by the counter register.\n-    \/\/  - Fortunately, the crypto instruction (kmctr) updates all related addresses such that we\n-    \/\/    know where to continue with \"from\" and \"to\" and which counter value to use next.\n-\n-    \/\/ Use speaking alias for temp register\n-    Register dataBlk = counter;\n-    __ z_stg(counter, -24, parmBlk);                      \/\/ spill address of counter array\n-    __ add2reg(dataBlk, -(AES_parmBlk_addspace + AES_dataBlk_space), parmBlk);\n-\n-    __ z_lgf(srclen, msglen_offset, parmBlk);             \/\/ full plaintext\/ciphertext len.\n-    __ z_nilf(srclen, AES_ctrVal_len - 1);                \/\/ those rightmost bits indicate the unprocessed #bytes\n-    __ z_braz(allDone);                                   \/\/ no unprocessed bytes? Then we are done.\n-\n-    __ add2reg(srclen, -1);                               \/\/ decrement for exrl\n-    __ z_stg(srclen, localSpill_offset, parmBlk);         \/\/ save for later reuse\n-    __ z_xc(0, AES_ctrVal_len - 1, dataBlk, 0, dataBlk);  \/\/ clear src block (zero padding)\n-    __ z_exrl(srclen, srcMover);                          \/\/ copy src byte stream (remaining bytes)\n-    __ load_const_optimized(srclen, AES_ctrVal_len);      \/\/ kmctr processes only complete blocks\n-\n-    __ z_lgr(src, dataBlk);                               \/\/ tmp src address for kmctr\n-    __ z_lg(counter, -24, parmBlk);                       \/\/ restore counter\n-    __ z_stg(dst, -24, parmBlk);                          \/\/ save current dst\n-    __ add2reg(dst, AES_ctrVal_len, src);                 \/\/ tmp dst is right after tmp src\n-\n-    __ kmctr(dst, counter, src);   \/\/ Cipher the remaining bytes.\n-\n-    __ add2reg(dataBlk, -AES_ctrVal_len, dst);            \/\/ tmp dst address\n-    __ z_lg(dst, -24, parmBlk);                           \/\/ real dst address\n-    __ z_lg(srclen, localSpill_offset, parmBlk);          \/\/ reuse calc from above\n+    \/\/  - The counter value to be used is pointed at by the counter register.\n+    \/\/  - Fortunately, the crypto instruction (kmctr) has updated all related addresses such that\n+    \/\/    we know where to continue with \"from\" and \"to\" and which counter value to use next.\n+\n+    Register encCtr    = Z_R12;  \/\/ encrypted counter value, points to stub argument.\n+    Register tmpDst    = Z_R12;  \/\/ addr of temp destination (for last partial block encryption)\n+\n+    __ z_lgf(srclen, msglen_red_offset, parmBlk);          \/\/ plaintext\/ciphertext len after potential preLoop processing.\n+    __ z_nilf(srclen, AES_ctrVal_len - 1);                 \/\/ those rightmost bits indicate the unprocessed #bytes\n+    __ z_stg(srclen, localSpill_offset, parmBlk);          \/\/ save for later reuse\n+    __ z_mvhi(0, cvIxAddr, 16);                            \/\/ write back arg7 (default 16 in case of allDone).\n+    __ z_braz(allDone_noInc);                              \/\/ no unprocessed bytes? Then we are done.\n+                                                           \/\/ This also means the last block of data processed was\n+                                                           \/\/ a full-sized block (AES_ctrVal_len bytes) which results\n+                                                           \/\/ in no leftover encrypted counter bytes.\n+    __ z_st(srclen, 0, cvIxAddr);                          \/\/ This will be the index of the first unused byte in the encrypted counter.\n+    __ z_stg(counter, counter_offset, parmBlk);            \/\/ save counter location for easy later restore\n+\n+    \/\/ calculate address (on stack) for final dst and src blocks.\n+    __ add2reg(tmpDst, AES_dataBlk_offset, parmBlk);       \/\/ tmp dst (on stack) is right before tmp src\n+\n+    \/\/ We have a residue of [1..15] unprocessed bytes, srclen holds the exact number.\n+    \/\/ Residue == 0 was checked just above, residue == AES_ctrVal_len would be another\n+    \/\/ full-sized block and would have been handled by CryptoLoop.\n+\n+    __ add2reg(srclen, -1);                                \/\/ decrement for exrl\n+    __ z_exrl(srclen, srcMover);                           \/\/ copy remaining bytes of src byte stream\n+    __ load_const_optimized(srclen, AES_ctrVal_len);       \/\/ kmctr processes only complete blocks\n+    __ add2reg(src, AES_ctrVal_len, tmpDst);               \/\/ tmp dst is right before tmp src\n+\n+    __ kmctr(tmpDst, counter, src);                        \/\/ Cipher the remaining bytes.\n+\n+    __ add2reg(tmpDst, -AES_ctrVal_len, tmpDst);           \/\/ restore tmp dst address\n+    __ z_lg(srclen, localSpill_offset, parmBlk);           \/\/ residual len, saved above\n+    __ add2reg(srclen, -1);                                \/\/ decrement for exrl\n@@ -2332,0 +2466,10 @@\n+    \/\/ Write back new encrypted counter\n+    __ add2reg(src, AES_dataBlk_offset, parmBlk);\n+    __ clear_mem(Address(src, RegisterOrConstant((intptr_t)0)), AES_ctrVal_len);\n+    __ load_const_optimized(srclen, AES_ctrVal_len);       \/\/ kmctr processes only complete blocks\n+    __ z_lg(encCtr, arg6_Offset, Z_SP);                    \/\/ write encrypted counter to arg6\n+    __ z_lg(counter, counter_offset, parmBlk);             \/\/ restore counter\n+    __ kmctr(encCtr, counter, src);\n+\n+    \/\/ The last used element of the counter vector contains the latest counter value that was used.\n+    \/\/ As described above, the counter value on exit must be the one to be used next.\n@@ -2333,4 +2477,7 @@\n-    __ z_llgf(srclen, msglen_offset, parmBlk);            \/\/ increment unencrypted ctr by #blocks processed.\n-    __ z_srag(srclen, srclen, exact_log2(AES_ctrVal_len));\n-    __ z_ag(srclen, 8, Z_R0, ctr);\n-    __ z_stg(srclen, 8, Z_R0, ctr);\n+    __ z_lg(counter, counter_offset, parmBlk);             \/\/ restore counter\n+    generate_increment128(counter, 0, 1, Z_R0);\n+\n+    __ bind(allDone_noInc);\n+    __ z_mvc(0, AES_ctrVal_len, ctr, 0, counter);\n+\n+    __ bind(popAndExit);\n@@ -2348,1 +2495,1 @@\n-      __ z_lgf(srclen, remmsg_len_offset, parmBlk);           \/\/ remaining #blocks in memory is < 0\n+      __ z_lgf(srclen, rem_msgblk_offset, parmBlk);           \/\/ remaining #blocks in memory is < 0\n@@ -2352,1 +2499,2 @@\n-      __ z_bru(CryptoLoop_end);\n+      __ z_bru(CryptoLoop_end);                               \/\/ There is at least one unused counter vector element.\n+                                                              \/\/ no need to increment.\n@@ -2358,0 +2506,8 @@\n+    \/\/-------------------------------------------\n+    \/\/---<  execution templates for preLoop  >---\n+    \/\/-------------------------------------------\n+    __ bind(fromMover);\n+    __ z_mvc(0, 0, to, 0, from);               \/\/ Template instruction to move input data to dst.\n+    __ bind(ctrXOR);\n+    __ z_xc(0,  0, to, 0, encCtr);             \/\/ Template instruction to XOR input data (now in to) with encrypted counter.\n+\n@@ -2364,1 +2520,1 @@\n-    __ z_mvc(0, 0, dst, 0, dataBlk);     \/\/ Template instruction to move encrypted reminder from stack to dst.\n+    __ z_mvc(0, 0, dst, 0, tmpDst);      \/\/ Template instruction to move encrypted reminder from stack to dst.\n@@ -2366,1 +2522,1 @@\n-    __ z_mvc(0, 0, dataBlk, 0, src);     \/\/ Template instruction to move reminder of source byte stream to stack.\n+    __ z_mvc(AES_ctrVal_len, 0, tmpDst, 0, src); \/\/ Template instruction to move reminder of source byte stream to stack.\n@@ -2371,1 +2527,0 @@\n-  \/\/\n@@ -2385,0 +2540,2 @@\n+    __ bind(AESCTR_short);\n+\n@@ -2387,1 +2544,0 @@\n-    __ bind(AESCTR_short);\n","filename":"src\/hotspot\/cpu\/s390\/stubGenerator_s390.cpp","additions":342,"deletions":186,"binary":false,"changes":528,"status":"modified"},{"patch":"@@ -0,0 +1,257 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023 SAP SE. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/**\n+ * @test\n+ * @key randomness\n+ * @bug 8299817\n+ * @summary AES-CTR cipher failure with multiple short (< 16 bytes) update calls.\n+ * @library \/test\/lib \/\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ *\n+ * @run main\/othervm -Xbatch\n+ * -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ * compiler.codegen.aes.Test8299817\n+ *\/\n+\n+package compiler.codegen.aes;\n+\n+import java.util.Arrays;\n+import java.util.Random;\n+import javax.crypto.Cipher;\n+import javax.crypto.spec.IvParameterSpec;\n+import javax.crypto.spec.SecretKeySpec;\n+\n+import compiler.whitebox.CompilerWhiteBoxTest;\n+import jdk.test.whitebox.code.Compiler;\n+import jdk.test.lib.Utils;\n+import jtreg.SkippedException;\n+\n+public class Test8299817 {\n+    private static final String ALGO = \"AES\/CTR\/NoPadding\";\n+    private static final int LOOPS        = 20000;\n+    private static final int WARMUP_LOOPS = 10000;\n+    private static final int LEN_INC   = 5;\n+    private static final int LEN_STEPS = 13;\n+    private static final int LEN_MAX   = LEN_INC*LEN_STEPS;\n+    private static final int SEG_INC   = 3;\n+    private static final int SEG_MAX   = 11;\n+    private static final int SHOW_ARRAY_LIMIT = 72;\n+    private static final boolean DEBUG_MODE = false;\n+\n+    public static void main(String[] args) throws Exception {\n+        if (!DEBUG_MODE) {\n+            if (!Compiler.isIntrinsicAvailable(CompilerWhiteBoxTest.COMP_LEVEL_FULL_OPTIMIZATION,\n+                                               \"com.sun.crypto.provider.CounterMode\", \"implCrypt\",\n+                                                byte[].class, int.class, int.class, byte[].class, int.class)\n+               ) {\n+                throw new SkippedException(\"AES-CTR intrinsic is not available\");\n+            }\n+        }\n+\n+        Random random = Utils.getRandomInstance();\n+\n+        \/\/ Create secret key\n+        byte[] keyBytes = new byte[32];\n+        random.nextBytes(keyBytes);\n+        SecretKeySpec key = new SecretKeySpec(keyBytes, \"AES\");\n+\n+        \/\/ Create initial counter\n+        byte[] ivBytes = new byte[16];\n+        random.nextBytes(ivBytes);\n+        if (DEBUG_MODE) {\n+            for (int i = 0; i < 16; i++) {\n+                ivBytes[i] = (byte)0;\n+            }\n+            ivBytes[15] = (byte)1;\n+        }\n+        IvParameterSpec iv = new IvParameterSpec(ivBytes);\n+\n+        \/\/ Create cipher objects and initialize\n+        Cipher encryptCipher = Cipher.getInstance(ALGO);\n+        Cipher decryptCipher = Cipher.getInstance(ALGO);\n+\n+        encryptCipher.init(Cipher.ENCRYPT_MODE, key, iv);\n+        decryptCipher.init(Cipher.DECRYPT_MODE, key, iv);\n+\n+        \/\/ Create plaintext, ciphertext, and encrypted counter (reference copy)\n+        byte[] original           = new byte[LEN_MAX];\n+        byte[] original_encrypted = new byte[LEN_MAX];\n+        byte[] counter_encrypted  = new byte[LEN_MAX];\n+        \/\/ Retrieve the encrypted counter\n+        if (DEBUG_MODE) {\n+            for (int i = 0; i < LEN_MAX; i++) {\n+                original[i] = (byte)0;\n+            }\n+            encryptCipher.doFinal(original, 0, LEN_MAX, counter_encrypted);\n+        }\n+        \/\/ Create the encrypted message reference (no JIT, no intrinsic involved)\n+        if (DEBUG_MODE) {\n+            for (int i = 0; i < LEN_MAX; i++) {\n+                original[i] = (byte)i;\n+            }\n+            encryptCipher.doFinal(original, 0, LEN_MAX, original_encrypted);\n+        }\n+        if (DEBUG_MODE) {\n+            showArray(original,           original.length,           \"original:           \");\n+            showArray(original_encrypted, original_encrypted.length, \"original_encrypted: \");\n+            showArray(counter_encrypted,  counter_encrypted.length,  \"counter_encrypted:  \");\n+        }\n+\n+        \/\/ Warmup to have everything compiled\n+        System.out.println(\"Warming up, \" + WARMUP_LOOPS + \" iterations...\");\n+        byte[] work_encrypted = new byte[LEN_MAX];\n+        byte[] work_decrypted = new byte[LEN_MAX];\n+        byte[] varlen         = new byte[LEN_MAX*2];\n+\n+        for (int i = 0; i < WARMUP_LOOPS; i++) {\n+            boolean failed = false;\n+            if (!DEBUG_MODE) {\n+                random.nextBytes(original);\n+            }\n+            encryptCipher.doFinal(original, 0, LEN_MAX, work_encrypted);\n+\n+            random.nextBytes(varlen);\n+            for (int j = 0; j < LEN_MAX; j++) {\n+                int len1 = (varlen[2*j] & 0x0f) + 1;\n+                decryptCipher.update(work_encrypted,   0, len1,         work_decrypted,  0);\n+                for (int k = 0; k < len1; k++) {\n+                    if (original[k] != work_decrypted[k]) {\n+                        if (!failed) {\n+                            failed = true;\n+                            System.out.println(\"-------------------\");\n+                        }\n+                        System.out.println(\"Decrypt failure (warmup, update): LEN(\" +\n+                                           LEN_MAX + \"), iteration (\" + i + \"), k = \" + k);\n+                    }\n+                }\n+                int len2 = (varlen[2*j+1] & 0x0f) + 1;\n+                decryptCipher.update(work_encrypted, len1, len2,         work_decrypted, len1);\n+                for (int k = len1; k < len1+len2; k++) {\n+                    if (original[k] != work_decrypted[k]) {\n+                        if (!failed) {\n+                            failed = true;\n+                            System.out.println(\"-------------------\");\n+                        }\n+                        System.out.println(\"Decrypt failure (warmup, update): LEN(\" +\n+                                           LEN_MAX + \"), iteration (\" + i + \"), k = \" + k);\n+                    }\n+                }\n+                decryptCipher.doFinal(work_encrypted, len1+len2, LEN_MAX-len1-len2, work_decrypted, len1+len2);\n+                for (int k = len1+len2; k < LEN_MAX; k++) {\n+                    if (original[k] != work_decrypted[k]) {\n+                        if (!failed) {\n+                            failed = true;\n+                            System.out.println(\"-------------------\");\n+                        }\n+                        System.out.println(\"Decrypt failure (warmup, doFinal): LEN(\" +\n+                                           LEN_MAX + \"), iteration (\" + i + \"), k = \" + k);\n+                    }\n+                }\n+            }\n+            if (!compareArrays(work_decrypted, original, false)) {\n+                System.out.println(\"Warmup encrypt\/decrypt failure during iteration \" + i + \" of LEN \" + LEN_MAX);\n+                compareArrays(work_decrypted, original, true);\n+                showArray(work_encrypted,    work_encrypted.length,    \"encrypted:\");\n+                showArray(counter_encrypted, counter_encrypted.length, \"ctr_enc:  \");\n+                if (!DEBUG_MODE) {\n+                    System.exit(1);\n+                }\n+            }\n+        }\n+\n+        System.out.println(\"Testing, \" + LOOPS + \" iterations...\");\n+        for (int LEN = 1; LEN < LEN_MAX; LEN += LEN_INC) {\n+            work_encrypted = new byte[LEN];\n+            work_decrypted = new byte[LEN];\n+\n+            for (int i = 0; i < LOOPS; i++) {\n+                boolean failed = false;\n+                random.nextBytes(original);\n+                encryptCipher.doFinal(original, 0, LEN, work_encrypted);\n+\n+                int ix = 0;\n+                for (int SEG = 0; (SEG < SEG_MAX) && (ix + SEG_INC < LEN); SEG++) {\n+                    decryptCipher.update(work_encrypted, ix, SEG_INC, work_decrypted, ix);\n+                    for (int k = ix; k < ix + SEG_INC; k++) {\n+                        if (original[k] != work_decrypted[k]) {\n+                            if (!failed) {\n+                                failed = true;\n+                                System.out.println(\"-------------------\");\n+                            }\n+                            System.out.println(\"Decrypt failure (update): LEN(\" + LEN + \"), iteration \" +\n+                                               i + \", SEG(\" + SEG + \"), SEG_INC(\" + SEG_INC + \"), k = \" + k);\n+                        }\n+                    }\n+                    ix += SEG_INC;\n+                }\n+\n+                decryptCipher.doFinal(work_encrypted, ix, LEN - ix, work_decrypted, ix);\n+                if (!compareArrays(work_decrypted, original, false)) {\n+                    if (!failed) {\n+                        failed = true;\n+                        System.out.println(\"-------------------\");\n+                    }\n+                    System.out.println(\"While decrypting the remaining \" + (LEN - ix) +\n+                                       \"(\" + LEN + \") bytes of CT, iteration \" + i);\n+                    System.out.println(\"Decrypt failure (doFinal): LEN(\" + LEN +\n+                                       \"), SEG_INC(\" + SEG_INC + \"), SEG_MAX(\" + SEG_MAX + \")\");\n+                    showArray(work_encrypted, work_encrypted.length, \"encrypted:\");\n+                    compareArrays(work_decrypted, original, true);\n+                    if (!DEBUG_MODE) {\n+                        System.exit(1);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    static void showArray(byte b[], int len, String name) {\n+        System.out.format(\"%s [%d]: \", name, b.length);\n+        for (int i = 0; i < Math.min(len, SHOW_ARRAY_LIMIT); i++) {\n+            System.out.format(\"%02x \", b[i] & 0xff);\n+        }\n+        System.out.println();\n+    }\n+\n+    static boolean compareArrays(byte b[], byte exp[], boolean print) {\n+        boolean equal = true;\n+        int len = (b.length <= exp.length) ? b.length : exp.length;\n+        for (int i = 0; i < len; i++) {\n+            equal &= b[i] == exp[i];\n+            if (!equal) {\n+                if (print) {\n+                    System.out.format(\"encrypt\/decrypt error at index %d: got %02x, expected %02x\\n\",\n+                                      i, b[i] & 0xff, exp[i] & 0xff);\n+                    showArray(b,   len, \"result:   \");\n+                    showArray(exp, len, \"expected: \");\n+                }\n+                return equal;\n+            }\n+        }\n+        return equal;\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/codegen\/aes\/Test8299817.java","additions":257,"deletions":0,"binary":false,"changes":257,"status":"added"}]}