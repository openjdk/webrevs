{"files":[{"patch":"@@ -2337,77 +2337,0 @@\n-void C2_MacroAssembler::compress_bits_v(Register dst, Register src, Register mask, bool is_long) {\n-  Assembler::SEW sew = is_long ? Assembler::e64 : Assembler::e32;\n-  \/\/ intrinsic is enabled when MaxVectorSize >= 16\n-  Assembler::LMUL lmul = is_long ? Assembler::m4 : Assembler::m2;\n-  long len = is_long ? 64 : 32;\n-\n-  \/\/ load the src data(in bits) to be compressed.\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_s_x(v0, src);\n-  \/\/ reset the src data(in bytes) to zero.\n-  mv(t0, len);\n-  vsetvli(x0, t0, Assembler::e8, lmul);\n-  vmv_v_i(v4, 0);\n-  \/\/ convert the src data from bits to bytes.\n-  vmerge_vim(v4, v4, 1); \/\/ v0 as the implicit mask register\n-  \/\/ reset the dst data(in bytes) to zero.\n-  vmv_v_i(v8, 0);\n-  \/\/ load the mask data(in bits).\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_s_x(v0, mask);\n-  \/\/ compress the src data(in bytes) to dst(in bytes).\n-  vsetvli(x0, t0, Assembler::e8, lmul);\n-  vcompress_vm(v8, v4, v0);\n-  \/\/ convert the dst data from bytes to bits.\n-  vmseq_vi(v0, v8, 1);\n-  \/\/ store result back.\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_x_s(dst, v0);\n-}\n-\n-void C2_MacroAssembler::compress_bits_i_v(Register dst, Register src, Register mask) {\n-  compress_bits_v(dst, src, mask, \/* is_long *\/ false);\n-}\n-\n-void C2_MacroAssembler::compress_bits_l_v(Register dst, Register src, Register mask) {\n-  compress_bits_v(dst, src, mask, \/* is_long *\/ true);\n-}\n-\n-void C2_MacroAssembler::expand_bits_v(Register dst, Register src, Register mask, bool is_long) {\n-  Assembler::SEW sew = is_long ? Assembler::e64 : Assembler::e32;\n-  \/\/ intrinsic is enabled when MaxVectorSize >= 16\n-  Assembler::LMUL lmul = is_long ? Assembler::m4 : Assembler::m2;\n-  long len = is_long ? 64 : 32;\n-\n-  \/\/ load the src data(in bits) to be expanded.\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_s_x(v0, src);\n-  \/\/ reset the src data(in bytes) to zero.\n-  mv(t0, len);\n-  vsetvli(x0, t0, Assembler::e8, lmul);\n-  vmv_v_i(v4, 0);\n-  \/\/ convert the src data from bits to bytes.\n-  vmerge_vim(v4, v4, 1); \/\/ v0 as implicit mask register\n-  \/\/ reset the dst data(in bytes) to zero.\n-  vmv_v_i(v12, 0);\n-  \/\/ load the mask data(in bits).\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_s_x(v0, mask);\n-  \/\/ expand the src data(in bytes) to dst(in bytes).\n-  vsetvli(x0, t0, Assembler::e8, lmul);\n-  viota_m(v8, v0);\n-  vrgather_vv(v12, v4, v8, VectorMask::v0_t); \/\/ v0 as implicit mask register\n-  \/\/ convert the dst data from bytes to bits.\n-  vmseq_vi(v0, v12, 1);\n-  \/\/ store result back.\n-  vsetivli(x0, 1, sew, Assembler::m1);\n-  vmv_x_s(dst, v0);\n-}\n-\n-void C2_MacroAssembler::expand_bits_i_v(Register dst, Register src, Register mask) {\n-  expand_bits_v(dst, src, mask, \/* is_long *\/ false);\n-}\n-\n-void C2_MacroAssembler::expand_bits_l_v(Register dst, Register src, Register mask) {\n-  expand_bits_v(dst, src, mask, \/* is_long *\/ true);\n-}\n-\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":0,"deletions":77,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -42,3 +42,0 @@\n-  void compress_bits_v(Register dst, Register src, Register mask, bool is_long);\n-  void expand_bits_v(Register dst, Register src, Register mask, bool is_long);\n-\n@@ -183,7 +180,0 @@\n-  \/\/ compress bits, i.e. j.l.Integer\/Long::compress.\n-  void compress_bits_i_v(Register dst, Register src, Register mask);\n-  void compress_bits_l_v(Register dst, Register src, Register mask);\n-  \/\/ expand bits, i.e. j.l.Integer\/Long::expand.\n-  void expand_bits_i_v(Register dst, Register src, Register mask);\n-  void expand_bits_l_v(Register dst, Register src, Register mask);\n-\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -945,20 +945,0 @@\n-\/\/ class for vector register v12\n-reg_class v12_reg(\n-    V12, V12_H, V12_J, V12_K\n-);\n-\n-\/\/ class for vector register v13\n-reg_class v13_reg(\n-    V13, V13_H, V13_J, V13_K\n-);\n-\n-\/\/ class for vector register v14\n-reg_class v14_reg(\n-    V14, V14_H, V14_J, V14_K\n-);\n-\n-\/\/ class for vector register v15\n-reg_class v15_reg(\n-    V15, V15_H, V15_J, V15_K\n-);\n-\n@@ -1913,3 +1893,0 @@\n-    case Op_ExpandBits:        \/\/ fall through\n-    case Op_CompressBits:      \/\/ fall through\n-      guarantee(UseRVV == (MaxVectorSize >= 16), \"UseRVV and MaxVectorSize not matched\");\n@@ -3566,40 +3543,0 @@\n-operand vReg_V12()\n-%{\n-  constraint(ALLOC_IN_RC(v12_reg));\n-  match(VecA);\n-  match(vReg);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vReg_V13()\n-%{\n-  constraint(ALLOC_IN_RC(v13_reg));\n-  match(VecA);\n-  match(vReg);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vReg_V14()\n-%{\n-  constraint(ALLOC_IN_RC(v14_reg));\n-  match(VecA);\n-  match(vReg);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n-operand vReg_V15()\n-%{\n-  constraint(ALLOC_IN_RC(v15_reg));\n-  match(VecA);\n-  match(vReg);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":0,"deletions":63,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -3846,110 +3846,0 @@\n-\/\/ CompressBits of Long & Integer\n-\n-instruct compressBitsI(iRegINoSp dst, iRegIorL2I src, iRegIorL2I mask, vRegMask_V0 v0,\n-                       vReg_V4 v4, vReg_V5 v5, vReg_V8 v8, vReg_V9 v9) %{\n-  match(Set dst (CompressBits src mask));\n-  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v8, TEMP v9);\n-  format %{ \"vsetivli x0, 1, e32, m1, tu, mu\\t#@compressBitsI\\n\\t\"\n-            \"vmv.s.x $v0, $src\\n\\t\"\n-            \"mv t0, 32\\n\\t\"\n-            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n-            \"vmv.v.i $v4, 0\\n\\t\"\n-            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n-            \"vmv.v.i $v8, 0\\n\\t\"\n-            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n-            \"vmv.s.x $v0, $mask\\n\\t\"\n-            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n-            \"vcompress.vm $v8, $v4, $v0\\n\\t\"\n-            \"vmseq.vi $v0, $v8, 1\\n\\t\"\n-            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n-            \"vmv.x.s $dst, $v0\\t#@compressBitsI\\n\\t\"\n-          %}\n-  ins_encode %{\n-    __ compress_bits_i_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct compressBitsL(iRegLNoSp dst, iRegL src, iRegL mask, vRegMask_V0 v0,\n-                       vReg_V4 v4, vReg_V5 v5, vReg_V6 v6, vReg_V7 v7,\n-                       vReg_V8 v8, vReg_V9 v9, vReg_V10 v10, vReg_V11 v11) %{\n-  match(Set dst (CompressBits src mask));\n-  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v6, TEMP v7, TEMP v8, TEMP v9, TEMP v10, TEMP v11);\n-  format %{ \"vsetivli x0, 1, e64, m1, tu, mu\\t#@compressBitsL\\n\\t\"\n-            \"vmv.s.x $v0, $src\\n\\t\"\n-            \"mv t0, 64\\n\\t\"\n-            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n-            \"vmv.v.i $v4, 0\\n\\t\"\n-            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n-            \"vmv.v.i $v8, 0\\n\\t\"\n-            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n-            \"vmv.s.x $v0, $mask\\n\\t\"\n-            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n-            \"vcompress.vm $v8, $v4, $v0\\n\\t\"\n-            \"vmseq.vi $v0, $v8, 1\\n\\t\"\n-            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n-            \"vmv.x.s $dst, $v0\\t#@compressBitsL\\n\\t\"\n-          %}\n-  ins_encode %{\n-    __ compress_bits_l_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ ExpandBits of Long & Integer\n-\n-instruct expandBitsI(iRegINoSp dst, iRegIorL2I src, iRegIorL2I mask, vRegMask_V0 v0,\n-                     vReg_V4 v4, vReg_V5 v5, vReg_V8 v8, vReg_V9 v9, vReg_V12 v12, vReg_V13 v13) %{\n-  match(Set dst (ExpandBits src mask));\n-  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v8, TEMP v9, TEMP v12, TEMP v13);\n-  format %{ \"vsetivli x0, 1, e32, m1, tu, mu\\t#@expandBitsI\\n\\t\"\n-            \"vmv.s.x $v0, $src\\n\\t\"\n-            \"mv t0, 32\\n\\t\"\n-            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n-            \"vmv.v.i $v4, 0\\n\\t\"\n-            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n-            \"vmv.v.i $v12, 0\\n\\t\"\n-            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n-            \"vmv.s.x $v0, $mask\\n\\t\"\n-            \"vsetvli x0, t0, e8, m2, tu, mu\\n\\t\"\n-            \"viota.m $v8, $v0\\n\\t\"\n-            \"vrgather.vv $v12, $v4, $v8, $v0.t\\n\\t\"\n-            \"vmseq.vi $v0, $v12, 1\\n\\t\"\n-            \"vsetivli x0, 1, e32, m1, tu, mu\\n\\t\"\n-            \"vmv.x.s $dst, $v0\\t#@expandBitsI\\n\\t\"\n-          %}\n-  ins_encode %{\n-    __ expand_bits_i_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct expandBitsL(iRegLNoSp dst, iRegL src, iRegL mask, vRegMask_V0 v0,\n-                      vReg_V4 v4, vReg_V5 v5, vReg_V6 v6, vReg_V7 v7,\n-                      vReg_V8 v8, vReg_V9 v9, vReg_V10 v10, vReg_V11 v11,\n-                      vReg_V12 v12, vReg_V13 v13, vReg_V14 v14, vReg_V15 v15) %{\n-  match(Set dst (ExpandBits src mask));\n-  effect(TEMP v0, TEMP v4, TEMP v5, TEMP v6, TEMP v7, TEMP v8, TEMP v9, TEMP v10, TEMP v11,\n-         TEMP v12, TEMP v13, TEMP v14, TEMP v15);\n-  format %{ \"vsetivli x0, 1, e64, m1, tu, mu\\t#@expandBitsL\\n\\t\"\n-            \"vmv.s.x $v0, $src\\n\\t\"\n-            \"mv t0, 64\\n\\t\"\n-            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n-            \"vmv.v.i $v4, 0\\n\\t\"\n-            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n-            \"vmv.v.i $v12, 0\\n\\t\"\n-            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n-            \"vmv.s.x $v0, $mask\\n\\t\"\n-            \"vsetvli x0, t0, e8, m4, tu, mu\\n\\t\"\n-            \"viota.m $v8, $v0\\n\\t\"\n-            \"vrgather.vv $v12, $v4, $v8, $v0.t\\n\\t\"\n-            \"vmseq.vi $v0, $v12, 1\\n\\t\"\n-            \"vsetivli x0, 1, e64, m1, tu, mu\\n\\t\"\n-            \"vmv.x.s $dst, $v0\\t#@expandBitsL\\n\\t\"\n-          %}\n-  ins_encode %{\n-    __ expand_bits_l_v(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":0,"deletions":110,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -33,2 +33,1 @@\n- *            (os.arch==\"aarch64\" & vm.cpu.features ~= \".*svebitperm.*\") |\n- *            (os.arch==\"riscv64\" & vm.cpu.features ~= \".*rvv.*\"))\n+ *            (os.arch==\"aarch64\" & vm.cpu.features ~= \".*svebitperm.*\"))\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/TestBitShuffleOpers.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"}]}