{"files":[{"patch":"@@ -40,41 +40,0 @@\n-#ifndef _LP64\n-float ConversionStub::float_zero = 0.0;\n-double ConversionStub::double_zero = 0.0;\n-\n-void ConversionStub::emit_code(LIR_Assembler* ce) {\n-  __ bind(_entry);\n-  assert(bytecode() == Bytecodes::_f2i || bytecode() == Bytecodes::_d2i, \"other conversions do not require stub\");\n-\n-\n-  if (input()->is_single_xmm()) {\n-    __ comiss(input()->as_xmm_float_reg(),\n-              ExternalAddress((address)&float_zero));\n-  } else if (input()->is_double_xmm()) {\n-    __ comisd(input()->as_xmm_double_reg(),\n-              ExternalAddress((address)&double_zero));\n-  } else {\n-    __ push(rax);\n-    __ ftst();\n-    __ fnstsw_ax();\n-    __ sahf();\n-    __ pop(rax);\n-  }\n-\n-  Label NaN, do_return;\n-  __ jccb(Assembler::parity, NaN);\n-  __ jccb(Assembler::below, do_return);\n-\n-  \/\/ input is > 0 -> return maxInt\n-  \/\/ result register already contains 0x80000000, so subtracting 1 gives 0x7fffffff\n-  __ decrement(result()->as_register());\n-  __ jmpb(do_return);\n-\n-  \/\/ input is NaN -> return 0\n-  __ bind(NaN);\n-  __ xorptr(result()->as_register(), result()->as_register());\n-\n-  __ bind(do_return);\n-  __ jmp(_continuation);\n-}\n-#endif \/\/ !_LP64\n-\n@@ -84,1 +43,0 @@\n-#ifdef _LP64\n@@ -87,9 +45,0 @@\n-#else\n-  const Register tmp1 = rcx;\n-  const Register tmp2 = rdx;\n-  __ push(tmp1);\n-  __ push(tmp2);\n-\n-  __ lea(tmp1, safepoint_pc);\n-  __ get_thread(tmp2);\n-  __ movptr(Address(tmp2, JavaThread::saved_exception_pc_offset()), tmp1);\n@@ -97,3 +46,0 @@\n-  __ pop(tmp2);\n-  __ pop(tmp1);\n-#endif \/* _LP64 *\/\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":0,"deletions":54,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  pd_nof_cpu_regs_frame_map = NOT_LP64(8) LP64_ONLY(16),           \/\/ number of registers used during code emission\n+  pd_nof_cpu_regs_frame_map = 16,                                  \/\/ number of registers used during code emission\n@@ -40,1 +40,0 @@\n-#ifdef _LP64\n@@ -42,3 +41,0 @@\n-#else\n-  #define UNALLOCATED 2    \/\/ rsp, rbp\n-#endif \/\/ LP64\n@@ -57,3 +53,3 @@\n-  pd_last_cpu_reg = NOT_LP64(5) LP64_ONLY(11),\n-  pd_first_byte_reg = NOT_LP64(2) LP64_ONLY(0),\n-  pd_last_byte_reg = NOT_LP64(5) LP64_ONLY(11),\n+  pd_last_cpu_reg = 11,\n+  pd_first_byte_reg = 0,\n+  pd_last_byte_reg = 11,\n","filename":"src\/hotspot\/cpu\/x86\/c1_Defs_x86.hpp","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-  VMReg r_2 = reg->second();\n@@ -44,4 +43,1 @@\n-    if (r_2->is_Register() && (type == T_LONG || type == T_DOUBLE)) {\n-      Register reg2 = r_2->as_Register();\n-#ifdef _LP64\n-      assert(reg2 == reg, \"must be same register\");\n+    if (type == T_LONG || type == T_DOUBLE) {\n@@ -49,3 +45,0 @@\n-#else\n-      opr = as_long_opr(reg2, reg);\n-#endif \/\/ _LP64\n@@ -114,2 +107,0 @@\n-#ifdef _LP64\n-\n@@ -140,1 +131,0 @@\n-#endif \/\/ _LP64\n@@ -160,1 +150,1 @@\n-  assert(nof_cpu_regs == LP64_ONLY(16) NOT_LP64(8), \"wrong number of CPU registers\");\n+  assert(nof_cpu_regs == 16, \"wrong number of CPU registers\");\n@@ -167,10 +157,4 @@\n-\n-#ifndef _LP64\n-  \/\/ The unallocatable registers are at the end\n-  map_register(6, rsp);\n-  map_register(7, rbp);\n-#else\n-  map_register( 6, r8);    r8_opr = LIR_OprFact::single_cpu(6);\n-  map_register( 7, r9);    r9_opr = LIR_OprFact::single_cpu(7);\n-  map_register( 8, r11);  r11_opr = LIR_OprFact::single_cpu(8);\n-  map_register( 9, r13);  r13_opr = LIR_OprFact::single_cpu(9);\n+  map_register(6, r8);    r8_opr = LIR_OprFact::single_cpu(6);\n+  map_register(7, r9);    r9_opr = LIR_OprFact::single_cpu(7);\n+  map_register(8, r11);  r11_opr = LIR_OprFact::single_cpu(8);\n+  map_register(9, r13);  r13_opr = LIR_OprFact::single_cpu(9);\n@@ -186,1 +170,0 @@\n-#endif \/\/ _LP64\n@@ -188,1 +171,0 @@\n-#ifdef _LP64\n@@ -191,4 +173,0 @@\n-#else\n-  long0_opr = LIR_OprFact::double_cpu(3 \/*eax*\/, 4 \/*edx*\/);\n-  long1_opr = LIR_OprFact::double_cpu(2 \/*ebx*\/, 5 \/*ecx*\/);\n-#endif \/\/ _LP64\n@@ -204,2 +182,0 @@\n-\n-#ifdef _LP64\n@@ -212,2 +188,0 @@\n-#endif \/\/ _LP64\n-\n@@ -223,2 +197,0 @@\n-\n-#ifdef _LP64\n@@ -249,1 +221,0 @@\n-#endif \/\/ _LP64\n@@ -279,1 +250,0 @@\n-#ifdef _LP64\n@@ -293,1 +263,0 @@\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.cpp","additions":6,"deletions":37,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -44,4 +44,0 @@\n-#ifndef _LP64\n-    frame_pad_in_bytes = 8,\n-    nof_reg_args = 2\n-#else\n@@ -50,1 +46,0 @@\n-#endif \/\/ _LP64\n@@ -84,2 +79,0 @@\n-#ifdef _LP64\n-\n@@ -111,2 +104,0 @@\n-#endif \/\/ _LP64\n-\n@@ -118,1 +109,0 @@\n-#ifdef _LP64\n@@ -125,8 +115,0 @@\n-#else\n-  static LIR_Opr as_long_opr(Register r, Register r2) {\n-    return LIR_OprFact::double_cpu(cpu_reg2rnr(r), cpu_reg2rnr(r2));\n-  }\n-  static LIR_Opr as_pointer_opr(Register r) {\n-    return LIR_OprFact::single_cpu(cpu_reg2rnr(r));\n-  }\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/c1_FrameMap_x86.hpp","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -172,1 +172,0 @@\n-    NOT_LP64(__ push_reg(opr->as_register_hi()));\n@@ -328,2 +327,0 @@\n-  Register thread = LP64_ONLY( r15_thread ) NOT_LP64( noreg );\n-  assert(thread != noreg, \"x86_32 not implemented\");\n@@ -332,1 +329,1 @@\n-  __ clinit_barrier(klass, thread, &L_skip_barrier \/*L_fast_path*\/);\n+  __ clinit_barrier(klass, r15_thread, &L_skip_barrier \/*L_fast_path*\/);\n@@ -404,5 +401,3 @@\n-  Register thread = NOT_LP64(rsi) LP64_ONLY(r15_thread);\n-  NOT_LP64(__ get_thread(thread));\n-  __ movptr(rax, Address(thread, JavaThread::exception_oop_offset()));\n-  __ movptr(Address(thread, JavaThread::exception_oop_offset()), NULL_WORD);\n-  __ movptr(Address(thread, JavaThread::exception_pc_offset()), NULL_WORD);\n+  __ movptr(rax, Address(r15_thread, JavaThread::exception_oop_offset()));\n+  __ movptr(Address(r15_thread, JavaThread::exception_oop_offset()), NULL_WORD);\n+  __ movptr(Address(r15_thread, JavaThread::exception_pc_offset()), NULL_WORD);\n@@ -430,1 +425,0 @@\n-#ifdef _LP64\n@@ -433,5 +427,0 @@\n-#else\n-    __ get_thread(rax);\n-    __ movptr(Address(rsp, 0), rax);\n-    __ mov_metadata(Address(rsp, sizeof(void*)), method()->constant_encoding(), noreg);\n-#endif\n@@ -494,6 +483,0 @@\n-#ifdef _LP64\n-  const Register thread = r15_thread;\n-#else\n-  const Register thread = rbx;\n-  __ get_thread(thread);\n-#endif\n@@ -502,1 +485,1 @@\n-  __ safepoint_poll(*code_stub->entry(), thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n+  __ safepoint_poll(*code_stub->entry(), r15_thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -510,1 +493,0 @@\n-#ifdef _LP64\n@@ -513,6 +495,0 @@\n-#else\n-  assert(tmp->is_cpu_register(), \"needed\");\n-  const Register poll_addr = tmp->as_register();\n-  __ get_thread(poll_addr);\n-  __ movptr(poll_addr, Address(poll_addr, in_bytes(JavaThread::polling_page_offset())));\n-#endif\n@@ -524,1 +500,1 @@\n-  guarantee(pointer_delta(post_pc, pre_pc, 1) == 2 LP64_ONLY(+1), \"must be exact length\");\n+  guarantee(pointer_delta(post_pc, pre_pc, 1) == 3, \"must be exact length\");\n@@ -558,1 +534,0 @@\n-#ifdef _LP64\n@@ -560,4 +535,0 @@\n-#else\n-      __ movptr(dest->as_register_lo(), c->as_jint_lo());\n-      __ movptr(dest->as_register_hi(), c->as_jint_hi());\n-#endif \/\/ _LP64\n@@ -639,1 +610,0 @@\n-#ifdef _LP64\n@@ -644,6 +614,0 @@\n-#else\n-      __ movptr(frame_map()->address_for_slot(dest->double_stack_ix(),\n-                                              lo_word_offset_in_bytes), c->as_jint_lo_bits());\n-      __ movptr(frame_map()->address_for_slot(dest->double_stack_ix(),\n-                                              hi_word_offset_in_bytes), c->as_jint_hi_bits());\n-#endif \/\/ _LP64\n@@ -680,1 +644,0 @@\n-#ifdef _LP64\n@@ -684,3 +647,0 @@\n-#else\n-          __ movptr(as_Address(addr), NULL_WORD);\n-#endif\n@@ -693,1 +653,0 @@\n-#ifdef _LP64\n@@ -703,3 +662,0 @@\n-#else\n-          __ movoop(as_Address(addr), c->as_jobject(), noreg);\n-#endif\n@@ -712,1 +668,0 @@\n-#ifdef _LP64\n@@ -721,5 +676,0 @@\n-#else\n-      \/\/ Always reachable in 32bit so this doesn't produce useless move literal\n-      __ movptr(as_Address_hi(addr), c->as_jint_hi_bits());\n-      __ movptr(as_Address_lo(addr), c->as_jint_lo_bits());\n-#endif \/\/ _LP64\n@@ -754,1 +704,0 @@\n-#ifdef _LP64\n@@ -760,1 +709,0 @@\n-#endif\n@@ -768,1 +716,0 @@\n-#ifdef _LP64\n@@ -775,1 +722,0 @@\n-#endif\n@@ -781,1 +727,0 @@\n-#ifdef _LP64\n@@ -785,16 +730,0 @@\n-#else\n-    assert(f_lo != f_hi && t_lo != t_hi, \"invalid register allocation\");\n-\n-\n-    if (f_lo == t_hi && f_hi == t_lo) {\n-      swap_reg(f_lo, f_hi);\n-    } else if (f_hi == t_lo) {\n-      assert(f_lo != t_hi, \"overwriting register\");\n-      move_regs(f_hi, t_hi);\n-      move_regs(f_lo, t_lo);\n-    } else {\n-      assert(f_hi != t_lo, \"overwriting register\");\n-      move_regs(f_lo, t_lo);\n-      move_regs(f_hi, t_hi);\n-    }\n-#endif \/\/ LP64\n@@ -834,1 +763,0 @@\n-    NOT_LP64(__ movptr (dstHI, src->as_register_hi()));\n@@ -857,1 +785,0 @@\n-#ifdef _LP64\n@@ -865,1 +792,0 @@\n-#endif\n@@ -896,8 +822,0 @@\n-    case T_METADATA:\n-      \/\/ We get here to store a method pointer to the stack to pass to\n-      \/\/ a dtrace runtime call. This can't work on 64 bit with\n-      \/\/ compressed klass ptrs: T_METADATA can be a compressed klass\n-      \/\/ ptr or a 64 bit method pointer.\n-      LP64_ONLY(ShouldNotReachHere());\n-      __ movptr(as_Address(to_addr), src->as_register());\n-      break;\n@@ -914,1 +832,0 @@\n-#ifdef _LP64\n@@ -916,27 +833,0 @@\n-#else\n-      Register base = to_addr->base()->as_register();\n-      Register index = noreg;\n-      if (to_addr->index()->is_register()) {\n-        index = to_addr->index()->as_register();\n-      }\n-      if (base == from_lo || index == from_lo) {\n-        assert(base != from_hi, \"can't be\");\n-        assert(index == noreg || (index != base && index != from_hi), \"can't handle this\");\n-        __ movl(as_Address_hi(to_addr), from_hi);\n-        if (patch != nullptr) {\n-          patching_epilog(patch, lir_patch_high, base, info);\n-          patch = new PatchingStub(_masm, PatchingStub::access_field_id);\n-          patch_code = lir_patch_low;\n-        }\n-        __ movl(as_Address_lo(to_addr), from_lo);\n-      } else {\n-        assert(index == noreg || (index != base && index != from_lo), \"can't handle this\");\n-        __ movl(as_Address_lo(to_addr), from_lo);\n-        if (patch != nullptr) {\n-          patching_epilog(patch, lir_patch_low, base, info);\n-          patch = new PatchingStub(_masm, PatchingStub::access_field_id);\n-          patch_code = lir_patch_high;\n-        }\n-        __ movl(as_Address_hi(to_addr), from_hi);\n-      }\n-#endif \/\/ _LP64\n@@ -991,1 +881,0 @@\n-    NOT_LP64(__ movptr(dest->as_register_hi(), src_addr_HI));\n@@ -1013,4 +902,0 @@\n-#ifndef _LP64\n-      __ pushl(frame_map()->address_for_slot(src ->single_stack_ix()));\n-      __ popl (frame_map()->address_for_slot(dest->single_stack_ix()));\n-#else\n@@ -1020,1 +905,0 @@\n-#endif\n@@ -1024,1 +908,0 @@\n-#ifdef _LP64\n@@ -1027,7 +910,0 @@\n-#else\n-    __ pushl(frame_map()->address_for_slot(src ->double_stack_ix(), 0));\n-    \/\/ push and pop the part at src + wordSize, adding wordSize for the previous push\n-    __ pushl(frame_map()->address_for_slot(src ->double_stack_ix(), 2 * wordSize));\n-    __ popl (frame_map()->address_for_slot(dest->double_stack_ix(), 2 * wordSize));\n-    __ popl (frame_map()->address_for_slot(dest->double_stack_ix(), 0));\n-#endif \/\/ _LP64\n@@ -1116,1 +992,0 @@\n-#ifdef _LP64\n@@ -1118,36 +993,0 @@\n-#else\n-      Register base = addr->base()->as_register();\n-      Register index = noreg;\n-      if (addr->index()->is_register()) {\n-        index = addr->index()->as_register();\n-      }\n-      if ((base == to_lo && index == to_hi) ||\n-          (base == to_hi && index == to_lo)) {\n-        \/\/ addresses with 2 registers are only formed as a result of\n-        \/\/ array access so this code will never have to deal with\n-        \/\/ patches or null checks.\n-        assert(info == nullptr && patch == nullptr, \"must be\");\n-        __ lea(to_hi, as_Address(addr));\n-        __ movl(to_lo, Address(to_hi, 0));\n-        __ movl(to_hi, Address(to_hi, BytesPerWord));\n-      } else if (base == to_lo || index == to_lo) {\n-        assert(base != to_hi, \"can't be\");\n-        assert(index == noreg || (index != base && index != to_hi), \"can't handle this\");\n-        __ movl(to_hi, as_Address_hi(addr));\n-        if (patch != nullptr) {\n-          patching_epilog(patch, lir_patch_high, base, info);\n-          patch = new PatchingStub(_masm, PatchingStub::access_field_id);\n-          patch_code = lir_patch_low;\n-        }\n-        __ movl(to_lo, as_Address_lo(addr));\n-      } else {\n-        assert(index == noreg || (index != base && index != to_lo), \"can't handle this\");\n-        __ movl(to_lo, as_Address_lo(addr));\n-        if (patch != nullptr) {\n-          patching_epilog(patch, lir_patch_low, base, info);\n-          patch = new PatchingStub(_masm, PatchingStub::access_field_id);\n-          patch_code = lir_patch_high;\n-        }\n-        __ movl(to_hi, as_Address_hi(addr));\n-      }\n-#endif \/\/ _LP64\n@@ -1203,1 +1042,0 @@\n-#ifdef _LP64\n@@ -1207,1 +1045,0 @@\n-#endif\n@@ -1302,1 +1139,0 @@\n-#ifdef _LP64\n@@ -1304,5 +1140,0 @@\n-#else\n-      move_regs(src->as_register(), dest->as_register_lo());\n-      move_regs(src->as_register(), dest->as_register_hi());\n-      __ sarl(dest->as_register_hi(), 31);\n-#endif \/\/ LP64\n@@ -1312,1 +1143,0 @@\n-#ifdef _LP64\n@@ -1314,3 +1144,0 @@\n-#else\n-      move_regs(src->as_register_lo(), dest->as_register());\n-#endif\n@@ -1399,1 +1226,1 @@\n-  LP64_ONLY( __ movslq(len, len); )\n+  __ movslq(len, len);\n@@ -1467,1 +1294,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+  Register tmp_load_klass = rscratch1;\n@@ -1529,1 +1356,0 @@\n-#ifdef _LP64\n@@ -1531,1 +1357,0 @@\n-#endif \/\/ _LP64\n@@ -1538,1 +1363,0 @@\n-#ifdef _LP64\n@@ -1545,7 +1369,0 @@\n-#else\n-    if (k->is_loaded()) {\n-      __ cmpklass(Address(obj, oopDesc::klass_offset_in_bytes()), k->constant_encoding());\n-    } else {\n-      __ cmpptr(k_RInfo, Address(obj, oopDesc::klass_offset_in_bytes()));\n-    }\n-#endif\n@@ -1560,1 +1377,0 @@\n-#ifdef _LP64\n@@ -1562,3 +1378,0 @@\n-#else\n-      __ cmpklass(Address(klass_RInfo, k->super_check_offset()), k->constant_encoding());\n-#endif \/\/ _LP64\n@@ -1572,1 +1385,0 @@\n-#ifdef _LP64\n@@ -1574,3 +1386,0 @@\n-#else\n-        __ cmpklass(klass_RInfo, k->constant_encoding());\n-#endif \/\/ _LP64\n@@ -1580,1 +1389,0 @@\n-#ifdef _LP64\n@@ -1582,3 +1390,0 @@\n-#else\n-        __ pushklass(k->constant_encoding(), noreg);\n-#endif \/\/ _LP64\n@@ -1613,1 +1418,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+  Register tmp_load_klass = rscratch1;\n@@ -1717,11 +1522,1 @@\n-  if (LP64_ONLY(false &&) op->code() == lir_cas_long) {\n-    assert(op->cmp_value()->as_register_lo() == rax, \"wrong register\");\n-    assert(op->cmp_value()->as_register_hi() == rdx, \"wrong register\");\n-    assert(op->new_value()->as_register_lo() == rbx, \"wrong register\");\n-    assert(op->new_value()->as_register_hi() == rcx, \"wrong register\");\n-    Register addr = op->addr()->as_register();\n-    __ lock();\n-    NOT_LP64(__ cmpxchg8(Address(addr, 0)));\n-\n-  } else if (op->code() == lir_cas_int || op->code() == lir_cas_obj ) {\n-    NOT_LP64(assert(op->addr()->is_single_cpu(), \"must be single\");)\n+  if (op->code() == lir_cas_int || op->code() == lir_cas_obj) {\n@@ -1737,2 +1532,1 @@\n-    if ( op->code() == lir_cas_obj) {\n-#ifdef _LP64\n+    if (op->code() == lir_cas_obj) {\n@@ -1746,3 +1540,1 @@\n-      } else\n-#endif\n-      {\n+      } else {\n@@ -1757,1 +1549,0 @@\n-#ifdef _LP64\n@@ -1769,1 +1560,0 @@\n-#endif \/\/ _LP64\n@@ -1812,1 +1602,0 @@\n-      NOT_LP64(__ cmovptr(ncond, result->as_register_hi(), opr2->as_register_hi());)\n@@ -1817,1 +1606,0 @@\n-      NOT_LP64(__ cmovptr(ncond, result->as_register_hi(), frame_map()->address_for_slot(opr2->double_stack_ix(), hi_word_offset_in_bytes));)\n@@ -1893,2 +1681,1 @@\n-      NOT_LP64(assert_different_registers(lreg_lo, lreg_hi, rreg_lo, rreg_hi));\n-      LP64_ONLY(assert_different_registers(lreg_lo, rreg_lo));\n+      assert_different_registers(lreg_lo, rreg_lo);\n@@ -1898,1 +1685,0 @@\n-          NOT_LP64(__ adcl(lreg_hi, rreg_hi));\n@@ -1902,1 +1688,0 @@\n-          NOT_LP64(__ sbbl(lreg_hi, rreg_hi));\n@@ -1905,1 +1690,0 @@\n-#ifdef _LP64\n@@ -1907,8 +1691,0 @@\n-#else\n-          assert(lreg_lo == rax && lreg_hi == rdx, \"must be\");\n-          __ imull(lreg_hi, rreg_lo);\n-          __ imull(rreg_hi, lreg_lo);\n-          __ addl (rreg_hi, lreg_hi);\n-          __ mull (rreg_lo);\n-          __ addl (lreg_hi, rreg_hi);\n-#endif \/\/ _LP64\n@@ -1922,1 +1698,0 @@\n-#ifdef _LP64\n@@ -1935,16 +1710,0 @@\n-#else\n-      jint c_lo = right->as_constant_ptr()->as_jint_lo();\n-      jint c_hi = right->as_constant_ptr()->as_jint_hi();\n-      switch (code) {\n-        case lir_add:\n-          __ addptr(lreg_lo, c_lo);\n-          __ adcl(lreg_hi, c_hi);\n-          break;\n-        case lir_sub:\n-          __ subptr(lreg_lo, c_lo);\n-          __ sbbl(lreg_hi, c_hi);\n-          break;\n-        default:\n-          ShouldNotReachHere();\n-      }\n-#endif \/\/ _LP64\n@@ -2126,1 +1885,0 @@\n-#ifdef _LP64\n@@ -2140,19 +1898,0 @@\n-#else\n-      int r_lo = right->as_constant_ptr()->as_jint_lo();\n-      int r_hi = right->as_constant_ptr()->as_jint_hi();\n-      switch (code) {\n-        case lir_logic_and:\n-          __ andl(l_lo, r_lo);\n-          __ andl(l_hi, r_hi);\n-          break;\n-        case lir_logic_or:\n-          __ orl(l_lo, r_lo);\n-          __ orl(l_hi, r_hi);\n-          break;\n-        case lir_logic_xor:\n-          __ xorl(l_lo, r_lo);\n-          __ xorl(l_hi, r_hi);\n-          break;\n-        default: ShouldNotReachHere();\n-      }\n-#endif \/\/ _LP64\n@@ -2160,1 +1899,0 @@\n-#ifdef _LP64\n@@ -2167,5 +1905,0 @@\n-#else\n-      Register r_lo = right->as_register_lo();\n-      Register r_hi = right->as_register_hi();\n-      assert(l_lo != r_hi, \"overwriting registers\");\n-#endif\n@@ -2175,1 +1908,0 @@\n-          NOT_LP64(__ andptr(l_hi, r_hi);)\n@@ -2179,1 +1911,0 @@\n-          NOT_LP64(__ orptr(l_hi, r_hi);)\n@@ -2183,1 +1914,0 @@\n-          NOT_LP64(__ xorptr(l_hi, r_hi);)\n@@ -2192,1 +1922,0 @@\n-#ifdef _LP64\n@@ -2194,11 +1923,0 @@\n-#else\n-    if (dst_lo == l_hi) {\n-      assert(dst_hi != l_lo, \"overwriting registers\");\n-      move_regs(l_hi, dst_hi);\n-      move_regs(l_lo, dst_lo);\n-    } else {\n-      assert(dst_lo != l_hi, \"overwriting registers\");\n-      move_regs(l_lo, dst_lo);\n-      move_regs(l_hi, dst_hi);\n-    }\n-#endif \/\/ _LP64\n@@ -2332,1 +2050,0 @@\n-#ifdef _LP64\n@@ -2334,10 +2051,0 @@\n-#else\n-      \/\/ cpu register - cpu register\n-      Register ylo = opr2->as_register_lo();\n-      Register yhi = opr2->as_register_hi();\n-      __ subl(xlo, ylo);\n-      __ sbbl(xhi, yhi);\n-      if (condition == lir_cond_equal || condition == lir_cond_notEqual) {\n-        __ orl(xhi, xlo);\n-      }\n-#endif \/\/ _LP64\n@@ -2347,1 +2054,0 @@\n-#ifdef _LP64\n@@ -2349,4 +2055,0 @@\n-#else\n-      assert(condition == lir_cond_equal || condition == lir_cond_notEqual, \"only handles equals case\");\n-      __ orl(xhi, xlo);\n-#endif \/\/ _LP64\n@@ -2401,1 +2103,0 @@\n-#ifdef _LP64\n@@ -2406,1 +2107,0 @@\n-#endif \/\/ LP64\n@@ -2415,1 +2115,0 @@\n-#ifdef _LP64\n@@ -2419,3 +2118,0 @@\n-#else\n-      __ cmpoop(as_Address(addr), c->as_jobject());\n-#endif \/\/ _LP64\n@@ -2445,1 +2141,0 @@\n-#ifdef _LP64\n@@ -2454,7 +2149,0 @@\n-#else\n-    __ lcmp2int(left->as_register_hi(),\n-                left->as_register_lo(),\n-                right->as_register_hi(),\n-                right->as_register_lo());\n-    move_regs(left->as_register_hi(), dst->as_register());\n-#endif \/\/ _LP64\n@@ -2586,1 +2274,0 @@\n-#ifdef _LP64\n@@ -2593,9 +2280,0 @@\n-#else\n-\n-    switch (code) {\n-      case lir_shl:  __ lshl(hi, lo);        break;\n-      case lir_shr:  __ lshr(hi, lo, true);  break;\n-      case lir_ushr: __ lshr(hi, lo, false); break;\n-      default: ShouldNotReachHere();\n-    }\n-#endif \/\/ LP64\n@@ -2622,3 +2300,0 @@\n-#ifndef _LP64\n-    Unimplemented();\n-#else\n@@ -2636,1 +2311,0 @@\n-#endif \/\/ _LP64\n@@ -2686,1 +2360,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+  Register tmp_load_klass = rscratch1;\n@@ -2711,1 +2385,0 @@\n-    NOT_LP64(assert(src == rcx && src_pos == rdx, \"mismatch in calling convention\");)\n@@ -2717,1 +2390,0 @@\n-#ifdef _LP64\n@@ -2748,15 +2420,0 @@\n-#else\n-    __ push(length);\n-    __ push(dst_pos);\n-    __ push(dst);\n-    __ push(src_pos);\n-    __ push(src);\n-\n-#ifndef PRODUCT\n-    if (PrintC1Statistics) {\n-      __ incrementl(ExternalAddress((address)&Runtime1::_generic_arraycopystub_cnt), rscratch1);\n-    }\n-#endif\n-    __ call_VM_leaf(copyfunc_addr, 5); \/\/ removes pushed parameter from the stack\n-\n-#endif \/\/ _LP64\n@@ -2868,1 +2525,0 @@\n-#ifdef _LP64\n@@ -2871,1 +2527,0 @@\n-#endif\n@@ -2935,15 +2590,0 @@\n-#ifndef _LP64\n-       Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n-        __ movptr(tmp, dst_klass_addr);\n-        __ movptr(tmp, Address(tmp, ObjArrayKlass::element_klass_offset()));\n-        __ push(tmp);\n-        __ movl(tmp, Address(tmp, Klass::super_check_offset_offset()));\n-        __ push(tmp);\n-        __ push(length);\n-        __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));\n-        __ push(tmp);\n-        __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));\n-        __ push(tmp);\n-\n-        __ call_VM_leaf(copyfunc_addr, 5);\n-#else\n@@ -2976,2 +2616,0 @@\n-#endif\n-\n@@ -3033,1 +2671,0 @@\n-#ifdef _LP64\n@@ -3037,1 +2674,0 @@\n-#endif\n@@ -3062,1 +2698,0 @@\n-#ifdef _LP64\n@@ -3069,8 +2704,0 @@\n-#else\n-  __ lea(tmp, Address(src, src_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));\n-  store_parameter(tmp, 0);\n-  __ lea(tmp, Address(dst, dst_pos, scale, arrayOopDesc::base_offset_in_bytes(basic_type)));\n-  store_parameter(tmp, 1);\n-  store_parameter(length, 2);\n-#endif \/\/ _LP64\n-\n@@ -3149,1 +2776,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+  Register tmp_load_klass = rscratch1;\n@@ -3220,1 +2847,1 @@\n-  Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);\n+  Register tmp_load_klass = rscratch1;\n@@ -3240,1 +2867,0 @@\n-#ifdef _LP64\n@@ -3242,3 +2868,0 @@\n-#else\n-    assert_different_registers(obj, mdo_addr.base(), mdo_addr.index());\n-#endif\n@@ -3246,1 +2869,0 @@\n-#ifdef _LP64\n@@ -3248,3 +2870,0 @@\n-#else\n-    assert_different_registers(obj, tmp, mdo_addr.base(), mdo_addr.index());\n-#endif\n@@ -3304,1 +2923,0 @@\n-#ifdef _LP64\n@@ -3306,1 +2924,0 @@\n-#endif\n@@ -3319,1 +2936,0 @@\n-#ifdef _LP64\n@@ -3327,1 +2943,0 @@\n-#endif\n@@ -3421,1 +3036,0 @@\n-#ifdef _LP64\n@@ -3425,12 +3039,0 @@\n-#else\n-    Register hi = left->as_register_hi();\n-    __ lneg(hi, lo);\n-    if (dest->as_register_lo() == hi) {\n-      assert(dest->as_register_hi() != lo, \"destroying register\");\n-      move_regs(hi, dest->as_register_hi());\n-      move_regs(lo, dest->as_register_lo());\n-    } else {\n-      move_regs(lo, dest->as_register_lo());\n-      move_regs(hi, dest->as_register_hi());\n-    }\n-#endif \/\/ _LP64\n@@ -3499,1 +3101,0 @@\n-#ifdef _LP64\n@@ -3501,5 +3102,0 @@\n-#else\n-      __ movdl(dest->as_register_lo(), src->as_xmm_double_reg());\n-      __ psrlq(src->as_xmm_double_reg(), 32);\n-      __ movdl(dest->as_register_hi(), src->as_xmm_double_reg());\n-#endif \/\/ _LP64\n@@ -3522,0 +3118,1 @@\n+\n@@ -3604,2 +3201,0 @@\n-#ifdef _LP64\n-  \/\/ __ get_thread(result_reg->as_register_lo());\n@@ -3607,3 +3202,0 @@\n-#else\n-  __ get_thread(result_reg->as_register());\n-#endif \/\/ _LP64\n@@ -3630,1 +3222,0 @@\n-#ifdef _LP64\n@@ -3638,3 +3229,0 @@\n-#else\n-    __ xchgl(obj, as_Address(src->as_address_ptr()));\n-#endif\n@@ -3642,1 +3230,0 @@\n-#ifdef _LP64\n@@ -3650,3 +3237,0 @@\n-#else\n-    ShouldNotReachHere();\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":17,"deletions":433,"binary":false,"changes":450,"status":"modified"},{"patch":"@@ -49,1 +49,1 @@\n-    _call_stub_size = NOT_LP64(15) LP64_ONLY(28),\n+    _call_stub_size = 28,\n@@ -51,1 +51,1 @@\n-    _deopt_handler_size = NOT_LP64(10) LP64_ONLY(17)\n+    _deopt_handler_size = 17\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -145,1 +145,0 @@\n-  NOT_LP64( return new_register(T_ADDRESS); )\n@@ -155,1 +154,0 @@\n-#ifdef _LP64\n@@ -170,5 +168,0 @@\n-#else\n-    return new LIR_Address(base,\n-                           ((intx)(constant->as_jint()) << shift) + disp,\n-                           type);\n-#endif\n@@ -188,1 +181,0 @@\n-#ifdef _LP64\n@@ -200,14 +192,0 @@\n-#else\n-    \/\/ A displacement overflow can also occur for x86 but that is not a problem due to the 32-bit address range!\n-    \/\/ Let's assume an array 'a' and an access with displacement 'disp'. When disp overflows, then \"a + disp\" will\n-    \/\/ always be negative (i.e. underflows the 32-bit address range):\n-    \/\/ Let N = 2^32: a + signed_overflow(disp) = a + disp - N.\n-    \/\/ \"a + disp\" is always smaller than N. If an index was chosen which would point to an address beyond N, then\n-    \/\/ range checks would catch that and throw an exception. Thus, a + disp < 0 holds which means that it always\n-    \/\/ underflows the 32-bit address range:\n-    \/\/ unsigned_underflow(a + signed_overflow(disp)) = unsigned_underflow(a + disp - N)\n-    \/\/                                              = (a + disp - N) + N = a + disp\n-    \/\/ This shows that we still end up at the correct address with a displacement overflow due to the 32-bit address\n-    \/\/ range limitation. This overflow only needs to be handled if addresses can be larger as on 64-bit platforms.\n-    addr = new LIR_Address(array_opr, offset_in_bytes + (intx)(index_opr->as_jint()) * elem_size, type);\n-#endif \/\/ _LP64\n@@ -215,1 +193,0 @@\n-#ifdef _LP64\n@@ -221,1 +198,0 @@\n-#endif \/\/ _LP64\n@@ -361,18 +337,0 @@\n-#ifndef _LP64\n-  \/\/ do not load right operand if it is a constant.  only 0 and 1 are\n-  \/\/ loaded because there are special instructions for loading them\n-  \/\/ without memory access (not needed for SSE2 instructions)\n-  bool must_load_right = false;\n-  if (right.is_constant()) {\n-    LIR_Const* c = right.result()->as_constant_ptr();\n-    assert(c != nullptr, \"invalid constant\");\n-    assert(c->type() == T_FLOAT || c->type() == T_DOUBLE, \"invalid type\");\n-\n-    if (c->type() == T_FLOAT) {\n-      must_load_right = UseSSE < 1 && (c->is_one_float() || c->is_zero_float());\n-    } else {\n-      must_load_right = UseSSE < 2 && (c->is_one_double() || c->is_zero_double());\n-    }\n-  }\n-#endif \/\/ !LP64\n-\n@@ -385,4 +343,0 @@\n-#ifndef _LP64\n-  } else if (must_load_right) {\n-    right.load_item();\n-#endif \/\/ !LP64\n@@ -398,1 +352,0 @@\n-#ifdef _LP64\n@@ -433,21 +386,0 @@\n-#else\n-  if ((UseSSE >= 1 && x->op() == Bytecodes::_frem) || (UseSSE >= 2 && x->op() == Bytecodes::_drem)) {\n-    \/\/ special handling for frem and drem: no SSE instruction, so must use FPU with temporary fpu stack slots\n-    LIR_Opr fpu0, fpu1;\n-    if (x->op() == Bytecodes::_frem) {\n-      fpu0 = LIR_OprFact::single_fpu(0);\n-      fpu1 = LIR_OprFact::single_fpu(1);\n-    } else {\n-      fpu0 = LIR_OprFact::double_fpu(0);\n-      fpu1 = LIR_OprFact::double_fpu(1);\n-    }\n-    __ move(right.result(), fpu1); \/\/ order of left and right operand is important!\n-    __ move(left.result(), fpu0);\n-    __ rem (fpu0, fpu1, fpu0);\n-    __ move(fpu0, reg);\n-\n-  } else {\n-    arithmetic_op_fpu(x->op(), reg, left.result(), right.result(), tmp);\n-  }\n-  set_result(x, reg);\n-#endif \/\/ _LP64\n@@ -743,1 +675,1 @@\n-  assert(type == T_INT || is_oop LP64_ONLY( || type == T_LONG ), \"unexpected type\");\n+  assert(type == T_INT || is_oop || type == T_LONG, \"unexpected type\");\n@@ -753,1 +685,1 @@\n-  assert(type == T_INT LP64_ONLY( || type == T_LONG ), \"unexpected type\");\n+  assert(type == T_INT || type == T_LONG, \"unexpected type\");\n@@ -791,4 +723,1 @@\n-      x->id() == vmIntrinsics::_dlog10\n-#ifdef _LP64\n-      || x->id() == vmIntrinsics::_dtanh\n-#endif\n+      x->id() == vmIntrinsics::_dlog10 || x->id() == vmIntrinsics::_dtanh\n@@ -802,6 +731,0 @@\n-  bool use_fpu = false;\n-#ifndef _LP64\n-  if (UseSSE < 2) {\n-    value.set_destroys_register();\n-  }\n-#endif \/\/ !LP64\n@@ -835,4 +758,0 @@\n-\n-  if (use_fpu) {\n-    __ move(calc_result, x->operand());\n-  }\n@@ -959,14 +878,0 @@\n-#ifndef _LP64\n-  src.load_item_force     (FrameMap::rcx_oop_opr);\n-  src_pos.load_item_force (FrameMap::rdx_opr);\n-  dst.load_item_force     (FrameMap::rax_oop_opr);\n-  dst_pos.load_item_force (FrameMap::rbx_opr);\n-  length.load_item_force  (FrameMap::rdi_opr);\n-  LIR_Opr tmp =           (FrameMap::rsi_opr);\n-\n-  if (expected_type != nullptr && flags == 0) {\n-    FrameMap* f = Compilation::current()->frame_map();\n-    f->update_reserved_argument_area_size(3 * BytesPerWord);\n-  }\n-#else\n-\n@@ -988,1 +893,0 @@\n-#endif \/\/ LP64\n@@ -1030,6 +934,0 @@\n-#ifndef _LP64\n-      if (!is_updateBytes) { \/\/ long b raw address\n-         base_op = new_register(T_INT);\n-         __ convert(Bytecodes::_l2i, buf.result(), base_op);\n-      }\n-#else\n@@ -1041,1 +939,0 @@\n-#endif\n@@ -1175,8 +1072,0 @@\n-#ifndef _LP64\n-  result_a = new_register(T_INT);\n-  __ convert(Bytecodes::_l2i, a.result(), result_a);\n-  result_b = new_register(T_INT);\n-  __ convert(Bytecodes::_l2i, b.result(), result_b);\n-#endif\n-\n-\n@@ -1217,1 +1106,0 @@\n-#ifdef _LP64\n@@ -1225,60 +1113,0 @@\n-#else\n-  \/\/ flags that vary for the different operations and different SSE-settings\n-  bool fixed_input = false, fixed_result = false, round_result = false, needs_stub = false;\n-\n-  switch (x->op()) {\n-    case Bytecodes::_i2l: \/\/ fall through\n-    case Bytecodes::_l2i: \/\/ fall through\n-    case Bytecodes::_i2b: \/\/ fall through\n-    case Bytecodes::_i2c: \/\/ fall through\n-    case Bytecodes::_i2s: fixed_input = false;       fixed_result = false;       round_result = false;      needs_stub = false; break;\n-\n-    case Bytecodes::_f2d: fixed_input = UseSSE == 1; fixed_result = false;       round_result = false;      needs_stub = false; break;\n-    case Bytecodes::_d2f: fixed_input = false;       fixed_result = UseSSE == 1; round_result = UseSSE < 1; needs_stub = false; break;\n-    case Bytecodes::_i2f: fixed_input = false;       fixed_result = false;       round_result = UseSSE < 1; needs_stub = false; break;\n-    case Bytecodes::_i2d: fixed_input = false;       fixed_result = false;       round_result = false;      needs_stub = false; break;\n-    case Bytecodes::_f2i: fixed_input = false;       fixed_result = false;       round_result = false;      needs_stub = true;  break;\n-    case Bytecodes::_d2i: fixed_input = false;       fixed_result = false;       round_result = false;      needs_stub = true;  break;\n-    case Bytecodes::_l2f: fixed_input = false;       fixed_result = UseSSE >= 1; round_result = UseSSE < 1; needs_stub = false; break;\n-    case Bytecodes::_l2d: fixed_input = false;       fixed_result = UseSSE >= 2; round_result = UseSSE < 2; needs_stub = false; break;\n-    case Bytecodes::_f2l: fixed_input = true;        fixed_result = true;        round_result = false;      needs_stub = false; break;\n-    case Bytecodes::_d2l: fixed_input = true;        fixed_result = true;        round_result = false;      needs_stub = false; break;\n-    default: ShouldNotReachHere();\n-  }\n-\n-  LIRItem value(x->value(), this);\n-  value.load_item();\n-  LIR_Opr input = value.result();\n-  LIR_Opr result = rlock(x);\n-\n-  \/\/ arguments of lir_convert\n-  LIR_Opr conv_input = input;\n-  LIR_Opr conv_result = result;\n-  ConversionStub* stub = nullptr;\n-\n-  if (fixed_input) {\n-    conv_input = fixed_register_for(input->type());\n-    __ move(input, conv_input);\n-  }\n-\n-  assert(fixed_result == false || round_result == false, \"cannot set both\");\n-  if (fixed_result) {\n-    conv_result = fixed_register_for(result->type());\n-  } else if (round_result) {\n-    result = new_register(result->type());\n-    set_vreg_flag(result, must_start_in_memory);\n-  }\n-\n-  if (needs_stub) {\n-    stub = new ConversionStub(x->op(), conv_input, conv_result);\n-  }\n-\n-  __ convert(x->op(), conv_input, conv_result, stub);\n-\n-  if (result != conv_result) {\n-    __ move(conv_result, result);\n-  }\n-\n-  assert(result->is_virtual(), \"result must be virtual register\");\n-  set_result(x, result);\n-#endif \/\/ _LP64\n@@ -1550,1 +1378,0 @@\n-#ifdef _LP64\n@@ -1552,5 +1379,0 @@\n-#else\n-  LIR_Opr result = new_register(T_INT);\n-  __ get_thread(result);\n-  return result;\n-#endif \/\/\n@@ -1601,6 +1423,0 @@\n-#ifndef _LP64\n-    if (UseSSE < 2) {\n-      \/\/ no spill slot needed in SSE2 mode because xmm->cpu register move is possible\n-      set_vreg_flag(result, must_start_in_memory);\n-    }\n-#endif \/\/ !LP64\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":3,"deletions":187,"binary":false,"changes":190,"status":"modified"},{"patch":"@@ -61,1 +61,0 @@\n-#ifdef _LP64\n@@ -66,6 +65,0 @@\n-#else\n-  assert(base()->is_single_cpu(), \"wrong base operand\");\n-  assert(index()->is_illegal() || index()->is_single_cpu(), \"wrong index operand\");\n-  assert(base()->type() == T_ADDRESS || base()->type() == T_OBJECT || base()->type() == T_INT || base()->type() == T_METADATA,\n-         \"wrong type for addresses\");\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIR_x86.cpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -29,6 +29,0 @@\n-#ifndef _LP64\n-  \/\/ rsp and rbp (numbers 6 ancd 7) are ignored\n-  assert(FrameMap::rsp_opr->cpu_regnr() == 6, \"wrong assumption below\");\n-  assert(FrameMap::rbp_opr->cpu_regnr() == 7, \"wrong assumption below\");\n-  assert(reg_num >= 0, \"invalid reg_num\");\n-#else\n@@ -43,1 +37,0 @@\n-#endif \/\/ _LP64\n@@ -48,5 +41,0 @@\n-  \/\/ Intel requires two cpu registers for long,\n-  \/\/ but requires only one fpu register for double\n-  if (LP64_ONLY(false &&) type == T_LONG) {\n-    return 2;\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LinearScan_x86.hpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -65,1 +65,0 @@\n-#ifdef _LP64\n@@ -68,6 +67,0 @@\n-#else\n-    \/\/ Implicit null check.\n-    movptr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-    \/\/ Lacking registers and thread on x86_32. Always take slow path.\n-    jmp(slow_case);\n-#endif\n@@ -138,1 +131,0 @@\n-#ifdef _LP64\n@@ -140,4 +132,0 @@\n-#else\n-    \/\/ Lacking registers and thread on x86_32. Always take slow path.\n-    jmp(slow_case);\n-#endif\n@@ -172,1 +160,0 @@\n-#ifdef _LP64\n@@ -181,3 +168,1 @@\n-  } else\n-#endif\n-  {\n+  } else {\n@@ -190,1 +175,0 @@\n-#ifdef _LP64\n@@ -198,4 +182,1 @@\n-#endif\n-  }\n-#ifdef _LP64\n-  else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n+  } else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n@@ -205,1 +186,0 @@\n-#endif\n@@ -268,2 +248,0 @@\n-        NOT_LP64(movptr(Address(obj, index, Address::times_8, hdr_size_in_bytes - (2*BytesPerWord)),\n-               t1_zero);)\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":2,"deletions":24,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -54,1 +54,1 @@\n-  const Register thread = NOT_LP64(rdi) LP64_ONLY(r15_thread); \/\/ is callee-saved register (Visual C++ calling conventions)\n+  const Register thread = r15_thread; \/\/ is callee-saved register (Visual C++ calling conventions)\n@@ -59,1 +59,1 @@\n-#ifdef _LP64\n+\n@@ -63,1 +63,0 @@\n-#endif\n@@ -65,1 +64,0 @@\n-#ifdef _LP64\n@@ -68,7 +66,0 @@\n-#else\n-  set_num_rt_args(1 + args_size);\n-\n-  \/\/ push java thread (becomes first argument of C function)\n-  get_thread(thread);\n-  push(thread);\n-#endif \/\/ _LP64\n@@ -107,3 +98,0 @@\n-  \/\/ discard thread and arguments\n-  NOT_LP64(addptr(rsp, num_rt_args()*BytesPerWord));\n-\n@@ -147,1 +135,0 @@\n-#ifdef _LP64\n@@ -149,3 +136,0 @@\n-#else\n-  push(arg1);\n-#endif \/\/ _LP64\n@@ -157,1 +141,0 @@\n-#ifdef _LP64\n@@ -169,4 +152,0 @@\n-#else\n-  push(arg2);\n-  push(arg1);\n-#endif \/\/ _LP64\n@@ -178,1 +157,0 @@\n-#ifdef _LP64\n@@ -194,5 +172,0 @@\n-#else\n-  push(arg3);\n-  push(arg2);\n-  push(arg1);\n-#endif \/\/ _LP64\n@@ -265,7 +238,2 @@\n-#ifdef _LP64\n-  #define SLOT2(x) x,\n-  #define SLOT_PER_WORD 2\n-#else\n-  #define SLOT2(x)\n-  #define SLOT_PER_WORD 1\n-#endif \/\/ _LP64\n+#define SLOT2(x) x,\n+#define SLOT_PER_WORD 2\n@@ -276,1 +244,0 @@\n-#ifdef _LP64\n@@ -278,1 +245,0 @@\n-#endif \/\/ _LP64\n@@ -294,1 +260,0 @@\n-#ifdef _LP64\n@@ -304,3 +269,0 @@\n-#else\n-  rdi_off = extra_space_offset,\n-#endif \/\/ _LP64\n@@ -332,2 +294,2 @@\n-  LP64_ONLY(num_rt_args = 0);\n-  LP64_ONLY(assert((reg_save_frame_size * VMRegImpl::stack_slot_size) % 16 == 0, \"must be 16 byte aligned\");)\n+  num_rt_args = 0;\n+  assert((reg_save_frame_size * VMRegImpl::stack_slot_size) % 16 == 0, \"must be 16 byte aligned\");\n@@ -346,1 +308,0 @@\n-#ifdef _LP64\n@@ -372,1 +333,0 @@\n-#endif \/\/ _LP64\n@@ -377,26 +337,0 @@\n-#ifndef _LP64\n-    if (UseSSE < 2) {\n-      int fpu_off = float_regs_as_doubles_off;\n-      for (int n = 0; n < FrameMap::nof_fpu_regs; n++) {\n-        VMReg fpu_name_0 = FrameMap::fpu_regname(n);\n-        map->set_callee_saved(VMRegImpl::stack2reg(fpu_off +     num_rt_args), fpu_name_0);\n-        \/\/ %%% This is really a waste but we'll keep things as they were for now\n-        if (true) {\n-          map->set_callee_saved(VMRegImpl::stack2reg(fpu_off + 1 + num_rt_args), fpu_name_0->next());\n-        }\n-        fpu_off += 2;\n-      }\n-      assert(fpu_off == fpu_state_off, \"incorrect number of fpu stack slots\");\n-\n-      if (UseSSE == 1) {\n-        int xmm_off = xmm_regs_as_doubles_off;\n-        for (int n = 0; n < FrameMap::nof_fpu_regs; n++) {\n-          VMReg xmm_name_0 = as_XMMRegister(n)->as_VMReg();\n-          map->set_callee_saved(VMRegImpl::stack2reg(xmm_off + num_rt_args), xmm_name_0);\n-          xmm_off += 2;\n-        }\n-        assert(xmm_off == float_regs_as_doubles_off, \"incorrect number of xmm registers\");\n-      }\n-    }\n-#endif \/\/ !LP64\n-\n@@ -429,1 +363,0 @@\n-#ifdef _LP64\n@@ -431,6 +364,0 @@\n-#else\n-  __ pusha();\n-#endif\n-\n-  \/\/ assert(float_regs_as_doubles_off % 2 == 0, \"misaligned offset\");\n-  \/\/ assert(xmm_regs_as_doubles_off % 2 == 0, \"misaligned offset\");\n@@ -445,40 +372,0 @@\n-#ifndef _LP64\n-    if (UseSSE < 2) {\n-      \/\/ save FPU stack\n-      __ fnsave(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));\n-      __ fwait();\n-\n-#ifdef ASSERT\n-      Label ok;\n-      __ cmpw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::x86::fpu_cntrl_wrd_std());\n-      __ jccb(Assembler::equal, ok);\n-      __ stop(\"corrupted control word detected\");\n-      __ bind(ok);\n-#endif\n-\n-      \/\/ Reset the control word to guard against exceptions being unmasked\n-      \/\/ since fstp_d can cause FPU stack underflow exceptions.  Write it\n-      \/\/ into the on stack copy and then reload that to make sure that the\n-      \/\/ current and future values are correct.\n-      __ movw(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size), StubRoutines::x86::fpu_cntrl_wrd_std());\n-      __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));\n-\n-      \/\/ Save the FPU registers in de-opt-able form\n-      int offset = 0;\n-      for (int n = 0; n < FrameMap::nof_fpu_regs; n++) {\n-        __ fstp_d(Address(rsp, float_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));\n-        offset += 8;\n-      }\n-\n-      if (UseSSE == 1) {\n-        \/\/ save XMM registers as float because double not supported without SSE2(num MMX == num fpu)\n-        int offset = 0;\n-        for (int n = 0; n < FrameMap::nof_fpu_regs; n++) {\n-          XMMRegister xmm_name = as_XMMRegister(n);\n-          __ movflt(Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset), xmm_name);\n-          offset += 8;\n-        }\n-      }\n-    }\n-#endif \/\/ !_LP64\n-\n@@ -500,3 +387,0 @@\n-\n-  \/\/ FPU stack must be empty now\n-  NOT_LP64( __ verify_FPU(0, \"save_live_registers\"); )\n@@ -509,1 +393,0 @@\n-#ifdef _LP64\n@@ -520,32 +403,0 @@\n-#else\n-  if (restore_fpu_registers) {\n-    if (UseSSE >= 2) {\n-      \/\/ restore XMM registers\n-      int xmm_bypass_limit = FrameMap::nof_xmm_regs;\n-      int offset = 0;\n-      for (int n = 0; n < xmm_bypass_limit; n++) {\n-        XMMRegister xmm_name = as_XMMRegister(n);\n-        __ movdbl(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));\n-        offset += 8;\n-      }\n-    } else if (UseSSE == 1) {\n-      \/\/ restore XMM registers(num MMX == num fpu)\n-      int offset = 0;\n-      for (int n = 0; n < FrameMap::nof_fpu_regs; n++) {\n-        XMMRegister xmm_name = as_XMMRegister(n);\n-        __ movflt(xmm_name, Address(rsp, xmm_regs_as_doubles_off * VMRegImpl::stack_slot_size + offset));\n-        offset += 8;\n-      }\n-    }\n-\n-    if (UseSSE < 2) {\n-      __ frstor(Address(rsp, fpu_state_off * VMRegImpl::stack_slot_size));\n-    } else {\n-      \/\/ check that FPU stack is really empty\n-      __ verify_FPU(0, \"restore_live_registers\");\n-    }\n-  } else {\n-    \/\/ check that FPU stack is really empty\n-    __ verify_FPU(0, \"restore_live_registers\");\n-  }\n-#endif \/\/ _LP64\n@@ -573,1 +424,0 @@\n-#ifdef _LP64\n@@ -575,4 +425,0 @@\n-#else\n-  __ popa();\n-#endif\n-\n@@ -587,1 +433,0 @@\n-#ifdef _LP64\n@@ -605,11 +450,0 @@\n-#else\n-\n-  __ pop(rdi);\n-  __ pop(rsi);\n-  __ pop(rbp);\n-  __ pop(rbx); \/\/ skip this value\n-  __ pop(rbx);\n-  __ pop(rdx);\n-  __ pop(rcx);\n-  __ addptr(rsp, BytesPerWord);\n-#endif \/\/ _LP64\n@@ -642,1 +476,0 @@\n-#ifdef _LP64\n@@ -644,4 +477,0 @@\n-#else\n-  Unimplemented();\n-  return 0;\n-#endif\n@@ -667,1 +496,0 @@\n-#ifdef _LP64\n@@ -670,6 +498,0 @@\n-#else\n-    __ movptr(temp_reg, Address(rbp, 3*BytesPerWord));\n-    __ push(temp_reg);\n-    __ movptr(temp_reg, Address(rbp, 2*BytesPerWord));\n-    __ push(temp_reg);\n-#endif \/\/ _LP64\n@@ -695,1 +517,1 @@\n-  const Register thread = NOT_LP64(rdi) LP64_ONLY(r15_thread);\n+  const Register thread = r15_thread;\n@@ -728,1 +550,1 @@\n-    const int frame_size = 2 \/*BP, return address*\/ NOT_LP64(+ 1 \/*thread*\/) WIN64_ONLY(+ frame::arg_reg_save_area_bytes \/ BytesPerWord);\n+    const int frame_size = 2 \/*BP, return address*\/ WIN64_ONLY(+ frame::arg_reg_save_area_bytes \/ BytesPerWord);\n@@ -737,7 +559,0 @@\n-#if !defined(_LP64) && defined(COMPILER2)\n-  if (UseSSE < 2 && !CompilerConfig::is_c1_only_no_jvmci()) {\n-    \/\/ C2 can leave the fpu stack dirty\n-    __ empty_FPU_stack();\n-  }\n-#endif \/\/ !_LP64 && COMPILER2\n-\n@@ -749,3 +564,0 @@\n-  \/\/ load address of JavaThread object for thread-local data\n-  NOT_LP64(__ get_thread(thread);)\n-\n@@ -818,1 +630,1 @@\n-  const Register exception_oop_callee_saved = NOT_LP64(rsi) LP64_ONLY(r14);\n+  const Register exception_oop_callee_saved = r14;\n@@ -822,1 +634,1 @@\n-  const Register thread = NOT_LP64(rdi) LP64_ONLY(r15_thread);\n+  const Register thread = r15_thread;\n@@ -837,1 +649,0 @@\n-  NOT_LP64(__ get_thread(thread);)\n@@ -851,3 +662,0 @@\n-  \/\/ clear the FPU stack in case any FPU results are left behind\n-  NOT_LP64( __ empty_FPU_stack(); )\n-\n@@ -858,1 +666,0 @@\n-  NOT_LP64(__ get_thread(thread);)\n@@ -908,1 +715,0 @@\n-#ifdef _LP64\n@@ -912,8 +718,1 @@\n-#else\n-  __ push(rax); \/\/ push dummy\n-\n-  const Register thread = rdi; \/\/ is callee-saved register (Visual C++ calling conventions)\n-  \/\/ push java thread (becomes first argument of C function)\n-  __ get_thread(thread);\n-  __ push(thread);\n-#endif \/\/ _LP64\n+\n@@ -939,4 +738,0 @@\n-#ifndef _LP64\n-  __ pop(rcx); \/\/ discard thread arg\n-  __ pop(rcx); \/\/ discard dummy\n-#endif \/\/ _LP64\n@@ -1169,1 +964,0 @@\n-#ifdef _LP64\n@@ -1172,6 +966,0 @@\n-#else\n-        \/\/ The object is passed on the stack and we haven't pushed a\n-        \/\/ frame yet so it's one work away from top of stack.\n-        __ movptr(rax, Address(rsp, 1 * BytesPerWord));\n-        __ verify_oop(rax);\n-#endif \/\/ _LP64\n@@ -1470,1 +1258,1 @@\n-        __ NOT_LP64(push(rax)) LP64_ONLY(mov(c_rarg0, rax));\n+        __ mov(c_rarg0, rax);\n@@ -1472,1 +1260,0 @@\n-        NOT_LP64(__ pop(rax));\n@@ -1480,1 +1267,0 @@\n-#ifdef _LP64\n@@ -1492,72 +1278,0 @@\n-#else\n-        \/\/ rax, and rdx are destroyed, but should be free since the result is returned there\n-        \/\/ preserve rsi,ecx\n-        __ push(rsi);\n-        __ push(rcx);\n-\n-        \/\/ check for NaN\n-        Label return0, do_return, return_min_jlong, do_convert;\n-\n-        Address value_high_word(rsp, wordSize + 4);\n-        Address value_low_word(rsp, wordSize);\n-        Address result_high_word(rsp, 3*wordSize + 4);\n-        Address result_low_word(rsp, 3*wordSize);\n-\n-        __ subptr(rsp, 32);                    \/\/ more than enough on 32bit\n-        __ fst_d(value_low_word);\n-        __ movl(rax, value_high_word);\n-        __ andl(rax, 0x7ff00000);\n-        __ cmpl(rax, 0x7ff00000);\n-        __ jcc(Assembler::notEqual, do_convert);\n-        __ movl(rax, value_high_word);\n-        __ andl(rax, 0xfffff);\n-        __ orl(rax, value_low_word);\n-        __ jcc(Assembler::notZero, return0);\n-\n-        __ bind(do_convert);\n-        __ fnstcw(Address(rsp, 0));\n-        __ movzwl(rax, Address(rsp, 0));\n-        __ orl(rax, 0xc00);\n-        __ movw(Address(rsp, 2), rax);\n-        __ fldcw(Address(rsp, 2));\n-        __ fwait();\n-        __ fistp_d(result_low_word);\n-        __ fldcw(Address(rsp, 0));\n-        __ fwait();\n-        \/\/ This gets the entire long in rax on 64bit\n-        __ movptr(rax, result_low_word);\n-        \/\/ testing of high bits\n-        __ movl(rdx, result_high_word);\n-        __ mov(rcx, rax);\n-        \/\/ What the heck is the point of the next instruction???\n-        __ xorl(rcx, 0x0);\n-        __ movl(rsi, 0x80000000);\n-        __ xorl(rsi, rdx);\n-        __ orl(rcx, rsi);\n-        __ jcc(Assembler::notEqual, do_return);\n-        __ fldz();\n-        __ fcomp_d(value_low_word);\n-        __ fnstsw_ax();\n-        __ sahf();\n-        __ jcc(Assembler::above, return_min_jlong);\n-        \/\/ return max_jlong\n-        __ movl(rdx, 0x7fffffff);\n-        __ movl(rax, 0xffffffff);\n-        __ jmp(do_return);\n-\n-        __ bind(return_min_jlong);\n-        __ movl(rdx, 0x80000000);\n-        __ xorl(rax, rax);\n-        __ jmp(do_return);\n-\n-        __ bind(return0);\n-        __ fpop();\n-        __ xorptr(rdx,rdx);\n-        __ xorptr(rax,rax);\n-\n-        __ bind(do_return);\n-        __ addptr(rsp, 32);\n-        __ pop(rcx);\n-        __ pop(rsi);\n-        __ ret(0);\n-#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":12,"deletions":298,"binary":false,"changes":310,"status":"modified"}]}