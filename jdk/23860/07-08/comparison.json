{"files":[{"patch":"@@ -57,0 +57,7 @@\n+const Register scratch = r10;\n+const XMMRegister montMulPerm = xmm28;\n+const XMMRegister montRSquareModQ = xmm29;\n+const XMMRegister montQInvModR = xmm30;\n+const XMMRegister dilithium_q = xmm31;\n+\n+\n@@ -120,1 +127,1 @@\n-    __ vpmulld(xmm(i + scratchReg2), xmm(i + scratchReg1), xmm30,\n+    __ vpmulld(xmm(i + scratchReg2), xmm(i + scratchReg1), montQInvModR,\n@@ -124,1 +131,1 @@\n-    __ vpmuldq(xmm(i + scratchReg2), xmm(i + scratchReg2), xmm31,\n+    __ vpmuldq(xmm(i + scratchReg2), xmm(i + scratchReg2), dilithium_q,\n@@ -156,1 +163,1 @@\n-    __ vpmulld(xmm(scratchRegs[i + 4]), xmm(scratchRegs[i]), xmm30,\n+    __ vpmulld(xmm(scratchRegs[i + 4]), xmm(scratchRegs[i]), montQInvModR,\n@@ -160,1 +167,1 @@\n-    __ vpmuldq(xmm(scratchRegs[i + 4]), xmm(scratchRegs[i + 4]), xmm31,\n+    __ vpmuldq(xmm(scratchRegs[i + 4]), xmm(scratchRegs[i + 4]), dilithium_q,\n@@ -182,1 +189,1 @@\n-    __ vpmulld(xmm(scratchRegs[i + 8]), xmm(scratchRegs[i]), xmm30,\n+    __ vpmulld(xmm(scratchRegs[i + 8]), xmm(scratchRegs[i]), montQInvModR,\n@@ -186,1 +193,1 @@\n-    __ vpmuldq(xmm(scratchRegs[i + 8]), xmm(scratchRegs[i + 8]), xmm31,\n+    __ vpmuldq(xmm(scratchRegs[i + 8]), xmm(scratchRegs[i + 8]), dilithium_q,\n@@ -195,1 +202,1 @@\n-    __ evpermt2d(xmm(outputRegs[i]), xmm28, xmm(scratchRegs[i + 4]),\n+    __ evpermt2d(xmm(outputRegs[i]), montMulPerm, xmm(scratchRegs[i + 4]),\n@@ -219,1 +226,1 @@\n-    __ evpermt2d(xmm(i), xmm28, xmm(i + 8), Assembler::AVX_512bit);\n+    __ evpermt2d(xmm(i), montMulPerm, xmm(i + 8), Assembler::AVX_512bit);\n@@ -237,0 +244,19 @@\n+static void loadZetas(int destinationRegs[], Register zetas,\n+                      int offset, int incr, MacroAssembler *_masm) {\n+  for (int i = 0; i < 4; i++) {\n+    __ evmovdqul(xmm(destinationRegs[i]), Address(zetas, offset + i * incr),\n+                 Assembler::AVX_512bit);\n+  }\n+}\n+\n+\n+static void loadPerm(int destinationRegs[], Register perms,\n+                      int offset, MacroAssembler *_masm) {\n+  __ evmovdqul(xmm(destinationRegs[0]), Address(perms, offset),\n+                 Assembler::AVX_512bit);\n+  for (int i = 1; i < 4; i++) {\n+      __ evmovdqul(xmm(destinationRegs[i]), xmm(destinationRegs[0]),\n+                   Assembler::AVX_512bit);\n+    }\n+}\n+\n@@ -263,1 +289,2 @@\n-static address generate_dilithiumAlmostNtt_avx512(StubGenerator *stubgen, MacroAssembler *_masm) {\n+static address generate_dilithiumAlmostNtt_avx512(StubGenerator *stubgen,\n+                                                  MacroAssembler *_masm) {\n@@ -275,1 +302,0 @@\n-\n@@ -278,1 +304,0 @@\n-  const Register dilithiumConsts = r10;\n@@ -282,1 +307,0 @@\n-  __ lea(dilithiumConsts, ExternalAddress(dilithiumAvx512ConstsAddr()));\n@@ -284,1 +308,1 @@\n-  __ evmovdqul(xmm28, Address(perms, 0), Assembler::AVX_512bit);\n+  __ evmovdqul(montMulPerm, Address(perms, 0), Assembler::AVX_512bit);\n@@ -286,2 +310,5 @@\n-  __ vpbroadcastd(xmm30, Address(dilithiumConsts, 0), Assembler::AVX_512bit); \/\/ q^-1 mod 2^32\n-  __ vpbroadcastd(xmm31, Address(dilithiumConsts, 4), Assembler::AVX_512bit); \/\/ q\n+  __ vpbroadcastd(montQInvModR, ExternalAddress(dilithiumAvx512ConstsAddr()),\n+                  Assembler::AVX_512bit, scratch); \/\/ q^-1 mod 2^32\n+  __ vpbroadcastd(dilithium_q, ExternalAddress(dilithiumAvx512ConstsAddr() + 4),\n+                  Assembler::AVX_512bit, scratch); \/\/ q\n+\n@@ -332,5 +359,1 @@\n-  __ evmovdqul(xmm12, Address(zetas, 1024), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, Address(zetas, 1088), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, Address(zetas, 1152), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, Address(zetas, 1216), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm12_15, zetas, 2 * 512, 64, _masm);\n@@ -338,5 +361,1 @@\n-\n-  __ evmovdqul(xmm12, Address(zetas, 1536), Assembler::AVX_512bit); \/\/ for level 3\n-  __ evmovdqul(xmm13, Address(zetas, 1600), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, Address(zetas, 1664), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, Address(zetas, 1728), Assembler::AVX_512bit);\n+  loadZetas(xmm12_15, zetas, 3 * 512, 64, _masm); \/\/ for level 3\n@@ -351,13 +370,3 @@\n-  __ evmovdqul(xmm16, Address(perms, 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm17, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm18, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm19, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n-\n-  __ evmovdqul(xmm24, Address(zetas, 4 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm25, Address(zetas, 4 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm26, Address(zetas, 4 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm27, Address(zetas, 4 * 512 + 192), Assembler::AVX_512bit);\n+  loadPerm(xmm16_19, perms, 64, _masm);\n+  loadPerm(xmm12_15, perms, 128, _masm);\n+  loadZetas(xmm24_27, zetas, 4 * 512, 64, _masm); \/\/ for level 3\n@@ -376,13 +385,3 @@\n-  __ evmovdqul(xmm16, Address(perms, 192), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm17, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm18, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm19, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 256), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n-\n-  __ evmovdqul(xmm24, Address(zetas, 5 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm25, Address(zetas, 5 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm26, Address(zetas, 5 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm27, Address(zetas, 5 * 512 + 192), Assembler::AVX_512bit);\n+  loadPerm(xmm16_19, perms, 192, _masm);\n+  loadPerm(xmm12_15, perms, 256, _masm);\n+  loadZetas(xmm24_27, zetas, 5 * 512, 64, _masm);\n@@ -401,13 +400,3 @@\n-  __ evmovdqul(xmm16, Address(perms, 320), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm17, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm18, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm19, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 384), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n-\n-  __ evmovdqul(xmm24, Address(zetas, 6 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm25, Address(zetas, 6 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm26, Address(zetas, 6 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm27, Address(zetas, 6 * 512 + 192), Assembler::AVX_512bit);\n+  loadPerm(xmm16_19, perms, 320, _masm);\n+  loadPerm(xmm12_15, perms, 384, _masm);\n+  loadZetas(xmm24_27, zetas, 6 * 512, 64, _masm);\n@@ -426,13 +415,3 @@\n-  __ evmovdqul(xmm16, Address(perms, 448), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm17, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm18, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm19, xmm16, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n-\n-  __ evmovdqul(xmm24, Address(zetas, 7 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm25, Address(zetas, 7 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm26, Address(zetas, 7 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm27, Address(zetas, 7 * 512 + 192), Assembler::AVX_512bit);\n+  loadPerm(xmm16_19, perms, 448, _masm);\n+  loadPerm(xmm12_15, perms, 512, _masm);\n+  loadZetas(xmm24_27, zetas, 7 * 512, 64, _masm);\n@@ -448,10 +427,2 @@\n-\n-  __ evmovdqul(xmm0, Address(perms, 576), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm2, xmm0, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm4, xmm0, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, xmm0, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm1, Address(perms, 640), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm3, xmm1, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, xmm1, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, xmm1, Assembler::AVX_512bit);\n-\n+  loadPerm(xmm0246, perms, 576, _masm);\n+  loadPerm(xmm1357, perms, 640, _masm);\n@@ -515,1 +486,0 @@\n-  const Register dilithiumConsts = r10;\n@@ -519,1 +489,0 @@\n-  __ lea(dilithiumConsts, ExternalAddress(dilithiumAvx512ConstsAddr()));\n@@ -521,3 +490,5 @@\n-  __ evmovdqul(xmm28, Address(perms, 0), Assembler::AVX_512bit);\n-  __ vpbroadcastd(xmm30, Address(dilithiumConsts, 0), Assembler::AVX_512bit); \/\/ q^-1 mod 2^32\n-  __ vpbroadcastd(xmm31, Address(dilithiumConsts, 4), Assembler::AVX_512bit); \/\/ q\n+  __ evmovdqul(montMulPerm, Address(perms, 0), Assembler::AVX_512bit);\n+__ vpbroadcastd(montQInvModR, ExternalAddress(dilithiumAvx512ConstsAddr()),\n+                Assembler::AVX_512bit, scratch); \/\/ q^-1 mod 2^32\n+__ vpbroadcastd(dilithium_q, ExternalAddress(dilithiumAvx512ConstsAddr() + 4),\n+                Assembler::AVX_512bit, scratch); \/\/ q\n@@ -538,8 +509,2 @@\n-  __ evmovdqul(xmm8, Address(perms, 704), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm9, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm10, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm11, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 768), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n+  loadPerm(xmm8_11, perms, 704, _masm);\n+  loadPerm(xmm12_15, perms, 768, _masm);\n@@ -552,5 +517,1 @@\n-  __ evmovdqul(xmm4, Address(zetas, 0), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, Address(zetas, 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, Address(zetas, 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, Address(zetas, 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm4_7, zetas, 0, 64, _masm);\n@@ -561,8 +522,2 @@\n-  __ evmovdqul(xmm8, Address(perms, 832), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm9, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm10, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm11, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 896), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n+  loadPerm(xmm8_11, perms, 832, _masm);\n+  loadPerm(xmm12_15, perms, 896, _masm);\n@@ -575,5 +530,1 @@\n-  __ evmovdqul(xmm4, Address(zetas, 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, Address(zetas, 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, Address(zetas, 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, Address(zetas, 512 + 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm4_7, zetas, 512, 64, _masm);\n@@ -584,8 +535,2 @@\n-  __ evmovdqul(xmm8, Address(perms, 960), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm9, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm10, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm11, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 1024), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n+  loadPerm(xmm8_11, perms, 960, _masm);\n+  loadPerm(xmm12_15, perms, 1024, _masm);\n@@ -598,5 +543,1 @@\n-  __ evmovdqul(xmm4, Address(zetas, 2 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, Address(zetas, 2 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, Address(zetas, 2 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, Address(zetas, 2 * 512 + 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm4_7, zetas, 2 * 512, 64, _masm);\n@@ -607,8 +548,2 @@\n-  __ evmovdqul(xmm8, Address(perms, 1088), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm9, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm10, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm11, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 1152), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n+  loadPerm(xmm8_11, perms, 1088, _masm);\n+  loadPerm(xmm12_15, perms, 1152, _masm);\n@@ -621,5 +556,1 @@\n-  __ evmovdqul(xmm4, Address(zetas, 3 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, Address(zetas, 3 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, Address(zetas, 3 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, Address(zetas, 3 * 512 + 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm4_7, zetas, 3 * 512, 64, _masm);\n@@ -630,8 +561,2 @@\n-  __ evmovdqul(xmm8, Address(perms, 1216), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm9, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm10, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm11, xmm8, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm12, Address(perms, 1280), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, xmm12, Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, xmm12, Assembler::AVX_512bit);\n+  loadPerm(xmm8_11, perms, 1216, _masm);\n+  loadPerm(xmm12_15, perms, 1280, _masm);\n@@ -643,4 +568,0 @@\n-  __ evmovdqul(xmm4, Address(zetas, 4 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm5, Address(zetas, 4 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm6, Address(zetas, 4 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm7, Address(zetas, 4 * 512 + 192), Assembler::AVX_512bit);\n@@ -648,0 +569,1 @@\n+  loadZetas(xmm4_7, zetas, 4 * 512, 64, _masm);\n@@ -652,5 +574,1 @@\n-  __ evmovdqul(xmm12, Address(zetas, 5 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, Address(zetas, 5 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, Address(zetas, 5 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, Address(zetas, 5 * 512 + 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm12_15, zetas, 5 * 512, 64, _masm);\n@@ -661,5 +579,1 @@\n-  __ evmovdqul(xmm12, Address(zetas, 6 * 512), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm13, Address(zetas, 6 * 512 + 64), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm14, Address(zetas, 6 * 512 + 128), Assembler::AVX_512bit);\n-  __ evmovdqul(xmm15, Address(zetas, 6 * 512 + 192), Assembler::AVX_512bit);\n-\n+  loadZetas(xmm12_15, zetas, 6 * 512, 64, _masm);\n@@ -669,4 +583,0 @@\n-  for (int i = 0; i < 4; i++) {\n-    __ evpermt2d(xmm(i + 4), xmm28, xmm(i + 20), Assembler::AVX_512bit);\n-  }\n-\n@@ -750,2 +660,1 @@\n-  const Register dilithiumConsts = c_rarg3; \/\/ not used for argument\n-  const Register perms = r10;\n+  const Register perms = r10; \/\/ scratch reused after not needed any more\n@@ -754,2 +663,6 @@\n-  __ lea(dilithiumConsts, ExternalAddress(dilithiumAvx512ConstsAddr()));\n-  __ lea(perms, ExternalAddress(dilithiumAvx512PermsAddr()));\n+  __ vpbroadcastd(montQInvModR, ExternalAddress(dilithiumAvx512ConstsAddr()),\n+                  Assembler::AVX_512bit, scratch); \/\/ q^-1 mod 2^32\n+  __ vpbroadcastd(dilithium_q, ExternalAddress(dilithiumAvx512ConstsAddr() + 4),\n+                  Assembler::AVX_512bit, scratch); \/\/ q\n+  __ vpbroadcastd(montRSquareModQ, ExternalAddress(dilithiumAvx512ConstsAddr() + 12),\n+                  Assembler::AVX_512bit, scratch); \/\/ 2^64 mod q\n@@ -757,4 +670,2 @@\n-  __ vpbroadcastd(xmm30, Address(dilithiumConsts, 0), Assembler::AVX_512bit); \/\/ q^-1 mod 2^32\n-  __ vpbroadcastd(xmm31, Address(dilithiumConsts, 4), Assembler::AVX_512bit); \/\/ q\n-  __ vpbroadcastd(xmm29, Address(dilithiumConsts, 12), Assembler::AVX_512bit); \/\/ 2^64 mod q\n-  __ evmovdqul(xmm28, Address(perms, 0), Assembler::AVX_512bit);\n+  __ lea(perms, ExternalAddress(dilithiumAvx512PermsAddr()));\n+  __ evmovdqul(montMulPerm, Address(perms, 0), Assembler::AVX_512bit);\n@@ -773,1 +684,0 @@\n-\n@@ -811,1 +721,1 @@\n-  const Register constant = c_rarg1;\n+  const Register rConstant = c_rarg1;\n@@ -814,2 +724,1 @@\n-  const Register dilithiumConsts = c_rarg3; \/\/ not used for argument\n-  const Register len = r10;\n+  const Register len = r11;\n@@ -817,2 +726,1 @@\n-  __ lea(dilithiumConsts, ExternalAddress(dilithiumAvx512ConstsAddr()));\n-  __ lea(perms, ExternalAddress(dilithiumAvx512PermsAddr()));\n+  const XMMRegister constant = xmm29;\n@@ -820,3 +728,1 @@\n-  __ vpbroadcastd(xmm30, Address(dilithiumConsts, 0), Assembler::AVX_512bit); \/\/ q^-1 mod 2^32\n-  __ vpbroadcastd(xmm31, Address(dilithiumConsts, 4), Assembler::AVX_512bit); \/\/ q\n-  __ evmovdqul(xmm28, Address(perms, 0), Assembler::AVX_512bit);\n+  __ lea(perms, ExternalAddress(dilithiumAvx512PermsAddr()));\n@@ -824,1 +730,7 @@\n-  __ evpbroadcastd(xmm29, constant, Assembler::AVX_512bit); \/\/ constant multiplier\n+  \/\/ the following four vector registers are used in montMulByConst128\n+  __ vpbroadcastd(montQInvModR, ExternalAddress(dilithiumAvx512ConstsAddr()),\n+                  Assembler::AVX_512bit, scratch); \/\/ q^-1 mod 2^32\n+  __ vpbroadcastd(dilithium_q, ExternalAddress(dilithiumAvx512ConstsAddr() + 4),\n+                  Assembler::AVX_512bit, scratch); \/\/ q\n+  __ evmovdqul(montMulPerm, Address(perms, 0), Assembler::AVX_512bit);\n+  __ evpbroadcastd(constant, rConstant, Assembler::AVX_512bit); \/\/ constant multiplier\n@@ -876,1 +788,1 @@\n-  const Register twoGamma2 = c_rarg3;\n+  const Register rTwoGamma2 = c_rarg3;\n@@ -878,14 +790,19 @@\n-  const Register len = c_rarg3; \/\/ len is used only after twoGamma2 is consumed\n-  const Register dilithiumConsts = r10;\n-  const Register tmp = r11;\n-\n-  __ lea(dilithiumConsts, ExternalAddress(dilithiumAvx512ConstsAddr()));\n-\n-  __ xorl(tmp, tmp);\n-  __ evpbroadcastd(xmm24, tmp, Assembler::AVX_512bit); \/\/ 0\n-  __ addl(tmp, 1);\n-  __ evpbroadcastd(xmm25, tmp, Assembler::AVX_512bit); \/\/ 1\n-  __ vpbroadcastd(xmm30, Address(dilithiumConsts, 4), Assembler::AVX_512bit); \/\/ q\n-  __ vpbroadcastd(xmm31, Address(dilithiumConsts, 16), Assembler::AVX_512bit); \/\/ addend for mod q reduce\n-\n-  __ evpbroadcastd(xmm28, twoGamma2, Assembler::AVX_512bit); \/\/ 2 * gamma2\n+  const Register len = r11;\n+  const XMMRegister zero = xmm24;\n+  const XMMRegister one = xmm25;\n+  const XMMRegister qMinus1 = xmm26;\n+  const XMMRegister gamma2 = xmm27;\n+  const XMMRegister twoGamma2 = xmm28;\n+  const XMMRegister barrettMultiplier = xmm29;\n+  const XMMRegister barrettAddend = xmm30;\n+\n+  __ xorl(scratch, scratch);\n+  __ evpbroadcastd(zero, scratch, Assembler::AVX_512bit); \/\/ 0\n+  __ addl(scratch, 1);\n+  __ evpbroadcastd(one, scratch, Assembler::AVX_512bit); \/\/ 1\n+  __ vpbroadcastd(dilithium_q, ExternalAddress(dilithiumAvx512ConstsAddr() + 4),\n+                  Assembler::AVX_512bit, scratch); \/\/ q^-1 mod 2^32\n+  __ vpbroadcastd(barrettAddend, ExternalAddress(dilithiumAvx512ConstsAddr() + 16),\n+                  Assembler::AVX_512bit, scratch); \/\/ q\n+\n+  __ evpbroadcastd(twoGamma2, rTwoGamma2, Assembler::AVX_512bit); \/\/ 2 * gamma2\n@@ -894,1 +811,1 @@\n-    const Register multiplier = c_rarg4;\n+    const Register rMultiplier = c_rarg4;\n@@ -897,1 +814,1 @@\n-    const Register multiplier = c_rarg3;\n+    const Register rMultiplier = c_rarg3;\n@@ -900,1 +817,2 @@\n-  __ evpbroadcastd(xmm29, multiplier, Assembler::AVX_512bit); \/\/ multiplier for mod 2 * gamma2 reduce\n+  __ evpbroadcastd(barrettMultiplier, rMultiplier,\n+                   Assembler::AVX_512bit); \/\/ multiplier for mod 2 * gamma2 reduce\n@@ -902,2 +820,2 @@\n-  __ evpsubd(xmm26, k0, xmm30, xmm25, false, Assembler::AVX_512bit); \/\/ q - 1\n-  __ evpsrad(xmm27, k0, xmm28, 1, false, Assembler::AVX_512bit); \/\/ gamma2\n+  __ evpsubd(qMinus1, k0, dilithium_q, one, false, Assembler::AVX_512bit); \/\/ q - 1\n+  __ evpsrad(gamma2, k0, twoGamma2, 1, false, Assembler::AVX_512bit); \/\/ gamma2\n@@ -919,4 +837,4 @@\n-  __ evpaddd(xmm4, k0, xmm0, xmm31, false, Assembler::AVX_512bit);\n-  __ evpaddd(xmm5, k0, xmm1, xmm31, false, Assembler::AVX_512bit);\n-  __ evpaddd(xmm6, k0, xmm2, xmm31, false, Assembler::AVX_512bit);\n-  __ evpaddd(xmm7, k0, xmm3, xmm31, false, Assembler::AVX_512bit);\n+  __ evpaddd(xmm4, k0, xmm0, barrettAddend, false, Assembler::AVX_512bit);\n+  __ evpaddd(xmm5, k0, xmm1, barrettAddend, false, Assembler::AVX_512bit);\n+  __ evpaddd(xmm6, k0, xmm2, barrettAddend, false, Assembler::AVX_512bit);\n+  __ evpaddd(xmm7, k0, xmm3, barrettAddend, false, Assembler::AVX_512bit);\n@@ -929,4 +847,4 @@\n-  __ evpmulld(xmm4, k0, xmm4, xmm30, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm5, k0, xmm5, xmm30, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm6, k0, xmm6, xmm30, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm7, k0, xmm7, xmm30, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm4, k0, xmm4, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm5, k0, xmm5, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm6, k0, xmm6, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm7, k0, xmm7, dilithium_q, false, Assembler::AVX_512bit);\n@@ -946,4 +864,4 @@\n-  __ evpandd(xmm4, k0, xmm4, xmm30, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm5, k0, xmm5, xmm30, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm6, k0, xmm6, xmm30, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm7, k0, xmm7, xmm30, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm4, k0, xmm4, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm5, k0, xmm5, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm6, k0, xmm6, dilithium_q, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm7, k0, xmm7, dilithium_q, false, Assembler::AVX_512bit);\n@@ -957,5 +875,5 @@\n-  \/\/ int quotient = (rplus * multiplier) >> 22;\n-  __ evpmulld(xmm4, k0, xmm0, xmm29, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm5, k0, xmm1, xmm29, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm6, k0, xmm2, xmm29, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm7, k0, xmm3, xmm29, false, Assembler::AVX_512bit);\n+  \/\/ int quotient = (rplus * barrettMultiplier) >> 22;\n+  __ evpmulld(xmm4, k0, xmm0, barrettMultiplier, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm5, k0, xmm1, barrettMultiplier, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm6, k0, xmm2, barrettMultiplier, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm7, k0, xmm3, barrettMultiplier, false, Assembler::AVX_512bit);\n@@ -970,4 +888,4 @@\n-  __ evpmulld(xmm8, k0, xmm4, xmm28, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm9, k0, xmm5, xmm28, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm10, k0, xmm6, xmm28, false, Assembler::AVX_512bit);\n-  __ evpmulld(xmm11, k0, xmm7, xmm28, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm8, k0, xmm4, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm9, k0, xmm5, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm10, k0, xmm6, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpmulld(xmm11, k0, xmm7, twoGamma2, false, Assembler::AVX_512bit);\n@@ -982,4 +900,4 @@\n-  __ evpsubd(xmm12, k0, xmm28, xmm8, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm13, k0, xmm28, xmm9, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm14, k0, xmm28, xmm10, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm15, k0, xmm28, xmm11, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm12, k0, twoGamma2, xmm8, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm13, k0, twoGamma2, xmm9, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm14, k0, twoGamma2, xmm10, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm15, k0, twoGamma2, xmm11, false, Assembler::AVX_512bit);\n@@ -994,4 +912,4 @@\n-  __ evpandd(xmm16, k0, xmm12, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm17, k0, xmm13, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm18, k0, xmm14, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm19, k0, xmm15, xmm28, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm16, k0, xmm12, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm17, k0, xmm13, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm18, k0, xmm14, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm19, k0, xmm15, twoGamma2, false, Assembler::AVX_512bit);\n@@ -1006,4 +924,4 @@\n-  __ evpandd(xmm16, k0, xmm12, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm17, k0, xmm13, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm18, k0, xmm14, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm19, k0, xmm15, xmm25, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm16, k0, xmm12, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm17, k0, xmm13, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm18, k0, xmm14, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm19, k0, xmm15, one, false, Assembler::AVX_512bit);\n@@ -1017,4 +935,4 @@\n-  __ evpsubd(xmm12, k0, xmm27, xmm8, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm13, k0, xmm27, xmm9, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm14, k0, xmm27, xmm10, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm15, k0, xmm27, xmm11, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm12, k0, gamma2, xmm8, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm13, k0, gamma2, xmm9, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm14, k0, gamma2, xmm10, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm15, k0, gamma2, xmm11, false, Assembler::AVX_512bit);\n@@ -1028,4 +946,4 @@\n-  __ evpandd(xmm16, k0, xmm12, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm17, k0, xmm13, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm18, k0, xmm14, xmm28, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm19, k0, xmm15, xmm28, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm16, k0, xmm12, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm17, k0, xmm13, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm18, k0, xmm14, twoGamma2, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm19, k0, xmm15, twoGamma2, false, Assembler::AVX_512bit);\n@@ -1040,4 +958,4 @@\n-  __ evpandd(xmm16, k0, xmm12, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm17, k0, xmm13, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm18, k0, xmm14, xmm25, false, Assembler::AVX_512bit);\n-  __ evpandd(xmm19, k0, xmm15, xmm25, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm16, k0, xmm12, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm17, k0, xmm13, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm18, k0, xmm14, one, false, Assembler::AVX_512bit);\n+  __ evpandd(xmm19, k0, xmm15, one, false, Assembler::AVX_512bit);\n@@ -1064,4 +982,4 @@\n-  __ evpsubd(xmm20, k0, xmm24, xmm16, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm21, k0, xmm24, xmm17, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm22, k0, xmm24, xmm18, false, Assembler::AVX_512bit);\n-  __ evpsubd(xmm23, k0, xmm24, xmm19, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm20, k0, zero, xmm16, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm21, k0, zero, xmm17, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm22, k0, zero, xmm18, false, Assembler::AVX_512bit);\n+  __ evpsubd(xmm23, k0, zero, xmm19, false, Assembler::AVX_512bit);\n@@ -1074,1 +992,1 @@\n-  __ evpsubd(xmm12, k0, xmm24, xmm25, false, Assembler::AVX_512bit); \/\/ -1\n+  __ evpsubd(xmm12, k0, zero, one, false, Assembler::AVX_512bit); \/\/ -1\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_dilithium.cpp","additions":176,"deletions":258,"binary":false,"changes":434,"status":"modified"}]}