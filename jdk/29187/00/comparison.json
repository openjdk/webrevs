{"files":[{"patch":"@@ -563,17 +563,52 @@\n-     * workers to scan for tasks.  SignalWork is invoked in two cases:\n-     * (1) When a task is pushed onto an empty queue, and (2) When a\n-     * worker takes a top-level task from a queue that has additional\n-     * tasks. Together, these suffice in O(log(#threads)) steps to\n-     * fully activate with at least enough workers, and ideally no\n-     * more than required.  This ideal is unobtainable: Callers do not\n-     * know whether another worker will finish its current task and\n-     * poll for others without need of a signal (which is otherwise an\n-     * advantage of work-stealing vs other schemes), and also must\n-     * conservatively estimate the triggering conditions of emptiness\n-     * or non-emptiness; all of which usually cause more activations\n-     * than necessary (see below). (Method signalWork is also used as\n-     * failsafe in case of Thread failures in deregisterWorker, to\n-     * activate or create a new worker to replace them).\n-     *\n-     * Top-Level scheduling\n-     * ====================\n+     * workers to scan for tasks.  Method signalWork and its callers\n+     * try to approximate the unattainable goal of having the right\n+     * number of workers activated for the tasks at hand, but must err\n+     * on the side of too many workers vs too few to avoid stalls:\n+     *\n+     *  * If computations are purely tree structured, it suffices for\n+     *    every worker to activate another when it pushes a task into\n+     *    an empty queue, resulting in O(log(#threads)) steps to full\n+     *    activation. Emptiness must be conservatively approximated,\n+     *    which may result in unnecessary signals.  Also, to reduce\n+     *    resource usages in some cases, at the expense of slower\n+     *    startup in others, activation of an idle thread is preferred\n+     *    over creating a new one, here and elsewhere.\n+     *\n+     *  * At the other extreme, if \"flat\" tasks (those that do not in\n+     *    turn generate others) come in serially from only a single\n+     *    producer, each worker taking a task from a queue should\n+     *    propagate a signal if there are more tasks in that\n+     *    queue. This is equivalent to, but generally faster than,\n+     *    arranging the stealer take multiple tasks, re-pushing one or\n+     *    more on its own queue, and signalling (because its queue is\n+     *    empty), also resulting in logarithmic full activation\n+     *    time. If tasks do not not engage in unbounded loops based on\n+     *    the actions of other workers with unknown dependencies loop,\n+     *    this form of proagation can be limited to one signal per\n+     *    activation (phase change). We distinguish the cases by\n+     *    further signalling only if the task is an InterruptibleTask\n+     *    (see below), which are the only supported forms of task that\n+     *    may do so.\n+     *\n+     * * Because we don't know about usage patterns (or most commonly,\n+     *    mixtures), we use both approaches, which present even more\n+     *    opportunities to over-signal. (Failure to distinguish these\n+     *    cases in terms of submission methods was arguably an early\n+     *    design mistake.)  Note that in either of these contexts,\n+     *    signals may be (and often are) unnecessary because active\n+     *    workers continue scanning after running tasks without the\n+     *    need to be signalled (which is one reason work stealing is\n+     *    often faster than alternatives), so additional workers\n+     *    aren't needed.\n+     *\n+     * * For rapidly branching tasks that require full pool resources,\n+     *   oversignalling is OK, because signalWork will soon have no\n+     *   more workers to create or reactivate. But for others (mainly\n+     *   externally submitted tasks), overprovisioning may cause very\n+     *   noticeable slowdowns due to contention and resource\n+     *   wastage. We reduce impact by deactivating workers when\n+     *   queues don't have accessible tasks, but reactivating and\n+     *   rescanning if other tasks remain.\n+     *\n+     * * Despite these, signal contention and overhead effects still\n+     *   occur during ramp-up and ramp-down of small computations.\n@@ -586,2 +621,2 @@\n-     * permutation on each rescan.  The pseudorandom generator need\n-     * not have high-quality statistical properties in the long\n+     * permutation on each invocation.  The pseudorandom generator\n+     * need not have high-quality statistical properties in the long\n@@ -589,1 +624,12 @@\n-     * from ThreadLocalRandom probes, which are cheap and suffice.\n+     * from ThreadLocalRandom probes, which are cheap and\n+     * suffice. Each queue's polling attempts to avoid becoming stuck\n+     * when other scanners\/pollers stall.  Scans do not otherwise\n+     * explicitly take into account core affinities, loads, cache\n+     * localities, etc, However, they do exploit temporal locality\n+     * (which usually approximates these) by preferring to re-poll\n+     * from the same queue after a successful poll before trying\n+     * others, which also reduces bookkeeping, cache traffic, and\n+     * scanning overhead. But it also reduces fairness, which is\n+     * partially counteracted by giving up on detected interference\n+     * (which also reduces contention when too many workers try to\n+     * take small tasks from the same queue).\n@@ -592,35 +638,8 @@\n-     * it invokes deactivate, that first deactivates (to an IDLE\n-     * phase).  Avoiding missed signals during deactivation requires a\n-     * (conservative) rescan, reactivating if there may be tasks to\n-     * poll. Because idle workers are often not yet blocked (parked),\n-     * we use a WorkQueue field to advertise that a waiter actually\n-     * needs unparking upon signal.\n-     *\n-     * When tasks are constructed as (recursive) DAGs, top-level\n-     * scanning is usually infrequent, and doesn't encounter most\n-     * of the following problems addressed by runWorker and awaitWork:\n-     *\n-     * Locality. Polls are organized into \"runs\", continuing until\n-     * empty or contended, while also minimizing interference by\n-     * postponing bookeeping to ends of runs. This may reduce\n-     * fairness.\n-     *\n-     * Contention. When many workers try to poll few queues, they\n-     * often collide, generating CAS failures and disrupting locality\n-     * of workers already running their tasks. This also leads to\n-     * stalls when tasks cannot be taken because other workers have\n-     * not finished poll operations, which is detected by reading\n-     * ahead in queue arrays. In both cases, workers restart scans in a\n-     * way that approximates randomized backoff.\n-     *\n-     * Oversignalling. When many short top-level tasks are present in\n-     * a small number of queues, the above signalling strategy may\n-     * activate many more workers than needed, worsening locality and\n-     * contention problems, while also generating more global\n-     * contention (field ctl is CASed on every activation and\n-     * deactivation). We filter out (both in runWorker and\n-     * signalWork) attempted signals that are surely not needed\n-     * because the signalled tasks are already taken.\n-     *\n-     * Shutdown and Quiescence\n-     * =======================\n+     * it tries to deactivate()), giving up (and rescanning) on \"ctl\"\n+     * contention. To avoid missed signals during deactivation, the\n+     * method rescans and reactivates if there may have been a missed\n+     * signal during deactivation. To reduce false-alarm reactivations\n+     * while doing so, we scan multiple times (analogously to method\n+     * quiescent()) before trying to reactivate.  Because idle workers\n+     * are often not yet blocked (parked), we use a WorkQueue field to\n+     * advertise that a waiter actually needs unparking upon signal.\n@@ -876,1 +895,3 @@\n-     * paths.\n+     * paths. The inability to rely on caller-runs may also require\n+     * extra signalling (resulting in scanning and contention) so is\n+     * done only conditionally in methods push and runworker.\n@@ -943,7 +964,3 @@\n-     * embedded @Contended isolates the very busy top index, along\n-     * with status and bookkeeping fields written (mostly) by owners,\n-     * that otherwise interfere with reading array and base\n-     * fields. There are other variables commonly contributing to\n-     * false-sharing-related performance issues (including fields of\n-     * class Thread), but we can't do much about this except try to\n-     * minimize access.\n+     * embedded @Contended region segregates fields most heavily\n+     * updated by owners from those most commonly read by stealers or\n+     * other management.\n@@ -958,5 +975,7 @@\n-     * Currently, arrays are initialized to be just large enough to\n-     * avoid resizing in most tree-structured tasks, but grow rapidly\n-     * until large.  (Maintenance note: any changes in fields, queues,\n-     * or their uses, or JVM layout policies, must be accompanied by\n-     * re-evaluation of these placement and sizing decisions.)\n+     * Currently, arrays for workers are initialized to be just large\n+     * enough to avoid resizing in most tree-structured tasks, but\n+     * larger for external queues where both false-sharing problems\n+     * and the need for resizing are more common. (Maintenance note:\n+     * any changes in fields, queues, or their uses, or JVM layout\n+     * policies, must be accompanied by re-evaluation of these\n+     * placement and sizing decisions.)\n@@ -1045,1 +1064,1 @@\n-     * Initial capacity of work-stealing queue array.\n+     * Initial capacity of work-stealing queue array for workers.\n@@ -1050,0 +1069,6 @@\n+    \/**\n+     * Initial capacity of work-stealing queue array for external queues.\n+     * Must be a power of two, at least 2. See above.\n+     *\/\n+    static final int INITIAL_EXTERNAL_QUEUE_CAPACITY = 1 << 9;\n+\n@@ -1189,2 +1214,0 @@\n-        volatile int parking;      \/\/ nonzero if parked in awaitWork\n-        @jdk.internal.vm.annotation.Contended(\"w\")\n@@ -1194,0 +1217,2 @@\n+        @jdk.internal.vm.annotation.Contended(\"w\")\n+        volatile int parking;      \/\/ nonzero if parked in awaitWork\n@@ -1226,0 +1251,4 @@\n+            array = new ForkJoinTask<?>[owner == null ?\n+                                        INITIAL_EXTERNAL_QUEUE_CAPACITY :\n+                                        INITIAL_QUEUE_CAPACITY];\n+            this.owner = owner;\n@@ -1227,4 +1256,0 @@\n-            if ((this.owner = owner) == null) {\n-                array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n-                phase = id | IDLE;\n-            }\n@@ -1257,4 +1282,5 @@\n-            int s = top, b = base, m, cap, room; ForkJoinTask<?>[] a, na;\n-            if ((a = array) != null && (cap = a.length) > 0) { \/\/ else disabled\n-                int k = (m = cap - 1) & s;\n-                if ((room = m - (s - b)) >= 0) {\n+            int s = top, b = base, m, cap, room; ForkJoinTask<?>[] a;\n+            if ((a = array) != null && (cap = a.length) > 0 && \/\/ else disabled\n+                task != null) {\n+                int pk = task.noUserHelp() + 1;             \/\/ prev slot offset\n+                if ((room = (m = cap - 1) - (s - b)) >= 0) {\n@@ -1262,1 +1288,1 @@\n-                    long pos = slotOffset(k);\n+                    long pos = slotOffset(m & s);\n@@ -1267,2 +1293,2 @@\n-                    if (room == 0 && (na = growArray(a, cap, s)) != null)\n-                        k = ((a = na).length - 1) & s;      \/\/ resize\n+                    if (room == 0)                          \/\/ resize\n+                        growArray(a, cap, s);\n@@ -1274,4 +1300,3 @@\n-                if (pool != null &&\n-                    (room == 0 ||\n-                     U.getReferenceAcquire(a, slotOffset(m & (s - 1))) == null))\n-                    pool.signalWork(a, k);    \/\/ may have appeared empty\n+                if ((room == 0 || U.getReferenceAcquire(a, slotOffset(m & (s - pk))) == null) &&\n+                    pool != null)\n+                    pool.signalWork();   \/\/ may have appeared empty\n@@ -1286,1 +1311,0 @@\n-         * @return new array, or null on failure\n@@ -1288,3 +1312,2 @@\n-        private ForkJoinTask<?>[] growArray(ForkJoinTask<?>[] a, int cap, int s) {\n-            int newCap = (cap >= 1 << 16) ? cap << 1 : cap << 2;\n-            ForkJoinTask<?>[] newArray = null;\n+        private void growArray(ForkJoinTask<?>[] a, int cap, int s) {\n+            int newCap = cap << 1;\n@@ -1292,0 +1315,1 @@\n+                ForkJoinTask<?>[] newArray = null;\n@@ -1308,1 +1332,0 @@\n-            return newArray;\n@@ -1312,1 +1335,3 @@\n-         * Takes next task, if one exists, in lifo order.\n+         * Takes next task, if one exists, in order specified by mode,\n+         * so acts as either local-pop or local-poll. Called only by owner.\n+         * @param fifo nonzero if FIFO mode\n@@ -1314,1 +1339,1 @@\n-        private ForkJoinTask<?> localPop() {\n+        private ForkJoinTask<?> nextLocalTask(int fifo) {\n@@ -1316,23 +1341,9 @@\n-            int s = top - 1, cap; long k; ForkJoinTask<?>[] a;\n-            if ((a = array) != null && (cap = a.length) > 0 &&\n-                U.getReference(a, k = slotOffset((cap - 1) & s)) != null &&\n-                (t = (ForkJoinTask<?>)U.getAndSetReference(a, k, null)) != null)\n-                updateTop(s);\n-            return t;\n-        }\n-\n-        \/**\n-         * Takes next task, if one exists, in fifo order.\n-         *\/\n-        private ForkJoinTask<?> localPoll() {\n-            ForkJoinTask<?> t = null;\n-            int p = top, cap; ForkJoinTask<?>[] a;\n-            if ((a = array) != null && (cap = a.length) > 0) {\n-                for (int b = base; p - b > 0; ) {\n-                    int nb = b + 1;\n-                    long k = slotOffset((cap - 1) & b);\n-                    if (U.getReference(a, k) == null) {\n-                        if (nb == p)\n-                            break;          \/\/ else base is lagging\n-                        while (b == (b = U.getIntAcquire(this, BASE)))\n-                            Thread.onSpinWait(); \/\/ spin to reduce memory traffic\n+            ForkJoinTask<?>[] a = array;\n+            int b = base, p = top, cap;\n+            if (p - b > 0 && a != null && (cap = a.length) > 0) {\n+                for (int m = cap - 1, s, nb;;) {\n+                    if (fifo == 0 || (nb = b + 1) == p) {\n+                        if ((t = (ForkJoinTask<?>)U.getAndSetReference(\n+                                 a, slotOffset(m & (s = p - 1)), null)) != null)\n+                            updateTop(s);       \/\/ else lost race for only task\n+                        break;\n@@ -1340,2 +1351,2 @@\n-                    else if ((t = (ForkJoinTask<?>)\n-                              U.getAndSetReference(a, k, null)) != null) {\n+                    if ((t = (ForkJoinTask<?>)U.getAndSetReference(\n+                             a, slotOffset(m & b), null)) != null) {\n@@ -1345,2 +1356,4 @@\n-                    else\n-                        b = base;\n+                    while (b == (b = U.getIntAcquire(this, BASE)))\n+                        Thread.onSpinWait();    \/\/ spin to reduce memory traffic\n+                    if (p - b <= 0)\n+                        break;\n@@ -1354,0 +1367,1 @@\n+         * (Always internal, never called for Common pool.)\n@@ -1356,1 +1370,1 @@\n-            return (config & FIFO) == 0 ? localPop() : localPoll();\n+            return nextLocalTask(config & FIFO);\n@@ -1432,1 +1446,1 @@\n-         * Runs the given task, as well as remaining local tasks\n+         * Runs the given task, as well as remaining local tasks.\n@@ -1437,1 +1451,1 @@\n-                task = (fifo != 0) ? localPoll() : localPop();\n+                task = nextLocalTask(fifo);\n@@ -1567,1 +1581,1 @@\n-            for (ForkJoinTask<?> t; (t = localPop()) != null; ) {\n+            for (ForkJoinTask<?> t; (t = nextLocalTask(0)) != null; ) {\n@@ -1769,2 +1783,1 @@\n-        if (w != null) {\n-            w.array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n+        if (w != null && (runState & STOP) == 0L) {\n@@ -1848,0 +1861,1 @@\n+            signalWork();                  \/\/ possibly replace\n@@ -1849,1 +1863,0 @@\n-            signalWork(null, 0);           \/\/ possibly replace\n@@ -1856,2 +1869,1 @@\n-     * Releases an idle worker, or creates one if not enough exist,\n-     * giving up if array a is nonnull and task at a[k] already taken.\n+     * Releases an idle worker, or creates one if not enough exist.\n@@ -1859,1 +1871,1 @@\n-    final void signalWork(ForkJoinTask<?>[] a, int k) {\n+    final void signalWork() {\n@@ -1875,1 +1887,1 @@\n-                nc = ((c + TC_UNIT) & TC_MASK) | ac;\n+                nc = ((c + TC_UNIT) & TC_MASK);\n@@ -1880,4 +1892,2 @@\n-                nc = (v.stackPred & LMASK) | (c & TC_MASK) | ac;\n-            if (a != null && k < a.length && k >= 0 && a[k] == null)\n-                break;\n-            if (c == (c = ctl) && c == (c = compareAndExchangeCtl(c, nc))) {\n+                nc = (v.stackPred & LMASK) | (c & TC_MASK);\n+            if (c == (c = compareAndExchangeCtl(c, nc | ac))) {\n@@ -1966,7 +1976,5 @@\n-        if (w != null && w.phase != 0) {                  \/\/ else unregistered\n-            WorkQueue[] qs;\n-            int r = w.stackPred;                          \/\/ seed from registerWorker\n-            int fifo = (int)config & FIFO, rescans = 0, inactive = 0, taken = 0, n;\n-            while ((runState & STOP) == 0L && (qs = queues) != null &&\n-                   (n = qs.length) > 0) {\n-                int i = r, step = (r >>> 16) | 1;\n+        if (w != null) {\n+            int phase = w.phase, r = w.stackPred;     \/\/ seed from registerWorker\n+            int fifo = w.config & FIFO, nsteals = 0, src = -1;\n+            for (;;) {\n+                WorkQueue[] qs;\n@@ -1974,6 +1982,10 @@\n-                scan: for (int j = n; j != 0; --j, i += step) {\n-                    WorkQueue q; int qid;\n-                    if ((q = qs[qid = i & (n - 1)]) != null) {\n-                        ForkJoinTask<?>[] a; int cap;     \/\/ poll queue\n-                        while ((a = q.array) != null && (cap = a.length) > 0) {\n-                            int b, nb, nk; long bp; ForkJoinTask<?> t;\n+                if ((runState & STOP) != 0L || (qs = queues) == null)\n+                    break;\n+                int n = qs.length, i = r, step = (r >>> 16) | 1;\n+                boolean rescan = false;\n+                scan: for (int l = n; l > 0; --l, i += step) {  \/\/ scan queues\n+                    int j, cap; WorkQueue q; ForkJoinTask<?>[] a;\n+                    if ((q = qs[j = i & (n - 1)]) != null &&\n+                        (a = q.array) != null && (cap = a.length) > 0) {\n+                        for (int m = cap - 1, pb = -1, b = q.base;;) {\n+                            ForkJoinTask<?> t; long k;\n@@ -1981,13 +1993,9 @@\n-                                a, bp = slotOffset((cap - 1) & (b = q.base)));\n-                            long np = slotOffset(nk = (nb = b + 1) & (cap - 1));\n-                            if (q.base == b) {            \/\/ else inconsistent\n-                                if (t == null) {\n-                                    if (q.array == a) {   \/\/ else resized\n-                                        if (rescans > 0)  \/\/ ran or stalled\n-                                            break scan;\n-                                        if (U.getReference(a, np) == null &&\n-                                            (rescans >= 0 ||\n-                                             (U.getReferenceAcquire(a, bp) == null &&\n-                                              q.top == q.base)))\n-                                            break;\n-                                        rescans = 1;      \/\/ may be stalled\n+                                a, k = slotOffset(m & b));\n+                            if (b != (b = q.base) || t == null ||\n+                                !U.compareAndSetReference(a, k, t, null)) {\n+                                if (a[b & m] == null) {\n+                                    if (rescan)           \/\/ end of run\n+                                        break scan;\n+                                    if (a[(b + 1) & m] == null &&\n+                                        a[(b + 2) & m] == null) {\n+                                        break;            \/\/ probably empty\n@@ -1995,4 +2003,2 @@\n-                                }\n-                                else if (inactive != 0) {\n-                                    if ((inactive = tryReactivate(w)) != 0) {\n-                                        rescans = 1;      \/\/ can't take yet\n+                                    if (pb == (pb = b)) { \/\/ track progress\n+                                        rescan = true;    \/\/ stalled; reorder scan\n@@ -2002,11 +2008,14 @@\n-                                else if (U.compareAndSetReference(a, bp, t, null)) {\n-                                    q.base = nb;\n-                                    Object nt = U.getReferenceAcquire(a, np);\n-                                    w.source = qid;\n-                                    rescans = 1;\n-                                    ++taken;\n-                                    if (nt != null &&     \/\/ confirm a[nk]\n-                                        U.getReferenceAcquire(a, np) == nt)\n-                                        signalWork(a, nk); \/\/ propagate\n-                                    w.topLevelExec(t, fifo);\n-                                }\n+                            }\n+                            else {\n+                                boolean propagate;\n+                                int nb = q.base = b + 1, prevSrc = src;\n+                                w.nsteals = ++nsteals;\n+                                w.source = src = j;       \/\/ volatile\n+                                rescan = true;\n+                                int nh = t.noUserHelp();\n+                                if (propagate =\n+                                    (prevSrc != src || nh != 0) && a[nb & m] != null)\n+                                    signalWork();\n+                                w.topLevelExec(t, fifo);\n+                                if ((b = q.base) != nb && !propagate)\n+                                    break scan;          \/\/ reduce interference\n@@ -2017,44 +2026,4 @@\n-                if (rescans >= 0)\n-                    --rescans;\n-                else if (inactive == 0) {\n-                    if ((inactive = deactivate(w, taken)) != 0)\n-                        taken = 0;\n-                }\n-                else if (awaitWork(w) == 0)\n-                    inactive = rescans = 0;\n-                else\n-                    break;\n-            }\n-        }\n-    }\n-\n-    \/**\n-     * Tries to deactivate worker, keeping active on contention\n-     *\n-     * @param w the work queue\n-     * @param taken number of stolen tasks since last deactivation\n-     * @return nonzero if inactive\n-     *\/\n-    private int deactivate(WorkQueue w, int taken) {\n-        int inactive = 0, phase;\n-        if (w != null && (inactive = (phase = w.phase) & IDLE) == 0) {\n-            long sp = (phase + (IDLE << 1)) & LMASK, pc, c;\n-            w.phase = phase | IDLE;\n-            w.stackPred = (int)(pc = ctl);    \/\/ set ctl stack link\n-            if (!compareAndSetCtl(            \/\/ try to enqueue\n-                    pc, c = ((pc - RC_UNIT) & UMASK) | sp))\n-                w.phase = phase;              \/\/ back out on contention\n-            else {\n-                if (taken != 0) {\n-                    w.nsteals += taken;\n-                    if ((w.config & CLEAR_TLS) != 0 &&\n-                        (Thread.currentThread() instanceof ForkJoinWorkerThread f))\n-                        f.resetThreadLocals(); \/\/ (instanceof check always true)\n-                }\n-                if (((c & RC_MASK) == 0L && quiescent() > 0) || taken == 0)\n-                    inactive = w.phase & IDLE; \/\/ check quiescent termination\n-                else {                         \/\/ spin for approx 1 scan cost\n-                    int tc = (short)(c >>> TC_SHIFT);\n-                    int spins = Math.max((tc << 1) + tc, SPIN_WAITS);\n-                    while ((inactive = w.phase & IDLE) != 0 && --spins != 0)\n-                        Thread.onSpinWait();\n+                if (!rescan) {\n+                    if (((phase = deactivate(w, phase)) & IDLE) != 0)\n+                        break;\n+                    src = -1;                            \/\/ re-enable propagation\n@@ -2064,1 +2033,0 @@\n-        return inactive;\n@@ -2068,1 +2036,1 @@\n-     * Reactivates worker w if it is currently top of ctl stack\n+     * Deactivates and if necessary awaits signal or termination.\n@@ -2070,2 +2038,3 @@\n-     * @param w the work queue\n-     * @return 0 if now active\n+     * @param w the worker\n+     * @param phase current phase\n+     * @return current phase, with IDLE set if worker should exit\n@@ -2073,10 +2042,29 @@\n-    private int tryReactivate(WorkQueue w) {\n-        int inactive = 0;\n-        if (w != null) {                         \/\/ always true; hoist checks\n-            int sp = w.stackPred, phase, activePhase; long c;\n-            if ((inactive = (phase = w.phase) & IDLE) != 0 &&\n-                (int)(c = ctl) == (activePhase = phase + IDLE) &&\n-                compareAndSetCtl(c, (sp & LMASK) | ((c + RC_UNIT) & UMASK))) {\n-                w.phase = activePhase;\n-                inactive = 0;\n-            }\n+    private int deactivate(WorkQueue w, int phase) {\n+        if (w == null)                        \/\/ currently impossible\n+            return IDLE;\n+        int p = phase | IDLE, activePhase = phase + (IDLE << 1);\n+        long pc = ctl, qc = (activePhase & LMASK) | ((pc - RC_UNIT) & UMASK);\n+        int sp = w.stackPred = (int)pc;       \/\/ set ctl stack link\n+        w.phase = p;\n+        if (!compareAndSetCtl(pc, qc))        \/\/ try to enqueue\n+            return w.phase = phase;           \/\/ back out on possible signal\n+        int ac = (short)(qc >>> RC_SHIFT), n; long e; WorkQueue[] qs;\n+        if (((e = runState) & STOP) != 0L ||\n+            ((e & SHUTDOWN) != 0L && ac == 0 && quiescent() > 0) ||\n+            (qs = queues) == null || (n = qs.length) <= 0)\n+            return IDLE;                      \/\/ terminating\n+\n+        for (int prechecks = Math.min(ac, 2), \/\/ reactivation threshold\n+             k = Math.max(n + (n << 1), SPIN_WAITS << 1);;) {\n+            WorkQueue q; int cap; ForkJoinTask<?>[] a; long c;\n+            if (w.phase == activePhase)\n+                return activePhase;\n+            if (--k < 0)\n+                return awaitWork(w, p);       \/\/ block, drop, or exit\n+            if ((q = qs[k & (n - 1)]) == null)\n+                Thread.onSpinWait();\n+            else if ((a = q.array) != null && (cap = a.length) > 0 &&\n+                     a[q.base & (cap - 1)] != null && --prechecks < 0 &&\n+                     (int)(c = ctl) == activePhase &&\n+                     compareAndSetCtl(c, (sp & LMASK) | ((c + RC_UNIT) & UMASK)))\n+                return w.phase = activePhase; \/\/ reactivate\n@@ -2084,1 +2072,0 @@\n-        return inactive;\n@@ -2091,1 +2078,2 @@\n-     * @return 0 if now active\n+     * @param p current phase (known to be idle)\n+     * @return current phase, with IDLE set if worker should exit\n@@ -2093,5 +2081,13 @@\n-    private int awaitWork(WorkQueue w) {\n-        int inactive = 0, phase;\n-        if (w != null) {                          \/\/ always true; hoist checks\n-            long waitTime = (w.source == INVALID_ID) ? 0L : keepAlive;\n-            if ((inactive = (phase = w.phase) & IDLE) != 0) {\n+    private int awaitWork(WorkQueue w, int p) {\n+        if (w != null) {\n+            ForkJoinWorkerThread t; long deadline;\n+            if ((w.config & CLEAR_TLS) != 0 && (t = w.owner) != null)\n+                t.resetThreadLocals();          \/\/ clear before reactivate\n+            if ((ctl & RC_MASK) > 0L)\n+                deadline = 0L;\n+            else if ((deadline =\n+                      (((w.source != INVALID_ID) ? keepAlive : TIMEOUT_SLOP)) +\n+                      System.currentTimeMillis()) == 0L)\n+                deadline = 1L;                 \/\/ avoid zero\n+            int activePhase = p + IDLE;\n+            if ((p = w.phase) != activePhase && (runState & STOP) == 0L) {\n@@ -2099,3 +2095,4 @@\n-                int activePhase = phase + IDLE;\n-                for (long deadline = 0L;;) {\n-                    Thread.interrupted();         \/\/ clear status\n+                w.parking = 1;                 \/\/ enable unpark\n+                while ((p = w.phase) != activePhase) {\n+                    boolean trimmable = false; int trim;\n+                    Thread.interrupted();      \/\/ clear status\n@@ -2104,13 +2101,7 @@\n-                    boolean trimmable = false;    \/\/ use timed wait if trimmable\n-                    long d = 0L, c;\n-                    if (((c = ctl) & RC_MASK) == 0L && (int)c == activePhase) {\n-                        long now = System.currentTimeMillis();\n-                        if (deadline == 0L)\n-                            deadline = waitTime + now;\n-                        if (deadline - now <= TIMEOUT_SLOP) {\n-                            if (tryTrim(w, c, activePhase))\n-                                break;\n-                            continue;             \/\/ lost race to trim\n-                        }\n-                        d = deadline;\n-                        trimmable = true;\n+                    if (deadline != 0L) {\n+                        if ((trim = tryTrim(w, p, deadline)) > 0)\n+                            break;\n+                        else if (trim < 0)\n+                            deadline = 0L;\n+                        else\n+                            trimmable = true;\n@@ -2118,6 +2109,1 @@\n-                    w.parking = 1;                \/\/ enable unpark and recheck\n-                    if ((inactive = w.phase & IDLE) != 0)\n-                        U.park(trimmable, d);\n-                    w.parking = 0;                \/\/ close unpark window\n-                    if (inactive == 0 || (inactive = w.phase & IDLE) == 0)\n-                        break;\n+                    U.park(trimmable, deadline);\n@@ -2125,0 +2111,1 @@\n+                w.parking = 0;\n@@ -2128,1 +2115,1 @@\n-        return inactive;\n+        return p;\n@@ -2133,1 +2120,2 @@\n-     * another to do the same unless new tasks are found.\n+     * another to do the same.\n+     * @return > 0: trimmed, < 0 : not trimmable, else 0\n@@ -2135,18 +2123,22 @@\n-    private boolean tryTrim(WorkQueue w, long c, int activePhase) {\n-        if (w != null) {\n-            int vp, i; WorkQueue[] vs; WorkQueue v;\n-            long nc = ((w.stackPred & LMASK) |\n-                       ((RC_MASK & c) | (TC_MASK & (c - TC_UNIT))));\n-            if (compareAndSetCtl(c, nc)) {\n-                w.source = DROPPED;\n-                w.phase = activePhase;\n-                if ((vp = (int)nc) != 0 && (vs = queues) != null &&\n-                    vs.length > (i = vp & SMASK) && (v = vs[i]) != null &&\n-                    compareAndSetCtl(           \/\/ try to wake up next waiter\n-                        nc, ((v.stackPred & LMASK) |\n-                             ((UMASK & (nc + RC_UNIT)) | (nc & TC_MASK))))) {\n-                    v.source = INVALID_ID;      \/\/ enable cascaded timeouts\n-                    v.phase = vp;\n-                    U.unpark(v.owner);\n-                }\n-                return true;\n+    private int tryTrim(WorkQueue w, int phase, long deadline) {\n+        long c, nc; int stat, activePhase, vp, i; WorkQueue[] vs; WorkQueue v;\n+        if ((activePhase = phase + IDLE) != (int)(c = ctl) || w == null)\n+            stat = -1;                      \/\/ no longer ctl top\n+        else if (deadline - System.currentTimeMillis() >= TIMEOUT_SLOP)\n+            stat = 0;                       \/\/ spurious wakeup\n+        else if (!compareAndSetCtl(\n+                     c, nc = ((w.stackPred & LMASK) | (RC_MASK & c) |\n+                               (TC_MASK & (c - TC_UNIT)))))\n+            stat = -1;                      \/\/ lost race to signaller\n+        else {\n+            stat = 1;\n+            w.source = DROPPED;\n+            w.phase = activePhase;\n+            if ((vp = (int)nc) != 0 && (vs = queues) != null &&\n+                vs.length > (i = vp & SMASK) && (v = vs[i]) != null &&\n+                compareAndSetCtl(           \/\/ try to wake up next waiter\n+                    nc, ((UMASK & (nc + RC_UNIT)) |\n+                         (nc & TC_MASK) | (v.stackPred & LMASK)))) {\n+                v.source = INVALID_ID;      \/\/ enable cascaded timeouts\n+                v.phase = vp;\n+                U.unpark(v.owner);\n@@ -2155,1 +2147,1 @@\n-        return false;\n+        return stat;\n@@ -2572,1 +2564,2 @@\n-     * throws RejectedExecutionException if shutdown\n+     * throws RejectedExecutionException if shutdown or terminating.\n+     * @param r current ThreadLocalRandom.getProbe() value\n@@ -2574,1 +2567,1 @@\n-     *        should be thrown when shutdown\n+     *        should be thrown when shutdown (else only if terminating)\n@@ -2576,4 +2569,4 @@\n-    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n-        int r;\n-        if ((r = ThreadLocalRandom.getProbe()) == 0) {\n-            ThreadLocalRandom.localInit();   \/\/ initialize caller's probe\n+    private WorkQueue submissionQueue(int r, boolean rejectOnShutdown) {\n+        int reuse;                                   \/\/ nonzero if prefer create\n+        if ((reuse = r) == 0) {\n+            ThreadLocalRandom.localInit();           \/\/ initialize caller's probe\n@@ -2582,3 +2575,5 @@\n-        for (;;) {\n-            WorkQueue q; WorkQueue[] qs; int n, id, i;\n-            if ((qs = queues) == null || (n = qs.length) <= 0)\n+        for (int probes = 0; ; ++probes) {\n+            int n, i, id; WorkQueue[] qs; WorkQueue q;\n+            if ((qs = queues) == null)\n+                break;\n+            if ((n = qs.length) <= 0)\n@@ -2587,4 +2582,6 @@\n-                WorkQueue newq = new WorkQueue(null, id, 0, false);\n-                lockRunState();\n-                if (qs[i] == null && queues == qs)\n-                    q = qs[i] = newq;         \/\/ else lost race to install\n+                WorkQueue w = new WorkQueue(null, id, 0, false);\n+                w.phase = id;\n+                boolean reject = ((lockRunState() & SHUTDOWN) != 0 &&\n+                                  rejectOnShutdown);\n+                if (!reject && queues == qs && qs[i] == null)\n+                    q = qs[i] = w;                   \/\/ else lost race to install\n@@ -2592,4 +2589,3 @@\n-            }\n-            if (q != null && q.tryLockPhase()) {\n-                if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n-                    q.unlockPhase();          \/\/ check while q lock held\n+                if (q != null)\n+                    return q;\n+                if (reject)\n@@ -2597,0 +2593,6 @@\n+                reuse = 0;\n+            }\n+            if (reuse == 0 || !q.tryLockPhase()) {   \/\/ move index\n+                if (reuse == 0) {\n+                    if (probes >= n >> 1)\n+                        reuse = r;                   \/\/ stop prefering free slot\n@@ -2598,1 +2600,7 @@\n-                return q;\n+                else if (q != null)\n+                    reuse = 0;                       \/\/ probe on collision\n+                r = ThreadLocalRandom.advanceProbe(r);\n+            }\n+            else if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n+                q.unlockPhase();                     \/\/ check while q lock held\n+                break;\n@@ -2600,1 +2608,2 @@\n-            r = ThreadLocalRandom.advanceProbe(r); \/\/ move\n+            else\n+                return q;\n@@ -2614,1 +2623,1 @@\n-            q = externalSubmissionQueue(true);\n+            q = submissionQueue(ThreadLocalRandom.getProbe(), true);\n@@ -2620,0 +2629,12 @@\n+    \/**\n+     * Returns queue for an external submission, bypassing call to\n+     * submissionQueue if already established and unlocked.\n+     *\/\n+    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n+        WorkQueue[] qs; WorkQueue q; int n;\n+        int r = ThreadLocalRandom.getProbe();\n+        return (((qs = queues) != null && (n = qs.length) > 0 &&\n+                 (q = qs[r & EXTERNAL_ID_MASK & (n - 1)]) != null && r != 0 &&\n+                 q.tryLockPhase()) ? q : submissionQueue(r, rejectOnShutdown));\n+    }\n+\n@@ -3292,1 +3313,0 @@\n-        int prevSize;\n@@ -3297,3 +3317,1 @@\n-        if ((prevSize = getAndSetParallelism(size)) < size)\n-            signalWork(null, 0); \/\/ trigger worker activation\n-        return prevSize;\n+        return getAndSetParallelism(size);\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":326,"deletions":308,"binary":false,"changes":634,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-import java.util.concurrent.ForkJoinTask;\n@@ -46,1 +45,1 @@\n-    static void testSubmitExternalCallable() throws Exception {\n+    public static void main(String[] args) throws Exception {\n@@ -57,17 +56,0 @@\n-\n-    static void testSubmitAdaptedCallable() throws Exception {\n-        try (var pool = new ForkJoinPool(2)) {\n-            for (int i = 0; i < 100_000; i++) {\n-                var future1 = pool.submit(new AwaitCount(i));\n-                var future2 = pool.submit(ForkJoinTask.adapt(noop));\n-                future2.get();\n-                count.set(i + 1);\n-                future1.get();\n-            }\n-        }\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        testSubmitExternalCallable();\n-        testSubmitAdaptedCallable();\n-    }\n","filename":"test\/jdk\/java\/util\/concurrent\/forkjoin\/Starvation.java","additions":1,"deletions":19,"binary":false,"changes":20,"status":"modified"}]}