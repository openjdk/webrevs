{"files":[{"patch":"@@ -253,1 +253,1 @@\n-    _selected = new ObjectValue(id());\n+    _selected = new ObjectValue(id(), nullptr, false);\n@@ -259,2 +259,1 @@\n-    \/\/ No need to rematerialize\n-    return nullptr;\n+    return _selected;\n","filename":"src\/hotspot\/share\/code\/debugInfo.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -136,0 +136,2 @@\n+  bool                       _was_scalar_replaced;     \/\/ Whether this ObjectValue describes an object scalar replaced or just\n+                                                       \/\/ an object (possibly null) participating in an allocation merge.\n@@ -141,1 +143,1 @@\n-  ObjectValue(int id, ScopeValue* klass)\n+  ObjectValue(int id, ScopeValue* klass = nullptr, bool was_scalar_replaced = true)\n@@ -147,0 +149,1 @@\n+     , _was_scalar_replaced(was_scalar_replaced)\n@@ -148,1 +151,1 @@\n-    assert(klass->is_constant_oop(), \"should be constant java mirror oop\");\n+    assert(klass == nullptr || klass->is_constant_oop(), \"should be constant java mirror oop\");\n@@ -151,8 +154,0 @@\n-  ObjectValue(int id)\n-     : _id(id)\n-     , _klass(nullptr)\n-     , _field_values()\n-     , _value()\n-     , _visited(false)\n-     , _is_root(true) {}\n-\n@@ -168,0 +163,1 @@\n+  bool was_scalar_replaced() const { return _was_scalar_replaced; }\n@@ -173,0 +169,1 @@\n+  void                        set_was_scalar_replaced(bool scd) { _was_scalar_replaced = scd; }\n@@ -211,1 +208,1 @@\n-     : ObjectValue(id)\n+     : ObjectValue(id, nullptr, false)\n@@ -218,1 +215,1 @@\n-     : ObjectValue(id)\n+     : ObjectValue(id, nullptr, false)\n","filename":"src\/hotspot\/share\/code\/debugInfo.hpp","additions":9,"deletions":12,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -151,3 +151,3 @@\n-      \/\/ If select() returns nullptr, then the object doesn't need to be\n-      \/\/ rematerialized.\n-      if (sv == nullptr) {\n+      \/\/ 'select(...)' may return an ObjectValue that actually represents a\n+      \/\/ non-scalar replaced object participating in a merge.\n+      if (!sv->was_scalar_replaced()) {\n","filename":"src\/hotspot\/share\/code\/scopeDesc.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -183,0 +183,1 @@\n+    init_class_id(Class_CastPP);\n","filename":"src\/hotspot\/share\/opto\/castnode.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -43,0 +43,2 @@\n+#include \"opto\/narrowptrnode.hpp\"\n+#include \"opto\/castnode.hpp\"\n@@ -413,8 +415,11 @@\n-  \/\/ 6. Remove reducible allocation merges from ideal graph\n-  if (reducible_merges.size() > 0) {\n-    bool delay = _igvn->delay_transform();\n-    _igvn->set_delay_transform(true);\n-    for (uint i = 0; i < reducible_merges.size(); i++ ) {\n-      Node* n = reducible_merges.at(i);\n-      reduce_phi(n->as_Phi());\n-      if (C->failing()) {\n+  \/\/ 6. Reduce allocation merges used as debug information. This is done after\n+  \/\/ split_unique_types because the methods used to create SafePointScalarObject\n+  \/\/ need to traverse the memory graph to find values for object fields. We also\n+  \/\/ set to null the scalarized inputs of reducible Phis so that the Allocate\n+  \/\/ that they point can be later scalar replaced.\n+  bool delay = _igvn->delay_transform();\n+  _igvn->set_delay_transform(true);\n+  for (uint i = 0; i < reducible_merges.size(); i++) {\n+    Node* n = reducible_merges.at(i);\n+    if (n->outcnt() > 0) {\n+      if (!reduce_phi_on_safepoints(n->as_Phi())) {\n@@ -422,0 +427,1 @@\n+        C->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n@@ -424,0 +430,4 @@\n+\n+      \/\/ Now we set the scalar replaceable inputs of ophi to null, which is\n+      \/\/ the last piece that would prevent it from being scalar replaceable.\n+      reset_scalar_replaceable_entries(n->as_Phi());\n@@ -425,1 +435,0 @@\n-    _igvn->set_delay_transform(delay);\n@@ -427,0 +436,1 @@\n+  _igvn->set_delay_transform(delay);\n@@ -451,2 +461,1 @@\n-\/\/ if at least one scalar replaceable allocation participates in the merge and\n-\/\/ no input to the Phi is nullable.\n+\/\/ if at least one scalar replaceable allocation participates in the merge.\n@@ -454,1 +463,0 @@\n-  \/\/ Check if there is a scalar replaceable allocate in the Phi\n@@ -458,8 +466,0 @@\n-    \/\/ Right now we can't restore a \"null\" pointer during deoptimization\n-    const Type* inp_t = _igvn->type(ophi->in(i));\n-    if (inp_t == nullptr || inp_t->make_oopptr() == nullptr || inp_t->make_oopptr()->maybe_null()) {\n-      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Input %d is nullable.\", ophi->_idx, _invocation, i);)\n-      return false;\n-    }\n-\n-    \/\/ We are looking for at least one SR object in the merge\n@@ -471,0 +471,5 @@\n+      \/\/ Don't handle arrays.\n+      if (alloc->Opcode() != Op_Allocate) {\n+        continue;\n+      }\n+\n@@ -474,0 +479,1 @@\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"%dth input of Phi %d is SR but can't be eliminated.\", i, ophi->_idx);)\n@@ -483,5 +489,42 @@\n-\/\/ Check if we are able to untangle the merge. Right now we only reduce Phis\n-\/\/ which are only used as debug information.\n-bool ConnectionGraph::can_reduce_phi_check_users(PhiNode* ophi) const {\n-  for (DUIterator_Fast imax, i = ophi->fast_outs(imax); i < imax; i++) {\n-    Node* use = ophi->fast_out(i);\n+\/\/ We can reduce the Cmp if it's a comparison between the Phi and a constant.\n+\/\/ I require the 'other' input to be a constant so that I can move the Cmp\n+\/\/ around safely.\n+bool ConnectionGraph::can_reduce_cmp(Node* n, Node* cmp) const {\n+  Node* left = cmp->in(1);\n+  Node* right = cmp->in(2);\n+\n+  return (cmp->Opcode() == Op_CmpP || cmp->Opcode() == Op_CmpN) &&\n+         (left == n || right == n) &&\n+         (left->is_Con() || right->is_Con()) &&\n+         cmp->outcnt() == 1;\n+}\n+\n+\/\/ We are going to check if any of the SafePointScalarMerge entries\n+\/\/ in the SafePoint reference the Phi that we are checking.\n+bool ConnectionGraph::has_been_reduced(PhiNode* n, SafePointNode* sfpt) const {\n+  JVMState *jvms = sfpt->jvms();\n+\n+  for (uint i = jvms->debug_start(); i < jvms->debug_end(); i++) {\n+    Node* sfpt_in = sfpt->in(i);\n+    if (sfpt_in->is_SafePointScalarMerge()) {\n+      SafePointScalarMergeNode* smerge = sfpt_in->as_SafePointScalarMerge();\n+      Node* nsr_ptr = sfpt->in(smerge->merge_pointer_idx(jvms));\n+      if (nsr_ptr == n) {\n+        return true;\n+      }\n+    }\n+  }\n+\n+  return false;\n+}\n+\n+\/\/ Check if we are able to untangle the merge. The following patterns are\n+\/\/ supported:\n+\/\/  - Phi -> SafePoints\n+\/\/  - Phi -> CmpP\/N\n+\/\/  - Phi -> AddP -> Load\n+\/\/  - Phi -> CastPP -> SafePoints\n+\/\/  - Phi -> CastPP -> AddP -> Load\n+bool ConnectionGraph::can_reduce_check_users(Node* n, uint nesting) const {\n+  for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+    Node* use = n->fast_out(i);\n@@ -490,2 +533,5 @@\n-      if (use->is_Call() && use->as_Call()->has_non_debug_use(ophi)) {\n-        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Call has non_debug_use().\", ophi->_idx, _invocation);)\n+      if (use->is_Call() && use->as_Call()->has_non_debug_use(n)) {\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Call has non_debug_use().\", n->_idx, _invocation);)\n+        return false;\n+      } else if (has_been_reduced(n->is_Phi() ? n->as_Phi() : n->as_CastPP()->in(1)->as_Phi(), use->as_SafePoint())) {\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. It has already been reduced.\", n->_idx, _invocation);)\n@@ -498,0 +544,2 @@\n+        const Type* load_type = _igvn->type(use_use);\n+\n@@ -499,1 +547,4 @@\n-          NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. AddP user isn't a [splittable] Load(): %s\", ophi->_idx, _invocation, use_use->Name());)\n+          NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. AddP user isn't a [splittable] Load(): %s\", n->_idx, _invocation, use_use->Name());)\n+          return false;\n+        } else if (nesting > 0 && load_type->isa_narrowklass()) {\n+          NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Nested NarrowKlass Load: %s\", n->_idx, _invocation, use_use->Name());)\n@@ -503,0 +554,34 @@\n+    } else if (nesting > 0) {\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Unsupported user %s at nesting level %d.\", n->_idx, _invocation, use->Name(), nesting);)\n+      return false;\n+    } else if (use->is_CastPP()) {\n+      const Type* cast_t = _igvn->type(use);\n+      if (cast_t == nullptr || cast_t->make_ptr()->isa_instptr() == nullptr) {\n+        NOT_PRODUCT(use->dump();)\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. CastPP is not to an instance.\", n->_idx, _invocation);)\n+        return false;\n+      }\n+\n+      bool is_trivial_control = use->in(0) == nullptr || use->in(0) == n->in(0);\n+      if (!is_trivial_control) {\n+        \/\/ If it's not a trivial control then we check if we can reduce the\n+        \/\/ CmpP\/N used by the If controlling the cast.\n+        if (use->in(0)->is_IfTrue() || use->in(0)->is_IfFalse()) {\n+          Node* iff = use->in(0)->in(0);\n+          Node* iff_cmp = iff->in(1)->in(1); \/\/ if->bool->cmp\n+          if (!can_reduce_cmp(n, iff_cmp)) {\n+            NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. CastPP %d doesn't have simple control.\", n->_idx, _invocation, use->_idx);)\n+            NOT_PRODUCT(n->dump(5);)\n+            return false;\n+          }\n+        }\n+      }\n+\n+      if (!can_reduce_check_users(use, nesting+1)) {\n+        return false;\n+      }\n+    } else if (use->Opcode() == Op_CmpP || use->Opcode() == Op_CmpN) {\n+      if (!can_reduce_cmp(n, use)) {\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. CmpP\/N %d isn't reducible.\", n->_idx, _invocation, use->_idx);)\n+        return false;\n+      }\n@@ -504,1 +589,1 @@\n-      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. One of the uses is: %d %s\", ophi->_idx, _invocation, use->_idx, use->Name());)\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. One of the uses is: %d %s\", n->_idx, _invocation, use->_idx, use->Name());)\n@@ -520,2 +605,1 @@\n-  \/\/ If EliminateAllocations is False, there is no point in reducing merges.\n-  if (!_compile->do_reduce_allocation_merges()) {\n+  if (!_compile->do_reduce_allocation_merges() || ophi->region()->Opcode() != Op_Region) {\n@@ -526,4 +610,3 @@\n-  if (phi_t == nullptr || phi_t->make_ptr() == nullptr ||\n-                          phi_t->make_ptr()->isa_instptr() == nullptr ||\n-                          !phi_t->make_ptr()->isa_instptr()->klass_is_exact()) {\n-    NOT_PRODUCT(if (TraceReduceAllocationMerges) { tty->print_cr(\"Can NOT reduce Phi %d during invocation %d because it's nullable.\", ophi->_idx, _invocation); })\n+  if (phi_t == nullptr ||\n+      phi_t->make_ptr() == nullptr ||\n+      phi_t->make_ptr()->isa_aryptr() != nullptr) {\n@@ -533,1 +616,1 @@\n-  if (!can_reduce_phi_check_inputs(ophi) || !can_reduce_phi_check_users(ophi)) {\n+  if (!can_reduce_phi_check_inputs(ophi) || !can_reduce_check_users(ophi, \/* nesting: *\/ 0)) {\n@@ -541,11 +624,19 @@\n-void ConnectionGraph::reduce_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist) {\n-  \/\/ We'll pass this to 'split_through_phi' so that it'll do the split even\n-  \/\/ though the load doesn't have an unique instance type.\n-  bool ignore_missing_instance_id = true;\n-\n-#ifdef ASSERT\n-  if (VerifyReduceAllocationMerges && !can_reduce_phi(ophi)) {\n-    TraceReduceAllocationMerges = true;\n-    ophi->dump(2);\n-    ophi->dump(-2);\n-    assert(can_reduce_phi(ophi), \"Sanity: previous reducible Phi is no longer reducible inside reduce_phi_on_field_access.\");\n+\/\/ This method will return a CmpP\/N that we need to use on the If controlling a\n+\/\/ CastPP after it was split. This method is only called on bases that are\n+\/\/ nullable therefore we always need a controlling if for the splitted CastPP.\n+\/\/\n+\/\/ 'curr_ctrl' is the control of the CastPP that we want to split through phi.\n+\/\/ If the CastPP currently doesn't have a control then the CmpP\/N will be\n+\/\/ against the NULL constant, otherwise it will be against the constant input of\n+\/\/ the existing CmpP\/N. It's guaranteed that there will be a CmpP\/N in the later\n+\/\/ case because we have constraints on it and because the CastPP has a control\n+\/\/ input.\n+Node* ConnectionGraph::specialize_cmp(Node* base, Node* curr_ctrl) {\n+  const Type* t = base->bottom_type();\n+  Node* con = nullptr;\n+\n+  if (curr_ctrl == nullptr || curr_ctrl->is_Region()) {\n+    con = _igvn->zerocon(t->basic_type());\n+  } else {\n+    Node* curr_cmp = curr_ctrl->in(0)->in(1)->in(1); \/\/ true\/false -> if -> bool -> cmp\n+    con = curr_cmp->in(1)->is_Con() ? curr_cmp->in(1) : curr_cmp->in(2);\n@@ -553,1 +644,0 @@\n-#endif\n@@ -555,33 +645,2 @@\n-  \/\/ Iterate over Phi outputs looking for an AddP\n-  for (int j = ophi->outcnt()-1; j >= 0;) {\n-    Node* previous_addp = ophi->raw_out(j);\n-    if (previous_addp->is_AddP()) {\n-      \/\/ All AddPs are present in the connection graph\n-      FieldNode* fn = ptnode_adr(previous_addp->_idx)->as_Field();\n-\n-      \/\/ Iterate over AddP looking for a Load\n-      for (int k = previous_addp->outcnt()-1; k >= 0;) {\n-        Node* previous_load = previous_addp->raw_out(k);\n-        if (previous_load->is_Load()) {\n-          Node* data_phi = previous_load->as_Load()->split_through_phi(_igvn, ignore_missing_instance_id);\n-          _igvn->replace_node(previous_load, data_phi);\n-          assert(data_phi != nullptr, \"Output of split_through_phi is null.\");\n-          assert(data_phi != previous_load, \"Output of split_through_phi is same as input.\");\n-          assert(data_phi->is_Phi(), \"Return of split_through_phi should be a Phi.\");\n-\n-          \/\/ Push the newly created AddP on alloc_worklist and patch\n-          \/\/ the connection graph. Note that the changes in the CG below\n-          \/\/ won't affect the ES of objects since the new nodes have the\n-          \/\/ same status as the old ones.\n-          for (uint i = 1; i < data_phi->req(); i++) {\n-            Node* new_load = data_phi->in(i);\n-            if (new_load->is_Load()) {\n-              Node* new_addp = new_load->in(MemNode::Address);\n-              Node* base = get_addp_base(new_addp);\n-\n-              \/\/ The base might not be something that we can create an unique\n-              \/\/ type for. If that's the case we are done with that input.\n-              PointsToNode* jobj_ptn = unique_java_object(base);\n-              if (jobj_ptn == nullptr || !jobj_ptn->scalar_replaceable()) {\n-                continue;\n-              }\n+  return CmpNode::make(base, con, t->basic_type());\n+}\n@@ -589,20 +648,98 @@\n-              \/\/ Push to alloc_worklist since the base has an unique_type\n-              alloc_worklist.append_if_missing(new_addp);\n-\n-              \/\/ Now let's add the node to the connection graph\n-              _nodes.at_grow(new_addp->_idx, nullptr);\n-              add_field(new_addp, fn->escape_state(), fn->offset());\n-              add_base(ptnode_adr(new_addp->_idx)->as_Field(), ptnode_adr(base->_idx));\n-\n-              \/\/ If the load doesn't load an object then it won't be\n-              \/\/ part of the connection graph\n-              PointsToNode* curr_load_ptn = ptnode_adr(previous_load->_idx);\n-              if (curr_load_ptn != nullptr) {\n-                _nodes.at_grow(new_load->_idx, nullptr);\n-                add_local_var(new_load, curr_load_ptn->escape_state());\n-                add_edge(ptnode_adr(new_load->_idx), ptnode_adr(new_addp->_idx)->as_Field());\n-              }\n-            }\n-          }\n-        }\n-        k = MIN2(--k, (int)previous_addp->outcnt()-1);\n+\/\/ This method 'specializes' the CastPP passed as parameter to the base passed\n+\/\/ as parameter. Note that the existing CastPP input is a Phi. \"Specialize\"\n+\/\/ means that the CastPP now will be specific for a given base instead of a Phi.\n+\/\/ An If-Then-Else-Region block is inserted to control the CastPP. The control\n+\/\/ of the CastPP is a copy of the current one (if there is one) or a check\n+\/\/ against NULL.\n+\/\/\n+\/\/ Before:\n+\/\/\n+\/\/    C1     C2  ... Cn\n+\/\/     \\      |      \/\n+\/\/      \\     |     \/\n+\/\/       \\    |    \/\n+\/\/        \\   |   \/\n+\/\/         \\  |  \/\n+\/\/          \\ | \/\n+\/\/           \\|\/\n+\/\/          Region     B1      B2  ... Bn\n+\/\/            |          \\      |      \/\n+\/\/            |           \\     |     \/\n+\/\/            |            \\    |    \/\n+\/\/            |             \\   |   \/\n+\/\/            |              \\  |  \/\n+\/\/            |               \\ | \/\n+\/\/            ---------------> Phi\n+\/\/                              |\n+\/\/                      X       |\n+\/\/                      |       |\n+\/\/                      |       |\n+\/\/                      ------> CastPP\n+\/\/\n+\/\/ After (only partial illustration; base = B2, current_control = C2):\n+\/\/\n+\/\/                      C2\n+\/\/                      |\n+\/\/                      If\n+\/\/                     \/ \\\n+\/\/                    \/   \\\n+\/\/                   T     F\n+\/\/                  \/\\     \/\n+\/\/                 \/  \\   \/\n+\/\/                \/    \\ \/\n+\/\/      C1    CastPP   Reg        Cn\n+\/\/       |              |          |\n+\/\/       |              |          |\n+\/\/       |              |          |\n+\/\/       -------------- | ----------\n+\/\/                    | | |\n+\/\/                    Region\n+\/\/\n+Node* ConnectionGraph::specialize_castpp(Node* castpp, Node* base, Node* current_control) {\n+  Node* control_successor  = current_control->unique_ctrl_out();\n+  Node* minus_one          = _igvn->transform(ConINode::make(-1));\n+  Node* cmp                = _igvn->transform(specialize_cmp(base, castpp->in(0)));\n+  Node* boll               = _igvn->transform(new BoolNode(cmp, BoolTest::ne));\n+  IfNode* if_ne            = _igvn->transform(new IfNode(current_control, boll, PROB_MIN, COUNT_UNKNOWN))->as_If();\n+  Node* not_eq_control     = _igvn->transform(new IfTrueNode(if_ne));\n+  Node* yes_eq_control     = _igvn->transform(new IfFalseNode(if_ne));\n+  Node* end_region         = _igvn->transform(new RegionNode(3));\n+\n+  \/\/ Insert the new if-else-region block into the graph\n+  end_region->set_req(1, not_eq_control);\n+  end_region->set_req(2, yes_eq_control);\n+  control_successor->replace_edge(current_control, end_region, _igvn);\n+\n+  _igvn->_worklist.push(current_control);\n+  _igvn->_worklist.push(control_successor);\n+\n+  return _igvn->transform(ConstraintCastNode::make_cast_for_type(not_eq_control, base, _igvn->type(castpp), ConstraintCastNode::UnconditionalDependency, nullptr));\n+}\n+\n+Node* ConnectionGraph::split_castpp_load_through_phi(Node* curr_addp, Node* curr_load, Node* region, GrowableArray<Node*>* bases_for_loads, GrowableArray<Node *>  &alloc_worklist) {\n+  const Type* load_type = _igvn->type(curr_load);\n+  Node* nsr_value       = _igvn->zerocon(load_type->basic_type());\n+  Node* data_phi        = _igvn->transform(PhiNode::make(region, nsr_value, load_type));\n+  Node* memory          = curr_load->in(MemNode::Memory);\n+\n+  for (int i = 1; i < bases_for_loads->length(); i++) {\n+    Node* base = bases_for_loads->at(i);\n+    Node* cmp_region = nullptr;\n+    if (base != nullptr) {\n+      if (base->is_CFG()) { \/\/ means that we added a CastPP as child of this CFG node\n+        cmp_region = base->unique_ctrl_out_or_null();\n+        assert(cmp_region != nullptr, \"There should be.\");\n+        base = base->find_out_with(Op_CastPP);\n+      }\n+\n+      Node* addr = _igvn->transform(new AddPNode(base, base, curr_addp->in(AddPNode::Offset)));\n+      Node* mem = (memory->is_Phi() && (memory->in(0) == region)) ? memory->in(i) : memory;\n+      Node* load = _igvn->transform(curr_load->clone());\n+      load->set_req(0, nullptr);\n+      load->set_req(1, mem);\n+      load->set_req(2, addr);\n+\n+      if (cmp_region != nullptr) { \/\/ see comment on previous if\n+        Node* intermediate_phi = _igvn->transform(PhiNode::make(cmp_region, nsr_value, load_type));\n+        intermediate_phi->set_req(1, load);\n+        load = intermediate_phi;\n@@ -611,3 +748,3 @@\n-      \/\/ Remove the old AddP from the processing list because it's dead now\n-      alloc_worklist.remove_if_existing(previous_addp);\n-      _igvn->remove_globally_dead_node(previous_addp);\n+      data_phi->set_req(i, load);\n+    } else {\n+      \/\/ Just use the default, which is already in phi\n@@ -615,1 +752,0 @@\n-    j = MIN2(--j, (int)ophi->outcnt()-1);\n@@ -618,8 +754,109 @@\n-#ifdef ASSERT\n-  if (VerifyReduceAllocationMerges) {\n-    for (uint j = 0; j < ophi->outcnt(); j++) {\n-      Node* use = ophi->raw_out(j);\n-      if (!use->is_SafePoint()) {\n-        ophi->dump(2);\n-        ophi->dump(-2);\n-        assert(false, \"Should be a SafePoint.\");\n+  \/\/ Takes care of updating CG and split_unique_types worklists due to cloned\n+  \/\/ AddP->Load.\n+  updates_after_load_split(data_phi, curr_load, alloc_worklist);\n+\n+  return data_phi;\n+}\n+\n+\/\/ This method only reduces CastPP fields loads; SafePoints are handled\n+\/\/ separately. The idea here is basically to clone the CastPP and place copies\n+\/\/ on each input of the Phi, including non-scalar replaceable inputs.\n+\/\/ Experimentation shows that the resulting IR graph is simpler that way than if\n+\/\/ we just split the cast through scalar-replaceable inputs.\n+\/\/\n+\/\/ The reduction process requires that CastPP's control be one of:\n+\/\/  1) no control,\n+\/\/  2) the same region as Ophi, or\n+\/\/  3) an IfTrue\/IfFalse coming from an CmpP\/N between Ophi and a constant.\n+\/\/\n+\/\/ After splitting the CastPP we'll put it under an If-Then-Else-Region control\n+\/\/ flow. If the CastPP originally had an IfTrue\/False control input then we'll\n+\/\/ use a similar CmpP\/N to control the new If-Then-Else-Region. Otherwise, we'll\n+\/\/ juse use a CmpP\/N against the NULL constant.\n+\/\/\n+\/\/ The If-Then-Else-Region isn't always needed. For instance, if input to\n+\/\/ splitted cast was not nullable (or if it was the NULL constant) then we don't\n+\/\/ need (shouldn't) use a CastPP at all.\n+\/\/\n+\/\/ After the casts are splitted we'll split the AddP->Loads through the Phi and\n+\/\/ connect them to the just split CastPPs.\n+\/\/\n+\/\/ Before (CastPP control is same as Phi):\n+\/\/\n+\/\/          Region     Allocate   Null    Call\n+\/\/            |             \\      |      \/\n+\/\/            |              \\     |     \/\n+\/\/            |               \\    |    \/\n+\/\/            |                \\   |   \/\n+\/\/            |                 \\  |  \/\n+\/\/            |                  \\ | \/\n+\/\/            ------------------> Phi            # Oop Phi\n+\/\/            |                    |\n+\/\/            |                    |\n+\/\/            |                    |\n+\/\/            |                    |\n+\/\/            ----------------> CastPP\n+\/\/                                 |\n+\/\/                               AddP\n+\/\/                                 |\n+\/\/                               Load\n+\/\/\n+\/\/ After (Very much simplified):\n+\/\/\n+\/\/                         Call  NULL\n+\/\/                            \\  \/\n+\/\/                            CmpP\n+\/\/                             |\n+\/\/                           Bool#NE\n+\/\/                             |\n+\/\/                             If\n+\/\/                            \/ \\\n+\/\/                           T   F\n+\/\/                          \/ \\ \/\n+\/\/                         \/   R\n+\/\/                     CastPP  |\n+\/\/                       |     |\n+\/\/                     AddP    |\n+\/\/                       |     |\n+\/\/                     Load    |\n+\/\/                         \\   |   0\n+\/\/            Allocate      \\  |  \/\n+\/\/                \\          \\ | \/\n+\/\/               AddP         Phi\n+\/\/                  \\         \/\n+\/\/                 Load      \/\n+\/\/                    \\  0  \/\n+\/\/                     \\ | \/\n+\/\/                      \\|\/\n+\/\/                      Phi        # \"Field\" Phi\n+\/\/\n+void ConnectionGraph::reduce_phi_on_castpp_field_load(Node* curr_castpp, GrowableArray<Node *>  &alloc_worklist, GrowableArray<Node *>  &memnode_worklist) {\n+  Node* ophi = curr_castpp->in(1);\n+  assert(ophi->is_Phi(), \"Expected this to be a Phi node.\");\n+\n+  \/\/ Identify which base should be used for AddP->Load later when spliting the\n+  \/\/ CastPP->Loads through ophi. Three kind of values may be stored in this\n+  \/\/ array, depending on the nullability status of the corresponding input in\n+  \/\/ ophi.\n+  \/\/\n+  \/\/  - nullptr:    Meaning that the base is actually the NULL constant and therefore\n+  \/\/                we won't try to load from it.\n+  \/\/\n+  \/\/  - CFG Node:   Meaning that the base is a CastPP that was specialized for\n+  \/\/                this input of Ophi. I.e., we added an If->Then->Else-Region\n+  \/\/                that will 'activate' the CastPp only when the input is not Null.\n+  \/\/\n+  \/\/  - Other Node: Meaning that the base is not nullable and therefore we'll try\n+  \/\/                to load directly from it.\n+  GrowableArray<Node*> bases_for_loads(ophi->req(), ophi->req(), nullptr);\n+\n+  for (uint i = 1; i < ophi->req(); i++) {\n+    Node* base = ophi->in(i);\n+    const Type* base_t = _igvn->type(base);\n+\n+    if (base_t->maybe_null()) {\n+      if (base->is_Con()) {\n+        \/\/ Nothing todo as bases_for_loads[i] is already nullptr\n+      } else {\n+        Node* new_castpp = specialize_castpp(curr_castpp, base, ophi->in(0)->in(i));\n+        bases_for_loads.at_put(i, new_castpp->in(0)); \/\/ Use the ctrl of the new node just as a flag\n@@ -627,0 +864,2 @@\n+    } else {\n+      bases_for_loads.at_put(i, base);\n@@ -629,1 +868,25 @@\n-#endif\n+\n+  \/\/ Now let's split the CastPP->Loads through the Phi\n+  for (int i = curr_castpp->outcnt()-1; i >= 0;) {\n+    Node* use = curr_castpp->raw_out(i);\n+    if (use->is_AddP()) {\n+      for (int j = use->outcnt()-1; j >= 0;) {\n+        Node* use_use = use->raw_out(j);\n+        assert(use_use->is_Load(), \"Expected this to be a Load node.\");\n+\n+        \/\/ We can't make an unconditional load from a nullable input. The\n+        \/\/ 'split_castpp_load_through_phi` method will add an\n+        \/\/ 'If-Then-Else-Region` around nullable bases and only load from them\n+        \/\/ when the input is not null.\n+        Node* phi = split_castpp_load_through_phi(use, use_use, ophi->in(0), &bases_for_loads, alloc_worklist);\n+        _igvn->replace_node(use_use, phi);\n+\n+        --j;\n+        j = MIN2(j, (int)use->outcnt()-1);\n+      }\n+\n+      _igvn->remove_dead_node(use);\n+    }\n+    --i;\n+    i = MIN2(i, (int)curr_castpp->outcnt()-1);\n+  }\n@@ -632,7 +895,8 @@\n-\/\/ This method will create a SafePointScalarObjectNode for each combination of\n-\/\/ scalar replaceable allocation in 'ophi' and SafePoint node in 'safepoints'.\n-\/\/ The method will create a SafePointScalarMERGEnode for each combination of\n-\/\/ 'ophi' and SafePoint node in 'safepoints'.\n-\/\/ Each SafePointScalarMergeNode created here may describe multiple scalar\n-\/\/ replaced objects - check detailed description in SafePointScalarMergeNode\n-\/\/ class header.\n+\/\/ This method split a given CmpP\/N through the Phi used in one of its inputs.\n+\/\/ As a result we convert a comparison with a pointer to a comparison with an\n+\/\/ integer.\n+\/\/ The only requirement is that one of the inputs of the CmpP\/N must be a Phi\n+\/\/ while the other must be a constant.\n+\/\/ The splitting process is basically just cloning the CmpP\/N above the input\n+\/\/ Phi.  However, some (most) of the cloned CmpP\/Ns won't be requred because we\n+\/\/ can prove at compile time the result of the comparison.\n@@ -640,8 +904,44 @@\n-\/\/ This method will set entries in the Phi that are scalar replaceable to 'null'.\n-void ConnectionGraph::reduce_phi_on_safepoints(PhiNode* ophi, Unique_Node_List* safepoints) {\n-  Node* minus_one           = _igvn->register_new_node_with_optimizer(ConINode::make(-1));\n-  Node* selector            = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), minus_one, TypeInt::INT));\n-  Node* null_ptr            = _igvn->makecon(TypePtr::NULL_PTR);\n-  const TypeOopPtr* merge_t = _igvn->type(ophi)->make_oopptr();\n-  uint number_of_sr_objects = 0;\n-  PhaseMacroExpand mexp(*_igvn);\n+\/\/ Before:\n+\/\/\n+\/\/             in1    in2 ... inN\n+\/\/              \\      |      \/\n+\/\/               \\     |     \/\n+\/\/                \\    |    \/\n+\/\/                 \\   |   \/\n+\/\/                  \\  |  \/\n+\/\/                   \\ | \/\n+\/\/                    Phi\n+\/\/                     |   Other\n+\/\/                     |    \/\n+\/\/                     |   \/\n+\/\/                     |  \/\n+\/\/                    CmpP\/N\n+\/\/\n+\/\/ After:\n+\/\/\n+\/\/        in1  Other   in2 Other  inN  Other\n+\/\/         |    |      |   |      |    |\n+\/\/         \\    |      |   |      |    |\n+\/\/          \\  \/       |   \/      |    \/\n+\/\/          CmpP\/N    CmpP\/N     CmpP\/N\n+\/\/          Bool      Bool       Bool\n+\/\/            \\        |        \/\n+\/\/             \\       |       \/\n+\/\/              \\      |      \/\n+\/\/               \\     |     \/\n+\/\/                \\    |    \/\n+\/\/                 \\   |   \/\n+\/\/                  \\  |  \/\n+\/\/                   \\ | \/\n+\/\/                    Phi\n+\/\/                     |\n+\/\/                     |   Zero\n+\/\/                     |    \/\n+\/\/                     |   \/\n+\/\/                     |  \/\n+\/\/                     CmpI\n+\/\/\n+\/\/\n+void ConnectionGraph::reduce_phi_on_cmp(Node* cmp) {\n+  Node* ophi = cmp->in(1)->is_Con() ? cmp->in(2) : cmp->in(1);\n+  assert(ophi->is_Phi(), \"Expected this to be a Phi node.\");\n@@ -649,1 +949,99 @@\n-  _igvn->hash_delete(ophi);\n+  Node* other = cmp->in(1)->is_Con() ? cmp->in(1) : cmp->in(2);\n+  Node* zero = _igvn->intcon(0);\n+  BoolTest::mask mask = cmp->unique_out()->as_Bool()->_test._test;\n+\n+  \/\/ This Phi will merge the result of the Cmps split through the Phi\n+  Node* res_phi  = _igvn->transform(PhiNode::make(ophi->in(0), zero, TypeInt::INT));\n+\n+  for (uint i=1; i<ophi->req(); i++) {\n+    Node* ophi_input = ophi->in(i);\n+    Node* res_phi_input = nullptr;\n+\n+    const TypeInt* tcmp = optimize_ptr_compare(ophi_input, other);\n+    if (tcmp->singleton()) {\n+      res_phi_input = _igvn->makecon(tcmp);\n+    } else {\n+      Node* ncmp = _igvn->transform(cmp->clone());\n+      ncmp->set_req(1, ophi_input);\n+      ncmp->set_req(2, other);\n+      Node* boll = _igvn->transform(new BoolNode(ncmp, mask));\n+      res_phi_input = boll->as_Bool()->as_int_value(_igvn);\n+    }\n+\n+    res_phi->set_req(i, res_phi_input);\n+  }\n+\n+  Node* new_cmp = _igvn->transform(new CmpINode(res_phi, zero));\n+  _igvn->replace_node(cmp, new_cmp);\n+}\n+\n+\/\/ Push the newly created AddP on alloc_worklist and patch\n+\/\/ the connection graph. Note that the changes in the CG below\n+\/\/ won't affect the ES of objects since the new nodes have the\n+\/\/ same status as the old ones.\n+void ConnectionGraph::updates_after_load_split(Node* data_phi, Node* previous_load, GrowableArray<Node *>  &alloc_worklist) {\n+  assert(data_phi != nullptr, \"Output of split_through_phi is null.\");\n+  assert(data_phi != previous_load, \"Output of split_through_phi is same as input.\");\n+  assert(data_phi->is_Phi(), \"Output of split_through_phi isn't a Phi.\");\n+\n+  if (data_phi == nullptr || !data_phi->is_Phi()) {\n+    \/\/ Make this a retry?\n+    return ;\n+  }\n+\n+  Node* previous_addp = previous_load->in(MemNode::Address);\n+  FieldNode* fn = ptnode_adr(previous_addp->_idx)->as_Field();\n+  for (uint i = 1; i < data_phi->req(); i++) {\n+    Node* new_load = data_phi->in(i);\n+\n+    if (new_load->is_Phi()) {\n+      \/\/ new_load is currently the \"intermediate_phi\" from an specialized\n+      \/\/ CastPP.\n+      new_load = new_load->in(1);\n+    }\n+\n+    \/\/ \"new_load\" might actually be a constant, parameter, etc.\n+    if (new_load->is_Load()) {\n+      Node* new_addp = new_load->in(MemNode::Address);\n+      Node* base = get_addp_base(new_addp);\n+\n+      \/\/ The base might not be something that we can create an unique\n+      \/\/ type for. If that's the case we are done with that input.\n+      PointsToNode* jobj_ptn = unique_java_object(base);\n+      if (jobj_ptn == nullptr || !jobj_ptn->scalar_replaceable()) {\n+        continue;\n+      }\n+\n+      \/\/ Push to alloc_worklist since the base has an unique_type\n+      alloc_worklist.append_if_missing(new_addp);\n+\n+      \/\/ Now let's add the node to the connection graph\n+      _nodes.at_grow(new_addp->_idx, nullptr);\n+      add_field(new_addp, fn->escape_state(), fn->offset());\n+      add_base(ptnode_adr(new_addp->_idx)->as_Field(), ptnode_adr(base->_idx));\n+\n+      \/\/ If the load doesn't load an object then it won't be\n+      \/\/ part of the connection graph\n+      PointsToNode* curr_load_ptn = ptnode_adr(previous_load->_idx);\n+      if (curr_load_ptn != nullptr) {\n+        _nodes.at_grow(new_load->_idx, nullptr);\n+        add_local_var(new_load, curr_load_ptn->escape_state());\n+        add_edge(ptnode_adr(new_load->_idx), ptnode_adr(new_addp->_idx)->as_Field());\n+      }\n+    }\n+  }\n+}\n+\n+void ConnectionGraph::reduce_phi_on_field_access(Node* previous_addp, GrowableArray<Node *>  &alloc_worklist) {\n+  \/\/ We'll pass this to 'split_through_phi' so that it'll do the split even\n+  \/\/ though the load doesn't have an unique instance type.\n+  bool ignore_missing_instance_id = true;\n+\n+  \/\/ All AddPs are present in the connection graph\n+  FieldNode* fn = ptnode_adr(previous_addp->_idx)->as_Field();\n+\n+  \/\/ Iterate over AddP looking for a Load\n+  for (int k = previous_addp->outcnt()-1; k >= 0;) {\n+    Node* previous_load = previous_addp->raw_out(k);\n+    if (previous_load->is_Load()) {\n+      Node* data_phi = previous_load->as_Load()->split_through_phi(_igvn, ignore_missing_instance_id);\n@@ -651,5 +1049,24 @@\n-  \/\/ Fill in the 'selector' Phi. If index 'i' of the selector is:\n-  \/\/ -> a '-1' constant, the i'th input of the original Phi is NSR.\n-  \/\/ -> a 'x' constant >=0, the i'th input of of original Phi will be SR and the\n-  \/\/    info about the scalarized object will be at index x of\n-  \/\/    ObjectMergeValue::possible_objects\n+      \/\/ Takes care of updating CG and split_unique_types worklists due to cloned\n+      \/\/ AddP->Load.\n+      updates_after_load_split(data_phi, previous_load, alloc_worklist);\n+\n+      _igvn->replace_node(previous_load, data_phi);\n+    }\n+    --k;\n+    k = MIN2(k, (int)previous_addp->outcnt()-1);\n+  }\n+\n+  \/\/ Remove the old AddP from the processing list because it's dead now\n+  assert(previous_addp->outcnt() == 0, \"AddP should be dead now.\");\n+  alloc_worklist.remove_if_existing(previous_addp);\n+}\n+\n+\/\/ Create a 'selector' Phi based on the inputs of 'ophi'. If index 'i' of the\n+\/\/ selector is:\n+\/\/    -> a '-1' constant, the i'th input of the original Phi is NSR.\n+\/\/    -> a 'x' constant >=0, the i'th input of of original Phi will be SR and\n+\/\/       the info about the scalarized object will be at index x of ObjectMergeValue::possible_objects\n+PhiNode* ConnectionGraph::create_selector(PhiNode* ophi) const {\n+  Node* minus_one = _igvn->register_new_node_with_optimizer(ConINode::make(-1));\n+  Node* selector  = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), minus_one, TypeInt::INT));\n+  uint number_of_sr_objects = 0;\n@@ -657,1 +1074,1 @@\n-    Node* base          = ophi->in(i);\n+    Node* base = ophi->in(i);\n@@ -667,3 +1084,104 @@\n-  \/\/ Update the debug information of all safepoints in turn\n-  for (uint spi = 0; spi < safepoints->size(); spi++) {\n-    SafePointNode* sfpt = safepoints->at(spi)->as_SafePoint();\n+  return selector->as_Phi();\n+}\n+\n+\/\/ Returns true if the AddP node 'n' has at least one base that is a reducible\n+\/\/ merge. If the base is a CastPP\/CheckCastPP then the input of the cast is\n+\/\/ checked instead.\n+bool ConnectionGraph::has_reducible_merge_base(AddPNode* n, Unique_Node_List &reducible_merges) {\n+  PointsToNode* ptn = ptnode_adr(n->_idx);\n+  if (ptn == nullptr || !ptn->is_Field() || ptn->as_Field()->base_count() < 2) {\n+    return false;\n+  }\n+\n+  for (BaseIterator i(ptn->as_Field()); i.has_next(); i.next()) {\n+    Node* base = i.get()->ideal_node();\n+\n+    if (reducible_merges.member(base)) {\n+      return true;\n+    }\n+\n+    if (base->is_CastPP() || base->is_CheckCastPP()) {\n+      base = base->in(1);\n+      if (reducible_merges.member(base)) {\n+        return true;\n+      }\n+    }\n+  }\n+\n+  return false;\n+}\n+\n+\/\/ This method will call its helper method to reduce SafePoint nodes that use\n+\/\/ 'ophi' or a casted version of 'ophi'. All SafePoint nodes using the same\n+\/\/ \"version\" of Phi use the same debug information (regarding the Phi).\n+\/\/ Therefore, I collect all safepoints and patch them all at once.\n+\/\/\n+\/\/ The safepoints using the Phi node have to be processed before safepoints of\n+\/\/ CastPP nodes. The reason is, when reducing a CastPP we add a reference (the\n+\/\/ NSR merge pointer) to the input of the CastPP (i.e., the Phi) in the\n+\/\/ safepoint. If we process CastPP's safepoints before Phi's safepoints the\n+\/\/ algorithm that process Phi's safepoints will think that the added Phi\n+\/\/ reference is a regular reference.\n+bool ConnectionGraph::reduce_phi_on_safepoints(PhiNode* ophi) {\n+  PhiNode* selector = create_selector(ophi);\n+  Unique_Node_List safepoints;\n+  Unique_Node_List casts;\n+\n+  \/\/ Just collect the users of the Phis for later processing\n+  \/\/ in the needed order.\n+  for (uint i = 0; i < ophi->outcnt(); i++) {\n+    Node* use = ophi->raw_out(i);\n+    if (use->is_SafePoint()) {\n+      safepoints.push(use);\n+    } else if (use->is_CastPP()) {\n+      casts.push(use);\n+    } else {\n+      assert(use->outcnt() == 0, \"Only CastPP & SafePoint users should be left.\");\n+    }\n+  }\n+\n+  \/\/ Need to process safepoints using the Phi first\n+  if (!reduce_phi_on_safepoints_helper(ophi, nullptr, selector, safepoints)) {\n+    return false;\n+  }\n+\n+  \/\/ Now process CastPP->safepoints\n+  for (uint i = 0; i < casts.size(); i++) {\n+    Node* cast = casts.at(i);\n+    Unique_Node_List cast_sfpts;\n+\n+    for (DUIterator_Fast jmax, j = cast->fast_outs(jmax); j < jmax; j++) {\n+      Node* use_use = cast->fast_out(j);\n+      if (use_use->is_SafePoint()) {\n+        cast_sfpts.push(use_use);\n+      } else {\n+        assert(use_use->outcnt() == 0, \"Only SafePoint users should be left.\");\n+      }\n+    }\n+\n+    if (!reduce_phi_on_safepoints_helper(ophi, cast, selector, cast_sfpts)) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+\/\/ This method will create a SafePointScalarMERGEnode for each SafePoint in\n+\/\/ 'safepoints'. It then will iterate on the inputs of 'ophi' and create a\n+\/\/ SafePointScalarObjectNode for each scalar replaceable input. Each\n+\/\/ SafePointScalarMergeNode may describe multiple scalar replaced objects -\n+\/\/ check detailed description in SafePointScalarMergeNode class header.\n+bool ConnectionGraph::reduce_phi_on_safepoints_helper(Node* ophi, Node* cast, Node* selector, Unique_Node_List& safepoints) {\n+  PhaseMacroExpand mexp(*_igvn);\n+  Node* original_sfpt_parent =  cast != nullptr ? cast : ophi;\n+  const TypeOopPtr* merge_t = _igvn->type(original_sfpt_parent)->make_oopptr();\n+\n+  Node* nsr_merge_pointer = ophi;\n+  if (cast != nullptr) {\n+    const Type* new_t = merge_t->meet(TypePtr::NULL_PTR);\n+    nsr_merge_pointer = _igvn->transform(ConstraintCastNode::make_cast_for_type(cast->in(0), cast->in(1), new_t, ConstraintCastNode::RegularDependency, nullptr));\n+  }\n+\n+  for (uint spi = 0; spi < safepoints.size(); spi++) {\n+    SafePointNode* sfpt = safepoints.at(spi)->as_SafePoint();\n@@ -683,1 +1201,1 @@\n-    sfpt->add_req(ophi);\n+    sfpt->add_req(nsr_merge_pointer);\n@@ -687,1 +1205,1 @@\n-      Node* base          = ophi->in(i);\n+      Node* base = ophi->in(i);\n@@ -699,2 +1217,1 @@\n-        _compile->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n-        return;\n+        return false;\n@@ -712,2 +1229,2 @@\n-    \/\/ Replaces debug information references to \"ophi\" in \"sfpt\" with references to \"smerge\"\n-    sfpt->replace_edges_in_range(ophi, smerge, debug_start, jvms->debug_end(), _igvn);\n+    \/\/ Replaces debug information references to \"original_sfpt_parent\" in \"sfpt\" with references to \"smerge\"\n+    sfpt->replace_edges_in_range(original_sfpt_parent, smerge, debug_start, jvms->debug_end(), _igvn);\n@@ -718,1 +1235,1 @@\n-    sfpt->set_req(smerge->merge_pointer_idx(jvms), ophi);\n+    sfpt->set_req(smerge->merge_pointer_idx(jvms), nsr_merge_pointer);\n@@ -722,4 +1239,53 @@\n-  \/\/ Now we can change ophi since we don't need to know the types\n-  \/\/ of the input allocations anymore.\n-  const Type* new_t = merge_t->meet(TypePtr::NULL_PTR);\n-  Node* new_phi = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), null_ptr, new_t));\n+  return true;\n+}\n+\n+void ConnectionGraph::reduce_phi(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist, GrowableArray<Node *>  &memnode_worklist) {\n+  bool delay = _igvn->delay_transform();\n+  _igvn->set_delay_transform(true);\n+  _igvn->hash_delete(ophi);\n+\n+  \/\/ Copying all users first because some will be removed and others won't.\n+  \/\/ Ophi also may acquire some new users as part of Cast reduction.\n+  \/\/ CastPPs also need to be processed before CmpPs.\n+  Unique_Node_List castpps;\n+  Unique_Node_List others;\n+  for (DUIterator_Fast imax, i = ophi->fast_outs(imax); i < imax; i++) {\n+    Node* use = ophi->fast_out(i);\n+\n+    if (use->is_CastPP()) {\n+      castpps.push(use);\n+    } else if (use->is_AddP() || use->is_Cmp()) {\n+      others.push(use);\n+    } else if (use->is_SafePoint()) {\n+      \/\/ processed later\n+    } else {\n+      assert(use->is_SafePoint(), \"Unexpected user of reducible Phi %d -> %d:%s:%d\", ophi->_idx, use->_idx, use->Name(), use->outcnt());\n+    }\n+  }\n+\n+  \/\/ CastPPs need to be processed before Cmps because during the process of\n+  \/\/ splitting CastPPs we make reference to the inputs of the Cmp that is used\n+  \/\/ by the If controlling the CastPP.\n+  for (uint i = 0; i < castpps.size(); i++) {\n+    reduce_phi_on_castpp_field_load(castpps.at(i), alloc_worklist, memnode_worklist);\n+  }\n+\n+  for (uint i = 0; i < others.size(); i++) {\n+    Node* use = others.at(i);\n+\n+    if (use->is_AddP()) {\n+      reduce_phi_on_field_access(use, alloc_worklist);\n+    } else if(use->is_Cmp()) {\n+      reduce_phi_on_cmp(use);\n+    }\n+  }\n+\n+  _igvn->set_delay_transform(delay);\n+}\n+\n+void ConnectionGraph::reset_scalar_replaceable_entries(PhiNode* ophi) {\n+  Node* null_ptr            = _igvn->makecon(TypePtr::NULL_PTR);\n+  const TypeOopPtr* merge_t = _igvn->type(ophi)->make_oopptr();\n+  const Type* new_t         = merge_t->meet(TypePtr::NULL_PTR);\n+  Node* new_phi             = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), null_ptr, new_t));\n+\n@@ -737,4 +1303,2 @@\n-  _igvn->replace_node(ophi, new_phi);\n-  _igvn->hash_insert(ophi);\n-  _igvn->_worklist.push(ophi);\n-}\n+  for (int i = ophi->outcnt()-1; i >= 0;) {\n+    Node* out = ophi->raw_out(i);\n@@ -742,2 +1306,4 @@\n-void ConnectionGraph::reduce_phi(PhiNode* ophi) {\n-  Unique_Node_List safepoints;\n+    if (out->is_ConstraintCast()) {\n+      const Type* out_t = _igvn->type(out)->make_ptr();\n+      const Type* out_new_t = out_t->meet(TypePtr::NULL_PTR);\n+      bool change = out_new_t != out_t;\n@@ -745,2 +1311,7 @@\n-  for (uint i = 0; i < ophi->outcnt(); i++) {\n-    Node* use = ophi->raw_out(i);\n+      for (int j = out->outcnt()-1; change && j >= 0; --j) {\n+        Node* out2 = out->raw_out(j);\n+        if (!out2->is_SafePoint()) {\n+          change = false;\n+          break;\n+        }\n+      }\n@@ -748,13 +1319,5 @@\n-    \/\/ All SafePoint nodes using the same Phi node use the same debug\n-    \/\/ information (regarding the Phi). Furthermore, reducing the Phi used by a\n-    \/\/ SafePoint requires changing the Phi. Therefore, I collect all safepoints\n-    \/\/ and patch them all at once later.\n-    if (use->is_SafePoint()) {\n-      safepoints.push(use->as_SafePoint());\n-    } else {\n-#ifdef ASSERT\n-      ophi->dump(-3);\n-      assert(false, \"Unexpected user of reducible Phi %d -> %d:%s\", ophi->_idx, use->_idx, use->Name());\n-#endif\n-      _compile->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n-      return;\n+      if (change) {\n+        Node* new_cast = ConstraintCastNode::make_cast_for_type(out->in(0), out->in(1), out_new_t, ConstraintCastNode::StrongDependency, nullptr);\n+        _igvn->replace_node(out, new_cast);\n+        _igvn->register_new_node_with_optimizer(new_cast);\n+      }\n@@ -762,1 +1325,0 @@\n-  }\n@@ -764,2 +1326,2 @@\n-  if (safepoints.size() > 0) {\n-    reduce_phi_on_safepoints(ophi, &safepoints);\n+    --i;\n+    i = MIN2(i, (int)ophi->outcnt()-1);\n@@ -767,0 +1329,2 @@\n+\n+  _igvn->replace_node(ophi, new_phi);\n@@ -2331,0 +2895,6 @@\n+        \/\/ These other local vars may point to multiple objects through a Phi\n+        \/\/ In this case we skip them and see if we can reduce the Phi.\n+        if (use_n->is_CastPP() || use_n->is_CheckCastPP()) {\n+          use_n = use_n->in(1);\n+        }\n+\n@@ -2332,4 +2902,1 @@\n-        if (candidates.member(use_n)) {\n-          continue;\n-        } else if (reducible_merges.member(use_n)) {\n-          candidates.push(use_n);\n+        if (candidates.member(use_n) || reducible_merges.member(use_n)) {\n@@ -2409,0 +2976,2 @@\n+      bool further_validate = false;\n+\n@@ -2410,8 +2979,4 @@\n-        PointsToNode* base = i.get();\n-        \/\/ Don't take into account LocalVar nodes which\n-        \/\/ may point to only one object which should be also\n-        \/\/ this field's base by now.\n-        if (base->is_JavaObject() && base != jobj) {\n-          \/\/ Mark all bases.\n-          set_not_scalar_replaceable(jobj NOT_PRODUCT(COMMA \"may point to more than one object\"));\n-          set_not_scalar_replaceable(base NOT_PRODUCT(COMMA \"may point to more than one object\"));\n+        Node* base = i.get()->ideal_node();\n+        if (base->is_Phi() && !reducible_merges.member(base)) {\n+          further_validate = true;\n+          break;\n@@ -2421,2 +2986,16 @@\n-      if (!jobj->scalar_replaceable()) {\n-        return;\n+      if (further_validate) {\n+        for (BaseIterator i(field); i.has_next(); i.next()) {\n+          PointsToNode* base = i.get();\n+          \/\/ Don't take into account LocalVar nodes which\n+          \/\/ may point to only one object which should be also\n+          \/\/ this field's base by now.\n+          if (base->is_JavaObject() && base != jobj) {\n+            \/\/ Mark all bases.\n+            set_not_scalar_replaceable(jobj NOT_PRODUCT(COMMA \"may point to more than one object\"));\n+            set_not_scalar_replaceable(base NOT_PRODUCT(COMMA \"may point to more than one object\"));\n+          }\n+        }\n+\n+        if (!jobj->scalar_replaceable()) {\n+          return;\n+        }\n@@ -2569,1 +3148,2 @@\n-      const TypeInt* tcmp = optimize_ptr_compare(n);\n+      assert(n->Opcode() == Op_CmpN || n->Opcode() == Op_CmpP, \"must be\");\n+      const TypeInt* tcmp = optimize_ptr_compare(n->in(1), n->in(2));\n@@ -2602,1 +3182,1 @@\n-const TypeInt* ConnectionGraph::optimize_ptr_compare(Node* n) {\n+const TypeInt* ConnectionGraph::optimize_ptr_compare(Node* left, Node* right) {\n@@ -2604,1 +3184,0 @@\n-  assert(n->Opcode() == Op_CmpN || n->Opcode() == Op_CmpP, \"must be\");\n@@ -2609,4 +3188,13 @@\n-  PointsToNode* ptn1 = ptnode_adr(n->in(1)->_idx);\n-  PointsToNode* ptn2 = ptnode_adr(n->in(2)->_idx);\n-  JavaObjectNode* jobj1 = unique_java_object(n->in(1));\n-  JavaObjectNode* jobj2 = unique_java_object(n->in(2));\n+  PointsToNode* ptn1 = ptnode_adr(left->_idx);\n+  PointsToNode* ptn2 = ptnode_adr(right->_idx);\n+  JavaObjectNode* jobj1 = unique_java_object(left);\n+  JavaObjectNode* jobj2 = unique_java_object(right);\n+\n+  \/\/ The use of this method during allocation merge reduction may cause 'left'\n+  \/\/ or 'right' be something (e.g., a Phi) that isn't in the connection graph or\n+  \/\/ that doesn't reference an unique java object.\n+  if (ptn1 == nullptr || ptn2 == nullptr ||\n+      jobj1 == nullptr || jobj2 == nullptr) {\n+    return UNKNOWN;\n+  }\n+\n@@ -3803,2 +4391,1 @@\n-      Node* addp_base = get_addp_base(n);\n-      if (addp_base != nullptr && reducible_merges.member(addp_base)) {\n+      if (has_reducible_merge_base(n->as_AddP(), reducible_merges)) {\n@@ -3808,0 +4395,1 @@\n+      Node* addp_base = get_addp_base(n);\n@@ -3829,1 +4417,3 @@\n-      \/\/ Reducible Phi's will be removed from the graph after split_unique_types finishes\n+      \/\/ Reducible Phi's will be removed from the graph after split_unique_types\n+      \/\/ finishes. For now we just try to split out the SR inputs of the merge.\n+      Node* parent = n->in(1);\n@@ -3831,2 +4421,1 @@\n-        \/\/ Split loads through phi\n-        reduce_phi_on_field_access(n->as_Phi(), alloc_worklist);\n+        reduce_phi(n->as_Phi(), alloc_worklist, memnode_worklist);\n@@ -3839,0 +4428,4 @@\n+      } else if (reducible_merges.member(parent)) {\n+        \/\/ 'n' is an user of a reducible merge (a Phi). It will be simplified as\n+        \/\/ part of reduce_merge.\n+        continue;\n@@ -3951,1 +4544,0 @@\n-    \/\/ At this point reducible Phis shouldn't have AddP users anymore; only SafePoints.\n@@ -3961,0 +4553,1 @@\n+      \/\/ At this point reducible Phis shouldn't have AddP users anymore; only SafePoints or Casts.\n@@ -3963,1 +4556,1 @@\n-        if (!use->is_SafePoint()) {\n+        if (!use->is_SafePoint() && !use->is_CastPP()) {\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":795,"deletions":202,"binary":false,"changes":997,"status":"modified"},{"patch":"@@ -482,1 +482,1 @@\n-  const TypeInt* optimize_ptr_compare(Node* n);\n+  const TypeInt* optimize_ptr_compare(Node* left, Node* right);\n@@ -593,1 +593,10 @@\n-\n+  PhiNode* create_selector(PhiNode* ophi) const;\n+  void updates_after_load_split(Node* data_phi, Node* previous_load, GrowableArray<Node *>  &alloc_worklist);\n+  Node* split_castpp_load_through_phi(Node* curr_addp, Node* curr_load, Node* region, GrowableArray<Node*>* bases_for_loads, GrowableArray<Node *>  &alloc_worklist);\n+  void reset_scalar_replaceable_entries(PhiNode* ophi);\n+  bool has_reducible_merge_base(AddPNode* n, Unique_Node_List &reducible_merges);\n+  Node* specialize_cmp(Node* base, Node* curr_ctrl);\n+  Node* specialize_castpp(Node* castpp, Node* base, Node* current_control);\n+\n+  bool can_reduce_cmp(Node* n, Node* cmp) const;\n+  bool has_been_reduced(PhiNode* n, SafePointNode* sfpt) const;\n@@ -595,1 +604,1 @@\n-  bool can_reduce_phi_check_users(PhiNode* ophi) const;\n+  bool can_reduce_check_users(Node* n, uint nesting) const;\n@@ -598,3 +607,6 @@\n-  void reduce_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist);\n-  void reduce_phi_on_safepoints(PhiNode* ophi, Unique_Node_List* safepoints);\n-  void reduce_phi(PhiNode* ophi);\n+  void reduce_phi_on_field_access(Node* previous_addp, GrowableArray<Node *>  &alloc_worklist);\n+  void reduce_phi_on_castpp_field_load(Node* castpp, GrowableArray<Node *>  &alloc_worklist, GrowableArray<Node *>  &memnode_worklist);\n+  void reduce_phi_on_cmp(Node* cmp);\n+  bool reduce_phi_on_safepoints(PhiNode* ophi);\n+  bool reduce_phi_on_safepoints_helper(Node* ophi, Node* cast, Node* selector, Unique_Node_List& safepoints);\n+  void reduce_phi(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist, GrowableArray<Node *>  &memnode_worklist);\n","filename":"src\/hotspot\/share\/opto\/escape.hpp","additions":18,"deletions":6,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -230,1 +230,1 @@\n-      if (t_oop->is_aryptr()) {\n+      if (t_oop->isa_aryptr()) {\n@@ -947,0 +947,1 @@\n+  case T_NARROWOOP:\n@@ -1551,0 +1552,2 @@\n+\/\/ Some differences from original method:\n+\/\/  - If base->is_CastPP(): base = base->in(1)\n@@ -1556,0 +1559,1 @@\n+           base    = (base->is_CastPP()) ? base->in(1) : base;\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -64,0 +64,1 @@\n+class CastPPNode;\n@@ -716,0 +717,1 @@\n+        DEFINE_CLASS_ID(CastPP, ConstraintCast, 6)\n@@ -893,0 +895,1 @@\n+  DEFINE_CLASS_QUERY(CastPP)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -646,0 +646,8 @@\n+    case T_OBJECT:\n+    case T_ARRAY:\n+    case T_ADDRESS:\n+    case T_METADATA:\n+      return new CmpPNode(in1, in2);\n+    case T_NARROWOOP:\n+    case T_NARROWKLASS:\n+      return new CmpNNode(in1, in2);\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -304,1 +304,0 @@\n-    Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n@@ -307,3 +306,0 @@\n-    st.print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n-    k->print_value_on(&st);\n-    assert(obj.not_null() || realloc_failures, \"reallocation was missed\");\n@@ -311,3 +307,2 @@\n-      st.print(\" allocation failed\");\n-    } else {\n-      st.print(\" allocated (\" SIZE_FORMAT \" bytes)\", obj->size() * HeapWordSize);\n+      st.print_cr(\"     nullptr\");\n+      continue;\n@@ -315,1 +310,0 @@\n-    st.cr();\n@@ -317,1 +311,7 @@\n-    if (Verbose && !obj.is_null()) {\n+    Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n+\n+    st.print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n+    k->print_value_on(&st);\n+    st.print_cr(\" allocated (\" SIZE_FORMAT \" bytes)\", obj->size() * HeapWordSize);\n+\n+    if (Verbose && k != nullptr) {\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -251,2 +251,3 @@\n-    Handle ov = ((ObjectValue *)sv)->value();\n-    return new StackValue(ov, (ov.is_null()) ? 1 : 0);\n+    ObjectValue* ov = (ObjectValue *)sv;\n+    Handle hdl = ov->value();\n+    return new StackValue(hdl, hdl.is_null() && ov->was_scalar_replaced() ? 1 : 0);\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+                                   \"-XX:CompileCommand=inline,*Nested::*\",\n@@ -95,1 +96,3 @@\n-                 \"testString_two_C2\"\n+                 \"testString_two_C2\",\n+                 \"testLoadNarrowKlass_C2\",\n+                 \"testReReduce_C2\"\n@@ -150,0 +153,2 @@\n+        Asserts.assertEQ(testLoadNarrowKlass_Interp(cond1),                         testLoadNarrowKlass_C2(cond1));\n+        Asserts.assertEQ(testReReduce_Interp(cond1, x, y),                          testReReduce_C2(cond1, x, y));\n@@ -298,2 +303,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ Merge won't be reduced because the inputs to the Phi have different Klasses\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -407,2 +411,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"1\" })\n-    \/\/ The merge won't be simplified because the merge with NULL\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -513,1 +516,0 @@\n-    \/\/ Merge won't be reduced because, among other things, one of the inputs is null.\n@@ -533,2 +535,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"1\" })\n-    \/\/ The allocation won't be removed because the merge doesn't have exact type\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -565,3 +566,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ The initial allocation assigned to 's' will always be dead.\n-    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -593,1 +592,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -623,3 +622,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ The unused allocation will be removed.\n-    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -1234,1 +1231,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"0\" })\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -1255,1 +1252,1 @@\n-    @IR(counts = { IRNode.ALLOC, \"0\" })\n+    @IR(failOn = { IRNode.ALLOC })\n@@ -1261,0 +1258,56 @@\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    Class testLoadNarrowKlass(boolean cond1) {\n+        Object p = new Circle(10);\n+\n+        if (cond1) {\n+            p = dummy(1, 2);\n+        }\n+\n+        return p.getClass();\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ The allocation won't be reduced because we don't support NarrowKlass\n+    \/\/ loads under CastPPs.\n+    Class testLoadNarrowKlass_C2(boolean cond1) { return testLoadNarrowKlass(cond1); }\n+\n+    @DontCompile\n+    Class testLoadNarrowKlass_Interp(boolean cond1) { return testLoadNarrowKlass(cond1); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testReReduce(boolean cond, int x, int y) {\n+        Nested A = new Nested(x, y);\n+        Nested B = new Nested(y, x);\n+        Nested C = new Nested(y, x);\n+        Nested P = null;\n+\n+        if (x == y) {\n+            A.other = B;\n+            P = A;\n+        } else if (x > y) {\n+            P = B;\n+        } else {\n+            C.other = B;\n+            P = C;\n+        }\n+\n+        if (x == y)\n+            dummy_defaults();\n+\n+        return P.x;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ The last allocation won't be reduced because it would cause the creation\n+    \/\/ of a nested SafePointScalarMergeNode.\n+    int testReReduce_C2(boolean cond1, int x, int y) { return testReReduce(cond1, x, y); }\n+\n+    @DontCompile\n+    int testReReduce_Interp(boolean cond1, int x, int y) { return testReReduce(cond1, x, y); }\n+\n@@ -1292,0 +1345,10 @@\n+    static class Nested {\n+        int x, y;\n+        Nested other;\n+        Nested(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+            this.other = null;\n+        }\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/scalarReplacement\/AllocationMergesTests.java","additions":80,"deletions":17,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -0,0 +1,1379 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.bench.vm.compiler;\n+\n+import org.openjdk.jmh.annotations.*;\n+import org.openjdk.jmh.infra.*;\n+import java.util.concurrent.TimeUnit;\n+import java.util.random.RandomGenerator;\n+import java.util.random.RandomGeneratorFactory;\n+\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+@State(Scope.Thread)\n+@Warmup(iterations = 5, time = 2, timeUnit = TimeUnit.SECONDS)\n+@Measurement(iterations = 5, time = 2, timeUnit = TimeUnit.SECONDS)\n+@Fork(value = 3)\n+public abstract class AllocationMerges {\n+    private static final int SIZE        = 1000000;\n+    private static final boolean cond1[] = new boolean[SIZE];\n+    private static final boolean cond2[] = new boolean[SIZE];\n+    private static final int ws[]        = new int[SIZE];\n+    private static final int xs[]        = new int[SIZE];\n+    private static final int ys[]        = new int[SIZE];\n+    private static final int zs[]        = new int[SIZE];\n+    private static Load global_escape   = new Load(2022, 2023);\n+    private RandomGenerator rng          = RandomGeneratorFactory.getDefault().create();\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @Setup\n+    public void setup() {\n+        for (int i = 0; i < SIZE; i++) {\n+            cond1[i] = i % 2 == 0;\n+            cond2[i] = i % 2 == 1;\n+\n+            ws[i] = rng.nextInt();\n+            xs[i] = rng.nextInt();\n+            ys[i] = rng.nextInt();\n+            zs[i] = rng.nextInt();\n+        }\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testGlobalEscape(int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        AllocationMerges.global_escape = p;\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Benchmark\n+    public void testGlobalEscape_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testGlobalEscape(xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testArgEscape(int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        int val = dummy(p);\n+\n+        return val + p.x + p.y;\n+    }\n+\n+    @Benchmark\n+    public void testArgEscape_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testArgEscape(xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testEscapeInCallAfterMerge(boolean cond, boolean cond2, int x, int y) {\n+        Load p = new Load(x, x);\n+\n+        if (cond) {\n+            p = new Load(y, y);\n+        }\n+\n+        if (cond2) {\n+            dummy(p);\n+        }\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Benchmark\n+    public void testEscapeInCallAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testEscapeInCallAfterMerge(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testNoEscapeWithWriteInLoop(boolean cond, boolean cond2, int x, int y) {\n+        Load p = new Load(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Load(y, x);\n+        }\n+\n+        for (int i=0; i<100; i++) {\n+            p.x += p.y + i;\n+            p.y += p.x + i;\n+        }\n+\n+        return res + p.x + p.y;\n+    }\n+\n+    @Benchmark\n+    public void testNoEscapeWithWriteInLoop_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testNoEscapeWithWriteInLoop(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testPollutedWithWrite(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Square(l);\n+        Shape obj = null;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i=1; i<132; i++) {\n+            obj.x++;\n+        }\n+\n+        return obj1.x + obj2.y;\n+    }\n+\n+    @Benchmark\n+    public void testPollutedWithWrite_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testPollutedWithWrite(cond1[i], xs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testPollutedPolymorphic(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Circle(l);\n+        Shape obj = (cond ? obj1 : obj2);\n+        int res = 0;\n+\n+        for (int i=1; i<232; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res + obj1.x + obj2.y;\n+    }\n+\n+    @Benchmark\n+    public void testPollutedPolymorphic_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testPollutedPolymorphic(cond1[i], xs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testMergedLoadAfterDirectStore(boolean cond, int x, int y) {\n+        Load p0 = new Load(x, x);\n+        Load p1 = new Load(y, y);\n+        Load p = null;\n+\n+        if (cond) {\n+            p = p0;\n+        } else {\n+            p = p1;\n+        }\n+\n+        p0.x = x * y;\n+\n+        return p.x;\n+    }\n+\n+    @Benchmark\n+    public void testMergedLoadAfterDirectStore_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testMergedLoadAfterDirectStore(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testMergedAccessAfterCallWithWrite(boolean cond, int x, int y) {\n+        Load p2 = new Load(x, x);\n+        Load p = new Load(y, y);\n+\n+        p.x = p.x * y;\n+\n+        if (cond) {\n+            p = new Load(x, x);\n+        }\n+\n+        dummy(p2);\n+\n+        for (int i=3; i<324; i++) {\n+            p.x += i * x;\n+        }\n+\n+        return p.x;\n+    }\n+\n+    @Benchmark\n+    public void testMergedAccessAfterCallWithWrite_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testMergedAccessAfterCallWithWrite(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testLoadAfterTrap(boolean cond, int x, int y) {\n+        Load p = null;\n+\n+        if (cond) {\n+            p = new Load(x, x);\n+        } else {\n+            p = new Load(y, y);\n+        }\n+\n+        dummy(x+y);\n+\n+        return p.x + p.y;\n+    }\n+\n+    @Benchmark\n+    public void testLoadAfterTrap_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testLoadAfterTrap(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCondAfterMergeWithNull(boolean cond1, boolean cond2, int x, int y) {\n+        Load p = null;\n+\n+        if (cond1) {\n+            p = new Load(y, x);\n+        }\n+\n+        if (cond2 && cond1) {\n+            return p.x;\n+        } else {\n+            return 321;\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testCondAfterMergeWithNull_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCondAfterMergeWithNull(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testLoadAfterLoopAlias(boolean cond, int x, int y) {\n+        Load a = new Load(x, y);\n+        Load b = new Load(y, x);\n+        Load c = a;\n+\n+        for (int i=10; i<232; i++) {\n+            if (i == x) {\n+                c = b;\n+            }\n+        }\n+\n+        return cond ? c.x : c.y;\n+    }\n+\n+    @Benchmark\n+    public void testLoadAfterLoopAlias_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testLoadAfterLoopAlias(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCallTwoSide(boolean cond1, int x, int y) {\n+        Load p = dummy(x, y);\n+\n+        if (cond1) {\n+            p = dummy(y, x);\n+        }\n+\n+        return (p != null) ? p.x : 0;\n+    }\n+\n+    @Benchmark\n+    public void testCallTwoSide_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCallTwoSide(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testMergedAccessAfterCallNoWrite(boolean cond, int x, int y) {\n+        Load p2 = new Load(x, x);\n+        Load p = new Load(y, y);\n+        int res = 0;\n+\n+        p.x = p.x * y;\n+\n+        if (cond) {\n+            p = new Load(y, y);\n+        }\n+\n+        dummy(p2);\n+\n+        for (int i=3; i<324; i++) {\n+            res += p.x + i * x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testMergedAccessAfterCallNoWrite_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testMergedAccessAfterCallNoWrite(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCmpMergeWithNull_Second(boolean cond, int x, int y) {\n+        Load p = null;\n+\n+        if (cond) {\n+            p = new Load(x*x, y*y);\n+        }\n+\n+        dummy(x);\n+\n+        if (p != null) {\n+            return p.x * p.y;\n+        } else {\n+            return 1984;\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testCmpMergeWithNull_Second_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCmpMergeWithNull_Second(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testObjectIdentity(boolean cond, int x, int y) {\n+        Load o = new Load(x, y);\n+\n+        if (cond && x == 42) {\n+            o = global_escape;\n+        }\n+\n+        return o.x + o.y;\n+    }\n+\n+    @Benchmark\n+    public void testObjectIdentity_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testObjectIdentity(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSubclassesTrapping(boolean c1, boolean c2, int x, int y, int w, int z) {\n+        new A();\n+        Root s = new Home(x, y);\n+        new B();\n+\n+        if (c1) {\n+            new C();\n+            s = new Etc(\"Hello\");\n+            new D();\n+        } else {\n+            new E();\n+            s = new Usr(y, x, z);\n+            new F();\n+        }\n+\n+        int res = s.a;\n+        dummy();\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testSubclassesTrapping_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSubclassesTrapping(cond1[i], cond2[i], xs[i], ys[i], ws[i], zs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCmpMergeWithNull(boolean cond, int x, int y) {\n+        Load p = null;\n+\n+        if (cond) {\n+            p = new Load(x*x, y*y);\n+        } else if (x > y) {\n+            p = new Load(x+y, x*y);\n+        }\n+\n+        if (p != null) {\n+            return p.x * p.y;\n+        } else {\n+            return 1984;\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testCmpMergeWithNull_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCmpMergeWithNull(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSubclasses(boolean c1, boolean c2, int x, int y, int w, int z) {\n+        new A();\n+        Root s = new Home(x, y);\n+        new B();\n+\n+        if (c1) {\n+            new C();\n+            s = new Etc(\"Hello\");\n+            new D();\n+        } else {\n+            new E();\n+            s = new Usr(y, x, z);\n+            new F();\n+        }\n+\n+        new G();\n+\n+        return s.a;\n+    }\n+\n+    @Benchmark\n+    public void testSubclasses_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSubclasses(cond1[i], cond2[i], xs[i], ys[i], ws[i], zs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ ------------------ Some Scalar Replacement Should Happen in The Tests Below ------------------- \/\/\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testPartialPhis(boolean cond, int l, int x, int y) {\n+        int k = l;\n+\n+        if (l == 0) {\n+            k = l + 1;\n+        } else if (l == 2) {\n+            k = l + 2;\n+        } else if (l == 3) {\n+            new Load(x, y);\n+        } else if (l == 4) {\n+            new Load(y, x);\n+        }\n+\n+        return k;\n+    }\n+\n+    @Benchmark\n+    public void testPartialPhis_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testPartialPhis(cond1[i], xs[i], ys[i], zs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testPollutedNoWrite(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Square(l);\n+        Shape obj = null;\n+        int res = 0;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i=1; i<132; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res + obj1.x + obj2.y;\n+    }\n+\n+    @Benchmark\n+    public void testPollutedNoWrite_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testPollutedNoWrite(cond1[i], xs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testThreeWayAliasedAlloc(boolean cond, int x, int y) {\n+        Load p1 = new Load(x, y);\n+        Load p2 = new Load(x+1, y+1);\n+        Load p3 = new Load(x+2, y+2);\n+\n+        if (cond) {\n+            p3 = p1;\n+        } else {\n+            p3 = p2;\n+        }\n+\n+        return p3.x + p3.y;\n+    }\n+\n+    @Benchmark\n+    public void testThreeWayAliasedAlloc_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testThreeWayAliasedAlloc(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int TestTrapAfterMerge(boolean cond, int x, int y) {\n+        Load p = new Load(x, x);\n+\n+        if (cond) {\n+            p = new Load(y, y);\n+        }\n+\n+        for (int i=402; i<432; i+=x) {\n+            x++;\n+        }\n+\n+        return p.x + x;\n+    }\n+\n+    @Benchmark\n+    public void TestTrapAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += TestTrapAfterMerge(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    Load testNestedObjectsObject(boolean cond, int x, int y) {\n+        Picture p = new Picture(x, x, y);\n+\n+        if (cond) {\n+            p = new Picture(y, y, x);\n+        }\n+\n+        return p.position;\n+    }\n+\n+    @Benchmark\n+    public void testNestedObjectsObject_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testNestedObjectsObject(cond1[i], xs[i], ys[i]).x;\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testNestedObjectsNoEscapeObject(boolean cond, int x, int y) {\n+        Picture p = new Picture(x, x, y);\n+\n+        if (cond) {\n+            p = new Picture(y, y, x);\n+        }\n+\n+        return p.position.x;\n+    }\n+\n+    @Benchmark\n+    public void testNestedObjectsNoEscapeObject_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testNestedObjectsNoEscapeObject(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    Load[] testNestedObjectsArray(boolean cond, int x, int y) {\n+        PicturePositions p = new PicturePositions(x, y, x+y);\n+\n+        if (cond) {\n+            p = new PicturePositions(x+1, y+1, x+y+1);\n+        }\n+\n+        return p.positions;\n+    }\n+\n+    @Benchmark\n+    public void testNestedObjectsArray_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            Load[] partial = testNestedObjectsArray(cond1[i], xs[i], ys[i]);\n+            result += partial[0].x;\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testTrappingAfterMerge(boolean cond, int x, int y) {\n+        Load p = new Load(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Load(y, y);\n+        }\n+\n+        for (int i=832; i<932; i++) {\n+            res += p.x;\n+        }\n+\n+        if (x > y) {\n+            res += new Load(p.x, p.y).x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testTrappingAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testTrappingAfterMerge(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSimpleAliasedAlloc(boolean cond, int x, int y) {\n+        Load p1 = new Load(x, y);\n+        Load p2 = new Load(y, x);\n+        Load p = p1;\n+\n+        if (cond) {\n+            p = p2;\n+        }\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Benchmark\n+    public void testSimpleAliasedAlloc_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSimpleAliasedAlloc(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSimpleDoubleMerge(boolean cond, int x, int y) {\n+        Load p1 = new Load(x, y);\n+        Load p2 = new Load(x+1, y+1);\n+\n+        if (cond) {\n+            p1 = new Load(y, x);\n+            p2 = new Load(y+1, x+1);\n+        }\n+\n+        return p1.x + p2.y;\n+    }\n+\n+    @Benchmark\n+    public void testSimpleDoubleMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSimpleDoubleMerge(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testConsecutiveSimpleMerge(boolean cond1, boolean cond2, int x, int y) {\n+        Load p0 = new Load(x, x);\n+        Load p1 = new Load(x, y);\n+        Load pA = null;\n+\n+        Load p2 = new Load(y, x);\n+        Load p3 = new Load(y, y);\n+        Load pB = null;\n+\n+        if (cond1) {\n+            pA = p0;\n+        } else {\n+            pA = p1;\n+        }\n+\n+        if (cond2) {\n+            pB = p2;\n+        } else {\n+            pB = p3;\n+        }\n+\n+        return pA.x * pA.y + pB.x * pB.y;\n+    }\n+\n+    @Benchmark\n+    public void testConsecutiveSimpleMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testConsecutiveSimpleMerge(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testDoubleIfElseMerge(boolean cond, int x, int y) {\n+        Load p1 = new Load(x, y);\n+        Load p2 = new Load(x+1, y+1);\n+\n+        if (cond) {\n+            p1 = new Load(y, x);\n+            p2 = new Load(y, x);\n+        } else {\n+            p1 = new Load(x, y);\n+            p2 = new Load(x+1, y+1);\n+        }\n+\n+        return p1.x * p2.y;\n+    }\n+\n+    @Benchmark\n+    public void testDoubleIfElseMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testDoubleIfElseMerge(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testNoEscapeWithLoadInLoop(boolean cond, int x, int y) {\n+        Load p = new Load(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Load(y, x);\n+        }\n+\n+        for (int i=3342; i<4234; i++) {\n+            res += p.x + p.y + i;\n+        }\n+\n+        return res + p.x + p.y;\n+    }\n+\n+    @Benchmark\n+    public void testNoEscapeWithLoadInLoop_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testNoEscapeWithLoadInLoop(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCmpAfterMerge(boolean cond, boolean cond2, int x, int y) {\n+        Load a = new Load(x, y);\n+        Load b = new Load(y, x);\n+        Load c = null;\n+\n+        if (x+2 >= y-5) {\n+            c = a;\n+        } else {\n+            c = b;\n+        }\n+\n+        return cond2 ? c.x : c.y;\n+    }\n+\n+    @Benchmark\n+    public void testCmpAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCmpAfterMerge(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCondAfterMergeWithAllocate(boolean cond1, boolean cond2, int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        if (cond1) {\n+            p = new Load(y, x);\n+        }\n+\n+        if (cond2 && cond1) {\n+            return p.x;\n+        } else {\n+            return 321;\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testCondAfterMergeWithAllocate_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCondAfterMergeWithAllocate(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testCondLoadAfterMerge(boolean cond1, boolean cond2, int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        if (cond1) {\n+            p = new Load(y, x);\n+        }\n+\n+        if (cond1 == false && cond2 == false) {\n+            return p.x + 1;\n+        } else if (cond1 == false && cond2 == true) {\n+            return p.x + 30;\n+        } else if (cond1 == true && cond2 == false) {\n+            return p.x + 40;\n+        } else if (cond1 == true && cond2 == true) {\n+            return p.x + 50;\n+        } else {\n+            return -1;\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testCondLoadAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testCondLoadAfterMerge(cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    public int testIfElseInLoop(int x, int y, int w, int z) {\n+        int res = 0;\n+\n+        for (int i=x; i<y; i++) {\n+            Load obj = new Load(w, z);\n+\n+            if (i % 2 == 1) {\n+                obj = new Load(i, i+1);\n+            } else {\n+                obj = new Load(i-1, i);\n+            }\n+\n+            res += obj.x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testIfElseInLoop_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testIfElseInLoop(xs[i] % 100, ys[i] % 100, ws[i], zs[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testLoadInCondAfterMerge(boolean cond, int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        if (cond) {\n+            p = new Load(y, x);\n+        }\n+\n+        if (p.x == 10) {\n+            if (p.y == 10) {\n+                return dummy(10);\n+            } else {\n+                return dummy(20);\n+            }\n+        } else if (p.x == 20) {\n+            if (p.y == 20) {\n+                return dummy(30);\n+            } else {\n+                return dummy(40);\n+            }\n+        }\n+\n+        return 1984;\n+    }\n+\n+    @Benchmark\n+    public void testLoadInCondAfterMerge_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testLoadInCondAfterMerge(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testLoadInLoop(boolean cond, int x, int y) {\n+        Load obj1 = new Load(x, y);\n+        Load obj2 = new Load(y, x);\n+        Load obj = null;\n+        int res = 0;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i = 0; i < 532; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testLoadInLoop_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testLoadInLoop(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testMergesAndMixedEscape(boolean cond, int x, int y) {\n+        Load p1 = new Load(x, y);\n+        Load p2 = new Load(x, y);\n+        int val = 0;\n+\n+        if (cond) {\n+            p1 = new Load(x+1, y+1);\n+            val = dummy(p2);\n+        }\n+\n+        return val + p1.x + p2.y;\n+    }\n+\n+    @Benchmark\n+    public void testMergesAndMixedEscape_runner(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testMergesAndMixedEscape(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSRAndNSR_NoTrap(boolean cond1, int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        if (cond1) {\n+            p = new Load(x+1, y+1);\n+            global_escape = p;\n+        }\n+\n+        return p.y;\n+    }\n+\n+    @Benchmark\n+    public void testSRAndNSR_NoTrap_caller(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSRAndNSR_NoTrap(cond1[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    int testSRAndNSR_Trap(boolean is_c2, boolean cond1, boolean cond2, int x, int y) {\n+        Load p = new Load(x, y);\n+\n+        if (cond1) {\n+            p = new Load(x+1, y+1);\n+            global_escape = p;\n+        }\n+\n+        int res = p.x;\n+        if (is_c2) {\n+            \/\/ This will show up to C2 as a trap.\n+            dummy_defaults();\n+        }\n+\n+        return res;\n+    }\n+\n+    @Benchmark\n+    public void testSRAndNSR_Trap_caller(Blackhole bh) {\n+        int result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testSRAndNSR_Trap(true, cond1[i], cond2[i], xs[i], ys[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    char testString_one(boolean cond1) {\n+        String p = new String(\"Java\");\n+\n+        if (cond1) {\n+            p = new String(\"HotSpot\");\n+        }\n+\n+        return p.charAt(0);\n+    }\n+\n+    @Benchmark\n+    public void testString_one_caller(Blackhole bh) {\n+        char result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testString_two(cond1[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @CompilerControl(CompilerControl.Mode.DONT_INLINE)\n+    private char testString_two(boolean cond1) {\n+        String p = new String(\"HotSpot\");\n+\n+        if (cond1) {\n+            p = dummy(\"String\");\n+            if (p == null) return 'J';\n+        }\n+\n+        return p.charAt(0);\n+    }\n+\n+    @Benchmark\n+    public void testString_two_caller(Blackhole bh) {\n+        char result = 0;\n+        for (int i = 0 ; i < SIZE; i++) {\n+            result += testString_two(cond1[i]);\n+        }\n+        bh.consume(result);\n+    }\n+\n+    \/\/ ------------------ Utility for Benchmarking ------------------- \/\/\n+\n+    @Fork(value = 3, jvmArgsPrepend = {\n+        \"-XX:+UnlockDiagnosticVMOptions\",\n+        \"-XX:+UseTLAB\",\n+        \"-XX:-ReduceAllocationMerges\",\n+    })\n+    public static class NopRAM extends AllocationMerges {\n+    }\n+\n+    @Fork(value = 3, jvmArgsPrepend = {\n+        \"-XX:+UnlockDiagnosticVMOptions\",\n+        \"-XX:+ReduceAllocationMerges\",\n+    })\n+    public static class YesRAM extends AllocationMerges {\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static void dummy() {\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static int dummy(Load p) {\n+        return p.x * p.y;\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static int dummy(int x) {\n+        return x;\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static Load dummy(int x, int y) {\n+        return new Load(x, y);\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static String dummy(String str) {\n+        return str;\n+    }\n+\n+    @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+    static ADefaults dummy_defaults() {\n+        return new ADefaults();\n+    }\n+\n+    static class Load {\n+        long id;\n+        String name;\n+        Integer[] values = new Integer[10];\n+        int x, y;\n+\n+        @CompilerControl(CompilerControl.Mode.INLINE)\n+        Load(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (o == this) return true;\n+            if (!(o instanceof Load)) return false;\n+            Load p = (Load) o;\n+            return (p.x == x) && (p.y == y);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return x + y;\n+        }\n+    }\n+\n+    class Shape {\n+        int x, y, l;\n+        Shape(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+    }\n+\n+    class Square extends Shape {\n+        Square(int l) {\n+            super(0, 0);\n+            this.l = l;\n+        }\n+    }\n+\n+    class Circle extends Shape {\n+        Circle(int l) {\n+            super(0, 0);\n+            this.l = l;\n+        }\n+    }\n+\n+    static class ADefaults {\n+        static int ble;\n+        int i;\n+        @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+        ADefaults(int i) { this.i = i; }\n+        @CompilerControl(CompilerControl.Mode.EXCLUDE)\n+        ADefaults() { }\n+    }\n+\n+    static class Picture {\n+        public int id;\n+        public Load position;\n+\n+        public Picture(int id, int x, int y) {\n+            this.id = id;\n+            this.position = new Load(x, y);\n+        }\n+    }\n+\n+    static class PicturePositions {\n+        public int id;\n+        public Load[] positions;\n+\n+        @CompilerControl(CompilerControl.Mode.INLINE)\n+        public PicturePositions(int id, int x, int y) {\n+            this.id = id;\n+            this.positions = new Load[] { new Load(x, y), new Load(y, x) };\n+        }\n+    }\n+\n+    class Root {\n+        public int a;\n+        public int b;\n+        public int c;\n+        public int d;\n+        public int e;\n+\n+        public Root(int a, int b, int c, int d, int e) {\n+            this.a = a;\n+            this.b = b;\n+            this.c = c;\n+            this.d = d;\n+            this.e = e;\n+        }\n+    }\n+\n+    class Usr extends Root {\n+        public float flt;\n+\n+        public Usr(float a, float b, float c) {\n+            super((int)a, (int)b, (int)c, 0, 0);\n+            this.flt = a;\n+        }\n+    }\n+\n+    class Home extends Root {\n+        public double[] arr;\n+\n+        public Home(double a, double b) {\n+            super((int)a, (int)b, 0, 0, 0);\n+            this.arr = new double[] {a, b};\n+        }\n+\n+    }\n+\n+    class Tmp extends Root {\n+        public String s;\n+\n+        public Tmp(String s) {\n+            super((int)s.length(), 0, 0, 0, 0);\n+            this.s = s;\n+        }\n+    }\n+\n+    class Etc extends Root {\n+        public String a;\n+\n+        public Etc(String s) {\n+            super((int)s.length(), 0, 0, 0, 0);\n+            this.a = s;\n+        }\n+    }\n+\n+    class A { }\n+    class B { }\n+    class C { }\n+    class D { }\n+    class E { }\n+    class F { }\n+    class G { }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/compiler\/AllocationMerges.java","additions":1379,"deletions":0,"binary":false,"changes":1379,"status":"added"}]}