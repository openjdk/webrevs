{"files":[{"patch":"@@ -1695,0 +1695,57 @@\n+bool G1CollectedHeap::wait_full_mark_finished(GCCause::Cause cause,\n+                                              uint old_marking_started_before,\n+                                              uint old_marking_started_after,\n+                                              uint old_marking_completed_after) {\n+  \/\/ Request is finished if a full collection (concurrent or stw)\n+  \/\/ was started after this request and has completed, e.g.\n+  \/\/ started_before < completed_after.\n+  if (gc_counter_less_than(old_marking_started_before,\n+                           old_marking_completed_after)) {\n+    LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);\n+    return true;\n+  }\n+\n+  if (old_marking_started_after != old_marking_completed_after) {\n+    \/\/ If there is an in-progress cycle (possibly started by us), then\n+    \/\/ wait for that cycle to complete, e.g.\n+    \/\/ while completed_now < started_after.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"wait\");\n+    MonitorLocker ml(G1OldGCCount_lock);\n+    while (gc_counter_less_than(_old_marking_cycles_completed,\n+                                old_marking_started_after)) {\n+      ml.wait();\n+    }\n+    \/\/ Request is finished if the collection we just waited for was\n+    \/\/ started after this request.\n+    if (old_marking_started_before != old_marking_started_after) {\n+      LOG_COLLECT_CONCURRENTLY(cause, \"complete after wait\");\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+static bool should_retry_vm_op(GCCause::Cause cause,\n+                               VM_G1TryInitiateConcMark* op) {\n+  if (op->cycle_already_in_progress()) {\n+    \/\/ If VMOp failed because a cycle was already in progress, it\n+    \/\/ is now complete.  But it didn't finish this user-requested\n+    \/\/ GC, so try again.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"retry after in-progress\");\n+    return true;\n+  } else if (op->whitebox_attached()) {\n+    \/\/ If WhiteBox wants control, wait for notification of a state\n+    \/\/ change in the controller, then try again.  Don't wait for\n+    \/\/ release of control, since collections may complete while in\n+    \/\/ control.  Note: This won't recognize a STW full collection\n+    \/\/ while waiting; we can't wait on multiple monitors.\n+    LOG_COLLECT_CONCURRENTLY(cause, \"whitebox control stall\");\n+    MonitorLocker ml(ConcurrentGCBreakpoints::monitor());\n+    if (ConcurrentGCBreakpoints::is_controlled()) {\n+      ml.wait();\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n@@ -1755,4 +1812,20 @@\n-    } else if (GCCause::is_codecache_requested_gc(cause) && op.marking_in_progress()) {\n-        \/\/ For a CodeCache requested GC, before marking, progress is ensured as the\n-        \/\/ following Remark pause unloads code (and signals the requestr such).\n-        \/\/ Otherwise we must ensure that it is restarted later further below.\n+    } else if (GCCause::is_codecache_requested_gc(cause)) {\n+      \/\/ For a CodeCache requested GC, before marking, progress is ensured as the\n+      \/\/ following Remark pause unloads code (and signals the requester such).\n+      \/\/ Otherwise we must ensure that it is restarted.\n+      \/\/\n+      \/\/ For a CodeCache requested GC, a successful GC operation means that\n+      \/\/ (1) marking is in progress. I.e. the VMOp started the marking or a\n+      \/\/     Remark pause is pending from a different VM op; we will potentially\n+      \/\/     abort a mixed phase if needed.\n+      \/\/ (2) a new cycle was started (by this thread or some other), or\n+      \/\/ (3) a Full GC was performed.\n+      \/\/\n+      \/\/ Cases (2) and (3) are detected together by a change to\n+      \/\/ _old_marking_cycles_started.\n+      \/\/\n+      \/\/ Compared to other \"automatic\" GCs (see below), we do not consider being\n+      \/\/ in whitebox as sufficient too because we might be anywhere within that\n+      \/\/ cycle and we need to make progress.\n+      if (op.mark_in_progress() ||\n+          (old_marking_started_before != old_marking_started_after)) {\n@@ -1761,3 +1834,15 @@\n-    } else if (!GCCause::is_user_requested_gc(cause) && !GCCause::is_codecache_requested_gc(cause)) {\n-      \/\/ For an \"automatic\" (not user-requested, non-codecache related) collection,\n-      \/\/ we just need to ensure that progress is made.\n+      }\n+\n+      if (wait_full_mark_finished(cause,\n+                                  old_marking_started_before,\n+                                  old_marking_started_after,\n+                                  old_marking_completed_after)) {\n+        return true;\n+      }\n+\n+      if (should_retry_vm_op(cause, &op)) {\n+        continue;\n+      }\n+     } else if (!GCCause::is_user_requested_gc(cause)) {\n+      \/\/ For an \"automatic\" (not user-requested) collection, we just need to\n+      \/\/ ensure that progress is made.\n@@ -1767,2 +1852,1 @@\n-      \/\/ (2) a concurrent cycle was already in progress and we were\n-      \/\/     before the Remark pause for CodeCache requested GCs,\n+      \/\/ (2) a concurrent cycle was already in progress,\n@@ -1774,5 +1858,0 @@\n-      \/\/\n-      \/\/ Note that (1) does not imply (4).  If we're still in the mixed\n-      \/\/ phase of an earlier concurrent collection, the request to make the\n-      \/\/ collection a concurrent start won't be honored.  If we don't check for\n-      \/\/ both conditions we'll spin doing back-to-back collections.\n@@ -1786,15 +1865,8 @@\n-    } else {\n-      \/\/ GC request that needs to ensure that a complete full collection has been\n-      \/\/ performed before returning, but without waiting for more than needed.\n-      \/\/\n-      \/\/ This may either be a user-requested GC (e.g. System.gc()) or a CodeCache\n-      \/\/ requested collection where we already passed code unloading during a\n-      \/\/ concurrent cycle.\n-      \/\/\n-      \/\/ For these GCs a distinction needs to be made:\n-      \/\/ - CodeCache related GCs \"successfully\" triggered a GC,\n-      \/\/ - for other GCs (unlike non-UR), a successful VMOp implies a\n-      \/\/   new cycle was started. That's good, because it's not clear what we\n-      \/\/   should do otherwise.\n-      \/\/\n-      \/\/ In both cases, immediately trying again just does back to back GCs.\n+    } else {                    \/\/ User-requested GC.\n+      \/\/ For a user-requested collection, we want to ensure that a complete\n+      \/\/ full collection has been performed before returning, but without\n+      \/\/ waiting for more than needed.\n+\n+      \/\/ For user-requested GCs (unlike non-UR), a successful VMOp implies a\n+      \/\/ new cycle was started.  That's good, because it's not clear what we\n+      \/\/ should do otherwise.  Trying again just does back to back GCs.\n@@ -1803,4 +1875,1 @@\n-      bool is_codecache_gc = GCCause::is_codecache_requested_gc(cause);\n-\n-      assert(is_codecache_gc ||\n-             !op.gc_succeeded() ||\n+      assert(!op.gc_succeeded() ||\n@@ -1808,2 +1877,1 @@\n-             \"invariant: codecache gc: %s succeeded %s, started before %u, started after %u\",\n-             BOOL_TO_STR(is_codecache_gc),\n+             \"invariant: succeeded %s, started before %u, started after %u\",\n@@ -1813,6 +1881,4 @@\n-      \/\/ Request is finished if a full collection (concurrent or stw)\n-      \/\/ was started after this request and has completed, e.g.\n-      \/\/ started_before < completed_after.\n-      if (gc_counter_less_than(old_marking_started_before,\n-                               old_marking_completed_after)) {\n-        LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);\n+      if (wait_full_mark_finished(cause,\n+                                  old_marking_started_before,\n+                                  old_marking_started_after,\n+                                  old_marking_completed_after)) {\n@@ -1822,18 +1888,0 @@\n-      if (old_marking_started_after != old_marking_completed_after) {\n-        \/\/ If there is an in-progress cycle (possibly started by us), then\n-        \/\/ wait for that cycle to complete, e.g.\n-        \/\/ while completed_now < started_after.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"wait\");\n-        MonitorLocker ml(G1OldGCCount_lock);\n-        while (gc_counter_less_than(_old_marking_cycles_completed,\n-                                    old_marking_started_after)) {\n-          ml.wait();\n-        }\n-        \/\/ Request is finished if the collection we just waited for was\n-        \/\/ started after this request.\n-        if (old_marking_started_before != old_marking_started_after) {\n-          LOG_COLLECT_CONCURRENTLY(cause, \"complete after wait\");\n-          return true;\n-        }\n-      }\n-\n@@ -1844,1 +1892,1 @@\n-      assert(!op.gc_succeeded() || is_codecache_gc, \"invariant\");\n+      assert(!op.gc_succeeded(), \"invariant\");\n@@ -1846,17 +1894,1 @@\n-      if (op.cycle_already_in_progress()) {\n-        \/\/ If VMOp failed because a cycle was already in progress, it\n-        \/\/ is now complete.  But it didn't finish this user-requested\n-        \/\/ GC, so try again.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"retry after in-progress\");\n-        continue;\n-      } else if (op.whitebox_attached()) {\n-        \/\/ If WhiteBox wants control, wait for notification of a state\n-        \/\/ change in the controller, then try again.  Don't wait for\n-        \/\/ release of control, since collections may complete while in\n-        \/\/ control.  Note: This won't recognize a STW full collection\n-        \/\/ while waiting; we can't wait on multiple monitors.\n-        LOG_COLLECT_CONCURRENTLY(cause, \"whitebox control stall\");\n-        MonitorLocker ml(ConcurrentGCBreakpoints::monitor());\n-        if (ConcurrentGCBreakpoints::is_controlled()) {\n-          ml.wait();\n-        }\n+      if (should_retry_vm_op(cause, &op)) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":109,"deletions":77,"binary":false,"changes":186,"status":"modified"},{"patch":"@@ -277,0 +277,7 @@\n+  \/\/ Wait until a full mark (either currently in progress or one that completed\n+  \/\/ after the current request) has finished. Returns whether that full mark started\n+  \/\/ after this request. If so, we typically do not need another one.\n+  bool wait_full_mark_finished(GCCause::Cause cause,\n+                               uint old_marking_started_before,\n+                               uint old_marking_started_after,\n+                               uint old_marking_completed_after);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1233,0 +1233,11 @@\n+static const char* requester_for_mixed_abort(GCCause::Cause cause) {\n+  if (cause == GCCause::_wb_breakpoint) {\n+    return \"run_to breakpoint\";\n+  } else if (GCCause::is_codecache_requested_gc(cause)) {\n+    return \"codecache\";\n+  } else {\n+    assert(G1CollectedHeap::heap()->is_user_requested_concurrent_full_gc(cause), \"must be\");\n+    return \"user\";\n+  }\n+}\n+\n@@ -1265,2 +1276,1 @@\n-               (cause == GCCause::_codecache_GC_threshold) ||\n-               (cause == GCCause::_codecache_GC_aggressive) ||\n+               GCCause::is_codecache_requested_gc(cause) ||\n@@ -1281,1 +1291,1 @@\n-                          (cause == GCCause::_wb_breakpoint) ? \"run_to breakpoint\" : \"user\");\n+                          requester_for_mixed_abort(cause));\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-  _marking_in_progress(false),\n+  _mark_in_progress(false),\n@@ -87,0 +87,3 @@\n+  _mark_in_progress = g1h->collector_state()->mark_in_progress();\n+  _cycle_already_in_progress = g1h->concurrent_mark()->cm_thread()->in_progress();\n+\n@@ -95,4 +98,2 @@\n-    \/\/ there is already a concurrent marking cycle in progress.  Set flags\n-    \/\/ to notify the caller and return immediately.\n-    _marking_in_progress = g1h->collector_state()->mark_in_progress();\n-    _cycle_already_in_progress = true;\n+    \/\/ there is already a concurrent marking cycle in progress. Flags to indicate\n+    \/\/ that were already set, so return immediately.\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.cpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-  bool _marking_in_progress;\n+  bool _mark_in_progress;\n@@ -63,1 +63,1 @@\n-  bool marking_in_progress() const { return _marking_in_progress; }\n+  bool mark_in_progress() const { return _mark_in_progress; }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}