{"files":[{"patch":"@@ -3924,0 +3924,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -109,0 +109,7 @@\n+  \/\/ The main load is a candidate to implement implicit null checks, as long as\n+  \/\/ legitimize_address() does not require a preceding lea instruction to\n+  \/\/ materialize the memory operand. The absence of a preceding lea instruction\n+  \/\/ is guaranteed for immLoffset8 memory operands, because these do not lead to\n+  \/\/ out-of-range offsets (see definition of immLoffset8). Fortunately,\n+  \/\/ immLoffset8 memory operands are the most common ones in practice.\n+  ins_is_late_expanded_null_check_candidate(opnd_array(1)->opcode() == INDOFFL8);\n@@ -120,1 +127,5 @@\n-      ref_addr = __ legitimize_address(ref_addr, 8, rscratch2);\n+      int size = 8;\n+      assert(!this->is_late_expanded_null_check_candidate() ||\n+             !MacroAssembler::legitimize_address_requires_lea(ref_addr, size),\n+             \"an instruction that can be used for implicit null checking should emit the candidate memory access first\");\n+      ref_addr = __ legitimize_address(ref_addr, size, rscratch2);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/z_aarch64.ad","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -131,0 +131,7 @@\n+  \/\/ Whether materializing the given address for a LDR\/STR requires an\n+  \/\/ additional lea instruction.\n+  static bool legitimize_address_requires_lea(const Address &a, int size) {\n+    return a.getMode() == Address::base_plus_offset &&\n+           !Address::offset_ok_for_immed(a.offset(), exact_log2(size));\n+  }\n+\n@@ -134,7 +141,5 @@\n-    if (a.getMode() == Address::base_plus_offset) {\n-      if (! Address::offset_ok_for_immed(a.offset(), exact_log2(size))) {\n-        block_comment(\"legitimize_address {\");\n-        lea(scratch, a);\n-        block_comment(\"} legitimize_address\");\n-        return Address(scratch);\n-      }\n+    if (legitimize_address_requires_lea(a, size)) {\n+      block_comment(\"legitimize_address {\");\n+      lea(scratch, a);\n+      block_comment(\"} legitimize_address\");\n+      return Address(scratch);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  ins_is_late_expanded_null_check_candidate(true);\n@@ -163,0 +164,1 @@\n+  ins_is_late_expanded_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/z\/z_ppc.ad","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3844,0 +3844,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -99,0 +99,1 @@\n+  ins_is_late_expanded_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/riscv\/gc\/z\/z_riscv.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2672,0 +2672,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -121,0 +121,4 @@\n+  \/\/ The main load is a candidate to implement implicit null checks. The\n+  \/\/ barrier's slow path includes an identical reload, which does not need to be\n+  \/\/ registered in the exception table because it is dominated by the main one.\n+  ins_is_late_expanded_null_check_candidate(true);\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/z_x86_64.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2059,0 +2059,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1629,0 +1629,2 @@\n+      } else if (strcmp (attr->_ident, \"ins_is_late_expanded_null_check_candidate\") == 0) {\n+        fprintf(fp, \"  virtual bool           is_late_expanded_null_check_candidate() const { return %s; }\\n\", attr->_val);\n","filename":"src\/hotspot\/share\/adlc\/output_h.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -467,0 +467,8 @@\n+  \/\/ Ensure that n happens at b or above, i.e. at a block that dominates b.\n+  \/\/ We expect n to be an orphan node without further inputs.\n+  void ensure_node_is_at_block_or_above(Node* n, Block* b);\n+\n+  \/\/ Move node n from its current placement into the end of block b.\n+  \/\/ Move also outgoing Mach projections.\n+  void move_node_and_its_projections_to_block(Node* n, Block* b);\n+\n","filename":"src\/hotspot\/share\/opto\/block.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -79,0 +79,30 @@\n+void PhaseCFG::move_node_and_its_projections_to_block(Node* n, Block* b) {\n+  assert(!is_CFG(n), \"cannot move CFG node\");\n+  Block* old = get_block_for_node(n);\n+  old->find_remove(n);\n+  b->add_inst(n);\n+  map_node_to_block(n, b);\n+  \/\/ Check for Mach projections that also need to be moved.\n+  for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+    Node* out = n->fast_out(i);\n+    if (!out->is_MachProj()) {\n+      continue;\n+    }\n+    assert(!n->is_MachProj(), \"nested projections are not allowed\");\n+    move_node_and_its_projections_to_block(out, b);\n+  }\n+}\n+\n+void PhaseCFG::ensure_node_is_at_block_or_above(Node* n, Block* b) {\n+  assert(!is_CFG(n), \"cannot move CFG node\");\n+  Block* current = get_block_for_node(n);\n+  if (current->dominates(b)) {\n+    return; \/\/ n is already placed above b, do nothing.\n+  }\n+  \/\/ We only expect nodes without further inputs, like MachTemp or load Base.\n+  assert(n->req() == 0 || (n->req() == 1 && n->in(0) == (Node*)C->root()),\n+         \"need for recursive hoisting not expected\");\n+  assert(b->dominates(current), \"precondition: can only move n to b if b dominates n\");\n+  move_node_and_its_projections_to_block(n, b);\n+}\n+\n@@ -163,1 +193,2 @@\n-    if (mach->barrier_data() != 0) {\n+    if (mach->barrier_data() != 0 &&\n+        !mach->is_late_expanded_null_check_candidate()) {\n@@ -165,4 +196,5 @@\n-      \/\/ not supported. These operations might expand into multiple assembly\n-      \/\/ instructions during code emission, including new memory accesses (e.g.\n-      \/\/ in G1's pre-barrier), which would invalidate the implicit null\n-      \/\/ exception table.\n+      \/\/ only supported if these are explicit marked as emitting a candidate\n+      \/\/ memory access instruction at their initial address. If not marked as\n+      \/\/ such, barrier-tagged operations might expand into one or several memory\n+      \/\/ access instructions located at arbitrary offsets from the initial\n+      \/\/ address, which would invalidate the implicit null exception table.\n@@ -324,0 +356,8 @@\n+      if (mach->in(j)->is_MachTemp()) {\n+        assert(mach->in(j)->outcnt() == 1, \"MachTemp nodes should not be shared\");\n+        \/\/ Ignore MachTemp inputs, they can be safely hoisted with the candidate.\n+        \/\/ MachTemp nodes have no inputs themselves and are only used to reserve\n+        \/\/ a scratch register for the implementation of the node (e.g. in\n+        \/\/ late-expanded GC barriers).\n+        continue;\n+      }\n@@ -391,24 +431,2 @@\n-        Node *temp = val->in(i);\n-        Block *tempb = get_block_for_node(temp);\n-        if (!tempb->dominates(block)) {\n-          assert(block->dominates(tempb), \"sanity check: temp node placement\");\n-          \/\/ We only expect nodes without further inputs, like MachTemp or load Base.\n-          assert(temp->req() == 0 || (temp->req() == 1 && temp->in(0) == (Node*)C->root()),\n-                 \"need for recursive hoisting not expected\");\n-          tempb->find_remove(temp);\n-          block->add_inst(temp);\n-          map_node_to_block(temp, block);\n-        }\n-      }\n-      valb->find_remove(val);\n-      block->add_inst(val);\n-      map_node_to_block(val, block);\n-      \/\/ DecodeN on x86 may kill flags. Check for flag-killing projections\n-      \/\/ that also need to be hoisted.\n-      for (DUIterator_Fast jmax, j = val->fast_outs(jmax); j < jmax; j++) {\n-        Node* n = val->fast_out(j);\n-        if( n->is_MachProj() ) {\n-          get_block_for_node(n)->find_remove(n);\n-          block->add_inst(n);\n-          map_node_to_block(n, block);\n-        }\n+        \/\/ Inputs of val may already be early enough, but if not move them together with val.\n+        ensure_node_is_at_block_or_above(val->in(i), block);\n@@ -416,0 +434,9 @@\n+      move_node_and_its_projections_to_block(val, block);\n+    }\n+  }\n+\n+  \/\/ Move any MachTemp inputs to the end of the test block.\n+  for (uint i = 0; i < best->req(); i++) {\n+    Node* n = best->in(i);\n+    if (n == nullptr || !n->is_MachTemp()) {\n+      continue;\n@@ -417,0 +444,1 @@\n+    ensure_node_is_at_block_or_above(n, block);\n@@ -418,0 +446,1 @@\n+\n@@ -419,4 +448,1 @@\n-  Block *old_block = get_block_for_node(best);\n-  old_block->find_remove(best);\n-  block->add_inst(best);\n-  map_node_to_block(best, block);\n+  move_node_and_its_projections_to_block(best, block);\n@@ -432,11 +458,0 @@\n-  \/\/ Check for flag-killing projections that also need to be hoisted\n-  \/\/ Should be DU safe because no edge updates.\n-  for (DUIterator_Fast jmax, j = best->fast_outs(jmax); j < jmax; j++) {\n-    Node* n = best->fast_out(j);\n-    if( n->is_MachProj() ) {\n-      get_block_for_node(n)->find_remove(n);\n-      block->add_inst(n);\n-      map_node_to_block(n, block);\n-    }\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":59,"deletions":44,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -389,0 +389,7 @@\n+\n+  \/\/ Whether this node is expanded during code emission into a sequence of\n+  \/\/ instructions and the first instruction can perform an implicit null check.\n+  virtual bool is_late_expanded_null_check_candidate() const {\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2017,2 +2017,4 @@\n-      assert(n->in(1)->as_Mach()->barrier_data() == 0,\n-             \"Implicit null checks on memory accesses with barriers are not yet supported\");\n+      MachNode* access = n->in(1)->as_Mach();\n+      assert(access->barrier_data() == 0 ||\n+             access->is_late_expanded_null_check_candidate(),\n+             \"Implicit null checks on memory accesses with barriers are only supported on nodes explicitly marked as null-check candidates\");\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,231 @@\n+\/*\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.gcbarriers;\n+\n+import compiler.lib.ir_framework.*;\n+import java.lang.invoke.VarHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.ref.Reference;\n+import java.lang.ref.ReferenceQueue;\n+import java.lang.ref.SoftReference;\n+import java.lang.ref.WeakReference;\n+import jdk.test.lib.Asserts;\n+\n+\/**\n+ * @test\n+ * @summary Test that implicit null checks are generated as expected for\n+            different GC memory accesses.\n+ * @library \/test\/lib \/\n+ * @run driver compiler.gcbarriers.TestImplicitNullChecks\n+ *\/\n+\n+\n+public class TestImplicitNullChecks {\n+\n+    static class Outer {\n+        Object f;\n+    }\n+\n+    static class OuterWithVolatileField {\n+        volatile Object f;\n+    }\n+\n+    static final VarHandle fVarHandle;\n+    static {\n+        MethodHandles.Lookup l = MethodHandles.lookup();\n+        try {\n+            fVarHandle = l.findVarHandle(Outer.class, \"f\", Object.class);\n+        } catch (Exception e) {\n+            throw new Error(e);\n+        }\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFramework.runWithFlags(\"-XX:CompileCommand=inline,java.lang.ref.*::*\",\n+                                   \"-XX:-TieredCompilation\");\n+    }\n+\n+    @Test\n+    @IR(applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoad(Outer o) {\n+        return o.f;\n+    }\n+\n+    @Test\n+    \/\/ On aarch64, volatile loads always use indirect memory operands, which\n+    \/\/ leads to a pattern that cannot be exploited by the current C2 analysis.\n+    \/\/ On PPC64, volatile loads are preceded by membar_volatile instructions,\n+    \/\/ which also inhibits the current C2 analysis.\n+    @IR(applyIfPlatformAnd = {\"aarch64\", \"false\", \"ppc\", \"false\"},\n+        applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadVolatile(OuterWithVolatileField o) {\n+        return o.f;\n+    }\n+\n+    @Run(test = {\"testLoad\",\n+                 \"testLoadVolatile\"},\n+         mode = RunMode.STANDALONE)\n+    static void runLoadTests() {\n+        {\n+            Outer o = new Outer();\n+            \/\/ Trigger compilation with implicit null check.\n+            for (int i = 0; i < 10_000; i++) {\n+                testLoad(o);\n+            }\n+            \/\/ Trigger null pointer exception.\n+            o = null;\n+            boolean nullPointerException = false;\n+            try {\n+                testLoad(o);\n+            } catch (NullPointerException e) { nullPointerException = true; }\n+            Asserts.assertTrue(nullPointerException);\n+        }\n+        {\n+            OuterWithVolatileField o = new OuterWithVolatileField();\n+            \/\/ Trigger compilation with implicit null check.\n+            for (int i = 0; i < 10_000; i++) {\n+                testLoadVolatile(o);\n+            }\n+            \/\/ Trigger null pointer exception.\n+            o = null;\n+            boolean nullPointerException = false;\n+            try {\n+                testLoadVolatile(o);\n+            } catch (NullPointerException e) { nullPointerException = true; }\n+            Asserts.assertTrue(nullPointerException);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 and ZGC stores cannot be currently used to implement implicit null\n+    \/\/ checks, because they expand into multiple memory access instructions that\n+    \/\/ are not necessarily located at the initial instruction start address.\n+    @IR(applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static void testStore(Outer o, Object o1) {\n+        o.f = o1;\n+    }\n+\n+    @Run(test = {\"testStore\"})\n+    static void runStoreTests() {\n+        {\n+            Outer o = new Outer();\n+            Object o1 = new Object();\n+            testStore(o, o1);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 and ZGC compare-and-exchange operations cannot be currently used to\n+    \/\/ implement implicit null checks, because they expand into multiple memory\n+    \/\/ access instructions that are not necessarily located at the initial\n+    \/\/ instruction start address. The same holds for testCompareAndSwap and\n+    \/\/ testGetAndSet below.\n+    @IR(applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testCompareAndExchange(Outer o, Object oldVal, Object newVal) {\n+        return fVarHandle.compareAndExchange(o, oldVal, newVal);\n+    }\n+\n+    @Test\n+    @IR(applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static boolean testCompareAndSwap(Outer o, Object oldVal, Object newVal) {\n+        return fVarHandle.compareAndSet(o, oldVal, newVal);\n+    }\n+\n+    @Test\n+    @IR(applyIfOr = {\"UseZGC\", \"true\", \"UseG1GC\", \"true\"},\n+        failOn = IRNode.NULL_CHECK,\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testGetAndSet(Outer o, Object newVal) {\n+        return fVarHandle.getAndSet(o, newVal);\n+    }\n+\n+    @Run(test = {\"testCompareAndExchange\",\n+                 \"testCompareAndSwap\",\n+                 \"testGetAndSet\"})\n+    static void runAtomicTests() {\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testCompareAndExchange(o, oldVal, newVal);\n+        }\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testCompareAndSwap(o, oldVal, newVal);\n+        }\n+        {\n+            Outer o = new Outer();\n+            Object oldVal = new Object();\n+            Object newVal = new Object();\n+            testGetAndSet(o, newVal);\n+        }\n+    }\n+\n+    @Test\n+    \/\/ G1 reference loads use indirect memory operands, which leads to a pattern\n+    \/\/ that cannot be exploited by the current C2 analysis. The same holds for\n+    \/\/ testLoadWeakReference.\n+    @IR(applyIf = {\"UseZGC\", \"true\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadSoftReference(SoftReference<Object> ref) {\n+        return ref.get();\n+    }\n+\n+    @Test\n+    @IR(applyIf = {\"UseZGC\", \"true\"},\n+        counts = {IRNode.NULL_CHECK, \"1\"},\n+        phase = CompilePhase.FINAL_CODE)\n+    static Object testLoadWeakReference(WeakReference<Object> ref) {\n+        return ref.get();\n+    }\n+\n+    @Run(test = {\"testLoadSoftReference\",\n+                 \"testLoadWeakReference\"})\n+    static void runReferenceTests() {\n+        {\n+            Object o1 = new Object();\n+            SoftReference<Object> sref = new SoftReference<Object>(o1);\n+            Object o2 = testLoadSoftReference(sref);\n+        }\n+        {\n+            Object o1 = new Object();\n+            WeakReference<Object> wref = new WeakReference<Object>(o1);\n+            Object o2 = testLoadWeakReference(wref);\n+        }\n+    }\n+\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/gcbarriers\/TestImplicitNullChecks.java","additions":231,"deletions":0,"binary":false,"changes":231,"status":"added"},{"patch":"@@ -1502,0 +1502,5 @@\n+    public static final String NULL_CHECK = PREFIX + \"NULL_CHECK\" + POSTFIX;\n+    static {\n+        machOnlyNameRegex(NULL_CHECK, \"NullCheck\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"}]}