{"files":[{"patch":"@@ -171,1 +171,1 @@\n-    rf(Rd, 0);\n+    zrf(Rd, 0);\n@@ -359,0 +359,10 @@\n+void Assembler::wrap_label(FloatRegister r, Label &L,\n+                           fp_memory_access_insn insn) {\n+  if (L.is_bound()) {\n+    (this->*insn)(r, target(L));\n+  } else {\n+    L.add_patch_at(code(), locator());\n+    (this->*insn)(r, pc());\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -781,0 +781,1 @@\n+  typedef void (Assembler::* fp_memory_access_insn)(FloatRegister Rt, address dest);\n@@ -786,0 +787,1 @@\n+  void wrap_label(FloatRegister r, Label &L, fp_memory_access_insn insn);\n@@ -1453,0 +1455,10 @@\n+  }                                                                     \\\n+  void NAME(FloatRegister Rt, address dest, relocInfo::relocType rtype) { \\\n+    InstructionMark im(this);                                           \\\n+    guarantee(rtype == relocInfo::internal_word_type,                   \\\n+              \"only internal_word_type relocs make sense here\");        \\\n+    code_section()->relocate(inst_mark(), InternalAddress(dest).rspec()); \\\n+    NAME(Rt, dest);                                                     \\\n+  }                                                                     \\\n+  void NAME(FloatRegister Rt, Label &L) {                               \\\n+    wrap_label(Rt, L, &Assembler::NAME);                                \\\n@@ -1455,0 +1467,1 @@\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -110,31 +111,0 @@\n-address LIR_Assembler::float_constant(float f) {\n-  address const_addr = __ float_constant(f);\n-  if (const_addr == nullptr) {\n-    bailout(\"const section overflow\");\n-    return __ code()->consts()->start();\n-  } else {\n-    return const_addr;\n-  }\n-}\n-\n-\n-address LIR_Assembler::double_constant(double d) {\n-  address const_addr = __ double_constant(d);\n-  if (const_addr == nullptr) {\n-    bailout(\"const section overflow\");\n-    return __ code()->consts()->start();\n-  } else {\n-    return const_addr;\n-  }\n-}\n-\n-address LIR_Assembler::int_constant(jlong n) {\n-  address const_addr = __ long_constant(n);\n-  if (const_addr == nullptr) {\n-    bailout(\"const section overflow\");\n-    return __ code()->consts()->start();\n-  } else {\n-    return const_addr;\n-  }\n-}\n-\n@@ -561,2 +531,8 @@\n-        __ adr(rscratch1, InternalAddress(float_constant(c->as_jfloat())));\n-        __ ldrs(dest->as_float_reg(), Address(rscratch1));\n+        union {\n+          jfloat as_float;\n+          uint32_t as_uint32;\n+        };\n+\n+        as_float = c->as_jfloat();\n+        __ movw(rscratch1, as_uint32);\n+        __ fmovs(dest->as_float_reg(), rscratch1);\n@@ -571,2 +547,21 @@\n-        __ adr(rscratch1, InternalAddress(double_constant(c->as_jdouble())));\n-        __ ldrd(dest->as_double_reg(), Address(rscratch1));\n+        union {\n+          jdouble as_double;\n+          uint64_t as_uint64;\n+        };\n+        as_double = c->as_jdouble();\n+\n+        int insns_for_mov_imm64 = __ mov_immediate64_insts_count(rscratch1, as_uint64);\n+        if (insns_for_mov_imm64 + 1 <= 4) {\n+          __ mov_immediate64(rscratch1, as_uint64);\n+          __ fmovd(dest->as_double_reg(), rscratch1);\n+        } else {\n+          Label after_constant;\n+          Label constant;\n+          __ ldrd(dest->as_double_reg(), constant);\n+          __ b(after_constant);\n+\n+          __ bind(constant);\n+          __ emit_double(as_double);\n+\n+          __ bind(after_constant);\n+        }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":30,"deletions":35,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -36,7 +36,0 @@\n-  \/\/ helper functions which checks for overflow and sets bailout if it\n-  \/\/ occurs.  Always returns a valid embeddable pointer but in the\n-  \/\/ bailout case the pointer won't be to unique storage.\n-  address float_constant(float f);\n-  address double_constant(double d);\n-\n-  address int_constant(jlong n);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.hpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -130,0 +130,3 @@\n+  product(bool, UsePostCallSequenceWithADRP, false,                     \\\n+          \"Use ADRP\/ADR to store metadata within post-call NOP \"        \\\n+          \"instruction sequences.\")\n","filename":"src\/hotspot\/cpu\/aarch64\/globals_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -1145,0 +1146,8 @@\n+  uint32_t offs = offset() + CodeBlob::align_code_offset(sizeof(nmethod));\n+  offs += code()->total_offset_of(code()->insts());\n+  uint32_t chunks_count = NativePostCallNop::metadata_chunks_count(offs);\n+  if (code_section()->scratch_emit()) {\n+    \/\/ Review\n+    \/\/ For size estimation, conservatively assume two slots will be required.\n+    chunks_count = 2;\n+  }\n@@ -1146,2 +1155,16 @@\n-  movk(zr, 0);\n-  movk(zr, 0);\n+  if (chunks_count == 1) {\n+    if (UsePostCallSequenceWithADRP) {\n+      adr(zr, pc());\n+    } else {\n+      movk(zr, 0);\n+    }\n+  } else if (chunks_count > 1) {\n+    assert(chunks_count == 2, \"either 1 or 2\");\n+    if (UsePostCallSequenceWithADRP) {\n+      _adrp(zr, pc());\n+      adr(zr, pc());\n+    } else {\n+      movz(zr, 0);\n+      movk(zr, 0);\n+    }\n+  }\n@@ -2277,1 +2300,2 @@\n-void MacroAssembler::mov_immediate64(Register dst, uint64_t imm64)\n+template<bool count_only> ALWAYSINLINE\n+int MacroAssembler::mov_immediate64(Register dst, uint64_t imm64)\n@@ -2280,1 +2304,1 @@\n-  {\n+  if (!count_only) {\n@@ -2286,0 +2310,10 @@\n+\n+  int insns_count = 0;\n+  int start_offset = offset();\n+#define DO(op) do { \\\n+      insns_count++; \\\n+      if (!count_only) { \\\n+        op; \\\n+      } \\\n+    } while (0)\n+\n@@ -2287,1 +2321,1 @@\n-    orr(dst, zr, imm64);\n+    DO(orr(dst, zr, imm64));\n@@ -2305,1 +2339,1 @@\n-      movz(dst, 0);\n+      DO(movz(dst, 0));\n@@ -2308,1 +2342,1 @@\n-      movn(dst, 0);\n+      DO(movn(dst, 0));\n@@ -2312,1 +2346,1 @@\n-          movz(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movz(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2320,1 +2354,1 @@\n-          movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4));\n+          DO(movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4)));\n@@ -2328,1 +2362,1 @@\n-          movz(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movz(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2335,1 +2369,1 @@\n-          movk(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movk(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2342,1 +2376,1 @@\n-          movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4));\n+          DO(movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4)));\n@@ -2349,1 +2383,1 @@\n-          movk(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movk(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2356,1 +2390,1 @@\n-          movz(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movz(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2363,1 +2397,1 @@\n-          movk(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movk(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2370,1 +2404,1 @@\n-          movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4));\n+          DO(movn(dst, (uint32_t)imm_h[i] ^ 0xffffL, (i << 4)));\n@@ -2377,1 +2411,1 @@\n-          movk(dst, (uint32_t)imm_h[i], (i << 4));\n+          DO(movk(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2382,1 +2416,1 @@\n-      movz(dst, (uint32_t)imm_h[0], 0);\n+      DO(movz(dst, (uint32_t)imm_h[0], 0));\n@@ -2384,1 +2418,1 @@\n-        movk(dst, (uint32_t)imm_h[i], (i << 4));\n+        DO(movk(dst, (uint32_t)imm_h[i], (i << 4)));\n@@ -2388,0 +2422,21 @@\n+\n+#undef DO\n+\n+  assert(insns_count != 0, \"expected at least one instruction\");\n+\n+  int emitted = offset() - start_offset;\n+  if (count_only) {\n+    assert(emitted == 0, \"no instruction should be emitted if counting only\");\n+  } else {\n+    assert(emitted == insns_count * NativeInstruction::instruction_size, \"incorrect count\");\n+  }\n+\n+  return insns_count;\n+}\n+\n+int MacroAssembler::mov_immediate64(Register dst, uint64_t imm64) {\n+  return mov_immediate64<\/*count_only=*\/false>(dst, imm64);\n+}\n+\n+int MacroAssembler::mov_immediate64_insts_count(Register dst, uint64_t imm64) {\n+  return mov_immediate64<\/*count_only=*\/true>(dst, imm64);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":74,"deletions":19,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -499,1 +499,4 @@\n-  void mov_immediate64(Register dst, uint64_t imm64);\n+  template<bool count_only>\n+  int mov_immediate64(Register dst, uint64_t imm64);\n+  int mov_immediate64_insts_count(Register dst, uint64_t imm64);\n+  int mov_immediate64(Register dst, uint64_t imm64);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -397,3 +398,39 @@\n-bool NativePostCallNop::patch(int32_t oopmap_slot, int32_t cb_offset) {\n-  if (((oopmap_slot & 0xff) != oopmap_slot) || ((cb_offset & 0xffffff) != cb_offset)) {\n-    return false; \/\/ cannot encode\n+template<typename Variant>\n+bool NativePostCallNop::patch_helper(int32_t oopmap_slot, int32_t cb_offset) {\n+  constexpr size_t block_size = HeapBlock::minimum_alignment();\n+  const int32_t cb_offset_to_segment = cb_offset + CodeHeap::header_size();\n+  const int32_t cb_blocks_offset = cb_offset_to_segment \/ block_size;\n+\n+  const uint32_t chunk1 = *(uint32_t*)addr_at(first_check_size);\n+  uint32_t data1 = Variant::extract_metadata(chunk1);\n+\n+  const uint32_t chunks_count = Variant::two_chunks_flag.extract(data1) + 1;\n+#ifdef ASSERT\n+  const uint32_t req_chunks_count = metadata_chunks_count<Variant>(cb_offset);\n+\n+  assert(block_size <= CodeCacheSegmentSize, \"incorrect block size value\");\n+\n+  uintptr_t code_blob_address = (uintptr_t) this - cb_offset;\n+  uint32_t code_blob_offset_from_segment = code_blob_address % block_size;\n+  assert(CodeHeap::header_size() == code_blob_offset_from_segment, \"unexpected offset value\");\n+\n+  bool is_empty;\n+\n+  if (chunks_count == 1) {\n+    is_empty = (data1 == 0);\n+    assert(req_chunks_count == 1, \"one metadata chunk is sufficient\");\n+  } else {\n+    assert(req_chunks_count <= 2, \"two metadata chunks are sufficient\");\n+    assert(chunks_count == 2, \"unexpected number of chunks\");\n+\n+    const uint32_t chunk2_offset = first_check_size + NativeInstruction::instruction_size;\n+    const uint32_t chunk2 = *(uint32_t*)addr_at(chunk2_offset);\n+    uint32_t data2 = Variant::extract_metadata(chunk2);\n+\n+    is_empty = (data1 == 1 && data2 == 0);\n+  }\n+\n+  if (!is_empty) {\n+    \/\/ If not empty, it can be a copy of the nmethod, in which case the\n+    \/\/ contents should already match the values requested from this method.\n+    verify(cb_offset, oopmap_slot);\n@@ -401,1 +438,16 @@\n-  uint32_t data = ((uint32_t)oopmap_slot << 24) | cb_offset;\n+#endif\n+\n+  uint64_t data = Variant::two_chunks_flag.insert(0, chunks_count - 1);\n+\n+  if (chunks_count == 1) {\n+    if (!pack<typename Variant::one_chunk>(\/* output *\/ data,\n+                                           oopmap_slot, cb_blocks_offset)) {\n+      return false;\n+    }\n+  } else {\n+    if (!pack<typename Variant::two_chunks>(\/* output *\/ data,\n+                                            oopmap_slot, cb_blocks_offset)) {\n+      return false;\n+    }\n+  }\n+\n@@ -403,4 +455,3 @@\n-  assert(data != 0, \"must be\");\n-  uint32_t insn1 = uint_at(4);\n-  uint32_t insn2 = uint_at(8);\n-  assert (is_movk_to_zr(insn1) && is_movk_to_zr(insn2), \"must be\");\n+  const uint32_t metadata_bits_count = chunks_count * Variant::metadata_chunk_width;\n+  const uint64_t metadata_mask = (1ull << metadata_bits_count) - 1;\n+  assert((data & metadata_mask) == data, \"insufficient metadata bits\");\n@@ -409,4 +460,10 @@\n-  uint32_t lo = data & 0xffff;\n-  uint32_t hi = data >> 16;\n-  Instruction_aarch64::patch(addr_at(4), 20, 5, lo);\n-  Instruction_aarch64::patch(addr_at(8), 20, 5, hi);\n+  address addr = addr_at(first_check_size);\n+\n+  data = Variant::patch_chunk(addr, data);\n+\n+  if (chunks_count == 2) {\n+    data = Variant::patch_chunk(addr + NativeInstruction::instruction_size, data);\n+  }\n+\n+  verify(cb_offset, oopmap_slot);\n+\n@@ -416,0 +473,9 @@\n+bool NativePostCallNop::patch(int32_t oopmap_slot, int32_t cb_offset) {\n+  const uint32_t chunk = *(uint32_t*)addr_at(first_check_size);\n+  if (VariantADR::is_match(chunk)) {\n+    return patch_helper<VariantADR>(oopmap_slot, cb_offset);\n+  } else {\n+    return patch_helper<VariantMOV>(oopmap_slot, cb_offset);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/nativeInst_aarch64.cpp","additions":78,"deletions":12,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -30,0 +31,1 @@\n+#include \"memory\/heap.hpp\"\n@@ -521,2 +523,3 @@\n-\/\/ A NativePostCallNop takes the form of three instructions:\n-\/\/     nop; movk zr, lo; movk zr, hi\n+\/\/ A NativePostCallNop takes the form of NOP followed by one or two instruction\n+\/\/ slots holding metadata chunks represented as instructions with no side\n+\/\/ effects.\n@@ -524,3 +527,52 @@\n-\/\/ The nop is patchable for a deoptimization trap. The two movk\n-\/\/ instructions execute as nops but have a 16-bit payload in which we\n-\/\/ can store an offset from the initial nop to the nmethod.\n+\/\/ The options are:\n+\/\/   - variant MOV\n+\/\/     - nop; movk zr, metadata (18-bit payload)\n+\/\/     - nop; movz zr, metadata_lo; movk\/movz zr, metadata_hi (37-bit payload)\n+\/\/   - variant ADR\n+\/\/     - nop; adr zr, metadata (21-bit payload)\n+\/\/     - nop; adrp zr, metadata_lo; adr\/adrp zr, metadata_hi (43-bit payload)\n+\/\/\n+\/\/ The nop is patchable for a deoptimization trap. The subsequent movk\/movz\/adr\/adrp\n+\/\/ execute as nops but contain metadata payload.\n+\/\/\n+\/\/ The metadata layout is as follows:\n+\/\/  - 1-bit field indicating whether one or two metadata chunks are present;\n+\/\/  - cb_blocks_offset (9 or 19 bits for MOV variant; 11 or 22 bits for ADR variant)\n+\/\/   - offset from the start of the code heap's space allocated for the method,\n+\/\/     in HeapBlock::minimum_alignment() blocks.\n+\/\/  - oopmap_slot (9 or 18 bits for MOV variant; 10 or 21 bits for ADR variant)\n+\/\/\n+\/\/ The metadata layout for these options is described via VariantMOV \/ VariantADR helpers,\n+\/\/ which also provide variant-specific implementation for matching format, extracting and\n+\/\/ patching metadata.\n+class NativePostCallNopMetadataField {\n+public:\n+  constexpr NativePostCallNopMetadataField(uint32_t shift, uint32_t width)\n+    : _shift(shift), _width(width), _mask((1ull << width) - 1) {\n+    assert(_shift + _width <= sizeof(uint64_t) * BitsPerByte, \"overflow\");\n+  }\n+\n+  constexpr NativePostCallNopMetadataField(NativePostCallNopMetadataField previous_field, uint32_t width)\n+    : NativePostCallNopMetadataField(previous_field.end_pos(), width) {}\n+\n+  constexpr uint32_t end_pos() const {\n+    return _shift + _width;\n+  }\n+\n+  constexpr bool can_hold(int32_t value) const {\n+    return (static_cast<int32_t>(value & _mask) == value);\n+  }\n+\n+  constexpr uint64_t extract(uint64_t data) const {\n+    return ((data >> _shift) & _mask);\n+  }\n+\n+  constexpr uint64_t insert(uint64_t data, uint32_t value) const {\n+    return data | ((uint64_t) value << _shift);\n+  }\n+\n+private:\n+  const uint32_t _shift;\n+  const uint32_t _width;\n+  const uint64_t _mask;\n+};\n@@ -530,2 +582,162 @@\n-  static bool is_movk_to_zr(uint32_t insn) {\n-    return ((insn & 0xffe0001f) == 0xf280001f);\n+  struct VariantADR {\n+    static constexpr uint32_t metadata_chunk_width = 22;\n+\n+    static constexpr NativePostCallNopMetadataField two_chunks_flag { 0, 1 };\n+\n+    struct one_chunk {\n+      static constexpr NativePostCallNopMetadataField cb_blocks_offset { two_chunks_flag, 11 };\n+      static constexpr NativePostCallNopMetadataField oopmap_slot { cb_blocks_offset, 10 };\n+      static_assert(oopmap_slot.end_pos() == metadata_chunk_width,\n+                    \"Should take exactly the width of one metadata chunk.\");\n+    };\n+\n+    struct two_chunks {\n+      static constexpr NativePostCallNopMetadataField cb_blocks_offset { two_chunks_flag, 22 };\n+      static constexpr NativePostCallNopMetadataField oopmap_slot { cb_blocks_offset, 21 };\n+      static_assert(oopmap_slot.end_pos() == 2 * metadata_chunk_width,\n+                    \"Should take exactly the width of two metadata chunks.\");\n+    };\n+\n+    static bool is_match(uint32_t chunk, bool assertion = true) {\n+      \/\/ Metadata chunks are in form of ADRP\/ADR XZR, <data>.\n+      bool matches = ((chunk & 0x1f00001f) == 0x1000001f);\n+      if (assertion) {\n+        assert(matches == UsePostCallSequenceWithADRP, \"mismatch with configuration\");\n+      }\n+      return matches;\n+    }\n+\n+    static uint32_t extract_metadata(uint32_t chunk) {\n+      uint32_t field1 = Instruction_aarch64::extract(chunk, 31, 31);\n+      uint32_t field2 = Instruction_aarch64::extract(chunk, 30, 29);\n+      uint32_t field3 = Instruction_aarch64::extract(chunk, 23, 5);\n+\n+      uint32_t data = field3;\n+      data <<= 2;\n+      data |= field2;\n+      data <<= 1;\n+      data |= field1;\n+\n+      return data;\n+    }\n+\n+    static uint64_t patch_chunk(address addr, uint64_t data) {\n+      uint32_t field1 = data & 1;\n+      data >>= 1;\n+      uint32_t field2 = data & 3;\n+      data >>= 2;\n+      uint32_t field3 = data & 0x7ffff;\n+      data >>= 19;\n+\n+      Instruction_aarch64::patch(addr, 31, 31, field1);\n+      Instruction_aarch64::patch(addr, 30, 29, field2);\n+      Instruction_aarch64::patch(addr, 23, 5, field3);\n+\n+      return data;\n+    }\n+  };\n+\n+  struct VariantMOV {\n+    static constexpr uint32_t metadata_chunk_width = 19;\n+\n+    static constexpr NativePostCallNopMetadataField two_chunks_flag { 0, 1 };\n+\n+    struct one_chunk {\n+      static constexpr NativePostCallNopMetadataField cb_blocks_offset { two_chunks_flag, 9 };\n+      static constexpr NativePostCallNopMetadataField oopmap_slot { cb_blocks_offset, 9 };\n+      static_assert(oopmap_slot.end_pos() == metadata_chunk_width,\n+                    \"Should take exactly the width of one metadata chunk.\");\n+    };\n+\n+    struct two_chunks {\n+      static constexpr NativePostCallNopMetadataField cb_blocks_offset { two_chunks_flag, 19 } ;\n+      static constexpr NativePostCallNopMetadataField oopmap_slot { cb_blocks_offset, 18 };\n+      static_assert(oopmap_slot.end_pos() == 2 * metadata_chunk_width,\n+                    \"Should take exactly the width of two metadata chunks.\");\n+    };\n+\n+    static bool is_match(uint32_t chunk, bool assertion = true) {\n+      \/\/ Metadata chunks are in form of MOVK\/MOVZ XZR, <data>.\n+      bool matches = ((chunk & 0xdf80001f) == 0xd280001f);\n+      if (assertion) {\n+        assert(matches == !UsePostCallSequenceWithADRP, \"mismatch with configuration\");\n+      }\n+      return matches;\n+    }\n+\n+    static uint32_t extract_metadata(uint32_t chunk) {\n+      uint32_t field1 = Instruction_aarch64::extract(chunk, 29, 29) ^ 1;\n+      uint32_t field2 = Instruction_aarch64::extract(chunk, 22, 21);\n+      uint32_t field3 = Instruction_aarch64::extract(chunk, 20, 5);\n+\n+      uint32_t data = field3;\n+      data <<= 2;\n+      data |= field2;\n+      data <<= 1;\n+      data |= field1;\n+\n+      return data;\n+    }\n+\n+    static uint64_t patch_chunk(address addr, uint64_t data) {\n+      uint32_t field1 = data & 1;\n+      data >>= 1;\n+      uint32_t field2 = data & 3;\n+      data >>= 2;\n+      uint32_t field3 = data & 0xffff;\n+      data >>= 16;\n+\n+      Instruction_aarch64::patch(addr, 29, 29, field1 ^ 1);\n+      Instruction_aarch64::patch(addr, 22, 21, field2);\n+      Instruction_aarch64::patch(addr, 20, 5, field3);\n+\n+      return data;\n+    }\n+  };\n+\n+  template<typename FieldsDescription>\n+  static bool unpack(uint64_t data, int32_t& oopmap_slot, int32_t& cb_blocks_offset) {\n+    oopmap_slot = FieldsDescription::oopmap_slot.extract(data);\n+    cb_blocks_offset = FieldsDescription::cb_blocks_offset.extract(data);\n+\n+    if (cb_blocks_offset == 0) {\n+      if (oopmap_slot == 0) {\n+        return false; \/\/ no information stored\n+      }\n+\n+      oopmap_slot--;\n+    }\n+\n+    return true;\n+  }\n+\n+  template<typename FieldsDescription>\n+  static bool pack(uint64_t& data, int32_t oopmap_slot, int32_t cb_blocks_offset) {\n+    if (!FieldsDescription::cb_blocks_offset.can_hold(cb_blocks_offset)) {\n+      return false;\n+    }\n+\n+    if (cb_blocks_offset == 0) {\n+      \/\/ Distinguish from the case when the fields are empty.\n+      oopmap_slot++;\n+    }\n+\n+    if (!FieldsDescription::oopmap_slot.can_hold(oopmap_slot)) {\n+      return false;\n+    }\n+\n+    data = FieldsDescription::cb_blocks_offset.insert(data, cb_blocks_offset);\n+    data = FieldsDescription::oopmap_slot.insert(data, oopmap_slot);\n+\n+    return true;\n+  }\n+\n+  template<typename Variant>\n+  bool patch_helper(int32_t oopmap_slot, int32_t cb_offset);\n+\n+  void verify(int32_t cb_offset, int32_t oopmap_slot) const {\n+    int32_t test_oopmap_slot;\n+    int32_t test_cb_offset;\n+    assert(decode(test_oopmap_slot, test_cb_offset), \"unpacking values failed\");\n+    assert(test_oopmap_slot == oopmap_slot, \"oopmap_slot mismatch\");\n+    assert(test_cb_offset == cb_offset, \"cb_offset mismatch\");\n@@ -538,1 +750,1 @@\n-    \/\/ at the end of page.\n+    \/\/ at the end of a page.\n@@ -543,1 +755,4 @@\n-    \/\/ Check the first instruction is NOP.\n+    \/\/ Check for a NOP followed by a metadata chunk.\n+    \/\/ This sequence only ever appears in a post-call\n+    \/\/ NOP, so it's unnecessary to check whether there is\n+    \/\/ a second metadata chunk following the sequence.\n@@ -545,6 +760,6 @@\n-      uint32_t insn = *(uint32_t*)addr_at(first_check_size);\n-      \/\/ Check next instruction is MOVK zr, xx.\n-      \/\/ These instructions only ever appear together in a post-call\n-      \/\/ NOP, so it's unnecessary to check that the third instruction is\n-      \/\/ a MOVK as well.\n-      return is_movk_to_zr(insn);\n+      uint32_t chunk = *(uint32_t*)addr_at(first_check_size);\n+      if (VariantADR::is_match(chunk, \/* assertion = *\/false)) {\n+        return true;\n+      } else if (VariantMOV::is_match(chunk, \/* assertion = *\/false)) {\n+        return true;\n+      }\n@@ -556,0 +771,1 @@\n+  template<typename Variant>\n@@ -557,6 +773,56 @@\n-    uint64_t movk_insns = *(uint64_t*)addr_at(4);\n-    uint32_t lo = (movk_insns >> 5) & 0xffff;\n-    uint32_t hi = (movk_insns >> (5 + 32)) & 0xffff;\n-    uint32_t data = (hi << 16) | lo;\n-    if (data == 0) {\n-      return false; \/\/ no information encoded\n+    uint32_t chunk_offset = first_check_size;\n+    const uint32_t chunk = *(uint32_t*)addr_at(chunk_offset);\n+\n+    assert(Variant::is_match(chunk), \"unexpected format\");\n+\n+    uint64_t data = Variant::extract_metadata(chunk);\n+    const uint32_t chunks_count = Variant::two_chunks_flag.extract(data) + 1;\n+\n+    int32_t cb_blocks_offset;\n+    if (chunks_count == 1) {\n+      if (!unpack<typename Variant::one_chunk>(data, oopmap_slot, cb_blocks_offset)) {\n+        return false;\n+      }\n+    } else {\n+      assert(chunks_count == 2, \"expected either one or two chunks\");\n+\n+      chunk_offset += NativeInstruction::instruction_size;\n+\n+      uint64_t data2 = Variant::extract_metadata(*(uint32_t*)addr_at(chunk_offset));\n+      data2 <<= Variant::metadata_chunk_width;\n+      data |= data2;\n+\n+      if (!unpack<typename Variant::two_chunks>(data, oopmap_slot, cb_blocks_offset)) {\n+        return false;\n+      }\n+    }\n+\n+    constexpr size_t block_size = HeapBlock::minimum_alignment();\n+    cb_offset = cb_blocks_offset * block_size;\n+    cb_offset += (uintptr_t) this % block_size;\n+    cb_offset -= CodeHeap::header_size();\n+\n+    return true;\n+  }\n+\n+  bool decode(int32_t& oopmap_slot, int32_t& cb_offset) const {\n+    const uint32_t chunk = *(uint32_t*)addr_at(first_check_size);\n+    if (VariantADR::is_match(chunk)) {\n+      return decode<VariantADR>(oopmap_slot, cb_offset);\n+    } else {\n+      return decode<VariantMOV>(oopmap_slot, cb_offset);\n+    }\n+  }\n+\n+  template<typename Variant>\n+  static uint32_t metadata_chunks_count(int32_t cb_offset) {\n+    constexpr size_t block_size = HeapBlock::minimum_alignment();\n+    uint32_t cb_blocks_offset = (cb_offset + CodeHeap::header_size()) \/ block_size;\n+    return Variant::one_chunk::cb_blocks_offset.can_hold(cb_blocks_offset) ? 1 : 2;\n+  }\n+\n+  static uint32_t metadata_chunks_count(int32_t cb_offset) {\n+    if (UsePostCallSequenceWithADRP) {\n+      return metadata_chunks_count<VariantADR>(cb_offset);\n+    } else {\n+      return metadata_chunks_count<VariantMOV>(cb_offset);\n@@ -564,3 +830,0 @@\n-    cb_offset = (data & 0xffffff);\n-    oopmap_slot = (data >> 24) & 0xff;\n-    return true; \/\/ decoding succeeded\n","filename":"src\/hotspot\/cpu\/aarch64\/nativeInst_aarch64.hpp","additions":287,"deletions":24,"binary":false,"changes":311,"status":"modified"},{"patch":"@@ -47,0 +47,2 @@\n+  static constexpr size_t minimum_alignment() { return 16; }\n+\n@@ -177,1 +179,1 @@\n-  static size_t header_size()         { return sizeof(HeapBlock); } \/\/ returns the header size for each heap block\n+  static constexpr size_t header_size() { return sizeof(HeapBlock); } \/\/ returns the header size for each heap block\n","filename":"src\/hotspot\/share\/memory\/heap.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"memory\/heap.hpp\"\n@@ -175,0 +176,8 @@\n+  if (CodeCacheSegmentSize < HeapBlock::minimum_alignment()) {\n+      JVMFlag::printError(verbose,\n+                          \"CodeCacheSegmentSize (%zu) must be \"\n+                          \"greater than or equal to %zu\\n\",\n+                          CodeCacheSegmentSize, HeapBlock::minimum_alignment());\n+      return JVMFlag::VIOLATES_CONSTRAINT;\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlagConstraintsCompiler.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -59,0 +59,19 @@\n+\/*\n+ * @test id=aarch64-post-call-nop-using-adr\n+ * @key randomness\n+ * @summary Fuzz tests for jdk.internal.vm.Continuation\n+ * @requires os.arch == \"aarch64\"\n+ * @requires vm.continuations\n+ * @requires vm.flavor == \"server\" & (vm.opt.TieredStopAtLevel == null | vm.opt.TieredStopAtLevel == 4)\n+ * @requires vm.opt.TieredCompilation == null | vm.opt.TieredCompilation == true\n+ * @modules java.base java.base\/jdk.internal.vm.annotation java.base\/jdk.internal.vm\n+ * @library \/test\/lib\n+ * @build java.base\/java.lang.StackWalkerHelper\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ *\n+ * @run main\/othervm\/timeout=1200 -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *                                -XX:+UnlockExperimentalVMOptions -XX:+UsePostCallSequenceWithADRP\n+ *                                Fuzz\n+ *\/\n+\n","filename":"test\/jdk\/jdk\/internal\/vm\/Continuation\/Fuzz.java","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"}]}