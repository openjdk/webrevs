{"files":[{"patch":"@@ -248,0 +248,16 @@\n+        if (UseSVE == 0 && !is_feat_fp16_supported()) {\n+          return false;\n+        }\n+        break;\n+      \/\/ At the time of writing this, the Vector API has no half-float (FP16) species.\n+      \/\/ Consequently, AddReductionVHF and MulReductionVHF are only produced by the\n+      \/\/ auto-vectorizer, which requires strictly ordered semantics for FP reductions.\n+      \/\/\n+      \/\/ There is no direct Neon instruction that performs strictly ordered floating\n+      \/\/ point add reduction. Hence, on Neon only machines, the add reduction operation\n+      \/\/ is implemented as a scalarized sequence using half-precision scalar instruction\n+      \/\/ FADD which requires FEAT_FP16 and ASIMDHP to be available on the target.\n+      \/\/ On SVE machines (UseSVE > 0) however, there is a direct instruction (FADDA) which\n+      \/\/ implements strictly ordered floating point add reduction which does not require\n+      \/\/ the FEAT_FP16 and ASIMDHP checks as SVE supports half-precision floats by default.\n+      case Op_AddReductionVHF:\n@@ -251,1 +267,14 @@\n-        if (UseSVE == 0 && !is_feat_fp16_supported()) {\n+        if (length_in_bytes < 8 || (UseSVE == 0 && !is_feat_fp16_supported())) {\n+          return false;\n+        }\n+        break;\n+      case Op_MulReductionVHF:\n+        \/\/ There are no direct Neon\/SVE instructions that perform strictly ordered\n+        \/\/ floating point multiply reduction.\n+        \/\/ For vector length ≤ 16 bytes, the reduction is implemented as a scalarized\n+        \/\/ sequence using half-precision scalar instruction FMUL. This path requires\n+        \/\/ FEAT_FP16 and ASIMDHP to be available on the target.\n+        \/\/ For vector length > 16 bytes, this operation is disabled because there is no\n+        \/\/ direct SVE instruction that performs a strictly ordered FP16 multiply\n+        \/\/ reduction.\n+        if (length_in_bytes < 8 || length_in_bytes > 16 || !is_feat_fp16_supported()) {\n@@ -301,0 +330,1 @@\n+      case Op_MulReductionVHF:\n@@ -365,0 +395,1 @@\n+      case Op_AddReductionVHF:\n@@ -3405,0 +3436,38 @@\n+\/\/ Add Reduction for Half floats (FP16).\n+\/\/ Neon does not provide direct instructions for strictly ordered floating-point add reductions.\n+\/\/ On Neon-only targets (UseSVE = 0), this operation is implemented as a sequence of scalar additions:\n+\/\/ values equal to the vector width are loaded into a vector register, each lane is extracted,\n+\/\/ and its value is accumulated into the running sum, producing a final scalar result.\n+instruct reduce_addHF_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVHF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addHF $dst, $fsrc, $vsrc\\t# 4HF\/8HF. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_fp16($dst$$FloatRegister, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ This rule calculates the reduction result in strict order. Two cases will\n+\/\/ reach here:\n+\/\/ 1. Non strictly-ordered AddReductionVHF when vector size > 128-bits. For example -\n+\/\/    AddReductionVHF generated by Vector API. For vector size > 128-bits, it is more\n+\/\/    beneficial performance-wise to generate direct SVE instruction even if it is\n+\/\/    strictly ordered.\n+\/\/ 2. Strictly-ordered AddReductionVHF. For example - AddReductionVHF generated by\n+\/\/    auto-vectorization on SVE machine.\n+instruct reduce_addHF_sve(vRegF dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionVHF dst_src1 src2));\n+  format %{ \"reduce_addHF_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_fadda($dst_src1$$FloatRegister, __ H, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -3495,1 +3564,1 @@\n-instruct reduce_addF_masked(vRegF dst_src1, vReg src2, pRegGov pg) %{\n+instruct reduce_addFHF_masked(vRegF dst_src1, vReg src2, pRegGov pg) %{\n@@ -3497,0 +3566,1 @@\n+  match(Set dst_src1 (AddReductionVHF (Binary dst_src1 src2) pg));\n@@ -3498,1 +3568,1 @@\n-  format %{ \"reduce_addF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  format %{ \"reduce_addFHF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n@@ -3500,1 +3570,2 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ S,\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n@@ -3548,1 +3619,2 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+\n+instruct reduce_mulFHF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -3550,0 +3622,1 @@\n+  match(Set dst (MulReductionVHF fsrc vsrc));\n@@ -3552,1 +3625,1 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulFHF $dst, $fsrc, $vsrc\\t# 2F\/4F\/4HF\/8HF. KILL $tmp\" %}\n@@ -3555,1 +3628,2 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, bt, $fsrc$$FloatRegister,\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":81,"deletions":7,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -238,0 +238,16 @@\n+        if (UseSVE == 0 && !is_feat_fp16_supported()) {\n+          return false;\n+        }\n+        break;\n+      \/\/ At the time of writing this, the Vector API has no half-float (FP16) species.\n+      \/\/ Consequently, AddReductionVHF and MulReductionVHF are only produced by the\n+      \/\/ auto-vectorizer, which requires strictly ordered semantics for FP reductions.\n+      \/\/\n+      \/\/ There is no direct Neon instruction that performs strictly ordered floating\n+      \/\/ point add reduction. Hence, on Neon only machines, the add reduction operation\n+      \/\/ is implemented as a scalarized sequence using half-precision scalar instruction\n+      \/\/ FADD which requires FEAT_FP16 and ASIMDHP to be available on the target.\n+      \/\/ On SVE machines (UseSVE > 0) however, there is a direct instruction (FADDA) which\n+      \/\/ implements strictly ordered floating point add reduction which does not require\n+      \/\/ the FEAT_FP16 and ASIMDHP checks as SVE supports half-precision floats by default.\n+      case Op_AddReductionVHF:\n@@ -241,1 +257,14 @@\n-        if (UseSVE == 0 && !is_feat_fp16_supported()) {\n+        if (length_in_bytes < 8 || (UseSVE == 0 && !is_feat_fp16_supported())) {\n+          return false;\n+        }\n+        break;\n+      case Op_MulReductionVHF:\n+        \/\/ There are no direct Neon\/SVE instructions that perform strictly ordered\n+        \/\/ floating point multiply reduction.\n+        \/\/ For vector length ≤ 16 bytes, the reduction is implemented as a scalarized\n+        \/\/ sequence using half-precision scalar instruction FMUL. This path requires\n+        \/\/ FEAT_FP16 and ASIMDHP to be available on the target.\n+        \/\/ For vector length > 16 bytes, this operation is disabled because there is no\n+        \/\/ direct SVE instruction that performs a strictly ordered FP16 multiply\n+        \/\/ reduction.\n+        if (length_in_bytes < 8 || length_in_bytes > 16 || !is_feat_fp16_supported()) {\n@@ -291,0 +320,1 @@\n+      case Op_MulReductionVHF:\n@@ -355,0 +385,1 @@\n+      case Op_AddReductionVHF:\n@@ -2062,0 +2093,19 @@\n+\n+\/\/ Add Reduction for Half floats (FP16).\n+\/\/ Neon does not provide direct instructions for strictly ordered floating-point add reductions.\n+\/\/ On Neon-only targets (UseSVE = 0), this operation is implemented as a sequence of scalar additions:\n+\/\/ values equal to the vector width are loaded into a vector register, each lane is extracted,\n+\/\/ and its value is accumulated into the running sum, producing a final scalar result.\n+instruct reduce_addHF_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVHF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addHF $dst, $fsrc, $vsrc\\t# 4HF\/8HF. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_fp16($dst$$FloatRegister, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n@@ -2073,3 +2123,5 @@\n-instruct reduce_add$1_sve(vReg$1 dst_src1, vReg src2) %{\n-  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n-            n->as_Reduction()->requires_strict_order());\n+instruct reduce_add$1_sve(vReg`'ifelse($1, HF, F, $1) dst_src1, vReg src2) %{\n+  ifelse($1, HF,\n+       `predicate(UseSVE > 0);',\n+       `predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());')\n@@ -2079,2 +2131,4 @@\n-    assert(UseSVE > 0, \"must be sve\");\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n+    ifelse($1, HF, `',\n+       `assert(UseSVE > 0, \"must be sve\");\n+    ')dnl\n+uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n@@ -2087,1 +2141,2 @@\n-REDUCE_ADD_FP_SVE(F, S)\n+REDUCE_ADD_FP_SVE(HF, H)\n+REDUCE_ADD_FP_SVE(F,  S)\n@@ -2128,1 +2183,1 @@\n-instruct reduce_add$1_masked(vReg$1 dst_src1, vReg src2, pRegGov pg) %{\n+instruct reduce_add$1_masked(vReg$2 dst_src1, vReg src2, pRegGov pg) %{\n@@ -2130,1 +2185,4 @@\n-  match(Set dst_src1 (AddReductionV$1 (Binary dst_src1 src2) pg));\n+  ifelse($2, F,\n+       `match(Set dst_src1 (AddReductionVHF (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (AddReductionV$2 (Binary dst_src1 src2) pg));',\n+       `match(Set dst_src1 (AddReductionV$2 (Binary dst_src1 src2) pg));')\n@@ -2133,2 +2191,8 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ $2,\n-                 $pg$$PRegister, $src2$$FloatRegister);\n+    ifelse($2, F,\n+       `BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    ',)dnl\n+ifelse($2, F,\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister);',\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ $2,\n+                 $pg$$PRegister, $src2$$FloatRegister);')\n@@ -2141,2 +2205,2 @@\n-REDUCE_ADD_FP_PREDICATE(F, S)\n-REDUCE_ADD_FP_PREDICATE(D, D)\n+REDUCE_ADD_FP_PREDICATE(FHF, F)\n+REDUCE_ADD_FP_PREDICATE(D,   D)\n@@ -2175,3 +2239,9 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(2)) <= 16);\n-  match(Set dst (MulReductionVF fsrc vsrc));\n+dnl REDUCE_MUL_FP($1,        $2     )\n+dnl REDUCE_MUL_FP(insn_name, op_name)\n+define(`REDUCE_MUL_FP', `\n+instruct reduce_mul$1(vReg$2 dst, vReg$2 ifelse($2, F, fsrc, dsrc), vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) ifelse($2, F, <=, ==) 16);\n+  ifelse($2, F,\n+       `match(Set dst (MulReductionVHF fsrc vsrc));\n+  match(Set dst (MulReductionV$2 fsrc vsrc));',\n+       `match(Set dst (MulReductionV$2 dsrc vsrc));')\n@@ -2179,5 +2249,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n-  ins_encode %{\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  ifelse($2, F,\n+         `format %{ \"reduce_mul$1 $dst, $fsrc, $vsrc\\t# 2F\/4F\/4HF\/8HF. KILL $tmp\" %}',\n+         `format %{ \"reduce_mul$1 $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}')\n+  ins_encode %{\n+    ifelse($2, F,\n+       `uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    ',)dnl\n+ifelse($2, F,\n+       `BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    ',)dnl\n+ifelse($2, F,\n+       `__ neon_reduce_mul_fp($dst$$FloatRegister, bt, $fsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);',\n+       `__ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);')\n@@ -2186,13 +2266,4 @@\n-%}\n-\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n-  match(Set dst (MulReductionVD dsrc vsrc));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n-  ins_encode %{\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n+%}')dnl\n+dnl\n+REDUCE_MUL_FP(FHF, F)\n+REDUCE_MUL_FP(D,   D)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":105,"deletions":34,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -1869,0 +1870,21 @@\n+      \/\/ The T_SHORT type below is for Float16 type which also uses floating-point\n+      \/\/ instructions.\n+      case T_SHORT:\n+        fmulh(dst, fsrc, vsrc);\n+        ext(vtmp, T8B, vsrc, vsrc, 2);\n+        fmulh(dst, dst, vtmp);\n+        ext(vtmp, T8B, vsrc, vsrc, 4);\n+        fmulh(dst, dst, vtmp);\n+        ext(vtmp, T8B, vsrc, vsrc, 6);\n+        fmulh(dst, dst, vtmp);\n+        if (isQ) {\n+          ext(vtmp, T16B, vsrc, vsrc, 8);\n+          fmulh(dst, dst, vtmp);\n+          ext(vtmp, T16B, vsrc, vsrc, 10);\n+          fmulh(dst, dst, vtmp);\n+          ext(vtmp, T16B, vsrc, vsrc, 12);\n+          fmulh(dst, dst, vtmp);\n+          ext(vtmp, T16B, vsrc, vsrc, 14);\n+          fmulh(dst, dst, vtmp);\n+        }\n+        break;\n@@ -1893,0 +1915,27 @@\n+\/\/ Vector reduction add for half float type with ASIMD instructions.\n+void C2_MacroAssembler::neon_reduce_add_fp16(FloatRegister dst, FloatRegister fsrc, FloatRegister vsrc,\n+                                             unsigned vector_length_in_bytes, FloatRegister vtmp) {\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_add_fp16 {\");\n+    faddh(dst, fsrc, vsrc);\n+    ext(vtmp, T8B, vsrc, vsrc, 2);\n+    faddh(dst, dst, vtmp);\n+    ext(vtmp, T8B, vsrc, vsrc, 4);\n+    faddh(dst, dst, vtmp);\n+    ext(vtmp, T8B, vsrc, vsrc, 6);\n+    faddh(dst, dst, vtmp);\n+      if (isQ) {\n+        ext(vtmp, T16B, vsrc, vsrc, 8);\n+        faddh(dst, dst, vtmp);\n+        ext(vtmp, T16B, vsrc, vsrc, 10);\n+        faddh(dst, dst, vtmp);\n+        ext(vtmp, T16B, vsrc, vsrc, 12);\n+        faddh(dst, dst, vtmp);\n+        ext(vtmp, T16B, vsrc, vsrc, 14);\n+        faddh(dst, dst, vtmp);\n+      }\n+  BLOCK_COMMENT(\"} neon_reduce_add_fp16\");\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":49,"deletions":0,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -147,0 +147,3 @@\n+  void neon_reduce_add_fp16(FloatRegister dst, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4236,0 +4236,1 @@\n+        strcmp(opType, \"AddReductionVHF\")==0 ||\n@@ -4241,0 +4242,1 @@\n+        strcmp(opType,\"MulReductionVHF\")==0 ||\n@@ -4349,1 +4351,1 @@\n-    \"AddReductionVF\", \"AddReductionVD\",\n+    \"AddReductionVHF\", \"AddReductionVF\", \"AddReductionVD\",\n@@ -4351,1 +4353,1 @@\n-    \"MulReductionVF\", \"MulReductionVD\",\n+    \"MulReductionVHF\", \"MulReductionVF\", \"MulReductionVD\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -396,0 +396,1 @@\n+macro(AddReductionVHF)\n@@ -413,0 +414,1 @@\n+macro(MulReductionVHF)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3193,1 +3193,1 @@\n-    case Op_AddI:  case Op_AddF:  case Op_AddD:  case Op_AddL:\n+    case Op_AddI:  case Op_AddF:  case Op_AddD:  case Op_AddHF:  case Op_AddL:\n@@ -3196,1 +3196,1 @@\n-    case Op_MulI:  case Op_MulF:  case Op_MulD:  case Op_MulL:\n+    case Op_MulI:  case Op_MulF:  case Op_MulD:  case Op_MulHF:  case Op_MulL:\n@@ -3275,0 +3275,2 @@\n+  case Op_AddHF:\n+  case Op_MulHF:\n@@ -3782,0 +3784,1 @@\n+  case Op_AddReductionVHF:\n@@ -3786,0 +3789,1 @@\n+  case Op_MulReductionVHF:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1249,0 +1249,4 @@\n+    case Op_AddHF:\n+      assert(bt == T_SHORT, \"must be\");\n+      vopc = Op_AddReductionVHF;\n+      break;\n@@ -1273,0 +1277,4 @@\n+    case Op_MulHF:\n+      assert(bt == T_SHORT, \"must be\");\n+      vopc = Op_MulReductionVHF;\n+      break;\n@@ -1395,0 +1403,1 @@\n+  case Op_AddReductionVHF: return new AddReductionVHFNode(ctrl, n1, n2, requires_strict_order);\n@@ -1399,0 +1408,1 @@\n+  case Op_MulReductionVHF: return new MulReductionVHFNode(ctrl, n1, n2, requires_strict_order);\n@@ -1567,0 +1577,1 @@\n+    case Op_AddReductionVHF: \/\/ fallthrough\n@@ -1576,0 +1587,2 @@\n+    case Op_MulReductionVHF:\n+      return gvn.makecon(TypeH::ONE);\n@@ -1644,0 +1657,2 @@\n+    case Op_AddReductionVHF:\n+    case Op_MulReductionVHF:\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -274,1 +275,1 @@\n-  \/\/ AddReductionVF\/D and MulReductionVF\/D require strict ordering\n+  \/\/ AddReductionVHF\/F\/D and MulReductionVHF\/F\/D require strict ordering\n@@ -313,0 +314,30 @@\n+\/\/------------------------------AddReductionVHFNode-------------------------------------\n+\/\/ Vector add half float as a reduction\n+class AddReductionVHFNode : public ReductionNode {\n+private:\n+  \/\/ True if add reduction operation for half floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for half floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n+\n+public:\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVHFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n+  int Opcode() const override;\n+  bool requires_strict_order() const override { return _requires_strict_order; }\n+\n+  uint hash() const override { return Node::hash() + _requires_strict_order; }\n+\n+  bool cmp(const Node& n) const override {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  uint size_of() const override { return sizeof(*this); }\n+\n+  const Type* bottom_type() const override { return Type::HALF_FLOAT; }\n+  uint ideal_reg() const override { return Op_RegF; }\n+};\n+\n@@ -323,1 +354,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -350,1 +381,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -558,0 +589,30 @@\n+\/\/------------------------------MulReductionVHFNode-------------------------------------\n+\/\/ Vector multiply half float as a reduction\n+class MulReductionVHFNode : public ReductionNode {\n+private:\n+  \/\/ True if mul reduction operation for half floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for half floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n+\n+public:\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVHFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n+  int Opcode() const override;\n+  bool requires_strict_order() const override { return _requires_strict_order; }\n+\n+  uint hash() const override { return Node::hash() + _requires_strict_order; }\n+\n+  bool cmp(const Node& n) const override {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  uint size_of() const override { return sizeof(*this); }\n+\n+  const Type* bottom_type() const override { return Type::HALF_FLOAT; }\n+  uint ideal_reg() const override { return Op_RegF; }\n+};\n+\n@@ -567,1 +628,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -593,1 +654,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":66,"deletions":5,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -325,0 +325,5 @@\n+    public static final String ADD_REDUCTION_VHF = PREFIX + \"ADD_REDUCTION_VHF\" + POSTFIX;\n+    static {\n+        superWordNodes(ADD_REDUCTION_VHF, \"AddReductionVHF\");\n+    }\n+\n@@ -1557,0 +1562,5 @@\n+    public static final String MUL_REDUCTION_VHF = PREFIX + \"MUL_REDUCTION_VHF\" + POSTFIX;\n+    static {\n+        superWordNodes(MUL_REDUCTION_VHF, \"MulReductionVHF\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+import compiler.lib.generators.Generator;\n@@ -37,3 +38,1 @@\n-import jdk.incubator.vector.Float16;\n-import static jdk.incubator.vector.Float16.*;\n-import static java.lang.Float.*;\n+import compiler.lib.verify.Verify;\n@@ -41,0 +40,1 @@\n+import jdk.incubator.vector.Float16;\n@@ -42,1 +42,0 @@\n-import compiler.lib.generators.Generator;\n@@ -44,0 +43,2 @@\n+import static java.lang.Float.*;\n+import static jdk.incubator.vector.Float16.*;\n@@ -352,1 +353,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.SUB_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -370,1 +373,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MUL_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -388,1 +393,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.DIV_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -406,1 +413,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MAX_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -424,1 +433,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MIN_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -438,0 +449,102 @@\n+\n+    @Test\n+    @Warmup(50)\n+    @IR(counts = {IRNode.ADD_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    @IR(counts = {IRNode.ADD_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public short vectorAddReductionFloat16() {\n+        short result = (short) 0;\n+        for (int i = 0; i < LEN; i++) {\n+            result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(input1[i])));\n+        }\n+        return result;\n+    }\n+\n+    @Check(test=\"vectorAddReductionFloat16\")\n+    public void checkResultAddReductionFloat16() {\n+        short expected = (short) 0;\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i]));\n+        }\n+        Verify.checkEQ(shortBitsToFloat16(expected), shortBitsToFloat16(vectorAddReductionFloat16()));\n+    }\n+\n+    @Test\n+    @Warmup(50)\n+    @IR(counts = {IRNode.MUL_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"<=16\"})\n+    public short vectorMulReductionFloat16() {\n+        short result = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; i++) {\n+            result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(input1[i])));\n+        }\n+        return result;\n+    }\n+\n+    @Check(test=\"vectorMulReductionFloat16\")\n+    public void checkResultMulReductionFloat16() {\n+        short expected = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i]));\n+        }\n+        Verify.checkEQ(shortBitsToFloat16(expected), shortBitsToFloat16(vectorMulReductionFloat16()));\n+    }\n+\n+    \/\/ This testcase verifies that autovectorization takes place in scenarios where masked\n+    \/\/ add reduction instructions are required to be generated on platforms that support\n+    \/\/ such masked\/partial instructions.\n+    @Test\n+    @Warmup(500)\n+    @IR(counts = {\"reduce_addFHF_masked\", \" >0 \"}, phase = {CompilePhase.FINAL_CODE},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    public short vectorAddReductionFloat16Partial() {\n+        short result = (short) 0;\n+        for (int i = 0; i < LEN; i+=8) {\n+            result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(input1[i])));\n+            result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+1])));\n+            result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+2])));\n+            result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+3])));\n+        }\n+        return result;\n+    }\n+\n+    @Check(test=\"vectorAddReductionFloat16Partial\")\n+    public void checkResultvectorAddReductionFloat16Partial() {\n+        short expected = (short) 0;\n+        for (int i = 0; i < LEN; i+=8) {\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+1]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+2]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+3]));\n+        }\n+        Verify.checkEQ(shortBitsToFloat16(expected), shortBitsToFloat16(vectorAddReductionFloat16Partial()));\n+    }\n+\n+    \/\/ Partial multiply reduction for floating point is disabled on aarch64. This test makes sure that code that performs such partial\n+    \/\/ multiply reduction operation for FP16 runs without any failures\/result mismatch.\n+    @Test\n+    @Warmup(500)\n+    public short vectorMulReductionFloat16Partial() {\n+        short result = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; i+=8) {\n+            result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(input1[i])));\n+            result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+1])));\n+            result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+2])));\n+            result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(input1[i+3])));\n+        }\n+        return result;\n+    }\n+\n+    @Check(test=\"vectorMulReductionFloat16Partial\")\n+    public void checkResultvectorMulReductionFloat16Partial() {\n+        short expected = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; i+=8) {\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+1]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+2]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+3]));\n+        }\n+        Verify.checkEQ(shortBitsToFloat16(expected), shortBitsToFloat16(vectorMulReductionFloat16Partial()));\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloat16VectorOperations.java","additions":122,"deletions":9,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -317,0 +318,18 @@\n+\n+    @Benchmark\n+    public short ReductionAddFP16() {\n+       short result = (short) 0;\n+       for (int i = 0; i < vectorDim; i++) {\n+           result = float16ToRawShortBits(add(shortBitsToFloat16(result), shortBitsToFloat16(vector1[i])));\n+       }\n+       return result;\n+    }\n+\n+    @Benchmark\n+    public short ReductionMulFP16() {\n+       short result = floatToFloat16(1.0f);\n+       for (int i = 0; i < vectorDim; i++) {\n+           result = float16ToRawShortBits(multiply(shortBitsToFloat16(result), shortBitsToFloat16(vector1[i])));\n+       }\n+       return result;\n+    }\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/vector\/Float16OperationsBenchmark.java","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"}]}