{"files":[{"patch":"@@ -242,0 +242,12 @@\n+      \/\/ At the time of writing this, the Vector API has no half-float (FP16) species.\n+      \/\/ Consequently, AddReductionVHF and MulReductionVHF are only produced by the\n+      \/\/ auto-vectorizer, which requires strictly ordered semantics for FP reductions.\n+      \/\/\n+      \/\/ There is no direct Neon instruction that performs strictly ordered floating\n+      \/\/ point add reduction. Hence, on Neon only machines, the add reduction operation\n+      \/\/ is implemented as a scalarized sequence using half-precision scalar instruction\n+      \/\/ FADD which requires FEAT_FP16 and ASIMDHP to be available on the target.\n+      \/\/ On SVE machines (UseSVE > 0) however, there is a direct instruction (FADDA) which\n+      \/\/ implements strictly ordered floating point add reduction which does not require\n+      \/\/ the FEAT_FP16 and ASIMDHP checks as SVE supports half-precision floats by default.\n+      case Op_AddReductionVHF:\n@@ -249,0 +261,13 @@\n+      case Op_MulReductionVHF:\n+        \/\/ There are no direct Neon\/SVE instructions that perform strictly ordered\n+        \/\/ floating point multiply reduction.\n+        \/\/ For vector length ≤ 16 bytes, the reduction is implemented as a scalarized\n+        \/\/ sequence using half-precision scalar instruction FMUL. This path requires\n+        \/\/ FEAT_FP16 and ASIMDHP to be available on the target.\n+        \/\/ For vector length > 16 bytes, this operation is disabled because there is no\n+        \/\/ direct SVE instruction that performs a strictly ordered FP16 multiply\n+        \/\/ reduction.\n+        if (length_in_bytes > 16 || !is_feat_fp16_supported()) {\n+          return false;\n+        }\n+        break;\n@@ -295,0 +320,1 @@\n+      case Op_MulReductionVHF:\n@@ -354,0 +380,1 @@\n+      case Op_AddReductionVHF:\n@@ -3366,0 +3393,19 @@\n+\/\/ Add Reduction for Half floats (FP16).\n+\/\/ Neon does not provide direct instructions for strictly ordered floating-point add reductions.\n+\/\/ On Neon-only targets (UseSVE = 0), this operation is implemented as a sequence of scalar additions:\n+\/\/ values equal to the vector width are loaded into a vector register, each lane is extracted,\n+\/\/ and its value is accumulated into the running sum, producing a final scalar result.\n+instruct reduce_addHF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVHF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addHF $dst, $fsrc, $vsrc\\t# 4HF\/8HF. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_fp16($dst$$FloatRegister, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n@@ -3367,1 +3413,1 @@\n-\/\/ reach here:\n+\/\/ reach here for T_FLOAT type:\n@@ -3374,3 +3420,9 @@\n-instruct reduce_addF_sve(vRegF dst_src1, vReg src2) %{\n-  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n-            n->as_Reduction()->requires_strict_order());\n+\/\/ For half float input (inferred as a T_SHORT type) - the only case that can reach here is\n+\/\/ through autovectorization which is strictly ordered. At the time of writing this, support for\n+\/\/ Float16 in VectorAPI is not available and thus only support for autovectorization has been added.\n+instruct reduce_addFHF_sve(vRegF dst_src1, vReg src2) %{\n+  predicate((Matcher::vector_element_basic_type(n->in(2)) == T_FLOAT &&\n+             (!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+              n->as_Reduction()->requires_strict_order())) ||\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_SHORT && UseSVE > 0));\n+  match(Set dst_src1 (AddReductionVHF dst_src1 src2));\n@@ -3378,1 +3430,1 @@\n-  format %{ \"reduce_addF_sve $dst_src1, $dst_src1, $src2\" %}\n+  format %{ \"reduce_addFHF_sve $dst_src1, $dst_src1, $src2\" %}\n@@ -3383,1 +3435,2 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ S, ptrue, $src2$$FloatRegister);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt), ptrue, $src2$$FloatRegister);\n@@ -3405,1 +3458,1 @@\n-\/\/ reach here:\n+\/\/ reach here for T_DOUBLE type:\n@@ -3456,1 +3509,1 @@\n-instruct reduce_addF_masked(vRegF dst_src1, vReg src2, pRegGov pg) %{\n+instruct reduce_addFHF_masked(vRegF dst_src1, vReg src2, pRegGov pg) %{\n@@ -3458,0 +3511,1 @@\n+  match(Set dst_src1 (AddReductionVHF (Binary dst_src1 src2) pg));\n@@ -3459,1 +3513,1 @@\n-  format %{ \"reduce_addF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  format %{ \"reduce_addFHF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n@@ -3461,1 +3515,2 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ S,\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n@@ -3509,1 +3564,2 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+\n+instruct reduce_mulFHF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n@@ -3511,0 +3567,1 @@\n+  match(Set dst (MulReductionVHF fsrc vsrc));\n@@ -3513,1 +3570,1 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  format %{ \"reduce_mulFHF $dst, $fsrc, $vsrc\\t# 2F\/4F\/4HF\/8HF. KILL $tmp\" %}\n@@ -3516,1 +3573,2 @@\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, bt, $fsrc$$FloatRegister,\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":71,"deletions":13,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -232,0 +232,12 @@\n+      \/\/ At the time of writing this, the Vector API has no half-float (FP16) species.\n+      \/\/ Consequently, AddReductionVHF and MulReductionVHF are only produced by the\n+      \/\/ auto-vectorizer, which requires strictly ordered semantics for FP reductions.\n+      \/\/\n+      \/\/ There is no direct Neon instruction that performs strictly ordered floating\n+      \/\/ point add reduction. Hence, on Neon only machines, the add reduction operation\n+      \/\/ is implemented as a scalarized sequence using half-precision scalar instruction\n+      \/\/ FADD which requires FEAT_FP16 and ASIMDHP to be available on the target.\n+      \/\/ On SVE machines (UseSVE > 0) however, there is a direct instruction (FADDA) which\n+      \/\/ implements strictly ordered floating point add reduction which does not require\n+      \/\/ the FEAT_FP16 and ASIMDHP checks as SVE supports half-precision floats by default.\n+      case Op_AddReductionVHF:\n@@ -239,0 +251,13 @@\n+      case Op_MulReductionVHF:\n+        \/\/ There are no direct Neon\/SVE instructions that perform strictly ordered\n+        \/\/ floating point multiply reduction.\n+        \/\/ For vector length ≤ 16 bytes, the reduction is implemented as a scalarized\n+        \/\/ sequence using half-precision scalar instruction FMUL. This path requires\n+        \/\/ FEAT_FP16 and ASIMDHP to be available on the target.\n+        \/\/ For vector length > 16 bytes, this operation is disabled because there is no\n+        \/\/ direct SVE instruction that performs a strictly ordered FP16 multiply\n+        \/\/ reduction.\n+        if (length_in_bytes > 16 || !is_feat_fp16_supported()) {\n+          return false;\n+        }\n+        break;\n@@ -285,0 +310,1 @@\n+      case Op_MulReductionVHF:\n@@ -344,0 +370,1 @@\n+      case Op_AddReductionVHF:\n@@ -2023,2 +2050,21 @@\n-dnl REDUCE_ADD_FP_SVE($1,   $2  )\n-dnl REDUCE_ADD_FP_SVE(type, size)\n+\n+\/\/ Add Reduction for Half floats (FP16).\n+\/\/ Neon does not provide direct instructions for strictly ordered floating-point add reductions.\n+\/\/ On Neon-only targets (UseSVE = 0), this operation is implemented as a sequence of scalar additions:\n+\/\/ values equal to the vector width are loaded into a vector register, each lane is extracted,\n+\/\/ and its value is accumulated into the running sum, producing a final scalar result.\n+instruct reduce_addHF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVHF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addHF $dst, $fsrc, $vsrc\\t# 4HF\/8HF. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_fp16($dst$$FloatRegister, $fsrc$$FloatRegister,\n+                            $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl REDUCE_ADD_FP_SVE($1,        $2     )\n+dnl REDUCE_ADD_FP_SVE(insn_name, op_name)\n@@ -2027,3 +2073,3 @@\n-\/\/ reach here:\n-\/\/ 1. Non strictly-ordered AddReductionV$1 when vector size > 128-bits. For example -\n-\/\/    AddReductionV$1 generated by Vector API. For vector size > 128-bits, it is more\n+\/\/ reach here for ifelse($2, F, T_FLOAT, T_DOUBLE) type:\n+\/\/ 1. Non strictly-ordered AddReductionV$2 when vector size > 128-bits. For example -\n+\/\/    AddReductionV$2 generated by Vector API. For vector size > 128-bits, it is more\n@@ -2032,1 +2078,1 @@\n-\/\/ 2. Strictly-ordered AddReductionV$1. For example - AddReductionV$1 generated by\n+\/\/ 2. Strictly-ordered AddReductionV$2. For example - AddReductionV$2 generated by\n@@ -2034,4 +2080,17 @@\n-instruct reduce_add$1_sve(vReg$1 dst_src1, vReg src2) %{\n-  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n-            n->as_Reduction()->requires_strict_order());\n-  match(Set dst_src1 (AddReductionV$1 dst_src1 src2));\n+ifelse($2, F,\n+`\/\/ For half float input (inferred as a T_SHORT type) - the only case that can reach here is\n+\/\/ through autovectorization which is strictly ordered. At the time of writing this, support for\n+\/\/ Float16 in VectorAPI is not available and thus only support for autovectorization has been added.\n+',)dnl\n+instruct reduce_add$1_sve(vReg$2 dst_src1, vReg src2) %{\n+  ifelse($2, F,\n+       `predicate((Matcher::vector_element_basic_type(n->in(2)) == T_FLOAT &&\n+             (!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+              n->as_Reduction()->requires_strict_order())) ||\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_SHORT && UseSVE > 0));',\n+       `predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) ||\n+            n->as_Reduction()->requires_strict_order());')\n+  ifelse($2, F,\n+       `match(Set dst_src1 (AddReductionVHF dst_src1 src2));\n+  match(Set dst_src1 (AddReductionV$2 dst_src1 src2));',\n+       `match(Set dst_src1 (AddReductionV$2 dst_src1 src2));')\n@@ -2043,1 +2102,6 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ $2, ptrue, $src2$$FloatRegister);\n+    ifelse($2, F,\n+       `BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    ',)dnl\n+ifelse($2, F,\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt), ptrue, $src2$$FloatRegister);',\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ $2, ptrue, $src2$$FloatRegister);')\n@@ -2048,1 +2112,1 @@\n-REDUCE_ADD_FP_SVE(F, S)\n+REDUCE_ADD_FP_SVE(FHF, F)\n@@ -2089,1 +2153,1 @@\n-instruct reduce_add$1_masked(vReg$1 dst_src1, vReg src2, pRegGov pg) %{\n+instruct reduce_add$1_masked(vReg$2 dst_src1, vReg src2, pRegGov pg) %{\n@@ -2091,1 +2155,4 @@\n-  match(Set dst_src1 (AddReductionV$1 (Binary dst_src1 src2) pg));\n+  ifelse($2, F,\n+       `match(Set dst_src1 (AddReductionVHF (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (AddReductionV$2 (Binary dst_src1 src2) pg));',\n+       `match(Set dst_src1 (AddReductionV$2 (Binary dst_src1 src2) pg));')\n@@ -2094,2 +2161,8 @@\n-    __ sve_fadda($dst_src1$$FloatRegister, __ $2,\n-                 $pg$$PRegister, $src2$$FloatRegister);\n+    ifelse($2, F,\n+       `BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    ',)dnl\n+ifelse($2, F,\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister);',\n+       `__ sve_fadda($dst_src1$$FloatRegister, __ $2,\n+                 $pg$$PRegister, $src2$$FloatRegister);')\n@@ -2102,2 +2175,2 @@\n-REDUCE_ADD_FP_PREDICATE(F, S)\n-REDUCE_ADD_FP_PREDICATE(D, D)\n+REDUCE_ADD_FP_PREDICATE(FHF, F)\n+REDUCE_ADD_FP_PREDICATE(D,   D)\n@@ -2136,3 +2209,9 @@\n-instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(2)) <= 16);\n-  match(Set dst (MulReductionVF fsrc vsrc));\n+dnl REDUCE_MUL_FP($1,        $2     )\n+dnl REDUCE_MUL_FP(insn_name, op_name)\n+define(`REDUCE_MUL_FP', `\n+instruct reduce_mul$1(vReg$2 dst, vReg$2 ifelse($2, F, fsrc, dsrc), vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) ifelse($2, F, <=, ==) 16);\n+  ifelse($2, F,\n+       `match(Set dst (MulReductionVHF fsrc vsrc));\n+  match(Set dst (MulReductionV$2 fsrc vsrc));',\n+       `match(Set dst (MulReductionV$2 dsrc vsrc));')\n@@ -2140,17 +2219,15 @@\n-  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n-  ins_encode %{\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n-  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n-  match(Set dst (MulReductionVD dsrc vsrc));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n-  ins_encode %{\n-    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n-                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  ifelse($2, F,\n+         `format %{ \"reduce_mul$1 $dst, $fsrc, $vsrc\\t# 2F\/4F\/4HF\/8HF. KILL $tmp\" %}',\n+         `format %{ \"reduce_mul$1 $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}')\n+  ins_encode %{\n+    ifelse($2, F,\n+       `uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    ',)dnl\n+ifelse($2, F,\n+       `BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    ',)dnl\n+ifelse($2, F,\n+       `__ neon_reduce_mul_fp($dst$$FloatRegister, bt, $fsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);',\n+       `__ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);')\n@@ -2159,1 +2236,4 @@\n-%}\n+%}')dnl\n+dnl\n+REDUCE_MUL_FP(FHF, F)\n+REDUCE_MUL_FP(D,   D)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":119,"deletions":39,"binary":false,"changes":158,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -1881,0 +1882,21 @@\n+      \/\/ The T_SHORT type below is for Float16 type which also uses floating-point\n+      \/\/ instructions.\n+      case T_SHORT:\n+        fmulh(dst, fsrc, vsrc);\n+        ins(vtmp, H, vsrc, 0, 1);\n+        fmulh(dst, dst, vtmp);\n+        ins(vtmp, H, vsrc, 0, 2);\n+        fmulh(dst, dst, vtmp);\n+        ins(vtmp, H, vsrc, 0, 3);\n+        fmulh(dst, dst, vtmp);\n+        if (isQ) {\n+          ins(vtmp, H, vsrc, 0, 4);\n+          fmulh(dst, dst, vtmp);\n+          ins(vtmp, H, vsrc, 0, 5);\n+          fmulh(dst, dst, vtmp);\n+          ins(vtmp, H, vsrc, 0, 6);\n+          fmulh(dst, dst, vtmp);\n+          ins(vtmp, H, vsrc, 0, 7);\n+          fmulh(dst, dst, vtmp);\n+        }\n+        break;\n@@ -1905,0 +1927,27 @@\n+\/\/ Vector reduction add for half float type with ASIMD instructions.\n+void C2_MacroAssembler::neon_reduce_add_fp16(FloatRegister dst, FloatRegister fsrc, FloatRegister vsrc,\n+                                             unsigned vector_length_in_bytes, FloatRegister vtmp) {\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_add_fp16 {\");\n+    faddh(dst, fsrc, vsrc);\n+    ins(vtmp, H, vsrc, 0, 1);\n+    faddh(dst, dst, vtmp);\n+    ins(vtmp, H, vsrc, 0, 2);\n+    faddh(dst, dst, vtmp);\n+    ins(vtmp, H, vsrc, 0, 3);\n+    faddh(dst, dst, vtmp);\n+      if (isQ) {\n+        ins(vtmp, H, vsrc, 0, 4);\n+        faddh(dst, dst, vtmp);\n+        ins(vtmp, H, vsrc, 0, 5);\n+        faddh(dst, dst, vtmp);\n+        ins(vtmp, H, vsrc, 0, 6);\n+        faddh(dst, dst, vtmp);\n+        ins(vtmp, H, vsrc, 0, 7);\n+        faddh(dst, dst, vtmp);\n+      }\n+  BLOCK_COMMENT(\"} neon_reduce_add_fp16\");\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":49,"deletions":0,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -143,0 +143,3 @@\n+  void neon_reduce_add_fp16(FloatRegister dst, FloatRegister fsrc, FloatRegister vsrc,\n+                            unsigned vector_length_in_bytes, FloatRegister vtmp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4236,0 +4236,1 @@\n+        strcmp(opType, \"AddReductionVHF\")==0 ||\n@@ -4241,0 +4242,1 @@\n+        strcmp(opType,\"MulReductionVHF\")==0 ||\n@@ -4349,1 +4351,1 @@\n-    \"AddReductionVF\", \"AddReductionVD\",\n+    \"AddReductionVHF\", \"AddReductionVF\", \"AddReductionVD\",\n@@ -4351,1 +4353,1 @@\n-    \"MulReductionVF\", \"MulReductionVD\",\n+    \"MulReductionVHF\", \"MulReductionVF\", \"MulReductionVD\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -395,0 +395,1 @@\n+macro(AddReductionVHF)\n@@ -412,0 +413,1 @@\n+macro(MulReductionVHF)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3183,1 +3183,1 @@\n-    case Op_AddI:  case Op_AddF:  case Op_AddD:  case Op_AddL:\n+    case Op_AddI:  case Op_AddF:  case Op_AddD:  case Op_AddHF:  case Op_AddL:\n@@ -3186,1 +3186,1 @@\n-    case Op_MulI:  case Op_MulF:  case Op_MulD:  case Op_MulL:\n+    case Op_MulI:  case Op_MulF:  case Op_MulD:  case Op_MulHF:  case Op_MulL:\n@@ -3265,0 +3265,2 @@\n+  case Op_AddHF:\n+  case Op_MulHF:\n@@ -3775,0 +3777,1 @@\n+  case Op_AddReductionVHF:\n@@ -3779,0 +3782,1 @@\n+  case Op_MulReductionVHF:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1349,0 +1349,4 @@\n+    case Op_AddHF:\n+      assert(bt == T_SHORT, \"must be\");\n+      vopc = Op_AddReductionVHF;\n+      break;\n@@ -1373,0 +1377,4 @@\n+    case Op_MulHF:\n+      assert(bt == T_SHORT, \"must be\");\n+      vopc = Op_MulReductionVHF;\n+      break;\n@@ -1493,13 +1501,15 @@\n-  case Op_AddReductionVI: return new AddReductionVINode(ctrl, n1, n2);\n-  case Op_AddReductionVL: return new AddReductionVLNode(ctrl, n1, n2);\n-  case Op_AddReductionVF: return new AddReductionVFNode(ctrl, n1, n2, requires_strict_order);\n-  case Op_AddReductionVD: return new AddReductionVDNode(ctrl, n1, n2, requires_strict_order);\n-  case Op_MulReductionVI: return new MulReductionVINode(ctrl, n1, n2);\n-  case Op_MulReductionVL: return new MulReductionVLNode(ctrl, n1, n2);\n-  case Op_MulReductionVF: return new MulReductionVFNode(ctrl, n1, n2, requires_strict_order);\n-  case Op_MulReductionVD: return new MulReductionVDNode(ctrl, n1, n2, requires_strict_order);\n-  case Op_MinReductionV:  return new MinReductionVNode (ctrl, n1, n2);\n-  case Op_MaxReductionV:  return new MaxReductionVNode (ctrl, n1, n2);\n-  case Op_AndReductionV:  return new AndReductionVNode (ctrl, n1, n2);\n-  case Op_OrReductionV:   return new OrReductionVNode  (ctrl, n1, n2);\n-  case Op_XorReductionV:  return new XorReductionVNode (ctrl, n1, n2);\n+  case Op_AddReductionVI:  return new AddReductionVINode(ctrl, n1, n2);\n+  case Op_AddReductionVL:  return new AddReductionVLNode(ctrl, n1, n2);\n+  case Op_AddReductionVHF: return new AddReductionVHFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_AddReductionVF:  return new AddReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_AddReductionVD:  return new AddReductionVDNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MulReductionVI:  return new MulReductionVINode(ctrl, n1, n2);\n+  case Op_MulReductionVL:  return new MulReductionVLNode(ctrl, n1, n2);\n+  case Op_MulReductionVHF: return new MulReductionVHFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MulReductionVF:  return new MulReductionVFNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MulReductionVD:  return new MulReductionVDNode(ctrl, n1, n2, requires_strict_order);\n+  case Op_MinReductionV:   return new MinReductionVNode (ctrl, n1, n2);\n+  case Op_MaxReductionV:   return new MaxReductionVNode (ctrl, n1, n2);\n+  case Op_AndReductionV:   return new AndReductionVNode (ctrl, n1, n2);\n+  case Op_OrReductionV:    return new OrReductionVNode  (ctrl, n1, n2);\n+  case Op_XorReductionV:   return new XorReductionVNode (ctrl, n1, n2);\n@@ -1667,0 +1677,1 @@\n+    case Op_AddReductionVHF: \/\/ fallthrough\n@@ -1676,0 +1687,2 @@\n+    case Op_MulReductionVHF:\n+      return gvn.makecon(TypeH::ONE);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":26,"deletions":13,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -276,1 +277,1 @@\n-  \/\/ AddReductionVF\/D and MulReductionVF\/D require strict ordering\n+  \/\/ AddReductionVHF\/F\/D and MulReductionVHF\/F\/D require strict ordering\n@@ -313,0 +314,29 @@\n+\/\/------------------------------AddReductionVHFNode-------------------------------------\n+\/\/ Vector add half float as a reduction\n+class AddReductionVHFNode : public ReductionNode {\n+private:\n+  \/\/ True if add reduction operation for half floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for half floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n+public:\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n+  AddReductionVHFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n+  virtual int Opcode() const;\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n+\n+  virtual const Type* bottom_type() const { return Type::HALF_FLOAT; }\n+  virtual uint ideal_reg() const { return Op_RegF; }\n+};\n+\n@@ -323,1 +353,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -350,1 +380,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -558,0 +588,29 @@\n+\/\/------------------------------MulReductionVHFNode-------------------------------------\n+\/\/ Vector multiply half float as a reduction\n+class MulReductionVHFNode : public ReductionNode {\n+private:\n+  \/\/ True if mul reduction operation for half floats requires strict ordering.\n+  \/\/ As an example - The value is true when add reduction for half floats is auto-vectorized\n+  \/\/ as auto-vectorization mandates strict ordering but the value is false when this node\n+  \/\/ is generated through VectorAPI as VectorAPI does not impose any such rules on ordering.\n+  const bool _requires_strict_order;\n+public:\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n+  MulReductionVHFNode(Node* ctrl, Node* in1, Node* in2, bool requires_strict_order = true) :\n+    ReductionNode(ctrl, in1, in2), _requires_strict_order(requires_strict_order) {}\n+\n+  virtual int Opcode() const;\n+  virtual bool requires_strict_order() const { return _requires_strict_order; }\n+\n+  virtual uint hash() const { return Node::hash() + _requires_strict_order; }\n+\n+  virtual bool cmp(const Node& n) const {\n+    return Node::cmp(n) && _requires_strict_order == ((ReductionNode&)n).requires_strict_order();\n+  }\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n+\n+  virtual const Type* bottom_type() const { return Type::HALF_FLOAT; }\n+  virtual uint ideal_reg() const { return Op_RegF; }\n+};\n+\n@@ -567,1 +626,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n@@ -593,1 +652,1 @@\n-  \/\/_requires_strict_order is set to true by default as mandated by auto-vectorization\n+  \/\/ _requires_strict_order is set to true by default as mandated by auto-vectorization\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":64,"deletions":5,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -325,0 +325,5 @@\n+    public static final String ADD_REDUCTION_VHF = PREFIX + \"ADD_REDUCTION_VHF\" + POSTFIX;\n+    static {\n+        superWordNodes(ADD_REDUCTION_VHF, \"AddReductionVHF\");\n+    }\n+\n@@ -1501,0 +1506,5 @@\n+    public static final String MUL_REDUCTION_VHF = PREFIX + \"MUL_REDUCTION_VHF\" + POSTFIX;\n+    static {\n+        superWordNodes(MUL_REDUCTION_VHF, \"MulReductionVHF\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -76,0 +76,8 @@\n+    public static void assertResults(short expected, short actual, String reductionFunc) {\n+        Float16 expected_fp16 = shortBitsToFloat16(expected);\n+        Float16 actual_fp16 = shortBitsToFloat16(actual);\n+        if(!expected_fp16.equals(actual_fp16)) {\n+            throw new AssertionError(\"Result Mismatch!, reduction type = \" + reductionFunc + \" actual = \" + actual_fp16 +  \" expected = \" + expected_fp16);\n+        }\n+    }\n+\n@@ -352,1 +360,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.SUB_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -370,1 +380,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MUL_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -388,1 +400,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.DIV_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -406,1 +420,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MAX_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -424,1 +440,3 @@\n-        applyIfCPUFeature = {\"avx512_fp16\", \"true\"})\n+        applyIfCPUFeatureOr = {\"avx512_fp16\", \"true\", \"sve\", \"true\"})\n+    @IR(counts = {IRNode.MIN_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n@@ -438,0 +456,102 @@\n+\n+    @Test\n+    @Warmup(50)\n+    @IR(counts = {IRNode.ADD_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    @IR(counts = {IRNode.ADD_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"})\n+    public short vectorAddReductionFloat16() {\n+    short result = (short) 0;\n+       for (int i = 0; i < LEN; i++) {\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i])));\n+       }\n+       return result;\n+    }\n+\n+    @Check(test=\"vectorAddReductionFloat16\")\n+    public void checkResultAddReductionFloat16() {\n+        short expected = (short) 0;\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i]));\n+        }\n+        assertResults(expected, vectorAddReductionFloat16(), \"vectorAddReductionFloat16\");\n+    }\n+\n+    @Test\n+    @Warmup(50)\n+    @IR(counts = {IRNode.MUL_REDUCTION_VHF, \" >0 \"},\n+        applyIfCPUFeatureAnd = {\"fphp\", \"true\", \"asimdhp\", \"true\"},\n+        applyIf = {\"MaxVectorSize\", \"<=16\"})\n+    public short vectorMulReductionFloat16() {\n+       short result = floatToFloat16(1.0f);\n+       for (int i = 0; i < LEN; i++) {\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i])));\n+       }\n+       return result;\n+    }\n+\n+    @Check(test=\"vectorMulReductionFloat16\")\n+    public void checkResultMulReductionFloat16() {\n+        short expected = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; ++i) {\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i]));\n+        }\n+        assertResults(expected, vectorMulReductionFloat16(), \"vectorMulReductionFloat16\");\n+    }\n+\n+    \/\/ This testcase verifies that autovectorization takes place in scenarios where masked\n+    \/\/ add reduction instructions are required to be generated on platforms that support\n+    \/\/ such masked\/partial instructions.\n+    @Test\n+    @Warmup(500)\n+    @IR(counts = {\"reduce_addFHF_masked\", \" >0 \"}, phase = {CompilePhase.FINAL_CODE},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n+    public short vectorAddReductionFloat16Partial() {\n+       short result = (short) 0;\n+       for (int i = 0; i < LEN; i+=8) {\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i])));\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+1])));\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+2])));\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+3])));\n+       }\n+       return result;\n+    }\n+\n+    @Check(test=\"vectorAddReductionFloat16Partial\")\n+    public void checkResultvectorAddReductionFloat16Partial() {\n+        short expected = (short) 0;\n+        for (int i = 0; i < LEN; i+=8) {\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+1]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+2]));\n+            expected = floatToFloat16(float16ToFloat(expected) + float16ToFloat(input1[i+3]));\n+        }\n+        assertResults(expected, vectorAddReductionFloat16Partial(), \"vectorAddReductionFloat16Partial\");\n+    }\n+\n+    \/\/ Partial multiply reduction for floating point is disabled on aarch64. This test makes sure that code that performs such partial\n+    \/\/ multiply reduction operation for FP16 runs without any failures\/result mismatch.\n+    @Test\n+    @Warmup(500)\n+    public short vectorMulReductionFloat16Partial() {\n+       short result = floatToFloat16(1.0f);\n+       for (int i = 0; i < LEN; i+=8) {\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i])));\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+1])));\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+2])));\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(input1[i+3])));\n+       }\n+       return result;\n+    }\n+\n+    @Check(test=\"vectorMulReductionFloat16Partial\")\n+    public void checkResultvectorMulReductionFloat16Partial() {\n+        short expected = floatToFloat16(1.0f);\n+        for (int i = 0; i < LEN; i+=8) {\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+1]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+2]));\n+            expected = floatToFloat16(float16ToFloat(expected) * float16ToFloat(input1[i+3]));\n+        }\n+        assertResults(expected, vectorMulReductionFloat16Partial(), \"vectorMulReductionFloat16Partial\");\n+    }\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloat16VectorOperations.java","additions":125,"deletions":5,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright 2025 Arm Limited and\/or its affiliates.\n@@ -317,0 +318,18 @@\n+\n+    @Benchmark\n+    public short ReductionAddFP16() {\n+       short result = (short) 0;\n+       for (int i = 0; i < vectorDim; i++) {\n+           result = float16ToRawShortBits(Float16.add(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(vector1[i])));\n+       }\n+       return result;\n+    }\n+\n+    @Benchmark\n+    public short ReductionMulFP16() {\n+       short result = floatToFloat16(1.0f);\n+       for (int i = 0; i < vectorDim; i++) {\n+           result = float16ToRawShortBits(Float16.multiply(Float16.shortBitsToFloat16(result), Float16.shortBitsToFloat16(vector1[i])));\n+       }\n+       return result;\n+    }\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/vector\/Float16OperationsBenchmark.java","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"}]}