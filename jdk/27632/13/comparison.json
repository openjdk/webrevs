{"files":[{"patch":"@@ -149,1 +149,1 @@\n-      \/\/ Count in just trashed collection set, during coalesced CM-with-UR\n+      \/\/ Count in just trashed humongous continuations\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/heuristics\/shenandoahGenerationalHeuristics.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -60,11 +60,0 @@\n-  if (ShenandoahGenerationalAdaptiveTenuring) {\n-    _local_age_tables = NEW_C_HEAP_ARRAY(AgeTable*, _max_workers, mtGC);\n-    CENSUS_NOISE(_local_noise = NEW_C_HEAP_ARRAY(ShenandoahNoiseStats, max_workers, mtGC);)\n-    for (uint i = 0; i < _max_workers; i++) {\n-      _local_age_tables[i] = new AgeTable(false);\n-      CENSUS_NOISE(_local_noise[i].clear();)\n-    }\n-  } else {\n-    _local_age_tables = nullptr;\n-  }\n-  _epoch = MAX_SNAPSHOTS - 1;  \/\/ see prepare_for_census_update()\n@@ -72,2 +61,5 @@\n-  if (!ShenandoahGenerationalAdaptiveTenuring) {\n-    _tenuring_threshold[_epoch] = InitialTenuringThreshold;\n+  _local_age_tables = NEW_C_HEAP_ARRAY(AgeTable*, _max_workers, mtGC);\n+  CENSUS_NOISE(_local_noise = NEW_C_HEAP_ARRAY(ShenandoahNoiseStats, max_workers, mtGC);)\n+  for (uint i = 0; i < _max_workers; i++) {\n+    _local_age_tables[i] = new AgeTable(false);\n+    CENSUS_NOISE(_local_noise[i].clear();)\n@@ -75,0 +67,1 @@\n+  _epoch = MAX_SNAPSHOTS - 1;  \/\/ see prepare_for_census_update()\n@@ -157,1 +150,0 @@\n-  assert(ShenandoahGenerationalAdaptiveTenuring, \"Only update census when adaptive tenuring is enabled\");\n@@ -184,0 +176,13 @@\n+size_t ShenandoahAgeCensus::get_tenurable_bytes(const uint tenuring_threshold) const {\n+  assert(_epoch < MAX_SNAPSHOTS, \"Out of bounds\");\n+  size_t total = 0;\n+  const AgeTable* pv = _global_age_tables[_epoch];\n+  for (uint i = 0; i < MAX_COHORTS; i++) {\n+    if (i >= tenuring_threshold) {\n+      total += pv->sizes[i];\n+    }\n+  }\n+  return total * HeapWordSize;\n+}\n+\n+\n@@ -198,5 +203,1 @@\n-  if (!ShenandoahGenerationalAdaptiveTenuring) {\n-    assert(_local_age_tables == nullptr, \"Error\");\n-    return;\n-  }\n-  for (uint i = 0; i < _max_workers; i++) {\n+for (uint i = 0; i < _max_workers; i++) {\n@@ -224,4 +225,0 @@\n-  if (!ShenandoahGenerationalAdaptiveTenuring) {\n-    assert(_local_age_tables == nullptr, \"Error\");\n-    return true;\n-  }\n@@ -261,1 +258,0 @@\n-  assert(ShenandoahGenerationalAdaptiveTenuring, \"Only update when adaptive tenuring is enabled\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAgeCensus.cpp","additions":20,"deletions":24,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -176,1 +176,0 @@\n-  \/\/ Only used in the case of ShenandoahGenerationalAdaptiveTenuring\n@@ -214,0 +213,6 @@\n+  \/\/ Return the total size of the population above the given threshold for the current epoch\n+  size_t get_tenurable_bytes(uint tenuring_threshold) const;\n+\n+  \/\/ As above, but use the current tenuring threshold by default\n+  size_t get_tenurable_bytes() const { return get_tenurable_bytes(tenuring_threshold()); }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAgeCensus.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/shenandoah\/shenandoahAgeCensus.hpp\"\n@@ -248,0 +249,22 @@\n+\/\/ Here's the algebra.\n+\/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n+\/\/     OE = old evac,\n+\/\/     YE = young evac, and\n+\/\/     TE = total evac = OE + YE\n+\/\/ By definition:\n+\/\/            SOEP\/100 = OE\/TE\n+\/\/                     = OE\/(OE+YE)\n+\/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)         \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n+\/\/                     = OE\/YE\n+\/\/  =>              OE = YE*SOEP\/(100-SOEP)\n+size_t get_maximum_old_evacuation_reserve(size_t maximum_young_evacuation_reserve, size_t old_available) {\n+  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n+  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n+  if (ShenandoahOldEvacRatioPercent == 100) {\n+    return old_available;\n+  }\n+\n+  const size_t ratio_of_old_in_collection_set = (maximum_young_evacuation_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent);\n+  return MIN2(ratio_of_old_in_collection_set, old_available);\n+}\n+\n@@ -272,15 +295,0 @@\n-  \/\/\n-  \/\/ Here's the algebra.\n-  \/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n-  \/\/     OE = old evac,\n-  \/\/     YE = young evac, and\n-  \/\/     TE = total evac = OE + YE\n-  \/\/ By definition:\n-  \/\/            SOEP\/100 = OE\/TE\n-  \/\/                     = OE\/(OE+YE)\n-  \/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)         \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n-  \/\/                     = OE\/YE\n-  \/\/  =>              OE = YE*SOEP\/(100-SOEP)\n-\n-  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n-  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n@@ -288,3 +296,2 @@\n-  const size_t maximum_old_evacuation_reserve = (ShenandoahOldEvacRatioPercent == 100) ?\n-    old_available : MIN2((maximum_young_evacuation_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent),\n-                          old_available);\n+  const size_t maximum_old_evacuation_reserve = get_maximum_old_evacuation_reserve(maximum_young_evacuation_reserve, old_available);\n+\n@@ -292,0 +299,2 @@\n+  log_debug(gc, cset)(\"max_young_evac_reserver: \" PROPERFMT\", max_old_evac_reserve: \" PROPERFMT \", old_available: \" PROPERFMT,\n+                      PROPERFMTARGS(maximum_young_evacuation_reserve), PROPERFMTARGS(maximum_old_evacuation_reserve), PROPERFMTARGS(old_available));\n@@ -347,0 +356,4 @@\n+  assert(consumed_by_advance_promotion <= old_promo_reserve, \"Cannot promote more than was reserved\");\n+\n+  log_info(gc, ergo)(\"Initial evacuation reserves: young: \" PROPERFMT \", promotion: \" PROPERFMT \", old: \" PROPERFMT,\n+                     PROPERFMTARGS(young_evacuation_reserve), PROPERFMTARGS(consumed_by_advance_promotion), PROPERFMTARGS(old_evacuation_reserve));\n@@ -369,2 +382,2 @@\n-  \/\/ We may find that old_evacuation_reserve and\/or loaned_for_young_evacuation are not fully consumed, in which case we may\n-  \/\/  be able to increase regions_available_to_loan\n+  \/\/ We may find that old_evacuation_reserve is not fully consumed, in which case we may be able to transfer old\n+  \/\/ unaffiliated regions back to young.\n@@ -372,1 +385,1 @@\n-  \/\/ The role of adjust_evacuation_budgets() is to compute the correct value of regions_available_to_loan and to make\n+  \/\/ The role of adjust_evacuation_budgets() is to compute the correct value of regions to transfer to young and to make\n@@ -406,5 +419,1 @@\n-  size_t young_advance_promoted = collection_set->get_live_bytes_in_tenurable_regions();\n-  size_t young_advance_promoted_reserve_used = (size_t) (ShenandoahPromoEvacWaste * double(young_advance_promoted));\n-\n-  size_t young_evacuated = collection_set->get_live_bytes_in_untenurable_regions();\n-  size_t young_evacuated_reserve_used = (size_t) (ShenandoahEvacWaste * double(young_evacuated));\n+  old_generation->reset_promoted_expended();\n@@ -412,3 +421,4 @@\n-  size_t total_young_available = young_generation->available_with_reserve();\n-  assert(young_evacuated_reserve_used <= total_young_available, \"Cannot evacuate more than is available in young\");\n-  young_generation->set_evacuation_reserve(young_evacuated_reserve_used);\n+  const size_t young_evacuated = collection_set->get_live_bytes_in_untenurable_regions();\n+  const size_t young_evacuated_commited = (size_t) (ShenandoahEvacWaste * double(young_evacuated));\n+  assert(young_evacuated_commited <= young_generation->available_with_reserve(), \"Cannot evacuate more than is available in young\");\n+  young_generation->set_evacuation_reserve(young_evacuated_commited);\n@@ -417,13 +427,8 @@\n-  \/\/ Now that we've established the collection set, we know how much memory is really required by old-gen for evacuation\n-  \/\/ and promotion reserves.  Try shrinking OLD now in case that gives us a bit more runway for mutator allocations during\n-  \/\/ evac and update phases.\n-  size_t old_consumed = old_evacuated_committed + young_advance_promoted_reserve_used;\n-\n-  if (old_available < old_consumed) {\n-    \/\/ This can happen due to round-off errors when adding the results of truncated integer arithmetic.\n-    \/\/ We've already truncated old_evacuated_committed.  Truncate young_advance_promoted_reserve_used here.\n-    assert(young_advance_promoted_reserve_used <= (33 * (old_available - old_evacuated_committed)) \/ 32,\n-           \"Round-off errors should be less than 3.125%%, committed: %zu, reserved: %zu\",\n-           young_advance_promoted_reserve_used, old_available - old_evacuated_committed);\n-    young_advance_promoted_reserve_used = old_available - old_evacuated_committed;\n-    old_consumed = old_evacuated_committed + young_advance_promoted_reserve_used;\n+  const size_t promoted_reserve = old_generation->get_promoted_reserve();\n+  const size_t old_consumed = old_evacuated_committed + promoted_reserve;\n+\n+  if (is_global() && old_available < old_consumed) {\n+    \/\/ The global heuristic may transfer young regions to the old generation to allow more old evacuations.\n+    \/\/ It will increase the old evacuation reserve when it does this, but old available will be adjusted\n+    \/\/ when the free set is rebuilt (after this method exits).\n+    old_available = old_consumed;\n@@ -432,2 +437,1 @@\n-  assert(old_available >= old_consumed, \"Cannot consume (%zu) more than is available (%zu)\",\n-         old_consumed, old_available);\n+  assert(old_available >= old_consumed, \"Cannot consume (%zu) more than is available (%zu)\", old_consumed, old_available);\n@@ -435,2 +439,2 @@\n-  size_t unaffiliated_old_regions = old_generation->free_unaffiliated_regions();\n-  size_t unaffiliated_old = unaffiliated_old_regions * region_size_bytes;\n+  const size_t unaffiliated_old_regions = old_generation->free_unaffiliated_regions();\n+  const size_t unaffiliated_old = unaffiliated_old_regions * region_size_bytes;\n@@ -440,0 +444,1 @@\n+  log_debug(gc, cset)(\"excess_old is: %zu, unaffiliated_old_regions is: %zu\", excess_old, unaffiliated_old_regions);\n@@ -441,39 +446,4 @@\n-  \/\/ Make sure old_evac_committed is unaffiliated\n-  if (old_evacuated_committed > 0) {\n-    if (unaffiliated_old > old_evacuated_committed) {\n-      size_t giveaway = unaffiliated_old - old_evacuated_committed;\n-      size_t giveaway_regions = giveaway \/ region_size_bytes;  \/\/ round down\n-      if (giveaway_regions > 0) {\n-        excess_old = MIN2(excess_old, giveaway_regions * region_size_bytes);\n-      } else {\n-        excess_old = 0;\n-      }\n-    } else {\n-      excess_old = 0;\n-    }\n-  }\n-\n-  \/\/ If we find that OLD has excess regions, give them back to YOUNG now to reduce likelihood we run out of allocation\n-  \/\/ runway during evacuation and update-refs.\n-  size_t regions_to_xfer = 0;\n-  if (excess_old > unaffiliated_old) {\n-    \/\/ we can give back unaffiliated_old (all of unaffiliated is excess)\n-    if (unaffiliated_old_regions > 0) {\n-      regions_to_xfer = unaffiliated_old_regions;\n-    }\n-  } else if (unaffiliated_old_regions > 0) {\n-    \/\/ excess_old < unaffiliated old: we can give back MIN(excess_old\/region_size_bytes, unaffiliated_old_regions)\n-    size_t excess_regions = excess_old \/ region_size_bytes;\n-    regions_to_xfer = MIN2(excess_regions, unaffiliated_old_regions);\n-  }\n-  if (regions_to_xfer > 0) {\n-    excess_old -= regions_to_xfer * region_size_bytes;\n-    log_debug(gc, ergo)(\"Before start of evacuation, total_promotion reserve is young_advance_promoted_reserve: %zu \"\n-                        \"plus excess: old: %zu\", young_advance_promoted_reserve_used, excess_old);\n-  }\n-\n-  \/\/ Add in the excess_old memory to hold unanticipated promotions, if any.  If there are more unanticipated\n-  \/\/ promotions than fit in reserved memory, they will be deferred until a future GC pass.\n-  size_t total_promotion_reserve = young_advance_promoted_reserve_used + excess_old;\n-  old_generation->set_promoted_reserve(total_promotion_reserve);\n-  old_generation->reset_promoted_expended();\n+  log_info(gc, ergo)(\"Adjusted evacuation reserves: young: \" PROPERFMT \", promotion: \" PROPERFMT \", old: \" PROPERFMT,\n+                     PROPERFMTARGS(young_generation->get_evacuation_reserve()),\n+                     PROPERFMTARGS(old_generation->get_promoted_reserve()),\n+                     PROPERFMTARGS(old_generation->get_evacuation_reserve()));\n@@ -539,1 +509,0 @@\n-  size_t promo_potential = 0;\n@@ -553,2 +522,0 @@\n-  ShenandoahFreeSet* freeset = heap->free_set();\n-\n@@ -556,1 +523,1 @@\n-  idx_t pip_low_collector_idx = freeset->max_regions();\n+  idx_t pip_low_collector_idx = free_set->max_regions();\n@@ -558,1 +525,1 @@\n-  idx_t pip_low_mutator_idx = freeset->max_regions();\n+  idx_t pip_low_mutator_idx = free_set->max_regions();\n@@ -647,21 +614,0 @@\n-    } else {\n-      \/\/ We only evacuate & promote objects from regular regions whose garbage() is above old-garbage-threshold.\n-      \/\/ Objects in tenure-worthy regions with less garbage are promoted in place. These take a different path to\n-      \/\/ old-gen.  Regions excluded from promotion because their garbage content is too low (causing us to anticipate that\n-      \/\/ the region would be promoted in place) may be eligible for evacuation promotion by the time promotion takes\n-      \/\/ place during a subsequent GC pass because more garbage is found within the region between now and then.  This\n-      \/\/ should not happen if we are properly adapting the tenure age.  The theory behind adaptive tenuring threshold\n-      \/\/ is to choose the youngest age that demonstrates no \"significant\" further loss of population since the previous\n-      \/\/ age.  If not this, we expect the tenure age to demonstrate linear population decay for at least two population\n-      \/\/ samples, whereas we expect to observe exponential population decay for ages younger than the tenure age.\n-      \/\/\n-      \/\/ In the case that certain regions which were anticipated to be promoted in place need to be promoted by\n-      \/\/ evacuation, it may be the case that there is not sufficient reserve within old-gen to hold evacuation of\n-      \/\/ these regions.  The likely outcome is that these regions will not be selected for evacuation or promotion\n-      \/\/ in the current cycle and we will anticipate that they will be promoted in the next cycle.  This will cause\n-      \/\/ us to reserve more old-gen memory so that these objects can be promoted in the subsequent cycle.\n-      if (heap->is_aging_cycle() && heap->age_census()->is_tenurable(r->age() + 1)) {\n-        if (r->garbage() >= old_garbage_threshold) {\n-          promo_potential += r->get_live_data_bytes();\n-        }\n-      }\n@@ -674,1 +620,1 @@\n-    freeset->account_for_pip_regions(pip_mutator_regions, pip_mutator_bytes, pip_collector_regions, pip_collector_bytes);\n+    free_set->account_for_pip_regions(pip_mutator_regions, pip_mutator_bytes, pip_collector_regions, pip_collector_bytes);\n@@ -679,1 +625,1 @@\n-    freeset->shrink_interval_if_range_modifies_either_boundary(ShenandoahFreeSetPartitionId::Collector,\n+    free_set->shrink_interval_if_range_modifies_either_boundary(ShenandoahFreeSetPartitionId::Collector,\n@@ -684,1 +630,1 @@\n-    freeset->shrink_interval_if_range_modifies_either_boundary(ShenandoahFreeSetPartitionId::Mutator,\n+    free_set->shrink_interval_if_range_modifies_either_boundary(ShenandoahFreeSetPartitionId::Mutator,\n@@ -689,0 +635,2 @@\n+  heap->old_generation()->set_pad_for_promote_in_place(promote_in_place_pad);\n+\n@@ -700,10 +648,3 @@\n-      if (old_consumed + promotion_need <= old_promotion_reserve) {\n-        old_consumed += promotion_need;\n-        candidate_regions_for_promotion_by_copy[region->index()] = true;\n-        selected_regions++;\n-        selected_live += region_live_data;\n-      } else {\n-        \/\/ We rejected this promotable region from the collection set because we had no room to hold its copy.\n-        \/\/ Add this region to promo potential for next GC.\n-        promo_potential += region_live_data;\n-        assert(!candidate_regions_for_promotion_by_copy[region->index()], \"Shouldn't be selected\");\n+      if (old_consumed + promotion_need > old_promotion_reserve) {\n+        \/\/ We rejected the remaining promotable regions from the collection set because we had no room to hold their evacuees.\n+        break;\n@@ -711,2 +652,5 @@\n-      \/\/ We keep going even if one region is excluded from selection because we need to accumulate all eligible\n-      \/\/ regions that are not preselected into promo_potential\n+\n+      old_consumed += promotion_need;\n+      candidate_regions_for_promotion_by_copy[region->index()] = true;\n+      selected_regions++;\n+      selected_live += region_live_data;\n@@ -714,0 +658,1 @@\n+\n@@ -719,1 +664,1 @@\n-  log_info(gc, ergo)(\"Promotion potential of aged regions with sufficient garbage: \" PROPERFMT, PROPERFMTARGS(promo_potential));\n+  assert(old_consumed <= old_promotion_reserve, \"Consumed more (%zu) than we reserved (%zu)\", old_consumed, old_promotion_reserve);\n@@ -721,3 +666,19 @@\n-  heap->old_generation()->set_pad_for_promote_in_place(promote_in_place_pad);\n-  heap->old_generation()->set_promotion_potential(promo_potential);\n-  return old_consumed;\n+  const uint tenuring_threshold = heap->age_census()->tenuring_threshold();\n+  const size_t tenurable_this_cycle = heap->age_census()->get_tenurable_bytes(tenuring_threshold);\n+  size_t tenurable_next_cycle = heap->age_census()->get_tenurable_bytes(tenuring_threshold - 1);\n+\n+  \/\/ Don't include the bytes we expect to promote in this cycle, in the next\n+  assert(tenurable_next_cycle >= tenurable_this_cycle,\n+         \"Tenurable next cycle (\" PROPERFMT \") should include tenurable this cycle (\" PROPERFMT \")\",\n+         PROPERFMTARGS(tenurable_next_cycle), PROPERFMTARGS(tenurable_this_cycle));\n+\n+  tenurable_next_cycle -= tenurable_this_cycle;\n+\n+  log_info(gc, ergo)(\"Tenurable next cycle: \" PROPERFMT \", tenurable this cycle: \" PROPERFMT \", selected for promotion: \" PROPERFMT ,\n+                     PROPERFMTARGS(tenurable_next_cycle), PROPERFMTARGS(tenurable_this_cycle), PROPERFMTARGS(old_consumed));\n+\n+  heap->old_generation()->set_promotion_potential(tenurable_next_cycle);\n+\n+  \/\/ old_consumed may exceed tenurable_this_cycle because it has been scaled by ShenandoahPromoEvacWaste.\n+  old_consumed = MAX2(old_consumed, tenurable_this_cycle);\n+  return MIN2(old_consumed, old_promotion_reserve);\n@@ -750,1 +711,1 @@\n-  if (is_generational && ShenandoahGenerationalAdaptiveTenuring) {\n+  if (is_generational) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":92,"deletions":131,"binary":false,"changes":223,"status":"modified"},{"patch":"@@ -307,1 +307,1 @@\n-      if (!is_promotion || !has_plab || (size > PLAB::min_size())) {\n+      if (!is_promotion || !has_plab || (size > plab_min_size())) {\n@@ -311,0 +311,11 @@\n+        if (is_promotion && copy != nullptr) {\n+          \/\/ Our plab has too much remaining to throw away, but it can't fit this object so we allow a shared allocation\n+          \/\/ in this case.\n+          PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n+          if (plab != nullptr) {\n+            log_debug(gc, plab)(\"Made a shared promotion of size: %zu, actual PLAB size for thread: %zu, remaining: %zu, min PLAB: %zu, max PLAB: %zu\",\n+                                size * HeapWordSize, ShenandoahThreadLocalData::get_plab_actual_size(thread) * HeapWordSize,\n+                                plab->words_remaining() * HeapWordSize, plab_min_size() * HeapWordSize, plab_max_size() * HeapWordSize);\n+\n+          }\n+        }\n@@ -314,2 +325,3 @@\n-      \/\/ costly.  Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB) and will promote in a future\n-      \/\/ evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size <= PLAB::min_size())\n+      \/\/ costly (such objects should use the PLAB). Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB)\n+      \/\/ and will promote in a future evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size\n+      \/\/ <= PLAB::min_size())\n@@ -419,1 +431,0 @@\n-  HeapWord* obj;\n@@ -424,0 +435,1 @@\n+    log_debug(gc, plab)(\"Thread has no PLAB\");\n@@ -425,1 +437,4 @@\n-  } else if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+  }\n+\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    log_develop_trace(gc, plab)(\"Thread is not allowed to use PLAB for promotions\");\n@@ -428,2 +443,2 @@\n-  \/\/ if plab->word_size() <= 0, thread's plab not yet initialized for this pass, so allow_plab_promotions() is not trustworthy\n-  obj = plab->allocate(size);\n+\n+  HeapWord* obj = plab->allocate(size);\n@@ -431,0 +446,1 @@\n+    \/\/ What remains in this plab is smaller than the minimum plab, so allocate a new plab (retiring this pla).\n@@ -434,0 +450,1 @@\n+\n@@ -436,0 +453,2 @@\n+    log_debug(gc, plab)(\"PLAB remaining (%zu) is more than the minimum PLAB size (%zu), save this PLAB\",\n+                        plab->words_remaining() * HeapWordSize, plab_min_size() * HeapWordSize);\n@@ -482,1 +501,0 @@\n-  \/\/ Retire current PLAB, and allocate a new one.\n@@ -484,39 +502,1 @@\n-  if (plab->words_remaining() < plab_min_size) {\n-    \/\/ Retire current PLAB. This takes care of any PLAB book-keeping.\n-    \/\/ retire_plab() registers the remnant filler object with the remembered set scanner without a lock.\n-    \/\/ Since PLABs are card-aligned, concurrent registrations in other PLABs don't interfere.\n-    retire_plab(plab, thread);\n-\n-    size_t actual_size = 0;\n-    HeapWord* plab_buf = allocate_new_plab(min_size, cur_size, &actual_size);\n-    if (plab_buf == nullptr) {\n-      if (min_size == plab_min_size) {\n-        \/\/ Disable PLAB promotions for this thread because we cannot even allocate a minimal PLAB. This allows us\n-        \/\/ to fail faster on subsequent promotion attempts.\n-        ShenandoahThreadLocalData::disable_plab_promotions(thread);\n-      }\n-      return nullptr;\n-    } else {\n-      ShenandoahThreadLocalData::enable_plab_retries(thread);\n-    }\n-    \/\/ Since the allocated PLAB may have been down-sized for alignment, plab->allocate(size) below may still fail.\n-    if (ZeroTLAB) {\n-      \/\/ ... and clear it.\n-      Copy::zero_to_words(plab_buf, actual_size);\n-    } else {\n-      \/\/ ...and zap just allocated object.\n-#ifdef ASSERT\n-      \/\/ Skip mangling the space corresponding to the object header to\n-      \/\/ ensure that the returned space is not considered parsable by\n-      \/\/ any concurrent GC thread.\n-      size_t hdr_size = oopDesc::header_size();\n-      Copy::fill_to_words(plab_buf + hdr_size, actual_size - hdr_size, badHeapWordVal);\n-#endif \/\/ ASSERT\n-    }\n-    assert(is_aligned(actual_size, CardTable::card_size_in_words()), \"Align by design\");\n-    plab->set_buf(plab_buf, actual_size);\n-    if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n-      return nullptr;\n-    }\n-    return plab->allocate(size);\n-  } else {\n+  if (plab->words_remaining() >= plab_min_size) {\n@@ -527,0 +507,46 @@\n+    log_debug(gc, plab)(\"Existing PLAB is still viable (words remaining: %zu, plab_min_size: %zu)\", plab->words_remaining(), plab_min_size);\n+    return nullptr;\n+  }\n+\n+  \/\/ The current plab has fewer words remaining than the minimum PLAB. Retire it. This takes care of any PLAB book-keeping.\n+  \/\/ retire_plab() registers the remnant filler object with the remembered set scanner without a lock.\n+  \/\/ Since PLABs are card-aligned, concurrent registrations in other PLABs don't interfere.\n+  retire_plab(plab, thread);\n+\n+  size_t actual_size = 0;\n+  HeapWord* plab_buf = allocate_new_plab(min_size, cur_size, &actual_size);\n+  if (plab_buf == nullptr) {\n+    if (min_size == plab_min_size) {\n+      \/\/ Disable PLAB promotions for this thread because we cannot even allocate a minimal PLAB. This allows us\n+      \/\/ to fail faster on subsequent promotion attempts.\n+      log_debug(gc, plab)(\"Disable PLAB promotions because we can't allocate minimum sized PLAB: %zu\", min_size * HeapWordSize);\n+      ShenandoahThreadLocalData::disable_plab_promotions(thread);\n+    }\n+    return nullptr;\n+  }\n+\n+  log_debug(gc, plab)(\"Allocated new PLAB of size: %zu bytes, enable PLAB retries\", actual_size * HeapWordSize);\n+  ShenandoahThreadLocalData::enable_plab_retries(thread);\n+\n+\n+  if (ZeroTLAB) {\n+    \/\/ ... and clear it.\n+    Copy::zero_to_words(plab_buf, actual_size);\n+  } else {\n+    \/\/ ...and zap just allocated object.\n+#ifdef ASSERT\n+    \/\/ Skip mangling the space corresponding to the object header to\n+    \/\/ ensure that the returned space is not considered parsable by\n+    \/\/ any concurrent GC thread.\n+    const size_t hdr_size = oopDesc::header_size();\n+    Copy::fill_to_words(plab_buf + hdr_size, actual_size - hdr_size, badHeapWordVal);\n+#endif \/\/ ASSERT\n+  }\n+\n+  assert(is_aligned(actual_size, CardTable::card_size_in_words()), \"Align by design\");\n+  plab->set_buf(plab_buf, actual_size);\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    \/\/ Thinking here is that the thread has exhausted promotion reserve, but there may yet be old objects\n+    \/\/ to evacuate and this plab could be used for those.\n+    log_debug(gc, plab)(\"Thread has new PLAB of size %zu, but is not allowed to promote %zu. Mixed evac in progress? %s\",\n+      actual_size * HeapWordSize, size * HeapWordSize, BOOL_TO_STR(collection_set()->has_old_regions()));\n@@ -529,0 +555,3 @@\n+\n+  \/\/ Since the allocated PLAB may have been down-sized for alignment, plab->allocate(size) below may still fail.\n+  return plab->allocate(size);\n@@ -557,1 +586,1 @@\n-  \/\/  1. Some of the plab may have been dedicated to evacuations.\n+  \/\/  1. Some of the plab may have been dedicated to old evacuations.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":77,"deletions":48,"binary":false,"changes":125,"status":"modified"},{"patch":"@@ -1287,0 +1287,1 @@\n+  assert(!heap_region_containing(p)->is_humongous(), \"never evacuate humongous objects\");\n@@ -1288,5 +1289,1 @@\n-  ShenandoahHeapRegion* r = heap_region_containing(p);\n-  assert(!r->is_humongous(), \"never evacuate humongous objects\");\n-\n-  ShenandoahAffiliation target_gen = r->affiliation();\n-  return try_evacuate_object(p, thread, r, target_gen);\n+  return try_evacuate_object(p, thread);\n@@ -1295,4 +1292,1 @@\n-oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region,\n-                                               ShenandoahAffiliation target_gen) {\n-  assert(target_gen == YOUNG_GENERATION, \"Only expect evacuations to young in this mode\");\n-  assert(from_region->is_young(), \"Only expect evacuations from young in this mode\");\n+oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread) {\n@@ -1314,1 +1308,1 @@\n-      ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, target_gen);\n+      ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, YOUNG_GENERATION);\n@@ -1331,1 +1325,1 @@\n-    evac_tracker()->begin_evacuation(thread, size * HeapWordSize, from_region->affiliation(), target_gen);\n+    evac_tracker()->begin_evacuation(thread, size * HeapWordSize, YOUNG_GENERATION, YOUNG_GENERATION);\n@@ -1345,1 +1339,1 @@\n-      evac_tracker()->end_evacuation(thread, size * HeapWordSize, from_region->affiliation(), target_gen);\n+      evac_tracker()->end_evacuation(thread, size * HeapWordSize, YOUNG_GENERATION, YOUNG_GENERATION);\n@@ -1600,6 +1594,0 @@\n-    if (ShenandoahEvacTracking) {\n-      evac_tracker()->print_global_on(&ls);\n-      ls.cr();\n-      ls.cr();\n-    }\n-\n@@ -1615,0 +1603,4 @@\n+\n+    if (ShenandoahEvacTracking) {\n+      evac_tracker()->print_global_on(&ls);\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":10,"deletions":18,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -777,1 +777,1 @@\n-  oop try_evacuate_object(oop src, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahAffiliation target_gen);\n+  oop try_evacuate_object(oop src, Thread* thread);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -121,7 +121,5 @@\n-    if (ShenandoahGenerationalAdaptiveTenuring) {\n-      assert(region->is_young(), \"Only for young objects\");\n-      uint age = ShenandoahHeap::get_object_age(obj);\n-      ShenandoahAgeCensus* const census = ShenandoahGenerationalHeap::heap()->age_census();\n-      CENSUS_NOISE(census->add(age, region->age(), region->youth(), size, worker_id);)\n-      NO_CENSUS_NOISE(census->add(age, region->age(), size, worker_id);)\n-    }\n+    assert(region->is_young(), \"Only for young objects\");\n+    const uint age = ShenandoahHeap::get_object_age(obj);\n+    ShenandoahAgeCensus* const census = ShenandoahGenerationalHeap::heap()->age_census();\n+    CENSUS_NOISE(census->add(age, region->age(), region->youth(), size, worker_id);)\n+    NO_CENSUS_NOISE(census->add(age, region->age(), size, worker_id);)\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.inline.hpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -420,1 +420,1 @@\n-    \/\/ We may also find that we have accumulated canddiate regions for mixed evacuation.  If so, we will want to expand\n+    \/\/ We may also find that we have accumulated candidate regions for mixed evacuation.  If so, we will want to expand\n@@ -611,1 +611,2 @@\n-    ls.print_cr(\"Promotion failed, size %zu, has plab? %s, PLAB remaining: %zu\"\n+    ResourceMark resources; \/\/ for thread name\n+    ls.print_cr(\"Promotion failed for %s, size %zu, has plab? %s, PLAB remaining: %zu\"\n@@ -614,1 +615,1 @@\n-                size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n+                thread->name(), size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -102,3 +102,0 @@\n-  product(bool, ShenandoahGenerationalAdaptiveTenuring, true, EXPERIMENTAL, \\\n-          \"(Generational mode only) Dynamically adapt tenuring age.\")       \\\n-                                                                            \\\n@@ -129,2 +126,1 @@\n-          \"it. Used only when ShenandoahGenerationalhenAdaptiveTenuring is \"\\\n-          \"enabled.\")                                                       \\\n+          \"it.\")                                                            \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoah_globals.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-    return total;\n+    return total * HeapWordSize;\n@@ -90,0 +90,7 @@\n+TEST_F(ShenandoahAgeCensusTest, get_tenurable_bytes) {\n+  ShenandoahAgeCensus census(1);\n+  update(census);\n+  EXPECT_EQ(get_total_population_older_than(1), census.get_tenurable_bytes(1));\n+  EXPECT_LT(census.get_tenurable_bytes(2), census.get_tenurable_bytes(1));\n+}\n+\n","filename":"test\/hotspot\/gtest\/gc\/shenandoah\/test_shenandoahAgeCensus.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"}]}