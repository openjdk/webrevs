{"files":[{"patch":"@@ -184,0 +184,13 @@\n+size_t ShenandoahAgeCensus::get_tenurable_bytes(const uint tenuring_threshold) const {\n+  assert(_epoch < MAX_SNAPSHOTS, \"Out of bounds\");\n+  size_t total = 0;\n+  const AgeTable* pv = _global_age_tables[_epoch];\n+  for (uint i = 0; i < MAX_COHORTS; i++) {\n+    if (i >= tenuring_threshold) {\n+      total += pv->sizes[i];\n+    }\n+  }\n+  return total * HeapWordSize;\n+}\n+\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAgeCensus.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -214,0 +214,6 @@\n+  \/\/ Return the total size of the population above the given threshold for the current epoch\n+  size_t get_tenurable_bytes(uint tenuring_threshold) const;\n+\n+  \/\/ As above, but use the current tenuring threshold by default\n+  size_t get_tenurable_bytes() const { return get_tenurable_bytes(tenuring_threshold()); }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAgeCensus.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/shenandoah\/shenandoahAgeCensus.hpp\"\n@@ -245,0 +246,22 @@\n+\/\/ Here's the algebra.\n+\/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n+\/\/     OE = old evac,\n+\/\/     YE = young evac, and\n+\/\/     TE = total evac = OE + YE\n+\/\/ By definition:\n+\/\/            SOEP\/100 = OE\/TE\n+\/\/                     = OE\/(OE+YE)\n+\/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)         \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n+\/\/                     = OE\/YE\n+\/\/  =>              OE = YE*SOEP\/(100-SOEP)\n+size_t get_maximum_old_evacuation_reserve(size_t maximum_young_evacuation_reserve, size_t old_available) {\n+  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n+  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n+  if (ShenandoahOldEvacRatioPercent == 100) {\n+    return old_available;\n+  }\n+\n+  const size_t ratio_of_old_in_collection_set = (maximum_young_evacuation_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent);\n+  return MIN2(ratio_of_old_in_collection_set, old_available);\n+}\n+\n@@ -269,15 +292,0 @@\n-  \/\/\n-  \/\/ Here's the algebra.\n-  \/\/ Let SOEP = ShenandoahOldEvacRatioPercent,\n-  \/\/     OE = old evac,\n-  \/\/     YE = young evac, and\n-  \/\/     TE = total evac = OE + YE\n-  \/\/ By definition:\n-  \/\/            SOEP\/100 = OE\/TE\n-  \/\/                     = OE\/(OE+YE)\n-  \/\/  => SOEP\/(100-SOEP) = OE\/((OE+YE)-OE)         \/\/ componendo-dividendo: If a\/b = c\/d, then a\/(b-a) = c\/(d-c)\n-  \/\/                     = OE\/YE\n-  \/\/  =>              OE = YE*SOEP\/(100-SOEP)\n-\n-  \/\/ We have to be careful in the event that SOEP is set to 100 by the user.\n-  assert(ShenandoahOldEvacRatioPercent <= 100, \"Error\");\n@@ -285,3 +293,2 @@\n-  const size_t maximum_old_evacuation_reserve = (ShenandoahOldEvacRatioPercent == 100) ?\n-    old_available : MIN2((maximum_young_evacuation_reserve * ShenandoahOldEvacRatioPercent) \/ (100 - ShenandoahOldEvacRatioPercent),\n-                          old_available);\n+  const size_t maximum_old_evacuation_reserve = get_maximum_old_evacuation_reserve(maximum_young_evacuation_reserve, old_available);\n+\n@@ -289,0 +296,2 @@\n+  log_debug(gc, cset)(\"max_young_evac_reserver: \" PROPERFMT\", max_old_evac_reserve: \" PROPERFMT \", old_available: \" PROPERFMT,\n+                      PROPERFMTARGS(maximum_young_evacuation_reserve), PROPERFMTARGS(maximum_old_evacuation_reserve), PROPERFMTARGS(old_available));\n@@ -344,0 +353,4 @@\n+  assert(consumed_by_advance_promotion <= old_promo_reserve, \"Cannot promote more than was reserved\");\n+\n+  log_info(gc, ergo)(\"Initial evacuation reserves: young: \" PROPERFMT \", promotion: \" PROPERFMT \", old: \" PROPERFMT,\n+                     PROPERFMTARGS(young_evacuation_reserve), PROPERFMTARGS(consumed_by_advance_promotion), PROPERFMTARGS(old_evacuation_reserve));\n@@ -366,2 +379,2 @@\n-  \/\/ We may find that old_evacuation_reserve and\/or loaned_for_young_evacuation are not fully consumed, in which case we may\n-  \/\/  be able to increase regions_available_to_loan\n+  \/\/ We may find that old_evacuation_reserve is not fully consumed, in which case we may be able to transfer old\n+  \/\/ unaffiliated regions back to young.\n@@ -369,1 +382,1 @@\n-  \/\/ The role of adjust_evacuation_budgets() is to compute the correct value of regions_available_to_loan and to make\n+  \/\/ The role of adjust_evacuation_budgets() is to compute the correct value of regions to transfer to young and to make\n@@ -403,5 +416,4 @@\n-  size_t young_advance_promoted = collection_set->get_live_bytes_in_tenurable_regions();\n-  size_t young_advance_promoted_reserve_used = (size_t) (ShenandoahPromoEvacWaste * double(young_advance_promoted));\n-\n-  size_t young_evacuated = collection_set->get_live_bytes_in_untenurable_regions();\n-  size_t young_evacuated_reserve_used = (size_t) (ShenandoahEvacWaste * double(young_evacuated));\n+  const size_t young_evacuated = collection_set->get_live_bytes_in_untenurable_regions();\n+  const size_t young_evacuated_commited = (size_t) (ShenandoahEvacWaste * double(young_evacuated));\n+  assert(young_evacuated_commited <= young_generation->available_with_reserve(), \"Cannot evacuate more than is available in young\");\n+  young_generation->set_evacuation_reserve(young_evacuated_commited);\n@@ -409,5 +421,0 @@\n-  size_t total_young_available = young_generation->available_with_reserve();\n-  assert(young_evacuated_reserve_used <= total_young_available, \"Cannot evacuate more than is available in young\");\n-  young_generation->set_evacuation_reserve(young_evacuated_reserve_used);\n-\n-  size_t old_available = old_generation->available();\n@@ -417,11 +424,3 @@\n-  size_t old_consumed = old_evacuated_committed + young_advance_promoted_reserve_used;\n-\n-  if (old_available < old_consumed) {\n-    \/\/ This can happen due to round-off errors when adding the results of truncated integer arithmetic.\n-    \/\/ We've already truncated old_evacuated_committed.  Truncate young_advance_promoted_reserve_used here.\n-    assert(young_advance_promoted_reserve_used <= (33 * (old_available - old_evacuated_committed)) \/ 32,\n-           \"Round-off errors should be less than 3.125%%, committed: %zu, reserved: %zu\",\n-           young_advance_promoted_reserve_used, old_available - old_evacuated_committed);\n-    young_advance_promoted_reserve_used = old_available - old_evacuated_committed;\n-    old_consumed = old_evacuated_committed + young_advance_promoted_reserve_used;\n-  }\n+  const size_t old_available = old_generation->available();\n+  const size_t promoted_reserve = old_generation->get_promoted_reserve();\n+  const size_t old_consumed = old_evacuated_committed + promoted_reserve;\n@@ -429,2 +428,1 @@\n-  assert(old_available >= old_consumed, \"Cannot consume (%zu) more than is available (%zu)\",\n-         old_consumed, old_available);\n+  assert(old_available >= old_consumed, \"Cannot consume (%zu) more than is available (%zu)\", old_consumed, old_available);\n@@ -432,2 +430,2 @@\n-  size_t unaffiliated_old_regions = old_generation->free_unaffiliated_regions();\n-  size_t unaffiliated_old = unaffiliated_old_regions * region_size_bytes;\n+  const size_t unaffiliated_old_regions = old_generation->free_unaffiliated_regions();\n+  const size_t unaffiliated_old = unaffiliated_old_regions * region_size_bytes;\n@@ -437,0 +435,1 @@\n+  log_debug(gc, cset)(\"excess_old is: %zu, unaffiliated_old_regions is: %zu\", excess_old, unaffiliated_old_regions);\n@@ -438,33 +437,0 @@\n-  \/\/ Make sure old_evac_committed is unaffiliated\n-  if (old_evacuated_committed > 0) {\n-    if (unaffiliated_old > old_evacuated_committed) {\n-      size_t giveaway = unaffiliated_old - old_evacuated_committed;\n-      size_t giveaway_regions = giveaway \/ region_size_bytes;  \/\/ round down\n-      if (giveaway_regions > 0) {\n-        excess_old = MIN2(excess_old, giveaway_regions * region_size_bytes);\n-      } else {\n-        excess_old = 0;\n-      }\n-    } else {\n-      excess_old = 0;\n-    }\n-  }\n-\n-  \/\/ If we find that OLD has excess regions, give them back to YOUNG now to reduce likelihood we run out of allocation\n-  \/\/ runway during evacuation and update-refs.\n-  size_t regions_to_xfer = 0;\n-  if (excess_old > unaffiliated_old) {\n-    \/\/ we can give back unaffiliated_old (all of unaffiliated is excess)\n-    if (unaffiliated_old_regions > 0) {\n-      regions_to_xfer = unaffiliated_old_regions;\n-    }\n-  } else if (unaffiliated_old_regions > 0) {\n-    \/\/ excess_old < unaffiliated old: we can give back MIN(excess_old\/region_size_bytes, unaffiliated_old_regions)\n-    size_t excess_regions = excess_old \/ region_size_bytes;\n-    regions_to_xfer = MIN2(excess_regions, unaffiliated_old_regions);\n-  }\n-  if (regions_to_xfer > 0) {\n-    excess_old -= regions_to_xfer * region_size_bytes;\n-    log_debug(gc, ergo)(\"Before start of evacuation, total_promotion reserve is young_advance_promoted_reserve: %zu \"\n-                        \"plus excess: old: %zu\", young_advance_promoted_reserve_used, excess_old);\n-  }\n@@ -472,4 +438,0 @@\n-  \/\/ Add in the excess_old memory to hold unanticipated promotions, if any.  If there are more unanticipated\n-  \/\/ promotions than fit in reserved memory, they will be deferred until a future GC pass.\n-  size_t total_promotion_reserve = young_advance_promoted_reserve_used + excess_old;\n-  old_generation->set_promoted_reserve(total_promotion_reserve);\n@@ -477,0 +439,4 @@\n+  log_info(gc, ergo)(\"Adjusted evacuation reserves: young: \" PROPERFMT \", promotion: \" PROPERFMT \", old: \" PROPERFMT,\n+                     PROPERFMTARGS(young_generation->get_evacuation_reserve()),\n+                     PROPERFMTARGS(old_generation->get_promoted_reserve()),\n+                     PROPERFMTARGS(old_generation->get_evacuation_reserve()));\n@@ -717,1 +683,6 @@\n-  log_info(gc, ergo)(\"Promotion potential of aged regions with sufficient garbage: \" PROPERFMT, PROPERFMTARGS(promo_potential));\n+  const uint tenuring_threshold = heap->age_census()->tenuring_threshold();\n+  const size_t tenurable_next_cycle = heap->age_census()->get_tenurable_bytes(tenuring_threshold - 1);\n+  const size_t tenurable_this_cycle = heap->age_census()->get_tenurable_bytes(tenuring_threshold);\n+\n+  log_info(gc, ergo)(\"Promotion potential: \" PROPERFMT \", tenurable next cycle: \" PROPERFMT \", tenurable this cycle: \" PROPERFMT \", selected for promotion: \" PROPERFMT ,\n+                     PROPERFMTARGS(promo_potential), PROPERFMTARGS(tenurable_next_cycle), PROPERFMTARGS(tenurable_this_cycle), PROPERFMTARGS(old_consumed));\n@@ -720,2 +691,7 @@\n-  heap->old_generation()->set_promotion_potential(promo_potential);\n-  return old_consumed;\n+  heap->old_generation()->set_promotion_potential(tenurable_next_cycle);\n+\n+  assert(old_consumed <= old_promotion_reserve, \"Consumed more (%zu) than we reserved (%zu)\", old_consumed, old_promotion_reserve);\n+\n+  \/\/ old_consumed may exceed tenurable_this_cycle because it has been scaled by ShenandoahPromoEvacWaste.\n+  old_consumed = MAX2(old_consumed, tenurable_this_cycle);\n+  return MIN2(old_consumed, old_promotion_reserve);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGeneration.cpp","additions":62,"deletions":86,"binary":false,"changes":148,"status":"modified"},{"patch":"@@ -302,1 +302,1 @@\n-      if (!is_promotion || !has_plab || (size > PLAB::min_size())) {\n+      if (!is_promotion || !has_plab || (size > plab_min_size())) {\n@@ -306,0 +306,11 @@\n+        if (is_promotion && copy != nullptr) {\n+          \/\/ Our plab has too much remaining to throw away, but it can't fit this object so we allow a shared allocation\n+          \/\/ in this case.\n+          PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n+          if (plab != nullptr) {\n+            log_debug(gc, plab)(\"Made a shared promotion of size: %zu, actual PLAB size for thread: %zu, remaining: %zu, min PLAB: %zu, max PLAB: %zu\",\n+                                size * HeapWordSize, ShenandoahThreadLocalData::get_plab_actual_size(thread) * HeapWordSize,\n+                                plab->words_remaining() * HeapWordSize, plab_min_size() * HeapWordSize, plab_max_size() * HeapWordSize);\n+\n+          }\n+        }\n@@ -308,3 +319,4 @@\n-      \/\/ We choose not to promote objects smaller than PLAB::min_size() by way of shared allocations, as this is too\n-      \/\/ costly.  Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB) and will promote in a future\n-      \/\/ evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size <= PLAB::min_size())\n+      \/\/ We choose not to promote objects smaller than PLAB::max_size() by way of shared allocations, as this is too\n+      \/\/ costly (such objects should use the PLAB). Instead, we'll simply \"evacuate\" to young-gen memory (using a GCLAB)\n+      \/\/ and will promote in a future evacuation pass.  This condition is denoted by: is_promotion && has_plab && (size\n+      \/\/ <= PLAB::max_size())\n@@ -367,1 +379,1 @@\n-      old_generation()->handle_evacuation(copy, size, from_region->is_young());\n+      old_generation()->handle_evacuation(copy, size);\n@@ -369,2 +381,0 @@\n-      \/\/ When copying to the old generation above, we don't care\n-      \/\/ about recording object age in the census stats.\n@@ -420,1 +430,0 @@\n-  HeapWord* obj;\n@@ -425,0 +434,1 @@\n+    log_debug(gc, plab)(\"Thread has no PLAB\");\n@@ -426,1 +436,4 @@\n-  } else if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+  }\n+\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    log_develop_trace(gc, plab)(\"Thread is not allowed to use PLAB for promotions\");\n@@ -429,2 +442,2 @@\n-  \/\/ if plab->word_size() <= 0, thread's plab not yet initialized for this pass, so allow_plab_promotions() is not trustworthy\n-  obj = plab->allocate(size);\n+\n+  HeapWord* obj = plab->allocate(size);\n@@ -432,0 +445,1 @@\n+    \/\/ What remains in this plab is smaller than the minimum plab, so allocate a new plab (retiring this pla).\n@@ -435,0 +449,1 @@\n+\n@@ -437,0 +452,2 @@\n+    log_debug(gc, plab)(\"PLAB remaining (%zu) is more than the minimum PLAB size (%zu), save this PLAB\",\n+                        plab->words_remaining() * HeapWordSize, plab_min_size() * HeapWordSize);\n@@ -483,1 +500,0 @@\n-  \/\/ Retire current PLAB, and allocate a new one.\n@@ -485,39 +501,1 @@\n-  if (plab->words_remaining() < plab_min_size) {\n-    \/\/ Retire current PLAB. This takes care of any PLAB book-keeping.\n-    \/\/ retire_plab() registers the remnant filler object with the remembered set scanner without a lock.\n-    \/\/ Since PLABs are card-aligned, concurrent registrations in other PLABs don't interfere.\n-    retire_plab(plab, thread);\n-\n-    size_t actual_size = 0;\n-    HeapWord* plab_buf = allocate_new_plab(min_size, cur_size, &actual_size);\n-    if (plab_buf == nullptr) {\n-      if (min_size == plab_min_size) {\n-        \/\/ Disable PLAB promotions for this thread because we cannot even allocate a minimal PLAB. This allows us\n-        \/\/ to fail faster on subsequent promotion attempts.\n-        ShenandoahThreadLocalData::disable_plab_promotions(thread);\n-      }\n-      return nullptr;\n-    } else {\n-      ShenandoahThreadLocalData::enable_plab_retries(thread);\n-    }\n-    \/\/ Since the allocated PLAB may have been down-sized for alignment, plab->allocate(size) below may still fail.\n-    if (ZeroTLAB) {\n-      \/\/ ... and clear it.\n-      Copy::zero_to_words(plab_buf, actual_size);\n-    } else {\n-      \/\/ ...and zap just allocated object.\n-#ifdef ASSERT\n-      \/\/ Skip mangling the space corresponding to the object header to\n-      \/\/ ensure that the returned space is not considered parsable by\n-      \/\/ any concurrent GC thread.\n-      size_t hdr_size = oopDesc::header_size();\n-      Copy::fill_to_words(plab_buf + hdr_size, actual_size - hdr_size, badHeapWordVal);\n-#endif \/\/ ASSERT\n-    }\n-    assert(is_aligned(actual_size, CardTable::card_size_in_words()), \"Align by design\");\n-    plab->set_buf(plab_buf, actual_size);\n-    if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n-      return nullptr;\n-    }\n-    return plab->allocate(size);\n-  } else {\n+  if (plab->words_remaining() >= plab_min_size) {\n@@ -528,0 +506,1 @@\n+    log_debug(gc, plab)(\"Existing PLAB is still viable (words remaining: %zu, plab_min_size: %zu)\", plab->words_remaining(), plab_min_size);\n@@ -530,0 +509,48 @@\n+\n+  \/\/ The current plab has fewer words remaining than the minimum PLAB. Retire it. This takes care of any PLAB book-keeping.\n+  \/\/ retire_plab() registers the remnant filler object with the remembered set scanner without a lock.\n+  \/\/ Since PLABs are card-aligned, concurrent registrations in other PLABs don't interfere.\n+  retire_plab(plab, thread);\n+\n+  size_t actual_size = 0;\n+  HeapWord* plab_buf = allocate_new_plab(min_size, cur_size, &actual_size);\n+  if (plab_buf == nullptr) {\n+    if (min_size == plab_min_size) {\n+      \/\/ Disable PLAB promotions for this thread because we cannot even allocate a minimal PLAB. This allows us\n+      \/\/ to fail faster on subsequent promotion attempts.\n+      log_debug(gc, plab)(\"Disable PLAB promotions because we can't allocate minimum sized PLAB: %zu\", min_size * HeapWordSize);\n+      ShenandoahThreadLocalData::disable_plab_promotions(thread);\n+    }\n+    return nullptr;\n+  }\n+\n+  log_debug(gc, plab)(\"Allocated new PLAB of size: %zu bytes, enable PLAB retries\", actual_size * HeapWordSize);\n+  ShenandoahThreadLocalData::enable_plab_retries(thread);\n+\n+\n+  if (ZeroTLAB) {\n+    \/\/ ... and clear it.\n+    Copy::zero_to_words(plab_buf, actual_size);\n+  } else {\n+    \/\/ ...and zap just allocated object.\n+#ifdef ASSERT\n+    \/\/ Skip mangling the space corresponding to the object header to\n+    \/\/ ensure that the returned space is not considered parsable by\n+    \/\/ any concurrent GC thread.\n+    const size_t hdr_size = oopDesc::header_size();\n+    Copy::fill_to_words(plab_buf + hdr_size, actual_size - hdr_size, badHeapWordVal);\n+#endif \/\/ ASSERT\n+  }\n+\n+  assert(is_aligned(actual_size, CardTable::card_size_in_words()), \"Align by design\");\n+  plab->set_buf(plab_buf, actual_size);\n+  if (is_promotion && !ShenandoahThreadLocalData::allow_plab_promotions(thread)) {\n+    \/\/ Thinking here is that the thread has exhausted promotion reserve, but there may yet be old objects\n+    \/\/ to evacuate and this plab could be used for those.\n+    log_debug(gc, plab)(\"Thread has new PLAB of size %zu, but is not allowed to promote %zu. Mixed evac in progress? %s\",\n+      actual_size * HeapWordSize, size * HeapWordSize, BOOL_TO_STR(collection_set()->has_old_regions()));\n+    return nullptr;\n+  }\n+\n+  \/\/ Since the allocated PLAB may have been down-sized for alignment, plab->allocate(size) below may still fail.\n+  return plab->allocate(size);\n@@ -558,1 +585,1 @@\n-  \/\/  1. Some of the plab may have been dedicated to evacuations.\n+  \/\/  1. Some of the plab may have been dedicated to old evacuations.\n@@ -560,0 +587,7 @@\n+#ifdef ASSERT\n+  \/\/ const size_t actual_size_words = ShenandoahThreadLocalData::get_plab_actual_size(thread);\n+  \/\/ const size_t plab_size_words = plab->word_sz();\n+  \/\/ assert(actual_size_words == plab_size_words || actual_size_words == 0, \"Actual plab size (%zu) and plab word sz (%zu) should be the same\",\n+  \/\/   actual_size_words, plab_size_words);\n+#endif\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":86,"deletions":52,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -1279,0 +1279,1 @@\n+  assert(!heap_region_containing(p)->is_humongous(), \"never evacuate humongous objects\");\n@@ -1280,5 +1281,1 @@\n-  ShenandoahHeapRegion* r = heap_region_containing(p);\n-  assert(!r->is_humongous(), \"never evacuate humongous objects\");\n-\n-  ShenandoahAffiliation target_gen = r->affiliation();\n-  return try_evacuate_object(p, thread, r, target_gen);\n+  return try_evacuate_object(p, thread);\n@@ -1287,4 +1284,1 @@\n-oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread, ShenandoahHeapRegion* from_region,\n-                                               ShenandoahAffiliation target_gen) {\n-  assert(target_gen == YOUNG_GENERATION, \"Only expect evacuations to young in this mode\");\n-  assert(from_region->is_young(), \"Only expect evacuations from young in this mode\");\n+oop ShenandoahHeap::try_evacuate_object(oop p, Thread* thread) {\n@@ -1306,1 +1300,1 @@\n-      ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, target_gen);\n+      ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared_gc(size, YOUNG_GENERATION);\n@@ -1323,1 +1317,1 @@\n-    evac_tracker()->begin_evacuation(thread, size * HeapWordSize, from_region->affiliation(), target_gen);\n+    evac_tracker()->begin_evacuation(thread, size * HeapWordSize, YOUNG_GENERATION, YOUNG_GENERATION);\n@@ -1337,1 +1331,1 @@\n-      evac_tracker()->end_evacuation(thread, size * HeapWordSize, from_region->affiliation(), target_gen);\n+      evac_tracker()->end_evacuation(thread, size * HeapWordSize, YOUNG_GENERATION, YOUNG_GENERATION);\n@@ -1592,6 +1586,0 @@\n-    if (ShenandoahEvacTracking) {\n-      evac_tracker()->print_global_on(&ls);\n-      ls.cr();\n-      ls.cr();\n-    }\n-\n@@ -1607,0 +1595,4 @@\n+\n+    if (ShenandoahEvacTracking) {\n+      evac_tracker()->print_global_on(&ls);\n+    }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":10,"deletions":18,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -775,1 +775,1 @@\n-  oop try_evacuate_object(oop src, Thread* thread, ShenandoahHeapRegion* from_region, ShenandoahAffiliation target_gen);\n+  oop try_evacuate_object(oop src, Thread* thread);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -719,1 +719,2 @@\n-    ls.print_cr(\"Promotion failed, size %zu, has plab? %s, PLAB remaining: %zu\"\n+    ResourceMark resources; \/\/ for thread name\n+    ls.print_cr(\"Promotion failed for %s, size %zu, has plab? %s, PLAB remaining: %zu\"\n@@ -722,1 +723,1 @@\n-                size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n+                thread->name(), size * HeapWordSize, plab == nullptr? \"no\": \"yes\",\n@@ -733,1 +734,1 @@\n-void ShenandoahOldGeneration::handle_evacuation(HeapWord* obj, size_t words, bool promotion) {\n+void ShenandoahOldGeneration::handle_evacuation(HeapWord* obj, size_t words) const {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -182,1 +182,1 @@\n-  void handle_evacuation(HeapWord* obj, size_t words, bool promotion);\n+  void handle_evacuation(HeapWord* obj, size_t words) const;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOldGeneration.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-    return total;\n+    return total * HeapWordSize;\n@@ -90,0 +90,7 @@\n+TEST_F(ShenandoahAgeCensusTest, get_tenurable_bytes) {\n+  ShenandoahAgeCensus census(1);\n+  update(census);\n+  EXPECT_EQ(get_total_population_older_than(1), census.get_tenurable_bytes(1));\n+  EXPECT_LT(census.get_tenurable_bytes(2), census.get_tenurable_bytes(1));\n+}\n+\n","filename":"test\/hotspot\/gtest\/gc\/shenandoah\/test_shenandoahAgeCensus.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"}]}