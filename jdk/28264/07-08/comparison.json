{"files":[{"patch":"@@ -2040,24 +2040,18 @@\n-  {\n-    SpinCriticalSection scs(&_wait_set_lock);\n-    ObjectWaiter* iterator = dequeue_waiter();\n-    if (iterator != nullptr) {\n-      guarantee(iterator->TState == ObjectWaiter::TS_WAIT, \"invariant\");\n-\n-      if (iterator->is_vthread()) {\n-        oop vthread = iterator->vthread();\n-        java_lang_VirtualThread::set_notified(vthread, true);\n-        int old_state = java_lang_VirtualThread::state(vthread);\n-        \/\/ If state is not WAIT\/TIMED_WAIT then target could still be on\n-        \/\/ unmount transition, or wait could have already timed-out or target\n-        \/\/ could have been interrupted. In the first case, the target itself\n-        \/\/ will set the state to BLOCKED at the end of the unmount transition.\n-        \/\/ In the other cases the target would have been already unblocked so\n-        \/\/ there is nothing to do.\n-        if (old_state == java_lang_VirtualThread::WAIT ||\n-          old_state == java_lang_VirtualThread::TIMED_WAIT) {\n-          java_lang_VirtualThread::cmpxchg_state(vthread, old_state, java_lang_VirtualThread::BLOCKED);\n-        }\n-        \/\/ Increment counter *before* adding the vthread to the _entry_list.\n-        \/\/ Adding to _entry_list uses Atomic::cmpxchg() which already provides\n-        \/\/ a fence that prevents reordering of the stores.\n-        inc_unmounted_vthreads();\n+  SpinCriticalSection scs(&_wait_set_lock);\n+  ObjectWaiter* iterator = dequeue_waiter();\n+  if (iterator != nullptr) {\n+    guarantee(iterator->TState == ObjectWaiter::TS_WAIT, \"invariant\");\n+\n+    if (iterator->is_vthread()) {\n+      oop vthread = iterator->vthread();\n+      java_lang_VirtualThread::set_notified(vthread, true);\n+      int old_state = java_lang_VirtualThread::state(vthread);\n+      \/\/ If state is not WAIT\/TIMED_WAIT then target could still be on\n+      \/\/ unmount transition, or wait could have already timed-out or target\n+      \/\/ could have been interrupted. In the first case, the target itself\n+      \/\/ will set the state to BLOCKED at the end of the unmount transition.\n+      \/\/ In the other cases the target would have been already unblocked so\n+      \/\/ there is nothing to do.\n+      if (old_state == java_lang_VirtualThread::WAIT ||\n+        old_state == java_lang_VirtualThread::TIMED_WAIT) {\n+        java_lang_VirtualThread::cmpxchg_state(vthread, old_state, java_lang_VirtualThread::BLOCKED);\n@@ -2065,0 +2059,5 @@\n+      \/\/ Increment counter *before* adding the vthread to the _entry_list.\n+      \/\/ Adding to _entry_list uses Atomic::cmpxchg() which already provides\n+      \/\/ a fence that prevents reordering of the stores.\n+      inc_unmounted_vthreads();\n+    }\n@@ -2066,32 +2065,31 @@\n-      iterator->_notifier_tid = JFR_THREAD_ID(current);\n-      did_notify = true;\n-      add_to_entry_list(current, iterator);\n-\n-      \/\/ _wait_set_lock protects the wait queue, not the entry_list.  We could\n-      \/\/ move the add-to-entry_list operation, above, outside the critical section\n-      \/\/ protected by _wait_set_lock.  In practice that's not useful.  With the\n-      \/\/ exception of  wait() timeouts and interrupts the monitor owner\n-      \/\/ is the only thread that grabs _wait_set_lock.  There's almost no contention\n-      \/\/ on _wait_set_lock so it's not profitable to reduce the length of the\n-      \/\/ critical section.\n-\n-      if (!iterator->is_vthread()) {\n-        iterator->wait_reenter_begin(this);\n-\n-        \/\/ Read counter *after* adding the thread to the _entry_list.\n-        \/\/ Adding to _entry_list uses Atomic::cmpxchg() which already provides\n-        \/\/ a fence that prevents this load from floating up previous store.\n-        if (has_unmounted_vthreads()) {\n-          \/\/ Wake up the thread to alleviate some deadlock cases where the successor\n-          \/\/ that will be picked up when this thread releases the monitor is an unmounted\n-          \/\/ virtual thread that cannot run due to having run out of carriers. Upon waking\n-          \/\/ up, the thread will call reenter_internal() which will use timed-park in case\n-          \/\/ there is contention and there are still vthreads in the _entry_list.\n-          \/\/ If the target was interrupted or the wait timed-out at the same time, it could\n-          \/\/ have reached reenter_internal and read a false value of has_unmounted_vthreads()\n-          \/\/ before we added it to the _entry_list above. To deal with that case, we set _do_timed_park\n-          \/\/ which will be read by the target on the next loop iteration in reenter_internal.\n-          iterator->_do_timed_park = true;\n-          JavaThread* t = iterator->thread();\n-          t->_ParkEvent->unpark();\n-        }\n+    iterator->_notifier_tid = JFR_THREAD_ID(current);\n+    did_notify = true;\n+    add_to_entry_list(current, iterator);\n+\n+    \/\/ _wait_set_lock protects the wait queue, not the entry_list.  We could\n+    \/\/ move the add-to-entry_list operation, above, outside the critical section\n+    \/\/ protected by _wait_set_lock.  In practice that's not useful.  With the\n+    \/\/ exception of  wait() timeouts and interrupts the monitor owner\n+    \/\/ is the only thread that grabs _wait_set_lock.  There's almost no contention\n+    \/\/ on _wait_set_lock so it's not profitable to reduce the length of the\n+    \/\/ critical section.\n+\n+    if (!iterator->is_vthread()) {\n+      iterator->wait_reenter_begin(this);\n+\n+      \/\/ Read counter *after* adding the thread to the _entry_list.\n+      \/\/ Adding to _entry_list uses Atomic::cmpxchg() which already provides\n+      \/\/ a fence that prevents this load from floating up previous store.\n+      if (has_unmounted_vthreads()) {\n+        \/\/ Wake up the thread to alleviate some deadlock cases where the successor\n+        \/\/ that will be picked up when this thread releases the monitor is an unmounted\n+        \/\/ virtual thread that cannot run due to having run out of carriers. Upon waking\n+        \/\/ up, the thread will call reenter_internal() which will use timed-park in case\n+        \/\/ there is contention and there are still vthreads in the _entry_list.\n+        \/\/ If the target was interrupted or the wait timed-out at the same time, it could\n+        \/\/ have reached reenter_internal and read a false value of has_unmounted_vthreads()\n+        \/\/ before we added it to the _entry_list above. To deal with that case, we set _do_timed_park\n+        \/\/ which will be read by the target on the next loop iteration in reenter_internal.\n+        iterator->_do_timed_park = true;\n+        JavaThread* t = iterator->thread();\n+        t->_ParkEvent->unpark();\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":54,"deletions":56,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -36,0 +36,2 @@\n+\/\/ The class uses low-level leaf-lock primitives to implement\n+\/\/ synchronization. Not for general synchronization use.\n@@ -42,2 +44,0 @@\n-  \/\/ Low-level leaf-lock primitives used to implement synchronization.\n-  \/\/ Not for general synchronization use.\n","filename":"src\/hotspot\/share\/utilities\/spinCriticalSection.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}