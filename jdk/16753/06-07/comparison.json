{"files":[{"patch":"@@ -4143,1 +4143,1 @@\n-void C2_MacroAssembler::arrays_equals(bool is_array_equ, Register ary1, Register ary2,\n+void C2_MacroAssembler::arrays_equals(bool is_array_equ, Register ary1, Register ary2, \/\/ Move to MacroAssembler_x86.cpp\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -542,1 +542,2 @@\n-  void string_indexof_loop_helper(int size, Label& bailout, Label& loop_top);\n+  void string_indexof_big_loop_helper(int size, Label& bailout, Label& loop_top);\n+  void string_indexof_small_loop_helper(int size, Label& bailout, Label& loop_top);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"opto\/c2_MacroAssembler.hpp\"\n@@ -117,1 +118,1 @@\n-void StubGenerator::string_indexof_loop_helper(int size, Label& bailout, Label& loop_top) {\n+void StubGenerator::string_indexof_big_loop_helper(int size, Label& bailout, Label& loop_top) {\n@@ -120,2 +121,2 @@\n-  __ movq(r13, -1);\n-  __ testq(r15, r15);\n+  __ movq(r11, -1);\n+  __ testq(rsi, rsi);\n@@ -123,4 +124,4 @@\n-  __ vpbroadcastb(xmm0, Address(r10, 0), Assembler::AVX_256bit);\n-  __ vpbroadcastb(xmm1, Address(r10, size - 1), Assembler::AVX_256bit);\n-  __ leaq(rax, Address(r11, r15, Address::times_1));\n-  __ leal(rcx, Address(r15, 33 - size));\n+  __ vpbroadcastb(xmm0, Address(r14, 0), Assembler::AVX_256bit);\n+  __ vpbroadcastb(xmm1, Address(r14, size - 1), Assembler::AVX_256bit);\n+  __ leaq(rax, Address(r14, rsi, Address::times_1));\n+  __ leal(rcx, Address(rsi, 33 - size));\n@@ -128,4 +129,4 @@\n-  __ cmpl(r15, 0x21);\n-  __ movl(r15, 0x20);\n-  __ cmovl(Assembler::aboveEqual, r15, rcx);\n-  __ movq(rcx, r11);\n+  __ cmpl(rsi, 0x21);\n+  __ movl(rdx, 0x20);\n+  __ cmovl(Assembler::aboveEqual, rdx, rcx);\n+  __ movq(rcx, rbx);\n@@ -134,2 +135,2 @@\n-  __ addq(rcx, r15);\n-  __ movl(r15, 0x20);\n+  __ addq(rcx, rdx);\n+  __ movl(rdx, 0x20);\n@@ -142,2 +143,2 @@\n-  __ vpmovmskb(rdx, xmm2, Assembler::AVX_256bit);\n-  __ testl(rdx, rdx);\n+  __ vpmovmskb(rsi, xmm2, Assembler::AVX_256bit);\n+  __ testl(rsi, rsi);\n@@ -147,0 +148,45 @@\n+\/******************************************************************************\/\n+\/\/                     Helper for loop construct\n+\/\/                     --------------------------\n+\/\/\n+\/\/ Code:\n+\/\/\n+\/\/ template <size_t k, typename MEMCMP>\n+\/\/ size_t FORCE_INLINE avx2_strstr_memcmp_small(const char *s, size_t n, const char *needle, MEMCMP memcmp_fun)\n+\/\/ {\n+\/\/ #pragma nounroll\n+\/\/   for (size_t i = 0; i < n - k + 1; i++) {\n+\/\/     if (s[i] == needle[0] && s[i + k - 1] == needle[k - 1]) {\n+\/\/ \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/  Helper code ends here, before comparing full needle\n+\/\/       if (!memcmp_fun(s + i + 1, needle + 1, k - 2)) {\n+\/\/         return i;\n+\/\/       }\n+\/\/     }\n+\/\/   }\n+\n+\/\/   return std::string::npos;\n+\/\/ }\n+\/******************************************************************************\/\n+\n+void StubGenerator::string_indexof_small_loop_helper(int size, Label& bailout, Label& loop_top) {\n+  Label temp;\n+\n+  __ addq(rsi, -(size - 1));\n+  __ je(bailout);\n+  __ movzbl(rcx, Address(r14, 0));\n+  __ xorq(rax, rax);\n+  __ jmpb(temp);\n+\n+  __ bind(loop_top);\n+  __ incq(rax);\n+  __ cmpq(rsi, rax);\n+  __ je(bailout);\n+\n+  __ bind(temp);\n+  __ cmpb(Address(rbx, rax, Address::times_1), rcx);\n+  __ jne(loop_top);\n+  __ movzbl(rdx, Address(rbx, rax, Address::times_1, size - 1));\n+  __ cmpb(rdx, Address(r14, size - 1));\n+  __ jne(loop_top);\n+}\n+\n@@ -149,2 +195,2 @@\n-  address large_hs_jmp_table[32];   \/\/ Jump table for large haystacks\n-  address small_hs_jmp_table[32];   \/\/ Jump table for small haystacks\n+  address large_hs_jmp_table[10];   \/\/ Jump table for large haystacks\n+  address small_hs_jmp_table[10];   \/\/ Jump table for small haystacks\n@@ -162,1 +208,1 @@\n-    Label memcmp_avx2;\n+    Label L_begin;\n@@ -164,8 +210,5 @@\n-    Label L_begin, L_0x406044, L_CASE_0, L_0x406019;\n-    Label L_trampoline, L_anysize, L_0x404912;\n-    Label L_exit, L_long_compare, L_top_loop_1, L_0x4049cc, L_error;\n-    Label L_small_string, L_0x405cee, L_0x405f5d, L_0x406008;\n-    Label L_0x405fff, L_final_check, L_mid_anysize_loop, L_top_anysize_loop;\n-    Label L_inner_anysize_loop, L_0x40602e, L_0x40607f, L_0x405018;\n-    Label L_0x40605e, L_0x406093, L_0x40559d, L_0x404933, L_byte_copy;\n-    Label L_set_s, L_small_string2, L_0x4060a3;\n+    Label L_0x403852, L_0x403bbd, L_0x403bca, L_0x403844;\n+    Label L_0x403b91, L_0x403bd2, L_0x4033c2, L_0x403838, L_0x403733, L_0x403841;\n+    Label L_0x40320e, L_0x403215, L_0x403265, L_0x40326f, L_0x403233, L_0x40315a;\n+    Label L_0x4032a0, L_0x40386a, L_0x40331c, L_0x403302, L_0x403b38, L_0x403360;\n+    Label L_0x4038bd, L_0x4038b5;\n@@ -176,0 +219,1 @@\n+    \/\/ Jump past jump table setups to get addresses of cases.\n@@ -181,37 +225,2 @@\n-    \/\/ Small-ish string\n-    \/\/ On entry:\n-    \/\/    r15, rsi <= n\n-    \/\/    rax <= scratch\n-    \/\/    rdi, r11 <= s\n-    \/\/    r10, rdx <= needle\n-    \/\/    r12, rcx <= k\n-    \/\/    rbx <= n - k\n-    \/\/ if (n <= STACK_SZ) {\n-    \/\/   \/\/ Copy haystack to stack and adjust parameters\n-    \/\/   int i = n;\n-    \/\/   char *hs = (char *) s;\n-    \/\/   char *dst = tmp_string;\n-    \/\/   int ndx = 0;\n-    __ bind(L_small_string);\n-    __ cmpq(r15, 0x20);\n-    __ ja(L_small_string2);\n-    __ leaq(r12, Address(rsp, 0x80));  \/\/ tmp_string\n-\n-    \/\/ if (i <= 16) {\n-    \/\/   hs = (char *) &s[i - 16];\n-    \/\/   ndx = 16 - i;\n-    \/\/   const __m128i *A = reinterpret_cast<const __m128i*>(hs);\n-    \/\/   __m128i *B = reinterpret_cast<__m128i*>(dst);\n-    \/\/   *B = *A;\n-    __ cmpl(r15, 0x10);\n-    __ ja(L_byte_copy);\n-    __ movdqu(xmm0, Address(r11, r15, Address::times_1, -0x10));\n-    __ movdqu(Address(r12, 0), xmm0);\n-    __ movl(rax, 0x10);\n-    __ subl(rax, r15);  \/\/ 16 - i\n-\n-    __ bind(L_set_s);\n-    \/\/ s = &tmp_string[ndx];\n-    __ leaq(rdi, Address(r12, rax, Address::times_1));\n-    __ movq(r12, rcx);\n-    __ jmp(L_0x404933);\n+    \/\/\n+    \/\/ Set up jump table entries for both small and large haystack switches.\n@@ -219,2 +228,60 @@\n-\/\/  Copy the haystack (16 < size < 32) to the stack\n-    __ bind(L_byte_copy);\n+\/\/ Small case 1:\n+    \/\/ Unroll for speed\n+    small_hs_jmp_table[0] = __ pc();\n+    {\n+      Label L_tmp1, L_tmp2, L_tmp3, L_tmp4, L_tmp5, L_0x403ba5;\n+      __ movzbl(rcx, Address(r14, 0));\n+      __ movl(rax, rbx);\n+      __ andl(rax, 0xf);\n+      __ movl(rdx, 0x10);\n+      __ subq(rdx, rax);\n+      __ cmpq(rdx, rsi);\n+      __ movq(rax, rsi);\n+      __ cmovl(Assembler::below, rax, rdx);\n+      __ testq(rax, rax);\n+      __ je_b(L_tmp1);\n+      __ xorl(rdi, rdi);\n+      __ bind(L_tmp2);\n+      __ cmpb(Address(rbx, rdi, Address::times_1), rcx);\n+      __ je(L_0x403ba5);\n+      __ incq(rdi);\n+      __ cmpq(rax, rdi);\n+      __ jne(L_tmp2);\n+      __ bind(L_tmp1);\n+      __ cmpq(rdx, rsi);\n+      __ jae(L_0x403852);\n+      __ movq(rdi, rsi);\n+      __ subq(rdi, rax);\n+      __ movq(rdx, rdi);\n+      __ andq(rdx, -16);\n+      __ je(L_tmp3);\n+      __ leaq(r9, Address(rdx, -1));\n+      __ movdl(xmm0, rcx);\n+      __ vpbroadcastb(xmm0, xmm0, Assembler::AVX_256bit);\n+      __ leaq(r10, Address(rbx, rax, Address::times_1));\n+      __ xorl(r8, r8);\n+      __ bind(L_tmp4);\n+      __ vpcmpeqb(xmm1, xmm0, Address(r10, r8, Address::times_1), Assembler::AVX_256bit);\n+      __ vpmovmskb(r11, xmm1, Assembler::AVX_256bit);\n+      __ testl(r11, r11);\n+      __ jne(L_0x403bbd);\n+      __ addq(r8, 0x10);\n+      __ cmpq(r8, r9);\n+      __ jbe(L_tmp4);\n+      __ bind(L_tmp3);\n+      __ cmpq(rdx, rdi);\n+      __ jae(L_0x403852);\n+      __ addq(rax, rdx);\n+      __ bind(L_tmp5);\n+      __ cmpb(Address(rbx, rax, Address::times_1), rcx);\n+      __ je(L_0x403bca);\n+      __ incq(rax);\n+      __ cmpq(rsi, rax);\n+      __ jne(L_tmp5);\n+      __ jmp(L_0x403852);\n+      __ bind(L_0x403ba5);\n+      __ movq(rbp, rdi);\n+      __ jmp(L_0x403852);\n+    }\n+\/\/ Small case 2:\n+    small_hs_jmp_table[1] = __ pc();\n@@ -222,47 +289,3 @@\n-      Label L_8, L_4, L_2, L_1, L_restore;\n-      __ cmpl(r15, 0x10);\n-      __ jb_b(L_8);\n-      __ movdqu(xmm0, Address(r11, 0));\n-      __ movdqu(Address(r12, 0), xmm0);\n-      __ subl(r15, 0x10);\n-      __ addptr(r11, 0x10);\n-      __ addptr(r12, 0x10);\n-\n-      __ bind(L_8);\n-      __ cmpl(r15, 0x8);\n-      __ jb_b(L_4);\n-      __ movq(rax, Address(r11, 0));\n-      __ movq(Address(r12, 0), rax);\n-      __ subl(r15, 0x8);\n-      __ addptr(r11, 0x8);\n-      __ addptr(r12, 0x8);\n-\n-      __ bind(L_4);\n-      __ cmpl(r15, 0x4);\n-      __ jb_b(L_2);\n-      __ movl(rax, Address(r11, 0));\n-      __ movl(Address(r12, 0), rax);\n-      __ subl(r15, 0x4);\n-      __ addptr(r11, 0x4);\n-      __ addptr(r12, 0x4);\n-\n-      __ bind(L_2);\n-      __ cmpl(r15, 0x2);\n-      __ jb_b(L_1);\n-      __ movzwl(rax, Address(r11, 0));\n-      __ movw(Address(r12, 0), rax);\n-      __ subl(r15, 0x2);\n-      __ addptr(r11, 0x2);\n-      __ addptr(r12, 0x2);\n-\n-      __ bind(L_1);\n-      __ cmpl(r15, 0x1);\n-      __ jb_b(L_restore);\n-      __ movzbl(rax, Address(r11, 0));\n-      __ movb(Address(r12, 0), rax);\n-\n-      __ bind(L_restore);\n-      __ xorq(rax, rax);\n-      __ movq(r15, rsi);\n-      __ movq(r11, rdi);\n-      __ jmp(L_set_s);\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(2, L_0x403844, L_loopTop);\n+      __ jmp(L_0x403bca);\n@@ -270,58 +293,1 @@\n-\n-    \/\/    Move through the small-ish string char by char\n-    \/\/ for (size_t i = 0; i < n - k + 1; i++) {\n-    \/\/   if (s[i] == needle[0] && s[i + k - 1] == needle[k - 1]) {\n-    \/\/     switch (k) {\n-    __ bind(L_small_string2);\n-    __ incrementq(r15);\n-    __ subq(r15, r12);\n-    __ je(L_error);\n-    __ movzbl(rbp, Address(r10, 0));\n-    __ leaq(rcx, Address(r10, 0x1));\n-    __ leaq(rdx, Address(r12, -0x2));\n-    __ cmpq(r15, 0x2);\n-    __ movl(r13, 1);\n-    __ cmovq(Assembler::aboveEqual, r13, r15);\n-    __ leaq(rbx, Address(r11, 0x1d));\n-    __ leaq(r14, Address(r12, r11, Address::times_1));\n-    __ decrementq(r14);\n-    __ incrementq(r11);\n-    __ xorl(r15, r15);\n-    __ jmpb(L_0x4049cc);\n-\n-    __ align(8);\n-    __ bind(L_top_loop_1);\n-    __ incrementq(r15);\n-    __ cmpq(r13, r15);\n-    __ je(L_error);\n-    __ bind(L_0x4049cc);\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x1d), rbp);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r14, r15, Address::times_1));\n-    __ cmpb(rax, Address(r10, r12, Address::times_1, -0x1));\n-    __ jne(L_top_loop_1);\n-\n-    __ leaq(rax, Address(r12, -0x1));\n-    __ cmpq(rax, 0x1e);\n-    __ ja_b(L_long_compare);\n-    __ jmp(L_trampoline);  \/\/ Jump to the correct case for small haystacks\n-\n-    \/\/  Needle size >= 32 - use memcmp\n-    __ bind(L_long_compare);\n-    __ leaq(rdi, Address(r11, r15, Address::times_1));\n-    __ movq(Address(rsp, 0x10), rcx);\n-    __ movq(rsi, Address(rsp, 0x10));\n-    __ movq(Address(rsp, 0x8), rdx);\n-    __ movq(rdx, Address(rsp, 0x8));\n-    __ movq(Address(rsp, 0x18), r11);\n-    __ movq(Address(rsp, 0x30), r10);\n-    __ call(memcmp_avx2, relocInfo::none);\n-    __ movq(rdx, Address(rsp, 0x8));\n-    __ movq(rcx, Address(rsp, 0x10));\n-    __ movq(r10, Address(rsp, 0x30));\n-    __ movq(r11, Address(rsp, 0x18));\n-    __ testl(rax, rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 2:\n+\/\/ Small case 3:\n@@ -329,6 +295,9 @@\n-    __ movzbl(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpb(rax, Address(rcx, 0));\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 3:\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(3, L_0x403844, L_loopTop);\n+      __ movzbl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpb(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 4:\n@@ -336,6 +305,9 @@\n-    __ movzwl(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpw(Address(rcx, 0), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 4: CASE 5:\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(4, L_0x403844, L_loopTop);\n+      __ movzwl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpw(Address(r14, 1), rdx);\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 5:\n@@ -343,0 +315,9 @@\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(5, L_0x403844, L_loopTop);\n+      __ movl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpl(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 6:\n@@ -344,6 +325,9 @@\n-    __ movl(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpl(rax, Address(rcx, 0));\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 6:\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(6, L_0x403844, L_loopTop);\n+      __ movl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpl(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 7:\n@@ -351,9 +335,12 @@\n-    __ movl(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpl(rax, Address(rcx, 0));\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(rbx, r15, Address::times_1, -0x18));\n-    __ cmpb(rax, Address(r10, 0x5));\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 7:\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(7, L_0x403844, L_loopTop);\n+      __ movl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpl(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ movzbl(rdx, Address(rbx, rax, Address::times_1, 5));\n+      __ cmpb(rdx, Address(r14, 5));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 8:\n@@ -361,9 +348,12 @@\n-    __ movl(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpl(rax, Address(rcx, 0));\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(rbx, r15, Address::times_1, -0x18));\n-    __ cmpw(Address(r10, 0x5), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 8 CASE 9:\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(8, L_0x403844, L_loopTop);\n+      __ movl(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpl(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ movzwl(rdx, Address(rbx, rax, Address::times_1, 5));\n+      __ cmpw(Address(r14, 5), rdx);\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 9:\n@@ -371,0 +361,9 @@\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(9, L_0x403844, L_loopTop);\n+      __ movq(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpq(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n+\/\/ Small case 10:\n@@ -372,345 +371,8 @@\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(rcx, 0));\n-    __ je(L_0x406019);\n-\n-    \/\/  CASE 10:\n-    small_hs_jmp_table[10] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x9));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 11:\n-    small_hs_jmp_table[11] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0x9));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 12:\n-    small_hs_jmp_table[12] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(rcx, 0));\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(rbx, r15, Address::times_1, -0x14));\n-    __ cmpw(Address(r10, 0x9), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(rbx, r15, Address::times_1, -0x12));\n-    __ cmpb(rax, Address(r10, 0xb));\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 13:\n-    small_hs_jmp_table[13] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x9));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 14:\n-    small_hs_jmp_table[14] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x9));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0xd));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x10), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 15:\n-    small_hs_jmp_table[15] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x9));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0xd));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x10), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 16:\n-    small_hs_jmp_table[16] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x9));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0xd));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x10), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0xf));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0xe), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 17:\n-    small_hs_jmp_table[17] = __ pc();\n-    __ movq(rax, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ cmpq(rax, Address(r10, 0x1));\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x9));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0x14), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 18:\n-    small_hs_jmp_table[18] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x11));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 19:\n-    small_hs_jmp_table[19] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0x11));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 20:\n-    small_hs_jmp_table[20] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0x11));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x13));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0xa), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 21:\n-    small_hs_jmp_table[21] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x11));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 22:\n-    small_hs_jmp_table[22] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x11));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x15));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x8), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 23:\n-    small_hs_jmp_table[23] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x11));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movw(rax, Address(r10, 0x15));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x8), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 24:\n-    small_hs_jmp_table[24] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x11));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movw(rax, Address(r10, 0x15));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x8), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x17));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x6), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 25:\n-    small_hs_jmp_table[25] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 26:\n-    small_hs_jmp_table[26] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x19));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x4), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 27:\n-    small_hs_jmp_table[27] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0x19));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x4), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 28:\n-    small_hs_jmp_table[28] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzwl(rax, Address(r10, 0x19));\n-    __ cmpw(Address(rbx, r15, Address::times_1, -0x4), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x1b));\n-    __ cmpb(Address(rbx, r15, Address::times_1, -0x2), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 29:\n-    small_hs_jmp_table[29] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x19));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x4), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/  CASE 30:\n-    small_hs_jmp_table[30] = __ pc();\n-    __ movdqu(xmm0, Address(rbx, r15, Address::times_1, -0x1c));\n-    __ vpsubb(xmm0, xmm0, Address(r10, 0x1), Assembler::AVX_128bit);\n-    __ vptest(xmm0, xmm0, Assembler::AVX_128bit);\n-    __ jne(L_top_loop_1);\n-    __ movq(rax, Address(r10, 0x11));\n-    __ cmpq(Address(rbx, r15, Address::times_1, -0xc), rax);\n-    __ jne(L_top_loop_1);\n-    __ movl(rax, Address(r10, 0x19));\n-    __ cmpl(Address(rbx, r15, Address::times_1, -0x4), rax);\n-    __ jne(L_top_loop_1);\n-    __ movzbl(rax, Address(r10, 0x1d));\n-    __ cmpb(Address(rbx, r15, Address::times_1), rax);\n-    __ jne(L_top_loop_1);\n-    __ jmp(L_0x406019);\n-\n-    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-    \/\/ anysize - needle >= 32 and haystack > 32\n-    __ bind(L_anysize);\n-    __ movq(r13, -1);\n-    __ testq(r15, r15);\n-    __ jle(L_exit);\n-    __ movq(Address(rsp, 0x20), rbx);\n-    __ leaq(rax, Address(r11, r15, Address::times_1));\n-    __ movq(Address(rsp, 0x28), rax);\n-    __ vpbroadcastb(xmm0, Address(r10, 0), Assembler::AVX_256bit);\n-    __ vmovdqu(Address(rsp, 0x30), xmm0);\n-    __ vpbroadcastb(xmm0, Address(r12, r10, Address::times_1, -0x1),\n-                    Assembler::AVX_256bit);\n-    __ vmovdqu(Address(rsp, 0x50), xmm0);\n-    __ subl(r15, r12);\n-    __ incrementl(r15);\n-    __ andl(r15, 0x1f);\n-    __ incrementq(r10);\n-    __ leaq(rax, Address(r12, -0x2));\n-    __ movq(Address(rsp, 0x10), rax);\n-    __ movq(Address(rsp, 0x18), r11);\n-    __ jmpb(L_mid_anysize_loop);\n-\n-    __ bind(L_top_anysize_loop);\n-    __ movq(r11, Address(rsp, 0x8));\n-    __ addq(r11, r15);\n-    __ movl(r15, 0x20);\n-    __ cmpq(r11, Address(rsp, 0x28));\n-    __ jae(L_0x4060a3);\n-\n-    __ bind(L_mid_anysize_loop);\n-    __ vmovdqu(xmm0, Address(rsp, 0x30));\n-    __ vpcmpeqb(xmm0, xmm0, Address(r11, 0), Assembler::AVX_256bit);\n-    __ vmovdqu(xmm1, Address(rsp, 0x50));\n-    __ movq(Address(rsp, 0x8), r11);\n-    __ vpcmpeqb(xmm1, xmm1, Address(r11, r12, Address::times_1, -0x1),\n-                Assembler::AVX_256bit);\n-    __ vpand(xmm0, xmm1, xmm0, Assembler::AVX_256bit);\n-    __ vpmovmskb(rbx, xmm0);\n-    __ testl(rbx, rbx);\n-    __ je(L_top_anysize_loop);\n-    __ movq(rax, Address(rsp, 0x8));\n-    __ leaq(r14, Address(rax, 1));\n-\n-    __ bind(L_inner_anysize_loop);\n-    __ tzcntl(rbp, rbx);\n-    __ leaq(rdi, Address(r14, rbp, Address::times_1));\n-    __ movq(r13, r10);\n-    __ movq(rsi, r10);\n-    __ movq(rdx, Address(rsp, 0x10));\n-    __ vzeroupper();\n-    __ call(memcmp_avx2, relocInfo::none);\n-    __ testl(rax, rax);\n-    __ je(L_0x40602e);\n-    __ blsrl(rbx, rbx);\n-    __ movq(r10, r13);\n-    __ jne_b(L_inner_anysize_loop);\n-    __ jmpb(L_top_anysize_loop);\n-\n-    large_hs_jmp_table[0] = __ pc();  \/\/ Case for needle size == 1\n-    __ vpbroadcastb(xmm0, Address(r10, 0), Assembler::AVX_256bit);\n-    __ vpcmpeqb(xmm1, xmm0, Address(r11, 0), Assembler::AVX_256bit);\n-    __ vpmovmskb(rax, xmm1);\n-    __ testl(rax, rax);\n-    __ je(L_0x406044);\n-    __ tzcntl(r13, rax);\n-    __ jmp(L_exit);\n+    {\n+      Label L_loopTop;\n+      string_indexof_small_loop_helper(10, L_0x403844, L_loopTop);\n+      __ movq(rdx, Address(rbx, rax, Address::times_1, 1));\n+      __ cmpq(rdx, Address(r14, 1));\n+      __ jne(L_loopTop);\n+      __ jmp(L_0x403bca);\n+    }\n@@ -718,3 +380,5 @@\n-    __ bind(L_CASE_0);  \/\/ Needle size == 0\n-    __ xorl(r15, r15);\n-    __ jmp(L_0x406019);\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\n+    \/\/ Large haystack (>32 bytes) switch\n@@ -722,1 +386,64 @@\n-    \/\/    case 2:   \/\/ case for needle size == 2\n+\/\/ Big case 1:\n+    large_hs_jmp_table[0] = __ pc();\n+    {\n+      Label L_0x403b51, L_0x403bad, L_0x403b6e;\n+      __ vpbroadcastb(xmm0, Address(r14, 0), Assembler::AVX_256bit);\n+      __ vpcmpeqb(xmm1, xmm0, Address(rbx, 0), Assembler::AVX_256bit);\n+      __ vpmovmskb(rax, xmm1, Assembler::AVX_256bit);\n+      __ testl(rax, rax);\n+      __ je_b(L_0x403b51);\n+      __ tzcntl(r11, rax);\n+      __ jmp(L_0x403844);\n+\/\/ Big case 1 body:\n+      __ bind(L_0x403b51);\n+      __ movq(rax, rsi);\n+      __ andq(rax, -32);\n+      __ andl(rsi, 0x1f);\n+      __ movq(r11, -1);\n+      __ cmpq(rsi, rax);\n+      __ jge(L_0x403844);\n+      __ addq(rax, rbx);\n+\n+      __ bind(L_0x403b6e);\n+      __ vpcmpeqb(xmm1, xmm0, Address(rbx, rsi, Address::times_1), Assembler::AVX_256bit);\n+      __ vpmovmskb(rcx, xmm1, Assembler::AVX_256bit);\n+      __ testl(rcx, rcx);\n+      __ je_b(L_0x403bad);\n+      __ leaq(rcx, Address(rbx, rsi, Address::times_1));\n+      __ addq(rcx, 0x20);\n+      __ addq(rsi, 0x20);\n+      __ cmpq(rcx, rax);\n+      __ jb(L_0x403b6e);\n+      __ jmp(L_0x403844);\n+\n+      __ bind(L_0x403bad);\n+      __ tzcntl(r11, rcx);\n+      __ addq(r11, rsi);\n+      __ jmp(L_0x403844);\n+    }\n+\n+  __ bind(L_0x403b91);\n+  __ tzcntl(rcx, rsi);\n+  __ subq(rax, rbx);\n+  __ addq(rax, rcx);\n+  __ movq(r11, rax);\n+  __ jmp(L_0x403844);\n+\n+  __ bind(L_0x403bbd);\n+   \/\/ Small case tail stuff\n+  __ tzcntl(rcx, r11);\n+  __ addq(rax, rcx);\n+  __ addq(rax, r8);\n+  __ bind(L_0x403bca);\n+  __ movq(rbp, rax);\n+  __ jmp(L_0x403852);\n+\n+   \/\/ Big case default stuff\n+  __ bind(L_0x403bd2);\n+  __ movq(r10, Address(rsp, 0x20));\n+  __ movq(r11, -1);\n+  __ jmp(L_0x403844);\n+\n+\n+\n+\/\/ Big case 2:\n@@ -724,36 +451,40 @@\n-    __ movq(r13, -1);\n-    __ testq(r15, r15);\n-    __ jle(L_exit);\n-    __ vpbroadcastb(xmm0, Address(r10, 0), Assembler::AVX_256bit);\n-    __ vpbroadcastb(xmm1, Address(r10, 0x1), Assembler::AVX_256bit);\n-    __ leaq(rcx, Address(r11, r15, Address::times_1));\n-    __ decl(r15);\n-    __ andl(r15, 0x1f);\n-    __ cmpl(r15, 0x21);\n-    __ movl(rdx, 0x20);\n-    __ cmovl(Assembler::aboveEqual, rdx, r15);\n-    __ movl(r15, rdx);\n-    __ movq(rax, r11);\n-    __ bind(L_0x405018);\n-    __ vpcmpeqb(xmm2, xmm0, Address(rax, 0), Assembler::AVX_256bit);\n-    __ vpcmpeqb(xmm3, xmm1, Address(rax, 0x1), Assembler::AVX_256bit);\n-    __ vpand(xmm2, xmm3, xmm2, Assembler::AVX_256bit);\n-    __ vpmovmskb(rdx, xmm2, Assembler::AVX_256bit);\n-    __ testl(rdx, rdx);\n-    __ jne(L_0x40607f);\n-    __ addq(rax, r15);\n-    __ cmpq(rax, rcx);\n-    __ jae(L_exit);\n-    __ vpcmpeqb(xmm2, xmm0, Address(rax, 0), Assembler::AVX_256bit);\n-    __ vpcmpeqb(xmm3, xmm1, Address(rax, 0x1), Assembler::AVX_256bit);\n-    __ vpand(xmm2, xmm3, xmm2, Assembler::AVX_256bit);\n-    __ vpmovmskb(rdx, xmm2, Assembler::AVX_256bit);\n-    __ testl(rdx, rdx);\n-    __ jne(L_0x40607f);\n-    __ addq(rax, 0x20);\n-    __ movl(r15, 0x20);\n-    __ cmpq(rax, rcx);\n-    __ jb(L_0x405018);\n-    __ jmp(L_exit);\n-\n-    \/\/    case 3:\n+    {\n+      __ movq(r11, -1);\n+      __ testq(rsi, rsi);\n+      __ jle(L_0x403844);\n+      __ vpbroadcastb(xmm0, Address(r14, 0), Assembler::AVX_256bit);\n+      __ vpbroadcastb(xmm1, Address(r14, 1), Assembler::AVX_256bit);\n+      __ leaq(rcx, Address(rbx, rsi, Address::times_1));\n+      __ leal(rax, Address(rsi, -1));\n+      __ andl(rax, 0x1f);\n+      __ cmpl(rsi, 0x21);\n+      __ movl(rdx, 0x20);\n+      __ cmovl(Assembler::aboveEqual, rdx, rax);\n+      __ movq(rax, rbx);\n+\n+      __ bind(L_0x4033c2);\n+      __ vpcmpeqb(xmm2, xmm0, Address(rax, 0), Assembler::AVX_256bit);\n+      __ vpcmpeqb(xmm3, xmm1, Address(rcx, 1), Assembler::AVX_256bit);\n+      __ vpand(xmm2, xmm3, xmm2, Assembler::AVX_256bit);\n+      __ vpmovmskb(rsi, xmm2, Assembler::AVX_256bit);\n+      __ testl(rsi, rsi);\n+      __ je_b(L_0x403b91);\n+      __ addq(rax, rdx);\n+      __ cmpq(rax, rcx);\n+      __ jae(L_0x403844);\n+      __ vpcmpeqb(xmm2, xmm0, Address(rax, 0), Assembler::AVX_256bit);\n+      __ vpcmpeqb(xmm3, xmm1, Address(rax, 1), Assembler::AVX_256bit);\n+      __ vpand(xmm2, xmm3, xmm2, Assembler::AVX_256bit);\n+      __ vpmovmskb(rsi, xmm2, Assembler::AVX_256bit);\n+      __ testl(rsi, rsi);\n+      __ jne_b(L_0x403b91);\n+      __ addq(rax, 0x20);\n+      __ movl(rdx, 0x20);\n+      __ cmpq(rax, rcx);\n+      __ jb(L_0x4033c2);\n+      __ jmp(L_0x403844);\n+    }\n+\n+\n+\n+\/\/ Big case 3:\n@@ -762,10 +493,12 @@\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(3, L_exit, L_top);\n-      __ movzbl(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpb(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n+      Label L_loopTop, L_innerLoop;\n+\n+      string_indexof_big_loop_helper(3, L_0x403844, L_loopTop);\n+      __ movzbl(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpb(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -774,1 +507,3 @@\n-    \/\/    case 4:\n+\n+\n+\/\/ Big case 4:\n@@ -777,10 +512,12 @@\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(4, L_exit, L_top);\n-      __ movzwl(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpw(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n+      Label L_loopTop, L_innerLoop;\n+\n+      string_indexof_big_loop_helper(4, L_0x403844, L_loopTop);\n+      __ movzwl(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpw(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -789,1 +526,3 @@\n-    \/\/    case 5:\n+\n+\n+\/\/ Big case 5:\n@@ -792,10 +531,12 @@\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(5, L_exit, L_top);\n-      __ movl(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpl(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n+      Label L_loopTop, L_innerLoop;\n+\n+      string_indexof_big_loop_helper(5, L_0x403844, L_loopTop);\n+      __ movl(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpl(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -804,1 +545,3 @@\n-    \/\/    case 6:\n+\n+\n+\/\/ Big case 6:\n@@ -807,10 +550,12 @@\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(6, L_exit, L_top);\n-      __ movl(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpl(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n+      Label L_loopTop, L_innerLoop;\n+\n+      string_indexof_big_loop_helper(6, L_0x403844, L_loopTop);\n+      __ movl(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpl(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -819,1 +564,3 @@\n-    \/\/    case 7:\n+\n+\n+\/\/ Big case 7:\n@@ -822,16 +569,1 @@\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(7, L_exit, L_top);\n-      __ movl(rsi, Address(r10, 0x1));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpl(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ movzbl(r8, Address(rcx, rdi, Address::times_1, 0x5));\n-      __ cmpb(r8, Address(r10, 0x5));\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x40559d);\n-    }\n+      Label L_loopTop, L_innerLoop, L_tmp;\n@@ -839,6 +571,2 @@\n-    \/\/    case 8:\n-    large_hs_jmp_table[7] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(8, L_exit, L_top);\n-      __ movl(rsi, Address(r10, 0x1));\n+      string_indexof_big_loop_helper(7, L_0x403844, L_loopTop);\n+      __ movl(rdi, Address(r14, 1));\n@@ -846,11 +574,11 @@\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpl(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ movzwl(r8, Address(rcx, rdi, Address::times_1, 0x5));\n-      __ cmpw(Address(r10, 0x5), r8);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x40559d);\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ blsrl(rsi, rsi);\n+      __ je(L_loopTop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpl(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ jne(L_innerLoop);\n+      __ movzbl(r9, Address(rcx, r8, Address::times_1, 5));\n+      __ cmpb(r9, Address(r14, 5));\n+      __ jne(L_innerLoop);\n+      __ jmp(L_0x403733);\n@@ -859,14 +587,0 @@\n-    \/\/    case 9:\n-    large_hs_jmp_table[8] = __ pc();\n-    {\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(9, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpq(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n-    }\n@@ -874,14 +588,0 @@\n-    \/\/    case 10:\n-    large_hs_jmp_table[9] = __ pc();\n-    {\n-      Label L_top, L_inner;\n-      string_indexof_loop_helper(10, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ bind(L_inner);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpq(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ je(L_0x405cee);\n-      __ blsrl(rdx, rdx);\n-      __ jne_b(L_inner);\n-      __ jmp(L_top);\n-    }\n@@ -889,2 +589,2 @@\n-    \/\/    case 11:\n-    large_hs_jmp_table[10] = __ pc();\n+\/\/ Big case 8:\n+    large_hs_jmp_table[7] = __ pc();\n@@ -892,16 +592,1 @@\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(11, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movzbl(rdi, Address(r10, 0x9));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r8, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n+      Label L_loopTop, L_innerLoop, L_tmp;\n@@ -909,7 +594,2 @@\n-    \/\/    case 12:\n-    large_hs_jmp_table[11] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(12, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movzwl(rdi, Address(r10, 0x9));\n+      string_indexof_big_loop_helper(8, L_0x403844, L_loopTop);\n+      __ movl(rdi, Address(r14, 1));\n@@ -917,10 +597,14 @@\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r8, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ blsrl(rsi, rsi);\n+      __ je(L_loopTop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpl(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ jne(L_innerLoop);\n+      __ movzwl(r9, Address(rcx, r8, Address::times_1, 5));\n+      __ cmpw(Address(r14, 5), r9);\n+      __ jne(L_innerLoop);\n+      __ bind(L_0x403733);\n+      __ subq(rcx, rbx);\n+      __ addq(rcx, r8);\n+      __ jmp(L_0x403841);\n@@ -929,26 +613,0 @@\n-    \/\/    case 13:\n-    large_hs_jmp_table[12] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(13, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ jmpb(L_tmp);\n-      __ align(8);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ cmpq(Address(rcx, rdi, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ movzwl(r8, Address(rcx, rdi, Address::times_1, 0x9));\n-      __ cmpw(Address(r10, 0x9), r8);\n-      __ jne_b(L_inner);\n-      __ movzbl(r8, Address(rcx, rdi, Address::times_1, 0xb));\n-      __ cmpb(r8, Address(r10, 0xb));\n-      __ jne_b(L_inner);\n-      __ bind(L_0x40559d);\n-      __ subq(rcx, r11);\n-      __ addq(rcx, rdi);\n-      __ jmp(L_0x406008);\n-    }\n@@ -956,19 +614,0 @@\n-    \/\/    case 14:\n-    large_hs_jmp_table[13] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(14, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movl(rdi, Address(r10, 0x9));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r8, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n@@ -976,2 +615,2 @@\n-    \/\/    case 15:\n-    large_hs_jmp_table[14] = __ pc();\n+\/\/ Big case 9:\n+    large_hs_jmp_table[8] = __ pc();\n@@ -979,19 +618,1 @@\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(15, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movl(rdi, Address(r10, 0x9));\n-      __ movzbl(r8, Address(r10, 0xd));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r9, rdx);\n-      __ cmpq(Address(rcx, r9, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r9, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r9, Address::times_1, 0xd), r8);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405fff);\n-    }\n+      Label L_loopTop, L_innerLoop;\n@@ -999,21 +620,10 @@\n-    \/\/    case 16:\n-    large_hs_jmp_table[15] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(16, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movl(rdi, Address(r10, 0x9));\n-      __ movzwl(r8, Address(r10, 0xd));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r9, rdx);\n-      __ cmpq(Address(rcx, r9, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r9, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r9, Address::times_1, 0xd), r8);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405fff);\n+      string_indexof_big_loop_helper(9, L_0x403844, L_loopTop);\n+      __ movq(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpq(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -1022,28 +632,0 @@\n-    \/\/    case 17:\n-    large_hs_jmp_table[16] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      __ movq(r14, r10);\n-      string_indexof_loop_helper(17, L_exit, L_top);\n-      __ movq(r9, r14);\n-      __ movq(rsi, Address(r14, 0x1));\n-      __ movl(rdi, Address(r14, 0x9));\n-      __ movzwl(r8, Address(r14, 0xd));\n-      __ movzbl(r9, Address(r14, 0xf));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r10, rdx);\n-      __ cmpq(Address(rcx, r10, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r10, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r10, Address::times_1, 0xd), r8);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r10, Address::times_1, 0xf), r9);\n-      __ jne_b(L_inner);\n-      __ movl(rax, r10);\n-      __ jmp(L_final_check);\n-    }\n@@ -1051,19 +633,0 @@\n-    \/\/    case 18:\n-    large_hs_jmp_table[17] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(18, L_exit, L_top);\n-      __ movq(rsi, Address(r10, 0x1));\n-      __ movq(rdi, Address(r10, 0x9));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x1), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x9), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n@@ -1071,2 +634,2 @@\n-    \/\/    case 19:\n-    large_hs_jmp_table[18] = __ pc();\n+\/\/ Big case 10:\n+    large_hs_jmp_table[9] = __ pc();\n@@ -1074,18 +637,1 @@\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(19, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movzbl(rsi, Address(r10, 0x11));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ movdqu(xmm3, Address(rcx, rdi, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, rdi, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405cee);\n-    }\n+      Label L_loopTop, L_innerLoop;\n@@ -1093,20 +639,10 @@\n-    \/\/    case 20:\n-    large_hs_jmp_table[19] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(20, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movzwl(rsi, Address(r10, 0x11));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ movdqu(xmm3, Address(rcx, rdi, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, rdi, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405cee);\n+      string_indexof_big_loop_helper(10, L_0x403844, L_loopTop);\n+      __ movq(rdi, Address(r14, 1));\n+      __ align(16);\n+      __ bind(L_innerLoop);\n+      __ tzcntl(r8, rsi);\n+      __ cmpq(Address(rcx, r8, Address::times_1, 1), rdi);\n+      __ je(L_0x403838);\n+      __ blsrl(rsi, rsi);\n+      __ jne(L_innerLoop);\n+      __ jmp(L_loopTop);\n@@ -1114,0 +650,1 @@\n+\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n@@ -1115,24 +652,0 @@\n-    \/\/    case 21:\n-    large_hs_jmp_table[20] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(21, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movzwl(rsi, Address(r10, 0x11));\n-      __ movzbl(rdi, Address(r10, 0x13));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r8, Address::times_1, 0x13), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n@@ -1140,21 +653,4 @@\n-    \/\/    case 22:\n-    large_hs_jmp_table[21] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(22, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movl(rsi, Address(r10, 0x11));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ movdqu(xmm3, Address(rcx, rdi, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, rdi, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405cee);\n-    }\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    __ align(8);\n@@ -1162,24 +658,1 @@\n-    \/\/    case 23:\n-    large_hs_jmp_table[22] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(23, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movl(rsi, Address(r10, 0x11));\n-      __ movzbl(rdi, Address(r10, 0x15));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r8, Address::times_1, 0x15), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n+    jump_table = __ pc();\n@@ -1187,23 +660,2 @@\n-    \/\/    case 24:\n-    large_hs_jmp_table[23] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(24, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movl(rsi, Address(r10, 0x11));\n-      __ movzwl(rdi, Address(r10, 0x15));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r8, Address::times_1, 0x15), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n+    for (jmp_ndx = 0; jmp_ndx < 10; jmp_ndx++) {\n+      __ emit_address(large_hs_jmp_table[jmp_ndx]);\n@@ -1212,27 +664,1 @@\n-    \/\/    case 25:\n-    large_hs_jmp_table[24] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(25, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movl(rsi, Address(r10, 0x11));\n-      __ movzwl(rdi, Address(r10, 0x15));\n-      __ movzbl(r8, Address(r10, 0x17));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r9, rdx);\n-      __ movdqu(xmm3, Address(rcx, r9, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r9, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r9, Address::times_1, 0x15), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r9, Address::times_1, 0x17), r8);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405fff);\n-    }\n+    jump_table_1 = __ pc();\n@@ -1240,22 +666,2 @@\n-    \/\/    case 26:\n-    large_hs_jmp_table[25] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(26, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(rdi, rdx);\n-      __ movdqu(xmm3, Address(rcx, rdi, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, rdi, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ bind(L_0x405cee);\n-      __ movl(rax, rdi);\n-      __ jmp(L_final_check);\n+    for (jmp_ndx = 0; jmp_ndx < 10; jmp_ndx++) {\n+      __ emit_address(small_hs_jmp_table[jmp_ndx]);\n@@ -1264,24 +670,61 @@\n-    \/\/    case 27:\n-    large_hs_jmp_table[26] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(27, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ movzbl(rdi, Address(r10, 0x19));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r8, Address::times_1, 0x19), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\n+    \/\/ Big case default:\n+\n+    __ bind(L_0x4032a0);\n+    __ movq(r11, -1);\n+    __ testq(rsi, rsi);\n+    __ jle(L_0x403844);\n+    __ movq(Address(rsp, 0x20), r10);\n+    __ leaq(rax, Address(rbx, rsi, Address::times_1));\n+    __ movq(Address(rsp, 0x10), rax);\n+    __ vpbroadcastb(xmm0, Address(r14, 0), Assembler::AVX_256bit);\n+    __ vmovdqu(Address(rsp, 0x50), xmm0);\n+    __ vpbroadcastb(xmm0, Address(r12, r14, Address::times_1, -1), Assembler::AVX_256bit);\n+    __ vmovdqu(Address(rsp, 0x30), xmm0);\n+    __ movl(rax, rsi);\n+    __ subl(rax, r12);\n+    __ incl(rax);\n+    __ andl(rax, 0x1f);\n+    __ cmpq(rsi, 0x21);\n+    __ movl(rcx, 0x20);\n+    __ cmovl(Assembler::aboveEqual, rcx, rax);\n+    __ incq(r14);\n+    __ movq(rax, rbx);\n+    __ movq(rbx, r14);\n+    __ leaq(r15, Address(r12, -0x2));\n+    __ movq(Address(rsp, 0x28), rax);\n+    __ jmpb(L_0x40331c);\n+    __ bind(L_0x403302);\n+    __ movq(rax, Address(rsp, 0x8));\n+    __ addq(rax, Address(rsp, 0x18));\n+    __ movl(rcx, 0x20);\n+    __ cmpq(rax, Address(rsp, 0x10));\n+    __ jae(L_0x403bd2);\n+\n+    __ bind(L_0x40331c);\n+    __ movq(Address(rsp, 0x18), rcx);\n+    __ vmovdqu(xmm0, Address(rsp, 0x50));\n+    __ vpcmpeqb(xmm0, xmm0, Address(rax, 0), Assembler::AVX_256bit);\n+    __ vmovdqu(xmm1, Address(rsp, 0x30));\n+    __ movq(Address(rsp, 0x8), rax);\n+    __ vpcmpeqb(xmm1, xmm1, Address(rax, r12, Address::times_1, -1), Assembler::AVX_256bit);\n+    __ vpand(xmm0, xmm1, xmm0, Assembler::AVX_256bit);\n+    __ vpmovmskb(r13, xmm0, Assembler::AVX_256bit);\n+    __ testl(r13, r13);\n+    __ je(L_0x403302);\n+    __ movq(rax, Address(rsp, 0x8));\n+    __ leaq(r14, Address(rax, 0x1));\n+    __ align(8);\n+    __ bind(L_0x403360);\n+    __ tzcntl(rbp, r13);\n+    __ leaq(rdi, Address(r14, rbp, Address::times_1));\n+    ((C2_MacroAssembler*) _masm)-> arrays_equals(true, rdi, rbx, r15, rax, rdx, xmm0, xmm1,\n+                     false \/* char *\/, knoreg);\n+    __ testl(rax, rax);\n+    __ je_b(L_0x403b38);\n+    __ blsrl(r13, r13);\n+    __ jne(L_0x403360);\n+    __ jmp(L_0x403302);\n@@ -1289,24 +732,7 @@\n-    \/\/    case 28:\n-    large_hs_jmp_table[27] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(28, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ movzwl(rdi, Address(r10, 0x19));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r8, Address::times_1, 0x19), rdi);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405f5d);\n-    }\n+    __ bind(L_0x403b38);\n+    __ movl(rax, rbp);\n+    __ movq(r11, Address(rsp, 0x8));\n+    __ subq(r11, Address(rsp, 0x28));\n+    __ addq(r11, rax);\n+    __ movq(r10, Address(rsp, 0x20));\n+    __ jmp(L_0x403844);\n@@ -1314,27 +740,48 @@\n-    \/\/    case 29:\n-    large_hs_jmp_table[28] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(29, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ movzwl(rdi, Address(r10, 0x19));\n-      __ movzbl(r8, Address(r10, 0x1b));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r9, rdx);\n-      __ movdqu(xmm3, Address(rcx, r9, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r9, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpw(Address(rcx, r9, Address::times_1, 0x19), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r9, Address::times_1, 0x1b), r8);\n-      __ jne_b(L_inner);\n-      __ jmp(L_0x405fff);\n-    }\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\n+    \/\/ Small case default:\n+\n+    __ bind(L_0x40386a);\n+    __ incq(rsi);\n+    __ subq(rsi, r12);\n+    __ je(L_0x403852);\n+    __ movzbl(rcx, Address(r14, 0));\n+    __ leaq(rax, Address(r14, 0x1));\n+    __ movq(Address(rsp, 0x8), rax);\n+    __ cmpq(rsi, 0x2);\n+    __ movl(rcx, 0x1);\n+    __ cmovl(Assembler::aboveEqual, rdx, rsi);\n+    __ leaq(rax, Address(r12, -0x2));\n+    __ movq(Address(rsp, 0x50), rax);\n+    __ leaq(rsi, Address(rbx, r12, Address::times_1));\n+    __ decq(rsi);\n+    __ leaq(rax, Address(rbx, 0x1));\n+    __ movq(Address(rsp, 0x10), rax);\n+    __ xorl(r15, r15);\n+    __ movq(Address(rsp, 0x18), rdx);\n+    __ movq(Address(rsp, 0x30), rsi);\n+    __ jmpb(L_0x4038bd);\n+    __ bind(L_0x4038b5);\n+    __ incq(r15);\n+    __ cmpq(rdx, r15);\n+    __ je(L_0x403852);\n+\n+    __ bind(L_0x4038bd);\n+    __ cmpb(Address(rbx, r15, Address::times_1), rcx);\n+    __ jne(L_0x4038b5);\n+    __ movzbl(rax, Address(rsi, r15, Address::times_1));\n+    __ cmpb(Address(r14, r13, Address::times_1), rax);\n+    __ jne(L_0x4038b5);\n+\n+    __ movq(rax, Address(rsp, 0x10));\n+    __ leaq(rdi, Address(rax, r15, Address::times_1));\n+    __ movq(rsi, Address(rsp, 0x8));\n+    __ movq(rdx, Address(rsp, 0x50));\n+    ((C2_MacroAssembler*) _masm)-> arrays_equals(true, rdi, rsi, rdx, rax, r12, xmm0, xmm1,\n+                     false \/* char *\/, knoreg);\n+    __ testl(rax, rax);\n+    __ jne(L_0x4038b5);\n+    __ movq(rbp, r15);\n+    __ jmp(L_0x403852);\n@@ -1342,26 +789,3 @@\n-    \/\/    case 30:\n-    large_hs_jmp_table[29] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(30, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ movl(rdi, Address(r10, 0x19));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r8, rdx);\n-      __ movdqu(xmm3, Address(rcx, r8, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r8, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r8, Address::times_1, 0x19), rdi);\n-      __ jne_b(L_inner);\n-      __ bind(L_0x405f5d);\n-      __ movl(rax, r8);\n-      __ jmp(L_final_check);\n-    }\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n@@ -1369,35 +793,3 @@\n-    \/\/    case 31:\n-    large_hs_jmp_table[30] = __ pc();\n-    {\n-      Label L_top, L_inner, L_tmp;\n-      string_indexof_loop_helper(31, L_exit, L_top);\n-      __ movdqu(xmm2, Address(r10, 0x1));\n-      __ movq(rsi, Address(r10, 0x11));\n-      __ movl(rdi, Address(r10, 0x19));\n-      __ movzbl(r8, Address(r10, 0x1d));\n-      __ jmpb(L_tmp);\n-      __ bind(L_inner);\n-      __ blsrl(rdx, rdx);\n-      __ je(L_top);\n-      __ bind(L_tmp);\n-      __ tzcntl(r9, rdx);\n-      __ movdqu(xmm3, Address(rcx, r9, Address::times_1, 0x1));\n-      __ vpsubb(xmm3, xmm3, xmm2, Assembler::AVX_128bit);\n-      __ vptest(xmm3, xmm3, Assembler::AVX_128bit);\n-      __ jne_b(L_inner);\n-      __ cmpq(Address(rcx, r9, Address::times_1, 0x11), rsi);\n-      __ jne_b(L_inner);\n-      __ cmpl(Address(rcx, r9, Address::times_1, 0x19), rdi);\n-      __ jne_b(L_inner);\n-      __ cmpb(Address(rcx, r9, Address::times_1, 0x1d), r8);\n-      __ jne_b(L_inner);\n-    }\n-    __ bind(L_0x405fff);\n-    __ movl(rax, r9);\n-\n-    \/\/   if (result <= n - k)\n-    \/\/   {\n-    \/\/     return result;\n-    \/\/   }\n-    __ bind(L_final_check);\n-    __ subq(rcx, r11);\n+    __ bind(L_0x403838);\n+    __ movl(rax, r8);\n+    __ subq(rcx, rbx);\n@@ -1406,2 +798,2 @@\n-    __ bind(L_0x406008);\n-    __ movq(r13, rcx);\n+    __ bind(L_0x403841);\n+    __ movq(r11, rcx);\n@@ -1409,5 +801,4 @@\n-    __ bind(L_exit);\n-    __ cmpq(r13, rbx);\n-    __ movq(r15, -1);\n-    __ cmovq(Assembler::belowEqual, r15, r13);\n-    __ bind(L_0x406019);\n+    __ bind(L_0x403844);\n+    __ cmpq(r11, r10);\n+    __ movq(rbp, -1);\n+    __ cmovq(Assembler::belowEqual, rbp, r11);\n@@ -1415,4 +806,2 @@\n-    \/\/ CASE 0: CASE 1:\n-    small_hs_jmp_table[0] = __ pc();\n-    small_hs_jmp_table[1] = __ pc();\n-    __ movq(rax, r15);\n+    __ bind(L_0x403852);\n+    __ movq(rax, rbp);\n@@ -1438,65 +827,0 @@\n-\/\/  Tail cleanup stuff\n-    __ bind(L_0x40602e);\n-    __ movl(rax, rbp);\n-    __ movq(r13, Address(rsp, 0x8));\n-    __ subq(r13, Address(rsp, 0x18));\n-    __ addq(r13, rax);\n-    __ movq(rbx, Address(rsp, 0x20));\n-    __ jmpb(L_exit);\n-\n-    __ bind(L_0x406044);\n-    __ movq(rax, r15);\n-    __ andq(rax, -32);\n-    __ andl(r15, 0x1f);\n-    __ movq(r13, -1);\n-    __ cmpq(r15, rax);\n-    __ jge(L_exit);\n-    __ addq(rax, r11);\n-\n-    __ bind(L_0x40605e);\n-    __ vpcmpeqb(xmm1, xmm0, Address(r11, r15, Address::times_1),\n-                Assembler::AVX_256bit);\n-    __ vpmovmskb(rcx, xmm1, Assembler::AVX_256bit);\n-    __ testl(rcx, rcx);\n-    __ jne_b(L_0x406093);\n-    __ leaq(rcx, Address(r11, r15, Address::times_1));\n-    __ addq(rcx, 0x20);\n-    __ addq(r15, 0x20);\n-    __ cmpq(rcx, rax);\n-    __ jb(L_0x40605e);\n-    __ jmp(L_exit);\n-\n-    __ bind(L_0x40607f);\n-    __ tzcntl(rcx, rdx);\n-    __ subq(rax, r11);\n-    __ addq(rax, rcx);\n-    __ movq(r13, rax);\n-    __ jmp(L_exit);\n-\n-    __ bind(L_0x406093);\n-    __ tzcntl(r13, rcx);\n-    __ addq(r13, r15);\n-    __ jmp(L_exit);\n-\n-    __ bind(L_0x4060a3);\n-    __ movq(rbx, Address(rsp, 0x20));\n-    __ movq(r13, -1);\n-    __ jmp(L_exit);\n-\n-    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-    __ align(8);\n-\n-    jump_table = __ pc();\n-\n-    for (jmp_ndx = 0; jmp_ndx < 32; jmp_ndx++) {\n-      __ emit_address(large_hs_jmp_table[jmp_ndx]);\n-    }\n-\n-    jump_table_1 = __ pc();\n-\n-    for (jmp_ndx = 0; jmp_ndx < 32; jmp_ndx++) {\n-      __ emit_address(small_hs_jmp_table[jmp_ndx]);\n-    }\n-\n@@ -1529,0 +853,1 @@\n+    __ movq(rbp, -1);\n@@ -1530,14 +855,1 @@\n-    \/\/   return result;\n-    \/\/ }\n-    __ movq(rbx, rsi);\n-    __ subq(rbx, rcx);\n-    __ jae_b(L_0x404912);\n-\n-    __ bind(L_error);\n-    __ movq(r15, -1);\n-    __ jmp(L_0x406019);\n-\n-    __ bind(L_0x404912);\n-\n-    \/\/ if (k == 0) {\n-    \/\/   return 0;\n+    \/\/   return -1;\n@@ -1545,0 +857,3 @@\n+    __ movq(r10, rsi);\n+    __ subq(r10, rcx);\n+    __ jb(L_0x403852);\n@@ -1547,4 +862,3 @@\n-    __ je(L_CASE_0);\n-    __ movq(r10, rdx);\n-    __ movq(r15, rsi);\n-    __ movq(r11, rdi);\n+    __ je_b(L_0x40320e);\n+    __ movq(r14, rdx);\n+    __ movq(rbx, rdi);\n@@ -1552,1 +866,16 @@\n-    __ jb(L_small_string);\n+    __ jae_b(L_0x403215);\n+\n+    __ cmpq(r10, 0xb);\n+    __ jae_b(L_0x403233);\n+    __ bind(L_0x40315a);\n+    __ leaq(r13, Address(r12, -1));\n+    __ cmpq(r13, 0x9);\n+    __ ja(L_0x40386a);\n+    __ mov64(r15, (int64_t)jump_table_1);\n+    __ jmp(Address(r15, r13, Address::times_8));\n+\n+    __ bind(L_0x40320e);\n+    __ xorl(rbp, rbp);\n+    __ jmp(L_0x403852);\n+\n+    __ bind(L_0x403215);\n@@ -1554,1019 +883,14 @@\n-    __ cmpq(rax, r15);\n-    __ jg(L_small_string);\n-\n-    \/\/ if ((n < 32) || ((long long)n < 32 + (long long)k - 1))\n-    __ bind(L_0x404933);\n-    __ leaq(rax, Address(r12, -0x1));\n-    __ cmpq(rax, 0x1e);\n-    __ ja(L_anysize);\n-    __ mov64(r13, (int64_t)jump_table);\n-    __ jmp(Address(r13, rax, Address::times_8));\n-\n-    __ bind(L_trampoline);\n-    __ mov64(rdi, (int64_t)jump_table_1);\n-    __ jmp(Address(rdi, rax, Address::times_8));\n-\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-  \/\/                         memcmp_avx2\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\n-    __ align(CodeEntryAlignment);\n-    __ bind(memcmp_avx2);\n-\n-    \/\/    1 \/* memcmp\/wmemcmp optimized with AVX2.\n-    \/\/    2    Copyright (C) 2017-2023 Free Software Foundation, Inc.\n-    \/\/    3    This file is part of the GNU C Library.\n-    \/\/    4\n-    \/\/    5    The GNU C Library is free software; you can redistribute it\n-    \/\/    and\/or 6    modify it under the terms of the GNU Lesser General Public\n-    \/\/    7    License as published by the Free Software Foundation; either\n-    \/\/    8    version 2.1 of the License, or (at your option) any later\n-    \/\/    version.\n-    \/\/    9\n-    \/\/   10    The GNU C Library is distributed in the hope that it will be\n-    \/\/   useful, 11    but WITHOUT ANY WARRANTY; without even the implied\n-    \/\/   warranty of 12    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n-    \/\/   See the GNU 13    Lesser General Public License for more details. 14 15\n-    \/\/   You should have received a copy of the GNU Lesser General Public 16\n-    \/\/   License along with the GNU C Library; if not, see 17\n-    \/\/   <https:\/\/www.gnu.org\/licenses\/>.  *\/ 18 23 \/* memcmp\/wmemcmp is\n-    \/\/   implemented as: 24    1. Use ymm vector compares when possible. The\n-    \/\/   only case where 25       vector compares is not possible for when size\n-    \/\/   < VEC_SIZE 26       and loading from either s1 or s2 would cause a page\n-    \/\/   cross. 27    2. For size from 2 to 7 bytes on page cross, load as big\n-    \/\/   endian 28       with movbe and bswap to avoid branches. 29    3. Use\n-    \/\/   xmm vector compare when size >= 4 bytes for memcmp or 30       size >=\n-    \/\/   8 bytes for wmemcmp. 31    4. Optimistically compare up to first 4 *\n-    \/\/   VEC_SIZE one at a 32       to check for early mismatches. Only do this\n-    \/\/   if its guaranteed the 33       work is not wasted. 34    5. If size is\n-    \/\/   8 * VEC_SIZE or less, unroll the loop. 35    6. Compare 4 * VEC_SIZE at\n-    \/\/   a time with the aligned first memory 36       area. 37    7. Use 2\n-    \/\/   vector compares when size is 2 * VEC_SIZE or less. 38    8. Use 4\n-    \/\/   vector compares when size is 4 * VEC_SIZE or less. 39    9. Use 8\n-    \/\/   vector compares when size is 8 * VEC_SIZE or less.  *\/\n-\n-    Label L_less_vec, L_return_vec_0, L_last_1x_vec, L_return_vec_1,\n-        L_last_2x_vec;\n-    Label L_return_vec_2, L_retun_vec_3, L_more_8x_vec, L_return_vec_0_1_2_3;\n-    Label L_return_vzeroupper, L_8x_return_vec_0_1_2_3, L_loop_4x_vec;\n-    Label L_return_vec_3, L_8x_last_1x_vec, L_8x_last_2x_vec, L_8x_return_vec_2;\n-    Label L_8x_return_vec_3, L_return_vec_1_end, L_return_vec_0_end,\n-        L_one_or_less;\n-    Label L_page_cross_less_vec, L_between_16_31, L_between_8_15, L_between_2_3,\n-        L_zero;\n-    Label L_ret_nonzero;\n-\n-    \/\/ 72              .section SECTION(.text),\"ax\",@progbits\n-    \/\/ 73      ENTRY (MEMCMP)\n-    \/\/ 74      # ifdef USE_AS_WMEMCMP\n-    \/\/ 75              shl     $2, %RDX_LP\n-    \/\/ 76      # elif defined __ILP32__\n-    \/\/ 77              \/* Clear the upper 32 bits.  *\/\n-    \/\/ 78              movl    %edx, %edx\n-\n-    \/\/ 79      # endif\n-\n-    \/\/ 80              cmp     $VEC_SIZE, %RDX_LP\n-    \/\/ 81              jb      L(less_vec)\n-    \/\/ 82\n-    __ cmpq(rdx, 0x20);\n-    __ jb(L_less_vec);\n-    __ vmovdqu(xmm1, Address(rsi, 0));\n-\n-    \/\/ 83              \/* From VEC to 2 * VEC.  No branch when size == VEC_SIZE.\n-    \/\/ *\/\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdi, 0), Assembler::AVX_256bit);\n-\n-    \/\/ 84              vmovdqu (%rsi), %ymm1\n-    __ vpmovmskb(rax, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 85              VPCMPEQ (%rdi), %ymm1, %ymm1\n-    \/\/ 86              vpmovmskb %ymm1, %eax\n-    \/\/ 87              \/* NB: eax must be destination register if going to\n-    \/\/ 88                 L(return_vec_[0,2]). For L(return_vec_3 destination\n-    \/\/ register 89                 must be ecx.  *\/\n-    __ incrementl(rax);\n-    __ jne(L_return_vec_0);\n-\n-    \/\/ 90              incl    %eax\n-    \/\/ 91              jnz     L(return_vec_0)\n-    __ cmpq(rdx, 0x40);\n-\n-    \/\/ 92\n-    __ jbe(L_last_1x_vec);\n-\n-    \/\/ 93              cmpq    $(VEC_SIZE * 2), %rdx\n-    \/\/ 94              jbe     L(last_1x_vec)\n-    \/\/ 95\n-    __ vmovdqu(xmm2, Address(rsi, 0x20));\n-\n-    \/\/ 96              \/* Check second VEC no matter what.  *\/\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0x20), Assembler::AVX_256bit);\n-\n-    \/\/ 97              vmovdqu VEC_SIZE(%rsi), %ymm2\n-    __ vpmovmskb(rax, xmm2, Assembler::AVX_256bit);\n-\n-    \/\/ 98              VPCMPEQ VEC_SIZE(%rdi), %ymm2, %ymm2\n-    \/\/ 99              vpmovmskb %ymm2, %eax\n-    \/\/ 100             \/* If all 4 VEC where equal eax will be all 1s so incl\n-    \/\/ will\n-    __ incrementl(rax);\n-\n-    \/\/ 101                overflow and set zero flag.  *\/\n-    __ jne(L_return_vec_1);\n-\n-    \/\/ 102             incl    %eax\n-    \/\/ 103             jnz     L(return_vec_1)\n-    \/\/ 104\n-    __ cmpq(rdx, 0x80);\n-\n-    \/\/ 105             \/* Less than 4 * VEC.  *\/\n-    __ jbe(L_last_2x_vec);\n-\n-    \/\/ 106             cmpq    $(VEC_SIZE * 4), %rdx\n-    \/\/ 107             jbe     L(last_2x_vec)\n-    \/\/ 108\n-    __ vmovdqu(xmm3, Address(rsi, 0x40));\n-\n-    \/\/ 109             \/* Check third and fourth VEC no matter what.  *\/\n-    __ vpcmpeqb(xmm3, xmm3, Address(rdi, 0x40), Assembler::AVX_256bit);\n-\n-    \/\/ 110             vmovdqu (VEC_SIZE * 2)(%rsi), %ymm3\n-    __ vpmovmskb(rax, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 111             VPCMPEQ (VEC_SIZE * 2)(%rdi), %ymm3, %ymm3\n-    __ incrementl(rax);\n-\n-    \/\/ 112             vpmovmskb %ymm3, %eax\n-    __ jne(L_return_vec_2);\n-\n-    \/\/ 113             incl    %eax\n-    __ vmovdqu(xmm4, Address(rsi, 0x60));\n-\n-    \/\/ 114             jnz     L(return_vec_2)\n-    __ vpcmpeqb(xmm4, xmm4, Address(rdi, 0x60), Assembler::AVX_256bit);\n-\n-    \/\/ 115             vmovdqu (VEC_SIZE * 3)(%rsi), %ymm4\n-    __ vpmovmskb(rcx, xmm4, Assembler::AVX_256bit);\n-\n-    \/\/ 116             VPCMPEQ (VEC_SIZE * 3)(%rdi), %ymm4, %ymm4\n-    __ incrementl(rcx);\n-\n-    \/\/ 117             vpmovmskb %ymm4, %ecx\n-    __ jne(L_return_vec_3);\n-\n-    \/\/ 118             incl    %ecx\n-    \/\/ 119             jnz     L(return_vec_3)\n-    \/\/ 120\n-    __ cmpq(rdx, 0x100);\n-\n-    \/\/ 121             \/* Go to 4x VEC loop.  *\/\n-    __ ja(L_more_8x_vec);\n-\n-    \/\/ 122             cmpq    $(VEC_SIZE * 8), %rdx\n-    \/\/ 123             ja      L(more_8x_vec)\n-    \/\/ 124\n-    \/\/ 125             \/* Handle remainder of size = 4 * VEC + 1 to 8 * VEC\n-    \/\/ without any 126                branches.  *\/ 127\n-    __ vmovdqu(xmm1, Address(rsi, rdx, Address::times_1, -0x80));\n-\n-    \/\/ 128             \/* Load first two VEC from s2 before adjusting addresses.\n-    \/\/ *\/\n-    __ vmovdqu(xmm2, Address(rsi, rdx, Address::times_1, -0x60));\n-\n-    \/\/ 129             vmovdqu -(VEC_SIZE * 4)(%rsi, %rdx), %ymm1\n-    __ leaq(rdi, Address(rdi, rdx, Address::times_1, -0x80));\n-\n-    \/\/ 130             vmovdqu -(VEC_SIZE * 3)(%rsi, %rdx), %ymm2\n-    __ leaq(rsi, Address(rsi, rdx, Address::times_1, -0x80));\n-\n-    \/\/ 131             leaq    -(4 * VEC_SIZE)(%rdi, %rdx), %rdi\n-    \/\/ 132             leaq    -(4 * VEC_SIZE)(%rsi, %rdx), %rsi\n-    \/\/ 133\n-    \/\/ 134             \/* Wait to load from s1 until addressed adjust due to\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdi, 0), Assembler::AVX_256bit);\n-\n-    \/\/ 135                unlamination of microfusion with complex address mode.\n-    \/\/ *\/\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0x20), Assembler::AVX_256bit);\n-\n-    \/\/ 136             VPCMPEQ (%rdi), %ymm1, %ymm1\n-    \/\/ 137             VPCMPEQ (VEC_SIZE)(%rdi), %ymm2, %ymm2\n-    __ vmovdqu(xmm3, Address(rsi, 0x40));\n-\n-    \/\/ 138\n-    __ vpcmpeqb(xmm3, xmm3, Address(rdi, 0x40), Assembler::AVX_256bit);\n-\n-    \/\/ 139             vmovdqu (VEC_SIZE * 2)(%rsi), %ymm3\n-    __ vmovdqu(xmm4, Address(rsi, 0x60));\n-\n-    \/\/ 140             VPCMPEQ (VEC_SIZE * 2)(%rdi), %ymm3, %ymm3\n-    __ vpcmpeqb(xmm4, xmm4, Address(rdi, 0x60), Assembler::AVX_256bit);\n-\n-    \/\/ 141             vmovdqu (VEC_SIZE * 3)(%rsi), %ymm4\n-    \/\/ 142             VPCMPEQ (VEC_SIZE * 3)(%rdi), %ymm4, %ymm4\n-    \/\/ 143\n-    __ vpand(xmm5, xmm2, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 144             \/* Reduce VEC0 - VEC4.  *\/\n-    __ vpand(xmm6, xmm4, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 145             vpand   %ymm1, %ymm2, %ymm5\n-    __ vpand(xmm7, xmm6, xmm5, Assembler::AVX_256bit);\n-\n-    \/\/ 146             vpand   %ymm3, %ymm4, %ymm6\n-    __ vpmovmskb(rcx, xmm7, Assembler::AVX_256bit);\n-\n-    \/\/ 147             vpand   %ymm5, %ymm6, %ymm7\n-    __ incrementl(rcx);\n-\n-    \/\/ 148             vpmovmskb %ymm7, %ecx\n-    __ jne_b(L_return_vec_0_1_2_3);\n-\n-    \/\/ 149             incl    %ecx\n-    \/\/ 150             jnz     L(return_vec_0_1_2_3)\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_return_vec_0);\n-\n-    \/\/ 151             \/* NB: eax must be zero to reach here.  *\/\n-    \/\/ 152             VZEROUPPER_RETURN\n-    \/\/ 153\n-    \/\/ 154             .p2align 4\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 155     L(return_vec_0):\n-    \/\/ 156             tzcntl  %eax, %eax\n-    \/\/ 157     # ifdef USE_AS_WMEMCMP\n-    \/\/ 158             movl    (%rdi, %rax), %ecx\n-    \/\/ 159             xorl    %edx, %edx\n-    \/\/ 160             cmpl    (%rsi, %rax), %ecx\n-    \/\/ 161             \/* NB: no partial register stall here because xorl zero\n-    \/\/ idiom 162                above.  *\/ 163             setg    %dl 164 leal\n-    \/\/ -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1));\n-\n-    \/\/ 165     # else\n-    __ movzbl(rax, Address(rdi, rax, Address::times_1));\n-\n-    \/\/ 166             movzbl  (%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 167             movzbl  (%rdi, %rax), %eax\n-    \/\/ 168             subl    %ecx, %eax\n-    \/\/ 169     # endif\n-    __ bind(L_return_vzeroupper);\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_return_vec_1);\n-\n-    \/\/ 170     L(return_vzeroupper):\n-    \/\/ 171             ZERO_UPPER_VEC_REGISTERS_RETURN\n-    \/\/ 172\n-    \/\/ 173             .p2align 4\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 174     L(return_vec_1):\n-    \/\/ 175             tzcntl  %eax, %eax\n-    \/\/ 176     # ifdef USE_AS_WMEMCMP\n-    \/\/ 177             movl    VEC_SIZE(%rdi, %rax), %ecx\n-    \/\/ 178             xorl    %edx, %edx\n-    \/\/ 179             cmpl    VEC_SIZE(%rsi, %rax), %ecx\n-    \/\/ 180             setg    %dl\n-    \/\/ 181             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1, 0x20));\n-\n-    \/\/ 182     # else\n-    __ movzbl(rax, Address(rdi, rax, Address::times_1, 0x20));\n-\n-    \/\/ 183             movzbl  VEC_SIZE(%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 184             movzbl  VEC_SIZE(%rdi, %rax), %eax\n-    \/\/ 185             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_return_vec_2);\n-\n-    \/\/ 186     # endif\n-    \/\/ 187             VZEROUPPER_RETURN\n-    \/\/ 188\n-    \/\/ 189             .p2align 4\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 190     L(return_vec_2):\n-    \/\/ 191             tzcntl  %eax, %eax\n-    \/\/ 192     # ifdef USE_AS_WMEMCMP\n-    \/\/ 193             movl    (VEC_SIZE * 2)(%rdi, %rax), %ecx\n-    \/\/ 194             xorl    %edx, %edx\n-    \/\/ 195             cmpl    (VEC_SIZE * 2)(%rsi, %rax), %ecx\n-    \/\/ 196             setg    %dl\n-    \/\/ 197             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1, 0x40));\n-\n-    \/\/ 198     # else\n-    __ movzbl(rax, Address(rdi, rax, Address::times_1, 0x40));\n-\n-    \/\/ 199             movzbl  (VEC_SIZE * 2)(%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 200             movzbl  (VEC_SIZE * 2)(%rdi, %rax), %eax\n-    \/\/ 201             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(32);\n-\n-    __ bind(L_8x_return_vec_0_1_2_3);\n-\n-    \/\/ 202     # endif\n-    \/\/ 203             VZEROUPPER_RETURN\n-    \/\/ 204\n-    \/\/ 205             \/* NB: p2align 5 here to ensure 4x loop is 32 byte\n-    \/\/ aligned.  *\/ 206             .p2align 5 207     L(8x_return_vec_0_1_2_3):\n-    __ addq(rsi, rdi);\n-\n-    \/\/ 208             \/* Returning from L(more_8x_vec) requires restoring rsi.\n-    \/\/ *\/ 209             addq    %rdi, %rsi\n-    __ bind(L_return_vec_0_1_2_3);\n-    __ vpmovmskb(rax, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 210     L(return_vec_0_1_2_3):\n-    __ incrementl(rax);\n-\n-    \/\/ 211             vpmovmskb %ymm1, %eax\n-    __ jne_b(L_return_vec_0);\n-\n-    \/\/ 212             incl    %eax\n-    \/\/ 213             jnz     L(return_vec_0)\n-    __ vpmovmskb(rax, xmm2, Assembler::AVX_256bit);\n-\n-    \/\/ 214\n-    __ incrementl(rax);\n-\n-    \/\/ 215             vpmovmskb %ymm2, %eax\n-    __ jne_b(L_return_vec_1);\n-\n-    \/\/ 216             incl    %eax\n-    \/\/ 217             jnz     L(return_vec_1)\n-    __ vpmovmskb(rax, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 218\n-    __ incrementl(rax);\n-\n-    \/\/ 219             vpmovmskb %ymm3, %eax\n-    __ jne_b(L_return_vec_2);\n-\n-    \/\/ 220             incl    %eax\n-    \/\/ 221             jnz     L(return_vec_2)\n-    __ bind(L_return_vec_3);\n-    __ tzcntl(rcx, rcx);\n-\n-    \/\/ 222     L(return_vec_3):\n-    \/\/ 223             tzcntl  %ecx, %ecx\n-    \/\/ 224     # ifdef USE_AS_WMEMCMP\n-    \/\/ 225             movl    (VEC_SIZE * 3)(%rdi, %rcx), %eax\n-    \/\/ 226             xorl    %edx, %edx\n-    \/\/ 227             cmpl    (VEC_SIZE * 3)(%rsi, %rcx), %eax\n-    \/\/ 228             setg    %dl\n-    \/\/ 229             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rax, Address(rdi, rcx, Address::times_1, 0x60));\n-\n-    \/\/ 230     # else\n-    __ movzbl(rcx, Address(rsi, rcx, Address::times_1, 0x60));\n-\n-    \/\/ 231             movzbl  (VEC_SIZE * 3)(%rdi, %rcx), %eax\n-    __ subl(rax, rcx);\n-\n-    \/\/ 232             movzbl  (VEC_SIZE * 3)(%rsi, %rcx), %ecx\n-    \/\/ 233             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_more_8x_vec);\n-\n-    \/\/ 234     # endif\n-    \/\/ 235             VZEROUPPER_RETURN\n-    \/\/ 236\n-    \/\/ 237             .p2align 4\n-    \/\/ 238     L(more_8x_vec):\n-    __ leaq(rdx, Address(rdi, rdx, Address::times_1, -0x80));\n-\n-    \/\/ 239             \/* Set end of s1 in rdx.  *\/\n-    \/\/ 240             leaq    -(VEC_SIZE * 4)(%rdi, %rdx), %rdx\n-    \/\/ 241             \/* rsi stores s2 - s1. This allows loop to only update\n-    \/\/ one\n-    __ subq(rsi, rdi);\n-\n-    \/\/ 242                pointer.  *\/\n-    \/\/ 243             subq    %rdi, %rsi\n-    __ andq(rdi, -32);\n-\n-    \/\/ 244             \/* Align s1 pointer.  *\/\n-    \/\/ 245             andq    $-VEC_SIZE, %rdi\n-    __ subq(rdi, -128);\n-    __ align(16);\n-    __ bind(L_loop_4x_vec);\n-\n-    \/\/ 246             \/* Adjust because first 4x vec where check already.  *\/\n-    \/\/ 247             subq    $-(VEC_SIZE * 4), %rdi\n-    \/\/ 248             .p2align 4\n-    \/\/ 249     L(loop_4x_vec):\n-    \/\/ 250             \/* rsi has s2 - s1 so get correct address by adding s1\n-    \/\/ (in rdi).\n-    __ vmovdqu(xmm1, Address(rsi, rdi, Address::times_1));\n-\n-    \/\/ 251              *\/\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdi, 0), Assembler::AVX_256bit);\n-\n-    \/\/ 252             vmovdqu (%rsi, %rdi), %ymm1\n-    \/\/ 253             VPCMPEQ (%rdi), %ymm1, %ymm1\n-    __ vmovdqu(xmm2, Address(rsi, rdi, Address::times_1, 0x20));\n-\n-    \/\/ 254\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0x20), Assembler::AVX_256bit);\n-\n-    \/\/ 255             vmovdqu VEC_SIZE(%rsi, %rdi), %ymm2\n-    \/\/ 256             VPCMPEQ VEC_SIZE(%rdi), %ymm2, %ymm2\n-    __ vmovdqu(xmm3, Address(rsi, rdi, Address::times_1, 0x40));\n-\n-    \/\/ 257\n-    __ vpcmpeqb(xmm3, xmm3, Address(rdi, 0x40), Assembler::AVX_256bit);\n-\n-    \/\/ 258             vmovdqu (VEC_SIZE * 2)(%rsi, %rdi), %ymm3\n-    \/\/ 259             VPCMPEQ (VEC_SIZE * 2)(%rdi), %ymm3, %ymm3\n-    __ vmovdqu(xmm4, Address(rsi, rdi, Address::times_1, 0x60));\n-\n-    \/\/ 260\n-    __ vpcmpeqb(xmm4, xmm4, Address(rdi, 0x60), Assembler::AVX_256bit);\n-\n-    \/\/ 261             vmovdqu (VEC_SIZE * 3)(%rsi, %rdi), %ymm4\n-    \/\/ 262             VPCMPEQ (VEC_SIZE * 3)(%rdi), %ymm4, %ymm4\n-    __ vpand(xmm5, xmm2, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 263\n-    __ vpand(xmm6, xmm4, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 264             vpand   %ymm1, %ymm2, %ymm5\n-    __ vpand(xmm7, xmm6, xmm5, Assembler::AVX_256bit);\n-\n-    \/\/ 265             vpand   %ymm3, %ymm4, %ymm6\n-    __ vpmovmskb(rcx, xmm7, Assembler::AVX_256bit);\n-\n-    \/\/ 266             vpand   %ymm5, %ymm6, %ymm7\n-    __ incrementl(rcx);\n-\n-    \/\/ 267             vpmovmskb %ymm7, %ecx\n-    __ jne_b(L_8x_return_vec_0_1_2_3);\n-\n-    \/\/ 268             incl    %ecx\n-    __ subq(rdi, -128);\n-\n-    \/\/ 269             jnz     L(8x_return_vec_0_1_2_3)\n-    \/\/ 270             subq    $-(VEC_SIZE * 4), %rdi\n-    __ cmpq(rdi, rdx);\n-\n-    \/\/ 271             \/* Check if s1 pointer at end.  *\/\n-    __ jb_b(L_loop_4x_vec);\n-\n-    \/\/ 272             cmpq    %rdx, %rdi\n-    \/\/ 273             jb      L(loop_4x_vec)\n-    __ subq(rdi, rdx);\n-\n-    \/\/ 274\n-    \/\/ 275             subq    %rdx, %rdi\n-    __ cmpl(rdi, 0x60);\n-\n-    \/\/ 276             \/* rdi has 4 * VEC_SIZE - remaining length.  *\/\n-    __ jae_b(L_8x_last_1x_vec);\n-\n-    \/\/ 277             cmpl    $(VEC_SIZE * 3), %edi\n-    \/\/ 278             jae     L(8x_last_1x_vec)\n-    __ vmovdqu(xmm3, Address(rsi, rdx, Address::times_1, 0x40));\n-\n-    \/\/ 279             \/* Load regardless of branch.  *\/\n-    __ cmpl(rdi, 0x40);\n-\n-    \/\/ 280             vmovdqu (VEC_SIZE * 2)(%rsi, %rdx), %ymm3\n-    __ jae_b(L_8x_last_2x_vec);\n-\n-    \/\/ 281             cmpl    $(VEC_SIZE * 2), %edi\n-    \/\/ 282             jae     L(8x_last_2x_vec)\n-    \/\/ 283\n-    __ vmovdqu(xmm1, Address(rsi, rdx, Address::times_1));\n-\n-    \/\/ 284             \/* Check last 4 VEC.  *\/\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdx, 0), Assembler::AVX_256bit);\n-\n-    \/\/ 285             vmovdqu (%rsi, %rdx), %ymm1\n-    \/\/ 286             VPCMPEQ (%rdx), %ymm1, %ymm1\n-    __ vmovdqu(xmm2, Address(rsi, rdx, Address::times_1, 0x20));\n-\n-    \/\/ 287\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdx, 0x20), Assembler::AVX_256bit);\n-\n-    \/\/ 288             vmovdqu VEC_SIZE(%rsi, %rdx), %ymm2\n-    \/\/ 289             VPCMPEQ VEC_SIZE(%rdx), %ymm2, %ymm2\n-    __ vpcmpeqb(xmm3, xmm3, Address(rdx, 0x40), Assembler::AVX_256bit);\n-\n-    \/\/ 290\n-    \/\/ 291             VPCMPEQ (VEC_SIZE * 2)(%rdx), %ymm3, %ymm3\n-    __ vmovdqu(xmm4, Address(rsi, rdx, Address::times_1, 0x60));\n-\n-    \/\/ 292\n-    __ vpcmpeqb(xmm4, xmm4, Address(rdx, 0x60), Assembler::AVX_256bit);\n-\n-    \/\/ 293             vmovdqu (VEC_SIZE * 3)(%rsi, %rdx), %ymm4\n-    \/\/ 294             VPCMPEQ (VEC_SIZE * 3)(%rdx), %ymm4, %ymm4\n-    __ vpand(xmm5, xmm2, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 295\n-    __ vpand(xmm6, xmm4, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 296             vpand   %ymm1, %ymm2, %ymm5\n-    __ vpand(xmm7, xmm6, xmm5, Assembler::AVX_256bit);\n-\n-    \/\/ 297             vpand   %ymm3, %ymm4, %ymm6\n-    __ vpmovmskb(rcx, xmm7, Assembler::AVX_256bit);\n-\n-    \/\/ 298             vpand   %ymm5, %ymm6, %ymm7\n-    \/\/ 299             vpmovmskb %ymm7, %ecx\n-    __ movq(rdi, rdx);\n-\n-    \/\/ 300             \/* Restore s1 pointer to rdi.  *\/\n-    __ incrementl(rcx);\n-\n-    \/\/ 301             movq    %rdx, %rdi\n-    __ jne(L_8x_return_vec_0_1_2_3);\n-\n-    \/\/ 302             incl    %ecx\n-    \/\/ 303             jnz     L(8x_return_vec_0_1_2_3)\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_8x_last_2x_vec);\n-\n-    \/\/ 304             \/* NB: eax must be zero to reach here.  *\/\n-    \/\/ 305             VZEROUPPER_RETURN\n-    \/\/ 306\n-    \/\/ 307             \/* Only entry is from L(more_8x_vec).  *\/\n-    \/\/ 308             .p2align 4\n-    \/\/ 309     L(8x_last_2x_vec):\n-    \/\/ 310             \/* Check second to last VEC. rdx store end pointer of s1\n-    \/\/ and 311                ymm3 has already been loaded with second to last\n-    \/\/ VEC from s2.\n-    __ vpcmpeqb(xmm3, xmm3, Address(rdx, 0x40), Assembler::AVX_256bit);\n-\n-    \/\/ 312              *\/\n-    __ vpmovmskb(rax, xmm3, Assembler::AVX_256bit);\n-\n-    \/\/ 313             VPCMPEQ (VEC_SIZE * 2)(%rdx), %ymm3, %ymm3\n-    __ incrementl(rax);\n-\n-    \/\/ 314             vpmovmskb %ymm3, %eax\n-    __ jne_b(L_8x_return_vec_2);\n-    __ align(16);\n-\n-    __ bind(L_8x_last_1x_vec);\n-\n-    \/\/ 315             incl    %eax\n-    \/\/ 316             jnz     L(8x_return_vec_2)\n-    \/\/ 317             \/* Check last VEC.  *\/\n-    \/\/ 318             .p2align 4\n-    __ vmovdqu(xmm4, Address(rsi, rdx, Address::times_1, 0x60));\n-\n-    \/\/ 319     L(8x_last_1x_vec):\n-    __ vpcmpeqb(xmm4, xmm4, Address(rdx, 0x60), Assembler::AVX_256bit);\n-\n-    \/\/ 320             vmovdqu (VEC_SIZE * 3)(%rsi, %rdx), %ymm4\n-    __ vpmovmskb(rax, xmm4, Assembler::AVX_256bit);\n-\n-    \/\/ 321             VPCMPEQ (VEC_SIZE * 3)(%rdx), %ymm4, %ymm4\n-    __ incrementl(rax);\n-\n-    \/\/ 322             vpmovmskb %ymm4, %eax\n-    __ jne_b(L_8x_return_vec_3);\n-\n-    \/\/ 323             incl    %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_last_2x_vec);\n-\n-    \/\/ 324             jnz     L(8x_return_vec_3)\n-    \/\/ 325             VZEROUPPER_RETURN\n-    \/\/ 326\n-    \/\/ 327             .p2align 4\n-    \/\/ 328     L(last_2x_vec):\n-    __ vmovdqu(xmm1, Address(rsi, rdx, Address::times_1, -0x40));\n-\n-    \/\/ 329             \/* Check second to last VEC.  *\/\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdi, rdx, Address::times_1, -0x40),\n-                Assembler::AVX_256bit);\n-\n-    \/\/ 330             vmovdqu -(VEC_SIZE * 2)(%rsi, %rdx), %ymm1\n-    __ vpmovmskb(rax, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 331             VPCMPEQ -(VEC_SIZE * 2)(%rdi, %rdx), %ymm1, %ymm1\n-    __ incrementl(rax);\n-\n-    \/\/ 332             vpmovmskb %ymm1, %eax\n-    __ jne_b(L_return_vec_1_end);\n-\n-    __ bind(L_last_1x_vec);\n-\n-    \/\/ 333             incl    %eax\n-    \/\/ 334             jnz     L(return_vec_1_end)\n-    \/\/ 335             \/* Check last VEC.  *\/\n-    __ vmovdqu(xmm1, Address(rsi, rdx, Address::times_1, -0x20));\n-\n-    \/\/ 336     L(last_1x_vec):\n-    __ vpcmpeqb(xmm1, xmm1, Address(rdi, rdx, Address::times_1, -0x20),\n-                Assembler::AVX_256bit);\n-\n-    \/\/ 337             vmovdqu -(VEC_SIZE * 1)(%rsi, %rdx), %ymm1\n-    __ vpmovmskb(rax, xmm1, Assembler::AVX_256bit);\n-\n-    \/\/ 338             VPCMPEQ -(VEC_SIZE * 1)(%rdi, %rdx), %ymm1, %ymm1\n-    __ incrementl(rax);\n-\n-    \/\/ 339             vpmovmskb %ymm1, %eax\n-    __ jne_b(L_return_vec_0_end);\n-\n-    \/\/ 340             incl    %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_8x_return_vec_2);\n-\n-    \/\/ 341             jnz     L(return_vec_0_end)\n-    \/\/ 342             VZEROUPPER_RETURN\n-    \/\/ 343\n-    \/\/ 344             .p2align 4\n-    __ subq(rdx, 0x20);\n-    __ bind(L_8x_return_vec_3);\n-\n-    \/\/ 345     L(8x_return_vec_2):\n-    \/\/ 346             subq    $VEC_SIZE, %rdx\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 347     L(8x_return_vec_3):\n-    __ addq(rax, rdx);\n-\n-    \/\/ 348             tzcntl  %eax, %eax\n-    \/\/ 349             addq    %rdx, %rax\n-    \/\/ 350     # ifdef USE_AS_WMEMCMP\n-    \/\/ 351             movl    (VEC_SIZE * 3)(%rax), %ecx\n-    \/\/ 352             xorl    %edx, %edx\n-    \/\/ 353             cmpl    (VEC_SIZE * 3)(%rsi, %rax), %ecx\n-    \/\/ 354             setg    %dl\n-    \/\/ 355             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1, 0x60));\n-\n-    \/\/ 356     # else\n-    __ movzbl(rax, Address(rax, 0x60));\n-\n-    \/\/ 357             movzbl  (VEC_SIZE * 3)(%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 358             movzbl  (VEC_SIZE * 3)(%rax), %eax\n-    \/\/ 359             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_return_vec_1_end);\n-\n-    \/\/ 360     # endif\n-    \/\/ 361             VZEROUPPER_RETURN\n-    \/\/ 362\n-    \/\/ 363             .p2align 4\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 364     L(return_vec_1_end):\n-    __ addl(rax, rdx);\n-\n-    \/\/ 365             tzcntl  %eax, %eax\n-    \/\/ 366             addl    %edx, %eax\n-    \/\/ 367     # ifdef USE_AS_WMEMCMP\n-    \/\/ 368             movl    -(VEC_SIZE * 2)(%rdi, %rax), %ecx\n-    \/\/ 369             xorl    %edx, %edx\n-    \/\/ 370             cmpl    -(VEC_SIZE * 2)(%rsi, %rax), %ecx\n-    \/\/ 371             setg    %dl\n-    \/\/ 372             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1, -0x40));\n-\n-    \/\/ 373     # else\n-    __ movzbl(rax, Address(rdi, rax, Address::times_1, -0x40));\n-\n-    \/\/ 374             movzbl  -(VEC_SIZE * 2)(%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 375             movzbl  -(VEC_SIZE * 2)(%rdi, %rax), %eax\n-    \/\/ 376             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_return_vec_0_end);\n-\n-    \/\/ 377     # endif\n-    \/\/ 378             VZEROUPPER_RETURN\n-    \/\/ 379\n-    \/\/ 380             .p2align 4\n-    __ tzcntl(rax, rax);\n-\n-    \/\/ 381     L(return_vec_0_end):\n-    __ addl(rax, rdx);\n-\n-    \/\/ 382             tzcntl  %eax, %eax\n-    \/\/ 383             addl    %edx, %eax\n-    \/\/ 384     # ifdef USE_AS_WMEMCMP\n-    \/\/ 385             movl    -VEC_SIZE(%rdi, %rax), %ecx\n-    \/\/ 386             xorl    %edx, %edx\n-    \/\/ 387             cmpl    -VEC_SIZE(%rsi, %rax), %ecx\n-    \/\/ 388             setg    %dl\n-    \/\/ 389             leal    -1(%rdx, %rdx), %eax\n-    __ movzbl(rcx, Address(rsi, rax, Address::times_1, -0x20));\n-\n-    \/\/ 390     # else\n-    __ movzbl(rax, Address(rdi, rax, Address::times_1, -0x20));\n-\n-    \/\/ 391             movzbl  -VEC_SIZE(%rsi, %rax), %ecx\n-    __ subl(rax, rcx);\n-\n-    \/\/ 392             movzbl  -VEC_SIZE(%rdi, %rax), %eax\n-    \/\/ 393             subl    %ecx, %eax\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_less_vec);\n-\n-    \/\/ 394     # endif\n-    \/\/ 395             VZEROUPPER_RETURN\n-    \/\/ 396\n-    \/\/ 397             .p2align 4\n-    \/\/ 398     L(less_vec):\n-    \/\/ 399             \/* Check if one or less CHAR. This is necessary for size\n-    \/\/ = 0 but\n-    __ cmpl(rdx, 0x1);\n-\n-    \/\/ 400                is also faster for size = CHAR_SIZE.  *\/\n-    __ jbe_b(L_one_or_less);\n-\n-    \/\/ 401             cmpl    $CHAR_SIZE, %edx\n-    \/\/ 402             jbe     L(one_or_less)\n-    \/\/ 403\n-    \/\/ 404             \/* Check if loading one VEC from either s1 or s2 could\n-    \/\/ cause a 405                page cross. This can have false positives but\n-    \/\/ is by far the\n-    __ movl(rax, rdi);\n-\n-    \/\/ 406                fastest method.  *\/\n-    __ orl(rax, rsi);\n-\n-    \/\/ 407             movl    %edi, %eax\n-    __ andl(rax, 0xfff);\n-\n-    \/\/ 408             orl     %esi, %eax\n-    __ cmpl(rax, 0xfe0);\n-\n-    \/\/ 409             andl    $(PAGE_SIZE - 1), %eax\n-    __ jg_b(L_page_cross_less_vec);\n-\n-    \/\/ 410             cmpl    $(PAGE_SIZE - VEC_SIZE), %eax\n-    \/\/ 411             jg      L(page_cross_less_vec)\n-    \/\/ 412\n-    __ vmovdqu(xmm2, Address(rsi, 0));\n-\n-    \/\/ 413             \/* No page cross possible.  *\/\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0), Assembler::AVX_256bit);\n-\n-    \/\/ 414             vmovdqu (%rsi), %ymm2\n-    __ vpmovmskb(rax, xmm2, Assembler::AVX_256bit);\n-\n-    \/\/ 415             VPCMPEQ (%rdi), %ymm2, %ymm2\n-    __ incrementl(rax);\n-\n-    \/\/ 416             vpmovmskb %ymm2, %eax\n-    \/\/ 417             incl    %eax\n-    \/\/ 418             \/* Result will be zero if s1 and s2 match. Otherwise\n-    \/\/ first set\n-    __ bzhil(rdx, rax, rdx);\n-\n-    \/\/ 419                bit will be first mismatch.  *\/\n-    __ jne(L_return_vec_0);\n-\n-    \/\/ 420             bzhil   %edx, %eax, %edx\n-    __ xorl(rax, rax);\n-\n-    \/\/ 421             jnz     L(return_vec_0)\n-    __ vzeroupper();\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_page_cross_less_vec);\n-\n-    \/\/ 422             xorl    %eax, %eax\n-    \/\/ 423             VZEROUPPER_RETURN\n-    \/\/ 424\n-    \/\/ 425             .p2align 4\n-    \/\/ 426     L(page_cross_less_vec):\n-    \/\/ 427             \/* if USE_AS_WMEMCMP it can only be 0, 4, 8, 12, 16, 20,\n-    \/\/ 24, 28\n-    __ cmpl(rdx, 0x10);\n-\n-    \/\/ 428                bytes.  *\/\n-    __ jae(L_between_16_31);\n-\n-    \/\/ 429             cmpl    $16, %edx\n-    \/\/ 430             jae     L(between_16_31)\n-    __ cmpl(rdx, 0x8);\n-\n-    \/\/ 431     # ifndef USE_AS_WMEMCMP\n-    __ jae_b(L_between_8_15);\n-\n-    \/\/ 432             cmpl    $8, %edx\n-    __ cmpl(rdx, 0x4);\n-\n-    \/\/ 433             jae     L(between_8_15)\n-    __ jae(L_between_2_3);\n-\n-    \/\/ 434             \/* Fall through for [4, 7].  *\/\n-    \/\/ 435             cmpl    $4, %edx\n-    \/\/ 436             jb      L(between_2_3)\n-    __ movzbl(rax, Address(rdi, 0));\n-\n-    \/\/ 437\n-    __ movzbl(rcx, Address(rsi, 0));\n-\n-    \/\/ 438             movbe   (%rdi), %eax\n-    \/\/ 439             movbe   (%rsi), %ecx\n-\n-    __ shlq(rax, 0x20);\n-    \/\/   shlq  $32, %rcx\n-    __ shlq(rcx, 0x20);\n-    \/\/   movbe  -4(%rdi, %rdx), %edi\n-    __ movzbl(rdi, Address(rdi, rdx, Address::times_1, -0x4));\n-    \/\/   movbe  -4(%rsi, %rdx), %esi\n-    __ movzbl(rsi, Address(rsi, rdx, Address::times_1, -0x4));\n-    \/\/   orq  %rdi, %rax\n-    __ orq(rax, rdi);\n-    \/\/   orq  %rsi, %rcx\n-    __ orq(rcx, rsi);\n-    \/\/   subq  %rcx, %rax\n-    __ subq(rax, rcx);\n-    \/\/   \/* Fast path for return zero.  *\/\n-    \/\/   jnz  L(ret_nonzero)\n-    __ jne_b(L_ret_nonzero);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_one_or_less);\n-\n-    \/\/   .p2align 4\n-    \/\/ L(one_or_less):\n-    \/\/   jb  L(zero)\n-    __ jb_b(L_zero);\n-    \/\/   movzbl  (%rsi), %ecx\n-    __ movzbl(rcx, Address(rsi, 0));\n-    \/\/   movzbl  (%rdi), %eax\n-    __ movzbl(rax, Address(rdi, 0));\n-    \/\/   subl  %ecx, %eax\n-    __ subl(rax, rcx);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    __ ret(0);\n-    __ p2align(16, 5);\n-\n-    __ bind(L_ret_nonzero);\n-\n-    \/\/   .p2align 4,, 5\n-    \/\/ L(ret_nonzero):\n-    \/\/   sbbl  %eax, %eax\n-    __ sbbl(rax, rax);\n-    \/\/   orl  $1, %eax\n-    __ orl(rax, 0x1);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    __ ret(0);\n-    __ p2align(16, 2);\n-\n-    __ bind(L_zero);\n-\n-    \/\/   .p2align 4,, 2\n-    \/\/ L(zero):\n-    \/\/   xorl  %eax, %eax\n-    __ xorl(rax, rax);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_between_8_15);\n-\n-    \/\/   .p2align 4\n-    \/\/ L(between_8_15):\n-    \/\/   movbe  (%rdi), %rax\n-    __ movzbl(rax, Address(rdi, 0));\n-    \/\/   movbe  (%rsi), %rcx\n-    __ movzbl(rcx, Address(rsi, 0));\n-    \/\/   subq  %rcx, %rax\n-    __ subq(rax, rcx);\n-    \/\/   jnz  L(ret_nonzero)\n-    __ jne_b(L_ret_nonzero);\n-    \/\/   movbe  -8(%rdi, %rdx), %rax\n-    __ movzbl(rax, Address(rdi, rdx, Address::times_1, -0x8));\n-    \/\/   movbe  -8(%rsi, %rdx), %rcx\n-    __ movzbl(rcx, Address(rsi, rdx, Address::times_1, -0x8));\n-    \/\/   subq  %rcx, %rax\n-    __ subq(rax, rcx);\n-    \/\/   \/* Fast path for return zero.  *\/\n-    \/\/   jnz  L(ret_nonzero)\n-    __ jne_b(L_ret_nonzero);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    \/\/ # endif\n-    __ ret(0);\n-    __ p2align(16, 10);\n-\n-    __ bind(L_between_16_31);\n-\n-    \/\/   .p2align 4,, 10\n-    \/\/ L(between_16_31):\n-    \/\/   \/* From 16 to 31 bytes.  No branch when size == 16.  *\/\n-    \/\/   vmovdqu  (%rsi), %xmm2\n-    __ movdqu(xmm2, Address(rsi, 0));\n-    \/\/   VPCMPEQ  (%rdi), %xmm2, %xmm2\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0), Assembler::AVX_128bit);\n-    \/\/   vpmovmskb %xmm2, %eax\n-    __ vpmovmskb(rax, xmm2, Assembler::AVX_128bit);\n-    \/\/   subl  $0xffff, %eax\n-    __ subl(rax, 0xffff);\n-    \/\/   jnz  L(return_vec_0)\n-    __ jne(L_return_vec_0);\n-\n-    \/\/   \/* Use overlapping loads to avoid branches.  *\/\n-\n-    \/\/   vmovdqu  -16(%rsi, %rdx), %xmm2\n-    __ movdqu(xmm2, Address(rsi, rdx, Address::times_1, -0x10));\n-    \/\/   leaq  -16(%rdi, %rdx), %rdi\n-    __ leaq(rdi, Address(rdi, rdx, Address::times_1, -0x10));\n-    \/\/   leaq  -16(%rsi, %rdx), %rsi\n-    __ leaq(rsi, Address(rsi, rdx, Address::times_1, -0x10));\n-    \/\/   VPCMPEQ  (%rdi), %xmm2, %xmm2\n-    __ vpcmpeqb(xmm2, xmm2, Address(rdi, 0), Assembler::AVX_128bit);\n-    \/\/   vpmovmskb %xmm2, %eax\n-    __ vpmovmskb(rax, xmm2, Assembler::AVX_128bit);\n-    \/\/   subl  $0xffff, %eax\n-    __ subl(rax, 0xffff);\n-    \/\/   \/* Fast path for return zero.  *\/\n-    \/\/   jnz  L(return_vec_0)\n-    __ jne(L_return_vec_0);\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    \/\/ # else\n-    __ ret(0);\n-    __ align(16);\n-\n-    __ bind(L_between_2_3);\n-\n-    \/\/   .p2align 4\n-    \/\/ L(between_2_3):\n-    \/\/   \/* Load as big endian to avoid branches.  *\/\n-    \/\/   movzwl  (%rdi), %eax\n-    __ movzwl(rax, Address(rdi, 0));\n-    \/\/   movzwl  (%rsi), %ecx\n-    __ movzwl(rcx, Address(rsi, 0));\n-    \/\/   bswap  %eax\n-    __ bswapl(rax);\n-    \/\/   bswap  %ecx\n-    __ bswapl(rcx);\n-    \/\/   shrl  %eax\n-    __ shrl(rax, 1);\n-    \/\/   shrl  %ecx\n-    __ shrl(rcx, 1);\n-    \/\/   movzbl  -1(%rdi, %rdx), %edi\n-    __ movzbl(rdi, Address(rdi, rdx, Address::times_1, -0x1));\n-    \/\/   movzbl  -1(%rsi, %rdx), %esi\n-    __ movzbl(rsi, Address(rsi, rdx, Address::times_1, -0x1));\n-    \/\/   orl  %edi, %eax\n-    __ orl(rax, rdi);\n-    \/\/   orl  %esi, %ecx\n-    __ orl(rcx, rsi);\n-    \/\/   \/* Subtraction is okay because the upper bit is zero.  *\/\n-    \/\/   subl  %ecx, %eax\n+    __ cmpq(rax, rsi);\n+    __ jle(L_0x40326f);\n+    __ cmpq(rsi, 0x20);\n+    __ ja(L_0x40315a);\n+    \/\/ __ cmpq(r10, 0xa);\n+    \/\/ __ jbe(L_0x40315a);\n+\n+    __ bind(L_0x403233);\n+    __ leal(rdx, Address(rsi, -1));\n+    __ andl(rdx, 0x10);\n+    __ movl(rax, rsi);\n+    __ subl(rax, rdx);\n+    __ movslq(rcx, rax);\n+    __ movl(rax, 0x10);\n@@ -2574,3 +898,17 @@\n-    \/\/   \/* No ymm register was touched.  *\/\n-    \/\/   ret\n-    __ ret(0);\n+    __ vmovdqu(xmm0, Address(rcx, rbx, Address::times_1, -0x10));\n+    __ vmovdqu(Address(rsp, 0x70), xmm0);\n+    __ testl(rdx, rdx);\n+    __ je_b(L_0x403265);\n+\n+    __ vmovdqu(xmm0, Address(rbx, rcx, Address::times_1));\n+    __ vmovdqu(Address(rsp, 0x80), xmm0);\n+    __ bind(L_0x403265);\n+    __ emit_int16(0x48, 0x98);\n+    __ leaq(rbx, Address(rsp, rax, Address::times_1));\n+    __ addq(rbx, 0x70);\n+    __ bind(L_0x40326f);\n+    __ leaq(rax, Address(r12, -1));\n+    __ cmpq(rax, 0x9);\n+    __ ja(L_0x4032a0);\n+    __ mov64(r15, (int64_t)jump_table);\n+    __ jmp(Address(r15, rax, Address::times_8));\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_string.cpp","additions":637,"deletions":2299,"binary":false,"changes":2936,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-    if(make_new) {\n+    if (make_new) {\n@@ -262,1 +262,1 @@\n-    if(make_new)\n+    if (make_new)\n@@ -295,1 +295,1 @@\n-      if(make_new) testIndex = getRandomIndex(-100, 100);\n+      if (make_new) testIndex = getRandomIndex(-100, 100);\n","filename":"test\/jdk\/java\/lang\/StringBuffer\/IndexOf.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"}]}