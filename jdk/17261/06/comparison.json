{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -819,2 +819,2 @@\n-  void emit_data(jint data, relocInfo::relocType    rtype, int format);\n-  void emit_data(jint data, RelocationHolder const& rspec, int format);\n+  void emit_data(jint data, relocInfo::relocType    rtype, int format = 0);\n+  void emit_data(jint data, RelocationHolder const& rspec, int format = 0);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -5283,0 +5283,53 @@\n+#ifdef _LP64\n+void C2_MacroAssembler::vector_compress_expand_avx2(int opcode, XMMRegister dst, XMMRegister src, XMMRegister mask,\n+                                                    Register rtmp, Register rscratch, XMMRegister permv,\n+                                                    XMMRegister xtmp, XMMRegister xtmp1, BasicType bt, int vec_enc) {\n+  assert(type2aelembytes(bt) >= 4, \"\");\n+  assert(opcode == Op_CompressV || opcode == Op_ExpandV, \"\");\n+  if (bt == T_INT || bt == T_FLOAT) {\n+    vmovmskps(rtmp, mask, vec_enc);\n+    shlq(rtmp, 5);  \/\/ for 32 byte permute row of 8 x 32 bits.\n+    if (opcode == Op_CompressV) {\n+      lea(rscratch, ExternalAddress(StubRoutines::x86::compress_perm_table32()));\n+    } else {\n+      lea(rscratch, ExternalAddress(StubRoutines::x86::expand_perm_table32()));\n+    }\n+    addptr(rtmp, rscratch);\n+    vmovdqu(permv, Address(rtmp));\n+    vpermps(dst, permv, src, Assembler::AVX_256bit);\n+    vpxor(xtmp, xtmp, xtmp, vec_enc);\n+    \/\/ Blend the result with zero vector using permute mask, each row of\n+    \/\/ permute table contains either a valid permute index or a -1 (default)\n+    \/\/ value, this can potentially be used as a blending mask after\n+    \/\/ compressing\/expanding the source vector lanes.\n+    vblendvps(dst, dst, xtmp, permv, vec_enc, false, xtmp1);\n+  } else {\n+    assert(bt == T_LONG || bt == T_DOUBLE, \"\");\n+    vmovmskpd(rtmp, mask, vec_enc);\n+    shlq(rtmp, 5); \/\/ for 32 bytes permute row of 4 x 64 bits.\n+    if (opcode == Op_CompressV) {\n+      lea(rscratch, ExternalAddress(StubRoutines::x86::compress_perm_table64()));\n+    } else {\n+      lea(rscratch, ExternalAddress(StubRoutines::x86::expand_perm_table64()));\n+    }\n+    addptr(rtmp, rscratch);\n+    vmovdqu(permv, Address(rtmp));\n+    vmovdqu(xtmp, permv);\n+    \/\/ Multiply permute index by 2 to get double word index.\n+    vpsllq(permv, permv, 1, vec_enc);\n+    \/\/ Duplicate each double word shuffle\n+    vpsllq(dst, permv, 32, vec_enc);\n+    vpor(permv, permv, dst, vec_enc);\n+    \/\/ Add one to get alternate double word index\n+    vpaddd(permv, permv, ExternalAddress(StubRoutines::x86::vector_long_shuffle_mask()), vec_enc, noreg);\n+    vpermps(dst, permv, src, Assembler::AVX_256bit);\n+    vpxor(permv, permv, permv, vec_enc);\n+    \/\/ Blend the result with zero vector using permute mask, each row of\n+    \/\/ permute table contains either a valid permute index or a -1 (default)\n+    \/\/ value, this can potentially be used as a blending mask after\n+    \/\/ compressing\/expanding the source vector lanes.\n+    vblendvps(dst, dst, permv, xtmp, vec_enc, false, xtmp1);\n+  }\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":53,"deletions":0,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -393,0 +393,4 @@\n+\n+  void vector_compress_expand_avx2(int opcode, XMMRegister dst, XMMRegister src, XMMRegister mask,\n+                                   Register rtmp, Register rscratch, XMMRegister permv, XMMRegister xtmp,\n+                                   XMMRegister xtmp1, BasicType bt, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -954,0 +954,82 @@\n+address StubGenerator::generate_compress_perm_table(const char *stub_name, int32_t esize) {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  address start = __ pc();\n+  if (esize == 32) {\n+    \/\/ Loop to generate 256 x 8 int compression permute index table. A row is\n+    \/\/ accessed using 8 bit index computed using vector mask. An entry in\n+    \/\/ the row holds either a valid permute index corresponding to set bit position\n+    \/\/ or a -1 (default) value.\n+    for (int mask = 0; mask < 256; mask++) {\n+      int ctr = 0;\n+      for (int j = 0; j < 8; j++) {\n+        if (mask & (1 << j)) {\n+          __ emit_data(j, relocInfo::none);\n+          ctr++;\n+        }\n+      }\n+      for (; ctr < 8; ctr++) {\n+        __ emit_data(-1, relocInfo::none);\n+      }\n+    }\n+  } else {\n+    assert(esize == 64, \"\");\n+    \/\/ Loop to generate 16 x 4 long compression permute index table. A row is\n+    \/\/ accessed using 4 bit index computed using vector mask. An entry in\n+    \/\/ the row holds either a valid permute index corresponding to set bit position\n+    \/\/ or a -1 (default) value.\n+    for (int mask = 0; mask < 16; mask++) {\n+      int ctr = 0;\n+      for (int j = 0; j < 4; j++) {\n+        if (mask & (1 << j)) {\n+          __ emit_data64(j, relocInfo::none);\n+          ctr++;\n+        }\n+      }\n+      for (; ctr < 4; ctr++) {\n+        __ emit_data64(-1L, relocInfo::none);\n+      }\n+    }\n+  }\n+  return start;\n+}\n+\n+address StubGenerator::generate_expand_perm_table(const char *stub_name, int32_t esize) {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+  address start = __ pc();\n+  if (esize == 32) {\n+    \/\/ Loop to generate 256 x 8 int expand permute index table. A row is accessed\n+    \/\/ using 8 bit index computed using vector mask. An entry in the row holds either\n+    \/\/ a valid permute index (starting from least significant lane) placed at poisition\n+    \/\/ corresponding to set bit position or a -1 (default) value.\n+    for (int mask = 0; mask < 256; mask++) {\n+      int ctr = 0;\n+      for (int j = 0; j < 8; j++) {\n+        if (mask & (1 << j)) {\n+          __ emit_data(ctr++, relocInfo::none);\n+        } else {\n+          __ emit_data(-1, relocInfo::none);\n+        }\n+      }\n+    }\n+  } else {\n+    assert(esize == 64, \"\");\n+    \/\/ Loop to generate 16 x 4 long expand permute index table. A row is accessed\n+    \/\/ using 4 bit index computed using vector mask. An entry in the row holds either\n+    \/\/ a valid permute index (starting from least significant lane) placed at poisition\n+    \/\/ corresponding to set bit position or a -1 (default) value.\n+    for (int mask = 0; mask < 16; mask++) {\n+      int ctr = 0;\n+      for (int j = 0; j < 4; j++) {\n+        if (mask & (1 << j)) {\n+          __ emit_data64(ctr++, relocInfo::none);\n+        } else {\n+          __ emit_data64(-1L, relocInfo::none);\n+        }\n+      }\n+    }\n+  }\n+  return start;\n+}\n+\n@@ -4098,0 +4180,7 @@\n+  if (VM_Version::supports_avx2() && !VM_Version::supports_avx512vl()) {\n+    StubRoutines::x86::_compress_perm_table32 = generate_compress_perm_table(\"compress_perm_table32\", 32);\n+    StubRoutines::x86::_compress_perm_table64 = generate_compress_perm_table(\"compress_perm_table64\", 64);\n+    StubRoutines::x86::_expand_perm_table32 = generate_expand_perm_table(\"expand_perm_table32\", 32);\n+    StubRoutines::x86::_expand_perm_table64 = generate_expand_perm_table(\"expand_perm_table64\", 64);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":89,"deletions":0,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -102,0 +102,4 @@\n+  address generate_compress_perm_table(const char *stub_name, int32_t esize);\n+\n+  address generate_expand_perm_table(const char *stub_name, int32_t esize);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -85,0 +85,4 @@\n+address StubRoutines::x86::_compress_perm_table32 = nullptr;\n+address StubRoutines::x86::_compress_perm_table64 = nullptr;\n+address StubRoutines::x86::_expand_perm_table32 = nullptr;\n+address StubRoutines::x86::_expand_perm_table64 = nullptr;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,1 +40,1 @@\n-  _compiler_stubs_code_size     = 20000 LP64_ONLY(+32000) WINDOWS_ONLY(+2000),\n+  _compiler_stubs_code_size     = 20000 LP64_ONLY(+39000) WINDOWS_ONLY(+2000),\n@@ -61,0 +61,4 @@\n+  static address _compress_perm_table32;\n+  static address _compress_perm_table64;\n+  static address _expand_perm_table32;\n+  static address _expand_perm_table64;\n@@ -341,0 +345,4 @@\n+  static address compress_perm_table32() { return _compress_perm_table32; }\n+  static address compress_perm_table64() { return _compress_perm_table64; }\n+  static address expand_perm_table32() { return _expand_perm_table32; }\n+  static address expand_perm_table64() { return _expand_perm_table64; }\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86_64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1428,0 +1428,2 @@\n+    case Op_CompressV:\n+    case Op_ExpandV:\n@@ -1662,6 +1664,0 @@\n-    case Op_CompressV:\n-    case Op_ExpandV:\n-      if (!VM_Version::supports_avx512vl()) {\n-        return false;\n-      }\n-      break;\n@@ -1955,1 +1951,1 @@\n-      if (size_in_bits < 128 ) {\n+      if (!is_LP64 && !VM_Version::supports_avx512vl() && size_in_bits < 512) {\n@@ -1958,1 +1954,1 @@\n-      if (size_in_bits < 512 && !VM_Version::supports_avx512vl()) {\n+      if (size_in_bits < 128 ) {\n@@ -1961,1 +1957,0 @@\n-      break;\n@@ -9166,0 +9161,34 @@\n+#ifdef _LP64\n+instruct vcompress_reg_avx(vec dst, vec src, vec mask, rRegI rtmp, rRegL rscratch, vec perm, vec xtmp, rFlagsReg cr) %{\n+  predicate(!EnableX86ECoreOpts && !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n+  match(Set dst (CompressV src mask));\n+  match(Set dst (ExpandV src mask));\n+  effect(TEMP_DEF dst, TEMP perm, TEMP xtmp, TEMP rtmp, TEMP rscratch, KILL cr);\n+  format %{ \"vector_compress $dst, $src, $mask \\t!using $xtmp, $rtmp, $rscratch and $perm as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt  = Matcher::vector_element_basic_type(this);\n+    __ vector_compress_expand_avx2(opcode, $dst$$XMMRegister, $src$$XMMRegister, $mask$$XMMRegister, $rtmp$$Register,\n+                                   $rscratch$$Register, $perm$$XMMRegister, $xtmp$$XMMRegister, xnoreg, bt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcompress_reg_avx_ecore(vec dst, vec src, vec mask, rRegI rtmp, rRegL rscratch, vec perm, vec xtmp, vec xtmp1, rFlagsReg cr) %{\n+  predicate(EnableX86ECoreOpts && !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n+  match(Set dst (CompressV src mask));\n+  match(Set dst (ExpandV src mask));\n+  effect(TEMP_DEF dst, TEMP perm, TEMP xtmp, TEMP xtmp1, TEMP rtmp, TEMP rscratch, KILL cr);\n+  format %{ \"vector_compress $dst, $src, $mask \\t!using $xtmp, $rtmp, $rscratch and $perm as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vlen_enc = vector_length_encoding(this);\n+    BasicType bt  = Matcher::vector_element_basic_type(this);\n+    __ vector_compress_expand_avx2(opcode, $dst$$XMMRegister, $src$$XMMRegister, $mask$$XMMRegister, $rtmp$$Register,\n+                                   $rscratch$$Register, $perm$$XMMRegister, $xtmp$$XMMRegister, $xtmp1$$XMMRegister,\n+                                   bt, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+#endif\n@@ -9168,0 +9197,1 @@\n+  predicate(VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":39,"deletions":9,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -0,0 +1,185 @@\n+\/*\n+ *  Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ *  DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ *  This code is free software; you can redistribute it and\/or modify it\n+ *  under the terms of the GNU General Public License version 2 only, as\n+ *  published by the Free Software Foundation.\n+ *\n+ *  This code is distributed in the hope that it will be useful, but WITHOUT\n+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ *  version 2 for more details (a copy is included in the LICENSE file that\n+ *  accompanied this code).\n+ *\n+ *  You should have received a copy of the GNU General Public License version\n+ *  2 along with this work; if not, write to the Free Software Foundation,\n+ *  Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ *  Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ *  or visit www.oracle.com if you need additional information or have any\n+ *  questions.\n+ *\n+ *\/\n+\n+package org.openjdk.bench.jdk.incubator.vector;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.Random;\n+import jdk.incubator.vector.*;\n+import org.openjdk.jmh.annotations.*;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+@State(Scope.Thread)\n+@Fork(jvmArgsPrepend = {\"--add-modules=jdk.incubator.vector\", \"-XX:UseAVX=2\"})\n+public class ColumnFilterBenchmark {\n+    @Param({\"1024\", \"2047\", \"4096\"})\n+    int size;\n+\n+    float [] floatinCol;\n+    float [] floatoutCol;\n+    float fpivot;\n+\n+    double [] doubleinCol;\n+    double [] doubleoutCol;\n+    double dpivot;\n+\n+    int [] intinCol;\n+    int [] intoutCol;\n+    int ipivot;\n+\n+    long [] longinCol;\n+    long [] longoutCol;\n+    long lpivot;\n+\n+    static final VectorSpecies<Float> fspecies = FloatVector.SPECIES_256;\n+    static final VectorSpecies<Double> dspecies = DoubleVector.SPECIES_256;\n+    static final VectorSpecies<Integer> ispecies = IntVector.SPECIES_256;\n+    static final VectorSpecies<Long> lspecies = LongVector.SPECIES_256;\n+\n+    @Setup(Level.Trial)\n+    public void BmSetup() {\n+        Random r = new Random(2048);\n+\n+        floatinCol = new float[size];\n+        floatoutCol = new float[size];\n+        fpivot = (float) (size \/ 2);\n+        doubleinCol = new double[size];\n+        doubleoutCol = new double[size];\n+        dpivot = (double) (size \/ 2);\n+        intinCol = new int[size];\n+        intoutCol = new int[size];\n+        ipivot = size \/ 2;\n+        longinCol = new long[size];\n+        longoutCol = new long[size];\n+        lpivot = size \/ 2;\n+\n+        for (int i = 4; i < size; i++) {\n+            floatinCol[i] = r.nextFloat() * size;\n+            doubleinCol[i] = r.nextDouble() * size;\n+            intinCol[i] = r.nextInt(size);\n+            longinCol[i] = (long)intinCol[i];\n+        }\n+    }\n+\n+    @Benchmark\n+    public void fuzzyFilterIntColumn() {\n+       int i = 0;\n+       int j = 0;\n+       long maskctr = 1;\n+       int endIndex = ispecies.loopBound(size);\n+       for (; i < endIndex; i += ispecies.length()) {\n+           IntVector vec = IntVector.fromArray(ispecies, intinCol, i);\n+           VectorMask<Integer> pred = VectorMask.fromLong(ispecies, maskctr++);\n+           vec.compress(pred).intoArray(intoutCol, j);\n+           j += pred.trueCount();\n+       }\n+   }\n+\n+   @Benchmark\n+   public void fuzzyFilterLongColumn() {\n+       int i = 0;\n+       int j = 0;\n+       long maskctr = 1;\n+       int endIndex = lspecies.loopBound(size);\n+       for (; i < endIndex; i += lspecies.length()) {\n+           LongVector vec = LongVector.fromArray(lspecies, longinCol, i);\n+           VectorMask<Long> pred = VectorMask.fromLong(lspecies, maskctr++);\n+           vec.compress(pred).intoArray(longoutCol, j);\n+           j += pred.trueCount();\n+       }\n+   }\n+\n+    @Benchmark\n+    public void filterIntColumn() {\n+       int i = 0;\n+       int j = 0;\n+       int endIndex = ispecies.loopBound(size);\n+       for (; i < endIndex; i += ispecies.length()) {\n+           IntVector vec = IntVector.fromArray(ispecies, intinCol, i);\n+           VectorMask<Integer> pred = vec.compare(VectorOperators.GT, ipivot);\n+           vec.compress(pred).intoArray(intoutCol, j);\n+           j += pred.trueCount();\n+       }\n+       for (; i < endIndex; i++) {\n+           if (intinCol[i] > ipivot) {\n+               intoutCol[j++] = intinCol[i];\n+           }\n+       }\n+   }\n+\n+   @Benchmark\n+   public void filterLongColumn() {\n+       int i = 0;\n+       int j = 0;\n+       int endIndex = lspecies.loopBound(size);\n+       for (; i < endIndex; i += lspecies.length()) {\n+           LongVector vec = LongVector.fromArray(lspecies, longinCol, i);\n+           VectorMask<Long> pred = vec.compare(VectorOperators.GT, lpivot);\n+           vec.compress(pred).intoArray(longoutCol, j);\n+           j += pred.trueCount();\n+       }\n+       for (; i < endIndex; i++) {\n+           if (longinCol[i] > lpivot) {\n+               longoutCol[j++] = longinCol[i];\n+           }\n+       }\n+   }\n+\n+   @Benchmark\n+   public void filterFloatColumn() {\n+       int i = 0;\n+       int j = 0;\n+       int endIndex = fspecies.loopBound(size);\n+       for (; i < endIndex; i += fspecies.length()) {\n+           FloatVector vec = FloatVector.fromArray(fspecies, floatinCol, i);\n+           VectorMask<Float> pred = vec.compare(VectorOperators.GT, fpivot);\n+           vec.compress(pred).intoArray(floatoutCol, j);\n+           j += pred.trueCount();\n+       }\n+       for (; i < endIndex; i++) {\n+           if (floatinCol[i] > fpivot) {\n+               floatoutCol[j++] = floatinCol[i];\n+           }\n+       }\n+   }\n+\n+   @Benchmark\n+   public void filterDoubleColumn() {\n+       int i = 0;\n+       int j = 0;\n+       int endIndex = dspecies.loopBound(size);\n+       for (; i < endIndex; i += dspecies.length()) {\n+           DoubleVector vec = DoubleVector.fromArray(dspecies, doubleinCol, i);\n+           VectorMask<Double> pred = vec.compare(VectorOperators.GT, dpivot);\n+           vec.compress(pred).intoArray(doubleoutCol, j);\n+           j += pred.trueCount();\n+       }\n+       for (; i < endIndex; i++) {\n+           if (doubleinCol[i] > dpivot) {\n+               doubleoutCol[j++] = doubleinCol[i];\n+           }\n+       }\n+   }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/vector\/ColumnFilterBenchmark.java","additions":185,"deletions":0,"binary":false,"changes":185,"status":"added"}]}