{"files":[{"patch":"@@ -5284,3 +5284,4 @@\n-void C2_MacroAssembler::vector_compress_expand_avx2(int opcode, XMMRegister dst, XMMRegister src, XMMRegister mask,\n-                                                    Register rtmp, Register rscratch, XMMRegister permv,\n-                                                    XMMRegister xtmp, XMMRegister xtmp1, BasicType bt, int vec_enc) {\n+void C2_MacroAssembler::vector_compress_expand_avx2(int opcode, XMMRegister dst, XMMRegister src,\n+                                                    XMMRegister mask, Register rtmp, Register rscratch,\n+                                                    XMMRegister permv, XMMRegister xtmp, BasicType bt,\n+                                                    int vec_enc) {\n@@ -5289,19 +5290,5 @@\n-  if (bt == T_INT || bt == T_FLOAT) {\n-    vmovmskps(rtmp, mask, vec_enc);\n-    shlq(rtmp, 5);  \/\/ for 32 byte permute row of 8 x 32 bits.\n-    if (opcode == Op_CompressV) {\n-      lea(rscratch, ExternalAddress(StubRoutines::x86::compress_perm_table32()));\n-    } else {\n-      lea(rscratch, ExternalAddress(StubRoutines::x86::expand_perm_table32()));\n-    }\n-    addptr(rtmp, rscratch);\n-    vmovdqu(permv, Address(rtmp));\n-    vpermps(dst, permv, src, Assembler::AVX_256bit);\n-    vpxor(xtmp, xtmp, xtmp, vec_enc);\n-    \/\/ Blend the result with zero vector using permute mask, each row of\n-    \/\/ permute table contains either a valid permute index or a -1 (default)\n-    \/\/ value, this can potentially be used as a blending mask after\n-    \/\/ compressing\/expanding the source vector lanes.\n-    vblendvps(dst, dst, xtmp, permv, vec_enc, false, xtmp1);\n-  } else {\n-    assert(bt == T_LONG || bt == T_DOUBLE, \"\");\n+  address compress_perm_table = nullptr;\n+  address expand_perm_table = nullptr;\n+  if (type2aelembytes(bt) == 8) {\n+    compress_perm_table = StubRoutines::x86::compress_perm_table64();\n+    expand_perm_table  = StubRoutines::x86::expand_perm_table64();\n@@ -5309,23 +5296,4 @@\n-    shlq(rtmp, 5); \/\/ for 32 bytes permute row of 4 x 64 bits.\n-    if (opcode == Op_CompressV) {\n-      lea(rscratch, ExternalAddress(StubRoutines::x86::compress_perm_table64()));\n-    } else {\n-      lea(rscratch, ExternalAddress(StubRoutines::x86::expand_perm_table64()));\n-    }\n-    addptr(rtmp, rscratch);\n-    vmovdqu(permv, Address(rtmp));\n-    vmovdqu(xtmp, permv);\n-    \/\/ Multiply permute index by 2 to get double word index.\n-    vpsllq(permv, permv, 1, vec_enc);\n-    \/\/ Duplicate each double word shuffle\n-    vpsllq(dst, permv, 32, vec_enc);\n-    vpor(permv, permv, dst, vec_enc);\n-    \/\/ Add one to get alternate double word index\n-    vpaddd(permv, permv, ExternalAddress(StubRoutines::x86::vector_long_shuffle_mask()), vec_enc, noreg);\n-    vpermps(dst, permv, src, Assembler::AVX_256bit);\n-    vpxor(permv, permv, permv, vec_enc);\n-    \/\/ Blend the result with zero vector using permute mask, each row of\n-    \/\/ permute table contains either a valid permute index or a -1 (default)\n-    \/\/ value, this can potentially be used as a blending mask after\n-    \/\/ compressing\/expanding the source vector lanes.\n-    vblendvps(dst, dst, permv, xtmp, vec_enc, false, xtmp1);\n+  } else {\n+    compress_perm_table = StubRoutines::x86::compress_perm_table32();\n+    expand_perm_table = StubRoutines::x86::expand_perm_table32();\n+    vmovmskps(rtmp, mask, vec_enc);\n@@ -5333,0 +5301,15 @@\n+  shlq(rtmp, 5); \/\/ for 32 byte permute row of 8 x 32 bits.\n+  if (opcode == Op_CompressV) {\n+    lea(rscratch, ExternalAddress(compress_perm_table));\n+  } else {\n+    lea(rscratch, ExternalAddress(expand_perm_table));\n+  }\n+  addptr(rtmp, rscratch);\n+  vmovdqu(permv, Address(rtmp));\n+  vpermps(dst, permv, src, Assembler::AVX_256bit);\n+  vpxor(xtmp, xtmp, xtmp, vec_enc);\n+  \/\/ Blend the result with zero vector using permute mask, each column entry\n+  \/\/ in a permute table row contains either a valid permute index or a -1 (default)\n+  \/\/ value, this can potentially be used as a blending mask after\n+  \/\/ compressing\/expanding the source vector lanes.\n+  vblendvps(dst, dst, xtmp, permv, vec_enc, false, permv);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":28,"deletions":45,"binary":false,"changes":73,"status":"modified"},{"patch":"@@ -396,1 +396,1 @@\n-                                   XMMRegister xtmp1, BasicType bt, int vec_enc);\n+                                   BasicType bt, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -985,1 +985,2 @@\n-          __ emit_data64(j, relocInfo::none);\n+          __ emit_data(2 * j, relocInfo::none);\n+          __ emit_data(2 * j + 1, relocInfo::none);\n@@ -1020,2 +1021,3 @@\n-    \/\/ a valid permute index (starting from least significant lane) placed at poisition\n-    \/\/ corresponding to set bit position or a -1 (default) value.\n+    \/\/ a valid doubleword permute index pair representing a quadword index (starting\n+    \/\/ from least significant lane) placed at poisition corresponding to set bit\n+    \/\/ position or a -1 (default) value.\n@@ -1026,1 +1028,3 @@\n-          __ emit_data64(ctr++, relocInfo::none);\n+          __ emit_data(2 * ctr, relocInfo::none);\n+          __ emit_data(2 * ctr + 1, relocInfo::none);\n+          ctr++;\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -9163,1 +9163,1 @@\n-  predicate(!EnableX86ECoreOpts && !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n@@ -9173,18 +9173,1 @@\n-                                   $rscratch$$Register, $perm$$XMMRegister, $xtmp$$XMMRegister, xnoreg, bt, vlen_enc);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct vcompress_reg_avx_ecore(vec dst, vec src, vec mask, rRegI rtmp, rRegL rscratch, vec perm, vec xtmp, vec xtmp1, rFlagsReg cr) %{\n-  predicate(EnableX86ECoreOpts && !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n) <= 32);\n-  match(Set dst (CompressV src mask));\n-  match(Set dst (ExpandV src mask));\n-  effect(TEMP_DEF dst, TEMP perm, TEMP xtmp, TEMP xtmp1, TEMP rtmp, TEMP rscratch, KILL cr);\n-  format %{ \"vector_compress $dst, $src, $mask \\t!using $xtmp, $rtmp, $rscratch and $perm as TEMP\" %}\n-  ins_encode %{\n-    int opcode = this->ideal_Opcode();\n-    int vlen_enc = vector_length_encoding(this);\n-    BasicType bt  = Matcher::vector_element_basic_type(this);\n-    __ vector_compress_expand_avx2(opcode, $dst$$XMMRegister, $src$$XMMRegister, $mask$$XMMRegister, $rtmp$$Register,\n-                                   $rscratch$$Register, $perm$$XMMRegister, $xtmp$$XMMRegister, $xtmp1$$XMMRegister,\n-                                   bt, vlen_enc);\n+                                   $rscratch$$Register, $perm$$XMMRegister, $xtmp$$XMMRegister, bt, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":2,"deletions":19,"binary":false,"changes":21,"status":"modified"}]}