{"files":[{"patch":"@@ -1098,1 +1098,1 @@\n-   *\n+   * \n@@ -1108,0 +1108,6 @@\n+\n+   *  Following pseudo code describes the algorithm for max[FD] (Min algorithm is on similar lines):\n+   *   btmp = (b < +0.0) ? a : b\n+   *   atmp = (b < +0.0) ? b : a\n+   *   Tmp  = Max_Float(atmp , btmp)\n+   *   Res  = (atmp == NaN) ? atmp : Tmp\n@@ -5358,1 +5364,1 @@\n-    vblendvpd(dst, one, dst, src, vec_enc, false, xtmp1);\n+    vblendvpd(dst, one, dst, src, vec_enc, true, xtmp1);\n@@ -5361,1 +5367,1 @@\n-    vblendvpd(dst, dst, src, xtmp1, vec_enc, true, xtmp1);\n+    vblendvpd(dst, dst, src, xtmp1, vec_enc, false, xtmp1);\n@@ -5366,1 +5372,1 @@\n-    vblendvps(dst, one, dst, src, vec_enc, false, xtmp1);\n+    vblendvps(dst, one, dst, src, vec_enc, true, xtmp1);\n@@ -5369,1 +5375,1 @@\n-    vblendvps(dst, dst, src, xtmp1, vec_enc, true, xtmp1);\n+    vblendvps(dst, dst, src, xtmp1, vec_enc, false, xtmp1);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -3570,2 +3570,2 @@\n-\/\/ vblendvps(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool fully_masked = false, XMMRegister scratch = xnoreg)\n-void MacroAssembler::vblendvps(XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister mask, int vector_len, bool fully_masked, XMMRegister scratch) {\n+\/\/ vblendvps(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool compute_mask = true, XMMRegister scratch = xnoreg)\n+void MacroAssembler::vblendvps(XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister mask, int vector_len, bool compute_mask, XMMRegister scratch) {\n@@ -3576,2 +3576,1 @@\n-    XMMRegister full_mask = mask;\n-    if (!fully_masked) {\n+    if (compute_mask) {\n@@ -3579,1 +3578,1 @@\n-      full_mask = scratch;\n+      mask = scratch;\n@@ -3582,2 +3581,2 @@\n-      vpandn(dst,     full_mask, src1, vector_len); \/\/ if mask == 0, src1\n-      vpand (scratch, full_mask, src2, vector_len); \/\/ if mask == 1, src2\n+      vpandn(dst,     mask, src1, vector_len); \/\/ if mask == 0, src1\n+      vpand (scratch, mask, src2, vector_len); \/\/ if mask == 1, src2\n@@ -3585,2 +3584,2 @@\n-      vpand (dst,     full_mask, src2, vector_len); \/\/ if mask == 1, src2\n-      vpandn(scratch, full_mask, src1, vector_len); \/\/ if mask == 0, src1\n+      vpand (dst,     mask, src2, vector_len); \/\/ if mask == 1, src2\n+      vpandn(scratch, mask, src1, vector_len); \/\/ if mask == 0, src1\n@@ -3594,2 +3593,2 @@\n-\/\/ vblendvpd(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool fully_masked = false, XMMRegister scratch = xnoreg)\n-void MacroAssembler::vblendvpd(XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister mask, int vector_len, bool fully_masked, XMMRegister scratch) {\n+\/\/ vblendvpd(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool compute_mask = true, XMMRegister scratch = xnoreg)\n+void MacroAssembler::vblendvpd(XMMRegister dst, XMMRegister src1, XMMRegister src2, XMMRegister mask, int vector_len, bool compute_mask, XMMRegister scratch) {\n@@ -3597,1 +3596,1 @@\n-  bool scratch_available = scratch != xnoreg && scratch != src1 && scratch != src2 && scratch != dst && (fully_masked || scratch != mask);\n+  bool scratch_available = scratch != xnoreg && scratch != src1 && scratch != src2 && scratch != dst && (!compute_mask || scratch != mask);\n@@ -3600,2 +3599,1 @@\n-    XMMRegister full_mask = mask;\n-    if (!fully_masked) {\n+    if (compute_mask) {\n@@ -3604,1 +3602,1 @@\n-      full_mask = scratch;\n+      mask = scratch;\n@@ -3607,3 +3605,2 @@\n-      vpandn(dst,     full_mask, src1, vector_len); \/\/ if mask == 0, src\n-      vpand (scratch, full_mask, src2, vector_len); \/\/ if mask == 1, src2\n-      vpor(dst, dst, scratch, vector_len);\n+      vpandn(dst,     mask, src1, vector_len); \/\/ if mask == 0, src\n+      vpand (scratch, mask, src2, vector_len); \/\/ if mask == 1, src2\n@@ -3611,3 +3608,2 @@\n-      vpand (dst,     full_mask, src2, vector_len); \/\/ if mask == 1, src2\n-      vpandn(scratch, full_mask, src1, vector_len); \/\/ if mask == 0, src\n-      vpor(dst, dst, scratch, vector_len);\n+      vpand (dst,     mask, src2, vector_len); \/\/ if mask == 1, src2\n+      vpandn(scratch, mask, src1, vector_len); \/\/ if mask == 0, src\n@@ -3615,0 +3611,1 @@\n+    vpor(dst, dst, scratch, vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":18,"deletions":21,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -1133,2 +1133,2 @@\n-  void vblendvps(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool fully_masked = false, XMMRegister scratch = xnoreg);\n-  void vblendvpd(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool fully_masked = false, XMMRegister scratch = xnoreg);\n+  void vblendvps(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool compute_mask = true, XMMRegister scratch = xnoreg);\n+  void vblendvpd(XMMRegister dst, XMMRegister nds, XMMRegister src, XMMRegister mask, int vector_len, bool compute_mask = true, XMMRegister scratch = xnoreg);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4481,8 +4481,0 @@\n-\n-\/\/ Following pseudo code describes the algorithm for max[FD]:\n-\/\/ Min algorithm is on similar lines\n-\/\/  btmp = (b < +0.0) ? a : b\n-\/\/  atmp = (b < +0.0) ? b : a\n-\/\/  Tmp  = Max_Float(atmp , btmp)\n-\/\/  Res  = (atmp == NaN) ? atmp : Tmp\n-\n@@ -4494,7 +4486,1 @@\n-  format %{\n-     \"vblendvps        $btmp,$b,$a,$b           \\n\\t\"\n-     \"vblendvps        $atmp,$a,$b,$b           \\n\\t\"\n-     \"vmaxss           $tmp,$atmp,$btmp         \\n\\t\"\n-     \"vcmpps.unordered $btmp,$atmp,$atmp        \\n\\t\"\n-     \"vblendvps        $dst,$tmp,$atmp,$btmp    \\n\\t\"\n-  %}\n+  format %{ \"maxF $dst, $a, $b \\t! using tmp, atmp and btmp as TEMP\" %}\n@@ -4502,19 +4488,2 @@\n-    int vector_len = Assembler::AVX_128bit;\n-    XMMRegister mask = $b$$XMMRegister;\n-    if (EnableX86ECoreOpts) {\n-      __ vpsrad($tmp$$XMMRegister, mask, 32, vector_len);\n-      mask = $tmp$$XMMRegister;\n-    }\n-    __ vblendvps($btmp$$XMMRegister, $b$$XMMRegister, $a$$XMMRegister, mask, vector_len, true, $atmp$$XMMRegister);\n-    __ vblendvps($atmp$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, mask, vector_len, true, $tmp$$XMMRegister);\n-\n-    if ($dst$$XMMRegister == $btmp$$XMMRegister) {\n-      __ vmaxss($btmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmpps($tmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvps($dst$$XMMRegister, $btmp$$XMMRegister, $atmp$$XMMRegister, $tmp$$XMMRegister, vector_len, true, $tmp$$XMMRegister);\n-    } else {\n-      __ vmaxss($tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmpps($btmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvps($dst$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, vector_len, true, $btmp$$XMMRegister);\n-    }\n- %}\n+    __ vminmax_fp(Op_MaxV, T_FLOAT, $dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, Assembler::AVX_128bit);\n+  %}\n@@ -4542,7 +4511,1 @@\n-  format %{\n-     \"vblendvpd        $btmp,$b,$a,$b            \\n\\t\"\n-     \"vblendvpd        $atmp,$a,$b,$b            \\n\\t\"\n-     \"vmaxsd           $tmp,$atmp,$btmp          \\n\\t\"\n-     \"vcmppd.unordered $btmp,$atmp,$atmp         \\n\\t\"\n-     \"vblendvpd        $dst,$tmp,$atmp,$btmp     \\n\\t\"\n-  %}\n+  format %{ \"maxD $dst, $a, $b \\t! using tmp, atmp and btmp as TEMP\" %}\n@@ -4550,19 +4513,1 @@\n-    int vector_len = Assembler::AVX_128bit;\n-    XMMRegister mask = $b$$XMMRegister;\n-    if (EnableX86ECoreOpts) {\n-      __ vpxor($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp$$XMMRegister, vector_len);\n-      __ vpcmpgtq($tmp$$XMMRegister, $tmp$$XMMRegister, mask, vector_len);\n-      mask = $tmp$$XMMRegister;\n-    }\n-    __ vblendvpd($btmp$$XMMRegister, $b$$XMMRegister, $a$$XMMRegister, mask, vector_len, true, $atmp$$XMMRegister);\n-    __ vblendvpd($atmp$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, mask, vector_len, true, $tmp$$XMMRegister);\n-\n-    if ($dst$$XMMRegister == $btmp$$XMMRegister) {\n-      __ vmaxsd($btmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmppd($tmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvpd($dst$$XMMRegister, $btmp$$XMMRegister, $atmp$$XMMRegister, $tmp$$XMMRegister, vector_len, true, $tmp$$XMMRegister);\n-    } else {\n-      __ vmaxsd($tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmppd($btmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvpd($dst$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, vector_len, true, $btmp$$XMMRegister);\n-    }\n+    __ vminmax_fp(Op_MaxV, T_DOUBLE, $dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, Assembler::AVX_128bit);\n@@ -4591,7 +4536,1 @@\n-  format %{\n-     \"vblendvps        $atmp,$a,$b,$a             \\n\\t\"\n-     \"vblendvps        $btmp,$b,$a,$a             \\n\\t\"\n-     \"vminss           $tmp,$atmp,$btmp           \\n\\t\"\n-     \"vcmpps.unordered $btmp,$atmp,$atmp          \\n\\t\"\n-     \"vblendvps        $dst,$tmp,$atmp,$btmp      \\n\\t\"\n-  %}\n+  format %{ \"minF $dst, $a, $b \\t! using tmp, atmp and btmp as TEMP\" %}\n@@ -4599,18 +4538,1 @@\n-    int vector_len = Assembler::AVX_128bit;\n-    XMMRegister mask = $a$$XMMRegister;\n-    if (EnableX86ECoreOpts) {\n-      __ vpsrad($tmp$$XMMRegister, mask, 32, vector_len);\n-      mask = $tmp$$XMMRegister;\n-    }\n-    __ vblendvps($atmp$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, mask, vector_len, true, $btmp$$XMMRegister);\n-    __ vblendvps($btmp$$XMMRegister, $b$$XMMRegister, $a$$XMMRegister, mask, vector_len, true, $tmp$$XMMRegister);\n-\n-    if ($dst$$XMMRegister == $btmp$$XMMRegister) {\n-      __ vminss($btmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmpps($tmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvps($dst$$XMMRegister, $btmp$$XMMRegister, $atmp$$XMMRegister, $tmp$$XMMRegister, vector_len, true, $tmp$$XMMRegister);\n-    } else {\n-      __ vminss($tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmpps($btmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvps($dst$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, vector_len, true, $btmp$$XMMRegister);\n-    }\n+    __ vminmax_fp(Op_MinV, T_FLOAT, $dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, Assembler::AVX_128bit);\n@@ -4639,7 +4561,1 @@\n-  format %{\n-     \"vblendvpd        $atmp,$a,$b,$a           \\n\\t\"\n-     \"vblendvpd        $btmp,$b,$a,$a           \\n\\t\"\n-     \"vminsd           $tmp,$atmp,$btmp         \\n\\t\"\n-     \"vcmppd.unordered $btmp,$atmp,$atmp        \\n\\t\"\n-     \"vblendvpd        $dst,$tmp,$atmp,$btmp    \\n\\t\"\n-  %}\n+    format %{ \"minD $dst, $a, $b \\t! using tmp, atmp and btmp as TEMP\" %}\n@@ -4647,19 +4563,1 @@\n-    int vector_len = Assembler::AVX_128bit;\n-    XMMRegister mask = $a$$XMMRegister;\n-    if (EnableX86ECoreOpts) {\n-      __ vpxor($tmp$$XMMRegister, $tmp$$XMMRegister, $tmp$$XMMRegister, vector_len);\n-      __ vpcmpgtq($tmp$$XMMRegister, $tmp$$XMMRegister, mask, vector_len);\n-      mask = $tmp$$XMMRegister;\n-    }\n-    __ vblendvpd($atmp$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, mask, vector_len, true, $btmp$$XMMRegister);\n-    __ vblendvpd($btmp$$XMMRegister, $b$$XMMRegister, $a$$XMMRegister, mask, vector_len, true, $tmp$$XMMRegister);\n-\n-    if ($dst$$XMMRegister == $btmp$$XMMRegister) {\n-      __ vminsd($btmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmppd($tmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvpd($dst$$XMMRegister, $btmp$$XMMRegister, $atmp$$XMMRegister, $tmp$$XMMRegister, vector_len, true, $tmp$$XMMRegister);\n-    } else {\n-      __ vminsd($tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister);\n-      __ vcmppd($btmp$$XMMRegister, $atmp$$XMMRegister, $atmp$$XMMRegister, Assembler::_false, vector_len);\n-      __ vblendvpd($dst$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, vector_len, true, $btmp$$XMMRegister);\n-    }\n+    __ vminmax_fp(Op_MinV, T_DOUBLE, $dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, $tmp$$XMMRegister, $atmp$$XMMRegister, $btmp$$XMMRegister, Assembler::AVX_128bit);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":9,"deletions":111,"binary":false,"changes":120,"status":"modified"}]}