{"files":[{"patch":"@@ -718,1 +718,1 @@\n-        $1_CFLAGS_CPU=\"-mcpu=powerpc64 -mtune=power5\"\n+        $1_CFLAGS_CPU=\"-mcpu=power8 -mtune=power8\"\n","filename":"make\/autoconf\/flags-cflags.m4","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -211,2 +211,1 @@\n-inline void Assembler::isel(Register d, Register a, Register b, int c) { guarantee(VM_Version::has_isel(), \"opcode not supported on this hardware\");\n-                                                                         emit_int32(ISEL_OPCODE    | rt(d)  | ra(a) | rb(b) | bc(c)); }\n+inline void Assembler::isel(Register d, Register a, Register b, int c) { emit_int32(ISEL_OPCODE    | rt(d)  | ra(a) | rb(b) | bc(c)); }\n@@ -778,6 +777,3 @@\n-inline void Assembler::cmpb(   Register a, Register s, Register b) { guarantee(VM_Version::has_cmpb(), \"opcode not supported on this hardware\");\n-                                                                     emit_int32( CMPB_OPCODE    | rta(a) | rs(s) | rb(b) | rc(0)); }\n-inline void Assembler::popcntb(Register a, Register s)             { guarantee(VM_Version::has_popcntb(), \"opcode not supported on this hardware\");\n-                                                                     emit_int32( POPCNTB_OPCODE | rta(a) | rs(s)); };\n-inline void Assembler::popcntw(Register a, Register s)             { guarantee(VM_Version::has_popcntw(), \"opcode not supported on this hardware\");\n-                                                                     emit_int32( POPCNTW_OPCODE | rta(a) | rs(s)); };\n+inline void Assembler::cmpb(   Register a, Register s, Register b) { emit_int32( CMPB_OPCODE    | rta(a) | rs(s) | rb(b) | rc(0)); }\n+inline void Assembler::popcntb(Register a, Register s)             { emit_int32( POPCNTB_OPCODE | rta(a) | rs(s)); };\n+inline void Assembler::popcntw(Register a, Register s)             { emit_int32( POPCNTW_OPCODE | rta(a) | rs(s)); };\n@@ -838,2 +834,1 @@\n-inline void Assembler::fcfids(FloatRegister d, FloatRegister b) { guarantee(VM_Version::has_fcfids(), \"opcode not supported on this hardware\");\n-                                                                  emit_int32( FCFIDS_OPCODE | frt(d) | frb(b) | rc(0)); }\n+inline void Assembler::fcfids(FloatRegister d, FloatRegister b) { emit_int32( FCFIDS_OPCODE | frt(d) | frb(b) | rc(0)); }\n@@ -845,4 +840,2 @@\n-inline void Assembler::fsqrt( FloatRegister d, FloatRegister b) { guarantee(VM_Version::has_fsqrt(), \"opcode not supported on this hardware\");\n-                                                                  emit_int32( FSQRT_OPCODE  | frt(d) | frb(b) | rc(0)); }\n-inline void Assembler::fsqrts(FloatRegister d, FloatRegister b) { guarantee(VM_Version::has_fsqrts(), \"opcode not supported on this hardware\");\n-                                                                  emit_int32( FSQRTS_OPCODE | frt(d) | frb(b) | rc(0)); }\n+inline void Assembler::fsqrt( FloatRegister d, FloatRegister b) { emit_int32( FSQRT_OPCODE  | frt(d) | frb(b) | rc(0)); }\n+inline void Assembler::fsqrts(FloatRegister d, FloatRegister b) { emit_int32( FSQRTS_OPCODE | frt(d) | frb(b) | rc(0)); }\n@@ -1055,2 +1048,1 @@\n-inline void Assembler::vand(    VectorRegister d, VectorRegister a, VectorRegister b) { guarantee(VM_Version::has_vand(), \"opcode not supported on this hardware\");\n-                                                                                        emit_int32( VAND_OPCODE     | vrt(d) | vra(a) | vrb(b)); }\n+inline void Assembler::vand(    VectorRegister d, VectorRegister a, VectorRegister b) { emit_int32( VAND_OPCODE     | vrt(d) | vra(a) | vrb(b)); }\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.inline.hpp","additions":8,"deletions":16,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -543,1 +543,0 @@\n-      bool src_in_memory = !VM_Version::has_mtfprd();\n@@ -546,2 +545,3 @@\n-      if (src_in_memory) {\n-        rsrc = src->as_double_reg(); \/\/ via mem\n+      \/\/ move src to dst register\n+      if (code == Bytecodes::_i2d) {\n+        __ mtfprwa(rdst, src->as_register());\n@@ -549,7 +549,1 @@\n-        \/\/ move src to dst register\n-        if (code == Bytecodes::_i2d) {\n-          __ mtfprwa(rdst, src->as_register());\n-        } else {\n-          __ mtfprd(rdst, src->as_register_lo());\n-        }\n-        rsrc = rdst;\n+        __ mtfprd(rdst, src->as_register_lo());\n@@ -557,0 +551,1 @@\n+      rsrc = rdst;\n@@ -562,1 +557,0 @@\n-      bool src_in_memory = !VM_Version::has_mtfprd();\n@@ -565,2 +559,3 @@\n-      if (src_in_memory) {\n-        rsrc = src->as_double_reg(); \/\/ via mem\n+      \/\/ move src to dst register\n+      if (code == Bytecodes::_i2f) {\n+        __ mtfprwa(rdst, src->as_register());\n@@ -568,14 +563,1 @@\n-        \/\/ move src to dst register\n-        if (code == Bytecodes::_i2f) {\n-          __ mtfprwa(rdst, src->as_register());\n-        } else {\n-          __ mtfprd(rdst, src->as_register_lo());\n-        }\n-        rsrc = rdst;\n-      }\n-      if (VM_Version::has_fcfids()) {\n-        __ fcfids(rdst, rsrc);\n-      } else {\n-        assert(code == Bytecodes::_i2f, \"fcfid+frsp needs fixup code to avoid rounding incompatibility\");\n-        __ fcfid(rdst, rsrc);\n-        __ frsp(rdst, rdst);\n+        __ mtfprd(rdst, src->as_register_lo());\n@@ -583,0 +565,2 @@\n+      rsrc = rdst;\n+      __ fcfids(rdst, rsrc);\n@@ -595,1 +579,0 @@\n-      bool dst_in_memory = !VM_Version::has_mtfprd();\n@@ -597,1 +580,1 @@\n-      Address       addr = dst_in_memory ? frame_map()->address_for_slot(dst->double_stack_ix()) : Address();\n+      Address       addr = Address();\n@@ -601,6 +584,1 @@\n-      if (dst_in_memory) {\n-        __ li(R0, 0); \/\/ 0 in case of NAN\n-        __ std(R0, addr);\n-      } else {\n-        __ li(dst->as_register(), 0);\n-      }\n+      __ li(dst->as_register(), 0);\n@@ -609,5 +587,1 @@\n-      if (dst_in_memory) {\n-        __ stfd(rsrc, addr.disp(), addr.base());\n-      } else {\n-        __ mffprd(dst->as_register(), rsrc);\n-      }\n+      __ mffprd(dst->as_register(), rsrc);\n@@ -619,1 +593,0 @@\n-      bool dst_in_memory = !VM_Version::has_mtfprd();\n@@ -621,1 +594,1 @@\n-      Address       addr = dst_in_memory ? frame_map()->address_for_slot(dst->double_stack_ix()) : Address();\n+      Address       addr = Address();\n@@ -625,6 +598,1 @@\n-      if (dst_in_memory) {\n-        __ li(R0, 0); \/\/ 0 in case of NAN\n-        __ std(R0, addr);\n-      } else {\n-        __ li(dst->as_register_lo(), 0);\n-      }\n+      __ li(dst->as_register_lo(), 0);\n@@ -633,5 +601,1 @@\n-      if (dst_in_memory) {\n-        __ stfd(rsrc, addr.disp(), addr.base());\n-      } else {\n-        __ mffprd(dst->as_register_lo(), rsrc);\n-      }\n+      __ stfd(rsrc, addr.disp(), addr.base());\n@@ -1585,1 +1549,1 @@\n-  if (VM_Version::has_isel() && result->is_cpu_register()) {\n+  if (result->is_cpu_register()) {\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":18,"deletions":54,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -717,8 +717,6 @@\n-      if (VM_Version::has_fsqrt()) {\n-        assert(x->number_of_arguments() == 1, \"wrong type\");\n-        LIRItem value(x->argument_at(0), this);\n-        value.load_item();\n-        LIR_Opr dst = rlock_result(x);\n-        __ sqrt(value.result(), dst, LIR_OprFact::illegalOpr);\n-        break;\n-      } \/\/ else fallthru\n+      assert(x->number_of_arguments() == 1, \"wrong type\");\n+      LIRItem value(x->argument_at(0), this);\n+      value.load_item();\n+      LIR_Opr dst = rlock_result(x);\n+      __ sqrt(value.result(), dst, LIR_OprFact::illegalOpr);\n+      break;\n@@ -822,72 +820,0 @@\n-  if (!VM_Version::has_mtfprd()) {\n-    switch (x->op()) {\n-\n-      \/\/ int -> float: force spill\n-      case Bytecodes::_l2f: {\n-        if (!VM_Version::has_fcfids()) { \/\/ fcfids is >= Power7 only\n-          \/\/ fcfid+frsp needs fixup code to avoid rounding incompatibility.\n-          address entry = CAST_FROM_FN_PTR(address, SharedRuntime::l2f);\n-          LIR_Opr result = call_runtime(x->value(), entry, x->type(), nullptr);\n-          set_result(x, result);\n-          return;\n-        } \/\/ else fallthru\n-      }\n-      case Bytecodes::_l2d: {\n-        LIRItem value(x->value(), this);\n-        LIR_Opr reg = rlock_result(x);\n-        value.load_item();\n-        LIR_Opr tmp = force_to_spill(value.result(), T_DOUBLE);\n-        __ convert(x->op(), tmp, reg);\n-        return;\n-      }\n-      case Bytecodes::_i2f:\n-      case Bytecodes::_i2d: {\n-        LIRItem value(x->value(), this);\n-        LIR_Opr reg = rlock_result(x);\n-        value.load_item();\n-        \/\/ Convert i2l first.\n-        LIR_Opr tmp1 = new_register(T_LONG);\n-        __ convert(Bytecodes::_i2l, value.result(), tmp1);\n-        LIR_Opr tmp2 = force_to_spill(tmp1, T_DOUBLE);\n-        __ convert(x->op(), tmp2, reg);\n-        return;\n-      }\n-\n-      \/\/ float -> int: result will be stored\n-      case Bytecodes::_f2l:\n-      case Bytecodes::_d2l: {\n-        LIRItem value(x->value(), this);\n-        LIR_Opr reg = rlock_result(x);\n-        value.set_destroys_register(); \/\/ USE_KILL\n-        value.load_item();\n-        set_vreg_flag(reg, must_start_in_memory);\n-        __ convert(x->op(), value.result(), reg);\n-        return;\n-      }\n-      case Bytecodes::_f2i:\n-      case Bytecodes::_d2i: {\n-        LIRItem value(x->value(), this);\n-        LIR_Opr reg = rlock_result(x);\n-        value.set_destroys_register(); \/\/ USE_KILL\n-        value.load_item();\n-        \/\/ Convert l2i afterwards.\n-        LIR_Opr tmp1 = new_register(T_LONG);\n-        set_vreg_flag(tmp1, must_start_in_memory);\n-        __ convert(x->op(), value.result(), tmp1);\n-        __ convert(Bytecodes::_l2i, tmp1, reg);\n-        return;\n-      }\n-\n-      \/\/ Within same category: just register conversions.\n-      case Bytecodes::_i2b:\n-      case Bytecodes::_i2c:\n-      case Bytecodes::_i2s:\n-      case Bytecodes::_i2l:\n-      case Bytecodes::_l2i:\n-      case Bytecodes::_f2d:\n-      case Bytecodes::_d2f:\n-        break;\n-\n-      default: ShouldNotReachHere();\n-    }\n-  }\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRGenerator_ppc.cpp","additions":6,"deletions":80,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -237,8 +237,1 @@\n-  if (VM_Version::has_isel()) {\n-    isel(cnt1, CR0, Assembler::greater, \/*invert*\/ false, cnt2);\n-  } else {\n-    Label Lskip;\n-    blt(CR0, Lskip);\n-    mr(cnt1, cnt2);\n-    bind(Lskip);\n-  }\n+  isel(cnt1, CR0, Assembler::greater, \/*invert*\/ false, cnt2);\n","filename":"src\/hotspot\/cpu\/ppc\/c2_MacroAssembler_ppc.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -129,6 +129,1 @@\n-        if (VM_Version::has_mtfprd()) {\n-          __ mtfprd(as_FloatRegister(to_reg), as_Register(from_reg));\n-        } else {\n-          __ std(as_Register(from_reg), -8, R1_SP);\n-          __ lfd(as_FloatRegister(to_reg), -8, R1_SP);\n-        }\n+        __ mtfprd(as_FloatRegister(to_reg), as_Register(from_reg));\n@@ -167,6 +162,1 @@\n-        if (VM_Version::has_mtfprd()) {\n-          __ mffprd(as_Register(to_reg), as_FloatRegister(from_reg));\n-        } else {\n-          __ stfd(as_FloatRegister(from_reg), -8, R1_SP);\n-          __ ld(as_Register(to_reg), -8, R1_SP);\n-        }\n+        __ mffprd(as_Register(to_reg), as_FloatRegister(from_reg));\n","filename":"src\/hotspot\/cpu\/ppc\/foreignGlobals_ppc.cpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -363,7 +363,2 @@\n-  if (VM_Version::has_isel()) {\n-    __ xori(tmp1, tmp1, markWord::lock_mask_in_place);\n-    __ isel(dst, CR0, Assembler::equal, false, tmp1);\n-  } else {\n-    __ bne(CR0, done);\n-    __ xori(dst, tmp1, markWord::lock_mask_in_place);\n-  }\n+  __ xori(tmp1, tmp1, markWord::lock_mask_in_place);\n+  __ isel(dst, CR0, Assembler::equal, false, tmp1);\n","filename":"src\/hotspot\/cpu\/ppc\/gc\/shenandoah\/shenandoahBarrierSetAssembler_ppc.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -118,1 +118,1 @@\n-  product(bool, SuperwordUseVSX, false,                                     \\\n+  product(bool, SuperwordUseVSX, true,                                     \\\n","filename":"src\/hotspot\/cpu\/ppc\/globals_ppc.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -311,6 +311,1 @@\n-  if (VM_Version::has_mtfprd()) {\n-    mtfprd(d, l);\n-  } else {\n-    std(l, 0, R15_esp);\n-    lfd(d, 0, R15_esp);\n-  }\n+  mtfprd(d, l);\n@@ -320,6 +315,1 @@\n-  if (VM_Version::has_mtfprd()) {\n-    mffprd(l, d);\n-  } else {\n-    stfd(d, 0, R15_esp);\n-    ld(l, 0, R15_esp);\n-  }\n+  mffprd(l, d);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1583,4 +1583,0 @@\n-  \/\/ For older processors, instruction_type != size holds, and we\n-  \/\/ emulate the sub-word instructions by constructing a 4-byte value\n-  \/\/ that leaves the other bytes unchanged.\n-  const int instruction_type = VM_Version::has_lqarx() ? size : 4;\n@@ -1588,0 +1584,1 @@\n+  const int instruction_type = size;\n@@ -1593,15 +1590,0 @@\n-  if (instruction_type != size) {\n-    assert_different_registers(tmp1, tmp2, tmp3, dest_current_value, exchange_value, addr_base);\n-    modval = tmp1;\n-    shift_amount = tmp2;\n-    val32 = tmp3;\n-    \/\/ Need some preparation: Compute shift amount, align address. Note: shorts must be 2 byte aligned.\n-#ifdef VM_LITTLE_ENDIAN\n-    rldic(shift_amount, addr_base, 3, 64-5); \/\/ (dest & 3) * 8;\n-    clrrdi(addr_base, addr_base, 2);\n-#else\n-    xori(shift_amount, addr_base, (size == 1) ? 3 : 2);\n-    clrrdi(addr_base, addr_base, 2);\n-    rldic(shift_amount, shift_amount, 3, 64-5); \/\/ byte: ((3-dest) & 3) * 8; short: ((1-dest\/2) & 1) * 16;\n-#endif\n-  }\n@@ -1619,4 +1601,0 @@\n-  if (instruction_type != size) {\n-    srw(dest_current_value, val32, shift_amount);\n-  }\n-\n@@ -1625,7 +1603,0 @@\n-  if (instruction_type != size) {\n-    \/\/ Transform exchange value such that the replacement can be done by one xor instruction.\n-    xorr(modval, dest_current_value, is_add ? modval : exchange_value);\n-    clrldi(modval, modval, (size == 1) ? 56 : 48);\n-    slw(modval, modval, shift_amount);\n-    xorr(modval, val32, modval);\n-  }\n@@ -1658,2 +1629,1 @@\n-                                       Register addr_base, Register tmp1, Register tmp2,\n-                                       Label &retry, Label &failed, bool cmpxchgx_hint, int size) {\n+                                       Register addr_base, Label &retry, Label &failed, bool cmpxchgx_hint, int size) {\n@@ -1661,4 +1631,1 @@\n-  \/\/ For older processors, instruction_type != size holds, and we\n-  \/\/ emulate the sub-word instructions by constructing a 4-byte value\n-  \/\/ that leaves the other bytes unchanged.\n-  const int instruction_type = VM_Version::has_lqarx() ? size : 4;\n+  const int instruction_type = size;\n@@ -1670,20 +1637,0 @@\n-  if (instruction_type != size) {\n-    assert_different_registers(tmp1, tmp2, dest_current_value, compare_value.register_or_noreg(), exchange_value, addr_base);\n-    shift_amount = tmp1;\n-    val32 = tmp2;\n-    modval = tmp2;\n-    \/\/ Need some preparation: Compute shift amount, align address. Note: shorts must be 2 byte aligned.\n-#ifdef VM_LITTLE_ENDIAN\n-    rldic(shift_amount, addr_base, 3, 64-5); \/\/ (dest & 3) * 8;\n-    clrrdi(addr_base, addr_base, 2);\n-#else\n-    xori(shift_amount, addr_base, (size == 1) ? 3 : 2);\n-    clrrdi(addr_base, addr_base, 2);\n-    rldic(shift_amount, shift_amount, 3, 64-5); \/\/ byte: ((3-dest) & 3) * 8; short: ((1-dest\/2) & 1) * 16;\n-#endif\n-    \/\/ Transform exchange value such that the replacement can be done by one xor instruction.\n-    xorr(exchange_value, compare_value, exchange_value);\n-    clrldi(exchange_value, exchange_value, (size == 1) ? 56 : 48);\n-    slw(exchange_value, exchange_value, shift_amount);\n-  }\n-\n@@ -1700,3 +1647,0 @@\n-  if (instruction_type != size) {\n-    srw(dest_current_value, val32, shift_amount);\n-  }\n@@ -1718,4 +1662,0 @@\n-  if (instruction_type != size) {\n-    xorr(modval, val32, exchange_value);\n-  }\n-\n@@ -1733,2 +1673,1 @@\n-                                     Register addr_base, Register tmp1, Register tmp2,\n-                                     int semantics, bool cmpxchgx_hint, Register int_flag_success,\n+                                     Register addr_base, int semantics, bool cmpxchgx_hint, Register int_flag_success,\n@@ -1745,2 +1684,1 @@\n-                            int_flag_success != exchange_value && int_flag_success != addr_base &&\n-                            int_flag_success != tmp1 && int_flag_success != tmp2);\n+                            int_flag_success != exchange_value && int_flag_success != addr_base);\n@@ -1772,1 +1710,1 @@\n-  cmpxchg_loop_body(flag, dest_current_value, compare_value, exchange_value, addr_base, tmp1, tmp2,\n+  cmpxchg_loop_body(flag, dest_current_value, compare_value, exchange_value, addr_base,\n@@ -3749,1 +3687,0 @@\n-  assert(!VM_Version::has_vpmsumb(), \"Vector version should be used instead!\");\n@@ -4093,5 +4030,3 @@\n-  \/\/ If supported set DSCR pre-fetch to deepest.\n-  if (VM_Version::has_mfdscr()) {\n-    load_const_optimized(t0, VM_Version::_dscr_val | 7);\n-    mtdscr(t0);\n-  }\n+  \/\/ Set DSCR pre-fetch to deepest.\n+  load_const_optimized(t0, VM_Version::_dscr_val | 7);\n+  mtdscr(t0);\n@@ -4241,4 +4176,2 @@\n-  if (VM_Version::has_mfdscr()) {\n-    load_const_optimized(t0, VM_Version::_dscr_val);\n-    mtdscr(t0);\n-  }\n+  load_const_optimized(t0, VM_Version::_dscr_val);\n+  mtdscr(t0);\n@@ -4316,5 +4249,1 @@\n-  if (VM_Version::has_vpmsumb()) {\n-    kernel_crc32_vpmsum(crc, buf, len, t0, t1, t2, t3, t4, t5, t6, t7, !is_crc32c);\n-  } else {\n-    kernel_crc32_1word(crc, buf, len, t0, t1, t2, t3, t4, t5, t6, t7, t0, !is_crc32c);\n-  }\n+  kernel_crc32_vpmsum(crc, buf, len, t0, t1, t2, t3, t4, t5, t6, t7, !is_crc32c);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":12,"deletions":83,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -502,2 +502,1 @@\n-                         Register addr_base, Register tmp1, Register tmp2,\n-                         Label &retry, Label &failed, bool cmpxchgx_hint, int size);\n+                         Register addr_base,Label &retry, Label &failed, bool cmpxchgx_hint, int size);\n@@ -506,2 +505,1 @@\n-                       Register addr_base, Register tmp1, Register tmp2,\n-                       int semantics, bool cmpxchgx_hint, Register int_flag_success,\n+                       Register addr_base, int semantics, bool cmpxchgx_hint, Register int_flag_success,\n@@ -550,5 +548,5 @@\n-                Register addr_base, Register tmp1, Register tmp2,\n-                int semantics, bool cmpxchgx_hint = false, Register int_flag_success = noreg,\n-                Label* failed = nullptr, bool contention_hint = false, bool weak = false) {\n-    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base, tmp1, tmp2,\n-                    semantics, cmpxchgx_hint, int_flag_success, failed, contention_hint, weak, 1);\n+                Register addr_base, int semantics, bool cmpxchgx_hint = false,\n+                Register int_flag_success = noreg, Label* failed = nullptr,\n+                bool contention_hint = false, bool weak = false) {\n+    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base, semantics,\n+                    cmpxchgx_hint, int_flag_success, failed, contention_hint, weak, 1);\n@@ -560,4 +558,4 @@\n-                Register addr_base, Register tmp1, Register tmp2,\n-                int semantics, bool cmpxchgx_hint = false, Register int_flag_success = noreg,\n-                Label* failed = nullptr, bool contention_hint = false, bool weak = false) {\n-    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base, tmp1, tmp2,\n+                Register addr_base, int semantics, bool cmpxchgx_hint = false,\n+                Register int_flag_success = noreg, Label* failed = nullptr,\n+                bool contention_hint = false, bool weak = false) {\n+    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base,\n@@ -571,1 +569,1 @@\n-    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base, noreg, noreg,\n+    cmpxchg_generic(flag, dest_current_value, compare_value, exchange_value, addr_base,\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.hpp","additions":12,"deletions":14,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -470,12 +470,4 @@\n-    if (VM_Version::has_isel()) {\n-      cmpdi(CR0, src, 0);\n-      Register co = encode_heap_oop_not_null(d, src);\n-      assert(co == d, \"sanity\");\n-      isel_0(d, CR0, Assembler::equal);\n-    } else {\n-      Label isNull;\n-      or_(d, src, src); \/\/ move and compare 0\n-      beq(CR0, isNull);\n-      encode_heap_oop_not_null(d, src);\n-      bind(isNull);\n-    }\n+    cmpdi(CR0, src, 0);\n+    Register co = encode_heap_oop_not_null(d, src);\n+    assert(co == d, \"sanity\");\n+    isel_0(d, CR0, Assembler::equal);\n@@ -513,5 +505,1 @@\n-    if (VM_Version::has_isel()) {\n-      use_isel = true;\n-    } else {\n-      beq(CR0, isNull);\n-    }\n+    use_isel = true;\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.inline.hpp","additions":5,"deletions":17,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -164,1 +164,0 @@\n-  \/\/ false means that conversion is done by runtime call\n@@ -168,1 +167,1 @@\n-    return VM_Version::has_fcfids();\n+    return true;\n","filename":"src\/hotspot\/cpu\/ppc\/matcher_ppc.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2068,1 +2068,0 @@\n-      return VM_Version::has_fsqrt();\n@@ -2070,1 +2069,0 @@\n-      return VM_Version::has_vsx();\n@@ -2079,1 +2077,1 @@\n-      return (UsePopCountInstruction && VM_Version::has_popcntw());\n+      return (UsePopCountInstruction);\n@@ -2083,1 +2081,0 @@\n-\n@@ -2926,0 +2923,10 @@\n+    \/\/ use isel instruction with Power 7\n+    cmpP_reg_imm16Node *n_compare  = new cmpP_reg_imm16Node();\n+    encodeP_subNode    *n_sub_base = new encodeP_subNode();\n+    encodeP_shiftNode  *n_shift    = new encodeP_shiftNode();\n+    cond_set_0_oopNode *n_cond_set = new cond_set_0_oopNode();\n+\n+    n_compare->add_req(n_region, n_src);\n+    n_compare->_opnds[0] = op_crx;\n+    n_compare->_opnds[1] = op_src;\n+    n_compare->_opnds[2] = new immL16Oper(0);\n@@ -2927,37 +2934,4 @@\n-    if (VM_Version::has_isel()) {\n-      \/\/ use isel instruction with Power 7\n-      cmpP_reg_imm16Node *n_compare  = new cmpP_reg_imm16Node();\n-      encodeP_subNode    *n_sub_base = new encodeP_subNode();\n-      encodeP_shiftNode  *n_shift    = new encodeP_shiftNode();\n-      cond_set_0_oopNode *n_cond_set = new cond_set_0_oopNode();\n-\n-      n_compare->add_req(n_region, n_src);\n-      n_compare->_opnds[0] = op_crx;\n-      n_compare->_opnds[1] = op_src;\n-      n_compare->_opnds[2] = new immL16Oper(0);\n-\n-      n_sub_base->add_req(n_region, n_src);\n-      n_sub_base->_opnds[0] = op_dst;\n-      n_sub_base->_opnds[1] = op_src;\n-      n_sub_base->_bottom_type = _bottom_type;\n-\n-      n_shift->add_req(n_region, n_sub_base);\n-      n_shift->_opnds[0] = op_dst;\n-      n_shift->_opnds[1] = op_dst;\n-      n_shift->_bottom_type = _bottom_type;\n-\n-      n_cond_set->add_req(n_region, n_compare, n_shift);\n-      n_cond_set->_opnds[0] = op_dst;\n-      n_cond_set->_opnds[1] = op_crx;\n-      n_cond_set->_opnds[2] = op_dst;\n-      n_cond_set->_bottom_type = _bottom_type;\n-\n-      ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n-      ra_->set_pair(n_sub_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_cond_set->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-\n-      nodes->push(n_compare);\n-      nodes->push(n_sub_base);\n-      nodes->push(n_shift);\n-      nodes->push(n_cond_set);\n+    n_sub_base->add_req(n_region, n_src);\n+    n_sub_base->_opnds[0] = op_dst;\n+    n_sub_base->_opnds[1] = op_src;\n+    n_sub_base->_bottom_type = _bottom_type;\n@@ -2965,40 +2939,20 @@\n-    } else {\n-      \/\/ before Power 7\n-      moveRegNode        *n_move     = new moveRegNode();\n-      cmpP_reg_imm16Node *n_compare  = new cmpP_reg_imm16Node();\n-      encodeP_shiftNode  *n_shift    = new encodeP_shiftNode();\n-      cond_sub_baseNode  *n_sub_base = new cond_sub_baseNode();\n-\n-      n_move->add_req(n_region, n_src);\n-      n_move->_opnds[0] = op_dst;\n-      n_move->_opnds[1] = op_src;\n-      ra_->set_oop(n_move, true); \/\/ Until here, 'n_move' still produces an oop.\n-\n-      n_compare->add_req(n_region, n_src);\n-      n_compare->add_prec(n_move);\n-\n-      n_compare->_opnds[0] = op_crx;\n-      n_compare->_opnds[1] = op_src;\n-      n_compare->_opnds[2] = new immL16Oper(0);\n-\n-      n_sub_base->add_req(n_region, n_compare, n_src);\n-      n_sub_base->_opnds[0] = op_dst;\n-      n_sub_base->_opnds[1] = op_crx;\n-      n_sub_base->_opnds[2] = op_src;\n-      n_sub_base->_bottom_type = _bottom_type;\n-\n-      n_shift->add_req(n_region, n_sub_base);\n-      n_shift->_opnds[0] = op_dst;\n-      n_shift->_opnds[1] = op_dst;\n-      n_shift->_bottom_type = _bottom_type;\n-\n-      ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n-      ra_->set_pair(n_sub_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_move->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-\n-      nodes->push(n_move);\n-      nodes->push(n_compare);\n-      nodes->push(n_sub_base);\n-      nodes->push(n_shift);\n-    }\n+    n_shift->add_req(n_region, n_sub_base);\n+    n_shift->_opnds[0] = op_dst;\n+    n_shift->_opnds[1] = op_dst;\n+    n_shift->_bottom_type = _bottom_type;\n+\n+    n_cond_set->add_req(n_region, n_compare, n_shift);\n+    n_cond_set->_opnds[0] = op_dst;\n+    n_cond_set->_opnds[1] = op_crx;\n+    n_cond_set->_opnds[2] = op_dst;\n+    n_cond_set->_bottom_type = _bottom_type;\n+\n+    ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n+    ra_->set_pair(n_sub_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    ra_->set_pair(n_cond_set->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+\n+    nodes->push(n_compare);\n+    nodes->push(n_sub_base);\n+    nodes->push(n_shift);\n+    nodes->push(n_cond_set);\n@@ -3044,23 +2998,6 @@\n-    if (VM_Version::has_isel()) {\n-      \/\/ use isel instruction with Power 7\n-\n-      decodeN_addNode *n_add_base = new decodeN_addNode();\n-      n_add_base->add_req(n_region, n_shift);\n-      n_add_base->_opnds[0] = op_dst;\n-      n_add_base->_opnds[1] = op_dst;\n-      n_add_base->_bottom_type = _bottom_type;\n-\n-      cond_set_0_ptrNode *n_cond_set = new cond_set_0_ptrNode();\n-      n_cond_set->add_req(n_region, n_compare, n_add_base);\n-      n_cond_set->_opnds[0] = op_dst;\n-      n_cond_set->_opnds[1] = op_crx;\n-      n_cond_set->_opnds[2] = op_dst;\n-      n_cond_set->_bottom_type = _bottom_type;\n-\n-      assert(ra_->is_oop(this) == true, \"A decodeN node must produce an oop!\");\n-      ra_->set_oop(n_cond_set, true);\n-\n-      ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n-      ra_->set_pair(n_add_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_cond_set->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    \/\/ use isel instruction with Power 7\n+    decodeN_addNode *n_add_base = new decodeN_addNode();\n+    n_add_base->add_req(n_region, n_shift);\n+    n_add_base->_opnds[0] = op_dst;\n+    n_add_base->_opnds[1] = op_dst;\n+    n_add_base->_bottom_type = _bottom_type;\n@@ -3068,8 +3005,6 @@\n-      nodes->push(n_compare);\n-      nodes->push(n_shift);\n-      nodes->push(n_add_base);\n-      nodes->push(n_cond_set);\n-\n-    } else {\n-      \/\/ before Power 7\n-      cond_add_baseNode *n_add_base = new cond_add_baseNode();\n+    cond_set_0_ptrNode *n_cond_set = new cond_set_0_ptrNode();\n+    n_cond_set->add_req(n_region, n_compare, n_add_base);\n+    n_cond_set->_opnds[0] = op_dst;\n+    n_cond_set->_opnds[1] = op_crx;\n+    n_cond_set->_opnds[2] = op_dst;\n+    n_cond_set->_bottom_type = _bottom_type;\n@@ -3077,5 +3012,2 @@\n-      n_add_base->add_req(n_region, n_compare, n_shift);\n-      n_add_base->_opnds[0] = op_dst;\n-      n_add_base->_opnds[1] = op_crx;\n-      n_add_base->_opnds[2] = op_dst;\n-      n_add_base->_bottom_type = _bottom_type;\n+    assert(ra_->is_oop(this) == true, \"A decodeN node must produce an oop!\");\n+    ra_->set_oop(n_cond_set, true);\n@@ -3083,2 +3015,4 @@\n-      assert(ra_->is_oop(this) == true, \"A decodeN node must produce an oop!\");\n-      ra_->set_oop(n_add_base, true);\n+    ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n+    ra_->set_pair(n_add_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    ra_->set_pair(n_cond_set->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n@@ -3086,3 +3020,4 @@\n-      ra_->set_pair(n_shift->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n-      ra_->set_pair(n_compare->_idx, ra_->get_reg_second(n_crx), ra_->get_reg_first(n_crx));\n-      ra_->set_pair(n_add_base->_idx, ra_->get_reg_second(this), ra_->get_reg_first(this));\n+    nodes->push(n_compare);\n+    nodes->push(n_shift);\n+    nodes->push(n_add_base);\n+    nodes->push(n_cond_set);\n@@ -3090,4 +3025,0 @@\n-      nodes->push(n_compare);\n-      nodes->push(n_shift);\n-      nodes->push(n_add_base);\n-    }\n@@ -6785,1 +6716,1 @@\n-            CompressedOops::base_disjoint() && VM_Version::has_isel());\n+            CompressedOops::base_disjoint());\n@@ -7165,1 +7096,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -7180,13 +7110,0 @@\n-instruct cmovI_reg(cmpOp cmp, flagsRegSrc crx, iRegIdst dst, iRegIsrc src) %{\n-  match(Set dst (CMoveI (Binary cmp crx) (Binary dst src)));\n-  predicate(!VM_Version::has_isel());\n-  ins_cost(DEFAULT_COST+BRANCH_COST);\n-\n-  ins_variable_size_depending_on_alignment(true);\n-\n-  format %{ \"CMOVE   $cmp, $crx, $dst, $src\\n\\t\" %}\n-  \/\/ Worst case is branch + move + stop, no stop without scheduler\n-  size(8);\n-  ins_encode( enc_cmove_reg(dst, crx, src, cmp) );\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7210,1 +7127,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -7225,13 +7141,1 @@\n-instruct cmovL_reg(cmpOp cmp, flagsRegSrc crx, iRegLdst dst, iRegLsrc src) %{\n-  match(Set dst (CMoveL (Binary cmp crx) (Binary dst src)));\n-  predicate(!VM_Version::has_isel());\n-  ins_cost(DEFAULT_COST+BRANCH_COST);\n-\n-  ins_variable_size_depending_on_alignment(true);\n-\n-  format %{ \"CMOVE   $cmp, $crx, $dst, $src\\n\\t\" %}\n-  \/\/ Worst case is branch + move + stop, no stop without scheduler.\n-  size(8);\n-  ins_encode( enc_cmove_reg(dst, crx, src, cmp) );\n-  ins_pipe(pipe_class_default);\n-%}\n+ \n@@ -7255,1 +7159,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -7270,7 +7173,0 @@\n-\/\/ Conditional move for RegN. Only cmov(reg, reg).\n-instruct cmovN_reg(cmpOp cmp, flagsRegSrc crx, iRegNdst dst, iRegNsrc src) %{\n-  match(Set dst (CMoveN (Binary cmp crx) (Binary dst src)));\n-  predicate(!VM_Version::has_isel());\n-  ins_cost(DEFAULT_COST+BRANCH_COST);\n-\n-  ins_variable_size_depending_on_alignment(true);\n@@ -7278,6 +7174,0 @@\n-  format %{ \"CMOVE   $cmp, $crx, $dst, $src\\n\\t\" %}\n-  \/\/ Worst case is branch + move + stop, no stop without scheduler.\n-  size(8);\n-  ins_encode( enc_cmove_reg(dst, crx, src, cmp) );\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7301,1 +7191,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -7316,13 +7205,0 @@\n-instruct cmovP_reg(cmpOp cmp, flagsRegSrc crx, iRegPdst dst, iRegP_N2P src) %{\n-  match(Set dst (CMoveP (Binary cmp crx) (Binary dst src)));\n-  predicate(!VM_Version::has_isel());\n-  ins_cost(DEFAULT_COST+BRANCH_COST);\n-\n-  ins_variable_size_depending_on_alignment(true);\n-\n-  format %{ \"CMOVE   $cmp, $crx, $dst, $src\\n\\t\" %}\n-  \/\/ Worst case is branch + move + stop, no stop without scheduler.\n-  size(8);\n-  ins_encode( enc_cmove_reg(dst, crx, src, cmp) );\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7393,1 +7269,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -7398,1 +7273,1 @@\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7410,18 +7285,0 @@\n-instruct compareAndSwapB4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndSwapB mem_ptr (Binary src1 src2)));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"CMPXCHGB $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                $res$$Register, nullptr, true);\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7431,1 +7288,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -7436,1 +7292,1 @@\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7448,18 +7304,0 @@\n-instruct compareAndSwapS4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndSwapS mem_ptr (Binary src1 src2)));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"CMPXCHGH $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                $res$$Register, nullptr, true);\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7545,1 +7383,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && VM_Version::has_lqarx());\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n@@ -7550,1 +7388,1 @@\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7557,13 +7395,0 @@\n-instruct weakCompareAndSwapB4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (WeakCompareAndSwapB mem_ptr (Binary src1 src2)));\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"weak CMPXCHGB $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                MacroAssembler::MemBarNone,\n-                MacroAssembler::cmpxchgx_hint_atomic_update(), $res$$Register, nullptr, true, \/*weak*\/ true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7573,1 +7398,1 @@\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && VM_Version::has_lqarx());\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) );\n@@ -7578,1 +7403,1 @@\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7585,13 +7410,0 @@\n-instruct weakCompareAndSwapB4_acq_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (WeakCompareAndSwapB mem_ptr (Binary src1 src2)));\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"weak CMPXCHGB acq $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgb(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                support_IRIW_for_not_multiple_copy_atomic_cpu ? MacroAssembler::MemBarAcq : MacroAssembler::MemBarFenceAfter,\n-                MacroAssembler::cmpxchgx_hint_atomic_update(), $res$$Register, nullptr, true, \/*weak*\/ true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7601,1 +7413,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && VM_Version::has_lqarx());\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n@@ -7606,1 +7418,1 @@\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7613,13 +7425,0 @@\n-instruct weakCompareAndSwapS4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (WeakCompareAndSwapS mem_ptr (Binary src1 src2)));\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"weak CMPXCHGH $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                MacroAssembler::MemBarNone,\n-                MacroAssembler::cmpxchgx_hint_atomic_update(), $res$$Register, nullptr, true, \/*weak*\/ true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7629,1 +7428,1 @@\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && VM_Version::has_lqarx());\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) );\n@@ -7634,1 +7433,1 @@\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7641,13 +7440,0 @@\n-instruct weakCompareAndSwapS4_acq_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, iRegIdst tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (WeakCompareAndSwapS mem_ptr (Binary src1 src2)));\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0); \/\/ TEMP_DEF to avoid jump\n-  format %{ \"weak CMPXCHGH acq $res, $mem_ptr, $src1, $src2; as bool\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgh(CR0, R0, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, $tmp2$$Register,\n-                support_IRIW_for_not_multiple_copy_atomic_cpu ? MacroAssembler::MemBarAcq : MacroAssembler::MemBarFenceAfter,\n-                MacroAssembler::cmpxchgx_hint_atomic_update(), $res$$Register, nullptr, true, \/*weak*\/ true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7780,1 +7566,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && VM_Version::has_lqarx());\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n@@ -7785,1 +7571,1 @@\n-    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7792,13 +7578,0 @@\n-instruct compareAndExchangeB4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndExchangeB mem_ptr (Binary src1 src2)));\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP cr0);\n-  format %{ \"CMPXCHGB $res, $mem_ptr, $src1, $src2; as int\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, R0,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                noreg, nullptr, true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7808,1 +7581,1 @@\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && VM_Version::has_lqarx());\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) );\n@@ -7813,1 +7586,1 @@\n-    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7826,19 +7599,0 @@\n-instruct compareAndExchangeB4_acq_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndExchangeB mem_ptr (Binary src1 src2)));\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP cr0);\n-  format %{ \"CMPXCHGB acq $res, $mem_ptr, $src1, $src2; as int\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgb(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, R0,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                noreg, nullptr, true);\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7848,1 +7602,1 @@\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && VM_Version::has_lqarx());\n+  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst);\n@@ -7853,1 +7607,1 @@\n-    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7860,13 +7614,0 @@\n-instruct compareAndExchangeS4_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndExchangeS mem_ptr (Binary src1 src2)));\n-  predicate(((CompareAndSwapNode*)n)->order() != MemNode::acquire && ((CompareAndSwapNode*)n)->order() != MemNode::seqcst && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP cr0);\n-  format %{ \"CMPXCHGH $res, $mem_ptr, $src1, $src2; as int\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, R0,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                noreg, nullptr, true);\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -7876,1 +7617,1 @@\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && VM_Version::has_lqarx());\n+  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) );\n@@ -7881,1 +7622,1 @@\n-    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, noreg, noreg,\n+    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register,\n@@ -7894,19 +7635,0 @@\n-instruct compareAndExchangeS4_acq_regP_regI_regI(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src1, rarg4RegI src2, iRegIdst tmp1, flagsRegCR0 cr0) %{\n-  match(Set res (CompareAndExchangeS mem_ptr (Binary src1 src2)));\n-  predicate((((CompareAndSwapNode*)n)->order() == MemNode::acquire || ((CompareAndSwapNode*)n)->order() == MemNode::seqcst) && !VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL src2, USE_KILL mem_ptr, TEMP tmp1, TEMP cr0);\n-  format %{ \"CMPXCHGH acq $res, $mem_ptr, $src1, $src2; as int\" %}\n-  ins_encode %{\n-    \/\/ CmpxchgX sets CR0 to cmpX(src1, src2) and Rres to 'true'\/'false'.\n-    __ cmpxchgh(CR0, $res$$Register, $src1$$Register, $src2$$Register, $mem_ptr$$Register, $tmp1$$Register, R0,\n-                MacroAssembler::MemBarNone, MacroAssembler::cmpxchgx_hint_atomic_update(),\n-                noreg, nullptr, true);\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      \/\/ isync would be sufficient in case of CompareAndExchangeAcquire, but we currently don't optimize for that.\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -8056,1 +7778,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -8071,16 +7792,0 @@\n-instruct getAndAddB4(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src, iRegIsrc tmp1, iRegIsrc tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (GetAndAddB mem_ptr src));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0);\n-  format %{ \"GetAndAddB $res, $mem_ptr, $src\" %}\n-  ins_encode %{\n-    __ getandaddb($res$$Register, $src$$Register, $mem_ptr$$Register,\n-                  R0, $tmp1$$Register, $tmp2$$Register, MacroAssembler::cmpxchgx_hint_atomic_update());\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -8090,1 +7795,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -8105,16 +7809,0 @@\n-instruct getAndAddS4(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src, iRegIsrc tmp1, iRegIsrc tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (GetAndAddS mem_ptr src));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0);\n-  format %{ \"GetAndAddS $res, $mem_ptr, $src\" %}\n-  ins_encode %{\n-    __ getandaddh($res$$Register, $src$$Register, $mem_ptr$$Register,\n-                  R0, $tmp1$$Register, $tmp2$$Register, MacroAssembler::cmpxchgx_hint_atomic_update());\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -8156,1 +7844,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -8171,17 +7858,0 @@\n-instruct getAndSetB4(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src, iRegIsrc tmp1, iRegIsrc tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (GetAndSetB mem_ptr src));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0);\n-  format %{ \"GetAndSetB $res, $mem_ptr, $src\" %}\n-  ins_encode %{\n-    __ getandsetb($res$$Register, $src$$Register, $mem_ptr$$Register,\n-                  R0, $tmp1$$Register, $tmp2$$Register, MacroAssembler::cmpxchgx_hint_atomic_update());\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n@@ -8190,1 +7860,0 @@\n-  predicate(VM_Version::has_lqarx());\n@@ -8205,16 +7874,0 @@\n-instruct getAndSetS4(iRegIdst res, rarg3RegP mem_ptr, iRegIsrc src, iRegIsrc tmp1, iRegIsrc tmp2, flagsRegCR0 cr0) %{\n-  match(Set res (GetAndSetS mem_ptr src));\n-  predicate(!VM_Version::has_lqarx());\n-  effect(TEMP_DEF res, USE_KILL mem_ptr, TEMP tmp1, TEMP tmp2, TEMP cr0);\n-  format %{ \"GetAndSetS $res, $mem_ptr, $src\" %}\n-  ins_encode %{\n-    __ getandseth($res$$Register, $src$$Register, $mem_ptr$$Register,\n-                  R0, $tmp1$$Register, $tmp2$$Register, MacroAssembler::cmpxchgx_hint_atomic_update());\n-    if (support_IRIW_for_not_multiple_copy_atomic_cpu) {\n-      __ isync();\n-    } else {\n-      __ sync();\n-    }\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n@@ -9509,1 +9162,0 @@\n-\/\/ VM_Version::has_fsqrt() decides if this node will be used.\n@@ -9524,1 +9176,0 @@\n-  predicate(VM_Version::has_fsqrts());\n@@ -10048,1 +9699,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -10736,1 +10386,0 @@\n-  predicate(!VM_Version::has_mtfprd());\n@@ -10753,1 +10402,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -10781,1 +10429,0 @@\n-  predicate(!VM_Version::has_mtfprd());\n@@ -10798,1 +10445,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -10994,1 +10640,0 @@\n-  predicate(!VM_Version::has_mtfprd());\n@@ -11011,1 +10656,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -11039,1 +10683,0 @@\n-  predicate(!VM_Version::has_mtfprd());\n@@ -11056,1 +10699,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -11098,1 +10740,0 @@\n-  predicate(!VM_Version::has_fcfids());\n@@ -11130,1 +10771,0 @@\n-  predicate(VM_Version::has_fcfids() && !VM_Version::has_mtfprd());\n@@ -11147,1 +10787,0 @@\n-  predicate(VM_Version::has_fcfids() && VM_Version::has_mtfprd());\n@@ -11160,1 +10799,0 @@\n-  predicate(VM_Version::has_fcfids() && !VM_Version::has_mtfprd());\n@@ -11175,1 +10813,0 @@\n-  predicate(VM_Version::has_fcfids() && VM_Version::has_mtfprd());\n@@ -11193,1 +10830,0 @@\n-  predicate(!VM_Version::has_mtfprd());\n@@ -11210,1 +10846,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -11235,1 +10870,0 @@\n-  predicate(VM_Version::has_mtfprd());\n@@ -12853,1 +12487,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -12886,1 +12519,0 @@\n-  predicate(VM_Version::has_isel());\n@@ -12901,1 +12533,1 @@\n-  predicate(UsePopCountInstruction && VM_Version::has_popcntw());\n+  predicate(UsePopCountInstruction);\n@@ -12914,1 +12546,1 @@\n-  predicate(UsePopCountInstruction && VM_Version::has_popcntw());\n+  predicate(UsePopCountInstruction);\n@@ -13273,1 +12905,1 @@\n-  predicate(VM_Version::has_ldbrx() && (n->in(1)->as_Load()->is_unordered() || followed_by_acquire(n->in(1))));\n+  predicate((n->in(1)->as_Load()->is_unordered() || followed_by_acquire(n->in(1))));\n@@ -13285,1 +12917,0 @@\n-  predicate(VM_Version::has_ldbrx());\n@@ -13366,1 +12997,0 @@\n-  predicate(VM_Version::has_stdbrx());\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":80,"deletions":450,"binary":false,"changes":530,"status":"modified"},{"patch":"@@ -812,4 +812,2 @@\n-    if (VM_Version::has_mfdscr()) {\n-      __ load_const_optimized(tmp1, VM_Version::_dscr_val);\n-      __ mtdscr(tmp1);\n-    }\n+    __ load_const_optimized(tmp1, VM_Version::_dscr_val);\n+    __ mtdscr(tmp1);\n@@ -927,1 +925,0 @@\n-       if (!VM_Version::has_vsx()) {\n@@ -945,36 +942,0 @@\n-      } else { \/\/ Processor supports VSX, so use it to mass copy.\n-\n-        \/\/ Prefetch the data into the L2 cache.\n-        __ dcbt(R3_ARG1, 0);\n-\n-        \/\/ If supported set DSCR pre-fetch to deepest.\n-        if (VM_Version::has_mfdscr()) {\n-          __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-          __ mtdscr(tmp2);\n-        }\n-\n-        __ li(tmp1, 16);\n-\n-        \/\/ Backbranch target aligned to 32-byte. Not 16-byte align as\n-        \/\/ loop contains < 8 instructions that fit inside a single\n-        \/\/ i-cache sector.\n-        __ align(32);\n-\n-        __ bind(l_10);\n-        \/\/ Use loop with VSX load\/store instructions to\n-        \/\/ copy 32 elements a time.\n-        __ lxvd2x(tmp_vsr1, R3_ARG1);        \/\/ Load src\n-        __ stxvd2x(tmp_vsr1, R4_ARG2);       \/\/ Store to dst\n-        __ lxvd2x(tmp_vsr2, tmp1, R3_ARG1);  \/\/ Load src + 16\n-        __ stxvd2x(tmp_vsr2, tmp1, R4_ARG2); \/\/ Store to dst + 16\n-        __ addi(R3_ARG1, R3_ARG1, 32);       \/\/ Update src+=32\n-        __ addi(R4_ARG2, R4_ARG2, 32);       \/\/ Update dsc+=32\n-        __ bdnz(l_10);                       \/\/ Dec CTR and loop if not zero.\n-\n-        \/\/ Restore DSCR pre-fetch value.\n-        if (VM_Version::has_mfdscr()) {\n-          __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n-          __ mtdscr(tmp2);\n-        }\n-\n-      } \/\/ VSX\n@@ -1223,51 +1184,0 @@\n-        if (!VM_Version::has_vsx()) {\n-\n-          __ bind(l_8);\n-          \/\/ Use unrolled version for mass copying (copy 16 elements a time).\n-          \/\/ Load feeding store gets zero latency on Power6, however not on Power5.\n-          \/\/ Therefore, the following sequence is made for the good of both.\n-          __ ld(tmp1, 0, R3_ARG1);\n-          __ ld(tmp2, 8, R3_ARG1);\n-          __ ld(tmp3, 16, R3_ARG1);\n-          __ ld(tmp4, 24, R3_ARG1);\n-          __ std(tmp1, 0, R4_ARG2);\n-          __ std(tmp2, 8, R4_ARG2);\n-          __ std(tmp3, 16, R4_ARG2);\n-          __ std(tmp4, 24, R4_ARG2);\n-          __ addi(R3_ARG1, R3_ARG1, 32);\n-          __ addi(R4_ARG2, R4_ARG2, 32);\n-          __ bdnz(l_8);\n-\n-        } else { \/\/ Processor supports VSX, so use it to mass copy.\n-\n-          \/\/ Prefetch src data into L2 cache.\n-          __ dcbt(R3_ARG1, 0);\n-\n-          \/\/ If supported set DSCR pre-fetch to deepest.\n-          if (VM_Version::has_mfdscr()) {\n-            __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-            __ mtdscr(tmp2);\n-          }\n-          __ li(tmp1, 16);\n-\n-          \/\/ Backbranch target aligned to 32-byte. It's not aligned 16-byte\n-          \/\/ as loop contains < 8 instructions that fit inside a single\n-          \/\/ i-cache sector.\n-          __ align(32);\n-\n-          __ bind(l_9);\n-          \/\/ Use loop with VSX load\/store instructions to\n-          \/\/ copy 16 elements a time.\n-          __ lxvd2x(tmp_vsr1, R3_ARG1);        \/\/ Load from src.\n-          __ stxvd2x(tmp_vsr1, R4_ARG2);       \/\/ Store to dst.\n-          __ lxvd2x(tmp_vsr2, R3_ARG1, tmp1);  \/\/ Load from src + 16.\n-          __ stxvd2x(tmp_vsr2, R4_ARG2, tmp1); \/\/ Store to dst + 16.\n-          __ addi(R3_ARG1, R3_ARG1, 32);       \/\/ Update src+=32.\n-          __ addi(R4_ARG2, R4_ARG2, 32);       \/\/ Update dsc+=32.\n-          __ bdnz(l_9);                        \/\/ Dec CTR and loop if not zero.\n-\n-          \/\/ Restore DSCR pre-fetch value.\n-          if (VM_Version::has_mfdscr()) {\n-            __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n-            __ mtdscr(tmp2);\n-          }\n@@ -1275,1 +1185,16 @@\n-        }\n+        __ bind(l_8);\n+        \/\/ Use unrolled version for mass copying (copy 16 elements a time).\n+        \/\/ Load feeding store gets zero latency on Power6, however not on Power5.\n+        \/\/ Therefore, the following sequence is made for the good of both.\n+        __ ld(tmp1, 0, R3_ARG1);\n+        __ ld(tmp2, 8, R3_ARG1);\n+        __ ld(tmp3, 16, R3_ARG1);\n+        __ ld(tmp4, 24, R3_ARG1);\n+        __ std(tmp1, 0, R4_ARG2);\n+        __ std(tmp2, 8, R4_ARG2);\n+        __ std(tmp3, 16, R4_ARG2);\n+        __ std(tmp4, 24, R4_ARG2);\n+        __ addi(R3_ARG1, R3_ARG1, 32);\n+        __ addi(R4_ARG2, R4_ARG2, 32);\n+        __ bdnz(l_8);\n+\n@@ -1430,1 +1355,1 @@\n-     if (!VM_Version::has_vsx()) {\n+    \/\/ Processor supports VSX, so use it to mass copy.\n@@ -1432,17 +1357,2 @@\n-      __ bind(l_6);\n-      \/\/ Use unrolled version for mass copying (copy 8 elements a time).\n-      \/\/ Load feeding store gets zero latency on power6, however not on power 5.\n-      \/\/ Therefore, the following sequence is made for the good of both.\n-      __ ld(tmp1, 0, R3_ARG1);\n-      __ ld(tmp2, 8, R3_ARG1);\n-      __ ld(tmp3, 16, R3_ARG1);\n-      __ ld(tmp4, 24, R3_ARG1);\n-      __ std(tmp1, 0, R4_ARG2);\n-      __ std(tmp2, 8, R4_ARG2);\n-      __ std(tmp3, 16, R4_ARG2);\n-      __ std(tmp4, 24, R4_ARG2);\n-      __ addi(R3_ARG1, R3_ARG1, 32);\n-      __ addi(R4_ARG2, R4_ARG2, 32);\n-      __ bdnz(l_6);\n-\n-    } else { \/\/ Processor supports VSX, so use it to mass copy.\n+    \/\/ Prefetch the data into the L2 cache.\n+    __ dcbt(R3_ARG1, 0);\n@@ -1450,2 +1360,3 @@\n-      \/\/ Prefetch the data into the L2 cache.\n-      __ dcbt(R3_ARG1, 0);\n+    \/\/ If supported set DSCR pre-fetch to deepest.\n+    __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n+    __ mtdscr(tmp2);\n@@ -1453,5 +1364,1 @@\n-      \/\/ If supported set DSCR pre-fetch to deepest.\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-        __ mtdscr(tmp2);\n-      }\n+    __ li(tmp1, 16);\n@@ -1459,1 +1366,4 @@\n-      __ li(tmp1, 16);\n+    \/\/ Backbranch target aligned to 32-byte. Not 16-byte align as\n+    \/\/ loop contains < 8 instructions that fit inside a single\n+    \/\/ i-cache sector.\n+    __ align(32);\n@@ -1461,4 +1371,10 @@\n-      \/\/ Backbranch target aligned to 32-byte. Not 16-byte align as\n-      \/\/ loop contains < 8 instructions that fit inside a single\n-      \/\/ i-cache sector.\n-      __ align(32);\n+    __ bind(l_7);\n+    \/\/ Use loop with VSX load\/store instructions to\n+    \/\/ copy 8 elements a time.\n+    __ lxvd2x(tmp_vsr1, R3_ARG1);        \/\/ Load src\n+    __ stxvd2x(tmp_vsr1, R4_ARG2);       \/\/ Store to dst\n+    __ lxvd2x(tmp_vsr2, tmp1, R3_ARG1);  \/\/ Load src + 16\n+    __ stxvd2x(tmp_vsr2, tmp1, R4_ARG2); \/\/ Store to dst + 16\n+    __ addi(R3_ARG1, R3_ARG1, 32);       \/\/ Update src+=32\n+    __ addi(R4_ARG2, R4_ARG2, 32);       \/\/ Update dsc+=32\n+    __ bdnz(l_7);                        \/\/ Dec CTR and loop if not zero.\n@@ -1466,10 +1382,3 @@\n-      __ bind(l_7);\n-      \/\/ Use loop with VSX load\/store instructions to\n-      \/\/ copy 8 elements a time.\n-      __ lxvd2x(tmp_vsr1, R3_ARG1);        \/\/ Load src\n-      __ stxvd2x(tmp_vsr1, R4_ARG2);       \/\/ Store to dst\n-      __ lxvd2x(tmp_vsr2, tmp1, R3_ARG1);  \/\/ Load src + 16\n-      __ stxvd2x(tmp_vsr2, tmp1, R4_ARG2); \/\/ Store to dst + 16\n-      __ addi(R3_ARG1, R3_ARG1, 32);       \/\/ Update src+=32\n-      __ addi(R4_ARG2, R4_ARG2, 32);       \/\/ Update dsc+=32\n-      __ bdnz(l_7);                        \/\/ Dec CTR and loop if not zero.\n+    \/\/ Restore DSCR pre-fetch value.\n+    __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n+    __ mtdscr(tmp2);\n@@ -1477,5 +1386,0 @@\n-      \/\/ Restore DSCR pre-fetch value.\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n-        __ mtdscr(tmp2);\n-      }\n@@ -1483,1 +1387,0 @@\n-    } \/\/ VSX\n@@ -1598,17 +1501,1 @@\n-     if (!VM_Version::has_vsx()) {\n-      __ bind(l_4);\n-      \/\/ Use unrolled version for mass copying (copy 4 elements a time).\n-      \/\/ Load feeding store gets zero latency on Power6, however not on Power5.\n-      \/\/ Therefore, the following sequence is made for the good of both.\n-      __ addi(R3_ARG1, R3_ARG1, -32);\n-      __ addi(R4_ARG2, R4_ARG2, -32);\n-      __ ld(tmp4, 24, R3_ARG1);\n-      __ ld(tmp3, 16, R3_ARG1);\n-      __ ld(tmp2, 8, R3_ARG1);\n-      __ ld(tmp1, 0, R3_ARG1);\n-      __ std(tmp4, 24, R4_ARG2);\n-      __ std(tmp3, 16, R4_ARG2);\n-      __ std(tmp2, 8, R4_ARG2);\n-      __ std(tmp1, 0, R4_ARG2);\n-      __ bdnz(l_4);\n-     } else {  \/\/ Processor supports VSX, so use it to mass copy.\n+      \/\/ Processor supports VSX, so use it to mass copy.\n@@ -1618,5 +1505,3 @@\n-      \/\/ If supported set DSCR pre-fetch to deepest.\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-        __ mtdscr(tmp2);\n-      }\n+      \/\/ Set DSCR pre-fetch to deepest.\n+      __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n+      __ mtdscr(tmp2);\n@@ -1643,1 +1528,0 @@\n-      if (VM_Version::has_mfdscr()) {\n@@ -1646,2 +1530,0 @@\n-      }\n-     }\n@@ -1734,18 +1616,1 @@\n-    if (!VM_Version::has_vsx()) {\n-      __ bind(l_4);\n-      \/\/ Use unrolled version for mass copying (copy 4 elements a time).\n-      \/\/ Load feeding store gets zero latency on Power6, however not on Power5.\n-      \/\/ Therefore, the following sequence is made for the good of both.\n-      __ ld(tmp1, 0, R3_ARG1);\n-      __ ld(tmp2, 8, R3_ARG1);\n-      __ ld(tmp3, 16, R3_ARG1);\n-      __ ld(tmp4, 24, R3_ARG1);\n-      __ std(tmp1, 0, R4_ARG2);\n-      __ std(tmp2, 8, R4_ARG2);\n-      __ std(tmp3, 16, R4_ARG2);\n-      __ std(tmp4, 24, R4_ARG2);\n-      __ addi(R3_ARG1, R3_ARG1, 32);\n-      __ addi(R4_ARG2, R4_ARG2, 32);\n-      __ bdnz(l_4);\n-\n-    } else { \/\/ Processor supports VSX, so use it to mass copy.\n+      \/\/ Processor supports VSX, so use it to mass copy.\n@@ -1756,5 +1621,3 @@\n-      \/\/ If supported set DSCR pre-fetch to deepest.\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-        __ mtdscr(tmp2);\n-      }\n+      \/\/ Set DSCR pre-fetch to deepest.\n+      __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n+      __ mtdscr(tmp2);\n@@ -1781,4 +1644,2 @@\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n-        __ mtdscr(tmp2);\n-      }\n+      __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n+      __ mtdscr(tmp2);\n@@ -1786,1 +1647,0 @@\n-    } \/\/ VSX\n@@ -1879,17 +1739,1 @@\n-     if (!VM_Version::has_vsx()) {\n-      __ bind(l_4);\n-      \/\/ Use unrolled version for mass copying (copy 4 elements a time).\n-      \/\/ Load feeding store gets zero latency on Power6, however not on Power5.\n-      \/\/ Therefore, the following sequence is made for the good of both.\n-      __ addi(R3_ARG1, R3_ARG1, -32);\n-      __ addi(R4_ARG2, R4_ARG2, -32);\n-      __ ld(tmp4, 24, R3_ARG1);\n-      __ ld(tmp3, 16, R3_ARG1);\n-      __ ld(tmp2, 8, R3_ARG1);\n-      __ ld(tmp1, 0, R3_ARG1);\n-      __ std(tmp4, 24, R4_ARG2);\n-      __ std(tmp3, 16, R4_ARG2);\n-      __ std(tmp2, 8, R4_ARG2);\n-      __ std(tmp1, 0, R4_ARG2);\n-      __ bdnz(l_4);\n-     } else { \/\/ Processor supports VSX, so use it to mass copy.\n+      \/\/ Processor supports VSX, so use it to mass copy.\n@@ -1899,5 +1743,3 @@\n-      \/\/ If supported set DSCR pre-fetch to deepest.\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n-        __ mtdscr(tmp2);\n-      }\n+      \/\/ Set DSCR pre-fetch to deepest.\n+      __ load_const_optimized(tmp2, VM_Version::_dscr_val | 7);\n+      __ mtdscr(tmp2);\n@@ -1924,5 +1766,2 @@\n-      if (VM_Version::has_mfdscr()) {\n-        __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n-        __ mtdscr(tmp2);\n-      }\n-     }\n+      __ load_const_optimized(tmp2, VM_Version::_dscr_val);\n+      __ mtdscr(tmp2);\n","filename":"src\/hotspot\/cpu\/ppc\/stubGenerator_ppc.cpp","additions":58,"deletions":219,"binary":false,"changes":277,"status":"modified"},{"patch":"@@ -83,1 +83,0 @@\n-  const bool use_vector = VM_Version::has_vpmsumb();\n@@ -86,1 +85,1 @@\n-  const int size = use_vector ? CRC32_TABLE_SIZE + vector_size : (4 BIG_ENDIAN_ONLY(+1)) * CRC32_TABLE_SIZE;\n+  const int size = CRC32_TABLE_SIZE + vector_size;\n@@ -94,37 +93,2 @@\n-  LITTLE_ENDIAN_ONLY(if (use_vector)) {\n-    for (int i = 0; i < 256; ++i) {\n-      ptr[i] = fold_byte(i, reverse_poly);\n-    }\n-  }\n-\n-  if (!use_vector) {\n-    BIG_ENDIAN_ONLY(ptr = (juint*)(consts + CRC32_TABLE_SIZE);)\n-    \/\/ <= Power7: 4 tables\n-    for (int i = 0; i < 256; ++i) {\n-      juint a = fold_byte(i, reverse_poly),\n-            b = fold_byte(a, reverse_poly),\n-            c = fold_byte(b, reverse_poly),\n-            d = fold_byte(c, reverse_poly);\n-#ifndef VM_LITTLE_ENDIAN\n-      a = byteswap(a);\n-      b = byteswap(b);\n-      c = byteswap(c);\n-      d = byteswap(d);\n-#endif\n-      ptr[i         ] = a;\n-      ptr[i +    256] = b;\n-      ptr[i + 2* 256] = c;\n-      ptr[i + 3* 256] = d;\n-    }\n-#if 0\n-    for (int i = 0; i < 4; ++i) {\n-      tty->print_cr(\"table %d:\", i);\n-      for (int j = 0; j < 32; ++j) {\n-        for (int k = 0; k < 8; ++k) {\n-          tty->print(\"%08x \", ptr[i*256 + j*8 + k]);\n-        }\n-        tty->cr();\n-      }\n-    }\n-#endif\n-    return consts;\n+  for (int i = 0; i < 256; ++i) {\n+    ptr[i] = fold_byte(i, reverse_poly);\n","filename":"src\/hotspot\/cpu\/ppc\/stubRoutines_ppc_64.cpp","additions":3,"deletions":39,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -1080,1 +1080,1 @@\n-    case Interpreter::java_lang_math_sqrt: use_instruction = VM_Version::has_fsqrt(); break;\n+    case Interpreter::java_lang_math_sqrt: use_instruction = true; break;\n","filename":"src\/hotspot\/cpu\/ppc\/templateInterpreterGenerator_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -322,8 +322,1 @@\n-  if (VM_Version::has_isel()) {\n-    __ isel_0(R17_tos, CR0, Assembler::equal);\n-  } else {\n-    Label not_sentinel;\n-    __ bne(CR0, not_sentinel);\n-    __ li(R17_tos, 0);\n-    __ bind(not_sentinel);\n-  }\n+  __ isel_0(R17_tos, CR0, Assembler::equal);\n@@ -1537,7 +1530,1 @@\n-      if (VM_Version::has_fcfids()) { \/\/ fcfids is >= Power7 only\n-        \/\/ Comment: alternatively, load with sign extend could be done by lfiwax.\n-        __ fcfids(F15_ftos, F15_ftos);\n-      } else {\n-        __ fcfid(F15_ftos, F15_ftos);\n-        __ frsp(F15_ftos, F15_ftos);\n-      }\n+      __ fcfids(F15_ftos, F15_ftos);\n@@ -1547,9 +1534,2 @@\n-      if (VM_Version::has_fcfids()) { \/\/ fcfids is >= Power7 only\n-        __ move_l_to_d();\n-        __ fcfids(F15_ftos, F15_ftos);\n-      } else {\n-        \/\/ Avoid rounding problem when result should be 0x3f800001: need fixup code before fcfid+frsp.\n-        __ mr(R3_ARG1, R17_tos);\n-        __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::l2f));\n-        __ fmr(F15_ftos, F1_RET);\n-      }\n+      __ move_l_to_d();\n+      __ fcfids(F15_ftos, F15_ftos);\n","filename":"src\/hotspot\/cpu\/ppc\/templateTable_ppc_64.cpp","additions":4,"deletions":24,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -67,8 +67,0 @@\n-    } else if (VM_Version::has_lqarx()) {\n-      FLAG_SET_ERGO(PowerArchitecturePPC64, 8);\n-    } else if (VM_Version::has_popcntw()) {\n-      FLAG_SET_ERGO(PowerArchitecturePPC64, 7);\n-    } else if (VM_Version::has_cmpb()) {\n-      FLAG_SET_ERGO(PowerArchitecturePPC64, 6);\n-    } else if (VM_Version::has_popcntb()) {\n-      FLAG_SET_ERGO(PowerArchitecturePPC64, 5);\n@@ -84,4 +76,0 @@\n-    case  8: if (!VM_Version::has_lqarx()  ) break;\n-    case  7: if (!VM_Version::has_popcntw()) break;\n-    case  6: if (!VM_Version::has_cmpb()   ) break;\n-    case  5: if (!VM_Version::has_popcntb()) break;\n@@ -95,3 +83,1 @@\n-  if (PowerArchitecturePPC64 >= 8 && has_mfdscr()) {\n-    config_dscr();\n-  }\n+  config_dscr();\n@@ -112,8 +98,1 @@\n-  \/\/ Power7 and later.\n-  if (PowerArchitecturePPC64 > 6) {\n-    if (FLAG_IS_DEFAULT(UsePopCountInstruction)) {\n-      FLAG_SET_ERGO(UsePopCountInstruction, true);\n-    }\n-  }\n-\n-  if (!VM_Version::has_isel() && FLAG_IS_DEFAULT(ConditionalMoveLimit)) {\n+  if (FLAG_IS_DEFAULT(ConditionalMoveLimit)) {\n@@ -123,14 +102,2 @@\n-  if (PowerArchitecturePPC64 >= 8) {\n-    if (FLAG_IS_DEFAULT(SuperwordUseVSX)) {\n-      FLAG_SET_ERGO(SuperwordUseVSX, true);\n-    }\n-  } else {\n-    if (SuperwordUseVSX) {\n-      warning(\"SuperwordUseVSX specified, but needs at least Power8.\");\n-      FLAG_SET_DEFAULT(SuperwordUseVSX, false);\n-    }\n-  }\n-  MaxVectorSize = SuperwordUseVSX ? 16 : 8;\n-  if (FLAG_IS_DEFAULT(AlignVector)) {\n-    FLAG_SET_ERGO(AlignVector, false);\n-  }\n+\n+  MaxVectorSize = 16;\n@@ -145,7 +112,2 @@\n-    if (SuperwordUseVSX) {\n-      if (FLAG_IS_DEFAULT(UseVectorByteReverseInstructionsPPC64)) {\n-        FLAG_SET_ERGO(UseVectorByteReverseInstructionsPPC64, true);\n-      }\n-    } else if (UseVectorByteReverseInstructionsPPC64) {\n-      warning(\"UseVectorByteReverseInstructionsPPC64 specified, but needs SuperwordUseVSX.\");\n-      FLAG_SET_DEFAULT(UseVectorByteReverseInstructionsPPC64, false);\n+    if (FLAG_IS_DEFAULT(UseVectorByteReverseInstructionsPPC64)) {\n+      FLAG_SET_ERGO(UseVectorByteReverseInstructionsPPC64, true);\n@@ -201,3 +163,1 @@\n-               \"ppc64%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s\",\n-               (has_fsqrt()   ? \" fsqrt\"   : \"\"),\n-               (has_isel()    ? \" isel\"    : \"\"),\n+               \"ppc64%s%s%s%s\",\n@@ -205,12 +165,0 @@\n-               (has_cmpb()    ? \" cmpb\"    : \"\"),\n-               (has_popcntb() ? \" popcntb\" : \"\"),\n-               (has_popcntw() ? \" popcntw\" : \"\"),\n-               (has_fcfids()  ? \" fcfids\"  : \"\"),\n-               (has_vand()    ? \" vand\"    : \"\"),\n-               (has_lqarx()   ? \" lqarx\"   : \"\"),\n-               (has_vcipher() ? \" aes\"     : \"\"),\n-               (has_vpmsumb() ? \" vpmsumb\" : \"\"),\n-               (has_mfdscr()  ? \" mfdscr\"  : \"\"),\n-               (has_vsx()     ? \" vsx\"     : \"\"),\n-               (has_ldbrx()   ? \" ldbrx\"   : \"\"),\n-               (has_stdbrx()  ? \" stdbrx\"  : \"\"),\n@@ -286,8 +234,2 @@\n-  if (has_vcipher()) {\n-    if (FLAG_IS_DEFAULT(UseAES)) {\n-      UseAES = true;\n-    }\n-  } else if (UseAES) {\n-    if (!FLAG_IS_DEFAULT(UseAES))\n-      warning(\"AES instructions are not available on this CPU\");\n-    FLAG_SET_DEFAULT(UseAES, false);\n+  if (FLAG_IS_DEFAULT(UseAES)) {\n+    UseAES = true;\n@@ -296,8 +238,2 @@\n-  if (UseAES && has_vcipher()) {\n-    if (FLAG_IS_DEFAULT(UseAESIntrinsics)) {\n-      UseAESIntrinsics = true;\n-    }\n-  } else if (UseAESIntrinsics) {\n-    if (!FLAG_IS_DEFAULT(UseAESIntrinsics))\n-      warning(\"AES intrinsics are not available on this CPU\");\n-    FLAG_SET_DEFAULT(UseAESIntrinsics, false);\n+  if (FLAG_IS_DEFAULT(UseAESIntrinsics)) {\n+    UseAESIntrinsics = true;\n@@ -367,6 +303,0 @@\n-  if (UseSecondarySupersTable && PowerArchitecturePPC64 < 7) {\n-    if (!FLAG_IS_DEFAULT(UseSecondarySupersTable)) {\n-      warning(\"UseSecondarySupersTable requires Power7 or later.\");\n-    }\n-    FLAG_SET_DEFAULT(UseSecondarySupersTable, false);\n-  }\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.cpp","additions":11,"deletions":81,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -104,1 +104,0 @@\n-  static bool has_fsqrt()   { return (_features & fsqrt_m) != 0; }\n@@ -106,1 +105,0 @@\n-  static bool has_isel()    { return (_features & isel_m) != 0; }\n@@ -108,12 +106,0 @@\n-  static bool has_cmpb()    { return (_features & cmpb_m) != 0; }\n-  static bool has_popcntb() { return (_features & popcntb_m) != 0; }\n-  static bool has_popcntw() { return (_features & popcntw_m) != 0; }\n-  static bool has_fcfids()  { return (_features & fcfids_m) != 0; }\n-  static bool has_vand()    { return (_features & vand_m) != 0; }\n-  static bool has_lqarx()   { return (_features & lqarx_m) != 0; }\n-  static bool has_vcipher() { return (_features & vcipher_m) != 0; }\n-  static bool has_vpmsumb() { return (_features & vpmsumb_m) != 0; }\n-  static bool has_mfdscr()  { return (_features & mfdscr_m) != 0; }\n-  static bool has_vsx()     { return (_features & vsx_m) != 0; }\n-  static bool has_ldbrx()   { return (_features & ldbrx_m) != 0; }\n-  static bool has_stdbrx()  { return (_features & stdbrx_m) != 0; }\n@@ -124,2 +110,0 @@\n-  static bool has_mtfprd()  { return has_vpmsumb(); } \/\/ alias for P8\n-\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.hpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -143,6 +143,0 @@\n-#ifndef PV_7\n-  #define PV_7 0x200000          \/* Power PC 7 *\/\n-#endif\n-#ifndef PV_7_Compat\n-  #define PV_7_Compat 0x208000   \/* Power PC 7 *\/\n-#endif\n@@ -1246,27 +1240,0 @@\n-  case PV_7:\n-    strncpy(buf, \"Power PC 7\", buflen);\n-    break;\n-  case PV_6_1:\n-    strncpy(buf, \"Power PC 6 DD1.x\", buflen);\n-    break;\n-  case PV_6:\n-    strncpy(buf, \"Power PC 6\", buflen);\n-    break;\n-  case PV_5:\n-    strncpy(buf, \"Power PC 5\", buflen);\n-    break;\n-  case PV_5_2:\n-    strncpy(buf, \"Power PC 5_2\", buflen);\n-    break;\n-  case PV_5_3:\n-    strncpy(buf, \"Power PC 5_3\", buflen);\n-    break;\n-  case PV_5_Compat:\n-    strncpy(buf, \"PV_5_Compat\", buflen);\n-    break;\n-  case PV_6_Compat:\n-    strncpy(buf, \"PV_6_Compat\", buflen);\n-    break;\n-  case PV_7_Compat:\n-    strncpy(buf, \"PV_7_Compat\", buflen);\n-    break;\n","filename":"src\/hotspot\/os\/aix\/os_aix.cpp","additions":0,"deletions":33,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -249,13 +249,1 @@\n-  volatile int *dest_base = (volatile int*)((uintptr_t)dest & ~3);\n-\n-#ifdef VM_LITTLE_ENDIAN\n-  const unsigned int shift_amount        = ((uintptr_t)dest & 3) * 8;\n-#else\n-  const unsigned int shift_amount        = ((~(uintptr_t)dest) & 3) * 8;\n-#endif\n-  const unsigned int masked_compare_val  = ((unsigned int)(unsigned char)compare_value),\n-                     masked_exchange_val = ((unsigned int)(unsigned char)exchange_value),\n-                     xor_value           = (masked_compare_val ^ masked_exchange_val) << shift_amount;\n-\n-  unsigned int old_value, value32;\n-\n+  unsigned int old_value, loaded_value;\n@@ -265,4 +253,0 @@\n-    \/* simple guard *\/\n-    \"   lbz     %[old_value], 0(%[dest])                  \\n\"\n-    \"   cmpw    %[masked_compare_val], %[old_value]       \\n\"\n-    \"   bne-    2f                                        \\n\"\n@@ -271,1 +255,1 @@\n-    \"   lwarx   %[value32], 0, %[dest_base]               \\n\"\n+    \"   lbarx   %[old_value], 0, %[dest]                  \\n\"\n@@ -273,3 +257,1 @@\n-    \"   srd     %[old_value], %[value32], %[shift_amount] \\n\"\n-    \"   clrldi  %[old_value], %[old_value], 56            \\n\"\n-    \"   cmpw    %[masked_compare_val], %[old_value]       \\n\"\n+    \"   cmpw    %[compare_value], %[old_value] \\n\"\n@@ -278,2 +260,1 @@\n-    \"   xor     %[value32], %[xor_value], %[value32]      \\n\"\n-    \"   stwcx.  %[value32], 0, %[dest_base]               \\n\"\n+    \"   stbcx.  %[exchange_value], 0, %[dest]             \\n\"\n@@ -285,3 +266,2 @@\n-      [value32]             \"=&r\"   (value32),\n-                            \"=m\"    (*dest),\n-                            \"=m\"    (*dest_base)\n+      [loaded_value]             \"=&r\"   (loaded_value),\n+                            \"=m\"    (*dest)\n@@ -289,7 +269,4 @@\n-    : [dest]                \"b\"     (dest),\n-      [dest_base]           \"b\"     (dest_base),\n-      [shift_amount]        \"r\"     (shift_amount),\n-      [masked_compare_val]  \"r\"     (masked_compare_val),\n-      [xor_value]           \"r\"     (xor_value),\n-                            \"m\"     (*dest),\n-                            \"m\"     (*dest_base)\n+    : [dest]            \"b\"     (dest),\n+      [compare_value]   \"r\"     (compare_value),\n+      [exchange_value]  \"r\"     (exchange_value),\n+                        \"m\"     (*dest)\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/atomic_linux_ppc.hpp","additions":10,"deletions":33,"binary":false,"changes":43,"status":"modified"}]}