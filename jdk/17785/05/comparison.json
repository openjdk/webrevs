{"files":[{"patch":"@@ -520,1 +520,1 @@\n-  extend_packlist();\n+  extend_packset_with_more_pairs_by_following_use_and_def();\n@@ -522,1 +522,1 @@\n-  combine_packs();\n+  combine_pairs_to_longer_packs();\n@@ -524,1 +524,1 @@\n-  filter_packs_for_alignment();\n+  split_packs_longer_than_max_vector_size();\n@@ -526,0 +526,1 @@\n+  \/\/ Now we only remove packs:\n@@ -527,2 +528,5 @@\n-\n-  filter_packs();\n+  filter_packs_for_power_of_2_size();\n+  filter_packs_for_mutual_independence();\n+  filter_packs_for_alignment();\n+  filter_packs_for_implemented();\n+  filter_packs_for_profitable();\n@@ -1084,1 +1088,1 @@\n-bool SuperWord::mutually_independent(Node_List* nodes) const {\n+bool SuperWord::mutually_independent(const Node_List* nodes) const {\n@@ -1172,1 +1176,0 @@\n-\/\/------------------------------extend_packlist---------------------------\n@@ -1174,1 +1177,1 @@\n-void SuperWord::extend_packlist() {\n+void SuperWord::extend_packset_with_more_pairs_by_following_use_and_def() {\n@@ -1195,1 +1198,1 @@\n-    tty->print_cr(\"\\nAfter Superword::extend_packlist\");\n+    tty->print_cr(\"\\nAfter Superword::extend_packset_with_more_pairs_by_following_use_and_def\");\n@@ -1481,1 +1484,0 @@\n-\/\/------------------------------combine_packs---------------------------\n@@ -1483,1 +1485,1 @@\n-void SuperWord::combine_packs() {\n+void SuperWord::combine_pairs_to_longer_packs() {\n@@ -1485,0 +1487,1 @@\n+  assert(!_packset.is_empty(), \"packset not empty\");\n@@ -1487,0 +1490,1 @@\n+    assert(_packset.at(i)->size() == 2, \"all packs are pairs\");\n@@ -1512,9 +1516,5 @@\n-  \/\/ Split packs which have size greater then max vector size.\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p1 = _packset.at(i);\n-    if (p1 != nullptr) {\n-      uint max_vlen = max_vector_size_in_def_use_chain(p1->at(0)); \/\/ Max elements in vector\n-      assert(is_power_of_2(max_vlen), \"sanity\");\n-      uint psize = p1->size();\n-      if (!is_power_of_2(psize)) {\n-        \/\/ We currently only support power-of-2 sizes for vectors.\n+  \/\/ Remove all nullptr from packset\n+  compress_packset();\n+\n+  assert(!_packset.is_empty(), \"must have combined some packs\");\n+\n@@ -1522,5 +1522,4 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Removed pack[%d] with size that is not a power of 2:\", i);\n-          print_pack(p1);\n-        }\n+  if (is_trace_superword_packset()) {\n+    tty->print_cr(\"\\nAfter Superword::combine_pairs_to_longer_packs\");\n+    print_packset();\n+  }\n@@ -1528,38 +1527,6 @@\n-        _packset.at_put(i, nullptr);\n-        continue;\n-      }\n-      if (psize > max_vlen) {\n-        Node_List* pack = new Node_List();\n-        for (uint j = 0; j < psize; j++) {\n-          pack->push(p1->at(j));\n-          if (pack->size() >= max_vlen) {\n-            assert(is_power_of_2(pack->size()), \"sanity\");\n-            _packset.append(pack);\n-            pack = new Node_List();\n-          }\n-        }\n-        _packset.at_put(i, nullptr);\n-      }\n-    }\n-  }\n-\n-  \/\/ We know that the nodes in a pair pack were independent - this gives us independence\n-  \/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n-  \/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n-  \/\/ This is better than giving up completely - we can have partial vectorization if some\n-  \/\/ are rejected and others still accepted.\n-  \/\/\n-  \/\/ Examples with dependence at distance 1 (pack pairs are not created):\n-  \/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n-  \/\/\n-  \/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n-  \/\/ created and we need to filter them out now):\n-  \/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n-  \/\/\n-  \/\/ Note: dependencies are created when a later load may reference the same memory location\n-  \/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n-  \/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n-  \/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n-  \/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n+}\n+\n+void SuperWord::split_packs_longer_than_max_vector_size() {\n+  assert(!_packset.is_empty(), \"packset not empty\");\n+  DEBUG_ONLY( int old_packset_length = _packset.length(); )\n+\n@@ -1567,5 +1534,24 @@\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      \/\/ reductions are trivially connected\n-      if (!is_marked_reduction(p->at(0)) &&\n-          !mutually_independent(p)) {\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    uint max_vlen = max_vector_size_in_def_use_chain(pack->at(0));\n+    assert(is_power_of_2(max_vlen), \"sanity\");\n+    uint pack_size = pack->size();\n+    if (pack_size <= max_vlen) {\n+      continue;\n+    }\n+    \/\/ Split off the \"upper\" nodes into new packs\n+    Node_List* new_pack = new Node_List();\n+    for (uint j = max_vlen; j < pack_size; j++) {\n+      Node* n = pack->at(j);\n+      \/\/ is new_pack full?\n+      if (new_pack->size() >= max_vlen) {\n+        assert(is_power_of_2(new_pack->size()), \"sanity %d\", new_pack->size());\n+        _packset.append(new_pack);\n+        new_pack = new Node_List();\n+      }\n+      new_pack->push(n);\n+    }\n+    \/\/ remaining new_pack\n+    if (new_pack->size() > 1) {\n+      _packset.append(new_pack);\n+    } else {\n@@ -1573,8 +1559,5 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Found dependency at distance greater than 1.\");\n-          tty->print_cr(\"In pack[%d]\", i);\n-          print_pack(p);\n-        }\n-#endif\n-        _packset.at_put(i, nullptr);\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Node dropped out of odd size pack:\");\n+        new_pack->at(0)->dump();\n+        print_pack(pack);\n@@ -1582,0 +1565,5 @@\n+#endif\n+    }\n+    \/\/ truncate\n+    while (pack->size() > max_vlen) {\n+      pack->pop();\n@@ -1585,2 +1573,1 @@\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n+  assert(old_packset_length <= _packset.length(), \"we only increased the number of packs\");\n@@ -1590,1 +1577,35 @@\n-    tty->print_cr(\"\\nAfter Superword::combine_packs\");\n+    tty->print_cr(\"\\nAfter Superword::split_packs_longer_than_max_vector_size\");\n+    print_packset();\n+  }\n+#endif\n+}\n+\n+template <typename FilterPredicate>\n+void SuperWord::filter_packs(const char* filter_name,\n+                             const char* error_message,\n+                             FilterPredicate filter) {\n+  int new_packset_length = 0;\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    if (filter(pack)) {\n+      assert(i >= new_packset_length, \"only move packs down\");\n+      _packset.at_put(new_packset_length++, pack);\n+    } else {\n+      remove_pack_at(i);\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed pack: %s:\", error_message);\n+        print_pack(pack);\n+      }\n+#endif\n+    }\n+  }\n+\n+  assert(_packset.length() >= new_packset_length, \"filter only reduces number of packs\");\n+  _packset.trunc_to(new_packset_length);\n+\n+#ifndef PRODUCT\n+  if (is_trace_superword_packset() && filter_name != nullptr) {\n+    tty->print_cr(\"\\nAfter %s:\", filter_name);\n@@ -1596,0 +1617,38 @@\n+void SuperWord::filter_packs_for_power_of_2_size() {\n+  filter_packs(\"SuperWord::filter_packs_for_power_of_2_size\",\n+               \"size is not a power of 2\",\n+               [&](const Node_List* pack) {\n+                 return is_power_of_2(pack->size());\n+               });\n+}\n+\n+\/\/ We know that the nodes in a pair pack were independent - this gives us independence\n+\/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n+\/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n+\/\/ This is better than giving up completely - we can have partial vectorization if some\n+\/\/ are rejected and others still accepted.\n+\/\/\n+\/\/ Examples with dependence at distance 1 (pack pairs are not created):\n+\/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n+\/\/\n+\/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n+\/\/ created and we need to filter them out now):\n+\/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n+\/\/\n+\/\/ Note: dependencies are created when a later load may reference the same memory location\n+\/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n+\/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n+\/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n+\/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n+void SuperWord::filter_packs_for_mutual_independence() {\n+  filter_packs(\"SuperWord::filter_packs_for_mutual_independence\",\n+               \"found dependency between nodes at distance greater than 1\",\n+               [&](const Node_List* pack) {\n+                 \/\/ reductions are trivially connected\n+                 return is_marked_reduction(pack->at(0)) ||\n+                        mutually_independent(pack);\n+               });\n+}\n+\n@@ -1597,1 +1656,1 @@\n-const AlignmentSolution* SuperWord::pack_alignment_solution(Node_List* pack) {\n+const AlignmentSolution* SuperWord::pack_alignment_solution(const Node_List* pack) {\n@@ -1641,8 +1700,0 @@\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      if (p->at(0)->is_Load() || p->at(0)->is_Store()) {\n-        mem_ops_count++;\n-        \/\/ Find solution for pack p, and filter with current solution.\n-        const AlignmentSolution* s = pack_alignment_solution(p);\n-        const AlignmentSolution* intersect = current->filter(s);\n@@ -1650,8 +1701,12 @@\n-#ifndef PRODUCT\n-        if (is_trace_align_vector()) {\n-          tty->print(\"  solution for pack:         \");\n-          s->print();\n-          tty->print(\"  intersection with current: \");\n-          intersect->print();\n-        }\n-#endif\n+  filter_packs(\"SuperWord::filter_packs_for_alignment\",\n+               \"rejected by AlignVector (strict alignment requirement)\",\n+               [&](const Node_List* pack) {\n+                 \/\/ Only memops need to be aligned.\n+                 if (!pack->at(0)->is_Load() &&\n+                     !pack->at(0)->is_Store()) {\n+                   return true; \/\/ accept all non memops\n+                 }\n+\n+                 mem_ops_count++;\n+                 const AlignmentSolution* s = pack_alignment_solution(pack);\n+                 const AlignmentSolution* intersect = current->filter(s);\n@@ -1659,2 +1714,0 @@\n-        if (intersect->is_empty()) {\n-          \/\/ Solution failed or is not compatible, remove pack i.\n@@ -1662,4 +1715,6 @@\n-          if (is_trace_superword_rejections() || is_trace_align_vector()) {\n-            tty->print_cr(\"Rejected by AlignVector:\");\n-            p->at(0)->dump();\n-          }\n+                 if (is_trace_align_vector()) {\n+                   tty->print(\"  solution for pack:         \");\n+                   s->print();\n+                   tty->print(\"  intersection with current: \");\n+                   intersect->print();\n+                 }\n@@ -1667,9 +1722,8 @@\n-          _packset.at_put(i, nullptr);\n-          mem_ops_rejected++;\n-        } else {\n-          \/\/ Solution is compatible.\n-          current = intersect;\n-        }\n-      }\n-    }\n-  }\n+                 if (intersect->is_empty()) {\n+                   mem_ops_rejected++;\n+                   return false; \/\/ reject because of empty solution\n+                 }\n+\n+                 current = intersect;\n+                 return true; \/\/ accept because of non-empty solution\n+               });\n@@ -1692,10 +1746,0 @@\n-\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n-\n-#ifndef PRODUCT\n-  if (is_trace_superword_packset() || is_trace_align_vector()) {\n-    tty->print_cr(\"\\nAfter Superword::filter_packs_for_alignment\");\n-    print_packset();\n-  }\n-#endif\n@@ -1719,1 +1763,1 @@\n-\/\/ point where a node is only in one pack (after combine_packs).\n+\/\/ point where a node is only in one pack (after combine_pairs_to_longer_packs).\n@@ -1738,17 +1782,16 @@\n-\/\/------------------------------filter_packs---------------------------\n-\/\/ Remove packs that are not implemented or not profitable.\n-void SuperWord::filter_packs() {\n-  \/\/ Remove packs that are not implemented\n-  for (int i = _packset.length() - 1; i >= 0; i--) {\n-    Node_List* pk = _packset.at(i);\n-    bool impl = implemented(pk);\n-    if (!impl) {\n-#ifndef PRODUCT\n-      if (is_trace_superword_rejections()) {\n-        tty->print_cr(\"Unimplemented\");\n-        pk->at(0)->dump();\n-      }\n-#endif\n-      remove_pack_at(i);\n-    }\n-    Node *n = pk->at(0);\n+\/\/ Remove packs that are not implemented\n+void SuperWord::filter_packs_for_implemented() {\n+  filter_packs(\"SuperWord::filter_packs_for_implemented\",\n+               \"Unimplemented\",\n+               [&](const Node_List* pack) {\n+                 return implemented(pack);\n+               });\n+}\n+\n+\/\/ Remove packs that are not profitable.\n+void SuperWord::filter_packs_for_profitable() {\n+  \/\/ Count the number of reductions vs other vector ops, for the\n+  \/\/ reduction profitability heuristic.\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    Node* n = pack->at(0);\n@@ -1763,16 +1806,10 @@\n-  bool changed;\n-  do {\n-    changed = false;\n-    for (int i = _packset.length() - 1; i >= 0; i--) {\n-      Node_List* pk = _packset.at(i);\n-      bool prof = profitable(pk);\n-      if (!prof) {\n-#ifndef PRODUCT\n-        if (is_trace_superword_rejections()) {\n-          tty->print_cr(\"Unprofitable\");\n-          pk->at(0)->dump();\n-        }\n-#endif\n-        remove_pack_at(i);\n-        changed = true;\n-      }\n+  while (true) {\n+    int old_packset_length = _packset.length();\n+    filter_packs(nullptr, \/\/ don't dump each time\n+                 \"size is not a power of 2\",\n+                 [&](const Node_List* pack) {\n+                   return profitable(pack);\n+                 });\n+    \/\/ Repeat until stable\n+    if (old_packset_length == _packset.length()) {\n+      break;\n@@ -1780,1 +1817,1 @@\n-  } while (changed);\n+  }\n@@ -1784,1 +1821,1 @@\n-    tty->print_cr(\"\\nAfter Superword::filter_packs\");\n+    tty->print_cr(\"\\nAfter Superword::filter_packs_for_profitable\");\n@@ -1793,1 +1830,1 @@\n-bool SuperWord::implemented(Node_List* p) {\n+bool SuperWord::implemented(const Node_List* p) {\n@@ -1853,1 +1890,1 @@\n-bool SuperWord::same_inputs(Node_List* p, int idx) {\n+bool SuperWord::same_inputs(const Node_List* p, int idx) {\n@@ -1869,1 +1906,1 @@\n-bool SuperWord::profitable(Node_List* p) {\n+bool SuperWord::profitable(const Node_List* p) {\n@@ -3332,1 +3369,1 @@\n-  _packset.remove_at(pos);\n+  _packset.at_put(pos, nullptr);\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":198,"deletions":161,"binary":false,"changes":359,"status":"modified"},{"patch":"@@ -374,1 +374,1 @@\n-  bool same_inputs(Node_List* p, int idx);\n+  bool same_inputs(const Node_List* p, int idx);\n@@ -465,1 +465,1 @@\n-  bool mutually_independent(Node_List* nodes) const;\n+  bool mutually_independent(const Node_List* nodes) const;\n@@ -474,1 +474,1 @@\n-  void extend_packlist();\n+  void extend_packset_with_more_pairs_by_following_use_and_def();\n@@ -487,0 +487,1 @@\n+\n@@ -488,1 +489,11 @@\n-  void combine_packs();\n+  void combine_pairs_to_longer_packs();\n+\n+  void split_packs_longer_than_max_vector_size();\n+\n+  \/\/ Filter out packs with various filter predicates\n+  template <typename FilterPredicate>\n+  void filter_packs(const char* filter_name,\n+                    const char* error_message,\n+                    FilterPredicate filter);\n+  void filter_packs_for_power_of_2_size();\n+  void filter_packs_for_mutual_independence();\n@@ -492,1 +503,1 @@\n-  const AlignmentSolution* pack_alignment_solution(Node_List* pack);\n+  const AlignmentSolution* pack_alignment_solution(const Node_List* pack);\n@@ -497,2 +508,4 @@\n-  \/\/ Remove packs that are not implemented or not profitable.\n-  void filter_packs();\n+  \/\/ Remove packs that are not implemented.\n+  void filter_packs_for_implemented();\n+  \/\/ Remove packs that are not profitable.\n+  void filter_packs_for_profitable();\n@@ -512,1 +525,1 @@\n-  bool implemented(Node_List* p);\n+  bool implemented(const Node_List* p);\n@@ -514,1 +527,1 @@\n-  bool profitable(Node_List* p);\n+  bool profitable(const Node_List* p);\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":22,"deletions":9,"binary":false,"changes":31,"status":"modified"}]}