{"files":[{"patch":"@@ -575,0 +575,1 @@\n+  \/\/ Combine pairs to longer packs\n@@ -577,1 +578,2 @@\n-  filter_packs_for_alignment();\n+  \/\/ Split packs if they are too long\n+  split_packs_for_max_vector_size();\n@@ -579,0 +581,1 @@\n+  \/\/ Now we only remove packs:\n@@ -580,2 +583,5 @@\n-\n-  filter_packs();\n+  filter_packs_for_power_of_2_size();\n+  filter_packs_for_mutual_independence();\n+  filter_packs_for_alignment();\n+  filter_packs_for_implemented();\n+  filter_packs_for_profitable();\n@@ -1137,1 +1143,1 @@\n-bool SuperWord::mutually_independent(Node_List* nodes) const {\n+bool SuperWord::mutually_independent(const Node_List* nodes) const {\n@@ -1537,0 +1543,1 @@\n+  assert(!_packset.is_empty(), \"packset not empty\");\n@@ -1565,9 +1572,5 @@\n-  \/\/ Split packs which have size greater then max vector size.\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p1 = _packset.at(i);\n-    if (p1 != nullptr) {\n-      uint max_vlen = max_vector_size_in_def_use_chain(p1->at(0)); \/\/ Max elements in vector\n-      assert(is_power_of_2(max_vlen), \"sanity\");\n-      uint psize = p1->size();\n-      if (!is_power_of_2(psize)) {\n-        \/\/ We currently only support power-of-2 sizes for vectors.\n+  \/\/ Remove all nullptr from packset\n+  compress_packset();\n+\n+  assert(!_packset.is_empty(), \"must have combined some packs\");\n+\n@@ -1575,5 +1578,4 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Removed pack[%d] with size that is not a power of 2:\", i);\n-          print_pack(p1);\n-        }\n+  if (is_trace_superword_packset()) {\n+    tty->print_cr(\"\\nAfter Superword::combine_packs\");\n+    print_packset();\n+  }\n@@ -1581,38 +1583,5 @@\n-        _packset.at_put(i, nullptr);\n-        continue;\n-      }\n-      if (psize > max_vlen) {\n-        Node_List* pack = new Node_List();\n-        for (uint j = 0; j < psize; j++) {\n-          pack->push(p1->at(j));\n-          if (pack->size() >= max_vlen) {\n-            assert(is_power_of_2(pack->size()), \"sanity\");\n-            _packset.append(pack);\n-            pack = new Node_List();\n-          }\n-        }\n-        _packset.at_put(i, nullptr);\n-      }\n-    }\n-  }\n-\n-  \/\/ We know that the nodes in a pair pack were independent - this gives us independence\n-  \/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n-  \/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n-  \/\/ This is better than giving up completely - we can have partial vectorization if some\n-  \/\/ are rejected and others still accepted.\n-  \/\/\n-  \/\/ Examples with dependence at distance 1 (pack pairs are not created):\n-  \/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n-  \/\/\n-  \/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n-  \/\/ created and we need to filter them out now):\n-  \/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n-  \/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n-  \/\/\n-  \/\/ Note: dependencies are created when a later load may reference the same memory location\n-  \/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n-  \/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n-  \/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n-  \/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n+}\n+\n+void SuperWord::split_packs_for_max_vector_size() {\n+  assert(!_packset.is_empty(), \"packset not empty\");\n+\n@@ -1620,5 +1589,24 @@\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      \/\/ reductions are trivially connected\n-      if (!is_marked_reduction(p->at(0)) &&\n-          !mutually_independent(p)) {\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    uint max_vlen = max_vector_size_in_def_use_chain(pack->at(0));\n+    assert(is_power_of_2(max_vlen), \"sanity\");\n+    uint pack_size = pack->size();\n+    if (pack_size <= max_vlen) {\n+      continue;\n+    }\n+    \/\/ Split off the \"upper\" nodes into new packs\n+    Node_List* new_pack = new Node_List();\n+    for (uint j = max_vlen; j < pack_size; j++) {\n+      Node* n = pack->at(j);\n+      \/\/ is new_pack full?\n+      if (new_pack->size() >= max_vlen) {\n+        assert(is_power_of_2(new_pack->size()), \"sanity\");\n+        _packset.append(new_pack);\n+        Node_List* new_pack = new Node_List();\n+      }\n+      new_pack->push(n);\n+    }\n+    \/\/ remaining new_pack\n+    if (new_pack->size() > 1) {\n+      _packset.append(new_pack);\n+    } else {\n@@ -1626,8 +1614,5 @@\n-        if (is_trace_superword_rejections()) {\n-          tty->cr();\n-          tty->print_cr(\"WARNING: Found dependency at distance greater than 1.\");\n-          tty->print_cr(\"In pack[%d]\", i);\n-          print_pack(p);\n-        }\n-#endif\n-        _packset.at_put(i, nullptr);\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Node dropped out of odd size pack:\");\n+        new_pack->at(0)->dump();\n+        print_pack(pack);\n@@ -1635,0 +1620,5 @@\n+#endif\n+    }\n+    \/\/ truncate\n+    while (pack->size() > max_vlen) {\n+      pack->pop();\n@@ -1638,2 +1628,1 @@\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n+  assert(!_packset.is_empty(), \"we only increased the number of packs\");\n@@ -1643,1 +1632,35 @@\n-    tty->print_cr(\"\\nAfter Superword::combine_packs\");\n+    tty->print_cr(\"\\nAfter Superword::split_packs_for_max_vector_size\");\n+    print_packset();\n+  }\n+#endif\n+}\n+\n+template <typename FilterPredicate>\n+void SuperWord::filter_packs(const char* filter_name,\n+                             const char* error_message,\n+                             FilterPredicate filter) {\n+  int new_packset_length = 0;\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    if (filter(pack)) {\n+      assert(i >= new_packset_length, \"only move packs down\");\n+      _packset.at_put(new_packset_length++, pack);\n+    } else {\n+      remove_pack_at(i);\n+#ifndef PRODUCT\n+      if (is_trace_superword_rejections()) {\n+        tty->cr();\n+        tty->print_cr(\"WARNING: Removed pack: %s:\", error_message);\n+        print_pack(pack);\n+      }\n+#endif\n+    }\n+  }\n+\n+  assert(_packset.length() >= new_packset_length, \"filter only reduces number of packs\");\n+  _packset.trunc_to(new_packset_length);\n+\n+#ifndef PRODUCT\n+  if (is_trace_superword_packset() && filter_name != nullptr) {\n+    tty->print_cr(\"\\nAfter %s:\", filter_name);\n@@ -1649,0 +1672,38 @@\n+void SuperWord::filter_packs_for_power_of_2_size() {\n+  filter_packs(\"SuperWord::filter_packs_for_power_of_2_size\",\n+               \"size is not a power of 2\",\n+               [&](const Node_List* pack) {\n+                 return is_power_of_2(pack->size());\n+               });\n+}\n+\n+\/\/ We know that the nodes in a pair pack were independent - this gives us independence\n+\/\/ at distance 1. But now that we may have more than 2 nodes in a pack, we need to check\n+\/\/ if they are all mutually independent. If there is a dependence we remove the pack.\n+\/\/ This is better than giving up completely - we can have partial vectorization if some\n+\/\/ are rejected and others still accepted.\n+\/\/\n+\/\/ Examples with dependence at distance 1 (pack pairs are not created):\n+\/\/ for (int i ...) { v[i + 1] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 1] + 5; }\n+\/\/\n+\/\/ Example with independence at distance 1, but dependence at distance 2 (pack pairs are\n+\/\/ created and we need to filter them out now):\n+\/\/ for (int i ...) { v[i + 2] = v[i] + 5; }\n+\/\/ for (int i ...) { v[i] = v[i - 2] + 5; }\n+\/\/\n+\/\/ Note: dependencies are created when a later load may reference the same memory location\n+\/\/ as an earlier store. This happens in \"read backward\" or \"store forward\" cases. On the\n+\/\/ other hand, \"read forward\" or \"store backward\" cases do not have such dependencies:\n+\/\/ for (int i ...) { v[i] = v[i + 1] + 5; }\n+\/\/ for (int i ...) { v[i - 1] = v[i] + 5; }\n+void SuperWord::filter_packs_for_mutual_independence() {\n+  filter_packs(\"SuperWord::filter_packs_for_mutual_independence\",\n+               \"found dependency between nodes at distance greater than 1\",\n+               [&](const Node_List* pack) {\n+                 \/\/ reductions are trivially connected\n+                 return is_marked_reduction(pack->at(0)) ||\n+                        mutually_independent(pack);\n+               });\n+}\n+\n@@ -1694,0 +1755,1 @@\n+  int new_packset_length = 0;\n@@ -1695,7 +1757,8 @@\n-    Node_List* p = _packset.at(i);\n-    if (p != nullptr) {\n-      if (p->at(0)->is_Load() || p->at(0)->is_Store()) {\n-        mem_ops_count++;\n-        \/\/ Find solution for pack p, and filter with current solution.\n-        const AlignmentSolution* s = pack_alignment_solution(p);\n-        const AlignmentSolution* intersect = current->filter(s);\n+    Node_List* pack = _packset.at(i);\n+    assert(pack != nullptr, \"no nullptr in packset\");\n+    bool keep = true;\n+    if (pack->at(0)->is_Load() || pack->at(0)->is_Store()) {\n+      mem_ops_count++;\n+      \/\/ Find solution for pack p, and filter with current solution.\n+      const AlignmentSolution* s = pack_alignment_solution(pack);\n+      const AlignmentSolution* intersect = current->filter(s);\n@@ -1704,6 +1767,6 @@\n-        if (is_trace_align_vector()) {\n-          tty->print(\"  solution for pack:         \");\n-          s->print();\n-          tty->print(\"  intersection with current: \");\n-          intersect->print();\n-        }\n+      if (is_trace_align_vector()) {\n+        tty->print(\"  solution for pack:         \");\n+        s->print();\n+        tty->print(\"  intersection with current: \");\n+        intersect->print();\n+      }\n@@ -1712,2 +1775,2 @@\n-        if (intersect->is_empty()) {\n-          \/\/ Solution failed or is not compatible, remove pack i.\n+      if (intersect->is_empty()) {\n+        \/\/ Solution failed or is not compatible, remove pack i.\n@@ -1715,10 +1778,3 @@\n-          if (is_trace_superword_rejections() || is_trace_align_vector()) {\n-            tty->print_cr(\"Rejected by AlignVector:\");\n-            p->at(0)->dump();\n-          }\n-#endif\n-          _packset.at_put(i, nullptr);\n-          mem_ops_rejected++;\n-        } else {\n-          \/\/ Solution is compatible.\n-          current = intersect;\n+        if (is_trace_superword_rejections() || is_trace_align_vector()) {\n+          tty->print_cr(\"Rejected by AlignVector:\");\n+          pack->at(0)->dump();\n@@ -1726,0 +1782,6 @@\n+#endif\n+        keep = false;\n+        mem_ops_rejected++;\n+      } else {\n+        \/\/ Solution is compatible.\n+        current = intersect;\n@@ -1728,0 +1790,6 @@\n+    if (keep) {\n+      assert(i >= new_packset_length, \"only move packs down\");\n+      _packset.at_put(new_packset_length++, pack);\n+    } else {\n+      remove_pack_at(i);\n+    }\n@@ -1730,0 +1798,3 @@\n+  assert(_packset.length() >= new_packset_length, \"filter only reduces number of packs\");\n+  _packset.trunc_to(new_packset_length);\n+\n@@ -1746,3 +1817,0 @@\n-  \/\/ Remove all nullptr from packset\n-  compress_packset();\n-\n@@ -1791,17 +1859,16 @@\n-\/\/------------------------------filter_packs---------------------------\n-\/\/ Remove packs that are not implemented or not profitable.\n-void SuperWord::filter_packs() {\n-  \/\/ Remove packs that are not implemented\n-  for (int i = _packset.length() - 1; i >= 0; i--) {\n-    Node_List* pk = _packset.at(i);\n-    bool impl = implemented(pk);\n-    if (!impl) {\n-#ifndef PRODUCT\n-      if (is_trace_superword_rejections()) {\n-        tty->print_cr(\"Unimplemented\");\n-        pk->at(0)->dump();\n-      }\n-#endif\n-      remove_pack_at(i);\n-    }\n-    Node *n = pk->at(0);\n+\/\/ Remove packs that are not implemented\n+void SuperWord::filter_packs_for_implemented() {\n+  filter_packs(\"SuperWord::filter_packs_for_implemented\",\n+               \"Unimplemented\",\n+               [&](const Node_List* pack) {\n+                 return implemented(pack);\n+               });\n+}\n+\n+\/\/ Remove packs that are not profitable.\n+void SuperWord::filter_packs_for_profitable() {\n+  \/\/ Count the number of reductions vs other vector ops, for the\n+  \/\/ reduction profitability heuristic.\n+  for (int i = 0; i < _packset.length(); i++) {\n+    Node_List* pack = _packset.at(i);\n+    Node* n = pack->at(0);\n@@ -1816,16 +1883,10 @@\n-  bool changed;\n-  do {\n-    changed = false;\n-    for (int i = _packset.length() - 1; i >= 0; i--) {\n-      Node_List* pk = _packset.at(i);\n-      bool prof = profitable(pk);\n-      if (!prof) {\n-#ifndef PRODUCT\n-        if (is_trace_superword_rejections()) {\n-          tty->print_cr(\"Unprofitable\");\n-          pk->at(0)->dump();\n-        }\n-#endif\n-        remove_pack_at(i);\n-        changed = true;\n-      }\n+  while (true) {\n+    int old_packset_length = _packset.length();\n+    filter_packs(nullptr, \/\/ don't dump each time\n+                 \"size is not a power of 2\",\n+                 [&](const Node_List* pack) {\n+                   return profitable(pack);\n+                 });\n+    \/\/ Repeat until stable\n+    if (old_packset_length == _packset.length()) {\n+      break;\n@@ -1833,1 +1894,1 @@\n-  } while (changed);\n+  }\n@@ -1837,1 +1898,1 @@\n-    tty->print_cr(\"\\nAfter Superword::filter_packs\");\n+    tty->print_cr(\"\\nAfter Superword::filter_packs_for_profitable\");\n@@ -1846,1 +1907,1 @@\n-bool SuperWord::implemented(Node_List* p) {\n+bool SuperWord::implemented(const Node_List* p) {\n@@ -1906,1 +1967,1 @@\n-bool SuperWord::same_inputs(Node_List* p, int idx) {\n+bool SuperWord::same_inputs(const Node_List* p, int idx) {\n@@ -1922,1 +1983,1 @@\n-bool SuperWord::profitable(Node_List* p) {\n+bool SuperWord::profitable(const Node_List* p) {\n@@ -3385,1 +3446,1 @@\n-  _packset.remove_at(pos);\n+  _packset.at_put(pos, nullptr);\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":200,"deletions":139,"binary":false,"changes":339,"status":"modified"},{"patch":"@@ -396,1 +396,1 @@\n-  bool same_inputs(Node_List* p, int idx);\n+  bool same_inputs(const Node_List* p, int idx);\n@@ -487,1 +487,1 @@\n-  bool mutually_independent(Node_List* nodes) const;\n+  bool mutually_independent(const Node_List* nodes) const;\n@@ -509,0 +509,1 @@\n+\n@@ -511,0 +512,11 @@\n+\n+  \/\/ Split packs that are too long\n+  void split_packs_for_max_vector_size();\n+\n+  \/\/ Filter out packs with various filter predicates\n+  template <typename FilterPredicate>\n+  void filter_packs(const char* filter_name,\n+                    const char* error_message,\n+                    FilterPredicate filter);\n+  void filter_packs_for_power_of_2_size();\n+  void filter_packs_for_mutual_independence();\n@@ -519,2 +531,4 @@\n-  \/\/ Remove packs that are not implemented or not profitable.\n-  void filter_packs();\n+  \/\/ Remove packs that are not implemented.\n+  void filter_packs_for_implemented();\n+  \/\/ Remove packs that are not profitable.\n+  void filter_packs_for_profitable();\n@@ -534,1 +548,1 @@\n-  bool implemented(Node_List* p);\n+  bool implemented(const Node_List* p);\n@@ -536,1 +550,1 @@\n-  bool profitable(Node_List* p);\n+  bool profitable(const Node_List* p);\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"}]}