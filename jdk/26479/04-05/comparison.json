{"files":[{"patch":"@@ -563,49 +563,16 @@\n-     * workers to scan for tasks.  Method signalWork and its callers\n-     * try to approximate the unattainable goal of having the right\n-     * number of workers activated for the tasks at hand, but must err\n-     * on the side of too many workers vs too few to avoid stalls:\n-     *\n-     *  * If computations are purely tree structured, it suffices for\n-     *    every worker to activate another when it pushes a task into\n-     *    an empty queue, resulting in O(log(#threads)) steps to full\n-     *    activation. Emptiness must be conservatively approximated,\n-     *    which may result in unnecessary signals.  Also, to reduce\n-     *    resource usages in some cases, at the expense of slower\n-     *    startup in others, activation of an idle thread is preferred\n-     *    over creating a new one, here and elsewhere.\n-     *\n-     *  * At the other extreme, if \"flat\" tasks (those that do not in\n-     *    turn generate others) come in serially from only a single\n-     *    producer, each worker taking a task from a queue should\n-     *    propagate a signal if there are more tasks in that\n-     *    queue. This is equivalent to, but generally faster than,\n-     *    arranging the stealer take multiple tasks, re-pushing one or\n-     *    more on its own queue, and signalling (because its queue is\n-     *    empty), also resulting in logarithmic full activation\n-     *    time. If tasks do not not engage in unbounded loops based on\n-     *    the actions of other workers with unknown dependencies loop,\n-     *    this form of proagation can be limited to one signal per\n-     *    activation (phase change).\n-     *\n-     * * Because we don't know about usage patterns (or most commonly,\n-     *    mixtures), we use both approaches, which present even more\n-     *    opportunities to over-signal. (Failure to distinguish these\n-     *    cases in terms of submission methods was arguably an early\n-     *    design mistake.)  Note that in either of these contexts,\n-     *    signals may be (and often are) unnecessary because active\n-     *    workers continue scanning after running tasks without the\n-     *    need to be signalled (which is one reason work stealing is\n-     *    often faster than alternatives), so additional workers\n-     *    aren't needed.\n-     *\n-     * * For rapidly branching tasks that require full pool resources,\n-     *   oversignalling is OK, because signalWork will soon have no\n-     *   more workers to create or reactivate. But for others (mainly\n-     *   externally submitted tasks), overprovisioning may cause very\n-     *   noticeable slowdowns due to contention and resource\n-     *   wastage. We reduce impact by deactivating workers when\n-     *   queues don't have accessible tasks, but reactivating and\n-     *   rescanning if other tasks remain.\n-     *\n-     * * Despite these, signal contention and overhead effects still\n-     *   occur during ramp-up and ramp-down of small computations.\n+     * workers to scan for tasks.  SignalWork is invoked in two cases:\n+     * (1) When a task is pushed onto an empty queue, and (2) When a\n+     * worker takes a top-level task from a queue that has additional\n+     * tasks. Together, these suffice in O(log(#threads)) steps to\n+     * fully activate with at least enough workers, and ideally no\n+     * more than required.  This ideal is unobtainable: Callers do not\n+     * know whether another worker will finish its current task and\n+     * poll for others without need of a signal (which is otherwise an\n+     * advantage of work-stealing vs other schemes), and also must\n+     * conservatively estimate the triggering conditions of emptiness\n+     * or non-emptiness; all of which usually cause more activations\n+     * than necessary (see below). (Method signalWork is also used as\n+     * failsafe in case of Thread failures in deregisterWorker.)\n+     *\n+     * Top-Level scheduling\n+     * ====================\n@@ -621,12 +588,1 @@\n-     * from ThreadLocalRandom probes, which are cheap and\n-     * suffice. Each queue's polling attempts to avoid becoming stuck\n-     * when other scanners\/pollers stall.  Scans do not otherwise\n-     * explicitly take into account core affinities, loads, cache\n-     * localities, etc, However, they do exploit temporal locality\n-     * (which usually approximates these) by preferring to re-poll\n-     * from the same queue after a successful poll before trying\n-     * others, which also reduces bookkeeping, cache traffic, and\n-     * scanning overhead. But it also reduces fairness, which is\n-     * partially counteracted by giving up on detected interference\n-     * (which also reduces contention when too many workers try to\n-     * take small tasks from the same queue).\n+     * from ThreadLocalRandom probes, which are cheap and suffice.\n@@ -635,8 +591,37 @@\n-     * it tries to deactivate()), giving up (and rescanning) on \"ctl\"\n-     * contention. To avoid missed signals during deactivation, the\n-     * method rescans and reactivates if there may have been a missed\n-     * signal during deactivation. To reduce false-alarm reactivations\n-     * while doing so, we scan multiple times (analogously to method\n-     * quiescent()) before trying to reactivate.  Because idle workers\n-     * are often not yet blocked (parked), we use a WorkQueue field to\n-     * advertise that a waiter actually needs unparking upon signal.\n+     * it invokes awaitWork, that first deactivates (to an IDLE\n+     * phase)()).  Avoiding missed signals during deactivation\n+     * requires a (conservative) rescan, reactivating if there may be\n+     * tasks to poll.  signal during deactivation.  Because idle\n+     * workers are often not yet blocked (parked), we use a WorkQueue\n+     * field to advertise that a waiter actually needs unparking upon\n+     * signal.\n+     *\n+     * When tasks are constructed as (recursive) dags, top-level\n+     * scanning is usually infrequent, and doesn't encounter most\n+     * of the following problems addressed by runWorker and awaitWork:\n+     *\n+     * Locality. Polls are organized into \"runs\" from the same source\n+     * queue, until empty or contended, while also minimizing\n+     * interference by postponing bookeeping to ends of runs. This may\n+     * reduce fairness, which is partially counteracted by the\n+     * following.\n+     *\n+     * Contention. When many workers try to poll few queues, they\n+     * often collide, generating CAS failures and disrupting locality\n+     * of workers already running their tasks. This also leads to\n+     * stalls when tasks cannot be taken because other workers have\n+     * not finished poll operations, which is detected by reading\n+     * ahead in queue arrays. In both caes, workers restart scans in a\n+     * way that approximates randomized backoff.\n+     *\n+     * Oversignalling. When many small top-level tasks are present in\n+     * a small number of queues, the above signalling strategy may\n+     * activate many more workers than needed, worsening locality and\n+     * contention problems, while also generating more global ctl\n+     * contention (which is CASed on every activation and\n+     * deactivation.) We filter out (both in runWorker and signalWork)\n+     * attempted signals that are surely not needed because the\n+     * signalled tasks are already taken.\n+     *\n+     * Shutdown and Quiescence\n+     * =======================\n@@ -892,3 +877,1 @@\n-     * paths. The inability to rely on caller-runs may also require\n-     * extra signalling (resulting in scanning and contention) so is\n-     * done only conditionally in methods push and runworker.\n+     * paths.\n@@ -972,7 +955,5 @@\n-     * Currently, arrays for workers are initialized to be just large\n-     * enough to avoid resizing in most tree-structured tasks, but\n-     * larger for external queues where both false-sharing problems\n-     * and the need for resizing are more common. (Maintenance note:\n-     * any changes in fields, queues, or their uses, or JVM layout\n-     * policies, must be accompanied by re-evaluation of these\n-     * placement and sizing decisions.)\n+     * Currently, arrays are initialized to be just large enough to\n+     * avoid resizing in most tree-structured tasks, but grow rapidly\n+     * until large.  (Maintenance note: any changes in fields, queues,\n+     * or their uses, or JVM layout policies, must be accompanied by\n+     * re-evaluation of these placement and sizing decisions.)\n@@ -1061,1 +1042,1 @@\n-     * Initial capacity of work-stealing queue array for workers.\n+     * Initial capacity of work-stealing queue array.\n@@ -1066,6 +1047,0 @@\n-    \/**\n-     * Initial capacity of work-stealing queue array for external queues.\n-     * Must be a power of two, at least 2. See above.\n-     *\/\n-    static final int INITIAL_EXTERNAL_QUEUE_CAPACITY = 1 << 9;\n-\n@@ -1248,4 +1223,0 @@\n-            array = new ForkJoinTask<?>[owner == null ?\n-                                        INITIAL_EXTERNAL_QUEUE_CAPACITY :\n-                                        INITIAL_QUEUE_CAPACITY];\n-            this.owner = owner;\n@@ -1253,0 +1224,4 @@\n+            if ((this.owner = owner) == null) {\n+                phase = id | IDLE;\n+                array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n+            }\n@@ -1288,4 +1263,2 @@\n-                    if (room == 0) {                        \/\/ resize\n-                        growArray(a, cap, s);\n-                        a = null;\n-                    }\n+                    if (room == 0 && (a = growArray(a, cap, s)) != null)\n+                        m = a.length - 1;                   \/\/ resize\n@@ -1297,3 +1270,2 @@\n-                if (pool != null &&\n-                    (a == null ||                \/\/ always signal on resize\n-                     U.getReferenceAcquire(a, slotOffset(m & (s - 1))) == null))\n+                if (pool != null && a != null &&\n+                    U.getReferenceAcquire(a, slotOffset(m & (s - 1))) == null)\n@@ -1309,0 +1281,1 @@\n+         * @return new array, or null on failure\n@@ -1310,2 +1283,3 @@\n-        private void growArray(ForkJoinTask<?>[] a, int cap, int s) {\n-            int newCap = cap << 1;\n+        private ForkJoinTask<?>[] growArray(ForkJoinTask<?>[] a, int cap, int s) {\n+            int newCap = (cap >= 1 << 16) ? cap << 1 : cap << 2;\n+            ForkJoinTask<?>[] newArray = null;\n@@ -1313,1 +1287,0 @@\n-                ForkJoinTask<?>[] newArray = null;\n@@ -1330,0 +1303,1 @@\n+            return newArray;\n@@ -1337,1 +1311,1 @@\n-        private ForkJoinTask<?> nextLocalTask(int fifo) {\n+        final ForkJoinTask<?> nextLocalTask(int fifo) {\n@@ -1443,10 +1417,0 @@\n-        \/**\n-         * Runs the given task, as well as remaining local tasks.\n-         *\/\n-        final void topLevelExec(ForkJoinTask<?> task, int fifo) {\n-            while (task != null) {\n-                task.doExec();\n-                task = nextLocalTask(fifo);\n-            }\n-        }\n-\n@@ -1781,1 +1745,2 @@\n-        if (w != null && (runState & STOP) == 0L) {\n+        if (w != null) {\n+            w.array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n@@ -1978,4 +1943,7 @@\n-            int phase = w.phase, r = w.stackPred;     \/\/ seed from registerWorker\n-            int fifo = w.config & FIFO, nsteals = 0;\n-            rescan: for (boolean propagated = false;;) {\n-                WorkQueue[] qs;\n+            int phase = w.phase, r = w.stackPred;         \/\/ seed from registerWorker\n+            int cfg = w.config, fifo = cfg & FIFO, clearLocals = cfg & CLEAR_TLS;\n+            int nsteals = 0, src = -1;                    \/\/ current source queue\n+            rescan: while ((runState & STOP) == 0L) {\n+                WorkQueue[] qs = queues;\n+                int n = (qs == null) ? 0 : qs.length;\n+                int i = r, step = (r >>> 16) | 1;         \/\/ random origin\n@@ -1983,3 +1951,1 @@\n-                if ((runState & STOP) != 0L || (qs = queues) == null)\n-                    break;\n-                int n = qs.length, i = r, step = (r >>> 16) | 1;\n+                boolean taken = false;\n@@ -1987,8 +1953,7 @@\n-                    int j, m; WorkQueue q; ForkJoinTask<?>[] a;\n-                    if ((q = qs[j = i & (n - 1)]) != null &&\n-                        (a = q.array) != null && (m = a.length - 1) >= 0) {\n-                        boolean ran = false;\n-                        for (int pb = -1, b = q.base;;) {\n-                            ForkJoinTask<?> t; long k; int bk;\n-                            t = (ForkJoinTask<?>)U.getReferenceAcquire(\n-                                a, k = slotOffset(bk = b & m));\n+                    WorkQueue q; int j;\n+                    if ((q = qs[j = i & (n - 1)]) != null) {\n+                        for (;;) {                        \/\/ poll q\n+                            ForkJoinTask<?>[] a; int cap, b, m, k;\n+                            if ((a = q.array) == null || (cap = a.length) <= 0)\n+                                break;\n+                            long bp = slotOffset(k = (b = q.base) & (m = cap - 1));\n@@ -1996,5 +1961,11 @@\n-                            if (b != (b = q.base))\n-                               ;                          \/\/ inconsistent\n-                            else if (t == null ||\n-                                     !U.compareAndSetReference(a, k, t, null)) {\n-                                if (q.array != a)         \/\/ resized\n+                            ForkJoinTask<?> t = (ForkJoinTask<?>)\n+                                U.getReferenceAcquire(a, bp);\n+                            if (q.array != a || q.base != b || a[k] != t)\n+                                continue;                 \/\/ inconsistent\n+                            if (t == null) {\n+                                if (taken) {              \/\/ end of run\n+                                    w.nsteals = nsteals;\n+                                    if (clearLocals != 0 &&\n+                                        Thread.currentThread()\n+                                        instanceof ForkJoinWorkerThread wt)\n+                                        wt.resetThreadLocals();\n@@ -2002,8 +1973,0 @@\n-                                if (b == (b = q.base) && a[bk] == null) {\n-                                    if (a[nk] == null && a[(b + 2) & m] == null) {\n-                                        if (ran)          \/\/ end of run\n-                                            continue rescan;\n-                                        break;            \/\/ probably empty\n-                                    }\n-                                    if (pb == (pb = b))   \/\/ track progress\n-                                        continue rescan;  \/\/ stalled; reorder scan\n@@ -2011,0 +1974,3 @@\n+                                if (a[nk] != null || a[(b + 2) & m] != null)\n+                                    continue rescan;      \/\/ stalled; reorder scan\n+                                break;                    \/\/ probably empty\n@@ -2012,1 +1978,1 @@\n-                            else {\n+                            if (U.compareAndSetReference(a, bp, t, null)) {\n@@ -2014,11 +1980,11 @@\n-                                w.nsteals = ++nsteals;\n-                                w.source = j;             \/\/ volatile\n-                                ran = true;\n-                                if ((!propagated || (j & 1) == 0) && a[nk] != null) {\n-                                    propagated = true;\n-                                    signalWork(a, nk);\n-                                }\n-                                w.topLevelExec(t, fifo);\n-                                b = q.base;               \/\/ refresh\n-                                if ((a = q.array) == null || (m = a.length - 1) < 0)\n-                                    break;\n+                                Object nt = U.getReferenceAcquire\n+                                    (a, slotOffset(nk));  \/\/ confirm below\n+                                taken = true;\n+                                ++nsteals;\n+                                if (src != (src = j))\n+                                    w.source = j;\n+                                if (nt != null && nt == a[nk])\n+                                    signalWork(a, nk);    \/\/ propagate\n+                                do {\n+                                    t.doExec();           \/\/ run task & subtasks\n+                                } while ((t = w.nextLocalTask(fifo)) != null);\n@@ -2029,2 +1995,3 @@\n-                propagated = false;\n-                if (((phase = deactivate(w, phase)) & IDLE) != 0)\n+                if ((runState & STOP) != 0L)              \/\/ check before deactivate\n+                    break;\n+                if ((phase = awaitWork(w, phase)) == IDLE)\n@@ -2037,1 +2004,1 @@\n-     * Deactivates and if necessary awaits signal or termination.\n+     * Deactivates and awaits signal or termination.\n@@ -2039,1 +2006,1 @@\n-     * @param w the worker\n+     * @param w the work queue\n@@ -2041,1 +2008,1 @@\n-     * @return current phase, with IDLE set if worker should exit\n+     * @return current phase or IDLE if worker should exit\n@@ -2043,1 +2010,3 @@\n-    private int deactivate(WorkQueue w, int phase) {\n+    private int awaitWork(WorkQueue w, int phase) {\n+        if (w == null)                        \/\/ never true; hoist checks\n+            return IDLE;\n@@ -2045,23 +2014,20 @@\n-        if (w != null) {                      \/\/ always true\n-            long e;\n-            long pc = ctl, qc = (activePhase & LMASK) | ((pc - RC_UNIT) & UMASK);\n-            w.stackPred = (int)pc;            \/\/ set ctl stack link\n-            w.phase = p;\n-            if (!compareAndSetCtl(pc, qc))    \/\/ try to enqueue\n-                p = w.phase = phase;          \/\/ back out on possible signal\n-            else if (((e = runState) & STOP) == 0L &&\n-                     ((e & SHUTDOWN) == 0L || (qc >> RC_SHIFT) > 0L ||\n-                      quiescent() <= 0) &&    \/\/ termination checks\n-                     (p = w.phase) != activePhase) {\n-                WorkQueue[] qs = queues;      \/\/ missed signal check\n-                int n = (qs == null) ? 0 : qs.length;\n-                for (int i = 0; i < n; ++i) {\n-                    WorkQueue q; long c;\n-                    if ((q = qs[i]) != null && q.top - q.base > 0) {\n-                        if ((p = w.phase) != activePhase &&\n-                            (int)(c = ctl) == activePhase &&\n-                            compareAndSetCtl(c, ((pc & LMASK) |\n-                                                 ((c + RC_UNIT) & UMASK))))\n-                            p = w.phase = activePhase; \/\/ reactivate\n-                        break;\n-                    }\n+        long qsp = activePhase & LMASK;\n+        long pc = ctl, qc = qsp | ((pc - RC_UNIT) & UMASK);\n+        int sp = w.stackPred = (int)pc;       \/\/ set ctl stack link\n+        w.phase = p;                          \/\/ deactivate\n+        while (pc != (pc = compareAndExchangeCtl(pc, qc))) {\n+            sp = w.stackPred = (int)pc;\n+            qc = qsp | ((pc - RC_UNIT) & UMASK);\n+        }\n+        WorkQueue[] qs = queues;              \/\/ missed signal check\n+        int n = (qs == null) ? 0 : qs.length;\n+        long psp = sp & LMASK;                \/\/ reactivation stack prefix\n+        for (int m = n - 1, origin = p + 1, i = 0; i < m; ++i) {\n+            WorkQueue q; long cc;             \/\/ stagger origins\n+            if ((q = qs[(origin + i) & m]) != null && q.top - q.base > 0) {\n+                if ((p = w.phase) == activePhase)\n+                    break;\n+                if ((int)(cc = ctl) == activePhase &&\n+                    compareAndSetCtl(cc, psp | ((cc + RC_UNIT) & UMASK))) {\n+                    p = w.phase = activePhase;\n+                    break;                    \/\/ reactivated\n@@ -2069,2 +2035,0 @@\n-                if (p != activePhase)\n-                    p = awaitWork(w, p);      \/\/ block, drop, or exit\n@@ -2073,26 +2037,7 @@\n-        return p;\n-    }\n-\n-    \/**\n-     * Awaits signal or termination.\n-     *\n-     * @param w the work queue\n-     * @param p current phase (known to be idle)\n-     * @return current phase, with IDLE set if worker should exit\n-     *\/\n-    private int awaitWork(WorkQueue w, int p) {\n-        int activePhase = p + IDLE, spins = 0;\n-        if ((runState & STOP) == 0L && w != null && (p = w.phase) != activePhase) {\n-            ForkJoinWorkerThread t;\n-            if ((w.config & CLEAR_TLS) != 0 && (t = w.owner) != null)\n-                t.resetThreadLocals();         \/\/ clear before reactivate\n-            long deadline = 0L, c = ctl;\n-            if ((int)c == activePhase) {       \/\/ w is at ctl top\n-                if ((c >> RC_SHIFT) <= 0L &&\n-                    (deadline =                \/\/ use timeout\n-                     (((w.source != INVALID_ID) ? keepAlive : TIMEOUT_SLOP)) +\n-                     System.currentTimeMillis()) == 0L)\n-                    deadline = 1L;             \/\/ avoid zero\n-                spins = Math.max(((short)(c >>> TC_SHIFT)) << 2, SPIN_WAITS);\n-                while ((p = w.phase) != activePhase && --spins != 0)\n-                    Thread.onSpinWait();       \/\/ spin at head\n+        if (p != activePhase && (p = w.phase) != activePhase) {\n+            long deadline = 0L, c, e;         \/\/ quiescence checks\n+            if (((e = runState) & STOP) != 0)\n+                return IDLE;\n+            else if ((int)(c = ctl) != activePhase || (c & RC_MASK) > 0L) {\n+                for (int spins = n; (p = w.phase) != activePhase && --spins > 0;)\n+                    Thread.onSpinWait();      \/\/ spin unless possibly quiescent\n@@ -2100,1 +2045,9 @@\n-            if (spins == 0) {\n+            else if ((e & SHUTDOWN) != 0L && quiescent() > 0)\n+                return IDLE;                  \/\/ quiescent termination\n+            else {                            \/\/ use trim timeout\n+                long d = ((w.source != INVALID_ID) ? keepAlive :\n+                          TIMEOUT_SLOP) + System.currentTimeMillis();\n+                deadline = (d == 0L)? 1L : d; \/\/ avoid zero\n+                p = w.phase;\n+            }\n+            if (p != activePhase) {           \/\/ block\n@@ -2102,1 +2055,1 @@\n-                w.parking = 1;                 \/\/ enable unpark\n+                w.parking = 1;                \/\/ enable unpark\n@@ -2105,1 +2058,1 @@\n-                    Thread.interrupted();      \/\/ clear status\n+                    Thread.interrupted();     \/\/ clear status\n@@ -2121,0 +2074,2 @@\n+            if (p != activePhase)\n+                return IDLE;\n@@ -2122,1 +2077,1 @@\n-        return p;\n+        return activePhase;\n@@ -2571,2 +2526,1 @@\n-     * throws RejectedExecutionException if shutdown or terminating.\n-     * @param r current ThreadLocalRandom.getProbe() value\n+     * throws RejectedExecutionException if shutdown\n@@ -2574,1 +2528,1 @@\n-     *        should be thrown when shutdown (else only if terminating)\n+     *        should be thrown when shutdown\n@@ -2576,4 +2530,4 @@\n-    private WorkQueue submissionQueue(int r, boolean rejectOnShutdown) {\n-        int reuse;                                   \/\/ nonzero if prefer create\n-        if ((reuse = r) == 0) {\n-            ThreadLocalRandom.localInit();           \/\/ initialize caller's probe\n+    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n+        int r;\n+        if ((r = ThreadLocalRandom.getProbe()) == 0) {\n+            ThreadLocalRandom.localInit();   \/\/ initialize caller's probe\n@@ -2582,5 +2536,3 @@\n-        for (int probes = 0; ; ++probes) {\n-            int n, i, id; WorkQueue[] qs; WorkQueue q;\n-            if ((qs = queues) == null)\n-                break;\n-            if ((n = qs.length) <= 0)\n+        for (;;) {\n+            WorkQueue q; WorkQueue[] qs; int n, id, i;\n+            if ((qs = queues) == null || (n = qs.length) <= 0)\n@@ -2589,6 +2541,4 @@\n-                WorkQueue w = new WorkQueue(null, id, 0, false);\n-                w.phase = id;\n-                boolean reject = ((lockRunState() & SHUTDOWN) != 0 &&\n-                                  rejectOnShutdown);\n-                if (!reject && queues == qs && qs[i] == null)\n-                    q = qs[i] = w;                   \/\/ else lost race to install\n+                WorkQueue newq = new WorkQueue(null, id, 0, false);\n+                lockRunState();\n+                if (qs[i] == null && queues == qs)\n+                    q = qs[i] = newq;         \/\/ else lost race to install\n@@ -2596,5 +2546,0 @@\n-                if (q != null)\n-                    return q;\n-                if (reject)\n-                    break;\n-                reuse = 0;\n@@ -2602,12 +2547,5 @@\n-            if (reuse == 0 || !q.tryLockPhase()) {   \/\/ move index\n-                if (probes >= 4)                     \/\/ probably nearly full\n-                    reuse = 1;                       \/\/ stop prefering free slot\n-                else if (q != null)\n-                    reuse = 0;                       \/\/ collision\n-                r = ThreadLocalRandom.advanceProbe(r);\n-            }\n-            else if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n-                q.unlockPhase();                     \/\/ check while q lock held\n-                break;\n-            }\n-            else\n+            if (q != null && q.tryLockPhase()) {\n+                if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n+                    q.unlockPhase();          \/\/ check while q lock held\n+                    break;\n+                }\n@@ -2615,0 +2553,2 @@\n+            }\n+            r = ThreadLocalRandom.advanceProbe(r); \/\/ move\n@@ -2628,1 +2568,1 @@\n-            q = submissionQueue(ThreadLocalRandom.getProbe(), true);\n+            q = externalSubmissionQueue(true);\n@@ -2634,12 +2574,0 @@\n-    \/**\n-     * Returns queue for an external submission, bypassing call to\n-     * submissionQueue if already established and unlocked.\n-     *\/\n-    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n-        WorkQueue[] qs; WorkQueue q; int n;\n-        int r = ThreadLocalRandom.getProbe();\n-        return (((qs = queues) != null && (n = qs.length) > 0 &&\n-                 (q = qs[r & EXTERNAL_ID_MASK & (n - 1)]) != null && r != 0 &&\n-                 q.tryLockPhase()) ? q : submissionQueue(r, rejectOnShutdown));\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":189,"deletions":261,"binary":false,"changes":450,"status":"modified"}]}