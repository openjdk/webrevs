{"files":[{"patch":"@@ -315,0 +315,12 @@\n+    \/**\n+     * Submits the given task to the given executor. If the scheduler is a\n+     * ForkJoinPool then the task is first adapted to a ForkJoinTask.\n+     *\/\n+    private void submit(Executor executor, Runnable task) {\n+        if (executor instanceof ForkJoinPool pool) {\n+            pool.submit(ForkJoinTask.adapt(task));\n+        } else {\n+            executor.execute(task);\n+        }\n+    }\n+\n@@ -335,1 +347,1 @@\n-                        scheduler.execute(runContinuation);\n+                        submit(scheduler, runContinuation);\n@@ -340,1 +352,1 @@\n-                    scheduler.execute(runContinuation);\n+                    submit(scheduler, runContinuation);\n@@ -1535,1 +1547,1 @@\n-}\n\\ No newline at end of file\n+}\n","filename":"src\/java.base\/share\/classes\/java\/lang\/VirtualThread.java","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -563,52 +563,16 @@\n-     * workers to scan for tasks.  Method signalWork and its callers\n-     * try to approximate the unattainable goal of having the right\n-     * number of workers activated for the tasks at hand, but must err\n-     * on the side of too many workers vs too few to avoid stalls:\n-     *\n-     *  * If computations are purely tree structured, it suffices for\n-     *    every worker to activate another when it pushes a task into\n-     *    an empty queue, resulting in O(log(#threads)) steps to full\n-     *    activation. Emptiness must be conservatively approximated,\n-     *    which may result in unnecessary signals.  Also, to reduce\n-     *    resource usages in some cases, at the expense of slower\n-     *    startup in others, activation of an idle thread is preferred\n-     *    over creating a new one, here and elsewhere.\n-     *\n-     *  * At the other extreme, if \"flat\" tasks (those that do not in\n-     *    turn generate others) come in serially from only a single\n-     *    producer, each worker taking a task from a queue should\n-     *    propagate a signal if there are more tasks in that\n-     *    queue. This is equivalent to, but generally faster than,\n-     *    arranging the stealer take multiple tasks, re-pushing one or\n-     *    more on its own queue, and signalling (because its queue is\n-     *    empty), also resulting in logarithmic full activation\n-     *    time. If tasks do not not engage in unbounded loops based on\n-     *    the actions of other workers with unknown dependencies loop,\n-     *    this form of proagation can be limited to one signal per\n-     *    activation (phase change). We distinguish the cases by\n-     *    further signalling only if the task is an InterruptibleTask\n-     *    (see below), which are the only supported forms of task that\n-     *    may do so.\n-     *\n-     * * Because we don't know about usage patterns (or most commonly,\n-     *    mixtures), we use both approaches, which present even more\n-     *    opportunities to over-signal. (Failure to distinguish these\n-     *    cases in terms of submission methods was arguably an early\n-     *    design mistake.)  Note that in either of these contexts,\n-     *    signals may be (and often are) unnecessary because active\n-     *    workers continue scanning after running tasks without the\n-     *    need to be signalled (which is one reason work stealing is\n-     *    often faster than alternatives), so additional workers\n-     *    aren't needed.\n-     *\n-     * * For rapidly branching tasks that require full pool resources,\n-     *   oversignalling is OK, because signalWork will soon have no\n-     *   more workers to create or reactivate. But for others (mainly\n-     *   externally submitted tasks), overprovisioning may cause very\n-     *   noticeable slowdowns due to contention and resource\n-     *   wastage. We reduce impact by deactivating workers when\n-     *   queues don't have accessible tasks, but reactivating and\n-     *   rescanning if other tasks remain.\n-     *\n-     * * Despite these, signal contention and overhead effects still\n-     *   occur during ramp-up and ramp-down of small computations.\n+     * workers to scan for tasks.  SignalWork is invoked in two cases:\n+     * (1) When a task is pushed onto an empty queue, and (2) When a\n+     * worker takes a top-level task from a queue that has additional\n+     * tasks. Together, these suffice in O(log(#threads)) steps to\n+     * fully activate with at least enough workers, and ideally no\n+     * more than required.  This ideal is unobtainable: Callers do not\n+     * know whether another worker will finish its current task and\n+     * poll for others without need of a signal (which is otherwise an\n+     * advantage of work-stealing vs other schemes), and also must\n+     * conservatively estimate the triggering conditions of emptiness\n+     * or non-emptiness; all of which usually cause more activations\n+     * than necessary (see below). (Method signalWork is also used as\n+     * failsafe in case of Thread failures in deregisterWorker.)\n+     *\n+     * Top-Level scheduling\n+     * ====================\n@@ -621,2 +585,2 @@\n-     * permutation on each invocation.  The pseudorandom generator\n-     * need not have high-quality statistical properties in the long\n+     * permutation on each rescan.  The pseudorandom generator need\n+     * not have high-quality statistical properties in the long\n@@ -624,12 +588,1 @@\n-     * from ThreadLocalRandom probes, which are cheap and\n-     * suffice. Each queue's polling attempts to avoid becoming stuck\n-     * when other scanners\/pollers stall.  Scans do not otherwise\n-     * explicitly take into account core affinities, loads, cache\n-     * localities, etc, However, they do exploit temporal locality\n-     * (which usually approximates these) by preferring to re-poll\n-     * from the same queue after a successful poll before trying\n-     * others, which also reduces bookkeeping, cache traffic, and\n-     * scanning overhead. But it also reduces fairness, which is\n-     * partially counteracted by giving up on detected interference\n-     * (which also reduces contention when too many workers try to\n-     * take small tasks from the same queue).\n+     * from ThreadLocalRandom probes, which are cheap and suffice.\n@@ -638,8 +591,35 @@\n-     * it tries to deactivate()), giving up (and rescanning) on \"ctl\"\n-     * contention. To avoid missed signals during deactivation, the\n-     * method rescans and reactivates if there may have been a missed\n-     * signal during deactivation. To reduce false-alarm reactivations\n-     * while doing so, we scan multiple times (analogously to method\n-     * quiescent()) before trying to reactivate.  Because idle workers\n-     * are often not yet blocked (parked), we use a WorkQueue field to\n-     * advertise that a waiter actually needs unparking upon signal.\n+     * it invokes awaitWork, that first deactivates (to an IDLE\n+     * phase).  Avoiding missed signals during deactivation requires a\n+     * (conservative) rescan, reactivating if there may be tasks to\n+     * poll. Because idle workers are often not yet blocked (parked),\n+     * we use a WorkQueue field to advertise that a waiter actually\n+     * needs unparking upon signal.\n+     *\n+     * When tasks are constructed as (recursive) dags, top-level\n+     * scanning is usually infrequent, and doesn't encounter most\n+     * of the following problems addressed by runWorker and awaitWork:\n+     *\n+     * Locality. Polls are organized into \"runs\", continuing until\n+     * empty or contended, while also minimizing interference by\n+     * postponing bookeeping to ends of runs. This may reduce\n+     * fairness, which is partially counteracted by the following.\n+     *\n+     * Contention. When many workers try to poll few queues, they\n+     * often collide, generating CAS failures and disrupting locality\n+     * of workers already running their tasks. This also leads to\n+     * stalls when tasks cannot be taken because other workers have\n+     * not finished poll operations, which is detected by reading\n+     * ahead in queue arrays. In both caes, workers restart scans in a\n+     * way that approximates randomized backoff.\n+     *\n+     * Oversignalling. When many short top-level tasks are present in\n+     * a small number of queues, the above signalling strategy may\n+     * activate many more workers than needed, worsening locality and\n+     * contention problems, while also generating more global\n+     * contention (field is CASed on every activation and\n+     * deactivation). We filter out (both in runWorker and\n+     * signalWork) attempted signals that are surely not needed\n+     * because the signalled tasks are already taken.\n+     *\n+     * Shutdown and Quiescence\n+     * =======================\n@@ -895,3 +875,1 @@\n-     * paths. The inability to rely on caller-runs may also require\n-     * extra signalling (resulting in scanning and contention) so is\n-     * done only conditionally in methods push and runworker.\n+     * paths.\n@@ -975,7 +953,5 @@\n-     * Currently, arrays for workers are initialized to be just large\n-     * enough to avoid resizing in most tree-structured tasks, but\n-     * larger for external queues where both false-sharing problems\n-     * and the need for resizing are more common. (Maintenance note:\n-     * any changes in fields, queues, or their uses, or JVM layout\n-     * policies, must be accompanied by re-evaluation of these\n-     * placement and sizing decisions.)\n+     * Currently, arrays are initialized to be just large enough to\n+     * avoid resizing in most tree-structured tasks, but grow rapidly\n+     * until large.  (Maintenance note: any changes in fields, queues,\n+     * or their uses, or JVM layout policies, must be accompanied by\n+     * re-evaluation of these placement and sizing decisions.)\n@@ -1064,1 +1040,1 @@\n-     * Initial capacity of work-stealing queue array for workers.\n+     * Initial capacity of work-stealing queue array.\n@@ -1069,6 +1045,0 @@\n-    \/**\n-     * Initial capacity of work-stealing queue array for external queues.\n-     * Must be a power of two, at least 2. See above.\n-     *\/\n-    static final int INITIAL_EXTERNAL_QUEUE_CAPACITY = 1 << 9;\n-\n@@ -1251,4 +1221,0 @@\n-            array = new ForkJoinTask<?>[owner == null ?\n-                                        INITIAL_EXTERNAL_QUEUE_CAPACITY :\n-                                        INITIAL_QUEUE_CAPACITY];\n-            this.owner = owner;\n@@ -1256,0 +1222,4 @@\n+            if ((this.owner = owner) == null) {\n+                phase = id | IDLE;\n+                array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n+            }\n@@ -1283,3 +1253,1 @@\n-            if ((a = array) != null && (cap = a.length) > 0 && \/\/ else disabled\n-                task != null) {\n-                int pk = task.noUserHelp() + 1;             \/\/ prev slot offset\n+            if ((a = array) != null && (cap = a.length) > 0) { \/\/ else disabled\n@@ -1293,2 +1261,2 @@\n-                    if (room == 0)                          \/\/ resize\n-                        growArray(a, cap, s);\n+                    if (room == 0 && (a = growArray(a, cap, s)) != null)\n+                        m = a.length - 1;                   \/\/ resize\n@@ -1300,3 +1268,3 @@\n-                if ((room == 0 || a[m & (s - pk)] == null) &&\n-                    pool != null)\n-                    pool.signalWork();   \/\/ may have appeared empty\n+                if (pool != null && a != null &&\n+                    U.getReferenceAcquire(a, slotOffset(m & (s - 1))) == null)\n+                    pool.signalWork(a, m & s);   \/\/ may have appeared empty\n@@ -1311,0 +1279,1 @@\n+         * @return new array, or null on failure\n@@ -1312,2 +1281,3 @@\n-        private void growArray(ForkJoinTask<?>[] a, int cap, int s) {\n-            int newCap = cap << 1;\n+        private ForkJoinTask<?>[] growArray(ForkJoinTask<?>[] a, int cap, int s) {\n+            int newCap = (cap >= 1 << 16) ? cap << 1 : cap << 2;\n+            ForkJoinTask<?>[] newArray = null;\n@@ -1315,1 +1285,0 @@\n-                ForkJoinTask<?>[] newArray = null;\n@@ -1332,0 +1301,1 @@\n+            return newArray;\n@@ -1783,1 +1753,2 @@\n-        if (w != null && (runState & STOP) == 0L) {\n+        if (w != null) {\n+            w.array = new ForkJoinTask<?>[INITIAL_QUEUE_CAPACITY];\n@@ -1861,1 +1832,0 @@\n-            signalWork();                  \/\/ possibly replace\n@@ -1863,0 +1833,1 @@\n+            signalWork(null, 0);           \/\/ possibly replace\n@@ -1869,1 +1840,2 @@\n-     * Releases an idle worker, or creates one if not enough exist.\n+     * Releases an idle worker, or creates one if not enough exist,\n+     * giving up if array a is nonnull and task at a[k] already taken.\n@@ -1871,1 +1843,1 @@\n-    final void signalWork() {\n+    final void signalWork(ForkJoinTask<?>[] a, int k) {\n@@ -1887,1 +1859,1 @@\n-                nc = ((c + TC_UNIT) & TC_MASK);\n+                nc = ((c + TC_UNIT) & TC_MASK) | ac;\n@@ -1892,2 +1864,4 @@\n-                nc = (v.stackPred & LMASK) | (c & TC_MASK);\n-            if (c == (c = compareAndExchangeCtl(c, nc | ac))) {\n+                nc = (v.stackPred & LMASK) | (c & TC_MASK) | ac;\n+            if (a != null && k < a.length && k >= 0 && a[k] == null)\n+                break;\n+            if (c == (c = ctl) && c == (c = compareAndExchangeCtl(c, nc))) {\n@@ -1977,30 +1951,27 @@\n-            int phase = w.phase, r = w.stackPred;     \/\/ seed from registerWorker\n-            int fifo = w.config & FIFO, nsteals = 0, src = -1;\n-            for (;;) {\n-                WorkQueue[] qs;\n-                r ^= r << 13; r ^= r >>> 17; r ^= r << 5; \/\/ xorshift\n-                if ((runState & STOP) != 0L || (qs = queues) == null)\n-                    break;\n-                int n = qs.length, i = r, step = (r >>> 16) | 1;\n-                boolean rescan = false;\n-                scan: for (int l = n; l > 0; --l, i += step) {  \/\/ scan queues\n-                    int j, cap; WorkQueue q; ForkJoinTask<?>[] a;\n-                    if ((q = qs[j = i & (n - 1)]) != null &&\n-                        (a = q.array) != null && (cap = a.length) > 0) {\n-                        for (int m = cap - 1, pb = -1, b = q.base;;) {\n-                            ForkJoinTask<?> t; long k;\n-                            t = (ForkJoinTask<?>)U.getReferenceAcquire(\n-                                a, k = slotOffset(m & b));\n-                            if (b != (b = q.base) || t == null ||\n-                                !U.compareAndSetReference(a, k, t, null)) {\n-                                if (a[b & m] == null) {\n-                                    if (rescan)           \/\/ end of run\n-                                        break scan;\n-                                    if (a[(b + 1) & m] == null &&\n-                                        a[(b + 2) & m] == null) {\n-                                        break;            \/\/ probably empty\n-                                    }\n-                                    if (pb == (pb = b)) { \/\/ track progress\n-                                        rescan = true;    \/\/ stalled; reorder scan\n-                                        break scan;\n-                                    }\n+            int phase = w.phase;\n+            int r = w.stackPred, origin = r;              \/\/ seed from registerWorker\n+            int cfg = w.config, fifo = cfg & FIFO, clearLocals = cfg & CLEAR_TLS;\n+            int src = -1;                                 \/\/ current source queue\n+            int taken = 0, ptaken = 0, staken = 0;        \/\/ takes per phase and scan\n+            rescan: while ((runState & STOP) == 0L) {\n+                WorkQueue[] qs = queues;\n+                int n = (qs == null) ? 0 : qs.length;\n+                int i = origin, step = (r >>> 16) | 1;\n+                r ^= r << 13; r ^= r >>> 17; origin = r ^= r << 5; \/\/ xorshift\n+                for (int l = n; l > 0; --l, i += step) {  \/\/ scan queues\n+                    WorkQueue q; int j;\n+                    if ((q = qs[j = i & (n - 1)]) != null) {\n+                        for (;;) {                        \/\/ poll q\n+                            ForkJoinTask<?>[] a; int cap, b, m, k;\n+                            if ((a = q.array) == null || (cap = a.length) <= 0)\n+                                break;\n+                            long bp = slotOffset(k = (b = q.base) & (m = cap - 1));\n+                            int nb = b + 1, nk = nb & m;\n+                            ForkJoinTask<?> t = (ForkJoinTask<?>)\n+                                U.getReferenceAcquire(a, bp);\n+                            if (q.array != a || q.base != b || a[k] != t)\n+                                continue;                 \/\/ inconsistent\n+                            if (t == null) {\n+                                if (taken != staken) {\n+                                    staken = taken;\n+                                    continue rescan;      \/\/ sweep until clean\n@@ -2008,0 +1979,3 @@\n+                                if (a[nk] != null || a[(b + 2) & m] != null)\n+                                    continue rescan;      \/\/ stalled; reorder scan\n+                                break;                    \/\/ probably empty\n@@ -2009,13 +1983,10 @@\n-                            else {\n-                                boolean propagate;\n-                                int nb = q.base = b + 1, prevSrc = src;\n-                                w.nsteals = ++nsteals;\n-                                w.source = src = j;       \/\/ volatile\n-                                rescan = true;\n-                                int nh = t.noUserHelp();\n-                                if (propagate =\n-                                    (prevSrc != src || nh != 0) && a[nb & m] != null)\n-                                    signalWork();\n-                                w.topLevelExec(t, fifo);\n-                                if ((b = q.base) != nb && !propagate)\n-                                    break scan;          \/\/ reduce interference\n+                            if (U.compareAndSetReference(a, bp, t, null)) {\n+                                q.base = nb;\n+                                Object nt = U.getReferenceAcquire\n+                                    (a, slotOffset(nk));  \/\/ confirm below\n+                                ++taken;\n+                                if (src != j)\n+                                    w.source = src = j;\n+                                if (nt != null && nt == a[nk])\n+                                    signalWork(a, nk);    \/\/ propagate\n+                                w.topLevelExec(t, fifo);  \/\/ run t & its subtasks\n@@ -2026,4 +1997,7 @@\n-                if (!rescan) {\n-                    if (((phase = deactivate(w, phase)) & IDLE) != 0)\n-                        break;\n-                    src = -1;                            \/\/ re-enable propagation\n+                if (taken != ptaken) {                    \/\/ end run\n+                    ptaken = taken;\n+                    origin = src;                         \/\/ hint for next run\n+                    if (clearLocals != 0 &&\n+                        Thread.currentThread() instanceof ForkJoinWorkerThread wt)\n+                        wt.resetThreadLocals();\n+                    w.nsteals = taken;\n@@ -2031,0 +2005,3 @@\n+                w.phase = phase += IDLE;                  \/\/ deactivate\n+                if ((phase = awaitWork(w, phase)) == IDLE)\n+                    break;\n@@ -2035,39 +2012,0 @@\n-    \/**\n-     * Deactivates and if necessary awaits signal or termination.\n-     *\n-     * @param w the worker\n-     * @param phase current phase\n-     * @return current phase, with IDLE set if worker should exit\n-     *\/\n-    private int deactivate(WorkQueue w, int phase) {\n-        if (w == null)                        \/\/ currently impossible\n-            return IDLE;\n-        int p = phase | IDLE, activePhase = phase + (IDLE << 1);\n-        long pc = ctl, qc = (activePhase & LMASK) | ((pc - RC_UNIT) & UMASK);\n-        int sp = w.stackPred = (int)pc;       \/\/ set ctl stack link\n-        w.phase = p;\n-        if (!compareAndSetCtl(pc, qc))        \/\/ try to enqueue\n-            return w.phase = phase;           \/\/ back out on possible signal\n-        int ac = (short)(qc >>> RC_SHIFT), n; long e; WorkQueue[] qs;\n-        if (((e = runState) & STOP) != 0L ||\n-            ((e & SHUTDOWN) != 0L && ac == 0 && quiescent() > 0) ||\n-            (qs = queues) == null || (n = qs.length) <= 0)\n-            return IDLE;                      \/\/ terminating\n-\n-        for (int prechecks = Math.min(ac, 2), \/\/ reactivation threshold\n-             k = Math.max(n + (n << 1), SPIN_WAITS << 1);;) {\n-            WorkQueue q; int cap; ForkJoinTask<?>[] a; long c;\n-            if (w.phase == activePhase)\n-                return activePhase;\n-            if (--k < 0)\n-                return awaitWork(w, p);       \/\/ block, drop, or exit\n-            if ((q = qs[k & (n - 1)]) == null)\n-                Thread.onSpinWait();\n-            else if ((a = q.array) != null && (cap = a.length) > 0 &&\n-                     a[q.base & (cap - 1)] != null && --prechecks < 0 &&\n-                     (int)(c = ctl) == activePhase &&\n-                     compareAndSetCtl(c, (sp & LMASK) | ((c + RC_UNIT) & UMASK)))\n-                return w.phase = activePhase; \/\/ reactivate\n-        }\n-    }\n-\n@@ -2078,2 +2016,2 @@\n-     * @param p current phase (known to be idle)\n-     * @return current phase, with IDLE set if worker should exit\n+     * @param p current phase (known to be idle\n+     * @return current phase or IDLE if worker should exit\n@@ -2082,12 +2020,41 @@\n-        if (w != null) {\n-            ForkJoinWorkerThread t; long deadline;\n-            if ((w.config & CLEAR_TLS) != 0 && (t = w.owner) != null)\n-                t.resetThreadLocals();          \/\/ clear before reactivate\n-            if ((ctl & RC_MASK) > 0L)\n-                deadline = 0L;\n-            else if ((deadline =\n-                      (((w.source != INVALID_ID) ? keepAlive : TIMEOUT_SLOP)) +\n-                      System.currentTimeMillis()) == 0L)\n-                deadline = 1L;                 \/\/ avoid zero\n-            int activePhase = p + IDLE;\n-            if ((p = w.phase) != activePhase && (runState & STOP) == 0L) {\n+        if (w == null)                        \/\/ never true; hoist checks\n+            return IDLE;\n+        int activePhase = p + IDLE;\n+        long ap = activePhase & LMASK, pc = ctl, qc;\n+        do {                                  \/\/ enqueue\n+            qc = ap | ((pc - RC_UNIT) & UMASK);\n+            w.stackPred = (int)pc;            \/\/ set ctl stack link\n+        } while (pc != (pc = compareAndExchangeCtl(pc, qc)));\n+        long psp = pc & LMASK;                \/\/ reactivation stack prefix\n+        WorkQueue[] qs; int n;                \/\/ missed signal check\n+        if ((runState & STOP) != 0 || (qs = queues) == null || (n = qs.length) <= 0)\n+            return IDLE;                      \/\/ already terminating\n+        for (int m = n - 1, origin = p + 1, i = 0; i < m; ++i) {\n+            WorkQueue q; long cc;             \/\/ stagger origins\n+            if ((q = qs[(origin + i) & m]) != null && q.top - q.base > 0) {\n+                if ((p = w.phase) == activePhase)\n+                    break;\n+                if ((int)(cc = ctl) == activePhase &&\n+                    compareAndSetCtl(cc, psp | ((cc + RC_UNIT) & UMASK))) {\n+                    p = w.phase = activePhase;\n+                    break;                    \/\/ reactivated\n+                }\n+            }\n+        }\n+        if (p != activePhase && (p = w.phase) != activePhase) {\n+            long deadline = 0L, c, e;         \/\/ quiescence checks\n+            if (((e = runState) & STOP) != 0)\n+                return IDLE;\n+            else if ((int)(c = ctl) != activePhase || (c & RC_MASK) > 0L) {\n+                for (int spins = n; (p = w.phase) != activePhase && --spins > 0;)\n+                    Thread.onSpinWait();      \/\/ spin unless possibly quiescent\n+            }\n+            else if ((e & SHUTDOWN) != 0L && quiescent() > 0)\n+                return IDLE;                  \/\/ quiescent termination\n+            else {                            \/\/ use trim timeout\n+                long d = ((w.source != INVALID_ID) ? keepAlive :\n+                          TIMEOUT_SLOP) + System.currentTimeMillis();\n+                deadline = (d == 0L)? 1L : d; \/\/ avoid zero\n+                p = w.phase;\n+            }\n+            if (p != activePhase) {           \/\/ block\n@@ -2095,1 +2062,1 @@\n-                w.parking = 1;                 \/\/ enable unpark\n+                w.parking = 1;                \/\/ enable unpark\n@@ -2098,1 +2065,1 @@\n-                    Thread.interrupted();      \/\/ clear status\n+                    Thread.interrupted();     \/\/ clear status\n@@ -2113,0 +2080,2 @@\n+                if (p != activePhase)\n+                    return IDLE;\n@@ -2115,1 +2084,1 @@\n-        return p;\n+        return activePhase;\n@@ -2564,2 +2533,1 @@\n-     * throws RejectedExecutionException if shutdown or terminating.\n-     * @param r current ThreadLocalRandom.getProbe() value\n+     * throws RejectedExecutionException if shutdown\n@@ -2567,1 +2535,1 @@\n-     *        should be thrown when shutdown (else only if terminating)\n+     *        should be thrown when shutdown\n@@ -2569,4 +2537,4 @@\n-    private WorkQueue submissionQueue(int r, boolean rejectOnShutdown) {\n-        int reuse;                                   \/\/ nonzero if prefer create\n-        if ((reuse = r) == 0) {\n-            ThreadLocalRandom.localInit();           \/\/ initialize caller's probe\n+    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n+        int r;\n+        if ((r = ThreadLocalRandom.getProbe()) == 0) {\n+            ThreadLocalRandom.localInit();   \/\/ initialize caller's probe\n@@ -2575,5 +2543,3 @@\n-        for (int probes = 0; ; ++probes) {\n-            int n, i, id; WorkQueue[] qs; WorkQueue q;\n-            if ((qs = queues) == null)\n-                break;\n-            if ((n = qs.length) <= 0)\n+        for (;;) {\n+            WorkQueue q; WorkQueue[] qs; int n, id, i;\n+            if ((qs = queues) == null || (n = qs.length) <= 0)\n@@ -2582,6 +2548,4 @@\n-                WorkQueue w = new WorkQueue(null, id, 0, false);\n-                w.phase = id;\n-                boolean reject = ((lockRunState() & SHUTDOWN) != 0 &&\n-                                  rejectOnShutdown);\n-                if (!reject && queues == qs && qs[i] == null)\n-                    q = qs[i] = w;                   \/\/ else lost race to install\n+                WorkQueue newq = new WorkQueue(null, id, 0, false);\n+                lockRunState();\n+                if (qs[i] == null && queues == qs)\n+                    q = qs[i] = newq;         \/\/ else lost race to install\n@@ -2589,5 +2553,0 @@\n-                if (q != null)\n-                    return q;\n-                if (reject)\n-                    break;\n-                reuse = 0;\n@@ -2595,4 +2554,4 @@\n-            if (reuse == 0 || !q.tryLockPhase()) {   \/\/ move index\n-                if (reuse == 0) {\n-                    if (probes >= n >> 1)\n-                        reuse = r;                   \/\/ stop prefering free slot\n+            if (q != null && q.tryLockPhase()) {\n+                if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n+                    q.unlockPhase();          \/\/ check while q lock held\n+                    break;\n@@ -2600,9 +2559,0 @@\n-                else if (q != null)\n-                    reuse = 0;                       \/\/ probe on collision\n-                r = ThreadLocalRandom.advanceProbe(r);\n-            }\n-            else if (rejectOnShutdown && (runState & SHUTDOWN) != 0L) {\n-                q.unlockPhase();                     \/\/ check while q lock held\n-                break;\n-            }\n-            else\n@@ -2610,0 +2560,2 @@\n+            }\n+            r = ThreadLocalRandom.advanceProbe(r); \/\/ move\n@@ -2623,1 +2575,1 @@\n-            q = submissionQueue(ThreadLocalRandom.getProbe(), true);\n+            q = externalSubmissionQueue(true);\n@@ -2629,12 +2581,0 @@\n-    \/**\n-     * Returns queue for an external submission, bypassing call to\n-     * submissionQueue if already established and unlocked.\n-     *\/\n-    final WorkQueue externalSubmissionQueue(boolean rejectOnShutdown) {\n-        WorkQueue[] qs; WorkQueue q; int n;\n-        int r = ThreadLocalRandom.getProbe();\n-        return (((qs = queues) != null && (n = qs.length) > 0 &&\n-                 (q = qs[r & EXTERNAL_ID_MASK & (n - 1)]) != null && r != 0 &&\n-                 q.tryLockPhase()) ? q : submissionQueue(r, rejectOnShutdown));\n-    }\n-\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/ForkJoinPool.java","additions":205,"deletions":265,"binary":false,"changes":470,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+import java.util.concurrent.ForkJoinTask;\n@@ -45,1 +46,1 @@\n-    public static void main(String[] args) throws Exception {\n+    static void testSubmitExternalCallable() throws Exception {\n@@ -56,0 +57,17 @@\n+\n+    static void testSubmitAdaptedCallable() throws Exception {\n+        try (var pool = new ForkJoinPool(2)) {\n+            for (int i = 0; i < 100_000; i++) {\n+                var future1 = pool.submit(new AwaitCount(i));\n+                var future2 = pool.submit(ForkJoinTask.adapt(noop));\n+                future2.get();\n+                count.set(i + 1);\n+                future1.get();\n+            }\n+        }\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        testSubmitExternalCallable();\n+        testSubmitAdaptedCallable();\n+    }\n","filename":"test\/jdk\/java\/util\/concurrent\/forkjoin\/Starvation.java","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"}]}