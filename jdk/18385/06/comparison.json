{"files":[{"patch":"@@ -37,2 +37,9 @@\n- * This class implements a stream filter for reading compressed data in\n- * the GZIP file format.\n+ * This class implements a stream filter for reading compressed data in the GZIP file format.\n+ *\n+ * <p>\n+ * The GZIP compressed data format is self-delimiting, i.e., it includes an explicit trailer\n+ * frame that marks the end of the compressed data. Therefore it's possible for the underlying\n+ * input to contain additional data beyond the end of the compressed GZIP data. In particular,\n+ * some GZIP compression tools will concatenate multiple compressed data streams together.\n+ * This class includes configurable support for decompressing multiple concatenated compressed\n+ * data streams as a single uncompressed data stream.\n@@ -56,0 +63,2 @@\n+    private final ConcatPolicy policy;\n+\n@@ -68,1 +77,3 @@\n-     * Creates a new input stream with the specified buffer size.\n+     * Creates a new input stream with the specified buffer size that will decode\n+     * concatenated GZIP streams according to {@link ConcatPolicy#ALLOW_LENIENT}.\n+     *\n@@ -79,0 +90,65 @@\n+        this(in, size, ConcatPolicy.ALLOW_LENIENT);\n+    }\n+\n+    \/**\n+     * Creates a new input stream with the default buffer size that will decode\n+     * concatenated GZIP streams according to {@link ConcatPolicy#ALLOW_LENIENT}.\n+     *\n+     * @param in the input stream\n+     *\n+     * @throws    ZipException if a GZIP format error has occurred or the\n+     *                         compression method used is unsupported\n+     * @throws    NullPointerException if {@code in} is null\n+     * @throws    IOException if an I\/O error has occurred\n+     *\/\n+    public GZIPInputStream(InputStream in) throws IOException {\n+        this(in, 512, ConcatPolicy.ALLOW_LENIENT);\n+    }\n+\n+    \/**\n+     * Creates a new input stream with the specified buffer size that will decode\n+     * concatenated GZIP streams according to the specified {@link ConcatPolicy}.\n+     *\n+     * <p>\n+     * When configured with {@link ConcatPolicy#DISALLOW}, decompression stops after the end of\n+     * the first compressed data stream (i.e., after encountering a GZIP trailer frame), and any\n+     * additional bytes in the input stream will cause an {@link IOException} to be thrown.\n+     *\n+     * <p>\n+     * When configured with {@link ConcatPolicy#ALLOW} or {@link ConcatPolicy#ALLOW_LENIENT},\n+     * this class will attempt to decode any data that follows a GZIP trailer frame as the GZIP\n+     * header frame of a new compressed data stream and proceed to decompress it. As a result,\n+     * arbitrarily many consecutive compressed data streams in the underlying input will be read\n+     * back as a single uncompressed stream.\n+     *\n+     * <p>\n+     * The choice between {@link ConcatPolicy#ALLOW} and {@link ConcatPolicy#ALLOW_LENIENT}\n+     * affects how an invalid GZIP header frame following a GZIP trailer frame is handled.\n+     * With {@link ConcatPolicy#ALLOW_LENIENT}, if the GZIP header frame is invalid, or reading it\n+     * generates an {@link IOException}, then the additional bytes read are discarded and EOF is returned.\n+     * In this scenario, it is indeterminate (a) how many additional bytes (if any) were read beyond the\n+     * GZIP trailer frame, and (b) whether reading stopped due to EOF, invalid data, or an underlying\n+     * {@link IOException}.\n+     *\n+     * <p>\n+     * With {@link ConcatPolicy#ALLOW}, an invalid GZIP header frame always triggers an {@link IOException},\n+     * and any {@link IOException} thrown while trying to read a GZIP header frame is propagated to the caller.\n+     * In this scenario, every byte of the underlying input stream must be part of a complete and valid\n+     * compressed data stream, or else an {@link IOException} is guaranteed to be thrown.\n+     *\n+     * @apiNote The original behavior of this class is replicated by {@link ConcatPolicy#ALLOW_LENIENT}.\n+     * However, use of {@link ConcatPolicy#ALLOW_LENIENT} is discouraged because of its imprecision in how\n+     * many additional bytes are read and the possibility that {@link IOException}s and\/or data corruption\n+     * in the underlying input stream can go undetected.\n+     *\n+     * @param in the input stream\n+     * @param size the input buffer size\n+     * @param policy policy regarding concatenated GZIP streams\n+     *\n+     * @throws    ZipException if a GZIP format error has occurred or the\n+     *                         compression method used is unsupported\n+     * @throws    NullPointerException if {@code in} or {@code policy} is null\n+     * @throws    IOException if an I\/O error has occurred\n+     * @since     24\n+     *\/\n+    public GZIPInputStream(InputStream in, int size, ConcatPolicy policy) throws IOException {\n@@ -80,0 +156,1 @@\n+        this.policy = Objects.requireNonNull(policy, \"policy\");\n@@ -82,1 +159,1 @@\n-            readHeader(in);\n+            readHeader(in, -1);\n@@ -104,13 +181,0 @@\n-    \/**\n-     * Creates a new input stream with a default buffer size.\n-     * @param in the input stream\n-     *\n-     * @throws    ZipException if a GZIP format error has occurred or the\n-     *                         compression method used is unsupported\n-     * @throws    NullPointerException if {@code in} is null\n-     * @throws    IOException if an I\/O error has occurred\n-     *\/\n-    public GZIPInputStream(InputStream in) throws IOException {\n-        this(in, 512);\n-    }\n-\n@@ -192,1 +256,3 @@\n-     * of this member header.\n+     * of this member header. Use the given value as the first byte\n+     * if not equal to -1 (and include it in the returned byte count).\n+     * Throws EOFException if there's not enough input data.\n@@ -194,1 +260,1 @@\n-    private int readHeader(InputStream this_in) throws IOException {\n+    private int readHeader(InputStream this_in, int firstByte) throws IOException {\n@@ -198,1 +264,4 @@\n-        if (readUShort(in) != GZIP_MAGIC) {\n+        int byte1 = firstByte != -1 ? firstByte : readUByte(in);\n+        int byte2 = readUByte(in);\n+        int magic = (byte2 << 8) | byte1;\n+        if (magic != GZIP_MAGIC) {\n@@ -261,6 +330,25 @@\n-        \/\/ try concatenated case\n-        int m = 8;                  \/\/ this.trailer\n-        try {\n-            m += readHeader(in);    \/\/ next.header\n-        } catch (IOException ze) {\n-            return true;  \/\/ ignore any malformed, do nothing\n+        \/\/ Keep track of how many bytes of buffered data we may have read\n+        int m = 8;                                          \/\/ this.trailer\n+\n+        \/\/ Handle concatenation and\/or extra bytes\n+        if (policy.equals(ConcatPolicy.ALLOW_LENIENT)) {    \/\/ i.e., the legacy behavior\n+            try {\n+                m += readHeader(in, -1);                    \/\/ next.header\n+            } catch (IOException ze) {\n+                return true;  \/\/ ignore any malformed, do nothing\n+            }\n+        } else {\n+\n+            \/\/ If there is no more data, the input has terminated at a proper GZIP boundary\n+            int nextByte = in.read();\n+            if (nextByte == -1)\n+                return true;\n+\n+            \/\/ There is more data; verify that we are allowing concatenation\n+            if (!policy.isAllowsConcatenation()) {\n+                assert !policy.isLenient();\n+                throw new ZipException(\"Extra bytes after GZIP trailer\");\n+            }\n+\n+            \/\/ Read in the next header\n+            m += readHeader(in, nextByte);                  \/\/ next.header\n@@ -268,0 +356,2 @@\n+\n+        \/\/ Pass along any remaining buffered data to the new inflater\n@@ -321,0 +411,68 @@\n+\n+    \/**\n+     * Policy relating to the handling of an input stream containing multiple concatenated GZIP streams.\n+     *\n+     * @since 24\n+     *\/\n+    public enum ConcatPolicy {\n+\n+        \/**\n+         * Disallow concatenated GZIP streams.\n+         *\n+         * <p>\n+         * If any bytes follow the GZIP trailer frame, an {@link IOException} is thrown.\n+         *\/\n+        DISALLOW(false, false),\n+\n+        \/**\n+         * Allow concatenated GZIP streams.\n+         *\n+         * <p>\n+         * Any data that follows a GZIP trailer frame must constitute the valid GZIP header frame\n+         * of a new GZIP compressed stream.\n+         *\/\n+        ALLOW(true, false),\n+\n+        \/**\n+         * Allow concatenated GZIP streams with leniency for extra trailing data.\n+         *\n+         * <p>\n+         * Any data that follows a GZIP trailer frame but does not constitute a valid GZIP header\n+         * frame, or triggers an {@link IOException}, is discarded and ignored.\n+         *\/\n+        ALLOW_LENIENT(true, true);\n+\n+        private final boolean allowsConcatenation;\n+        private final boolean lenient;\n+\n+        \/**\n+         * Determine whether this policy permits the decoding of multiple concatenated GZIP streams\n+         * as a single output stream.\n+         *\n+         * <p>\n+         * Returns true for {@link #ALLOW} and {@link #ALLOW_LENIENT}.\n+         *\n+         * @return true if multiple concatenated GZIP streams are allowed\n+         *\/\n+        public boolean isAllowsConcatenation() {\n+            return this.allowsConcatenation;\n+        }\n+\n+        \/**\n+         * Determine whether this policy permits extra bytes following a GZIP trailer frame that do not\n+         * constitute a proper GZIP header frame.\n+         *\n+         * <p>\n+         * Returns true for {@link #ALLOW_LENIENT}.\n+         *\n+         * @return true if this policy is lenient towards extra bytes\n+         *\/\n+        public boolean isLenient() {\n+            return this.lenient;\n+        }\n+\n+        private ConcatPolicy(boolean allowsConcatenation, boolean lenient) {\n+            this.allowsConcatenation = allowsConcatenation;\n+            this.lenient = lenient;\n+        }\n+    }\n","filename":"src\/java.base\/share\/classes\/java\/util\/zip\/GZIPInputStream.java","additions":184,"deletions":26,"binary":false,"changes":210,"status":"modified"},{"patch":"@@ -0,0 +1,186 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/* @test\n+ * @bug 8322256\n+ * @summary Test configurable support for concatenated gzip streams\n+ * @run junit GZIPInputStreamConcat\n+ *\/\n+\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.MethodSource;\n+\n+import java.io.*;\n+import java.util.*;\n+import java.util.stream.*;\n+import java.util.zip.*;\n+\n+import static java.util.zip.GZIPInputStream.ConcatPolicy;\n+\n+import static org.junit.jupiter.api.Assertions.assertArrayEquals;\n+\n+public class GZIPInputStreamConcat {\n+\n+    private int bufsize;\n+    private ConcatPolicy policy;\n+\n+    public static Stream<Object[]> testScenarios() throws IOException {\n+\n+        \/\/ Test concat vs. non-concat, garbage vs. no-garbage, and various buffer sizes on random data\n+        Random random = new Random();\n+        final ArrayList<List<Object>> scenarios = new ArrayList<>();\n+        for (ConcatPolicy policy : ConcatPolicy.values()) {\n+            for (int size = 1; size < 1024; size += random.nextInt(32) + 1) {\n+                scenarios.add(List.of(randomData(0, 100), size, policy));\n+            }\n+        }\n+        return scenarios.stream().map(List::toArray);\n+    }\n+\n+    @ParameterizedTest\n+    @MethodSource(\"testScenarios\")\n+    public void testScenario(byte[] uncompressed, int size, ConcatPolicy policy) throws IOException {\n+        this.bufsize = size;\n+        this.policy = policy;\n+        testScenario(uncompressed);\n+    }\n+\n+    public void testScenario(byte[] uncompressed) throws IOException {\n+\n+        \/\/ Compress the test data\n+        byte[] compressed = deflate(uncompressed);\n+\n+        \/\/ Decompress a single stream with no extra garbage - should always work\n+        byte[] input = compressed;\n+        byte[] output = uncompressed;\n+        testDecomp(input, output, null);\n+\n+        \/\/ Decompress a truncated GZIP header\n+        input = oneByteShort(gzipHeader());\n+        testDecomp(input, null, EOFException.class);\n+\n+        \/\/ Decompress a single stream that is one byte short - should always fail\n+        input = oneByteShort(compressed);\n+        output = null;\n+        testDecomp(input, null, EOFException.class);\n+\n+        \/\/ Decompress a single stream with one byte of extra garbage (trying all 256 possible values)\n+        for (int extra = 0; extra < 0x100; extra++) {\n+            input = oneByteLong(compressed, extra);\n+            output = uncompressed;\n+            testDecomp(input, output, !policy.isLenient() ? IOException.class : null);\n+        }\n+\n+        \/\/ Decompress a single stream followed by a truncated GZIP header\n+        input = concat(compressed, oneByteShort(gzipHeader()));\n+        output = uncompressed;\n+        testDecomp(input, output, !policy.isLenient() ? IOException.class : null);\n+\n+        \/\/ Decompress a single stream followed by another stream that is one byte short\n+        input = concat(compressed, oneByteShort(compressed));\n+        output = uncompressed;\n+        testDecomp(input, output, policy.isAllowsConcatenation() || !policy.isLenient() ? IOException.class : null);\n+\n+        \/\/ Decompress two streams concatenated\n+        input = concat(compressed, compressed);\n+        output = policy.isAllowsConcatenation() ? concat(uncompressed, uncompressed) : uncompressed;\n+        testDecomp(input, output, !policy.isAllowsConcatenation() && !policy.isLenient() ? ZipException.class : null);\n+\n+        \/\/ Decompress three streams concatenated\n+        input = concat(compressed, compressed, compressed);\n+        output = policy.isAllowsConcatenation() ? concat(uncompressed, uncompressed, uncompressed) : uncompressed;\n+        testDecomp(input, output, !policy.isAllowsConcatenation() && !policy.isLenient() ? ZipException.class : null);\n+\n+        \/\/ Decompress three streams concatenated followed by a truncated GZIP header\n+        input = concat(compressed, compressed, compressed, oneByteShort(gzipHeader()));\n+        output = policy.isAllowsConcatenation() ? concat(uncompressed, uncompressed, uncompressed) : uncompressed;\n+        testDecomp(input, output, !policy.isLenient() ? IOException.class : null);\n+    }\n+\n+    \/\/ Do decompression and check result\n+    public void testDecomp(byte[] compressed, byte[] uncompressed, Class<? extends IOException> exceptionType) {\n+        try {\n+            byte[] readback = inflate(new ByteArrayInputStream(compressed));\n+            if (exceptionType != null)\n+                throw new AssertionError(\"expected \" + exceptionType.getSimpleName());\n+            assertArrayEquals(uncompressed, readback);\n+        } catch (IOException e) {\n+            if (exceptionType == null)\n+                throw new AssertionError(\"unexpected exception\", e);\n+            if (!exceptionType.isAssignableFrom(e.getClass())) {\n+                throw new AssertionError(String.format(\n+                  \"expected %s but got %s\", exceptionType.getSimpleName(), e.getClass().getSimpleName()), e);\n+            }\n+        }\n+    }\n+\n+    \/\/ Create a GZIP header\n+    public static byte[] gzipHeader() throws IOException {\n+        byte[] compressed = deflate(new byte[0]);\n+        return Arrays.copyOfRange(compressed, 0, 10);\n+    }\n+\n+    \/\/ Add one extra byte to the given array\n+    public static byte[] oneByteLong(byte[] array, int value) {\n+        byte[] array2 = new byte[array.length + 1];\n+        System.arraycopy(array, 0, array2, 0, array.length);\n+        array2[array.length] = (byte)value;\n+        return array2;\n+    }\n+\n+    \/\/ Chop off the last byte of the given array\n+    public static byte[] oneByteShort(byte[] array) {\n+        return Arrays.copyOfRange(array, 0, array.length - 1);\n+    }\n+\n+    \/\/ Create some random data\n+    public static byte[] randomData(int min, int max) {\n+        Random random = new Random();\n+        byte[] data = new byte[min + random.nextInt(max - min)];\n+        random.nextBytes(data);\n+        return data;\n+    }\n+\n+    \/\/ Concatenate byte arrays\n+    public static byte[] concat(byte[]... arrays) {\n+        final ByteArrayOutputStream buf = new ByteArrayOutputStream();\n+        for (byte[] array : arrays)\n+            buf.writeBytes(array);\n+        return buf.toByteArray();\n+    }\n+\n+    \/\/ GZIP compress data\n+    public static byte[] deflate(byte[] data) throws IOException {\n+        ByteArrayOutputStream buf = new ByteArrayOutputStream();\n+        try (GZIPOutputStream out = new GZIPOutputStream(buf)) {\n+            out.write(data);\n+        }\n+        return buf.toByteArray();\n+    }\n+\n+    \/\/ GZIP decompress data\n+    public byte[] inflate(InputStream in) throws IOException {\n+        return new GZIPInputStream(in, bufsize, policy).readAllBytes();\n+    }\n+}\n","filename":"test\/jdk\/java\/util\/zip\/GZIP\/GZIPInputStreamConcat.java","additions":186,"deletions":0,"binary":false,"changes":186,"status":"added"}]}