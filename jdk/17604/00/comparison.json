{"files":[{"patch":"@@ -192,1 +192,0 @@\n-      is_marked_reduction(n) ||\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,1 +67,1 @@\n-        for (int i = 0; i < data.length; i++) {\n+        for (int i = 0; i < data.length; i+=2) {\n@@ -80,0 +80,11 @@\n+\n+            \/\/ This example used to rely on that reductions were ignored in SuperWord::unrolling_analysis,\n+            \/\/ and hence the largest data type in the loop was the ints. This would then unroll the doubles\n+            \/\/ for twice the vector length, and this resulted in us having twice as many packs. Because of\n+            \/\/ the store \"data[0] = 0\", the first packs were destroyed, since they do not have power of 2\n+            \/\/ size.\n+            \/\/ Now, we no longer ignore reductions, and now we unroll half as much before SuperWord. This\n+            \/\/ means we would only get one pack per operation, and that one would get ruined, and we have\n+            \/\/ no vectorization. We now ensure there are again 2 packs per operation with a 2x hand unroll.\n+            int v2 = data[i + 1];\n+            sum |= v2;\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"}]}