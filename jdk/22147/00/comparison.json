{"files":[{"patch":"@@ -2486,0 +2486,208 @@\n+void G1CMTask::process_current_region(G1CMBitMapClosure& bitmap_closure) {\n+  if (has_aborted() || _curr_region == nullptr) {\n+    return;\n+  }\n+\n+  \/\/ This means that we're already holding on to a region.\n+  assert(_finger != nullptr, \"if region is not null, then the finger \"\n+         \"should not be null either\");\n+\n+  \/\/ We might have restarted this task after an evacuation pause\n+  \/\/ which might have evacuated the region we're holding on to\n+  \/\/ underneath our feet. Let's read its limit again to make sure\n+  \/\/ that we do not iterate over a region of the heap that\n+  \/\/ contains garbage (update_region_limit() will also move\n+  \/\/ _finger to the start of the region if it is found empty).\n+  update_region_limit();\n+  \/\/ We will start from _finger not from the start of the region,\n+  \/\/ as we might be restarting this task after aborting half-way\n+  \/\/ through scanning this region. In this case, _finger points to\n+  \/\/ the address where we last found a marked object. If this is a\n+  \/\/ fresh region, _finger points to start().\n+  MemRegion mr = MemRegion(_finger, _region_limit);\n+\n+  assert(!_curr_region->is_humongous() || mr.start() == _curr_region->bottom(),\n+         \"humongous regions should go around loop once only\");\n+\n+  \/\/ Some special cases:\n+  \/\/ If the memory region is empty, we can just give up the region.\n+  \/\/ If the current region is humongous then we only need to check\n+  \/\/ the bitmap for the bit associated with the start of the object,\n+  \/\/ scan the object if it's live, and give up the region.\n+  \/\/ Otherwise, let's iterate over the bitmap of the part of the region\n+  \/\/ that is left.\n+  \/\/ If the iteration is successful, give up the region.\n+  if (mr.is_empty()) {\n+    giveup_current_region();\n+    abort_marking_if_regular_check_fail();\n+  } else if (_curr_region->is_humongous() && mr.start() == _curr_region->bottom()) {\n+    if (_mark_bitmap->is_marked(mr.start())) {\n+      \/\/ The object is marked - apply the closure\n+      bitmap_closure.do_addr(mr.start());\n+    }\n+    \/\/ Even if this task aborted while scanning the humongous object\n+    \/\/ we can (and should) give up the current region.\n+    giveup_current_region();\n+    abort_marking_if_regular_check_fail();\n+  } else if (_mark_bitmap->iterate(&bitmap_closure, mr)) {\n+    giveup_current_region();\n+    abort_marking_if_regular_check_fail();\n+  } else {\n+    assert(has_aborted(), \"currently the only way to do so\");\n+    \/\/ The only way to abort the bitmap iteration is to return\n+    \/\/ false from the do_bit() method. However, inside the\n+    \/\/ do_bit() method we move the _finger to point to the\n+    \/\/ object currently being looked at. So, if we bail out, we\n+    \/\/ have definitely set _finger to something non-null.\n+    assert(_finger != nullptr, \"invariant\");\n+\n+    \/\/ Region iteration was actually aborted. So now _finger\n+    \/\/ points to the address of the object we last scanned. If we\n+    \/\/ leave it there, when we restart this task, we will rescan\n+    \/\/ the object. It is easy to avoid this. We move the finger by\n+    \/\/ enough to point to the next possible object header.\n+    assert(_finger < _region_limit, \"invariant\");\n+    HeapWord* const new_finger = _finger + cast_to_oop(_finger)->size();\n+    if (new_finger >= _region_limit) {\n+      giveup_current_region();\n+    } else {\n+      move_finger_to(new_finger);\n+    }\n+  }\n+}\n+\n+void G1CMTask::claim_new_region() {\n+  \/\/ Read the note on the claim_region() method on why it might\n+  \/\/ return null with potentially more regions available for\n+  \/\/ claiming and why we have to check out_of_regions() to determine\n+  \/\/ whether we're done or not.\n+  while (!has_aborted() && _curr_region == nullptr && !_cm->out_of_regions()) {\n+    \/\/ We are going to try to claim a new region. We should have\n+    \/\/ given up on the previous one.\n+    \/\/ Separated the asserts so that we know which one fires.\n+    assert(_curr_region  == nullptr, \"invariant\");\n+    assert(_finger       == nullptr, \"invariant\");\n+    assert(_region_limit == nullptr, \"invariant\");\n+    G1HeapRegion* claimed_region = _cm->claim_region(_worker_id);\n+    if (claimed_region != nullptr) {\n+      \/\/ Yes, we managed to claim one\n+      setup_for_region(claimed_region);\n+      assert(_curr_region == claimed_region, \"invariant\");\n+    }\n+    \/\/ It is important to call the regular clock here. It might take\n+    \/\/ a while to claim a region if, for example, we hit a large\n+    \/\/ block of empty regions. So we need to call the regular clock\n+    \/\/ method once round the loop to make sure it's called\n+    \/\/ frequently enough.\n+    abort_marking_if_regular_check_fail();\n+  }\n+}\n+\n+void G1CMTask::attempt_stealing() {\n+  \/\/ We cannot check whether the global stack is empty, since other\n+  \/\/ tasks might be pushing objects to it concurrently.\n+  assert(_cm->out_of_regions() && _task_queue->size() == 0,\n+         \"only way to reach here\");\n+  while (!has_aborted()) {\n+    G1TaskQueueEntry entry;\n+    if (_cm->try_stealing(_worker_id, entry)) {\n+      scan_task_entry(entry);\n+\n+      \/\/ And since we're towards the end, let's totally drain the\n+      \/\/ local queue and global stack.\n+      drain_local_queue(false);\n+      drain_global_stack(false);\n+    } else {\n+      break;\n+    }\n+  }\n+}\n+\n+void G1CMTask::attempt_termination(bool is_serial) {\n+  \/\/ We cannot check whether the global stack is empty, since other\n+  \/\/ tasks might be concurrently pushing objects on it.\n+  \/\/ Separated the asserts so that we know which one fires.\n+  assert(_cm->out_of_regions(), \"only way to reach here\");\n+  assert(_task_queue->size() == 0, \"only way to reach here\");\n+  double termination_start_time_ms = os::elapsedTime() * 1000.0;\n+\n+  \/\/ The G1CMTask class also extends the TerminatorTerminator class,\n+  \/\/ hence its should_exit_termination() method will also decide\n+  \/\/ whether to exit the termination protocol or not.\n+  bool finished = (is_serial ||\n+                   _cm->terminator()->offer_termination(this));\n+  _termination_time_ms += (os::elapsedTime() * 1000.0 - termination_start_time_ms);\n+\n+  if (finished) {\n+    \/\/ We're all done.\n+\n+    \/\/ We can now guarantee that the global stack is empty, since\n+    \/\/ all other tasks have finished. We separated the guarantees so\n+    \/\/ that, if a condition is false, we can immediately find out\n+    \/\/ which one.\n+    guarantee(_cm->out_of_regions(), \"only way to reach here\");\n+    guarantee(_cm->mark_stack_empty(), \"only way to reach here\");\n+    guarantee(_task_queue->size() == 0, \"only way to reach here\");\n+    guarantee(!_cm->has_overflown(), \"only way to reach here\");\n+    guarantee(!has_aborted(), \"should never happen if termination has completed\");\n+  } else {\n+    \/\/ Apparently there's more work to do. Let's abort this task. We\n+    \/\/ will restart it and hopefully we can find more things to do.\n+    set_has_aborted();\n+  }\n+}\n+\n+void G1CMTask::handle_abort(bool is_serial, double elapsed_time_ms) {\n+  if (_has_timed_out) {\n+    double diff_ms = elapsed_time_ms - _time_target_ms;\n+    \/\/ Keep statistics of how well we did with respect to hitting\n+    \/\/ our target only if we actually timed out (if we aborted for\n+    \/\/ other reasons, then the results might get skewed).\n+    _marking_step_diff_ms.add(diff_ms);\n+  }\n+\n+  if (!_cm->has_overflown()) {\n+    return;\n+  }\n+\n+  \/\/ This is the interesting one. We aborted because a global\n+  \/\/ overflow was raised. This means we have to restart the\n+  \/\/ marking phase and start iterating over regions. However, in\n+  \/\/ order to do this we have to make sure that all tasks stop\n+  \/\/ what they are doing and re-initialize in a safe manner. We\n+  \/\/ will achieve this with the use of two barrier sync points.\n+  if (!is_serial) {\n+    \/\/ We only need to enter the sync barrier if being called\n+    \/\/ from a parallel context\n+    _cm->enter_first_sync_barrier(_worker_id);\n+\n+    \/\/ When we exit this sync barrier we know that all tasks have\n+    \/\/ stopped doing marking work. So, it's now safe to\n+    \/\/ re-initialize our data structures.\n+  }\n+\n+  clear_region_fields();\n+  flush_mark_stats_cache();\n+\n+  if (!is_serial) {\n+    \/\/ If we're executing the concurrent phase of marking, reset the marking\n+    \/\/ state; otherwise the marking state is reset after reference processing,\n+    \/\/ during the remark pause.\n+    \/\/ If we reset here as a result of an overflow during the remark we will\n+    \/\/ see assertion failures from any subsequent set_concurrency_and_phase()\n+    \/\/ calls.\n+    if (_cm->concurrent() && _worker_id == 0) {\n+      \/\/ Worker 0 is responsible for clearing the global data structures because\n+      \/\/ of an overflow. During STW we should not clear the overflow flag (in\n+      \/\/ G1ConcurrentMark::reset_marking_state()) since we rely on it being true when we exit\n+      \/\/ method to abort the pause and restart concurrent marking.\n+      _cm->reset_marking_for_restart();\n+\n+      log_info(gc, marking)(\"Concurrent Mark reset for overflow\");\n+    }\n+\n+    \/\/ ...and enter the second barrier.\n+    _cm->enter_second_sync_barrier(_worker_id);\n+  }\n+}\n+\n@@ -2656,69 +2864,1 @@\n-    if (!has_aborted() && _curr_region != nullptr) {\n-      \/\/ This means that we're already holding on to a region.\n-      assert(_finger != nullptr, \"if region is not null, then the finger \"\n-             \"should not be null either\");\n-\n-      \/\/ We might have restarted this task after an evacuation pause\n-      \/\/ which might have evacuated the region we're holding on to\n-      \/\/ underneath our feet. Let's read its limit again to make sure\n-      \/\/ that we do not iterate over a region of the heap that\n-      \/\/ contains garbage (update_region_limit() will also move\n-      \/\/ _finger to the start of the region if it is found empty).\n-      update_region_limit();\n-      \/\/ We will start from _finger not from the start of the region,\n-      \/\/ as we might be restarting this task after aborting half-way\n-      \/\/ through scanning this region. In this case, _finger points to\n-      \/\/ the address where we last found a marked object. If this is a\n-      \/\/ fresh region, _finger points to start().\n-      MemRegion mr = MemRegion(_finger, _region_limit);\n-\n-      assert(!_curr_region->is_humongous() || mr.start() == _curr_region->bottom(),\n-             \"humongous regions should go around loop once only\");\n-\n-      \/\/ Some special cases:\n-      \/\/ If the memory region is empty, we can just give up the region.\n-      \/\/ If the current region is humongous then we only need to check\n-      \/\/ the bitmap for the bit associated with the start of the object,\n-      \/\/ scan the object if it's live, and give up the region.\n-      \/\/ Otherwise, let's iterate over the bitmap of the part of the region\n-      \/\/ that is left.\n-      \/\/ If the iteration is successful, give up the region.\n-      if (mr.is_empty()) {\n-        giveup_current_region();\n-        abort_marking_if_regular_check_fail();\n-      } else if (_curr_region->is_humongous() && mr.start() == _curr_region->bottom()) {\n-        if (_mark_bitmap->is_marked(mr.start())) {\n-          \/\/ The object is marked - apply the closure\n-          bitmap_closure.do_addr(mr.start());\n-        }\n-        \/\/ Even if this task aborted while scanning the humongous object\n-        \/\/ we can (and should) give up the current region.\n-        giveup_current_region();\n-        abort_marking_if_regular_check_fail();\n-      } else if (_mark_bitmap->iterate(&bitmap_closure, mr)) {\n-        giveup_current_region();\n-        abort_marking_if_regular_check_fail();\n-      } else {\n-        assert(has_aborted(), \"currently the only way to do so\");\n-        \/\/ The only way to abort the bitmap iteration is to return\n-        \/\/ false from the do_bit() method. However, inside the\n-        \/\/ do_bit() method we move the _finger to point to the\n-        \/\/ object currently being looked at. So, if we bail out, we\n-        \/\/ have definitely set _finger to something non-null.\n-        assert(_finger != nullptr, \"invariant\");\n-\n-        \/\/ Region iteration was actually aborted. So now _finger\n-        \/\/ points to the address of the object we last scanned. If we\n-        \/\/ leave it there, when we restart this task, we will rescan\n-        \/\/ the object. It is easy to avoid this. We move the finger by\n-        \/\/ enough to point to the next possible object header.\n-        assert(_finger < _region_limit, \"invariant\");\n-        HeapWord* const new_finger = _finger + cast_to_oop(_finger)->size();\n-        \/\/ Check if bitmap iteration was aborted while scanning the last object\n-        if (new_finger >= _region_limit) {\n-          giveup_current_region();\n-        } else {\n-          move_finger_to(new_finger);\n-        }\n-      }\n-    }\n+    process_current_region(bitmap_closure);\n@@ -2729,1 +2869,0 @@\n-    \/\/ (Do we really need this?)\n@@ -2733,24 +2872,1 @@\n-    \/\/ Read the note on the claim_region() method on why it might\n-    \/\/ return null with potentially more regions available for\n-    \/\/ claiming and why we have to check out_of_regions() to determine\n-    \/\/ whether we're done or not.\n-    while (!has_aborted() && _curr_region == nullptr && !_cm->out_of_regions()) {\n-      \/\/ We are going to try to claim a new region. We should have\n-      \/\/ given up on the previous one.\n-      \/\/ Separated the asserts so that we know which one fires.\n-      assert(_curr_region  == nullptr, \"invariant\");\n-      assert(_finger       == nullptr, \"invariant\");\n-      assert(_region_limit == nullptr, \"invariant\");\n-      G1HeapRegion* claimed_region = _cm->claim_region(_worker_id);\n-      if (claimed_region != nullptr) {\n-        \/\/ Yes, we managed to claim one\n-        setup_for_region(claimed_region);\n-        assert(_curr_region == claimed_region, \"invariant\");\n-      }\n-      \/\/ It is important to call the regular clock here. It might take\n-      \/\/ a while to claim a region if, for example, we hit a large\n-      \/\/ block of empty regions. So we need to call the regular clock\n-      \/\/ method once round the loop to make sure it's called\n-      \/\/ frequently enough.\n-      abort_marking_if_regular_check_fail();\n-    }\n+    claim_new_region();\n@@ -2758,4 +2874,2 @@\n-    if (!has_aborted() && _curr_region == nullptr) {\n-      assert(_cm->out_of_regions(),\n-             \"at this point we should be out of regions\");\n-    }\n+    assert(has_aborted() || _curr_region != nullptr || _cm->out_of_regions(),\n+           \"at this point we should be out of regions\");\n@@ -2764,9 +2878,7 @@\n-  if (!has_aborted()) {\n-    \/\/ We cannot check whether the global stack is empty, since other\n-    \/\/ tasks might be pushing objects to it concurrently.\n-    assert(_cm->out_of_regions(),\n-           \"at this point we should be out of regions\");\n-    \/\/ Try to reduce the number of available SATB buffers so that\n-    \/\/ remark has less work to do.\n-    drain_satb_buffers();\n-  }\n+  \/\/ We cannot check whether the global stack is empty, since other\n+  \/\/ tasks might be pushing objects to it concurrently.\n+  assert(has_aborted() || _cm->out_of_regions(),\n+         \"at this point we should be out of regions\");\n+  \/\/ Try to reduce the number of available SATB buffers so that\n+  \/\/ remark has less work to do.\n+  drain_satb_buffers();\n@@ -2783,18 +2895,1 @@\n-\n-    \/\/ We cannot check whether the global stack is empty, since other\n-    \/\/ tasks might be pushing objects to it concurrently.\n-    assert(_cm->out_of_regions() && _task_queue->size() == 0,\n-           \"only way to reach here\");\n-    while (!has_aborted()) {\n-      G1TaskQueueEntry entry;\n-      if (_cm->try_stealing(_worker_id, entry)) {\n-        scan_task_entry(entry);\n-\n-        \/\/ And since we're towards the end, let's totally drain the\n-        \/\/ local queue and global stack.\n-        drain_local_queue(false);\n-        drain_global_stack(false);\n-      } else {\n-        break;\n-      }\n-    }\n+    attempt_stealing();\n@@ -2806,31 +2901,1 @@\n-    \/\/ We cannot check whether the global stack is empty, since other\n-    \/\/ tasks might be concurrently pushing objects on it.\n-    \/\/ Separated the asserts so that we know which one fires.\n-    assert(_cm->out_of_regions(), \"only way to reach here\");\n-    assert(_task_queue->size() == 0, \"only way to reach here\");\n-    double termination_start_time_ms = os::elapsedTime() * 1000.0;\n-\n-    \/\/ The G1CMTask class also extends the TerminatorTerminator class,\n-    \/\/ hence its should_exit_termination() method will also decide\n-    \/\/ whether to exit the termination protocol or not.\n-    bool finished = (is_serial ||\n-                     _cm->terminator()->offer_termination(this));\n-    _termination_time_ms += (os::elapsedTime() * 1000.0 - termination_start_time_ms);\n-\n-    if (finished) {\n-      \/\/ We're all done.\n-\n-      \/\/ We can now guarantee that the global stack is empty, since\n-      \/\/ all other tasks have finished. We separated the guarantees so\n-      \/\/ that, if a condition is false, we can immediately find out\n-      \/\/ which one.\n-      guarantee(_cm->out_of_regions(), \"only way to reach here\");\n-      guarantee(_cm->mark_stack_empty(), \"only way to reach here\");\n-      guarantee(_task_queue->size() == 0, \"only way to reach here\");\n-      guarantee(!_cm->has_overflown(), \"only way to reach here\");\n-      guarantee(!has_aborted(), \"should never happen if termination has completed\");\n-    } else {\n-      \/\/ Apparently there's more work to do. Let's abort this task. It\n-      \/\/ will restart it and we can hopefully find more things to do.\n-      set_has_aborted();\n-    }\n+    attempt_termination(is_serial);\n@@ -2850,53 +2915,1 @@\n-    if (_has_timed_out) {\n-      double diff_ms = elapsed_time_ms - _time_target_ms;\n-      \/\/ Keep statistics of how well we did with respect to hitting\n-      \/\/ our target only if we actually timed out (if we aborted for\n-      \/\/ other reasons, then the results might get skewed).\n-      _marking_step_diff_ms.add(diff_ms);\n-    }\n-\n-    if (_cm->has_overflown()) {\n-      \/\/ This is the interesting one. We aborted because a global\n-      \/\/ overflow was raised. This means we have to restart the\n-      \/\/ marking phase and start iterating over regions. However, in\n-      \/\/ order to do this we have to make sure that all tasks stop\n-      \/\/ what they are doing and re-initialize in a safe manner. We\n-      \/\/ will achieve this with the use of two barrier sync points.\n-\n-      if (!is_serial) {\n-        \/\/ We only need to enter the sync barrier if being called\n-        \/\/ from a parallel context\n-        _cm->enter_first_sync_barrier(_worker_id);\n-\n-        \/\/ When we exit this sync barrier we know that all tasks have\n-        \/\/ stopped doing marking work. So, it's now safe to\n-        \/\/ re-initialize our data structures.\n-      }\n-\n-      clear_region_fields();\n-      flush_mark_stats_cache();\n-\n-      if (!is_serial) {\n-        \/\/ If we're executing the concurrent phase of marking, reset the marking\n-        \/\/ state; otherwise the marking state is reset after reference processing,\n-        \/\/ during the remark pause.\n-        \/\/ If we reset here as a result of an overflow during the remark we will\n-        \/\/ see assertion failures from any subsequent set_concurrency_and_phase()\n-        \/\/ calls.\n-        if (_cm->concurrent() && _worker_id == 0) {\n-          \/\/ Worker 0 is responsible for clearing the global data structures because\n-          \/\/ of an overflow. During STW we should not clear the overflow flag (in\n-          \/\/ G1ConcurrentMark::reset_marking_state()) since we rely on it being true when we exit\n-          \/\/ method to abort the pause and restart concurrent marking.\n-          _cm->reset_marking_for_restart();\n-\n-          log_info(gc, marking)(\"Concurrent Mark reset for overflow\");\n-        }\n-\n-        \/\/ ...and enter the second barrier.\n-        _cm->enter_second_sync_barrier(_worker_id);\n-      }\n-      \/\/ At this point, if we're during the concurrent phase of\n-      \/\/ marking, everything has been re-initialized and we're\n-      \/\/ ready to restart.\n-    }\n+    handle_abort(is_serial, elapsed_time_ms);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":222,"deletions":209,"binary":false,"changes":431,"status":"modified"},{"patch":"@@ -813,0 +813,15 @@\n+  \/\/ Handles the processing of the current region.\n+  void process_current_region(G1CMBitMapClosure& bitmap_closure);\n+\n+  \/\/ Claims a new region if available.\n+  void claim_new_region();\n+\n+  \/\/ Attempts to steal work from other tasks.\n+  void attempt_stealing();\n+\n+  \/\/ Handles the termination protocol.\n+  void attempt_termination(bool is_serial);\n+\n+  \/\/ Handles the has_aborted scenario.\n+  void handle_abort(bool is_serial, double elapsed_time_ms);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.hpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"}]}