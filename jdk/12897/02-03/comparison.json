{"files":[{"patch":"@@ -618,1 +618,1 @@\n-    assert(jvms != nullptr, \"JVMS reference is nullptr.\");\n+    assert(jvms != nullptr, \"JVMS reference is null.\");\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -46,1 +46,6 @@\n-  _nodes(C->comp_arena(), C->unique(), C->unique(), nullptr),\n+  \/\/ If ReduceAllocationMerges is enabled we might call split_through_phi during\n+  \/\/ split_unique_types and that will create additional nodes that need to be\n+  \/\/ pushed to the ConnectionGraph. The code below bumps the initial capacity of\n+  \/\/ _nodes by 10% to account for these additional nodes. If capacity is exceeded\n+  \/\/ the array will be reallocated.\n+  _nodes(C->comp_arena(), ReduceAllocationMerges ? C->unique()*1.10 : C->unique(), C->unique(), nullptr),\n@@ -313,0 +318,9 @@\n+  \/\/ alloc_worklist will be processed in reverse push order.\n+  \/\/ Therefore the reducible Phis will be processed for last and that's what we\n+  \/\/ want because by then the scalarizable inputs of the merge will already have\n+  \/\/ an unique instance type.\n+  for (uint i = 0; i < reducible_merges.size(); i++ ) {\n+    Node* n = reducible_merges.at(i);\n+    alloc_worklist.append(n);\n+  }\n+\n@@ -422,1 +436,1 @@\n-bool ConnectionGraph::can_reduce_this_phi_check_inputs(PhiNode* phi) const {\n+bool ConnectionGraph::can_reduce_this_phi_check_inputs(PhiNode* ophi) const {\n@@ -426,1 +440,1 @@\n-  for (uint i = 1; i < phi->req(); i++) {\n+  for (uint i = 1; i < ophi->req(); i++) {\n@@ -428,2 +442,3 @@\n-    if (_igvn->type(phi->in(i))->maybe_null()) {\n-      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d. Input %d is nullable.\", phi->_idx, i);)\n+    const Type* inp_t = _igvn->type(ophi->in(i));\n+    if (inp_t == nullptr || inp_t->make_oopptr() == nullptr || inp_t->make_oopptr()->maybe_null()) {\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print(\"Can NOT reduce Phi %d on invocation %d. Input %d is nullable.\", ophi->_idx, _invocation, i);)\n@@ -434,1 +449,1 @@\n-    JavaObjectNode* ptn = unique_java_object(phi->in(i));\n+    JavaObjectNode* ptn = unique_java_object(ophi->in(i));\n@@ -447,1 +462,1 @@\n-  NOT_PRODUCT(if (TraceReduceAllocationMerges && !found_sr_allocate) tty->print_cr(\"Can NOT reduce Phi %d. No SR Allocate as input.\", phi->_idx);)\n+  NOT_PRODUCT(if (TraceReduceAllocationMerges && !found_sr_allocate) tty->print_cr(\"\\tCan NOT reduce Phi %d on invocation %d. No SR Allocate as input.\", ophi->_idx, _invocation);)\n@@ -453,3 +468,3 @@\n-bool ConnectionGraph::can_reduce_this_phi_check_users(PhiNode* phi) const {\n-  for (DUIterator_Fast imax, i = phi->fast_outs(imax); i < imax; i++) {\n-    Node* use = phi->fast_out(i);\n+bool ConnectionGraph::can_reduce_this_phi_check_users(PhiNode* ophi) const {\n+  for (DUIterator_Fast imax, i = ophi->fast_outs(imax); i < imax; i++) {\n+    Node* use = ophi->fast_out(i);\n@@ -458,2 +473,2 @@\n-      if (use->is_Call() && use->as_Call()->has_non_debug_use(phi)) {\n-        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d. Call has non_debug_use().\", phi->_idx);)\n+      if (use->is_Call() && use->as_Call()->has_non_debug_use(ophi)) {\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Call has non_debug_use().\", ophi->_idx, _invocation);)\n@@ -462,0 +477,9 @@\n+    } else if (use->is_AddP()) {\n+      Node* addp = use;\n+      for (DUIterator_Fast jmax, j = addp->fast_outs(jmax); j < jmax; j++) {\n+        Node* use_use = addp->fast_out(j);\n+        if (!use_use->is_Load() || !use_use->as_Load()->can_split_through_phi_base(_igvn)) {\n+          NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. AddP user isn't a [splittable] Load(): %s\", ophi->_idx, _invocation, use_use->Name());)\n+          return false;\n+        }\n+      }\n@@ -463,1 +487,1 @@\n-      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d. One of the uses is: %d %s\", phi->_idx, use->_idx, use->Name());)\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. One of the uses is: %d %s\", ophi->_idx, _invocation, use->_idx, use->Name());)\n@@ -477,1 +501,3 @@\n-  if (phi_t == nullptr || phi_t->isa_instptr() == nullptr || !phi_t->is_instptr()->klass_is_exact()) {\n+  if (phi_t == nullptr || phi_t->make_ptr() == nullptr ||\n+                          phi_t->make_ptr()->isa_instptr() == nullptr ||\n+                          !phi_t->make_ptr()->isa_instptr()->klass_is_exact()) {\n@@ -485,1 +511,1 @@\n-  NOT_PRODUCT(if (TraceReduceAllocationMerges) { tty->print_cr(\"Can reduce this Phi during invocation %d: \", _invocation); ophi->dump(); })\n+  NOT_PRODUCT(if (TraceReduceAllocationMerges) { tty->print_cr(\"Can reduce Phi %d during invocation %d: \", ophi->_idx, _invocation); })\n@@ -489,0 +515,73 @@\n+void ConnectionGraph::reduce_this_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist) {\n+  \/\/ We'll pass this to 'split_through_phi' so that it'll do the split even\n+  \/\/ though the load doesn't have an unique instance type.\n+  bool ignore_missing_instance_id = true;\n+\n+  \/\/ Iterate over Phi outputs looking for an AddP\n+  for (int j = ophi->outcnt()-1; j >= 0;) {\n+    Node* previous_addp = ophi->raw_out(j);\n+    uint num_edges = 1;\n+    if (previous_addp->is_AddP()) {\n+      \/\/ All AddPs are present in the connection graph\n+      FieldNode* fn = ptnode_adr(previous_addp->_idx)->as_Field();\n+      num_edges = previous_addp->in(AddPNode::Address) == previous_addp->in(AddPNode::Base) ? 2 : 1;\n+\n+      \/\/ Iterate over AddP looking for a Load\n+      for (int k = previous_addp->outcnt()-1; k >= 0;) {\n+        Node* previous_load = previous_addp->raw_out(k);\n+        if (previous_load->is_Load()) {\n+          Node* data_phi = previous_load->as_Load()->split_through_phi(_igvn, ignore_missing_instance_id);\n+          _igvn->replace_node(previous_load, data_phi);\n+          assert(data_phi != nullptr, \"Output of split_through_phi is null.\");\n+          assert(data_phi != previous_load, \"Output of split_through_phi is same as input.\");\n+\n+          \/\/ Push the newly created AddP on alloc_worklist and patch\n+          \/\/ the connection graph. Note that the changes in the CG below\n+          \/\/ won't affect the ES of objects since the new nodes have the\n+          \/\/ same status as the old ones.\n+          if (data_phi != nullptr && data_phi->is_Phi()) {\n+            for (uint i = 1; i < data_phi->req(); i++) {\n+              Node* new_load = data_phi->in(i);\n+              if (new_load->is_Load()) {\n+                Node* new_addp = new_load->in(MemNode::Address);\n+                Node* base = get_addp_base(new_addp);\n+\n+                \/\/ The base might not be something that we can create an unique\n+                \/\/ type for. If that's the case we are done with that input.\n+                PointsToNode* jobj_ptn = unique_java_object(base);\n+                if (jobj_ptn == nullptr || !jobj_ptn->scalar_replaceable()) {\n+                  continue;\n+                }\n+\n+                \/\/ Push to alloc_worklist since the base has an unique_type\n+                alloc_worklist.append_if_missing(new_addp);\n+\n+                \/\/ Now let's add the node to the connection graph\n+                _nodes.at_grow(new_addp->_idx, nullptr);\n+                add_field(new_addp, fn->escape_state(), fn->offset());\n+                add_base(ptnode_adr(new_addp->_idx)->as_Field(), ptnode_adr(base->_idx));\n+\n+                \/\/ If the load doesn't load an object then it won't be\n+                \/\/ part of the connection graph\n+                PointsToNode* curr_load_ptn = ptnode_adr(previous_load->_idx);\n+                if (curr_load_ptn != nullptr) {\n+                  _nodes.at_grow(new_load->_idx, nullptr);\n+                  add_local_var(new_load, curr_load_ptn->escape_state());\n+                  add_edge(ptnode_adr(new_load->_idx), ptnode_adr(new_addp->_idx)->as_Field());\n+                }\n+              }\n+            }\n+          }\n+        }\n+        --k;\n+        k = MIN2(k, (int)previous_addp->outcnt()-1);\n+      }\n+\n+      \/\/ Remove the old AddP from the processing list because it's dead now\n+      alloc_worklist.remove_if_existing(previous_addp);\n+    }\n+    j -= num_edges;\n+    j = MIN2(j, (int)ophi->outcnt()-1);\n+  }\n+}\n+\n@@ -639,0 +738,2 @@\n+    } else {\n+      assert(false, \"Unexpected use of reducible Phi.\");\n@@ -642,1 +743,3 @@\n-  reduce_this_phi_on_safepoints(ophi, &safepoints);\n+  if (safepoints.size() > 0) {\n+    reduce_this_phi_on_safepoints(ophi, &safepoints);\n+  }\n@@ -2110,0 +2213,8 @@\n+  \/\/ A Phi 'x' is a _candidate_ to be reducible if 'can_reduce_this_phi(x)'\n+  \/\/ returns true. If one of the constraints in this method set 'jobj' to NSR\n+  \/\/ then the candidate Phi is discarded. If the Phi has another SR 'jobj' as\n+  \/\/ input, 'adjust_scalar_replaceable_state' will eventually be called with\n+  \/\/ that other object and the Phi will become a reducible Phi.\n+  \/\/ There could be multiple merges involving the same jobj.\n+  Unique_Node_List candidates;\n+\n@@ -2112,1 +2223,0 @@\n-\n@@ -2149,4 +2259,4 @@\n-        Node* use_ideal = use->ideal_node();\n-        if (ReduceAllocationMerges &&\n-            use_ideal->is_Phi() && can_reduce_this_phi(use_ideal->as_Phi())) {\n-          reducible_merges.push(use_ideal);\n+        Node* use_n = use->ideal_node();\n+        if (ReduceAllocationMerges && use_n->is_Phi() &&\n+            (reducible_merges.member(use_n) || can_reduce_this_phi(use_n->as_Phi()))) {\n+          candidates.push(use_n);\n@@ -2220,1 +2330,1 @@\n-    if (field->base_count() > 1) {\n+    if (field->base_count() > 1 && candidates.size() == 0) {\n@@ -2234,0 +2344,9 @@\n+\n+  \/\/ The candidate is truly a reducible merge only if none of the other\n+  \/\/ constraints ruled it as NSR. There could be multiple merges involving the\n+  \/\/ same jobj.\n+  assert(jobj->scalar_replaceable(), \"sanity\");\n+  for (uint i = 0; i < candidates.size(); i++ ) {\n+    Node* candidate = candidates.at(i);\n+    reducible_merges.push(candidate);\n+  }\n@@ -3586,1 +3705,6 @@\n-      JavaObjectNode* jobj = unique_java_object(get_addp_base(n));\n+      Node* addp_base = get_addp_base(n);\n+      if (addp_base != nullptr && reducible_merges.member(addp_base)) {\n+        \/\/ This AddP will go away when we reduce the the Phi\n+        continue;\n+      }\n+      JavaObjectNode* jobj = unique_java_object(addp_base);\n@@ -3609,0 +3733,2 @@\n+        \/\/ Split loads through phi\n+        reduce_this_phi_on_field_access(n->as_Phi(), alloc_worklist);\n@@ -3753,1 +3879,0 @@\n-  assert(unique_old == _compile->unique(), \"there should be no new ideal nodes after Phase 1\");\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":149,"deletions":24,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -597,0 +597,1 @@\n+  void reduce_this_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist);\n","filename":"src\/hotspot\/share\/opto\/escape.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -632,1 +632,1 @@\n-      } else if (ignore_merges && use->is_Phi()) {\n+      } else if (ignore_merges && (use->is_Phi() || use->is_EncodeP() || use->Opcode() == Op_MemBarRelease)) {\n@@ -645,1 +645,1 @@\n-          }else {\n+          } else {\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1521,0 +1521,28 @@\n+\/\/------------------------------split_through_phi------------------------------\n+\/\/ Check whether a call to 'split_through_phi' would split this load through the\n+\/\/ Phi *base*. This method is essentially a copy of the validations performed\n+\/\/ by 'split_through_phi'. The first use of this method was in EA code as part\n+\/\/ of simplification of allocation merges.\n+bool LoadNode::can_split_through_phi_base(PhaseGVN* phase) {\n+  Node* mem        = in(Memory);\n+  Node* address    = in(Address);\n+  intptr_t ignore  = 0;\n+  Node*    base    = AddPNode::Ideal_base_and_offset(address, phase, ignore);\n+  bool base_is_phi = (base != nullptr) && base->is_Phi();\n+\n+  if (req() > 3 || !base_is_phi) {\n+    return false;\n+  }\n+\n+  if (!mem->is_Phi()) {\n+    if (!MemNode::all_controls_dominate(mem, base->in(0)))\n+      return false;\n+  } else if (base->in(0) != mem->in(0)) {\n+    if (!MemNode::all_controls_dominate(mem, base->in(0))) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n@@ -1523,1 +1551,1 @@\n-Node* LoadNode::split_through_phi(PhaseGVN* phase) {\n+Node* LoadNode::split_through_phi(PhaseGVN* phase, bool ignore_missing_instance_id) {\n@@ -1534,1 +1562,2 @@\n-         (t_oop->is_known_instance_field() ||\n+         (ignore_missing_instance_id ||\n+          t_oop->is_known_instance_field() ||\n@@ -1546,2 +1575,2 @@\n-        (load_boxed_values || t_oop->is_known_instance_field()))) {\n-    return nullptr; \/\/ memory is not Phi\n+        (ignore_missing_instance_id || load_boxed_values || t_oop->is_known_instance_field()))) {\n+    return nullptr; \/\/ Neither memory or base are Phi\n@@ -1591,1 +1620,1 @@\n-  assert(C->have_alias_type(t_oop), \"instance should have alias type\");\n+  assert(ignore_missing_instance_id || C->have_alias_type(t_oop), \"instance should have alias type\");\n@@ -1627,0 +1656,1 @@\n+  Node* phi = nullptr;\n@@ -1628,7 +1658,0 @@\n-  int this_index  = C->get_alias_index(t_oop);\n-  int this_offset = t_oop->offset();\n-  int this_iid    = t_oop->instance_id();\n-  if (!t_oop->is_known_instance() && load_boxed_values) {\n-    \/\/ Use _idx of address base for boxed values.\n-    this_iid = base->_idx;\n-  }\n@@ -1636,1 +1659,11 @@\n-  Node* phi = new PhiNode(region, this_type, nullptr, mem->_idx, this_iid, this_index, this_offset);\n+  if (t_oop != nullptr && (t_oop->is_known_instance_field() || load_boxed_values)) {\n+    int this_index = C->get_alias_index(t_oop);\n+    int this_offset = t_oop->offset();\n+    int this_iid = t_oop->is_known_instance_field() ? t_oop->instance_id() : base->_idx;\n+    phi = new PhiNode(region, this_type, nullptr, mem->_idx, this_iid, this_index, this_offset);\n+  } else if (ignore_missing_instance_id) {\n+    phi = new PhiNode(region, this_type, nullptr, mem->_idx);\n+  } else {\n+    return nullptr;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":46,"deletions":13,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -247,0 +247,3 @@\n+  \/\/ Return true if it's possible to split the Load through a Phi merging the bases\n+  bool can_split_through_phi_base(PhaseGVN *phase);\n+\n@@ -248,1 +251,1 @@\n-  Node* split_through_phi(PhaseGVN *phase);\n+  Node* split_through_phi(PhaseGVN *phase, bool ignore_missing_instance_id = false);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -143,1 +143,1 @@\n-  \/\/ If \"objs\" contains an ObjectValue\/ObjectMergeValue whose id is \"id\", returns it, else NULL.\n+  \/\/ If \"objs\" contains an ObjectValue\/ObjectMergeValue whose id is \"id\", returns it, else null.\n","filename":"src\/hotspot\/share\/opto\/output.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -303,0 +303,1 @@\n+    Klass* k = nullptr;\n@@ -306,0 +307,5 @@\n+      \/\/ This object is only a candidate inside an ObjectMergeValue\n+      if (sv->is_merge_candidate()) {\n+        continue;\n+      }\n+      k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n@@ -309,0 +315,2 @@\n+      \/\/ Klass may be null if the object was actually a NSR input of a merge.\n+      k = sv->klass() != nullptr ? java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()()) : nullptr;\n@@ -311,1 +319,0 @@\n-    Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n@@ -314,2 +321,7 @@\n-    st.print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n-    k->print_value_on(&st);\n+    st.print(\"     object <\" INTPTR_FORMAT \">\", p2i(sv->value()()));\n+    if (k == nullptr) {\n+      st.print(\" from an allocation merge.\");\n+    } else {\n+      st.print(\" of type \");\n+      k->print_value_on(&st);\n+    }\n@@ -324,1 +336,1 @@\n-    if (Verbose && !obj.is_null()) {\n+    if (Verbose && !obj.is_null() && k != nullptr) {\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":16,"deletions":4,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+                                   \"-XX:+IgnoreUnrecognizedVMOptions\",\n+                                   \"-XX:+TraceReduceAllocationMerges\",\n@@ -87,1 +89,1 @@\n-    \/\/ Merge won't be reduced because of the field accesses\n+    \/\/ Merge won't be reduced because of the write to the fields\n@@ -107,1 +109,1 @@\n-    \/\/ Merge won't be reduced because of the field accesses\n+    \/\/ Merge won't be reduced because of the write to the field\n@@ -129,1 +131,1 @@\n-    \/\/ Merge won't be reduced because of the field accesses\n+    \/\/ Merge won't be reduced because the inputs to the Phi have different Klasses\n@@ -189,1 +191,1 @@\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @Arguments({ Argument.BOOLEAN_TOGGLE_FIRST_FALSE, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n@@ -191,1 +193,1 @@\n-    \/\/ Allocations won't be removed because of the field accesses\n+    \/\/ The allocations won't be removed because 'split_through_phi' won't split the load through the bases.\n@@ -209,1 +211,1 @@\n-    \/\/ The merge won't be simplified because the merge with NULL and the field x access\n+    \/\/ The merge won't be simplified because the merge with NULL\n@@ -226,2 +228,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ The access to the fields at the end of the method will prevent the scalar replacement\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations should be removed\n@@ -234,1 +236,1 @@\n-            if (i == 124) {\n+            if (i == x) {\n@@ -242,14 +244,0 @@\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"1\" })\n-    \/\/ Merge won't be reduced because of field access\n-    int testCallOneSide(boolean cond1, int x, int y) {\n-        Point p = dummy(x, y);\n-\n-        if (cond1) {\n-            p = new Point(y, x);\n-        }\n-\n-        return p.x;\n-    }\n-\n@@ -273,1 +261,2 @@\n-    \/\/ The allocations to \"p\" won't be removed because of the access to x inside the loop.\n+    \/\/ p2 escapes and therefore won't be removed.\n+    \/\/ The allocations won't be removed because 'split_through_phi' won't split the load through the bases.\n@@ -315,1 +304,1 @@\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @Arguments({ Argument.RANDOM_EACH, Argument.NUMBER_42, Argument.RANDOM_EACH })\n@@ -317,1 +306,1 @@\n-    \/\/ The field access will block the reduction\n+    \/\/ The allocation won't be removed because the merge doesn't have exact type\n@@ -321,1 +310,1 @@\n-        if (cond) {\n+        if (cond && x == 42) {\n@@ -323,1 +312,0 @@\n-            dummy();\n@@ -326,3 +314,1 @@\n-        dummy();\n-\n-        return o == global_escape ? o.x + o.y : 0;\n+        return o.x + o.y;\n@@ -331,1 +317,0 @@\n-\n@@ -335,0 +320,2 @@\n+    \/\/ The initial allocation assigned to 's' will always be dead.\n+    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n@@ -356,1 +343,1 @@\n-    @Arguments({ Argument.RANDOM_EACH, Argument.NUMBER_42, Argument.NUMBER_42 })\n+    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n@@ -363,1 +350,1 @@\n-        } else if (x == y) {\n+        } else if (x > y) {\n@@ -378,1 +365,1 @@\n-    \/\/ The merge on \"s\" will remain because of the access to \"a\"\n+    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n@@ -399,0 +386,47 @@\n+\n+    \/\/ ------------------ Some Scalar Replacement Should Happen in The Tests Below ------------------- \/\/\n+\n+    @Test\n+    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ all allocations will be dead\n+    int testPartialPhis(boolean cond, int l, int x, int y) {\n+        int k = l;\n+\n+        if (l == 0) {\n+            k = l + 1;\n+        } else if (l == 2) {\n+            k = l + 2;\n+        } else if (l == 3) {\n+            new Point(x, y);\n+        } else if (l == 4) {\n+            new Point(y, x);\n+        }\n+\n+        return k;\n+    }\n+\n+    @Test\n+    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be removed. After initialization they are read-only objects.\n+    \/\/ Access to the input of the merge, after the merge, is fine.\n+    int testPollutedNoWrite(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Square(l);\n+        Shape obj = null;\n+        int res = 0;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i=1; i<132; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res + obj1.x + obj2.y;\n+    }\n+\n@@ -401,2 +435,39 @@\n-    @IR(counts = { IRNode.ALLOC, \"4\" })\n-    \/\/ Won't be reduced because of the field access\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Initial p3 will always be dead.\n+    \/\/ The other two allocations will be reduced and scaled\n+    int testThreeWayAliasedAlloc(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(x+1, y+1);\n+        Point p3 = new Point(x+2, y+2);\n+\n+        if (cond) {\n+            p3 = p1;\n+        } else {\n+            p3 = p2;\n+        }\n+\n+        return p3.x + p3.y;\n+    }\n+\n+    @Test\n+    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n+    int TestTrapAfterMerge(boolean cond, int x, int y) {\n+        Point p = new Point(x, x);\n+\n+        if (cond) {\n+            p = new Point(y, y);\n+        }\n+\n+        for (int i=402; i<432; i+=x) {\n+            x++;\n+        }\n+\n+        return p.x + x;\n+    }\n+\n+    @Test\n+    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ The allocation of \"Picture\" will be removed and only allocations of \"Position\" will be kept\n@@ -415,1 +486,5 @@\n-    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    @IR(counts = { IRNode.ALLOC, \"2\" }, applyIf = { \"UseCompressedOops\", \"false\" })\n+    \/\/ The two Picture objects will be removed. The nested Point objects won't\n+    \/\/ be removed because the Phi merging them will have a DecodeN user - which\n+    \/\/ currently isn't supported. The 'applyIf' directive is needed to make the\n+    \/\/ test pass on x86_32 VMs.\n@@ -428,2 +503,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"6\" })\n-    \/\/ 2 arrays inside each of the two PicturePositions. Each array have 2 other objects.\n+    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    \/\/ The two PicturePositions objects will be reduced and scaled.\n@@ -442,2 +517,3 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ The allocation inside the last if will be removed\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The allocation inside the last if will be removed because it's not part of a merge\n+    \/\/ The other two allocations will be reduced and removed\n@@ -465,1 +541,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both merges will be reduced and removed\n@@ -480,1 +557,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both merges will be reduced and removed\n@@ -495,1 +573,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ All allocations will be removed.\n@@ -522,1 +601,3 @@\n-    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The initial allocation is always dead. The other\n+    \/\/ two will be reduced and scaled.\n@@ -540,1 +621,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and scaled.\n@@ -558,1 +640,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and scaled\n@@ -575,1 +658,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n@@ -592,1 +676,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n@@ -614,1 +699,3 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The initial allocation is always dead. The other\n+    \/\/ two will be reduced and scaled.\n@@ -635,1 +722,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and removed.\n@@ -662,1 +750,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and removed.\n@@ -684,1 +773,2 @@\n-    @IR(counts = { IRNode.ALLOC, \"3\" })\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ p2 escapes and will remain. The other two allocations will be reduced and scaled.\n@@ -698,89 +788,0 @@\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"0\" })\n-    \/\/ all allocations will be dead\n-    int testPartialPhis(boolean cond, int l, int x, int y) {\n-        int k = l;\n-\n-        if (l == 0) {\n-            k = l + 1;\n-        } else if (l == 2) {\n-            k = l + 2;\n-        } else if (l == 3) {\n-            new Point(x, y);\n-        } else if (l == 4) {\n-            new Point(y, x);\n-        }\n-\n-        return k;\n-    }\n-\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    int testPollutedNoWrite(boolean cond, int l) {\n-        Shape obj1 = new Square(l);\n-        Shape obj2 = new Square(l);\n-        Shape obj = null;\n-        int res = 0;\n-\n-        if (cond) {\n-            obj = obj1;\n-        } else {\n-            obj = obj2;\n-        }\n-\n-        for (int i=1; i<132; i++) {\n-            res += obj.x;\n-        }\n-\n-        return res + obj1.x + obj2.y;\n-    }\n-\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    \/\/ just 2 allocations because initial p3 will always be dead\n-    int testThreeWayAliasedAlloc(boolean cond, int x, int y) {\n-        Point p1 = new Point(x, y);\n-        Point p2 = new Point(x+1, y+1);\n-        Point p3 = new Point(x+2, y+2);\n-\n-        if (cond) {\n-            p3 = p1;\n-        } else {\n-            p3 = p2;\n-        }\n-\n-        return p3.x + p3.y;\n-    }\n-\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    int TestTrapAfterMerge(boolean cond, int x, int y) {\n-        Point p = new Point(x, x);\n-\n-        if (cond) {\n-            p = new Point(y, y);\n-        }\n-\n-        for (int i=402; i<432; i+=x) {\n-            x++;\n-        }\n-\n-        return p.x + x;\n-    }\n-\n-    @Test\n-    @Arguments({ Argument.RANDOM_EACH, Argument.RANDOM_EACH })\n-    @IR(counts = { IRNode.ALLOC, \"2\" })\n-    int testMergedWithDeadCode(boolean cond, int x) {\n-        ADefaults obj1 = new ADefaults(x);\n-        ADefaults obj2 = new ADefaults();\n-        ADefaults obj = cond ? obj1 : obj2;\n-\n-        return obj1.i + obj.ble + 1082;\n-    }\n-\n-\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/scalarReplacement\/AllocationMergesTests.java","additions":144,"deletions":143,"binary":false,"changes":287,"status":"modified"}]}