{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/stackValue.hpp\"\n@@ -83,0 +84,14 @@\n+ScopeValue* DebugInfoReadStream::read_object_merge_value() {\n+  int id = read_int();\n+#ifdef ASSERT\n+  assert(_obj_pool != nullptr, \"object pool does not exist\");\n+  for (int i = _obj_pool->length() - 1; i >= 0; i--) {\n+    assert(_obj_pool->at(i)->as_ObjectValue()->id() != id, \"should not be read twice\");\n+  }\n+#endif\n+  ObjectMergeValue* result = new ObjectMergeValue(id);\n+  _obj_pool->push(result);\n+  result->read_object(this);\n+  return result;\n+}\n+\n@@ -101,1 +116,2 @@\n-                          AUTO_BOX_OBJECT_CODE = 7, MARKER_CODE = 8 };\n+                          AUTO_BOX_OBJECT_CODE = 7, MARKER_CODE = 8,\n+                          OBJECT_MERGE_CODE = 9 };\n@@ -113,0 +129,1 @@\n+   case OBJECT_MERGE_CODE:    result = stream->read_object_merge_value();                break;\n@@ -152,0 +169,1 @@\n+  _is_root = stream->read_bool();\n@@ -169,0 +187,1 @@\n+    stream->write_bool(_is_root);\n@@ -179,1 +198,1 @@\n-  st->print(\"%s[%d]\", is_auto_box() ? \"box_obj\" : \"obj\", _id);\n+  st->print(\"%s[%d]\", is_auto_box() ? \"box_obj\" : is_object_merge() ? \"merge_obj\" : \"obj\", _id);\n@@ -184,6 +203,28 @@\n-  if (_field_values.length() > 0) {\n-    _field_values.at(0)->print_on(st);\n-  }\n-  for (int i = 1; i < _field_values.length(); i++) {\n-    st->print(\", \");\n-    _field_values.at(i)->print_on(st);\n+  if (is_object_merge()) {\n+    ObjectMergeValue* omv = (ObjectMergeValue*)this;\n+    st->print(\"selector=\\\"\");\n+    omv->selector()->print_on(st);\n+    st->print(\"\\\"\");\n+    ScopeValue* merge_pointer = omv->merge_pointer();\n+    if (!(merge_pointer->is_object() && merge_pointer->as_ObjectValue()->value()() == nullptr) &&\n+        !(merge_pointer->is_constant_oop() && merge_pointer->as_ConstantOopReadValue()->value()() == nullptr)) {\n+      st->print(\", merge_pointer=\\\"\");\n+      merge_pointer->print_on(st);\n+      st->print(\"\\\"\");\n+    }\n+    GrowableArray<ScopeValue*>* possible_objects = omv->possible_objects();\n+    st->print(\", candidate_objs=[%d\", possible_objects->at(0)->as_ObjectValue()->id());\n+    int ncandidates = possible_objects->length();\n+    for (int i = 1; i < ncandidates; i++) {\n+      st->print(\", %d\", possible_objects->at(i)->as_ObjectValue()->id());\n+    }\n+    st->print(\"]\");\n+  } else {\n+    st->print(\"\\n        Fields: \");\n+    if (_field_values.length() > 0) {\n+      _field_values.at(0)->print_on(st);\n+    }\n+    for (int i = 1; i < _field_values.length(); i++) {\n+      st->print(\", \");\n+      _field_values.at(i)->print_on(st);\n+    }\n@@ -194,0 +235,63 @@\n+\n+\/\/ ObjectMergeValue\n+\n+\/\/ Returns the ObjectValue that should be used for the local that this\n+\/\/ ObjectMergeValue represents. ObjectMergeValue represents allocation\n+\/\/ merges in C2. This method will select which path the allocation merge\n+\/\/ took during execution of the Trap that triggered the rematerialization\n+\/\/ of the object.\n+ObjectValue* ObjectMergeValue::select(frame& fr, RegisterMap& reg_map) {\n+  StackValue* sv_selector = StackValue::create_stack_value(&fr, &reg_map, _selector);\n+  jint selector = sv_selector->get_int();\n+\n+  \/\/ If the selector is '-1' it means that execution followed the path\n+  \/\/ where no scalar replacement happened.\n+  \/\/ Otherwise, it is the index in _possible_objects array that holds\n+  \/\/ the description of the scalar replaced object.\n+  if (selector == -1) {\n+    StackValue* sv_merge_pointer = StackValue::create_stack_value(&fr, &reg_map, _merge_pointer);\n+    _selected = new ObjectValue(id());\n+\n+    \/\/ Retrieve the pointer to the real object and use it as if we had\n+    \/\/ allocated it during the deoptimization\n+    _selected->set_value(sv_merge_pointer->get_obj()());\n+\n+    \/\/ No need to rematerialize\n+    return nullptr;\n+  } else {\n+    assert(selector < _possible_objects.length(), \"sanity\");\n+    _selected = (ObjectValue*) _possible_objects.at(selector);\n+    return _selected;\n+  }\n+}\n+\n+void ObjectMergeValue::read_object(DebugInfoReadStream* stream) {\n+  _selector = read_from(stream);\n+  _merge_pointer = read_from(stream);\n+  int ncandidates = stream->read_int();\n+  for (int i = 0; i < ncandidates; i++) {\n+    ScopeValue* result = read_from(stream);\n+    assert(result->is_object(), \"Candidate is not an object!\");\n+    ObjectValue* obj = result->as_ObjectValue();\n+    _possible_objects.append(obj);\n+  }\n+}\n+\n+void ObjectMergeValue::write_on(DebugInfoWriteStream* stream) {\n+  if (is_visited()) {\n+    stream->write_int(OBJECT_ID_CODE);\n+    stream->write_int(_id);\n+  } else {\n+    set_visited(true);\n+    stream->write_int(OBJECT_MERGE_CODE);\n+    stream->write_int(_id);\n+    _selector->write_on(stream);\n+    _merge_pointer->write_on(stream);\n+    int ncandidates = _possible_objects.length();\n+    stream->write_int(ncandidates);\n+    for (int i = 0; i < ncandidates; i++) {\n+      _possible_objects.at(i)->as_ObjectValue()->write_on(stream);\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/code\/debugInfo.cpp","additions":112,"deletions":8,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+class ObjectMergeValue;\n@@ -53,0 +54,1 @@\n+  virtual bool is_object_merge() const { return false; }\n@@ -76,0 +78,5 @@\n+  ObjectMergeValue* as_ObjectMergeValue() {\n+    assert(is_object_merge(), \"must be\");\n+    return (ObjectMergeValue*)this;\n+  }\n+\n@@ -129,0 +136,4 @@\n+  bool                       _is_root;   \/\/ Will be true if this object is referred to\n+                                         \/\/ as a local\/expression\/monitor in the JVMs.\n+                                         \/\/ Otherwise false, meaning it's just a candidate\n+                                         \/\/ in an object allocation merge.\n@@ -135,1 +146,2 @@\n-     , _visited(false) {\n+     , _visited(false)\n+     , _is_root(true) {\n@@ -144,1 +156,2 @@\n-     , _visited(false) {}\n+     , _visited(false)\n+     , _is_root(true) {}\n@@ -147,11 +160,14 @@\n-  bool                        is_object() const         { return true; }\n-  int                         id() const                { return _id; }\n-  ScopeValue*                 klass() const             { return _klass; }\n-  GrowableArray<ScopeValue*>* field_values()            { return &_field_values; }\n-  ScopeValue*                 field_at(int i) const     { return _field_values.at(i); }\n-  int                         field_size()              { return _field_values.length(); }\n-  Handle                      value() const             { return _value; }\n-  bool                        is_visited() const        { return _visited; }\n-\n-  void                        set_value(oop value);\n-  void                        set_visited(bool visited) { _visited = visited; }\n+  bool                        is_object() const           { return true; }\n+  int                         id() const                  { return _id; }\n+  virtual ScopeValue*         klass() const               { return _klass; }\n+  virtual GrowableArray<ScopeValue*>* field_values()      { return &_field_values; }\n+  virtual ScopeValue*         field_at(int i) const       { return _field_values.at(i); }\n+  virtual int                 field_size()                { return _field_values.length(); }\n+  virtual Handle              value() const               { return _value; }\n+  bool                        is_visited() const          { return _visited; }\n+  bool                        is_root() const             { return _is_root; }\n+\n+  void                        set_id(int id)              { _id = id; }\n+  virtual void                set_value(oop value);\n+  void                        set_visited(bool visited)   { _visited = visited; }\n+  void                        set_root(bool root)         { _is_root = root; }\n@@ -168,0 +184,59 @@\n+\/\/ An ObjectMergeValue describes objects that were inputs to a Phi in C2 and at\n+\/\/ least one of them was scalar replaced.\n+\/\/ '_selector' is an integer value that will be '-1' if during the execution of\n+\/\/ the C2 compiled code the path taken was that of the Phi input that was NOT\n+\/\/ scalar replaced. In that case '_merge_pointer' is a pointer to an already\n+\/\/ allocated object. If '_selector' is not '-1' then it should be the index of\n+\/\/ an object in '_possible_objects'. That object is an ObjectValue describing an\n+\/\/ object that was scalar replaced.\n+\n+class ObjectMergeValue: public ObjectValue {\n+protected:\n+  ScopeValue*                _selector;\n+  ScopeValue*                _merge_pointer;\n+  GrowableArray<ScopeValue*> _possible_objects;\n+\n+  \/\/ This holds the ObjectValue that should be used in place of this\n+  \/\/ ObjectMergeValue. I.e., it's the ScopeValue from _possible_objects that was\n+  \/\/ selected by 'select()' or is a on-the-fly created ScopeValue representing\n+  \/\/ the _merge_pointer if _selector is -1.\n+  \/\/\n+  \/\/ We need to keep this reference around because there will be entries in\n+  \/\/ ScopeDesc that reference this ObjectMergeValue directly. After\n+  \/\/ rematerialization ObjectMergeValue will be just a wrapper for the\n+  \/\/ Objectvalue pointed by _selected.\n+  ObjectValue*               _selected;\n+public:\n+  ObjectMergeValue(int id, ScopeValue* merge_pointer, ScopeValue* selector)\n+     : ObjectValue(id)\n+     , _selector(selector)\n+     , _merge_pointer(merge_pointer)\n+     , _possible_objects()\n+     , _selected(nullptr) {}\n+\n+  ObjectMergeValue(int id)\n+     : ObjectValue(id)\n+     , _selector(nullptr)\n+     , _merge_pointer(nullptr)\n+     , _possible_objects()\n+     , _selected(nullptr) {}\n+\n+  bool                        is_object_merge() const         { return true; }\n+  ScopeValue*                 selector() const                { return _selector; }\n+  ScopeValue*                 merge_pointer() const           { return _merge_pointer; }\n+  GrowableArray<ScopeValue*>* possible_objects()              { return &_possible_objects; }\n+  ObjectValue*                select(frame& fr, RegisterMap& reg_map) ;\n+\n+  ScopeValue*                 klass() const                   { ShouldNotReachHere(); return nullptr; }\n+  GrowableArray<ScopeValue*>* field_values()                  { ShouldNotReachHere(); return nullptr; }\n+  ScopeValue*                 field_at(int i) const           { ShouldNotReachHere(); return nullptr; }\n+  int                         field_size()                    { ShouldNotReachHere(); return -1; }\n+\n+  Handle                      value() const                   { assert(_selected != nullptr, \"Should call select() first.\"); return _selected->value(); }\n+  void                        set_value(oop value)            { assert(_selected != nullptr, \"Should call select() first.\"); _selected->set_value(value); }\n+\n+  \/\/ Serialization of debugging information\n+  void read_object(DebugInfoReadStream* stream);\n+  void write_on(DebugInfoWriteStream* stream);\n+};\n+\n@@ -319,0 +394,1 @@\n+  ScopeValue* read_object_merge_value();\n","filename":"src\/hotspot\/share\/code\/debugInfo.hpp","additions":89,"deletions":13,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -117,1 +117,0 @@\n-  assert(result->length() == length, \"inconsistent debug information\");\n@@ -133,0 +132,32 @@\n+GrowableArray<ScopeValue*>* ScopeDesc::objects_to_rematerialize(frame& frm, RegisterMap& map) {\n+  if (_objects == nullptr) {\n+    return nullptr;\n+  }\n+\n+  GrowableArray<ScopeValue*>* result = new GrowableArray<ScopeValue*>();\n+  for (int i = 0; i < _objects->length(); i++) {\n+    assert(_objects->at(i)->is_object(), \"invalid debug information\");\n+    ObjectValue* sv = _objects->at(i)->as_ObjectValue();\n+\n+    \/\/ If the object is not referenced in current JVM state, then it's only\n+    \/\/ a candidate in an ObjectMergeValue, we don't need to rematerialize it\n+    \/\/ unless when\/if it's returned by 'select()' below.\n+    if (!sv->is_root()) {\n+      continue;\n+    }\n+\n+    if (sv->is_object_merge()) {\n+      sv = sv->as_ObjectMergeValue()->select(frm, map);\n+      \/\/ If select() returns nullptr, then the object doesn't need to be\n+      \/\/ rematerialized.\n+      if (sv == nullptr) {\n+        continue;\n+      }\n+    }\n+\n+    result->append_if_missing(sv);\n+  }\n+\n+  return result;\n+}\n+\n@@ -241,2 +272,6 @@\n-      st->print(\"    - %d: \", sv->id());\n-      st->print(\"%s \", java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()())->external_name());\n+      st->print(\"    - %d: %c \", i, sv->is_root() ? 'R' : ' ');\n+      sv->print_on(st);\n+      st->print(\", \");\n+      if (!sv->is_object_merge()) {\n+        st->print(\"%s\", java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()())->external_name());\n+      }\n","filename":"src\/hotspot\/share\/code\/scopeDesc.cpp","additions":38,"deletions":3,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -137,0 +137,1 @@\n+  GrowableArray<ScopeValue*>* objects_to_rematerialize(frame& frm, RegisterMap& map);\n","filename":"src\/hotspot\/share\/code\/scopeDesc.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1501,0 +1501,1 @@\n+              assert(!value->is_object_merge(), \"Should not be.\");\n@@ -1743,0 +1744,1 @@\n+        assert(!scopedValues->at(i2)->is_object_merge(), \"Should not be.\");\n@@ -1756,0 +1758,1 @@\n+        assert(!scopeExpressions->at(i2)->is_object_merge(), \"Should not be.\");\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -473,0 +473,6 @@\n+  product(bool, ReduceAllocationMerges, true,                               \\\n+          \"Try to simplify allocation merges before Scalar Replacement\")    \\\n+                                                                            \\\n+  develop(bool, TraceReduceAllocationMerges, false,                         \\\n+          \"Trace decision for simplifying allocation merges.\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -55,0 +55,3 @@\n+const char* C2Compiler::retry_no_reduce_allocation_merges() {\n+  return \"retry without reducing allocation merges\";\n+}\n@@ -109,0 +112,1 @@\n+  bool do_reduce_allocation_merges = ReduceAllocationMerges;\n@@ -114,1 +118,1 @@\n-    Options options(subsume_loads, do_escape_analysis, do_iterative_escape_analysis, eliminate_boxing, do_locks_coarsening, install_code);\n+    Options options(subsume_loads, do_escape_analysis, do_iterative_escape_analysis, do_reduce_allocation_merges, eliminate_boxing, do_locks_coarsening, install_code);\n@@ -137,0 +141,6 @@\n+      if (C.failure_reason_is(retry_no_reduce_allocation_merges())) {\n+        assert(do_reduce_allocation_merges, \"must make progress\");\n+        do_reduce_allocation_merges = false;\n+        env->report_failure(C.failure_reason());\n+        continue;  \/\/ retry\n+      }\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -53,0 +53,1 @@\n+  static const char* retry_no_reduce_allocation_merges();\n","filename":"src\/hotspot\/share\/opto\/c2compiler.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1106,0 +1106,6 @@\n+\/\/----------------------------is_uncommon_trap----------------------------\n+\/\/ Returns true if this is an uncommon trap.\n+bool CallStaticJavaNode::is_uncommon_trap() const {\n+  return (_name != nullptr && !strcmp(_name, \"uncommon_trap\"));\n+}\n+\n@@ -1109,4 +1115,1 @@\n-  if (_name != nullptr && !strcmp(_name, \"uncommon_trap\")) {\n-    return extract_uncommon_trap_request(this);\n-  }\n-  return 0;\n+  return is_uncommon_trap() ? extract_uncommon_trap_request(this) : 0;\n@@ -1463,6 +1466,1 @@\n-SafePointScalarObjectNode::SafePointScalarObjectNode(const TypeOopPtr* tp,\n-#ifdef ASSERT\n-                                                     Node* alloc,\n-#endif\n-                                                     uint first_index,\n-                                                     uint n_fields) :\n+SafePointScalarObjectNode::SafePointScalarObjectNode(const TypeOopPtr* tp, Node* alloc, uint first_index, uint n_fields) :\n@@ -1471,4 +1469,2 @@\n-  _n_fields(n_fields)\n-#ifdef ASSERT\n-  , _alloc(alloc)\n-#endif\n+  _n_fields(n_fields),\n+  _alloc(alloc)\n@@ -1477,2 +1473,1 @@\n-  if (!alloc->is_Allocate()\n-      && !(alloc->Opcode() == Op_VectorBox)) {\n+  if (!alloc->is_Allocate() && !(alloc->Opcode() == Op_VectorBox)) {\n@@ -1524,2 +1519,21 @@\n-  st->print(\" # fields@[%d..%d]\", first_index(),\n-             first_index() + n_fields() - 1);\n+  st->print(\" # fields@[%d..%d]\", first_index(), first_index() + n_fields() - 1);\n+}\n+#endif\n+\n+\/\/==============  SafePointScalarMergeNode  ==============\n+\n+SafePointScalarMergeNode::SafePointScalarMergeNode(const TypeOopPtr* tp, int merge_pointer_idx) :\n+  TypeNode(tp, 1), \/\/ 1 control input -- seems required.  Get from root.\n+  _merge_pointer_idx(merge_pointer_idx)\n+{\n+  init_class_id(Class_SafePointScalarMerge);\n+}\n+\n+\/\/ Do not allow value-numbering for SafePointScalarMerge node.\n+uint SafePointScalarMergeNode::hash() const { return NO_HASH; }\n+bool SafePointScalarMergeNode::cmp( const Node &n ) const {\n+  return (&n == this); \/\/ Always fail except on self\n+}\n+\n+uint SafePointScalarMergeNode::ideal_reg() const {\n+  return 0; \/\/ No matching to machine instruction\n@@ -1528,0 +1542,29 @@\n+const RegMask &SafePointScalarMergeNode::in_RegMask(uint idx) const {\n+  return *(Compile::current()->matcher()->idealreg2debugmask[in(idx)->ideal_reg()]);\n+}\n+\n+const RegMask &SafePointScalarMergeNode::out_RegMask() const {\n+  return RegMask::Empty;\n+}\n+\n+uint SafePointScalarMergeNode::match_edge(uint idx) const {\n+  return 0;\n+}\n+\n+SafePointScalarMergeNode*\n+SafePointScalarMergeNode::clone(Dict* sosn_map, bool& new_node) const {\n+  void* cached = (*sosn_map)[(void*)this];\n+  if (cached != nullptr) {\n+    new_node = false;\n+    return (SafePointScalarMergeNode*)cached;\n+  }\n+  new_node = true;\n+  SafePointScalarMergeNode* res = (SafePointScalarMergeNode*)Node::clone();\n+  sosn_map->Insert((void*)this, (void*)res);\n+  return res;\n+}\n+\n+#ifndef PRODUCT\n+void SafePointScalarMergeNode::dump_spec(outputStream *st) const {\n+  st->print(\" # merge_pointer_idx=%d, scalarized_objects=%d\", _merge_pointer_idx, req()-1);\n+}\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":61,"deletions":18,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -508,1 +508,0 @@\n-\n@@ -510,5 +509,6 @@\n-  uint _first_index; \/\/ First input edge relative index of a SafePoint node where\n-                     \/\/ states of the scalarized object fields are collected.\n-                     \/\/ It is relative to the last (youngest) jvms->_scloff.\n-  uint _n_fields;    \/\/ Number of non-static fields of the scalarized object.\n-  DEBUG_ONLY(Node* _alloc;)\n+  uint _first_index;              \/\/ First input edge relative index of a SafePoint node where\n+                                  \/\/ states of the scalarized object fields are collected.\n+                                  \/\/ It is relative to the last (youngest) jvms->_scloff.\n+  uint _n_fields;                 \/\/ Number of non-static fields of the scalarized object.\n+\n+  Node* _alloc;                   \/\/ Just for debugging purposes.\n@@ -516,1 +516,1 @@\n-  virtual uint hash() const ; \/\/ { return NO_HASH; }\n+  virtual uint hash() const;\n@@ -522,5 +522,2 @@\n-  SafePointScalarObjectNode(const TypeOopPtr* tp,\n-#ifdef ASSERT\n-                            Node* alloc,\n-#endif\n-                            uint first_index, uint n_fields);\n+  SafePointScalarObjectNode(const TypeOopPtr* tp, Node* alloc, uint first_index, uint n_fields);\n+\n@@ -559,0 +556,86 @@\n+\/\/------------------------------SafePointScalarMergeNode----------------------\n+\/\/\n+\/\/ This class represents an allocation merge that is used as debug information\n+\/\/ and had at least one of its input scalar replaced.\n+\/\/\n+\/\/ The required inputs of this node, except the control, are pointers to\n+\/\/ SafePointScalarObjectNodes that describe scalarized inputs of the original\n+\/\/ allocation merge. The other(s) properties of the class are described below.\n+\/\/\n+\/\/ _merge_pointer_idx : index in the SafePointNode's input array where the\n+\/\/   description of the _allocation merge_ starts. The index is zero based and\n+\/\/   relative to the SafePoint's scloff. The two entries in the SafePointNode's\n+\/\/   input array starting at '_merge_pointer_idx` are Phi nodes representing:\n+\/\/\n+\/\/   1) The original merge Phi. During rematerialization this input will only be\n+\/\/   used if the \"selector Phi\" (see below) indicates that the execution of the\n+\/\/   Phi took the path of a non scalarized input.\n+\/\/\n+\/\/   2) A \"selector Phi\". The output of this Phi will be '-1' if the execution\n+\/\/   of the method exercised a non scalarized input of the original Phi.\n+\/\/   Otherwise, the output will be >=0, and it will indicate the index-1 in the\n+\/\/   SafePointScalarMergeNode input array where the description of the\n+\/\/   scalarized object that should be used is.\n+\/\/\n+\/\/ As an example, consider a Phi merging 3 inputs, of which the last 2 are\n+\/\/ scalar replaceable.\n+\/\/\n+\/\/    Phi(Region, NSR, SR, SR)\n+\/\/\n+\/\/ During scalar replacement the SR inputs will be changed to null:\n+\/\/\n+\/\/    Phi(Region, NSR, nullptr, nullptr)\n+\/\/\n+\/\/ A corresponding selector Phi will be created with a configuration like this:\n+\/\/\n+\/\/    Phi(Region, -1, 0, 1)\n+\/\/\n+\/\/ During execution of the compiled method, if the execution reaches a Trap, the\n+\/\/ output of the selector Phi will tell if we need to rematerialize one of the\n+\/\/ scalar replaced inputs or if we should just use the pointer returned by the\n+\/\/ original Phi.\n+\n+class SafePointScalarMergeNode: public TypeNode {\n+  int _merge_pointer_idx;         \/\/ This is the first input edge relative\n+                                  \/\/ index of a SafePoint node where metadata information relative\n+                                  \/\/ to restoring the merge is stored. The corresponding input\n+                                  \/\/ in the associated SafePoint will point to a Phi representing\n+                                  \/\/ potential non-scalar replaced objects.\n+\n+  virtual uint hash() const;\n+  virtual bool cmp( const Node &n ) const;\n+\n+public:\n+  SafePointScalarMergeNode(const TypeOopPtr* tp, int merge_pointer_idx);\n+\n+  virtual int            Opcode() const;\n+  virtual uint           ideal_reg() const;\n+  virtual const RegMask &in_RegMask(uint) const;\n+  virtual const RegMask &out_RegMask() const;\n+  virtual uint           match_edge(uint idx) const;\n+\n+  virtual uint size_of() const { return sizeof(*this); }\n+\n+  int merge_pointer_idx(JVMState* jvms) const {\n+    assert(jvms != nullptr, \"JVMS reference is null.\");\n+    return jvms->scloff() + _merge_pointer_idx;\n+  }\n+\n+  int selector_idx(JVMState* jvms) const {\n+    assert(jvms != nullptr, \"JVMS reference is null.\");\n+    return jvms->scloff() + _merge_pointer_idx + 1;\n+  }\n+\n+  \/\/ Assumes that \"this\" is an argument to a safepoint node \"s\", and that\n+  \/\/ \"new_call\" is being created to correspond to \"s\".  But the difference\n+  \/\/ between the start index of the jvmstates of \"new_call\" and \"s\" is\n+  \/\/ \"jvms_adj\".  Produce and return a SafePointScalarObjectNode that\n+  \/\/ corresponds appropriately to \"this\" in \"new_call\".  Assumes that\n+  \/\/ \"sosn_map\" is a map, specific to the translation of \"s\" to \"new_call\",\n+  \/\/ mapping old SafePointScalarObjectNodes to new, to avoid multiple copies.\n+  SafePointScalarMergeNode* clone(Dict* sosn_map, bool& new_node) const;\n+\n+#ifndef PRODUCT\n+  virtual void              dump_spec(outputStream *st) const;\n+#endif\n+};\n@@ -738,0 +821,1 @@\n+  bool is_uncommon_trap() const;\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":96,"deletions":12,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -315,0 +315,1 @@\n+macro(SafePointScalarMerge)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -522,0 +522,6 @@\n+  if (do_reduce_allocation_merges() != ReduceAllocationMerges && PrintOpto) {\n+    \/\/ Recompiling without reducing allocation merges\n+    tty->print_cr(\"*********************************************************\");\n+    tty->print_cr(\"** Bailout: Recompile without reduce allocation merges **\");\n+    tty->print_cr(\"*********************************************************\");\n+  }\n@@ -2295,1 +2301,0 @@\n-      if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n@@ -2299,0 +2304,1 @@\n+    print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);\n@@ -2320,2 +2326,0 @@\n-\n-        if (failing())  return;\n@@ -2323,0 +2327,4 @@\n+\n+      ConnectionGraph::verify_ram_nodes(this, root());\n+      if (failing())  return;\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -179,0 +179,1 @@\n+  const bool _do_reduce_allocation_merges;  \/\/ Do try to reduce allocation merges.\n@@ -185,0 +186,1 @@\n+          bool do_reduce_allocation_merges,\n@@ -190,0 +192,1 @@\n+          _do_reduce_allocation_merges(do_reduce_allocation_merges),\n@@ -200,0 +203,1 @@\n+       \/* do_reduce_allocation_merges = *\/ false,\n@@ -568,0 +572,1 @@\n+  bool              do_reduce_allocation_merges() const  { return _options._do_reduce_allocation_merges; }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"opto\/macro.hpp\"\n@@ -45,1 +46,6 @@\n-  _nodes(C->comp_arena(), C->unique(), C->unique(), nullptr),\n+  \/\/ If ReduceAllocationMerges is enabled we might call split_through_phi during\n+  \/\/ split_unique_types and that will create additional nodes that need to be\n+  \/\/ pushed to the ConnectionGraph. The code below bumps the initial capacity of\n+  \/\/ _nodes by 10% to account for these additional nodes. If capacity is exceeded\n+  \/\/ the array will be reallocated.\n+  _nodes(C->comp_arena(), ReduceAllocationMerges ? C->unique()*1.10 : C->unique(), C->unique(), nullptr),\n@@ -59,0 +65,1 @@\n+  set_not_scalar_replaceable(phantom_obj NOT_PRODUCT(COMMA \"Phantom object\"));\n@@ -64,0 +71,1 @@\n+  set_not_scalar_replaceable(null_obj NOT_PRODUCT(COMMA \"Null object\"));\n@@ -127,0 +135,1 @@\n+  Unique_Node_List reducible_merges;\n@@ -295,1 +304,1 @@\n-      adjust_scalar_replaceable_state(ptn);\n+      adjust_scalar_replaceable_state(ptn, reducible_merges);\n@@ -309,0 +318,9 @@\n+  \/\/ alloc_worklist will be processed in reverse push order.\n+  \/\/ Therefore the reducible Phis will be processed for last and that's what we\n+  \/\/ want because by then the scalarizable inputs of the merge will already have\n+  \/\/ an unique instance type.\n+  for (uint i = 0; i < reducible_merges.size(); i++ ) {\n+    Node* n = reducible_merges.at(i);\n+    alloc_worklist.append(n);\n+  }\n+\n@@ -362,1 +380,1 @@\n-    split_unique_types(alloc_worklist, arraycopy_worklist, mergemem_worklist);\n+    split_unique_types(alloc_worklist, arraycopy_worklist, mergemem_worklist, reducible_merges);\n@@ -382,0 +400,15 @@\n+  \/\/ 6. Remove reducible allocation merges from ideal graph\n+  if (ReduceAllocationMerges && reducible_merges.size() > 0) {\n+    bool delay = _igvn->delay_transform();\n+    _igvn->set_delay_transform(true);\n+    for (uint i = 0; i < reducible_merges.size(); i++ ) {\n+      Node* n = reducible_merges.at(i);\n+      reduce_phi(n->as_Phi());\n+      if (C->failing()) {\n+        NOT_PRODUCT(escape_state_statistics(java_objects_worklist);)\n+        return false;\n+      }\n+    }\n+    _igvn->set_delay_transform(delay);\n+  }\n+\n@@ -404,0 +437,339 @@\n+\/\/ Check if it's profitable to reduce the Phi passed as parameter.  Returns true\n+\/\/ if at least one scalar replaceable allocation participates in the merge and\n+\/\/ no input to the Phi is nullable.\n+bool ConnectionGraph::can_reduce_phi_check_inputs(PhiNode* ophi) const {\n+  \/\/ Check if there is a scalar replaceable allocate in the Phi\n+  bool found_sr_allocate = false;\n+\n+  for (uint i = 1; i < ophi->req(); i++) {\n+    \/\/ Right now we can't restore a \"null\" pointer during deoptimization\n+    const Type* inp_t = _igvn->type(ophi->in(i));\n+    if (inp_t == nullptr || inp_t->make_oopptr() == nullptr || inp_t->make_oopptr()->maybe_null()) {\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Input %d is nullable.\", ophi->_idx, _invocation, i);)\n+      return false;\n+    }\n+\n+    \/\/ We are looking for at least one SR object in the merge\n+    JavaObjectNode* ptn = unique_java_object(ophi->in(i));\n+    if (ptn != nullptr && ptn->scalar_replaceable()) {\n+      assert(ptn->ideal_node() != nullptr && ptn->ideal_node()->is_Allocate(), \"sanity\");\n+      AllocateNode* alloc = ptn->ideal_node()->as_Allocate();\n+\n+      if (PhaseMacroExpand::can_eliminate_allocation(_igvn, alloc, nullptr)) {\n+        found_sr_allocate = true;\n+      } else {\n+        ptn->set_scalar_replaceable(false);\n+      }\n+    }\n+  }\n+\n+  NOT_PRODUCT(if (TraceReduceAllocationMerges && !found_sr_allocate) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. No SR Allocate as input.\", ophi->_idx, _invocation);)\n+  return found_sr_allocate;\n+}\n+\n+\/\/ Check if we are able to untangle the merge. Right now we only reduce Phis\n+\/\/ which are only used as debug information.\n+bool ConnectionGraph::can_reduce_phi_check_users(PhiNode* ophi) const {\n+  for (DUIterator_Fast imax, i = ophi->fast_outs(imax); i < imax; i++) {\n+    Node* use = ophi->fast_out(i);\n+\n+    if (use->is_SafePoint()) {\n+      if (use->is_Call() && use->as_Call()->has_non_debug_use(ophi)) {\n+        NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. Call has non_debug_use().\", ophi->_idx, _invocation);)\n+        return false;\n+      }\n+    } else if (use->is_AddP()) {\n+      Node* addp = use;\n+      for (DUIterator_Fast jmax, j = addp->fast_outs(jmax); j < jmax; j++) {\n+        Node* use_use = addp->fast_out(j);\n+        if (!use_use->is_Load() || !use_use->as_Load()->can_split_through_phi_base(_igvn)) {\n+          NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. AddP user isn't a [splittable] Load(): %s\", ophi->_idx, _invocation, use_use->Name());)\n+          return false;\n+        }\n+      }\n+    } else {\n+      NOT_PRODUCT(if (TraceReduceAllocationMerges) tty->print_cr(\"Can NOT reduce Phi %d on invocation %d. One of the uses is: %d %s\", ophi->_idx, _invocation, use->_idx, use->Name());)\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n+\/\/ Returns true if: 1) It's profitable to reduce the merge, and 2) The Phi is\n+\/\/ only used in some certain code shapes. Check comments in\n+\/\/ 'can_reduce_phi_inputs' and 'can_reduce_phi_users' for more\n+\/\/ details.\n+bool ConnectionGraph::can_reduce_phi(PhiNode* ophi) const {\n+  \/\/ If there was an error attempting to reduce allocation merges for this\n+  \/\/ method we might have disabled the compilation and be retrying\n+  \/\/ with RAM disabled.\n+  if (!_compile->do_reduce_allocation_merges()) {\n+    return false;\n+  }\n+\n+  const Type* phi_t = _igvn->type(ophi);\n+  if (phi_t == nullptr || phi_t->make_ptr() == nullptr ||\n+                          phi_t->make_ptr()->isa_instptr() == nullptr ||\n+                          !phi_t->make_ptr()->isa_instptr()->klass_is_exact()) {\n+    NOT_PRODUCT(if (TraceReduceAllocationMerges) { tty->print_cr(\"Can NOT reduce Phi %d during invocation %d because it's nullable.\", ophi->_idx, _invocation); })\n+    return false;\n+  }\n+\n+  if (!can_reduce_phi_check_inputs(ophi) || !can_reduce_phi_check_users(ophi)) {\n+    return false;\n+  }\n+\n+  NOT_PRODUCT(if (TraceReduceAllocationMerges) { tty->print_cr(\"Can reduce Phi %d during invocation %d: \", ophi->_idx, _invocation); })\n+  return true;\n+}\n+\n+void ConnectionGraph::reduce_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist) {\n+  \/\/ We'll pass this to 'split_through_phi' so that it'll do the split even\n+  \/\/ though the load doesn't have an unique instance type.\n+  bool ignore_missing_instance_id = true;\n+\n+  \/\/ Iterate over Phi outputs looking for an AddP\n+  for (int j = ophi->outcnt()-1; j >= 0;) {\n+    Node* previous_addp = ophi->raw_out(j);\n+    uint num_edges = 1;\n+    if (previous_addp->is_AddP()) {\n+      \/\/ All AddPs are present in the connection graph\n+      FieldNode* fn = ptnode_adr(previous_addp->_idx)->as_Field();\n+      num_edges = previous_addp->in(AddPNode::Address) == previous_addp->in(AddPNode::Base) ? 2 : 1;\n+\n+      \/\/ Iterate over AddP looking for a Load\n+      for (int k = previous_addp->outcnt()-1; k >= 0;) {\n+        Node* previous_load = previous_addp->raw_out(k);\n+        if (previous_load->is_Load()) {\n+          Node* data_phi = previous_load->as_Load()->split_through_phi(_igvn, ignore_missing_instance_id);\n+          _igvn->replace_node(previous_load, data_phi);\n+          assert(data_phi != nullptr, \"Output of split_through_phi is null.\");\n+          assert(data_phi != previous_load, \"Output of split_through_phi is same as input.\");\n+\n+          \/\/ Push the newly created AddP on alloc_worklist and patch\n+          \/\/ the connection graph. Note that the changes in the CG below\n+          \/\/ won't affect the ES of objects since the new nodes have the\n+          \/\/ same status as the old ones.\n+          if (data_phi != nullptr && data_phi->is_Phi()) {\n+            for (uint i = 1; i < data_phi->req(); i++) {\n+              Node* new_load = data_phi->in(i);\n+              if (new_load->is_Load()) {\n+                Node* new_addp = new_load->in(MemNode::Address);\n+                Node* base = get_addp_base(new_addp);\n+\n+                \/\/ The base might not be something that we can create an unique\n+                \/\/ type for. If that's the case we are done with that input.\n+                PointsToNode* jobj_ptn = unique_java_object(base);\n+                if (jobj_ptn == nullptr || !jobj_ptn->scalar_replaceable()) {\n+                  continue;\n+                }\n+\n+                \/\/ Push to alloc_worklist since the base has an unique_type\n+                alloc_worklist.append_if_missing(new_addp);\n+\n+                \/\/ Now let's add the node to the connection graph\n+                _nodes.at_grow(new_addp->_idx, nullptr);\n+                add_field(new_addp, fn->escape_state(), fn->offset());\n+                add_base(ptnode_adr(new_addp->_idx)->as_Field(), ptnode_adr(base->_idx));\n+\n+                \/\/ If the load doesn't load an object then it won't be\n+                \/\/ part of the connection graph\n+                PointsToNode* curr_load_ptn = ptnode_adr(previous_load->_idx);\n+                if (curr_load_ptn != nullptr) {\n+                  _nodes.at_grow(new_load->_idx, nullptr);\n+                  add_local_var(new_load, curr_load_ptn->escape_state());\n+                  add_edge(ptnode_adr(new_load->_idx), ptnode_adr(new_addp->_idx)->as_Field());\n+                }\n+              }\n+            }\n+          }\n+        }\n+        --k;\n+        k = MIN2(k, (int)previous_addp->outcnt()-1);\n+      }\n+\n+      \/\/ Remove the old AddP from the processing list because it's dead now\n+      alloc_worklist.remove_if_existing(previous_addp);\n+    }\n+    j -= num_edges;\n+    j = MIN2(j, (int)ophi->outcnt()-1);\n+  }\n+}\n+\n+\/\/ This method will create a SafePointScalarObjectNode for each combination of\n+\/\/ scalar replaceable allocation in 'ophi' and SafePoint node in 'safepoints'.\n+\/\/ The method will create a SafePointScalarMERGEnode for each combination of\n+\/\/ 'ophi' and SafePoint node in 'safepoints'.\n+\/\/ Each SafePointScalarMergeNode created here may describe multiple scalar\n+\/\/ replaced objects - check detailed description in SafePointScalarMergeNode\n+\/\/ class header.\n+\/\/\n+\/\/ This method will set entries in the Phi that are scalar replaceable to 'null'.\n+void ConnectionGraph::reduce_phi_on_safepoints(PhiNode* ophi, Unique_Node_List* safepoints) {\n+  Node* minus_one           = _igvn->register_new_node_with_optimizer(ConINode::make(-1));\n+  Node* selector            = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), minus_one, TypeInt::INT));\n+  Node* null_ptr            = _igvn->makecon(TypePtr::NULL_PTR);\n+  const TypeOopPtr* merge_t = _igvn->type(ophi)->make_oopptr();\n+  uint number_of_sr_objects = 0;\n+  PhaseMacroExpand mexp(*_igvn);\n+\n+  _igvn->hash_delete(ophi);\n+\n+  \/\/ Fill in the 'selector' Phi. If index 'i' of the selector is:\n+  \/\/ -> a '-1' constant, the i'th input of the original Phi is NSR.\n+  \/\/ -> a 'x' constant >=0, the i'th input of of original Phi will be SR and the\n+  \/\/    info about the scalarized object will be at index x of\n+  \/\/    ObjectMergeValue::possible_objects\n+  for (uint i = 1; i < ophi->req(); i++) {\n+    Node* base          = ophi->in(i);\n+    JavaObjectNode* ptn = unique_java_object(base);\n+\n+    if (ptn != nullptr && ptn->scalar_replaceable()) {\n+      Node* sr_obj_idx = _igvn->register_new_node_with_optimizer(ConINode::make(number_of_sr_objects));\n+      selector->set_req(i, sr_obj_idx);\n+      number_of_sr_objects++;\n+    }\n+  }\n+\n+  \/\/ Update the debug information of all safepoints in turn\n+  for (uint spi = 0; spi < safepoints->size(); spi++) {\n+    SafePointNode* sfpt = safepoints->at(spi)->as_SafePoint();\n+    JVMState *jvms      = sfpt->jvms();\n+    uint merge_idx      = (sfpt->req() - jvms->scloff());\n+    int debug_start     = jvms->debug_start();\n+\n+    SafePointScalarMergeNode* smerge = new SafePointScalarMergeNode(merge_t, merge_idx);\n+    smerge->init_req(0, _compile->root());\n+    _igvn->register_new_node_with_optimizer(smerge);\n+\n+    \/\/ The next two inputs are:\n+    \/\/  (1) A copy of the original pointer to NSR objects.\n+    \/\/  (2) A selector, used to decide if we need to rematerialize an object\n+    \/\/      or use the pointer to a NSR object.\n+    \/\/ See more details of these fields in the declaration of SafePointScalarMergeNode\n+    sfpt->add_req(ophi);\n+    sfpt->add_req(selector);\n+\n+    for (uint i = 1; i < ophi->req(); i++) {\n+      Node* base          = ophi->in(i);\n+      JavaObjectNode* ptn = unique_java_object(base);\n+\n+      \/\/ If the base is not scalar replaceable we don't need to register information about\n+      \/\/ it at this time.\n+      if (ptn == nullptr || !ptn->scalar_replaceable()) {\n+        continue;\n+      }\n+\n+      AllocateNode* alloc = ptn->ideal_node()->as_Allocate();\n+      SafePointScalarObjectNode* sobj = mexp.create_scalarized_object_description(alloc, sfpt);\n+      if (sobj == nullptr) {\n+        _compile->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n+        return;\n+      }\n+\n+      \/\/ Now make a pass over the debug information replacing any references\n+      \/\/ to the allocated object with \"sobj\"\n+      Node* ccpp = alloc->result_cast();\n+      sfpt->replace_edges_in_range(ccpp, sobj, debug_start, jvms->debug_end(), _igvn);\n+\n+      \/\/ Register the scalarized object as a candidate for reallocation\n+      smerge->add_req(sobj);\n+    }\n+\n+    \/\/ Replaces debug information references to \"ophi\" in \"sfpt\" with references to \"smerge\"\n+    sfpt->replace_edges_in_range(ophi, smerge, debug_start, jvms->debug_end(), _igvn);\n+\n+    \/\/ The call to 'replace_edges_in_range' above might have removed the\n+    \/\/ reference to ophi that we need at _merge_pointer_idx. The line below make\n+    \/\/ sure the reference is maintained.\n+    sfpt->set_req(smerge->merge_pointer_idx(jvms), ophi);\n+    _igvn->_worklist.push(sfpt);\n+  }\n+\n+  \/\/ Now we can change ophi since we don't need to know the types\n+  \/\/ of the input allocations anymore.\n+  const Type* new_t = merge_t->meet(TypePtr::NULL_PTR);\n+  Node* new_phi = _igvn->register_new_node_with_optimizer(PhiNode::make(ophi->region(), null_ptr, new_t));\n+  for (uint i = 1; i < ophi->req(); i++) {\n+    Node* base          = ophi->in(i);\n+    JavaObjectNode* ptn = unique_java_object(base);\n+\n+    if (ptn != nullptr && ptn->scalar_replaceable()) {\n+      new_phi->set_req(i, null_ptr);\n+    } else {\n+      new_phi->set_req(i, ophi->in(i));\n+    }\n+  }\n+\n+  _igvn->replace_node(ophi, new_phi);\n+  _igvn->hash_insert(ophi);\n+  _igvn->_worklist.push(ophi);\n+}\n+\n+void ConnectionGraph::reduce_phi(PhiNode* ophi) {\n+  Unique_Node_List safepoints;\n+\n+  for (uint i = 0; i < ophi->outcnt(); i++) {\n+    Node* use = ophi->raw_out(i);\n+\n+    \/\/ All SafePoint nodes using the same Phi node use the same debug\n+    \/\/ information (regarding the Phi). Furthermore, reducing the Phi used by a\n+    \/\/ SafePoint requires changing the Phi. Therefore, I collect all safepoints\n+    \/\/ and patch them all at once later.\n+    if (use->is_SafePoint()) {\n+      safepoints.push(use->as_SafePoint());\n+    } else {\n+      assert(false, \"Unexpected use of reducible Phi.\");\n+    }\n+  }\n+\n+  if (safepoints.size() > 0) {\n+    reduce_phi_on_safepoints(ophi, &safepoints);\n+  }\n+}\n+\n+void ConnectionGraph::verify_ram_nodes(Compile* C, Node* root) {\n+  Unique_Node_List ideal_nodes;\n+\n+  ideal_nodes.map(C->live_nodes(), nullptr);  \/\/ preallocate space\n+  ideal_nodes.push(root);\n+\n+  for (uint next = 0; next < ideal_nodes.size(); ++next) {\n+    Node* n = ideal_nodes.at(next);\n+\n+    if (n->is_SafePointScalarMerge()) {\n+      SafePointScalarMergeNode* merge = n->as_SafePointScalarMerge();\n+\n+      \/\/ Validate inputs of merge\n+      for (uint i = 1; i < merge->req(); i++) {\n+        if (merge->in(i) != nullptr && !merge->in(i)->is_top() && !merge->in(i)->is_SafePointScalarObject()) {\n+          assert(false, \"SafePointScalarMerge inputs should be null\/top or SafePointScalarObject.\");\n+          C->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n+        }\n+      }\n+\n+      \/\/ Validate users of merge\n+      for (DUIterator_Fast imax, i = merge->fast_outs(imax); i < imax; i++) {\n+        Node* sfpt = merge->fast_out(i);\n+        if (sfpt->is_SafePoint()) {\n+          int merge_idx = merge->merge_pointer_idx(sfpt->as_SafePoint()->jvms());\n+\n+          if (sfpt->in(merge_idx) != nullptr && sfpt->in(merge_idx)->is_SafePointScalarMerge()) {\n+            assert(false, \"SafePointScalarMerge nodes can't be nested.\");\n+            C->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n+          }\n+        } else {\n+          assert(false, \"Only safepoints can use SafePointScalarMerge nodes.\");\n+          C->record_failure(C2Compiler::retry_no_reduce_allocation_merges());\n+        }\n+      }\n+    }\n+\n+    for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+      Node* m = n->fast_out(i);\n+      ideal_nodes.push(m);\n+    }\n+  }\n+}\n+\n@@ -583,1 +955,2 @@\n-      add_java_object(n, es);\n+      PointsToNode* ptn_con = add_java_object(n, es);\n+      set_not_scalar_replaceable(ptn_con NOT_PRODUCT(COMMA \"Constant pointer\"));\n@@ -672,1 +1045,2 @@\n-      add_java_object(n, PointsToNode::ArgEscape);\n+      PointsToNode* ptn_thr = add_java_object(n, PointsToNode::ArgEscape);\n+      set_not_scalar_replaceable(ptn_thr NOT_PRODUCT(COMMA \"Constant pointer\"));\n@@ -1050,0 +1424,3 @@\n+      if (es == PointsToNode::GlobalEscape) {\n+        set_not_scalar_replaceable(ptnode_adr(call->_idx) NOT_PRODUCT(COMMA \"object can be loaded from boxing cache\"));\n+      }\n@@ -1863,1 +2240,9 @@\n-void ConnectionGraph::adjust_scalar_replaceable_state(JavaObjectNode* jobj) {\n+void ConnectionGraph::adjust_scalar_replaceable_state(JavaObjectNode* jobj, Unique_Node_List &reducible_merges) {\n+  \/\/ A Phi 'x' is a _candidate_ to be reducible if 'can_reduce_phi(x)'\n+  \/\/ returns true. If one of the constraints in this method set 'jobj' to NSR\n+  \/\/ then the candidate Phi is discarded. If the Phi has another SR 'jobj' as\n+  \/\/ input, 'adjust_scalar_replaceable_state' will eventually be called with\n+  \/\/ that other object and the Phi will become a reducible Phi.\n+  \/\/ There could be multiple merges involving the same jobj.\n+  Unique_Node_List candidates;\n+\n@@ -1898,1 +2283,2 @@\n-    \/\/ 3. An object is not scalar replaceable if it is merged with other objects.\n+    \/\/ 3. An object is not scalar replaceable if it is merged with other objects\n+    \/\/ and we can't remove the merge\n@@ -1902,3 +2288,17 @@\n-        \/\/ Mark all objects.\n-        set_not_scalar_replaceable(jobj NOT_PRODUCT(COMMA trace_merged_message(ptn)));\n-        set_not_scalar_replaceable(ptn NOT_PRODUCT(COMMA trace_merged_message(jobj)));\n+        Node* use_n = use->ideal_node();\n+\n+        \/\/ If it's already a candidate or confirmed reducible merge we can skip verification\n+        if (candidates.member(use_n)) {\n+          continue;\n+        } else if (reducible_merges.member(use_n)) {\n+          candidates.push(use_n);\n+          continue;\n+        }\n+\n+        if (ReduceAllocationMerges && use_n->is_Phi() && can_reduce_phi(use_n->as_Phi())) {\n+          candidates.push(use_n);\n+        } else {\n+          \/\/ Mark all objects as NSR if we can't remove the merge\n+          set_not_scalar_replaceable(jobj NOT_PRODUCT(COMMA trace_merged_message(ptn)));\n+          set_not_scalar_replaceable(ptn NOT_PRODUCT(COMMA trace_merged_message(jobj)));\n+        }\n@@ -1967,1 +2367,1 @@\n-    if (field->base_count() > 1) {\n+    if (field->base_count() > 1 && candidates.size() == 0) {\n@@ -1979,0 +2379,4 @@\n+\n+      if (!jobj->scalar_replaceable()) {\n+        return;\n+      }\n@@ -1981,0 +2385,9 @@\n+\n+  \/\/ The candidate is truly a reducible merge only if none of the other\n+  \/\/ constraints ruled it as NSR. There could be multiple merges involving the\n+  \/\/ same jobj.\n+  assert(jobj->scalar_replaceable(), \"sanity\");\n+  for (uint i = 0; i < candidates.size(); i++ ) {\n+    Node* candidate = candidates.at(i);\n+    reducible_merges.push(candidate);\n+  }\n@@ -2246,1 +2659,1 @@\n-void ConnectionGraph::add_java_object(Node *n, PointsToNode::EscapeState es) {\n+PointsToNode* ConnectionGraph::add_java_object(Node *n, PointsToNode::EscapeState es) {\n@@ -2250,1 +2663,1 @@\n-    return;\n+    return ptadr;\n@@ -2255,0 +2668,1 @@\n+  return ptadr;\n@@ -2345,2 +2759,1 @@\n-JavaObjectNode* ConnectionGraph::unique_java_object(Node *n) {\n-  assert(!_collecting, \"should not call when constructed graph\");\n+JavaObjectNode* ConnectionGraph::unique_java_object(Node *n) const {\n@@ -3185,1 +3598,2 @@\n-                                         GrowableArray<MergeMemNode*> &mergemem_worklist) {\n+                                         GrowableArray<MergeMemNode*> &mergemem_worklist,\n+                                         Unique_Node_List &reducible_merges) {\n@@ -3332,1 +3746,6 @@\n-      JavaObjectNode* jobj = unique_java_object(get_addp_base(n));\n+      Node* addp_base = get_addp_base(n);\n+      if (addp_base != nullptr && reducible_merges.member(addp_base)) {\n+        \/\/ This AddP will go away when we reduce the the Phi\n+        continue;\n+      }\n+      JavaObjectNode* jobj = unique_java_object(addp_base);\n@@ -3353,0 +3772,6 @@\n+      \/\/ Reducible Phi's will be removed from the graph after split_unique_types finishes\n+      if (reducible_merges.member(n)) {\n+        \/\/ Split loads through phi\n+        reduce_phi_on_field_access(n->as_Phi(), alloc_worklist);\n+        continue;\n+      }\n@@ -3495,1 +3920,0 @@\n-  assert(unique_old == _compile->unique(), \"there should be no new ideal nodes after Phase 1\");\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":442,"deletions":18,"binary":false,"changes":460,"status":"modified"},{"patch":"@@ -364,1 +364,1 @@\n-  void add_java_object(Node* n, PointsToNode::EscapeState es);\n+  PointsToNode* add_java_object(Node* n, PointsToNode::EscapeState es);\n@@ -445,0 +445,4 @@\n+\n+      if (esc != PointsToNode::NoEscape) {\n+        ptn->set_scalar_replaceable(false);\n+      }\n@@ -455,0 +459,4 @@\n+\n+      if (esc != PointsToNode::NoEscape) {\n+        ptn->set_scalar_replaceable(false);\n+      }\n@@ -464,1 +472,1 @@\n-  void adjust_scalar_replaceable_state(JavaObjectNode* jobj);\n+  void adjust_scalar_replaceable_state(JavaObjectNode* jobj, Unique_Node_List &reducible_merges);\n@@ -476,1 +484,1 @@\n-  JavaObjectNode* unique_java_object(Node *n);\n+  JavaObjectNode* unique_java_object(Node *n) const;\n@@ -536,1 +544,2 @@\n-                          GrowableArray<MergeMemNode*> &mergemem_worklist);\n+                          GrowableArray<MergeMemNode*> &mergemem_worklist,\n+                          Unique_Node_List &reducible_merges);\n@@ -581,0 +590,11 @@\n+  \/\/ -------------------------------------------\n+  \/\/ Methods related to Reduce Allocation Merges\n+\n+  bool can_reduce_phi(PhiNode* ophi) const;\n+  bool can_reduce_phi_check_users(PhiNode* ophi) const;\n+  bool can_reduce_phi_check_inputs(PhiNode* ophi) const;\n+\n+  void reduce_phi_on_field_access(PhiNode* ophi, GrowableArray<Node *>  &alloc_worklist);\n+  void reduce_phi_on_safepoints(PhiNode* ophi, Unique_Node_List* safepoints);\n+  void reduce_phi(PhiNode* ophi);\n+\n@@ -602,0 +622,3 @@\n+  \/\/ Verify that SafePointScalarMerge nodes are correctly connected\n+  static void verify_ram_nodes(Compile* C, Node* root);\n+\n","filename":"src\/hotspot\/share\/opto\/escape.hpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-    Node* adr = _igvn.transform(new AddPNode(base, base, MakeConX(offset)));\n+    Node* adr = _igvn.transform(new AddPNode(base, base, _igvn.MakeConX(offset)));\n@@ -307,1 +307,1 @@\n-        adr = _igvn.transform(new AddPNode(base, base, MakeConX(off)));\n+        adr = _igvn.transform(new AddPNode(base, base, _igvn.MakeConX(off)));\n@@ -318,1 +318,1 @@\n-        diff = _igvn.transform(new LShiftXNode(diff, intcon(shift)));\n+        diff = _igvn.transform(new LShiftXNode(diff, _igvn.intcon(shift)));\n@@ -320,1 +320,1 @@\n-        Node* off = _igvn.transform(new AddXNode(MakeConX(offset), diff));\n+        Node* off = _igvn.transform(new AddXNode(_igvn.MakeConX(offset), diff));\n@@ -553,1 +553,1 @@\n-bool PhaseMacroExpand::can_eliminate_allocation(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints) {\n+bool PhaseMacroExpand::can_eliminate_allocation(PhaseIterGVN* igvn, AllocateNode *alloc, GrowableArray <SafePointNode *>* safepoints) {\n@@ -558,1 +558,2 @@\n-  bool  can_eliminate = true;\n+  bool can_eliminate = true;\n+  bool reduce_merge_precheck = (safepoints == nullptr);\n@@ -568,1 +569,1 @@\n-    res_type = _igvn.type(res)->isa_oopptr();\n+    res_type = igvn->type(res)->isa_oopptr();\n@@ -588,1 +589,1 @@\n-        const TypePtr* addp_type = _igvn.type(use)->is_ptr();\n+        const TypePtr* addp_type = igvn->type(use)->is_ptr();\n@@ -629,2 +630,2 @@\n-        } else {\n-          safepoints.append_if_missing(sfpt);\n+        } else if (!reduce_merge_precheck) {\n+          safepoints->append_if_missing(sfpt);\n@@ -632,0 +633,2 @@\n+      } else if (reduce_merge_precheck && (use->is_Phi() || use->is_EncodeP() || use->Opcode() == Op_MemBarRelease)) {\n+        \/\/ Nothing to do\n@@ -643,1 +646,1 @@\n-          }else {\n+          } else {\n@@ -654,1 +657,1 @@\n-  if (PrintEliminateAllocations) {\n+  if (PrintEliminateAllocations && safepoints != nullptr) {\n@@ -679,11 +682,1 @@\n-\/\/ Do scalar replacement.\n-bool PhaseMacroExpand::scalar_replacement(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints) {\n-  GrowableArray <SafePointNode *> safepoints_done;\n-\n-  ciInstanceKlass* iklass = nullptr;\n-  int nfields = 0;\n-  int array_base = 0;\n-  int element_size = 0;\n-  BasicType basic_elem_type = T_ILLEGAL;\n-  const Type* field_type = nullptr;\n-\n+void PhaseMacroExpand::undo_previous_scalarizations(GrowableArray <SafePointNode *> safepoints_done, AllocateNode* alloc) {\n@@ -691,0 +684,1 @@\n+  int nfields = 0;\n@@ -692,0 +686,50 @@\n+\n+  if (res != nullptr) {\n+    const TypeOopPtr* res_type = _igvn.type(res)->isa_oopptr();\n+\n+    if (res_type->isa_instptr()) {\n+      \/\/ find the fields of the class which will be needed for safepoint debug information\n+      ciInstanceKlass* iklass = res_type->is_instptr()->instance_klass();\n+      nfields = iklass->nof_nonstatic_fields();\n+    } else {\n+      \/\/ find the array's elements which will be needed for safepoint debug information\n+      nfields = alloc->in(AllocateNode::ALength)->find_int_con(-1);\n+      assert(nfields >= 0, \"must be an array klass.\");\n+    }\n+  }\n+\n+  \/\/ rollback processed safepoints\n+  while (safepoints_done.length() > 0) {\n+    SafePointNode* sfpt_done = safepoints_done.pop();\n+    \/\/ remove any extra entries we added to the safepoint\n+    uint last = sfpt_done->req() - 1;\n+    for (int k = 0;  k < nfields; k++) {\n+      sfpt_done->del_req(last--);\n+    }\n+    JVMState *jvms = sfpt_done->jvms();\n+    jvms->set_endoff(sfpt_done->req());\n+    \/\/ Now make a pass over the debug information replacing any references\n+    \/\/ to SafePointScalarObjectNode with the allocated object.\n+    int start = jvms->debug_start();\n+    int end   = jvms->debug_end();\n+    for (int i = start; i < end; i++) {\n+      if (sfpt_done->in(i)->is_SafePointScalarObject()) {\n+        SafePointScalarObjectNode* scobj = sfpt_done->in(i)->as_SafePointScalarObject();\n+        if (scobj->first_index(jvms) == sfpt_done->req() &&\n+            scobj->n_fields() == (uint)nfields) {\n+          assert(scobj->alloc() == alloc, \"sanity\");\n+          sfpt_done->set_req(i, res);\n+        }\n+      }\n+    }\n+    _igvn._worklist.push(sfpt_done);\n+  }\n+}\n+\n+SafePointScalarObjectNode* PhaseMacroExpand::create_scalarized_object_description(AllocateNode *alloc, SafePointNode* sfpt) {\n+  \/\/ Fields of scalar objs are referenced only at the end\n+  \/\/ of regular debuginfo at the last (youngest) JVMS.\n+  \/\/ Record relative start index.\n+  ciInstanceKlass* iklass    = nullptr;\n+  BasicType basic_elem_type  = T_ILLEGAL;\n+  const Type* field_type     = nullptr;\n@@ -693,0 +737,9 @@\n+  int nfields                = 0;\n+  int array_base             = 0;\n+  int element_size           = 0;\n+  uint first_ind             = (sfpt->req() - sfpt->jvms()->scloff());\n+  Node* res                  = alloc->result_cast();\n+\n+  assert(res == nullptr || res->is_CheckCastPP(), \"unexpected AllocateNode result\");\n+  assert(sfpt->jvms() != nullptr, \"missed JVMS\");\n+\n@@ -695,1 +748,0 @@\n-  }\n@@ -697,1 +749,0 @@\n-  if (res != nullptr) {\n@@ -712,47 +763,25 @@\n-  \/\/\n-  \/\/ Process the safepoint uses\n-  \/\/\n-  while (safepoints.length() > 0) {\n-    SafePointNode* sfpt = safepoints.pop();\n-    Node* mem = sfpt->memory();\n-    Node* ctl = sfpt->control();\n-    assert(sfpt->jvms() != nullptr, \"missed JVMS\");\n-    \/\/ Fields of scalar objs are referenced only at the end\n-    \/\/ of regular debuginfo at the last (youngest) JVMS.\n-    \/\/ Record relative start index.\n-    uint first_ind = (sfpt->req() - sfpt->jvms()->scloff());\n-    SafePointScalarObjectNode* sobj = new SafePointScalarObjectNode(res_type,\n-#ifdef ASSERT\n-                                                 alloc,\n-#endif\n-                                                 first_ind, nfields);\n-    sobj->init_req(0, C->root());\n-    transform_later(sobj);\n-\n-    \/\/ Scan object's fields adding an input to the safepoint for each field.\n-    for (int j = 0; j < nfields; j++) {\n-      intptr_t offset;\n-      ciField* field = nullptr;\n-      if (iklass != nullptr) {\n-        field = iklass->nonstatic_field_at(j);\n-        offset = field->offset_in_bytes();\n-        ciType* elem_type = field->type();\n-        basic_elem_type = field->layout_type();\n-\n-        \/\/ The next code is taken from Parse::do_get_xxx().\n-        if (is_reference_type(basic_elem_type)) {\n-          if (!elem_type->is_loaded()) {\n-            field_type = TypeInstPtr::BOTTOM;\n-          } else if (field != nullptr && field->is_static_constant()) {\n-            ciObject* con = field->constant_value().as_object();\n-            \/\/ Do not \"join\" in the previous type; it doesn't add value,\n-            \/\/ and may yield a vacuous result if the field is of interface type.\n-            field_type = TypeOopPtr::make_from_constant(con)->isa_oopptr();\n-            assert(field_type != nullptr, \"field singleton type must be consistent\");\n-          } else {\n-            field_type = TypeOopPtr::make_from_klass(elem_type->as_klass());\n-          }\n-          if (UseCompressedOops) {\n-            field_type = field_type->make_narrowoop();\n-            basic_elem_type = T_NARROWOOP;\n-          }\n+\n+  SafePointScalarObjectNode* sobj = new SafePointScalarObjectNode(res_type, alloc, first_ind, nfields);\n+  sobj->init_req(0, C->root());\n+  transform_later(sobj);\n+\n+  \/\/ Scan object's fields adding an input to the safepoint for each field.\n+  for (int j = 0; j < nfields; j++) {\n+    intptr_t offset;\n+    ciField* field = nullptr;\n+    if (iklass != nullptr) {\n+      field = iklass->nonstatic_field_at(j);\n+      offset = field->offset_in_bytes();\n+      ciType* elem_type = field->type();\n+      basic_elem_type = field->layout_type();\n+\n+      \/\/ The next code is taken from Parse::do_get_xxx().\n+      if (is_reference_type(basic_elem_type)) {\n+        if (!elem_type->is_loaded()) {\n+          field_type = TypeInstPtr::BOTTOM;\n+        } else if (field != nullptr && field->is_static_constant()) {\n+          ciObject* con = field->constant_value().as_object();\n+          \/\/ Do not \"join\" in the previous type; it doesn't add value,\n+          \/\/ and may yield a vacuous result if the field is of interface type.\n+          field_type = TypeOopPtr::make_from_constant(con)->isa_oopptr();\n+          assert(field_type != nullptr, \"field singleton type must be consistent\");\n@@ -760,1 +789,5 @@\n-          field_type = Type::get_const_basic_type(basic_elem_type);\n+          field_type = TypeOopPtr::make_from_klass(elem_type->as_klass());\n+        }\n+        if (UseCompressedOops) {\n+          field_type = field_type->make_narrowoop();\n+          basic_elem_type = T_NARROWOOP;\n@@ -763,1 +796,1 @@\n-        offset = array_base + j * (intptr_t)element_size;\n+        field_type = Type::get_const_basic_type(basic_elem_type);\n@@ -765,0 +798,3 @@\n+    } else {\n+      offset = array_base + j * (intptr_t)element_size;\n+    }\n@@ -766,1 +802,1 @@\n-      const TypeOopPtr *field_addr_type = res_type->add_offset(offset)->isa_oopptr();\n+    const TypeOopPtr *field_addr_type = res_type->add_offset(offset)->isa_oopptr();\n@@ -768,4 +804,10 @@\n-      Node *field_val = value_from_mem(mem, ctl, basic_elem_type, field_type, field_addr_type, alloc);\n-      if (field_val == nullptr) {\n-        \/\/ We weren't able to find a value for this field,\n-        \/\/ give up on eliminating this allocation.\n+    Node *field_val = value_from_mem(sfpt->memory(), sfpt->control(), basic_elem_type, field_type, field_addr_type, alloc);\n+\n+    \/\/ We weren't able to find a value for this field,\n+    \/\/ give up on eliminating this allocation.\n+    if (field_val == nullptr) {\n+      uint last = sfpt->req() - 1;\n+      for (int k = 0;  k < j; k++) {\n+        sfpt->del_req(last--);\n+      }\n+      _igvn._worklist.push(sfpt);\n@@ -773,32 +815,0 @@\n-        \/\/ Remove any extra entries we added to the safepoint.\n-        uint last = sfpt->req() - 1;\n-        for (int k = 0;  k < j; k++) {\n-          sfpt->del_req(last--);\n-        }\n-        _igvn._worklist.push(sfpt);\n-        \/\/ rollback processed safepoints\n-        while (safepoints_done.length() > 0) {\n-          SafePointNode* sfpt_done = safepoints_done.pop();\n-          \/\/ remove any extra entries we added to the safepoint\n-          last = sfpt_done->req() - 1;\n-          for (int k = 0;  k < nfields; k++) {\n-            sfpt_done->del_req(last--);\n-          }\n-          JVMState *jvms = sfpt_done->jvms();\n-          jvms->set_endoff(sfpt_done->req());\n-          \/\/ Now make a pass over the debug information replacing any references\n-          \/\/ to SafePointScalarObjectNode with the allocated object.\n-          int start = jvms->debug_start();\n-          int end   = jvms->debug_end();\n-          for (int i = start; i < end; i++) {\n-            if (sfpt_done->in(i)->is_SafePointScalarObject()) {\n-              SafePointScalarObjectNode* scobj = sfpt_done->in(i)->as_SafePointScalarObject();\n-              if (scobj->first_index(jvms) == sfpt_done->req() &&\n-                  scobj->n_fields() == (uint)nfields) {\n-                assert(scobj->alloc() == alloc, \"sanity\");\n-                sfpt_done->set_req(i, res);\n-              }\n-            }\n-          }\n-          _igvn._worklist.push(sfpt_done);\n-        }\n@@ -806,16 +816,8 @@\n-        if (PrintEliminateAllocations) {\n-          if (field != nullptr) {\n-            tty->print(\"=== At SafePoint node %d can't find value of Field: \",\n-                       sfpt->_idx);\n-            field->print();\n-            int field_idx = C->get_alias_index(field_addr_type);\n-            tty->print(\" (alias_idx=%d)\", field_idx);\n-          } else { \/\/ Array's element\n-            tty->print(\"=== At SafePoint node %d can't find value of array element [%d]\",\n-                       sfpt->_idx, j);\n-          }\n-          tty->print(\", which prevents elimination of: \");\n-          if (res == nullptr)\n-            alloc->dump();\n-          else\n-            res->dump();\n+      if (PrintEliminateAllocations) {\n+        if (field != nullptr) {\n+          tty->print(\"=== At SafePoint node %d can't find value of field: \", sfpt->_idx);\n+          field->print();\n+          int field_idx = C->get_alias_index(field_addr_type);\n+          tty->print(\" (alias_idx=%d)\", field_idx);\n+        } else { \/\/ Array's element\n+          tty->print(\"=== At SafePoint node %d can't find value of array element [%d]\", sfpt->_idx, j);\n@@ -823,2 +825,5 @@\n-#endif\n-        return false;\n+        tty->print(\", which prevents elimination of: \");\n+        if (res == nullptr)\n+          alloc->dump();\n+        else\n+          res->dump();\n@@ -826,8 +831,12 @@\n-      if (UseCompressedOops && field_type->isa_narrowoop()) {\n-        \/\/ Enable \"DecodeN(EncodeP(Allocate)) --> Allocate\" transformation\n-        \/\/ to be able scalar replace the allocation.\n-        if (field_val->is_EncodeP()) {\n-          field_val = field_val->in(1);\n-        } else {\n-          field_val = transform_later(new DecodeNNode(field_val, field_val->get_ptr_type()));\n-        }\n+#endif\n+\n+      return nullptr;\n+    }\n+\n+    if (UseCompressedOops && field_type->isa_narrowoop()) {\n+      \/\/ Enable \"DecodeN(EncodeP(Allocate)) --> Allocate\" transformation\n+      \/\/ to be able scalar replace the allocation.\n+      if (field_val->is_EncodeP()) {\n+        field_val = field_val->in(1);\n+      } else {\n+        field_val = transform_later(new DecodeNNode(field_val, field_val->get_ptr_type()));\n@@ -835,1 +844,0 @@\n-      sfpt->add_req(field_val);\n@@ -837,2 +845,24 @@\n-    JVMState *jvms = sfpt->jvms();\n-    jvms->set_endoff(sfpt->req());\n+    sfpt->add_req(field_val);\n+  }\n+\n+  sfpt->jvms()->set_endoff(sfpt->req());\n+\n+  return sobj;\n+}\n+\n+\/\/ Do scalar replacement.\n+bool PhaseMacroExpand::scalar_replacement(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints) {\n+  GrowableArray <SafePointNode *> safepoints_done;\n+  Node* res = alloc->result_cast();\n+  assert(res == nullptr || res->is_CheckCastPP(), \"unexpected AllocateNode result\");\n+\n+  \/\/ Process the safepoint uses\n+  while (safepoints.length() > 0) {\n+    SafePointNode* sfpt = safepoints.pop();\n+    SafePointScalarObjectNode* sobj = create_scalarized_object_description(alloc, sfpt);\n+\n+    if (sobj == nullptr) {\n+      undo_previous_scalarizations(safepoints_done, alloc);\n+      return false;\n+    }\n+\n@@ -841,3 +871,2 @@\n-    int start = jvms->debug_start();\n-    int end   = jvms->debug_end();\n-    sfpt->replace_edges_in_range(res, sobj, start, end, &_igvn);\n+    JVMState *jvms = sfpt->jvms();\n+    sfpt->replace_edges_in_range(res, sobj, jvms->debug_start(), jvms->debug_end(), &_igvn);\n@@ -845,1 +874,3 @@\n-    safepoints_done.append_if_missing(sfpt); \/\/ keep it for rollback\n+\n+    \/\/ keep it for rollback\n+    safepoints_done.append_if_missing(sfpt);\n@@ -847,0 +878,1 @@\n+\n@@ -1033,1 +1065,1 @@\n-  if (!can_eliminate_allocation(alloc, safepoints)) {\n+  if (!can_eliminate_allocation(&_igvn, alloc, &safepoints)) {\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":177,"deletions":145,"binary":false,"changes":322,"status":"modified"},{"patch":"@@ -102,2 +102,2 @@\n-  bool can_eliminate_allocation(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints);\n-  bool scalar_replacement(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints_done);\n+  void undo_previous_scalarizations(GrowableArray <SafePointNode *> safepoints_done, AllocateNode* alloc);\n+  bool scalar_replacement(AllocateNode *alloc, GrowableArray <SafePointNode *>& safepoints);\n@@ -208,0 +208,4 @@\n+  SafePointScalarObjectNode* create_scalarized_object_description(AllocateNode *alloc, SafePointNode* sfpt);\n+  static bool can_eliminate_allocation(PhaseIterGVN *igvn, AllocateNode *alloc, GrowableArray <SafePointNode *> *safepoints);\n+\n+\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1520,0 +1520,29 @@\n+\n+\/\/------------------------------split_through_phi------------------------------\n+\/\/ Check whether a call to 'split_through_phi' would split this load through the\n+\/\/ Phi *base*. This method is essentially a copy of the validations performed\n+\/\/ by 'split_through_phi'. The first use of this method was in EA code as part\n+\/\/ of simplification of allocation merges.\n+bool LoadNode::can_split_through_phi_base(PhaseGVN* phase) {\n+  Node* mem        = in(Memory);\n+  Node* address    = in(Address);\n+  intptr_t ignore  = 0;\n+  Node*    base    = AddPNode::Ideal_base_and_offset(address, phase, ignore);\n+  bool base_is_phi = (base != nullptr) && base->is_Phi();\n+\n+  if (req() > 3 || !base_is_phi) {\n+    return false;\n+  }\n+\n+  if (!mem->is_Phi()) {\n+    if (!MemNode::all_controls_dominate(mem, base->in(0)))\n+      return false;\n+  } else if (base->in(0) != mem->in(0)) {\n+    if (!MemNode::all_controls_dominate(mem, base->in(0))) {\n+      return false;\n+    }\n+  }\n+\n+  return true;\n+}\n+\n@@ -1522,1 +1551,1 @@\n-Node* LoadNode::split_through_phi(PhaseGVN* phase) {\n+Node* LoadNode::split_through_phi(PhaseGVN* phase, bool ignore_missing_instance_id) {\n@@ -1533,1 +1562,2 @@\n-         (t_oop->is_known_instance_field() ||\n+         (ignore_missing_instance_id ||\n+          t_oop->is_known_instance_field() ||\n@@ -1545,2 +1575,2 @@\n-        (load_boxed_values || t_oop->is_known_instance_field()))) {\n-    return nullptr; \/\/ memory is not Phi\n+        (ignore_missing_instance_id || load_boxed_values || t_oop->is_known_instance_field()))) {\n+    return nullptr; \/\/ Neither memory or base are Phi\n@@ -1590,1 +1620,1 @@\n-  assert(C->have_alias_type(t_oop), \"instance should have alias type\");\n+  assert(ignore_missing_instance_id || C->have_alias_type(t_oop), \"instance should have alias type\");\n@@ -1626,0 +1656,1 @@\n+  Node* phi = nullptr;\n@@ -1627,7 +1658,0 @@\n-  int this_index  = C->get_alias_index(t_oop);\n-  int this_offset = t_oop->offset();\n-  int this_iid    = t_oop->instance_id();\n-  if (!t_oop->is_known_instance() && load_boxed_values) {\n-    \/\/ Use _idx of address base for boxed values.\n-    this_iid = base->_idx;\n-  }\n@@ -1635,1 +1659,11 @@\n-  Node* phi = new PhiNode(region, this_type, nullptr, mem->_idx, this_iid, this_index, this_offset);\n+  if (t_oop != nullptr && (t_oop->is_known_instance_field() || load_boxed_values)) {\n+    int this_index = C->get_alias_index(t_oop);\n+    int this_offset = t_oop->offset();\n+    int this_iid = t_oop->is_known_instance_field() ? t_oop->instance_id() : base->_idx;\n+    phi = new PhiNode(region, this_type, nullptr, mem->_idx, this_iid, this_index, this_offset);\n+  } else if (ignore_missing_instance_id) {\n+    phi = new PhiNode(region, this_type, nullptr, mem->_idx);\n+  } else {\n+    return nullptr;\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":47,"deletions":13,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -247,0 +247,3 @@\n+  \/\/ Return true if it's possible to split the Load through a Phi merging the bases\n+  bool can_split_through_phi_base(PhaseGVN *phase);\n+\n@@ -248,1 +251,1 @@\n-  Node* split_through_phi(PhaseGVN *phase);\n+  Node* split_through_phi(PhaseGVN *phase, bool ignore_missing_instance_id = false);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -161,0 +161,1 @@\n+class SafePointScalarMergeNode;\n@@ -729,0 +730,1 @@\n+      DEFINE_CLASS_ID(SafePointScalarMerge, Type, 9)\n@@ -956,0 +958,1 @@\n+  DEFINE_CLASS_QUERY(SafePointScalarMerge)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -752,1 +752,1 @@\n-    ObjectValue* sv = sv_for_node_id(objs, spobj->_idx);\n+    ObjectValue* sv = (ObjectValue*) sv_for_node_id(objs, spobj->_idx);\n@@ -769,0 +769,25 @@\n+  } else if (local->is_SafePointScalarMerge()) {\n+    SafePointScalarMergeNode* smerge = local->as_SafePointScalarMerge();\n+    ObjectMergeValue* mv = (ObjectMergeValue*) sv_for_node_id(objs, smerge->_idx);\n+\n+    if (mv == NULL) {\n+      GrowableArray<ScopeValue*> deps;\n+\n+      int merge_pointer_idx = smerge->merge_pointer_idx(sfpt->jvms());\n+      (void)FillLocArray(0, sfpt, sfpt->in(merge_pointer_idx), &deps, objs);\n+      assert(deps.length() == 1, \"missing value\");\n+\n+      int selector_idx = smerge->selector_idx(sfpt->jvms());\n+      (void)FillLocArray(1, NULL, sfpt->in(selector_idx), &deps, NULL);\n+      assert(deps.length() == 2, \"missing value\");\n+\n+      mv = new ObjectMergeValue(smerge->_idx, deps.at(0), deps.at(1));\n+      set_sv_for_object_node(objs, mv);\n+\n+      for (uint i = 1; i < smerge->req(); i++) {\n+        Node* obj_node = smerge->in(i);\n+        (void)FillLocArray(mv->possible_objects()->length(), sfpt, obj_node, mv->possible_objects(), objs);\n+      }\n+    }\n+    array->append(mv);\n+    return;\n@@ -934,0 +959,12 @@\n+\/\/ Determine if there is a monitor that has 'ov' as its owner.\n+bool PhaseOutput::contains_as_owner(GrowableArray<MonitorValue*> *monarray, ObjectValue *ov) const {\n+  for (int k = 0; k < monarray->length(); k++) {\n+    MonitorValue* mv = monarray->at(k);\n+    if (mv->owner() == ov) {\n+      return true;\n+    }\n+  }\n+\n+  return false;\n+}\n+\n@@ -1064,0 +1101,15 @@\n+    \/\/ Mark ObjectValue nodes as root nodes if they are directly\n+    \/\/ referenced in the JVMS.\n+    for (int i = 0; i < objs->length(); i++) {\n+      ScopeValue* sv = objs->at(i);\n+      if (sv->is_object_merge()) {\n+        ObjectMergeValue* merge = sv->as_ObjectMergeValue();\n+\n+        for (int j = 0; j< merge->possible_objects()->length(); j++) {\n+          ObjectValue* ov = merge->possible_objects()->at(j)->as_ObjectValue();\n+          bool is_root = locarray->contains(ov) || exparray->contains(ov) || contains_as_owner(monarray, ov);\n+          ov->set_root(is_root);\n+        }\n+      }\n+    }\n+\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":53,"deletions":1,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -213,0 +213,1 @@\n+  bool contains_as_owner(GrowableArray<MonitorValue*> *monarray, ObjectValue *ov) const;\n","filename":"src\/hotspot\/share\/opto\/output.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -274,5 +274,1 @@\n-    Node* sobj = new SafePointScalarObjectNode(vec_box->box_type(),\n-#ifdef ASSERT\n-                                               vec_box,\n-#endif \/\/ ASSERT\n-                                               first_ind, n_fields);\n+    Node* sobj = new SafePointScalarObjectNode(vec_box->box_type(), vec_box, first_ind, n_fields);\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -333,1 +333,1 @@\n-  GrowableArray<ScopeValue*>* objects = chunk->at(0)->scope()->objects();\n+  GrowableArray<ScopeValue*>* objects = chunk->at(0)->scope()->objects_to_rematerialize(deoptee, map);\n@@ -1567,0 +1567,1 @@\n+    assert(objects->at(i)->is_object(), \"invalid debug information\");\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -781,0 +781,7 @@\n+        \/\/ The 'getStackAccessControlContext' call inside 'isPrivileged'\n+        \/\/ requires that no Local was scalar replaced. However, in some\n+        \/\/ situations, after inlining, 'result' (or part of a possibly\n+        \/\/ allocation merge Phi leading to it) might become NonEscaping and get\n+        \/\/ scalar replaced. The call below enforces 'result' to always escape.\n+        ensureMaterializedForStackWalk(result);\n+\n@@ -812,0 +819,7 @@\n+        \/\/ The 'getStackAccessControlContext' call inside 'isPrivileged'\n+        \/\/ requires that no Local was scalar replaced. However, in some\n+        \/\/ situations, after inlining, 'result' (or part of a possibly\n+        \/\/ allocation merge Phi leading to it) might become NonEscaping and get\n+        \/\/ scalar replaced. The call below enforces 'result' to always escape.\n+        ensureMaterializedForStackWalk(result);\n+\n","filename":"src\/java.base\/share\/classes\/java\/security\/AccessController.java","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -0,0 +1,1412 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package compiler.c2.irTests.scalarReplacement;\n+\n+import java.util.Random;\n+import jdk.test.lib.Asserts;\n+import compiler.lib.ir_framework.*;\n+\n+\/*\n+ * @test\n+ * @bug 8281429\n+ * @summary Tests that C2 can correctly scalar replace some object allocation merges.\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == 64 & vm.compiler2.enabled & vm.opt.final.UseCompressedOops & vm.opt.final.EliminateAllocations\n+ * @run driver compiler.c2.irTests.scalarReplacement.AllocationMergesTests\n+ *\/\n+public class AllocationMergesTests {\n+    private int invocations = 0;\n+    private static Point global_escape = new Point(2022, 2023);\n+\n+    public static void main(String[] args) {\n+        TestFramework.runWithFlags(\"-XX:+ReduceAllocationMerges\",\n+                                   \"-XX:+TraceReduceAllocationMerges\",\n+                                   \"-XX:+DeoptimizeALot\",\n+                                   \"-XX:CompileCommand=exclude,*::dummy*\");\n+    }\n+\n+    \/\/ ------------------ No Scalar Replacement Should Happen in The Tests Below ------------------- \/\/\n+\n+    @Run(test = {\"testGlobalEscape_C2\",\n+                 \"testArgEscape_C2\",\n+                 \"testEscapeInCallAfterMerge_C2\",\n+                 \"testNoEscapeWithWriteInLoop_C2\",\n+                 \"testPollutedWithWrite_C2\",\n+                 \"testPollutedPolymorphic_C2\",\n+                 \"testMergedLoadAfterDirectStore_C2\",\n+                 \"testMergedAccessAfterCallWithWrite_C2\",\n+                 \"testLoadAfterTrap_C2\",\n+                 \"testCondAfterMergeWithNull_C2\",\n+                 \"testLoadAfterLoopAlias_C2\",\n+                 \"testCallTwoSide_C2\",\n+                 \"testMergedAccessAfterCallNoWrite_C2\",\n+                 \"testCmpMergeWithNull_Second_C2\",\n+                 \"testObjectIdentity_C2\",\n+                 \"testSubclassesTrapping_C2\",\n+                 \"testCmpMergeWithNull_C2\",\n+                 \"testSubclasses_C2\",\n+                 \"testPartialPhis_C2\",\n+                 \"testPollutedNoWrite_C2\",\n+                 \"testThreeWayAliasedAlloc_C2\",\n+                 \"TestTrapAfterMerge_C2\",\n+                 \"testNestedObjectsObject_C2\",\n+                 \"testNestedObjectsNoEscapeObject_C2\",\n+                 \"testNestedObjectsArray_C2\",\n+                 \"testTrappingAfterMerge_C2\",\n+                 \"testSimpleAliasedAlloc_C2\",\n+                 \"testSimpleDoubleMerge_C2\",\n+                 \"testConsecutiveSimpleMerge_C2\",\n+                 \"testDoubleIfElseMerge_C2\",\n+                 \"testNoEscapeWithLoadInLoop_C2\",\n+                 \"testCmpAfterMerge_C2\",\n+                 \"testCondAfterMergeWithAllocate_C2\",\n+                 \"testCondLoadAfterMerge_C2\",\n+                 \"testIfElseInLoop_C2\",\n+                 \"testLoadInCondAfterMerge_C2\",\n+                 \"testLoadInLoop_C2\",\n+                 \"testMergesAndMixedEscape_C2\",\n+                 \"testSRAndNSR_NoTrap_C2\",\n+                 \"testSRAndNSR_Trap_C2\",\n+                 \"testString_one_C2\",\n+                 \"testString_two_C2\"\n+                })\n+    public void runner(RunInfo info) {\n+        Random random = info.getRandom();\n+        boolean cond1 = random.nextBoolean();\n+        boolean cond2 = random.nextBoolean();\n+\n+        int l = random.nextInt();\n+        int w = random.nextInt();\n+        int x = random.nextInt();\n+        int y = random.nextInt();\n+        int z = random.nextInt();\n+\n+        Asserts.assertEQ(testGlobalEscape_Interp(x, y),                             testGlobalEscape_C2(x, y));\n+        Asserts.assertEQ(testArgEscape_Interp(x, y),                                testArgEscape_C2(x, y));\n+        Asserts.assertEQ(testEscapeInCallAfterMerge_Interp(cond1, cond2, x, y),     testEscapeInCallAfterMerge_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testNoEscapeWithWriteInLoop_Interp(cond1, cond2, x, y),    testNoEscapeWithWriteInLoop_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testPollutedWithWrite_Interp(cond1, x),                    testPollutedWithWrite_C2(cond1, x));\n+        Asserts.assertEQ(testPollutedPolymorphic_Interp(cond1, x),                  testPollutedPolymorphic_C2(cond1, x));\n+        Asserts.assertEQ(testMergedLoadAfterDirectStore_Interp(cond1, x, y),        testMergedLoadAfterDirectStore_C2(cond1, x, y));\n+        Asserts.assertEQ(testMergedAccessAfterCallWithWrite_Interp(cond1, x, y),    testMergedAccessAfterCallWithWrite_C2(cond1, x, y));\n+        Asserts.assertEQ(testLoadAfterTrap_Interp(cond1, x, y),                     testLoadAfterTrap_C2(cond1, x, y));\n+        Asserts.assertEQ(testCondAfterMergeWithNull_Interp(cond1, cond2, x, y),     testCondAfterMergeWithNull_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testLoadAfterLoopAlias_Interp(cond1, x, y),                testLoadAfterLoopAlias_C2(cond1, x, y));\n+        Asserts.assertEQ(testCallTwoSide_Interp(cond1, x, y),                       testCallTwoSide_C2(cond1, x, y));\n+        Asserts.assertEQ(testMergedAccessAfterCallNoWrite_Interp(cond1, x, y),      testMergedAccessAfterCallNoWrite_C2(cond1, x, y));\n+        Asserts.assertEQ(testCmpMergeWithNull_Second_Interp(cond1, x, y),           testCmpMergeWithNull_Second_C2(cond1, x, y));\n+        Asserts.assertEQ(testObjectIdentity_Interp(cond1, 42, y),                   testObjectIdentity_C2(cond1, 42, y));\n+        Asserts.assertEQ(testSubclassesTrapping_Interp(cond1, cond2, x, y, w, z),   testSubclassesTrapping_C2(cond1, cond2, x, y, w, z));\n+        Asserts.assertEQ(testCmpMergeWithNull_Interp(cond1, x, y),                  testCmpMergeWithNull_C2(cond1, x, y));\n+        Asserts.assertEQ(testSubclasses_Interp(cond1, cond2, x, y, w, z),           testSubclasses_C2(cond1, cond2, x, y, w, z));\n+        Asserts.assertEQ(testPartialPhis_Interp(cond1, l, x, y),                    testPartialPhis_C2(cond1, l, x, y));\n+        Asserts.assertEQ(testPollutedNoWrite_Interp(cond1, l),                      testPollutedNoWrite_C2(cond1, l));\n+        Asserts.assertEQ(testThreeWayAliasedAlloc_Interp(cond1, x, y),              testThreeWayAliasedAlloc_C2(cond1, x, y));\n+        Asserts.assertEQ(TestTrapAfterMerge_Interp(cond1, x, y),                    TestTrapAfterMerge_C2(cond1, x, y));\n+        Asserts.assertEQ(testNestedObjectsObject_Interp(cond1, x, y),               testNestedObjectsObject_C2(cond1, x, y));\n+        Asserts.assertEQ(testNestedObjectsNoEscapeObject_Interp(cond1, x, y),       testNestedObjectsNoEscapeObject_C2(cond1, x, y));\n+        Asserts.assertEQ(testTrappingAfterMerge_Interp(cond1, x, y),                testTrappingAfterMerge_C2(cond1, x, y));\n+        Asserts.assertEQ(testSimpleAliasedAlloc_Interp(cond1, x, y),                testSimpleAliasedAlloc_C2(cond1, x, y));\n+        Asserts.assertEQ(testSimpleDoubleMerge_Interp(cond1, x, y),                 testSimpleDoubleMerge_C2(cond1, x, y));\n+        Asserts.assertEQ(testConsecutiveSimpleMerge_Interp(cond1, cond2, x, y),     testConsecutiveSimpleMerge_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testDoubleIfElseMerge_Interp(cond1, x, y),                 testDoubleIfElseMerge_C2(cond1, x, y));\n+        Asserts.assertEQ(testNoEscapeWithLoadInLoop_Interp(cond1, x, y),            testNoEscapeWithLoadInLoop_C2(cond1, x, y));\n+        Asserts.assertEQ(testCmpAfterMerge_Interp(cond1, cond2, x, y),              testCmpAfterMerge_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testCondAfterMergeWithAllocate_Interp(cond1, cond2, x, y), testCondAfterMergeWithAllocate_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testCondLoadAfterMerge_Interp(cond1, cond2, x, y),         testCondLoadAfterMerge_C2(cond1, cond2, x, y));\n+        Asserts.assertEQ(testIfElseInLoop_Interp(),                                 testIfElseInLoop_C2());\n+        Asserts.assertEQ(testLoadInCondAfterMerge_Interp(cond1, x, y),              testLoadInCondAfterMerge_C2(cond1, x, y));\n+        Asserts.assertEQ(testLoadInLoop_Interp(cond1, x, y),                        testLoadInLoop_C2(cond1, x, y));\n+        Asserts.assertEQ(testMergesAndMixedEscape_Interp(cond1, x, y),              testMergesAndMixedEscape_C2(cond1, x, y));\n+        Asserts.assertEQ(testSRAndNSR_NoTrap_Interp(cond1, x, y),                   testSRAndNSR_NoTrap_C2(cond1, x, y));\n+        Asserts.assertEQ(testString_one_Interp(cond1),                              testString_one_C2(cond1));\n+        Asserts.assertEQ(testString_two_Interp(cond1),                              testString_two_C2(cond1));\n+\n+        Asserts.assertEQ(testSRAndNSR_Trap_Interp(false, cond1, cond2, x, y),\n+                         testSRAndNSR_Trap_C2(info.isTestC2Compiled(\"testSRAndNSR_Trap_C2\"), cond1, cond2, x, y));\n+\n+        var arr1 = testNestedObjectsArray_Interp(cond1, x, y);\n+        var arr2 = testNestedObjectsArray_C2(cond1, x, y);\n+\n+        if (arr1.length != arr2.length) Asserts.fail(\"testNestedObjectsArray result size mismatch.\");\n+        for (int i=0; i<arr1.length; i++) {\n+            if (!arr1[i].equals(arr2[i])) {\n+                Asserts.fail(\"testNestedObjectsArray objects mismatch.\");\n+            }\n+        }\n+\n+    }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testGlobalEscape(int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        AllocationMergesTests.global_escape = p;\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    int testGlobalEscape_C2(int x, int y) { return testGlobalEscape(x, y); }\n+\n+    @DontCompile\n+    int testGlobalEscape_Interp(int x, int y) { return testGlobalEscape(x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testArgEscape(int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        int val = dummy(p);\n+\n+        return val + p.x + p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    int testArgEscape_C2(int x, int y) { return testArgEscape(x, y); }\n+\n+    @DontCompile\n+    int testArgEscape_Interp(int x, int y) { return testArgEscape(x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testEscapeInCallAfterMerge(boolean cond, boolean cond2, int x, int y) {\n+        Point p = new Point(x, x);\n+\n+        if (cond) {\n+            p = new Point(y, y);\n+        }\n+\n+        if (cond2) {\n+            dummy(p);\n+        }\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    int testEscapeInCallAfterMerge_C2(boolean cond, boolean cond2, int x, int y) { return testEscapeInCallAfterMerge(cond, cond2, x, y); }\n+\n+    @DontCompile\n+    int testEscapeInCallAfterMerge_Interp(boolean cond, boolean cond2, int x, int y) { return testEscapeInCallAfterMerge(cond, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testNoEscapeWithWriteInLoop(boolean cond, boolean cond2, int x, int y) {\n+        Point p = new Point(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Point(y, x);\n+        }\n+\n+        for (int i=0; i<100; i++) {\n+            p.x += p.y + i;\n+            p.y += p.x + i;\n+        }\n+\n+        return res + p.x + p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ Merge won't be reduced because of the write to the fields\n+    int testNoEscapeWithWriteInLoop_C2(boolean cond, boolean cond2, int x, int y) { return testNoEscapeWithWriteInLoop(cond, cond2, x, y); }\n+\n+    @DontCompile\n+    int testNoEscapeWithWriteInLoop_Interp(boolean cond, boolean cond2, int x, int y) { return testNoEscapeWithWriteInLoop(cond, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testPollutedWithWrite(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Square(l);\n+        Shape obj = null;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i=1; i<132; i++) {\n+            obj.x++;\n+        }\n+\n+        return obj1.x + obj2.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ Merge won't be reduced because of the write to the field\n+    int testPollutedWithWrite_C2(boolean cond, int l) { return testPollutedWithWrite(cond, l); }\n+\n+    @DontCompile\n+    int testPollutedWithWrite_Interp(boolean cond, int l) { return testPollutedWithWrite(cond, l); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+    @ForceInline\n+    int testPollutedPolymorphic(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Circle(l);\n+        Shape obj = (cond ? obj1 : obj2);\n+        int res = 0;\n+\n+        for (int i=1; i<232; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res + obj1.x + obj2.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ Merge won't be reduced because the inputs to the Phi have different Klasses\n+    int testPollutedPolymorphic_C2(boolean cond, int l) { return testPollutedPolymorphic(cond, l); }\n+\n+    @DontCompile\n+    int testPollutedPolymorphic_Interp(boolean cond, int l) { return testPollutedPolymorphic(cond, l); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testMergedLoadAfterDirectStore(boolean cond, int x, int y) {\n+        Point p0 = new Point(x, x);\n+        Point p1 = new Point(y, y);\n+        Point p = null;\n+\n+        if (cond) {\n+            p = p0;\n+        } else {\n+            p = p1;\n+        }\n+\n+        p0.x = x * y;\n+\n+        return p.x;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ Merge won't be reduced because write to one of the inputs *after* the merge\n+    int testMergedLoadAfterDirectStore_C2(boolean cond, int x, int y) { return testMergedLoadAfterDirectStore(cond, x, y); }\n+\n+    @DontCompile\n+    int testMergedLoadAfterDirectStore_Interp(boolean cond, int x, int y) { return testMergedLoadAfterDirectStore(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testMergedAccessAfterCallWithWrite(boolean cond, int x, int y) {\n+        Point p2 = new Point(x, x);\n+        Point p = new Point(y, y);\n+\n+        p.x = p.x * y;\n+\n+        if (cond) {\n+            p = new Point(x, x);\n+        }\n+\n+        dummy(p2);\n+\n+        for (int i=3; i<324; i++) {\n+            p.x += i * x;\n+        }\n+\n+        return p.x;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"3\" })\n+    \/\/ Objects won't be scalar replaced because:\n+    \/\/  - p is written inside the loop.\n+    \/\/  - p2 is ArgEscape\n+    int testMergedAccessAfterCallWithWrite_C2(boolean cond, int x, int y) { return testMergedAccessAfterCallWithWrite(cond, x, y); }\n+\n+    @DontCompile\n+    int testMergedAccessAfterCallWithWrite_Interp(boolean cond, int x, int y) { return testMergedAccessAfterCallWithWrite(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testLoadAfterTrap(boolean cond, int x, int y) {\n+        Point p = null;\n+\n+        if (cond) {\n+            p = new Point(x, x);\n+        } else {\n+            p = new Point(y, y);\n+        }\n+\n+        dummy(x+y);\n+\n+        return p.x + p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ The allocations won't be removed because 'split_through_phi' won't split the load through the bases.\n+    int testLoadAfterTrap_C2(boolean cond, int x, int y) { return testLoadAfterTrap(cond, x, y); }\n+\n+    @DontCompile\n+    int testLoadAfterTrap_Interp(boolean cond, int x, int y) { return testLoadAfterTrap(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCondAfterMergeWithNull(boolean cond1, boolean cond2, int x, int y) {\n+        Point p = null;\n+\n+        if (cond1) {\n+            p = new Point(y, x);\n+        }\n+\n+        if (cond2 && cond1) {\n+            return p.x;\n+        } else {\n+            return 321;\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ The merge won't be simplified because the merge with NULL\n+    int testCondAfterMergeWithNull_C2(boolean cond1, boolean cond2, int x, int y) { return testCondAfterMergeWithNull(cond1, cond2, x, y); }\n+\n+    @DontCompile\n+    int testCondAfterMergeWithNull_Interp(boolean cond1, boolean cond2, int x, int y) { return testCondAfterMergeWithNull(cond1, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testLoadAfterLoopAlias(boolean cond, int x, int y) {\n+        Point a = new Point(x, y);\n+        Point b = new Point(y, x);\n+        Point c = a;\n+\n+        for (int i=10; i<232; i++) {\n+            if (i == x) {\n+                c = b;\n+            }\n+        }\n+\n+        return cond ? c.x : c.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations should be removed\n+    int testLoadAfterLoopAlias_C2(boolean cond, int x, int y) { return testLoadAfterLoopAlias(cond, x, y); }\n+\n+    @DontCompile\n+    int testLoadAfterLoopAlias_Interp(boolean cond, int x, int y) { return testLoadAfterLoopAlias(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCallTwoSide(boolean cond1, int x, int y) {\n+        Point p = dummy(x, y);\n+\n+        if (cond1) {\n+            p = dummy(y, x);\n+        }\n+\n+        return (p != null) ? p.x : 0;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.CALL, \"<=3\" })\n+    \/\/ Merge won't be reduced because both of the inputs are NSR.\n+    \/\/ There could be 3 call nodes because one if can became an unstable trap.\n+    int testCallTwoSide_C2(boolean cond1, int x, int y) { return testCallTwoSide(cond1, x, y); }\n+\n+    @DontCompile\n+    int testCallTwoSide_Interp(boolean cond1, int x, int y) { return testCallTwoSide(cond1, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testMergedAccessAfterCallNoWrite(boolean cond, int x, int y) {\n+        Point p2 = new Point(x, x);\n+        Point p = new Point(y, y);\n+        int res = 0;\n+\n+        p.x = p.x * y;\n+\n+        if (cond) {\n+            p = new Point(y, y);\n+        }\n+\n+        dummy(p2);\n+\n+        for (int i=3; i<324; i++) {\n+            res += p.x + i * x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"3\" })\n+    \/\/ p2 escapes and therefore won't be removed.\n+    \/\/ The allocations won't be removed because 'split_through_phi' won't split the load through the bases.\n+    int testMergedAccessAfterCallNoWrite_C2(boolean cond, int x, int y) { return testMergedAccessAfterCallNoWrite(cond, x, y); }\n+\n+    @DontCompile\n+    int testMergedAccessAfterCallNoWrite_Interp(boolean cond, int x, int y) { return testMergedAccessAfterCallNoWrite(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCmpMergeWithNull_Second(boolean cond, int x, int y) {\n+        Point p = null;\n+\n+        if (cond) {\n+            p = new Point(x*x, y*y);\n+        }\n+\n+        dummy(x);\n+\n+        if (p != null) {\n+            return p.x * p.y;\n+        } else {\n+            return 1984;\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ Merge won't be reduced because, among other things, one of the inputs is null.\n+    int testCmpMergeWithNull_Second_C2(boolean cond, int x, int y) { return testCmpMergeWithNull_Second(cond, x, y); }\n+\n+    @DontCompile\n+    int testCmpMergeWithNull_Second_Interp(boolean cond, int x, int y) { return testCmpMergeWithNull_Second(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testObjectIdentity(boolean cond, int x, int y) {\n+        Point o = new Point(x, y);\n+\n+        if (cond && x == 42) {\n+            o = global_escape;\n+        }\n+\n+        return o.x + o.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ The allocation won't be removed because the merge doesn't have exact type\n+    int testObjectIdentity_C2(boolean cond, int x, int y) { return testObjectIdentity(cond, x, y); }\n+\n+    @DontCompile\n+    int testObjectIdentity_Interp(boolean cond, int x, int y) { return testObjectIdentity(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSubclassesTrapping(boolean c1, boolean c2, int x, int y, int w, int z) {\n+        new A();\n+        Root s = new Home(x, y);\n+        new B();\n+\n+        if (c1) {\n+            new C();\n+            s = new Etc(\"Hello\");\n+            new D();\n+        } else {\n+            new E();\n+            s = new Usr(y, x, z);\n+            new F();\n+        }\n+\n+        dummy();\n+\n+        return s.a;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ The initial allocation assigned to 's' will always be dead.\n+    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n+    int testSubclassesTrapping_C2(boolean c1, boolean c2, int x, int y, int w, int z) { return testSubclassesTrapping(c1, c2, x, y, w, z); }\n+\n+    @DontCompile\n+    int testSubclassesTrapping_Interp(boolean c1, boolean c2, int x, int y, int w, int z) { return testSubclassesTrapping(c1, c2, x, y, w, z); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCmpMergeWithNull(boolean cond, int x, int y) {\n+        Point p = null;\n+\n+        if (cond) {\n+            p = new Point(x*x, y*y);\n+        } else if (x > y) {\n+            p = new Point(x+y, x*y);\n+        }\n+\n+        if (p != null) {\n+            return p.x * p.y;\n+        } else {\n+            return 1984;\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    int testCmpMergeWithNull_C2(boolean cond, int x, int y) { return testCmpMergeWithNull(cond, x, y); }\n+\n+    @DontCompile\n+    int testCmpMergeWithNull_Interp(boolean cond, int x, int y) { return testCmpMergeWithNull(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSubclasses(boolean c1, boolean c2, int x, int y, int w, int z) {\n+        new A();\n+        Root s = new Home(x, y);\n+        new B();\n+\n+        if (c1) {\n+            new C();\n+            s = new Etc(\"Hello\");\n+            new D();\n+        } else {\n+            new E();\n+            s = new Usr(y, x, z);\n+            new F();\n+        }\n+\n+        new G();\n+\n+        return s.a;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ The unused allocation will be removed.\n+    \/\/ The other two allocations assigned to 's' won't be removed because they have different type.\n+    int testSubclasses_C2(boolean c1, boolean c2, int x, int y, int w, int z) { return testSubclasses(c1, c2, x, y, w, z); }\n+\n+    @DontCompile\n+    int testSubclasses_Interp(boolean c1, boolean c2, int x, int y, int w, int z) { return testSubclasses(c1, c2, x, y, w, z); }\n+\n+\n+    \/\/ ------------------ Some Scalar Replacement Should Happen in The Tests Below ------------------- \/\/\n+\n+    @ForceInline\n+    int testPartialPhis(boolean cond, int l, int x, int y) {\n+        int k = l;\n+\n+        if (l == 0) {\n+            k = l + 1;\n+        } else if (l == 2) {\n+            k = l + 2;\n+        } else if (l == 3) {\n+            new Point(x, y);\n+        } else if (l == 4) {\n+            new Point(y, x);\n+        }\n+\n+        return k;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ all allocations will be dead\n+    int testPartialPhis_C2(boolean cond, int l, int x, int y) { return testPartialPhis(cond, l, x, y); }\n+\n+    @DontCompile\n+    int testPartialPhis_Interp(boolean cond, int l, int x, int y) { return testPartialPhis(cond, l, x, y); }\n+\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testPollutedNoWrite(boolean cond, int l) {\n+        Shape obj1 = new Square(l);\n+        Shape obj2 = new Square(l);\n+        Shape obj = null;\n+        int res = 0;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i=1; i<132; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res + obj1.x + obj2.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be removed. After initialization they are read-only objects.\n+    \/\/ Access to the input of the merge, after the merge, is fine.\n+    int testPollutedNoWrite_C2(boolean cond, int l) { return testPollutedNoWrite(cond, l); }\n+\n+    @DontCompile\n+    int testPollutedNoWrite_Interp(boolean cond, int l) { return testPollutedNoWrite(cond, l); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testThreeWayAliasedAlloc(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(x+1, y+1);\n+        Point p3 = new Point(x+2, y+2);\n+\n+        if (cond) {\n+            p3 = p1;\n+        } else {\n+            p3 = p2;\n+        }\n+\n+        return p3.x + p3.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Initial p3 will always be dead.\n+    \/\/ The other two allocations will be reduced and scaled\n+    int testThreeWayAliasedAlloc_C2(boolean cond, int x, int y) { return testThreeWayAliasedAlloc(cond, x, y); }\n+\n+    @DontCompile\n+    int testThreeWayAliasedAlloc_Interp(boolean cond, int x, int y) { return testThreeWayAliasedAlloc(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int TestTrapAfterMerge(boolean cond, int x, int y) {\n+        Point p = new Point(x, x);\n+\n+        if (cond) {\n+            p = new Point(y, y);\n+        }\n+\n+        for (int i=402; i<432; i+=x) {\n+            x++;\n+        }\n+\n+        return p.x + x;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n+    int TestTrapAfterMerge_C2(boolean cond, int x, int y) { return TestTrapAfterMerge(cond, x, y); }\n+\n+    @DontCompile\n+    int TestTrapAfterMerge_Interp(boolean cond, int x, int y) { return TestTrapAfterMerge(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    Point testNestedObjectsObject(boolean cond, int x, int y) {\n+        Picture p = new Picture(x, x, y);\n+\n+        if (cond) {\n+            p = new Picture(y, y, x);\n+        }\n+\n+        return p.position;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" })\n+    \/\/ The allocation of \"Picture\" will be removed and only allocations of \"Position\" will be kept\n+    Point testNestedObjectsObject_C2(boolean cond, int x, int y) { return testNestedObjectsObject(cond, x, y); }\n+\n+    @DontCompile\n+    Point testNestedObjectsObject_Interp(boolean cond, int x, int y) { return testNestedObjectsObject(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testNestedObjectsNoEscapeObject(boolean cond, int x, int y) {\n+        Picture p = new Picture(x, x, y);\n+\n+        if (cond) {\n+            p = new Picture(y, y, x);\n+        }\n+\n+        return p.position.x;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"2\" } )\n+    \/\/ The two Picture objects will be removed. The nested Point objects won't\n+    \/\/ be removed because the Phi merging them will have a DecodeN user - which\n+    \/\/ currently isn't supported.\n+    int testNestedObjectsNoEscapeObject_C2(boolean cond, int x, int y) { return testNestedObjectsNoEscapeObject(cond, x, y); }\n+\n+    @DontCompile\n+    int testNestedObjectsNoEscapeObject_Interp(boolean cond, int x, int y) { return testNestedObjectsNoEscapeObject(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    Point[] testNestedObjectsArray(boolean cond, int x, int y) {\n+        PicturePositions p = new PicturePositions(x, y, x+y);\n+\n+        if (cond) {\n+            p = new PicturePositions(x+1, y+1, x+y+1);\n+        }\n+\n+        return p.positions;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"4\" })\n+    \/\/ The two PicturePositions objects will be reduced and scaled.\n+    Point[] testNestedObjectsArray_C2(boolean cond, int x, int y) { return testNestedObjectsArray(cond, x, y); }\n+\n+    @DontCompile\n+    Point[] testNestedObjectsArray_Interp(boolean cond, int x, int y) { return testNestedObjectsArray(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testTrappingAfterMerge(boolean cond, int x, int y) {\n+        Point p = new Point(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Point(y, y);\n+        }\n+\n+        for (int i=832; i<932; i++) {\n+            res += p.x;\n+        }\n+\n+        if (x > y) {\n+            res += new Point(p.x, p.y).x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The allocation inside the last if will be removed because it's not part of a merge\n+    \/\/ The other two allocations will be reduced and removed\n+    int testTrappingAfterMerge_C2(boolean cond, int x, int y) { return testTrappingAfterMerge(cond, x, y); }\n+\n+    @DontCompile\n+    int testTrappingAfterMerge_Interp(boolean cond, int x, int y) { return testTrappingAfterMerge(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSimpleAliasedAlloc(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(y, x);\n+        Point p = p1;\n+\n+        if (cond) {\n+            p = p2;\n+        }\n+\n+        return p.x * p.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both merges will be reduced and removed\n+    int testSimpleAliasedAlloc_C2(boolean cond, int x, int y) { return testSimpleAliasedAlloc(cond, x, y); }\n+\n+    @DontCompile\n+    int testSimpleAliasedAlloc_Interp(boolean cond, int x, int y) { return testSimpleAliasedAlloc(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSimpleDoubleMerge(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(x+1, y+1);\n+\n+        if (cond) {\n+            p1 = new Point(y, x);\n+            p2 = new Point(y+1, x+1);\n+        }\n+\n+        return p1.x + p2.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both merges will be reduced and removed\n+    int testSimpleDoubleMerge_C2(boolean cond, int x, int y) { return testSimpleDoubleMerge(cond, x, y); }\n+\n+    @DontCompile\n+    int testSimpleDoubleMerge_Interp(boolean cond, int x, int y) { return testSimpleDoubleMerge(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testConsecutiveSimpleMerge(boolean cond1, boolean cond2, int x, int y) {\n+        Point p0 = new Point(x, x);\n+        Point p1 = new Point(x, y);\n+        Point pA = null;\n+\n+        Point p2 = new Point(y, x);\n+        Point p3 = new Point(y, y);\n+        Point pB = null;\n+\n+        if (cond1) {\n+            pA = p0;\n+        } else {\n+            pA = p1;\n+        }\n+\n+        if (cond2) {\n+            pB = p2;\n+        } else {\n+            pB = p3;\n+        }\n+\n+        return pA.x * pA.y + pB.x * pB.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ All allocations will be removed.\n+    int testConsecutiveSimpleMerge_C2(boolean cond1, boolean cond2, int x, int y) { return testConsecutiveSimpleMerge(cond1, cond2, x, y); }\n+\n+    @DontCompile\n+    int testConsecutiveSimpleMerge_Interp(boolean cond1, boolean cond2, int x, int y) { return testConsecutiveSimpleMerge(cond1, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testDoubleIfElseMerge(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(x+1, y+1);\n+\n+        if (cond) {\n+            p1 = new Point(y, x);\n+            p2 = new Point(y, x);\n+        } else {\n+            p1 = new Point(x, y);\n+            p2 = new Point(x+1, y+1);\n+        }\n+\n+        return p1.x * p2.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The initial allocation is always dead. The other\n+    \/\/ two will be reduced and scaled.\n+    int testDoubleIfElseMerge_C2(boolean cond, int x, int y) { return testDoubleIfElseMerge(cond, x, y); }\n+\n+    @DontCompile\n+    int testDoubleIfElseMerge_Interp(boolean cond, int x, int y) { return testDoubleIfElseMerge(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testNoEscapeWithLoadInLoop(boolean cond, int x, int y) {\n+        Point p = new Point(x, y);\n+        int res = 0;\n+\n+        if (cond) {\n+            p = new Point(y, x);\n+        }\n+\n+        for (int i=3342; i<4234; i++) {\n+            res += p.x + p.y + i;\n+        }\n+\n+        return res + p.x + p.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and scaled.\n+    int testNoEscapeWithLoadInLoop_C2(boolean cond, int x, int y) { return testNoEscapeWithLoadInLoop(cond, x, y); }\n+\n+    @DontCompile\n+    int testNoEscapeWithLoadInLoop_Interp(boolean cond, int x, int y) { return testNoEscapeWithLoadInLoop(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCmpAfterMerge(boolean cond, boolean cond2, int x, int y) {\n+        Point a = new Point(x, y);\n+        Point b = new Point(y, x);\n+        Point c = null;\n+\n+        if (x+2 >= y-5) {\n+            c = a;\n+        } else {\n+            c = b;\n+        }\n+\n+        return cond2 ? c.x : c.y;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and scaled\n+    int testCmpAfterMerge_C2(boolean cond, boolean cond2, int x, int y) { return testCmpAfterMerge(cond, cond2, x, y); }\n+\n+    @DontCompile\n+    int testCmpAfterMerge_Interp(boolean cond, boolean cond2, int x, int y) { return testCmpAfterMerge(cond, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCondAfterMergeWithAllocate(boolean cond1, boolean cond2, int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        if (cond1) {\n+            p = new Point(y, x);\n+        }\n+\n+        if (cond2 && cond1) {\n+            return p.x;\n+        } else {\n+            return 321;\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n+    int testCondAfterMergeWithAllocate_C2(boolean cond1, boolean cond2, int x, int y) { return testCondAfterMergeWithAllocate(cond1, cond2, x, y); }\n+\n+    @DontCompile\n+    int testCondAfterMergeWithAllocate_Interp(boolean cond1, boolean cond2, int x, int y) { return testCondAfterMergeWithAllocate(cond1, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testCondLoadAfterMerge(boolean cond1, boolean cond2, int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        if (cond1) {\n+            p = new Point(y, x);\n+        }\n+\n+        if (cond1 == false && cond2 == false) {\n+            return p.x + 1;\n+        } else if (cond1 == false && cond2 == true) {\n+            return p.x + 30;\n+        } else if (cond1 == true && cond2 == false) {\n+            return p.x + 40;\n+        } else if (cond1 == true && cond2 == true) {\n+            return p.x + 50;\n+        } else {\n+            return -1;\n+        }\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be eliminated.\n+    int testCondLoadAfterMerge_C2(boolean cond1, boolean cond2, int x, int y) { return testCondLoadAfterMerge(cond1, cond2, x, y); }\n+\n+    @DontCompile\n+    int testCondLoadAfterMerge_Interp(boolean cond1, boolean cond2, int x, int y) { return testCondLoadAfterMerge(cond1, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testIfElseInLoop() {\n+        int res = 0;\n+\n+        for (int i=1; i<1000; i++) {\n+            Point obj = new Point(i, i);\n+\n+            if (i % 2 == 1) {\n+                obj = new Point(i, i+1);\n+            } else {\n+                obj = new Point(i-1, i);\n+            }\n+\n+            res += obj.x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ The initial allocation is always dead. The other\n+    \/\/ two will be reduced and scaled.\n+    int testIfElseInLoop_C2() { return testIfElseInLoop(); }\n+\n+    @DontCompile\n+    int testIfElseInLoop_Interp() { return testIfElseInLoop(); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testLoadInCondAfterMerge(boolean cond, int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        if (cond) {\n+            p = new Point(y, x);\n+        }\n+\n+        if (p.x == 10) {\n+            if (p.y == 10) {\n+                return dummy(10);\n+            } else {\n+                return dummy(20);\n+            }\n+        } else if (p.x == 20) {\n+            if (p.y == 20) {\n+                return dummy(30);\n+            } else {\n+                return dummy(40);\n+            }\n+        }\n+\n+        return 1984;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and removed.\n+    int testLoadInCondAfterMerge_C2(boolean cond, int x, int y) { return testLoadInCondAfterMerge(cond, x, y); }\n+\n+    @DontCompile\n+    int testLoadInCondAfterMerge_Interp(boolean cond, int x, int y) { return testLoadInCondAfterMerge(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testLoadInLoop(boolean cond, int x, int y) {\n+        Point obj1 = new Point(x, y);\n+        Point obj2 = new Point(y, x);\n+        Point obj = null;\n+        int res = 0;\n+\n+        if (cond) {\n+            obj = obj1;\n+        } else {\n+            obj = obj2;\n+        }\n+\n+        for (int i = 0; i < 532; i++) {\n+            res += obj.x;\n+        }\n+\n+        return res;\n+    }\n+\n+    @Test\n+    @IR(failOn = { IRNode.ALLOC })\n+    \/\/ Both allocations will be reduced and removed.\n+    int testLoadInLoop_C2(boolean cond, int x, int y) { return testLoadInLoop(cond, x, y); }\n+\n+    @DontCompile\n+    int testLoadInLoop_Interp(boolean cond, int x, int y) { return testLoadInLoop(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testMergesAndMixedEscape(boolean cond, int x, int y) {\n+        Point p1 = new Point(x, y);\n+        Point p2 = new Point(x, y);\n+        int val  = 0;\n+\n+        if (cond) {\n+            p1 = new Point(x+1, y+1);\n+            val = dummy(p2);\n+        }\n+\n+        return val + p1.x + p2.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"1\" })\n+    \/\/ p2 escapes and will remain. The other two allocations will be reduced and scaled.\n+    int testMergesAndMixedEscape_C2(boolean cond, int x, int y) { return testMergesAndMixedEscape(cond, x, y); }\n+\n+    @DontCompile\n+    int testMergesAndMixedEscape_Interp(boolean cond, int x, int y) { return testMergesAndMixedEscape(cond, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSRAndNSR_NoTrap(boolean cond1, int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        if (cond1) {\n+            p = new Point(x+1, y+1);\n+            global_escape = p;\n+        }\n+\n+        return p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"<=1\" })\n+    int testSRAndNSR_NoTrap_C2(boolean cond1, int x, int y) { return testSRAndNSR_NoTrap(cond1, x, y); }\n+\n+    @DontCompile\n+    int testSRAndNSR_NoTrap_Interp(boolean cond1, int x, int y) { return testSRAndNSR_NoTrap(cond1, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    int testSRAndNSR_Trap(boolean is_c2, boolean cond1, boolean cond2, int x, int y) {\n+        Point p = new Point(x, y);\n+\n+        if (cond1) {\n+            p = new Point(x+1, y+1);\n+            global_escape = p;\n+        }\n+\n+        if (is_c2) {\n+            \/\/ This will show up to C2 as a trap.\n+            dummy_defaults();\n+        }\n+\n+        return p.y;\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"<=1\" })\n+    int testSRAndNSR_Trap_C2(boolean is_c2, boolean cond1, boolean cond2, int x, int y) { return testSRAndNSR_Trap(is_c2, cond1, cond2, x, y); }\n+\n+    @DontCompile\n+    int testSRAndNSR_Trap_Interp(boolean is_c2, boolean cond1, boolean cond2, int x, int y) { return testSRAndNSR_Trap(is_c2, cond1, cond2, x, y); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    char testString_one(boolean cond1) {\n+        String p = new String(\"Java\");\n+\n+        if (cond1) {\n+            p = new String(\"HotSpot\");\n+        }\n+\n+        return p.charAt(0);\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"0\" })\n+    char testString_one_C2(boolean cond1) { return testString_one(cond1); }\n+\n+    @DontCompile\n+    char testString_one_Interp(boolean cond1) { return testString_one(cond1); }\n+\n+    \/\/ -------------------------------------------------------------------------\n+\n+    @ForceInline\n+    char testString_two(boolean cond1) {\n+        String p = new String(\"HotSpot\");\n+\n+        if (cond1) {\n+            p = dummy(\"String\");\n+            if (p == null) return 'J';\n+        }\n+\n+        return p.charAt(0);\n+    }\n+\n+    @Test\n+    @IR(counts = { IRNode.ALLOC, \"0\" })\n+    char testString_two_C2(boolean cond1) { return testString_two(cond1); }\n+\n+    @DontCompile\n+    char testString_two_Interp(boolean cond1) { return testString_two(cond1); }\n+\n+    \/\/ ------------------ Utility for Testing ------------------- \/\/\n+\n+    @DontCompile\n+    static void dummy() {\n+    }\n+\n+    @DontCompile\n+    static int dummy(Point p) {\n+        return p.x * p.y;\n+    }\n+\n+    @DontCompile\n+    static int dummy(int x) {\n+        return x;\n+    }\n+\n+    @DontCompile\n+    static Point dummy(int x, int y) {\n+        return new Point(x, y);\n+    }\n+\n+    @DontCompile\n+    static String dummy(String str) {\n+        return str;\n+    }\n+\n+    @DontCompile\n+    static ADefaults dummy_defaults() {\n+        return new ADefaults();\n+    }\n+\n+    static class Point {\n+        int x, y;\n+        Point(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (o == this) return true;\n+            if (!(o instanceof Point)) return false;\n+            Point p = (Point) o;\n+            return (p.x == x) && (p.y == y);\n+        }\n+    }\n+\n+    class Shape {\n+        int x, y, l;\n+        Shape(int x, int y) {\n+            this.x = x;\n+            this.y = y;\n+        }\n+    }\n+\n+    class Square extends Shape {\n+        Square(int l) {\n+            super(0, 0);\n+            this.l = l;\n+        }\n+    }\n+\n+    class Circle extends Shape {\n+        Circle(int l) {\n+            super(0, 0);\n+            this.l = l;\n+        }\n+    }\n+\n+    static class ADefaults {\n+        static int ble;\n+        int i;\n+        @DontCompile\n+        ADefaults(int i) { this.i = i; }\n+        @DontCompile\n+        ADefaults() { }\n+    }\n+\n+    static class Picture {\n+        public int id;\n+        public Point position;\n+\n+        public Picture(int id, int x, int y) {\n+            this.id = id;\n+            this.position = new Point(x, y);\n+        }\n+    }\n+\n+    static class PicturePositions {\n+        public int id;\n+        public Point[] positions;\n+\n+        public PicturePositions(int id, int x, int y) {\n+            this.id = id;\n+            this.positions = new Point[] { new Point(x, y), new Point(y, x) };\n+        }\n+    }\n+\n+    class Root {\n+        public int a;\n+        public int b;\n+        public int c;\n+        public int d;\n+        public int e;\n+\n+        public Root(int a, int b, int c, int d, int e) {\n+            this.a = a;\n+            this.b = b;\n+            this.c = c;\n+            this.d = d;\n+            this.e = e;\n+        }\n+    }\n+\n+    class Usr extends Root {\n+        public float flt;\n+\n+        public Usr(float a, float b, float c) {\n+            super((int)a, (int)b, (int)c, 0, 0);\n+            this.flt = a;\n+        }\n+    }\n+\n+    class Home extends Root {\n+        public double[] arr;\n+\n+        public Home(double a, double b) {\n+            super((int)a, (int)b, 0, 0, 0);\n+            this.arr = new double[] {a, b};\n+        }\n+\n+    }\n+\n+    class Tmp extends Root {\n+        public String s;\n+\n+        public Tmp(String s) {\n+            super((int)s.length(), 0, 0, 0, 0);\n+            this.s = s;\n+        }\n+    }\n+\n+    class Etc extends Root {\n+        public String a;\n+\n+        public Etc(String s) {\n+            super((int)s.length(), 0, 0, 0, 0);\n+            this.a = s;\n+        }\n+    }\n+\n+    class A { }\n+    class B { }\n+    class C { }\n+    class D { }\n+    class E { }\n+    class F { }\n+    class G { }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/scalarReplacement\/AllocationMergesTests.java","additions":1412,"deletions":0,"binary":false,"changes":1412,"status":"added"}]}