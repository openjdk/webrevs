{"files":[{"patch":"@@ -4517,1 +4517,1 @@\n-instruct ReplH_imm(vec dst, immH con, rRegI rtmp) %{\n+instruct ReplHF_imm(vec dst, immH con, rRegI rtmp) %{\n@@ -4520,1 +4520,1 @@\n-  format %{ \"replicateH $dst, $con \\t! using $rtmp as TEMP\" %}\n+  format %{ \"replicateHF $dst, $con \\t! using $rtmp as TEMP\" %}\n@@ -4531,1 +4531,1 @@\n-instruct ReplH_short_reg(vec dst, rRegI src) %{\n+instruct ReplHF_short_reg(vec dst, rRegI src) %{\n@@ -4534,1 +4534,1 @@\n-  format %{ \"replicateH $dst, $src\" %}\n+  format %{ \"replicateHF $dst, $src\" %}\n@@ -4542,1 +4542,1 @@\n-instruct ReplH_reg(vec dst, regF src, rRegI rtmp) %{\n+instruct ReplHF_reg(vec dst, regF src, rRegI rtmp) %{\n@@ -4546,1 +4546,1 @@\n-  format %{ \"replicateH $dst, $src \\t! using $rtmp as TEMP\" %}\n+  format %{ \"replicateHF $dst, $src \\t! using $rtmp as TEMP\" %}\n@@ -10900,1 +10900,1 @@\n-instruct reinterpretS2H(regF dst, rRegI src)\n+instruct reinterpretS2HF(regF dst, rRegI src)\n@@ -10920,1 +10920,1 @@\n-instruct reinterpretH2S(rRegI dst, regF src)\n+instruct reinterpretHF2S(rRegI dst, regF src)\n@@ -10930,1 +10930,1 @@\n-instruct scalar_sqrt_fp16_reg(regF dst, regF src)\n+instruct scalar_sqrt_HF_reg(regF dst, regF src)\n@@ -10933,1 +10933,1 @@\n-  format %{ \"vsqrtsh $dst, $src\" %}\n+  format %{ \"scalar_sqrt_fp16 $dst, $src\" %}\n@@ -10940,1 +10940,1 @@\n-instruct scalar_binOps_fp16_reg(regF dst, regF src1, regF src2)\n+instruct scalar_binOps_HF_reg(regF dst, regF src1, regF src2)\n@@ -10948,1 +10948,1 @@\n-  format %{ \"efp16sh $dst, $src1, $src2\" %}\n+  format %{ \"scalar_binop_fp16 $dst, $src1, $src2\" %}\n@@ -10956,1 +10956,1 @@\n-instruct scalar_fma_fp16_reg(regF dst, regF src1, regF src2)\n+instruct scalar_fma_HF_reg(regF dst, regF src1, regF src2)\n@@ -10960,1 +10960,1 @@\n-  format %{ \"evfmash $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  format %{ \"scalar_fma_fp16 $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n@@ -10967,1 +10967,1 @@\n-instruct vector_sqrt_fp16_reg(vec dst, vec src)\n+instruct vector_sqrt_HF_reg(vec dst, vec src)\n@@ -10970,1 +10970,1 @@\n-  format %{ \"evsqrtph_reg $dst, $src\" %}\n+  format %{ \"vector_sqrt_fp16 $dst, $src\" %}\n@@ -10978,1 +10978,1 @@\n-instruct vector_sqrt_fp16_mem(vec dst, memory src)\n+instruct vector_sqrt_HF_mem(vec dst, memory src)\n@@ -10981,1 +10981,1 @@\n-  format %{ \"evsqrtph_mem $dst, $src\" %}\n+  format %{ \"vector_sqrt_fp16_mem $dst, $src\" %}\n@@ -10989,1 +10989,1 @@\n-instruct vector_binOps_fp16_reg(vec dst, vec src1, vec src2)\n+instruct vector_binOps_HF_reg(vec dst, vec src1, vec src2)\n@@ -10997,1 +10997,1 @@\n-  format %{ \"evbinopfp16_reg $dst, $src1, $src2\" %}\n+  format %{ \"vector_binop_fp16 $dst, $src1, $src2\" %}\n@@ -11006,1 +11006,1 @@\n-instruct vector_binOps_fp16_mem(vec dst, vec src1, memory src2)\n+instruct vector_binOps_HF_mem(vec dst, vec src1, memory src2)\n@@ -11014,1 +11014,1 @@\n-  format %{ \"evbinopfp16_mem $dst, $src1, $src2\" %}\n+  format %{ \"vector_binop_fp16_mem $dst, $src1, $src2\" %}\n@@ -11024,1 +11024,1 @@\n-instruct vector_fma_fp16_reg(vec dst, vec src1, vec src2)\n+instruct vector_fma_HF_reg(vec dst, vec src1, vec src2)\n@@ -11028,1 +11028,1 @@\n-  format %{ \"evfmaph_reg $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  format %{ \"vector_fma_fp16 $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n@@ -11036,1 +11036,1 @@\n-instruct vector_fma_fp16_mem(vec dst, memory src1, vec src2)\n+instruct vector_fma_HF_mem(vec dst, memory src1, vec src2)\n@@ -11040,1 +11040,1 @@\n-  format %{ \"evfmaph_mem $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n+  format %{ \"vector_fma_fp16_mem $dst, $src1, $src2\\t# $dst = $dst * $src1 + $src2 fma packedH\" %}\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":26,"deletions":26,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -713,1 +713,1 @@\n-const Type *AddHFNode::add_of_identity(const Type *t1, const Type *t2) const {\n+const Type *AddHFNode::add_of_identity(const Type* t1, const Type* t2) const {\n@@ -717,1 +717,0 @@\n-\/\/------------------------------add_ring---------------------------------------\n@@ -721,1 +720,1 @@\n-const Type *AddHFNode::add_ring(const Type *t0, const Type *t1) const {\n+const Type* AddHFNode::add_ring(const Type* t0, const Type* t1) const {\n@@ -1624,1 +1623,3 @@\n-  \/\/ handle min of 0.0, -0.0 case.\n+  \/\/ As per IEEE 754 specification, floating point comparison consider +ve and -ve\n+  \/\/ zeros as equals. Thus, performing signed integral comparison for max value\n+  \/\/ detection.\n@@ -1649,1 +1650,3 @@\n-  \/\/ handle min of 0.0, -0.0 case.\n+  \/\/ As per IEEE 754 specification, floating point comparison consider +ve and -ve\n+  \/\/ zeros as equals. Thus, performing signed integral comparison for min value\n+  \/\/ detection.\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -169,1 +169,1 @@\n-  AddHFNode(Node *in1, Node *in2) : AddNode(in1,in2) {}\n+  AddHFNode(Node* in1, Node* in2) : AddNode(in1,in2) {}\n@@ -171,1 +171,1 @@\n-  virtual const Type* add_of_identity(const Type *t1, const Type *t2) const;\n+  virtual const Type* add_of_identity(const Type* t1, const Type* t2) const;\n","filename":"src\/hotspot\/share\/opto\/addnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -47,0 +47,3 @@\n+  if (t->isa_half_float_constant()) {\n+    return new ConHNode( t->is_half_float_constant() );\n+  }\n@@ -49,1 +52,0 @@\n-  case T_SHORT:       return new ConHNode( t->is_half_float_constant() );\n","filename":"src\/hotspot\/share\/opto\/connode.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -122,1 +122,1 @@\n-  ConHNode( const TypeH *t ) : ConNode(t) {}\n+  ConHNode(const TypeH* t) : ConNode(t) {}\n@@ -127,1 +127,1 @@\n-    return new ConHNode( TypeH::make(con) );\n+    return new ConHNode(TypeH::make(con));\n@@ -129,1 +129,0 @@\n-\n","filename":"src\/hotspot\/share\/opto\/connode.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -256,2 +256,16 @@\n-  \/\/ Optimize pattern - ConvHF2F (FP32BinOp) ConvF2HF ==> ReinterpretS2HF (FP16BinOp) ReinterpretHF2S.\n-  if (Float16NodeFactory::is_binary_oper(in(1)->Opcode()) &&\n+  \/\/ Float16 instance encapsulates a short field holding IEEE 754\n+  \/\/ binary16 value. On unboxing, this short field is loaded into a\n+  \/\/ GPR register while FP operation operates over floating point\n+  \/\/ registers. ConvHF2F converts incoming short value to a FP32 value\n+  \/\/ to perform operation at FP32 granularity. However, if target\n+  \/\/ support FP16 ISA we can save this redundant up casting and\n+  \/\/ optimize the graph pallet using following transformation.\n+  \/\/\n+  \/\/ ConvF2HF(FP32BinOp(ConvHF2F(x), ConvHF2F(y))) =>\n+  \/\/        ReinterpretHF2S(FP16BinOp(ReinterpretS2HF(x), ReinterpretS2HF(y)))\n+  \/\/\n+  \/\/ Please note we need to inject appropriate reinterpretation\n+  \/\/ IR to move the values b\/w GPR and floating point register\n+  \/\/ before and after FP16 operation.\n+\n+  if (Float16NodeFactory::is_float32_binary_oper(in(1)->Opcode()) &&\n@@ -948,1 +962,1 @@\n-bool Float16NodeFactory::is_binary_oper(int opc) {\n+bool Float16NodeFactory::is_float32_binary_oper(int opc) {\n","filename":"src\/hotspot\/share\/opto\/convertnode.cpp","additions":17,"deletions":3,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -234,1 +234,1 @@\n-  ReinterpretHF2SNode( Node *in1 ) : Node(0,in1) {}\n+  ReinterpretHF2SNode(Node* in1) : Node(0,in1) {}\n@@ -299,1 +299,1 @@\n-  static bool is_binary_oper(int opc);\n+  static bool is_float32_binary_oper(int opc);\n","filename":"src\/hotspot\/share\/opto\/convertnode.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -758,2 +758,2 @@\n-  if(t1 == Type::TOP) return Type::TOP;\n-  if(t2 == Type::TOP) return Type::TOP;\n+  if(t1 == Type::TOP) { return Type::TOP; }\n+  if(t2 == Type::TOP) { return Type::TOP; }\n@@ -764,1 +764,1 @@\n-     (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM))\n+     (t1 == Type::BOTTOM) || (t2 == Type::BOTTOM)) {\n@@ -766,0 +766,1 @@\n+  }\n@@ -775,1 +776,1 @@\n-  if(t2 == TypeH::ONE)\n+  if(t2 == TypeH::ONE) {\n@@ -777,0 +778,1 @@\n+  }\n@@ -781,1 +783,2 @@\n-     t2->getf() != 0.0) \/\/ could be negative zero\n+     t2->getf() != 0.0)  {\n+    \/\/ could be negative zero\n@@ -783,0 +786,1 @@\n+  }\n@@ -788,1 +792,1 @@\n-  if(t1 == TypeH::ZERO && !g_isnan(t2->getf()) && t2->getf() != 0.0)\n+  if(t1 == TypeH::ZERO && !g_isnan(t2->getf()) && t2->getf() != 0.0) {\n@@ -790,0 +794,1 @@\n+  }\n@@ -797,1 +802,1 @@\n-\/\/ If the divisor is 1, we are an identity on the dividend.\n+\/\/ IF the divisor is 1, we are an identity on the dividend.\n@@ -804,2 +809,2 @@\n-Node *DivHFNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  if (in(0) && remove_dead_region(phase, can_reshape))  return this;\n+Node* DivHFNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (in(0) != nullptr && remove_dead_region(phase, can_reshape))  return this;\n@@ -807,1 +812,1 @@\n-  if(in(0) && in(0)->is_top())  return nullptr;\n+  if (in(0) != nullptr && in(0)->is_top())  { return nullptr; }\n@@ -810,1 +815,1 @@\n-  if(t2 == TypeH::ONE)         \/\/ Identity?\n+  if (t2 == TypeH::ONE) {      \/\/ Identity?\n@@ -812,1 +817,1 @@\n-\n+  }\n@@ -814,2 +819,2 @@\n-  if(!tf) return nullptr;\n-  if(tf->base() != Type::HalfFloatCon) return nullptr;\n+  if(tf == nullptr) { return nullptr; }\n+  if(tf->base() != Type::HalfFloatCon) { return nullptr; }\n@@ -818,1 +823,1 @@\n-  if(tf->is_nan() || !tf->is_finite()) return nullptr;\n+  if(tf->is_nan() || !tf->is_finite()) { return nullptr; }\n@@ -824,2 +829,6 @@\n-  \/\/ Only for special case of dividing by a power of 2\n-  if(frexp((double)f, &exp) != 0.5) return nullptr;\n+  \/\/ Consider the following geometric progression series of POT(power of two) numbers.\n+  \/\/ 0.5 x 2^0 = 0.5, 0.5 x 2^1 = 1.0, 0.5 x 2^2 = 2.0, 0.5 x 2^3 = 4.0 ... 0.5 x 2^n,\n+  \/\/ In all the above cases, normalized mantissa returned by frexp routine will\n+  \/\/ be exactly equal to 0.5 while exponent will be 0,1,2,3...n\n+  \/\/ Perform division to multiplication transform only if divisor is a POT value.\n+  if(frexp((double)f, &exp) != 0.5) { return nullptr; }\n@@ -828,3 +837,10 @@\n-  if(exp < -14 || exp > 15) return nullptr;\n-\n-  \/\/ Compute the reciprocal\n+  if(exp < -14 || exp > 15) { return nullptr; }\n+\n+  \/\/ Since divisor is a POT number, hence its reciprocal will never\n+  \/\/ overflow 11 bits precision range of Float16\n+  \/\/ value if exponent returned by frexp routine strictly lie\n+  \/\/ within the exponent range of normal min(0x1.0P-14) and\n+  \/\/ normal max(0x1.ffcP+15) values.\n+  \/\/ Thus we can safely compute the reciprocal of divisor without\n+  \/\/ any concerns about the precision loss and transform the division\n+  \/\/ into a multiplication operation.\n","filename":"src\/hotspot\/share\/opto\/divnode.cpp","additions":36,"deletions":20,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -559,3 +559,3 @@\n-const Type *MulHFNode::mul_ring(const Type *t0, const Type *t1) const {\n-  if( t0 == Type::HALF_FLOAT || t1 == Type::HALF_FLOAT ) return Type::HALF_FLOAT;\n-  return TypeH::make( t0->getf() * t1->getf() );\n+const Type* MulHFNode::mul_ring(const Type* t0, const Type* t1) const {\n+  if(t0 == Type::HALF_FLOAT || t1 == Type::HALF_FLOAT) return Type::HALF_FLOAT;\n+  return TypeH::make(t0->getf() * t1->getf());\n@@ -1928,9 +1928,9 @@\n-  const Type *t1 = phase->type(in(1));\n-  if (t1 == Type::TOP) return Type::TOP;\n-  if (t1->base() != Type::HalfFloatCon) return Type::HALF_FLOAT;\n-  const Type *t2 = phase->type(in(2));\n-  if (t2 == Type::TOP) return Type::TOP;\n-  if (t2->base() != Type::HalfFloatCon) return Type::HALF_FLOAT;\n-  const Type *t3 = phase->type(in(3));\n-  if (t3 == Type::TOP) return Type::TOP;\n-  if (t3->base() != Type::HalfFloatCon) return Type::HALF_FLOAT;\n+  const Type* t1 = phase->type(in(1));\n+  if (t1 == Type::TOP) { return Type::TOP; }\n+  if (t1->base() != Type::HalfFloatCon) { return Type::HALF_FLOAT; }\n+  const Type* t2 = phase->type(in(2));\n+  if (t2 == Type::TOP) { return Type::TOP; }\n+  if (t2->base() != Type::HalfFloatCon) { return Type::HALF_FLOAT; }\n+  const Type* t3 = phase->type(in(3));\n+  if (t3 == Type::TOP) { return Type::TOP; }\n+  if (t3->base() != Type::HalfFloatCon) { return Type::HALF_FLOAT; }\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -153,3 +153,3 @@\n-  virtual const Type *mul_ring( const Type *, const Type * ) const;\n-  const Type *mul_id() const { return TypeH::ONE; }\n-  const Type *add_id() const { return TypeH::ZERO; }\n+  virtual const Type* mul_ring(const Type*, const Type*) const;\n+  const Type* mul_id() const { return TypeH::ONE; }\n+  const Type* add_id() const { return TypeH::ZERO; }\n@@ -160,1 +160,1 @@\n-  const Type *bottom_type() const { return Type::HALF_FLOAT; }\n+  const Type* bottom_type() const { return Type::HALF_FLOAT; }\n","filename":"src\/hotspot\/share\/opto\/mulnode.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1969,3 +1969,3 @@\n-  const Type *t1 = phase->type( in(1) );\n-  if( t1 == Type::TOP ) return Type::TOP;\n-  if( t1->base() != Type::HalfFloatCon ) return Type::HALF_FLOAT;\n+  const Type* t1 = phase->type(in(1));\n+  if (t1 == Type::TOP) { return Type::TOP; }\n+  if (t1->base() != Type::HalfFloatCon) { return Type::HALF_FLOAT; }\n@@ -1973,2 +1973,2 @@\n-  if( f < 0.0f ) return Type::HALF_FLOAT;\n-  return TypeH::make( (float)sqrt( (double)f ) );\n+  if (f < 0.0f) return Type::HALF_FLOAT;\n+  return TypeH::make((float)sqrt((double)f));\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -139,3 +139,3 @@\n-  virtual const Type *sub( const Type *, const Type * ) const;\n-  const Type   *add_id() const { return TypeH::ZERO; }\n-  const Type   *bottom_type() const { return Type::HALF_FLOAT; }\n+  virtual const Type* sub(const Type*, const Type*) const;\n+  const Type* add_id() const { return TypeH::ZERO; }\n+  const Type* bottom_type() const { return Type::HALF_FLOAT; }\n@@ -547,1 +547,1 @@\n-  SqrtHFNode(Compile* C, Node *c, Node *in1) : Node(c, in1) {\n+  SqrtHFNode(Compile* C, Node* c, Node* in1) : Node(c, in1) {\n@@ -552,1 +552,1 @@\n-  const Type *bottom_type() const { return Type::HALF_FLOAT; }\n+  const Type* bottom_type() const { return Type::HALF_FLOAT; }\n","filename":"src\/hotspot\/share\/opto\/subnode.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1487,2 +1487,2 @@\n-  case HalfFloatCon:                \/\/ Float-constant vs Float-constant?\n-    if( jint_cast(_f) != jint_cast(t->getf()) )         \/\/ unequal constants?\n+  case HalfFloatCon:            \/\/ Float-constant vs Float-constant?\n+    if(jint_cast(_f) != jint_cast(t->getf())) {         \/\/ unequal constants?\n@@ -1492,1 +1492,1 @@\n-                                \/\/ Equal constants\n+    }                           \/\/ Equal constants\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n- * @requires vm.compiler2.enabled\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/MulHFNodeIdealizationTests.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}