{"files":[{"patch":"@@ -509,1 +509,1 @@\n-\/\/ convenience methods for splitting 8-way of 4-way vector register\n+\/\/ convenience methods for splitting 8-way or 4-way vector register\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5012,1 +5012,1 @@\n-    \/\/ schedule 2 streams of i<nstructions across the vector sequences\n+    \/\/ schedule 2 streams of instructions across the vector sequences\n@@ -5166,1 +5166,1 @@\n-    \/\/ array elements that need to be multiplied by the zetas be in one\n+    \/\/ array elements that need to be multiplied by the zetas go into one\n@@ -5168,3 +5168,9 @@\n-    \/\/ be multiplied, in another set. We can do 32 Montgomery multiplications\n-    \/\/ in parallel, using 12 vector registers interleaving the steps of 4\n-    \/\/ identical computations, each done on 8 16-bit values per register.\n+    \/\/ be multiplied, go into another set.\n+    \/\/ We can do 32 Montgomery multiplications in parallel, using 12 vector\n+    \/\/ registers interleaving the steps of 4 identical computations,\n+    \/\/ each done on 8 16-bit values per register.\n+\n+    \/\/ At levels 0-3 the coefficients multiplied by or added\/subtracted\n+    \/\/ to the zetas occur in discrete blocks whose size is some multiple\n+    \/\/ of 32.\n+\n@@ -5277,0 +5283,3 @@\n+    \/\/ At level 4 coefficients occur in 8 discrete blocks of size 16\n+    \/\/ so they are loaded using employing an ldr at 8 distinct offsets.\n+\n@@ -5299,0 +5308,3 @@\n+    \/\/ At level 5 related coefficients occur in discrete blocks of size 8 so\n+    \/\/ need to be loaded interleaved using an ld2 operation with arrangement 2D.\n+\n@@ -5320,0 +5332,3 @@\n+    \/\/ At level 6 related coefficients occur in discrete blocks of size 4 so\n+    \/\/ need to be loaded interleaved using an ld2 operation with arrangement 4S.\n+\n@@ -5376,0 +5391,3 @@\n+    \/\/ At level 0 related coefficients occur in discrete blocks of size 4 so\n+    \/\/ need to be loaded interleaved using an ld2 operation with arrangement 4S.\n+\n@@ -5400,0 +5418,3 @@\n+    \/\/ At level 1 related coefficients occur in discrete blocks of size 8 so\n+    \/\/ need to be loaded interleaved using an ld2 operation with arrangement 2D.\n+\n@@ -5423,0 +5444,3 @@\n+    \/\/ At level 2 coefficients occur in 8 discrete blocks of size 16\n+    \/\/ so they are loaded using employing an ldr at 8 distinct offsets.\n+\n@@ -5465,0 +5489,3 @@\n+    \/\/ From level 3 upwards coefficients occur in discrete blocks whose size is\n+    \/\/ some multiple of 32 so can be loaded using ldpq and suitable indexes.\n+\n@@ -5487,0 +5514,1 @@\n+\n@@ -5509,0 +5537,1 @@\n+\n@@ -5550,0 +5579,1 @@\n+\n@@ -5591,0 +5621,1 @@\n+    \/\/ now tmpAddr contains coeffs + 128 because store64shorts adjusted it so\n@@ -5596,0 +5627,1 @@\n+    \/\/ now tmpAddr contains coeffs + 256\n@@ -5601,0 +5633,1 @@\n+    \/\/ now tmpAddr contains coeffs + 384\n@@ -5640,1 +5673,1 @@\n-    VSeq<2> vq(30);          \/\/ pair of constants for montmul\n+    VSeq<2> vq(30);          \/\/ pair of constants for montmul: q, qinv\n@@ -5642,1 +5675,1 @@\n-    VSeq<4> vc(27, 0);       \/\/ constant sequence for montmul\n+    VSeq<4> vc(27, 0);       \/\/ constant sequence for montmul: montRSquareModQ\n@@ -5933,1 +5966,28 @@\n-    \/\/ expand groups of input bytes in vin to shorts in va and vb\n+    \/\/ The front half of sequence vin (vin[0], vin[1] and vin[2])\n+    \/\/ holds 48 (16x3) contiguous bytes from memory striped\n+    \/\/ horizontally across each of the 16 byte lanes. Equivalently,\n+    \/\/ that is 16 pairs of 12-bit integers. Likewise the back half\n+    \/\/ holds the next 48 bytes in the same arrangement.\n+\n+    \/\/ Each vector in the front half can also be viewed as a vertical\n+    \/\/ strip across the 16 pairs of 12 bit integers. Each byte in\n+    \/\/ vin[0] stores the low 8 bits of the first int in a pair. Each\n+    \/\/ byte in vin[1] stores the high 4 bits of the first int and the\n+    \/\/ low 4 bits of the second int. Each byte in vin[2] stores the\n+    \/\/ high 8 bits of the second int. Likewise the vectors in second\n+    \/\/ half.\n+\n+    \/\/ Converting the data to 16-bit shorts requires first of all\n+    \/\/ expanding each of the 6 x 16B vectors into 6 corresponding\n+    \/\/ pairs of 8H vectors. Mask, shift and add operations on the\n+    \/\/ resulting vector pairs can be used to combine 4 and 8 bit\n+    \/\/ parts of related 8H vector elements.\n+    \/\/\n+    \/\/ The middle vectors (vin[2] and vin[5]) are actually expanded\n+    \/\/ twice, one copy manipulated to provide the lower 4 bits\n+    \/\/ belonging to the first short in a pair and another copy\n+    \/\/ manipulated to provide the higher 4 bits belonging to the\n+    \/\/ second short in a pair. This is why the the vector sequences va\n+    \/\/ and vb used to hold the expanded 8H elements are of length 8.\n+\n+    \/\/ Expand vin[0] into va[0:1], and vin[1] into va[2:3] and va[4:5]\n@@ -5942,0 +6002,2 @@\n+    \/\/ likewise expand vin[3] into vb[0:1], and vin[4] into vb[2:3]\n+    \/\/ and vb[4:5]\n@@ -5949,1 +6011,1 @@\n-    \/\/ offset duplicated elements in va and vb by 8\n+    \/\/ shift lo byte of copy 1 of the middle stripe into the high byte\n@@ -5955,2 +6017,3 @@\n-    \/\/ expand remaining input bytes in vin to shorts in va and vb\n-    \/\/ but this time pre-shifted by 4\n+    \/\/ expand vin[2] into va[6:7] and vin[5] into vb[6:7] but this\n+    \/\/ time pre-shifted by 4 to ensure top bits of input 12-bit int\n+    \/\/ are in bit positions [4..11].\n@@ -5962,2 +6025,3 @@\n-    \/\/ split the duplicated 8 bit values into two distinct 4 bit\n-    \/\/ upper and lower halves using a mask or a shift\n+    \/\/ mask hi 4 bits of the 1st 12-bit int in a pair from copy1 and\n+    \/\/ shift lo 4 bits of the 2nd 12-bit int in a pair to the bottom of\n+    \/\/ copy2\n@@ -5973,2 +6037,6 @@\n-    \/\/ sum resulting short values into the front halves of va and\n-    \/\/ vb pairing registers offset by stride 2\n+    \/\/ sum hi 4 bits and lo 8 bits of the 1st 12-bit int in each pair and\n+    \/\/ hi 8 bits plus lo 4 bits of the 2nd 12-bit int in each pair\n+    \/\/ n.b. the ordering ensures: i) inputs are consumed before they\n+    \/\/ are overwritten ii) the order of 16-bit results across successive\n+    \/\/ pairs of vectors in va and then vb reflects the order of the\n+    \/\/ corresponding 12-bit inputs\n@@ -5984,1 +6052,1 @@\n-    \/\/ store results interleaved as shorts\n+    \/\/ store 64 results interleaved as shorts\n@@ -5993,3 +6061,4 @@\n-    \/\/ if anything is left it should be a final 72 bytes. so we\n-    \/\/ load 48 bytes into both lanes of front(vin) and 24 bytes\n-    \/\/ into the lower lane of back(vin)\n+    \/\/ if anything is left it should be a final 72 bytes of input\n+    \/\/ i.e. a final 48 12-bit values. so we handle this by loading\n+    \/\/ 48 bytes into all 16B lanes of front(vin) and only 24\n+    \/\/ bytes into the lower 8B lane of back(vin)\n@@ -5999,1 +6068,1 @@\n-    \/\/ expand groups of input bytes in vin to shorts in va and vb\n+    \/\/ Expand vin[0] into va[0:1], and vin[1] into va[2:3] and va[4:5]\n@@ -6009,0 +6078,1 @@\n+    \/\/ This time expand just the lower 8 lanes\n@@ -6013,1 +6083,1 @@\n-    \/\/ offset duplicated elements in va and vb by 8\n+    \/\/ shift lo byte of copy 1 of the middle stripe into the high byte\n@@ -6018,2 +6088,3 @@\n-    \/\/ expand remaining input bytes in vin to shorts in va and vb\n-    \/\/ but this time pre-shifted by 4\n+    \/\/ expand vin[2] into va[6:7] and lower 8 lanes of vin[5] into\n+    \/\/ vb[6] pre-shifted by 4 to ensure top bits of the input 12-bit\n+    \/\/ int are in bit positions [4..11].\n@@ -6024,2 +6095,3 @@\n-    \/\/ split the duplicated 8 bit values into two distinct 4 bit\n-    \/\/ upper and lower halves using a mask or a shift\n+    \/\/ mask hi 4 bits of each 1st 12-bit int in pair from copy1 and\n+    \/\/ shift lo 4 bits of each 2nd 12-bit int in pair to bottom of\n+    \/\/ copy2\n@@ -6033,2 +6105,9 @@\n-    \/\/ sum resulting short values into the front halves of va and\n-    \/\/ vb pairing registers offset by stride 2\n+\n+\n+    \/\/ sum hi 4 bits and lo 8 bits of each 1st 12-bit int in pair and\n+    \/\/ hi 8 bits plus lo 4 bits of each 2nd 12-bit int in pair\n+\n+    \/\/ n.b. ordering ensures: i) inputs are consumed before they are\n+    \/\/ overwritten ii) order of 16-bit results across succsessive\n+    \/\/ pairs of vectors in va and then lower half of vb reflects order\n+    \/\/ of corresponding 12-bit inputs\n@@ -6042,1 +6121,1 @@\n-    \/\/ store results interleaved as shorts\n+    \/\/ store 48 results interleaved as shorts\n@@ -6088,0 +6167,1 @@\n+\n@@ -6090,0 +6170,1 @@\n+    FloatRegister vc1_3 = v30; \/\/ for kyber_q\n@@ -6091,1 +6172,0 @@\n-    FloatRegister vc1_3 = v30;\n@@ -6094,1 +6174,1 @@\n-    FloatRegister vc2_3 = v31;\n+    FloatRegister vc2_3 = v31; \/\/ for kyberBarrettMultiplier\n@@ -6111,0 +6191,2 @@\n+\n+      \/\/ vs2 <- (2 * vs1 * kyberBarrettMultiplier) >> 16\n@@ -6116,0 +6198,2 @@\n+\n+      \/\/ vs2 <- (vs1 * kyberBarrettMultiplier) >> 26\n@@ -6121,0 +6205,2 @@\n+\n+      \/\/ vs1 <- vs1 - vs2 * kyber_q\n@@ -6126,0 +6212,1 @@\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":117,"deletions":30,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -652,1 +652,1 @@\n-        mlKemG.update((byte)mlKem_k);\n+\/\/        mlKemG.update((byte)mlKem_k);\n@@ -1011,0 +1011,1 @@\n+        assert poly.length == ML_KEM_N;\n@@ -1035,0 +1036,1 @@\n+        assert(poly.length == ML_KEM_N);\n@@ -1152,0 +1154,2 @@\n+        assert (result.length == ML_KEM_N) && (ntta.length == ML_KEM_N &&\n+                (nttb.length == ML_KEM_N));\n@@ -1189,1 +1193,2 @@\n-                    implKyberAddPoly(a, a, b);\n+        assert (a.length == ML_KEM_N) && (b.length == ML_KEM_N);\n+        implKyberAddPoly(a, a, b);\n@@ -1212,0 +1217,2 @@\n+        assert (a.length == ML_KEM_N) && (b.length == ML_KEM_N) &&\n+                (c.length == ML_KEM_N);\n@@ -1364,5 +1371,2 @@\n-        if (((remainder != 0) && (remainder != 48)) ||\n-            index + i * 96 > condensed.length) {\n-            \/\/ this should never happen\n-            throw new ProviderException(\"Bad parameters\");\n-        }\n+        assert (((remainder != 0) && (remainder != 48)) ||\n+            index + i * 96 > condensed.length);\n@@ -1533,0 +1537,1 @@\n+        assert poly.length == ML_KEM_N;\n","filename":"src\/java.base\/share\/classes\/com\/sun\/crypto\/provider\/ML_KEM.java","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"}]}