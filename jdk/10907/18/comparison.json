{"files":[{"patch":"@@ -1791,0 +1791,12 @@\n+  int max_monitors = C->method() != nullptr ? C->max_monitors() : 0;\n+  if (UseFastLocking && max_monitors > 0) {\n+    C2CheckLockStackStub* stub = new (C->comp_arena()) C2CheckLockStackStub();\n+    C->output()->add_stub(stub);\n+    __ ldr(r9, Address(rthread, JavaThread::lock_stack_current_offset()));\n+    __ ldr(r10, Address(rthread, JavaThread::lock_stack_limit_offset()));\n+    __ add(r9, r9, max_monitors * oopSize);\n+    __ cmp(r9, r10);\n+    __ br(Assembler::GE, stub->entry());\n+    __ bind(stub->continuation());\n+  }\n+\n@@ -3821,1 +3833,1 @@\n-    Label no_count;\n+    Label count, no_count;\n@@ -3839,12 +3851,2 @@\n-      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n-\n-      \/\/ Initialize the box. (Must happen before we update the object mark!)\n-      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ Compare object markWord with an unlocked value (tmp) and if\n-      \/\/ equal exchange the stack address of our box with object markWord.\n-      \/\/ On failure disp_hdr contains the possibly locked markWord.\n-      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n-                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n-      __ br(Assembler::EQ, cont);\n+      if (UseFastLocking) {\n+        __ fast_lock(oop, disp_hdr, tmp, rscratch1, no_count, false);\n@@ -3852,14 +3854,33 @@\n-      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-      \/\/ object, will have now locked it will continue at label cont\n-\n-      \/\/ Check if the owner is self by comparing the value in the\n-      \/\/ markWord of object (disp_hdr) with the stack pointer.\n-      __ mov(rscratch1, sp);\n-      __ sub(disp_hdr, disp_hdr, rscratch1);\n-      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-      \/\/ If condition is true we are cont and hence we can store 0 as the\n-      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n-      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+        \/\/ Indicate success on completion.\n+        __ cmp(oop, oop);\n+        __ b(count);\n+      } else {\n+        \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+        __ orr(tmp, disp_hdr, markWord::unlocked_value);\n+\n+        \/\/ Initialize the box. (Must happen before we update the object mark!)\n+        __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+        \/\/ Compare object markWord with an unlocked value (tmp) and if\n+        \/\/ equal exchange the stack address of our box with object markWord.\n+        \/\/ On failure disp_hdr contains the possibly locked markWord.\n+        __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n+                   \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n+        __ br(Assembler::EQ, cont);\n+\n+        assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+        \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+        \/\/ object, will have now locked it will continue at label cont\n+\n+        \/\/ Check if the owner is self by comparing the value in the\n+        \/\/ markWord of object (disp_hdr) with the stack pointer.\n+        __ mov(rscratch1, sp);\n+        __ sub(disp_hdr, disp_hdr, rscratch1);\n+        __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+        \/\/ If condition is true we are cont and hence we can store 0 as the\n+        \/\/ displaced header in the box, which indicates that it is a recursive lock.\n+        __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n+        __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+        __ b(cont);\n+      }\n@@ -3868,0 +3889,1 @@\n+      __ b(cont);\n@@ -3869,1 +3891,0 @@\n-    __ b(cont);\n@@ -3882,7 +3903,8 @@\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n-    __ mov(tmp, (address)markWord::unused_mark().value());\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n+    if (!UseFastLocking) {\n+      \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+      \/\/ lock. The fast-path monitor unlock code checks for\n+      \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+      \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n+      __ mov(tmp, (address)markWord::unused_mark().value());\n+      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    }\n@@ -3903,0 +3925,1 @@\n+    __ bind(count);\n@@ -3916,1 +3939,1 @@\n-    Label no_count;\n+    Label count, no_count;\n@@ -3920,1 +3943,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -3934,3 +3957,10 @@\n-      \/\/ Check if it is still a light weight lock, this is is true if we\n-      \/\/ see the stack address of the basicLock in the markWord of the\n-      \/\/ object.\n+      if (UseFastLocking) {\n+        __ fast_unlock(oop, tmp, box, disp_hdr, no_count);\n+\n+        \/\/ Indicate success on completion.\n+        __ cmp(oop, oop);\n+        __ b(count);\n+      } else {\n+        \/\/ Check if it is still a light weight lock, this is is true if we\n+        \/\/ see the stack address of the basicLock in the markWord of the\n+        \/\/ object.\n@@ -3938,2 +3968,4 @@\n-      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n-                 \/*release*\/ true, \/*weak*\/ false, tmp);\n+        __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n+                   \/*release*\/ true, \/*weak*\/ false, tmp);\n+        __ b(cont);\n+      }\n@@ -3942,0 +3974,1 @@\n+      __ b(cont);\n@@ -3943,1 +3976,0 @@\n-    __ b(cont);\n@@ -3951,0 +3983,14 @@\n+\n+    if (UseFastLocking) {\n+      \/\/ If the owner is anonymous, we need to fix it -- in an outline stub.\n+      Register tmp2 = disp_hdr;\n+      __ ldr(tmp2, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n+      \/\/ We cannot use tbnz here, the target might be too far away and cannot\n+      \/\/ be encoded.\n+      __ tst(tmp2, (uint64_t)(intptr_t) ANONYMOUS_OWNER);\n+      C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmp, tmp2);\n+      Compile::current()->output()->add_stub(stub);\n+      __ br(Assembler::NE, stub->entry());\n+      __ bind(stub->continuation());\n+    }\n+\n@@ -3977,0 +4023,1 @@\n+    __ bind(count);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":90,"deletions":43,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -245,1 +245,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,2 +66,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr);\n@@ -86,33 +85,38 @@\n-  \/\/ and mark it as unlocked\n-  orr(hdr, hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  lea(rscratch2, Address(obj, hdr_offset));\n-  cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/NULL);\n-  \/\/ if the object header was the same, we're done\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) sp <= hdr\n-  \/\/ 3) hdr <= sp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - sp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  mov(rscratch1, sp);\n-  sub(hdr, hdr, rscratch1);\n-  ands(hdr, hdr, aligned_mask - (int)os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  cbnz(hdr, slow_case);\n-  \/\/ done\n-  bind(done);\n+  if (UseFastLocking) {\n+    fast_lock(obj, hdr, rscratch1, rscratch2, slow_case, false);\n+  } else {\n+    Label done;\n+    \/\/ and mark it as unlocked\n+     orr(hdr, hdr, markWord::unlocked_value);\n+    \/\/ save unlocked object header into the displaced header location on the stack\n+    str(hdr, Address(disp_hdr, 0));\n+    \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+    \/\/ displaced header address in the object header - if it is not the same, get the\n+    \/\/ object header instead\n+    lea(rscratch2, Address(obj, hdr_offset));\n+    cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/nullptr);\n+    \/\/ if the object header was the same, we're done\n+    \/\/ if the object header was not the same, it is now in the hdr register\n+    \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+    \/\/\n+    \/\/ 1) (hdr & aligned_mask) == 0\n+    \/\/ 2) sp <= hdr\n+    \/\/ 3) hdr <= sp + page_size\n+    \/\/\n+    \/\/ these 3 tests can be done by evaluating the following expression:\n+    \/\/\n+    \/\/ (hdr - sp) & (aligned_mask - page_size)\n+    \/\/\n+    \/\/ assuming both the stack pointer and page_size have their least\n+    \/\/ significant 2 bits cleared and page_size is a power of 2\n+    mov(rscratch1, sp);\n+    sub(hdr, hdr, rscratch1);\n+    ands(hdr, hdr, aligned_mask - (int)os::vm_page_size());\n+    \/\/ for recursive locking, the result is zero => save it in the displaced header\n+    \/\/ location (null in the displaced hdr location indicates recursive locking)\n+    str(hdr, Address(disp_hdr, 0));\n+    \/\/ otherwise we don't care about the result and handle locking via runtime call\n+    cbnz(hdr, slow_case);\n+    \/\/ done\n+    bind(done);\n+  }\n@@ -130,5 +134,8 @@\n-  \/\/ load displaced header\n-  ldr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  \/\/ if we had recursive locking, we are done\n-  cbz(hdr, done);\n+  if (!UseFastLocking) {\n+    \/\/ load displaced header\n+    ldr(hdr, Address(disp_hdr, 0));\n+    \/\/ if the loaded hdr is null we had recursive locking\n+    \/\/ if we had recursive locking, we are done\n+    cbz(hdr, done);\n+  }\n+\n@@ -138,8 +145,4 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  if (hdr_offset) {\n-    lea(rscratch1, Address(obj, hdr_offset));\n-    cmpxchgptr(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n+\n+  if (UseFastLocking) {\n+    ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    fast_unlock(obj, hdr, rscratch1, rscratch2, slow_case);\n@@ -147,1 +150,13 @@\n-    cmpxchgptr(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n+    \/\/ test if object header is pointing to the displaced header, and if so, restore\n+    \/\/ the displaced header in the object - if the object header is not pointing to\n+    \/\/ the displaced header, get the object header instead\n+    \/\/ if the object header was not pointing to the displaced header,\n+    \/\/ we do unlocking via runtime call\n+    if (hdr_offset) {\n+      lea(rscratch1, Address(obj, hdr_offset));\n+      cmpxchgptr(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n+    } else {\n+      cmpxchgptr(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n+    }\n+    \/\/ done\n+    bind(done);\n@@ -149,2 +164,0 @@\n-  \/\/ done\n-  bind(done);\n@@ -305,1 +318,1 @@\n-void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes, int max_monitors) {\n@@ -312,0 +325,12 @@\n+  if (UseFastLocking && max_monitors > 0) {\n+    Label ok;\n+    ldr(r9, Address(rthread, JavaThread::lock_stack_current_offset()));\n+    ldr(r10, Address(rthread, JavaThread::lock_stack_limit_offset()));\n+    add(r9, r9, max_monitors * oopSize);\n+    cmp(r9, r10);\n+    br(Assembler::LT, ok);\n+    assert(StubRoutines::aarch64::check_lock_stack() != nullptr, \"need runtime call stub\");\n+    far_call(StubRoutines::aarch64::check_lock_stack());\n+    bind(ok);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":77,"deletions":52,"binary":false,"changes":129,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -66,0 +67,38 @@\n+int C2CheckLockStackStub::max_size() const {\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return 20;\n+}\n+\n+void C2CheckLockStackStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  assert(StubRoutines::aarch64::check_lock_stack() != nullptr, \"need runtime call stub\");\n+  __ far_call(StubRoutines::aarch64::check_lock_stack());\n+  __ b(continuation());\n+}\n+\n+int C2HandleAnonOMOwnerStub::max_size() const {\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return 20;\n+}\n+\n+void C2HandleAnonOMOwnerStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  Register mon = monitor();\n+  Register t = tmp();\n+  assert(t != noreg, \"need tmp register\");\n+\n+  \/\/ Fix owner to be the current thread.\n+  __ str(rthread, Address(mon, ObjectMonitor::owner_offset_in_bytes()));\n+\n+  \/\/ Pop owner object from lock-stack.\n+  __ ldr(t, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  __ sub(t, t, oopSize);\n+  __ str(t, Address(rthread, JavaThread::lock_stack_current_offset()));\n+\n+  __ b(continuation());\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_CodeStubs_aarch64.cpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -761,50 +761,55 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg\n-    ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    orr(swap_reg, rscratch1, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-\n-    assert(lock_offset == 0,\n-           \"displached header must be first word in BasicObjectLock\");\n-\n-    Label fail;\n-    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 7) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from sp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 3 bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n-    \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n-    \/\/ copy\n-    mov(rscratch1, sp);\n-    sub(swap_reg, swap_reg, rscratch1);\n-    ands(swap_reg, swap_reg, (uint64_t)(7 - (int)os::vm_page_size()));\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-    br(Assembler::EQ, count);\n-\n+    if (UseFastLocking) {\n+      ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock(obj_reg, tmp, rscratch1, rscratch2, slow_case);\n+      b(count);\n+    } else {\n+      \/\/ Load (object->mark() | 1) into swap_reg\n+      ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      orr(swap_reg, rscratch1, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      str(swap_reg, Address(lock_reg, mark_offset));\n+\n+      assert(lock_offset == 0,\n+             \"displached header must be first word in BasicObjectLock\");\n+\n+      Label fail;\n+      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+\n+      \/\/ Fast check for recursive lock.\n+      \/\/\n+      \/\/ Can apply the optimization only if this is a stack lock\n+      \/\/ allocated in this thread. For efficiency, we can focus on\n+      \/\/ recently allocated stack locks (instead of reading the stack\n+      \/\/ base and checking whether 'mark' points inside the current\n+      \/\/ thread stack):\n+      \/\/  1) (mark & 7) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n+      \/\/ neither apply the optimization for an inflated lock allocated\n+      \/\/ just above the thread stack (this is why condition 1 matters)\n+      \/\/ nor apply the optimization if the stack lock is inside the stack\n+      \/\/ of another thread. The latter is avoided even in case of overflow\n+      \/\/ because we have guard pages at the end of all stacks. Hence, if\n+      \/\/ we go over the stack base and hit the stack of another thread,\n+      \/\/ this should not be in a writeable area that could contain a\n+      \/\/ stack lock allocated by that thread. As a consequence, a stack\n+      \/\/ lock less than page size away from sp is guaranteed to be\n+      \/\/ owned by the current thread.\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 3 bits clear.\n+      \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n+      \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n+      \/\/ copy\n+      mov(rscratch1, sp);\n+      sub(swap_reg, swap_reg, rscratch1);\n+      ands(swap_reg, swap_reg, (uint64_t)(7 - (int)os::vm_page_size()));\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      str(swap_reg, Address(lock_reg, mark_offset));\n+      br(Assembler::EQ, count);\n+    }\n@@ -816,1 +821,1 @@\n-            lock_reg);\n+            UseFastLocking ? obj_reg : lock_reg);\n@@ -853,3 +858,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %r0\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (!UseFastLocking) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %r0\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    }\n@@ -863,3 +870,2 @@\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(header_reg, Address(swap_reg,\n-                            BasicLock::displaced_header_offset_in_bytes()));\n+    if (UseFastLocking) {\n+      Label slow_case;\n@@ -867,2 +873,16 @@\n-    \/\/ Test for recursion\n-    cbz(header_reg, count);\n+      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n+      \/\/ must handle it.\n+      Register tmp = header_reg;\n+      ldr(tmp, Address(rthread, JavaThread::lock_stack_current_offset()));\n+      ldr(tmp, Address(tmp, -oopSize));\n+      cmpoop(tmp, obj_reg);\n+      br(Assembler::NE, slow_case);\n+\n+      ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_unlock(obj_reg, header_reg, swap_reg, rscratch1, slow_case);\n+      b(count);\n+      bind(slow_case);\n+    } else {\n+      \/\/ Load the old header from BasicLock structure\n+      ldr(header_reg, Address(swap_reg,\n+                              BasicLock::displaced_header_offset_in_bytes()));\n@@ -870,2 +890,2 @@\n-    \/\/ Atomic swap back the old header\n-    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n+      \/\/ Test for recursion\n+      cbz(header_reg, count);\n@@ -873,0 +893,3 @@\n+      \/\/ Atomic swap back the old header\n+      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":84,"deletions":61,"binary":false,"changes":145,"status":"modified"},{"patch":"@@ -6214,0 +6214,55 @@\n+\n+\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n+\/\/ on failure.\n+\/\/ Registers:\n+\/\/  - obj: the object to be locked\n+\/\/  - hdr: the header, already loaded from obj, will be destroyed\n+\/\/  - t1, t2, t3: temporary registers, will be destroyed\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow, bool rt_check_stack) {\n+  assert(UseFastLocking, \"only used with fast-locking\");\n+  assert_different_registers(obj, hdr, t1, t2);\n+\n+  if (rt_check_stack) {\n+    \/\/ Check if we would have space on lock-stack for the object.\n+    ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+    ldr(t2, Address(rthread, JavaThread::lock_stack_limit_offset()));\n+    cmp(t1, t2);\n+    br(Assembler::GE, slow);\n+  }\n+\n+  \/\/ Load (object->mark() | 1) into hdr\n+  orr(hdr, hdr, markWord::unlocked_value);\n+  \/\/ Clear lock-bits, into t2\n+  eor(t2, hdr, markWord::unlocked_value);\n+  \/\/ Try to swing header from unlocked to locked\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ hdr, \/*new*\/ t2, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t1);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful lock, push object on lock-stack\n+  ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  str(obj, Address(t1, 0));\n+  add(t1, t1, oopSize);\n+  str(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+}\n+\n+void MacroAssembler::fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+  assert(UseFastLocking, \"only used with fast-locking\");\n+  assert_different_registers(obj, hdr, t1, t2);\n+\n+  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n+  andr(hdr, hdr, ~markWord::lock_mask_in_place);\n+\n+  \/\/ Load the new header (unlocked) into t1\n+  orr(t1, hdr, markWord::unlocked_value);\n+\n+  \/\/ Try to swing header from locked to unlocked\n+  cmpxchg(obj, hdr, t1, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t2);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful unlock, pop object from lock-stack\n+  ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  sub(t1, t1, oopSize);\n+  str(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":55,"deletions":0,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -1584,0 +1584,3 @@\n+  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow, bool rt_check_stack = true);\n+  void fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1778,28 +1778,33 @@\n-      \/\/ Load (object->mark() | 1) into swap_reg %r0\n-      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ orr(swap_reg, rscratch1, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-      \/\/ src -> dest iff dest == r0 else r0 <- dest\n-      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n-\n-      \/\/ Hmm should this move to the slow path code area???\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n-\n-      __ sub(swap_reg, sp, swap_reg);\n-      __ neg(swap_reg, swap_reg);\n-      __ ands(swap_reg, swap_reg, 3 - (int)os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-      __ br(Assembler::NE, slow_path_lock);\n+      if (UseFastLocking) {\n+        __ ldr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_lock(obj_reg, swap_reg, tmp, rscratch1, slow_path_lock);\n+      } else {\n+        \/\/ Load (object->mark() | 1) into swap_reg %r0\n+        __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ orr(swap_reg, rscratch1, 1);\n+\n+        \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+        __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+\n+        \/\/ src -> dest iff dest == r0 else r0 <- dest\n+        __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/nullptr);\n+\n+        \/\/ Hmm should this move to the slow path code area???\n+\n+        \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+        \/\/  1) (mark & 3) == 0, and\n+        \/\/  2) sp <= mark < mark + os::pagesize()\n+        \/\/ These 3 tests can be done by evaluating the following\n+        \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+        \/\/ assuming both stack pointer and pagesize have their\n+        \/\/ least significant 2 bits clear.\n+        \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n+\n+        __ sub(swap_reg, sp, swap_reg);\n+        __ neg(swap_reg, swap_reg);\n+        __ ands(swap_reg, swap_reg, 3 - (int)os::vm_page_size());\n+\n+        \/\/ Save the test result, for recursive case, the result is zero\n+        __ str(swap_reg, Address(lock_reg, mark_word_offset));\n+        __ br(Assembler::NE, slow_path_lock);\n+      }\n@@ -1916,1 +1921,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -1932,9 +1937,14 @@\n-      \/\/ get address of the stack lock\n-      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ ldr(old_hdr, Address(r0, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      Label count;\n-      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, count, &slow_path_unlock);\n-      __ bind(count);\n+      if (UseFastLocking) {\n+        __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n+      } else {\n+        \/\/ get address of the stack lock\n+        __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+        \/\/  get old displaced header\n+        __ ldr(old_hdr, Address(r0, 0));\n+\n+        \/\/ Atomic swap old header if oop still contains the stack lock\n+        Label count;\n+        __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, count, &slow_path_unlock);\n+        __ bind(count);\n+      }\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":48,"deletions":38,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -5477,0 +5477,22 @@\n+  address generate_check_lock_stack() {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"check_lock_stack\");\n+\n+    address start = __ pc();\n+\n+    __ set_last_Java_frame(sp, rfp, lr, rscratch1);\n+    __ enter();\n+    __ push_call_clobbered_registers();\n+\n+    __ mov(c_rarg0, r9);\n+    __ call_VM_leaf(CAST_FROM_FN_PTR(address, LockStack::ensure_lock_stack_size), 1);\n+\n+    __ pop_call_clobbered_registers();\n+    __ leave();\n+    __ reset_last_Java_frame(true);\n+\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n@@ -8109,0 +8131,3 @@\n+    if (UseFastLocking) {\n+      StubRoutines::aarch64::_check_lock_stack = generate_check_lock_stack();\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+address StubRoutines::aarch64::_check_lock_stack = nullptr;\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -73,0 +73,2 @@\n+  static address _check_lock_stack;\n+\n@@ -183,0 +185,4 @@\n+  static address check_lock_stack() {\n+    return _check_lock_stack;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -56,1 +56,1 @@\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors) {\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -72,1 +72,1 @@\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors) {\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -218,1 +218,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/cpu\/riscv\/c1_LIRAssembler_riscv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -75,31 +75,36 @@\n-  \/\/ and mark it as unlocked\n-  ori(hdr, hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  sd(hdr, Address(disp_hdr, 0));\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  la(t1, Address(obj, hdr_offset));\n-  cmpxchgptr(hdr, disp_hdr, t1, t0, done, \/*fallthough*\/NULL);\n-  \/\/ if the object header was the same, we're done\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) sp <= hdr\n-  \/\/ 3) hdr <= sp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr -sp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  sub(hdr, hdr, sp);\n-  mv(t0, aligned_mask - (int)os::vm_page_size());\n-  andr(hdr, hdr, t0);\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  sd(hdr, Address(disp_hdr, 0));\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  bnez(hdr, slow_case, \/* is_far *\/ true);\n+\n+  if (UseFastLocking) {\n+    fast_lock(obj, hdr, t0, t1, slow_case);\n+  } else {\n+    \/\/ and mark it as unlocked\n+    ori(hdr, hdr, markWord::unlocked_value);\n+    \/\/ save unlocked object header into the displaced header location on the stack\n+    sd(hdr, Address(disp_hdr, 0));\n+    \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+    \/\/ displaced header address in the object header - if it is not the same, get the\n+    \/\/ object header instead\n+    la(t1, Address(obj, hdr_offset));\n+    cmpxchgptr(hdr, disp_hdr, t1, t0, done, \/*fallthough*\/NULL);\n+    \/\/ if the object header was the same, we're done\n+    \/\/ if the object header was not the same, it is now in the hdr register\n+    \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+    \/\/\n+    \/\/ 1) (hdr & aligned_mask) == 0\n+    \/\/ 2) sp <= hdr\n+    \/\/ 3) hdr <= sp + page_size\n+    \/\/\n+    \/\/ these 3 tests can be done by evaluating the following expression:\n+    \/\/\n+    \/\/ (hdr -sp) & (aligned_mask - page_size)\n+    \/\/\n+    \/\/ assuming both the stack pointer and page_size have their least\n+    \/\/ significant 2 bits cleared and page_size is a power of 2\n+    sub(hdr, hdr, sp);\n+    mv(t0, aligned_mask - (int)os::vm_page_size());\n+    andr(hdr, hdr, t0);\n+    \/\/ for recursive locking, the result is zero => save it in the displaced header\n+    \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n+    sd(hdr, Address(disp_hdr, 0));\n+    \/\/ otherwise we don't care about the result and handle locking via runtime call\n+    bnez(hdr, slow_case, \/* is_far *\/ true);\n+  }\n@@ -118,16 +123,6 @@\n-  \/\/ load displaced header\n-  ld(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  \/\/ if we had recursive locking, we are done\n-  beqz(hdr, done);\n-  \/\/ load object\n-  ld(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-  verify_oop(obj);\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  if (hdr_offset) {\n-    la(t0, Address(obj, hdr_offset));\n-    cmpxchgptr(disp_hdr, hdr, t0, t1, done, &slow_case);\n+  if (UseFastLocking) {\n+    \/\/ load object\n+    ld(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+    verify_oop(obj);\n+    ld(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    fast_unlock(obj, hdr, t0, t1, slow_case);\n@@ -135,1 +130,21 @@\n-    cmpxchgptr(disp_hdr, hdr, obj, t1, done, &slow_case);\n+    \/\/ load displaced header\n+    ld(hdr, Address(disp_hdr, 0));\n+    \/\/ if the loaded hdr is NULL we had recursive locking\n+    \/\/ if we had recursive locking, we are done\n+    beqz(hdr, done);\n+    \/\/ load object\n+    ld(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n+    verify_oop(obj);\n+    \/\/ test if object header is pointing to the displaced header, and if so, restore\n+    \/\/ the displaced header in the object - if the object header is not pointing to\n+    \/\/ the displaced header, get the object header instead\n+    \/\/ if the object header was not pointing to the displaced header,\n+    \/\/ we do unlocking via runtime call\n+    if (hdr_offset) {\n+      la(t0, Address(obj, hdr_offset));\n+      cmpxchgptr(disp_hdr, hdr, t0, t1, done, &slow_case);\n+    } else {\n+      cmpxchgptr(disp_hdr, hdr, obj, t1, done, &slow_case);\n+    }\n+    \/\/ done\n+    bind(done);\n@@ -137,2 +152,0 @@\n-  \/\/ done\n-  bind(done);\n@@ -308,1 +321,1 @@\n-void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes, int max_monitors) {\n","filename":"src\/hotspot\/cpu\/riscv\/c1_MacroAssembler_riscv.cpp","additions":64,"deletions":51,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -812,28 +812,34 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg\n-    ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    ori(swap_reg, t0, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    sd(swap_reg, Address(lock_reg, mark_offset));\n-\n-    assert(lock_offset == 0,\n-           \"displached header must be first word in BasicObjectLock\");\n-\n-    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n-\n-    \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-    \/\/  1) (mark & 7) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 3 bits clear.\n-    \/\/ NOTE: the oopMark is in swap_reg x10 as the result of cmpxchg\n-    sub(swap_reg, swap_reg, sp);\n-    mv(t0, (int64_t)(7 - (int)os::vm_page_size()));\n-    andr(swap_reg, swap_reg, t0);\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    sd(swap_reg, Address(lock_reg, mark_offset));\n-    beqz(swap_reg, count);\n+    if (UseFastLocking) {\n+      ld(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock(obj_reg, tmp, t0, t1, slow_case);\n+      j(count);\n+    } else {\n+      \/\/ Load (object->mark() | 1) into swap_reg\n+      ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      ori(swap_reg, t0, 1);\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      sd(swap_reg, Address(lock_reg, mark_offset));\n+\n+      assert(lock_offset == 0,\n+             \"displached header must be first word in BasicObjectLock\");\n+\n+      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n+\n+      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+      \/\/  1) (mark & 7) == 0, and\n+      \/\/  2) sp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant 3 bits clear.\n+      \/\/ NOTE: the oopMark is in swap_reg x10 as the result of cmpxchg\n+      sub(swap_reg, swap_reg, sp);\n+      mv(t0, (int64_t)(7 - (int)os::vm_page_size()));\n+      andr(swap_reg, swap_reg, t0);\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      sd(swap_reg, Address(lock_reg, mark_offset));\n+      beqz(swap_reg, count);\n+    }\n@@ -846,1 +852,1 @@\n-            lock_reg);\n+            UseFastLocking ? obj_reg : lock_reg);\n@@ -884,3 +890,4 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into x10\n-    la(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (UseFastLocking) {\n+      Label slow_case;\n+      \/\/ Load oop into obj_reg(c_rarg3)\n+      ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -888,2 +895,2 @@\n-    \/\/ Load oop into obj_reg(c_rarg3)\n-    ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+      \/\/ Free entry\n+      sd(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -891,2 +898,6 @@\n-    \/\/ Free entry\n-    sd(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n+      \/\/ must handle it.\n+      Register tmp = header_reg;\n+      ld(tmp, Address(xthread, JavaThread::lock_stack_current_offset()));\n+      ld(tmp, Address(tmp, -oopSize));\n+      bne(tmp, obj_reg, slow_case);\n@@ -894,3 +905,9 @@\n-    \/\/ Load the old header from BasicLock structure\n-    ld(header_reg, Address(swap_reg,\n-                           BasicLock::displaced_header_offset_in_bytes()));\n+      ld(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_unlock(obj_reg, header_reg, swap_reg, t0, slow_case);\n+      j(count);\n+\n+      bind(slow_case);\n+    } else {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into x10\n+      la(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n@@ -898,2 +915,2 @@\n-    \/\/ Test for recursion\n-    beqz(header_reg, count);\n+      \/\/ Load oop into obj_reg(c_rarg3)\n+      ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -901,2 +918,13 @@\n-    \/\/ Atomic swap back the old header\n-    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n+      \/\/ Free entry\n+      sd(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+      \/\/ Load the old header from BasicLock structure\n+      ld(header_reg, Address(swap_reg,\n+                             BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Test for recursion\n+      beqz(header_reg, count);\n+\n+      \/\/ Atomic swap back the old header\n+      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n+    }\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":71,"deletions":43,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -4485,0 +4485,55 @@\n+\n+\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n+\/\/ on failure.\n+\/\/ Registers:\n+\/\/  - obj: the object to be locked\n+\/\/  - hdr: the header, already loaded from obj, will be destroyed\n+\/\/  - tmp1, tmp2: temporary registers, will be destroyed\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow) {\n+  assert(UseFastLocking, \"only used with fast-locking\");\n+  assert_different_registers(obj, hdr, tmp1, tmp2);\n+\n+  \/\/ Check if we would have space on lock-stack for the object.\n+  ld(tmp1, Address(xthread, JavaThread::lock_stack_current_offset()));\n+  ld(tmp2, Address(xthread, JavaThread::lock_stack_limit_offset()));\n+  bge(tmp1, tmp2, slow, true);\n+\n+  \/\/ Load (object->mark() | 1) into hdr\n+  ori(hdr, hdr, markWord::unlocked_value);\n+  \/\/ Clear lock-bits, into tmp2\n+  xori(tmp2, hdr, markWord::unlocked_value);\n+  \/\/ Try to swing header from unlocked to locked\n+  Label success;\n+  cmpxchgptr(hdr, tmp2, obj, tmp1, success, &slow);\n+  bind(success);\n+\n+  \/\/ After successful lock, push object on lock-stack\n+  \/\/ TODO: Can we avoid re-loading the current offset? The CAS above clobbers it.\n+  \/\/ Maybe we could ensure that we have enough space on the lock stack more cleverly.\n+  ld(tmp1, Address(xthread, JavaThread::lock_stack_current_offset()));\n+  sd(obj, Address(tmp1, 0));\n+  add(tmp1, tmp1, oopSize);\n+  sd(tmp1, Address(xthread, JavaThread::lock_stack_current_offset()));\n+}\n+\n+void MacroAssembler::fast_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow) {\n+  assert(UseFastLocking, \"only used with fast-locking\");\n+  assert_different_registers(obj, hdr, tmp1, tmp2);\n+\n+  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n+  mv(tmp1, ~markWord::lock_mask_in_place);\n+  andr(hdr, hdr, tmp1);\n+\n+  \/\/ Load the new header (unlocked) into tmp1\n+  ori(tmp1, hdr, markWord::unlocked_value);\n+\n+  \/\/ Try to swing header from locked to unlocked\n+  Label success;\n+  cmpxchgptr(hdr, tmp1, obj, tmp2, success, &slow);\n+  bind(success);\n+\n+  \/\/ After successful unlock, pop object from lock-stack\n+  ld(tmp1, Address(xthread, JavaThread::lock_stack_current_offset()));\n+  sub(tmp1, tmp1, oopSize);\n+  sd(tmp1, Address(xthread, JavaThread::lock_stack_current_offset()));\n+}\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":55,"deletions":0,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -1386,0 +1386,4 @@\n+\n+public:\n+  void fast_lock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow);\n+  void fast_unlock(Register obj, Register hdr, Register tmp1, Register tmp2, Label& slow);\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2416,30 +2416,40 @@\n-      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-      __ ori(tmp, disp_hdr, markWord::unlocked_value);\n-\n-      \/\/ Initialize the box. (Must happen before we update the object mark!)\n-      __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ Compare object markWord with an unlocked value (tmp) and if\n-      \/\/ equal exchange the stack address of our box with object markWord.\n-      \/\/ On failure disp_hdr contains the possibly locked markWord.\n-      __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64, Assembler::aq,\n-                 Assembler::rl, \/*result*\/disp_hdr);\n-      __ mv(flag, zr);\n-      __ beq(disp_hdr, tmp, cont); \/\/ prepare zero flag and goto cont if we won the cas\n-\n-      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-      \/\/ object, will have now locked it will continue at label cont\n-      \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-      \/\/ Check if the owner is self by comparing the value in the\n-      \/\/ markWord of object (disp_hdr) with the stack pointer.\n-      __ sub(disp_hdr, disp_hdr, sp);\n-      __ mv(tmp, (intptr_t) (~(os::vm_page_size()-1) | (uintptr_t)markWord::lock_mask_in_place));\n-      \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto cont,\n-      \/\/ hence we can store 0 as the displaced header in the box, which indicates that it is a\n-      \/\/ recursive lock.\n-      __ andr(tmp\/*==0?*\/, disp_hdr, tmp);\n-      __ sd(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-      __ mv(flag, tmp); \/\/ we can use the value of tmp as the result here\n+      if (UseFastLocking) {\n+        Label slow;\n+        __ fast_lock(oop, disp_hdr, tmp, t0, slow);\n+        \/\/ Indicate success at cont.\n+        __ mv(flag, zr);\n+        __ j(cont);\n+        __ bind(slow);\n+        __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow-path\n+      } else {\n+        \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+        __ ori(tmp, disp_hdr, markWord::unlocked_value);\n+\n+        \/\/ Initialize the box. (Must happen before we update the object mark!)\n+        __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+        \/\/ Compare object markWord with an unlocked value (tmp) and if\n+        \/\/ equal exchange the stack address of our box with object markWord.\n+        \/\/ On failure disp_hdr contains the possibly locked markWord.\n+        __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64, Assembler::aq,\n+                   Assembler::rl, \/*result*\/disp_hdr);\n+        __ mv(flag, zr);\n+        __ beq(disp_hdr, tmp, cont); \/\/ prepare zero flag and goto cont if we won the cas\n+\n+        assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+        \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+        \/\/ object, will have now locked it will continue at label cont\n+        \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+        \/\/ Check if the owner is self by comparing the value in the\n+        \/\/ markWord of object (disp_hdr) with the stack pointer.\n+        __ sub(disp_hdr, disp_hdr, sp);\n+        __ mv(tmp, (intptr_t) (~(os::vm_page_size()-1) | (uintptr_t)markWord::lock_mask_in_place));\n+        \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto cont,\n+        \/\/ hence we can store 0 as the displaced header in the box, which indicates that it is a\n+        \/\/ recursive lock.\n+        __ andr(tmp\/*==0?*\/, disp_hdr, tmp);\n+        __ sd(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+        __ mv(flag, tmp); \/\/ we can use the value of tmp as the result here\n+      }\n@@ -2462,6 +2472,8 @@\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n-    __ mv(tmp, (address)markWord::unused_mark().value());\n-    __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    if (!UseFastLocking) {\n+      \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+      \/\/ lock. The fast-path monitor unlock code checks for\n+      \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+      \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n+      __ mv(tmp, (address)markWord::unused_mark().value());\n+      __ sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    }\n@@ -2500,1 +2512,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -2515,3 +2527,13 @@\n-      \/\/ Check if it is still a light weight lock, this is true if we\n-      \/\/ see the stack address of the basicLock in the markWord of the\n-      \/\/ object.\n+      if (UseFastLocking) {\n+        Label slow;\n+        __ fast_unlock(oop, tmp, box, disp_hdr, slow);\n+\n+        \/\/ Indicate success at cont.\n+        __ mv(flag, zr);\n+        __ j(cont);\n+        __ bind(slow);\n+        __ mv(flag, 1); \/\/ Set non-zero flag to indicate 'failure' -> take slow path\n+      } else {\n+        \/\/ Check if it is still a light weight lock, this is true if we\n+        \/\/ see the stack address of the basicLock in the markWord of the\n+        \/\/ object.\n@@ -2519,3 +2541,4 @@\n-      __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64, Assembler::relaxed,\n-                 Assembler::rl, \/*result*\/tmp);\n-      __ xorr(flag, box, tmp); \/\/ box == tmp if cas succeeds\n+        __ cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64, Assembler::relaxed,\n+                   Assembler::rl, \/*result*\/tmp);\n+        __ xorr(flag, box, tmp); \/\/ box == tmp if cas succeeds\n+      }\n@@ -2533,0 +2556,11 @@\n+\n+    if (UseFastLocking) {\n+      Label L;\n+      __ ld(disp_hdr, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n+      __ mv(t0, (unsigned char)(intptr_t)ANONYMOUS_OWNER);\n+      __ bne(disp_hdr, t0, L);\n+      __ mv(flag, 1); \/\/ Indicate failure at cont -- dive into slow-path.\n+      __ j(cont);\n+      __ bind(L);\n+    }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":77,"deletions":43,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -1675,25 +1675,30 @@\n-      \/\/ Load (object->mark() | 1) into swap_reg % x10\n-      __ ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ ori(swap_reg, t0, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-      \/\/ src -> dest if dest == x10 else x10 <- dest\n-      __ cmpxchg_obj_header(x10, lock_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg % 10 as the result of cmpxchg\n-\n-      __ sub(swap_reg, swap_reg, sp);\n-      __ andi(swap_reg, swap_reg, 3 - (int)os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n-      __ bnez(swap_reg, slow_path_lock);\n+      if (UseFastLocking) {\n+        __ ld(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_lock(obj_reg, swap_reg, tmp, t0, slow_path_lock);\n+      } else {\n+        \/\/ Load (object->mark() | 1) into swap_reg % x10\n+        __ ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ ori(swap_reg, t0, 1);\n+\n+        \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+        __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n+\n+        \/\/ src -> dest if dest == x10 else x10 <- dest\n+        __ cmpxchg_obj_header(x10, lock_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n+\n+        \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+        \/\/  1) (mark & 3) == 0, and\n+        \/\/  2) sp <= mark < mark + os::pagesize()\n+        \/\/ These 3 tests can be done by evaluating the following\n+        \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n+        \/\/ assuming both stack pointer and pagesize have their\n+        \/\/ least significant 2 bits clear.\n+        \/\/ NOTE: the oopMark is in swap_reg % 10 as the result of cmpxchg\n+\n+        __ sub(swap_reg, swap_reg, sp);\n+        __ andi(swap_reg, swap_reg, 3 - (int)os::vm_page_size());\n+\n+        \/\/ Save the test result, for recursive case, the result is zero\n+        __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n+        __ bnez(swap_reg, slow_path_lock);\n+      }\n@@ -1794,1 +1799,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -1810,9 +1815,14 @@\n-      \/\/ get address of the stack lock\n-      __ la(x10, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ ld(old_hdr, Address(x10, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      Label count;\n-      __ cmpxchg_obj_header(x10, old_hdr, obj_reg, t0, count, &slow_path_unlock);\n-      __ bind(count);\n+      if (UseFastLocking) {\n+        __ ld(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_unlock(obj_reg, old_hdr, swap_reg, t0, slow_path_unlock);\n+      } else {\n+        \/\/ get address of the stack lock\n+        __ la(x10, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+        \/\/  get old displaced header\n+        __ ld(old_hdr, Address(x10, 0));\n+\n+        \/\/ Atomic swap old header if oop still contains the stack lock\n+        Label count;\n+        __ cmpxchg_obj_header(x10, old_hdr, obj_reg, t0, count, &slow_path_unlock);\n+        __ bind(count);\n+      }\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":45,"deletions":35,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -115,1 +115,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -72,1 +72,1 @@\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors) {\n","filename":"src\/hotspot\/cpu\/s390\/c1_MacroAssembler_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n@@ -3511,0 +3511,1 @@\n+    Register tmp = UseFastLocking ? op->scratch_opr()->as_register() : noreg;\n@@ -3512,1 +3513,1 @@\n-    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n+    int null_check_offset = __ lock_object(hdr, obj, lock, tmp, *op->stub()->entry());\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -322,1 +322,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n+  LIR_Opr tmp = UseFastLocking ? new_register(T_INT) : LIR_OprFact::illegalOpr;\n+  monitor_enter(obj.result(), lock, syncTempOpr(), tmp,\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register tmp, Label& slow_case) {\n@@ -45,2 +45,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr, tmp);\n@@ -65,33 +64,45 @@\n-  \/\/ and mark it as unlocked\n-  orptr(hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(disp_hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was the same, we're done\n-  jcc(Assembler::equal, done);\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) rsp <= hdr\n-  \/\/ 3) hdr <= rsp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - rsp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  subptr(hdr, rsp);\n-  andptr(hdr, aligned_mask - (int)os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  jcc(Assembler::notZero, slow_case);\n-  \/\/ done\n-  bind(done);\n+\n+  if (UseFastLocking) {\n+#ifdef _LP64\n+    const Register thread = r15_thread;\n+#else\n+    const Register thread = disp_hdr;\n+    get_thread(thread);\n+#endif\n+    fast_lock_impl(obj, hdr, thread, tmp, slow_case, LP64_ONLY(false) NOT_LP64(true));\n+  } else {\n+    Label done;\n+    \/\/ and mark it as unlocked\n+    orptr(hdr, markWord::unlocked_value);\n+    \/\/ save unlocked object header into the displaced header location on the stack\n+    movptr(Address(disp_hdr, 0), hdr);\n+    \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n+    \/\/ displaced header address in the object header - if it is not the same, get the\n+    \/\/ object header instead\n+    MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n+    cmpxchgptr(disp_hdr, Address(obj, hdr_offset));\n+    \/\/ if the object header was the same, we're done\n+    jcc(Assembler::equal, done);\n+    \/\/ if the object header was not the same, it is now in the hdr register\n+    \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n+    \/\/\n+    \/\/ 1) (hdr & aligned_mask) == 0\n+    \/\/ 2) rsp <= hdr\n+    \/\/ 3) hdr <= rsp + page_size\n+    \/\/\n+    \/\/ these 3 tests can be done by evaluating the following expression:\n+    \/\/\n+    \/\/ (hdr - rsp) & (aligned_mask - page_size)\n+    \/\/\n+    \/\/ assuming both the stack pointer and page_size have their least\n+    \/\/ significant 2 bits cleared and page_size is a power of 2\n+    subptr(hdr, rsp);\n+    andptr(hdr, aligned_mask - (int)os::vm_page_size());\n+    \/\/ for recursive locking, the result is zero => save it in the displaced header\n+    \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n+    movptr(Address(disp_hdr, 0), hdr);\n+    \/\/ otherwise we don't care about the result and handle locking via runtime call\n+    jcc(Assembler::notZero, slow_case);\n+    \/\/ done\n+    bind(done);\n+  }\n@@ -111,6 +122,9 @@\n-  \/\/ load displaced header\n-  movptr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  testptr(hdr, hdr);\n-  \/\/ if we had recursive locking, we are done\n-  jcc(Assembler::zero, done);\n+  if (!UseFastLocking) {\n+    \/\/ load displaced header\n+    movptr(hdr, Address(disp_hdr, 0));\n+    \/\/ if the loaded hdr is NULL we had recursive locking\n+    testptr(hdr, hdr);\n+    \/\/ if we had recursive locking, we are done\n+    jcc(Assembler::zero, done);\n+  }\n+\n@@ -119,1 +133,0 @@\n-\n@@ -121,10 +134,0 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  jcc(Assembler::notEqual, slow_case);\n-  \/\/ done\n-  bind(done);\n@@ -132,0 +135,16 @@\n+  if (UseFastLocking) {\n+    movptr(disp_hdr, Address(obj, hdr_offset));\n+    andptr(disp_hdr, ~(int32_t)markWord::lock_mask_in_place);\n+    fast_unlock_impl(obj, disp_hdr, hdr, slow_case);\n+  } else {\n+    \/\/ test if object header is pointing to the displaced header, and if so, restore\n+    \/\/ the displaced header in the object - if the object header is not pointing to\n+    \/\/ the displaced header, get the object header instead\n+    MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n+    cmpxchgptr(hdr, Address(obj, hdr_offset));\n+    \/\/ if the object header was not pointing to the displaced header,\n+    \/\/ we do unlocking via runtime call\n+    jcc(Assembler::notEqual, slow_case);\n+    \/\/ done\n+  }\n+  bind(done);\n@@ -302,1 +321,1 @@\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors) {\n@@ -323,0 +342,13 @@\n+#ifdef _LP64\n+  if (UseFastLocking && max_monitors > 0) {\n+    Label ok;\n+    movptr(rax, Address(r15_thread, JavaThread::lock_stack_current_offset()));\n+    addptr(rax, max_monitors * wordSize);\n+    cmpptr(rax, Address(r15_thread, JavaThread::lock_stack_limit_offset()));\n+    jcc(Assembler::less, ok);\n+    assert(StubRoutines::x86::check_lock_stack() != NULL, \"need runtime call stub\");\n+    call(RuntimeAddress(StubRoutines::x86::check_lock_stack()));\n+    bind(ok);\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":86,"deletions":54,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  int lock_object  (Register swap, Register obj, Register disp_hdr, Label& slow_case);\n+  int lock_object  (Register swap, Register obj, Register disp_hdr, Register tmp, Label& slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -75,0 +76,31 @@\n+int C2CheckLockStackStub::max_size() const {\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return 10;\n+}\n+\n+void C2CheckLockStackStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  assert(StubRoutines::x86::check_lock_stack() != NULL, \"need runtime call stub\");\n+  __ call(RuntimeAddress(StubRoutines::x86::check_lock_stack()));\n+  __ jmp(continuation(), false \/* maybe_short *\/);\n+}\n+\n+#ifdef _LP64\n+int C2HandleAnonOMOwnerStub::max_size() const {\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return 17;\n+}\n+\n+void C2HandleAnonOMOwnerStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  Register mon = monitor();\n+  __ movptr(Address(mon, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), r15_thread);\n+  __ subptr(Address(r15_thread, JavaThread::lock_stack_current_offset()), oopSize);\n+  __ jmp(continuation());\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-void C2_MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {\n+void C2_MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub, int max_monitors) {\n@@ -130,0 +130,14 @@\n+#ifdef _LP64\n+  if (UseFastLocking && max_monitors > 0) {\n+    C2CheckLockStackStub* stub = new (Compile::current()->comp_arena()) C2CheckLockStackStub();\n+    Compile::current()->output()->add_stub(stub);\n+    assert(!is_stub, \"only methods have monitors\");\n+    Register thread = r15_thread;\n+    movptr(rax, Address(thread, JavaThread::lock_stack_current_offset()));\n+    addptr(rax, max_monitors * oopSize);\n+    cmpptr(rax, Address(thread, JavaThread::lock_stack_limit_offset()));\n+    jcc(Assembler::greaterEqual, stub->entry());\n+    bind(stub->continuation());\n+  }\n+#endif\n+\n@@ -551,1 +565,1 @@\n-                                 Register scrReg, Register cx1Reg, Register cx2Reg,\n+                                 Register scrReg, Register cx1Reg, Register cx2Reg, Register thread,\n@@ -605,14 +619,32 @@\n-    \/\/ Attempt stack-locking ...\n-    orptr (tmpReg, markWord::unlocked_value);\n-    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n-    lock();\n-    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n-    jcc(Assembler::equal, COUNT);           \/\/ Success\n-\n-    \/\/ Recursive locking.\n-    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n-    \/\/ Locked by current thread if difference with current SP is less than one page.\n-    subptr(tmpReg, rsp);\n-    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n-    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - (int)os::vm_page_size())) );\n-    movptr(Address(boxReg, 0), tmpReg);\n+    if (UseFastLocking) {\n+#ifdef _LP64\n+      fast_lock_impl(objReg, tmpReg, thread, scrReg, NO_COUNT, false);\n+      jmp(COUNT);\n+#else\n+      \/\/ We cannot emit the lock-stack-check in verified_entry() because we don't have enough\n+      \/\/ registers (for thread ptr). Therefore we have to emit the lock-stack-check in\n+      \/\/ fast_lock_impl(). However, that check can take a slow-path with ZF=1, therefore\n+      \/\/ we need to handle it specially and force ZF=0 before taking the actual slow-path.\n+      Label slow;\n+      fast_lock_impl(objReg, tmpReg, thread, scrReg, slow);\n+      jmp(COUNT);\n+      bind(slow);\n+      testptr(objReg, objReg); \/\/ force ZF=0 to indicate failure\n+      jmp(NO_COUNT);\n+#endif\n+    } else {\n+      \/\/ Attempt stack-locking ...\n+      orptr (tmpReg, markWord::unlocked_value);\n+      movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n+      lock();\n+      cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n+      jcc(Assembler::equal, COUNT);           \/\/ Success\n+\n+      \/\/ Recursive locking.\n+      \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n+      \/\/ Locked by current thread if difference with current SP is less than one page.\n+      subptr(tmpReg, rsp);\n+      \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n+      andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - (int)os::vm_page_size())) );\n+      movptr(Address(boxReg, 0), tmpReg);\n+    }\n@@ -650,2 +682,1 @@\n-  \/\/ Optimistic form: consider XORL tmpReg,tmpReg\n-  movptr(tmpReg, NULL_WORD);\n+  xorptr(tmpReg, tmpReg);\n@@ -653,7 +684,1 @@\n-  \/\/ Appears unlocked - try to swing _owner from null to non-null.\n-  \/\/ Ideally, I'd manifest \"Self\" with get_thread and then attempt\n-  \/\/ to CAS the register containing Self into m->Owner.\n-  \/\/ But we don't have enough registers, so instead we can either try to CAS\n-  \/\/ rsp or the address of the box (in scr) into &m->owner.  If the CAS succeeds\n-  \/\/ we later store \"Self\" into m->Owner.  Transiently storing a stack address\n-  \/\/ (rsp or the address of the box) into  m->owner is harmless.\n+  \/\/ Appears unlocked - try to swing _owner from null to curren thread.\n@@ -662,1 +687,1 @@\n-  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -664,7 +689,0 @@\n-  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n-  \/\/ then take the slow path.\n-  jccb  (Assembler::notZero, NO_COUNT);\n-  \/\/ update _owner from BasicLock to thread\n-  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n-  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n@@ -776,1 +794,1 @@\n-  if (!UseHeavyMonitors) {\n+  if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -783,1 +801,20 @@\n-    jccb   (Assembler::zero, Stacked);\n+#if INCLUDE_RTM_OPT\n+    if (UseFastLocking && use_rtm) {\n+      jcc(Assembler::zero, Stacked);\n+    } else\n+#endif\n+    jccb(Assembler::zero, Stacked);\n+    if (UseFastLocking) {\n+      \/\/ If the owner is ANONYMOUS, we need to fix it -  in an outline stub.\n+      testb(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t) (intptr_t) ANONYMOUS_OWNER);\n+#ifdef _LP64\n+      C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmpReg);\n+      Compile::current()->output()->add_stub(stub);\n+      jcc(Assembler::notEqual, stub->entry());\n+      bind(stub->continuation());\n+#else\n+      \/\/ We can't easily implement this optimization on 32 bit because we don't have a thread register.\n+      \/\/ Call the slow-path instead.\n+      jcc(Assembler::notEqual, NO_COUNT);\n+#endif\n+    }\n@@ -795,1 +832,1 @@\n-    jmpb(DONE_LABEL);\n+    jmp(DONE_LABEL);\n@@ -909,3 +946,9 @@\n-    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-    lock();\n-    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+    if (UseFastLocking) {\n+      mov(boxReg, tmpReg);\n+      fast_unlock_impl(objReg, boxReg, tmpReg, NO_COUNT);\n+      jmp(COUNT);\n+    } else {\n+      movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+      lock();\n+      cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":82,"deletions":39,"binary":false,"changes":121,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-  void verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub);\n+  void verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub, int max_monitors);\n@@ -39,1 +39,1 @@\n-                 Register scr, Register cx1, Register cx2,\n+                 Register scr, Register cx1, Register cx2, Register thread,\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1226,53 +1226,65 @@\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    movl(swap_reg, 1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    assert(lock_offset == 0,\n-           \"displaced header must be first word in BasicObjectLock\");\n-\n-    lock();\n-    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    jcc(Assembler::zero, count_locking);\n-\n-    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & zero_bits) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from rsp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n-    subptr(swap_reg, rsp);\n-    andptr(swap_reg, zero_bits - (int)os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-    jcc(Assembler::notZero, slow_case);\n-\n-    bind(count_locking);\n+    if (UseFastLocking) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = lock_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Load object header, prepare for CAS from unlocked to locked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, slow_case);\n+    } else {\n+      \/\/ Load immediate 1 into swap_reg %rax\n+      movl(swap_reg, 1);\n+\n+      \/\/ Load (object->mark() | 1) into swap_reg %rax\n+      orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+\n+      assert(lock_offset == 0,\n+             \"displaced header must be first word in BasicObjectLock\");\n+\n+      lock();\n+      cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      jcc(Assembler::zero, count_locking);\n+\n+      const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n+\n+      \/\/ Fast check for recursive lock.\n+      \/\/\n+      \/\/ Can apply the optimization only if this is a stack lock\n+      \/\/ allocated in this thread. For efficiency, we can focus on\n+      \/\/ recently allocated stack locks (instead of reading the stack\n+      \/\/ base and checking whether 'mark' points inside the current\n+      \/\/ thread stack):\n+      \/\/  1) (mark & zero_bits) == 0, and\n+      \/\/  2) rsp <= mark < mark + os::pagesize()\n+      \/\/\n+      \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n+      \/\/ neither apply the optimization for an inflated lock allocated\n+      \/\/ just above the thread stack (this is why condition 1 matters)\n+      \/\/ nor apply the optimization if the stack lock is inside the stack\n+      \/\/ of another thread. The latter is avoided even in case of overflow\n+      \/\/ because we have guard pages at the end of all stacks. Hence, if\n+      \/\/ we go over the stack base and hit the stack of another thread,\n+      \/\/ this should not be in a writeable area that could contain a\n+      \/\/ stack lock allocated by that thread. As a consequence, a stack\n+      \/\/ lock less than page size away from rsp is guaranteed to be\n+      \/\/ owned by the current thread.\n+      \/\/\n+      \/\/ These 3 tests can be done by evaluating the following\n+      \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n+      \/\/ assuming both stack pointer and pagesize have their\n+      \/\/ least significant bits clear.\n+      \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n+      subptr(swap_reg, rsp);\n+      andptr(swap_reg, zero_bits - (int)os::vm_page_size());\n+\n+      \/\/ Save the test result, for recursive case, the result is zero\n+      movptr(Address(lock_reg, mark_offset), swap_reg);\n+      jcc(Assembler::notZero, slow_case);\n+\n+      bind(count_locking);\n+    }\n@@ -1287,1 +1299,1 @@\n-            lock_reg);\n+            UseFastLocking ? obj_reg : lock_reg);\n@@ -1321,3 +1333,5 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %rax\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    if (!UseFastLocking) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %rax\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    }\n@@ -1331,3 +1345,20 @@\n-    \/\/ Load the old header from BasicLock structure\n-    movptr(header_reg, Address(swap_reg,\n-                               BasicLock::displaced_header_offset_in_bytes()));\n+    if (UseFastLocking) {\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = header_reg;\n+      get_thread(thread);\n+#endif\n+      \/\/ Handle unstructured locking.\n+      Register tmp = swap_reg;\n+      movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n+      cmpptr(obj_reg, Address(tmp, -oopSize));\n+      jcc(Assembler::notEqual, slow_case);\n+      \/\/ Try to swing header from locked to unlocked.\n+      movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n+    } else {\n+      \/\/ Load the old header from BasicLock structure\n+      movptr(header_reg, Address(swap_reg,\n+                                 BasicLock::displaced_header_offset_in_bytes()));\n@@ -1335,2 +1366,2 @@\n-    \/\/ Test for recursion\n-    testptr(header_reg, header_reg);\n+      \/\/ Test for recursion\n+      testptr(header_reg, header_reg);\n@@ -1338,2 +1369,2 @@\n-    \/\/ zero for recursive case\n-    jcc(Assembler::zero, count_locking);\n+      \/\/ zero for recursive case\n+      jcc(Assembler::zero, count_locking);\n@@ -1341,3 +1372,3 @@\n-    \/\/ Atomic swap back the old header\n-    lock();\n-    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      \/\/ Atomic swap back the old header\n+      lock();\n+      cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -1345,2 +1376,2 @@\n-    \/\/ zero for simple unlock of a stack-lock case\n-    jcc(Assembler::notZero, slow_case);\n+      \/\/ zero for simple unlock of a stack-lock case\n+      jcc(Assembler::notZero, slow_case);\n@@ -1348,1 +1379,2 @@\n-    bind(count_locking);\n+      bind(count_locking);\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":102,"deletions":70,"binary":false,"changes":172,"status":"modified"},{"patch":"@@ -9679,0 +9679,58 @@\n+\n+void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow, bool rt_check_stack) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, thread, tmp);\n+\n+  \/\/ First we need to check if the lock-stack has room for pushing the object reference.\n+  if (rt_check_stack) {\n+    movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n+    cmpptr(tmp, Address(thread, JavaThread::lock_stack_limit_offset()));\n+    jcc(Assembler::greaterEqual, slow);\n+  }\n+#ifdef ASSERT\n+  else {\n+    Label ok;\n+    movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n+    cmpptr(tmp, Address(thread, JavaThread::lock_stack_limit_offset()));\n+    jcc(Assembler::less, ok);\n+    stop(\"Not enough room in lock stack; should have been checked in the method prologue\");\n+    bind(ok);\n+  }\n+#endif\n+\n+  \/\/ Now we attempt to take the fast-lock.\n+  \/\/ Clear lowest two header bits (locked state).\n+  andptr(hdr, ~(int32_t)markWord::lock_mask_in_place);\n+  movptr(tmp, hdr);\n+  \/\/ Set lowest bit (unlocked state).\n+  orptr(hdr, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notEqual, slow);\n+\n+  \/\/ If successful, push object to lock-stack.\n+  movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n+  movptr(Address(tmp, 0), obj);\n+  increment(tmp, oopSize);\n+  movptr(Address(thread, JavaThread::lock_stack_current_offset()), tmp);\n+}\n+\n+void MacroAssembler::fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, tmp);\n+\n+  \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+  movptr(tmp, hdr); \/\/ The expected old value\n+  orptr(tmp, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notEqual, slow);\n+  \/\/ Pop the lock object from the lock-stack.\n+#ifdef _LP64\n+  const Register thread = r15_thread;\n+#else\n+  const Register thread = rax;\n+  get_thread(thread);\n+#endif\n+  subptr(Address(thread, JavaThread::lock_stack_current_offset()), oopSize);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":58,"deletions":0,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2011,0 +2011,2 @@\n+  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow, bool rt_check_stack = true);\n+  void fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1680,30 +1680,36 @@\n-      \/\/ Load immediate 1 into swap_reg %rax,\n-      __ movptr(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, count_mon);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+      if (UseFastLocking) {\n+        \/\/ Load object header\n+        __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_lock_impl(obj_reg, swap_reg, thread, lock_reg, slow_path_lock);\n+      } else {\n+        \/\/ Load immediate 1 into swap_reg %rax,\n+        __ movptr(swap_reg, 1);\n+\n+        \/\/ Load (object->mark() | 1) into swap_reg %rax,\n+        __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+\n+        \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+        __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+\n+        \/\/ src -> dest iff dest == rax, else rax, <- dest\n+        \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n+        __ lock();\n+        __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ jcc(Assembler::equal, count_mon);\n+\n+        \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+        \/\/  1) (mark & 3) == 0, and\n+        \/\/  2) rsp <= mark < mark + os::pagesize()\n+        \/\/ These 3 tests can be done by evaluating the following\n+        \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+        \/\/ assuming both stack pointer and pagesize have their\n+        \/\/ least significant 2 bits clear.\n+        \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n+\n+        __ subptr(swap_reg, rsp);\n+        __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n+\n+        \/\/ Save the test result, for recursive case, the result is zero\n+        __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+       __ jcc(Assembler::notEqual, slow_path_lock);\n+      }\n@@ -1833,1 +1839,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -1849,12 +1855,18 @@\n-      \/\/  get old displaced header\n-      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      if (UseFastLocking) {\n+        __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+        __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n+      } else {\n+        \/\/  get old displaced header\n+        __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n+\n+        \/\/ get address of the stack lock\n+        __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n+\n+        \/\/ Atomic swap old header if oop still contains the stack lock\n+        \/\/ src -> dest iff dest == rax, else rax, <- dest\n+        \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n+        __ lock();\n+        __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ jcc(Assembler::notEqual, slow_path_unlock);\n+      }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":55,"deletions":43,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -2148,0 +2148,7 @@\n+      if (UseFastLocking) {\n+        \/\/ Load object header\n+        __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ fast_lock_impl(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n+      } else {\n+        \/\/ Load immediate 1 into swap_reg %rax\n+        __ movl(swap_reg, 1);\n@@ -2149,5 +2156,2 @@\n-      \/\/ Load immediate 1 into swap_reg %rax\n-      __ movl(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        \/\/ Load (object->mark() | 1) into swap_reg %rax\n+        __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n@@ -2155,2 +2159,2 @@\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+        \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n+        __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n@@ -2158,4 +2162,4 @@\n-      \/\/ src -> dest iff dest == rax else rax <- dest\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, count_mon);\n+        \/\/ src -> dest iff dest == rax else rax <- dest\n+        __ lock();\n+        __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ jcc(Assembler::equal, count_mon);\n@@ -2163,1 +2167,1 @@\n-      \/\/ Hmm should this move to the slow path code area???\n+        \/\/ Hmm should this move to the slow path code area???\n@@ -2165,8 +2169,8 @@\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n+        \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n+        \/\/  1) (mark & 3) == 0, and\n+        \/\/  2) rsp <= mark < mark + os::pagesize()\n+        \/\/ These 3 tests can be done by evaluating the following\n+        \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n+        \/\/ assuming both stack pointer and pagesize have their\n+        \/\/ least significant 2 bits clear.\n+        \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n@@ -2174,2 +2178,2 @@\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n+        __ subptr(swap_reg, rsp);\n+        __ andptr(swap_reg, 3 - (int)os::vm_page_size());\n@@ -2177,3 +2181,4 @@\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+        \/\/ Save the test result, for recursive case, the result is zero\n+        __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n+        __ jcc(Assembler::notEqual, slow_path_lock);\n+      }\n@@ -2293,1 +2298,1 @@\n-    if (!UseHeavyMonitors) {\n+    if (!UseHeavyMonitors && !UseFastLocking) {\n@@ -2309,9 +2314,15 @@\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ movptr(old_hdr, Address(rax, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      __ lock();\n-      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      if (UseFastLocking) {\n+        __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+        __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n+      } else {\n+        \/\/ get address of the stack lock\n+        __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+        \/\/  get old displaced header\n+        __ movptr(old_hdr, Address(rax, 0));\n+\n+        \/\/ Atomic swap old header if oop still contains the stack lock\n+        __ lock();\n+        __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+        __ jcc(Assembler::notEqual, slow_path_unlock);\n+      }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":46,"deletions":35,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -3195,0 +3195,49 @@\n+\/\/ Call runtime to ensure lock-stack size.\n+\/\/ Arguments:\n+\/\/ - c_rarg0: the required _limit pointer\n+address StubGenerator::generate_check_lock_stack() {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", \"check_lock_stack\");\n+  address start = __ pc();\n+\n+  BLOCK_COMMENT(\"Entry:\");\n+  __ enter(); \/\/ save rbp\n+\n+  __ pusha();\n+\n+  \/\/ The method may have floats as arguments, and we must spill them before calling\n+  \/\/ the VM runtime.\n+  assert(Argument::n_float_register_parameters_j == 8, \"Assumption\");\n+  const int xmm_size = wordSize * 2;\n+  const int xmm_spill_size = xmm_size * Argument::n_float_register_parameters_j;\n+  __ subptr(rsp, xmm_spill_size);\n+  __ movdqu(Address(rsp, xmm_size * 7), xmm7);\n+  __ movdqu(Address(rsp, xmm_size * 6), xmm6);\n+  __ movdqu(Address(rsp, xmm_size * 5), xmm5);\n+  __ movdqu(Address(rsp, xmm_size * 4), xmm4);\n+  __ movdqu(Address(rsp, xmm_size * 3), xmm3);\n+  __ movdqu(Address(rsp, xmm_size * 2), xmm2);\n+  __ movdqu(Address(rsp, xmm_size * 1), xmm1);\n+  __ movdqu(Address(rsp, xmm_size * 0), xmm0);\n+\n+  __ call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<void (*)(oop*)>(LockStack::ensure_lock_stack_size)), rax);\n+\n+  __ movdqu(xmm0, Address(rsp, xmm_size * 0));\n+  __ movdqu(xmm1, Address(rsp, xmm_size * 1));\n+  __ movdqu(xmm2, Address(rsp, xmm_size * 2));\n+  __ movdqu(xmm3, Address(rsp, xmm_size * 3));\n+  __ movdqu(xmm4, Address(rsp, xmm_size * 4));\n+  __ movdqu(xmm5, Address(rsp, xmm_size * 5));\n+  __ movdqu(xmm6, Address(rsp, xmm_size * 6));\n+  __ movdqu(xmm7, Address(rsp, xmm_size * 7));\n+  __ addptr(rsp, xmm_spill_size);\n+\n+  __ popa();\n+\n+  __ leave();\n+\n+  __ ret(0);\n+\n+  return start;\n+}\n+\n@@ -4091,0 +4140,3 @@\n+  if (UseFastLocking) {\n+    StubRoutines::x86::_check_lock_stack = generate_check_lock_stack();\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -472,0 +472,2 @@\n+  address generate_check_lock_stack();\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -87,0 +87,1 @@\n+address StubRoutines::x86::_check_lock_stack = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -129,0 +129,2 @@\n+  static address _check_lock_stack;\n+\n@@ -218,0 +220,2 @@\n+  static address check_lock_stack() { return _check_lock_stack; }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -617,1 +617,2 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL);\n+  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL, max_monitors);\n@@ -13805,1 +13806,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2) %{\n+instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n@@ -13808,1 +13809,1 @@\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box, TEMP thread);\n@@ -13812,0 +13813,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13813,1 +13815,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n@@ -13821,1 +13823,1 @@\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr) %{\n+instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, eRegP thread) %{\n@@ -13824,1 +13826,1 @@\n-  effect(TEMP tmp, TEMP scr, USE_KILL box);\n+  effect(TEMP tmp, TEMP scr, USE_KILL box, TEMP thread);\n@@ -13828,0 +13830,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13829,1 +13832,1 @@\n-                 $scr$$Register, noreg, noreg, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, noreg, noreg, $thread$$Register, NULL, NULL, NULL, false, false);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -925,1 +925,2 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL);\n+  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL, max_monitors);\n@@ -13364,1 +13365,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n@@ -13380,1 +13381,1 @@\n-                 $scr$$Register, noreg, noreg, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, noreg, noreg, r15_thread, NULL, NULL, NULL, false, false);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -387,0 +387,1 @@\n+    push_monitor();\n@@ -574,0 +575,1 @@\n+, _max_monitors(0)\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -86,0 +86,1 @@\n+  int                _max_monitors; \/\/ Max number of active monitors, for fast-locking\n@@ -143,0 +144,1 @@\n+  int max_monitors() const                       { return _max_monitors; }\n@@ -175,0 +177,2 @@\n+  void push_monitor()                            { _max_monitors++; }\n+\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2318,0 +2318,1 @@\n+  compilation()->push_monitor();\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -776,1 +776,1 @@\n-  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n+  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  void build_frame(int frame_size_in_bytes, int bang_size_in_bytes);\n+  void build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors);\n","filename":"src\/hotspot\/share\/c1\/c1_MacroAssembler.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -760,2 +760,2 @@\n-  assert(obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n+  assert(UseFastLocking || obj == lock->obj(), \"must match\");\n+  SharedRuntime::monitor_enter_helper(obj, UseFastLocking ? NULL : lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -738,0 +738,9 @@\n+  if (!UseHeavyMonitors && UseFastLocking) {\n+    \/\/ This is a hack to get around the limitation of registers in x86_32. We really\n+    \/\/ send an oopDesc* instead of a BasicObjectLock*.\n+    Handle h_obj(current, oop((reinterpret_cast<oopDesc*>(elem))));\n+    assert(Universe::heap()->is_in_or_null(h_obj()),\n+           \"must be NULL or an object\");\n+    ObjectSynchronizer::enter(h_obj, NULL, current);\n+    return;\n+  }\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -53,1 +53,2 @@\n-\/\/    [ptr             | 00]  locked             ptr points to real header on stack\n+\/\/    [ptr             | 00]  locked             ptr points to real header on stack (stack-locking in use)\n+\/\/    [header          | 00]  locked             locked regular object header (fast-locking in use)\n@@ -55,1 +56,1 @@\n-\/\/    [ptr             | 10]  monitor            inflated lock (header is wapped out)\n+\/\/    [ptr             | 10]  monitor            inflated lock (header is swapped out)\n@@ -57,1 +58,1 @@\n-\/\/    [0 ............ 0| 00]  inflating          inflation in progress\n+\/\/    [0 ............ 0| 00]  inflating          inflation in progress (stack-locking in use)\n@@ -159,0 +160,1 @@\n+  \/\/ Fast-locking does not use INFLATING.\n@@ -173,1 +175,1 @@\n-    return ((value() & lock_mask_in_place) == locked_value);\n+    return !UseFastLocking && ((value() & lock_mask_in_place) == locked_value);\n@@ -179,0 +181,9 @@\n+\n+  bool is_fast_locked() const {\n+    return UseFastLocking && ((value() & lock_mask_in_place) == locked_value);\n+  }\n+  markWord set_fast_locked() const {\n+    \/\/ Clear the lock_mask_in_place bits to set locked_value:\n+    return markWord(value() & ~lock_mask_in_place);\n+  }\n+\n@@ -188,1 +199,3 @@\n-    return ((value() & unlocked_value) == 0);\n+    intptr_t lockbits = value() & lock_mask_in_place;\n+    return UseFastLocking ? lockbits == monitor_value   \/\/ monitor?\n+                    : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":18,"deletions":5,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -122,1 +122,2 @@\n-  \/\/ at a safepoint, it must not be zero.\n+  \/\/ at a safepoint, it must not be zero. fast-locking does allow the\n+  \/\/ mark to be zero at a safepoint.\n@@ -125,1 +126,1 @@\n-  if (ignore_mark_word) {\n+  if (ignore_mark_word || UseFastLocking) {\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -89,0 +89,23 @@\n+class C2CheckLockStackStub : public C2CodeStub {\n+public:\n+  C2CheckLockStackStub() : C2CodeStub() {}\n+\n+  int max_size() const;\n+  void emit(C2_MacroAssembler& masm);\n+};\n+\n+#ifdef _LP64\n+class C2HandleAnonOMOwnerStub : public C2CodeStub {\n+private:\n+  Register _monitor;\n+  Register _tmp;\n+public:\n+  C2HandleAnonOMOwnerStub(Register monitor, Register tmp = noreg) : C2CodeStub(),\n+    _monitor(monitor), _tmp(tmp) {}\n+  Register monitor() { return _monitor; }\n+  Register tmp() { return _tmp; }\n+  int max_size() const;\n+  void emit(C2_MacroAssembler& masm);\n+};\n+#endif\n+\n","filename":"src\/hotspot\/share\/opto\/c2_CodeStubs.hpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1024,0 +1024,1 @@\n+  reset_max_monitors();\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -340,0 +340,1 @@\n+  uint                  _max_monitors;          \/\/ Keep track of maximum number of active monitors in this compilation\n@@ -634,0 +635,4 @@\n+  void          push_monitor() { _max_monitors++; }\n+  void          reset_max_monitors() { _max_monitors = 0; }\n+  uint          max_monitors() { return _max_monitors; }\n+\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -183,0 +183,1 @@\n+  C->push_monitor();\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -426,0 +426,1 @@\n+    C->push_monitor();\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1981,0 +1981,3 @@\n+                                                                            \\\n+  product(bool, UseFastLocking, false, EXPERIMENTAL,                        \\\n+                \"Use fast-locking instead of stack-locking\")                \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -490,2 +491,3 @@\n-  _SleepEvent(ParkEvent::Allocate(this))\n-{\n+  _SleepEvent(ParkEvent::Allocate(this)),\n+\n+  _lock_stack() {\n@@ -988,0 +990,1 @@\n+  assert(!UseFastLocking, \"should not be called with fast-locking\");\n@@ -1381,0 +1384,4 @@\n+\n+  if (!UseHeavyMonitors && UseFastLocking) {\n+    lock_stack().oops_do(f);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"runtime\/lockStack.hpp\"\n@@ -1143,0 +1144,10 @@\n+private:\n+  LockStack _lock_stack;\n+\n+public:\n+  LockStack& lock_stack() { return _lock_stack; }\n+\n+  static ByteSize lock_stack_current_offset()    { return byte_offset_of(JavaThread, _lock_stack) + LockStack::current_offset(); }\n+  static ByteSize lock_stack_limit_offset()    { return byte_offset_of(JavaThread, _lock_stack) + LockStack::limit_offset(); }\n+\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -0,0 +1,83 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/thread.hpp\"\n+#include \"utilities\/copy.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+LockStack::LockStack() :\n+  _base(UseFastLocking && !UseHeavyMonitors ? _initial : NULL),\n+  _limit(_base + INITIAL_CAPACITY),\n+  _current(_base) {\n+}\n+\n+LockStack::~LockStack() {\n+  if (UseFastLocking && !UseHeavyMonitors) {\n+    if (_base != _initial) {\n+      FREE_C_HEAP_ARRAY(oop, _base);\n+    }\n+  }\n+}\n+\n+#ifndef PRODUCT\n+void LockStack::validate(const char* msg) const {\n+  assert(UseFastLocking && !UseHeavyMonitors, \"never use lock-stack when fast-locking is disabled\");\n+  for (oop* loc1 = _base; loc1 < _current - 1; loc1++) {\n+    for (oop* loc2 = loc1 + 1; loc2 < _current; loc2++) {\n+      assert(*loc1 != *loc2, \"entries must be unique: %s\", msg);\n+    }\n+  }\n+}\n+#endif\n+\n+void LockStack::grow(size_t min_capacity) {\n+  \/\/ Grow stack.\n+  assert(_limit > _base, \"invariant\");\n+  size_t capacity = _limit - _base;\n+  size_t index = _current - _base;\n+  size_t new_capacity = MAX2(min_capacity, capacity * 2);\n+  if (_base == _initial) {\n+    oop* new_stack = NEW_C_HEAP_ARRAY(oop, new_capacity, mtSynchronizer);\n+    for (size_t i = 0; i < index; i++) {\n+      *(new_stack + i) = *(_base + i);\n+    }\n+    _base = new_stack;\n+  } else {\n+    _base = REALLOC_C_HEAP_ARRAY(oop, _base, new_capacity, mtSynchronizer);\n+  }\n+  _limit = _base + new_capacity;\n+  _current = _base + index;\n+  assert(_current < _limit, \"must fit after growing\");\n+  assert((_limit - _base) >= (ptrdiff_t) min_capacity, \"must grow enough\");\n+}\n+\n+void LockStack::ensure_lock_stack_size(oop* required_limit) {\n+  JavaThread* jt = JavaThread::current();\n+  LockStack& lock_stack = jt->lock_stack();\n+  lock_stack.grow(required_limit - lock_stack._base);\n+}\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":83,"deletions":0,"binary":false,"changes":83,"status":"added"},{"patch":"@@ -0,0 +1,68 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_HPP\n+\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/sizes.hpp\"\n+\n+class Thread;\n+class OopClosure;\n+\n+class LockStack {\n+  friend class VMStructs;\n+private:\n+  static const size_t INITIAL_CAPACITY = 4;\n+  oop* _base;\n+  oop* _limit;\n+  oop* _current;\n+  oop _initial[INITIAL_CAPACITY];\n+\n+  void grow(size_t min_capacity);\n+\n+  void validate(const char* msg) const PRODUCT_RETURN;\n+public:\n+  static ByteSize current_offset()    { return byte_offset_of(LockStack, _current); }\n+  static ByteSize base_offset()       { return byte_offset_of(LockStack, _base); }\n+  static ByteSize limit_offset()      { return byte_offset_of(LockStack, _limit); }\n+\n+  static void ensure_lock_stack_size(oop* _required_limit);\n+\n+  LockStack();\n+  ~LockStack();\n+\n+  inline void push(oop o);\n+  inline oop pop();\n+  inline void remove(oop o);\n+\n+  inline bool contains(oop o) const;\n+\n+  \/\/ GC support\n+  inline void oops_do(OopClosure* cl);\n+\n+};\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":68,"deletions":0,"binary":false,"changes":68,"status":"added"},{"patch":"@@ -0,0 +1,94 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+\n+inline void LockStack::push(oop o) {\n+  validate(\"pre-push\");\n+  assert(oopDesc::is_oop(o), \"must be\");\n+  assert(!contains(o), \"entries must be unique\");\n+  if (_current >= _limit) {\n+    grow((_limit - _base) + 1);\n+  }\n+  *_current = o;\n+  _current++;\n+  validate(\"post-push\");\n+}\n+\n+inline oop LockStack::pop() {\n+  validate(\"pre-pop\");\n+  oop* new_loc = _current - 1;\n+  assert(new_loc < _current, \"underflow, probably unbalanced push\/pop\");\n+  _current = new_loc;\n+  oop o = *_current;\n+  assert(!contains(o), \"entries must be unique\");\n+  validate(\"post-pop\");\n+  return o;\n+}\n+\n+inline void LockStack::remove(oop o) {\n+  validate(\"pre-remove\");\n+  assert(contains(o), \"entry must be present\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    if (*loc == o) {\n+      oop* last = _current - 1;\n+      for (; loc < last; loc++) {\n+        *loc = *(loc + 1);\n+      }\n+      _current--;\n+      break;\n+    }\n+  }\n+  assert(!contains(o), \"entries must be unique: \" PTR_FORMAT, p2i(o));\n+  validate(\"post-remove\");\n+}\n+\n+inline bool LockStack::contains(oop o) const {\n+  validate(\"pre-contains\");\n+  bool found = false;\n+  size_t i = 0;\n+  size_t found_i = 0;\n+  for (oop* loc = _current - 1; loc >= _base; loc--) {\n+    if (*loc == o) {\n+      validate(\"post-contains\");\n+      return true;\n+    }\n+  }\n+  validate(\"post-contains\");\n+  return false;\n+}\n+\n+inline void LockStack::oops_do(OopClosure* cl) {\n+  validate(\"pre-oops-do\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    cl->do_oop(loc);\n+  }\n+  validate(\"post-oops-do\");\n+}\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":94,"deletions":0,"binary":false,"changes":94,"status":"added"},{"patch":"@@ -337,1 +337,1 @@\n-  if (current->is_lock_owned((address)cur)) {\n+  if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n@@ -1138,1 +1138,1 @@\n-    if (current->is_lock_owned((address)cur)) {\n+    if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n@@ -1358,1 +1358,1 @@\n-    if (current->is_lock_owned((address)cur)) {\n+    if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n@@ -1407,0 +1407,1 @@\n+  assert(cur != ANONYMOUS_OWNER, \"no anon owner here\");\n@@ -1410,1 +1411,1 @@\n-  if (current->is_lock_owned((address)cur)) {\n+  if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -147,2 +147,10 @@\n-  \/\/ Used by async deflation as a marker in the _owner field:\n-  #define DEFLATER_MARKER reinterpret_cast<void*>(-1)\n+  \/\/ Used by async deflation as a marker in the _owner field.\n+  \/\/ Note that the choice of the two markers is peculiar:\n+  \/\/ - They need to represent values that cannot be pointers. In particular,\n+  \/\/   we achieve this by using the lowest two bits.\n+  \/\/ - ANONYMOUS_OWNER should be a small value, it is used in generated code\n+  \/\/   and small values encode much better.\n+  \/\/ - We test for anonymous owner by testing for the lowest bit, therefore\n+  \/\/   DEFLATER_MARKER must *not* have that bit set.\n+  #define DEFLATER_MARKER reinterpret_cast<void*>(2)\n+  #define ANONYMOUS_OWNER reinterpret_cast<void*>(1)\n@@ -266,0 +274,12 @@\n+  void set_owner_anonymous() {\n+    set_owner_from(NULL, ANONYMOUS_OWNER);\n+  }\n+\n+  bool is_owner_anonymous() const {\n+    return owner_raw() == ANONYMOUS_OWNER;\n+  }\n+\n+  void set_owner_from_anonymous(Thread* owner) {\n+    set_owner_from(ANONYMOUS_OWNER, owner);\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":22,"deletions":2,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -36,3 +37,11 @@\n-  void* owner = owner_raw();\n-  if (current == owner || current->is_lock_owned((address)owner)) {\n-    return 1;\n+  if (UseFastLocking) {\n+    if (is_owner_anonymous()) {\n+      return current->lock_stack().contains(object()) ? 1 : 0;\n+    } else {\n+      return current == owner_raw() ? 1 : 0;\n+    }\n+  } else {\n+    void* owner = owner_raw();\n+    if (current == owner || current->is_lock_owned((address)owner)) {\n+      return 1;\n+    }\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -314,1 +315,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -316,1 +318,1 @@\n-    \/\/ stack-locked by caller so by definition the implied waitset is empty.\n+    \/\/ fast-locked or stack-locked by caller so by definition the implied waitset is empty.\n@@ -388,10 +390,12 @@\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-null so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ stack-locking in the object's header, the second check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    lock->set_displaced_header(markWord::unused_mark());\n+    if (!UseFastLocking) {\n+      \/\/ This Java Monitor is inflated so obj's header will never be\n+      \/\/ displaced to this thread's BasicLock. Make the displaced header\n+      \/\/ non-null so this BasicLock is not seen as recursive nor as\n+      \/\/ being locked. We do this unconditionally so that this thread's\n+      \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n+      \/\/ performance reasons, stack walkers generally first check for\n+      \/\/ stack-locking in the object's header, the second check is for\n+      \/\/ recursive stack-locking in the displaced header in the BasicLock,\n+      \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n+      lock->set_displaced_header(markWord::unused_mark());\n+    }\n@@ -486,6 +490,38 @@\n-    markWord mark = obj->mark();\n-    if (mark.is_neutral()) {\n-      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-      \/\/ be visible <= the ST performed by the CAS.\n-      lock->set_displaced_header(mark);\n-      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+    if (UseFastLocking) {\n+      \/\/ fast-locking does not use the 'lock' parameter.\n+      LockStack& lock_stack = current->lock_stack();\n+\n+      markWord header = obj()->mark_acquire();\n+      while (true) {\n+        if (header.is_neutral()) {\n+          assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+          \/\/ Try to swing into 'fast-locked' state without inflating.\n+          markWord locked_header = header.set_fast_locked();\n+          markWord witness = obj()->cas_set_mark(locked_header, header);\n+          if (witness == header) {\n+            \/\/ Successfully fast-locked, push object to lock-stack and return.\n+            lock_stack.push(obj());\n+            return;\n+          }\n+          \/\/ Otherwise retry.\n+          header = witness;\n+        } else {\n+          \/\/ Fall-through to inflate-enter.\n+          break;\n+        }\n+      }\n+    } else {\n+      markWord mark = obj->mark();\n+      if (mark.is_neutral()) {\n+        \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+        \/\/ be visible <= the ST performed by the CAS.\n+        lock->set_displaced_header(mark);\n+        if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+          return;\n+        }\n+        \/\/ Fall through to inflate() ...\n+      } else if (mark.has_locker() &&\n+                 current->is_lock_owned((address) mark.locker())) {\n+        assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+        assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n+        lock->set_displaced_header(markWord::from_pointer(nullptr));\n@@ -494,8 +530,0 @@\n-      \/\/ Fall through to inflate() ...\n-    } else if (mark.has_locker() &&\n-               current->is_lock_owned((address)mark.locker())) {\n-      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-      assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-      lock->set_displaced_header(markWord::from_pointer(nullptr));\n-      return;\n-    }\n@@ -503,5 +531,6 @@\n-    \/\/ The object header will never be displaced to this lock,\n-    \/\/ so it does not matter what the value is, except that it\n-    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-    \/\/ and must not look locked either.\n-    lock->set_displaced_header(markWord::unused_mark());\n+      \/\/ The object header will never be displaced to this lock,\n+      \/\/ so it does not matter what the value is, except that it\n+      \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+      \/\/ and must not look locked either.\n+      lock->set_displaced_header(markWord::unused_mark());\n+    }\n@@ -509,1 +538,1 @@\n-    guarantee(!obj->mark().has_locker(), \"must not be stack-locked\");\n+    guarantee(!obj->mark().has_locker() && !obj->mark().is_fast_locked(), \"must not be stack-locked or fast-locked\");\n@@ -528,25 +557,15 @@\n-\n-    markWord dhw = lock->displaced_header();\n-    if (dhw.value() == 0) {\n-      \/\/ If the displaced header is null, then this exit matches up with\n-      \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-      if (mark != markWord::INFLATING()) {\n-        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-        \/\/ exiting a recursive enter of a Java Monitor that is being\n-        \/\/ inflated is safe; see the has_monitor() comment below.\n-        assert(!mark.is_neutral(), \"invariant\");\n-        assert(!mark.has_locker() ||\n-        current->is_lock_owned((address)mark.locker()), \"invariant\");\n-        if (mark.has_monitor()) {\n-          \/\/ The BasicLock's displaced_header is marked as a recursive\n-          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-          \/\/ This is a special case where the Java Monitor was inflated\n-          \/\/ after this thread entered the stack-lock recursively. When a\n-          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-          \/\/ Monitor owner's stack and update the BasicLocks because a\n-          \/\/ Java Monitor can be asynchronously inflated by a thread that\n-          \/\/ does not own the Java Monitor.\n-          ObjectMonitor* m = mark.monitor();\n-          assert(m->object()->mark() == mark, \"invariant\");\n-          assert(m->is_entered(current), \"invariant\");\n+    if (UseFastLocking) {\n+      \/\/ fast-locking does not use the 'lock' parameter.\n+      if (mark.is_fast_locked()) {\n+        markWord unlocked_header = mark.set_unlocked();\n+        markWord witness = object->cas_set_mark(unlocked_header, mark);\n+        if (witness != mark) {\n+          \/\/ Another thread won the CAS, it must have inflated the monitor.\n+          \/\/ It can only have installed an anonymously locked monitor at this point.\n+          \/\/ Fetch that monitor, set owner correctly to this thread, and\n+          \/\/ exit it (allowing waiting threads to enter).\n+          assert(witness.has_monitor(), \"must have monitor\");\n+          ObjectMonitor* monitor = witness.monitor();\n+          assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n+          monitor->set_owner_from_anonymous(current);\n+          monitor->exit(current);\n@@ -554,0 +573,3 @@\n+        LockStack& lock_stack = current->lock_stack();\n+        lock_stack.remove(object);\n+        return;\n@@ -555,0 +577,27 @@\n+    } else {\n+      markWord dhw = lock->displaced_header();\n+      if (dhw.value() == 0) {\n+        \/\/ If the displaced header is null, then this exit matches up with\n+        \/\/ a recursive enter. No real work to do here except for diagnostics.\n+#ifndef PRODUCT\n+        if (mark != markWord::INFLATING()) {\n+          \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+          \/\/ exiting a recursive enter of a Java Monitor that is being\n+          \/\/ inflated is safe; see the has_monitor() comment below.\n+          assert(!mark.is_neutral(), \"invariant\");\n+          assert(!mark.has_locker() ||\n+                 current->is_lock_owned((address)mark.locker()), \"invariant\");\n+          if (mark.has_monitor()) {\n+            \/\/ The BasicLock's displaced_header is marked as a recursive\n+            \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+            \/\/ This is a special case where the Java Monitor was inflated\n+            \/\/ after this thread entered the stack-lock recursively. When a\n+            \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+            \/\/ Monitor owner's stack and update the BasicLocks because a\n+            \/\/ Java Monitor can be asynchronously inflated by a thread that\n+            \/\/ does not own the Java Monitor.\n+            ObjectMonitor* m = mark.monitor();\n+            assert(m->object()->mark() == mark, \"invariant\");\n+            assert(m->is_entered(current), \"invariant\");\n+          }\n+        }\n@@ -556,8 +605,0 @@\n-      return;\n-    }\n-\n-    if (mark == markWord::from_pointer(lock)) {\n-      \/\/ If the object is stack-locked by the current thread, try to\n-      \/\/ swing the displaced header from the BasicLock back to the mark.\n-      assert(dhw.is_neutral(), \"invariant\");\n-      if (object->cas_set_mark(dhw, mark) == mark) {\n@@ -566,0 +607,9 @@\n+\n+      if (mark == markWord::from_pointer(lock)) {\n+        \/\/ If the object is stack-locked by the current thread, try to\n+        \/\/ swing the displaced header from the BasicLock back to the mark.\n+        assert(dhw.is_neutral(), \"invariant\");\n+        if (object->cas_set_mark(dhw, mark) == mark) {\n+          return;\n+        }\n+      }\n@@ -575,0 +625,7 @@\n+  if (UseFastLocking && monitor->is_owner_anonymous()) {\n+    \/\/ It must be owned by us. Pop lock object from lock stack.\n+    LockStack& lock_stack = current->lock_stack();\n+    oop popped = lock_stack.pop();\n+    assert(popped == object, \"must be owned by this thread\");\n+    monitor->set_owner_from_anonymous(current);\n+  }\n@@ -701,1 +758,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -716,1 +774,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -744,1 +803,2 @@\n-  if (!mark.is_being_inflated()) {\n+  if (!mark.is_being_inflated() || UseFastLocking) {\n+    \/\/ fast-locking does not use the markWord::INFLATING() protocol.\n@@ -859,0 +919,5 @@\n+static bool is_lock_owned(Thread* thread, oop obj) {\n+  assert(UseFastLocking, \"only call this with fast-locking enabled\");\n+  return thread->is_Java_thread() ? reinterpret_cast<JavaThread*>(thread)->lock_stack().contains(obj) : false;\n+}\n+\n@@ -868,1 +933,1 @@\n-      guarantee(!mark.has_locker(), \"must not be stack locked\");\n+      guarantee(!mark.has_locker(), \"must not be stack-locked\");\n@@ -913,2 +978,9 @@\n-    } else if (current->is_lock_owned((address)mark.locker())) {\n-      \/\/ This is a stack lock owned by the calling thread so fetch the\n+    } else if (mark.is_fast_locked() && is_lock_owned(current, obj)) {\n+      \/\/ This is a fast-lock owned by the calling thread so use the\n+      \/\/ markWord from the object.\n+      hash = mark.hash();\n+      if (hash != 0) {                  \/\/ if it has a hash, just return it\n+        return hash;\n+      }\n+    } else if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ This is a stack-lock owned by the calling thread so fetch the\n@@ -925,1 +997,1 @@\n-      \/\/ So we have to inflate the stack lock into an ObjectMonitor\n+      \/\/ So we have to inflate the stack-lock into an ObjectMonitor\n@@ -978,1 +1050,0 @@\n-  \/\/ Uncontended case, header points to stack\n@@ -980,0 +1051,1 @@\n+    \/\/ stack-locked case, header points into owner's stack\n@@ -982,1 +1054,6 @@\n-  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n+\n+  if (mark.is_fast_locked()) {\n+    \/\/ fast-locking case, see if lock is in current's lock stack\n+    return current->lock_stack().contains(h_obj());\n+  }\n+\n@@ -984,0 +1061,1 @@\n+    \/\/ inflated monitor so header points to ObjectMonitor (tagged pointer).\n@@ -996,2 +1074,0 @@\n-  address owner = nullptr;\n-\n@@ -1000,1 +1076,0 @@\n-  \/\/ Uncontended case, header points to stack\n@@ -1002,1 +1077,9 @@\n-    owner = (address) mark.locker();\n+    \/\/ stack-locked so header points into owner's stack.\n+    \/\/ owning_thread_from_monitor_owner() may also return null here:\n+    return Threads::owning_thread_from_monitor_owner(t_list, (address) mark.locker());\n+  }\n+\n+  if (mark.is_fast_locked()) {\n+    \/\/ fast-locked so get owner from the object.\n+    \/\/ owning_thread_from_object() may also return null here:\n+    return Threads::owning_thread_from_object(t_list, h_obj());\n@@ -1005,2 +1088,2 @@\n-  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n-  else if (mark.has_monitor()) {\n+  if (mark.has_monitor()) {\n+    \/\/ inflated monitor so header points to ObjectMonitor (tagged pointer).\n@@ -1011,6 +1094,2 @@\n-    owner = (address) monitor->owner();\n-  }\n-\n-  if (owner != nullptr) {\n-    \/\/ owning_thread_from_monitor_owner() may also return null here\n-    return Threads::owning_thread_from_monitor_owner(t_list, owner);\n+    \/\/ owning_thread_from_monitor() may also return null here:\n+    return Threads::owning_thread_from_monitor(t_list, monitor);\n@@ -1019,5 +1098,0 @@\n-  \/\/ Unlocked case, header in place\n-  \/\/ Cannot have assertion since this object may have been\n-  \/\/ locked by another thread when reaching here.\n-  \/\/ assert(mark.is_neutral(), \"sanity check\");\n-\n@@ -1030,1 +1104,1 @@\n-\/\/ ObjectMonitors where owner is set to a stack lock address in thread.\n+\/\/ ObjectMonitors where owner is set to a stack-lock address in thread.\n@@ -1040,1 +1114,1 @@\n-      \/\/ is set to a stack lock address in the target thread.\n+      \/\/ is set to a stack-lock address in the target thread.\n@@ -1066,1 +1140,1 @@\n-    \/\/ Owner set to a stack lock address in thread should never be seen here:\n+    \/\/ Owner set to a stack-lock address in thread should never be seen here:\n@@ -1211,4 +1285,11 @@\n-    \/\/ *  Inflated     - just return\n-    \/\/ *  Stack-locked - coerce it to inflated\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n-    \/\/ *  Neutral      - aggressively inflate the object.\n+    \/\/ *  inflated     - Just return if using stack-locking.\n+    \/\/                   If using fast-locking and the ObjectMonitor owner\n+    \/\/                   is anonymous and the current thread owns the\n+    \/\/                   object lock, then we make the current thread the\n+    \/\/                   ObjectMonitor owner and remove the lock from the\n+    \/\/                   current thread's lock stack.\n+    \/\/ *  fast-locked  - Coerce it to inflated from fast-locked.\n+    \/\/ *  stack-locked - Coerce it to inflated from stack-locked.\n+    \/\/ *  INFLATING    - Busy wait for conversion from stack-locked to\n+    \/\/                   inflated.\n+    \/\/ *  neutral      - Aggressively inflate the object.\n@@ -1221,0 +1302,5 @@\n+      if (UseFastLocking && inf->is_owner_anonymous() && is_lock_owned(current, object)) {\n+        inf->set_owner_from_anonymous(current);\n+        assert(current->is_Java_thread(), \"must be Java thread\");\n+        reinterpret_cast<JavaThread*>(current)->lock_stack().remove(object);\n+      }\n@@ -1224,9 +1310,66 @@\n-    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-    \/\/ Some other thread is converting from stack-locked to inflated.\n-    \/\/ Only that thread can complete inflation -- other threads must wait.\n-    \/\/ The INFLATING value is transient.\n-    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-    if (mark == markWord::INFLATING()) {\n-      read_stable_mark(object);\n-      continue;\n+    if (!UseFastLocking) {\n+      \/\/ Fast-locking does not use INFLATING.\n+      \/\/ CASE: inflation in progress - inflating over a stack-lock.\n+      \/\/ Some other thread is converting from stack-locked to inflated.\n+      \/\/ Only that thread can complete inflation -- other threads must wait.\n+      \/\/ The INFLATING value is transient.\n+      \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n+      \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n+      if (mark == markWord::INFLATING()) {\n+        read_stable_mark(object);\n+        continue;\n+      }\n+    }\n+\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by current or by some other thread.\n+    \/\/\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_\n+    \/\/ attempting to set the object's mark to the new ObjectMonitor. If\n+    \/\/ this thread owns the monitor, then we set the ObjectMonitor's\n+    \/\/ owner to this thread. Otherwise, we set the ObjectMonitor's owner\n+    \/\/ to anonymous. If we lose the race to set the object's mark to the\n+    \/\/ new ObjectMonitor, then we just delete it and loop around again.\n+    \/\/\n+    LogStreamHandle(Trace, monitorinflation) lsh;\n+    if (mark.is_fast_locked()) {\n+      assert(UseFastLocking, \"can only happen with fast-locking\");\n+      ObjectMonitor* monitor = new ObjectMonitor(object);\n+      monitor->set_header(mark.set_unlocked());\n+      bool own = is_lock_owned(current, object);\n+      if (own) {\n+        \/\/ Owned by us.\n+        monitor->set_owner_from(NULL, current);\n+      } else {\n+        \/\/ Owned by somebody else.\n+        monitor->set_owner_anonymous();\n+      }\n+      markWord monitor_mark = markWord::encode(monitor);\n+      markWord witness = object->cas_set_mark(monitor_mark, mark);\n+      if (witness == mark) {\n+        \/\/ Success! Return inflated monitor.\n+        if (own) {\n+          assert(current->is_Java_thread(), \"must be: checked in is_lock_owned()\");\n+          reinterpret_cast<JavaThread*>(current)->lock_stack().remove(object);\n+        }\n+        \/\/ Once the ObjectMonitor is configured and object is associated\n+        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+        _in_use_list.add(monitor);\n+\n+        \/\/ Hopefully the performance counters are allocated on distinct\n+        \/\/ cache lines to avoid false sharing on MP systems ...\n+        OM_PERFDATA_OP(Inflations, inc());\n+        if (log_is_enabled(Trace, monitorinflation)) {\n+          ResourceMark rm(current);\n+          lsh.print_cr(\"inflate(fast-locked): object=\" INTPTR_FORMAT \", mark=\"\n+                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                       object->mark().value(), object->klass()->external_name());\n+        }\n+        if (event.should_commit()) {\n+          post_monitor_inflate_event(&event, object, cause);\n+        }\n+        return monitor;\n+      } else {\n+        delete monitor;\n+        continue;  \/\/ Interference -- just retry\n+      }\n@@ -1236,1 +1379,1 @@\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    \/\/ Could be stack-locked either by current or by some other thread.\n@@ -1243,4 +1386,3 @@\n-    \/\/ the odds of inflation contention.\n-\n-    LogStreamHandle(Trace, monitorinflation) lsh;\n-\n+    \/\/ the odds of inflation contention. If we lose the race to set INFLATING,\n+    \/\/ then we just delete the ObjectMonitor and loop around again.\n+    \/\/\n@@ -1248,0 +1390,1 @@\n+      assert(!UseFastLocking, \"cannot happen with fast-locking\");\n@@ -1409,2 +1552,2 @@\n-\/\/ is set to a stack lock address are NOT associated with the JavaThread\n-\/\/ that holds that stack lock. All of the current consumers of\n+\/\/ is set to a stack-lock address are NOT associated with the JavaThread\n+\/\/ that holds that stack-lock. All of the current consumers of\n@@ -1412,1 +1555,1 @@\n-\/\/ those do not have the owner set to a stack lock address.\n+\/\/ those do not have the owner set to a stack-lock address.\n@@ -1429,1 +1572,1 @@\n-      \/\/ not include when owner is set to a stack lock address in thread.\n+      \/\/ not include when owner is set to a stack-lock address in thread.\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":259,"deletions":116,"binary":false,"changes":375,"status":"modified"},{"patch":"@@ -536,0 +536,1 @@\n+  assert(!UseFastLocking, \"should not be called with fast-locking\");\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -1391,0 +1392,1 @@\n+  assert(!UseFastLocking, \"only with stack-locking\");\n@@ -1420,0 +1422,10 @@\n+JavaThread* Threads::owning_thread_from_object(ThreadsList * t_list, oop obj) {\n+  assert(UseFastLocking, \"Only with fast-locking\");\n+  for (JavaThread* q : *t_list) {\n+    if (q->lock_stack().contains(obj)) {\n+      return q;\n+    }\n+  }\n+  return NULL;\n+}\n+\n@@ -1421,2 +1433,12 @@\n-  address owner = (address)monitor->owner();\n-  return owning_thread_from_monitor_owner(t_list, owner);\n+  if (UseFastLocking) {\n+    if (monitor->is_owner_anonymous()) {\n+      return owning_thread_from_object(t_list, monitor->object());\n+    } else {\n+      Thread* owner = reinterpret_cast<Thread*>(monitor->owner());\n+      assert(owner == NULL || owner->is_Java_thread(), \"only JavaThreads own monitors\");\n+      return reinterpret_cast<JavaThread*>(owner);\n+    }\n+  } else {\n+    address owner = (address)monitor->owner();\n+    return owning_thread_from_monitor_owner(t_list, owner);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":24,"deletions":2,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -141,0 +141,1 @@\n+  static JavaThread* owning_thread_from_object(ThreadsList* t_list, oop obj);\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -702,0 +702,3 @@\n+  nonstatic_field(JavaThread,                  _lock_stack,                                   LockStack)                             \\\n+  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n+  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n@@ -1315,0 +1318,1 @@\n+  declare_toplevel_type(LockStack)                                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -47,0 +47,2 @@\n+  private static long          lockStackCurrentOffset;\n+  private static long          lockStackBaseOffset;\n@@ -56,0 +58,1 @@\n+  private static long oopPtrSize;\n@@ -88,0 +91,1 @@\n+    Type typeLockStack = db.lookupType(\"LockStack\");\n@@ -101,0 +105,4 @@\n+    lockStackCurrentOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_current\").getOffset();\n+    lockStackBaseOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base\").getOffset();\n+    oopPtrSize = VM.getVM().getAddressSize();\n+\n@@ -397,0 +405,13 @@\n+  public boolean isLockOwned(OopHandle obj) {\n+    Address current = addr.getAddressAt(lockStackCurrentOffset);\n+    Address base = addr.getAddressAt(lockStackBaseOffset);\n+    while (base.lessThan(current)) {\n+        Address oop = base.getAddressAt(0);\n+        if (oop.equals(obj)) {\n+            return true;\n+        }\n+        base = base.addOffsetTo(oopPtrSize);\n+    }\n+    return false;\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+          mark.monitor().isOwnedAnonymous() ||\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaVFrame.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -82,0 +82,4 @@\n+  public boolean isOwnedAnonymous() {\n+    return addr.getAddressAt(ownerFieldOffset).asLongValue() == 1;\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -213,0 +213,1 @@\n+        assert(!VM.getVM().getCommandLineBooleanFlag(\"UseFastLocking\"));\n@@ -230,1 +231,18 @@\n-        return owningThreadFromMonitor(monitor.owner());\n+        if (VM.getVM().getCommandLineBooleanFlag(\"UseFastLocking\")) {\n+            if (monitor.isOwnedAnonymous()) {\n+                OopHandle object = monitor.object();\n+                for (int i = 0; i < getNumberOfThreads(); i++) {\n+                    JavaThread thread = getJavaThreadAt(i);\n+                    if (thread.isLockOwned(object)) {\n+                        return thread;\n+                     }\n+                }\n+                throw new InternalError(\"We should have found a thread that owns the anonymous lock\");\n+            }\n+            \/\/ Owner can only be threads at this point.\n+            Address o = monitor.owner();\n+            if (o == null) return null;\n+            return new JavaThread(o);\n+        } else {\n+            return owningThreadFromMonitor(monitor.owner());\n+        }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"}]}