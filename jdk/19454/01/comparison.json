{"files":[{"patch":"@@ -153,0 +153,1 @@\n+  Register owner_addr = tmpReg;\n@@ -157,0 +158,1 @@\n+  Label unlocked;\n@@ -207,0 +209,10 @@\n+\n+  \/\/ Compute owner address.\n+  lea(owner_addr, Address(tmp, ObjectMonitor::owner_offset()));\n+\n+  \/\/ Set owner to null.\n+  \/\/ Release to satisfy the JMM\n+  stlr(zr, owner_addr);\n+  membar(StoreLoad);\n+\n+  \/\/ Check if the entry lists are empty.\n@@ -208,7 +220,21 @@\n-  ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset()));\n-  orr(rscratch1, rscratch1, disp_hdr); \/\/ Will be 0 if both are 0.\n-  cmp(rscratch1, zr); \/\/ Sets flags for result\n-  cbnz(rscratch1, cont);\n-  \/\/ need a release store here\n-  lea(tmp, Address(tmp, ObjectMonitor::owner_offset()));\n-  stlr(zr, tmp); \/\/ set unowned\n+  ldr(tmpReg, Address(tmp, ObjectMonitor::cxq_offset()));\n+  orr(rscratch1, rscratch1, tmpReg);\n+  cmp(rscratch1, zr);\n+  br(Assembler::EQ, cont);     \/\/ If so we are done.\n+\n+  \/\/ Check if there is a successor.\n+  ldr(rscratch1, Address(tmp, ObjectMonitor::succ_offset()));\n+  cmp(rscratch1, zr);\n+  br(Assembler::NE, unlocked); \/\/ If so we are done.\n+\n+  \/\/ Save the monitor pointer in the current thread, so we can try to\n+  \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+  str(tmp, Address(rthread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+  cmp(zr, rthread); \/\/ Set Flag to NE => slow path\n+  b(cont);\n+\n+  bind(unlocked);\n+  cmp(zr, zr); \/\/ Set Flag to EQ => fast path\n+\n+  \/\/ Intentional fall-through\n@@ -501,1 +527,0 @@\n-    Label release;\n@@ -507,0 +532,5 @@\n+    \/\/ Set owner to null.\n+    \/\/ Release to satisfy the JMM\n+    stlr(zr, t2_owner_addr);\n+    membar(StoreLoad);\n+\n@@ -512,1 +542,1 @@\n-    br(Assembler::EQ, release);\n+    br(Assembler::EQ, unlocked);  \/\/ If so we are done.\n@@ -514,5 +544,4 @@\n-    \/\/ The owner may be anonymous and we removed the last obj entry in\n-    \/\/ the lock-stack. This loses the information about the owner.\n-    \/\/ Write the thread to the owner field so the runtime knows the owner.\n-    str(rthread, Address(t2_owner_addr));\n-    b(slow_path);\n+    \/\/ Check if there is a successor.\n+    ldr(rscratch1, Address(t1_monitor, ObjectMonitor::succ_offset()));\n+    cmp(rscratch1, zr);\n+    br(Assembler::NE, unlocked);  \/\/ If so we are done.\n@@ -520,4 +549,6 @@\n-    bind(release);\n-    \/\/ Set owner to null.\n-    \/\/ Release to satisfy the JMM\n-    stlr(zr, t2_owner_addr);\n+    \/\/ Save the monitor pointer in the current thread, so we can try to\n+    \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+    str(t1_monitor, Address(rthread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+    cmp(zr, rthread); \/\/ Set Flag to NE => slow path\n+    b(slow_path);\n@@ -528,0 +559,1 @@\n+  cmp(zr, zr); \/\/ Set Flags to EQ => fast path\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":50,"deletions":18,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -2665,1 +2665,1 @@\n-  Label success, failure, object_has_monitor, notRecursive;\n+  Label success, unlocked, failure, object_has_monitor, notRecursive;\n@@ -2726,5 +2726,3 @@\n-  ld(temp,             in_bytes(ObjectMonitor::EntryList_offset()), current_header);\n-  ld(displaced_header, in_bytes(ObjectMonitor::cxq_offset()), current_header);\n-  orr(temp, temp, displaced_header); \/\/ Will be 0 if both are 0.\n-  cmpdi(flag, temp, 0);\n-  bne(flag, failure);\n+  const Register temp2 = displaced_header;\n+\n+  \/\/ Set owner to null.\n@@ -2732,0 +2730,1 @@\n+  li(temp, 0);\n@@ -2733,0 +2732,23 @@\n+  membar(StoreLoad);\n+\n+  \/\/ Check if the entry lists are empty.\n+  ld(temp, in_bytes(ObjectMonitor::EntryList_offset()), current_header);\n+  ld(temp2, in_bytes(ObjectMonitor::cxq_offset()), current_header);\n+  orr(temp, temp, temp2);\n+  cmpdi(flag, temp, 0);\n+  beq(flag, success);  \/\/ If so we are done.\n+\n+  \/\/ Check if there is a successor.\n+  ld(temp, in_bytes(ObjectMonitor::succ_offset()), current_header);\n+  cmpdi(flag, temp, 0);\n+  bne(flag, success);  \/\/ If so we are done.\n+\n+  \/\/ Save the monitor pointer in the current thread, so we can try\n+  \/\/ to reacquire the lock in SharedRuntime::monitor_exit_helper().\n+  std(current_header, in_bytes(JavaThread::unlocked_inflated_monitor_offset()), R16_thread);\n+\n+  crxor(flag, Assembler::equal, flag, Assembler::equal); \/\/ Set flag = NE => slow path\n+  b(failure);\n+\n+  bind(unlocked);\n+  crorc(flag, Assembler::equal, flag, Assembler::equal); \/\/ Set flag = EQ => fast path\n@@ -2981,2 +3003,5 @@\n-      Label release_;\n-      const Register t2 = tmp2;\n+      \/\/ Set owner to null.\n+      release();\n+      li(t, 0);\n+      std(t, in_bytes(ObjectMonitor::owner_offset()), monitor);\n+      membar(StoreLoad);\n@@ -2986,2 +3011,2 @@\n-      ld(t2, in_bytes(ObjectMonitor::cxq_offset()), monitor);\n-      orr(t, t, t2);\n+      ld(tmp2, in_bytes(ObjectMonitor::cxq_offset()), monitor);\n+      orr(t, t, tmp2);\n@@ -2989,1 +3014,1 @@\n-      beq(flag, release_);\n+      beq(flag, unlocked); \/\/ If so we are done.\n@@ -2991,5 +3016,4 @@\n-      \/\/ The owner may be anonymous and we removed the last obj entry in\n-      \/\/ the lock-stack. This loses the information about the owner.\n-      \/\/ Write the thread to the owner field so the runtime knows the owner.\n-      std(R16_thread, in_bytes(ObjectMonitor::owner_offset()), monitor);\n-      b(slow_path);\n+      \/\/ Check if there is a successor.\n+      ld(t, in_bytes(ObjectMonitor::succ_offset()), monitor);\n+      cmpdi(flag, t, 0);\n+      bne(flag, unlocked); \/\/ If so we are done.\n@@ -2997,5 +3021,6 @@\n-      bind(release_);\n-      \/\/ Set owner to null.\n-      release();\n-      \/\/ t contains 0\n-      std(t, in_bytes(ObjectMonitor::owner_offset()), monitor);\n+      \/\/ Save the monitor pointer in the current thread, so we can try\n+      \/\/ to reacquire the lock in SharedRuntime::monitor_exit_helper().\n+      std(monitor, in_bytes(JavaThread::unlocked_inflated_monitor_offset()), R16_thread);\n+\n+      crxor(flag, Assembler::equal, flag, Assembler::equal); \/\/ Set flag = NE => slow path\n+      b(slow_path);\n@@ -3012,0 +3037,1 @@\n+  crorc(flag, Assembler::equal, flag, Assembler::equal); \/\/ Set flag = EQ => fast path\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":47,"deletions":21,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -168,0 +168,1 @@\n+  Register owner_addr = tmp1Reg;\n@@ -225,4 +226,2 @@\n-  ld(t0, Address(tmp, ObjectMonitor::EntryList_offset()));\n-  ld(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset()));\n-  orr(t0, t0, disp_hdr); \/\/ Will be 0 if both are 0.\n-  bnez(t0, slow_path);\n+  \/\/ Compute owner address.\n+  la(owner_addr, Address(tmp, ObjectMonitor::owner_offset()));\n@@ -230,2 +229,1 @@\n-  \/\/ need a release store here\n-  la(tmp, Address(tmp, ObjectMonitor::owner_offset()));\n+  \/\/ Set owner to null.\n@@ -233,1 +231,19 @@\n-  sd(zr, Address(tmp)); \/\/ set unowned\n+  sd(zr, Address(owner_addr));\n+  membar(StoreLoad);\n+\n+  \/\/ Check if the entry lists are empty.\n+  ld(t0, Address(tmp, ObjectMonitor::EntryList_offset()));\n+  ld(tmp1Reg, Address(tmp, ObjectMonitor::cxq_offset()));\n+  orr(t0, t0, tmp1Reg);\n+  beqz(t0, unlocked); \/\/ If so we are done.\n+\n+  \/\/ Check if there is a successor.\n+  ld(t0, Address(tmp, ObjectMonitor::succ_offset()));\n+  bnez(t0, unlocked); \/\/ If so we are done.\n+\n+  \/\/ Save the monitor pointer in the current thread, so we can try to\n+  \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+  sd(tmp, Address(xthread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+  mv(flag, 1);\n+  j(slow_path);\n@@ -537,1 +553,0 @@\n-    Label release;\n@@ -543,0 +558,5 @@\n+    \/\/ Set owner to null.\n+    membar(MacroAssembler::LoadStore | MacroAssembler::StoreStore);\n+    sd(zr, Address(tmp2_owner_addr));\n+    membar(StoreLoad);\n+\n@@ -547,1 +567,1 @@\n-    beqz(t0, release);\n+    beqz(t0, unlocked); \/\/ If so we are done.\n@@ -549,5 +569,3 @@\n-    \/\/ The owner may be anonymous and we removed the last obj entry in\n-    \/\/ the lock-stack. This loses the information about the owner.\n-    \/\/ Write the thread to the owner field so the runtime knows the owner.\n-    sd(xthread, Address(tmp2_owner_addr));\n-    j(slow_path);\n+    \/\/ Check if there is a successor.\n+    ld(tmp3_t, Address(tmp1_monitor, ObjectMonitor::succ_offset()));\n+    bnez(tmp3_t, unlocked); \/\/ If so we are done.\n@@ -555,4 +573,6 @@\n-    bind(release);\n-    \/\/ Set owner to null.\n-    membar(MacroAssembler::LoadStore | MacroAssembler::StoreStore);\n-    sd(zr, Address(tmp2_owner_addr));\n+    \/\/ Save the monitor pointer in the current thread, so we can try\n+    \/\/ to reacquire the lock in SharedRuntime::monitor_exit_helper().\n+    sd(tmp1_monitor, Address(xthread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+    mv(flag, 1);\n+    j(slow_path);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":38,"deletions":18,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -3660,0 +3660,9 @@\n+  NearLabel check_succ, set_eq_unlocked;\n+\n+  \/\/ Set owner to null.\n+  z_release();\n+  z_lghi(temp, 0);\n+  z_stg(temp, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), currentHeader);\n+  z_fence(); \/\/ membar(StoreLoad);\n+\n+  \/\/ Check if the entry lists are empty.\n@@ -3661,1 +3670,1 @@\n-  z_brne(done);\n+  z_brne(check_succ);\n@@ -3663,3 +3672,18 @@\n-  z_brne(done);\n-  z_release();\n-  z_stg(temp\/*=0*\/, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), currentHeader);\n+  z_bre(done); \/\/ If so we are done.\n+\n+  bind(check_succ);\n+\n+  \/\/ Check if there is a successor.\n+  load_and_test_long(temp, Address(currentHeader, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)));\n+  z_brne(set_eq_unlocked); \/\/ If so we are done.\n+\n+  \/\/ Save the monitor pointer in the current thread, so we can try to\n+  \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+  z_xilf(currentHeader, markWord::monitor_value);\n+  z_stg(currentHeader, Address(Z_thread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+  z_cr(currentHeader, Z_thread); \/\/ Set flag = NE\n+  z_bru(done);\n+\n+  bind(set_eq_unlocked);\n+  z_cr(temp, temp); \/\/ Set flag = EQ\n@@ -6398,1 +6422,8 @@\n-      NearLabel not_ok;\n+      NearLabel check_succ, set_eq_unlocked;\n+\n+      \/\/ Set owner to null.\n+      z_release();\n+      z_lghi(tmp2, 0);\n+      z_stg(tmp2, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), monitor);\n+      z_fence(); \/\/ membar(StoreLoad);\n+\n@@ -6401,1 +6432,1 @@\n-      z_brne(not_ok);\n+      z_brne(check_succ);\n@@ -6403,1 +6434,1 @@\n-      z_brne(not_ok);\n+      z_bre(unlocked); \/\/ If so we are done.\n@@ -6405,2 +6436,1 @@\n-      z_release();\n-      z_stg(tmp2 \/*=0*\/, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), monitor);\n+      bind(check_succ);\n@@ -6408,1 +6438,3 @@\n-      z_bru(unlocked); \/\/ CC = EQ here\n+      \/\/ Check if there is a successor.\n+      load_and_test_long(tmp2, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)));\n+      z_brne(set_eq_unlocked); \/\/ If so we are done.\n@@ -6410,1 +6442,7 @@\n-      bind(not_ok);\n+      \/\/ Save the monitor pointer in the current thread, so we can try to\n+      \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+      z_xilf(monitor, markWord::monitor_value);\n+      z_stg(monitor, Address(Z_thread, JavaThread::unlocked_inflated_monitor_offset()));\n+\n+      z_ltgr(obj, obj); \/\/ Set flag = NE\n+      z_bru(slow_path);\n@@ -6412,5 +6450,2 @@\n-      \/\/ The owner may be anonymous, and we removed the last obj entry in\n-      \/\/ the lock-stack. This loses the information about the owner.\n-      \/\/ Write the thread to the owner field so the runtime knows the owner.\n-      z_stg(Z_thread, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner), monitor);\n-      z_bru(slow_path); \/\/ CC = NE here\n+      bind(set_eq_unlocked);\n+      z_cr(tmp2, tmp2); \/\/ Set flag = EQ\n","filename":"src\/hotspot\/cpu\/s390\/macroAssembler_s390.cpp","additions":51,"deletions":16,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -83,2 +83,0 @@\n-  Label restore_held_monitor_count_and_slow_path;\n-\n@@ -94,9 +92,1 @@\n-  }\n-\n-  { \/\/ Restore held monitor count and slow path.\n-\n-    __ bind(restore_held_monitor_count_and_slow_path);\n-    __ bind(_slow_path);\n-    \/\/ Restore held monitor count.\n-    __ increment(Address(_thread, JavaThread::held_monitor_count_offset()));\n-    \/\/ increment will always result in ZF = 0 (no overflows).\n+    \/\/ addl will always result in ZF = 0 (no overflows).\n@@ -105,44 +95,0 @@\n-\n-  { \/\/ Handle monitor medium path.\n-\n-    __ bind(_check_successor);\n-\n-    Label fix_zf_and_unlocked;\n-    const Register monitor = _mark;\n-\n-#ifndef _LP64\n-    __ jmpb(restore_held_monitor_count_and_slow_path);\n-#else \/\/ _LP64\n-    const ByteSize monitor_tag = in_ByteSize(UseObjectMonitorTable ? 0 : checked_cast<int>(markWord::monitor_value));\n-    const Address succ_address(monitor, ObjectMonitor::succ_offset() - monitor_tag);\n-    const Address owner_address(monitor, ObjectMonitor::owner_offset() - monitor_tag);\n-\n-    \/\/ successor null check.\n-    __ cmpptr(succ_address, NULL_WORD);\n-    __ jccb(Assembler::equal, restore_held_monitor_count_and_slow_path);\n-\n-    \/\/ Release lock.\n-    __ movptr(owner_address, NULL_WORD);\n-\n-    \/\/ Fence.\n-    \/\/ Instead of MFENCE we use a dummy locked add of 0 to the top-of-stack.\n-    __ lock(); __ addl(Address(rsp, 0), 0);\n-\n-    \/\/ Recheck successor.\n-    __ cmpptr(succ_address, NULL_WORD);\n-    \/\/ Observed a successor after the release -> fence we have handed off the monitor\n-    __ jccb(Assembler::notEqual, fix_zf_and_unlocked);\n-\n-    \/\/ Try to relock, if it fails the monitor has been handed over\n-    \/\/ TODO: Caveat, this may fail due to deflation, which does\n-    \/\/       not handle the monitor handoff. Currently only works\n-    \/\/       due to the responsible thread.\n-    __ xorptr(rax, rax);\n-    __ lock(); __ cmpxchgptr(_thread, owner_address);\n-    __ jccb  (Assembler::equal, restore_held_monitor_count_and_slow_path);\n-#endif\n-\n-    __ bind(fix_zf_and_unlocked);\n-    __ xorl(rax, rax);\n-    __ jmp(unlocked_continuation());\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":1,"deletions":55,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -463,16 +463,1 @@\n-#ifndef _LP64\n-  \/\/ Note that we could employ various encoding schemes to reduce\n-  \/\/ the number of loads below (currently 4) to just 2 or 3.\n-  \/\/ Refer to the comments in synchronizer.cpp.\n-  \/\/ In practice the chain of fetches doesn't seem to impact performance, however.\n-  xorptr(boxReg, boxReg);\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n-  jccb  (Assembler::notZero, DONE_LABEL);\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  jccb  (Assembler::notZero, DONE_LABEL);\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n-  jmpb  (DONE_LABEL);\n-#else \/\/ _LP64\n-  \/\/ It's inflated\n-  Label CheckSucc, LNotRecursive, LSuccess, LGoSlowPath;\n+  Label LSuccess, LNotRecursive;\n@@ -484,1 +469,1 @@\n-  decq(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  decrement(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -488,4 +473,2 @@\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-  jccb  (Assembler::notZero, CheckSucc);\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n+\n+  \/\/ Release lock.\n@@ -493,1 +476,1 @@\n-  jmpb  (DONE_LABEL);\n+  membar(StoreLoad);\n@@ -495,2 +478,4 @@\n-  \/\/ Try to avoid passing control into the slow_path ...\n-  bind  (CheckSucc);\n+  \/\/ Check if the entry lists are empty.\n+  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  jccb(Assembler::zero, LSuccess);    \/\/ If so we are done.\n@@ -498,4 +483,1 @@\n-  \/\/ The following optional optimization can be elided if necessary\n-  \/\/ Effectively: if (succ == null) goto slow path\n-  \/\/ The code reduces the window for a race, however,\n-  \/\/ and thus benefits performance.\n+  \/\/ Check if there is a successor.\n@@ -503,5 +485,1 @@\n-  jccb  (Assembler::zero, LGoSlowPath);\n-\n-  xorptr(boxReg, boxReg);\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+  jccb(Assembler::notZero, LSuccess); \/\/ If so we are done.\n@@ -509,8 +487,9 @@\n-  \/\/ Memory barrier\/fence\n-  \/\/ Dekker pivot point -- fulcrum : ST Owner; MEMBAR; LD Succ\n-  \/\/ Instead of MFENCE we use a dummy locked add of 0 to the top-of-stack.\n-  \/\/ This is faster on Nehalem and AMD Shanghai\/Barcelona.\n-  \/\/ See https:\/\/blogs.oracle.com\/dave\/entry\/instruction_selection_for_volatile_fences\n-  \/\/ We might also restructure (ST Owner=0;barrier;LD _Succ) to\n-  \/\/ (mov box,0; xchgq box, &m->Owner; LD _succ) .\n-  lock(); addl(Address(rsp, 0), 0);\n+  \/\/ Save the monitor pointer in the current thread, so we can try to\n+  \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+  andptr(tmpReg, ~(int32_t)markWord::monitor_value);\n+#ifndef _LP64\n+  get_thread(boxReg);\n+  movptr(Address(boxReg, JavaThread::unlocked_inflated_monitor_offset()), tmpReg);\n+#else \/\/ _LP64\n+  movptr(Address(r15_thread, JavaThread::unlocked_inflated_monitor_offset()), tmpReg);\n+#endif\n@@ -518,23 +497,0 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), NULL_WORD);\n-  jccb  (Assembler::notZero, LSuccess);\n-\n-  \/\/ Rare inopportune interleaving - race.\n-  \/\/ The successor vanished in the small window above.\n-  \/\/ The lock is contended -- (cxq|EntryList) != null -- and there's no apparent successor.\n-  \/\/ We need to ensure progress and succession.\n-  \/\/ Try to reacquire the lock.\n-  \/\/ If that fails then the new owner is responsible for succession and this\n-  \/\/ thread needs to take no further action and can exit via the fast path (success).\n-  \/\/ If the re-acquire succeeds then pass control into the slow path.\n-  \/\/ As implemented, this latter mode is horrible because we generated more\n-  \/\/ coherence traffic on the lock *and* artificially extended the critical section\n-  \/\/ length while by virtue of passing control into the slow path.\n-\n-  \/\/ box is really RAX -- the following CMPXCHG depends on that binding\n-  \/\/ cmpxchg R,[M] is equivalent to rax = CAS(M,rax,R)\n-  lock();\n-  cmpxchgptr(r15_thread, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  \/\/ There's no successor so we tried to regrab the lock.\n-  \/\/ If that didn't work, then another thread grabbed the\n-  \/\/ lock so we're done (and exit was a success).\n-  jccb  (Assembler::notEqual, LSuccess);\n@@ -543,1 +499,0 @@\n-  bind  (LGoSlowPath);\n@@ -551,1 +506,0 @@\n-#endif\n@@ -749,4 +703,1 @@\n-  Label unlocked;\n-\n-  \/\/ Assume success.\n-  decrement(Address(thread, JavaThread::held_monitor_count_offset()));\n+  Label unlocked, slow_path;\n@@ -768,2 +719,0 @@\n-  Label& check_successor = stub == nullptr ? dummy : stub->check_successor();\n-  Label& slow_path = stub == nullptr ? dummy : stub->slow_path();\n@@ -844,0 +793,1 @@\n+    const Address succ_address{monitor, ObjectMonitor::succ_offset() - monitor_tag};\n@@ -851,1 +801,5 @@\n-    jccb(Assembler::notEqual, recursive);\n+    jccb(Assembler::notZero, recursive);\n+\n+    \/\/ Release lock.\n+    movptr(owner_address, NULL_WORD);\n+    membar(StoreLoad);\n@@ -856,1 +810,1 @@\n-    jcc(Assembler::notZero, check_successor);\n+    jccb(Assembler::zero, unlocked);    \/\/ If so we are done.\n@@ -858,3 +812,13 @@\n-    \/\/ Release lock.\n-    movptr(owner_address, NULL_WORD);\n-    jmpb(unlocked);\n+    \/\/ Check if there is a successor.\n+    cmpptr(succ_address, NULL_WORD);\n+    jccb(Assembler::notZero, unlocked); \/\/ If so we are done.\n+\n+    \/\/ Save the monitor pointer in the current thread, so we can try to\n+    \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n+    if (!UseObjectMonitorTable) {\n+      andptr(monitor, ~(int32_t)markWord::monitor_value);\n+    }\n+    movptr(Address(thread, JavaThread::unlocked_inflated_monitor_offset()), monitor);\n+\n+    testl(monitor, monitor);            \/\/ Fast Unlock ZF = 0\n+    jmpb(slow_path);\n@@ -865,1 +829,0 @@\n-    xorl(t, t);\n@@ -869,3 +832,2 @@\n-  if (stub != nullptr) {\n-    bind(stub->unlocked_continuation());\n-  }\n+  decrement(Address(thread, JavaThread::held_monitor_count_offset()));\n+  xorl(t, t); \/\/ Fast Unlock ZF = 1\n@@ -880,0 +842,1 @@\n+  bind(slow_path);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":44,"deletions":81,"binary":false,"changes":125,"status":"modified"},{"patch":"@@ -108,1 +108,0 @@\n-  Label _check_successor;\n@@ -117,1 +116,0 @@\n-  Label& check_successor() { return _check_successor; }\n","filename":"src\/hotspot\/share\/opto\/c2_CodeStubs.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -490,0 +490,1 @@\n+  _unlocked_inflated_monitor(nullptr),\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -467,0 +467,1 @@\n+  ObjectMonitor* _unlocked_inflated_monitor;\n@@ -618,0 +619,6 @@\n+  \/\/ Support for SharedRuntime::monitor_exit_helper()\n+  ObjectMonitor* unlocked_inflated_monitor() const { return _unlocked_inflated_monitor; }\n+  void clear_unlocked_inflated_monitor() {\n+    _unlocked_inflated_monitor = nullptr;\n+  }\n+\n@@ -831,0 +838,1 @@\n+  static ByteSize unlocked_inflated_monitor_offset() { return byte_offset_of(JavaThread, _unlocked_inflated_monitor); }\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -714,1 +714,1 @@\n-  assert(!mark.is_unlocked(), \"must be\");\n+  assert(mark.is_locked(), \"must be\");\n","filename":"src\/hotspot\/share\/runtime\/lightweightSynchronizer.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -181,1 +181,1 @@\n-\/\/   a singly-linked LIFO.  We drain _cxq into EntryList  at unlock-time when\n+\/\/   a singly-linked LIFO.  We drain _cxq into EntryList at unlock-time when\n@@ -213,13 +213,0 @@\n-\/\/\n-\/\/ * An interesting alternative is to encode cxq as (List,LockByte) where\n-\/\/   the LockByte is 0 iff the monitor is owned.  _owner is simply an auxiliary\n-\/\/   variable, like _recursions, in the scheme.  The threads or Events that form\n-\/\/   the list would have to be aligned in 256-byte addresses.  A thread would\n-\/\/   try to acquire the lock or enqueue itself with CAS, but exiting threads\n-\/\/   could use a 1-0 protocol and simply STB to set the LockByte to 0.\n-\/\/   Note that is is *not* word-tearing, but it does presume that full-word\n-\/\/   CAS operations are coherent with intermix with STB operations.  That's true\n-\/\/   on most common processors.\n-\/\/\n-\/\/ * See also http:\/\/blogs.sun.com\/dave\n-\n@@ -260,1 +247,0 @@\n-  _Responsible(nullptr),\n@@ -323,2 +309,1 @@\n-void ObjectMonitor::enter_for_with_contention_mark(JavaThread* locking_thread, ObjectMonitorContentionMark& contention_mark) {\n-  \/\/ Used by ObjectSynchronizer::enter_for to enter for another thread.\n+bool ObjectMonitor::TryLock_with_contention_mark(JavaThread* locking_thread, ObjectMonitorContentionMark& contention_mark) {\n@@ -331,1 +316,0 @@\n-\n@@ -333,1 +317,0 @@\n-\n@@ -346,2 +329,7 @@\n-      \/\/ Cancelled deflation. Increment contentions as part of the deflation protocol.\n-      add_to_contentions(1);\n+      \/\/ We successfully cancelled the in-progress async deflation.\n+      \/\/ By extending the lifetime of the contention_mark, we\n+      \/\/ prevent the destructor from decrementing the contentions\n+      \/\/ counter when the contention_mark goes out of scope. Instead\n+      \/\/ ObjectMonitor::deflate_monitor() will decrement contentions\n+      \/\/ after it recognizes that the async deflation was cancelled.\n+      contention_mark.extend();\n@@ -363,0 +351,9 @@\n+  assert(!success || owner_raw() == locking_thread, \"must be\");\n+\n+  return success;\n+}\n+\n+void ObjectMonitor::enter_for_with_contention_mark(JavaThread* locking_thread, ObjectMonitorContentionMark& contention_mark) {\n+  \/\/ Used by LightweightSynchronizer::inflate_and_enter in deoptimization path to enter for another thread.\n+  bool success = ObjectMonitor::TryLock_with_contention_mark(locking_thread, contention_mark);\n+\n@@ -364,2 +361,2 @@\n-          \", this=\" INTPTR_FORMAT \"{owner=\" INTPTR_FORMAT \"}, observed owner: \" INTPTR_FORMAT,\n-          p2i(locking_thread), p2i(this), p2i(owner_raw()), p2i(prev_owner));\n+         \", this=\" INTPTR_FORMAT \"{owner=\" INTPTR_FORMAT \"}\",\n+         p2i(locking_thread), p2i(this), p2i(owner_raw()));\n@@ -369,0 +366,1 @@\n+  \/\/ Used by ObjectSynchronizer::enter_for() to enter for another thread.\n@@ -378,1 +376,5 @@\n-  enter_for_with_contention_mark(locking_thread, contention_mark);\n+  bool success = ObjectMonitor::TryLock_with_contention_mark(locking_thread, contention_mark);\n+\n+  assert(success, \"Failed to enter_for: locking_thread=\" INTPTR_FORMAT\n+         \", this=\" INTPTR_FORMAT \"{owner=\" INTPTR_FORMAT \"}\",\n+         p2i(locking_thread), p2i(this), p2i(owner_raw()));\n@@ -564,4 +566,32 @@\n-  if (own != nullptr) return TryLockResult::HasOwner;\n-  if (try_set_owner_from(nullptr, current) == nullptr) {\n-    assert(_recursions == 0, \"invariant\");\n-    return TryLockResult::Success;\n+  void* first_own = own;\n+\n+  for (;;) {\n+    if (own == DEFLATER_MARKER) {\n+      \/\/ Block out deflation as soon as possible.\n+      ObjectMonitorContentionMark contention_mark(this);\n+\n+      \/\/ Check for deflation.\n+      if (enter_is_async_deflating()) {\n+        \/\/ Treat deflation as interference.\n+        return TryLockResult::Interference;\n+      }\n+      if (TryLock_with_contention_mark(current, contention_mark)) {\n+        assert(_recursions == 0, \"invariant\");\n+        return TryLockResult::Success;\n+      } else {\n+        \/\/ Deflation won or change of owner; dont spin\n+        break;\n+      }\n+    } else if (own == nullptr) {\n+      void* prev_own = try_set_owner_from(nullptr, current);\n+      if (prev_own == nullptr) {\n+        assert(_recursions == 0, \"invariant\");\n+        return TryLockResult::Success;\n+      } else {\n+        \/\/ The lock had been free momentarily, but we lost the race to the lock.\n+        own = prev_own;\n+      }\n+    } else {\n+      \/\/ Retry doesn't make as much sense because the lock was just acquired.\n+      break;\n+    }\n@@ -569,5 +599,1 @@\n-  \/\/ The lock had been free momentarily, but we lost the race to the lock.\n-  \/\/ Interference -- the CAS failed.\n-  \/\/ We can either return -1 or retry.\n-  \/\/ Retry doesn't make as much sense because the lock was just acquired.\n-  return TryLockResult::Interference;\n+  return first_own == own ? TryLockResult::HasOwner : TryLockResult::Interference;\n@@ -749,2 +775,0 @@\n-#define MAX_RECHECK_INTERVAL 1000\n-\n@@ -758,19 +782,0 @@\n-    assert(_Responsible != current, \"invariant\");\n-    return;\n-  }\n-\n-  if (try_set_owner_from(DEFLATER_MARKER, current) == DEFLATER_MARKER) {\n-    \/\/ Cancelled the in-progress async deflation by changing owner from\n-    \/\/ DEFLATER_MARKER to current. As part of the contended enter protocol,\n-    \/\/ contentions was incremented to a positive value before EnterI()\n-    \/\/ was called and that prevents the deflater thread from winning the\n-    \/\/ last part of the 2-part async deflation protocol. After EnterI()\n-    \/\/ returns to enter(), contentions is decremented because the caller\n-    \/\/ now owns the monitor. We bump contentions an extra time here to\n-    \/\/ prevent the deflater thread from winning the last part of the\n-    \/\/ 2-part async deflation protocol after the regular decrement\n-    \/\/ occurs in enter(). The deflater thread will decrement contentions\n-    \/\/ after it recognizes that the async deflation was cancelled.\n-    add_to_contentions(1);\n-    assert(_succ != current, \"invariant\");\n-    assert(_Responsible != current, \"invariant\");\n@@ -792,1 +797,0 @@\n-    assert(_Responsible != current, \"invariant\");\n@@ -799,1 +803,0 @@\n-  assert(_Responsible != current, \"invariant\");\n@@ -829,1 +832,0 @@\n-      assert(_Responsible != current, \"invariant\");\n@@ -834,29 +836,0 @@\n-  \/\/ Check for cxq|EntryList edge transition to non-null.  This indicates\n-  \/\/ the onset of contention.  While contention persists exiting threads\n-  \/\/ will use a ST:MEMBAR:LD 1-1 exit protocol.  When contention abates exit\n-  \/\/ operations revert to the faster 1-0 mode.  This enter operation may interleave\n-  \/\/ (race) a concurrent 1-0 exit operation, resulting in stranding, so we\n-  \/\/ arrange for one of the contending thread to use a timed park() operations\n-  \/\/ to detect and recover from the race.  (Stranding is form of progress failure\n-  \/\/ where the monitor is unlocked but all the contending threads remain parked).\n-  \/\/ That is, at least one of the contended threads will periodically poll _owner.\n-  \/\/ One of the contending threads will become the designated \"Responsible\" thread.\n-  \/\/ The Responsible thread uses a timed park instead of a normal indefinite park\n-  \/\/ operation -- it periodically wakes and checks for and recovers from potential\n-  \/\/ strandings admitted by 1-0 exit operations.   We need at most one Responsible\n-  \/\/ thread per-monitor at any given moment.  Only threads on cxq|EntryList may\n-  \/\/ be responsible for a monitor.\n-  \/\/\n-  \/\/ Currently, one of the contended threads takes on the added role of \"Responsible\".\n-  \/\/ A viable alternative would be to use a dedicated \"stranding checker\" thread\n-  \/\/ that periodically iterated over all the threads (or active monitors) and unparked\n-  \/\/ successors where there was risk of stranding.  This would help eliminate the\n-  \/\/ timer scalability issues we see on some platforms as we'd only have one thread\n-  \/\/ -- the checker -- parked on a timer.\n-\n-  if (nxt == nullptr && _EntryList == nullptr) {\n-    \/\/ Try to assume the role of responsible thread for the monitor.\n-    \/\/ CONSIDER:  ST vs CAS vs { if (Responsible==null) Responsible=current }\n-    Atomic::replace_if_null(&_Responsible, current);\n-  }\n-\n@@ -874,2 +847,0 @@\n-  int recheckInterval = 1;\n-\n@@ -884,10 +855,1 @@\n-    if (_Responsible == current) {\n-      current->_ParkEvent->park((jlong) recheckInterval);\n-      \/\/ Increase the recheckInterval, but clamp the value.\n-      recheckInterval *= 8;\n-      if (recheckInterval > MAX_RECHECK_INTERVAL) {\n-        recheckInterval = MAX_RECHECK_INTERVAL;\n-      }\n-    } else {\n-      current->_ParkEvent->park();\n-    }\n+    current->_ParkEvent->park();\n@@ -899,16 +861,0 @@\n-    if (try_set_owner_from(DEFLATER_MARKER, current) == DEFLATER_MARKER) {\n-      \/\/ Cancelled the in-progress async deflation by changing owner from\n-      \/\/ DEFLATER_MARKER to current. As part of the contended enter protocol,\n-      \/\/ contentions was incremented to a positive value before EnterI()\n-      \/\/ was called and that prevents the deflater thread from winning the\n-      \/\/ last part of the 2-part async deflation protocol. After EnterI()\n-      \/\/ returns to enter(), contentions is decremented because the caller\n-      \/\/ now owns the monitor. We bump contentions an extra time here to\n-      \/\/ prevent the deflater thread from winning the last part of the\n-      \/\/ 2-part async deflation protocol after the regular decrement\n-      \/\/ occurs in enter(). The deflater thread will decrement contentions\n-      \/\/ after it recognizes that the async deflation was cancelled.\n-      add_to_contentions(1);\n-      break;\n-    }\n-\n@@ -956,25 +902,4 @@\n-  if (_succ == current) _succ = nullptr;\n-\n-  assert(_succ != current, \"invariant\");\n-  if (_Responsible == current) {\n-    _Responsible = nullptr;\n-    OrderAccess::fence(); \/\/ Dekker pivot-point\n-\n-    \/\/ We may leave threads on cxq|EntryList without a designated\n-    \/\/ \"Responsible\" thread.  This is benign.  When this thread subsequently\n-    \/\/ exits the monitor it can \"see\" such preexisting \"old\" threads --\n-    \/\/ threads that arrived on the cxq|EntryList before the fence, above --\n-    \/\/ by LDing cxq|EntryList.  Newly arrived threads -- that is, threads\n-    \/\/ that arrive on cxq after the ST:MEMBAR, above -- will set Responsible\n-    \/\/ non-null and elect a new \"Responsible\" timer thread.\n-    \/\/\n-    \/\/ This thread executes:\n-    \/\/    ST Responsible=null; MEMBAR    (in enter epilogue - here)\n-    \/\/    LD cxq|EntryList               (in subsequent exit)\n-    \/\/\n-    \/\/ Entering threads in the slow\/contended path execute:\n-    \/\/    ST cxq=nonnull; MEMBAR; LD Responsible (in enter prolog)\n-    \/\/    The (ST cxq; MEMBAR) is accomplished with CAS().\n-    \/\/\n-    \/\/ The MEMBAR, above, prevents the LD of cxq|EntryList in the subsequent\n-    \/\/ exit operation from floating above the ST Responsible=null.\n+  if (_succ == current) {\n+    _succ = nullptr;\n+    \/\/ Note that we don't need to do OrderAccess::fence() after clearing\n+    \/\/ _succ here, since we own the lock.\n@@ -986,1 +911,1 @@\n-  \/\/ EntryList, cxq or Responsible.  These meta-data updates must be\n+  \/\/ EntryList or cxq.  These meta-data updates must be\n@@ -993,1 +918,1 @@\n-  \/\/ To that end, the 1-0 exit() operation must have at least STST|LDST\n+  \/\/ To that end, the exit() operation must have at least STST|LDST\n@@ -1003,2 +928,1 @@\n-  \/\/ monitorexit.  Recall too, that in 1-0 mode monitorexit does not necessarily\n-  \/\/ execute a serializing instruction.\n+  \/\/ monitorexit.\n@@ -1177,14 +1101,19 @@\n-\/\/ 1-0 exit\n-\/\/ ~~~~~~~~\n-\/\/ ::exit() uses a canonical 1-1 idiom with a MEMBAR although some of\n-\/\/ the fast-path operators have been optimized so the common ::exit()\n-\/\/ operation is 1-0, e.g., see macroAssembler_x86.cpp: fast_unlock().\n-\/\/ The code emitted by fast_unlock() elides the usual MEMBAR.  This\n-\/\/ greatly improves latency -- MEMBAR and CAS having considerable local\n-\/\/ latency on modern processors -- but at the cost of \"stranding\".  Absent the\n-\/\/ MEMBAR, a thread in fast_unlock() can race a thread in the slow\n-\/\/ ::enter() path, resulting in the entering thread being stranding\n-\/\/ and a progress-liveness failure.   Stranding is extremely rare.\n-\/\/ We use timers (timed park operations) & periodic polling to detect\n-\/\/ and recover from stranding.  Potentially stranded threads periodically\n-\/\/ wake up and poll the lock.  See the usage of the _Responsible variable.\n+\/\/ This is the exit part of the locking protocol, often implemented in\n+\/\/ C2_MacroAssembler::fast_unlock()\n+\/\/\n+\/\/   1. A release barrier ensures that changes to monitor meta-data\n+\/\/      (_succ, _EntryList, _cxq) and data protected by the lock will be\n+\/\/      visible before we release the lock.\n+\/\/   2. Release the lock by clearing the owner.\n+\/\/   3. A storeload MEMBAR is needed between releasing the owner and\n+\/\/      subsequently reading meta-data to safely determine if the lock is\n+\/\/      contended (step 4) without an elected successor (step 5).\n+\/\/   4. If both _EntryList and _cxq are null, we are done, since there is no\n+\/\/      other thread waiting on the lock to wake up. I.e. there is no\n+\/\/      contention.\n+\/\/   5. If there is a successor (_succ is non-null), we are done. The\n+\/\/      responsibility for guaranteeing progress-liveness has now implicitly\n+\/\/      been moved from the exiting thread to the successor.\n+\/\/   6. There are waiters in the entry list (_EntryList and\/or cxq are\n+\/\/      non-null), but there is no successor (_succ is null), so we need to\n+\/\/      wake up (unpark) a waiting thread to avoid stranding.\n@@ -1192,4 +1121,3 @@\n-\/\/ The CAS() in enter provides for safety and exclusion, while the CAS or\n-\/\/ MEMBAR in exit provides for progress and avoids stranding.  1-0 locking\n-\/\/ eliminates the CAS\/MEMBAR from the exit path, but it admits stranding.\n-\/\/ We detect and recover from stranding with timers.\n+\/\/ Note that since only the current lock owner can manipulate the _EntryList\n+\/\/ or drain _cxq, we need to reacquire the lock before we can wake up\n+\/\/ (unpark) a waiting thread.\n@@ -1197,13 +1125,2 @@\n-\/\/ If a thread transiently strands it'll park until (a) another\n-\/\/ thread acquires the lock and then drops the lock, at which time the\n-\/\/ exiting thread will notice and unpark the stranded thread, or, (b)\n-\/\/ the timer expires.  If the lock is high traffic then the stranding latency\n-\/\/ will be low due to (a).  If the lock is low traffic then the odds of\n-\/\/ stranding are lower, although the worst-case stranding latency\n-\/\/ is longer.  Critically, we don't want to put excessive load in the\n-\/\/ platform's timer subsystem.  We want to minimize both the timer injection\n-\/\/ rate (timers created\/sec) as well as the number of timers active at\n-\/\/ any one time.  (more precisely, we want to minimize timer-seconds, which is\n-\/\/ the integral of the # of active timers at any instant over time).\n-\/\/ Both impinge on OS scalability.  Given that, at most one thread parked on\n-\/\/ a monitor will use a timer.\n+\/\/ The CAS() in enter provides for safety and exclusion, while the\n+\/\/ MEMBAR in exit provides for progress and avoids stranding.\n@@ -1251,4 +1168,0 @@\n-  \/\/ Invariant: after setting Responsible=null an thread must execute\n-  \/\/ a MEMBAR or other serializing instruction before fetching EntryList|cxq.\n-  _Responsible = nullptr;\n-\n@@ -1281,8 +1194,9 @@\n-    \/\/ but if other successors are ready or other entering threads are spinning\n-    \/\/ then this thread can simply store null into _owner and exit without\n-    \/\/ waking a successor.  The existence of spinners or ready successors\n-    \/\/ guarantees proper succession (liveness).  Responsibility passes to the\n-    \/\/ ready or running successors.  The exiting thread delegates the duty.\n-    \/\/ More precisely, if a successor already exists this thread is absolved\n-    \/\/ of the responsibility of waking (unparking) one.\n-    \/\/\n+    \/\/ but if this thread observes other successors are ready or other\n+    \/\/ entering threads are spinning after it has stored null into _owner\n+    \/\/ then it can exit without waking a successor.  The existence of\n+    \/\/ spinners or ready successors guarantees proper succession (liveness).\n+    \/\/ Responsibility passes to the ready or running successors.  The exiting\n+    \/\/ thread delegates the duty.  More precisely, if a successor already\n+    \/\/ exists this thread is absolved of the responsibility of waking\n+    \/\/ (unparking) one.\n+\n@@ -1299,10 +1213,4 @@\n-    \/\/ Another less appealing alternative would be for the exiting thread\n-    \/\/ to drop the lock and then spin briefly to see if a spinner managed\n-    \/\/ to acquire the lock.  If so, the exiting thread could exit\n-    \/\/ immediately without waking a successor, otherwise the exiting\n-    \/\/ thread would need to dequeue and wake a successor.\n-    \/\/ (Note that we'd need to make the post-drop spin short, but no\n-    \/\/ shorter than the worst-case round-trip cache-line migration time.\n-    \/\/ The dropped lock needs to become visible to the spinner, and then\n-    \/\/ the acquisition of the lock by the spinner must become visible to\n-    \/\/ the exiting thread).\n+    \/\/ Which means that the exiting thread could exit immediately without\n+    \/\/ waking a successor, if it observes a successor after it has dropped\n+    \/\/ the lock.  Note that the dropped lock needs to become visible to the\n+    \/\/ spinner.\n@@ -1316,2 +1224,44 @@\n-    if (try_set_owner_from(nullptr, current) != nullptr) {\n-      return;\n+    void* owner = try_set_owner_from(nullptr, current);\n+    if (owner != nullptr) {\n+      if (owner != DEFLATER_MARKER) {\n+        \/\/ Owned by another thread, so we are done.\n+        return;\n+      }\n+\n+      \/\/ The deflator owns the lock.  Now try to cancel the async\n+      \/\/ deflation.  As part of the contended enter protocol,\n+      \/\/ contentions was incremented to a positive value before\n+      \/\/ EnterI() was called and that prevents the deflater thread\n+      \/\/ from winning the last part of the 2-part async deflation\n+      \/\/ protocol. After EnterI() returns to enter(), contentions is\n+      \/\/ decremented because the caller now owns the monitor. We need\n+      \/\/ to increment contentions an extra time here (done by the\n+      \/\/ ObjectMonitorContentionMark constructor) to prevent the\n+      \/\/ deflater thread from winning the last part of the 2-part\n+      \/\/ async deflation protocol after the regular decrement occurs\n+      \/\/ in enter().\n+      ObjectMonitorContentionMark contention_mark(this);\n+\n+      if (is_being_async_deflated()) {\n+        assert((intptr_t(_EntryList) | intptr_t(_cxq)) == 0 || _succ != nullptr, \"\");\n+        \/\/ Mr. Deflator won the race, so we are done.\n+        return;\n+      }\n+\n+      \/\/ Now try to take the ownership.\n+      if (try_set_owner_from(DEFLATER_MARKER, current) == DEFLATER_MARKER) {\n+        \/\/ We successfully cancelled the in-progress async deflation.\n+        \/\/ By extending the lifetime of the contention_mark, we\n+        \/\/ prevent the destructor from decrementing the contentions\n+        \/\/ counter when the contention_mark goes out of scope. Instead\n+        \/\/ ObjectMonitor::deflate_monitor() will decrement contentions\n+        \/\/ after it recognizes that the async deflation was cancelled.\n+        contention_mark.extend();\n+      } else {\n+        owner = try_set_owner_from(nullptr, current);\n+        if (owner != nullptr) {\n+          \/\/ The lock is owned by another thread, who is now\n+          \/\/ responsible for ensuring succession, so we are done.\n+          return;\n+        }\n+      }\n@@ -1379,1 +1329,1 @@\n-    \/\/ In 1-0 mode we need: ST EntryList; MEMBAR #storestore; ST _owner = nullptr\n+    \/\/ We need to: ST EntryList; MEMBAR #storestore; ST _owner = nullptr\n@@ -1569,2 +1519,0 @@\n-  _Responsible = nullptr;\n-\n@@ -2248,1 +2196,0 @@\n-\/\/   _Responsible = 0x0000000000000000\n@@ -2277,1 +2224,0 @@\n-  st->print_cr(\"  _Responsible = \" INTPTR_FORMAT, p2i(_Responsible));\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":149,"deletions":203,"binary":false,"changes":352,"status":"modified"},{"patch":"@@ -182,1 +182,0 @@\n-  JavaThread* volatile _Responsible;\n@@ -227,0 +226,1 @@\n+  static ByteSize contentions_offset() { return byte_offset_of(ObjectMonitor, _contentions); }\n@@ -359,0 +359,3 @@\n+  enum class TryLockResult { Interference = -1, HasOwner = 0, Success = 1 };\n+  TryLockResult  TryLock(JavaThread* current);\n+\n@@ -373,0 +376,1 @@\n+  bool      TryLock_with_contention_mark(JavaThread* locking_thread, ObjectMonitorContentionMark& contention_mark);\n@@ -376,6 +380,0 @@\n-\n-\n-  enum class TryLockResult { Interference = -1, HasOwner = 0, Success = 1 };\n-\n-  TryLockResult  TryLock(JavaThread* current);\n-\n@@ -398,0 +396,1 @@\n+  bool _extended;\n@@ -404,0 +403,4 @@\n+\n+  \/\/ Extends the contention scope beyond this objects lifetime.\n+  \/\/ Requires manual decrement of the contentions counter.\n+  void extend();\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -210,1 +210,1 @@\n-  : _monitor(monitor) {\n+  : _monitor(monitor), _extended(false) {\n@@ -215,1 +215,8 @@\n-  _monitor->add_to_contentions(-1);\n+  if (!_extended) {\n+    _monitor->add_to_contentions(-1);\n+  }\n+}\n+\n+inline void ObjectMonitorContentionMark::extend() {\n+  assert(!_extended, \"extending twice is probably a bad design\");\n+  _extended = true;\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1960,0 +1960,18 @@\n+\n+  \/\/ Check if C2_MacroAssembler::fast_unlock() or\n+  \/\/ C2_MacroAssembler::fast_unlock_lightweight() unlocked an inflated\n+  \/\/ monitor before going slow path.\n+  ObjectMonitor* m = current->unlocked_inflated_monitor();\n+  if (m != nullptr) {\n+    assert(m->owner_raw() != current, \"must be\");\n+    current->clear_unlocked_inflated_monitor();\n+\n+    \/\/ We need to reacquire the lock before we can call ObjectSynchronizer::exit().\n+    if (m->TryLock(current) != ObjectMonitor::TryLockResult::Success) {\n+      \/\/ Some other thread acquired the lock (or the monitor was\n+      \/\/ deflated). Either way we are done.\n+      current->inc_held_monitor_count(-1);\n+      return;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -315,1 +315,1 @@\n-    @Threads(2)\n+    @Threads(3)\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/lang\/LockUnlock.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}