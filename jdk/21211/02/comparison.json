{"files":[{"patch":"@@ -913,1 +913,0 @@\n-\n@@ -922,2 +921,6 @@\n-  \/\/ Relinquish the lock after this much time passed.\n-  static constexpr jlong deadline_ns = 30000; \/\/ 30 us\n+  size_t total_batches = 0;\n+  jlong batch_start_time = 0;\n+  jlong recycle_trash_start_time = os::javaTimeNanos();    \/\/ This value will be treated as the initial batch_start_time\n+  jlong batch_end_time = recycle_trash_start_time;\n+  \/\/ Process as many batches as can be processed within 10 us.\n+  static constexpr jlong deadline_ns = 10000;               \/\/ 10 us\n@@ -925,0 +928,2 @@\n+  jlong predicted_next_batch_end_time;\n+  jlong batch_process_time_estimate = 0;\n@@ -926,5 +931,2 @@\n-    os::naked_yield(); \/\/ Yield to allow allocators to take the lock\n-    ShenandoahHeapLocker locker(_heap->lock());\n-    const jlong deadline = os::javaTimeNanos() + deadline_ns;\n-    while (idx < count && os::javaTimeNanos() < deadline) {\n-      try_recycle_trashed(_trash_regions[idx++]);\n+    if (idx > 0) {\n+      os::naked_yield(); \/\/ Yield to allow allocators to take the lock, except on the first iteration\n@@ -932,0 +934,26 @@\n+    \/\/ Avoid another call to javaTimeNanos() if we already know time at which last batch ended\n+    batch_start_time = batch_end_time;\n+    const jlong deadline = batch_start_time + deadline_ns;\n+\n+    ShenandoahHeapLocker locker(_heap->lock());\n+    do {\n+      \/\/ Measurements on typical 2024 hardware suggest it typically requires between 1400 and 2000 ns to process a batch of\n+      \/\/ 32 regions, assuming low contention with other threads.  Sometimes this goes higher, when mutator threads\n+      \/\/ are contending for CPU cores and\/or the heap lock.  On this hardware with a 10 us deadline, we expect 3-6 batches\n+      \/\/ to be processed between yields most of the time.\n+      \/\/\n+      \/\/ Note that deadline is enforced since the end of previous batch.  In the case that yield() or acquisition of heap lock\n+      \/\/ takes a \"long time\", we will have less time to process regions, but we will always process at least one batch between\n+      \/\/ yields.  Yielding more frequently when there is heavy contention for the heap lock or for CPU cores is considered the\n+      \/\/ right thing to do.\n+      const size_t REGIONS_PER_BATCH = 32;\n+      size_t max_idx = MIN2(count, idx + REGIONS_PER_BATCH);\n+      while (idx < max_idx) {\n+        try_recycle_trashed(_trash_regions[idx++]);\n+      }\n+      total_batches++;\n+      batch_end_time = os::javaTimeNanos();\n+      \/\/ Estimate includes historic combination of yield times and heap lock acquisition times.\n+      batch_process_time_estimate = (batch_end_time - recycle_trash_start_time) \/ total_batches;\n+      predicted_next_batch_end_time = batch_end_time + batch_process_time_estimate;\n+    } while ((idx < count) && (predicted_next_batch_end_time < deadline));\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":36,"deletions":8,"binary":false,"changes":44,"status":"modified"}]}