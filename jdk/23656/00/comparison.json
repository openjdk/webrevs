{"files":[{"patch":"@@ -714,1 +714,1 @@\n-  _unloading_threshold_gc_requested = false;\n+  _unloading_gc_requested = false;\n@@ -783,0 +783,5 @@\n+  \/\/ We don't need more than one thread performing code cache memory pressure verification\n+  if (Atomic::cmpxchg(&_on_gc_allocation_ongoing, false, true) == true) {\n+    return;\n+  }\n+\n@@ -787,5 +792,30 @@\n-  if (free_ratio <= StartAggressiveSweepingAt \/ 100.0)  {\n-    \/\/ In case the GC is concurrent, we make sure only one thread requests the GC.\n-    if (Atomic::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n-      log_info(codecache)(\"Triggering aggressive GC due to having only %.3f%% free memory\", free_ratio * 100.0);\n-      Universe::heap()->collect(GCCause::_codecache_GC_aggressive);\n+\n+  if (free_ratio <= StartAggressiveSweepingAt \/ 100.0) {\n+    try_to_gc(GCCause::_codecache_GC_aggressive, [&] {\n+        log_info(codecache)(\"Triggering aggressive GC due to having only %.3f%% free memory\", free_ratio * 100.0);\n+    });\n+  } else {\n+    size_t last_used = _last_unloading_used;\n+\n+    \/\/ Only consider sweeping if increase since last GC\n+    if (used > last_used) {\n+      size_t allocated_since_last = used - last_used;\n+      double allocated_since_last_ratio = double(allocated_since_last) \/ double(max);\n+      double threshold = SweeperThreshold \/ 100.0;\n+      double used_ratio = double(used) \/ double(max);\n+      double last_used_ratio = double(last_used) \/ double(max);\n+\n+      if (used_ratio > threshold) {\n+        \/\/ After threshold is reached, scale it by free_ratio so that more aggressive\n+        \/\/ GC is triggered as we approach code cache exhaustion\n+        threshold *= free_ratio;\n+      }\n+\n+      \/\/ If code cache has been allocated without any GC at all, let's make sure\n+      \/\/ it is eventually invoked to avoid trouble.\n+      if (allocated_since_last_ratio > threshold) {\n+        try_to_gc(GCCause::_codecache_GC_threshold, [&] {\n+            log_info(codecache)(\"Triggering threshold (%.3f%%) GC due to allocating %.3f%% since last unloading (%.3f%% used -> %.3f%% used)\",\n+                                threshold * 100.0, allocated_since_last_ratio * 100.0, last_used_ratio * 100.0, used_ratio * 100.0);\n+        });\n+      }\n@@ -793,1 +823,0 @@\n-    return;\n@@ -796,23 +825,14 @@\n-  size_t last_used = _last_unloading_used;\n-  if (last_used >= used) {\n-    \/\/ No increase since last GC; no need to sweep yet\n-    return;\n-  }\n-  size_t allocated_since_last = used - last_used;\n-  double allocated_since_last_ratio = double(allocated_since_last) \/ double(max);\n-  double threshold = SweeperThreshold \/ 100.0;\n-  double used_ratio = double(used) \/ double(max);\n-  double last_used_ratio = double(last_used) \/ double(max);\n-  if (used_ratio > threshold) {\n-    \/\/ After threshold is reached, scale it by free_ratio so that more aggressive\n-    \/\/ GC is triggered as we approach code cache exhaustion\n-    threshold *= free_ratio;\n-  }\n-  \/\/ If code cache has been allocated without any GC at all, let's make sure\n-  \/\/ it is eventually invoked to avoid trouble.\n-  if (allocated_since_last_ratio > threshold) {\n-    \/\/ In case the GC is concurrent, we make sure only one thread requests the GC.\n-    if (Atomic::cmpxchg(&_unloading_threshold_gc_requested, false, true) == false) {\n-      log_info(codecache)(\"Triggering threshold (%.3f%%) GC due to allocating %.3f%% since last unloading (%.3f%% used -> %.3f%% used)\",\n-                          threshold * 100.0, allocated_since_last_ratio * 100.0, last_used_ratio * 100.0, used_ratio * 100.0);\n-      Universe::heap()->collect(GCCause::_codecache_GC_threshold);\n+  _on_gc_allocation_ongoing = false;\n+}\n+\n+template <typename Function>\n+void CodeCache::try_to_gc(GCCause::Cause cause, Function log_on_gc) {\n+  double time = os::elapsedTime();\n+  double elapsed_since_last_gc_request = time - _unloading_gc_requested_time;\n+\n+  \/\/ For different reasons, we don't have any guarantee that the GC implementation\n+  \/\/ will reset our flag correctly which may prevent future GC requests.\n+  \/\/ In order to avoid that, automatically reset it after a fixed delay of 250ms.\n+  if (elapsed_since_last_gc_request > 0.25 && _unloading_gc_requested) {\n+    if (Atomic::cmpxchg(&_unloading_gc_requested, true, false) == true) {\n+      log_debug(codecache)(\"Previous GC request has not been reset after %fs, forced auto-reset\", elapsed_since_last_gc_request);\n@@ -821,0 +841,7 @@\n+\n+  if (!_unloading_gc_requested) {\n+    log_on_gc();\n+    _unloading_gc_requested = true;\n+    _unloading_gc_requested_time = time;\n+    Universe::heap()->collect(cause);\n+  }\n@@ -835,1 +862,3 @@\n-volatile bool CodeCache::_unloading_threshold_gc_requested = false;\n+volatile bool CodeCache::_on_gc_allocation_ongoing = false;\n+volatile bool CodeCache::_unloading_gc_requested = false;\n+double CodeCache::_unloading_gc_requested_time = 0;\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":60,"deletions":31,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"gc\/shared\/gcCause.hpp\"\n@@ -111,1 +112,3 @@\n-  static volatile bool     _unloading_threshold_gc_requested;\n+  static volatile bool     _on_gc_allocation_ongoing;\n+  static volatile bool     _unloading_gc_requested;\n+  static double            _unloading_gc_requested_time;\n@@ -132,0 +135,3 @@\n+  template <typename Function>\n+  static void try_to_gc(GCCause::Cause cause, Function log_on_gc);\n+\n","filename":"src\/hotspot\/share\/code\/codeCache.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"}]}