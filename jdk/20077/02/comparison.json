{"files":[{"patch":"@@ -266,3 +266,2 @@\n-HeapWord* ParallelScavengeHeap::mem_allocate(\n-                                     size_t size,\n-                                     bool* gc_overhead_limit_was_exceeded) {\n+HeapWord* ParallelScavengeHeap::mem_allocate(size_t size,\n+                                             bool* gc_overhead_limit_was_exceeded) {\n@@ -273,0 +272,8 @@\n+  bool is_tlab = false;\n+  return mem_allocate_work(size, is_tlab, gc_overhead_limit_was_exceeded);\n+}\n+\n+HeapWord* ParallelScavengeHeap::mem_allocate_work(size_t size,\n+                                                  bool is_tlab,\n+                                                  bool* gc_overhead_limit_was_exceeded) {\n+\n@@ -306,3 +313,5 @@\n-      result = mem_allocate_old_gen(size);\n-      if (result != nullptr) {\n-        return result;\n+      if (!is_tlab) {\n+        result = mem_allocate_old_gen(size);\n+        if (result != nullptr) {\n+          return result;\n+        }\n@@ -341,1 +350,1 @@\n-      VM_ParallelGCFailedAllocation op(size, gc_count);\n+      VM_ParallelCollectForAllocation op(size, is_tlab, gc_count);\n@@ -398,17 +407,0 @@\n-\/\/ A \"death march\" is a series of ultra-slow allocations in which a full gc is\n-\/\/ done before each allocation, and after the full gc the allocation still\n-\/\/ cannot be satisfied from the young gen.  This routine detects that condition;\n-\/\/ it should be called after a full gc has been done and the allocation\n-\/\/ attempted from the young gen. The parameter 'addr' should be the result of\n-\/\/ that young gen allocation attempt.\n-void\n-ParallelScavengeHeap::death_march_check(HeapWord* const addr, size_t size) {\n-  if (addr != nullptr) {\n-    _death_march_count = 0;  \/\/ death march has ended\n-  } else if (_death_march_count == 0) {\n-    if (should_alloc_in_eden(size)) {\n-      _death_march_count = 1;    \/\/ death march has started\n-    }\n-  }\n-}\n-\n@@ -430,10 +422,0 @@\n-  \/\/ If a \"death march\" is in progress, allocate from the old gen a limited\n-  \/\/ number of times before doing a GC.\n-  if (_death_march_count > 0) {\n-    if (_death_march_count < 64) {\n-      ++_death_march_count;\n-      return allocate_old_gen_and_record(size);\n-    } else {\n-      _death_march_count = 0;\n-    }\n-  }\n@@ -444,14 +426,5 @@\n-  PSParallelCompact::invoke(clear_all_soft_refs);\n-}\n-\n-\/\/ Failed allocation policy. Must be called from the VM thread, and\n-\/\/ only at a safepoint! Note that this method has policy for allocation\n-\/\/ flow, and NOT collection policy. So we do not check for gc collection\n-\/\/ time over limit here, that is the responsibility of the heap specific\n-\/\/ collection methods. This method decides where to attempt allocations,\n-\/\/ and when to attempt collections, but no collection specific policy.\n-HeapWord* ParallelScavengeHeap::failed_mem_allocate(size_t size) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"should be at safepoint\");\n-  assert(Thread::current() == (Thread*)VMThread::vm_thread(), \"should be in vm thread\");\n-  assert(!is_stw_gc_active(), \"not reentrant\");\n-  assert(!Heap_lock->owned_by_self(), \"this thread should not own the Heap_lock\");\n+  if (GCLocker::check_active_before_gc()) {\n+    return;\n+  }\n+  do_full_collection_no_gc_locker(clear_all_soft_refs);\n+}\n@@ -459,1 +432,4 @@\n-  \/\/ We assume that allocation in eden will fail unless we collect.\n+void ParallelScavengeHeap::do_full_collection_no_gc_locker(bool clear_all_soft_refs) {\n+  bool maximum_compaction = clear_all_soft_refs;\n+  PSParallelCompact::invoke(maximum_compaction);\n+}\n@@ -461,4 +437,2 @@\n-  \/\/ First level allocation failure, scavenge and allocate in young gen.\n-  GCCauseSetter gccs(this, GCCause::_allocation_failure);\n-  const bool invoked_full_gc = PSScavenge::invoke();\n-  HeapWord* result = young_gen()->allocate(size);\n+HeapWord* ParallelScavengeHeap::expand_heap_and_allocate(size_t size, bool is_tlab) {\n+  HeapWord* result = nullptr;\n@@ -466,5 +440,4 @@\n-  \/\/ Second level allocation failure.\n-  \/\/   Mark sweep and allocate in young generation.\n-  if (result == nullptr && !invoked_full_gc) {\n-    do_full_collection(false);\n-    result = young_gen()->allocate(size);\n+  result = young_gen()->allocate(size);\n+  if (result == nullptr && !is_tlab) {\n+    \/\/ auto expand inside\n+    result = old_gen()->allocate(size);\n@@ -472,0 +445,5 @@\n+  return result;   \/\/ Could be null if we are out of space.\n+}\n+\n+HeapWord* ParallelScavengeHeap::satisfy_failed_allocation(size_t size, bool is_tlab) {\n+  assert(size != 0, \"precondition\");\n@@ -473,1 +451,1 @@\n-  death_march_check(result, size);\n+  HeapWord* result = nullptr;\n@@ -475,5 +453,3 @@\n-  \/\/ Third level allocation failure.\n-  \/\/   After mark sweep and young generation allocation failure,\n-  \/\/   allocate in old generation.\n-  if (result == nullptr) {\n-    result = allocate_old_gen_and_record(size);\n+  GCLocker::check_active_before_gc();\n+  if (GCLocker::is_active_and_needs_gc()) {\n+    return expand_heap_and_allocate(size, is_tlab);\n@@ -482,5 +458,7 @@\n-  \/\/ Fourth level allocation failure. We're running out of memory.\n-  \/\/   More complete mark sweep and allocate in young generation.\n-  if (result == nullptr) {\n-    do_full_collection(true);\n-    result = young_gen()->allocate(size);\n+  \/\/ If young-gen can handle this allocation, attempt young-gc firstly.\n+  bool should_run_young_gc = is_tlab || should_alloc_in_eden(size);\n+  collect_at_safepoint(!should_run_young_gc);\n+\n+  result = expand_heap_and_allocate(size, is_tlab);\n+  if (result != nullptr) {\n+    return result;\n@@ -489,4 +467,15 @@\n-  \/\/ Fifth level allocation failure.\n-  \/\/   After more complete mark sweep, allocate in old generation.\n-  if (result == nullptr) {\n-    result = allocate_old_gen_and_record(size);\n+  \/\/ If we reach this point, we're really out of memory. Try every trick\n+  \/\/ we can to reclaim memory. Force collection of soft references. Force\n+  \/\/ a complete compaction of the heap. Any additional methods for finding\n+  \/\/ free memory should be here, especially if they are expensive. If this\n+  \/\/ attempt fails, an OOM exception will be thrown.\n+  {\n+    \/\/ Make sure the heap is fully compacted\n+    uintx old_interval = HeapMaximumCompactionInterval;\n+    HeapMaximumCompactionInterval = 0;\n+\n+    const bool clear_all_soft_refs = true;\n+    do_full_collection_no_gc_locker(clear_all_soft_refs);\n+\n+    \/\/ Restore\n+    HeapMaximumCompactionInterval = old_interval;\n@@ -495,1 +484,10 @@\n-  return result;\n+  result = expand_heap_and_allocate(size, is_tlab);\n+  if (result != nullptr) {\n+    return result;\n+  }\n+\n+  \/\/ What else?  We might try synchronous finalization later.  If the total\n+  \/\/ space available is large enough for the allocation, then a more\n+  \/\/ complete compaction phase than we've tried so far might be\n+  \/\/ appropriate.\n+  return nullptr;\n@@ -498,0 +496,1 @@\n+\n@@ -516,1 +515,4 @@\n-  HeapWord* result = young_gen()->allocate(requested_size);\n+  bool dummy;\n+  HeapWord* result = mem_allocate_work(requested_size \/* size *\/,\n+                                       true \/* is_tlab *\/,\n+                                       &dummy);\n@@ -536,1 +538,0 @@\n-\/\/ This method is used by System.gc() and JVMTI.\n@@ -555,1 +556,1 @@\n-    VM_ParallelGCSystemGC op(gc_count, full_gc_count, cause);\n+    VM_ParallelGCCollect op(gc_count, full_gc_count, cause);\n@@ -558,1 +559,1 @@\n-    if (!GCCause::is_explicit_full_gc(cause) || op.full_gc_succeeded()) {\n+    if (!GCCause::is_explicit_full_gc(cause)) {\n@@ -576,0 +577,27 @@\n+void ParallelScavengeHeap::try_collect_at_safepoint(bool full) {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+  if (GCLocker::check_active_before_gc()) {\n+    return;\n+  }\n+  collect_at_safepoint(full);\n+}\n+\n+bool ParallelScavengeHeap::must_clear_all_soft_refs() {\n+  return _gc_cause == GCCause::_metadata_GC_clear_soft_refs ||\n+         _gc_cause == GCCause::_wb_full_gc;\n+}\n+\n+void ParallelScavengeHeap::collect_at_safepoint(bool full) {\n+  assert(!GCLocker::is_active(), \"precondition\");\n+  bool clear_soft_refs = must_clear_all_soft_refs();\n+\n+  if (!full) {\n+    bool success = PSScavenge::invoke(clear_soft_refs);\n+    if (success) {\n+      return;\n+    }\n+    \/\/ Upgrade to Full-GC if young-gc fails\n+  }\n+  do_full_collection_no_gc_locker(clear_soft_refs);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":106,"deletions":78,"binary":false,"changes":184,"status":"modified"},{"patch":"@@ -78,2 +78,0 @@\n-  unsigned int _death_march_count;\n-\n@@ -99,1 +97,4 @@\n- protected:\n+  void collect_at_safepoint(bool full);\n+\n+  bool must_clear_all_soft_refs();\n+\n@@ -103,1 +104,1 @@\n-  inline void death_march_check(HeapWord* const result, size_t size);\n+\n@@ -106,0 +107,11 @@\n+  HeapWord* mem_allocate_work(size_t size,\n+                              bool is_tlab,\n+                              bool* gc_overhead_limit_was_exceeded);\n+\n+  HeapWord* expand_heap_and_allocate(size_t size, bool is_tlab);\n+\n+  \/\/ Perform a full collection\n+  void do_full_collection(bool clear_all_soft_refs) override;\n+\n+  void do_full_collection_no_gc_locker(bool clear_all_soft_refs);\n+\n@@ -109,1 +121,0 @@\n-    _death_march_count(0),\n@@ -187,4 +198,1 @@\n-  \/\/ Allocation attempt(s) during a safepoint. It should never be called\n-  \/\/ to allocate a new TLAB as this allocation might be satisfied out\n-  \/\/ of the old generation.\n-  HeapWord* failed_mem_allocate(size_t size);\n+  HeapWord* satisfy_failed_allocation(size_t size, bool is_tlab);\n@@ -195,11 +203,1 @@\n-  \/\/ These also should be called by the vm thread at a safepoint (e.g., from a\n-  \/\/ VM operation).\n-  \/\/\n-  \/\/ The first collects the young generation only, unless the scavenge fails; it\n-  \/\/ will then attempt a full gc.  The second collects the entire heap; if\n-  \/\/ maximum_compaction is true, it will compact everything and clear all soft\n-  \/\/ references.\n-  inline bool invoke_scavenge();\n-\n-  \/\/ Perform a full collection\n-  void do_full_collection(bool clear_all_soft_refs) override;\n+  void try_collect_at_safepoint(bool full);\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.hpp","additions":18,"deletions":20,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -37,4 +37,0 @@\n-inline bool ParallelScavengeHeap::invoke_scavenge() {\n-  return PSScavenge::invoke();\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.inline.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -131,8 +131,0 @@\n-    cname = PerfDataManager::counter_name(name_space(), \"scavengeSkipped\");\n-    _scavenge_skipped = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) 0, CHECK);\n-\n-    cname = PerfDataManager::counter_name(name_space(), \"fullFollowsScavenge\");\n-    _full_follows_scavenge = PerfDataManager::create_variable(SUN_GC, cname,\n-      PerfData::U_Bytes, (jlong) 0, CHECK);\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psGCAdaptivePolicyCounters.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -64,3 +64,0 @@\n-  PerfVariable* _scavenge_skipped;\n-  PerfVariable* _full_follows_scavenge;\n-\n@@ -183,8 +180,0 @@\n-  inline void update_scavenge_skipped(int cause) {\n-    _scavenge_skipped->set_value(cause);\n-  }\n-\n-  inline void update_full_follows_scavenge(int event) {\n-    _full_follows_scavenge->set_value(event);\n-  }\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psGCAdaptivePolicyCounters.hpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+#include \"gc\/shared\/gcVMOperations.hpp\"\n@@ -971,0 +972,1 @@\n+  SvcGCMarker sgcm(SvcGCMarker::FULL);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"gc\/shared\/gcVMOperations.hpp\"\n@@ -224,36 +225,0 @@\n-\/\/ This method contains all heap specific policy for invoking scavenge.\n-\/\/ PSScavenge::invoke_no_policy() will do nothing but attempt to\n-\/\/ scavenge. It will not clean up after failed promotions, bail out if\n-\/\/ we've exceeded policy time limits, or any other special behavior.\n-\/\/ All such policy should be placed here.\n-\/\/\n-\/\/ Note that this method should only be called from the vm_thread while\n-\/\/ at a safepoint!\n-bool PSScavenge::invoke() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"should be at safepoint\");\n-  assert(Thread::current() == (Thread*)VMThread::vm_thread(), \"should be in vm thread\");\n-  assert(!ParallelScavengeHeap::heap()->is_stw_gc_active(), \"not reentrant\");\n-\n-  ParallelScavengeHeap* const heap = ParallelScavengeHeap::heap();\n-  IsSTWGCActiveMark mark;\n-\n-  const bool scavenge_done = PSScavenge::invoke_no_policy();\n-  const bool need_full_gc = !scavenge_done;\n-  bool full_gc_done = false;\n-\n-  if (UsePerfData) {\n-    PSGCAdaptivePolicyCounters* const counters = heap->gc_policy_counters();\n-    const int ffs_val = need_full_gc ? full_follows_scavenge : not_skipped;\n-    counters->update_full_follows_scavenge(ffs_val);\n-  }\n-\n-  if (need_full_gc) {\n-    GCCauseSetter gccs(heap, GCCause::_adaptive_size_policy);\n-    const bool clear_all_softrefs = heap->soft_ref_policy()->should_clear_all_soft_refs();\n-\n-    full_gc_done = PSParallelCompact::invoke_no_policy(clear_all_softrefs);\n-  }\n-\n-  return full_gc_done;\n-}\n-\n@@ -291,8 +256,8 @@\n-      WorkerTask(\"ScavengeRootsTask\"),\n-      _strong_roots_scope(active_workers),\n-      _subtasks(ParallelRootType::sentinel),\n-      _old_gen(old_gen),\n-      _gen_top(old_gen->object_space()->top()),\n-      _active_workers(active_workers),\n-      _is_old_gen_empty(old_gen->object_space()->is_empty()),\n-      _terminator(active_workers, PSPromotionManager::vm_thread_promotion_manager()->stack_array_depth()) {\n+    WorkerTask(\"ScavengeRootsTask\"),\n+    _strong_roots_scope(active_workers),\n+    _subtasks(ParallelRootType::sentinel),\n+    _old_gen(old_gen),\n+    _gen_top(old_gen->object_space()->top()),\n+    _active_workers(active_workers),\n+    _is_old_gen_empty(old_gen->object_space()->is_empty()),\n+    _terminator(active_workers, PSPromotionManager::vm_thread_promotion_manager()->stack_array_depth()) {\n@@ -356,3 +321,1 @@\n-\/\/ This method contains no policy. You should probably\n-\/\/ be calling invoke() instead.\n-bool PSScavenge::invoke_no_policy() {\n+bool PSScavenge::invoke(bool clear_soft_refs) {\n@@ -362,3 +325,2 @@\n-  _gc_timer.register_gc_start();\n-\n-  if (GCLocker::check_active_before_gc()) {\n+  \/\/ Check for potential problems.\n+  if (!should_attempt_scavenge()) {\n@@ -368,0 +330,4 @@\n+  IsSTWGCActiveMark mark;\n+\n+  _gc_timer.register_gc_start();\n+\n@@ -371,5 +337,1 @@\n-  \/\/ Check for potential problems.\n-  if (!should_attempt_scavenge()) {\n-    return false;\n-  }\n-\n+  SvcGCMarker sgcm(SvcGCMarker::MINOR);\n@@ -428,1 +390,1 @@\n-    reference_processor()->start_discovery(false \/* always_clear *\/);\n+    reference_processor()->start_discovery(clear_soft_refs);\n@@ -540,4 +502,3 @@\n-          size_policy->compute_survivor_space_size_and_threshold(\n-                                                           _survivor_overflow,\n-                                                           _tenuring_threshold,\n-                                                           survivor_limit);\n+          size_policy->compute_survivor_space_size_and_threshold(_survivor_overflow,\n+                                                                 _tenuring_threshold,\n+                                                                 survivor_limit);\n@@ -545,3 +506,3 @@\n-       log_debug(gc, age)(\"Desired survivor size %zu bytes, new threshold %u (max threshold %u)\",\n-                          size_policy->calculated_survivor_size_in_bytes(),\n-                          _tenuring_threshold, MaxTenuringThreshold);\n+        log_debug(gc, age)(\"Desired survivor size %zu bytes, new threshold %u (max threshold %u)\",\n+                           size_policy->calculated_survivor_size_in_bytes(),\n+                           _tenuring_threshold, MaxTenuringThreshold);\n@@ -571,2 +532,2 @@\n-            young_gen->from_space()->capacity_in_bytes() -\n-            young_gen->to_space()->capacity_in_bytes();\n+                                 young_gen->from_space()->capacity_in_bytes() -\n+                                 young_gen->to_space()->capacity_in_bytes();\n@@ -602,1 +563,1 @@\n-                        size_policy->calculated_survivor_size_in_bytes());\n+                               size_policy->calculated_survivor_size_in_bytes());\n@@ -660,5 +621,0 @@\n-  PSGCAdaptivePolicyCounters* counters = heap->gc_policy_counters();\n-\n-  if (UsePerfData) {\n-    counters->update_scavenge_skipped(not_skipped);\n-  }\n@@ -669,1 +625,0 @@\n-  \/\/ Do not attempt to promote unless to_space is empty\n@@ -671,3 +626,1 @@\n-    if (UsePerfData) {\n-      counters->update_scavenge_skipped(to_space_not_empty);\n-    }\n+    \/\/ To-space is not empty; should run full-gc instead.\n@@ -690,3 +643,0 @@\n-  if (young_gen->used_in_bytes() < (size_t) policy->padded_average_promoted_in_bytes()) {\n-    log_trace(ergo)(\" padded_promoted_average is greater than maximum promotion = \" SIZE_FORMAT, young_gen->used_in_bytes());\n-  }\n@@ -694,5 +644,0 @@\n-  if (!result) {\n-    if (UsePerfData) {\n-      counters->update_scavenge_skipped(promoted_too_large);\n-    }\n-  }\n","filename":"src\/hotspot\/share\/gc\/parallel\/psScavenge.cpp","additions":28,"deletions":83,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -48,7 +48,0 @@\n- enum ScavengeSkippedCause {\n-   not_skipped = 0,\n-   to_space_not_empty,\n-   promoted_too_large,\n-   full_follows_scavenge\n- };\n-\n@@ -108,4 +101,3 @@\n-  \/\/ Scavenge entry point.  This may invoke a full gc; return true if so.\n-  static bool invoke();\n-  \/\/ Return true if a collection was done; false otherwise.\n-  static bool invoke_no_policy();\n+  \/\/ Scavenge entry point.\n+  \/\/ Return true iff a young-gc is completed without promotion-failure.\n+  static bool invoke(bool clear_soft_refs);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psScavenge.hpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -34,3 +34,5 @@\n-VM_ParallelGCFailedAllocation::VM_ParallelGCFailedAllocation(size_t word_size,\n-                                                             uint gc_count) :\n-    VM_CollectForAllocation(word_size, gc_count, GCCause::_allocation_failure) {\n+VM_ParallelCollectForAllocation::VM_ParallelCollectForAllocation(size_t word_size,\n+                                                                 bool is_tlab,\n+                                                                 uint gc_count) :\n+  VM_CollectForAllocation(word_size, gc_count, GCCause::_allocation_failure),\n+  _is_tlab(is_tlab) {\n@@ -40,3 +42,1 @@\n-void VM_ParallelGCFailedAllocation::doit() {\n-  SvcGCMarker sgcm(SvcGCMarker::MINOR);\n-\n+void VM_ParallelCollectForAllocation::doit() {\n@@ -46,1 +46,1 @@\n-  _result = heap->failed_mem_allocate(_word_size);\n+  _result = heap->satisfy_failed_allocation(_word_size, _is_tlab);\n@@ -59,1 +59,1 @@\n-VM_ParallelGCSystemGC::VM_ParallelGCSystemGC(uint gc_count,\n+VM_ParallelGCCollect::VM_ParallelGCCollect(uint gc_count,\n@@ -62,7 +62,1 @@\n-  VM_GC_Operation(gc_count, gc_cause, full_gc_count, is_cause_full(gc_cause)),\n-  _full_gc_succeeded(false)\n-{\n-}\n-\n-void VM_ParallelGCSystemGC::doit() {\n-  SvcGCMarker sgcm(SvcGCMarker::FULL);\n+  VM_GC_Operation(gc_count, gc_cause, full_gc_count, is_cause_full(gc_cause)) {}\n@@ -70,0 +64,1 @@\n+void VM_ParallelGCCollect::doit() {\n@@ -73,6 +68,1 @@\n-  if (!_full) {\n-    \/\/ If (and only if) the scavenge fails, this will invoke a full gc.\n-    _full_gc_succeeded = heap->invoke_scavenge();\n-  } else {\n-    _full_gc_succeeded = PSParallelCompact::invoke(false);\n-  }\n+  heap->try_collect_at_safepoint(_full);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psVMOperations.cpp","additions":11,"deletions":21,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -32,3 +32,4 @@\n-class VM_ParallelGCFailedAllocation : public VM_CollectForAllocation {\n- public:\n-  VM_ParallelGCFailedAllocation(size_t word_size, uint gc_count);\n+class VM_ParallelCollectForAllocation : public VM_CollectForAllocation {\n+  bool _is_tlab;\n+public:\n+  VM_ParallelCollectForAllocation(size_t word_size, bool is_tlab, uint gc_count);\n@@ -37,1 +38,1 @@\n-    return VMOp_ParallelGCFailedAllocation;\n+    return VMOp_ParallelCollectForAllocation;\n@@ -42,2 +43,1 @@\n-class VM_ParallelGCSystemGC: public VM_GC_Operation {\n-  bool _full_gc_succeeded;\n+class VM_ParallelGCCollect: public VM_GC_Operation {\n@@ -45,2 +45,2 @@\n-  VM_ParallelGCSystemGC(uint gc_count, uint full_gc_count, GCCause::Cause gc_cause);\n-  virtual VMOp_Type type() const { return VMOp_ParallelGCSystemGC; }\n+  VM_ParallelGCCollect(uint gc_count, uint full_gc_count, GCCause::Cause gc_cause);\n+  virtual VMOp_Type type() const { return VMOp_ParallelGCCollect; }\n@@ -48,1 +48,0 @@\n-  bool full_gc_succeeded() const { return _full_gc_succeeded; }\n","filename":"src\/hotspot\/share\/gc\/parallel\/psVMOperations.hpp","additions":8,"deletions":9,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-\/\/        VM_ParallelGCSystemGC\n+\/\/        VM_ParallelGCCollect\n@@ -48,1 +48,1 @@\n-\/\/          VM_ParallelGCFailedAllocation\n+\/\/          VM_ParallelCollectForAllocation\n@@ -67,1 +67,1 @@\n-\/\/  VM_ParallelGCFailedAllocation\n+\/\/  VM_ParallelCollectForAllocation\n@@ -73,1 +73,1 @@\n-\/\/  VM_ParallelGCSystemGC\n+\/\/  VM_ParallelGCCollect\n","filename":"src\/hotspot\/share\/gc\/shared\/gcVMOperations.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -55,2 +55,2 @@\n-  template(ParallelGCFailedAllocation)            \\\n-  template(ParallelGCSystemGC)                    \\\n+  template(ParallelCollectForAllocation)          \\\n+  template(ParallelGCCollect)                     \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -462,2 +462,0 @@\n-alias sun.gc.policy.fullFollowsScavenge           \/\/ 1.5.0 b39\n-\thotspot.gc.policy.full_follows_scavenge   \/\/ 1.5.0 b21\n@@ -511,2 +509,0 @@\n-alias sun.gc.policy.scavengeSkipped               \/\/ 1.5.0 b39\n-\thotspot.gc.policy.scavenge_skipped        \/\/ 1.5.0 b21\n","filename":"src\/jdk.internal.jvmstat\/share\/classes\/sun\/jvmstat\/perfdata\/resources\/aliasmap","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -46,1 +46,1 @@\n-    private static final String VM_OPERATION = \"ParallelGCSystemGC\";\n+    private static final String VM_OPERATION = \"ParallelGCCollect\";\n","filename":"test\/jdk\/jdk\/jfr\/event\/runtime\/TestVMOperation.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}