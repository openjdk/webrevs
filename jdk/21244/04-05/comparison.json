{"files":[{"patch":"@@ -6176,1 +6176,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -54,0 +54,13 @@\n+    public static final long mask1 = r.nextLong(0xFFFFFFFFL);\n+    public static final long mask2 = r.nextLong(0xFFFFFFFFL);\n+    public static final long mask3 = r.nextLong(0xFFFFFFFFL);\n+    public static final long mask4 = r.nextLong(0xFFFFFFFFL);\n+    public static final long mask5 = r.nextLong(0xFFFFFFFFL);\n+    public static final long mask6 = r.nextLong(0xFFFFFFFFL);\n+\n+    public static final int shift1 = r.nextInt(32) + 32;\n+    public static final int shift2 = r.nextInt(32) + 32;\n+    public static final int shift3 = r.nextInt(32) + 32;\n+    public static final int shift4 = r.nextInt(32) + 32;\n+    public static final int shift5 = r.nextInt(32) + 32;\n+\n@@ -97,0 +110,1 @@\n+    @IR(counts = {\"vmuludq\", \" >0 \"}, phase = CompilePhase.FINAL_CODE, applyIfCPUFeature = {\"avx\", \"true\"})\n@@ -103,2 +117,2 @@\n-            vsrc1.lanewise(VectorOperators.AND, 0xFFFFFL)\n-                 .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.AND, 0xFFFFFL))\n+            vsrc1.lanewise(VectorOperators.AND, mask1)\n+                 .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.AND, mask1))\n@@ -108,1 +122,1 @@\n-            res[i] = (lsrc1[i] & 0xFFFFFL) * (lsrc2[i] & 0xFFFFFL);\n+            res[i] = (lsrc1[i] & mask1) * (lsrc2[i] & mask1);\n@@ -114,1 +128,1 @@\n-        validate(\"pattern1 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 & 0xFFFFFL) * (l2 & 0xFFFFFL));\n+        validate(\"pattern1 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 & mask1) * (l2 & mask1));\n@@ -119,0 +133,1 @@\n+    @IR(counts = {\"vmuludq\", \" >0 \"}, phase = CompilePhase.FINAL_CODE, applyIfCPUFeature = {\"avx\", \"true\"})\n@@ -125,2 +140,2 @@\n-            vsrc1.lanewise(VectorOperators.AND, 0xFFFFFFL)\n-                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.LSHR, 31))\n+            vsrc1.lanewise(VectorOperators.AND, mask2)\n+                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.LSHR, shift1))\n@@ -130,1 +145,1 @@\n-            res[i] = (lsrc1[i] & 0xFFFFFFL) * (lsrc2[i] >>> 31);\n+            res[i] = (lsrc1[i] & mask2) * (lsrc2[i] >>> shift1);\n@@ -136,1 +151,1 @@\n-        validate(\"pattern2 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 & 0xFFFFFFL) * (l2 >>> 31));\n+        validate(\"pattern2 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 & mask2) * (l2 >>> shift1));\n@@ -141,0 +156,1 @@\n+    @IR(counts = {\"vmuludq\", \" >0 \"}, phase = CompilePhase.FINAL_CODE, applyIfCPUFeature = {\"avx\", \"true\"})\n@@ -147,2 +163,2 @@\n-            vsrc1.lanewise(VectorOperators.LSHR, 32)\n-                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.LSHR, 32))\n+            vsrc1.lanewise(VectorOperators.LSHR, shift2)\n+                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.LSHR, shift3))\n@@ -152,1 +168,1 @@\n-            res[i] = (lsrc1[i] >>> 32) * (lsrc2[i] >>> 32);\n+            res[i] = (lsrc1[i] >>> shift2) * (lsrc2[i] >>> shift3);\n@@ -158,1 +174,1 @@\n-        validate(\"pattern3 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >>> 32) * (l2 >>> 32));\n+        validate(\"pattern3 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >>> shift2) * (l2 >>> shift3));\n@@ -163,0 +179,1 @@\n+    @IR(counts = {\"vmuludq\", \" >0 \"}, applyIfCPUFeature = {\"avx\", \"true\"}, phase = CompilePhase.FINAL_CODE)\n@@ -169,2 +186,2 @@\n-            vsrc1.lanewise(VectorOperators.LSHR, 30)\n-                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.AND, 0xFFFFFFFL))\n+            vsrc1.lanewise(VectorOperators.LSHR, shift4)\n+                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.AND, mask4))\n@@ -174,1 +191,1 @@\n-            res[i] = (lsrc1[i] >>> 30) * (lsrc2[i] & 0xFFFFFFFL);\n+            res[i] = (lsrc1[i] >>> shift4) * (lsrc2[i] & mask4);\n@@ -180,1 +197,1 @@\n-        validate(\"pattern4 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >>> 30) * (l2 & 0xFFFFFFFL));\n+        validate(\"pattern4 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >>> shift4) * (l2 & mask4));\n@@ -185,0 +202,1 @@\n+    @IR(counts = {\"vmuldq\", \" >0 \"}, applyIfCPUFeature = {\"avx\", \"true\"}, phase = CompilePhase.FINAL_CODE)\n@@ -210,0 +228,1 @@\n+    @IR(counts = {\"vmuldq\", \" >0 \"}, applyIfCPUFeature = {\"avx\", \"true\"}, phase = CompilePhase.FINAL_CODE)\n@@ -216,2 +235,2 @@\n-            vsrc1.lanewise(VectorOperators.ASHR, 22)\n-                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.ASHR, 22))\n+            vsrc1.lanewise(VectorOperators.ASHR, shift5)\n+                .lanewise(VectorOperators.MUL, vsrc2.lanewise(VectorOperators.ASHR, shift5))\n@@ -221,1 +240,1 @@\n-            res[i] = (lsrc1[i] >> 22) * (lsrc2[i] >> 22);\n+            res[i] = (lsrc1[i] >> shift5) * (lsrc2[i] >> shift5);\n@@ -227,1 +246,1 @@\n-        validate(\"pattern6 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >> 22) * (l2 >> 22));\n+        validate(\"pattern6 \", res, lsrc1, lsrc2, (l1, l2) -> (l1 >> shift5) * (l2 >> shift5));\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/VectorMultiplyOpt.java","additions":39,"deletions":20,"binary":false,"changes":59,"status":"modified"}]}