{"files":[{"patch":"@@ -342,5 +342,1 @@\n-    if (LockingMode == LM_MONITOR) {\n-      __ j(*stub->entry());\n-    } else {\n-      __ unlock_object(x15, x14, x10, x16, *stub->entry());\n-    }\n+    __ unlock_object(x15, x14, x10, x16, *stub->entry());\n@@ -1500,7 +1496,1 @@\n-  if (LockingMode == LM_MONITOR) {\n-    if (op->info() != nullptr) {\n-      add_debug_info_for_null_check_here(op->info());\n-      __ null_check(obj, -1);\n-    }\n-    __ j(*op->stub()->entry());\n-  } else if (op->code() == lir_lock) {\n+  if (op->code() == lir_lock) {\n","filename":"src\/hotspot\/cpu\/riscv\/c1_LIRAssembler_riscv.cpp","additions":2,"deletions":12,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -52,2 +52,0 @@\n-  const int aligned_mask = BytesPerWord - 1;\n-  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n@@ -64,50 +62,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    lightweight_lock(disp_hdr, obj, hdr, temp, t1, slow_case);\n-  } else if (LockingMode == LM_LEGACY) {\n-\n-    if (DiagnoseSyncOnValueBasedClasses != 0) {\n-      load_klass(hdr, obj);\n-      lbu(hdr, Address(hdr, Klass::misc_flags_offset()));\n-      test_bit(temp, hdr, exact_log2(KlassFlags::_misc_is_value_based_class));\n-      bnez(temp, slow_case, \/* is_far *\/ true);\n-    }\n-\n-    Label done;\n-    \/\/ Load object header\n-    ld(hdr, Address(obj, hdr_offset));\n-    \/\/ and mark it as unlocked\n-    ori(hdr, hdr, markWord::unlocked_value);\n-    \/\/ save unlocked object header into the displaced header location on the stack\n-    sd(hdr, Address(disp_hdr, 0));\n-    \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-    \/\/ displaced header address in the object header - if it is not the same, get the\n-    \/\/ object header instead\n-    la(temp, Address(obj, hdr_offset));\n-    \/\/ if the object header was the same, we're done\n-    cmpxchgptr(hdr, disp_hdr, temp, t1, done, \/*fallthough*\/nullptr);\n-    \/\/ if the object header was not the same, it is now in the hdr register\n-    \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-    \/\/\n-    \/\/ 1) (hdr & aligned_mask) == 0\n-    \/\/ 2) sp <= hdr\n-    \/\/ 3) hdr <= sp + page_size\n-    \/\/\n-    \/\/ these 3 tests can be done by evaluating the following expression:\n-    \/\/\n-    \/\/ (hdr -sp) & (aligned_mask - page_size)\n-    \/\/\n-    \/\/ assuming both the stack pointer and page_size have their least\n-    \/\/ significant 2 bits cleared and page_size is a power of 2\n-    sub(hdr, hdr, sp);\n-    mv(temp, aligned_mask - (int)os::vm_page_size());\n-    andr(hdr, hdr, temp);\n-    \/\/ for recursive locking, the result is zero => save it in the displaced header\n-    \/\/ location (null in the displaced hdr location indicates recursive locking)\n-    sd(hdr, Address(disp_hdr, 0));\n-    \/\/ otherwise we don't care about the result and handle locking via runtime call\n-    bnez(hdr, slow_case, \/* is_far *\/ true);\n-\n-    \/\/ done\n-    bind(done);\n-    inc_held_monitor_count(t0);\n-  }\n+  lightweight_lock(disp_hdr, obj, hdr, temp, t1, slow_case);\n@@ -119,2 +68,0 @@\n-  const int aligned_mask = BytesPerWord - 1;\n-  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n@@ -122,9 +69,0 @@\n-  Label done;\n-\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n-    \/\/ load displaced header\n-    ld(hdr, Address(disp_hdr, 0));\n-    \/\/ if the loaded hdr is null we had recursive locking\n-    \/\/ if we had recursive locking, we are done\n-    beqz(hdr, done);\n-  }\n@@ -136,19 +74,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    lightweight_unlock(obj, hdr, temp, t1, slow_case);\n-  } else if (LockingMode == LM_LEGACY) {\n-    \/\/ test if object header is pointing to the displaced header, and if so, restore\n-    \/\/ the displaced header in the object - if the object header is not pointing to\n-    \/\/ the displaced header, get the object header instead\n-    \/\/ if the object header was not pointing to the displaced header,\n-    \/\/ we do unlocking via runtime call\n-    if (hdr_offset) {\n-      la(temp, Address(obj, hdr_offset));\n-      cmpxchgptr(disp_hdr, hdr, temp, t1, done, &slow_case);\n-    } else {\n-      cmpxchgptr(disp_hdr, hdr, obj, t1, done, &slow_case);\n-    }\n-\n-    \/\/ done\n-    bind(done);\n-    dec_held_monitor_count(t0);\n-  }\n+  lightweight_unlock(obj, hdr, temp, t1, slow_case);\n","filename":"src\/hotspot\/cpu\/riscv\/c1_MacroAssembler_riscv.cpp","additions":2,"deletions":82,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -46,228 +46,0 @@\n-void C2_MacroAssembler::fast_lock(Register objectReg, Register boxReg,\n-                                  Register tmp1Reg, Register tmp2Reg, Register tmp3Reg, Register tmp4Reg) {\n-  \/\/ Use cr register to indicate the fast_lock result: zero for success; non-zero for failure.\n-  Register flag = t1;\n-  Register oop = objectReg;\n-  Register box = boxReg;\n-  Register disp_hdr = tmp1Reg;\n-  Register tmp = tmp2Reg;\n-  Label object_has_monitor;\n-  \/\/ Finish fast lock successfully. MUST branch to with flag == 0\n-  Label locked;\n-  \/\/ Finish fast lock unsuccessfully. slow_path MUST branch to with flag != 0\n-  Label slow_path;\n-\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_lock_lightweight\");\n-  assert_different_registers(oop, box, tmp, disp_hdr, flag, tmp3Reg, t0);\n-\n-  mv(flag, 1);\n-\n-  \/\/ Load markWord from object into displaced_header.\n-  ld(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(tmp, oop);\n-    lbu(tmp, Address(tmp, Klass::misc_flags_offset()));\n-    test_bit(tmp, tmp, exact_log2(KlassFlags::_misc_is_value_based_class));\n-    bnez(tmp, slow_path);\n-  }\n-\n-  \/\/ Check for existing monitor\n-  test_bit(tmp, disp_hdr, exact_log2(markWord::monitor_value));\n-  bnez(tmp, object_has_monitor);\n-\n-  if (LockingMode == LM_MONITOR) {\n-    j(slow_path);\n-  } else {\n-    assert(LockingMode == LM_LEGACY, \"must be\");\n-    \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-    ori(tmp, disp_hdr, markWord::unlocked_value);\n-\n-    \/\/ Initialize the box. (Must happen before we update the object mark!)\n-    sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Compare object markWord with an unlocked value (tmp) and if\n-    \/\/ equal exchange the stack address of our box with object markWord.\n-    \/\/ On failure disp_hdr contains the possibly locked markWord.\n-    cmpxchg(\/*memory address*\/oop, \/*expected value*\/tmp, \/*new value*\/box, Assembler::int64,\n-            Assembler::aq, Assembler::rl, \/*result*\/disp_hdr);\n-    beq(disp_hdr, tmp, locked);\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-    \/\/ object, will have now locked it will continue at label locked\n-    \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-    \/\/ Check if the owner is self by comparing the value in the\n-    \/\/ markWord of object (disp_hdr) with the stack pointer.\n-    sub(disp_hdr, disp_hdr, sp);\n-    mv(tmp, (intptr_t) (~(os::vm_page_size()-1) | (uintptr_t)markWord::lock_mask_in_place));\n-    \/\/ If (mark & lock_mask) == 0 and mark - sp < page_size, we are stack-locking and goto label\n-    \/\/ locked, hence we can store 0 as the displaced header in the box, which indicates that it\n-    \/\/ is a recursive lock.\n-    andr(tmp\/*==0?*\/, disp_hdr, tmp);\n-    sd(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-    beqz(tmp, locked);\n-    j(slow_path);\n-  }\n-\n-  \/\/ Handle existing monitor.\n-  bind(object_has_monitor);\n-\n-  \/\/ Try to CAS owner (no owner => current thread's _monitor_owner_id).\n-  add(tmp, disp_hdr, (in_bytes(ObjectMonitor::owner_offset()) - markWord::monitor_value));\n-  Register tid = tmp4Reg;\n-  ld(tid, Address(xthread, JavaThread::monitor_owner_id_offset()));\n-  cmpxchg(\/*memory address*\/tmp, \/*expected value*\/zr, \/*new value*\/tid, Assembler::int64,\n-          Assembler::aq, Assembler::rl, \/*result*\/tmp3Reg); \/\/ cas succeeds if tmp3Reg == zr(expected)\n-\n-  \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-  \/\/ lock. The fast-path monitor unlock code checks for\n-  \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-  \/\/ relevant bit set, and also matches ObjectSynchronizer::slow_enter.\n-  mv(tmp, (address)markWord::unused_mark().value());\n-  sd(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-  beqz(tmp3Reg, locked); \/\/ CAS success means locking succeeded\n-\n-  bne(tmp3Reg, tid, slow_path); \/\/ Check for recursive locking\n-\n-  \/\/ Recursive lock case\n-  increment(Address(disp_hdr, in_bytes(ObjectMonitor::recursions_offset()) - markWord::monitor_value), 1, tmp2Reg, tmp3Reg);\n-\n-  bind(locked);\n-  mv(flag, zr);\n-  if (LockingMode == LM_LEGACY) {\n-    inc_held_monitor_count(t0);\n-  }\n-\n-#ifdef ASSERT\n-  \/\/ Check that locked label is reached with flag == 0.\n-  Label flag_correct;\n-  beqz(flag, flag_correct);\n-  stop(\"Fast Lock Flag != 0\");\n-#endif\n-\n-  bind(slow_path);\n-#ifdef ASSERT\n-  \/\/ Check that slow_path label is reached with flag != 0.\n-  bnez(flag, flag_correct);\n-  stop(\"Fast Lock Flag == 0\");\n-  bind(flag_correct);\n-#endif\n-  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n-}\n-\n-void C2_MacroAssembler::fast_unlock(Register objectReg, Register boxReg,\n-                                    Register tmp1Reg, Register tmp2Reg) {\n-  \/\/ Use cr register to indicate the fast_unlock result: zero for success; non-zero for failure.\n-  Register flag = t1;\n-  Register oop = objectReg;\n-  Register box = boxReg;\n-  Register disp_hdr = tmp1Reg;\n-  Register owner_addr = tmp1Reg;\n-  Register tmp = tmp2Reg;\n-  Label object_has_monitor;\n-  \/\/ Finish fast lock successfully. MUST branch to with flag == 0\n-  Label unlocked;\n-  \/\/ Finish fast lock unsuccessfully. slow_path MUST branch to with flag != 0\n-  Label slow_path;\n-\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"lightweight locking should use fast_unlock_lightweight\");\n-  assert_different_registers(oop, box, tmp, disp_hdr, flag, t0);\n-\n-  mv(flag, 1);\n-\n-  if (LockingMode == LM_LEGACY) {\n-    \/\/ Find the lock address and load the displaced header from the stack.\n-    ld(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ If the displaced header is 0, we have a recursive unlock.\n-    beqz(disp_hdr, unlocked);\n-  }\n-\n-  \/\/ Handle existing monitor.\n-  ld(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));\n-  test_bit(t0, tmp, exact_log2(markWord::monitor_value));\n-  bnez(t0, object_has_monitor);\n-\n-  if (LockingMode == LM_MONITOR) {\n-    j(slow_path);\n-  } else {\n-    assert(LockingMode == LM_LEGACY, \"must be\");\n-    \/\/ Check if it is still a light weight lock, this is true if we\n-    \/\/ see the stack address of the basicLock in the markWord of the\n-    \/\/ object.\n-\n-    cmpxchg(\/*memory address*\/oop, \/*expected value*\/box, \/*new value*\/disp_hdr, Assembler::int64,\n-            Assembler::relaxed, Assembler::rl, \/*result*\/tmp);\n-    beq(box, tmp, unlocked); \/\/ box == tmp if cas succeeds\n-    j(slow_path);\n-  }\n-\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-  \/\/ Handle existing monitor.\n-  bind(object_has_monitor);\n-  subi(tmp, tmp, (int)markWord::monitor_value); \/\/ monitor\n-  ld(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset()));\n-\n-  Label notRecursive;\n-  beqz(disp_hdr, notRecursive); \/\/ Will be 0 if not recursive.\n-\n-  \/\/ Recursive lock\n-  subi(disp_hdr, disp_hdr, 1);\n-  sd(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset()));\n-  j(unlocked);\n-\n-  bind(notRecursive);\n-  \/\/ Compute owner address.\n-  la(owner_addr, Address(tmp, ObjectMonitor::owner_offset()));\n-\n-  \/\/ Set owner to null.\n-  \/\/ Release to satisfy the JMM\n-  membar(MacroAssembler::LoadStore | MacroAssembler::StoreStore);\n-  sd(zr, Address(owner_addr));\n-  \/\/ We need a full fence after clearing owner to avoid stranding.\n-  \/\/ StoreLoad achieves this.\n-  membar(StoreLoad);\n-\n-  \/\/ Check if the entry_list is empty.\n-  ld(t0, Address(tmp, ObjectMonitor::entry_list_offset()));\n-  beqz(t0, unlocked); \/\/ If so we are done.\n-\n-  \/\/ Check if there is a successor.\n-  ld(t0, Address(tmp, ObjectMonitor::succ_offset()));\n-  bnez(t0, unlocked); \/\/ If so we are done.\n-\n-  \/\/ Save the monitor pointer in the current thread, so we can try to\n-  \/\/ reacquire the lock in SharedRuntime::monitor_exit_helper().\n-  sd(tmp, Address(xthread, JavaThread::unlocked_inflated_monitor_offset()));\n-\n-  mv(flag, 1);\n-  j(slow_path);\n-\n-  bind(unlocked);\n-  mv(flag, zr);\n-  if (LockingMode == LM_LEGACY) {\n-    dec_held_monitor_count(t0);\n-  }\n-\n-#ifdef ASSERT\n-  \/\/ Check that unlocked label is reached with flag == 0.\n-  Label flag_correct;\n-  beqz(flag, flag_correct);\n-  stop(\"Fast Lock Flag != 0\");\n-#endif\n-\n-  bind(slow_path);\n-#ifdef ASSERT\n-  \/\/ Check that slow_path label is reached with flag != 0.\n-  bnez(flag, flag_correct);\n-  stop(\"Fast Lock Flag == 0\");\n-  bind(flag_correct);\n-#endif\n-  \/\/ C2 uses the value of flag (0 vs !0) to determine the continuation.\n-}\n-\n@@ -279,1 +51,0 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n@@ -442,1 +213,0 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":0,"deletions":230,"binary":false,"changes":230,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,5 +52,0 @@\n-  \/\/ Code used by cmpFastLock and cmpFastUnlock mach instructions in .ad file.\n-  void fast_lock(Register object, Register box,\n-                 Register tmp1, Register tmp2, Register tmp3, Register tmp4);\n-  void fast_unlock(Register object, Register box, Register tmp1, Register tmp2);\n-\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -736,34 +736,0 @@\n-  if (LockingMode == LM_MONITOR) {\n-    call_VM_preemptable(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            lock_reg);\n-  } else {\n-    Label count, done;\n-\n-    const Register swap_reg = x10;\n-    const Register tmp = c_rarg2;\n-    const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-    const Register tmp2 = c_rarg4;\n-    const Register tmp3 = c_rarg5;\n-\n-    const int obj_offset = in_bytes(BasicObjectLock::obj_offset());\n-    const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n-\n-    Label slow_case;\n-\n-    \/\/ Load object pointer into obj_reg c_rarg3\n-    ld(obj_reg, Address(lock_reg, obj_offset));\n-\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      lightweight_lock(lock_reg, obj_reg, tmp, tmp2, tmp3, slow_case);\n-      j(done);\n-    } else if (LockingMode == LM_LEGACY) {\n-\n-      if (DiagnoseSyncOnValueBasedClasses != 0) {\n-        load_klass(tmp, obj_reg);\n-        lbu(tmp, Address(tmp, Klass::misc_flags_offset()));\n-        test_bit(tmp, tmp, exact_log2(KlassFlags::_misc_is_value_based_class));\n-        bnez(tmp, slow_case);\n-      }\n@@ -771,33 +737,4 @@\n-      \/\/ Load (object->mark() | 1) into swap_reg\n-      ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      ori(swap_reg, t0, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      sd(swap_reg, Address(lock_reg, mark_offset));\n-\n-      assert(lock_offset == 0,\n-             \"displached header must be first word in BasicObjectLock\");\n-\n-      cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, tmp, count, \/*fallthrough*\/nullptr);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 7) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 3 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg x10 as the result of cmpxchg\n-      sub(swap_reg, swap_reg, sp);\n-      mv(t0, (int64_t)(7 - (int)os::vm_page_size()));\n-      andr(swap_reg, swap_reg, t0);\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      sd(swap_reg, Address(lock_reg, mark_offset));\n-      bnez(swap_reg, slow_case);\n-\n-      bind(count);\n-      inc_held_monitor_count(t0);\n-      j(done);\n-    }\n+  const Register tmp = c_rarg2;\n+  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n+  const Register tmp2 = c_rarg4;\n+  const Register tmp3 = c_rarg5;\n@@ -805,1 +742,2 @@\n-    bind(slow_case);\n+  \/\/ Load object pointer into obj_reg (c_rarg3)\n+  ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -807,4 +745,3 @@\n-    \/\/ Call the runtime routine for slow case\n-    call_VM_preemptable(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            lock_reg);\n+  Label done, slow_case;\n+  lightweight_lock(lock_reg, obj_reg, tmp, tmp2, tmp3, slow_case);\n+  j(done);\n@@ -812,2 +749,7 @@\n-    bind(done);\n-  }\n+  bind(slow_case);\n+  \/\/ Call the runtime routine for slow case\n+  call_VM_preemptable(noreg,\n+          CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+          lock_reg);\n+\n+  bind(done);\n@@ -832,9 +774,4 @@\n-  if (LockingMode == LM_MONITOR) {\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n-  } else {\n-    Label count, done;\n-\n-    const Register swap_reg   = x10;\n-    const Register header_reg = c_rarg2;  \/\/ Will contain the old oopMark\n-    const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n-    const Register tmp_reg    = c_rarg4;  \/\/ Temporary used by lightweight_unlock\n+  const Register swap_reg   = x10;\n+  const Register header_reg = c_rarg2;  \/\/ Will contain the old oopMark\n+  const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n+  const Register tmp_reg    = c_rarg4;  \/\/ Temporary used by lightweight_unlock\n@@ -842,1 +779,1 @@\n-    save_bcp(); \/\/ Save in case of exception\n+  save_bcp(); \/\/ Save in case of exception\n@@ -844,23 +781,2 @@\n-    if (LockingMode != LM_LIGHTWEIGHT) {\n-      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-      \/\/ structure Store the BasicLock address into x10\n-      la(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset()));\n-    }\n-\n-    \/\/ Load oop into obj_reg(c_rarg3)\n-    ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n-\n-    \/\/ Free entry\n-    sd(zr, Address(lock_reg, BasicObjectLock::obj_offset()));\n-\n-    Label slow_case;\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      lightweight_unlock(obj_reg, header_reg, swap_reg, tmp_reg, slow_case);\n-      j(done);\n-    } else if (LockingMode == LM_LEGACY) {\n-      \/\/ Load the old header from BasicLock structure\n-      ld(header_reg, Address(swap_reg,\n-                             BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ Test for recursion\n-      beqz(header_reg, count);\n+  \/\/ Load oop into obj_reg (c_rarg3)\n+  ld(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -868,2 +784,2 @@\n-      \/\/ Atomic swap back the old header\n-      cmpxchg_obj_header(swap_reg, header_reg, obj_reg, tmp_reg, count, &slow_case);\n+  \/\/ Free entry\n+  sd(zr, Address(lock_reg, BasicObjectLock::obj_offset()));\n@@ -871,4 +787,3 @@\n-      bind(count);\n-      dec_held_monitor_count(t0);\n-      j(done);\n-    }\n+  Label done, slow_case;\n+  lightweight_unlock(obj_reg, header_reg, swap_reg, tmp_reg, slow_case);\n+  j(done);\n@@ -876,4 +791,4 @@\n-    bind(slow_case);\n-    \/\/ Call the runtime routine for slow case.\n-    sd(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset())); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+  bind(slow_case);\n+  \/\/ Call the runtime routine for slow case.\n+  sd(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset())); \/\/ restore obj\n+  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n@@ -881,3 +796,2 @@\n-    bind(done);\n-    restore_bcp();\n-  }\n+  bind(done);\n+  restore_bcp();\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":34,"deletions":120,"binary":false,"changes":154,"status":"modified"},{"patch":"@@ -6424,1 +6424,0 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n@@ -6484,1 +6483,0 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -11024,35 +11024,0 @@\n-instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box,\n-                     iRegPNoSp tmp1, iRegPNoSp tmp2, iRegPNoSp tmp3, iRegPNoSp tmp4)\n-%{\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4);\n-\n-  ins_cost(10 * DEFAULT_COST);\n-  format %{ \"fastlock $object,$box\\t! kills $tmp1,$tmp2,$tmp3,$tmp4 #@cmpFastLock\" %}\n-\n-  ins_encode %{\n-    __ fast_lock($object$$Register, $box$$Register,\n-                 $tmp1$$Register, $tmp2$$Register, $tmp3$$Register, $tmp4$$Register);\n-  %}\n-\n-  ins_pipe(pipe_serial);\n-%}\n-\n-\/\/ using t1 as the 'flag' register to bridge the BoolNode producers and consumers\n-instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp1, iRegPNoSp tmp2)\n-%{\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp1, TEMP tmp2);\n-\n-  ins_cost(10 * DEFAULT_COST);\n-  format %{ \"fastunlock $object,$box\\t! kills $tmp1, $tmp2, #@cmpFastUnlock\" %}\n-\n-  ins_encode %{\n-    __ fast_unlock($object$$Register, $box$$Register, $tmp1$$Register, $tmp2$$Register);\n-  %}\n-\n-  ins_pipe(pipe_serial);\n-%}\n-\n@@ -11062,1 +11027,0 @@\n-  predicate(LockingMode == LM_LIGHTWEIGHT);\n@@ -11077,0 +11041,1 @@\n+\/\/ using t1 as the 'flag' register to bridge the BoolNode producers and consumers\n@@ -11080,1 +11045,0 @@\n-  predicate(LockingMode == LM_LIGHTWEIGHT);\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":2,"deletions":38,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -1640,1 +1640,1 @@\n-  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+  if (method->is_object_wait0()) {\n@@ -1682,2 +1682,0 @@\n-    Label count;\n-\n@@ -1696,36 +1694,1 @@\n-    if (LockingMode == LM_MONITOR) {\n-      __ j(slow_path_lock);\n-    } else if (LockingMode == LM_LEGACY) {\n-      \/\/ Load (object->mark() | 1) into swap_reg % x10\n-      __ ld(t0, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ ori(swap_reg, t0, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-      \/\/ src -> dest if dest == x10 else x10 <- dest\n-      __ cmpxchg_obj_header(x10, lock_reg, obj_reg, lock_tmp, count, \/*fallthrough*\/nullptr);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg % 10 as the result of cmpxchg\n-\n-      __ sub(swap_reg, swap_reg, sp);\n-      __ mv(t0, 3 - (int)os::vm_page_size());\n-      __ andr(swap_reg, swap_reg, t0);\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ sd(swap_reg, Address(lock_reg, mark_word_offset));\n-      __ bnez(swap_reg, slow_path_lock);\n-\n-      __ bind(count);\n-      __ inc_held_monitor_count(t0);\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n-      __ lightweight_lock(lock_reg, obj_reg, swap_reg, tmp, lock_tmp, slow_path_lock);\n-    }\n+    __ lightweight_lock(lock_reg, obj_reg, swap_reg, tmp, lock_tmp, slow_path_lock);\n@@ -1792,1 +1755,1 @@\n-  if (LockingMode != LM_LEGACY && method->is_object_wait0()) {\n+  if (method->is_object_wait0()) {\n@@ -1821,12 +1784,0 @@\n-    Label done, not_recursive;\n-\n-    if (LockingMode == LM_LEGACY) {\n-      \/\/ Simple recursive lock?\n-      __ ld(t0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      __ bnez(t0, not_recursive);\n-      __ dec_held_monitor_count(t0);\n-      __ j(done);\n-    }\n-\n-    __ bind(not_recursive);\n-\n@@ -1838,17 +1789,1 @@\n-    if (LockingMode == LM_MONITOR) {\n-      __ j(slow_path_unlock);\n-    } else if (LockingMode == LM_LEGACY) {\n-      \/\/ get address of the stack lock\n-      __ la(x10, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ ld(old_hdr, Address(x10, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      Label count;\n-      __ cmpxchg_obj_header(x10, old_hdr, obj_reg, lock_tmp, count, &slow_path_unlock);\n-      __ bind(count);\n-      __ dec_held_monitor_count(t0);\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n-      __ lightweight_unlock(obj_reg, old_hdr, swap_reg, lock_tmp, slow_path_unlock);\n-    }\n+    __ lightweight_unlock(obj_reg, old_hdr, swap_reg, lock_tmp, slow_path_unlock);\n@@ -1861,2 +1796,0 @@\n-\n-    __ bind(done);\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":4,"deletions":71,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -1256,16 +1256,11 @@\n-  if (LockingMode != LM_LEGACY) {\n-    \/\/ Check preemption for Object.wait()\n-    Label not_preempted;\n-    __ ld(t1, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n-    __ beqz(t1, not_preempted);\n-    __ sd(zr, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n-    __ jr(t1);\n-    __ bind(native_return);\n-    __ restore_after_resume(true \/* is_native *\/);\n-    \/\/ reload result_handler\n-    __ ld(result_handler, Address(fp, frame::interpreter_frame_result_handler_offset * wordSize));\n-    __ bind(not_preempted);\n-  } else {\n-    \/\/ any pc will do so just use this one for LM_LEGACY to keep code together.\n-    __ bind(native_return);\n-  }\n+  \/\/ Check preemption for Object.wait()\n+  Label not_preempted;\n+  __ ld(t1, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+  __ beqz(t1, not_preempted);\n+  __ sd(zr, Address(xthread, JavaThread::preempt_alternate_return_offset()));\n+  __ jr(t1);\n+  __ bind(native_return);\n+  __ restore_after_resume(true \/* is_native *\/);\n+  \/\/ reload result_handler\n+  __ ld(result_handler, Address(fp, frame::interpreter_frame_result_handler_offset * wordSize));\n+  __ bind(not_preempted);\n","filename":"src\/hotspot\/cpu\/riscv\/templateInterpreterGenerator_riscv.cpp","additions":11,"deletions":16,"binary":false,"changes":27,"status":"modified"}]}