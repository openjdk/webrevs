{"files":[{"patch":"@@ -179,9 +179,6 @@\n-    if (!jt->in_deopt_handler() && !Universe::heap()->is_stw_gc_active())  {\n-      ThreadInAsgct tia(jt);\n-      Atomic::inc(&active_recordings);\n-      if (thread_state_in_java(jt)) {\n-        record_java_trace(jt, ucontext);\n-      } else if (thread_state_in_non_java(jt)) {\n-        record_native_trace(jt, ucontext);\n-      }\n-      Atomic::dec(&active_recordings);\n+    ThreadInAsgct tia(jt);\n+    Atomic::inc(&active_recordings);\n+    if (thread_state_in_java(jt)) {\n+      record_java_trace(jt, ucontext);\n+    } else if (thread_state_in_non_java(jt)) {\n+      record_native_trace(jt, ucontext);\n@@ -189,0 +186,1 @@\n+    Atomic::dec(&active_recordings);\n@@ -227,0 +225,127 @@\n+\/\/ Queue used for the fresh traces\n+\/\/\n+\/\/ Fixed size async-signal-safe MPMC queue backed by an array.\n+\/\/ Serves for passing traces from a thread being sampled (producer)\n+\/\/ to a thread emitting JFR events (consumer).\n+\/\/ Does not own any frames.\n+\/\/\n+\/\/ _head and _tail of the queue are virtual (always increasing) positions modulo 2^32.\n+\/\/ Actual index into the backing array is computed as (position % _capacity).\n+\/\/ Generation G of an element at position P is the number of full wraps around the array:\n+\/\/   G = P \/ _capacity\n+\/\/ Generation allows to disambiguate situations when _head and _tail point to the same element.\n+\/\/\n+\/\/ Each element of the array is assigned a state, which encodes full\/empty flag in bit 31\n+\/\/ and the generation G of the element in bits 0..30:\n+\/\/   state (0,G): the element is empty and avaialble for enqueue() in generation G,\n+\/\/   state (1,G): the element is full and available for dequeue() in generation G.\n+\/\/ Possible transitions are:\n+\/\/   (0,G) --enqueue--> (1,G) --dequeue--> (0,G+1)\n+class JfrTraceQueue {\n+\n+  struct Element {\n+    \/\/ Encodes full\/empty flag along with generation of the element.\n+    \/\/ Also, establishes happens-before relationship between producer and consumer.\n+    \/\/ Update of this field \"commits\" enqueue\/dequeue transaction.\n+    u4 _state;\n+    JfrCPUTimeTrace* _trace;\n+  };\n+\n+  Element* _data;\n+  u4 _capacity;\n+  volatile size_t _size = 0;\n+\n+  \/\/ Pad _head and _tail to avoid false sharing\n+  DEFINE_PAD_MINUS_SIZE(0, DEFAULT_PADDING_SIZE, sizeof(Element*) + sizeof(u4));\n+\n+  volatile u4 _head;\n+  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_PADDING_SIZE, sizeof(u4));\n+\n+  volatile u4 _tail;\n+  DEFINE_PAD_MINUS_SIZE(2, DEFAULT_PADDING_SIZE, sizeof(u4));\n+\n+  inline Element* element(u4 position) {\n+    return &_data[position % _capacity];\n+  }\n+\n+  inline u4 state_empty(u4 position) {\n+    return (position \/ _capacity) & 0x7fffffff;\n+  }\n+\n+  inline u4 state_full(u4 position) {\n+    return (position \/ _capacity) | 0x80000000;\n+  }\n+\n+public:\n+  JfrTraceQueue(u4 capacity) : _capacity(capacity), _head(0), _tail(0) {\n+    _data = JfrCHeapObj::new_array<Element>(capacity);\n+    memset(_data, 0, _capacity * sizeof(Element));\n+  }\n+\n+  ~JfrTraceQueue() {\n+    JfrCHeapObj::free(_data, _capacity * sizeof(Element));\n+  }\n+\n+  bool enqueue(JfrCPUTimeTrace* trace) {\n+    int count = 10000;\n+    while (count -- > 0) {\n+      u4 tail = Atomic::load_acquire(&_tail);\n+      Element* e = element(tail);\n+      u4 state = Atomic::load_acquire(&e->_state);\n+      if (state == state_empty(tail)) {\n+        if (Atomic::cmpxchg(&_tail, tail, tail + 1, memory_order_seq_cst) == tail) {\n+            e->_trace = trace;\n+            \/\/ Mark element as full in current generation\n+            Atomic::release_store(&e->_state, state_full(tail));\n+            Atomic::inc(&_size);\n+            return true;\n+        }\n+      } else if (state == state_full(tail)) {\n+        \/\/ Another thread has just filled the same position; retry operation\n+      } else {\n+        return false;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  JfrCPUTimeTrace* dequeue() {\n+    int count = 1000;\n+    while (count-- > 0) {\n+      u4 head = Atomic::load_acquire(&_head);\n+      Element* e = element(head);\n+      u4 state = Atomic::load_acquire(&e->_state);\n+      if (state == state_full(head)) {\n+        if (Atomic::cmpxchg(&_head, head, head + 1, memory_order_seq_cst) == head) {\n+            JfrCPUTimeTrace* trace = e->_trace;\n+            \/\/ After taking an element, mark it as empty in the next generation,\n+            \/\/ so we can reuse it again after completing the full circle\n+            Atomic::release_store(&e->_state, state_empty(head + _capacity));\n+            Atomic::dec(&_size);\n+            return trace;\n+        }\n+      } else if (state == state_empty(head)) {\n+        return nullptr; \/\/ Queue is empty\n+      } else {\n+        \/\/ Producer has not yet completed transaction\n+        \/\/ mark it as empty to prevent stalling\n+        if (count < 500) {\n+          Atomic::release_store(&e->_state, state_empty(head));\n+          Atomic::dec(&_size);\n+        }\n+      }\n+    }\n+    return nullptr; \/\/ prevent hanging\n+  }\n+\n+  void reset() {\n+    memset(_data, 0, _capacity * sizeof(Element));\n+    _head = 0;\n+    _tail = 0;\n+    OrderAccess::release();\n+  }\n+\n+  size_t approximate_size() const {\n+    return Atomic::load_acquire(&_size);\n+  }\n+};\n@@ -231,1 +356,1 @@\n-  JfrCPUTimeStack<JfrCPUTimeTrace*> _fresh;\n+  JfrTraceQueue _fresh;\n@@ -253,1 +378,15 @@\n-  JfrCPUTimeStack<JfrCPUTimeTrace*>& fresh() { return _fresh; }\n+  size_t capacity() const {\n+    return _max_traces;\n+  }\n+\n+  JfrCPUTimeTrace* get_fresh_trace() {\n+    return _fresh.dequeue();\n+  }\n+\n+  void return_trace(JfrCPUTimeTrace* trace) {\n+    _fresh.enqueue(trace);\n+  }\n+\n+  size_t fresh_frames() const {\n+    return _fresh.approximate_size();\n+  }\n@@ -477,1 +616,1 @@\n-  event.set_failed(sid != 0);\n+  event.set_failed(sid == 0);\n@@ -515,1 +654,1 @@\n-    _frame_store.fresh().enqueue(stack.at(i));\n+    _frame_store.return_trace(stack.at(i));\n@@ -657,1 +796,1 @@\n-  JfrCPUTimeTrace* trace = this->_frame_store.fresh().dequeue();\n+  JfrCPUTimeTrace* trace = _frame_store.get_fresh_trace();\n@@ -676,2 +815,2 @@\n-    u4 fresh_size = this->_frame_store.fresh().size();\n-    u4 fresh_capacity = this->_frame_store.fresh().capacity();\n+    u4 fresh_size = this->_frame_store.fresh_frames();\n+    u4 fresh_capacity = this->_frame_store.capacity();\n@@ -700,1 +839,1 @@\n-  if (timer_settime(timerid, 0, &its, NULL) == -1) {\n+  if (timer_settime(timerid, 0, &its, nullptr) == -1) {\n@@ -722,0 +861,1 @@\n+    log_error(jfr)(\"Failed to create cpu timer for thread sampling: %s\", os::strerror(os::get_last_error()));\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.cpp","additions":157,"deletions":17,"binary":false,"changes":174,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-        return NULL;\n+        return nullptr;\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrCPUTimeThreadSampler.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -130,1 +130,3 @@\n-      send_java_thread_start_event(JavaThread::cast(t));\n+      JavaThread* jt = JavaThread::cast(t);\n+      send_java_thread_start_event(jt);\n+      JfrCPUTimeThreadSampling::on_javathread_create(jt);\n@@ -227,0 +229,1 @@\n+    JfrCPUTimeThreadSampling::on_javathread_terminate(jt);\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrThreadLocal.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -404,1 +404,1 @@\n-label = \"Java Methods that Execute the Most from CPU Time Sampler (Experimental)\"\n+label = \"Java Methods that Execute the Most from CPU Time Sampler\"\n","filename":"src\/jdk.jfr\/share\/classes\/jdk\/jfr\/internal\/query\/view.ini","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}