{"files":[{"patch":"@@ -282,1 +282,0 @@\n-  _page_allocator->reset_statistics(_id);\n@@ -863,1 +862,1 @@\n-  stat_heap()->at_mark_start(_page_allocator->stats(this));\n+  stat_heap()->at_mark_start(_page_allocator->update_and_stats(this));\n@@ -1212,1 +1211,1 @@\n-  stat_heap()->at_mark_start(_page_allocator->stats(this));\n+  stat_heap()->at_mark_start(_page_allocator->update_and_stats(this));\n","filename":"src\/hotspot\/share\/gc\/z\/zGeneration.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1376,2 +1376,4 @@\n-ZPageAllocatorStats ZPageAllocator::stats(ZGeneration* generation) const {\n-  ZLocker<ZLock> locker(&_lock);\n+void ZPageAllocator::update_collection_stats(ZGenerationId id) {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"Should be at safepoint\");\n+#ifdef ASSERT\n+  size_t total_used = 0;\n@@ -1379,0 +1381,12 @@\n+  ZPartitionIterator iter(&_partitions);\n+  for (ZPartition* partition; iter.next(&partition);) {\n+    total_used += partition->_used;\n+  }\n+\n+  assert(total_used == _used, \"Must be consistent at safepoint %zu == %zu\", total_used, _used);\n+#endif\n+  _collection_stats[(int)id]._used_high = _used;\n+  _collection_stats[(int)id]._used_low = _used;\n+}\n+\n+ZPageAllocatorStats ZPageAllocator::stats_inner(ZGeneration* generation) const {\n@@ -1393,17 +1407,4 @@\n-void ZPageAllocator::reset_statistics(ZGenerationId id) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Should be at safepoint\");\n-#ifdef ASSERT\n-  {\n-    \/\/ We may free without safepoint synchronization, take the lock to get\n-    \/\/ consistent values.\n-    ZLocker<ZLock> locker(&_lock);\n-    size_t total_used = 0;\n-\n-    ZPartitionIterator iter(&_partitions);\n-    for (ZPartition* partition; iter.next(&partition);) {\n-      total_used += partition->_used;\n-    }\n-\n-    assert(total_used == _used, \"Must be consistent at safepoint %zu == %zu\", total_used, _used);\n-  }\n-#endif\n+ZPageAllocatorStats ZPageAllocator::stats(ZGeneration* generation) const {\n+  ZLocker<ZLock> locker(&_lock);\n+  return stats_inner(generation);\n+}\n@@ -1411,2 +1412,2 @@\n-  \/\/ Read once, we may have concurrent writers.\n-  const size_t used = Atomic::load(&_used);\n+ZPageAllocatorStats ZPageAllocator::update_and_stats(ZGeneration* generation) {\n+  ZLocker<ZLock> locker(&_lock);\n@@ -1414,2 +1415,2 @@\n-  _collection_stats[(int)id]._used_high = used;\n-  _collection_stats[(int)id]._used_low = used;\n+  update_collection_stats(generation->id());\n+  return stats_inner(generation);\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.cpp","additions":24,"deletions":23,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -238,0 +238,3 @@\n+  void update_collection_stats(ZGenerationId id);\n+  ZPageAllocatorStats stats_inner(ZGeneration* generation) const;\n+\n@@ -265,2 +268,1 @@\n-\n-  void reset_statistics(ZGenerationId id);\n+  ZPageAllocatorStats update_and_stats(ZGeneration* generation);\n","filename":"src\/hotspot\/share\/gc\/z\/zPageAllocator.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"}]}