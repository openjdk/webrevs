{"files":[{"patch":"@@ -114,0 +114,2 @@\n+  \/\/ To collect per-region live-words in a worker local cache in order to\n+  \/\/ reduce threads contention.\n@@ -128,14 +130,1 @@\n-    void push(size_t region_id, size_t live_words) {\n-      size_t index = (region_id & entry_mask);\n-      if (entries[index].region_id == region_id) {\n-        \/\/ Hit\n-        entries[index].live_words += live_words;\n-        return;\n-      }\n-      \/\/ Miss\n-      if (entries[index].live_words != 0) {\n-        evict(index);\n-      }\n-      entries[index].region_id = region_id;\n-      entries[index].live_words = live_words;\n-    }\n+    inline void push(size_t region_id, size_t live_words);\n@@ -144,42 +133,5 @@\n-    void push(oop obj, size_t live_words) {\n-      ParallelCompactData& data = PSParallelCompact::summary_data();\n-      const size_t region_size = ParallelCompactData::RegionSize;\n-\n-      HeapWord* addr = cast_from_oop<HeapWord*>(obj);\n-      const size_t start_region_id = data.addr_to_region_idx(addr);\n-      const size_t end_region_id = data.addr_to_region_idx(addr + live_words - 1);\n-      if (start_region_id == end_region_id) {\n-        \/\/ Completely inside this region\n-        push(start_region_id, live_words);\n-        return;\n-      }\n-\n-      \/\/ First region\n-      push(start_region_id, region_size - data.region_offset(addr));\n-\n-      \/\/ Middle regions; bypass cache\n-      for (size_t i = start_region_id + 1; i < end_region_id; ++i) {\n-        data.region(i)->set_partial_obj_size(region_size);\n-        data.region(i)->set_partial_obj_addr(addr);\n-      }\n-\n-      \/\/ Last region; bypass cache\n-      const size_t end_offset = data.region_offset(addr + live_words - 1);\n-      data.region(end_region_id)->set_partial_obj_size(end_offset + 1);\n-      data.region(end_region_id)->set_partial_obj_addr(addr);\n-    }\n-\n-    void evict(size_t index) {\n-      ParallelCompactData& data = PSParallelCompact::summary_data();\n-      \/\/ flush to global data\n-      data.region(entries[index].region_id)->add_live_obj(entries[index].live_words);\n-    }\n-\n-    void evict_all() {\n-      for (size_t i = 0; i < num_entries; ++i) {\n-        if (entries[i].live_words != 0) {\n-          evict(i);\n-          entries[i].live_words = 0;\n-        }\n-      }\n-    }\n+    inline void push(oop obj, size_t live_words);\n+\n+    inline void evict(size_t index);\n+\n+    inline void evict_all();\n@@ -189,0 +141,1 @@\n+\n@@ -276,4 +229,1 @@\n-  void create_marking_stats_cache() {\n-    assert(_marking_stats_cache == nullptr, \"precondition\");\n-    _marking_stats_cache = new MarkingStatsCache();\n-  }\n+  inline void create_marking_stats_cache();\n@@ -281,5 +231,1 @@\n-  void destroy_marking_stats_cache() {\n-    _marking_stats_cache->evict_all();\n-    delete _marking_stats_cache;\n-    _marking_stats_cache = nullptr;\n-  }\n+  inline void flush_and_destroy_marking_stats_cache();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManager.hpp","additions":11,"deletions":65,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -179,0 +179,69 @@\n+inline void ParCompactionManager::MarkingStatsCache::push(size_t region_id, size_t live_words) {\n+  size_t index = (region_id & entry_mask);\n+  if (entries[index].region_id == region_id) {\n+    \/\/ Hit\n+    entries[index].live_words += live_words;\n+    return;\n+  }\n+  \/\/ Miss\n+  if (entries[index].live_words != 0) {\n+    evict(index);\n+  }\n+  entries[index].region_id = region_id;\n+  entries[index].live_words = live_words;\n+}\n+\n+inline void ParCompactionManager::MarkingStatsCache::push(oop obj, size_t live_words) {\n+  ParallelCompactData& data = PSParallelCompact::summary_data();\n+  const size_t region_size = ParallelCompactData::RegionSize;\n+\n+  HeapWord* addr = cast_from_oop<HeapWord*>(obj);\n+  const size_t start_region_id = data.addr_to_region_idx(addr);\n+  const size_t end_region_id = data.addr_to_region_idx(addr + live_words - 1);\n+  if (start_region_id == end_region_id) {\n+    \/\/ Completely inside this region\n+    push(start_region_id, live_words);\n+    return;\n+  }\n+\n+  \/\/ First region\n+  push(start_region_id, region_size - data.region_offset(addr));\n+\n+  \/\/ Middle regions; bypass cache\n+  for (size_t i = start_region_id + 1; i < end_region_id; ++i) {\n+    data.region(i)->set_partial_obj_size(region_size);\n+    data.region(i)->set_partial_obj_addr(addr);\n+  }\n+\n+  \/\/ Last region; bypass cache\n+  const size_t end_offset = data.region_offset(addr + live_words - 1);\n+  data.region(end_region_id)->set_partial_obj_size(end_offset + 1);\n+  data.region(end_region_id)->set_partial_obj_addr(addr);\n+}\n+\n+inline void ParCompactionManager::MarkingStatsCache::evict(size_t index) {\n+  ParallelCompactData& data = PSParallelCompact::summary_data();\n+  \/\/ flush to global data\n+  data.region(entries[index].region_id)->add_live_obj(entries[index].live_words);\n+}\n+\n+inline void ParCompactionManager::MarkingStatsCache::evict_all() {\n+  for (size_t i = 0; i < num_entries; ++i) {\n+    if (entries[i].live_words != 0) {\n+      evict(i);\n+      entries[i].live_words = 0;\n+    }\n+  }\n+}\n+\n+inline void ParCompactionManager::create_marking_stats_cache() {\n+  assert(_marking_stats_cache == nullptr, \"precondition\");\n+  _marking_stats_cache = new MarkingStatsCache();\n+}\n+\n+inline void ParCompactionManager::flush_and_destroy_marking_stats_cache() {\n+  _marking_stats_cache->evict_all();\n+  delete _marking_stats_cache;\n+  _marking_stats_cache = nullptr;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManager.inline.hpp","additions":69,"deletions":0,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -2056,1 +2056,1 @@\n-        cm->destroy_marking_stats_cache();\n+        cm->flush_and_destroy_marking_stats_cache();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}