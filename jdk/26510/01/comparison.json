{"files":[{"patch":"@@ -37,0 +37,1 @@\n+    _alloc_cds,         \/\/ Allocate for CDS\n@@ -49,0 +50,2 @@\n+      case _alloc_cds:\n+        return \"CDS\";\n@@ -124,0 +127,4 @@\n+  static inline ShenandoahAllocRequest for_cds(size_t requested_size) {\n+    return ShenandoahAllocRequest(0, requested_size, _alloc_cds, ShenandoahAffiliation::YOUNG_GENERATION);\n+  }\n+\n@@ -166,0 +173,1 @@\n+      case _alloc_cds:\n@@ -181,0 +189,1 @@\n+      case _alloc_cds:\n@@ -200,0 +209,1 @@\n+      case _alloc_cds:\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAllocRequest.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -819,0 +819,1 @@\n+    case ShenandoahAllocRequest::_alloc_cds:\n@@ -1172,2 +1173,2 @@\n-HeapWord* ShenandoahFreeSet::allocate_contiguous(ShenandoahAllocRequest& req) {\n-  assert(req.is_mutator_alloc(), \"All humongous allocations are performed by mutator\");\n+HeapWord* ShenandoahFreeSet::allocate_contiguous(ShenandoahAllocRequest& req, bool is_humongous) {\n+  assert(req.is_mutator_alloc(), \"All contiguous allocations are performed by mutator\");\n@@ -1247,2 +1248,8 @@\n-    if (i == beg) {\n-      r->make_humongous_start();\n+    r->set_affiliation(req.affiliation());\n+\n+    if (is_humongous) {\n+      if (i == beg) {\n+        r->make_humongous_start();\n+      } else {\n+        r->make_humongous_cont();\n+      }\n@@ -1250,1 +1257,1 @@\n-      r->make_humongous_cont();\n+      r->make_regular_allocation(req.affiliation());\n@@ -1260,2 +1267,0 @@\n-\n-    r->set_affiliation(req.affiliation());\n@@ -1270,2 +1275,2 @@\n-  size_t total_humongous_size = ShenandoahHeapRegion::region_size_bytes() * num;\n-  _partitions.increase_used(ShenandoahFreeSetPartitionId::Mutator, total_humongous_size);\n+  size_t total_contiguous_size = ShenandoahHeapRegion::region_size_bytes() * num;\n+  _partitions.increase_used(ShenandoahFreeSetPartitionId::Mutator, total_contiguous_size);\n@@ -2063,1 +2068,4 @@\n-        return allocate_contiguous(req);\n+        return allocate_contiguous(req, \/* is_humongous = *\/ true);\n+      case ShenandoahAllocRequest::_alloc_cds:\n+        in_new_region = true;\n+        return allocate_contiguous(req, \/* is_humongous = *\/ false);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.cpp","additions":18,"deletions":10,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -348,1 +348,1 @@\n-  HeapWord* allocate_contiguous(ShenandoahAllocRequest& req);\n+  HeapWord* allocate_contiguous(ShenandoahAllocRequest& req, bool is_humongous);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFreeSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2763,33 +2763,12 @@\n-  \/\/ CDS wants a continuous memory range to load a bunch of objects.\n-  \/\/ This effectively bypasses normal allocation paths, and requires\n-  \/\/ a bit of massaging to unbreak GC invariants.\n-\n-  ShenandoahAllocRequest req = ShenandoahAllocRequest::for_shared(size);\n-\n-  \/\/ Easy case: a single regular region, no further adjustments needed.\n-  if (!ShenandoahHeapRegion::requires_humongous(size)) {\n-    return allocate_memory(req);\n-  }\n-\n-  \/\/ Hard case: the requested size would cause a humongous allocation.\n-  \/\/ We need to make sure it looks like regular allocation to the rest of GC.\n-\n-  \/\/ CDS code would guarantee no objects straddle multiple regions, as long as\n-  \/\/ regions are as large as MIN_GC_REGION_ALIGNMENT. It is impractical at this\n-  \/\/ point to deal with case when Shenandoah runs with smaller regions.\n-  \/\/ TODO: This check can be dropped once MIN_GC_REGION_ALIGNMENT agrees more with Shenandoah.\n-  if (ShenandoahHeapRegion::region_size_bytes() < ArchiveHeapWriter::MIN_GC_REGION_ALIGNMENT) {\n-    return nullptr;\n-  }\n-\n-  HeapWord* mem = allocate_memory(req);\n-  size_t start_idx = heap_region_index_containing(mem);\n-  size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);\n-\n-  \/\/ Flip humongous -> regular.\n-  {\n-    ShenandoahHeapLocker locker(lock(), false);\n-    for (size_t c = start_idx; c < start_idx + num_regions; c++) {\n-      get_region(c)->make_regular_bypass();\n-    }\n-  }\n+  \/\/ CDS wants a raw continuous memory range to load a bunch of objects itself.\n+  \/\/ This is an unusual request, since all requested regions should be regular, not humongous.\n+  \/\/ Plus, the objects loaded by CDS are likely old and would survive lots of collections.\n+  \/\/\n+  \/\/ We handle the whole thing by allocating the contiguous set of full regions for CDS load.\n+  \/\/ This simplifies accounting in GC code, and makes sure the CDS loaded object are segregated\n+  \/\/ by age from the rest of the allocations. We will insert the filler object when load\n+  \/\/ is complete.\n+  \/\/\n+  \/\/ CDS would guarantee no objects straddle multiple regions, as long as regions are as large\n+  \/\/ as MIN_GC_REGION_ALIGNMENT.\n+  guarantee(ShenandoahHeapRegion::region_size_bytes() >= ArchiveHeapWriter::MIN_GC_REGION_ALIGNMENT, \"Must be\");\n@@ -2797,1 +2776,3 @@\n-  return mem;\n+  size_t aligned_size = ShenandoahHeapRegion::required_regions(size) * ShenandoahHeapRegion::region_size_bytes();\n+  ShenandoahAllocRequest req = ShenandoahAllocRequest::for_cds(aligned_size);\n+  return allocate_memory(req);\n@@ -2805,2 +2786,0 @@\n-  \/\/ Nothing to do here, except checking that heap looks fine.\n-#ifdef ASSERT\n@@ -2810,0 +2789,8 @@\n+  \/\/ Fill the tail with the filler object.\n+  HeapWord* regions_end = align_up(end, ShenandoahHeapRegion::region_size_bytes());\n+  if (regions_end > end) {\n+    fill_with_dummy_object(end, regions_end, false);\n+  }\n+\n+  \/\/ Nothing else to do here, except checking that heap looks fine.\n+#ifdef ASSERT\n@@ -2813,1 +2800,1 @@\n-  while (cur < end) {\n+  while (cur < regions_end) {\n@@ -2819,0 +2806,4 @@\n+  assert(cur == regions_end,\n+         \"Should allocate entire region space to maintain heap parsability: \" PTR_FORMAT \" \" PTR_FORMAT,\n+         p2i(cur), p2i(regions_end));\n+\n@@ -2820,1 +2811,1 @@\n-  assert(cur == end,\n+  assert(cur >= end,\n@@ -2824,11 +2815,19 @@\n-  \/\/ Region bounds are good.\n-  ShenandoahHeapRegion* begin_reg = heap_region_containing(start);\n-  ShenandoahHeapRegion* end_reg = heap_region_containing(end);\n-  assert(begin_reg->is_regular(), \"Must be\");\n-  assert(end_reg->is_regular(), \"Must be\");\n-  assert(begin_reg->bottom() == start,\n-         \"Must agree: archive-space-start: \" PTR_FORMAT \", begin-region-bottom: \" PTR_FORMAT,\n-         p2i(start), p2i(begin_reg->bottom()));\n-  assert(end_reg->top() == end,\n-         \"Must agree: archive-space-end: \" PTR_FORMAT \", end-region-top: \" PTR_FORMAT,\n-         p2i(end), p2i(end_reg->top()));\n+  \/\/ All regions in contiguous space have good state.\n+  size_t begin_reg_idx = heap_region_index_containing(start);\n+  size_t end_reg_idx   = heap_region_index_containing(end);\n+\n+  for (size_t idx = begin_reg_idx; idx <= end_reg_idx; idx++) {\n+    ShenandoahHeapRegion* r = get_region(idx);\n+    assert(r->is_regular(), \"Must be regular\");\n+    assert(r->is_young(), \"Must be young\");\n+    assert(r->top() == r->end(),\n+           \"All regions should be full: \" PTR_FORMAT \" \" PTR_FORMAT,\n+           p2i(r->top()), p2i(r->end()));\n+    assert(idx != begin_reg_idx || r->bottom() == start,\n+           \"Archive space start should be at the bottom of first region: \" PTR_FORMAT \" \" PTR_FORMAT,\n+           p2i(r->bottom()), p2i(start));\n+    assert(idx != end_reg_idx || (r->bottom() < end && end <= r->top()),\n+           \"Archive space end should be in the last region: \" PTR_FORMAT \" \" PTR_FORMAT \" \" PTR_FORMAT,\n+           p2i(r->bottom()), p2i(end), p2i(r->top()));\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":48,"deletions":49,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -145,2 +145,1 @@\n-  assert (!Universe::is_fully_initialized() ||\n-          ShenandoahHeap::heap()->is_full_gc_in_progress() ||\n+  assert (ShenandoahHeap::heap()->is_full_gc_in_progress() ||\n@@ -148,1 +147,1 @@\n-          \"Only for STW GC or when Universe is initializing (CDS)\");\n+          \"Only for STW GC\");\n@@ -150,2 +149,1 @@\n-  auto cur_state = state();\n-  switch (cur_state) {\n+  switch (state()) {\n@@ -158,8 +156,0 @@\n-      if (cur_state == _humongous_start || cur_state == _humongous_cont) {\n-        \/\/ CDS allocates chunks of the heap to fill with regular objects. The allocator\n-        \/\/ will dutifully track any waste in the unused portion of the last region. Once\n-        \/\/ CDS has finished initializing the objects, it will convert these regions to\n-        \/\/ regular regions. The 'waste' in the last region is no longer wasted at this point,\n-        \/\/ so we must stop treating it as such.\n-        decrement_humongous_waste();\n-      }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.cpp","additions":3,"deletions":13,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -115,0 +115,1 @@\n+    case ShenandoahAllocRequest::_alloc_cds:\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}