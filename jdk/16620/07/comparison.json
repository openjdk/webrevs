{"files":[{"patch":"@@ -2380,1 +2380,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -129,1 +129,1 @@\n-  bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+  bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -119,1 +119,1 @@\n-  bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+  bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2008, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2008, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1005,1 +1005,1 @@\n-bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n@@ -1077,1 +1077,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2011, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2176,1 +2176,1 @@\n-bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n@@ -2245,1 +2245,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2016,1 +2016,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -49,1 +49,1 @@\n-  bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+  bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1516,1 +1516,1 @@\n-bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n@@ -1577,1 +1577,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1706,1 +1706,1 @@\n-bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+bool Matcher::match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt) {\n@@ -2288,1 +2288,1 @@\n-int Matcher::superword_max_vector_size(const BasicType bt) {\n+int Matcher::max_vector_size_autovectorization(const BasicType bt) {\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2023, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -4483,1 +4483,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4494,1 +4494,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4508,1 +4508,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4519,1 +4519,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4533,1 +4533,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4544,1 +4544,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4558,1 +4558,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4569,1 +4569,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"opto\/traceautovectorizationtags.hpp\"\n@@ -303,1 +304,2 @@\n-  _ideal_phase_name_set(PHASE_NUM_TYPES, mtCompiler)\n+  _ideal_phase_name_set(PHASE_NUM_TYPES, mtCompiler),\n+  _traceautovectorization_tags(TRACEAUTOVECTORIZATION_TAGS_NUM, mtCompiler)\n@@ -436,0 +438,10 @@\n+    if (!_modified[TraceAutovectorizationIndex]) {\n+      \/\/ Parse ccstr and create mask\n+      ccstrlist option;\n+      if (CompilerOracle::has_option_value(method, CompileCommand::TraceAutovectorization, option)) {\n+        TraceAutovectorizationTagValidator validator(option, false);\n+        if (validator.is_valid()) {\n+          set.cloned()->set_traceautovectorization_tags(validator.tags());\n+        }\n+      }\n+    }\n","filename":"src\/hotspot\/share\/compiler\/compilerDirectives.cpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -90,1 +90,0 @@\n-    cflags(VectorizeDebug,          uintx, 0, VectorizeDebug) \\\n@@ -94,0 +93,1 @@\n+NOT_PRODUCT(cflags(TraceAutovectorization, ccstrlist, \"\", TraceAutovectorization)) \\\n@@ -134,0 +134,1 @@\n+  CHeapBitMap _traceautovectorization_tags;\n@@ -208,0 +209,6 @@\n+  void set_traceautovectorization_tags(const CHeapBitMap& tags) {\n+    _traceautovectorization_tags.set_from(tags);\n+  };\n+  const CHeapBitMap& traceautovectorization_tags() {\n+    return _traceautovectorization_tags;\n+  };\n","filename":"src\/hotspot\/share\/compiler\/compilerDirectives.hpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,1 @@\n+#include \"opto\/traceautovectorizationtags.hpp\"\n@@ -779,1 +780,7 @@\n-      else if (option == CompileCommand::PrintIdealPhase) {\n+      else if (option == CompileCommand::TraceAutovectorization) {\n+        TraceAutovectorizationTagValidator validator(value, true);\n+\n+        if (!validator.is_valid()) {\n+          jio_snprintf(errorbuf, buf_size, \"Unrecognized tag name in %s: %s\", option2name(option), validator.what());\n+        }\n+      } else if (option == CompileCommand::PrintIdealPhase) {\n","filename":"src\/hotspot\/share\/compiler\/compilerOracle.cpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -89,0 +89,1 @@\n+NOT_PRODUCT(option(TraceAutovectorization, \"TraceAutovectorization\", Ccstrlist)) \\\n@@ -90,1 +91,0 @@\n-  option(VectorizeDebug, \"VectorizeDebug\", Uintx) \\\n","filename":"src\/hotspot\/share\/compiler\/compilerOracle.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"opto\/traceautovectorizationtags.hpp\"\n@@ -338,0 +339,9 @@\n+        } else if (strncmp(option_key->name, \"TraceAutovectorization\", 22) == 0) {\n+          TraceAutovectorizationTagValidator validator(s, false);\n+\n+          valid = validator.is_valid();\n+          if (valid) {\n+            set->set_traceautovectorization_tags(validator.tags());\n+          } else {\n+            error(VALUE_ERROR, \"Unrecognized tag name detected in TraceAutovectorization: %s\", validator.what());\n+          }\n","filename":"src\/hotspot\/share\/compiler\/directivesParser.cpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -342,3 +342,0 @@\n-  develop(bool, SuperWordRTDepCheck, false,                                 \\\n-          \"Enable runtime dependency checks.\")                              \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -1099,6 +1099,3 @@\n-      SuperWord sw(phase);\n-      sw.transform_loop(this, false);\n-\n-      \/\/ If the loop is slp canonical analyze it\n-      if (sw.early_return() == false) {\n-        sw.unrolling_analysis(_local_loop_unroll_factor);\n+      VLoop vl(phase);\n+      if (vl.check_preconditions(this, true)) {\n+        SuperWord::unrolling_analysis(vl, _local_loop_unroll_factor);\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":4,"deletions":7,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -4665,1 +4665,1 @@\n-  \/\/ Convert scalar to superword operations at the end of all loop opts.\n+  \/\/ Auto-Vectorize the main-loop\n@@ -4667,2 +4667,2 @@\n-    \/\/ SuperWord transform\n-    SuperWord sw(this);\n+    VLoopAnalyzer vloop_analyzer(this);\n+    SuperWord sw(vloop_analyzer);\n@@ -4671,10 +4671,9 @@\n-      if (lpt->is_counted()) {\n-        CountedLoopNode *cl = lpt->_head->as_CountedLoop();\n-        if (cl->is_main_loop()) {\n-          if (!sw.transform_loop(lpt, true)) {\n-            \/\/ Instigate more unrolling for optimization when vectorization fails.\n-            if (cl->has_passed_slp()) {\n-              C->set_major_progress();\n-              cl->set_notpassed_slp();\n-              cl->mark_do_unroll_only();\n-            }\n+      CountedLoopNode* cl = lpt->_head->isa_CountedLoop();\n+      if (lpt->is_counted() && cl->is_main_loop()) {\n+        if (!vloop_analyzer.analyze(lpt, false) ||\n+            !sw.transform_loop()) {\n+          \/\/ Analyzer or Vectorization failed. From now on only unroll the loop.\n+          if (cl->has_passed_slp()) {\n+            C->set_major_progress();\n+            cl->set_notpassed_slp();\n+            cl->mark_do_unroll_only();\n@@ -5764,24 +5763,0 @@\n-  CountedLoopNode* CountedLoopNode::pre_loop_head() const {\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(_pre_loop_end != nullptr && _pre_loop_end->loopnode() != nullptr,\n-           \"should find head from pre loop end\");\n-    return _pre_loop_end->loopnode();\n-  }\n-\n-  CountedLoopEndNode* CountedLoopNode::pre_loop_end() {\n-#ifdef ASSERT\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(_pre_loop_end != nullptr, \"should be set when fetched\");\n-    Node* found_pre_end = find_pre_loop_end();\n-    assert(_pre_loop_end == found_pre_end && _pre_loop_end == pre_loop_head()->loopexit(),\n-           \"should find the pre loop end and must be the same result\");\n-#endif\n-    return _pre_loop_end;\n-  }\n-\n-  void CountedLoopNode::set_pre_loop_end(CountedLoopEndNode* pre_loop_end) {\n-    assert(is_main_loop(), \"Only main loop has pre loop\");\n-    assert(pre_loop_end, \"must be valid\");\n-    _pre_loop_end = pre_loop_end;\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":13,"deletions":38,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -234,3 +234,0 @@\n-  \/\/ Cached CountedLoopEndNode of pre loop for main loops\n-  CountedLoopEndNode* _pre_loop_end;\n-\n@@ -241,1 +238,1 @@\n-      _slp_maximum_unroll_factor(0), _pre_loop_end(nullptr) {\n+      _slp_maximum_unroll_factor(0) {\n@@ -333,3 +330,0 @@\n-  CountedLoopNode* pre_loop_head() const;\n-  CountedLoopEndNode* pre_loop_end();\n-  void set_pre_loop_end(CountedLoopEndNode* pre_loop_end);\n@@ -1106,0 +1100,1 @@\n+    _loop_or_ctrl(igvn.C->comp_arena()),\n@@ -1120,0 +1115,1 @@\n+    _loop_or_ctrl(igvn.C->comp_arena()),\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -334,1 +334,1 @@\n-  static bool match_rule_supported_superword(int opcode, int vlen, BasicType bt);\n+  static bool match_rule_supported_autovectorization(int opcode, int vlen, BasicType bt);\n@@ -358,1 +358,1 @@\n-  static int superword_max_vector_size(const BasicType bt);\n+  static int max_vector_size_autovectorization(const BasicType bt);\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -46,4 +46,3 @@\n-SuperWord::SuperWord(PhaseIdealLoop* phase) :\n-  _phase(phase),\n-  _arena(phase->C->comp_arena()),\n-  _igvn(phase->_igvn),\n+SuperWord::SuperWord(const VLoopAnalyzer &vla) :\n+  _vla(vla),\n+  _arena(phase()->C->comp_arena()),\n@@ -51,5 +50,0 @@\n-  _bb_idx(arena(), (int)(1.10 * phase->C->unique()), 0, 0), \/\/ node idx to index in bb\n-  _block(arena(), 8,  0, nullptr),                          \/\/ nodes in current block\n-  _data_entry(arena(), 8,  0, nullptr),                     \/\/ nodes with all inputs from outside\n-  _mem_slice_head(arena(), 8,  0, nullptr),                 \/\/ memory slice heads\n-  _mem_slice_tail(arena(), 8,  0, nullptr),                 \/\/ memory slice tails\n@@ -57,1 +51,1 @@\n-  _clone_map(phase->C->clone_map()),                        \/\/ map of nodes created in cloning\n+  _clone_map(phase()->C->clone_map()),                      \/\/ map of nodes created in cloning\n@@ -59,4 +53,0 @@\n-  _disjoint_ptrs(arena(), 8,  0, OrderedPair::initial),     \/\/ runtime disambiguated pointer pairs\n-  _dg(_arena),                                              \/\/ dependence graph\n-  _visited(arena()),                                        \/\/ visited node set\n-  _post_visited(arena()),                                   \/\/ post visited node set\n@@ -64,7 +54,0 @@\n-  _nlist(arena(), 8, 0, nullptr),                           \/\/ scratch list of nodes\n-  _stk(arena(), 8, 0, nullptr),                             \/\/ scratch stack of nodes\n-  _lpt(nullptr),                                            \/\/ loop tree node\n-  _lp(nullptr),                                             \/\/ CountedLoopNode\n-  _loop_reductions(arena()),                                \/\/ reduction nodes in the current loop\n-  _bb(nullptr),                                             \/\/ basic block\n-  _iv(nullptr),                                             \/\/ induction var\n@@ -72,2 +55,1 @@\n-  _early_return(true),                                      \/\/ analysis evaluations routine\n-  _do_vector_loop(phase->C->do_vector_loop()),              \/\/ whether to do vectorization\/simd style\n+  _do_vector_loop(phase()->C->do_vector_loop()),            \/\/ whether to do vectorization\/simd style\n@@ -77,7 +59,0 @@\n-#ifndef PRODUCT\n-  _vector_loop_debug = 0;\n-  if (_phase->C->method() != nullptr) {\n-    _vector_loop_debug = phase->C->directive()->VectorizeDebugOption;\n-  }\n-\n-#endif\n@@ -86,11 +61,5 @@\n-\/\/------------------------------transform_loop---------------------------\n-bool SuperWord::transform_loop(IdealLoopTree* lpt, bool do_optimization) {\n-  assert(_phase->C->do_superword(), \"SuperWord option should be enabled\");\n-  \/\/ SuperWord only works with power of two vector sizes.\n-  int vector_width = Matcher::vector_width_in_bytes(T_BYTE);\n-  if (vector_width < 2 || !is_power_of_2(vector_width)) {\n-    return false;\n-  }\n-\n-  assert(lpt->_head->is_CountedLoop(), \"must be\");\n-  CountedLoopNode *cl = lpt->_head->as_CountedLoop();\n+void SuperWord::unrolling_analysis(const VLoop &vloop, int &local_loop_unroll_factor) {\n+  IdealLoopTree* lpt    = vloop.lpt();\n+  CountedLoopNode* cl   = vloop.cl();\n+  Node* cl_exit         = vloop.cl_exit();\n+  PhaseIdealLoop* phase = vloop.phase();\n@@ -98,75 +67,0 @@\n-  if (!cl->is_valid_counted_loop(T_INT)) {\n-    return false; \/\/ skip malformed counted loop\n-  }\n-\n-  \/\/ Initialize simple data used by reduction marking early.\n-  set_lpt(lpt);\n-  set_lp(cl);\n-  \/\/ For now, define one block which is the entire loop body.\n-  set_bb(cl);\n-\n-  if (SuperWordReductions) {\n-    mark_reductions();\n-  }\n-\n-  \/\/ skip any loop that has not been assigned max unroll by analysis\n-  if (do_optimization) {\n-    if (SuperWordLoopUnrollAnalysis && cl->slp_max_unroll() == 0) {\n-      return false;\n-    }\n-  }\n-\n-  \/\/ Check for no control flow in body (other than exit)\n-  Node *cl_exit = cl->loopexit();\n-  if (cl->is_main_loop() && (cl_exit->in(0) != lpt->_head)) {\n-    #ifndef PRODUCT\n-      if (TraceSuperWord) {\n-        tty->print_cr(\"SuperWord::transform_loop: loop too complicated, cl_exit->in(0) != lpt->_head\");\n-        tty->print(\"cl_exit %d\", cl_exit->_idx); cl_exit->dump();\n-        tty->print(\"cl_exit->in(0) %d\", cl_exit->in(0)->_idx); cl_exit->in(0)->dump();\n-        tty->print(\"lpt->_head %d\", lpt->_head->_idx); lpt->_head->dump();\n-        lpt->dump_head();\n-      }\n-    #endif\n-    return false;\n-  }\n-\n-  \/\/ Make sure the are no extra control users of the loop backedge\n-  if (cl->back_control()->outcnt() != 1) {\n-    return false;\n-  }\n-\n-  \/\/ Skip any loops already optimized by slp\n-  if (cl->is_vectorized_loop()) {\n-    return false;\n-  }\n-\n-  if (cl->is_unroll_only()) {\n-    return false;\n-  }\n-\n-  if (cl->is_main_loop()) {\n-    \/\/ Check for pre-loop ending with CountedLoopEnd(Bool(Cmp(x,Opaque1(limit))))\n-    CountedLoopEndNode* pre_end = cl->find_pre_loop_end();\n-    if (pre_end == nullptr) {\n-      return false;\n-    }\n-    Node* pre_opaq1 = pre_end->limit();\n-    if (pre_opaq1->Opcode() != Op_Opaque1) {\n-      return false;\n-    }\n-    cl->set_pre_loop_end(pre_end);\n-  }\n-\n-  init(); \/\/ initialize data structures\n-\n-  bool success = true;\n-  if (do_optimization) {\n-    assert(_packset.length() == 0, \"packset must be empty\");\n-    success = SLP_extract();\n-  }\n-  return success;\n-}\n-\n-\/\/------------------------------early unrolling analysis------------------------------\n-void SuperWord::unrolling_analysis(int &local_loop_unroll_factor) {\n@@ -174,1 +68,1 @@\n-  size_t ignored_size = lpt()->_body.size();\n+  size_t ignored_size = lpt->_body.size();\n@@ -177,2 +71,0 @@\n-  CountedLoopNode *cl = lpt()->_head->as_CountedLoop();\n-  Node *cl_exit = cl->loopexit_or_null();\n@@ -181,1 +73,1 @@\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n+  for (uint i = 0; i < lpt->_body.size(); i++) {\n@@ -185,1 +77,1 @@\n-  int max_vector = Matcher::superword_max_vector_size(T_BYTE);\n+  int max_vector = Matcher::max_vector_size_autovectorization(T_BYTE);\n@@ -189,2 +81,2 @@\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n-    Node* n = lpt()->_body.at(i);\n+  for (uint i = 0; i < lpt->_body.size(); i++) {\n+    Node* n = lpt->_body.at(i);\n@@ -192,1 +84,0 @@\n-      is_marked_reduction(n) ||\n@@ -206,1 +97,1 @@\n-        if (lpt()->is_loop_exit(iff)) {\n+        if (lpt->is_loop_exit(iff)) {\n@@ -250,1 +141,1 @@\n-      Node* n_ctrl = _phase->get_ctrl(adr);\n+      Node* n_ctrl = phase->get_ctrl(adr);\n@@ -253,1 +144,1 @@\n-      if (n_ctrl != nullptr && lpt()->is_member(_phase->get_loop(n_ctrl))) {\n+      if (n_ctrl != nullptr && lpt->is_member(phase->get_loop(n_ctrl))) {\n@@ -261,1 +152,1 @@\n-          VPointer p1(current, phase(), lpt(), &nstack, true);\n+          VPointer p1(current, vloop, &nstack);\n@@ -268,2 +159,2 @@\n-          for (uint j = 0; j < lpt()->_body.size(); j++) {\n-            Node* cur_node = lpt()->_body.at(j);\n+          for (uint j = 0; j < lpt->_body.size(); j++) {\n+            Node* cur_node = lpt->_body.at(j);\n@@ -286,1 +177,1 @@\n-    for (uint i = 0; i < lpt()->_body.size(); i++) {\n+    for (uint i = 0; i < lpt->_body.size(); i++) {\n@@ -290,1 +181,1 @@\n-      Node* n = lpt()->_body.at(i);\n+      Node* n = lpt->_body.at(i);\n@@ -299,1 +190,1 @@\n-      int cur_max_vector = Matcher::superword_max_vector_size(bt);\n+      int cur_max_vector = Matcher::max_vector_size_autovectorization(bt);\n@@ -305,0 +196,1 @@\n+#ifndef PRODUCT\n@@ -308,0 +200,1 @@\n+#endif\n@@ -328,1 +221,3 @@\n-              if (!in->is_Mem() && in_bb(in) && in->bottom_type()->basic_type() == T_INT) {\n+              if (!in->is_Mem() &&\n+                  vloop.in_body(in) &&\n+                  in->bottom_type()->basic_type() == T_INT) {\n@@ -332,1 +227,2 @@\n-                  if (!in_bb(use) && use->bottom_type()->basic_type() != bt) {\n+                  if (!vloop.in_body(use) &&\n+                      use->bottom_type()->basic_type() != bt) {\n@@ -354,0 +250,5 @@\n+#ifndef PRODUCT\n+      if (TraceSuperWordLoopUnrollAnalysis) {\n+        tty->print_cr(\"slp analysis: set max unroll to %d\", local_loop_unroll_factor);\n+      }\n+#endif\n@@ -359,44 +260,6 @@\n-bool SuperWord::is_reduction(const Node* n) {\n-  if (!is_reduction_operator(n)) {\n-    return false;\n-  }\n-  \/\/ Test whether there is a reduction cycle via every edge index\n-  \/\/ (typically indices 1 and 2).\n-  for (uint input = 1; input < n->req(); input++) {\n-    if (in_reduction_cycle(n, input)) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-bool SuperWord::is_reduction_operator(const Node* n) {\n-  int opc = n->Opcode();\n-  return (opc != ReductionNode::opcode(opc, n->bottom_type()->basic_type()));\n-}\n-\n-bool SuperWord::in_reduction_cycle(const Node* n, uint input) {\n-  \/\/ First find input reduction path to phi node.\n-  auto has_my_opcode = [&](const Node* m){ return m->Opcode() == n->Opcode(); };\n-  PathEnd path_to_phi = find_in_path(n, input, LoopMaxUnroll, has_my_opcode,\n-                                     [&](const Node* m) { return m->is_Phi(); });\n-  const Node* phi = path_to_phi.first;\n-  if (phi == nullptr) {\n-    return false;\n-  }\n-  \/\/ If there is an input reduction path from the phi's loop-back to n, then n\n-  \/\/ is part of a reduction cycle.\n-  const Node* first = phi->in(LoopNode::LoopBackControl);\n-  PathEnd path_from_phi = find_in_path(first, input, LoopMaxUnroll, has_my_opcode,\n-                                       [&](const Node* m) { return m == n; });\n-  return path_from_phi.first != nullptr;\n-}\n-\n-Node* SuperWord::original_input(const Node* n, uint i) {\n-  if (n->has_swapped_edges()) {\n-    assert(n->is_Add() || n->is_Mul(), \"n should be commutative\");\n-    if (i == 1) {\n-      return n->in(2);\n-    } else if (i == 2) {\n-      return n->in(1);\n-    }\n+bool SuperWord::transform_loop() {\n+#ifndef PRODUCT\n+  if (is_trace_superword_any()) {\n+    tty->print_cr(\"\\nSuperWord::transform_loop:\");\n+    lpt()->dump_head();\n+    cl()->dump();\n@@ -404,6 +267,1 @@\n-  return n->in(i);\n-}\n-\n-void SuperWord::mark_reductions() {\n-\n-  _loop_reductions.clear();\n+#endif\n@@ -411,78 +269,3 @@\n-  \/\/ Iterate through all phi nodes associated to the loop and search for\n-  \/\/ reduction cycles in the basic block.\n-  for (DUIterator_Fast imax, i = lp()->fast_outs(imax); i < imax; i++) {\n-    const Node* phi = lp()->fast_out(i);\n-    if (!phi->is_Phi()) {\n-      continue;\n-    }\n-    if (phi->outcnt() == 0) {\n-      continue;\n-    }\n-    if (phi == iv()) {\n-      continue;\n-    }\n-    \/\/ The phi's loop-back is considered the first node in the reduction cycle.\n-    const Node* first = phi->in(LoopNode::LoopBackControl);\n-    if (first == nullptr) {\n-      continue;\n-    }\n-    \/\/ Test that the node fits the standard pattern for a reduction operator.\n-    if (!is_reduction_operator(first)) {\n-      continue;\n-    }\n-    \/\/ Test that 'first' is the beginning of a reduction cycle ending in 'phi'.\n-    \/\/ To contain the number of searched paths, assume that all nodes in a\n-    \/\/ reduction cycle are connected via the same edge index, modulo swapped\n-    \/\/ inputs. This assumption is realistic because reduction cycles usually\n-    \/\/ consist of nodes cloned by loop unrolling.\n-    int reduction_input = -1;\n-    int path_nodes = -1;\n-    for (uint input = 1; input < first->req(); input++) {\n-      \/\/ Test whether there is a reduction path in the basic block from 'first'\n-      \/\/ to the phi node following edge index 'input'.\n-      PathEnd path =\n-        find_in_path(\n-          first, input, lpt()->_body.size(),\n-          [&](const Node* n) { return n->Opcode() == first->Opcode() && in_bb(n); },\n-          [&](const Node* n) { return n == phi; });\n-      if (path.first != nullptr) {\n-        reduction_input = input;\n-        path_nodes = path.second;\n-        break;\n-      }\n-    }\n-    if (reduction_input == -1) {\n-      continue;\n-    }\n-    \/\/ Test that reduction nodes do not have any users in the loop besides their\n-    \/\/ reduction cycle successors.\n-    const Node* current = first;\n-    const Node* succ = phi; \/\/ current's successor in the reduction cycle.\n-    bool used_in_loop = false;\n-    for (int i = 0; i < path_nodes; i++) {\n-      for (DUIterator_Fast jmax, j = current->fast_outs(jmax); j < jmax; j++) {\n-        Node* u = current->fast_out(j);\n-        if (!in_bb(u)) {\n-          continue;\n-        }\n-        if (u == succ) {\n-          continue;\n-        }\n-        used_in_loop = true;\n-        break;\n-      }\n-      if (used_in_loop) {\n-        break;\n-      }\n-      succ = current;\n-      current = original_input(current, reduction_input);\n-    }\n-    if (used_in_loop) {\n-      continue;\n-    }\n-    \/\/ Reduction cycle found. Mark all nodes in the found path as reductions.\n-    current = first;\n-    for (int i = 0; i < path_nodes; i++) {\n-      _loop_reductions.set(current->_idx);\n-      current = original_input(current, reduction_input);\n-    }\n+  const char* state = transform_loop_helper();\n+  if (state == SuperWord::SUCCESS) {\n+    return true;\n@@ -490,37 +273,0 @@\n-}\n-\n-\/\/------------------------------SLP_extract---------------------------\n-\/\/ Extract the superword level parallelism\n-\/\/\n-\/\/ 1) A reverse post-order of nodes in the block is constructed.  By scanning\n-\/\/    this list from first to last, all definitions are visited before their uses.\n-\/\/\n-\/\/ 2) A point-to-point dependence graph is constructed between memory references.\n-\/\/    This simplifies the upcoming \"independence\" checker.\n-\/\/\n-\/\/ 3) The maximum depth in the node graph from the beginning of the block\n-\/\/    to each node is computed.  This is used to prune the graph search\n-\/\/    in the independence checker.\n-\/\/\n-\/\/ 4) For integer types, the necessary bit width is propagated backwards\n-\/\/    from stores to allow packed operations on byte, char, and short\n-\/\/    integers.  This reverses the promotion to type \"int\" that javac\n-\/\/    did for operations like: char c1,c2,c3;  c1 = c2 + c3.\n-\/\/\n-\/\/ 5) One of the memory references is picked to be an aligned vector reference.\n-\/\/    The pre-loop trip count is adjusted to align this reference in the\n-\/\/    unrolled body.\n-\/\/\n-\/\/ 6) The initial set of pack pairs is seeded with memory references.\n-\/\/\n-\/\/ 7) The set of pack pairs is extended by following use->def and def->use links.\n-\/\/\n-\/\/ 8) The pairs are combined into vector sized packs.\n-\/\/\n-\/\/ 9) Reorder the memory slices to co-locate members of the memory packs.\n-\/\/\n-\/\/ 10) Generate ideal vector nodes for the final set of packs and where necessary,\n-\/\/    inserting scalar promotion, vector creation from multiple scalars, and\n-\/\/    extraction of scalar values from vectors.\n-\/\/\n-bool SuperWord::SLP_extract() {\n@@ -529,8 +275,2 @@\n-  if (_do_vector_loop && TraceSuperWord) {\n-    tty->print(\"SuperWord::SLP_extract\\n\");\n-    tty->print(\"input loop\\n\");\n-    _lpt->dump_head();\n-    _lpt->dump();\n-    for (uint i = 0; i < _lpt->_body.size(); i++) {\n-      _lpt->_body.at(i)->dump();\n-    }\n+  if (is_trace_superword_any()) {\n+    tty->print_cr(\"\\nSuperWord::transform_loop: failed: %s\", state);\n@@ -539,0 +279,2 @@\n+  return false;\n+}\n@@ -540,10 +282,4 @@\n-  CountedLoopNode* cl = lpt()->_head->as_CountedLoop();\n-  assert(cl->is_main_loop(), \"SLP should only work on main loops\");\n-\n-  \/\/ Ready the block\n-  if (!construct_bb()) {\n-    return false; \/\/ Exit if no interesting nodes or complex graph.\n-  }\n-\n-  \/\/ build _dg, _disjoint_ptrs\n-  dependence_graph();\n+#define BAILOUT_ON_FAILURE(code) {{                  \\\n+  char const* state = code();                        \\\n+  if (state != SuperWord::SUCCESS) { return state; } \\\n+}}                                                   \\\n@@ -551,2 +287,0 @@\n-  \/\/ compute function depth(Node*)\n-  compute_max_depth();\n@@ -554,2 +288,3 @@\n-  \/\/ Compute vector element types\n-  compute_vector_element_type();\n+const char* SuperWord::transform_loop_helper() {\n+  assert(phase()->C->do_superword(), \"SuperWord option should be enabled\");\n+  assert(cl()->is_main_loop(), \"SLP should only work on main loops\");\n@@ -557,2 +292,2 @@\n-  \/\/ Attempt vectorization\n-  find_adjacent_refs();\n+  \/\/ Initialize data structures.\n+  init();\n@@ -560,9 +295,2 @@\n-  if (_packset.length() == 0) {\n-#ifndef PRODUCT\n-    if (TraceSuperWord) {\n-      tty->print_cr(\"\\nNo pair packs generated, abort SuperWord.\");\n-      tty->cr();\n-    }\n-#endif\n-    return false;\n-  }\n+  \/\/ Find adjacent loads and stores pairs.\n+  BAILOUT_ON_FAILURE(find_adjacent_refs);\n@@ -570,0 +298,1 @@\n+  \/\/ Extend pairs with non memory ops.\n@@ -572,1 +301,2 @@\n-  combine_packs();\n+  \/\/ Combine pairs into vectors sized packs.\n+  BAILOUT_ON_FAILURE(combine_packs);\n@@ -574,1 +304,1 @@\n-  filter_packs_for_alignment();\n+  BAILOUT_ON_FAILURE(filter_packs_for_alignment);\n@@ -576,0 +306,1 @@\n+  \/\/ Construct the map from nodes to packs.\n@@ -578,1 +309,2 @@\n-  filter_packs();\n+  \/\/ Remove packs that are not implemented or not profitable.\n+  BAILOUT_ON_FAILURE(filter_packs);\n@@ -582,1 +314,2 @@\n-  schedule();\n+  \/\/ Adjust the memory graph for the packed operations. And check for cycles.\n+  BAILOUT_ON_FAILURE(schedule);\n@@ -584,0 +317,1 @@\n+  \/\/ Convert packs into vector node operations.\n@@ -592,1 +326,3 @@\n-void SuperWord::find_adjacent_refs() {\n+const char* SuperWord::find_adjacent_refs() {\n+  assert(_packset.is_empty(), \"packset must be empty\");\n+\n@@ -595,3 +331,5 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n-    if (n->is_Mem() && !n->is_LoadStore() && in_bb(n) &&\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n+    if (n->is_Mem() &&\n+        !n->is_LoadStore() &&\n+        in_body(n) &&\n@@ -605,1 +343,2 @@\n-  if (TraceSuperWord) {\n+#ifndef PRODUCT\n+  if (is_trace_superword_adjacent_memops()) {\n@@ -608,0 +347,1 @@\n+#endif\n@@ -627,1 +367,1 @@\n-    VPointer align_to_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n+    VPointer align_to_ref_p(mem_ref, vla());\n@@ -633,1 +373,1 @@\n-        VPointer p2(s, phase(), lpt(), nullptr, false);\n+        VPointer p2(s, vla());\n@@ -674,0 +414,4 @@\n+  if (_packset.is_empty()) {\n+    return SuperWord::FAILURE_NO_ADJACENT_MEM;\n+  }\n+\n@@ -675,1 +419,1 @@\n-  if (TraceSuperWord) {\n+  if (is_trace_superword_packset()) {\n@@ -680,0 +424,2 @@\n+\n+  return SuperWord::SUCCESS;\n@@ -692,1 +438,1 @@\n-    VPointer p1(s1, phase(), lpt(), nullptr, false);\n+    VPointer p1(s1, vla());\n@@ -696,1 +442,1 @@\n-        VPointer p2(s2, phase(), lpt(), nullptr, false);\n+        VPointer p2(s2, vla());\n@@ -717,1 +463,1 @@\n-      VPointer p(s, phase(), lpt(), nullptr, false);\n+      VPointer p(s, vla());\n@@ -740,1 +486,1 @@\n-        VPointer p(s, phase(), lpt(), nullptr, false);\n+        VPointer p(s, vla());\n@@ -758,2 +504,2 @@\n-#ifdef ASSERT\n-  if (TraceSuperWord && Verbose) {\n+#ifndef PRODUCT\n+  if (is_trace_superword_verbose()) {\n@@ -770,3 +516,3 @@\n-#ifdef ASSERT\n-    if (TraceSuperWord) {\n-      tty->print(\"\\nVector align to node: \");\n+#ifndef PRODUCT\n+    if (is_trace_superword_adjacent_memops()) {\n+      tty->print(\"SuperWord::find_align_to_ref: \");\n@@ -797,1 +543,1 @@\n-      vw = MIN2(Matcher::superword_max_vector_size(btype)*type2aelembytes(btype), vw * 2);\n+      vw = MIN2(Matcher::max_vector_size_autovectorization(btype)*type2aelembytes(btype), vw * 2);\n@@ -803,1 +549,1 @@\n-  if (vectsize < Matcher::superword_max_vector_size(btype)) {\n+  if (vectsize < Matcher::max_vector_size_autovectorization(btype)) {\n@@ -813,1 +559,1 @@\n-  VPointer align_to_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n+  VPointer align_to_ref_p(mem_ref, vla());\n@@ -833,1 +579,1 @@\n-  if (TraceSuperWord) {\n+  if (is_trace_superword_alignment()) {\n@@ -842,140 +588,0 @@\n-\/\/---------------------------dependence_graph---------------------------\n-\/\/ Construct dependency graph.\n-\/\/ Add dependence edges to load\/store nodes for memory dependence\n-\/\/    A.out()->DependNode.in(1) and DependNode.out()->B.prec(x)\n-void SuperWord::dependence_graph() {\n-  CountedLoopNode *cl = lpt()->_head->as_CountedLoop();\n-  assert(cl->is_main_loop(), \"SLP should only work on main loops\");\n-\n-  \/\/ First, assign a dependence node to each memory node\n-  for (int i = 0; i < _block.length(); i++ ) {\n-    Node *n = _block.at(i);\n-    if (n->is_Mem() || n->is_memory_phi()) {\n-      _dg.make_node(n);\n-    }\n-  }\n-\n-  \/\/ For each memory slice, create the dependences\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* n      = _mem_slice_head.at(i);\n-    Node* n_tail = _mem_slice_tail.at(i);\n-\n-    \/\/ Get slice in predecessor order (last is first)\n-    mem_slice_preds(n_tail, n, _nlist);\n-\n-#ifndef PRODUCT\n-    if(TraceSuperWord && Verbose) {\n-      tty->print_cr(\"SuperWord::dependence_graph: built a new mem slice\");\n-      for (int j = _nlist.length() - 1; j >= 0 ; j--) {\n-        _nlist.at(j)->dump();\n-      }\n-    }\n-#endif\n-    \/\/ Make the slice dependent on the root\n-    DepMem* slice = _dg.dep(n);\n-    _dg.make_edge(_dg.root(), slice);\n-\n-    \/\/ Create a sink for the slice\n-    DepMem* slice_sink = _dg.make_node(nullptr);\n-    _dg.make_edge(slice_sink, _dg.tail());\n-\n-    \/\/ Now visit each pair of memory ops, creating the edges\n-    for (int j = _nlist.length() - 1; j >= 0 ; j--) {\n-      Node* s1 = _nlist.at(j);\n-\n-      \/\/ If no dependency yet, use slice\n-      if (_dg.dep(s1)->in_cnt() == 0) {\n-        _dg.make_edge(slice, s1);\n-      }\n-      VPointer p1(s1->as_Mem(), phase(), lpt(), nullptr, false);\n-      bool sink_dependent = true;\n-      for (int k = j - 1; k >= 0; k--) {\n-        Node* s2 = _nlist.at(k);\n-        if (s1->is_Load() && s2->is_Load())\n-          continue;\n-        VPointer p2(s2->as_Mem(), phase(), lpt(), nullptr, false);\n-\n-        int cmp = p1.cmp(p2);\n-        if (SuperWordRTDepCheck &&\n-            p1.base() != p2.base() && p1.valid() && p2.valid()) {\n-          \/\/ Trace disjoint pointers\n-          OrderedPair pp(p1.base(), p2.base());\n-          _disjoint_ptrs.append_if_missing(pp);\n-        }\n-        if (!VPointer::not_equal(cmp)) {\n-          \/\/ Possibly same address\n-          _dg.make_edge(s1, s2);\n-          sink_dependent = false;\n-        }\n-      }\n-      if (sink_dependent) {\n-        _dg.make_edge(s1, slice_sink);\n-      }\n-    }\n-\n-    if (TraceSuperWord) {\n-      tty->print_cr(\"\\nDependence graph for slice: %d\", n->_idx);\n-      for (int q = 0; q < _nlist.length(); q++) {\n-        _dg.print(_nlist.at(q));\n-      }\n-      tty->cr();\n-    }\n-\n-    _nlist.clear();\n-  }\n-\n-  if (TraceSuperWord) {\n-    tty->print_cr(\"\\ndisjoint_ptrs: %s\", _disjoint_ptrs.length() > 0 ? \"\" : \"NONE\");\n-    for (int r = 0; r < _disjoint_ptrs.length(); r++) {\n-      _disjoint_ptrs.at(r).print();\n-      tty->cr();\n-    }\n-    tty->cr();\n-  }\n-\n-}\n-\n-\/\/---------------------------mem_slice_preds---------------------------\n-\/\/ Return a memory slice (node list) in predecessor order starting at \"start\"\n-void SuperWord::mem_slice_preds(Node* start, Node* stop, GrowableArray<Node*> &preds) {\n-  assert(preds.length() == 0, \"start empty\");\n-  Node* n = start;\n-  Node* prev = nullptr;\n-  while (true) {\n-    NOT_PRODUCT( if(is_trace_mem_slice()) tty->print_cr(\"SuperWord::mem_slice_preds: n %d\", n->_idx);)\n-    assert(in_bb(n), \"must be in block\");\n-    for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n-      Node* out = n->fast_out(i);\n-      if (out->is_Load()) {\n-        if (in_bb(out)) {\n-          preds.push(out);\n-          if (TraceSuperWord && Verbose) {\n-            tty->print_cr(\"SuperWord::mem_slice_preds: added pred(%d)\", out->_idx);\n-          }\n-        }\n-      } else {\n-        \/\/ FIXME\n-        if (out->is_MergeMem() && !in_bb(out)) {\n-          \/\/ Either unrolling is causing a memory edge not to disappear,\n-          \/\/ or need to run igvn.optimize() again before SLP\n-        } else if (out->is_memory_phi() && !in_bb(out)) {\n-          \/\/ Ditto.  Not sure what else to check further.\n-        } else if (out->Opcode() == Op_StoreCM && out->in(MemNode::OopStore) == n) {\n-          \/\/ StoreCM has an input edge used as a precedence edge.\n-          \/\/ Maybe an issue when oop stores are vectorized.\n-        } else {\n-          assert(out == prev || prev == nullptr, \"no branches off of store slice\");\n-        }\n-      }\/\/else\n-    }\/\/for\n-    if (n == stop) break;\n-    preds.push(n);\n-    if (TraceSuperWord && Verbose) {\n-      tty->print_cr(\"SuperWord::mem_slice_preds: added pred(%d)\", n->_idx);\n-    }\n-    prev = n;\n-    assert(n->is_Mem(), \"unexpected node %s\", n->Name());\n-    n = n->in(MemNode::Memory);\n-  }\n-}\n-\n@@ -993,2 +599,2 @@\n-  if (Matcher::superword_max_vector_size(bt1) < 2 ||\n-      (longer_bt != T_ILLEGAL && Matcher::superword_max_vector_size(longer_bt) < 2)) {\n+  if (Matcher::max_vector_size_autovectorization(bt1) < 2 ||\n+      (longer_bt != T_ILLEGAL && Matcher::max_vector_size_autovectorization(longer_bt) < 2)) {\n@@ -1031,2 +637,6 @@\n-  if (!s1->is_Mem() || !s2->is_Mem()) return false;\n-  if (!in_bb(s1)    || !in_bb(s2))    return false;\n+  if (!s1->is_Mem() ||\n+      !s2->is_Mem() ||\n+      !in_body(s1) ||\n+      !in_body(s2)) {\n+    return false;\n+  }\n@@ -1047,2 +657,2 @@\n-  VPointer p1(s1->as_Mem(), phase(), lpt(), nullptr, false);\n-  VPointer p2(s2->as_Mem(), phase(), lpt(), nullptr, false);\n+  VPointer p1(s1->as_Mem(), vla());\n+  VPointer p2(s2->as_Mem(), vla());\n@@ -1077,53 +687,0 @@\n-\/\/------------------------------independent---------------------------\n-\/\/ Is there no data path from s1 to s2 or s2 to s1?\n-bool SuperWord::independent(Node* s1, Node* s2) {\n-  \/\/  assert(s1->Opcode() == s2->Opcode(), \"check isomorphic first\");\n-  int d1 = depth(s1);\n-  int d2 = depth(s2);\n-  if (d1 == d2) return s1 != s2;\n-  Node* deep    = d1 > d2 ? s1 : s2;\n-  Node* shallow = d1 > d2 ? s2 : s1;\n-\n-  visited_clear();\n-\n-  return independent_path(shallow, deep);\n-}\n-\n-\/\/------------------------------find_dependence---------------------\n-\/\/ Is any s1 in p dependent on any s2 in p? Yes: return such a s2. No: return nullptr.\n-\/\/ We could query independent(s1, s2) for all pairs, but that results\n-\/\/ in O(p.size * p.size) graph traversals. We can do it all in one BFS!\n-\/\/ Start the BFS traversal at all nodes from the pack. Traverse DepPreds\n-\/\/ recursively, for nodes that have at least depth min_d, which is the\n-\/\/ smallest depth of all nodes from the pack. Once we have traversed all\n-\/\/ those nodes, and have not found another node from the pack, we know\n-\/\/ that all nodes in the pack are independent.\n-Node* SuperWord::find_dependence(Node_List* p) {\n-  if (is_marked_reduction(p->at(0))) {\n-    return nullptr; \/\/ ignore reductions\n-  }\n-  ResourceMark rm;\n-  Unique_Node_List worklist; \/\/ traversal queue\n-  int min_d = depth(p->at(0));\n-  visited_clear();\n-  for (uint k = 0; k < p->size(); k++) {\n-    Node* n = p->at(k);\n-    min_d = MIN2(min_d, depth(n));\n-    worklist.push(n); \/\/ start traversal at all nodes in p\n-    visited_set(n); \/\/ mark node\n-  }\n-  for (uint i = 0; i < worklist.size(); i++) {\n-    Node* n = worklist.at(i);\n-    for (DepPreds preds(n, _dg); !preds.done(); preds.next()) {\n-      Node* pred = preds.current();\n-      if (in_bb(pred) && depth(pred) >= min_d) {\n-        if (visited_test(pred)) { \/\/ marked as in p?\n-          return pred;\n-        }\n-        worklist.push(pred);\n-      }\n-    }\n-  }\n-  return nullptr;\n-}\n-\n@@ -1153,43 +710,0 @@\n-\/\/------------------------------reduction---------------------------\n-\/\/ Is there a data path between s1 and s2 and the nodes reductions?\n-bool SuperWord::reduction(Node* s1, Node* s2) {\n-  bool retValue = false;\n-  int d1 = depth(s1);\n-  int d2 = depth(s2);\n-  if (d2 > d1) {\n-    if (is_marked_reduction(s1) && is_marked_reduction(s2)) {\n-      \/\/ This is an ordered set, so s1 should define s2\n-      for (DUIterator_Fast imax, i = s1->fast_outs(imax); i < imax; i++) {\n-        Node* t1 = s1->fast_out(i);\n-        if (t1 == s2) {\n-          \/\/ both nodes are reductions and connected\n-          retValue = true;\n-        }\n-      }\n-    }\n-  }\n-\n-  return retValue;\n-}\n-\n-\/\/------------------------------independent_path------------------------------\n-\/\/ Helper for independent\n-bool SuperWord::independent_path(Node* shallow, Node* deep, uint dp) {\n-  if (dp >= 1000) return false; \/\/ stop deep recursion\n-  visited_set(deep);\n-  int shal_depth = depth(shallow);\n-  assert(shal_depth <= depth(deep), \"must be\");\n-  for (DepPreds preds(deep, _dg); !preds.done(); preds.next()) {\n-    Node* pred = preds.current();\n-    if (in_bb(pred) && !visited_test(pred)) {\n-      if (shallow == pred) {\n-        return false;\n-      }\n-      if (shal_depth < depth(pred) && !independent_path(shallow, pred, dp+1)) {\n-        return false;\n-      }\n-    }\n-  }\n-  return true;\n-}\n-\n@@ -1206,7 +720,0 @@\n-\/\/------------------------------data_size---------------------------\n-int SuperWord::data_size(Node* s) {\n-  int bsize = type2aelembytes(velt_basic_type(s));\n-  assert(bsize != 0, \"valid size\");\n-  return bsize;\n-}\n-\n@@ -1216,0 +723,2 @@\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -1234,1 +743,2 @@\n-  if (TraceSuperWord) {\n+#ifndef PRODUCT\n+  if (is_trace_superword_packset()) {\n@@ -1238,0 +748,1 @@\n+#endif\n@@ -1267,1 +778,6 @@\n-  NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"SuperWord::follow_use_defs: s1 %d, align %d\", s1->_idx, alignment(s1));)\n+#ifndef PRODUCT\n+  if(is_trace_superword_alignment()) {\n+    tty->print_cr(\"SuperWord::follow_use_defs: s1 %d, align %d\",\n+                  s1->_idx, alignment(s1));\n+  }\n+#endif\n@@ -1275,1 +791,4 @@\n-    if (!in_bb(t1) || !in_bb(t2) || t1->is_Mem() || t2->is_Mem())  {\n+    if (!in_body(t1) ||\n+        !in_body(t2) ||\n+        t1->is_Mem() ||\n+        t2->is_Mem())  {\n@@ -1286,1 +805,6 @@\n-        NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"SuperWord::follow_use_defs: set_alignment(%d, %d, %d)\", t1->_idx, t2->_idx, align);)\n+#ifndef PRODUCT\n+        if(is_trace_superword_alignment()) {\n+          tty->print_cr(\"SuperWord::follow_use_defs: set_alignment(%d, %d, %d)\",\n+                        t1->_idx, t2->_idx, align);\n+        }\n+#endif\n@@ -1308,1 +832,6 @@\n-  NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"SuperWord::follow_def_uses: s1 %d, align %d\", s1->_idx, align);)\n+#ifndef PRODUCT\n+  if(is_trace_superword_alignment()) {\n+    tty->print_cr(\"SuperWord::follow_def_uses: s1 %d, align %d\",\n+                  s1->_idx, align);\n+  }\n+#endif\n@@ -1316,1 +845,1 @@\n-    if (!in_bb(t1) || t1->is_Mem()) {\n+    if (!in_body(t1) || t1->is_Mem()) {\n@@ -1322,1 +851,1 @@\n-      if (!in_bb(t2) || t2->is_Mem()) {\n+      if (!in_body(t2) || t2->is_Mem()) {\n@@ -1326,1 +855,1 @@\n-      if (t2->Opcode() == Op_AddI && t2 == _lp->as_CountedLoop()->incr()) continue; \/\/ don't mess with the iv\n+      if (t2->Opcode() == Op_AddI && t2 == cl()->incr()) continue; \/\/ don't mess with the iv\n@@ -1350,1 +879,6 @@\n-    NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"SuperWord::follow_def_uses: set_alignment(%d, %d, %d)\", u1->_idx, u2->_idx, align);)\n+#ifndef PRODUCT\n+    if(is_trace_superword_alignment()) {\n+      tty->print_cr(\"SuperWord::follow_def_uses: set_alignment(%d, %d, %d)\",\n+                    u1->_idx, u2->_idx, align);\n+    }\n+#endif\n@@ -1502,1 +1036,2 @@\n-void SuperWord::combine_packs() {\n+const char* SuperWord::combine_packs() {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n@@ -1541,1 +1076,1 @@\n-        if (TraceSuperWord) {\n+        if (is_trace_superword_rejections()) {\n@@ -1588,2 +1123,2 @@\n-      Node* dependence = find_dependence(p);\n-      if (dependence != nullptr) {\n+      if (!is_marked_reduction(p->at(0)) &&\n+          !vla().dependence_graph().mutually_independent(p)) {\n@@ -1591,1 +1126,1 @@\n-        if (TraceSuperWord) {\n+        if (is_trace_superword_rejections()) {\n@@ -1594,1 +1129,0 @@\n-          dependence->dump();\n@@ -1607,0 +1141,4 @@\n+  if(_packset.is_empty()) {\n+    return SuperWord::FAILURE_COMBINE_PACKS;\n+  }\n+\n@@ -1608,1 +1146,1 @@\n-  if (TraceSuperWord) {\n+  if (is_trace_superword_packset()) {\n@@ -1613,0 +1151,2 @@\n+\n+  return SuperWord::SUCCESS;\n@@ -1620,2 +1160,2 @@\n-  VPointer mem_ref_p(mem_ref, phase(), lpt(), nullptr, false);\n-  const CountedLoopEndNode* pre_end = lp()->pre_loop_end();\n+  VPointer mem_ref_p(mem_ref, vla());\n+  const CountedLoopEndNode* pre_end = vla().pre_loop_end();\n@@ -1634,1 +1174,1 @@\n-                         DEBUG_ONLY(COMMA is_trace_align_vector()));\n+                         NOT_PRODUCT(COMMA is_trace_align_vector()));\n@@ -1642,1 +1182,3 @@\n-void SuperWord::filter_packs_for_alignment() {\n+const char* SuperWord::filter_packs_for_alignment() {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -1644,2 +1186,2 @@\n-  if (!vectors_should_be_aligned()) {\n-    return;\n+  if (!VLoop::vectors_must_be_aligned()) {\n+    return SuperWord::SUCCESS;\n@@ -1649,2 +1191,2 @@\n-  if (TraceSuperWord || is_trace_align_vector()) {\n-    tty->print_cr(\"\\nfilter_packs_for_alignment:\");\n+  if (is_trace_superword_info() || is_trace_align_vector()) {\n+    tty->print_cr(\"\\nSuperWord::filter_packs_for_alignment:\");\n@@ -1680,0 +1222,6 @@\n+#ifndef PRODUCT\n+          if (is_trace_superword_rejections() || is_trace_align_vector()) {\n+            tty->print_cr(\"Rejected by AlignVector:\");\n+            p->at(0)->dump();\n+          }\n+#endif\n@@ -1691,1 +1239,1 @@\n-  if (TraceSuperWord || is_trace_align_vector()) {\n+  if (is_trace_superword_info() || is_trace_align_vector()) {\n@@ -1708,0 +1256,13 @@\n+\n+  if (_packset.is_empty()) {\n+    return SuperWord::FAILURE_ALIGN_VECTOR;\n+  }\n+\n+#ifndef PRODUCT\n+  if (is_trace_superword_packset() || is_trace_align_vector()) {\n+    tty->print_cr(\"\\nAfter filter_packs_for_alignment\");\n+    print_packset();\n+  }\n+#endif\n+\n+  return SuperWord::SUCCESS;\n@@ -1727,0 +1288,2 @@\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -1746,1 +1309,3 @@\n-void SuperWord::filter_packs() {\n+const char* SuperWord::filter_packs() {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -1753,2 +1318,2 @@\n-      if ((TraceSuperWord && Verbose) || _vector_loop_debug) {\n-        tty->print_cr(\"Unimplemented\");\n+      if (is_trace_superword_rejections()) {\n+        tty->print_cr(\"Unimplemented:\");\n@@ -1777,2 +1342,2 @@\n-        if ((TraceSuperWord && Verbose) || _vector_loop_debug) {\n-          tty->print_cr(\"Unprofitable\");\n+        if (is_trace_superword_rejections()) {\n+          tty->print_cr(\"Unprofitable:\");\n@@ -1788,0 +1353,4 @@\n+  if (_packset.is_empty()) {\n+    return SuperWord::FAILURE_FILTER_PACKS;\n+  }\n+\n@@ -1789,1 +1358,1 @@\n-  if (TraceSuperWord) {\n+  if (is_trace_superword_packset()) {\n@@ -1795,0 +1364,2 @@\n+\n+  return SuperWord::SUCCESS;\n@@ -1895,3 +1466,0 @@\n-      \/\/ Unmark reduction if no parent pack or if not enough work\n-      \/\/ to cover reduction expansion overhead\n-      _loop_reductions.remove(p0->_idx);\n@@ -1927,2 +1495,2 @@\n-                ((use->is_Phi() && use->in(0) == _lpt->_head) ||\n-                 (!_lpt->is_member(_phase->get_loop(_phase->ctrl_or_self(use))) && i == p->size()-1))) {\n+                ((use->is_Phi() && use->in(0) == cl()) ||\n+                 (!lpt()->is_member(phase()->get_loop(phase()->ctrl_or_self(use))) && i == p->size()-1))) {\n@@ -1973,1 +1541,3 @@\n-void SuperWord::verify_packs() {\n+void SuperWord::verify_packs() const {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -1977,12 +1547,3 @@\n-    Node* dependence = find_dependence(p);\n-    if (dependence != nullptr) {\n-      tty->print_cr(\"Other nodes in pack have dependence on:\");\n-      dependence->dump();\n-      tty->print_cr(\"The following nodes are not independent:\");\n-      for (uint k = 0; k < p->size(); k++) {\n-        Node* n = p->at(k);\n-        if (!independent(n, dependence)) {\n-          n->dump();\n-        }\n-      }\n-      tty->print_cr(\"They are all from pack[%d]\", i);\n+    if (!is_marked_reduction(p->at(0)) &&\n+        !vla().dependence_graph().mutually_independent(p)) {\n+      tty->print_cr(\"FAILURE: nodes not mutually independent in pack[%d]\", i);\n@@ -1990,0 +1551,1 @@\n+      assert(false, \"pack nodes not mutually independent\");\n@@ -1991,1 +1553,0 @@\n-    assert(dependence == nullptr, \"all nodes in pack must be mutually independent\");\n@@ -1995,0 +1556,1 @@\n+  ResourceMark rm;\n@@ -2000,1 +1562,1 @@\n-      assert(in_bb(n), \"only nodes in bb can be in packset\");\n+      assert(in_body(n), \"only nodes in bb can be in packset\");\n@@ -2008,2 +1570,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -2017,1 +1579,1 @@\n-\/\/ The PacksetGraph combines the DepPreds graph with the packset. In the PackSet\n+\/\/ The PacksetGraph combines the dependence graph with the packset. In the PackSet\n@@ -2022,1 +1584,1 @@\n-\/\/ For any edge (n1, n2) in DepPreds, we add an edge to the PacksetGraph for the\n+\/\/ For any edge (n1, n2) in Preds, we add an edge to the PacksetGraph for the\n@@ -2024,2 +1586,2 @@\n-\/\/ We work from the DepPreds graph, because it gives us all the data-dependencies,\n-\/\/ as well as more refined memory-dependencies than the C2 graph. DepPreds does\n+\/\/ We work from the dependence graph, because it gives us all the data-dependencies,\n+\/\/ as well as more refined memory-dependencies than the C2 graph. Preds does\n@@ -2037,1 +1599,1 @@\n-  GrowableArray<int> _pid;                 \/\/ bb_idx(n) -> pid\n+  GrowableArray<int> _pid;                 \/\/ body_idx(n) -> pid\n@@ -2052,1 +1614,1 @@\n-    if (!_slp->in_bb(n)) {\n+    if (!_slp->in_body(n)) {\n@@ -2055,1 +1617,1 @@\n-    int idx = _slp->bb_idx(n);\n+    int idx = _slp->body_idx(n);\n@@ -2069,2 +1631,2 @@\n-    assert(_slp->in_bb(n), \"must be\");\n-    int idx = _slp->bb_idx(n);\n+    assert(_slp->in_body(n), \"must be\");\n+    int idx = _slp->body_idx(n);\n@@ -2090,1 +1652,2 @@\n-  \/\/ Create nodes (from packs and scalar-nodes), and add edges, based on DepPreds.\n+  \/\/ Create nodes (from packs and scalar-nodes), and add edges, based on\n+  \/\/ dependence graph.\n@@ -2093,2 +1656,1 @@\n-    const GrowableArray<Node*> &block = _slp->block();\n-    const DepGraph &dg = _slp->dg();\n+    const GrowableArray<Node*> &block = _slp->body();\n@@ -2131,1 +1693,2 @@\n-        for (DepPreds preds(n, dg); !preds.done(); preds.next()) {\n+        VLoopDependenceGraph::PredsIterator preds(n, _slp->vla().dependence_graph());\n+        for (; !preds.done(); preds.next()) {\n@@ -2153,1 +1716,2 @@\n-      for (DepPreds preds(n, dg); !preds.done(); preds.next()) {\n+      VLoopDependenceGraph::PredsIterator preds(n, _slp->vla().dependence_graph());\n+      for (; !preds.done(); preds.next()) {\n@@ -2217,1 +1781,1 @@\n-    const GrowableArray<Node*> &block = _slp->block();\n+    const GrowableArray<Node*> &block = _slp->body();\n@@ -2244,1 +1808,1 @@\n-\/\/ (1) Build the PacksetGraph. It combines the DepPreds graph with the\n+\/\/ (1) Build the PacksetGraph. It combines the dependence graph with the\n@@ -2252,4 +1816,3 @@\n-void SuperWord::schedule() {\n-  if (_packset.length() == 0) {\n-    return; \/\/ empty packset\n-  }\n+const char* SuperWord::schedule() {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -2272,1 +1835,2 @@\n-    if (TraceSuperWord) {\n+#ifndef PRODUCT\n+    if (is_trace_superword_rejections()) {\n@@ -2277,0 +1841,1 @@\n+#endif\n@@ -2278,1 +1843,1 @@\n-    return;\n+    return SuperWord::FAILURE_SCHEDULE_CYCLE;\n@@ -2282,1 +1847,1 @@\n-  if (TraceSuperWord) {\n+  if (is_trace_superword_info()) {\n@@ -2289,1 +1854,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD1_BEFORE_SCHEDULE, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD1_BEFORE_SCHEDULE, 4, cl);\n@@ -2293,0 +1858,2 @@\n+\n+  return SuperWord::SUCCESS;\n@@ -2299,1 +1866,1 @@\n-  int max_slices = _phase->C->num_alias_types();\n+  int max_slices = phase()->C->num_alias_types();\n@@ -2307,0 +1874,2 @@\n+  const GrowableArray<PhiNode*> &mem_slice_head = _vla.memory_slices().heads();\n+\n@@ -2308,2 +1877,2 @@\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* phi  = _mem_slice_head.at(i);\n+  for (int i = 0; i < mem_slice_head.length(); i++) {\n+    Node* phi  = mem_slice_head.at(i);\n@@ -2311,1 +1880,1 @@\n-    int alias_idx = _phase->C->get_alias_index(phi->adr_type());\n+    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n@@ -2324,1 +1893,1 @@\n-    int alias_idx = _phase->C->get_alias_index(n->adr_type());\n+    int alias_idx = phase()->C->get_alias_index(n->adr_type());\n@@ -2330,1 +1899,1 @@\n-      assert(n->is_Load() && !in_bb(n->in(MemNode::Memory)),\n+      assert(n->is_Load() && !in_body(n->in(MemNode::Memory)),\n@@ -2333,1 +1902,1 @@\n-      _igvn.replace_input_of(n, MemNode::Memory, current_state);\n+      igvn().replace_input_of(n, MemNode::Memory, current_state);\n@@ -2344,3 +1913,3 @@\n-  for (int i = 0; i < _mem_slice_head.length(); i++) {\n-    Node* phi  = _mem_slice_head.at(i);\n-    int alias_idx = _phase->C->get_alias_index(phi->adr_type());\n+  for (int i = 0; i < mem_slice_head.length(); i++) {\n+    Node* phi  = mem_slice_head.at(i);\n+    int alias_idx = phase()->C->get_alias_index(phi->adr_type());\n@@ -2351,1 +1920,1 @@\n-    _igvn.replace_input_of(phi, 2, current_state);\n+    igvn().replace_input_of(phi, 2, current_state);\n@@ -2361,1 +1930,1 @@\n-      if (!in_bb(use)) {\n+      if (!in_body(use)) {\n@@ -2370,1 +1939,1 @@\n-          _igvn.replace_input_of(use, j, current_state);\n+          igvn().replace_input_of(use, j, current_state);\n@@ -2384,1 +1953,3 @@\n-bool SuperWord::output() {\n+const char* SuperWord::output() {\n+  assert(!_packset.is_empty(), \"packset must not be empty\");\n+\n@@ -2387,4 +1958,1 @@\n-  Compile* C = _phase->C;\n-  if (_packset.length() == 0) {\n-    return false;\n-  }\n+  Compile* C = phase()->C;\n@@ -2398,1 +1966,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD2_BEFORE_OUTPUT, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD2_BEFORE_OUTPUT, 4, cl);\n@@ -2410,2 +1978,2 @@\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n+  for (int i = 0; i < body().length(); i++) {\n+    Node* n = body().at(i);\n@@ -2421,1 +1989,0 @@\n-      NOT_PRODUCT(if(is_trace_cmov()) {tty->print_cr(\"VPointer::output: %d executed first, %d executed last in pack\", first->_idx, n->_idx); print_pack(p);})\n@@ -2430,1 +1997,1 @@\n-          VPointer p_store(mem->as_Mem(), phase(), lpt(), nullptr, false);\n+          VPointer p_store(mem->as_Mem(), vla());\n@@ -2447,1 +2014,1 @@\n-          return false; \/\/ bailout\n+          return SuperWord::FAILURE_OUTPUT_BAILOUT;\n@@ -2564,1 +2131,1 @@\n-        ConINode* bol_test_node  = _igvn.intcon((int)bol_test);\n+        ConINode* bol_test_node  = igvn().intcon((int)bol_test);\n@@ -2568,3 +2135,3 @@\n-        _igvn.register_new_node_with_optimizer(mask);\n-        _phase->set_ctrl(mask, _phase->get_ctrl(p->at(0)));\n-        _igvn._worklist.push(mask);\n+        igvn().register_new_node_with_optimizer(mask);\n+        phase()->set_ctrl(mask, phase()->get_ctrl(p->at(0)));\n+        igvn()._worklist.push(mask);\n@@ -2586,1 +2153,1 @@\n-            return false; \/\/ bailout\n+            return SuperWord::FAILURE_OUTPUT_BAILOUT;\n@@ -2593,1 +2160,1 @@\n-          return false; \/\/ bailout\n+          return SuperWord::FAILURE_OUTPUT_BAILOUT;\n@@ -2643,2 +2210,2 @@\n-        _igvn.register_new_node_with_optimizer(longval);\n-        _phase->set_ctrl(longval, _phase->get_ctrl(first));\n+        igvn().register_new_node_with_optimizer(longval);\n+        phase()->set_ctrl(longval, phase()->get_ctrl(first));\n@@ -2664,1 +2231,1 @@\n-        return false; \/\/ bailout\n+        return SuperWord::FAILURE_OUTPUT_BAILOUT;\n@@ -2670,1 +2237,1 @@\n-        return false; \/\/ bailout\n+        return SuperWord::FAILURE_OUTPUT_BAILOUT;\n@@ -2684,3 +2251,2 @@\n-      _block.at_put(i, vn);\n-      _igvn.register_new_node_with_optimizer(vn);\n-      _phase->set_ctrl(vn, _phase->get_ctrl(first));\n+      igvn().register_new_node_with_optimizer(vn);\n+      phase()->set_ctrl(vn, phase()->get_ctrl(first));\n@@ -2689,1 +2255,1 @@\n-        _igvn.replace_node(pm, vn);\n+        igvn().replace_node(pm, vn);\n@@ -2691,1 +2257,1 @@\n-      _igvn._worklist.push(vn);\n+      igvn()._worklist.push(vn);\n@@ -2701,1 +2267,1 @@\n-  }\/\/for (int i = 0; i < _block.length(); i++)\n+  }\/\/for (int i = 0; i < body().length(); i++)\n@@ -2714,0 +2280,1 @@\n+#ifndef PRODUCT\n@@ -2717,0 +2284,1 @@\n+#endif\n@@ -2728,1 +2296,1 @@\n-  _phase->C->print_method(PHASE_SUPERWORD3_AFTER_OUTPUT, 4, cl);\n+  phase()->C->print_method(PHASE_SUPERWORD3_AFTER_OUTPUT, 4, cl);\n@@ -2730,1 +2298,1 @@\n-  return true;\n+  return SuperWord::SUCCESS;\n@@ -2751,1 +2319,1 @@\n-    Node* vn = new PopulateIndexNode(iv(), _igvn.intcon(1), vt);\n+    Node* vn = new PopulateIndexNode(iv(), igvn().intcon(1), vt);\n@@ -2753,2 +2321,2 @@\n-    _igvn.register_new_node_with_optimizer(vn);\n-    _phase->set_ctrl(vn, _phase->get_ctrl(opd));\n+    igvn().register_new_node_with_optimizer(vn);\n+    phase()->set_ctrl(vn, phase()->get_ctrl(opd));\n@@ -2775,1 +2343,1 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n+          igvn().register_new_node_with_optimizer(cnt);\n@@ -2780,1 +2348,1 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n+          igvn().register_new_node_with_optimizer(cnt);\n@@ -2782,2 +2350,2 @@\n-          _igvn.register_new_node_with_optimizer(cnt);\n-          _phase->set_ctrl(cnt, _phase->get_ctrl(opd));\n+          igvn().register_new_node_with_optimizer(cnt);\n+          phase()->set_ctrl(cnt, phase()->get_ctrl(opd));\n@@ -2792,2 +2360,2 @@\n-      _igvn.register_new_node_with_optimizer(cnt);\n-      _phase->set_ctrl(cnt, _phase->get_ctrl(opd));\n+      igvn().register_new_node_with_optimizer(cnt);\n+      phase()->set_ctrl(cnt, phase()->get_ctrl(opd));\n@@ -2811,2 +2379,2 @@\n-         _igvn.register_new_node_with_optimizer(conv);\n-         _phase->set_ctrl(conv, _phase->get_ctrl(opd));\n+         igvn().register_new_node_with_optimizer(conv);\n+         phase()->set_ctrl(conv, phase()->get_ctrl(opd));\n@@ -2820,2 +2388,2 @@\n-    _igvn.register_new_node_with_optimizer(vn);\n-    _phase->set_ctrl(vn, _phase->get_ctrl(opd));\n+    igvn().register_new_node_with_optimizer(vn);\n+    phase()->set_ctrl(vn, phase()->get_ctrl(opd));\n@@ -2850,2 +2418,2 @@\n-  _igvn.register_new_node_with_optimizer(pk);\n-  _phase->set_ctrl(pk, _phase->get_ctrl(opd));\n+  igvn().register_new_node_with_optimizer(pk);\n+  phase()->set_ctrl(pk, phase()->get_ctrl(opd));\n@@ -2891,1 +2459,1 @@\n-    _igvn.hash_delete(def);\n+    igvn().hash_delete(def);\n@@ -2894,1 +2462,1 @@\n-    ConINode* def_pos_con = _igvn.intcon(def_pos)->as_ConI();\n+    ConINode* def_pos_con = igvn().intcon(def_pos)->as_ConI();\n@@ -2896,4 +2464,4 @@\n-    _igvn.register_new_node_with_optimizer(ex);\n-    _phase->set_ctrl(ex, _phase->get_ctrl(def));\n-    _igvn.replace_input_of(use, idx, ex);\n-    _igvn._worklist.push(def);\n+    igvn().register_new_node_with_optimizer(ex);\n+    phase()->set_ctrl(ex, phase()->get_ctrl(def));\n+    igvn().replace_input_of(use, idx, ex);\n+    igvn()._worklist.push(def);\n@@ -2901,2 +2469,1 @@\n-    bb_insert_after(ex, bb_idx(def));\n-    set_velt_type(ex, velt_type(def));\n+    assert(false, \"this is dead code as far as we know\");\n@@ -2983,204 +2550,0 @@\n-\/\/------------------------------construct_bb---------------------------\n-\/\/ Construct reverse postorder list of block members\n-bool SuperWord::construct_bb() {\n-  Node* entry = bb();\n-\n-  assert(_stk.length() == 0,            \"stk is empty\");\n-  assert(_block.length() == 0,          \"block is empty\");\n-  assert(_data_entry.length() == 0,     \"data_entry is empty\");\n-  assert(_mem_slice_head.length() == 0, \"mem_slice_head is empty\");\n-  assert(_mem_slice_tail.length() == 0, \"mem_slice_tail is empty\");\n-\n-  \/\/ Find non-control nodes with no inputs from within block,\n-  \/\/ create a temporary map from node _idx to bb_idx for use\n-  \/\/ by the visited and post_visited sets,\n-  \/\/ and count number of nodes in block.\n-  int bb_ct = 0;\n-  for (uint i = 0; i < lpt()->_body.size(); i++) {\n-    Node *n = lpt()->_body.at(i);\n-    set_bb_idx(n, i); \/\/ Create a temporary map\n-    if (in_bb(n)) {\n-      if (n->is_LoadStore() || n->is_MergeMem() ||\n-          (n->is_Proj() && !n->as_Proj()->is_CFG())) {\n-        \/\/ Bailout if the loop has LoadStore, MergeMem or data Proj\n-        \/\/ nodes. Superword optimization does not work with them.\n-        return false;\n-      }\n-      bb_ct++;\n-      if (!n->is_CFG()) {\n-        bool found = false;\n-        for (uint j = 0; j < n->req(); j++) {\n-          Node* def = n->in(j);\n-          if (def && in_bb(def)) {\n-            found = true;\n-            break;\n-          }\n-        }\n-        if (!found) {\n-          assert(n != entry, \"can't be entry\");\n-          _data_entry.push(n);\n-        }\n-      }\n-    }\n-  }\n-\n-  \/\/ Find memory slices (head and tail)\n-  for (DUIterator_Fast imax, i = lp()->fast_outs(imax); i < imax; i++) {\n-    Node *n = lp()->fast_out(i);\n-    if (in_bb(n) && n->is_memory_phi()) {\n-      Node* n_tail  = n->in(LoopNode::LoopBackControl);\n-      if (n_tail != n->in(LoopNode::EntryControl)) {\n-        if (!n_tail->is_Mem()) {\n-          assert(n_tail->is_Mem(), \"unexpected node for memory slice: %s\", n_tail->Name());\n-          return false; \/\/ Bailout\n-        }\n-        _mem_slice_head.push(n);\n-        _mem_slice_tail.push(n_tail);\n-      }\n-    }\n-  }\n-\n-  \/\/ Create an RPO list of nodes in block\n-\n-  visited_clear();\n-  post_visited_clear();\n-\n-  \/\/ Push all non-control nodes with no inputs from within block, then control entry\n-  for (int j = 0; j < _data_entry.length(); j++) {\n-    Node* n = _data_entry.at(j);\n-    visited_set(n);\n-    _stk.push(n);\n-  }\n-  visited_set(entry);\n-  _stk.push(entry);\n-\n-  \/\/ Do a depth first walk over out edges\n-  int rpo_idx = bb_ct - 1;\n-  int size;\n-  int reduction_uses = 0;\n-  while ((size = _stk.length()) > 0) {\n-    Node* n = _stk.top(); \/\/ Leave node on stack\n-    if (!visited_test_set(n)) {\n-      \/\/ forward arc in graph\n-    } else if (!post_visited_test(n)) {\n-      \/\/ cross or back arc\n-      for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n-        Node *use = n->fast_out(i);\n-        if (in_bb(use) && !visited_test(use) &&\n-            \/\/ Don't go around backedge\n-            (!use->is_Phi() || n == entry)) {\n-          if (is_marked_reduction(use)) {\n-            \/\/ First see if we can map the reduction on the given system we are on, then\n-            \/\/ make a data entry operation for each reduction we see.\n-            BasicType bt = use->bottom_type()->basic_type();\n-            if (ReductionNode::implemented(use->Opcode(), Matcher::superword_max_vector_size(bt), bt)) {\n-              reduction_uses++;\n-            }\n-          }\n-          _stk.push(use);\n-        }\n-      }\n-      if (_stk.length() == size) {\n-        \/\/ There were no additional uses, post visit node now\n-        _stk.pop(); \/\/ Remove node from stack\n-        assert(rpo_idx >= 0, \"\");\n-        _block.at_put_grow(rpo_idx, n);\n-        rpo_idx--;\n-        post_visited_set(n);\n-        assert(rpo_idx >= 0 || _stk.is_empty(), \"\");\n-      }\n-    } else {\n-      _stk.pop(); \/\/ Remove post-visited node from stack\n-    }\n-  }\/\/while\n-\n-  int ii_current = -1;\n-  unsigned int load_idx = (unsigned int)-1;\n-  \/\/ Create real map of block indices for nodes\n-  for (int j = 0; j < _block.length(); j++) {\n-    Node* n = _block.at(j);\n-    set_bb_idx(n, j);\n-  }\/\/for\n-\n-  \/\/ Ensure extra info is allocated.\n-  initialize_bb();\n-\n-#ifndef PRODUCT\n-  if (TraceSuperWord) {\n-    print_bb();\n-    tty->print_cr(\"\\ndata entry nodes: %s\", _data_entry.length() > 0 ? \"\" : \"NONE\");\n-    for (int m = 0; m < _data_entry.length(); m++) {\n-      tty->print(\"%3d \", m);\n-      _data_entry.at(m)->dump();\n-    }\n-    tty->print_cr(\"\\nmemory slices: %s\", _mem_slice_head.length() > 0 ? \"\" : \"NONE\");\n-    for (int m = 0; m < _mem_slice_head.length(); m++) {\n-      tty->print(\"%3d \", m); _mem_slice_head.at(m)->dump();\n-      tty->print(\"    \");    _mem_slice_tail.at(m)->dump();\n-    }\n-  }\n-#endif\n-  assert(rpo_idx == -1 && bb_ct == _block.length(), \"all block members found\");\n-  return (_mem_slice_head.length() > 0) || (reduction_uses > 0) || (_data_entry.length() > 0);\n-}\n-\n-\/\/------------------------------initialize_bb---------------------------\n-\/\/ Initialize per node info\n-void SuperWord::initialize_bb() {\n-  Node* last = _block.at(_block.length() - 1);\n-  grow_node_info(bb_idx(last));\n-}\n-\n-\/\/------------------------------bb_insert_after---------------------------\n-\/\/ Insert n into block after pos\n-void SuperWord::bb_insert_after(Node* n, int pos) {\n-  int n_pos = pos + 1;\n-  \/\/ Make room\n-  for (int i = _block.length() - 1; i >= n_pos; i--) {\n-    _block.at_put_grow(i+1, _block.at(i));\n-  }\n-  for (int j = _node_info.length() - 1; j >= n_pos; j--) {\n-    _node_info.at_put_grow(j+1, _node_info.at(j));\n-  }\n-  \/\/ Set value\n-  _block.at_put_grow(n_pos, n);\n-  _node_info.at_put_grow(n_pos, SWNodeInfo::initial);\n-  \/\/ Adjust map from node->_idx to _block index\n-  for (int i = n_pos; i < _block.length(); i++) {\n-    set_bb_idx(_block.at(i), i);\n-  }\n-}\n-\n-\/\/------------------------------compute_max_depth---------------------------\n-\/\/ Compute max depth for expressions from beginning of block\n-\/\/ Use to prune search paths during test for independence.\n-void SuperWord::compute_max_depth() {\n-  int ct = 0;\n-  bool again;\n-  do {\n-    again = false;\n-    for (int i = 0; i < _block.length(); i++) {\n-      Node* n = _block.at(i);\n-      if (!n->is_Phi()) {\n-        int d_orig = depth(n);\n-        int d_in   = 0;\n-        for (DepPreds preds(n, _dg); !preds.done(); preds.next()) {\n-          Node* pred = preds.current();\n-          if (in_bb(pred)) {\n-            d_in = MAX2(d_in, depth(pred));\n-          }\n-        }\n-        if (d_in + 1 != d_orig) {\n-          set_depth(n, d_in + 1);\n-          again = true;\n-        }\n-      }\n-    }\n-    ct++;\n-  } while (again);\n-\n-  if (TraceSuperWord && Verbose) {\n-    tty->print_cr(\"compute_max_depth iterated: %d times\", ct);\n-  }\n-}\n-\n@@ -3190,1 +2553,1 @@\n-      !in_bb(n->in(1))) {\n+      !in_body(n->in(1))) {\n@@ -3193,1 +2556,1 @@\n-  assert(in_bb(n), \"must be in the bb\");\n+  assert(in_body(n), \"must be in the bb\");\n@@ -3217,1 +2580,1 @@\n-    if (!in_bb(input)) continue;\n+    if (!in_body(input)) continue;\n@@ -3225,1 +2588,1 @@\n-    if (!in_bb(output)) continue;\n+    if (!in_body(output)) continue;\n@@ -3230,1 +2593,1 @@\n-  int max = Matcher::superword_max_vector_size(vt);\n+  int max = Matcher::max_vector_size_autovectorization(vt);\n@@ -3233,98 +2596,1 @@\n-  return max < 2 ? Matcher::superword_max_vector_size(bt) : max;\n-}\n-\n-\/\/-------------------------compute_vector_element_type-----------------------\n-\/\/ Compute necessary vector element type for expressions\n-\/\/ This propagates backwards a narrower integer type when the\n-\/\/ upper bits of the value are not needed.\n-\/\/ Example:  char a,b,c;  a = b + c;\n-\/\/ Normally the type of the add is integer, but for packed character\n-\/\/ operations the type of the add needs to be char.\n-void SuperWord::compute_vector_element_type() {\n-  if (TraceSuperWord && Verbose) {\n-    tty->print_cr(\"\\ncompute_velt_type:\");\n-  }\n-\n-  \/\/ Initial type\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n-    set_velt_type(n, container_type(n));\n-  }\n-\n-  \/\/ Propagate integer narrowed type backwards through operations\n-  \/\/ that don't depend on higher order bits\n-  for (int i = _block.length() - 1; i >= 0; i--) {\n-    Node* n = _block.at(i);\n-    \/\/ Only integer types need be examined\n-    const Type* vtn = velt_type(n);\n-    if (vtn->basic_type() == T_INT) {\n-      uint start, end;\n-      VectorNode::vector_operands(n, &start, &end);\n-\n-      for (uint j = start; j < end; j++) {\n-        Node* in  = n->in(j);\n-        \/\/ Don't propagate through a memory\n-        if (!in->is_Mem() && in_bb(in) && velt_type(in)->basic_type() == T_INT &&\n-            data_size(n) < data_size(in)) {\n-          bool same_type = true;\n-          for (DUIterator_Fast kmax, k = in->fast_outs(kmax); k < kmax; k++) {\n-            Node *use = in->fast_out(k);\n-            if (!in_bb(use) || !same_velt_type(use, n)) {\n-              same_type = false;\n-              break;\n-            }\n-          }\n-          if (same_type) {\n-            \/\/ In any Java arithmetic operation, operands of small integer types\n-            \/\/ (boolean, byte, char & short) should be promoted to int first.\n-            \/\/ During narrowed integer type backward propagation, for some operations\n-            \/\/ like RShiftI, Abs, and ReverseBytesI,\n-            \/\/ the compiler has to know the higher order bits of the 1st operand,\n-            \/\/ which will be lost in the narrowed type. These operations shouldn't\n-            \/\/ be vectorized if the higher order bits info is imprecise.\n-            const Type* vt = vtn;\n-            int op = in->Opcode();\n-            if (VectorNode::is_shift_opcode(op) || op == Op_AbsI || op == Op_ReverseBytesI) {\n-              Node* load = in->in(1);\n-              if (load->is_Load() && in_bb(load) && (velt_type(load)->basic_type() == T_INT)) {\n-                \/\/ Only Load nodes distinguish signed (LoadS\/LoadB) and unsigned\n-                \/\/ (LoadUS\/LoadUB) values. Store nodes only have one version.\n-                vt = velt_type(load);\n-              } else if (op != Op_LShiftI) {\n-                \/\/ Widen type to int to avoid the creation of vector nodes. Note\n-                \/\/ that left shifts work regardless of the signedness.\n-                vt = TypeInt::INT;\n-              }\n-            }\n-            set_velt_type(in, vt);\n-          }\n-        }\n-      }\n-    }\n-  }\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n-    Node* nn = n;\n-    if (nn->is_Bool() && nn->in(0) == nullptr) {\n-      nn = nn->in(1);\n-      assert(nn->is_Cmp(), \"always have Cmp above Bool\");\n-    }\n-    if (nn->is_Cmp() && nn->in(0) == nullptr) {\n-      assert(in_bb(nn->in(1)) || in_bb(nn->in(2)), \"one of the inputs must be in the loop too\");\n-      if (in_bb(nn->in(1))) {\n-        set_velt_type(n, velt_type(nn->in(1)));\n-      } else {\n-        set_velt_type(n, velt_type(nn->in(2)));\n-      }\n-    }\n-  }\n-#ifndef PRODUCT\n-  if (TraceSuperWord && Verbose) {\n-    for (int i = 0; i < _block.length(); i++) {\n-      Node* n = _block.at(i);\n-      velt_type(n)->dump();\n-      tty->print(\"\\t\");\n-      n->dump();\n-    }\n-  }\n-#endif\n+  return max < 2 ? Matcher::max_vector_size_autovectorization(bt) : max;\n@@ -3337,1 +2603,1 @@\n-  if ((TraceSuperWord && Verbose) || is_trace_alignment()) {\n+  if (is_trace_superword_alignment()) {\n@@ -3341,1 +2607,1 @@\n-  VPointer p(s, phase(), lpt(), nullptr, false);\n+  VPointer p(s, vla());\n@@ -3343,1 +2609,1 @@\n-    NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"VPointer::memory_alignment: VPointer p invalid, return bottom_align\");)\n+    NOT_PRODUCT(if(is_trace_superword_alignment()) tty->print_cr(\"SuperWord::memory_alignment: VPointer p invalid, return bottom_align\");)\n@@ -3348,1 +2614,1 @@\n-    NOT_PRODUCT(if(is_trace_alignment()) tty->print_cr(\"VPointer::memory_alignment: vector_width_in_bytes < 2, return bottom_align\");)\n+    NOT_PRODUCT(if(is_trace_superword_alignment()) tty->print_cr(\"SuperWord::memory_alignment: vector_width_in_bytes < 2, return bottom_align\");)\n@@ -3356,2 +2622,2 @@\n-  if ((TraceSuperWord && Verbose) || is_trace_alignment()) {\n-    tty->print_cr(\"VPointer::memory_alignment: off_rem = %d, off_mod = %d (offset = %d)\", off_rem, off_mod, offset);\n+  if (is_trace_superword_alignment()) {\n+    tty->print_cr(\"SuperWord::memory_alignment: off_rem = %d, off_mod = %d (offset = %d)\", off_rem, off_mod, offset);\n@@ -3363,42 +2629,0 @@\n-\/\/---------------------------container_type---------------------------\n-\/\/ Smallest type containing range of values\n-const Type* SuperWord::container_type(Node* n) {\n-  if (n->is_Mem()) {\n-    BasicType bt = n->as_Mem()->memory_type();\n-    if (n->is_Store() && (bt == T_CHAR)) {\n-      \/\/ Use T_SHORT type instead of T_CHAR for stored values because any\n-      \/\/ preceding arithmetic operation extends values to signed Int.\n-      bt = T_SHORT;\n-    }\n-    if (n->Opcode() == Op_LoadUB) {\n-      \/\/ Adjust type for unsigned byte loads, it is important for right shifts.\n-      \/\/ T_BOOLEAN is used because there is no basic type representing type\n-      \/\/ TypeInt::UBYTE. Use of T_BOOLEAN for vectors is fine because only\n-      \/\/ size (one byte) and sign is important.\n-      bt = T_BOOLEAN;\n-    }\n-    return Type::get_const_basic_type(bt);\n-  }\n-  const Type* t = _igvn.type(n);\n-  if (t->basic_type() == T_INT) {\n-    \/\/ A narrow type of arithmetic operations will be determined by\n-    \/\/ propagating the type of memory operations.\n-    return TypeInt::INT;\n-  }\n-  return t;\n-}\n-\n-bool SuperWord::same_velt_type(Node* n1, Node* n2) {\n-  const Type* vt1 = velt_type(n1);\n-  const Type* vt2 = velt_type(n2);\n-  if (vt1->basic_type() == T_INT && vt2->basic_type() == T_INT) {\n-    \/\/ Compare vectors element sizes for integer types.\n-    return data_size(n1) == data_size(n2);\n-  }\n-  return vt1 == vt2;\n-}\n-\n-bool SuperWord::same_memory_slice(MemNode* best_align_to_mem_ref, MemNode* mem_ref) const {\n-  return _phase->C->get_alias_index(mem_ref->adr_type()) == _phase->C->get_alias_index(best_align_to_mem_ref->adr_type());\n-}\n-\n@@ -3470,1 +2694,1 @@\n-  DEBUG_ONLY(                           \\\n+  NOT_PRODUCT(                          \\\n@@ -3484,1 +2708,1 @@\n-  assert(lp()->is_main_loop(), \"can only do alignment for main loop\");\n+  assert(cl()->is_main_loop(), \"can only do alignment for main loop\");\n@@ -3487,1 +2711,1 @@\n-  Opaque1Node* pre_opaq = lp()->pre_loop_end()->limit()->as_Opaque1();\n+  Opaque1Node* pre_opaq = vla().pre_loop_end()->limit()->as_Opaque1();\n@@ -3493,1 +2717,1 @@\n-  Node* pre_ctrl = lp()->pre_loop_head()->in(LoopNode::EntryControl);\n+  Node* pre_ctrl = vla().pre_loop_head()->in(LoopNode::EntryControl);\n@@ -3497,1 +2721,1 @@\n-  assert(orig_limit != nullptr && _igvn.type(orig_limit) != Type::TOP, \"\");\n+  assert(orig_limit != nullptr && igvn().type(orig_limit) != Type::TOP, \"\");\n@@ -3499,1 +2723,1 @@\n-  VPointer align_to_ref_p(align_to_ref, phase(), lpt(), nullptr, false);\n+  VPointer align_to_ref_p(align_to_ref, vla());\n@@ -3638,1 +2862,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -3665,1 +2889,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -3681,1 +2905,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -3693,1 +2917,1 @@\n-  Node* xboi = _igvn.intcon(is_sub ? -offset : offset);\n+  Node* xboi = igvn().intcon(is_sub ? -offset : offset);\n@@ -3698,1 +2922,1 @@\n-    if (_igvn.type(invar)->isa_long()) {\n+    if (igvn().type(invar)->isa_long()) {\n@@ -3703,1 +2927,1 @@\n-      _igvn.register_new_node_with_optimizer(invar);\n+      igvn().register_new_node_with_optimizer(invar);\n@@ -3705,1 +2929,1 @@\n-   }\n+    }\n@@ -3711,2 +2935,2 @@\n-    _igvn.register_new_node_with_optimizer(xboi);\n-    _phase->set_ctrl(xboi, pre_ctrl);\n+    igvn().register_new_node_with_optimizer(xboi);\n+    phase()->set_ctrl(xboi, pre_ctrl);\n@@ -3722,1 +2946,1 @@\n-    _igvn.register_new_node_with_optimizer(xbase);\n+    igvn().register_new_node_with_optimizer(xbase);\n@@ -3726,1 +2950,1 @@\n-    _igvn.register_new_node_with_optimizer(xbase);\n+    igvn().register_new_node_with_optimizer(xbase);\n@@ -3734,2 +2958,2 @@\n-    _igvn.register_new_node_with_optimizer(xboi);\n-    _phase->set_ctrl(xboi, pre_ctrl);\n+    igvn().register_new_node_with_optimizer(xboi);\n+    phase()->set_ctrl(xboi, pre_ctrl);\n@@ -3742,1 +2966,1 @@\n-  Node* log2_abs_scale = _igvn.intcon(exact_log2(abs(scale)));\n+  Node* log2_abs_scale = igvn().intcon(exact_log2(abs(scale)));\n@@ -3744,2 +2968,2 @@\n-  _igvn.register_new_node_with_optimizer(XBOI);\n-  _phase->set_ctrl(XBOI, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(XBOI);\n+  phase()->set_ctrl(XBOI, pre_ctrl);\n@@ -3759,2 +2983,2 @@\n-  _igvn.register_new_node_with_optimizer(XBOI_OP_old_limit);\n-  _phase->set_ctrl(XBOI_OP_old_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(XBOI_OP_old_limit);\n+  phase()->set_ctrl(XBOI_OP_old_limit, pre_ctrl);\n@@ -3769,1 +2993,1 @@\n-  Node* mask_AW = _igvn.intcon(AW-1);\n+  Node* mask_AW = igvn().intcon(AW-1);\n@@ -3771,2 +2995,2 @@\n-  _igvn.register_new_node_with_optimizer(adjust_pre_iter);\n-  _phase->set_ctrl(adjust_pre_iter, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(adjust_pre_iter);\n+  phase()->set_ctrl(adjust_pre_iter, pre_ctrl);\n@@ -3785,2 +3009,2 @@\n-  _igvn.register_new_node_with_optimizer(new_limit);\n-  _phase->set_ctrl(new_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(new_limit);\n+  phase()->set_ctrl(new_limit, pre_ctrl);\n@@ -3794,2 +3018,2 @@\n-  _igvn.register_new_node_with_optimizer(constrained_limit);\n-  _phase->set_ctrl(constrained_limit, pre_ctrl);\n+  igvn().register_new_node_with_optimizer(constrained_limit);\n+  phase()->set_ctrl(constrained_limit, pre_ctrl);\n@@ -3799,1 +3023,1 @@\n-  _igvn.replace_input_of(pre_opaq, 1, constrained_limit);\n+  igvn().replace_input_of(pre_opaq, 1, constrained_limit);\n@@ -3804,1 +3028,0 @@\n-  _dg.init();\n@@ -3806,5 +3029,0 @@\n-  _disjoint_ptrs.clear();\n-  _block.clear();\n-  _data_entry.clear();\n-  _mem_slice_head.clear();\n-  _mem_slice_tail.clear();\n@@ -3814,1 +3032,0 @@\n-  _early_return = false;\n@@ -3817,0 +3034,2 @@\n+  Node* last = body().at(body().length() - 1);\n+  grow_node_info(body_idx(last));\n@@ -3820,1 +3039,1 @@\n-void SuperWord::print_packset() {\n+void SuperWord::print_packset() const {\n@@ -3836,1 +3055,1 @@\n-void SuperWord::print_pack(Node_List* p) {\n+void SuperWord::print_pack(Node_List* p) const {\n@@ -3842,14 +3061,0 @@\n-\/\/------------------------------print_bb---------------------------\n-void SuperWord::print_bb() {\n-#ifndef PRODUCT\n-  tty->print_cr(\"\\nBlock\");\n-  for (int i = 0; i < _block.length(); i++) {\n-    Node* n = _block.at(i);\n-    tty->print(\"%d \", i);\n-    if (n) {\n-      n->dump();\n-    }\n-  }\n-#endif\n-}\n-\n@@ -3857,1 +3062,1 @@\n-void SuperWord::print_stmt(Node* s) {\n+void SuperWord::print_stmt(Node* s) const {\n@@ -3864,4 +3069,0 @@\n-\/\/ ========================= OrderedPair =====================\n-\n-const OrderedPair OrderedPair::initial;\n-\n@@ -3872,136 +3073,0 @@\n-\n-\/\/ ============================ DepGraph ===========================\n-\n-\/\/------------------------------make_node---------------------------\n-\/\/ Make a new dependence graph node for an ideal node.\n-DepMem* DepGraph::make_node(Node* node) {\n-  DepMem* m = new (_arena) DepMem(node);\n-  if (node != nullptr) {\n-    assert(_map.at_grow(node->_idx) == nullptr, \"one init only\");\n-    _map.at_put_grow(node->_idx, m);\n-  }\n-  return m;\n-}\n-\n-\/\/------------------------------make_edge---------------------------\n-\/\/ Make a new dependence graph edge from dpred -> dsucc\n-DepEdge* DepGraph::make_edge(DepMem* dpred, DepMem* dsucc) {\n-  DepEdge* e = new (_arena) DepEdge(dpred, dsucc, dsucc->in_head(), dpred->out_head());\n-  dpred->set_out_head(e);\n-  dsucc->set_in_head(e);\n-  return e;\n-}\n-\n-\/\/ ========================== DepMem ========================\n-\n-\/\/------------------------------in_cnt---------------------------\n-int DepMem::in_cnt() {\n-  int ct = 0;\n-  for (DepEdge* e = _in_head; e != nullptr; e = e->next_in()) ct++;\n-  return ct;\n-}\n-\n-\/\/------------------------------out_cnt---------------------------\n-int DepMem::out_cnt() {\n-  int ct = 0;\n-  for (DepEdge* e = _out_head; e != nullptr; e = e->next_out()) ct++;\n-  return ct;\n-}\n-\n-\/\/------------------------------print-----------------------------\n-void DepMem::print() {\n-#ifndef PRODUCT\n-  tty->print(\"  DepNode %d (\", _node->_idx);\n-  for (DepEdge* p = _in_head; p != nullptr; p = p->next_in()) {\n-    Node* pred = p->pred()->node();\n-    tty->print(\" %d\", pred != nullptr ? pred->_idx : 0);\n-  }\n-  tty->print(\") [\");\n-  for (DepEdge* s = _out_head; s != nullptr; s = s->next_out()) {\n-    Node* succ = s->succ()->node();\n-    tty->print(\" %d\", succ != nullptr ? succ->_idx : 0);\n-  }\n-  tty->print_cr(\" ]\");\n-#endif\n-}\n-\n-\/\/ =========================== DepEdge =========================\n-\n-\/\/------------------------------DepPreds---------------------------\n-void DepEdge::print() {\n-#ifndef PRODUCT\n-  tty->print_cr(\"DepEdge: %d [ %d ]\", _pred->node()->_idx, _succ->node()->_idx);\n-#endif\n-}\n-\n-\/\/ =========================== DepPreds =========================\n-\/\/ Iterator over predecessor edges in the dependence graph.\n-\n-\/\/------------------------------DepPreds---------------------------\n-DepPreds::DepPreds(Node* n, const DepGraph& dg) {\n-  _n = n;\n-  _done = false;\n-  if (_n->is_Store() || _n->is_Load()) {\n-    _next_idx = MemNode::Address;\n-    _end_idx  = n->req();\n-    _dep_next = dg.dep(_n)->in_head();\n-  } else if (_n->is_Mem()) {\n-    _next_idx = 0;\n-    _end_idx  = 0;\n-    _dep_next = dg.dep(_n)->in_head();\n-  } else {\n-    _next_idx = 1;\n-    _end_idx  = _n->req();\n-    _dep_next = nullptr;\n-  }\n-  next();\n-}\n-\n-\/\/------------------------------next---------------------------\n-void DepPreds::next() {\n-  if (_dep_next != nullptr) {\n-    _current  = _dep_next->pred()->node();\n-    _dep_next = _dep_next->next_in();\n-  } else if (_next_idx < _end_idx) {\n-    _current  = _n->in(_next_idx++);\n-  } else {\n-    _done = true;\n-  }\n-}\n-\n-\/\/ =========================== DepSuccs =========================\n-\/\/ Iterator over successor edges in the dependence graph.\n-\n-\/\/------------------------------DepSuccs---------------------------\n-DepSuccs::DepSuccs(Node* n, DepGraph& dg) {\n-  _n = n;\n-  _done = false;\n-  if (_n->is_Load()) {\n-    _next_idx = 0;\n-    _end_idx  = _n->outcnt();\n-    _dep_next = dg.dep(_n)->out_head();\n-  } else if (_n->is_Mem() || _n->is_memory_phi()) {\n-    _next_idx = 0;\n-    _end_idx  = 0;\n-    _dep_next = dg.dep(_n)->out_head();\n-  } else {\n-    _next_idx = 0;\n-    _end_idx  = _n->outcnt();\n-    _dep_next = nullptr;\n-  }\n-  next();\n-}\n-\n-\/\/-------------------------------next---------------------------\n-void DepSuccs::next() {\n-  if (_dep_next != nullptr) {\n-    _current  = _dep_next->succ()->node();\n-    _dep_next = _dep_next->next_out();\n-  } else if (_next_idx < _end_idx) {\n-    _current  = _n->raw_out(_next_idx++);\n-  } else {\n-    _done = true;\n-  }\n-}\n-\n-\/\/\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":365,"deletions":1300,"binary":false,"changes":1665,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+\n+\/\/ ----------------- SuperWord Auto-Vectorizer --------------\n@@ -32,5 +34,1 @@\n-\/\/                  S U P E R W O R D   T R A N S F O R M\n-\/\/\n-\/\/ SuperWords are short, fixed length vectors.\n-\/\/\n-\/\/ Algorithm from:\n+\/\/ Algorithm based on:\n@@ -49,3 +47,1 @@\n-\/\/ Definition 3.1 A Pack is an n-tuple, <s1, ...,sn>, where\n-\/\/ s1,...,sn are independent isomorphic statements in a basic\n-\/\/ block.\n+\/\/ ---------------------- Definitions -----------------------\n@@ -53,1 +49,1 @@\n-\/\/ Definition 3.2 A PackSet is a set of Packs.\n+\/\/ Definitions:\n@@ -55,132 +51,127 @@\n-\/\/ Definition 3.3 A Pair is a Pack of size two, where the\n-\/\/ first statement is considered the left element, and the\n-\/\/ second statement is considered the right element.\n-\n-class VPointer;\n-class OrderedPair;\n-\n-\/\/ ========================= Dependence Graph =====================\n-\n-class DepMem;\n-\n-\/\/------------------------------DepEdge---------------------------\n-\/\/ An edge in the dependence graph.  The edges incident to a dependence\n-\/\/ node are threaded through _next_in for incoming edges and _next_out\n-\/\/ for outgoing edges.\n-class DepEdge : public ArenaObj {\n- protected:\n-  DepMem* _pred;\n-  DepMem* _succ;\n-  DepEdge* _next_in;   \/\/ list of in edges, null terminated\n-  DepEdge* _next_out;  \/\/ list of out edges, null terminated\n-\n- public:\n-  DepEdge(DepMem* pred, DepMem* succ, DepEdge* next_in, DepEdge* next_out) :\n-    _pred(pred), _succ(succ), _next_in(next_in), _next_out(next_out) {}\n-\n-  DepEdge* next_in()  { return _next_in; }\n-  DepEdge* next_out() { return _next_out; }\n-  DepMem*  pred()     { return _pred; }\n-  DepMem*  succ()     { return _succ; }\n-\n-  void print();\n-};\n-\n-\/\/------------------------------DepMem---------------------------\n-\/\/ A node in the dependence graph.  _in_head starts the threaded list of\n-\/\/ incoming edges, and _out_head starts the list of outgoing edges.\n-class DepMem : public ArenaObj {\n- protected:\n-  Node*    _node;     \/\/ Corresponding ideal node\n-  DepEdge* _in_head;  \/\/ Head of list of in edges, null terminated\n-  DepEdge* _out_head; \/\/ Head of list of out edges, null terminated\n-\n- public:\n-  DepMem(Node* node) : _node(node), _in_head(nullptr), _out_head(nullptr) {}\n-\n-  Node*    node()                { return _node;     }\n-  DepEdge* in_head()             { return _in_head;  }\n-  DepEdge* out_head()            { return _out_head; }\n-  void set_in_head(DepEdge* hd)  { _in_head = hd;    }\n-  void set_out_head(DepEdge* hd) { _out_head = hd;   }\n-\n-  int in_cnt();  \/\/ Incoming edge count\n-  int out_cnt(); \/\/ Outgoing edge count\n-\n-  void print();\n-};\n-\n-\/\/------------------------------DepGraph---------------------------\n-class DepGraph {\n- protected:\n-  Arena* _arena;\n-  GrowableArray<DepMem*> _map;\n-  DepMem* _root;\n-  DepMem* _tail;\n-\n- public:\n-  DepGraph(Arena* a) : _arena(a), _map(a, 8,  0, nullptr) {\n-    _root = new (_arena) DepMem(nullptr);\n-    _tail = new (_arena) DepMem(nullptr);\n-  }\n-\n-  DepMem* root() { return _root; }\n-  DepMem* tail() { return _tail; }\n-\n-  \/\/ Return dependence node corresponding to an ideal node\n-  DepMem* dep(Node* node) const { return _map.at(node->_idx); }\n-\n-  \/\/ Make a new dependence graph node for an ideal node.\n-  DepMem* make_node(Node* node);\n-\n-  \/\/ Make a new dependence graph edge dprec->dsucc\n-  DepEdge* make_edge(DepMem* dpred, DepMem* dsucc);\n-\n-  DepEdge* make_edge(Node* pred,   Node* succ)   { return make_edge(dep(pred), dep(succ)); }\n-  DepEdge* make_edge(DepMem* pred, Node* succ)   { return make_edge(pred,      dep(succ)); }\n-  DepEdge* make_edge(Node* pred,   DepMem* succ) { return make_edge(dep(pred), succ);      }\n-\n-  void init() { _map.clear(); } \/\/ initialize\n-\n-  void print(Node* n)   { dep(n)->print(); }\n-  void print(DepMem* d) { d->print(); }\n-};\n-\n-\/\/------------------------------DepPreds---------------------------\n-\/\/ Iterator over predecessors in the dependence graph and\n-\/\/ non-memory-graph inputs of ideal nodes.\n-class DepPreds : public StackObj {\n-private:\n-  Node*    _n;\n-  int      _next_idx, _end_idx;\n-  DepEdge* _dep_next;\n-  Node*    _current;\n-  bool     _done;\n-\n-public:\n-  DepPreds(Node* n, const DepGraph& dg);\n-  Node* current() { return _current; }\n-  bool  done()    { return _done; }\n-  void  next();\n-};\n-\n-\/\/------------------------------DepSuccs---------------------------\n-\/\/ Iterator over successors in the dependence graph and\n-\/\/ non-memory-graph outputs of ideal nodes.\n-class DepSuccs : public StackObj {\n-private:\n-  Node*    _n;\n-  int      _next_idx, _end_idx;\n-  DepEdge* _dep_next;\n-  Node*    _current;\n-  bool     _done;\n-\n-public:\n-  DepSuccs(Node* n, DepGraph& dg);\n-  Node* current() { return _current; }\n-  bool  done()    { return _done; }\n-  void  next();\n-};\n-\n-\n-\/\/ ========================= SuperWord =====================\n+\/\/ ILP (Instruction Level Parallelism):\n+\/\/   Parallel or simultaneous execution of multiple operations.\n+\/\/   The average number of operations run per CPU cycle.\n+\/\/\n+\/\/ SIMD instructions (Single Input Multiple Data instructions):\n+\/\/   Instructions that perform a single operation (e.g. add \/ mul)\n+\/\/   on multiple data inputs (e.g. vector add \/ mul).\n+\/\/   Using SIMD instructions can be a way to increase ILP.\n+\/\/\n+\/\/ SLP (SuperWord Level Parallelism):\n+\/\/   ILP by the use of (short) SIMD instructions, where a piece\n+\/\/   of a program with scalar operations was analyzed for operations\n+\/\/   that can be packed into SIMD instructions, and hence executed\n+\/\/   in parallel.\n+\/\/\n+\/\/ Isomorphic:\n+\/\/   Adjective for operations which are of the same form. They\n+\/\/   perform the same operations on the same structure of inputs.\n+\/\/   SIMD instructions execute the same operations on every\n+\/\/   element, with the inputs all having the same structure.\n+\/\/   Hence, packed operations must be isomorphic.\n+\/\/\n+\/\/ Independent:\n+\/\/   Adjective for operations which can be executed in parallel\n+\/\/   without changing the semantics of the program. SIMD instructions\n+\/\/   execute all their packed operations in parallel. Hence packed\n+\/\/   operations must be independent.\n+\/\/\n+\/\/ Pack (definition 3.1):\n+\/\/   A pack is an n-tuple, <s1, ...,sn>, where, s1,...,sn are\n+\/\/   independent isomorphic operations (in a basic block).\n+\/\/\n+\/\/ Packset (definition 3.2):\n+\/\/   A packset is a set of packs.\n+\/\/\n+\/\/ Pair (definition 3.3):\n+\/\/   A pair is a pack of size two, where the first operation is\n+\/\/   considered the left element, and the second operation is\n+\/\/   considered the right element.\n+\/\/\n+\/\/ -------------------- Algorithm Summary -------------------\n+\/\/\n+\/\/ As designed by the paper cited above, the SuperWord algorithm can\n+\/\/ be applied to any basic block, not just loop nests. However, the\n+\/\/ implementation here is only applied to innermost loops.\n+\/\/\n+\/\/ These are the steps of the SuperWord auto-vectorizer:\n+\/\/\n+\/\/ 1)  PhaseIdealLoop::insert_pre_post_loops\n+\/\/     Split the CountedLoop into pre-main-post loops. The pre-loop\n+\/\/     ensures alignment for the main-loop, the main-loop is strip-\n+\/\/     mined (occasionally safepoints) and is the candidate for\n+\/\/     vectorization. The post-loop executes the remaining iterations.\n+\/\/\n+\/\/ 2)  VLoop::check_preconditions\n+\/\/     For vectorization loops must have a certain form, for example\n+\/\/     no control flow other than the loop exit check.\n+\/\/\n+\/\/ 3)  SuperWord::unrolling_analysis\n+\/\/     We check if there are any forbidden nodes in the loop. If not,\n+\/\/     then we determine the optimal unrolling factor, such that we\n+\/\/     do not unroll unnecessarily, but still can fill the maximal\n+\/\/     vector length. This depends on the types used in the loop.\n+\/\/\n+\/\/ 4)  PhaseIdealLoop::do_unroll\n+\/\/     We unroll until the desired unroll factor is reached. This\n+\/\/     is supposed to increase the parallelism in the loop body,\n+\/\/     as there are now many iterations merged together which can\n+\/\/     hopefully be packed into SIMD vector operations.\n+\/\/\n+\/\/ 5)  VLoopAnalyzer::analyze\n+\/\/     In preparation for auto-vectorization, the loop body is analyzed.\n+\/\/     We find reductions and the memory slices. We determine the type\n+\/\/     of every node, and construct a dependence graph. The resulting\n+\/\/     data structures are then available to the auto-vectorizer.\n+\/\/\n+\/\/ 6)  SuperWord::transform_loop\n+\/\/     We try to (partially) vectorize the loop. We do this as follows:\n+\/\/\n+\/\/     a) find_adjacent_refs:\n+\/\/        We find pairs independent isomorphic adjacent memory operations.\n+\/\/\n+\/\/     b) extend_packlist:\n+\/\/        We iteratively extend these \"seed\" pairs to their inputs and\n+\/\/        outputs (non-memory operations), hopefully extending to all\n+\/\/        operations that can be parallelized.\n+\/\/\n+\/\/     c) combine_packs:\n+\/\/        We combine the pairs into vector sized packs, hopefully filling\n+\/\/        the maximal vector size.\n+\/\/\n+\/\/     d) filter_packs:\n+\/\/        We filter the packs, checking if the operations are implemented\n+\/\/        in the backend, and checking if the inputs and outputs to the\n+\/\/        packs are also vectorizable.\n+\/\/\n+\/\/     e) schedule:\n+\/\/        We construct the PacksetGraph, based on the dependence graph\n+\/\/        and the packset. We schedule it to a linear order. If there\n+\/\/        are cycles in the graph, this is not possible and we bailout.\n+\/\/\n+\/\/        If the schedule succeeds, we know that vectorization will be\n+\/\/        successful. We can now start making changes to the graph.\n+\/\/\n+\/\/     f) schedule_reorder_memops:\n+\/\/        We adjust the memory graph of each memory slice according to\n+\/\/        the linear order of the schedule.\n+\/\/\n+\/\/     g) align_initial_loop_index:\n+\/\/        We adjust the pre-loop limit so that the main-loop is aligned.\n+\/\/\n+\/\/     h) output:\n+\/\/        For each pack, we replace the scalar operations with a vector\n+\/\/        operation.\n+\/\/\n+\/\/ 9)  PhaseIdealLoop::insert_vector_post_loop\n+\/\/     Before the main-loop is super-unrolled,  we first make a clone\n+\/\/     of it and call it the vector-post-loop, or vectorized drain-loop.\n+\/\/     The super-unrolled main-loop might have quite a large stride,\n+\/\/     and after its last iteration, there may still be many iterations\n+\/\/     left. To avoid doing all of them in the post-loop, we execute\n+\/\/     as many as possible with this vectorized drain-loop.\n+\/\/\n+\/\/ 10) PhaseIdealLoop::do_unroll\n+\/\/     We further unroll the vectorized main-loop (i.e. super-unroll).\n+\/\/     The goal is to saturate the CPU pipeline with vector instructions,\n+\/\/     and to reduce the overhead of the loop exit check.\n@@ -188,1 +179,0 @@\n-\/\/ -----------------------------SWNodeInfo---------------------------------\n@@ -193,2 +183,0 @@\n-  int         _depth;     \/\/ Max expression (DAG) depth from block start\n-  const Type* _velt_type; \/\/ vector element type\n@@ -197,1 +185,1 @@\n-  SWNodeInfo() : _alignment(-1), _depth(0), _velt_type(nullptr), _my_pack(nullptr) {}\n+  SWNodeInfo() : _alignment(-1), _my_pack(nullptr) {}\n@@ -201,28 +189,0 @@\n-class SuperWord;\n-\n-\/\/ JVMCI: OrderedPair is moved up to deal with compilation issues on Windows\n-\/\/------------------------------OrderedPair---------------------------\n-\/\/ Ordered pair of Node*.\n-class OrderedPair {\n- protected:\n-  Node* _p1;\n-  Node* _p2;\n- public:\n-  OrderedPair() : _p1(nullptr), _p2(nullptr) {}\n-  OrderedPair(Node* p1, Node* p2) {\n-    if (p1->_idx < p2->_idx) {\n-      _p1 = p1; _p2 = p2;\n-    } else {\n-      _p1 = p2; _p2 = p1;\n-    }\n-  }\n-\n-  bool operator==(const OrderedPair &rhs) {\n-    return _p1 == rhs._p1 && _p2 == rhs._p2;\n-  }\n-  void print() { tty->print(\"  (%d, %d)\", _p1->_idx, _p2->_idx); }\n-\n-  static const OrderedPair initial;\n-};\n-\n-\/\/ -----------------------------SuperWord---------------------------------\n@@ -231,2 +191,0 @@\n- friend class VPointer;\n- friend class CMoveKit;\n@@ -234,3 +192,2 @@\n-  PhaseIdealLoop* _phase;\n-  Arena*          _arena;\n-  PhaseIterGVN   &_igvn;\n+  const VLoopAnalyzer &_vla;\n+  Arena* _arena;\n@@ -242,6 +199,0 @@\n-  GrowableArray<int> _bb_idx;            \/\/ Map from Node _idx to index within block\n-\n-  GrowableArray<Node*> _block;           \/\/ Nodes in current block\n-  GrowableArray<Node*> _data_entry;      \/\/ Nodes with all inputs from outside\n-  GrowableArray<Node*> _mem_slice_head;  \/\/ Memory slice head nodes\n-  GrowableArray<Node*> _mem_slice_tail;  \/\/ Memory slice tail nodes\n@@ -252,4 +203,0 @@\n-  GrowableArray<OrderedPair> _disjoint_ptrs; \/\/ runtime disambiguated pointer pairs\n-\n-  DepGraph _dg; \/\/ Dependence graph\n-\n@@ -257,2 +204,0 @@\n-  VectorSet    _visited;       \/\/ Visited set\n-  VectorSet    _post_visited;  \/\/ Post-visited set\n@@ -260,2 +205,8 @@\n-  GrowableArray<Node*> _nlist; \/\/ List of nodes\n-  GrowableArray<Node*> _stk;   \/\/ Stack of nodes\n+\n+  static constexpr char const* SUCCESS                 = \"success\";\n+  static constexpr char const* FAILURE_NO_ADJACENT_MEM = \"no adjacent loads or stores found\";\n+  static constexpr char const* FAILURE_COMBINE_PACKS   = \"empty packset after combine_packs\";\n+  static constexpr char const* FAILURE_FILTER_PACKS    = \"empty packset after filter_packs\";\n+  static constexpr char const* FAILURE_ALIGN_VECTOR    = \"empty packset after filter_packs_for_alignment\";\n+  static constexpr char const* FAILURE_SCHEDULE_CYCLE  = \"schedule found cycle in packset\";\n+  static constexpr char const* FAILURE_OUTPUT_BAILOUT  = \"unexpected bailout in output\";\n@@ -264,1 +215,25 @@\n-  SuperWord(PhaseIdealLoop* phase);\n+  SuperWord(const VLoopAnalyzer &vla);\n+\n+  \/\/ Decide if loop can eventually be vectorized, and what unrolling factor is required.\n+  static void unrolling_analysis(const VLoop &vloop, int &local_loop_unroll_factor);\n+\n+  \/\/ Attempt to run the SuperWord algorithm on the loop. Return true if we succeed.\n+  bool transform_loop();\n+\n+  \/\/ VLoopAnalyzer\n+  const VLoopAnalyzer& vla()  const { return _vla; }\n+  IdealLoopTree* lpt()        const { return vla().lpt(); }\n+  PhaseIdealLoop* phase()     const { return vla().phase(); }\n+  PhaseIterGVN& igvn()        const { return vla().phase()->igvn(); }\n+  CountedLoopNode* cl()       const { return vla().cl(); }\n+  PhiNode* iv()               const { return vla().iv(); }\n+  int iv_stride()             const { return vla().iv_stride(); }\n+  bool in_body(const Node* n) const { return vla().in_body(n); }\n+\n+  \/\/ VLoopAnalyzer reductions\n+  bool is_marked_reduction(const Node* n) const {\n+    return vla().reductions().is_marked_reduction(n);\n+  }\n+  bool reduction(Node* s1, Node* s2) const {\n+    return vla().reductions().is_marked_reduction_pair(s1, s2);\n+  }\n@@ -266,1 +241,4 @@\n-  bool transform_loop(IdealLoopTree* lpt, bool do_optimization);\n+  \/\/ VLoopAnalyzer memory slices\n+  bool same_memory_slice(MemNode* n1, MemNode* n2) const {\n+    return vla().memory_slices().same_memory_slice(n1, n2);\n+  }\n@@ -268,1 +246,7 @@\n-  void unrolling_analysis(int &local_loop_unroll_factor);\n+  \/\/ VLoopAnalyzer body\n+  const GrowableArray<Node*>& body() const {\n+    return vla().body().body();\n+  }\n+  int body_idx(const Node* n) const     {\n+    return vla().body().body_idx(n);\n+  }\n@@ -270,4 +254,4 @@\n-  \/\/ Accessors for VPointer\n-  PhaseIdealLoop* phase() const    { return _phase; }\n-  IdealLoopTree* lpt() const       { return _lpt; }\n-  PhiNode* iv() const              { return _iv; }\n+  \/\/ VLoopAnalyzer dependence graph\n+  bool independent(Node* s1, Node* s2) const {\n+    return vla().dependence_graph().independent(s1, s2);\n+  }\n@@ -275,1 +259,19 @@\n-  bool early_return() const        { return _early_return; }\n+  \/\/ VLoopAnalyzer vector element type\n+  const Type* velt_type(Node* n) const {\n+    return vla().types().velt_type(n);\n+  }\n+  BasicType velt_basic_type(Node* n) const {\n+    return vla().types().velt_basic_type(n);\n+  }\n+  bool same_velt_type(Node* n1, Node* n2) const {\n+    return vla().types().same_velt_type(n1, n2);\n+  }\n+  int data_size(Node* n) const {\n+    return vla().types().data_size(n);\n+  }\n+  int vector_width(Node* n) const {\n+    return vla().types().vector_width(n);\n+  }\n+  int vector_width_in_bytes(const Node* n) const {\n+    return vla().types().vector_width_in_bytes(n);\n+  }\n@@ -278,7 +280,39 @@\n-  bool     is_debug()              { return _vector_loop_debug > 0; }\n-  bool     is_trace_alignment()    { return (_vector_loop_debug & 2) > 0; }\n-  bool     is_trace_mem_slice()    { return (_vector_loop_debug & 4) > 0; }\n-  bool     is_trace_loop()         { return (_vector_loop_debug & 8) > 0; }\n-  bool     is_trace_adjacent()     { return (_vector_loop_debug & 16) > 0; }\n-  bool     is_trace_cmov()         { return (_vector_loop_debug & 32) > 0; }\n-  bool     is_trace_align_vector() { return (_vector_loop_debug & 128) > 0; }\n+  \/\/ TraceAutoVectorization\n+  bool is_trace_superword_adjacent_memops() const {\n+    return TraceSuperWord ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_ADJACENT_MEMOPS);\n+  }\n+  bool is_trace_superword_alignment() const {\n+    \/\/ Too verbose for TraceSuperWord\n+    return vla().is_trace(TraceAutovectorizationTag::SW_ALIGNMENT);\n+  }\n+  bool is_trace_superword_rejections() const {\n+    return TraceSuperWord ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_REJECTIONS);\n+  }\n+  bool is_trace_superword_packset() const {\n+    return TraceSuperWord ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_PACKSET);\n+  }\n+  bool is_trace_superword_verbose() const {\n+    \/\/ Too verbose for TraceSuperWord\n+    return vla().is_trace(TraceAutovectorizationTag::SW_VERBOSE);\n+  }\n+  bool is_trace_superword_info() const {\n+    return TraceSuperWord ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_INFO);\n+  }\n+  bool is_trace_superword_any() const {\n+    return TraceSuperWord ||\n+           is_trace_align_vector() ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_ADJACENT_MEMOPS) ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_ALIGNMENT) ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_REJECTIONS) ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_PACKSET) ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_INFO) ||\n+           vla().is_trace(TraceAutovectorizationTag::SW_VERBOSE);\n+  }\n+  bool is_trace_align_vector() const {\n+    return vla().is_trace_align_vector() ||\n+           is_trace_superword_verbose();\n+  }\n@@ -286,0 +320,1 @@\n+\n@@ -289,2 +324,0 @@\n-  const GrowableArray<Node*>&      block()   const { return _block; }\n-  const DepGraph&                  dg()      const { return _dg; }\n@@ -292,5 +325,0 @@\n-  IdealLoopTree* _lpt;             \/\/ Current loop tree node\n-  CountedLoopNode* _lp;            \/\/ Current CountedLoopNode\n-  VectorSet      _loop_reductions; \/\/ Reduction nodes in the current loop\n-  Node*          _bb;              \/\/ Current basic block\n-  PhiNode*       _iv;              \/\/ Induction var\n@@ -298,1 +326,0 @@\n-  bool           _early_return;    \/\/ True if we do not initialize\n@@ -302,3 +329,0 @@\n-#ifndef PRODUCT\n-  uintx          _vector_loop_debug; \/\/ provide more printing in debug mode\n-#endif\n@@ -309,18 +333,0 @@\n-  Node* bb()                       { return _bb; }\n-  void set_bb(Node* bb)            { _bb = bb; }\n-  void set_lpt(IdealLoopTree* lpt) { _lpt = lpt; }\n-  CountedLoopNode* lp() const      { return _lp; }\n-  void set_lp(CountedLoopNode* lp) {\n-    _lp = lp;\n-    _iv = lp->as_CountedLoop()->phi()->as_Phi();\n-  }\n-  int iv_stride() const            { return lp()->stride_con(); }\n-\n-  int vector_width(const Node* n) const {\n-    BasicType bt = velt_basic_type(n);\n-    return MIN2(ABS(iv_stride()), Matcher::max_vector_size(bt));\n-  }\n-  int vector_width_in_bytes(const Node* n) const {\n-    BasicType bt = velt_basic_type(n);\n-    return vector_width(n)*type2aelembytes(bt);\n-  }\n@@ -331,18 +337,0 @@\n-  const Node* ctrl(const Node* n) const { return _phase->has_ctrl(n) ? _phase->get_ctrl(n) : n; }\n-\n-  \/\/ block accessors\n- public:\n-  bool in_bb(const Node* n) const  { return n != nullptr && n->outcnt() > 0 && ctrl(n) == _bb; }\n-  int  bb_idx(const Node* n) const { assert(in_bb(n), \"must be\"); return _bb_idx.at(n->_idx); }\n- private:\n-  void set_bb_idx(Node* n, int i)  { _bb_idx.at_put_grow(n->_idx, i); }\n-\n-  \/\/ visited set accessors\n-  void visited_clear()           { _visited.clear(); }\n-  void visited_set(Node* n)      { return _visited.set(bb_idx(n)); }\n-  int visited_test(Node* n)      { return _visited.test(bb_idx(n)); }\n-  int visited_test_set(Node* n)  { return _visited.test_set(bb_idx(n)); }\n-  void post_visited_clear()      { _post_visited.clear(); }\n-  void post_visited_set(Node* n) { return _post_visited.set(bb_idx(n)); }\n-  int post_visited_test(Node* n) { return _post_visited.test(bb_idx(n)); }\n-\n@@ -352,3 +340,0 @@\n-  \/\/ should we align vector memory references on this platform?\n-  bool vectors_should_be_aligned() { return !Matcher::misaligned_vectors_ok() || AlignVector; }\n-\n@@ -356,13 +341,2 @@\n-  int alignment(Node* n)                     { return _node_info.adr_at(bb_idx(n))->_alignment; }\n-  void set_alignment(Node* n, int a)         { int i = bb_idx(n); grow_node_info(i); _node_info.adr_at(i)->_alignment = a; }\n-\n-  \/\/ Max expression (DAG) depth from beginning of the block for each node\n-  int depth(Node* n)                         { return _node_info.adr_at(bb_idx(n))->_depth; }\n-  void set_depth(Node* n, int d)             { int i = bb_idx(n); grow_node_info(i); _node_info.adr_at(i)->_depth = d; }\n-\n-  \/\/ vector element type\n-  const Type* velt_type(const Node* n) const { return _node_info.adr_at(bb_idx(n))->_velt_type; }\n-  BasicType velt_basic_type(const Node* n) const { return velt_type(n)->array_element_basic_type(); }\n-  void set_velt_type(Node* n, const Type* t) { int i = bb_idx(n); grow_node_info(i); _node_info.adr_at(i)->_velt_type = t; }\n-  bool same_velt_type(Node* n1, Node* n2);\n-  bool same_memory_slice(MemNode* best_align_to_mem_ref, MemNode* mem_ref) const;\n+  int alignment(Node* n) const               { return _node_info.adr_at(body_idx(n))->_alignment; }\n+  void set_alignment(Node* n, int a)         { int i = body_idx(n); grow_node_info(i); _node_info.adr_at(i)->_alignment = a; }\n@@ -372,1 +346,3 @@\n-  Node_List* my_pack(Node* n)                 { return !in_bb(n) ? nullptr : _node_info.adr_at(bb_idx(n))->_my_pack; }\n+  Node_List* my_pack(Node* n) const {\n+    return !vla().in_body(n) ? nullptr : _node_info.adr_at(body_idx(n))->_my_pack;\n+  }\n@@ -374,1 +350,1 @@\n-  void set_my_pack(Node* n, Node_List* p)     { int i = bb_idx(n); grow_node_info(i); _node_info.adr_at(i)->_my_pack = p; }\n+  void set_my_pack(Node* n, Node_List* p)     { int i = body_idx(n); grow_node_info(i); _node_info.adr_at(i)->_my_pack = p; }\n@@ -383,60 +359,2 @@\n-  \/\/ methods\n-\n-  typedef const Pair<const Node*, int> PathEnd;\n-\n-  \/\/ Search for a path P = (n_1, n_2, ..., n_k) such that:\n-  \/\/ - original_input(n_i, input) = n_i+1 for all 1 <= i < k,\n-  \/\/ - path(n) for all n in P,\n-  \/\/ - k <= max, and\n-  \/\/ - there exists a node e such that original_input(n_k, input) = e and end(e).\n-  \/\/ Return <e, k>, if P is found, or <nullptr, -1> otherwise.\n-  \/\/ Note that original_input(n, i) has the same behavior as n->in(i) except\n-  \/\/ that it commutes the inputs of binary nodes whose edges have been swapped.\n-  template <typename NodePredicate1, typename NodePredicate2>\n-  static PathEnd find_in_path(const Node *n1, uint input, int max,\n-                              NodePredicate1 path, NodePredicate2 end) {\n-    const PathEnd no_path(nullptr, -1);\n-    const Node* current = n1;\n-    int k = 0;\n-    for (int i = 0; i <= max; i++) {\n-      if (current == nullptr) {\n-        return no_path;\n-      }\n-      if (end(current)) {\n-        return PathEnd(current, k);\n-      }\n-      if (!path(current)) {\n-        return no_path;\n-      }\n-      current = original_input(current, input);\n-      k++;\n-    }\n-    return no_path;\n-  }\n-\n-public:\n-  \/\/ Whether n is a reduction operator and part of a reduction cycle.\n-  \/\/ This function can be used for individual queries outside the SLP analysis,\n-  \/\/ e.g. to inform matching in target-specific code. Otherwise, the\n-  \/\/ almost-equivalent but faster SuperWord::mark_reductions() is preferable.\n-  static bool is_reduction(const Node* n);\n-  \/\/ Whether n is marked as a reduction node.\n-  bool is_marked_reduction(Node* n) { return _loop_reductions.test(n->_idx); }\n-  \/\/ Whether the current loop has any reduction node.\n-  bool is_marked_reduction_loop() { return !_loop_reductions.is_empty(); }\n-private:\n-  \/\/ Whether n is a standard reduction operator.\n-  static bool is_reduction_operator(const Node* n);\n-  \/\/ Whether n is part of a reduction cycle via the 'input' edge index. To bound\n-  \/\/ the search, constrain the size of reduction cycles to LoopMaxUnroll.\n-  static bool in_reduction_cycle(const Node* n, uint input);\n-  \/\/ Reference to the i'th input node of n, commuting the inputs of binary nodes\n-  \/\/ whose edges have been swapped. Assumes n is a commutative operation.\n-  static Node* original_input(const Node* n, uint i);\n-  \/\/ Find and mark reductions in a loop. Running mark_reductions() is similar to\n-  \/\/ querying is_reduction(n) for every n in the SuperWord loop, but stricter in\n-  \/\/ that it assumes counted loops and requires that reduction nodes are not\n-  \/\/ used within the loop except by their reduction cycle predecessors.\n-  void mark_reductions();\n-  \/\/ Extract the superword level parallelism\n-  bool SLP_extract();\n+  \/\/ Attempt to run the SuperWord algorithm on the loop. Return true if we succeed.\n+  const char* transform_loop_helper();\n@@ -444,1 +362,1 @@\n-  void find_adjacent_refs();\n+  const char* find_adjacent_refs();\n@@ -449,4 +367,0 @@\n-  \/\/ Construct dependency graph.\n-  void dependence_graph();\n-  \/\/ Return a memory slice (node list) in predecessor order starting at \"start\"\n-  void mem_slice_preds(Node* start, Node* stop, GrowableArray<Node*> &preds);\n@@ -461,4 +375,0 @@\n-  \/\/ Is there no data path from s1 to s2 or s2 to s1?\n-  bool independent(Node* s1, Node* s2);\n-  \/\/ Is any s1 in p dependent on any s2 in p? Yes: return such a s2. No: return nullptr.\n-  Node* find_dependence(Node_List* p);\n@@ -468,4 +378,0 @@\n-  \/\/ Is there a data path between s1 and s2 and both are reductions?\n-  bool reduction(Node* s1, Node* s2);\n-  \/\/ Helper for independent\n-  bool independent_path(Node* shallow, Node* deep, uint dp=0);\n@@ -473,1 +379,0 @@\n-  int data_size(Node* s);\n@@ -489,1 +394,1 @@\n-  void combine_packs();\n+  const char* combine_packs();\n@@ -491,1 +396,1 @@\n-  void filter_packs_for_alignment();\n+  const char* filter_packs_for_alignment();\n@@ -499,1 +404,1 @@\n-  void filter_packs();\n+  const char* filter_packs();\n@@ -502,1 +407,1 @@\n-  DEBUG_ONLY(void verify_packs();)\n+  DEBUG_ONLY(void verify_packs() const;)\n@@ -504,1 +409,1 @@\n-  void schedule();\n+  const char* schedule();\n@@ -509,1 +414,1 @@\n-  bool output();\n+  const char* output();\n@@ -520,8 +425,0 @@\n-  \/\/ Construct reverse postorder list of block members\n-  bool construct_bb();\n-  \/\/ Initialize per node info\n-  void initialize_bb();\n-  \/\/ Insert n into block after pos\n-  void bb_insert_after(Node* n, int pos);\n-  \/\/ Compute max depth for expressions from beginning of block\n-  void compute_max_depth();\n@@ -532,2 +429,0 @@\n-  \/\/ Compute necessary vector element type for expressions\n-  void compute_vector_element_type();\n@@ -541,2 +436,0 @@\n-  \/\/ Smallest type containing range of values\n-  const Type* container_type(Node* n);\n@@ -550,4 +443,3 @@\n-  void print_packset();\n-  void print_pack(Node_List* p);\n-  void print_bb();\n-  void print_stmt(Node* s);\n+  void print_packset() const;\n+  void print_pack(Node_List* p) const;\n+  void print_stmt(Node* s) const;\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":260,"deletions":368,"binary":false,"changes":628,"status":"modified"},{"patch":"@@ -0,0 +1,200 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_OPTO_TRACEAUTOVECTORIZATIONTAGS_HPP\n+#define SHARE_OPTO_TRACEAUTOVECTORIZATIONTAGS_HPP\n+\n+#include \"utilities\/bitMap.inline.hpp\"\n+\n+#define COMPILER_TRACEAUTOVECTORIZATION_TAGS(flags) \\\n+  flags(PRECONDITION,         \"Trace VLoop::check_preconditions\") \\\n+  flags(LOOP_ANALYZER,        \"Trace VLoopAnalyzer::analyze\") \\\n+  flags(MEMORY_SLICES,        \"Trace VLoopMemorySlices::analyze\") \\\n+  flags(BODY,                 \"Trace VLoopBody::construct\") \\\n+  flags(DEPENDENCE_GRAPH,     \"Trace VLoopDependenceGraph::build\") \\\n+  flags(TYPES,                \"Trace VLoopTypes::compute_vector_element_type\") \\\n+  flags(POINTER_ANALYSIS,     \"Trace VPointer\") \\\n+  flags(SW_ADJACENT_MEMOPS,   \"Trace SuperWord::find_adjacent_refs\") \\\n+  flags(SW_ALIGNMENT,         \"Trace SuperWord alignment analysis\") \\\n+  flags(SW_REJECTIONS,        \"Trace SuperWord rejections (non vectorizations)\") \\\n+  flags(SW_PACKSET,           \"Trace SuperWord packset at different stages\") \\\n+  flags(SW_INFO,              \"Trace SuperWord info\") \\\n+  flags(SW_VERBOSE,           \"Trace SuperWord verbose (all)\") \\\n+  flags(ALIGN_VECTOR,         \"Trace AlignVector\") \\\n+  flags(ALL,                  \"Trace everything (very verbose)\")\n+\n+#define table_entry(name, description) name,\n+enum TraceAutovectorizationTag {\n+  COMPILER_TRACEAUTOVECTORIZATION_TAGS(table_entry)\n+  TRACEAUTOVECTORIZATION_TAGS_NUM,\n+  TRACEAUTOVECTORIZATION_TAGS_NONE\n+};\n+#undef table_entry\n+\n+static const char* tag_descriptions[] = {\n+#define array_of_labels(name, description) description,\n+       COMPILER_TRACEAUTOVECTORIZATION_TAGS(array_of_labels)\n+#undef array_of_labels\n+};\n+\n+static const char* tag_names[] = {\n+#define array_of_labels(name, description) #name,\n+       COMPILER_TRACEAUTOVECTORIZATION_TAGS(array_of_labels)\n+#undef array_of_labels\n+};\n+\n+static TraceAutovectorizationTag find_tag(const char* str) {\n+  for (int i = 0; i < TRACEAUTOVECTORIZATION_TAGS_NUM; i++) {\n+    if (strcmp(tag_names[i], str) == 0) {\n+      return (TraceAutovectorizationTag)i;\n+    }\n+  }\n+  return TRACEAUTOVECTORIZATION_TAGS_NONE;\n+}\n+\n+class TraceAutovectorizationTagNameIter {\n+ private:\n+  char* _token;\n+  char* _saved_ptr;\n+  char* _list;\n+\n+ public:\n+  TraceAutovectorizationTagNameIter(ccstrlist option) {\n+    _list = (char*) canonicalize(option);\n+    _saved_ptr = _list;\n+    _token = strtok_r(_saved_ptr, \",\", &_saved_ptr);\n+  }\n+\n+  ~TraceAutovectorizationTagNameIter() {\n+    FREE_C_HEAP_ARRAY(char, _list);\n+  }\n+\n+  const char* operator*() const { return _token; }\n+\n+  TraceAutovectorizationTagNameIter& operator++() {\n+    _token = strtok_r(nullptr, \",\", &_saved_ptr);\n+    return *this;\n+  }\n+\n+  ccstrlist canonicalize(ccstrlist option_value) {\n+    char* canonicalized_list = NEW_C_HEAP_ARRAY(char, strlen(option_value) + 1, mtCompiler);\n+    int i = 0;\n+    char current;\n+    while ((current = option_value[i]) != '\\0') {\n+      if (current == '\\n' || current == ' ') {\n+        canonicalized_list[i] = ',';\n+      } else {\n+        canonicalized_list[i] = current;\n+      }\n+      i++;\n+    }\n+    canonicalized_list[i] = '\\0';\n+    return canonicalized_list;\n+  }\n+};\n+\n+class TraceAutovectorizationTagValidator {\n+ private:\n+  CHeapBitMap _tags;\n+  bool _valid;\n+  char* _bad;\n+  bool _is_print_usage;\n+\n+ public:\n+  TraceAutovectorizationTagValidator(ccstrlist option, bool is_print_usage) :\n+    _tags(TRACEAUTOVECTORIZATION_TAGS_NUM, mtCompiler),\n+    _valid(true),\n+    _bad(nullptr),\n+    _is_print_usage(is_print_usage)\n+  {\n+    for (TraceAutovectorizationTagNameIter iter(option); *iter != nullptr && _valid; ++iter) {\n+      char const* tag_name = *iter;\n+      if (strcmp(\"help\", tag_name) == 0) {\n+        if (_is_print_usage) {\n+          print_help();\n+        }\n+        continue;\n+      }\n+      bool set_bit = true;\n+      \/\/ Check for \"TAG\" or \"-TAG\"\n+      if (strncmp(\"-\", tag_name, strlen(\"-\")) == 0) {\n+        tag_name++;\n+        set_bit = false;\n+      }\n+      TraceAutovectorizationTag tat = find_tag(tag_name);\n+      if (TRACEAUTOVECTORIZATION_TAGS_NONE == tat) {\n+        \/\/ cap len to a value we know is enough for all tags\n+        const size_t len = MIN2<size_t>(strlen(*iter), 63) + 1;\n+        _bad = NEW_C_HEAP_ARRAY(char, len, mtCompiler);\n+        \/\/ strncpy always writes len characters. If the source string is\n+        \/\/ shorter, the function fills the remaining bytes with nulls.\n+        strncpy(_bad, *iter, len);\n+        _valid = false;\n+      } else if (ALL == tat) {\n+        _tags.set_range(0, TRACEAUTOVECTORIZATION_TAGS_NUM);\n+      } else if (SW_VERBOSE == tat) {\n+        _tags.at_put(SW_ADJACENT_MEMOPS, set_bit);\n+        _tags.at_put(SW_ALIGNMENT, set_bit);\n+        _tags.at_put(SW_REJECTIONS, set_bit);\n+        _tags.at_put(SW_PACKSET, set_bit);\n+        _tags.at_put(SW_INFO, set_bit);\n+        _tags.at_put(SW_VERBOSE, set_bit);\n+      } else if (SW_INFO == tat) {\n+        _tags.at_put(SW_ADJACENT_MEMOPS, set_bit);\n+        _tags.at_put(SW_REJECTIONS, set_bit);\n+        _tags.at_put(SW_PACKSET, set_bit);\n+        _tags.at_put(SW_INFO, set_bit);\n+      } else {\n+        assert(tat < TRACEAUTOVECTORIZATION_TAGS_NUM, \"out of bounds\");\n+        _tags.at_put(tat, set_bit);\n+      }\n+    }\n+  }\n+\n+  ~TraceAutovectorizationTagValidator() {\n+    if (_bad != nullptr) {\n+      FREE_C_HEAP_ARRAY(char, _bad);\n+    }\n+  }\n+\n+  bool is_valid() const { return _valid; }\n+  const char* what() const { return _bad; }\n+  const CHeapBitMap& tags() const {\n+    assert(is_valid(), \"only read tags when valid\");\n+    return _tags;\n+  }\n+\n+  static void print_help() {\n+    tty->cr();\n+    tty->print_cr(\"Usage for CompileCommand TraceAutoVectorization:\");\n+    tty->print_cr(\"  -XX:CompileCommand=TraceAutoVectorization,<package.class::method>,<tags>\");\n+    tty->print_cr(\"  %-22s %s\", \"tags\", \"descriptions\");\n+    for (int i = 0; i < TRACEAUTOVECTORIZATION_TAGS_NUM; i++) {\n+      tty->print_cr(\"  %-22s %s\", tag_names[i], tag_descriptions[i]);\n+    }\n+    tty->cr();\n+  }\n+};\n+\n+#endif \/\/ SHARE_OPTO_TRACEAUTOVECTORIZATIONTAGS_HPP\n","filename":"src\/hotspot\/share\/opto\/traceautovectorizationtags.hpp","additions":200,"deletions":0,"binary":false,"changes":200,"status":"added"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"opto\/vectornode.hpp\"\n@@ -38,2 +39,1 @@\n-VPointer::VPointer(const MemNode* mem,\n-                   PhaseIdealLoop* phase, IdealLoopTree* lpt,\n+VPointer::VPointer(const MemNode* mem, const VLoop& vloop,\n@@ -41,2 +41,1 @@\n-  _mem(mem), _phase(phase), _lpt(lpt),\n-  _iv(lpt->_head->as_CountedLoop()->phi()->as_Phi()),\n+  _mem(mem), _vloop(vloop),\n@@ -49,1 +48,1 @@\n-  , _tracer((phase->C->directive()->VectorizeDebugOption & 2) > 0)\n+  , _tracer(_vloop)\n@@ -72,1 +71,1 @@\n-  NOT_PRODUCT(if(_tracer._is_trace_alignment) _tracer.store_depth();)\n+  NOT_PRODUCT(if(_tracer.is_trace_pointer_analysis()) { _tracer.store_depth(); })\n@@ -101,1 +100,1 @@\n-  NOT_PRODUCT(if(_tracer._is_trace_alignment) _tracer.restore_depth();)\n+  NOT_PRODUCT(if(_tracer.is_trace_pointer_analysis()) { _tracer.restore_depth(); })\n@@ -112,1 +111,1 @@\n-  _mem(p->_mem), _phase(p->_phase), _lpt(p->_lpt), _iv(p->_iv),\n+  _mem(p->_mem), _vloop(p->_vloop),\n@@ -119,1 +118,1 @@\n-  , _tracer(p->_tracer._is_trace_alignment)\n+  , _tracer(_vloop)\n@@ -156,1 +155,1 @@\n-      return phase()->is_dominator(n_c, cl->pre_loop_head());\n+      return phase()->is_dominator(n_c, vloop().pre_loop_head());\n@@ -438,1 +437,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -444,2 +443,1 @@\n-  if (_is_trace_alignment) {\n-    \/\/store_depth();\n+  if (is_trace_pointer_analysis()) {\n@@ -454,1 +452,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -462,1 +460,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -469,1 +467,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -480,2 +478,1 @@\n-  if (_is_trace_alignment) {\n-    \/\/restore_depth();\n+  if (is_trace_pointer_analysis()) {\n@@ -487,1 +484,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -494,1 +491,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -500,1 +497,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -506,1 +503,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -514,1 +511,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -522,1 +519,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -530,1 +527,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -538,1 +535,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -544,1 +541,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -550,1 +547,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -557,1 +554,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -563,1 +560,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -571,1 +568,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -579,1 +576,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -587,1 +584,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -597,1 +594,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -603,1 +600,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -621,1 +618,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -627,1 +624,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -633,1 +630,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -639,1 +636,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -645,1 +642,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -652,1 +649,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -659,1 +656,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -668,1 +665,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -677,1 +674,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -686,1 +683,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -694,1 +691,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -701,1 +698,1 @@\n-  if (_is_trace_alignment) {\n+  if (is_trace_pointer_analysis()) {\n@@ -707,1 +704,0 @@\n-\n@@ -709,1 +705,1 @@\n-  DEBUG_ONLY( trace_start_solve(); )\n+  NOT_PRODUCT( trace_start_solve(); )\n@@ -796,1 +792,1 @@\n-  DEBUG_ONLY( trace_reshaped_form(C_const, C_const_init, C_invar, C_init, C_pre, C_main); )\n+  NOT_PRODUCT( trace_reshaped_form(C_const, C_const_init, C_invar, C_init, C_pre, C_main); )\n@@ -811,1 +807,1 @@\n-  DEBUG_ONLY( trace_main_iteration_alignment(C_const, C_invar, C_init, C_pre, C_main, C_main_mod_aw); )\n+  NOT_PRODUCT( trace_main_iteration_alignment(C_const, C_invar, C_init, C_pre, C_main, C_main_mod_aw); )\n@@ -983,1 +979,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -1136,1 +1132,1 @@\n-  DEBUG_ONLY( trace_constrained_solution(C_const, C_invar, C_init, C_pre, q, r); )\n+  NOT_PRODUCT( trace_constrained_solution(C_const, C_invar, C_init, C_pre, q, r); )\n@@ -1193,1 +1189,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -1357,0 +1353,948 @@\n+\n+bool VLoop::check_preconditions(IdealLoopTree* lpt, bool allow_cfg) {\n+  reset(lpt, allow_cfg);\n+\n+#ifndef PRODUCT\n+  if (is_trace_precondition()) {\n+    tty->print_cr(\"\\nVLoop::check_precondition\");\n+    lpt->dump_head();\n+    lpt->head()->dump();\n+  }\n+#endif\n+\n+  const char* return_state = check_preconditions_helper();\n+  assert(return_state != nullptr, \"must have return state\");\n+  if (return_state == VLoop::SUCCESS) {\n+    return true; \/\/ success\n+  }\n+\n+#ifndef PRODUCT\n+  if (is_trace_precondition()) {\n+    tty->print_cr(\"VLoop::check_precondition: failed: %s\", return_state);\n+  }\n+#endif\n+  return false; \/\/ failure\n+}\n+\n+const char* VLoop::check_preconditions_helper() {\n+  \/\/ Only accept vector width that is power of 2\n+  int vector_width = Matcher::vector_width_in_bytes(T_BYTE);\n+  if (vector_width < 2 || !is_power_of_2(vector_width)) {\n+    return VLoop::FAILURE_VECTOR_WIDTH;\n+  }\n+\n+  \/\/ Only accept valid counted loops (int)\n+  if (!_lpt->_head->as_Loop()->is_valid_counted_loop(T_INT)) {\n+    return VLoop::FAILURE_VALID_COUNTED_LOOP;\n+  }\n+  _cl = _lpt->_head->as_CountedLoop();\n+  _iv = _cl->phi()->as_Phi();\n+\n+  if (_cl->is_vectorized_loop()) {\n+    return VLoop::FAILURE_ALREADY_VECTORIZED;\n+  }\n+\n+  if (_cl->is_unroll_only()) {\n+    return VLoop::FAILURE_UNROLL_ONLY;\n+  }\n+\n+  \/\/ Check for control flow in the body\n+  _cl_exit = _cl->loopexit();\n+  bool has_cfg = _cl_exit->in(0) != _cl;\n+  if (has_cfg && !is_allow_cfg()) {\n+#ifndef PRODUCT\n+    if (is_trace_precondition()) {\n+      tty->print_cr(\"VLoop::check_preconditions: fails because of control flow.\");\n+      tty->print(\"  cl_exit %d\", _cl_exit->_idx); _cl_exit->dump();\n+      tty->print(\"  cl_exit->in(0) %d\", _cl_exit->in(0)->_idx); _cl_exit->in(0)->dump();\n+      tty->print(\"  lpt->_head %d\", _cl->_idx); _cl->dump();\n+      _lpt->dump_head();\n+    }\n+#endif\n+    return VLoop::FAILURE_CONTROL_FLOW;\n+  }\n+\n+  \/\/ Make sure the are no extra control users of the loop backedge\n+  if (_cl->back_control()->outcnt() != 1) {\n+    return VLoop::FAILURE_BACKEDGE;\n+  }\n+\n+  \/\/ To align vector memory accesses in the main-loop, we will have to adjust\n+  \/\/ the pre-loop limit.\n+  if (_cl->is_main_loop()) {\n+    CountedLoopEndNode* pre_end = _cl->find_pre_loop_end();\n+    if (pre_end == nullptr) {\n+      return VLoop::FAILURE_PRE_LOOP_LIMIT;\n+    }\n+    Node* pre_opaq1 = pre_end->limit();\n+    if (pre_opaq1->Opcode() != Op_Opaque1) {\n+      return VLoop::FAILURE_PRE_LOOP_LIMIT;\n+    }\n+    _pre_loop_end = pre_end;\n+  }\n+\n+  return VLoop::SUCCESS;\n+}\n+\n+bool VLoopAnalyzer::analyze(IdealLoopTree* lpt, bool allow_cfg) {\n+  bool success = check_preconditions(lpt, allow_cfg);\n+  if (!success) { return false; }\n+\n+#ifndef PRODUCT\n+  if (is_trace_loop_analyzer()) {\n+    tty->print_cr(\"VLoopAnalyzer::analyze\");\n+    lpt->dump_head();\n+    cl()->dump();\n+  }\n+#endif\n+\n+  const char* return_state = analyze_helper();\n+  assert(return_state != nullptr, \"must have return state\");\n+  if (return_state == VLoopAnalyzer::SUCCESS) {\n+    return true; \/\/ success\n+  }\n+\n+#ifndef PRODUCT\n+  if (is_trace_loop_analyzer()) {\n+    tty->print_cr(\"VLoopAnalyze::analyze: failed: %s\", return_state);\n+  }\n+#endif\n+  return false; \/\/ failure\n+}\n+\n+const char* VLoopAnalyzer::analyze_helper() {\n+  \/\/ skip any loop that has not been assigned max unroll by analysis\n+  if (SuperWordLoopUnrollAnalysis && _cl->slp_max_unroll() == 0) {\n+    return VLoopAnalyzer::FAILURE_NO_MAX_UNROLL;\n+  }\n+\n+  if (SuperWordReductions) {\n+    _reductions.mark_reductions();\n+  }\n+\n+  _memory_slices.analyze();\n+\n+  \/\/ If there is no memory slice detected, that means there is no store.\n+  \/\/ If there is no reduction and no store, then we give up, because\n+  \/\/ vectorization is not possible anyway (given current limitations).\n+  if (!_reductions.is_marked_reduction_loop() &&\n+      _memory_slices.heads().is_empty()) {\n+    return VLoopAnalyzer::FAILURE_NO_REDUCTION_OR_STORE;\n+  }\n+\n+  const char* body_failure = _body.construct();\n+  if (body_failure != nullptr) {\n+    return body_failure;\n+  }\n+\n+  _types.compute_vector_element_type();\n+\n+  _dependence_graph.build();\n+\n+  return VLoopAnalyzer::SUCCESS;\n+}\n+\n+bool VLoopReductions::is_reduction(const Node* n) {\n+  if (!is_reduction_operator(n)) {\n+    return false;\n+  }\n+  \/\/ Test whether there is a reduction cycle via every edge index\n+  \/\/ (typically indices 1 and 2).\n+  for (uint input = 1; input < n->req(); input++) {\n+    if (in_reduction_cycle(n, input)) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+bool VLoopReductions::is_marked_reduction_pair(Node* s1, Node* s2) const {\n+  if (is_marked_reduction(s1) &&\n+      is_marked_reduction(s2)) {\n+    \/\/ This is an ordered set, so s1 should define s2\n+    for (DUIterator_Fast imax, i = s1->fast_outs(imax); i < imax; i++) {\n+      Node* t1 = s1->fast_out(i);\n+      if (t1 == s2) {\n+        \/\/ both nodes are reductions and connected\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n+bool VLoopReductions::is_reduction_operator(const Node* n) {\n+  int opc = n->Opcode();\n+  return (opc != ReductionNode::opcode(opc, n->bottom_type()->basic_type()));\n+}\n+\n+bool VLoopReductions::in_reduction_cycle(const Node* n, uint input) {\n+  \/\/ First find input reduction path to phi node.\n+  auto has_my_opcode = [&](const Node* m){ return m->Opcode() == n->Opcode(); };\n+  PathEnd path_to_phi = find_in_path(n, input, LoopMaxUnroll, has_my_opcode,\n+                                     [&](const Node* m) { return m->is_Phi(); });\n+  const Node* phi = path_to_phi.first;\n+  if (phi == nullptr) {\n+    return false;\n+  }\n+  \/\/ If there is an input reduction path from the phi's loop-back to n, then n\n+  \/\/ is part of a reduction cycle.\n+  const Node* first = phi->in(LoopNode::LoopBackControl);\n+  PathEnd path_from_phi = find_in_path(first, input, LoopMaxUnroll, has_my_opcode,\n+                                       [&](const Node* m) { return m == n; });\n+  return path_from_phi.first != nullptr;\n+}\n+\n+Node* VLoopReductions::original_input(const Node* n, uint i) {\n+  if (n->has_swapped_edges()) {\n+    assert(n->is_Add() || n->is_Mul(), \"n should be commutative\");\n+    if (i == 1) {\n+      return n->in(2);\n+    } else if (i == 2) {\n+      return n->in(1);\n+    }\n+  }\n+  return n->in(i);\n+}\n+\n+void VLoopReductions::mark_reductions() {\n+  assert(_loop_reductions.is_empty(), \"must have been reset\");\n+  IdealLoopTree*  lpt = _vloop.lpt();\n+  CountedLoopNode* cl = _vloop.cl();\n+  PhiNode*         iv = _vloop.iv();\n+\n+  \/\/ Iterate through all phi nodes associated to the loop and search for\n+  \/\/ reduction cycles in the basic block.\n+  for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {\n+    const Node* phi = cl->fast_out(i);\n+    if (!phi->is_Phi()) {\n+      continue;\n+    }\n+    if (phi->outcnt() == 0) {\n+      continue;\n+    }\n+    if (phi == iv) {\n+      continue;\n+    }\n+    \/\/ The phi's loop-back is considered the first node in the reduction cycle.\n+    const Node* first = phi->in(LoopNode::LoopBackControl);\n+    if (first == nullptr) {\n+      continue;\n+    }\n+    \/\/ Test that the node fits the standard pattern for a reduction operator.\n+    if (!is_reduction_operator(first)) {\n+      continue;\n+    }\n+    \/\/ Test that 'first' is the beginning of a reduction cycle ending in 'phi'.\n+    \/\/ To contain the number of searched paths, assume that all nodes in a\n+    \/\/ reduction cycle are connected via the same edge index, modulo swapped\n+    \/\/ inputs. This assumption is realistic because reduction cycles usually\n+    \/\/ consist of nodes cloned by loop unrolling.\n+    int reduction_input = -1;\n+    int path_nodes = -1;\n+    for (uint input = 1; input < first->req(); input++) {\n+      \/\/ Test whether there is a reduction path in the basic block from 'first'\n+      \/\/ to the phi node following edge index 'input'.\n+      PathEnd path =\n+        find_in_path(\n+          first, input, lpt->_body.size(),\n+          [&](const Node* n) { return n->Opcode() == first->Opcode() &&\n+                                      _vloop.in_body(n); },\n+          [&](const Node* n) { return n == phi; });\n+      if (path.first != nullptr) {\n+        reduction_input = input;\n+        path_nodes = path.second;\n+        break;\n+      }\n+    }\n+    if (reduction_input == -1) {\n+      continue;\n+    }\n+    \/\/ Test that reduction nodes do not have any users in the loop besides their\n+    \/\/ reduction cycle successors.\n+    const Node* current = first;\n+    const Node* succ = phi; \/\/ current's successor in the reduction cycle.\n+    bool used_in_loop = false;\n+    for (int i = 0; i < path_nodes; i++) {\n+      for (DUIterator_Fast jmax, j = current->fast_outs(jmax); j < jmax; j++) {\n+        Node* u = current->fast_out(j);\n+        if (!_vloop.in_body(u)) {\n+          continue;\n+        }\n+        if (u == succ) {\n+          continue;\n+        }\n+        used_in_loop = true;\n+        break;\n+      }\n+      if (used_in_loop) {\n+        break;\n+      }\n+      succ = current;\n+      current = original_input(current, reduction_input);\n+    }\n+    if (used_in_loop) {\n+      continue;\n+    }\n+    \/\/ Reduction cycle found. Mark all nodes in the found path as reductions.\n+    current = first;\n+    for (int i = 0; i < path_nodes; i++) {\n+      _loop_reductions.set(current->_idx);\n+      current = original_input(current, reduction_input);\n+    }\n+  }\n+}\n+\n+void VLoopMemorySlices::analyze() {\n+  assert(_heads.is_empty(), \"must have been reset\");\n+  assert(_tails.is_empty(), \"must have been reset\");\n+\n+  CountedLoopNode* cl = _vloop.cl();\n+\n+  for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {\n+    PhiNode* phi = cl->fast_out(i)->isa_Phi();\n+    if (phi != nullptr &&\n+        _vloop.in_body(phi) &&\n+        phi->is_memory_phi()) {\n+      Node* phi_tail  = phi->in(LoopNode::LoopBackControl);\n+      if (phi_tail != phi->in(LoopNode::EntryControl)) {\n+        _heads.push(phi);\n+        _tails.push(phi_tail->as_Mem());\n+      }\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_memory_slices()) {\n+    print();\n+  }\n+#endif\n+}\n+\n+void VLoopMemorySlices::get_slice(Node* head,\n+                                  Node* tail,\n+                                  GrowableArray<Node*> &slice) const {\n+  slice.clear();\n+  \/\/ Start at tail, and go up through Store nodes.\n+  \/\/ For each Store node, find all Loads below that Store.\n+  \/\/ Terminate once we reach the head.\n+  Node* n = tail;\n+  Node* prev = nullptr;\n+  while (true) {\n+    assert(_vloop.in_body(n), \"must be in block\");\n+    for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+      Node* out = n->fast_out(i);\n+      if (out->is_Load()) {\n+        if (_vloop.in_body(out)) {\n+          slice.push(out);\n+        }\n+      } else {\n+        \/\/ Expect other outputs to be the prev (with some exceptions)\n+        if (out->is_MergeMem() && !_vloop.in_body(out)) {\n+          \/\/ Either unrolling is causing a memory edge not to disappear,\n+          \/\/ or need to run igvn.optimize() again before vectorization\n+        } else if (out->is_memory_phi() && !_vloop.in_body(out)) {\n+          \/\/ Ditto.  Not sure what else to check further.\n+        } else if (out->Opcode() == Op_StoreCM && out->in(MemNode::OopStore) == n) {\n+          \/\/ StoreCM has an input edge used as a precedence edge.\n+          \/\/ Maybe an issue when oop stores are vectorized.\n+        } else {\n+          assert(out == prev || prev == nullptr, \"no branches off of store slice\");\n+        }\n+      }\n+    }\n+    if (n == head) { break; };\n+    slice.push(n);\n+    prev = n;\n+    assert(n->is_Mem(), \"unexpected node %s\", n->Name());\n+    n = n->in(MemNode::Memory);\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_memory_slices()) {\n+    tty->print_cr(\"\\nVLoopMemorySlices::get_slice:\");\n+    head->dump();\n+    for (int j = slice.length() - 1; j >= 0 ; j--) {\n+      slice.at(j)->dump();\n+    }\n+  }\n+#endif\n+}\n+\n+bool VLoopMemorySlices::same_memory_slice(MemNode* n1, MemNode* n2) const {\n+  return _vloop.phase()->C->get_alias_index(n1->adr_type()) ==\n+         _vloop.phase()->C->get_alias_index(n2->adr_type());\n+}\n+\n+#ifndef PRODUCT\n+void VLoopMemorySlices::print() const {\n+  tty->print_cr(\"\\nVLoopMemorySlices::print: %s\",\n+                _heads.length() > 0 ? \"\" : \"NONE\");\n+  for (int m = 0; m < _heads.length(); m++) {\n+    tty->print(\"%6d \", m);  _heads.at(m)->dump();\n+    tty->print(\"       \");  _tails.at(m)->dump();\n+  }\n+}\n+#endif\n+\n+const char* VLoopBody::construct() {\n+  assert(_body.is_empty(),     \"must have been reset\");\n+  assert(_body_idx.is_empty(), \"must have been reset\");\n+\n+  IdealLoopTree*  lpt = _vloop.lpt();\n+  CountedLoopNode* cl = _vloop.cl();\n+\n+  \/\/ First pass over loop body:\n+  \/\/  (1) Check that there are no unwanted nodes (LoadStore, MergeMem, data Proj).\n+  \/\/  (2) Count number of nodes, and create a temporary map (_idx -> body_idx).\n+  \/\/  (3) Verify that all non-ctrl nodes have an input inside the loop.\n+  int body_count = 0;\n+  for (uint i = 0; i < lpt->_body.size(); i++) {\n+    Node* n = lpt->_body.at(i);\n+    if (!_vloop.in_body(n)) { continue; }\n+\n+    \/\/ Create a temporary map\n+    set_body_idx(n, i);\n+    body_count++;\n+\n+    if (n->is_LoadStore() ||\n+        n->is_MergeMem() ||\n+        (n->is_Proj() && !n->as_Proj()->is_CFG())) {\n+      \/\/ Bailout if the loop has LoadStore, MergeMem or data Proj\n+      \/\/ nodes. Superword optimization does not work with them.\n+#ifndef PRODUCT\n+      if (_vloop.is_trace_body()) {\n+        tty->print_cr(\"VLoopBody::construct: fails because of unhandled node:\");\n+        n->dump();\n+      }\n+#endif\n+      return VLoopBody::FAILURE_NODE_NOT_ALLOWED;\n+    }\n+#ifndef PRODUCT\n+    if (!n->is_CFG()) {\n+      bool found = false;\n+      for (uint j = 0; j < n->req(); j++) {\n+        Node* def = n->in(j);\n+        if (def != nullptr && _vloop.in_body(def)) {\n+          found = true;\n+          break;\n+        }\n+      }\n+      assert(found, \"every non-cfg node must have an input that is also inside the loop\");\n+    }\n+#endif\n+  }\n+\n+  \/\/ Create reverse-post-order list of nodes in body\n+  ResourceMark rm;\n+  GrowableArray<Node*> stack;\n+  VectorSet visited;\n+  VectorSet post_visited;\n+\n+  visited.set(body_idx(cl));\n+  stack.push(cl);\n+\n+  \/\/ Do a depth first walk over out edges\n+  int rpo_idx = body_count - 1;\n+  while (!stack.is_empty()) {\n+    Node* n = stack.top(); \/\/ Leave node on stack\n+    if (!visited.test_set(body_idx(n))) {\n+      \/\/ forward arc in graph\n+    } else if (!post_visited.test(body_idx(n))) {\n+      \/\/ cross or back arc\n+      int old_size = stack.length();\n+      for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+        Node* use = n->fast_out(i);\n+        if (_vloop.in_body(use) &&\n+            !visited.test(body_idx(use)) &&\n+            \/\/ Don't go around backedge\n+            (!use->is_Phi() || n == cl)) {\n+          stack.push(use);\n+        }\n+      }\n+      if (stack.length() == old_size) {\n+        \/\/ There were no additional uses, post visit node now\n+        stack.pop(); \/\/ Remove node from stack\n+        assert(rpo_idx >= 0, \"must still have idx to pass out\");\n+        _body.at_put_grow(rpo_idx, n);\n+        rpo_idx--;\n+        post_visited.set(body_idx(n));\n+        assert(rpo_idx >= 0 || stack.is_empty(), \"still have idx left or are finished\");\n+      }\n+    } else {\n+      stack.pop(); \/\/ Remove post-visited node from stack\n+    }\n+  }\n+\n+  \/\/ Create real map of block indices for nodes\n+  for (int j = 0; j < _body.length(); j++) {\n+    Node* n = _body.at(j);\n+    set_body_idx(n, j);\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_body()) {\n+    print();\n+  }\n+#endif\n+\n+  assert(rpo_idx == -1 && body_count == _body.length(), \"all block members found\");\n+  return nullptr; \/\/ success\n+}\n+\n+#ifndef PRODUCT\n+void VLoopBody::print() const {\n+  tty->print_cr(\"\\nVLoopBody::print:\");\n+  for (int i = 0; i < _body.length(); i++) {\n+    Node* n = _body.at(i);\n+    if (n != nullptr) {\n+      n->dump();\n+    }\n+  }\n+}\n+#endif\n+\n+void VLoopDependenceGraph::build() {\n+  assert(_map.length() == 0, \"must be freshly reset\");\n+  CountedLoopNode *cl = _vloop.cl();\n+\n+  \/\/ First, assign a dependence node to each memory node\n+  for (int i = 0; i < _body.body().length(); i++ ) {\n+    Node* n = _body.body().at(i);\n+    if (n->is_Mem() || n->is_memory_phi()) {\n+      make_node(n);\n+    }\n+  }\n+\n+  const GrowableArray<PhiNode*> &mem_slice_head = _memory_slices.heads();\n+  const GrowableArray<MemNode*> &mem_slice_tail = _memory_slices.tails();\n+\n+  ResourceMark rm;\n+  GrowableArray<Node*> slice_nodes;\n+\n+  \/\/ For each memory slice, create the dependences\n+  for (int i = 0; i < mem_slice_head.length(); i++) {\n+    Node* head = mem_slice_head.at(i);\n+    Node* tail = mem_slice_tail.at(i);\n+\n+    \/\/ Get slice in predecessor order (last is first)\n+    _memory_slices.get_slice(head, tail, slice_nodes);\n+\n+    \/\/ Make the slice dependent on the root\n+    DependenceNode* slice_head = get_node(head);\n+    make_edge(root(), slice_head);\n+\n+    \/\/ Create a sink for the slice\n+    DependenceNode* slice_sink = make_node(nullptr);\n+    make_edge(slice_sink, sink());\n+\n+    \/\/ Now visit each pair of memory ops, creating the edges\n+    for (int j = slice_nodes.length() - 1; j >= 0 ; j--) {\n+      Node* s1 = slice_nodes.at(j);\n+\n+      \/\/ If no dependency yet, use slice_head\n+      if (get_node(s1)->in_cnt() == 0) {\n+        make_edge(slice_head, get_node(s1));\n+      }\n+      VPointer p1(s1->as_Mem(), _vloop);\n+      bool sink_dependent = true;\n+      for (int k = j - 1; k >= 0; k--) {\n+        Node* s2 = slice_nodes.at(k);\n+        if (s1->is_Load() && s2->is_Load()) {\n+          continue;\n+        }\n+        VPointer p2(s2->as_Mem(), _vloop);\n+\n+        int cmp = p1.cmp(p2);\n+        if (!VPointer::not_equal(cmp)) {\n+          \/\/ Possibly same address\n+          make_edge(get_node(s1), get_node(s2));\n+          sink_dependent = false;\n+        }\n+      }\n+      if (sink_dependent) {\n+        make_edge(get_node(s1), slice_sink);\n+      }\n+    }\n+  }\n+\n+  compute_max_depth();\n+\n+#ifndef PRODUCT\n+  if(_vloop.is_trace_dependence_graph()) {\n+    print();\n+  }\n+#endif\n+}\n+\n+void VLoopDependenceGraph::compute_max_depth() {\n+  assert(_depth.length() == 0, \"must be freshly reset\");\n+  \/\/ set all depths to zero\n+  _depth.at_put_grow(_body.body().length()-1, 0);\n+\n+  int ct = 0;\n+  bool again;\n+  do {\n+    again = false;\n+    for (int i = 0; i < _body.body().length(); i++) {\n+      Node* n = _body.body().at(i);\n+      if (!n->is_Phi()) {\n+        int d_orig = depth(n);\n+        int d_in   = 0;\n+        for (PredsIterator preds(n, *this); !preds.done(); preds.next()) {\n+          Node* pred = preds.current();\n+          if (_vloop.in_body(pred)) {\n+            d_in = MAX2(d_in, depth(pred));\n+          }\n+        }\n+        if (d_in + 1 != d_orig) {\n+          set_depth(n, d_in + 1);\n+          again = true;\n+        }\n+      }\n+    }\n+    ct++;\n+  } while (again);\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_dependence_graph()) {\n+    tty->print_cr(\"\\nVLoopDependenceGraph::compute_max_depth iterated: %d times\", ct);\n+  }\n+#endif\n+}\n+\n+bool VLoopDependenceGraph::independent(Node* s1, Node* s2) const {\n+  int d1 = depth(s1);\n+  int d2 = depth(s2);\n+\n+  if (d1 == d2) {\n+    \/\/ Same depth:\n+    \/\/  1) same node       -> dependent\n+    \/\/  2) different nodes -> same level implies there is no path\n+    return s1 != s2;\n+  }\n+\n+  \/\/ Traversal starting at the deeper node to find the shallower one.\n+  Node* deep    = d1 > d2 ? s1 : s2;\n+  Node* shallow = d1 > d2 ? s2 : s1;\n+  int min_d = MIN2(d1, d2); \/\/ prune traversal at min_d\n+\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  worklist.push(deep);\n+  for (uint i = 0; i < worklist.size(); i++) {\n+    Node* n = worklist.at(i);\n+    for (PredsIterator preds(n, *this); !preds.done(); preds.next()) {\n+      Node* pred = preds.current();\n+      if (_vloop.in_body(pred) && depth(pred) >= min_d) {\n+        if (pred == shallow) {\n+          return false; \/\/ found it -> dependent\n+        }\n+        worklist.push(pred);\n+      }\n+    }\n+  }\n+  return true; \/\/ not found -> independent\n+}\n+\n+\/\/ Are all nodes in nodes mutually independent?\n+\/\/ We could query independent(s1, s2) for all pairs, but that results\n+\/\/ in O(size * size) graph traversals. We can do it all in one BFS!\n+\/\/ Start the BFS traversal at all nodes from the nodes list. Traverse\n+\/\/ Preds recursively, for nodes that have at least depth min_d, which\n+\/\/ is the smallest depth of all nodes from the nodes list. Once we have\n+\/\/ traversed all those nodes, and have not found another node from the\n+\/\/ nodes list, we know that all nodes in the nodes list are independent.\n+bool VLoopDependenceGraph::mutually_independent(Node_List* nodes) const {\n+  ResourceMark rm;\n+  Unique_Node_List worklist;\n+  VectorSet nodes_set;\n+  int min_d = depth(nodes->at(0));\n+  for (uint k = 0; k < nodes->size(); k++) {\n+    Node* n = nodes->at(k);\n+    min_d = MIN2(min_d, depth(n));\n+    worklist.push(n); \/\/ start traversal at all nodes in nodes list\n+    nodes_set.set(_body.body_idx(n));\n+  }\n+  for (uint i = 0; i < worklist.size(); i++) {\n+    Node* n = worklist.at(i);\n+    for (PredsIterator preds(n, *this); !preds.done(); preds.next()) {\n+      Node* pred = preds.current();\n+      if (_vloop.in_body(pred) && depth(pred) >= min_d) {\n+        if (nodes_set.test(_body.body_idx(pred))) { \/\/ in nodes list?\n+          return false;\n+        }\n+        worklist.push(pred);\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+#ifndef PRODUCT\n+void VLoopDependenceGraph::print() const {\n+  tty->print_cr(\"\\nVLoopDependenceGraph::print:\");\n+  \/\/ Memory graph\n+  tty->print_cr(\"memory root:\");\n+  root()->print();\n+  tty->print_cr(\"memory nodes:\");\n+  for (int i = 0; i < _map.length(); i++) {\n+    DependenceNode* d = _map.at(i);\n+    if (d != nullptr) {\n+      d->print();\n+    }\n+  }\n+  tty->print_cr(\"memory sink:\");\n+  sink()->print();\n+  \/\/ Combined graph\n+  tty->print_cr(\"\\nDependencies inside combined graph:\");\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n+    tty->print(\"d:%2d %5d %-10s (\", depth(n), n->_idx, n->Name());\n+    for (PredsIterator preds(n, *this); !preds.done(); preds.next()) {\n+      Node* pred = preds.current();\n+      if (_vloop.in_body(pred)) {\n+        tty->print(\"%d \", pred->_idx);\n+      }\n+    }\n+    tty->print_cr(\")\");\n+  }\n+}\n+#endif\n+\n+VLoopDependenceGraph::DependenceNode*\n+VLoopDependenceGraph::make_node(Node* node) {\n+  DependenceNode* m = new (_vloop.arena()) DependenceNode(node);\n+  if (node != nullptr) {\n+    assert(_map.at_grow(node->_idx) == nullptr, \"one init only\");\n+    _map.at_put_grow(node->_idx, m);\n+  }\n+  return m;\n+}\n+\n+VLoopDependenceGraph::DependenceEdge*\n+VLoopDependenceGraph::make_edge(DependenceNode* dpred, DependenceNode* dsucc) {\n+  DependenceEdge* e = new (_vloop.arena()) DependenceEdge(dpred,\n+                                                           dsucc,\n+                                                           dsucc->in_head(),\n+                                                           dpred->out_head());\n+  dpred->set_out_head(e);\n+  dsucc->set_in_head(e);\n+  return e;\n+}\n+\n+int VLoopDependenceGraph::DependenceNode::in_cnt() {\n+  int ct = 0;\n+  for (DependenceEdge* e = _in_head; e != nullptr; e = e->next_in()) {\n+    ct++;\n+  };\n+  return ct;\n+}\n+\n+int VLoopDependenceGraph::DependenceNode::out_cnt() {\n+  int ct = 0;\n+  for (DependenceEdge* e = _out_head; e != nullptr; e = e->next_out()) {\n+    ct++;\n+  }\n+  return ct;\n+}\n+\n+\n+void VLoopDependenceGraph::DependenceNode::print() const {\n+#ifndef PRODUCT\n+  if (_node != nullptr) {\n+    tty->print(\"  %4d %-6s (\", _node->_idx, _node->Name());\n+  } else {\n+    tty->print(\"  sentinel (\");\n+  }\n+  for (DependenceEdge* p = _in_head; p != nullptr; p = p->next_in()) {\n+    Node* pred = p->pred()->node();\n+    tty->print(\" %d\", pred != nullptr ? pred->_idx : 0);\n+  }\n+  tty->print(\") [\");\n+  for (DependenceEdge* s = _out_head; s != nullptr; s = s->next_out()) {\n+    Node* succ = s->succ()->node();\n+    tty->print(\" %d\", succ != nullptr ? succ->_idx : 0);\n+  }\n+  tty->print_cr(\" ]\");\n+#endif\n+}\n+\n+VLoopDependenceGraph::PredsIterator::PredsIterator(Node* n,\n+                                                   const VLoopDependenceGraph &dg) {\n+  _n = n;\n+  _done = false;\n+  if (_n->is_Store() || _n->is_Load()) {\n+    \/\/ Load: only memory dependencies\n+    \/\/ Store: memory dependence and data input\n+    _next_idx = MemNode::Address;\n+    _end_idx  = n->req();\n+    _dep_next = dg.get_node(_n)->in_head();\n+  } else if (_n->is_Mem()) {\n+    _next_idx = 0;\n+    _end_idx  = 0;\n+    _dep_next = dg.get_node(_n)->in_head();\n+  } else {\n+    \/\/ Data node: only has its own edges\n+    _next_idx = 1;\n+    _end_idx  = _n->req();\n+    _dep_next = nullptr;\n+  }\n+  next();\n+}\n+\n+void VLoopDependenceGraph::PredsIterator::next() {\n+  if (_dep_next != nullptr) {\n+    \/\/ Have memory preds left\n+    _current  = _dep_next->pred()->node();\n+    _dep_next = _dep_next->next_in();\n+  } else if (_next_idx < _end_idx) {\n+    \/\/ Have data preds left\n+    _current  = _n->in(_next_idx++);\n+  } else {\n+    _done = true;\n+  }\n+}\n+\n+void VLoopTypes::compute_vector_element_type() {\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_vector_element_type()) {\n+    tty->print_cr(\"\\nVLoopTypes::compute_vector_element_type:\");\n+  }\n+#endif\n+\n+  assert(_velt_type.length() == 0, \"must be freshly reset\");\n+  \/\/ reserve space\n+  _velt_type.at_put_grow(_body.body().length()-1, nullptr);\n+\n+  \/\/ Initial type\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n+    set_velt_type(n, container_type(n));\n+  }\n+\n+  \/\/ Propagate integer narrowed type backwards through operations\n+  \/\/ that don't depend on higher order bits\n+  for (int i = _body.body().length() - 1; i >= 0; i--) {\n+    Node* n = _body.body().at(i);\n+    \/\/ Only integer types need be examined\n+    const Type* vtn = velt_type(n);\n+    if (vtn->basic_type() == T_INT) {\n+      uint start, end;\n+      VectorNode::vector_operands(n, &start, &end);\n+\n+      for (uint j = start; j < end; j++) {\n+        Node* in  = n->in(j);\n+        \/\/ Don't propagate through a memory\n+        if (!in->is_Mem() &&\n+            _vloop.in_body(in) &&\n+            velt_type(in)->basic_type() == T_INT &&\n+            data_size(n) < data_size(in)) {\n+          bool same_type = true;\n+          for (DUIterator_Fast kmax, k = in->fast_outs(kmax); k < kmax; k++) {\n+            Node* use = in->fast_out(k);\n+            if (!_vloop.in_body(use) || !same_velt_type(use, n)) {\n+              same_type = false;\n+              break;\n+            }\n+          }\n+          if (same_type) {\n+            \/\/ In any Java arithmetic operation, operands of small integer types\n+            \/\/ (boolean, byte, char & short) should be promoted to int first.\n+            \/\/ During narrowed integer type backward propagation, for some operations\n+            \/\/ like RShiftI, Abs, and ReverseBytesI,\n+            \/\/ the compiler has to know the higher order bits of the 1st operand,\n+            \/\/ which will be lost in the narrowed type. These operations shouldn't\n+            \/\/ be vectorized if the higher order bits info is imprecise.\n+            const Type* vt = vtn;\n+            int op = in->Opcode();\n+            if (VectorNode::is_shift_opcode(op) || op == Op_AbsI || op == Op_ReverseBytesI) {\n+              Node* load = in->in(1);\n+              if (load->is_Load() &&\n+                  _vloop.in_body(load) &&\n+                  velt_type(load)->basic_type() == T_INT) {\n+                \/\/ Only Load nodes distinguish signed (LoadS\/LoadB) and unsigned\n+                \/\/ (LoadUS\/LoadUB) values. Store nodes only have one version.\n+                vt = velt_type(load);\n+              } else if (op != Op_LShiftI) {\n+                \/\/ Widen type to int to avoid the creation of vector nodes. Note\n+                \/\/ that left shifts work regardless of the signedness.\n+                vt = TypeInt::INT;\n+              }\n+            }\n+            set_velt_type(in, vt);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  \/\/ Look for pattern: Bool -> Cmp -> x.\n+  \/\/ Propagate type down to Cmp and Bool.\n+  \/\/ If this gets vectorized, the bit-mask\n+  \/\/ has the same size as the compared values.\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n+    Node* nn = n;\n+    if (nn->is_Bool() && nn->in(0) == nullptr) {\n+      nn = nn->in(1);\n+      assert(nn->is_Cmp(), \"always have Cmp above Bool\");\n+    }\n+    if (nn->is_Cmp() && nn->in(0) == nullptr) {\n+      assert(_vloop.in_body(nn->in(1)) ||\n+             _vloop.in_body(nn->in(2)),\n+             \"one of the inputs must be in the loop too\");\n+      if (_vloop.in_body(nn->in(1))) {\n+        set_velt_type(n, velt_type(nn->in(1)));\n+      } else {\n+        set_velt_type(n, velt_type(nn->in(2)));\n+      }\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (_vloop.is_trace_vector_element_type()) {\n+    print();\n+  }\n+#endif\n+}\n+\n+#ifndef PRODUCT\n+void VLoopTypes::print() const {\n+  tty->print_cr(\"\\nVLoopTypes::print:\");\n+  for (int i = 0; i < _body.body().length(); i++) {\n+    Node* n = _body.body().at(i);\n+    tty->print(\"  %5d %-10s \", n->_idx, n->Name());\n+    velt_type(n)->dump();\n+    tty->cr();\n+  }\n+}\n+#endif\n+\n+const Type* VLoopTypes::container_type(Node* n) const {\n+  if (n->is_Mem()) {\n+    BasicType bt = n->as_Mem()->memory_type();\n+    if (n->is_Store() && (bt == T_CHAR)) {\n+      \/\/ Use T_SHORT type instead of T_CHAR for stored values because any\n+      \/\/ preceding arithmetic operation extends values to signed Int.\n+      bt = T_SHORT;\n+    }\n+    if (n->Opcode() == Op_LoadUB) {\n+      \/\/ Adjust type for unsigned byte loads, it is important for right shifts.\n+      \/\/ T_BOOLEAN is used because there is no basic type representing type\n+      \/\/ TypeInt::UBYTE. Use of T_BOOLEAN for vectors is fine because only\n+      \/\/ size (one byte) and sign is important.\n+      bt = T_BOOLEAN;\n+    }\n+    return Type::get_const_basic_type(bt);\n+  }\n+  const Type* t = _vloop.phase()->igvn().type(n);\n+  if (t->basic_type() == T_INT) {\n+    \/\/ A narrow type of arithmetic operations will be determined by\n+    \/\/ propagating the type of memory operations.\n+    return TypeInt::INT;\n+  }\n+  return t;\n+}\n+\n+\n","filename":"src\/hotspot\/share\/opto\/vectorization.cpp","additions":998,"deletions":54,"binary":false,"changes":1052,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"utilities\/pair.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"opto\/traceautovectorizationtags.hpp\"\n@@ -34,0 +36,587 @@\n+\/\/ Base class, used to check basic structure in preparation for auto-vectorization.\n+\/\/ The subclass VLoopAnalyzer is used to analyze the loop and feed that information\n+\/\/ to the auto-vectorization.\n+class VLoop : public StackObj {\n+protected:\n+  PhaseIdealLoop* _phase = nullptr;\n+  Arena* _arena = nullptr;\n+  IdealLoopTree* _lpt = nullptr;\n+  CountedLoopNode* _cl = nullptr;\n+  Node* _cl_exit = nullptr;\n+  PhiNode* _iv = nullptr;\n+  bool _allow_cfg = false;\n+  CountedLoopEndNode* _pre_loop_end; \/\/ only for main loops\n+\n+  const CHeapBitMap &_trace_tags;\n+\n+  static constexpr char const* SUCCESS                    = \"success\";\n+  static constexpr char const* FAILURE_ALREADY_VECTORIZED = \"loop already vectorized\";\n+  static constexpr char const* FAILURE_UNROLL_ONLY        = \"loop only wants to be unrolled\";\n+  static constexpr char const* FAILURE_VECTOR_WIDTH       = \"vector_width must be power of 2\";\n+  static constexpr char const* FAILURE_VALID_COUNTED_LOOP = \"must be valid counted loop (int)\";\n+  static constexpr char const* FAILURE_CONTROL_FLOW       = \"control flow in loop not allowed\";\n+  static constexpr char const* FAILURE_BACKEDGE           = \"nodes on backedge not allowed\";\n+  static constexpr char const* FAILURE_PRE_LOOP_LIMIT     = \"main-loop must be able to adjust pre-loop-limit (not found)\";\n+\n+public:\n+  VLoop(PhaseIdealLoop* phase) :\n+    _phase(phase),\n+    _arena(phase->C->comp_arena()),\n+    _trace_tags(phase->C->directive()->traceautovectorization_tags()) {}\n+  NONCOPYABLE(VLoop);\n+\n+protected:\n+  virtual void reset(IdealLoopTree* lpt, bool allow_cfg) {\n+    assert(_phase == lpt->_phase, \"must be the same phase\");\n+    _lpt       = lpt;\n+    _cl        = nullptr;\n+    _cl_exit   = nullptr;\n+    _iv        = nullptr;\n+    _allow_cfg = allow_cfg;\n+  }\n+\n+public:\n+  Arena* arena()          const { return _arena; }\n+  IdealLoopTree* lpt()    const { assert(_lpt     != nullptr, \"\"); return _lpt; };\n+  PhaseIdealLoop* phase() const { assert(_phase   != nullptr, \"\"); return _phase; }\n+  CountedLoopNode* cl()   const { assert(_cl      != nullptr, \"\"); return _cl; };\n+  Node* cl_exit()         const { assert(_cl_exit != nullptr, \"\"); return _cl_exit; };\n+  PhiNode* iv()           const { assert(_iv      != nullptr, \"\"); return _iv; };\n+  int iv_stride()         const { return cl()->stride_con(); };\n+  bool is_allow_cfg()     const { return _allow_cfg; }\n+  CountedLoopEndNode* pre_loop_end() const {\n+    assert(cl()->is_main_loop(), \"only main loop can reference pre-loop\");\n+    assert(_pre_loop_end != nullptr, \"must have found it\");\n+    return _pre_loop_end;\n+  };\n+  CountedLoopNode* pre_loop_head() const {\n+    CountedLoopNode* head = pre_loop_end()->loopnode();\n+    assert(head != nullptr, \"must find head\");\n+    return head;\n+  };\n+\n+  bool in_body(const Node* n) const {\n+    \/\/ We only accept any nodes which have the loop head as their ctrl.\n+    const Node* ctrl = _phase->has_ctrl(n) ? _phase->get_ctrl(n) : n;\n+    return n != nullptr && n->outcnt() > 0 && ctrl == _cl;\n+  }\n+\n+  \/\/ Do we have to enforce strict alignment criteria on this platform?\n+  static bool vectors_must_be_aligned() {\n+   return !Matcher::misaligned_vectors_ok() || AlignVector;\n+  }\n+\n+#ifndef PRODUCT\n+  bool is_trace(TraceAutovectorizationTag tag) const {\n+    return _trace_tags.at(tag);\n+  }\n+  bool is_trace_precondition() const {\n+    return is_trace(TraceAutovectorizationTag::PRECONDITION);\n+  }\n+  bool is_trace_loop_analyzer() const {\n+    return is_trace(TraceAutovectorizationTag::LOOP_ANALYZER);\n+  }\n+  bool is_trace_memory_slices() const {\n+    return is_trace(TraceAutovectorizationTag::MEMORY_SLICES);\n+  }\n+  bool is_trace_body() const {\n+    return is_trace(TraceAutovectorizationTag::BODY);\n+  }\n+  bool is_trace_dependence_graph() const {\n+    return is_trace(TraceAutovectorizationTag::DEPENDENCE_GRAPH);\n+  }\n+  bool is_trace_vector_element_type() const {\n+    return is_trace(TraceAutovectorizationTag::TYPES);\n+  }\n+  bool is_trace_pointer_analysis() const {\n+    return is_trace(TraceAutovectorizationTag::POINTER_ANALYSIS);\n+  }\n+  bool is_trace_align_vector() const {\n+    return is_trace(TraceAutovectorizationTag::ALIGN_VECTOR);\n+  }\n+#endif\n+\n+  \/\/ Check if the loop passes some basic preconditions for vectorization.\n+  \/\/ Overwrite previous data. Return indicates if analysis succeeded.\n+  bool check_preconditions(IdealLoopTree* lpt, bool allow_cfg);\n+\n+protected:\n+  const char* check_preconditions_helper();\n+};\n+\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ Identify and mark all reductions in the loop.\n+class VLoopReductions : public StackObj {\n+private:\n+  typedef const Pair<const Node*, int> PathEnd;\n+\n+  const VLoop& _vloop;\n+  VectorSet _loop_reductions;\n+\n+public:\n+  VLoopReductions(const VLoop& vloop) :\n+    _vloop(vloop),\n+    _loop_reductions(_vloop.arena()){};\n+  NONCOPYABLE(VLoopReductions);\n+  void reset() {\n+    _loop_reductions.clear();\n+  }\n+\n+private:\n+  \/\/ Search for a path P = (n_1, n_2, ..., n_k) such that:\n+  \/\/ - original_input(n_i, input) = n_i+1 for all 1 <= i < k,\n+  \/\/ - path(n) for all n in P,\n+  \/\/ - k <= max, and\n+  \/\/ - there exists a node e such that original_input(n_k, input) = e and end(e).\n+  \/\/ Return <e, k>, if P is found, or <nullptr, -1> otherwise.\n+  \/\/ Note that original_input(n, i) has the same behavior as n->in(i) except\n+  \/\/ that it commutes the inputs of binary nodes whose edges have been swapped.\n+  template <typename NodePredicate1, typename NodePredicate2>\n+  static PathEnd find_in_path(const Node* n1, uint input, int max,\n+                              NodePredicate1 path, NodePredicate2 end) {\n+    const PathEnd no_path(nullptr, -1);\n+    const Node* current = n1;\n+    int k = 0;\n+    for (int i = 0; i <= max; i++) {\n+      if (current == nullptr) {\n+        return no_path;\n+      }\n+      if (end(current)) {\n+        return PathEnd(current, k);\n+      }\n+      if (!path(current)) {\n+        return no_path;\n+      }\n+      current = original_input(current, input);\n+      k++;\n+    }\n+    return no_path;\n+  }\n+\n+public:\n+  \/\/ Whether n is a reduction operator and part of a reduction cycle.\n+  \/\/ This function can be used for individual queries outside auto-vectorization,\n+  \/\/ e.g. to inform matching in target-specific code. Otherwise, the\n+  \/\/ almost-equivalent but faster mark_reductions() is preferable.\n+  static bool is_reduction(const Node* n);\n+  \/\/ Whether n is marked as a reduction node.\n+  bool is_marked_reduction(const Node* n) const { return _loop_reductions.test(n->_idx); }\n+  bool is_marked_reduction_loop() const { return !_loop_reductions.is_empty(); }\n+  \/\/ Are s1 and s2 reductions with a data path between them?\n+  bool is_marked_reduction_pair(Node* s1, Node* s2) const;\n+private:\n+  \/\/ Whether n is a standard reduction operator.\n+  static bool is_reduction_operator(const Node* n);\n+  \/\/ Whether n is part of a reduction cycle via the 'input' edge index. To bound\n+  \/\/ the search, constrain the size of reduction cycles to LoopMaxUnroll.\n+  static bool in_reduction_cycle(const Node* n, uint input);\n+  \/\/ Reference to the i'th input node of n, commuting the inputs of binary nodes\n+  \/\/ whose edges have been swapped. Assumes n is a commutative operation.\n+  static Node* original_input(const Node* n, uint i);\n+public:\n+  \/\/ Find and mark reductions in a loop. Running mark_reductions() is similar to\n+  \/\/ querying is_reduction(n) for every node in the loop, but stricter in\n+  \/\/ that it assumes counted loops and requires that reduction nodes are not\n+  \/\/ used within the loop except by their reduction cycle predecessors.\n+  void mark_reductions();\n+};\n+\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ Find the memory slices in the loop.\n+class VLoopMemorySlices : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+\n+  GrowableArray<PhiNode*> _heads;\n+  GrowableArray<MemNode*> _tails;\n+\n+public:\n+  VLoopMemorySlices(const VLoop& vloop) :\n+    _vloop(vloop),\n+    _heads(_vloop.arena(), 8,  0, nullptr),\n+    _tails(_vloop.arena(), 8,  0, nullptr) {};\n+\n+  NONCOPYABLE(VLoopMemorySlices);\n+\n+  void reset() {\n+    _heads.clear();\n+    _tails.clear();\n+  }\n+\n+  void analyze();\n+\n+  const GrowableArray<PhiNode*> &heads() const { return _heads; }\n+  const GrowableArray<MemNode*> &tails() const { return _tails; }\n+\n+  \/\/ Get all memory nodes of a slice, in reverse order\n+  void get_slice(Node* head, Node* tail, GrowableArray<Node*> &slice) const;\n+\n+  bool same_memory_slice(MemNode* n1, MemNode* n2) const;\n+\n+#ifndef PRODUCT\n+  void print() const;\n+#endif\n+};\n+\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ Find all nodes in the body, and create a mapping node->_idx to a body_idx.\n+\/\/ This mapping is used so that subsequent datastructures sizes only grow with\n+\/\/ the body size, and not the number of all nodes in the compilation.\n+class VLoopBody : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+\n+  GrowableArray<Node*> _body;\n+  GrowableArray<int> _body_idx;\n+\n+  static constexpr char const* FAILURE_NODE_NOT_ALLOWED  = \"encontered unhandled node\";\n+\n+public:\n+  VLoopBody(const VLoop& vloop) :\n+    _vloop(vloop),\n+    _body(_vloop.arena(), 8, 0, nullptr),\n+    _body_idx(_vloop.arena(), (int)(1.10 * _vloop.phase()->C->unique()), 0, 0) {}\n+\n+  NONCOPYABLE(VLoopBody);\n+\n+  void reset() {\n+    _body.clear();\n+    _body_idx.clear();\n+  }\n+\n+  const char* construct();\n+\n+#ifndef PRODUCT\n+  void print() const;\n+#endif\n+\n+  int body_idx(const Node* n) const {\n+    assert(_vloop.in_body(n), \"must be in loop_body\");\n+    return _body_idx.at(n->_idx);\n+  }\n+\n+  const GrowableArray<Node*>& body() const { return _body; }\n+\n+private:\n+  void set_body_idx(Node* n, int i) {\n+    assert(_vloop.in_body(n), \"must be in loop_body\");\n+    _body_idx.at_put_grow(n->_idx, i);\n+  }\n+};\n+\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ We construct a dependence graph for the loop body, based on:\n+\/\/ 1) data dependencies:\n+\/\/    The edges of the C2 IR nodes that represent data inputs.\n+\/\/ 2) memory dependencies:\n+\/\/    We must respect Store->Store, Store->Load, and Load->Store order.\n+\/\/    We do not have to respect the order if:\n+\/\/    2.1) two memory operations are in different memory slices or\n+\/\/    2.2) we can prove that the memory regions will never overlap.\n+\/\/\n+\/\/ The graph can be queried in the following ways:\n+\/\/ 1) PredsIterator:\n+\/\/    Given some node in the body, iterate over all its predecessors\n+\/\/    in the dependence graph.\n+\/\/ 2) independent(s1, s2):\n+\/\/    Check if there is a path s1->s2 or s2->s1. If not, then s1 and s2\n+\/\/    can be executed in parallel (e.g. in a vector operation).\n+\/\/ 3) mutually_independent:\n+\/\/    Check if all nodes in a list are mutually independent. If so, then\n+\/\/    they can be executed in parallel (e.g. in a vector operation).\n+class VLoopDependenceGraph : public StackObj {\n+private:\n+  class DependenceEdge;\n+  class DependenceNode;\n+\n+  const VLoop& _vloop;\n+  const VLoopMemorySlices& _memory_slices;\n+  const VLoopBody& _body;\n+\n+  \/\/ node->_idx -> DependenceNode* (or nullptr)\n+  GrowableArray<DependenceNode*> _map;\n+  DependenceNode* _root;\n+  DependenceNode* _sink;\n+  GrowableArray<int> _depth; \/\/ body_idx -> depth in graph (DAG)\n+\n+public:\n+  VLoopDependenceGraph(const VLoop& vloop,\n+                       const VLoopMemorySlices& memory_slices,\n+                       const VLoopBody& body) :\n+    _vloop(vloop),\n+    _memory_slices(memory_slices),\n+    _body(body),\n+    _map(vloop.arena(), 8,  0, nullptr),\n+    _root(nullptr),\n+    _sink(nullptr),\n+    _depth(vloop.arena(), 8,  0, 0) {}\n+\n+  NONCOPYABLE(VLoopDependenceGraph);\n+\n+  void reset() {\n+    _map.clear();\n+    _root = new (_vloop.arena()) DependenceNode(nullptr);\n+    _sink = new (_vloop.arena()) DependenceNode(nullptr);\n+    _depth.clear();\n+  }\n+\n+  void build();\n+\n+#ifndef PRODUCT\n+  void print() const;\n+#endif\n+\n+private:\n+  DependenceNode* root() const { return _root; }\n+  DependenceNode* sink() const { return _sink; }\n+\n+  \/\/ Return dependence node corresponding to an ideal node\n+  DependenceNode* get_node(Node* node) const {\n+    assert(node != nullptr, \"must not be nullptr\");\n+    DependenceNode* d = _map.at(node->_idx);\n+    assert(d != nullptr, \"must find dependence node\");\n+    return d;\n+  }\n+\n+  \/\/ Make a new dependence graph node for an ideal node.\n+  DependenceNode* make_node(Node* node);\n+\n+  \/\/ Make a new dependence graph edge dprec->dsucc\n+  DependenceEdge* make_edge(DependenceNode* dpred, DependenceNode* dsucc);\n+\n+  \/\/ An edge in the dependence graph.  The edges incident to a dependence\n+  \/\/ node are threaded through _next_in for incoming edges and _next_out\n+  \/\/ for outgoing edges.\n+  class DependenceEdge : public ArenaObj {\n+  protected:\n+    DependenceNode* _pred;\n+    DependenceNode* _succ;\n+    DependenceEdge* _next_in;  \/\/ list of in edges, null terminated\n+    DependenceEdge* _next_out; \/\/ list of out edges, null terminated\n+\n+  public:\n+    DependenceEdge(DependenceNode* pred,\n+                   DependenceNode* succ,\n+                   DependenceEdge* next_in,\n+                   DependenceEdge* next_out) :\n+      _pred(pred), _succ(succ), _next_in(next_in), _next_out(next_out) {}\n+\n+    DependenceEdge* next_in()  { return _next_in; }\n+    DependenceEdge* next_out() { return _next_out; }\n+    DependenceNode* pred()     { return _pred; }\n+    DependenceNode* succ()     { return _succ; }\n+  };\n+\n+  \/\/ A node in the dependence graph.  _in_head starts the threaded list of\n+  \/\/ incoming edges, and _out_head starts the list of outgoing edges.\n+  class DependenceNode : public ArenaObj {\n+  protected:\n+    Node*           _node;     \/\/ Corresponding ideal node\n+    DependenceEdge* _in_head;  \/\/ Head of list of in edges, null terminated\n+    DependenceEdge* _out_head; \/\/ Head of list of out edges, null terminated\n+\n+  public:\n+    DependenceNode(Node* node) :\n+      _node(node),\n+      _in_head(nullptr),\n+      _out_head(nullptr)\n+    {\n+      assert(node == nullptr ||\n+             node->is_Mem() ||\n+             node->is_memory_phi(),\n+             \"only memory graph nodes expected\");\n+    }\n+\n+    Node*           node()                { return _node;     }\n+    DependenceEdge* in_head()             { return _in_head;  }\n+    DependenceEdge* out_head()            { return _out_head; }\n+    void set_in_head(DependenceEdge* hd)  { _in_head = hd;    }\n+    void set_out_head(DependenceEdge* hd) { _out_head = hd;   }\n+\n+    int in_cnt();  \/\/ Incoming edge count\n+    int out_cnt(); \/\/ Outgoing edge count\n+\n+    void print() const;\n+  };\n+\n+public:\n+  \/\/ Given some node in the body, iterate over all its predecessors\n+  \/\/ in the dependence graph.\n+  class PredsIterator {\n+  private:\n+    Node*           _n;\n+    int             _next_idx;\n+    int             _end_idx;\n+    DependenceEdge* _dep_next;\n+    Node*           _current;\n+    bool            _done;\n+\n+  public:\n+    PredsIterator(Node* n, const VLoopDependenceGraph &dg);\n+    NONCOPYABLE(PredsIterator);\n+\n+    Node* current() { return _current; }\n+    bool  done()    { return _done; }\n+    void  next();\n+  };\n+\n+  \/\/ Are s1 and s2 independent? i.e. no path from s1 to s2 \/ s2 to s1?\n+  bool independent(Node* s1, Node* s2) const;\n+  \/\/ Are all nodes in nodes mutually independent?\n+  bool mutually_independent(Node_List* nodes) const;\n+\n+private:\n+  \/\/ Depth in graph (DAG). Used to prune search paths.\n+  int depth(Node* n) const {\n+    assert(_vloop.in_body(n), \"only call on nodes in loop\");\n+    return _depth.at(_body.body_idx(n));\n+  }\n+\n+  void set_depth(Node* n, int d) {\n+    assert(_vloop.in_body(n), \"only call on nodes in loop\");\n+    _depth.at_put(_body.body_idx(n), d);\n+  }\n+\n+  void compute_max_depth();\n+};\n+\n+\/\/ Submodule of VLoopAnalyzer.\n+\/\/ Compute the vector element type for every node in the loop body.\n+\/\/ We need to do this to be able to vectorize the narrower integer\n+\/\/ types (byte, char, short). In the C2 IR, their operations are\n+\/\/ done with full int type with 4 byte precision (e.g. AddI, MulI).\n+\/\/ Example:  char a,b,c;  a = (char)(b + c);\n+\/\/ However, if we can prove the the upper bits are only truncated,\n+\/\/ and the lower bits for the narrower type computed correctly, we\n+\/\/ can compute the operations in the narrower type directly (e.g we\n+\/\/ perform the AddI or MulI with 1 or 2 bytes). This allows us to\n+\/\/ fit more operations in a vector, and can remove the otherwise\n+\/\/ required conversion (int <-> narrower type).\n+\/\/ We compute the types backwards (use-to-def): If all use nodes\n+\/\/ only require the lower bits, then the def node can do the operation\n+\/\/ only with the lower bits, and we propagate the narrower type to it.\n+class VLoopTypes : public StackObj {\n+private:\n+  const VLoop& _vloop;\n+  const VLoopBody& _body;\n+\n+  \/\/ body_idx -> vector element type\n+  GrowableArray<const Type*> _velt_type;\n+\n+public:\n+  VLoopTypes(const VLoop& vloop,\n+             const VLoopBody& body) :\n+    _vloop(vloop),\n+    _body(body),\n+    _velt_type(vloop.arena(), 8,  0, nullptr) {}\n+\n+  NONCOPYABLE(VLoopTypes);\n+\n+  void reset() {\n+    _velt_type.clear();\n+  }\n+\n+  void compute_vector_element_type();\n+\n+#ifndef PRODUCT\n+  void print() const;\n+#endif\n+\n+  const Type* velt_type(const Node* n) const {\n+    assert(_vloop.in_body(n), \"only call on nodes in loop\");\n+    const Type* t = _velt_type.at(_body.body_idx(n));\n+    assert(t != nullptr, \"must have type\");\n+    return t;\n+  }\n+\n+  BasicType velt_basic_type(const Node* n) const {\n+    return velt_type(n)->array_element_basic_type();\n+  }\n+\n+  int data_size(Node* s) const {\n+    int bsize = type2aelembytes(velt_basic_type(s));\n+    assert(bsize != 0, \"valid size\");\n+    return bsize;\n+  }\n+\n+  bool same_velt_type(Node* n1, Node* n2) const {\n+    const Type* vt1 = velt_type(n1);\n+    const Type* vt2 = velt_type(n2);\n+    if (vt1->basic_type() == T_INT && vt2->basic_type() == T_INT) {\n+      \/\/ Compare vectors element sizes for integer types.\n+      return data_size(n1) == data_size(n2);\n+    }\n+    return vt1 == vt2;\n+  }\n+\n+  int vector_width(const Node* n) const {\n+    BasicType bt = velt_basic_type(n);\n+    return MIN2(ABS(_vloop.iv_stride()), Matcher::max_vector_size(bt));\n+  }\n+\n+  int vector_width_in_bytes(const Node* n) const {\n+    BasicType bt = velt_basic_type(n);\n+    return vector_width(n) * type2aelembytes(bt);\n+  }\n+\n+private:\n+  void set_velt_type(Node* n, const Type* t) {\n+    assert(t != nullptr, \"cannot set nullptr\");\n+    assert(_vloop.in_body(n), \"only call on nodes in loop\");\n+    _velt_type.at_put(_body.body_idx(n), t);\n+  }\n+\n+  const Type* container_type(Node* n) const;\n+};\n+\n+\/\/ Analyze the loop in preparation for auto-vectorization. This class is\n+\/\/ deliberately structured into many submodules, which are as independent\n+\/\/ as possible, though some submodules do require other submodules.\n+class VLoopAnalyzer : public VLoop {\n+protected:\n+  static constexpr char const* FAILURE_NO_MAX_UNROLL = \"slp max unroll analysis required\";\n+  static constexpr char const* FAILURE_NO_REDUCTION_OR_STORE = \"no reduction and no store in loop\";\n+\n+  \/\/ Submodules that analyze different aspects of the loop\n+  VLoopReductions      _reductions;\n+  VLoopMemorySlices    _memory_slices;\n+  VLoopBody            _body;\n+  VLoopTypes           _types;\n+  VLoopDependenceGraph _dependence_graph;\n+\n+public:\n+  VLoopAnalyzer(PhaseIdealLoop* phase) :\n+    VLoop(phase),\n+    _reductions(*this),\n+    _memory_slices(*this),\n+    _body(*this),\n+    _types(*this, _body), \/\/ types requires: body\n+    _dependence_graph(*this, _memory_slices, _body) \/\/ dependence_graph requires: memory_slices and body\n+  {\n+  };\n+  NONCOPYABLE(VLoopAnalyzer);\n+\n+  \/\/ Analyze the loop in preparation for vectorization.\n+  \/\/ Overwrite previous data. Return indicates if analysis succeeded.\n+  bool analyze(IdealLoopTree* lpt,\n+               bool allow_cfg);\n+\n+  \/\/ Read-only accessors for submodules\n+  const VLoopReductions& reductions() const            { return _reductions; }\n+  const VLoopMemorySlices& memory_slices() const       { return _memory_slices; }\n+  const VLoopBody& body() const                        { return _body; }\n+  const VLoopTypes& types() const                      { return _types; }\n+  const VLoopDependenceGraph& dependence_graph() const { return _dependence_graph; }\n+\n+private:\n+  virtual void reset(IdealLoopTree* lpt, bool allow_cfg) override {\n+    VLoop::reset(lpt, allow_cfg);\n+    _reductions.reset();\n+    _memory_slices.reset();\n+    _body.reset();\n+    _types.reset();\n+    _dependence_graph.reset();\n+  }\n+  const char* analyze_helper();\n+};\n+\n@@ -37,1 +626,1 @@\n-class VPointer : public ArenaObj {\n+class VPointer : public StackObj {\n@@ -40,3 +629,1 @@\n-  PhaseIdealLoop* _phase;    \/\/ PhaseIdealLoop handle\n-  IdealLoopTree*  _lpt;      \/\/ Current IdealLoopTree\n-  PhiNode*        _iv;       \/\/ The loop induction variable\n+  const VLoop&    _vloop;\n@@ -60,3 +647,4 @@\n-  PhaseIdealLoop* phase() const { return _phase; }\n-  IdealLoopTree*  lpt() const   { return _lpt; }\n-  PhiNode*        iv() const    { return _iv; }\n+  const VLoop&    vloop() const { return _vloop; }\n+  PhaseIdealLoop* phase() const { return _vloop.phase(); }\n+  IdealLoopTree*  lpt() const   { return _vloop.lpt(); }\n+  PhiNode*        iv() const    { return _vloop.iv(); }\n@@ -83,2 +671,6 @@\n-  VPointer(const MemNode* mem,\n-           PhaseIdealLoop* phase, IdealLoopTree* lpt,\n+  VPointer(const MemNode* mem, const VLoop& vloop) :\n+    VPointer(mem, vloop, nullptr, false) {}\n+  VPointer(const MemNode* mem, const VLoop& vloop, Node_Stack* nstack) :\n+    VPointer(mem, vloop, nstack, true) {}\n+ private:\n+  VPointer(const MemNode* mem, const VLoop& vloop,\n@@ -89,0 +681,1 @@\n+  NONCOPYABLE(VPointer);\n@@ -90,0 +683,1 @@\n+ public:\n@@ -92,1 +686,0 @@\n-\n@@ -129,1 +722,1 @@\n-      VPointer p_mem(mem, phase(), lpt(), nullptr, false);\n+      VPointer p_mem(mem, vloop());\n@@ -152,1 +745,1 @@\n-    bool _is_trace_alignment;\n+    const VLoop &_vloop;\n@@ -169,1 +762,3 @@\n-    Tracer(bool is_trace_alignment) : _is_trace_alignment(is_trace_alignment) {}\n+    Tracer(const VLoop &vloop) : _vloop(vloop) {}\n+\n+    bool is_trace_pointer_analysis() const { return _vloop.is_trace_pointer_analysis(); }\n@@ -564,1 +1159,1 @@\n-  DEBUG_ONLY( const bool _is_trace; );\n+  NOT_PRODUCT( const bool _is_trace; )\n@@ -582,2 +1177,1 @@\n-                  DEBUG_ONLY( COMMA const bool is_trace)\n-                  ) :\n+                  NOT_PRODUCT(COMMA const bool is_trace)) :\n@@ -597,1 +1191,1 @@\n-      DEBUG_ONLY( COMMA _is_trace(is_trace) )\n+      NOT_PRODUCT(COMMA _is_trace(is_trace))\n@@ -644,1 +1238,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n@@ -657,1 +1251,1 @@\n-#ifdef ASSERT\n+#ifndef PRODUCT\n","filename":"src\/hotspot\/share\/opto\/vectorization.hpp","additions":613,"deletions":19,"binary":false,"changes":632,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2007, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2007, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -175,3 +175,3 @@\n-    \/\/ Subword operations in superword usually don't have precise info\n-    \/\/ about signedness. But the behavior of reverseBytes for short and\n-    \/\/ char are exactly the same.\n+    \/\/ Subword operations in autovectorization usually don't have precise\n+    \/\/ info about signedness. But the behavior of reverseBytes for short\n+    \/\/ and char are exactly the same.\n@@ -391,2 +391,2 @@\n-bool VectorNode::vector_size_supported_superword(const BasicType bt, int size) {\n-  return Matcher::superword_max_vector_size(bt) >= size &&\n+bool VectorNode::vector_size_supported_autovectorization(const BasicType bt, int size) {\n+  return Matcher::max_vector_size_autovectorization(bt) >= size &&\n@@ -401,1 +401,1 @@\n-      vector_size_supported_superword(bt, vlen)) {\n+      vector_size_supported_autovectorization(bt, vlen)) {\n@@ -412,1 +412,1 @@\n-    return vopc > 0 && Matcher::match_rule_supported_superword(vopc, vlen, bt);\n+    return vopc > 0 && Matcher::match_rule_supported_autovectorization(vopc, vlen, bt);\n@@ -1435,1 +1435,1 @@\n-      VectorNode::vector_size_supported_superword(dst_type, vlen)) {\n+      VectorNode::vector_size_supported_autovectorization(dst_type, vlen)) {\n@@ -1437,1 +1437,1 @@\n-    return vopc > 0 && Matcher::match_rule_supported_superword(vopc, vlen, dst_type);\n+    return vopc > 0 && Matcher::match_rule_supported_autovectorization(vopc, vlen, dst_type);\n@@ -1529,1 +1529,1 @@\n-      VectorNode::vector_size_supported_superword(bt, vlen)) {\n+      VectorNode::vector_size_supported_autovectorization(bt, vlen)) {\n@@ -1531,1 +1531,1 @@\n-    return vopc != opc && Matcher::match_rule_supported_superword(vopc, vlen, bt);\n+    return vopc != opc && Matcher::match_rule_supported_autovectorization(vopc, vlen, bt);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -99,1 +99,1 @@\n-  static bool vector_size_supported_superword(const BasicType bt, int size);\n+  static bool vector_size_supported_autovectorization(const BasicType bt, int size);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,1 +67,1 @@\n-        for (int i = 0; i < data.length; i++) {\n+        for (int i = 0; i < data.length; i+=2) {\n@@ -80,0 +80,11 @@\n+\n+            \/\/ This example used to rely on that reductions were ignored in SuperWord::unrolling_analysis,\n+            \/\/ and hence the largest data type in the loop was the ints. This would then unroll the doubles\n+            \/\/ for twice the vector length, and this resulted in us having twice as many packs. Because of\n+            \/\/ the store \"data[0] = 0\", the first packs were destroyed, since they do not have power of 2\n+            \/\/ size.\n+            \/\/ Now, we no longer ignore reductions, and now we unroll half as much before SuperWord. This\n+            \/\/ means we would only get one pack per operation, and that one would get ruined, and we have\n+            \/\/ no vectorization. We now ensure there are again 2 packs per operation with a 2x hand unroll.\n+            int v2 = data[i + 1];\n+            sum |= v2;\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -55,1 +55,1 @@\n-            \"-XX:CompileCommand=option,Test::test,VectorizeDebug,3\",\n+            \"-XX:CompileCommand=option,Test::test,MemStat,3\",\n@@ -75,1 +75,1 @@\n-            \"Missing type 'uintx' before option 'VectorizeDebug'\"\n+            \"Missing type 'uintx' before option 'MemStat'\"\n","filename":"test\/hotspot\/jtreg\/compiler\/oracle\/TestInvalidCompileCommand.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"}]}