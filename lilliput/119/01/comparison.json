{"files":[{"patch":"@@ -55,3 +55,0 @@\n-          - s390x\n-          - ppc64le\n-          - riscv64\n@@ -70,15 +67,0 @@\n-          - target-cpu: s390x\n-            gnu-arch: s390x\n-            debian-arch: s390x\n-            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-            debian-version: bullseye\n-          - target-cpu: ppc64le\n-            gnu-arch: powerpc64le\n-            debian-arch: ppc64el\n-            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-            debian-version: bullseye\n-          - target-cpu: riscv64\n-            gnu-arch: riscv64\n-            debian-arch: riscv64\n-            debian-repository: https:\/\/httpredir.debian.org\/debian\/\n-            debian-version: sid\n","filename":".github\/workflows\/build-cross-compile.yml","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-project=jdk\n+project=lilliput\n@@ -7,1 +7,1 @@\n-error=author,committer,reviewers,merge,issues,executable,symlink,message,hg-tag,whitespace,problemlists\n+error=author,committer,reviewers,issues,executable,symlink,message,hg-tag,whitespace,problemlists\n@@ -21,3 +21,0 @@\n-[checks \"merge\"]\n-message=Merge\n-\n@@ -25,1 +22,1 @@\n-reviewers=1\n+committers=1\n","filename":".jcheck\/conf","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -835,0 +835,5 @@\n+  # Add more Lilliput-specific ProblemLists when UCOH is enabled\n+  ifneq ($$(findstring -XX:+UseCompactObjectHeaders, $$(TEST_OPTS)), )\n+    JTREG_EXTRA_PROBLEM_LISTS += $(TOPDIR)\/test\/hotspot\/jtreg\/ProblemList-lilliput.txt\n+  endif\n+\n","filename":"make\/RunTests.gmk","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -7134,1 +7134,1 @@\n-  predicate(!needs_acquiring_load(n));\n+  predicate(!needs_acquiring_load(n) && !UseCompactObjectHeaders);\n@@ -7144,0 +7144,14 @@\n+instruct loadNKlassCompactHeaders(iRegNNoSp dst, memory4 mem, rFlagsReg cr)\n+%{\n+  match(Set dst (LoadNKlass mem));\n+  effect(KILL cr);\n+  predicate(!needs_acquiring_load(n) && UseCompactObjectHeaders);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrw  $dst, $mem\\t# compressed class ptr\" %}\n+  ins_encode %{\n+    __ load_nklass_compact($dst$$Register, $mem$$base$$Register, $mem$$index$$Register, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -236,0 +237,7 @@\n+void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n+  assert(UseCompactObjectHeaders, \"Only use with compact object headers\");\n+  __ bind(_entry);\n+  Register d = _result->as_register();\n+  __ ldr(d, Address(d, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  __ b(_continuation);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1232,1 +1232,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n@@ -2269,2 +2269,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -2331,9 +2329,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(tmp, src_klass_addr);\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(tmp, src_klass_addr);\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(src, dst, tmp, rscratch1);\n@@ -2461,3 +2451,0 @@\n-    if (UseCompressedClassPointers) {\n-      __ encode_klass_not_null(tmp);\n-    }\n@@ -2466,8 +2453,1 @@\n-\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(dst, tmp, rscratch1);\n@@ -2475,7 +2455,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, src_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, src_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(src, tmp, rscratch1);\n@@ -2484,7 +2458,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(dst, tmp, rscratch1);\n@@ -2572,1 +2540,12 @@\n-    __ ldrw(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+    if (UseCompactObjectHeaders) {\n+      \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+      __ ldr(result, Address(obj, oopDesc::mark_offset_in_bytes()));\n+      __ tst(result, markWord::monitor_value);\n+      __ br(Assembler::NE, *op->stub()->entry());\n+      __ bind(*op->stub()->continuation());\n+\n+      \/\/ Shift to get proper narrow Klass*.\n+      __ lsr(result, result, markWord::klass_shift);\n+    } else {\n+      __ ldrw(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":17,"deletions":38,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -183,7 +183,3 @@\n-  \/\/ This assumes that all prototype bits fit in an int32_t\n-  mov(t1, (int32_t)(intptr_t)markWord::prototype().value());\n-  str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n-\n-  if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n-    encode_klass_not_null(t1, klass);\n-    strw(t1, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  if (UseCompactObjectHeaders) {\n+    ldr(t1, Address(klass, Klass::prototype_header_offset()));\n+    str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n@@ -191,1 +187,10 @@\n-    str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    \/\/ This assumes that all prototype bits fit in an int32_t\n+    mov(t1, (int32_t)(intptr_t)markWord::prototype().value());\n+    str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+      encode_klass_not_null(t1, klass);\n+      strw(t1, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    } else {\n+      str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    }\n@@ -196,1 +201,1 @@\n-  } else if (UseCompressedClassPointers) {\n+  } else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n@@ -274,1 +279,1 @@\n-void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int header_size, int f, Register klass, Label& slow_case) {\n+void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int base_offset_in_bytes, int f, Register klass, Label& slow_case) {\n@@ -287,1 +292,1 @@\n-  mov(arr_size, (int32_t)header_size * BytesPerWord + MinObjAlignmentInBytesMask);\n+  mov(arr_size, (int32_t)base_offset_in_bytes + MinObjAlignmentInBytesMask);\n@@ -295,0 +300,11 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    strw(zr, Address(obj, base_offset));\n+    base_offset += BytesPerInt;\n+  }\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word-aligned\");\n+\n@@ -296,1 +312,1 @@\n-  initialize_body(obj, arr_size, header_size * BytesPerWord, t1, t2);\n+  initialize_body(obj, arr_size, base_offset, t1, t2);\n@@ -316,1 +332,5 @@\n-  assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), \"must add explicit null check\");\n+  if (UseCompactObjectHeaders) {\n+    assert(!MacroAssembler::needs_explicit_null_check(oopDesc::mark_offset_in_bytes()), \"must add explicit null check\");\n+  } else {\n+    assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), \"must add explicit null check\");\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":33,"deletions":13,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -94,0 +94,11 @@\n+int C2LoadNKlassStub::max_size() const {\n+  return 8;\n+}\n+\n+void C2LoadNKlassStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  Register d = dst();\n+  __ ldr(d, Address(d, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  __ b(continuation());\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_CodeStubs_aarch64.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2257,0 +2257,27 @@\n+\n+void C2_MacroAssembler::load_nklass_compact(Register dst, Register obj, Register index, int scale, int disp) {\n+  C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+  Compile::current()->output()->add_stub(stub);\n+\n+  \/\/ Note: Don't clobber obj anywhere in that method!\n+\n+  \/\/ The incoming address is pointing into obj-start + klass_offset_in_bytes. We need to extract\n+  \/\/ obj-start, so that we can load from the object's mark-word instead. Usually the address\n+  \/\/ comes as obj-start in obj and klass_offset_in_bytes in disp. However, sometimes C2\n+  \/\/ emits code that pre-computes obj-start + klass_offset_in_bytes into a register, and\n+  \/\/ then passes that register as obj and 0 in disp. The following code extracts the base\n+  \/\/ and offset to load the mark-word.\n+  int offset = oopDesc::mark_offset_in_bytes() + disp - oopDesc::klass_offset_in_bytes();\n+  if (index == noreg) {\n+    ldr(dst, Address(obj, offset));\n+  } else {\n+    lea(dst, Address(obj, index, Address::lsl(scale)));\n+    ldr(dst, Address(dst, offset));\n+  }\n+  \/\/ NOTE: We can't use tbnz here, because the target is sometimes too far away\n+  \/\/ and cannot be encoded.\n+  tst(dst, markWord::monitor_value);\n+  br(Assembler::NE, stub->entry());\n+  bind(stub->continuation());\n+  lsr(dst, dst, markWord::klass_shift);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -180,0 +180,2 @@\n+  void load_nklass_compact(Register dst, Register obj, Register index, int scale, int disp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4422,0 +4422,19 @@\n+\/\/ Loads the obj's Klass* into dst.\n+\/\/ Preserves all registers (incl src, rscratch1 and rscratch2).\n+void MacroAssembler::load_nklass(Register dst, Register src) {\n+  assert(UseCompactObjectHeaders, \"expects UseCompactObjectHeaders\");\n+\n+  Label fast;\n+\n+  \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+  ldr(dst, Address(src, oopDesc::mark_offset_in_bytes()));\n+  tbz(dst, exact_log2(markWord::monitor_value), fast);\n+\n+  \/\/ Fetch displaced header\n+  ldr(dst, Address(dst, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+\n+  \/\/ Fast-path: shift and decode Klass*.\n+  bind(fast);\n+  lsr(dst, dst, markWord::klass_shift);\n+}\n+\n@@ -4423,1 +4442,4 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(dst, src);\n+    decode_klass_not_null(dst);\n+  } else if (UseCompressedClassPointers) {\n@@ -4462,0 +4484,1 @@\n+  assert_different_registers(oop, trial_klass, tmp);\n@@ -4463,1 +4486,5 @@\n-    ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));\n+    if (UseCompactObjectHeaders) {\n+      load_nklass(tmp, oop);\n+    } else {\n+      ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));\n+    }\n@@ -4480,0 +4507,16 @@\n+void MacroAssembler::cmp_klass(Register src, Register dst, Register tmp1, Register tmp2) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(tmp1, src);\n+    load_nklass(tmp2, dst);\n+    cmpw(tmp1, tmp2);\n+  } else if (UseCompressedClassPointers) {\n+    ldrw(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldrw(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmpw(tmp1, tmp2);\n+  } else {\n+    ldr(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldr(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmp(tmp1, tmp2);\n+  }\n+}\n+\n@@ -4483,0 +4526,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n@@ -4492,0 +4536,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":47,"deletions":2,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -866,0 +866,1 @@\n+  void load_nklass(Register dst, Register src);\n@@ -869,0 +870,1 @@\n+  void cmp_klass(Register src, Register dst, Register tmp1, Register tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3638,1 +3638,6 @@\n-    __ sub(r3, r3, sizeof(oopDesc));\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      __ sub(r3, r3, oopDesc::base_offset_in_bytes());\n+    } else {\n+      __ sub(r3, r3, sizeof(oopDesc));\n+    }\n@@ -3643,1 +3648,6 @@\n-      __ add(r2, r0, sizeof(oopDesc));\n+      if (UseCompactObjectHeaders) {\n+        assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+        __ add(r2, r0, oopDesc::base_offset_in_bytes());\n+      } else {\n+        __ add(r2, r0, sizeof(oopDesc));\n+      }\n@@ -3653,5 +3663,9 @@\n-    __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n-    __ str(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n-    __ store_klass_gap(r0, zr);  \/\/ zero klass gap for compressed oops\n-    __ store_klass(r0, r4);      \/\/ store klass last\n-\n+    if (UseCompactObjectHeaders) {\n+      __ ldr(rscratch1, Address(r4, Klass::prototype_header_offset()));\n+      __ str(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+    } else {\n+      __ mov(rscratch1, (intptr_t)markWord::prototype().value());\n+      __ str(rscratch1, Address(r0, oopDesc::mark_offset_in_bytes()));\n+      __ store_klass_gap(r0, zr);  \/\/ zero klass gap for compressed oops\n+      __ store_klass(r0, r4);      \/\/ store klass last\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":21,"deletions":7,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -200,1 +200,1 @@\n-  const ptrdiff_t estimate = 124;\n+  const ptrdiff_t estimate = UseCompactObjectHeaders ? 132 : 124;\n","filename":"src\/hotspot\/cpu\/aarch64\/vtableStubs_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -220,0 +220,4 @@\n+void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n+  \/\/ Currently not needed.\n+  Unimplemented();\n+}\n","filename":"src\/hotspot\/cpu\/arm\/c1_CodeStubs_arm.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -974,1 +974,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -166,1 +166,1 @@\n-                                       int header_size, int element_size,\n+                                       int header_size_in_bytes, int element_size,\n@@ -169,1 +169,0 @@\n-  const int header_size_in_bytes = header_size * BytesPerWord;\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-                      int header_size, int element_size,\n+                      int header_size_in_bytes, int element_size,\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -301,0 +301,4 @@\n+void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n+  \/\/ Currently not needed.\n+  Unimplemented();\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_CodeStubs_ppc.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1683,1 +1683,1 @@\n-      __ cmpxchg_obj_header(x10, lock_reg, obj_reg, t0, count, \/*fallthrough*\/nullptr);\n+      __ cmpxchg_obj_header(x10, lock_reg, obj_reg, t0, count, \/*fallthrough*\/NULL);\n","filename":"src\/hotspot\/cpu\/riscv\/sharedRuntime_riscv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -256,0 +256,5 @@\n+void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n+  \/\/ Currently not needed.\n+  Unimplemented();\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/c1_CodeStubs_s390.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/objectMonitor.hpp\"\n@@ -281,0 +282,11 @@\n+void LoadKlassStub::emit_code(LIR_Assembler* ce) {\n+  assert(UseCompactObjectHeaders, \"only with compact headers\");\n+  __ bind(_entry);\n+#ifdef _LP64\n+  Register d = _result->as_register();\n+  __ movq(d, Address(d, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  __ jmp(_continuation);\n+#else\n+  __ should_not_reach_here();\n+#endif\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1638,1 +1638,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n@@ -3067,0 +3067,1 @@\n+  Register tmp2 = UseCompactObjectHeaders ? rscratch2 : noreg;\n@@ -3191,2 +3192,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3258,7 +3257,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ movl(tmp, src_klass_addr);\n-        __ cmpl(tmp, dst_klass_addr);\n-      } else {\n-        __ movptr(tmp, src_klass_addr);\n-        __ cmpptr(tmp, dst_klass_addr);\n-      }\n+      __ cmp_klass(src, dst, tmp, tmp2);\n@@ -3323,0 +3316,1 @@\n+        Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3424,1 +3418,0 @@\n-\n@@ -3426,3 +3419,1 @@\n-\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);\n-      else                   __ cmpptr(tmp, dst_klass_addr);\n+      __ cmp_klass(tmp, dst, tmp2);\n@@ -3430,2 +3421,1 @@\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);\n-      else                   __ cmpptr(tmp, src_klass_addr);\n+      __ cmp_klass(tmp, src, tmp2);\n@@ -3434,2 +3424,1 @@\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);\n-      else                   __ cmpptr(tmp, dst_klass_addr);\n+      __ cmp_klass(tmp, dst, tmp2);\n@@ -3531,1 +3520,14 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    Register tmp = rscratch1;\n+    assert_different_registers(tmp, obj);\n+    assert_different_registers(tmp, result);\n+\n+    \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+    __ movq(result, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    __ testb(result, markWord::monitor_value);\n+    __ jcc(Assembler::notZero, *op->stub()->entry());\n+    __ bind(*op->stub()->continuation());\n+    \/\/ Fast-path: shift and decode Klass*.\n+    __ shrq(result, markWord::klass_shift);\n+    __ decode_klass_not_null(result, tmp);\n+  } else if (UseCompressedClassPointers) {\n@@ -3536,0 +3538,1 @@\n+  {\n@@ -3537,0 +3540,1 @@\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":23,"deletions":19,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -167,2 +167,1 @@\n-  assert_different_registers(obj, klass, len);\n-  movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n+  assert_different_registers(obj, klass, len, t1, t2);\n@@ -170,1 +169,5 @@\n-  if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+  if (UseCompactObjectHeaders) {\n+    movptr(t1, Address(klass, Klass::prototype_header_offset()));\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);\n+  } else if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n@@ -177,0 +180,1 @@\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n@@ -179,1 +183,0 @@\n-\n@@ -184,1 +187,1 @@\n-  else if (UseCompressedClassPointers) {\n+  else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n@@ -218,1 +221,3 @@\n-\n+  if (UseCompactObjectHeaders) {\n+    assert(hdr_size_in_bytes == 8, \"check object headers size\");\n+  }\n@@ -265,1 +270,1 @@\n-void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int header_size, Address::ScaleFactor f, Register klass, Label& slow_case) {\n+void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int base_offset_in_bytes, Address::ScaleFactor f, Register klass, Label& slow_case) {\n@@ -278,1 +283,1 @@\n-  movptr(arr_size, header_size * BytesPerWord + MinObjAlignmentInBytesMask);\n+  movptr(arr_size, (int32_t)base_offset_in_bytes + MinObjAlignmentInBytesMask);\n@@ -286,0 +291,13 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+#ifdef _LP64\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    movl(Address(obj, base_offset), 0);\n+    base_offset += BytesPerInt;\n+  }\n+#endif\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word aligned\");\n+\n@@ -288,1 +306,1 @@\n-  initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);\n+  initialize_body(obj, arr_size, base_offset, len_zero);\n@@ -303,2 +321,1 @@\n-  \/\/ check against inline cache\n-  assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), \"must add explicit null check\");\n+  \/\/ check against inline cache. This is checked in Universe::genesis().\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":28,"deletions":11,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -96,0 +96,11 @@\n+\n+int C2LoadNKlassStub::max_size() const {\n+  return 10;\n+}\n+\n+void C2LoadNKlassStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  Register d = dst();\n+  __ movq(d, Address(d, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  __ jmp(continuation());\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -6191,0 +6191,22 @@\n+\n+#ifdef _LP64\n+void C2_MacroAssembler::load_nklass_compact_c2(Register dst, Register obj, Register index, Address::ScaleFactor scale, int disp) {\n+  C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+  Compile::current()->output()->add_stub(stub);\n+\n+  \/\/ Note: Don't clobber obj anywhere in that method!\n+\n+  \/\/ The incoming address is pointing into obj-start + klass_offset_in_bytes. We need to extract\n+  \/\/ obj-start, so that we can load from the object's mark-word instead. Usually the address\n+  \/\/ comes as obj-start in obj and klass_offset_in_bytes in disp. However, sometimes C2\n+  \/\/ emits code that pre-computes obj-start + klass_offset_in_bytes into a register, and\n+  \/\/ then passes that register as obj and 0 in disp. The following code extracts the base\n+  \/\/ and offset to load the mark-word.\n+  int offset = oopDesc::mark_offset_in_bytes() + disp - oopDesc::klass_offset_in_bytes();\n+  movq(dst, Address(obj, index, scale, offset));\n+  testb(dst, markWord::monitor_value);\n+  jcc(Assembler::notZero, stub->entry());\n+  bind(stub->continuation());\n+  shrq(dst, markWord::klass_shift);\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -495,0 +495,2 @@\n+  void load_nklass_compact_c2(Register dst, Register obj, Register index, Address::ScaleFactor scale, int disp);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5328,0 +5328,17 @@\n+#ifdef _LP64\n+void MacroAssembler::load_nklass_compact(Register dst, Register src) {\n+  assert(UseCompactObjectHeaders, \"expect compact object headers\");\n+\n+  Label fast;\n+  movq(dst, Address(src, oopDesc::mark_offset_in_bytes()));\n+  testb(dst, markWord::monitor_value);\n+  jccb(Assembler::zero, fast);\n+\n+  \/\/ Fetch displaced header\n+  movq(dst, Address(dst, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+\n+  bind(fast);\n+  shrq(dst, markWord::klass_shift);\n+}\n+#endif\n+\n@@ -5332,1 +5349,4 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass_compact(dst, src);\n+    decode_klass_not_null(dst, tmp);\n+  } else if (UseCompressedClassPointers) {\n@@ -5337,0 +5357,1 @@\n+  {\n@@ -5338,0 +5359,1 @@\n+  }\n@@ -5341,0 +5363,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n@@ -5352,0 +5375,33 @@\n+void MacroAssembler::cmp_klass(Register klass, Register obj, Register tmp) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    load_nklass_compact(tmp, obj);\n+    cmpl(klass, tmp);\n+  } else if (UseCompressedClassPointers) {\n+    cmpl(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  } else\n+#endif\n+  {\n+    cmpptr(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n+void MacroAssembler::cmp_klass(Register src, Register dst, Register tmp1, Register tmp2) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    assert(tmp2 != noreg, \"need tmp2\");\n+    assert_different_registers(src, dst, tmp1, tmp2);\n+    load_nklass_compact(tmp1, src);\n+    load_nklass_compact(tmp2, dst);\n+    cmpl(tmp1, tmp2);\n+  } else if (UseCompressedClassPointers) {\n+    movl(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    cmpl(tmp1, Address(dst, oopDesc::klass_offset_in_bytes()));\n+  } else\n+#endif\n+  {\n+    movptr(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    cmpptr(tmp1, Address(dst, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -5399,0 +5455,1 @@\n+  assert(!UseCompactObjectHeaders, \"Don't use with compact headers\");\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":58,"deletions":1,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -367,0 +367,3 @@\n+#ifdef _LP64\n+  void load_nklass_compact(Register dst, Register src);\n+#endif\n@@ -370,0 +373,8 @@\n+  \/\/ Compares the Klass pointer of an object to a given Klass (which might be narrow,\n+  \/\/ depending on UseCompressedClassPointers).\n+  void cmp_klass(Register klass, Register dst, Register tmp);\n+\n+  \/\/ Compares the Klass pointer of two objects o1 and o2. Result is in the condition flags.\n+  \/\/ Uses t1 and t2 as temporary registers.\n+  void cmp_klass(Register src, Register dst, Register tmp1, Register tmp2);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -71,2 +71,7 @@\n-  __ shrptr(result, markWord::hash_shift);\n-  __ andptr(result, markWord::hash_mask);\n+  if (UseCompactObjectHeaders) {\n+    __ shrptr(result, markWord::hash_shift_compact);\n+    __ andptr(result, markWord::hash_mask_compact);\n+  } else {\n+    __ shrptr(result, markWord::hash_shift);\n+    __ andptr(result, markWord::hash_mask);\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -4083,1 +4083,6 @@\n-    __ decrement(rdx, sizeof(oopDesc));\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      __ decrement(rdx, oopDesc::base_offset_in_bytes());\n+    } else {\n+      __ decrement(rdx, sizeof(oopDesc));\n+    }\n@@ -4105,2 +4110,9 @@\n-    __ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 1*oopSize), rcx);\n-    NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 2*oopSize), rcx));\n+    if (UseCompactObjectHeaders) {\n+      assert(is_aligned(oopDesc::base_offset_in_bytes(), BytesPerLong), \"oop base offset must be 8-byte-aligned\");\n+      int header_size = oopDesc::base_offset_in_bytes();\n+      __ movptr(Address(rax, rdx, Address::times_8, header_size - 1*oopSize), rcx);\n+      NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, header_size - 2*oopSize), rcx));\n+    } else {\n+      __ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 1*oopSize), rcx);\n+      NOT_LP64(__ movptr(Address(rax, rdx, Address::times_8, sizeof(oopDesc) - 2*oopSize), rcx));\n+    }\n@@ -4113,3 +4125,8 @@\n-    __ movptr(Address(rax, oopDesc::mark_offset_in_bytes()),\n-              (intptr_t)markWord::prototype().value()); \/\/ header\n-    __ pop(rcx);   \/\/ get saved klass back in the register.\n+    if (UseCompactObjectHeaders) {\n+      __ pop(rcx);   \/\/ get saved klass back in the register.\n+      __ movptr(rbx, Address(rcx, Klass::prototype_header_offset()));\n+      __ movptr(Address(rax, oopDesc::mark_offset_in_bytes ()), rbx);\n+    } else {\n+      __ movptr(Address(rax, oopDesc::mark_offset_in_bytes()),\n+                (intptr_t)markWord::prototype().value()); \/\/ header\n+      __ pop(rcx);   \/\/ get saved klass back in the register.\n@@ -4117,2 +4134,2 @@\n-    __ xorl(rsi, rsi); \/\/ use zero reg to clear memory (shorter code)\n-    __ store_klass_gap(rax, rsi);  \/\/ zero klass gap for compressed oops\n+      __ xorl(rsi, rsi); \/\/ use zero reg to clear memory (shorter code)\n+      __ store_klass_gap(rax, rsi);  \/\/ zero klass gap for compressed oops\n@@ -4120,1 +4137,2 @@\n-    __ store_klass(rax, rcx, rscratch1);  \/\/ klass\n+      __ store_klass(rax, rcx, rscratch1);  \/\/ klass\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":27,"deletions":9,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -4431,0 +4431,1 @@\n+  predicate(!UseCompactObjectHeaders);\n@@ -4441,0 +4442,15 @@\n+instruct loadNKlassCompactHeaders(rRegN dst, memory mem, rFlagsReg cr)\n+%{\n+  predicate(UseCompactObjectHeaders);\n+  match(Set dst (LoadNKlass mem));\n+  effect(KILL cr);\n+  ins_cost(125); \/\/ XXX\n+  format %{ \"movl    $dst, $mem\\t# compressed klass ptr\" %}\n+  ins_encode %{\n+    Register index = $mem$$index != 4 ? $mem$$index$$Register : noreg;\n+    Address::ScaleFactor sf = (index != noreg) ? static_cast<Address::ScaleFactor>($mem$$scale) : Address::no_scale;\n+    __ load_nklass_compact_c2($dst$$Register, $mem$$base$$Register, index, sf, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow); \/\/ XXX\n+%}\n+\n@@ -11815,0 +11831,1 @@\n+  predicate(!UseCompactObjectHeaders);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -584,0 +584,18 @@\n+class LoadKlassStub: public CodeStub {\n+private:\n+  LIR_Opr          _result;\n+\n+public:\n+  LoadKlassStub(LIR_Opr result) :\n+    CodeStub(), _result(result) {};\n+\n+  virtual void emit_code(LIR_Assembler* e);\n+  virtual void visit(LIR_OpVisitState* visitor) {\n+    visitor->do_temp(_result);\n+    visitor->do_output(_result);\n+  }\n+#ifndef PRODUCT\n+virtual void print_name(outputStream* out) const { out->print(\"LoadKlassStub\"); }\n+#endif \/\/ PRODUCT\n+};\n+\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -893,0 +893,1 @@\n+      if (opLoadKlass->_stub) do_stub(opLoadKlass->_stub);\n@@ -1073,0 +1074,3 @@\n+  if (stub()) {\n+    masm->append_code_stub(stub());\n+  }\n@@ -2049,0 +2053,3 @@\n+  if (stub()) {\n+    out->print(\"[lbl:\" INTPTR_FORMAT \"]\", p2i(stub()->entry()));\n+  }\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1906,0 +1906,1 @@\n+  CodeStub* _stub;\n@@ -1907,1 +1908,1 @@\n-  LIR_OpLoadKlass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info)\n+  LIR_OpLoadKlass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info, CodeStub* stub)\n@@ -1910,0 +1911,1 @@\n+    , _stub(stub)\n@@ -1913,0 +1915,1 @@\n+  CodeStub* stub()     const { return _stub; }\n@@ -2378,1 +2381,1 @@\n-  void load_klass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info) { append(new LIR_OpLoadKlass(obj, result, info)); }\n+  void load_klass(LIR_Opr obj, LIR_Opr result, CodeEmitInfo* info, CodeStub* stub) { append(new LIR_OpLoadKlass(obj, result, info, stub)); }\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1247,1 +1247,2 @@\n-  __ load_klass(obj, klass, null_check_info);\n+  CodeStub* slow_path = UseCompactObjectHeaders ? new LoadKlassStub(klass) : nullptr;\n+  __ load_klass(obj, klass, null_check_info, slow_path);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -730,0 +730,9 @@\n+#ifdef _LP64\n+    if (UseCompactObjectHeaders) {\n+      Klass* requested_k = to_requested(k);\n+      address narrow_klass_base = _requested_static_archive_bottom; \/\/ runtime encoding base == runtime mapping start\n+      const int narrow_klass_shift = precomputed_narrow_klass_shift;\n+      narrowKlass nk = CompressedKlassPointers::encode_not_null(requested_k, narrow_klass_base, narrow_klass_shift);\n+      k->set_prototype_header(markWord::prototype().set_narrow_klass(nk));\n+    }\n+#endif \/\/_LP64\n@@ -832,1 +841,1 @@\n-  const int narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+  const int narrow_klass_shift = precomputed_narrow_klass_shift;\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -93,0 +93,14 @@\n+public:\n+  \/\/ The archive contains pre-computed narrow Klass IDs in two places:\n+  \/\/ - in the header of archived java objects (only if the archive contains java heap portions)\n+  \/\/ - within the prototype markword of archived Klass structures.\n+  \/\/ These narrow Klass ids have been computed at dump time with the following scheme:\n+  \/\/ 1) the encoding base must be the mapping start address.\n+  \/\/ 2) shift must be large enough to result in an encoding range that covers the runtime Klass range.\n+  \/\/    That Klass range is defined by CDS archive size and runtime class space size. Luckily, the maximum\n+  \/\/    size can be predicted: archive size is assumed to be <1G, class space size capped at 3G, and at\n+  \/\/    runtime we put both regions adjacent to each other. Therefore, runtime Klass range size < 4G.\n+  \/\/    Since nKlass itself is 32 bit, our encoding range len is 4G, and since we set the base directly\n+  \/\/    at mapping start, these 4G are enough. Therefore, we don't need to shift at all (shift=0).\n+  static constexpr int precomputed_narrow_klass_shift = 0;\n+\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.hpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -205,2 +205,7 @@\n-    oopDesc::set_mark(mem, markWord::prototype());\n-    oopDesc::release_set_klass(mem, k);\n+    if (UseCompactObjectHeaders) {\n+      narrowKlass nk = ArchiveBuilder::current()->get_requested_narrow_klass(k);\n+      oopDesc::release_set_mark(mem, markWord::prototype().set_narrow_klass(nk));\n+    } else {\n+      oopDesc::set_mark(mem, markWord::prototype());\n+      oopDesc::release_set_klass(mem, k);\n+    }\n@@ -272,1 +277,0 @@\n-  oopDesc::set_mark(mem, markWord::prototype());\n@@ -274,1 +278,6 @@\n-  cast_to_oop(mem)->set_narrow_klass(nk);\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, markWord::prototype().set_narrow_klass(nk));\n+  } else {\n+    oopDesc::set_mark(mem, markWord::prototype());\n+    cast_to_oop(mem)->set_narrow_klass(nk);\n+  }\n@@ -474,1 +483,3 @@\n-  fake_oop->set_narrow_klass(nk);\n+  if (!UseCompactObjectHeaders) {\n+    fake_oop->set_narrow_klass(nk);\n+  }\n@@ -482,1 +493,5 @@\n-    fake_oop->set_mark(markWord::prototype().copy_set_hash(src_hash));\n+    if (UseCompactObjectHeaders) {\n+      fake_oop->set_mark(markWord::prototype().set_narrow_klass(nk).copy_set_hash(src_hash));\n+    } else {\n+      fake_oop->set_mark(markWord::prototype().copy_set_hash(src_hash));\n+    }\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":21,"deletions":6,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -236,11 +236,0 @@\n-  \/\/ Archived heap object headers carry pre-computed narrow Klass ids calculated with the\n-  \/\/ following scheme:\n-  \/\/ 1) the encoding base must be the mapping start address.\n-  \/\/ 2) shift must be large enough to result in an encoding range that covers the runtime Klass range.\n-  \/\/    That Klass range is defined by CDS archive size and runtime class space size. Luckily, the maximum\n-  \/\/    size can be predicted: archive size is assumed to be <1G, class space size capped at 3G, and at\n-  \/\/    runtime we put both regions adjacent to each other. Therefore, runtime Klass range size < 4G.\n-  \/\/    Since nKlass itself is 32 bit, our encoding range len is 4G, and since we set the base directly\n-  \/\/    at mapping start, these 4G are enough. Therefore, we don't need to shift at all (shift=0).\n-  static constexpr int precomputed_narrow_klass_shift = 0;\n-\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.hpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -207,0 +207,1 @@\n+  _compact_headers = UseCompactObjectHeaders;\n@@ -273,0 +274,1 @@\n+  st->print_cr(\"- compact_headers:                %d\", _compact_headers);\n@@ -1993,1 +1995,1 @@\n-  \/\/ ArchiveHeapWriter::precomputed_narrow_klass_shift. We enforce this encoding at runtime (see\n+  \/\/ ArchiveBuilder::precomputed_narrow_klass_shift. We enforce this encoding at runtime (see\n@@ -1997,1 +1999,1 @@\n-  const int archive_narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+  const int archive_narrow_klass_shift = ArchiveBuilder::precomputed_narrow_klass_shift;\n@@ -2385,0 +2387,8 @@\n+  if (compact_headers() != UseCompactObjectHeaders) {\n+    log_info(cds)(\"The shared archive file's UseCompactObjectHeaders setting (%s)\"\n+                  \" does not equal the current UseCompactObjectHeaders setting (%s).\",\n+                  _compact_headers          ? \"enabled\" : \"disabled\",\n+                  UseCompactObjectHeaders   ? \"enabled\" : \"disabled\");\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -190,0 +190,1 @@\n+  bool   _compact_headers;                        \/\/ value of UseCompactObjectHeaders\n@@ -258,0 +259,1 @@\n+  bool compact_headers()                   const { return _compact_headers; }\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1157,1 +1157,1 @@\n-          const int precomputed_narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+          const int precomputed_narrow_klass_shift = ArchiveBuilder::precomputed_narrow_klass_shift;\n@@ -1160,1 +1160,1 @@\n-            precomputed_narrow_klass_base, precomputed_narrow_klass_shift \/\/ precomputed encoding, see ArchiveHeapWriter\n+            precomputed_narrow_klass_base, precomputed_narrow_klass_shift \/\/ precomputed encoding, see ArchiveBuilder\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -252,0 +252,20 @@\n+\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciKlass::prototype_header_offset\n+juint ciKlass::prototype_header_offset() {\n+  assert(is_loaded(), \"must be loaded\");\n+\n+  VM_ENTRY_MARK;\n+  Klass* this_klass = get_Klass();\n+  return in_bytes(this_klass->prototype_header_offset());\n+}\n+\n+\/\/ ------------------------------------------------------------------\n+\/\/ ciKlass::prototype_header\n+uintptr_t ciKlass::prototype_header() {\n+  assert(is_loaded(), \"must be loaded\");\n+\n+  VM_ENTRY_MARK;\n+  Klass* this_klass = get_Klass();\n+  return (uintptr_t)this_klass->prototype_header().to_pointer();\n+}\n","filename":"src\/hotspot\/share\/ci\/ciKlass.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -132,0 +132,3 @@\n+\n+  juint prototype_header_offset();\n+  uintptr_t prototype_header();\n","filename":"src\/hotspot\/share\/ci\/ciKlass.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n-  static const int first_vtableStub_size =  64;\n+  static const int first_vtableStub_size = 64;\n","filename":"src\/hotspot\/share\/code\/vtableStubs.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -90,0 +90,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -1520,0 +1521,2 @@\n+  SlidingForwarding::initialize(heap_rs.region(), HeapRegion::GrainWords);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -213,0 +214,2 @@\n+  SlidingForwarding::begin();\n+\n@@ -225,0 +228,2 @@\n+  SlidingForwarding::end();\n+\n@@ -400,1 +405,2 @@\n-void G1FullCollector::phase2c_prepare_serial_compaction() {\n+template <bool ALT_FWD>\n+void G1FullCollector::phase2c_prepare_serial_compaction_impl() {\n@@ -425,1 +431,1 @@\n-  G1SerialRePrepareClosure re_prepare(serial_cp, dense_prefix_top);\n+  G1SerialRePrepareClosure<ALT_FWD> re_prepare(serial_cp, dense_prefix_top);\n@@ -438,1 +444,10 @@\n-void G1FullCollector::phase2d_prepare_humongous_compaction() {\n+void G1FullCollector::phase2c_prepare_serial_compaction() {\n+  if (UseAltGCForwarding) {\n+    phase2c_prepare_serial_compaction_impl<true>();\n+  } else {\n+    phase2c_prepare_serial_compaction_impl<false>();\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void G1FullCollector::phase2d_prepare_humongous_compaction_impl() {\n@@ -456,1 +471,1 @@\n-      uint num_regions = humongous_cp->forward_humongous(hr);\n+      uint num_regions = humongous_cp->forward_humongous<ALT_FWD>(hr);\n@@ -467,0 +482,8 @@\n+void G1FullCollector::phase2d_prepare_humongous_compaction() {\n+  if (UseAltGCForwarding) {\n+    phase2d_prepare_humongous_compaction_impl<true>();\n+  } else {\n+    phase2d_prepare_humongous_compaction_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -161,0 +161,2 @@\n+  template <bool ALT_FWD>\n+  void phase2c_prepare_serial_compaction_impl();\n@@ -162,0 +164,2 @@\n+  template <bool ALT_FWD>\n+  void phase2d_prepare_humongous_compaction_impl();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+template <bool ALT_FWD>\n@@ -44,1 +45,1 @@\n-  G1AdjustClosure* _adjust_closure;\n+  G1AdjustClosure<ALT_FWD>* _adjust_closure;\n@@ -46,1 +47,1 @@\n-  G1AdjustLiveClosure(G1AdjustClosure* cl) :\n+  G1AdjustLiveClosure(G1AdjustClosure<ALT_FWD>* cl) :\n@@ -65,1 +66,11 @@\n-    G1AdjustClosure cl(_collector);\n+    if (UseAltGCForwarding) {\n+      return do_heap_region_impl<true>(r);\n+    } else {\n+      return do_heap_region_impl<false>(r);\n+    }\n+  }\n+\n+private:\n+  template <bool ALT_FWD>\n+  bool do_heap_region_impl(HeapRegion* r) {\n+    G1AdjustClosure<ALT_FWD> cl(_collector);\n@@ -73,1 +84,1 @@\n-      G1AdjustLiveClosure adjust(&cl);\n+      G1AdjustLiveClosure<ALT_FWD> adjust(&cl);\n@@ -84,2 +95,1 @@\n-    _hrclaimer(collector->workers()),\n-    _adjust(collector) {\n+    _hrclaimer(collector->workers()) {\n@@ -89,1 +99,2 @@\n-void G1FullGCAdjustTask::work(uint worker_id) {\n+template <bool ALT_FWD>\n+void G1FullGCAdjustTask::work_impl(uint worker_id) {\n@@ -97,0 +108,1 @@\n+  G1AdjustClosure<ALT_FWD> adjust(collector());\n@@ -100,1 +112,1 @@\n-    _weak_proc_task.work(worker_id, &always_alive, &_adjust);\n+    _weak_proc_task.work(worker_id, &always_alive, &adjust);\n@@ -103,3 +115,3 @@\n-  CLDToOopClosure adjust_cld(&_adjust, ClassLoaderData::_claim_stw_fullgc_adjust);\n-  CodeBlobToOopClosure adjust_code(&_adjust, CodeBlobToOopClosure::FixRelocations);\n-  _root_processor.process_all_roots(&_adjust, &adjust_cld, &adjust_code);\n+  CLDToOopClosure adjust_cld(&adjust, ClassLoaderData::_claim_stw_fullgc_adjust);\n+  CodeBlobToOopClosure adjust_code(&adjust, CodeBlobToOopClosure::FixRelocations);\n+  _root_processor.process_all_roots(&adjust, &adjust_cld, &adjust_code);\n@@ -112,0 +124,8 @@\n+\n+void G1FullGCAdjustTask::work(uint worker_id) {\n+  if (UseAltGCForwarding) {\n+    work_impl<true>(worker_id);\n+  } else {\n+    work_impl<false>(worker_id);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.cpp","additions":31,"deletions":11,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-  G1AdjustClosure          _adjust;\n@@ -43,0 +42,2 @@\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -37,1 +38,2 @@\n-void G1FullGCCompactTask::G1CompactRegionClosure::clear_in_bitmap(oop obj) {\n+template <bool ALT_FWD>\n+void G1FullGCCompactTask::G1CompactRegionClosure<ALT_FWD>::clear_in_bitmap(oop obj) {\n@@ -42,1 +44,2 @@\n-size_t G1FullGCCompactTask::G1CompactRegionClosure::apply(oop obj) {\n+template <bool ALT_FWD>\n+size_t G1FullGCCompactTask::G1CompactRegionClosure<ALT_FWD>::apply(oop obj) {\n@@ -44,2 +47,2 @@\n-  if (obj->is_forwarded()) {\n-    G1FullGCCompactTask::copy_object_to_new_location(obj);\n+  if (SlidingForwarding::is_forwarded(obj)) {\n+    G1FullGCCompactTask::copy_object_to_new_location<ALT_FWD>(obj);\n@@ -54,0 +57,1 @@\n+template <bool ALT_FWD>\n@@ -55,2 +59,2 @@\n-  assert(obj->is_forwarded(), \"Sanity!\");\n-  assert(obj->forwardee() != obj, \"Object must have a new location\");\n+  assert(SlidingForwarding::is_forwarded(obj), \"Sanity!\");\n+  assert(SlidingForwarding::forwardee<ALT_FWD>(obj) != obj, \"Object must have a new location\");\n@@ -61,1 +65,1 @@\n-  HeapWord* destination = cast_from_oop<HeapWord*>(obj->forwardee());\n+  HeapWord* destination = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj));\n@@ -80,2 +84,7 @@\n-    G1CompactRegionClosure compact(collector()->mark_bitmap());\n-    hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    if (UseAltGCForwarding) {\n+      G1CompactRegionClosure<true> compact(collector()->mark_bitmap());\n+      hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    } else {\n+      G1CompactRegionClosure<false> compact(collector()->mark_bitmap());\n+      hr->apply_to_marked_objects(collector()->mark_bitmap(), &compact);\n+    }\n@@ -107,3 +116,2 @@\n-void G1FullGCCompactTask::humongous_compaction() {\n-  GCTraceTime(Debug, gc, phases) tm(\"Phase 4: Humonguous Compaction\", collector()->scope()->timer());\n-\n+template <bool ALT_FWD>\n+void G1FullGCCompactTask::humongous_compaction_impl() {\n@@ -112,1 +120,10 @@\n-    compact_humongous_obj(hr);\n+    compact_humongous_obj<ALT_FWD>(hr);\n+  }\n+}\n+\n+void G1FullGCCompactTask::humongous_compaction() {\n+  GCTraceTime(Debug, gc, phases) tm(\"Phase 4: Humonguous Compaction\", collector()->scope()->timer());\n+  if (UseAltGCForwarding) {\n+    humongous_compaction_impl<true>();\n+  } else {\n+    humongous_compaction_impl<false>();\n@@ -116,0 +133,1 @@\n+template <bool ALT_FWD>\n@@ -123,1 +141,1 @@\n-  HeapWord* destination = cast_from_oop<HeapWord*>(obj->forwardee());\n+  HeapWord* destination = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj));\n@@ -128,1 +146,1 @@\n-  copy_object_to_new_location(obj);\n+  copy_object_to_new_location<ALT_FWD>(obj);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":33,"deletions":15,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+  template <bool ALT_FWD>\n@@ -47,0 +48,1 @@\n+  template <bool ALT_FWD>\n@@ -49,0 +51,3 @@\n+  template <bool ALT_FWD>\n+  void humongous_compaction_impl();\n+\n@@ -60,0 +65,1 @@\n+  template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -95,0 +96,1 @@\n+template <bool ALT_FWD>\n@@ -105,2 +107,2 @@\n-    object->forward_to(cast_to_oop(_compaction_top));\n-    assert(object->is_forwarded(), \"must be forwarded\");\n+    SlidingForwarding::forward_to<ALT_FWD>(object, cast_to_oop(_compaction_top));\n+    assert(SlidingForwarding::is_forwarded(object), \"must be forwarded\");\n@@ -108,1 +110,1 @@\n-    assert(!object->is_forwarded(), \"must not be forwarded\");\n+    assert(SlidingForwarding::is_not_forwarded(object), \"must not be forwarded\");\n@@ -116,0 +118,3 @@\n+template void G1FullGCCompactionPoint::forward<true>(oop object, size_t size);\n+template void G1FullGCCompactionPoint::forward<false>(oop object, size_t size);\n+\n@@ -148,0 +153,1 @@\n+template <bool ALT_FWD>\n@@ -171,2 +177,2 @@\n-  obj->forward_to(cast_to_oop(dest_hr->bottom()));\n-  assert(obj->is_forwarded(), \"Object must be forwarded!\");\n+  SlidingForwarding::forward_to<ALT_FWD>(obj, cast_to_oop(dest_hr->bottom()));\n+  assert(SlidingForwarding::is_forwarded(obj), \"Object must be forwarded!\");\n@@ -183,0 +189,3 @@\n+template uint G1FullGCCompactionPoint::forward_humongous<true>(HeapRegion* hr);\n+template uint G1FullGCCompactionPoint::forward_humongous<false>(HeapRegion* hr);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":14,"deletions":5,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+  template <bool ALT_FWD>\n@@ -58,0 +59,1 @@\n+  template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -54,1 +55,2 @@\n-template <class T> inline void G1AdjustClosure::adjust_pointer(T* p) {\n+template <bool ALT_FWD>\n+template <class T> inline void G1AdjustClosure<ALT_FWD>::adjust_pointer(T* p) {\n@@ -68,2 +70,2 @@\n-  if (obj->is_forwarded()) {\n-    oop forwardee = obj->forwardee();\n+  if (SlidingForwarding::is_forwarded(obj)) {\n+    oop forwardee = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -77,2 +79,4 @@\n-inline void G1AdjustClosure::do_oop(oop* p)       { do_oop_work(p); }\n-inline void G1AdjustClosure::do_oop(narrowOop* p) { do_oop_work(p); }\n+template <bool ALT_FWD>\n+inline void G1AdjustClosure<ALT_FWD>::do_oop(oop* p)       { do_oop_work(p); }\n+template <bool ALT_FWD>\n+inline void G1AdjustClosure<ALT_FWD>::do_oop(narrowOop* p) { do_oop_work(p); }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.inline.hpp","additions":10,"deletions":6,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -107,1 +107,2 @@\n-G1FullGCPrepareTask::G1PrepareCompactLiveClosure::G1PrepareCompactLiveClosure(G1FullGCCompactionPoint* cp) :\n+template <bool ALT_FWD>\n+G1FullGCPrepareTask::G1PrepareCompactLiveClosure<ALT_FWD>::G1PrepareCompactLiveClosure(G1FullGCCompactionPoint* cp) :\n@@ -110,1 +111,2 @@\n-size_t G1FullGCPrepareTask::G1PrepareCompactLiveClosure::apply(oop object) {\n+template <bool ALT_FWD>\n+size_t G1FullGCPrepareTask::G1PrepareCompactLiveClosure<ALT_FWD>::apply(oop object) {\n@@ -112,1 +114,1 @@\n-  _cp->forward(object, size);\n+  _cp->forward<ALT_FWD>(object, size);\n@@ -118,2 +120,7 @@\n-    G1PrepareCompactLiveClosure prepare_compact(_cp);\n-    hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    if (UseAltGCForwarding) {\n+      G1PrepareCompactLiveClosure<true> prepare_compact(_cp);\n+      hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    } else {\n+      G1PrepareCompactLiveClosure<false> prepare_compact(_cp);\n+      hr->apply_to_marked_objects(_bitmap, &prepare_compact);\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.cpp","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+  template <bool ALT_FWD>\n@@ -103,0 +104,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -104,2 +105,3 @@\n-inline size_t G1SerialRePrepareClosure::apply(oop obj) {\n-  if (obj->is_forwarded()) {\n+template <bool ALT_FWD>\n+inline size_t G1SerialRePrepareClosure<ALT_FWD>::apply(oop obj) {\n+  if (SlidingForwarding::is_forwarded(obj)) {\n@@ -108,1 +110,1 @@\n-    if (cast_from_oop<HeapWord*>(obj->forwardee()) < _dense_prefix_top) {\n+    if (cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(obj)) < _dense_prefix_top) {\n@@ -115,1 +117,1 @@\n-  _cp->forward(obj, size);\n+  _cp->forward<ALT_FWD>(obj, size);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.inline.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -231,1 +231,1 @@\n-      forwardee = cast_to_oop(m.decode_pointer());\n+      forwardee = obj->forwardee(m);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1OopClosures.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -215,1 +215,1 @@\n-    obj = cast_to_oop(m.decode_pointer());\n+    obj = obj->forwardee(m);\n@@ -229,1 +229,1 @@\n-  assert(from_obj->is_objArray(), \"must be obj array\");\n+  assert(from_obj->forward_safe_klass()->is_objArray_klass(), \"must be obj array\");\n@@ -259,1 +259,1 @@\n-  assert(from_obj->is_objArray(), \"precondition\");\n+  assert(from_obj->forward_safe_klass()->is_objArray_klass(), \"precondition\");\n@@ -386,1 +386,1 @@\n-                                                  oop const old, size_t word_sz, uint age,\n+                                                  Klass* klass, size_t word_sz, uint age,\n@@ -390,1 +390,1 @@\n-    _g1h->gc_tracer_stw()->report_promotion_in_new_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+    _g1h->gc_tracer_stw()->report_promotion_in_new_plab_event(klass, word_sz * HeapWordSize, age,\n@@ -394,1 +394,1 @@\n-    _g1h->gc_tracer_stw()->report_promotion_outside_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+    _g1h->gc_tracer_stw()->report_promotion_outside_plab_event(klass, word_sz * HeapWordSize, age,\n@@ -401,1 +401,1 @@\n-                                                   oop old,\n+                                                   Klass* klass,\n@@ -424,1 +424,1 @@\n-      report_promotion_event(*dest_attr, old, word_sz, age, obj_ptr, node_index);\n+      report_promotion_event(*dest_attr, klass, word_sz, age, obj_ptr, node_index);\n@@ -461,1 +461,7 @@\n-  Klass* klass = old->klass();\n+  \/\/ NOTE: With compact headers, it is not safe to load the Klass* from o, because\n+  \/\/ that would access the mark-word, and the mark-word might change at any time by\n+  \/\/ concurrent promotion. The promoted mark-word would point to the forwardee, which\n+  \/\/ may not yet have completed copying. Therefore we must load the Klass* from\n+  \/\/ the mark-word that we have already loaded. This is safe, because we have checked\n+  \/\/ that this is not yet forwarded in the caller.\n+  Klass* klass = old->forward_safe_klass(old_mark);\n@@ -474,1 +480,1 @@\n-    obj_ptr = allocate_copy_slow(&dest_attr, old, word_sz, age, node_index);\n+    obj_ptr = allocate_copy_slow(&dest_attr, klass, word_sz, age, node_index);\n@@ -630,1 +636,1 @@\n-  oop forward_ptr = old->forward_to_atomic(old, m, memory_order_relaxed);\n+  oop forward_ptr = old->forward_to_self_atomic(m, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -176,1 +176,1 @@\n-                               oop old,\n+                               Klass* klass,\n@@ -211,1 +211,1 @@\n-                              oop const old, size_t word_sz, uint age,\n+                              Klass* klass, size_t word_sz, uint age,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -235,1 +235,2 @@\n-void MutableSpace::object_iterate(ObjectClosure* cl) {\n+template<bool COMPACT_HEADERS>\n+void MutableSpace::object_iterate_impl(ObjectClosure* cl) {\n@@ -244,3 +245,2 @@\n-    }\n-#ifdef ASSERT\n-    else {\n+      p += obj->size();\n+    } else {\n@@ -248,0 +248,8 @@\n+      if (COMPACT_HEADERS) {\n+        \/\/ It is safe to use the forwardee here. Parallel GC only uses\n+        \/\/ header-based forwarding during promotion. Full GC doesn't\n+        \/\/ use the object header for forwarding at all.\n+        p += obj->forwardee()->size();\n+      } else {\n+        p += obj->size();\n+      }\n@@ -249,2 +257,8 @@\n-#endif\n-    p += obj->size();\n+  }\n+}\n+\n+void MutableSpace::object_iterate(ObjectClosure* cl) {\n+  if (UseCompactObjectHeaders) {\n+    object_iterate_impl<true>(cl);\n+  } else {\n+    object_iterate_impl<false>(cl);\n","filename":"src\/hotspot\/share\/gc\/parallel\/mutableSpace.cpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -70,0 +70,3 @@\n+  template<bool COMPACT_HEADERS>\n+  void object_iterate_impl(ObjectClosure* cl);\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/mutableSpace.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -398,1 +398,3 @@\n-    HeapWord* test_addr = cast_from_oop<HeapWord*>(obj) + 1;\n+    \/\/ With compact headers, the objects can be one-word sized.\n+    size_t int_off = UseCompactObjectHeaders ? MIN2((size_t)1, obj->size() - 1) : 1;\n+    HeapWord* test_addr = cast_from_oop<HeapWord*>(obj) + int_off;\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -290,1 +290,1 @@\n-  assert(old->is_objArray(), \"invariant\");\n+  assert(old->forward_safe_klass()->is_objArray_klass(), \"invariant\");\n@@ -328,1 +328,1 @@\n-  if (obj->forward_to_atomic(obj, obj_mark) == nullptr) {\n+  if (obj->forward_to_self_atomic(obj_mark) == nullptr) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -108,1 +108,1 @@\n-  inline void promotion_trace_event(oop new_obj, oop old_obj, size_t obj_size,\n+  inline void promotion_trace_event(oop new_obj, Klass* klass, size_t obj_size,\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-inline void PSPromotionManager::promotion_trace_event(oop new_obj, oop old_obj,\n+inline void PSPromotionManager::promotion_trace_event(oop new_obj, Klass* klass,\n@@ -79,1 +79,1 @@\n-        gc_tracer->report_promotion_in_new_plab_event(old_obj->klass(), obj_bytes,\n+        gc_tracer->report_promotion_in_new_plab_event(klass, obj_bytes,\n@@ -86,1 +86,1 @@\n-        gc_tracer->report_promotion_outside_plab_event(old_obj->klass(), obj_bytes,\n+        gc_tracer->report_promotion_outside_plab_event(klass, obj_bytes,\n@@ -155,1 +155,1 @@\n-    return cast_to_oop(m.decode_pointer());\n+    return o->forwardee(m);\n@@ -171,1 +171,8 @@\n-  size_t new_obj_size = o->size();\n+  \/\/ NOTE: With compact headers, it is not safe to load the Klass* from o, because\n+  \/\/ that would access the mark-word, and the mark-word might change at any time by\n+  \/\/ concurrent promotion. The promoted mark-word would point to the forwardee, which\n+  \/\/ may not yet have completed copying. Therefore we must load the Klass* from\n+  \/\/ the mark-word that we have already loaded. This is safe, because we have checked\n+  \/\/ that this is not yet forwarded in the caller.\n+  Klass* klass = o->forward_safe_klass(test_mark);\n+  size_t new_obj_size = o->size_given_klass(klass);\n@@ -186,1 +193,1 @@\n-          promotion_trace_event(new_obj, o, new_obj_size, age, false, nullptr);\n+          promotion_trace_event(new_obj, klass, new_obj_size, age, false, nullptr);\n@@ -196,1 +203,1 @@\n-            promotion_trace_event(new_obj, o, new_obj_size, age, false, &_young_lab);\n+            promotion_trace_event(new_obj, klass, new_obj_size, age, false, &_young_lab);\n@@ -222,1 +229,1 @@\n-          promotion_trace_event(new_obj, o, new_obj_size, age, true, nullptr);\n+          promotion_trace_event(new_obj, klass, new_obj_size, age, true, nullptr);\n@@ -232,1 +239,1 @@\n-            promotion_trace_event(new_obj, o, new_obj_size, age, true, &_old_lab);\n+            promotion_trace_event(new_obj, klass, new_obj_size, age, true, &_old_lab);\n@@ -255,3 +262,15 @@\n-  \/\/ Parallel GC claims with a release - so other threads might access this object\n-  \/\/ after claiming and they should see the \"completed\" object.\n-  ContinuationGCSupport::transform_stack_chunk(new_obj);\n+  if (UseCompactObjectHeaders) {\n+    \/\/ The copy above is not atomic. Make sure we have seen the proper mark\n+    \/\/ and re-install it into the copy, so that Klass* is guaranteed to be correct.\n+    markWord mark = o->mark();\n+    if (!mark.is_marked()) {\n+      new_obj->set_mark(mark);\n+      ContinuationGCSupport::transform_stack_chunk(new_obj);\n+    } else {\n+      \/\/ If we copied a mark-word that indicates 'forwarded' state, the object\n+      \/\/ installation would not succeed. We cannot access Klass* anymore either.\n+      \/\/ Skip the transformation.\n+    }\n+  } else {\n+    ContinuationGCSupport::transform_stack_chunk(new_obj);\n+  }\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.inline.hpp","additions":31,"deletions":12,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -879,1 +879,1 @@\n-        obj->init_mark();\n+        obj->forward_safe_init_mark();\n@@ -903,1 +903,1 @@\n-  old->forward_to(old);\n+  old->forward_to_self();\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -92,0 +93,2 @@\n+  SlidingForwarding::begin();\n+\n@@ -104,0 +107,2 @@\n+  SlidingForwarding::end();\n+\n@@ -253,9 +258,23 @@\n-  CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n-  gch->process_roots(SerialHeap::SO_AllCodeCache,\n-                     &adjust_pointer_closure,\n-                     &adjust_cld_closure,\n-                     &adjust_cld_closure,\n-                     &code_closure);\n-\n-  gch->gen_process_weak_roots(&adjust_pointer_closure);\n-\n+  if (UseAltGCForwarding) {\n+    AdjustPointerClosure<true> adjust_pointer_closure;\n+    CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+    CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+    gch->process_roots(SerialHeap::SO_AllCodeCache,\n+                       &adjust_pointer_closure,\n+                       &adjust_cld_closure,\n+                       &adjust_cld_closure,\n+                       &code_closure);\n+\n+    gch->gen_process_weak_roots(&adjust_pointer_closure);\n+  } else {\n+    AdjustPointerClosure<false> adjust_pointer_closure;\n+    CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+    CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+    gch->process_roots(SerialHeap::SO_AllCodeCache,\n+                       &adjust_pointer_closure,\n+                       &adjust_cld_closure,\n+                       &adjust_cld_closure,\n+                       &code_closure);\n+\n+    gch->gen_process_weak_roots(&adjust_pointer_closure);\n+  }\n","filename":"src\/hotspot\/share\/gc\/serial\/genMarkSweep.cpp","additions":28,"deletions":9,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -63,1 +63,0 @@\n-CLDToOopClosure    MarkSweep::adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n@@ -167,0 +166,4 @@\n+  \/\/ Do the transform while we still have the header intact,\n+  \/\/ which might include important class information.\n+  ContinuationGCSupport::transform_stack_chunk(obj);\n+\n@@ -170,3 +173,1 @@\n-  obj->set_mark(markWord::prototype().set_marked());\n-\n-  ContinuationGCSupport::transform_stack_chunk(obj);\n+  obj->set_mark(obj->prototype_mark().set_marked());\n@@ -195,3 +196,2 @@\n-AdjustPointerClosure MarkSweep::adjust_pointer_closure;\n-\n-void MarkSweep::adjust_marks() {\n+template <bool ALT_FWD>\n+void MarkSweep::adjust_marks_impl() {\n@@ -200,1 +200,1 @@\n-    PreservedMarks::adjust_preserved_mark(_preserved_marks + i);\n+    PreservedMarks::adjust_preserved_mark<ALT_FWD>(_preserved_marks + i);\n@@ -207,0 +207,8 @@\n+void MarkSweep::adjust_marks() {\n+  if (UseAltGCForwarding) {\n+    adjust_marks_impl<true>();\n+  } else {\n+    adjust_marks_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.cpp","additions":16,"deletions":8,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -54,1 +54,0 @@\n-class AdjustPointerClosure;\n@@ -88,1 +87,0 @@\n-  friend class AdjustPointerClosure;\n@@ -128,2 +126,0 @@\n-  static AdjustPointerClosure adjust_pointer_closure;\n-  static CLDToOopClosure      adjust_cld_closure;\n@@ -145,0 +141,1 @@\n+  template <bool ALT_FWD>\n@@ -149,1 +146,2 @@\n-  template <class T> static inline void adjust_pointer(T* p);\n+  template <bool ALT_FWD, class T>\n+  static void adjust_pointer(T* p);\n@@ -155,0 +153,3 @@\n+  template <bool ALT_FWD>\n+  static void adjust_marks_impl();\n+\n@@ -182,0 +183,1 @@\n+template <bool ALT_FWD>\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.hpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,0 +34,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -42,1 +43,2 @@\n-template <class T> inline void MarkSweep::adjust_pointer(T* p) {\n+template <bool ALT_FWD, class T>\n+inline void MarkSweep::adjust_pointer(T* p) {\n@@ -48,2 +50,2 @@\n-    if (obj->is_forwarded()) {\n-      oop new_obj = obj->forwardee();\n+    if (SlidingForwarding::is_forwarded(obj)) {\n+      oop new_obj = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -56,0 +58,1 @@\n+template <bool ALT_FWD>\n@@ -57,3 +60,3 @@\n-void AdjustPointerClosure::do_oop_work(T* p)           { MarkSweep::adjust_pointer(p); }\n-inline void AdjustPointerClosure::do_oop(oop* p)       { do_oop_work(p); }\n-inline void AdjustPointerClosure::do_oop(narrowOop* p) { do_oop_work(p); }\n+void AdjustPointerClosure<ALT_FWD>::do_oop_work(T* p)           { MarkSweep::adjust_pointer<ALT_FWD>(p); }\n+template <bool ALT_FWD>\n+inline void AdjustPointerClosure<ALT_FWD>::do_oop(oop* p)       { do_oop_work(p); }\n@@ -61,0 +64,4 @@\n+template <bool ALT_FWD>\n+inline void AdjustPointerClosure<ALT_FWD>::do_oop(narrowOop* p) { do_oop_work(p); }\n+\n+template <bool ALT_FWD>\n@@ -62,1 +69,2 @@\n-  return obj->oop_iterate_size(&MarkSweep::adjust_pointer_closure);\n+  AdjustPointerClosure<ALT_FWD> adjust_pointer_closure;\n+  return obj->oop_iterate_size(&adjust_pointer_closure);\n","filename":"src\/hotspot\/share\/gc\/serial\/markSweep.inline.hpp","additions":16,"deletions":8,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -232,1 +232,3 @@\n-  if (!Metaspace::contains(object->klass_raw())) {\n+  \/\/ With compact headers, we can't safely access the class, due\n+  \/\/ to possibly forwarded objects.\n+  if (!UseCompactObjectHeaders && !Metaspace::contains(object->klass_raw())) {\n@@ -404,0 +406,7 @@\n+\/\/ Returns the header size in words aligned to the requirements of the\n+\/\/ array object type.\n+static int int_array_header_size() {\n+  size_t typesize_in_bytes = arrayOopDesc::header_size_in_bytes();\n+  return (int)align_up(typesize_in_bytes, HeapWordSize)\/HeapWordSize;\n+}\n+\n@@ -413,1 +422,1 @@\n-  size_t max_int_size = typeArrayOopDesc::header_size(T_INT) +\n+  size_t max_int_size = int_array_header_size() +\n@@ -420,1 +429,1 @@\n-  return align_object_offset(arrayOopDesc::header_size(T_INT)); \/\/ align to Long\n+  return align_object_offset(int_array_header_size()); \/\/ align to Long\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -311,1 +311,1 @@\n-  static constexpr size_t min_dummy_object_size() {\n+  static size_t min_dummy_object_size() {\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -695,2 +695,6 @@\n-          constraint(GCCardSizeInBytesConstraintFunc,AtParse)\n-  \/\/ end of GC_FLAGS\n+          constraint(GCCardSizeInBytesConstraintFunc,AtParse)               \\\n+                                                                            \\\n+  product(bool, UseAltGCForwarding, false, EXPERIMENTAL,                    \\\n+          \"Use alternative GC forwarding that preserves object headers\")    \\\n+\n+\/\/ end of GC_FLAGS\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -133,0 +134,2 @@\n+  SlidingForwarding::initialize(_reserved, SpaceAlignment \/ HeapWordSize);\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/genCollectedHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -384,1 +384,3 @@\n-  oopDesc::set_klass_gap(mem, 0);\n+  if (!UseCompactObjectHeaders) {\n+    oopDesc::set_klass_gap(mem, 0);\n+  }\n@@ -390,2 +392,0 @@\n-  \/\/ May be bootstrapping\n-  oopDesc::set_mark(mem, markWord::prototype());\n@@ -395,1 +395,6 @@\n-  oopDesc::release_set_klass(mem, _klass);\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, _klass->prototype_header());\n+  } else {\n+    oopDesc::set_mark(mem, markWord::prototype());\n+    oopDesc::release_set_klass(mem, _klass);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -43,4 +44,6 @@\n-void PreservedMarks::adjust_preserved_mark(PreservedMark* elem) {\n-  oop obj = elem->get_oop();\n-  if (obj->is_forwarded()) {\n-    elem->set_oop(obj->forwardee());\n+template <bool ALT_FWD>\n+void PreservedMarks::adjust_during_full_gc_impl() {\n+  StackIterator<PreservedMark, mtGC> iter(_stack);\n+  while (!iter.is_empty()) {\n+    PreservedMark* elem = iter.next_addr();\n+    adjust_preserved_mark<ALT_FWD>(elem);\n@@ -51,4 +54,4 @@\n-  StackIterator<PreservedMark, mtGC> iter(_stack);\n-  while (!iter.is_empty()) {\n-    PreservedMark* elem = iter.next_addr();\n-    adjust_preserved_mark(elem);\n+  if (UseAltGCForwarding) {\n+    adjust_during_full_gc_impl<true>();\n+  } else {\n+    adjust_during_full_gc_impl<false>();\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.cpp","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -58,0 +58,3 @@\n+  template <bool ALT_FWD>\n+  void adjust_during_full_gc_impl();\n+\n@@ -68,1 +71,2 @@\n-  static void adjust_preserved_mark(PreservedMark* elem);\n+  template <bool ALT_FWD>\n+  static inline void adjust_preserved_mark(PreservedMark* elem);\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -63,0 +64,8 @@\n+template <bool ALT_FWD>\n+inline void PreservedMarks::adjust_preserved_mark(PreservedMark* elem) {\n+  oop obj = elem->get_oop();\n+  if (obj->is_forwarded()) {\n+    elem->set_oop(SlidingForwarding::forwardee<ALT_FWD>(obj));\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.inline.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -0,0 +1,123 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+\n+\/\/ We cannot use 0, because that may already be a valid base address in zero-based heaps.\n+\/\/ 0x1 is safe because heap base addresses must be aligned by much larger alignment\n+HeapWord* const SlidingForwarding::UNUSED_BASE = reinterpret_cast<HeapWord*>(0x1);\n+\n+HeapWord* SlidingForwarding::_heap_start = nullptr;\n+size_t SlidingForwarding::_region_size_words = 0;\n+size_t SlidingForwarding::_heap_start_region_bias = 0;\n+size_t SlidingForwarding::_num_regions = 0;\n+uint SlidingForwarding::_region_size_bytes_shift = 0;\n+uintptr_t SlidingForwarding::_region_mask = 0;\n+HeapWord** SlidingForwarding::_biased_bases[SlidingForwarding::NUM_TARGET_REGIONS] = { nullptr, nullptr };\n+HeapWord** SlidingForwarding::_bases_table = nullptr;\n+SlidingForwarding::FallbackTable* SlidingForwarding::_fallback_table = nullptr;\n+\n+void SlidingForwarding::initialize(MemRegion heap, size_t region_size_words) {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    _heap_start = heap.start();\n+\n+    \/\/ If the heap is small enough to fit directly into the available offset bits,\n+    \/\/ and we are running Serial GC, we can treat the whole heap as a single region\n+    \/\/ if it happens to be aligned to allow biasing.\n+    size_t rounded_heap_size = round_up_power_of_2(heap.byte_size());\n+\n+    if (UseSerialGC && (heap.word_size() <= (1 << NUM_OFFSET_BITS)) &&\n+        is_aligned((uintptr_t)_heap_start, rounded_heap_size)) {\n+      _num_regions = 1;\n+      _region_size_words = heap.word_size();\n+      _region_size_bytes_shift = log2i_exact(rounded_heap_size);\n+    } else {\n+      _num_regions = align_up(pointer_delta(heap.end(), heap.start()), region_size_words) \/ region_size_words;\n+      _region_size_words = region_size_words;\n+      _region_size_bytes_shift = log2i_exact(_region_size_words) + LogHeapWordSize;\n+    }\n+    _heap_start_region_bias = (uintptr_t)_heap_start >> _region_size_bytes_shift;\n+    _region_mask = ~((uintptr_t(1) << _region_size_bytes_shift) - 1);\n+\n+    guarantee((_heap_start_region_bias << _region_size_bytes_shift) == (uintptr_t)_heap_start, \"must be aligned: _heap_start_region_bias: \" SIZE_FORMAT \", _region_size_byte_shift: %u, _heap_start: \" PTR_FORMAT, _heap_start_region_bias, _region_size_bytes_shift, p2i(_heap_start));\n+\n+    assert(_region_size_words >= 1, \"regions must be at least a word large\");\n+    assert(_bases_table == nullptr, \"should not be initialized yet\");\n+    assert(_fallback_table == nullptr, \"should not be initialized yet\");\n+  }\n+#endif\n+}\n+\n+void SlidingForwarding::begin() {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    assert(_bases_table == nullptr, \"should not be initialized yet\");\n+    assert(_fallback_table == nullptr, \"should not be initialized yet\");\n+\n+    size_t max = _num_regions * NUM_TARGET_REGIONS;\n+    _bases_table = NEW_C_HEAP_ARRAY(HeapWord*, max, mtGC);\n+    HeapWord** biased_start = _bases_table - _heap_start_region_bias;\n+    _biased_bases[0] = biased_start;\n+    _biased_bases[1] = biased_start + _num_regions;\n+    for (size_t i = 0; i < max; i++) {\n+      _bases_table[i] = UNUSED_BASE;\n+    }\n+  }\n+#endif\n+}\n+\n+void SlidingForwarding::end() {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    assert(_bases_table != nullptr, \"should be initialized\");\n+    FREE_C_HEAP_ARRAY(HeapWord*, _bases_table);\n+    _bases_table = nullptr;\n+    delete _fallback_table;\n+    _fallback_table = nullptr;\n+  }\n+#endif\n+}\n+\n+void SlidingForwarding::fallback_forward_to(HeapWord* from, HeapWord* to) {\n+  if (_fallback_table == nullptr) {\n+    _fallback_table = new (mtGC) FallbackTable();\n+  }\n+  _fallback_table->put_when_absent(from, to);\n+}\n+\n+HeapWord* SlidingForwarding::fallback_forwardee(HeapWord* from) {\n+  assert(_fallback_table != nullptr, \"fallback table must be present\");\n+  HeapWord** found = _fallback_table->get(from);\n+  if (found != nullptr) {\n+    return *found;\n+  } else {\n+    return nullptr;\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.cpp","additions":123,"deletions":0,"binary":false,"changes":123,"status":"added"},{"patch":"@@ -0,0 +1,181 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHARED_SLIDINGFORWARDING_HPP\n+#define SHARE_GC_SHARED_SLIDINGFORWARDING_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/memRegion.hpp\"\n+#include \"oops\/markWord.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/fastHash.hpp\"\n+#include \"utilities\/resourceHash.hpp\"\n+\n+\/**\n+ * SlidingForwarding is a method to store forwarding information in a compressed form into the object header,\n+ * that has been specifically designed for sliding compaction GCs and compact object headers. With compact object\n+ * headers, we store the compressed class pointer in the header, which would be overwritten by full forwarding\n+ * pointer, if we allow the legacy forwarding code to act. This would lose the class information for the object,\n+ * which is required later in GC cycle to iterate the reference fields and get the object size for copying.\n+ *\n+ * SlidingForwarding requires only small side tables and guarantees constant-time access and modification.\n+ *\n+ * The idea is to use a pointer compression scheme very similar to the one that is used for compressed oops.\n+ * We divide the heap into number of logical regions. Each region spans maximum of 2^NUM_OFFSET_BITS words.\n+ *\n+ * The key advantage of sliding compaction for encoding efficiency: it can forward objects from one region to a\n+ * maximum of two regions. This is an intuitive property: when we slide the compact region full of data, it can\n+ * only span two adjacent regions. This property allows us to use the off-side table to record the addresses of\n+ * two target regions. The table holds N*2 entries for N logical regions. For each region, it gives the base\n+ * address of the two target regions, or a special placeholder if not used. A single bit in forwarding would\n+ * indicate to which of the two \"to\" regions the object is forwarded into.\n+ *\n+ * This encoding efficiency allows to store the forwarding information in the object header _together_ with the\n+ * compressed class pointer.\n+ *\n+ * When recording the sliding forwarding, the mark word would look roughly like this:\n+ *\n+ *   64                              32                                0\n+ *    [................................OOOOOOOOOOOOOOOOOOOOOOOOOOOOAFTT]\n+ *                                                                    ^----- normal lock bits, would record \"object is forwarded\"\n+ *                                                                  ^------- fallback bit (explained below)\n+ *                                                                 ^-------- alternate region select\n+ *                                     ^------------------------------------ in-region offset\n+ *     ^-------------------------------------------------------------------- protected area, *not touched* by this code, useful for\n+ *                                                                           compressed class pointer with compact object headers\n+ *\n+ * Adding a forwarding then generally works as follows:\n+ *   1. Compute the \"to\" offset in the \"to\" region, this gives \"offset\".\n+ *   2. Check if the primary \"from\" offset at base table contains \"to\" region base, use it.\n+ *      If not usable, continue to next step. If usable, set \"alternate\" = \"false\" and jump to (4).\n+ *   3. Check if the alternate \"from\" offset at base table contains \"to\" region base, use it.\n+ *      This gives us \"alternate\" = \"true\". This should always complete for sliding forwarding.\n+ *   4. Compute the mark word from \"offset\" and \"alternate\", write it out\n+ *\n+ * Similarly, looking up the target address, given an original object address generally works as follows:\n+ *   1. Load the mark from object, and decode \"offset\" and \"alternate\" from there\n+ *   2. Compute the \"from\" base offset from the object\n+ *   3. Look up \"to\" region base from the base table either at primary or alternate indices, using \"alternate\" flag\n+ *   4. Compute the \"to\" address from \"to\" region base and \"offset\"\n+ *\n+ * This algorithm is broken by G1 last-ditch serial compaction: there, object from a single region can be\n+ * forwarded to multiple, more than two regions. To deal with that, we initialize a fallback-hashtable for\n+ * storing those extra forwardings, and set another bit in the header to indicate that the forwardee is not\n+ * encoded but should be looked-up in the hashtable. G1 serial compaction is not very common - it is the\n+ * last-last-ditch GC that is used when the JVM is scrambling to squeeze more space out of the heap, and at\n+ * that point, ultimate performance is no longer the main concern.\n+ *\/\n+class SlidingForwarding : public AllStatic {\n+private:\n+\n+  \/*\n+   * A simple hash-table that acts as fallback for the sliding forwarding.\n+   * This is used in the case of G1 serial compaction, which violates the\n+   * assumption of sliding forwarding that each object of any region is only\n+   * ever forwarded to one of two target regions. At this point, the GC is\n+   * scrambling to free up more Java heap memory, and therefore performance\n+   * is not the major concern.\n+   *\n+   * The implementation is a straightforward open hashtable.\n+   * It is a single-threaded (not thread-safe) implementation, and that\n+   * is sufficient because G1 serial compaction is single-threaded.\n+   *\/\n+  inline static unsigned hash(HeapWord* const& from) {\n+    uint64_t val = reinterpret_cast<uint64_t>(from);\n+    uint64_t hash = FastHash::get_hash64(val, UCONST64(0xAAAAAAAAAAAAAAAA));\n+    return checked_cast<unsigned>(hash >> 32);\n+  }\n+  inline static bool equals(HeapWord* const& lhs, HeapWord* const& rhs) {\n+    return lhs == rhs;\n+  }\n+  typedef ResourceHashtable<HeapWord* \/* key-type *\/, HeapWord* \/* value-type *\/,\n+                            1024 \/* size *\/, AnyObj::C_HEAP \/* alloc-type *\/, mtGC,\n+                            SlidingForwarding::hash, SlidingForwarding::equals> FallbackTable;\n+\n+  static const uintptr_t MARK_LOWER_HALF_MASK = right_n_bits(32);\n+\n+  \/\/ We need the lowest two bits to indicate a forwarded object.\n+  \/\/ The next bit indicates that the forwardee should be looked-up in a fallback-table.\n+  static const int FALLBACK_SHIFT = markWord::lock_bits;\n+  static const int FALLBACK_BITS = 1;\n+  static const int FALLBACK_MASK = right_n_bits(FALLBACK_BITS) << FALLBACK_SHIFT;\n+\n+  \/\/ Next bit selects the target region\n+  static const int ALT_REGION_SHIFT = FALLBACK_SHIFT + FALLBACK_BITS;\n+  static const int ALT_REGION_BITS = 1;\n+  \/\/ This will be \"2\" always, but expose it as named constant for clarity\n+  static const size_t NUM_TARGET_REGIONS = 1 << ALT_REGION_BITS;\n+\n+  \/\/ The offset bits start then\n+  static const int OFFSET_BITS_SHIFT = ALT_REGION_SHIFT + ALT_REGION_BITS;\n+\n+  \/\/ How many bits we use for the offset\n+  static const int NUM_OFFSET_BITS = 32 - OFFSET_BITS_SHIFT;\n+\n+  \/\/ Indicates an unused base address in the target base table.\n+  static HeapWord* const UNUSED_BASE;\n+\n+  static HeapWord*      _heap_start;\n+  static size_t         _region_size_words;\n+\n+  static size_t         _heap_start_region_bias;\n+  static size_t         _num_regions;\n+  static uint           _region_size_bytes_shift;\n+  static uintptr_t      _region_mask;\n+\n+  \/\/ The target base table memory.\n+  static HeapWord**     _bases_table;\n+  \/\/ Entries into the target base tables, biased to the start of the heap.\n+  static HeapWord**     _biased_bases[NUM_TARGET_REGIONS];\n+\n+  static FallbackTable* _fallback_table;\n+\n+  static inline size_t biased_region_index_containing(HeapWord* addr);\n+\n+  static inline uintptr_t encode_forwarding(HeapWord* from, HeapWord* to);\n+  static inline HeapWord* decode_forwarding(HeapWord* from, uintptr_t encoded);\n+\n+  static void fallback_forward_to(HeapWord* from, HeapWord* to);\n+  static HeapWord* fallback_forwardee(HeapWord* from);\n+\n+  static inline void forward_to_impl(oop from, oop to);\n+  static inline oop forwardee_impl(oop from);\n+\n+public:\n+  static void initialize(MemRegion heap, size_t region_size_words);\n+\n+  static void begin();\n+  static void end();\n+\n+  static inline bool is_forwarded(oop obj);\n+  static inline bool is_not_forwarded(oop obj);\n+\n+  template <bool ALT_FWD>\n+  static inline void forward_to(oop from, oop to);\n+  template <bool ALT_FWD>\n+  static inline oop forwardee(oop from);\n+};\n+\n+#endif \/\/ SHARE_GC_SHARED_SLIDINGFORWARDING_HPP\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.hpp","additions":181,"deletions":0,"binary":false,"changes":181,"status":"added"},{"patch":"@@ -0,0 +1,171 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef SHARE_GC_SHARED_SLIDINGFORWARDING_INLINE_HPP\n+#define SHARE_GC_SHARED_SLIDINGFORWARDING_INLINE_HPP\n+\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n+#include \"oops\/markWord.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+inline bool SlidingForwarding::is_forwarded(oop obj) {\n+  return obj->is_forwarded();\n+}\n+\n+inline bool SlidingForwarding::is_not_forwarded(oop obj) {\n+  return !obj->is_forwarded();\n+}\n+\n+size_t SlidingForwarding::biased_region_index_containing(HeapWord* addr) {\n+  return (uintptr_t)addr >> _region_size_bytes_shift;\n+}\n+\n+uintptr_t SlidingForwarding::encode_forwarding(HeapWord* from, HeapWord* to) {\n+  static_assert(NUM_TARGET_REGIONS == 2, \"Only implemented for this amount\");\n+\n+  size_t from_reg_idx = biased_region_index_containing(from);\n+  HeapWord* to_region_base = (HeapWord*)((uintptr_t)to & _region_mask);\n+\n+  HeapWord** base = &_biased_bases[0][from_reg_idx];\n+  uintptr_t alternate = 0;\n+  if (*base == to_region_base) {\n+    \/\/ Primary is good\n+  } else if (*base == UNUSED_BASE) {\n+    \/\/ Primary is free\n+    *base = to_region_base;\n+  } else {\n+    base = &_biased_bases[1][from_reg_idx];\n+    if (*base == to_region_base) {\n+      \/\/ Alternate is good\n+    } else if (*base == UNUSED_BASE) {\n+      \/\/ Alternate is free\n+      *base = to_region_base;\n+    } else {\n+      \/\/ Both primary and alternate are not fitting\n+      \/\/ This happens only in the following rare situations:\n+      \/\/ - In Serial GC, sometimes when compact-top switches spaces, because the\n+      \/\/   region boudaries are virtual and objects can cross regions\n+      \/\/ - In G1 serial compaction, because tails of various compaction chains\n+      \/\/   are distributed across the remainders of already compacted regions.\n+      return (1 << FALLBACK_SHIFT) | markWord::marked_value;\n+    }\n+    alternate = 1;\n+  }\n+\n+  size_t offset = pointer_delta(to, to_region_base);\n+  assert(offset < _region_size_words, \"Offset should be within the region. from: \" PTR_FORMAT\n+         \", to: \" PTR_FORMAT \", to_region_base: \" PTR_FORMAT \", offset: \" SIZE_FORMAT,\n+         p2i(from), p2i(to), p2i(to_region_base), offset);\n+\n+  uintptr_t encoded = (offset << OFFSET_BITS_SHIFT) |\n+                      (alternate << ALT_REGION_SHIFT) |\n+                      markWord::marked_value;\n+\n+  assert(to == decode_forwarding(from, encoded), \"must be reversible\");\n+  assert((encoded & ~MARK_LOWER_HALF_MASK) == 0, \"must encode to lowest 32 bits\");\n+  return encoded;\n+}\n+\n+HeapWord* SlidingForwarding::decode_forwarding(HeapWord* from, uintptr_t encoded) {\n+  assert((encoded & markWord::lock_mask_in_place) == markWord::marked_value, \"must be marked as forwarded\");\n+  assert((encoded & FALLBACK_MASK) == 0, \"must not be fallback-forwarded\");\n+  assert((encoded & ~MARK_LOWER_HALF_MASK) == 0, \"must decode from lowest 32 bits\");\n+  size_t alternate = (encoded >> ALT_REGION_SHIFT) & right_n_bits(ALT_REGION_BITS);\n+  assert(alternate < NUM_TARGET_REGIONS, \"Sanity\");\n+  uintptr_t offset = (encoded >> OFFSET_BITS_SHIFT);\n+\n+  size_t from_idx = biased_region_index_containing(from);\n+  HeapWord* base = _biased_bases[alternate][from_idx];\n+  assert(base != UNUSED_BASE, \"must not be unused base\");\n+  HeapWord* decoded = base + offset;\n+  assert(decoded >= _heap_start,\n+         \"Address must be above heap start. encoded: \" INTPTR_FORMAT \", alt_region: \" SIZE_FORMAT \", base: \" PTR_FORMAT,\n+         encoded, alternate, p2i(base));\n+\n+  return decoded;\n+}\n+\n+inline void SlidingForwarding::forward_to_impl(oop from, oop to) {\n+  assert(_bases_table != nullptr, \"call begin() before forwarding\");\n+\n+  markWord from_header = from->mark();\n+  if (from_header.has_displaced_mark_helper()) {\n+    from_header = from_header.displaced_mark_helper();\n+  }\n+\n+  HeapWord* from_hw = cast_from_oop<HeapWord*>(from);\n+  HeapWord* to_hw   = cast_from_oop<HeapWord*>(to);\n+  uintptr_t encoded = encode_forwarding(from_hw, to_hw);\n+  markWord new_header = markWord((from_header.value() & ~MARK_LOWER_HALF_MASK) | encoded);\n+  from->set_mark(new_header);\n+\n+  if ((encoded & FALLBACK_MASK) != 0) {\n+    fallback_forward_to(from_hw, to_hw);\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+inline void SlidingForwarding::forward_to(oop obj, oop fwd) {\n+#ifdef _LP64\n+  if (ALT_FWD) {\n+    assert(_bases_table != nullptr, \"expect sliding forwarding initialized\");\n+    forward_to_impl(obj, fwd);\n+    assert(forwardee<ALT_FWD>(obj) == fwd, \"must be forwarded to correct forwardee\");\n+  } else\n+#endif\n+  {\n+    obj->forward_to(fwd);\n+  }\n+}\n+\n+inline oop SlidingForwarding::forwardee_impl(oop from) {\n+  assert(_bases_table != nullptr, \"call begin() before asking for forwarding\");\n+\n+  markWord header = from->mark();\n+  HeapWord* from_hw = cast_from_oop<HeapWord*>(from);\n+  if ((header.value() & FALLBACK_MASK) != 0) {\n+    HeapWord* to = fallback_forwardee(from_hw);\n+    return cast_to_oop(to);\n+  }\n+  uintptr_t encoded = header.value() & MARK_LOWER_HALF_MASK;\n+  HeapWord* to = decode_forwarding(from_hw, encoded);\n+  return cast_to_oop(to);\n+}\n+\n+template <bool ALT_FWD>\n+inline oop SlidingForwarding::forwardee(oop obj) {\n+#ifdef _LP64\n+  if (ALT_FWD) {\n+    assert(_bases_table != nullptr, \"expect sliding forwarding initialized\");\n+    return forwardee_impl(obj);\n+  } else\n+#endif\n+  {\n+    return obj->forwardee();\n+  }\n+}\n+\n+#endif \/\/ SHARE_GC_SHARED_SLIDINGFORWARDING_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shared\/slidingForwarding.inline.hpp","additions":171,"deletions":0,"binary":false,"changes":171,"status":"added"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -117,1 +118,1 @@\n-\n+template <bool ALT_FWD>\n@@ -141,1 +142,1 @@\n-    q->forward_to(cast_to_oop(compact_top));\n+    SlidingForwarding::forward_to<ALT_FWD>(q, cast_to_oop(compact_top));\n@@ -147,1 +148,1 @@\n-    assert(!q->is_forwarded(), \"should not be forwarded\");\n+    assert(SlidingForwarding::is_not_forwarded(q), \"should not be forwarded\");\n@@ -161,1 +162,2 @@\n-void ContiguousSpace::prepare_for_compaction(CompactPoint* cp) {\n+template <bool ALT_FWD>\n+void ContiguousSpace::prepare_for_compaction_impl(CompactPoint* cp) {\n@@ -193,1 +195,1 @@\n-      compact_top = cp->space->forward(cast_to_oop(cur_obj), size, cp, compact_top);\n+      compact_top = cp->space->forward<ALT_FWD>(cast_to_oop(cur_obj), size, cp, compact_top);\n@@ -209,1 +211,1 @@\n-        compact_top = cp->space->forward(obj, obj->size(), cp, compact_top);\n+        compact_top = cp->space->forward<ALT_FWD>(obj, obj->size(), cp, compact_top);\n@@ -240,1 +242,10 @@\n-void ContiguousSpace::adjust_pointers() {\n+void ContiguousSpace::prepare_for_compaction(CompactPoint* cp) {\n+  if (UseAltGCForwarding) {\n+    prepare_for_compaction_impl<true>(cp);\n+  } else {\n+    prepare_for_compaction_impl<false>(cp);\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void ContiguousSpace::adjust_pointers_impl() {\n@@ -263,1 +274,1 @@\n-      size_t size = MarkSweep::adjust_pointers(cast_to_oop(cur_obj));\n+      size_t size = MarkSweep::adjust_pointers<ALT_FWD>(cast_to_oop(cur_obj));\n@@ -277,1 +288,10 @@\n-void ContiguousSpace::compact() {\n+void ContiguousSpace::adjust_pointers() {\n+  if (UseAltGCForwarding) {\n+    adjust_pointers_impl<true>();\n+  } else {\n+    adjust_pointers_impl<false>();\n+  }\n+}\n+\n+template <bool ALT_FWD>\n+void ContiguousSpace::compact_impl() {\n@@ -306,1 +326,1 @@\n-    if (!cast_to_oop(cur_obj)->is_forwarded()) {\n+    if (SlidingForwarding::is_not_forwarded(cast_to_oop(cur_obj))) {\n@@ -317,1 +337,1 @@\n-      HeapWord* compaction_top = cast_from_oop<HeapWord*>(cast_to_oop(cur_obj)->forwardee());\n+      HeapWord* compaction_top = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(cast_to_oop(cur_obj)));\n@@ -340,0 +360,8 @@\n+void ContiguousSpace::compact() {\n+  if (UseAltGCForwarding) {\n+    compact_impl<true>();\n+  } else {\n+    compact_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/space.cpp","additions":39,"deletions":11,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -225,1 +225,12 @@\n- protected:\n+#if INCLUDE_SERIALGC\n+  template <bool ALT_FWD>\n+  void prepare_for_compaction_impl(CompactPoint* cp);\n+\n+  template <bool ALT_FWD>\n+  void adjust_pointers_impl();\n+\n+  template <bool ALT_FWD>\n+  void compact_impl();\n+#endif\n+\n+protected:\n@@ -314,1 +325,2 @@\n-  virtual HeapWord* forward(oop q, size_t size, CompactPoint* cp,\n+  template <bool ALT_FWD>\n+  HeapWord* forward(oop q, size_t size, CompactPoint* cp,\n","filename":"src\/hotspot\/share\/gc\/shared\/space.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -200,1 +200,1 @@\n-  Klass* obj_klass = obj->klass_or_null();\n+  Klass* obj_klass = obj->forward_safe_klass();\n@@ -232,1 +232,1 @@\n-    if (obj_klass != fwd->klass()) {\n+    if (obj_klass != fwd->forward_safe_klass()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahAsserts.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -224,0 +225,2 @@\n+    SlidingForwarding::begin();\n+\n@@ -237,0 +240,1 @@\n+    SlidingForwarding::end();\n@@ -298,0 +302,1 @@\n+template <bool ALT_FWD>\n@@ -366,1 +371,1 @@\n-    p->forward_to(cast_to_oop(_compact_point));\n+    SlidingForwarding::forward_to<ALT_FWD>(p, cast_to_oop(_compact_point));\n@@ -397,0 +402,10 @@\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n+\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -412,1 +427,1 @@\n-    ShenandoahPrepareForCompactionObjectClosure cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n+    ShenandoahPrepareForCompactionObjectClosure<ALT_FWD> cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n@@ -438,1 +453,2 @@\n-void ShenandoahFullGC::calculate_target_humongous_objects() {\n+template <bool ALT_FWD>\n+void ShenandoahFullGC::calculate_target_humongous_objects_impl() {\n@@ -474,1 +490,1 @@\n-        old_obj->forward_to(cast_to_oop(heap->get_region(start)->bottom()));\n+        SlidingForwarding::forward_to<ALT_FWD>(old_obj, cast_to_oop(heap->get_region(start)->bottom()));\n@@ -486,0 +502,8 @@\n+void ShenandoahFullGC::calculate_target_humongous_objects() {\n+  if (UseAltGCForwarding) {\n+    calculate_target_humongous_objects_impl<true>();\n+  } else {\n+    calculate_target_humongous_objects_impl<false>();\n+  }\n+}\n+\n@@ -723,0 +747,1 @@\n+template <bool ALT_FWD>\n@@ -734,2 +759,2 @@\n-      if (obj->is_forwarded()) {\n-        oop forw = obj->forwardee();\n+      if (SlidingForwarding::is_forwarded(obj)) {\n+        oop forw = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -752,0 +777,1 @@\n+template <bool ALT_FWD>\n@@ -755,1 +781,1 @@\n-  ShenandoahAdjustPointersClosure _cl;\n+  ShenandoahAdjustPointersClosure<ALT_FWD> _cl;\n@@ -778,1 +804,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -780,1 +808,1 @@\n-    ShenandoahAdjustPointersObjectClosure obj_cl;\n+    ShenandoahAdjustPointersObjectClosure<ALT_FWD> obj_cl;\n@@ -789,0 +817,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -795,0 +832,1 @@\n+\n@@ -801,1 +839,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -803,1 +843,1 @@\n-    ShenandoahAdjustPointersClosure cl;\n+    ShenandoahAdjustPointersClosure<ALT_FWD> cl;\n@@ -807,0 +847,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -833,0 +882,1 @@\n+template <bool ALT_FWD>\n@@ -845,1 +895,1 @@\n-    if (p->is_forwarded()) {\n+    if (SlidingForwarding::is_forwarded(p)) {\n@@ -847,1 +897,1 @@\n-      HeapWord* compact_to = cast_from_oop<HeapWord*>(p->forwardee());\n+      HeapWord* compact_to = cast_from_oop<HeapWord*>(SlidingForwarding::forwardee<ALT_FWD>(p));\n@@ -869,1 +919,3 @@\n-  void work(uint worker_id) {\n+private:\n+  template <bool ALT_FWD>\n+  void work_impl(uint worker_id) {\n@@ -873,1 +925,1 @@\n-    ShenandoahCompactObjectsClosure cl(worker_id);\n+    ShenandoahCompactObjectsClosure<ALT_FWD> cl(worker_id);\n@@ -884,0 +936,9 @@\n+\n+public:\n+  void work(uint worker_id) {\n+    if (UseAltGCForwarding) {\n+      work_impl<true>(worker_id);\n+    } else {\n+      work_impl<false>(worker_id);\n+    }\n+  }\n@@ -936,1 +997,2 @@\n-void ShenandoahFullGC::compact_humongous_objects() {\n+template <bool ALT_FWD>\n+void ShenandoahFullGC::compact_humongous_objects_impl() {\n@@ -949,1 +1011,1 @@\n-      if (!old_obj->is_forwarded()) {\n+      if (SlidingForwarding::is_not_forwarded(old_obj)) {\n@@ -958,1 +1020,1 @@\n-      size_t new_start = heap->heap_region_index_containing(old_obj->forwardee());\n+      size_t new_start = heap->heap_region_index_containing(SlidingForwarding::forwardee<ALT_FWD>(old_obj));\n@@ -999,0 +1061,8 @@\n+void ShenandoahFullGC::compact_humongous_objects() {\n+  if (UseAltGCForwarding) {\n+    compact_humongous_objects_impl<true>();\n+  } else {\n+    compact_humongous_objects_impl<false>();\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":88,"deletions":18,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+  template <bool ALT_FWD>\n@@ -85,0 +86,2 @@\n+  template <bool ALT_FWD>\n+  void calculate_target_humongous_objects_impl();\n@@ -87,0 +90,2 @@\n+  template <bool ALT_FWD>\n+  void compact_humongous_objects_impl();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -442,0 +443,2 @@\n+  SlidingForwarding::initialize(_heap_region, ShenandoahHeapRegion::region_size_words());\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -299,1 +299,1 @@\n-  size_t size = p->size();\n+  size_t size = p->forward_safe_size();\n@@ -334,2 +334,0 @@\n-\n-  \/\/ Try to install the new forwarding pointer.\n@@ -337,1 +335,15 @@\n-  ContinuationGCSupport::relativize_stack_chunk(copy_val);\n+  if (UseCompactObjectHeaders) {\n+    \/\/ The copy above is not atomic. Make sure we have seen the proper mark\n+    \/\/ and re-install it into the copy, so that Klass* is guaranteed to be correct.\n+    markWord mark = copy_val->mark();\n+    if (!mark.is_marked()) {\n+      copy_val->set_mark(mark);\n+      ContinuationGCSupport::relativize_stack_chunk(copy_val);\n+    } else {\n+      \/\/ If we copied a mark-word that indicates 'forwarded' state, the object\n+      \/\/ installation would not succeed. We cannot access Klass* anymore either.\n+      \/\/ Skip the transformation.\n+    }\n+  } else {\n+    ContinuationGCSupport::relativize_stack_chunk(copy_val);\n+  }\n@@ -339,0 +351,1 @@\n+  \/\/ Try to install the new forwarding pointer.\n@@ -514,1 +527,1 @@\n-    size_t size = obj->size();\n+    size_t size = obj->forward_safe_size();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":18,"deletions":5,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -176,1 +176,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkBitMap.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -101,1 +101,1 @@\n-      if (is_instance_ref_klass(obj->klass())) {\n+      if (is_instance_ref_klass(obj->forward_safe_klass())) {\n@@ -128,1 +128,1 @@\n-    Klass* obj_klass = obj->klass_or_null();\n+    Klass* obj_klass = obj->forward_safe_klass();\n@@ -143,1 +143,1 @@\n-        check(ShenandoahAsserts::_safe_unknown, obj, (obj_addr + obj->size()) <= obj_reg->top(),\n+        check(ShenandoahAsserts::_safe_unknown, obj, (obj_addr + obj->forward_safe_size()) <= obj_reg->top(),\n@@ -147,1 +147,1 @@\n-        size_t humongous_end = humongous_start + (obj->size() >> ShenandoahHeapRegion::region_size_words_shift());\n+        size_t humongous_end = humongous_start + (obj->forward_safe_size() >> ShenandoahHeapRegion::region_size_words_shift());\n@@ -164,1 +164,1 @@\n-          Atomic::add(&_ld[obj_reg->index()], (uint) obj->size(), memory_order_relaxed);\n+          Atomic::add(&_ld[obj_reg->index()], (uint) obj->forward_safe_size(), memory_order_relaxed);\n@@ -205,1 +205,1 @@\n-      check(ShenandoahAsserts::_safe_oop, obj, (fwd_addr + fwd->size()) <= fwd_reg->top(),\n+      check(ShenandoahAsserts::_safe_oop, obj, (fwd_addr + fwd->forward_safe_size()) <= fwd_reg->top(),\n@@ -308,1 +308,2 @@\n-    obj->oop_iterate(this);\n+    Klass* klass = obj->forward_safe_klass();\n+    obj->oop_iterate_backwards(this, klass);\n@@ -588,1 +589,1 @@\n-    if (!is_instance_ref_klass(obj->klass())) {\n+    if (!is_instance_ref_klass(obj->forward_safe_klass())) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVerifier.cpp","additions":9,"deletions":8,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -301,1 +301,1 @@\n-        assert(!UseCompressedClassPointers, \"should only happen without compressed class pointers\");\n+        assert(!UseCompressedClassPointers || UseCompactObjectHeaders, \"should only happen without compressed class pointers or with compact object headers\");\n","filename":"src\/hotspot\/share\/gc\/x\/c2\/xBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -53,2 +53,0 @@\n-  const size_t header = arrayOopDesc::header_size(element_type);\n-  const size_t payload_size = _word_size - header;\n@@ -56,0 +54,11 @@\n+  \/\/ Clear leading 32 bits, if necessary.\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n+  if (!is_aligned(base_offset, HeapWordSize)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"array base must be 32 bit aligned\");\n+    *reinterpret_cast<jint*>(reinterpret_cast<char*>(mem) + base_offset) = 0;\n+    base_offset += BytesPerInt;\n+  }\n+  assert(is_aligned(base_offset, HeapWordSize), \"remaining array base must be 64 bit aligned\");\n+\n+  const size_t header = heap_word_size(base_offset);\n+  const size_t payload_size = _word_size - header;\n@@ -66,2 +75,6 @@\n-  arrayOopDesc::set_mark(mem, markWord::prototype());\n-  arrayOopDesc::release_set_klass(mem, _klass);\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, _klass->prototype_header());\n+  } else {\n+    arrayOopDesc::set_mark(mem, markWord::prototype());\n+    arrayOopDesc::release_set_klass(mem, _klass);\n+  }\n","filename":"src\/hotspot\/share\/gc\/x\/xObjArrayAllocator.cpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -483,1 +483,1 @@\n-        assert(!UseCompressedClassPointers, \"should only happen without compressed class pointers\");\n+        assert(!UseCompressedClassPointers || UseCompactObjectHeaders, \"should only happen without compressed class pointers or with compact object headers\");\n","filename":"src\/hotspot\/share\/gc\/z\/c2\/zBarrierSetC2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -53,2 +53,0 @@\n-  const size_t header = arrayOopDesc::header_size(element_type);\n-  const size_t payload_size = _word_size - header;\n@@ -56,0 +54,11 @@\n+  \/\/ Clear leading 32 bits, if necessary.\n+  int base_offset = arrayOopDesc::base_offset_in_bytes(element_type);\n+  if (!is_aligned(base_offset, HeapWordSize)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"array base must be 32 bit aligned\");\n+    *reinterpret_cast<jint*>(reinterpret_cast<char*>(mem) + base_offset) = 0;\n+    base_offset += BytesPerInt;\n+  }\n+  assert(is_aligned(base_offset, HeapWordSize), \"remaining array base must be 64 bit aligned\");\n+\n+  const size_t header = heap_word_size(base_offset);\n+  const size_t payload_size = _word_size - header;\n@@ -69,2 +78,6 @@\n-  arrayOopDesc::set_mark(mem, markWord::prototype().set_marked());\n-  arrayOopDesc::release_set_klass(mem, _klass);\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, _klass->prototype_header().set_marked());\n+  } else {\n+    arrayOopDesc::set_mark(mem, markWord::prototype().set_marked());\n+    arrayOopDesc::release_set_klass(mem, _klass);\n+  }\n@@ -138,1 +151,5 @@\n-  oopDesc::release_set_mark(mem, markWord::prototype());\n+  if (UseCompactObjectHeaders) {\n+    oopDesc::release_set_mark(mem, _klass->prototype_header());\n+  } else {\n+    oopDesc::release_set_mark(mem, markWord::prototype());\n+  }\n","filename":"src\/hotspot\/share\/gc\/z\/zObjArrayAllocator.cpp","additions":22,"deletions":5,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -609,1 +609,0 @@\n-    const size_t size = ZUtils::object_size(from_addr);\n@@ -617,0 +616,1 @@\n+        const size_t size = ZUtils::object_size(to_addr);\n@@ -623,0 +623,1 @@\n+    const size_t size = ZUtils::object_size(from_addr);\n","filename":"src\/hotspot\/share\/gc\/z\/zRelocate.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2004,4 +2004,7 @@\n-              oopDesc::set_mark(result, markWord::prototype());\n-              oopDesc::set_klass_gap(result, 0);\n-              oopDesc::release_set_klass(result, ik);\n-\n+              if (UseCompactObjectHeaders) {\n+                oopDesc::release_set_mark(result, ik->prototype_header());\n+              } else {\n+                oopDesc::set_mark(result, markWord::prototype());\n+                oopDesc::set_klass_gap(result, 0);\n+                oopDesc::release_set_klass(result, ik);\n+              }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -73,1 +73,1 @@\n-    obj->set_mark(markWord::prototype().set_marked());\n+    obj->set_mark(obj->prototype_mark().set_marked());\n","filename":"src\/hotspot\/share\/jfr\/leakprofiler\/chains\/objectSampleMarker.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -449,1 +449,5 @@\n-  if (offset == oopDesc::klass_offset_in_bytes()) {\n+\n+  \/\/ With compact object headers, we can test for the explicit offset within\n+  \/\/ the header to figure out if compiler code is accessing the class.\n+  int klass_offset = UseCompactObjectHeaders ? 4 : oopDesc::klass_offset_in_bytes();\n+  if (offset == klass_offset) {\n@@ -2451,1 +2455,1 @@\n-  return arrayOopDesc::header_size(type) * HeapWordSize;\n+  return arrayOopDesc::base_offset_in_bytes(type);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -324,2 +324,7 @@\n-  assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n-         \"Klass offset is expected to be less than the page size\");\n+  if (UseCompactObjectHeaders) {\n+    assert(oopDesc::mark_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Mark offset is expected to be less than the page size\");\n+  } else {\n+    assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Klass offset is expected to be less than the page size\");\n+  }\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -48,16 +49,1 @@\n-  \/\/ Header size computation.\n-  \/\/ The header is considered the oop part of this type plus the length.\n-  \/\/ Returns the aligned header_size_in_bytes.  This is not equivalent to\n-  \/\/ sizeof(arrayOopDesc) which should not appear in the code.\n-  static int header_size_in_bytes() {\n-    size_t hs = align_up(length_offset_in_bytes() + sizeof(int),\n-                              HeapWordSize);\n-#ifdef ASSERT\n-    \/\/ make sure it isn't called before UseCompressedOops is initialized.\n-    static size_t arrayoopdesc_hs = 0;\n-    if (arrayoopdesc_hs == 0) arrayoopdesc_hs = hs;\n-    assert(arrayoopdesc_hs == hs, \"header size can't change\");\n-#endif \/\/ ASSERT\n-    return (int)hs;\n-  }\n-\n+private:\n@@ -70,2 +56,2 @@\n-  \/\/ Check whether an element of a typeArrayOop with the given type must be\n-  \/\/ aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this\n+  \/\/ Check whether an element of an arrayOop with the given type must be\n+  \/\/ aligned 0 mod 8.  The arrayOop itself must be aligned at least this\n@@ -74,0 +60,5 @@\n+#ifdef _LP64\n+    if (type == T_OBJECT || type == T_ARRAY) {\n+      return !UseCompressedOops;\n+    }\n+#endif\n@@ -78,0 +69,14 @@\n+  \/\/ Header size computation.\n+  \/\/ The header is considered the oop part of this type plus the length.\n+  \/\/ This is not equivalent to sizeof(arrayOopDesc) which should not appear in the code.\n+  static int header_size_in_bytes() {\n+    size_t hs = length_offset_in_bytes() + sizeof(int);\n+#ifdef ASSERT\n+    \/\/ make sure it isn't called before UseCompressedOops is initialized.\n+    static size_t arrayoopdesc_hs = 0;\n+    if (arrayoopdesc_hs == 0) arrayoopdesc_hs = hs;\n+    assert(arrayoopdesc_hs == hs, \"header size can't change\");\n+#endif \/\/ ASSERT\n+    return (int)hs;\n+  }\n+\n@@ -82,2 +87,7 @@\n-    return UseCompressedClassPointers ? klass_gap_offset_in_bytes() :\n-                               sizeof(arrayOopDesc);\n+    if (UseCompactObjectHeaders) {\n+      return oopDesc::base_offset_in_bytes();\n+    } else if (UseCompressedClassPointers) {\n+      return klass_gap_offset_in_bytes();\n+    } else {\n+      return sizeof(arrayOopDesc);\n+    }\n@@ -88,1 +98,2 @@\n-    return header_size(type) * HeapWordSize;\n+    size_t hs = header_size_in_bytes();\n+    return (int)(element_type_should_be_aligned(type) ? align_up(hs, BytesPerLong) : hs);\n@@ -125,12 +136,1 @@\n-  \/\/ Should only be called with constants as argument\n-  \/\/ (will not constant fold otherwise)\n-  \/\/ Returns the header size in words aligned to the requirements of the\n-  \/\/ array object type.\n-  static int header_size(BasicType type) {\n-    size_t typesize_in_bytes = header_size_in_bytes();\n-    return (int)(element_type_should_be_aligned(type)\n-      ? align_object_offset(typesize_in_bytes\/HeapWordSize)\n-      : typesize_in_bytes\/HeapWordSize);\n-  }\n-\n-  \/\/ Return the maximum length of an array of BasicType.  The length can passed\n+  \/\/ Return the maximum length of an array of BasicType.  The length can be passed\n@@ -144,0 +144,4 @@\n+    size_t hdr_size_in_bytes = base_offset_in_bytes(type);\n+    \/\/ This is rounded-up and may overlap with the first array elements.\n+    size_t hdr_size_in_words = align_up(hdr_size_in_bytes, HeapWordSize) \/ HeapWordSize;\n+\n@@ -145,1 +149,1 @@\n-      align_down((SIZE_MAX\/HeapWordSize - header_size(type)), MinObjAlignment);\n+      align_down((SIZE_MAX\/HeapWordSize - hdr_size_in_words), MinObjAlignment);\n@@ -153,1 +157,1 @@\n-      return align_down(max_jint - header_size(type), MinObjAlignment);\n+      return align_down(max_jint - hdr_size_in_words, MinObjAlignment);\n","filename":"src\/hotspot\/share\/oops\/arrayOop.hpp","additions":39,"deletions":35,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -36,3 +36,0 @@\n-  \/\/ aligned header size.\n-  static int header_size() { return sizeof(instanceOopDesc)\/HeapWordSize; }\n-\n@@ -41,4 +38,7 @@\n-    return (UseCompressedClassPointers) ?\n-            klass_gap_offset_in_bytes() :\n-            sizeof(instanceOopDesc);\n-\n+    if (UseCompactObjectHeaders) {\n+      return oopDesc::base_offset_in_bytes();\n+    } else if (UseCompressedClassPointers) {\n+      return klass_gap_offset_in_bytes();\n+    } else {\n+      return sizeof(instanceOopDesc);\n+    }\n","filename":"src\/hotspot\/share\/oops\/instanceOop.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -198,0 +198,10 @@\n+static markWord make_prototype(Klass* kls) {\n+  markWord prototype = markWord::prototype();\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    prototype = prototype.set_klass(kls);\n+  }\n+#endif\n+  return prototype;\n+}\n+\n@@ -207,0 +217,1 @@\n+                           _prototype_header(make_prototype(this)),\n@@ -753,0 +764,4 @@\n+     if (UseCompactObjectHeaders) {\n+       st->print(BULLET\"prototype_header: \" INTPTR_FORMAT, _prototype_header.value());\n+       st->cr();\n+     }\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -170,0 +170,2 @@\n+  markWord _prototype_header;   \/\/ Used to initialize objects' header\n+\n@@ -678,0 +680,7 @@\n+  markWord prototype_header() const      {\n+    assert(UseCompactObjectHeaders, \"only use with compact object headers\");\n+    return _prototype_header;\n+  }\n+  inline void set_prototype_header(markWord header);\n+  static ByteSize prototype_header_offset() { return in_ByteSize(offset_of(Klass, _prototype_header)); }\n+\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -55,0 +55,5 @@\n+inline void Klass::set_prototype_header(markWord header) {\n+  assert(UseCompactObjectHeaders, \"only with compact headers\");\n+  _prototype_header = header;\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -29,0 +30,1 @@\n+#include \"oops\/compressedKlass.hpp\"\n@@ -46,0 +48,4 @@\n+\/\/  64 bits (with compact headers):\n+\/\/  -------------------------------\n+\/\/  nklass:32 hash:25 -->| unused_gap:1  age:4  self-fwded:1  lock:2 (normal object)\n+\/\/\n@@ -106,2 +112,2 @@\n-  static const int first_unused_gap_bits          = 1;\n-  static const int max_hash_bits                  = BitsPerWord - age_bits - lock_bits - first_unused_gap_bits;\n+  static const int self_forwarded_bits            = 1;\n+  static const int max_hash_bits                  = BitsPerWord - age_bits - lock_bits - self_forwarded_bits;\n@@ -109,1 +115,7 @@\n-  static const int second_unused_gap_bits         = LP64_ONLY(1) NOT_LP64(0);\n+  static const int hash_bits_compact              = max_hash_bits > 25 ? 25 : max_hash_bits;\n+  \/\/ Used only without compact headers.\n+  static const int unused_gap_bits                = LP64_ONLY(1) NOT_LP64(0);\n+#ifdef _LP64\n+  \/\/ Used only with compact headers.\n+  static const int klass_bits                     = 32;\n+#endif\n@@ -112,2 +124,8 @@\n-  static const int age_shift                      = lock_bits + first_unused_gap_bits;\n-  static const int hash_shift                     = age_shift + age_bits + second_unused_gap_bits;\n+  static const int self_forwarded_shift           = lock_shift + lock_bits;\n+  static const int age_shift                      = self_forwarded_shift + self_forwarded_bits;\n+  static const int hash_shift                     = age_shift + age_bits + unused_gap_bits;\n+  static const int hash_shift_compact             = age_shift + age_bits;\n+#ifdef _LP64\n+  \/\/ Used only with compact headers.\n+  static const int klass_shift                    = hash_shift_compact + hash_bits_compact;\n+#endif\n@@ -117,0 +135,2 @@\n+  static const uintptr_t self_forwarded_mask      = right_n_bits(self_forwarded_bits);\n+  static const uintptr_t self_forwarded_mask_in_place = self_forwarded_mask << self_forwarded_shift;\n@@ -121,0 +141,6 @@\n+  static const uintptr_t hash_mask_compact        = right_n_bits(hash_bits_compact);\n+  static const uintptr_t hash_mask_compact_in_place = hash_mask_compact << hash_shift_compact;\n+#ifdef _LP64\n+  static const uintptr_t klass_mask               = right_n_bits(klass_bits);\n+  static const uintptr_t klass_mask_in_place      = klass_mask << klass_shift;\n+#endif\n@@ -208,3 +234,9 @@\n-    uintptr_t tmp = value() & (~hash_mask_in_place);\n-    tmp |= ((hash & hash_mask) << hash_shift);\n-    return markWord(tmp);\n+    if (UseCompactObjectHeaders) {\n+      uintptr_t tmp = value() & (~hash_mask_compact_in_place);\n+      tmp |= ((hash & hash_mask_compact) << hash_shift_compact);\n+      return markWord(tmp);\n+    } else {\n+      uintptr_t tmp = value() & (~hash_mask_in_place);\n+      tmp |= ((hash & hash_mask) << hash_shift);\n+      return markWord(tmp);\n+    }\n@@ -243,1 +275,5 @@\n-    return mask_bits(value() >> hash_shift, hash_mask);\n+    if (UseCompactObjectHeaders) {\n+      return mask_bits(value() >> hash_shift_compact, hash_mask_compact);\n+    } else {\n+      return mask_bits(value() >> hash_shift, hash_mask);\n+    }\n@@ -250,0 +286,9 @@\n+#ifdef _LP64\n+  inline markWord actual_mark() const;\n+  inline Klass* klass() const;\n+  inline Klass* klass_or_null() const;\n+  inline narrowKlass narrow_klass() const;\n+  inline markWord set_narrow_klass(narrowKlass nklass) const;\n+  inline markWord set_klass(Klass* klass) const;\n+#endif\n+\n@@ -263,0 +308,13 @@\n+\n+#ifdef _LP64\n+  inline bool self_forwarded() const {\n+    bool self_fwd = mask_bits(value(), self_forwarded_mask_in_place) != 0;\n+    assert(!self_fwd || UseAltGCForwarding, \"Only set self-fwd bit when using alt GC forwarding\");\n+    return self_fwd;\n+  }\n+\n+  inline markWord set_self_forwarded() const {\n+    assert(UseAltGCForwarding, \"Only call this with alt GC forwarding\");\n+    return markWord(value() | self_forwarded_mask_in_place | marked_value);\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":67,"deletions":9,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -0,0 +1,70 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_OOPS_MARKWORD_INLINE_HPP\n+#define SHARE_OOPS_MARKWORD_INLINE_HPP\n+\n+#include \"oops\/markWord.hpp\"\n+#include \"oops\/compressedOops.inline.hpp\"\n+\n+#ifdef _LP64\n+markWord markWord::actual_mark() const {\n+  assert(UseCompactObjectHeaders, \"only safe when using compact headers\");\n+  if (has_displaced_mark_helper()) {\n+    return displaced_mark_helper();\n+  } else {\n+    return *this;\n+  }\n+}\n+\n+Klass* markWord::klass() const {\n+  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n+  assert(!CompressedKlassPointers::is_null(narrow_klass()), \"narrow klass must not be null: \" INTPTR_FORMAT, value());\n+  return CompressedKlassPointers::decode_not_null(narrow_klass());\n+}\n+\n+Klass* markWord::klass_or_null() const {\n+  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n+  return CompressedKlassPointers::decode(narrow_klass());\n+}\n+\n+narrowKlass markWord::narrow_klass() const {\n+  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n+  return narrowKlass(value() >> klass_shift);\n+}\n+\n+markWord markWord::set_narrow_klass(narrowKlass nklass) const {\n+  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n+  return markWord((value() & ~klass_mask_in_place) | ((uintptr_t) nklass << klass_shift));\n+}\n+\n+markWord markWord::set_klass(Klass* klass) const {\n+  assert(UseCompactObjectHeaders, \"only used with compact object headers\");\n+  assert(UseCompressedClassPointers, \"expect compressed klass pointers\");\n+  narrowKlass nklass = CompressedKlassPointers::encode(const_cast<Klass*>(klass));\n+  return set_narrow_klass(nklass);\n+}\n+#endif \/\/ _LP64\n+\n+#endif \/\/ SHARE_OOPS_MARKWORD_INLINE_HPP\n","filename":"src\/hotspot\/share\/oops\/markWord.inline.hpp","additions":70,"deletions":0,"binary":false,"changes":70,"status":"added"},{"patch":"@@ -159,1 +159,2 @@\n-  assert(obj->is_objArray(), \"must be object array\");\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_objArray(), \"must be object array\");\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -73,1 +73,2 @@\n-  assert (obj->is_array(), \"obj must be array\");\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert (UseCompactObjectHeaders || obj->is_array(), \"obj must be array\");\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -54,26 +54,0 @@\n-private:\n-  \/\/ Give size of objArrayOop in HeapWords minus the header\n-  static int array_size(int length) {\n-    const uint OopsPerHeapWord = HeapWordSize\/heapOopSize;\n-    assert(OopsPerHeapWord >= 1 && (HeapWordSize % heapOopSize == 0),\n-           \"Else the following (new) computation would be in error\");\n-    uint res = ((uint)length + OopsPerHeapWord - 1)\/OopsPerHeapWord;\n-#ifdef ASSERT\n-    \/\/ The old code is left in for sanity-checking; it'll\n-    \/\/ go away pretty soon. XXX\n-    \/\/ Without UseCompressedOops, this is simply:\n-    \/\/ oop->length() * HeapWordsPerOop;\n-    \/\/ With narrowOops, HeapWordsPerOop is 1\/2 or equal 0 as an integer.\n-    \/\/ The oop elements are aligned up to wordSize\n-    const uint HeapWordsPerOop = heapOopSize\/HeapWordSize;\n-    uint old_res;\n-    if (HeapWordsPerOop > 0) {\n-      old_res = length * HeapWordsPerOop;\n-    } else {\n-      old_res = align_up((uint)length, OopsPerHeapWord)\/OopsPerHeapWord;\n-    }\n-    assert(res == old_res, \"Inconsistency between old and new.\");\n-#endif  \/\/ ASSERT\n-    return res;\n-  }\n-\n@@ -97,1 +71,0 @@\n-  static int header_size()    { return arrayOopDesc::header_size(T_OBJECT); }\n@@ -102,5 +75,5 @@\n-    uint asz = array_size(length);\n-    uint osz = align_object_size(header_size() + asz);\n-    assert(osz >= asz,   \"no overflow\");\n-    assert((int)osz > 0, \"no overflow\");\n-    return (size_t)osz;\n+    size_t asz = (size_t)length * heapOopSize;\n+    size_t size_words = heap_word_size(base_offset_in_bytes() + asz);\n+    size_t osz = align_object_size(size_words);\n+    assert(osz < max_jint, \"no overflow\");\n+    return osz;\n","filename":"src\/hotspot\/share\/oops\/objArrayOop.hpp","additions":5,"deletions":32,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -161,1 +161,2 @@\n-  return UseCompressedClassPointers;\n+  \/\/ Except when using compact headers.\n+  return UseCompressedClassPointers && !UseCompactObjectHeaders;\n@@ -173,1 +174,3 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    return obj->klass();\n+  } else if (UseCompressedClassPointers) {\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -83,0 +83,5 @@\n+  inline markWord resolve_mark() const;\n+\n+  \/\/ Returns the prototype mark that should be used for this object.\n+  inline markWord prototype_mark() const;\n+\n@@ -101,1 +106,7 @@\n-  static constexpr int header_size() { return sizeof(oopDesc)\/HeapWordSize; }\n+  static int header_size() {\n+    if (UseCompactObjectHeaders) {\n+      return sizeof(markWord) \/ HeapWordSize;\n+    } else {\n+      return sizeof(oopDesc)\/HeapWordSize;\n+    }\n+  }\n@@ -113,0 +124,14 @@\n+  \/\/ The following set of methods is used to access the mark-word and related\n+  \/\/ properties when the object may be forwarded. Be careful where and when\n+  \/\/ using this method. It assumes that the forwardee is installed in\n+  \/\/ the header as a plain pointer (or self-forwarded). In particular,\n+  \/\/ those methods can not deal with the sliding-forwarding that is used\n+  \/\/ in Serial, G1 and Shenandoah full-GCs.\n+private:\n+  inline Klass*   forward_safe_klass_impl(markWord m) const;\n+public:\n+  inline Klass*   forward_safe_klass() const;\n+  inline Klass*   forward_safe_klass(markWord m) const;\n+  inline size_t   forward_safe_size();\n+  inline void     forward_safe_init_mark();\n+\n@@ -263,0 +288,1 @@\n+  inline void forward_to_self();\n@@ -269,0 +295,1 @@\n+  inline oop forward_to_self_atomic(markWord compare, atomic_memory_order order = memory_order_conservative);\n@@ -271,0 +298,1 @@\n+  inline oop forwardee(markWord header) const;\n@@ -314,1 +342,11 @@\n-  static int klass_offset_in_bytes()     { return (int)offset_of(oopDesc, _metadata._klass); }\n+  static int klass_offset_in_bytes()     {\n+#ifdef _LP64\n+    if (UseCompactObjectHeaders) {\n+      STATIC_ASSERT(markWord::klass_shift % 8 == 0);\n+      return mark_offset_in_bytes() + markWord::klass_shift \/ 8;\n+    } else\n+#endif\n+    {\n+      return (int)offset_of(oopDesc, _metadata._klass);\n+    }\n+  }\n@@ -317,0 +355,1 @@\n+    assert(!UseCompactObjectHeaders, \"don't use klass_offset_in_bytes() with compact headers\");\n@@ -320,0 +359,16 @@\n+  static int base_offset_in_bytes() {\n+#ifdef _LP64\n+    if (UseCompactObjectHeaders) {\n+      \/\/ With compact headers, the Klass* field is not used for the Klass*\n+      \/\/ and is used for the object fields instead.\n+      assert(sizeof(markWord) == 8, \"sanity\");\n+      return sizeof(markWord);\n+    } else if (UseCompressedClassPointers) {\n+      return sizeof(markWord) + sizeof(narrowKlass);\n+    } else\n+#endif\n+    {\n+      return sizeof(oopDesc);\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":57,"deletions":2,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"oops\/markWord.hpp\"\n+#include \"oops\/markWord.inline.hpp\"\n@@ -41,0 +41,1 @@\n+#include \"runtime\/safepoint.hpp\"\n@@ -85,0 +86,17 @@\n+markWord oopDesc::resolve_mark() const {\n+  assert(LockingMode != LM_LEGACY, \"Not safe with legacy stack-locking\");\n+  markWord m = mark();\n+  if (m.has_displaced_mark_helper()) {\n+    m = m.displaced_mark_helper();\n+  }\n+  return m;\n+}\n+\n+markWord oopDesc::prototype_mark() const {\n+  if (UseCompactObjectHeaders) {\n+    return klass()->prototype_header();\n+  } else {\n+    return markWord::prototype();\n+  }\n+}\n+\n@@ -86,1 +104,5 @@\n-  set_mark(markWord::prototype());\n+  if (UseCompactObjectHeaders) {\n+    set_mark(prototype_mark());\n+  } else {\n+    set_mark(markWord::prototype());\n+  }\n@@ -90,1 +112,5 @@\n-  if (UseCompressedClassPointers) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    markWord m = resolve_mark();\n+    return m.klass();\n+  } else if (UseCompressedClassPointers) {\n@@ -92,1 +118,3 @@\n-  } else {\n+  } else\n+#endif\n+  {\n@@ -98,1 +126,5 @@\n-  if (UseCompressedClassPointers) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    markWord m = resolve_mark();\n+    return m.klass_or_null();\n+  } else if (UseCompressedClassPointers) {\n@@ -100,1 +132,3 @@\n-  } else {\n+  } else\n+#endif\n+  {\n@@ -106,4 +140,13 @@\n-  if (UseCompressedClassPointers) {\n-    narrowKlass nklass = Atomic::load_acquire(&_metadata._compressed_klass);\n-    return CompressedKlassPointers::decode(nklass);\n-  } else {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    markWord m = mark_acquire();\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n+    }\n+    return m.klass_or_null();\n+  } else if (UseCompressedClassPointers) {\n+     narrowKlass nklass = Atomic::load_acquire(&_metadata._compressed_klass);\n+     return CompressedKlassPointers::decode(nklass);\n+  } else\n+#endif\n+  {\n@@ -115,1 +158,3 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    return klass();\n+  } else if (UseCompressedClassPointers) {\n@@ -124,0 +169,1 @@\n+  assert(!UseCompactObjectHeaders, \"don't set Klass* with compact headers\");\n@@ -133,0 +179,1 @@\n+  assert(!UseCompactObjectHeaders, \"don't set Klass* with compact headers\");\n@@ -143,0 +190,1 @@\n+  assert(!UseCompactObjectHeaders, \"don't set Klass* gap with compact headers\");\n@@ -205,0 +253,47 @@\n+#ifdef _LP64\n+Klass* oopDesc::forward_safe_klass_impl(markWord m) const {\n+  assert(UseCompactObjectHeaders, \"Only get here with compact headers\");\n+  if (m.is_marked()) {\n+    oop fwd = forwardee(m);\n+    markWord m2 = fwd->mark();\n+    assert(!m2.is_marked() || m2.self_forwarded(), \"no double forwarding: this: \" PTR_FORMAT \" (\" INTPTR_FORMAT \"), fwd: \" PTR_FORMAT \" (\" INTPTR_FORMAT \")\", p2i(this), m.value(), p2i(fwd), m2.value());\n+    m = m2;\n+  }\n+  return m.actual_mark().klass();\n+}\n+#endif\n+\n+Klass* oopDesc::forward_safe_klass(markWord m) const {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    return forward_safe_klass_impl(m);\n+  } else\n+#endif\n+  {\n+    return klass();\n+  }\n+}\n+\n+Klass* oopDesc::forward_safe_klass() const {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    return forward_safe_klass_impl(mark());\n+  } else\n+#endif\n+  {\n+    return klass();\n+  }\n+}\n+\n+size_t oopDesc::forward_safe_size() {\n+  return size_given_klass(forward_safe_klass());\n+}\n+\n+void oopDesc::forward_safe_init_mark() {\n+  if (UseCompactObjectHeaders) {\n+    set_mark(forward_safe_klass()->prototype_header());\n+  } else {\n+    set_mark(markWord::prototype());\n+  }\n+}\n+\n@@ -273,0 +368,1 @@\n+  assert(p != cast_to_oop(this) || !UseAltGCForwarding, \"Must not be called with self-forwarding\");\n@@ -274,1 +370,1 @@\n-  assert(m.decode_pointer() == p, \"encoding must be reversible\");\n+  assert(forwardee(m) == p, \"encoding must be reversable\");\n@@ -278,0 +374,20 @@\n+void oopDesc::forward_to_self() {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    markWord m = mark();\n+    \/\/ If mark is displaced, we need to preserve the real header during GC.\n+    \/\/ It will be restored to the displaced header after GC.\n+    assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n+    }\n+    m = m.set_self_forwarded();\n+    assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversible\");\n+    set_mark(m);\n+  } else\n+#endif\n+  {\n+    forward_to(oop(this));\n+  }\n+}\n+\n@@ -279,0 +395,1 @@\n+  assert(p != cast_to_oop(this) || !UseAltGCForwarding, \"Must not be called with self-forwarding\");\n@@ -285,1 +402,39 @@\n-    return cast_to_oop(old_mark.decode_pointer());\n+    return forwardee(old_mark);\n+  }\n+}\n+\n+oop oopDesc::forward_to_self_atomic(markWord compare, atomic_memory_order order) {\n+#ifdef _LP64\n+  if (UseAltGCForwarding) {\n+    markWord m = compare;\n+    \/\/ If mark is displaced, we need to preserve the real header during GC.\n+    \/\/ It will be restored to the displaced header after GC.\n+    assert(SafepointSynchronize::is_at_safepoint(), \"we can only safely fetch the displaced header at safepoint\");\n+    if (m.has_displaced_mark_helper()) {\n+      m = m.displaced_mark_helper();\n+    }\n+    m = m.set_self_forwarded();\n+    assert(forwardee(m) == cast_to_oop(this), \"encoding must be reversible\");\n+    markWord old_mark = cas_set_mark(m, compare, order);\n+    if (old_mark == compare) {\n+      return nullptr;\n+    } else {\n+      assert(old_mark.is_marked(), \"must be marked here\");\n+      return forwardee(old_mark);\n+    }\n+  } else\n+#endif\n+  {\n+    return forward_to_atomic(cast_to_oop(this), compare, order);\n+  }\n+}\n+\n+oop oopDesc::forwardee(markWord header) const {\n+  assert(header.is_marked(), \"only decode when actually forwarded\");\n+#ifdef _LP64\n+  if (header.self_forwarded()) {\n+    return cast_to_oop(this);\n+  } else\n+#endif\n+  {\n+    return cast_to_oop(header.decode_pointer());\n@@ -293,2 +448,1 @@\n-  assert(is_forwarded(), \"only decode when actually forwarded\");\n-  return cast_to_oop(mark().decode_pointer());\n+  return forwardee(mark());\n@@ -351,1 +505,2 @@\n-  assert(k == klass(), \"wrong klass\");\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || k == klass(), \"wrong klass\");\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":171,"deletions":16,"binary":false,"changes":187,"status":"modified"},{"patch":"@@ -174,1 +174,2 @@\n-  assert(obj->is_typeArray(),\"must be a type array\");\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_typeArray(),\"must be a type array\");\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -38,1 +38,2 @@\n-  assert(obj->is_typeArray(),\"must be a type array\");\n+  \/\/ In this assert, we cannot safely access the Klass* with compact headers.\n+  assert(UseCompactObjectHeaders || obj->is_typeArray(),\"must be a type array\");\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -113,0 +113,10 @@\n+\n+class C2LoadNKlassStub : public C2CodeStub {\n+private:\n+  Register _dst;\n+public:\n+  C2LoadNKlassStub(Register dst) : C2CodeStub(), _dst(dst) {}\n+  Register dst() { return _dst; }\n+  int max_size() const;\n+  void emit(C2_MacroAssembler& masm);\n+};\n","filename":"src\/hotspot\/share\/opto\/c2_CodeStubs.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1619,2 +1619,8 @@\n-  \/\/ For now only enable fast locking for non-array types\n-  mark_node = phase->MakeConX(markWord::prototype().value());\n+  if (UseCompactObjectHeaders) {\n+    Node* klass_node = in(AllocateNode::KlassNode);\n+    Node* proto_adr = phase->transform(new AddPNode(klass_node, klass_node, phase->MakeConX(in_bytes(Klass::prototype_header_offset()))));\n+    mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  } else {\n+    \/\/ For now only enable fast locking for non-array types\n+    mark_node = phase->MakeConX(markWord::prototype().value());\n+  }\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1701,0 +1701,4 @@\n+      if (UseCompactObjectHeaders) {\n+        if (flat->offset() == in_bytes(Klass::prototype_header_offset()))\n+          alias_type(idx)->set_rewritable(false);\n+      }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4562,2 +4562,2 @@\n-  Node *hash_mask      = _gvn.intcon(markWord::hash_mask);\n-  Node *hash_shift     = _gvn.intcon(markWord::hash_shift);\n+  Node *hash_mask      = _gvn.intcon(UseCompactObjectHeaders ? markWord::hash_mask_compact  : markWord::hash_mask);\n+  Node *hash_shift     = _gvn.intcon(UseCompactObjectHeaders ? markWord::hash_shift_compact : markWord::hash_shift);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1701,1 +1701,4 @@\n-  rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  if (!UseCompactObjectHeaders) {\n+    rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1911,0 +1911,7 @@\n+  if (UseCompactObjectHeaders) {\n+    if (tkls->offset() == in_bytes(Klass::prototype_header_offset())) {\n+      \/\/ The field is Klass::_prototype_header.  Return its (constant) value.\n+      assert(this->Opcode() == Op_LoadX, \"must load a proper type from _prototype_header\");\n+      return TypeX::make(klass->prototype_header());\n+    }\n+  }\n@@ -2083,0 +2090,7 @@\n+      if (UseCompactObjectHeaders) {\n+        if (tkls->offset() == in_bytes(Klass::prototype_header_offset())) {\n+          \/\/ The field is Klass::_prototype_header. Return its (constant) value.\n+          assert(this->Opcode() == Op_LoadX, \"must load a proper type from _prototype_header\");\n+          return TypeX::make(klass->prototype_header());\n+        }\n+      }\n@@ -2173,1 +2187,1 @@\n-  if (alloc != nullptr) {\n+  if (!UseCompactObjectHeaders && alloc != nullptr) {\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -323,3 +323,2 @@\n-    const size_t hs = arrayOopDesc::header_size(elem_type);\n-    \/\/ Align to next 8 bytes to avoid trashing arrays's length.\n-    const size_t aligned_hs = align_object_offset(hs);\n+    size_t hs_bytes = arrayOopDesc::base_offset_in_bytes(elem_type);\n+    assert(is_aligned(hs_bytes, BytesPerInt), \"must be 4 byte aligned\");\n@@ -327,2 +326,3 @@\n-    if (aligned_hs > hs) {\n-      Copy::zero_to_words(obj+hs, aligned_hs-hs);\n+    if (!is_aligned(hs_bytes, BytesPerLong)) {\n+      *reinterpret_cast<jint*>(reinterpret_cast<char*>(obj) + hs_bytes) = 0;\n+      hs_bytes += BytesPerInt;\n@@ -330,0 +330,1 @@\n+\n@@ -331,0 +332,2 @@\n+    assert(is_aligned(hs_bytes, BytesPerLong), \"must be 8-byte aligned\");\n+    const size_t aligned_hs = hs_bytes \/ BytesPerLong;\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -5172,1 +5172,2 @@\n-    int header_size = objArrayOopDesc::header_size() * wordSize;\n+    BasicType basic_elem_type = elem()->basic_type();\n+    int header_size = arrayOopDesc::base_offset_in_bytes(basic_elem_type);\n@@ -5177,1 +5178,0 @@\n-      BasicType basic_elem_type = elem()->basic_type();\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,1 +70,1 @@\n-  ( arrayOopDesc::header_size(T_DOUBLE) * HeapWordSize \\\n+  ( arrayOopDesc::base_offset_in_bytes(T_DOUBLE) \\\n","filename":"src\/hotspot\/share\/prims\/unsafe.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3104,0 +3104,22 @@\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders && UseZGC && !ZGenerational) {\n+    if (FLAG_IS_CMDLINE(UseCompactObjectHeaders)) {\n+      warning(\"Single-generational ZGC does not work with compact object headers, disabling UseCompactObjectHeaders\");\n+    }\n+    FLAG_SET_DEFAULT(UseCompactObjectHeaders, false);\n+  }\n+  if (UseCompactObjectHeaders && FLAG_IS_CMDLINE(UseCompressedClassPointers) && !UseCompressedClassPointers) {\n+    warning(\"Compact object headers require compressed class pointers. Disabling compact object headers.\");\n+    FLAG_SET_DEFAULT(UseCompactObjectHeaders, false);\n+  }\n+  if (UseCompactObjectHeaders && LockingMode == LM_LEGACY) {\n+    FLAG_SET_DEFAULT(LockingMode, LM_LIGHTWEIGHT);\n+  }\n+  if (UseCompactObjectHeaders && !UseAltGCForwarding) {\n+    FLAG_SET_DEFAULT(UseAltGCForwarding, true);\n+  }\n+  if (UseCompactObjectHeaders && !UseCompressedClassPointers) {\n+    FLAG_SET_DEFAULT(UseCompressedClassPointers, true);\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -133,0 +133,3 @@\n+  product(bool, UseCompactObjectHeaders, false, EXPERIMENTAL,               \\\n+          \"Use compact 64-bit object headers in 64-bit VM\")                 \\\n+                                                                            \\\n@@ -150,0 +153,1 @@\n+const bool UseCompactObjectHeaders = false;\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -221,0 +221,1 @@\n+  static ByteSize header_offset()      { return byte_offset_of(ObjectMonitor, _header); }\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -866,1 +866,1 @@\n-  value &= markWord::hash_mask;\n+  value &= UseCompactObjectHeaders ? markWord::hash_mask_compact : markWord::hash_mask;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -117,0 +117,3 @@\n+#if INCLUDE_VM_STRUCTS\n+#include \"runtime\/vmStructs.hpp\"\n+#endif\n@@ -503,0 +506,7 @@\n+  \/\/ Should happen before any agent attaches and pokes into vmStructs\n+#if INCLUDE_VM_STRUCTS\n+  if (UseCompactObjectHeaders) {\n+    VMStructs::compact_headers_overrides();\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -150,0 +150,10 @@\n+\/\/ Used by VMStructs when CompactObjectHeaders are enabled.\n+\/\/ Must match the relevant parts from the real oopDesc.\n+class fakeOopDesc {\n+private:\n+  union _metadata {\n+    Klass*      _klass;\n+    narrowKlass _compressed_klass;\n+  } _metadata;\n+};\n+\n@@ -1160,0 +1170,2 @@\n+  declare_toplevel_type(fakeOopDesc)                                      \\\n+                                                                          \\\n@@ -2515,0 +2527,1 @@\n+  declare_constant(markWord::hash_bits_compact)                           \\\n@@ -2519,0 +2532,2 @@\n+  declare_constant(markWord::hash_shift_compact)                          \\\n+  LP64_ONLY(declare_constant(markWord::klass_shift))                      \\\n@@ -2526,0 +2541,2 @@\n+  declare_constant(markWord::hash_mask_compact)                           \\\n+  declare_constant(markWord::hash_mask_compact_in_place)                  \\\n@@ -3062,0 +3079,26 @@\n+\n+void VMStructs::compact_headers_overrides() {\n+  assert(UseCompactObjectHeaders, \"Should have been checked before\");\n+\n+  \/\/ We cannot allow SA and other facilities to poke into VM internal fields\n+  \/\/ expecting the class pointers there. This will crash in the best case,\n+  \/\/ or yield incorrect execution in the worst case. This code hides the\n+  \/\/ risky fields from external code by replacing their original container\n+  \/\/ type to a fake one. The fake type should exist for VMStructs verification\n+  \/\/ code to work.\n+\n+  size_t len = localHotSpotVMStructsLength();\n+  for (size_t off = 0; off < len; off++) {\n+    VMStructEntry* e = &localHotSpotVMStructs[off];\n+    if (e == nullptr) continue;\n+    if (e->typeName == nullptr) continue;\n+    if (e->fieldName == nullptr) continue;\n+\n+    if (strcmp(e->typeName, \"oopDesc\") == 0) {\n+      if ((strcmp(e->fieldName, \"_metadata._klass\") == 0) ||\n+          (strcmp(e->fieldName, \"_metadata._compressed_klass\") == 0)) {\n+        e->typeName = \"fakeOopDesc\";\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":43,"deletions":0,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -149,0 +149,3 @@\n+\n+public:\n+  static void compact_headers_overrides() NOT_VM_STRUCTS_RETURN;\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,97 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_FASTHASH_HPP\n+#define SHARE_UTILITIES_FASTHASH_HPP\n+\n+#include \"memory\/allStatic.hpp\"\n+\n+class FastHash : public AllStatic {\n+private:\n+  static void fullmul64(uint64_t& hi, uint64_t& lo, uint64_t op1, uint64_t op2) {\n+#if defined(__SIZEOF_INT128__)\n+    __uint128_t prod = static_cast<__uint128_t>(op1) * static_cast<__uint128_t>(op2);\n+    hi = static_cast<uint64_t>(prod >> 64);\n+    lo = static_cast<uint64_t>(prod >>  0);\n+#else\n+    \/* First calculate all of the cross products. *\/\n+    uint64_t lo_lo = (op1 & 0xFFFFFFFF) * (op2 & 0xFFFFFFFF);\n+    uint64_t hi_lo = (op1 >> 32)        * (op2 & 0xFFFFFFFF);\n+    uint64_t lo_hi = (op1 & 0xFFFFFFFF) * (op2 >> 32);\n+    uint64_t hi_hi = (op1 >> 32)        * (op2 >> 32);\n+\n+    \/* Now add the products together. These will never overflow. *\/\n+    uint64_t cross = (lo_lo >> 32) + (hi_lo & 0xFFFFFFFF) + lo_hi;\n+    uint64_t upper = (hi_lo >> 32) + (cross >> 32)        + hi_hi;\n+    hi = upper;\n+    lo = (cross << 32) | (lo_lo & 0xFFFFFFFF);\n+#endif\n+  }\n+\n+  static void fullmul32(uint32_t& hi, uint32_t& lo, uint32_t op1, uint32_t op2) {\n+    uint64_t x64 = op1, y64 = op2, xy64 = x64 * y64;\n+    hi = (uint32_t)(xy64 >> 32);\n+    lo = (uint32_t)(xy64 >>  0);\n+  }\n+\n+  static uint64_t ror(uint64_t x, uint64_t distance) {\n+    distance = distance & 0x3F;\n+    return (x >> distance) | (x << (64 - distance));\n+  }\n+\n+public:\n+  static uint64_t get_hash64(uint64_t x, uint64_t y) {\n+    const uint64_t M  = 0x8ADAE89C337954D5;\n+    const uint64_t A  = 0xAAAAAAAAAAAAAAAA; \/\/ REPAA\n+    const uint64_t H0 = (x ^ y), L0 = (x ^ A);\n+\n+    uint64_t U0, V0; fullmul64(U0, V0, L0, M);\n+    const uint64_t Q0 = (H0 * M);\n+    const uint64_t L1 = (Q0 ^ U0);\n+\n+    uint64_t U1, V1; fullmul64(U1, V1, L1, M);\n+    const uint64_t P1 = (V0 ^ M);\n+    const uint64_t Q1 = ror(P1, L1);\n+    const uint64_t L2 = (Q1 ^ U1);\n+    return V1 ^ L2;\n+  }\n+\n+  static uint32_t get_hash32(uint32_t x, uint32_t y) {\n+    const uint32_t M  = 0x337954D5;\n+    const uint32_t A  = 0xAAAAAAAA; \/\/ REPAA\n+    const uint32_t H0 = (x ^ y), L0 = (x ^ A);\n+\n+    uint32_t U0, V0; fullmul32(U0, V0, L0, M);\n+    const uint32_t Q0 = (H0 * M);\n+    const uint32_t L1 = (Q0 ^ U0);\n+\n+    uint32_t U1, V1; fullmul32(U1, V1, L1, M);\n+    const uint32_t P1 = (V0 ^ M);\n+    const uint32_t Q1 = ror(P1, L1);\n+    const uint32_t L2 = (Q1 ^ U1);\n+    return V1 ^ L2;\n+  }\n+};\n+\n+#endif\/\/ SHARE_UTILITIES_FASTHASH_HPP\n","filename":"src\/hotspot\/share\/utilities\/fastHash.hpp","additions":97,"deletions":0,"binary":false,"changes":97,"status":"added"},{"patch":"@@ -27,0 +27,3 @@\n+import sun.jvm.hotspot.oops.Mark;\n+import sun.jvm.hotspot.runtime.VM;\n+\n@@ -397,1 +400,9 @@\n-    long value = readCInteger(address, getKlassPtrSize(), true);\n+    long value;\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      \/\/ On 64 bit systems, the compressed Klass* is currently read from the mark\n+      \/\/ word. We need to load the whole mark, and shift the upper parts.\n+      value = readCInteger(address, machDesc.getAddressSize(), true);\n+      value = value >>> Mark.getKlassShift();\n+    } else {\n+      value = readCInteger(address, getKlassPtrSize(), true);\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/debugger\/DebuggerBase.java","additions":12,"deletions":1,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -119,7 +119,0 @@\n-  \/\/ Check whether an element of a typeArrayOop with the given type must be\n-  \/\/ aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this\n-  \/\/ strongly.\n-  public static boolean elementTypeShouldBeAligned(BasicType type) {\n-    return type == BasicType.T_DOUBLE || type == BasicType.T_LONG;\n-  }\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/memory\/Universe.java","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -60,0 +60,12 @@\n+  \/\/ Check whether an element of a typeArrayOop with the given type must be\n+  \/\/ aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this\n+  \/\/ strongly.\n+  private static boolean elementTypeShouldBeAligned(BasicType type) {\n+    if (VM.getVM().isLP64()) {\n+      if (type == BasicType.T_OBJECT || type == BasicType.T_ARRAY) {\n+        return !VM.getVM().isCompressedOopsEnabled();\n+      }\n+    }\n+    return type == BasicType.T_DOUBLE || type == BasicType.T_LONG;\n+  }\n+\n@@ -64,1 +76,3 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      headerSize = lengthOffsetInBytes() + VM.getVM().getIntSize();\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n@@ -73,9 +87,1 @@\n-  private static long headerSize(BasicType type) {\n-    if (Universe.elementTypeShouldBeAligned(type)) {\n-       return alignObjectSize(headerSizeInBytes())\/VM.getVM().getHeapWordSize();\n-    } else {\n-      return headerSizeInBytes()\/VM.getVM().getHeapWordSize();\n-    }\n-  }\n-\n-  private long lengthOffsetInBytes() {\n+  private static long lengthOffsetInBytes() {\n@@ -85,1 +91,3 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      lengthOffsetInBytes = Oop.getHeaderSize();\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n@@ -111,1 +119,7 @@\n-    return headerSize(type) * VM.getVM().getHeapWordSize();\n+    long typeSizeInBytes = headerSizeInBytes();\n+    if (elementTypeShouldBeAligned(type)) {\n+      VM vm = VM.getVM();\n+      return vm.alignUp(typeSizeInBytes, vm.getVM().getHeapWordSize());\n+    } else {\n+      return typeSizeInBytes;\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Array.java","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -58,1 +58,3 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      return Oop.getHeaderSize();\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Instance.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -54,0 +54,1 @@\n+    hashBitsCompact     = db.lookupLongConstant(\"markWord::hash_bits_compact\").longValue();\n@@ -57,0 +58,4 @@\n+    hashShiftCompact    = db.lookupLongConstant(\"markWord::hash_shift_compact\").longValue();\n+    if (VM.getVM().isLP64()) {\n+      klassShift          = db.lookupLongConstant(\"markWord::klass_shift\").longValue();\n+    }\n@@ -63,0 +68,2 @@\n+    hashMaskCompact     = db.lookupLongConstant(\"markWord::hash_mask_compact\").longValue();\n+    hashMaskCompactInPlace = db.lookupLongConstant(\"markWord::hash_mask_compact_in_place\").longValue();\n@@ -81,0 +88,1 @@\n+  private static long hashBitsCompact;\n@@ -85,0 +93,2 @@\n+  private static long hashShiftCompact;\n+  private static long klassShift;\n@@ -92,0 +102,2 @@\n+  private static long hashMaskCompact;\n+  private static long hashMaskCompactInPlace;\n@@ -105,0 +117,4 @@\n+  public static long getKlassShift() {\n+    return klassShift;\n+  }\n+\n@@ -177,1 +193,5 @@\n-    return Bits.maskBitsLong(value() >> hashShift, hashMask);\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      return Bits.maskBitsLong(value() >> hashShiftCompact, hashMaskCompact);\n+    } else {\n+      return Bits.maskBitsLong(value() >> hashShift, hashMask);\n+    }\n@@ -184,0 +204,6 @@\n+  public Klass getKlass() {\n+    assert(VM.getVM().isCompactObjectHeadersEnabled());\n+    assert(!hasMonitor());\n+    return (Klass)Metadata.instantiateWrapperFor(addr.getCompKlassAddressAt(0));\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":27,"deletions":1,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -49,3 +49,8 @@\n-    klass      = new MetadataField(type.getAddressField(\"_metadata._klass\"), 0);\n-    compressedKlass  = new NarrowKlassField(type.getAddressField(\"_metadata._compressed_klass\"), 0);\n-    headerSize = type.getSize();\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      Type markType = db.lookupType(\"markWord\");\n+      headerSize = markType.getSize();\n+    } else {\n+      headerSize = type.getSize();\n+      klass      = new MetadataField(type.getAddressField(\"_metadata._klass\"), 0);\n+      compressedKlass  = new NarrowKlassField(type.getAddressField(\"_metadata._compressed_klass\"), 0);\n+    }\n@@ -78,0 +83,10 @@\n+\n+  private static Klass getKlass(Mark mark) {\n+    assert(VM.getVM().isCompactObjectHeadersEnabled());\n+    if (mark.hasMonitor()) {\n+      ObjectMonitor mon = mark.monitor();\n+      mark = mon.header();\n+    }\n+    return mark.getKlass();\n+  }\n+\n@@ -79,1 +94,4 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+        assert(VM.getVM().isCompressedKlassPointersEnabled());\n+        return getKlass(getMark());\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n@@ -150,4 +168,6 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-        visitor.doMetadata(compressedKlass, true);\n-      } else {\n-        visitor.doMetadata(klass, true);\n+      if (!VM.getVM().isCompactObjectHeadersEnabled()) {\n+        if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+          visitor.doMetadata(compressedKlass, true);\n+        } else {\n+          visitor.doMetadata(klass, true);\n+        }\n@@ -209,1 +229,4 @@\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n+    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n+      Mark mark = new Mark(handle);\n+      return getKlass(mark);\n+    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Oop.java","additions":32,"deletions":9,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -151,0 +151,1 @@\n+  private Boolean compactObjectHeadersEnabled;\n@@ -963,0 +964,9 @@\n+  public boolean isCompactObjectHeadersEnabled() {\n+    if (compactObjectHeadersEnabled == null) {\n+        Flag flag = getCommandLineFlag(\"UseCompactObjectHeaders\");\n+        compactObjectHeadersEnabled = (flag == null) ? Boolean.FALSE:\n+             (flag.getBool()? Boolean.TRUE: Boolean.FALSE);\n+    }\n+    return compactObjectHeadersEnabled.booleanValue();\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/VM.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+import sun.jvm.hotspot.oops.Oop;\n@@ -40,20 +41,0 @@\n-  private static AddressField klassField;\n-\n-  static {\n-    VM.registerVMInitializedObserver(new Observer() {\n-        public void update(Observable o, Object data) {\n-          initialize(VM.getVM().getTypeDataBase());\n-        }\n-      });\n-  }\n-\n-  private static void initialize(TypeDataBase db) {\n-    Type type = db.lookupType(\"oopDesc\");\n-\n-    if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      klassField = type.getAddressField(\"_metadata._compressed_klass\");\n-    } else {\n-      klassField = type.getAddressField(\"_metadata._klass\");\n-    }\n-  }\n-\n@@ -69,5 +50,1 @@\n-      if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-        Metadata.instantiateWrapperFor(oop.getCompKlassAddressAt(klassField.getOffset()));\n-      } else {\n-        Metadata.instantiateWrapperFor(klassField.getValue(oop));\n-      }\n+      Oop.getKlassForOopHandle(oop);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/RobustOopDeterminator.java","additions":2,"deletions":25,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -45,1 +46,1 @@\n-  static markWord originalMark() { return markWord(markWord::lock_mask_in_place); }\n+  static markWord originalMark() { return markWord(markWord::unlocked_value); }\n@@ -58,0 +59,2 @@\n+  FlagSetting fs(UseAltGCForwarding, false);\n+\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_preservedMarks.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,124 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n+#include \"oops\/markWord.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"utilities\/align.hpp\"\n+#include \"unittest.hpp\"\n+\n+#ifdef _LP64\n+#ifndef PRODUCT\n+\n+static uintptr_t make_mark(uintptr_t target_region, uintptr_t offset) {\n+  return (target_region) << 3 | (offset << 4) | 3 \/* forwarded *\/;\n+}\n+\n+static uintptr_t make_fallback() {\n+  return ((uintptr_t(1) << 2) \/* fallback *\/ | 3 \/* forwarded *\/);\n+}\n+\n+\/\/ Test simple forwarding within the same region.\n+TEST_VM(SlidingForwarding, simple) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop obj1 = cast_to_oop(&heap[2]);\n+  oop obj2 = cast_to_oop(&heap[0]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 8);\n+  obj1->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj2);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(0 \/* target_region *\/, 0 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj2);\n+\n+  SlidingForwarding::end();\n+}\n+\n+\/\/ Test forwardings crossing 2 regions.\n+TEST_VM(SlidingForwarding, tworegions) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop obj1 = cast_to_oop(&heap[14]);\n+  oop obj2 = cast_to_oop(&heap[2]);\n+  oop obj3 = cast_to_oop(&heap[10]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 8);\n+  obj1->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj2);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(0 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj2);\n+\n+  SlidingForwarding::forward_to<true>(obj1, obj3);\n+  ASSERT_EQ(obj1->mark().value(), make_mark(1 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(obj1), obj3);\n+\n+  SlidingForwarding::end();\n+}\n+\n+\/\/ Test fallback forwardings crossing 4 regions.\n+TEST_VM(SlidingForwarding, fallback) {\n+  FlagSetting fs(UseAltGCForwarding, true);\n+  HeapWord fakeheap[32] = { nullptr };\n+  HeapWord* heap = align_up(fakeheap, 8 * sizeof(HeapWord));\n+  oop s_obj1 = cast_to_oop(&heap[12]);\n+  oop s_obj2 = cast_to_oop(&heap[13]);\n+  oop s_obj3 = cast_to_oop(&heap[14]);\n+  oop s_obj4 = cast_to_oop(&heap[15]);\n+  oop t_obj1 = cast_to_oop(&heap[2]);\n+  oop t_obj2 = cast_to_oop(&heap[4]);\n+  oop t_obj3 = cast_to_oop(&heap[10]);\n+  oop t_obj4 = cast_to_oop(&heap[12]);\n+  SlidingForwarding::initialize(MemRegion(&heap[0], &heap[16]), 4);\n+  s_obj1->set_mark(markWord::prototype());\n+  s_obj2->set_mark(markWord::prototype());\n+  s_obj3->set_mark(markWord::prototype());\n+  s_obj4->set_mark(markWord::prototype());\n+  SlidingForwarding::begin();\n+\n+  SlidingForwarding::forward_to<true>(s_obj1, t_obj1);\n+  ASSERT_EQ(s_obj1->mark().value(), make_mark(0 \/* target_region *\/, 2 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj1), t_obj1);\n+\n+  SlidingForwarding::forward_to<true>(s_obj2, t_obj2);\n+  ASSERT_EQ(s_obj2->mark().value(), make_mark(1 \/* target_region *\/, 0 \/* offset *\/));\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj2), t_obj2);\n+\n+  SlidingForwarding::forward_to<true>(s_obj3, t_obj3);\n+  ASSERT_EQ(s_obj3->mark().value(), make_fallback());\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj3), t_obj3);\n+\n+  SlidingForwarding::forward_to<true>(s_obj4, t_obj4);\n+  ASSERT_EQ(s_obj4->mark().value(), make_fallback());\n+  ASSERT_EQ(SlidingForwarding::forwardee<true>(s_obj4), t_obj4);\n+\n+  SlidingForwarding::end();\n+}\n+\n+#endif \/\/ PRODUCT\n+#endif \/\/ _LP64\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_slidingForwarding.cpp","additions":124,"deletions":0,"binary":false,"changes":124,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,8 +30,0 @@\n-class arrayOopDescTest {\n- public:\n-\n-  static int header_size_in_bytes() {\n-    return arrayOopDesc::header_size_in_bytes();\n-  }\n-};\n-\n@@ -42,1 +34,1 @@\n-          + arrayOopDescTest::header_size_in_bytes();\n+          + arrayOopDesc::base_offset_in_bytes(type);\n@@ -90,0 +82,55 @@\n+\n+TEST_VM(arrayOopDesc, base_offset) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  12);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   12);\n+  } else if (UseCompressedClassPointers) {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  16);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   16);\n+  } else {\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   20);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    24);\n+    EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  24);\n+    if (UseCompressedOops) {\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT), 20);\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),  20);\n+    } else {\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT), 24);\n+      EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),  24);\n+    }\n+  }\n+#else\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BOOLEAN), 12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_BYTE),    12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_SHORT),   12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_CHAR),    12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_INT),     12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_FLOAT),   12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_LONG),    16);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_DOUBLE),  16);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_OBJECT),  12);\n+  EXPECT_EQ(arrayOopDesc::base_offset_in_bytes(T_ARRAY),   12);\n+#endif\n+}\n","filename":"test\/hotspot\/gtest\/oops\/test_arrayOop.cpp","additions":57,"deletions":10,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -0,0 +1,69 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"oops\/objArrayOop.hpp\"\n+#include \"unittest.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+TEST_VM(objArrayOop, osize) {\n+  static const struct {\n+    int objal; bool ccp; bool coops; bool coh; int result;\n+  } x[] = {\n+\/\/    ObjAligInB, UseCCP, UseCoops, UseCOH, object size in heap words\n+#ifdef _LP64\n+    { 8,          false,  false,    false,  4 },  \/\/ 20 byte header, 8 byte oops\n+    { 8,          false,  true,     false,  3 },  \/\/ 20 byte header, 4 byte oops\n+    { 8,          true,   false,    false,  3 },  \/\/ 16 byte header, 8 byte oops\n+    { 8,          true,   true,     false,  3 },  \/\/ 16 byte header, 4 byte oops\n+    { 16,         false,  false,    false,  4 },  \/\/ 20 byte header, 8 byte oops, 16-byte align\n+    { 16,         false,  true,     false,  4 },  \/\/ 20 byte header, 4 byte oops, 16-byte align\n+    { 16,         true,   false,    false,  4 },  \/\/ 16 byte header, 8 byte oops, 16-byte align\n+    { 16,         true,   true,     false,  4 },  \/\/ 16 byte header, 4 byte oops, 16-byte align\n+    { 256,        false,  false,    false,  32 }, \/\/ 20 byte header, 8 byte oops, 256-byte align\n+    { 256,        false,  true,     false,  32 }, \/\/ 20 byte header, 4 byte oops, 256-byte align\n+    { 256,        true,   false,    false,  32 }, \/\/ 16 byte header, 8 byte oops, 256-byte align\n+    { 256,        true,   true,     false,  32 }, \/\/ 16 byte header, 4 byte oops, 256-byte align\n+    { 8,          false,  false,    true,   3 },  \/\/ 16 byte header, 8 byte oops\n+    { 8,          false,  true,     true,   2 },  \/\/ 12 byte header, 4 byte oops\n+    { 8,          true,   false,    true,   3 },  \/\/ 16 byte header, 8 byte oops\n+    { 8,          true,   true,     true,   2 },  \/\/ 12 byte header, 4 byte oops\n+    { 16,         false,  false,    true,   4 },  \/\/ 16 byte header, 8 byte oops, 16-byte align\n+    { 16,         false,  true,     true,   2 },  \/\/ 12 byte header, 4 byte oops, 16-byte align\n+    { 16,         true,   false,    true,   4 },  \/\/ 16 byte header, 8 byte oops, 16-byte align\n+    { 16,         true,   true,     true,   2 },  \/\/ 12 byte header, 4 byte oops, 16-byte align\n+    { 256,        false,  false,    true,   32 }, \/\/ 16 byte header, 8 byte oops, 256-byte align\n+    { 256,        false,  true,     true,   32 }, \/\/ 12 byte header, 4 byte oops, 256-byte align\n+    { 256,        true,   false,    true,   32 }, \/\/ 16 byte header, 8 byte oops, 256-byte align\n+    { 256,        true,   true,     true,   32 }, \/\/ 12 byte header, 4 byte oops, 256-byte align\n+#else\n+    { 8,          false,  false,    false,  4 }, \/\/ 12 byte header, 4 byte oops, wordsize 4\n+#endif\n+    { -1,         false,  false,    false, -1 }\n+  };\n+  for (int i = 0; x[i].result != -1; i++) {\n+    if (x[i].objal == (int)ObjectAlignmentInBytes && x[i].ccp == UseCompressedClassPointers && x[i].coops == UseCompressedOops && x[i].coh == UseCompactObjectHeaders) {\n+      EXPECT_EQ(objArrayOopDesc::object_size(1), (size_t)x[i].result);\n+    }\n+  }\n+}\n","filename":"test\/hotspot\/gtest\/oops\/test_objArrayOop.cpp","additions":69,"deletions":0,"binary":false,"changes":69,"status":"added"},{"patch":"@@ -39,1 +39,5 @@\n-  o->set_klass(Universe::boolArrayKlassObj());\n+  if (UseCompactObjectHeaders) {\n+    o->set_mark(Universe::boolArrayKlassObj()->prototype_header());\n+  } else {\n+    o->set_klass(Universe::boolArrayKlassObj());\n+  }\n","filename":"test\/hotspot\/gtest\/oops\/test_typeArrayOop.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,29 @@\n+#\n+# Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+#\n+# This code is free software; you can redistribute it and\/or modify it\n+# under the terms of the GNU General Public License version 2 only, as\n+# published by the Free Software Foundation.\n+#\n+# This code is distributed in the hope that it will be useful, but WITHOUT\n+# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+# version 2 for more details (a copy is included in the LICENSE file that\n+# accompanied this code).\n+#\n+# You should have received a copy of the GNU General Public License version\n+# 2 along with this work; if not, write to the Free Software Foundation,\n+# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+#\n+# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+# or visit www.oracle.com if you need additional information or have any\n+# questions.\n+#\n+\n+#\n+# These tests are problematic when +UseCompactObjectHeaders is enabled.\n+# The test exclusions are for the cases when we are sure the tests would fail\n+# for the known and innocuous implementation reasons.\n+#\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList-lilliput.txt","additions":29,"deletions":0,"binary":false,"changes":29,"status":"added"},{"patch":"@@ -35,1 +35,1 @@\n- * @run main\/timeout=240 gc.g1.plab.TestPLABPromotion\n+ * @run main\/othervm\/timeout=240 -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI gc.g1.plab.TestPLABPromotion\n@@ -51,0 +51,1 @@\n+import jdk.test.whitebox.WhiteBox;\n@@ -57,0 +58,2 @@\n+    private static final boolean COMPACT_HEADERS = Platform.is64bit() && WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompactObjectHeaders\");\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/plab\/TestPLABPromotion.java","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,107 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=default\n+ * @library \/test\/lib \/\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI BaseOffsets\n+ *\/\n+\/*\n+ * @test id=no-coops\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops BaseOffsets\n+ *\/\n+\n+import java.lang.reflect.Field;\n+import java.util.Arrays;\n+import java.util.Comparator;\n+import jdk.internal.misc.Unsafe;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Platform;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class BaseOffsets {\n+\n+    static class LIClass {\n+        public int i;\n+    }\n+\n+    public static final WhiteBox WB = WhiteBox.getWhiteBox();\n+\n+  \/\/ @0:  8 byte header,  @8: int field\n+    static final long INT_OFFSET;\n+    static final int  INT_ARRAY_OFFSET;\n+    static final int  LONG_ARRAY_OFFSET;\n+    static {\n+        if (!Platform.is64bit() || WB.getBooleanVMFlag(\"UseCompactObjectHeaders\")) {\n+            INT_OFFSET = 8;\n+            INT_ARRAY_OFFSET = 12;\n+            LONG_ARRAY_OFFSET = 16;\n+        } else if (WB.getBooleanVMFlag(\"UseCompressedClassPointers\")) {\n+            INT_OFFSET = 12;\n+            INT_ARRAY_OFFSET = 16;\n+            LONG_ARRAY_OFFSET = 16;\n+        } else {\n+            INT_OFFSET = 16;\n+            INT_ARRAY_OFFSET = 20;\n+            LONG_ARRAY_OFFSET = 24;\n+        }\n+    }\n+\n+    static public void main(String[] args) {\n+        Unsafe unsafe = Unsafe.getUnsafe();\n+        Class c = LIClass.class;\n+        Field[] fields = c.getFields();\n+        for (int i = 0; i < fields.length; i++) {\n+            long offset = unsafe.objectFieldOffset(fields[i]);\n+            if (fields[i].getType() == int.class) {\n+                Asserts.assertEquals(offset, INT_OFFSET, \"Misplaced int field\");\n+            } else {\n+                Asserts.fail(\"Unexpected field type\");\n+            }\n+        }\n+\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(boolean[].class), INT_ARRAY_OFFSET,  \"Misplaced boolean array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(byte[].class),    INT_ARRAY_OFFSET,  \"Misplaced byte    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(char[].class),    INT_ARRAY_OFFSET,  \"Misplaced char    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(short[].class),   INT_ARRAY_OFFSET,  \"Misplaced short   array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(int[].class),     INT_ARRAY_OFFSET,  \"Misplaced int     array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(long[].class),    LONG_ARRAY_OFFSET, \"Misplaced long    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(float[].class),   INT_ARRAY_OFFSET,  \"Misplaced float   array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(double[].class),  LONG_ARRAY_OFFSET, \"Misplaced double  array base\");\n+        boolean narrowOops = System.getProperty(\"java.vm.compressedOopsMode\") != null ||\n+                             !Platform.is64bit();\n+        int expected_objary_offset = narrowOops ? INT_ARRAY_OFFSET : LONG_ARRAY_OFFSET;\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(Object[].class),  expected_objary_offset, \"Misplaced object  array base\");\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/BaseOffsets.java","additions":107,"deletions":0,"binary":false,"changes":107,"status":"added"},{"patch":"@@ -28,1 +28,1 @@\n- * @library \/test\/lib\n+ * @library \/test\/lib \/\n@@ -32,1 +32,3 @@\n- * @run main\/othervm -XX:+UseCompressedClassPointers -XX:-UseEmptySlotsInSupers OldLayoutCheck\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedClassPointers -XX:-UseEmptySlotsInSupers OldLayoutCheck\n@@ -38,1 +40,1 @@\n- * @library \/test\/lib\n+ * @library \/test\/lib \/\n@@ -41,1 +43,3 @@\n- * @run main\/othervm -XX:-UseEmptySlotsInSupers OldLayoutCheck\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseEmptySlotsInSupers OldLayoutCheck\n@@ -51,0 +55,1 @@\n+import jdk.test.whitebox.WhiteBox;\n@@ -59,4 +64,15 @@\n-    \/\/ 32-bit VMs: @0:  8 byte header,  @8: long field, @16:  int field\n-    \/\/ 64-bit VMs: @0: 12 byte header, @12:  int field, @16: long field\n-    static final long INT_OFFSET  = Platform.is64bit() ? 12L : 16L;\n-    static final long LONG_OFFSET = Platform.is64bit() ? 16L :  8L;\n+    public static final WhiteBox WB = WhiteBox.getWhiteBox();\n+\n+    \/\/ 32-bit VMs\/compact headers: @0:  8 byte header,  @8: long field, @16:  int field\n+    \/\/ 64-bit VMs:                 @0: 12 byte header, @12:  int field, @16: long field\n+    static final long INT_OFFSET;\n+    static final long LONG_OFFSET;\n+    static {\n+      if (!Platform.is64bit() || WB.getBooleanVMFlag(\"UseCompactObjectHeaders\")) {\n+        INT_OFFSET = 16L;\n+        LONG_OFFSET = 8L;\n+      } else {\n+        INT_OFFSET = 12L;\n+        LONG_OFFSET = 16L;\n+      }\n+    }\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/OldLayoutCheck.java","additions":24,"deletions":8,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -0,0 +1,66 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test CdsDifferentCompactObjectHeaders\n+ * @summary Testing CDS (class data sharing) using opposite compact object header settings.\n+ *          Using different compact bject headers setting for each dump\/load pair.\n+ *          This is a negative test; using compact header setting for loading that\n+ *          is different from compact headers for creating a CDS file\n+ *          should fail when loading.\n+ * @requires vm.cds\n+ * @requires vm.bits == 64\n+ * @library \/test\/lib\n+ * @run driver CdsDifferentCompactObjectHeaders\n+ *\/\n+\n+import jdk.test.lib.cds.CDSTestUtils;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.Platform;\n+\n+public class CdsDifferentCompactObjectHeaders {\n+\n+    public static void main(String[] args) throws Exception {\n+        createAndLoadSharedArchive(true, false);\n+        createAndLoadSharedArchive(false, true);\n+    }\n+\n+    \/\/ Parameters are object alignment expressed in bytes\n+    private static void\n+    createAndLoadSharedArchive(boolean createCompactHeaders, boolean loadCompactHeaders)\n+    throws Exception {\n+        String createCompactHeadersArg = \"-XX:\" + (createCompactHeaders ? \"+\" : \"-\") + \"UseCompactObjectHeaders\";\n+        String loadCompactHeadersArg   = \"-XX:\" + (loadCompactHeaders   ? \"+\" : \"-\") + \"UseCompactObjectHeaders\";\n+        String expectedErrorMsg =\n+            String.format(\n+            \"The shared archive file's UseCompactObjectHeaders setting (%s)\" +\n+            \" does not equal the current UseCompactObjectHeaders setting (%s)\",\n+            createCompactHeaders ? \"enabled\" : \"disabled\",\n+            loadCompactHeaders   ? \"enabled\" : \"disabled\");\n+\n+        CDSTestUtils.createArchiveAndCheck(\"-XX:+UnlockExperimentalVMOptions\", createCompactHeadersArg);\n+\n+        OutputAnalyzer out = CDSTestUtils.runWithArchive(\"-Xlog:cds\", \"-XX:+UnlockExperimentalVMOptions\", loadCompactHeadersArg);\n+        CDSTestUtils.checkExecExpectError(out, 1, expectedErrorMsg);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/CdsDifferentCompactObjectHeaders.java","additions":66,"deletions":0,"binary":false,"changes":66,"status":"added"},{"patch":"@@ -166,0 +166,1 @@\n+                      \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n@@ -179,0 +180,1 @@\n+                                      \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/TestCombinedCompressedFlags.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+         String compactHeaders = \"-XX:\" + (zGenerational.equals(\"-XX:+ZGenerational\") ? \"+\" : \"-\") + \"UseCompactObjectHeaders\";\n@@ -66,0 +67,2 @@\n+                                        \"-XX:+UnlockExperimentalVMOptions\",\n+                                        compactHeaders,\n@@ -75,0 +78,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -86,0 +91,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -98,0 +105,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -110,0 +119,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -121,0 +132,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -133,0 +146,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -146,0 +161,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n@@ -155,0 +172,2 @@\n+                         \"-XX:+UnlockExperimentalVMOptions\",\n+                         compactHeaders,\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/TestZGCWithCDS.java","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -170,1 +170,1 @@\n-                                                \"-XX:+UseZGC\", zGenerational, \"-XX:ZCollectionInterval=0.01\",\n+                                                \"-XX:+UseZGC\", zGenerational, \"-XX:ZCollectionInterval=0.01\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/loaderConstraints\/DynamicLoaderConstraintsTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -304,0 +304,1 @@\n+    private static final boolean COMPACT_HEADERS = Platform.is64bit() && WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompactObjectHeaders\");\n@@ -374,0 +375,10 @@\n+    private static long expectedSmallObjSize() {\n+        long size;\n+        if (!Platform.is64bit() || COMPACT_HEADERS) {\n+            size = 8;\n+        } else {\n+            size = 16;\n+        }\n+        return roundUp(size, OBJ_ALIGN);\n+    }\n+\n@@ -375,1 +386,1 @@\n-        long expected = roundUp(Platform.is64bit() ? 16 : 8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n@@ -382,1 +393,1 @@\n-        long expected = roundUp(Platform.is64bit() ? 16 : 8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n@@ -392,1 +403,1 @@\n-        long expected = roundUp(Platform.is64bit() ? 16 : 8, OBJ_ALIGN);\n+        long expected = expectedSmallObjSize();\n","filename":"test\/jdk\/java\/lang\/instrument\/GetObjectSizeIntrinsicsTest.java","additions":14,"deletions":3,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -678,1 +678,5 @@\n-                \"CreateCoredumpOnCrash\"\n+                \"CreateCoredumpOnCrash\",\n+                \/\/ experimental features unlocking flag does not affect behavior\n+                \"UnlockExperimentalVMOptions\",\n+                \/\/ all compact headers settings should run flagless tests\n+                \"UseCompactObjectHeaders\"\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"}]}