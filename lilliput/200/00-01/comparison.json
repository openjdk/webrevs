{"files":[{"patch":"@@ -79,1 +79,1 @@\n-#include \"gc\/shared\/fullGCForwarding.hpp\"\n+#include \"gc\/shared\/fullGCForwarding.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"gc\/shared\/fullGCForwarding.hpp\"\n","filename":"src\/hotspot\/share\/gc\/serial\/serialArguments.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-#include \"gc\/shared\/fullGCForwarding.hpp\"\n+#include \"gc\/shared\/fullGCForwarding.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/serial\/serialHeap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,186 +0,0 @@\n-\/*\n- * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"gc\/shared\/fullGCForwarding.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"nmt\/memTag.hpp\"\n-#include \"utilities\/ostream.hpp\"\n-#include \"utilities\/concurrentHashTable.inline.hpp\"\n-#include \"utilities\/fastHash.hpp\"\n-#include \"utilities\/powerOfTwo.hpp\"\n-\n-static uintx hash(HeapWord* const& addr) {\n-  uint64_t val = reinterpret_cast<uint64_t>(addr);\n-  uint32_t hash = FastHash::get_hash32((uint32_t)val, (uint32_t)(val >> 32));\n-  return hash;\n-}\n-\n-struct ForwardingEntry {\n-  HeapWord* _from;\n-  HeapWord* _to;\n-  ForwardingEntry(HeapWord* from, HeapWord* to) : _from(from), _to(to) {}\n-};\n-\n-struct FallbackTableConfig {\n-  using Value = ForwardingEntry;\n-  static uintx get_hash(Value const& entry, bool* is_dead) {\n-    return hash(entry._from);\n-  }\n-  static void* allocate_node(void* context, size_t size, Value const& value) {\n-    return AllocateHeap(size, mtGC);\n-  }\n-  static void free_node(void* context, void* memory, Value const& value) {\n-    FreeHeap(memory);\n-  }\n-};\n-\n-class FallbackTable : public ConcurrentHashTable<FallbackTableConfig, mtGC> {\n-\n-};\n-\n-class FallbackTableLookup : public StackObj {\n-  ForwardingEntry const _entry;\n-public:\n-  explicit FallbackTableLookup(HeapWord* from) : _entry(from, nullptr) {}\n-  uintx get_hash() const {\n-    return hash(_entry._from);\n-  }\n-  bool equals(ForwardingEntry* value) {\n-    return _entry._from == value->_from;\n-  }\n-  bool is_dead(ForwardingEntry* value) { return false; }\n-};\n-\n-\/\/ We cannot use 0, because that may already be a valid base address in zero-based heaps.\n-\/\/ 0x1 is safe because heap base addresses must be aligned by much larger alignment\n-HeapWord* const FullGCForwarding::UNUSED_BASE = reinterpret_cast<HeapWord*>(0x1);\n-\n-HeapWord* FullGCForwarding::_heap_start = nullptr;\n-size_t FullGCForwarding::_heap_start_region_bias = 0;\n-size_t FullGCForwarding::_num_regions = 0;\n-uintptr_t FullGCForwarding::_region_mask = 0;\n-HeapWord** FullGCForwarding::_biased_bases = nullptr;\n-HeapWord** FullGCForwarding::_bases_table = nullptr;\n-FallbackTable* FullGCForwarding::_fallback_table = nullptr;\n-#ifndef PRODUCT\n-volatile uint64_t FullGCForwarding::_num_forwardings = 0;\n-volatile uint64_t FullGCForwarding::_num_fallback_forwardings = 0;\n-#endif\n-\n-void FullGCForwarding::initialize(MemRegion heap) {\n-#ifdef _LP64\n-  _heap_start = heap.start();\n-\n-  size_t rounded_heap_size = round_up_power_of_2(heap.byte_size());\n-\n-  _num_regions = (rounded_heap_size \/ BytesPerWord) \/ BLOCK_SIZE_WORDS;\n-\n-  _heap_start_region_bias = (uintptr_t)_heap_start >> BLOCK_SIZE_BYTES_SHIFT;\n-  _region_mask = ~((uintptr_t(1) << BLOCK_SIZE_BYTES_SHIFT) - 1);\n-\n-  assert(_bases_table == nullptr, \"should not be initialized yet\");\n-  assert(_fallback_table == nullptr, \"should not be initialized yet\");\n-#endif\n-}\n-\n-void FullGCForwarding::begin() {\n-#ifdef _LP64\n-  assert(_bases_table == nullptr, \"should not be initialized yet\");\n-  assert(_fallback_table == nullptr, \"should not be initialized yet\");\n-\n-  _fallback_table = new FallbackTable();\n-\n-#ifndef PRODUCT\n-  _num_forwardings = 0;\n-  _num_fallback_forwardings = 0;\n-#endif\n-\n-  size_t max = _num_regions;\n-  _bases_table = NEW_C_HEAP_ARRAY(HeapWord*, max, mtGC);\n-  HeapWord** biased_start = _bases_table - _heap_start_region_bias;\n-  _biased_bases = biased_start;\n-  for (size_t i = 0; i < max; i++) {\n-    _bases_table[i] = UNUSED_BASE;\n-  }\n-#endif\n-}\n-\n-void FullGCForwarding::end() {\n-#ifndef PRODUCT\n-  log_info(gc)(\"Total forwardings: \" UINT64_FORMAT \", fallback forwardings: \" UINT64_FORMAT\n-                \", ratio: %f, memory used by fallback table: %zu%s, memory used by bases table: %zu%s\",\n-               _num_forwardings, _num_fallback_forwardings, (float)_num_forwardings\/(float)_num_fallback_forwardings,\n-               byte_size_in_proper_unit(_fallback_table->get_mem_size(Thread::current())),\n-               proper_unit_for_byte_size(_fallback_table->get_mem_size(Thread::current())),\n-               byte_size_in_proper_unit(sizeof(HeapWord*) * _num_regions),\n-               proper_unit_for_byte_size(sizeof(HeapWord*) * _num_regions));\n-#endif\n-#ifdef _LP64\n-  assert(_bases_table != nullptr, \"should be initialized\");\n-  FREE_C_HEAP_ARRAY(HeapWord*, _bases_table);\n-  _bases_table = nullptr;\n-  delete _fallback_table;\n-  _fallback_table = nullptr;\n-#endif\n-}\n-\n-void FullGCForwarding::fallback_forward_to(HeapWord* from, HeapWord* to) {\n-  assert(to != nullptr, \"no null forwarding\");\n-  assert(_fallback_table != nullptr, \"should be initialized\");\n-  FallbackTableLookup lookup_f(from);\n-  ForwardingEntry entry(from, to);\n-  auto found_f = [&](ForwardingEntry* found) {\n-    \/\/ If dupe has been found, override it with new value.\n-    \/\/ This is also called when new entry is succussfully inserted.\n-    if (found->_to != to) {\n-      found->_to = to;\n-    }\n-  };\n-  Thread* current_thread = Thread::current();\n-  bool grow;\n-  bool added = _fallback_table->insert_get(current_thread, lookup_f, entry, found_f, &grow);\n-  NOT_PRODUCT(Atomic::inc(&_num_fallback_forwardings);)\n-#ifdef ASSERT\n-  assert(fallback_forwardee(from) != nullptr, \"must have entered forwarding\");\n-  assert(fallback_forwardee(from) == to, \"forwarding must be correct, added: %s, from: \" PTR_FORMAT \", to: \" PTR_FORMAT \", fwd: \" PTR_FORMAT, BOOL_TO_STR(added), p2i(from), p2i(to), p2i(fallback_forwardee(from)));\n-#endif\n-  if (grow) {\n-    _fallback_table->grow(current_thread);\n-    tty->print_cr(\"grow fallback table to size: %zu bytes\",\n-                  _fallback_table->get_mem_size(current_thread));\n-  }\n-}\n-\n-HeapWord* FullGCForwarding::fallback_forwardee(HeapWord* from) {\n-  assert(_fallback_table != nullptr, \"fallback table must be present\");\n-  HeapWord* result;\n-  FallbackTableLookup lookup_f(from);\n-  auto found_f = [&](ForwardingEntry* found) {\n-    result = found->_to;\n-  };\n-  bool found = _fallback_table->get(Thread::current(), lookup_f, found_f);\n-  assert(found, \"something must have been found\");\n-  assert(result != nullptr, \"must have found forwarding\");\n-  return result;\n-}\n","filename":"src\/hotspot\/share\/gc\/shared\/fullGCForwarding.cpp","additions":0,"deletions":186,"binary":false,"changes":186,"status":"deleted"},{"patch":"@@ -34,1 +34,0 @@\n-class Mutex;\n@@ -119,4 +118,5 @@\n-class FullGCForwarding : public AllStatic {\n-private:\n-  static constexpr int AVAILABLE_LOW_BITS       = 11;\n-  static constexpr int AVAILABLE_BITS_MASK      = right_n_bits(AVAILABLE_LOW_BITS);\n+template <int BITS>\n+class FullGCForwardingImpl : public AllStatic {\n+  friend class FullGCForwardingTest;\n+  static constexpr int AVAILABLE_LOW_BITS        = BITS;\n+  static constexpr uintptr_t AVAILABLE_BITS_MASK = right_n_bits(AVAILABLE_LOW_BITS);\n@@ -130,1 +130,1 @@\n-  static constexpr size_t BLOCK_SIZE_WORDS = 1 << NUM_OFFSET_BITS;\n+  static constexpr size_t BLOCK_SIZE_WORDS = 1ll << NUM_OFFSET_BITS;\n@@ -156,0 +156,1 @@\n+  static size_t _fallback_table_log2_start_size;\n@@ -163,1 +164,1 @@\n-  static inline size_t biased_region_index_containing(HeapWord* addr);\n+  static size_t biased_region_index_containing(HeapWord* addr);\n@@ -165,3 +166,3 @@\n-  static inline bool is_fallback(uintptr_t encoded);\n-  static inline uintptr_t encode_forwarding(HeapWord* from, HeapWord* to);\n-  static inline HeapWord* decode_forwarding(HeapWord* from, uintptr_t encoded);\n+  static bool is_fallback(uintptr_t encoded);\n+  static uintptr_t encode_forwarding(HeapWord* from, HeapWord* to);\n+  static HeapWord* decode_forwarding(HeapWord* from, uintptr_t encoded);\n@@ -169,0 +170,1 @@\n+  static void maybe_init_fallback_table();\n@@ -172,2 +174,2 @@\n-  static inline void forward_to_impl(oop from, oop to);\n-  static inline oop forwardee_impl(oop from);\n+  static void forward_to_impl(oop from, oop to);\n+  static oop forwardee_impl(oop from);\n@@ -175,0 +177,6 @@\n+  FullGCForwardingImpl() = delete;\n+\n+  \/\/ Used in unit-test, so that we can test fallback-table-growth.\n+  static void set_fallback_table_log2_start_size(size_t fallback_table_log2_start_size) {\n+    _fallback_table_log2_start_size = fallback_table_log2_start_size;\n+  }\n@@ -181,2 +189,1 @@\n-  static inline bool is_forwarded(oop obj);\n-  static inline bool is_not_forwarded(oop obj);\n+  static bool is_forwarded(oop obj);\n@@ -184,2 +191,2 @@\n-  static inline void forward_to(oop from, oop to);\n-  static inline oop forwardee(oop from);\n+  static void forward_to(oop from, oop to);\n+  static oop forwardee(oop from);\n@@ -188,0 +195,8 @@\n+#ifdef _LP64\n+using FullGCForwarding = FullGCForwardingImpl<markWord::klass_shift>;\n+#else\n+\/\/ On 32 bit, the BITS template argument is not used, but we still need\n+\/\/ to pass a value.\n+using FullGCForwarding = FullGCForwardingImpl<0>;\n+#endif\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/fullGCForwarding.hpp","additions":31,"deletions":16,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"gc\/shared\/gc_globals.hpp\"\n@@ -29,0 +28,2 @@\n+#include \"logging\/log.hpp\"\n+#include \"nmt\/memTag.hpp\"\n@@ -31,0 +32,2 @@\n+#include \"utilities\/concurrentHashTable.inline.hpp\"\n+#include \"utilities\/fastHash.hpp\"\n@@ -32,0 +35,1 @@\n+#include \"utilities\/powerOfTwo.hpp\"\n@@ -33,1 +37,30 @@\n-inline bool FullGCForwarding::is_forwarded(oop obj) {\n+\/\/ We cannot use 0, because that may already be a valid base address in zero-based heaps.\n+\/\/ 0x1 is safe because heap base addresses must be aligned by much larger alignment\n+template <int BITS>\n+HeapWord* const FullGCForwardingImpl<BITS>::UNUSED_BASE = reinterpret_cast<HeapWord*>(0x1);\n+\n+template <int BITS>\n+HeapWord* FullGCForwardingImpl<BITS>::_heap_start = nullptr;\n+template <int BITS>\n+size_t FullGCForwardingImpl<BITS>::_heap_start_region_bias = 0;\n+template <int BITS>\n+size_t FullGCForwardingImpl<BITS>::_num_regions = 0;\n+template <int BITS>\n+uintptr_t FullGCForwardingImpl<BITS>::_region_mask = 0;\n+template <int BITS>\n+HeapWord** FullGCForwardingImpl<BITS>::_biased_bases = nullptr;\n+template <int BITS>\n+HeapWord** FullGCForwardingImpl<BITS>::_bases_table = nullptr;\n+template <int BITS>\n+size_t FullGCForwardingImpl<BITS>::_fallback_table_log2_start_size = 9; \/\/ 512 entries.\n+template <int BITS>\n+FallbackTable* FullGCForwardingImpl<BITS>::_fallback_table = nullptr;\n+#ifndef PRODUCT\n+template <int BITS>\n+volatile uint64_t FullGCForwardingImpl<BITS>::_num_forwardings = 0;\n+template <int BITS>\n+volatile uint64_t FullGCForwardingImpl<BITS>::_num_fallback_forwardings = 0;\n+#endif\n+\n+template <int BITS>\n+bool FullGCForwardingImpl<BITS>::is_forwarded(oop obj) {\n@@ -37,2 +70,3 @@\n-size_t FullGCForwarding::biased_region_index_containing(HeapWord* addr) {\n-  return (uintptr_t)addr >> BLOCK_SIZE_BYTES_SHIFT;\n+template <int BITS>\n+size_t FullGCForwardingImpl<BITS>::biased_region_index_containing(HeapWord* addr) {\n+  return reinterpret_cast<uintptr_t>(addr) >> BLOCK_SIZE_BYTES_SHIFT;\n@@ -41,1 +75,2 @@\n-bool FullGCForwarding::is_fallback(uintptr_t encoded) {\n+template <int BITS>\n+bool FullGCForwardingImpl<BITS>::is_fallback(uintptr_t encoded) {\n@@ -45,1 +80,2 @@\n-uintptr_t FullGCForwarding::encode_forwarding(HeapWord* from, HeapWord* to) {\n+template <int BITS>\n+uintptr_t FullGCForwardingImpl<BITS>::encode_forwarding(HeapWord* from, HeapWord* to) {\n@@ -50,1 +86,7 @@\n-    _biased_bases[from_block_idx] = to_region_base = to;\n+    HeapWord* prev = Atomic::cmpxchg(&_biased_bases[from_block_idx], UNUSED_BASE, to);\n+    if (prev == UNUSED_BASE) {\n+      to_region_base = to;\n+    } else {\n+      to_region_base = prev;\n+    }\n+    \/\/ _biased_bases[from_block_idx] = to_region_base = to;\n@@ -52,1 +94,0 @@\n-\n@@ -57,1 +98,1 @@\n-  size_t offset = size_t(to - to_region_base);\n+  size_t offset = static_cast<size_t>(to - to_region_base);\n@@ -63,1 +104,1 @@\n-  assert(is_fallback(encoded) || to == decode_forwarding(from, encoded), \"must be reversible\");\n+  assert(is_fallback(encoded) || to == decode_forwarding(from, encoded), \"must be reversible: \" PTR_FORMAT \" -> \" PTR_FORMAT \", reversed: \" PTR_FORMAT \", encoded: \" INTPTR_FORMAT \", to_region_base: \" PTR_FORMAT \", from_block_idx: %lu\", p2i(from), p2i(to), p2i(decode_forwarding(from, encoded)), encoded, p2i(to_region_base), from_block_idx);\n@@ -68,1 +109,2 @@\n-HeapWord* FullGCForwarding::decode_forwarding(HeapWord* from, uintptr_t encoded) {\n+template <int BITS>\n+HeapWord* FullGCForwardingImpl<BITS>::decode_forwarding(HeapWord* from, uintptr_t encoded) {\n@@ -84,1 +126,2 @@\n-inline void FullGCForwarding::forward_to_impl(oop from, oop to) {\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::forward_to_impl(oop from, oop to) {\n@@ -100,1 +143,2 @@\n-inline void FullGCForwarding::forward_to(oop obj, oop fwd) {\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::forward_to(oop obj, oop fwd) {\n@@ -105,1 +149,1 @@\n-  assert(forwardee(obj) == fwd, \"must be forwarded to correct forwardee, obj: \" PTR_FORMAT \", forwardee(obj): \" PTR_FORMAT \", fwd: \" PTR_FORMAT \", mark: \" INTPTR_FORMAT, p2i(obj), p2i(forwardee(obj)), p2i(fwd), obj->mark().value());\n+  \/\/ assert(forwardee(obj) == fwd, \"must be forwarded to correct forwardee, obj: \" PTR_FORMAT \", forwardee(obj): \" PTR_FORMAT \", fwd: \" PTR_FORMAT \", mark: \" INTPTR_FORMAT \", num-regions: %lu, base: \" PTR_FORMAT \", OFFSET_MASK: \" INTPTR_FORMAT \", encoded: \" PTR_FORMAT \", biased-base: \" PTR_FORMAT \", heap-start: \" PTR_FORMAT, p2i(obj), p2i(forwardee(obj)), p2i(fwd), obj->mark().value(), _num_regions, p2i(_bases_table[0]), OFFSET_MASK, encode_forwarding(cast_from_oop<HeapWord*>(obj), cast_from_oop<HeapWord*>(fwd)), p2i(_biased_bases[biased_region_index_containing(cast_from_oop<HeapWord*>(obj))]), p2i(_heap_start));\n@@ -111,1 +155,2 @@\n-inline oop FullGCForwarding::forwardee_impl(oop from) {\n+template <int BITS>\n+oop FullGCForwardingImpl<BITS>::forwardee_impl(oop from) {\n@@ -125,1 +170,2 @@\n-inline oop FullGCForwarding::forwardee(oop obj) {\n+template <int BITS>\n+oop FullGCForwardingImpl<BITS>::forwardee(oop obj) {\n@@ -134,0 +180,169 @@\n+static uintx hash(HeapWord* const& addr) {\n+  uint64_t val = reinterpret_cast<uint64_t>(addr);\n+  uint32_t hash = FastHash::get_hash32(static_cast<uint32_t>(val), static_cast<uint32_t>(val >> 32));\n+  return hash;\n+}\n+\n+struct ForwardingEntry {\n+  HeapWord* _from;\n+  HeapWord* _to;\n+  ForwardingEntry(HeapWord* from, HeapWord* to) : _from(from), _to(to) {}\n+};\n+\n+struct FallbackTableConfig {\n+  using Value = ForwardingEntry;\n+  static uintx get_hash(Value const& entry, bool* is_dead) {\n+    return hash(entry._from);\n+  }\n+  static void* allocate_node(void* context, size_t size, Value const& value) {\n+    return AllocateHeap(size, mtGC);\n+  }\n+  static void free_node(void* context, void* memory, Value const& value) {\n+    FreeHeap(memory);\n+  }\n+};\n+\n+class FallbackTable : public ConcurrentHashTable<FallbackTableConfig, mtGC> {\n+public:\n+  explicit FallbackTable(size_t log2size) : ConcurrentHashTable(log2size) {}\n+};\n+\n+class FallbackTableLookup : public StackObj {\n+  ForwardingEntry const _entry;\n+public:\n+  explicit FallbackTableLookup(HeapWord* from) : _entry(from, nullptr) {}\n+  uintx get_hash() const {\n+    return hash(_entry._from);\n+  }\n+  bool equals(const ForwardingEntry* value) const {\n+    return _entry._from == value->_from;\n+  }\n+  static bool is_dead(ForwardingEntry* value) { return false; }\n+};\n+\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::initialize(MemRegion heap) {\n+#ifdef _LP64\n+  _heap_start = heap.start();\n+\n+  size_t rounded_heap_size = MAX2(round_up_power_of_2(heap.byte_size()) \/ BytesPerWord, BLOCK_SIZE_WORDS);\n+\n+  _num_regions = rounded_heap_size \/ BLOCK_SIZE_WORDS;\n+\n+  _heap_start_region_bias = reinterpret_cast<uintptr_t>(_heap_start) >> BLOCK_SIZE_BYTES_SHIFT;\n+  _region_mask = ~((static_cast<uintptr_t>(1) << BLOCK_SIZE_BYTES_SHIFT) - 1);\n+\n+  assert(_bases_table == nullptr, \"should not be initialized yet\");\n+  assert(_fallback_table == nullptr, \"should not be initialized yet\");\n+#endif\n+}\n+\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::begin() {\n+#ifdef _LP64\n+  assert(_bases_table == nullptr, \"should not be initialized yet\");\n+  assert(_fallback_table == nullptr, \"should not be initialized yet\");\n+\n+  _fallback_table = nullptr;\n+\n+#ifndef PRODUCT\n+  _num_forwardings = 0;\n+  _num_fallback_forwardings = 0;\n+#endif\n+\n+  size_t max = _num_regions;\n+  _bases_table = NEW_C_HEAP_ARRAY(HeapWord*, max, mtGC);\n+  HeapWord** biased_start = _bases_table - _heap_start_region_bias;\n+  _biased_bases = biased_start;\n+  if (max == 1) {\n+    \/\/ Optimize the case when the block-size >= heap-size.\n+    \/\/ In this case we can use the heap-start as block-start,\n+    \/\/ and don't risk that competing GC threads set a higher\n+    \/\/ address as block-start, which would lead to unnecessary\n+    \/\/ fallback-usage.\n+    _bases_table[0] = _heap_start;\n+  } else {\n+    for (size_t i = 0; i < max; i++) {\n+      _bases_table[i] = UNUSED_BASE;\n+    }\n+  }\n+#endif\n+}\n+\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::end() {\n+#ifndef PRODUCT\n+  size_t fallback_table_size = _fallback_table != nullptr ? _fallback_table->get_mem_size(Thread::current()) : 0;\n+  log_info(gc)(\"Total forwardings: \" UINT64_FORMAT \", fallback forwardings: \" UINT64_FORMAT\n+                \", ratio: %f, memory used by fallback table: %zu%s, memory used by bases table: %zu%s\",\n+               _num_forwardings, _num_fallback_forwardings, static_cast<float>(_num_forwardings) \/ static_cast<float>(_num_fallback_forwardings),\n+               byte_size_in_proper_unit(fallback_table_size),\n+               proper_unit_for_byte_size(fallback_table_size),\n+               byte_size_in_proper_unit(sizeof(HeapWord*) * _num_regions),\n+               proper_unit_for_byte_size(sizeof(HeapWord*) * _num_regions));\n+#endif\n+#ifdef _LP64\n+  assert(_bases_table != nullptr, \"should be initialized\");\n+  FREE_C_HEAP_ARRAY(HeapWord*, _bases_table);\n+  _bases_table = nullptr;\n+  if (_fallback_table != nullptr) {\n+    delete _fallback_table;\n+    _fallback_table = nullptr;\n+  }\n+#endif\n+}\n+\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::maybe_init_fallback_table() {\n+  if (_fallback_table == nullptr) {\n+    FallbackTable* fallback_table = new FallbackTable(_fallback_table_log2_start_size);\n+    FallbackTable* prev = Atomic::cmpxchg(&_fallback_table, static_cast<FallbackTable*>(nullptr), fallback_table);\n+    if (prev != nullptr) {\n+      \/\/ Another thread won, discard our table.\n+      delete fallback_table;\n+    }\n+  }\n+}\n+\n+template <int BITS>\n+void FullGCForwardingImpl<BITS>::fallback_forward_to(HeapWord* from, HeapWord* to) {\n+  assert(to != nullptr, \"no null forwarding\");\n+  maybe_init_fallback_table();\n+  assert(_fallback_table != nullptr, \"should be initialized\");\n+  FallbackTableLookup lookup_f(from);\n+  ForwardingEntry entry(from, to);\n+  auto found_f = [&](ForwardingEntry* found) {\n+    \/\/ If dupe has been found, override it with new value.\n+    \/\/ This is also called when new entry is succussfully inserted.\n+    if (found->_to != to) {\n+      found->_to = to;\n+    }\n+  };\n+  Thread* current_thread = Thread::current();\n+  bool grow;\n+  bool added = _fallback_table->insert_get(current_thread, lookup_f, entry, found_f, &grow);\n+  NOT_PRODUCT(Atomic::inc(&_num_fallback_forwardings);)\n+#ifdef ASSERT\n+  assert(fallback_forwardee(from) != nullptr, \"must have entered forwarding\");\n+  assert(fallback_forwardee(from) == to, \"forwarding must be correct, added: %s, from: \" PTR_FORMAT \", to: \" PTR_FORMAT \", fwd: \" PTR_FORMAT, BOOL_TO_STR(added), p2i(from), p2i(to), p2i(fallback_forwardee(from)));\n+#endif\n+  if (grow) {\n+    _fallback_table->grow(current_thread);\n+    log_debug(gc)(\"grow fallback table to size: %zu bytes\", _fallback_table->get_mem_size(current_thread));\n+  }\n+}\n+\n+template <int BITS>\n+HeapWord* FullGCForwardingImpl<BITS>::fallback_forwardee(HeapWord* from) {\n+  assert(_fallback_table != nullptr, \"fallback table must be present\");\n+  HeapWord* result;\n+  FallbackTableLookup lookup_f(from);\n+  auto found_f = [&](const ForwardingEntry* found) {\n+    result = found->_to;\n+  };\n+  bool found = _fallback_table->get(Thread::current(), lookup_f, found_f);\n+  assert(found, \"something must have been found\");\n+  assert(result != nullptr, \"must have found forwarding\");\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/fullGCForwarding.inline.hpp","additions":231,"deletions":16,"binary":false,"changes":247,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/shared\/fullGCForwarding.hpp\"\n+#include \"gc\/shared\/fullGCForwarding.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}