{"files":[{"patch":"@@ -1768,4 +1768,0 @@\n-  \/\/ insert a nop at the start of the prolog so we can patch in a\n-  \/\/ branch if we need to invalidate the method later\n-  __ nop();\n-\n@@ -1891,1 +1887,1 @@\n-    __ safepoint_poll(*code_stub, true \/* at_return *\/, false \/* acquire *\/, true \/* in_nmethod *\/);\n+    __ safepoint_poll(*code_stub, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -3924,0 +3920,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n@@ -7768,2 +7768,1 @@\n-  format %{ \"movw   $src, $src\\n\\t\"\n-            \"mov    $tmp, $src\\t# vector (1D)\\n\\t\"\n+  format %{ \"fmovs  $tmp, $src\\t# vector (1S)\\n\\t\"\n@@ -7774,2 +7773,1 @@\n-    __ movw($src$$Register, $src$$Register); \/\/ ensure top 32 bits 0\n-    __ mov($tmp$$FloatRegister, __ D, 0, $src$$Register);\n+    __ fmovs($tmp$$FloatRegister, $src$$Register);\n@@ -8243,0 +8241,10 @@\n+instruct castHH(vRegF dst)\n+%{\n+  match(Set dst (CastHH dst));\n+  size(0);\n+  format %{ \"# castHH of $dst\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_cost(0);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":17,"deletions":9,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -556,7 +556,2 @@\n-void MacroAssembler::safepoint_poll(Label& slow_path, bool at_return, bool acquire, bool in_nmethod, Register tmp) {\n-  if (acquire) {\n-    lea(tmp, Address(rthread, JavaThread::polling_word_offset()));\n-    ldar(tmp, tmp);\n-  } else {\n-    ldr(tmp, Address(rthread, JavaThread::polling_word_offset()));\n-  }\n+void MacroAssembler::safepoint_poll(Label& slow_path, bool at_return, bool in_nmethod, Register tmp) {\n+  ldr(tmp, Address(rthread, JavaThread::polling_word_offset()));\n@@ -992,2 +987,6 @@\n-  movptr(rscratch1, 0);\n-  br(rscratch1);\n+  if (codestub_branch_needs_far_jump()) {\n+    movptr(rscratch1, 0);\n+    br(rscratch1);\n+  } else {\n+    b(pc());\n+  }\n@@ -997,0 +996,4 @@\n+  if (!codestub_branch_needs_far_jump()) {\n+    \/\/ isb; movk; movz; movz; b\n+    return 5 * NativeInstruction::instruction_size;\n+  }\n@@ -5343,0 +5346,29 @@\n+static Register pick_different_tmp(Register dst, Register src) {\n+  auto tmps = RegSet::of(r0, r1, r2) - RegSet::of(src, dst);\n+  return *tmps.begin();\n+}\n+\n+void MacroAssembler::encode_klass_not_null_for_aot(Register dst, Register src) {\n+  \/\/ we have to load the klass base from the AOT constants area but\n+  \/\/ not the shift because it is not allowed to change\n+  int shift = CompressedKlassPointers::shift();\n+  assert(shift >= 0 && shift <= CompressedKlassPointers::max_shift(), \"unexpected compressed klass shift!\");\n+  if (dst != src) {\n+    \/\/ we can load the base into dst, subtract it formthe src and shift down\n+    lea(dst, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    ldr(dst, dst);\n+    sub(dst, src, dst);\n+    lsr(dst, dst, shift);\n+  } else {\n+    \/\/ we need an extra register in order to load the coop base\n+    Register tmp = pick_different_tmp(dst, src);\n+    RegSet regs = RegSet::of(tmp);\n+    push(regs, sp);\n+    lea(tmp, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    ldr(tmp, tmp);\n+    sub(dst, src, tmp);\n+    lsr(dst, dst, shift);\n+    pop(regs, sp);\n+  }\n+}\n+\n@@ -5344,0 +5376,5 @@\n+  if (AOTCodeCache::is_on_for_dump()) {\n+    encode_klass_not_null_for_aot(dst, src);\n+    return;\n+  }\n+\n@@ -5380,0 +5417,22 @@\n+void MacroAssembler::decode_klass_not_null_for_aot(Register dst, Register src) {\n+  \/\/ we have to load the klass base from the AOT constants area but\n+  \/\/ not the shift because it is not allowed to change\n+  int shift = CompressedKlassPointers::shift();\n+  assert(shift >= 0 && shift <= CompressedKlassPointers::max_shift(), \"unexpected compressed klass shift!\");\n+  if (dst != src) {\n+    \/\/ we can load the base into dst then add the offset with a suitable shift\n+    lea(dst, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    ldr(dst, dst);\n+    add(dst, dst, src, LSL,  shift);\n+  } else {\n+    \/\/ we need an extra register in order to load the coop base\n+    Register tmp = pick_different_tmp(dst, src);\n+    RegSet regs = RegSet::of(tmp);\n+    push(regs, sp);\n+    lea(tmp, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    ldr(tmp, tmp);\n+    add(dst, tmp,  src, LSL,  shift);\n+    pop(regs, sp);\n+  }\n+}\n+\n@@ -5383,0 +5442,5 @@\n+  if (AOTCodeCache::is_on_for_dump()) {\n+    decode_klass_not_null_for_aot(dst, src);\n+    return;\n+  }\n+\n@@ -6653,1 +6717,1 @@\n-  mov(lr, CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper));\n+  mov(lr, ExternalAddress(CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper)));\n@@ -6749,0 +6813,3 @@\n+      case SpinWait::SB:\n+        sb();\n+        break;\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":77,"deletions":10,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -1147,0 +1147,1 @@\n+  \/\/ Clobbers: r10, r11, r3\n@@ -1155,0 +1156,1 @@\n+  \/\/ Clobbers: r10, r11, r3\n@@ -1760,1 +1762,1 @@\n-  __ profile_taken_branch(r0, r1);\n+  __ profile_taken_branch(r0);\n@@ -1810,1 +1812,0 @@\n-    \/\/ w1: MDO bumped taken-count\n@@ -1821,1 +1822,0 @@\n-    __ push(r1);\n@@ -1826,1 +1826,0 @@\n-    __ pop(r1);\n@@ -1893,0 +1892,2 @@\n+    JFR_ONLY(__ enter_jfr_critical_section();)\n+\n@@ -1904,0 +1905,3 @@\n+\n+    JFR_ONLY(__ leave_jfr_critical_section();)\n+\n@@ -2880,0 +2884,1 @@\n+    \/\/ Clobbers: r10, r11, r3\n@@ -3075,2 +3080,2 @@\n-  \/\/ R1: field offset, R2: field holder, R3: flags\n-  load_resolved_field_entry(r2, r2, noreg, r1, r3);\n+  \/\/ R1: field offset, R2: field holder, R5: flags\n+  load_resolved_field_entry(r2, r2, noreg, r1, r5);\n@@ -3080,1 +3085,1 @@\n-    __ tbz(r3, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n+    __ tbz(r5, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n@@ -3096,0 +3101,1 @@\n+    \/\/ Clobbers: r10, r11, r3\n@@ -3128,1 +3134,1 @@\n-    __ tbz(r3, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n+    __ tbz(r5, ResolvedFieldEntry::is_volatile_shift, notVolatile);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":14,"deletions":8,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1371,8 +1371,0 @@\n-  \/\/ insert a nop at the start of the prolog so we can patch in a\n-  \/\/ branch if we need to invalidate the method later\n-  {\n-    Assembler::IncompressibleScope scope(masm); \/\/ keep the nop as 4 bytes for patching.\n-    MacroAssembler::assert_alignment(__ pc());\n-    __ nop();  \/\/ 4 bytes\n-  }\n-\n@@ -1496,1 +1488,1 @@\n-    __ safepoint_poll(*code_stub, true \/* at_return *\/, false \/* acquire *\/, true \/* in_nmethod *\/);\n+    __ safepoint_poll(*code_stub, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -1807,1 +1799,0 @@\n-  \/\/ Verified entry point must be properly 4 bytes aligned for patching by NativeJump::patch_verified_entry().\n@@ -1885,12 +1876,0 @@\n-    \/\/ Current test shows that, it brings performance gain when MaxVectorSize >= 32, but brings\n-    \/\/ regression when MaxVectorSize == 16. So only enable the intrinsic when MaxVectorSize >= 32.\n-    case Op_RoundVF:\n-      return UseRVV && MaxVectorSize >= 32;\n-\n-    \/\/ For double, current test shows that even with MaxVectorSize == 32, there is still some regression.\n-    \/\/ Although there is no hardware to verify it for now, from the trend of performance data on hardwares\n-    \/\/ (with vlenb == 16 and 32 respectively), it's promising to bring better performance rather than\n-    \/\/ regression for double when MaxVectorSize == 64+. So only enable the intrinsic when MaxVectorSize >= 64.\n-    case Op_RoundVD:\n-      return UseRVV && MaxVectorSize >= 64;\n-\n@@ -1920,3 +1899,0 @@\n-    case Op_FmaVF:\n-    case Op_FmaVD:\n-      return UseRVV && UseFMA;\n@@ -1936,1 +1912,1 @@\n-    case Op_SubHF:\n+    case Op_SubHF:\n@@ -2322,36 +2298,0 @@\n-  enc_class riscv_enc_cmpxchgw(iRegINoSp res, memory mem, iRegI oldval, iRegI newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int32,\n-               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n-  enc_class riscv_enc_cmpxchgn(iRegINoSp res, memory mem, iRegI oldval, iRegI newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::uint32,\n-               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n-  enc_class riscv_enc_cmpxchg(iRegINoSp res, memory mem, iRegL oldval, iRegL newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n-               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n-  enc_class riscv_enc_cmpxchgw_acq(iRegINoSp res, memory mem, iRegI oldval, iRegI newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int32,\n-               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n-  enc_class riscv_enc_cmpxchgn_acq(iRegINoSp res, memory mem, iRegI oldval, iRegI newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::uint32,\n-               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n-  enc_class riscv_enc_cmpxchg_acq(iRegINoSp res, memory mem, iRegL oldval, iRegL newval) %{\n-    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n-               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n-               \/*result as bool*\/ true);\n-  %}\n-\n@@ -2673,0 +2613,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n@@ -5269,2 +5213,2 @@\n-instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                         iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndSwapB_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5272,0 +5216,2 @@\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5274,1 +5220,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 10 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5280,1 +5226,1 @@\n-    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapB\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapB_narrow\"\n@@ -5292,2 +5238,1 @@\n-instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                         iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n@@ -5295,0 +5240,25 @@\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (CompareAndSwapB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $mem, $oldval, $newval\\t# (byte) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapB\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+               Assembler::relaxed \/* acquire *\/, Assembler::rl \/* release *\/, $res$$Register,\n+               true \/* result as bool *\/);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct compareAndSwapS_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5297,1 +5267,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 11 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5303,1 +5273,1 @@\n-    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapS\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapS_narrow\"\n@@ -5315,0 +5285,22 @@\n+instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (CompareAndSwapS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $mem, $oldval, $newval\\t# (short) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapS\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+               Assembler::relaxed \/* acquire *\/, Assembler::rl \/* release *\/, $res$$Register,\n+               true \/* result as bool *\/);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5319,1 +5311,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5326,1 +5318,5 @@\n-  ins_encode(riscv_enc_cmpxchgw(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int32,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5335,1 +5331,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5342,1 +5338,5 @@\n-  ins_encode(riscv_enc_cmpxchg(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5353,1 +5353,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5360,1 +5360,5 @@\n-  ins_encode(riscv_enc_cmpxchg(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5368,0 +5372,1 @@\n+\n@@ -5370,1 +5375,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 8 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5377,1 +5382,5 @@\n-  ins_encode(riscv_enc_cmpxchgn(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::uint32,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5383,2 +5392,2 @@\n-instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                            iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndSwapBAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                   iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5386,1 +5395,1 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5390,1 +5399,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 10 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5396,1 +5405,1 @@\n-    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapBAcq\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapBAcq_narrow\"\n@@ -5408,2 +5417,1 @@\n-instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                            iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n@@ -5411,1 +5419,24 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (CompareAndSwapB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $mem, $oldval, $newval\\t# (byte) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapBAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+               Assembler::aq \/* acquire *\/, Assembler::rl \/* release *\/, $res$$Register,\n+               true \/* result as bool *\/);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct compareAndSwapSAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                   iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5415,1 +5446,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 11 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5421,1 +5452,1 @@\n-    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapSAcq\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapSAcq_narrow\"\n@@ -5433,0 +5464,22 @@\n+instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (CompareAndSwapS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $mem, $oldval, $newval\\t# (short) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"mv $res, $res == $oldval\\t# $res <-- ($res == $oldval ? 1 : 0), #@compareAndSwapSAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+               Assembler::aq \/* acquire *\/, Assembler::rl \/* release *\/, $res$$Register,\n+               true \/* result as bool *\/);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5439,1 +5492,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5446,1 +5499,5 @@\n-  ins_encode(riscv_enc_cmpxchgw_acq(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int32,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5457,1 +5514,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5464,1 +5521,5 @@\n-  ins_encode(riscv_enc_cmpxchg_acq(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5475,1 +5536,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 6 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5482,1 +5543,5 @@\n-  ins_encode(riscv_enc_cmpxchg_acq(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int64,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5493,1 +5558,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + ALU_COST * 8 + BRANCH_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5500,1 +5565,5 @@\n-  ins_encode(riscv_enc_cmpxchgn_acq(res, mem, oldval, newval));\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::uint32,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register,\n+               \/*result as bool*\/ true);\n+  %}\n@@ -5511,2 +5580,2 @@\n-instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                             iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndExchangeB_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                    iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5514,0 +5583,2 @@\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5516,1 +5587,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST * 5);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5521,1 +5592,1 @@\n-    \"cmpxchg $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeB\"\n+    \"cmpxchg $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeB_narrow\"\n@@ -5533,2 +5604,22 @@\n-instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                             iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (CompareAndExchangeB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeB\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct compareAndExchangeS_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                    iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5536,0 +5627,2 @@\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5538,1 +5631,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST * 6);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5543,1 +5636,1 @@\n-    \"cmpxchg $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeS\"\n+    \"cmpxchg $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeS_narrow\"\n@@ -5555,0 +5648,20 @@\n+instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (CompareAndExchangeS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeS\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+               \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5559,3 +5672,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5579,3 +5690,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5598,2 +5707,1 @@\n-  match(Set res (CompareAndExchangeN mem (Binary oldval newval)));\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST * 3);\n+  match(Set res (CompareAndExchangeN mem (Binary oldval newval)));\n@@ -5602,1 +5710,1 @@\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5619,2 +5727,1 @@\n-  match(Set res (CompareAndExchangeP mem (Binary oldval newval)));\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n+  match(Set res (CompareAndExchangeP mem (Binary oldval newval)));\n@@ -5623,1 +5730,1 @@\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5637,2 +5744,2 @@\n-instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndExchangeBAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                       iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5640,1 +5747,1 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5644,1 +5751,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST * 5);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5649,1 +5756,1 @@\n-    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeBAcq\"\n+    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeBAcq_narrow\"\n@@ -5661,2 +5768,1 @@\n-instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n@@ -5664,1 +5770,22 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (CompareAndExchangeB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeBAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct compareAndExchangeSAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                       iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5668,1 +5795,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST * 6);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5673,1 +5800,1 @@\n-    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeSAcq\"\n+    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeSAcq_narrow\"\n@@ -5685,0 +5812,20 @@\n+instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (CompareAndExchangeS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"cmpxchg_acq $res = $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval, #@compareAndExchangeSAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+               \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5691,3 +5838,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5713,3 +5858,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5735,3 +5878,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5757,3 +5898,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 3 + ALU_COST);\n-\n-  effect(TEMP_DEF res);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5773,2 +5912,2 @@\n-instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                             iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct weakCompareAndSwapB_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                    iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5776,0 +5915,2 @@\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5778,1 +5919,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 6);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5784,1 +5925,1 @@\n-    \"# $res == 1 when success, #@weakCompareAndSwapB\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapB_narrow\"\n@@ -5796,2 +5937,23 @@\n-instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                             iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"weak_cmpxchg $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapB\"\n+  %}\n+\n+  ins_encode %{\n+    __ weak_cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+                    \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct weakCompareAndSwapS_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                    iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5799,0 +5961,2 @@\n+  predicate(!UseZabha || !UseZacas);\n+\n@@ -5801,1 +5965,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 7);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5807,1 +5971,1 @@\n-    \"# $res == 1 when success, #@weakCompareAndSwapS\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapS_narrow\"\n@@ -5819,0 +5983,21 @@\n+instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate(UseZabha && UseZacas);\n+\n+  match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"weak_cmpxchg $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapS\"\n+  %}\n+\n+  ins_encode %{\n+    __ weak_cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+                    \/*acquire*\/ Assembler::relaxed, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5823,1 +6008,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5842,1 +6027,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5860,0 +6045,1 @@\n+\n@@ -5862,1 +6048,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5880,0 +6066,1 @@\n+\n@@ -5882,1 +6069,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5897,2 +6084,2 @@\n-instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct weakCompareAndSwapBAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                       iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n@@ -5900,1 +6087,1 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5904,1 +6091,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 6);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5910,1 +6097,1 @@\n-    \"# $res == 1 when success, #@weakCompareAndSwapBAcq\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapBAcq_narrow\"\n@@ -5922,2 +6109,1 @@\n-instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n-                                iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n@@ -5925,1 +6111,23 @@\n-  predicate(needs_acquiring_load_reserved(n));\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"weak_cmpxchg_acq $mem, $oldval, $newval\\t# (byte, weak) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapBAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ weak_cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int8,\n+                    \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct weakCompareAndSwapSAcq_narrow(iRegINoSp res, indirect mem, iRegI_R12 oldval, iRegI_R13 newval,\n+                                       iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  predicate((!UseZabha || !UseZacas) && needs_acquiring_load_reserved(n));\n@@ -5929,1 +6137,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 7);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5935,1 +6143,1 @@\n-    \"# $res == 1 when success, #@weakCompareAndSwapSAcq\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapSAcq_narrow\"\n@@ -5947,0 +6155,21 @@\n+instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval)\n+%{\n+  predicate((UseZabha && UseZacas) && needs_acquiring_load_reserved(n));\n+\n+  match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));\n+\n+  ins_cost(2 * VOLATILE_REF_COST);\n+\n+  format %{\n+    \"weak_cmpxchg_acq $mem, $oldval, $newval\\t# (short, weak) if $mem == $oldval then $mem <-- $newval\\n\\t\"\n+    \"# $res == 1 when success, #@weakCompareAndSwapSAcq\"\n+  %}\n+\n+  ins_encode %{\n+    __ weak_cmpxchg(as_Register($mem$$base), $oldval$$Register, $newval$$Register, Assembler::int16,\n+                    \/*acquire*\/ Assembler::aq, \/*release*\/ Assembler::rl, $res$$Register);\n+  %}\n+\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -5953,1 +6182,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5974,1 +6203,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -5995,1 +6224,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 4);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -6016,1 +6245,1 @@\n-  ins_cost(LOAD_COST + STORE_COST + BRANCH_COST * 2 + ALU_COST * 2);\n+  ins_cost(2 * VOLATILE_REF_COST);\n@@ -7965,1 +8194,1 @@\n-  \n+ \n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":394,"deletions":165,"binary":false,"changes":559,"status":"modified"},{"patch":"@@ -1,2 +1,2 @@\n-\/*\n- * Copyright (c) 2023, Red Hat, Inc. All rights reserved.\n+ \/*\n+ * Copyright (c) 2023, 2025, Red Hat, Inc. All rights reserved.\n@@ -28,0 +28,1 @@\n+#include \"memory\/metaspace.hpp\"\n@@ -35,7 +36,18 @@\n-  \/\/ Optimize for unscaled encoding; failing that, for zero-based encoding:\n-  if (optimize_for_zero_base) {\n-    result = reserve_address_space_for_unscaled_encoding(size, aslr);\n-    if (result == nullptr) {\n-      result = reserve_address_space_for_zerobased_encoding(size, aslr);\n-    }\n-  } \/\/ end: low-address reservation\n+  assert(CompressedKlassPointers::narrow_klass_pointer_bits() == 32 ||\n+         CompressedKlassPointers::narrow_klass_pointer_bits() == 19, \"Rethink if we ever use different nKlass bit sizes\");\n+\n+  \/\/ Unconditionally attempting to reserve in lower 4G first makes always sense:\n+  \/\/ -CDS -COH: Try to get unscaled mode (zero base, zero shift)\n+  \/\/ +CDS -COH: No zero base possible (CDS prevents it); but we still benefit from small base pointers (imm32 movabs)\n+  \/\/ -CDS +COH: No zero base possible (22bit nKlass + zero base zero shift = 4MB encoding range, way too small);\n+  \/\/            but we still benefit from small base pointers (imm32 movabs)\n+  \/\/ +CDS +COH: No zero base possible for multiple reasons (CDS prevents it and encoding range too small);\n+  \/\/            but we still benefit from small base pointers (imm32 movabs)\n+\n+  result = reserve_address_space_below_4G(size, aslr);\n+\n+  if (result == nullptr && optimize_for_zero_base) {\n+    \/\/ Failing that, if we are running without CDS, attempt to allocate below 32G.\n+    \/\/ This allows us to use zero-based encoding with a non-zero shift.\n+    result = reserve_address_space_for_zerobased_encoding(size, aslr);\n+  }\n@@ -43,1 +55,0 @@\n-  \/\/ Nothing more to optimize for on x64. If base != 0, we will always emit the full 64-bit immediate.\n","filename":"src\/hotspot\/cpu\/x86\/compressedKlass_x86.cpp","additions":21,"deletions":10,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1624,13 +1624,0 @@\n-\/\/ A 5 byte nop that is safe for patching (see patch_verified_entry)\n-void MacroAssembler::fat_nop() {\n-  if (UseAddressNop) {\n-    addr_nop_5();\n-  } else {\n-    emit_int8((uint8_t)0x26); \/\/ es:\n-    emit_int8((uint8_t)0x2e); \/\/ cs:\n-    emit_int8((uint8_t)0x64); \/\/ fs:\n-    emit_int8((uint8_t)0x65); \/\/ gs:\n-    emit_int8((uint8_t)0x90);\n-  }\n-}\n-\n@@ -2253,0 +2240,10 @@\n+void MacroAssembler::movapd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n+  if (reachable(src)) {\n+    Assembler::movapd(dst, as_Address(src));\n+  } else {\n+    lea(rscratch, src);\n+    Assembler::movapd(dst, Address(rscratch, 0));\n+  }\n+}\n@@ -5405,0 +5402,1 @@\n+  BLOCK_COMMENT(\"encode_klass_not_null {\");\n@@ -5407,1 +5405,5 @@\n-    mov64(tmp, (int64_t)CompressedKlassPointers::base());\n+    if (AOTCodeCache::is_on_for_dump()) {\n+      movptr(tmp, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    } else {\n+      movptr(tmp, (intptr_t)CompressedKlassPointers::base());\n+    }\n@@ -5413,0 +5415,1 @@\n+  BLOCK_COMMENT(\"} encode_klass_not_null\");\n@@ -5416,0 +5419,1 @@\n+  BLOCK_COMMENT(\"encode_and_move_klass_not_null {\");\n@@ -5418,1 +5422,1 @@\n-    mov64(dst, -(int64_t)CompressedKlassPointers::base());\n+    movptr(dst, -(intptr_t)CompressedKlassPointers::base());\n@@ -5426,0 +5430,1 @@\n+  BLOCK_COMMENT(\"} encode_and_move_klass_not_null\");\n@@ -5429,0 +5434,1 @@\n+  BLOCK_COMMENT(\"decode_klass_not_null {\");\n@@ -5439,1 +5445,5 @@\n-    mov64(tmp, (int64_t)CompressedKlassPointers::base());\n+    if (AOTCodeCache::is_on_for_dump()) {\n+      movptr(tmp, ExternalAddress(CompressedKlassPointers::base_addr()));\n+    } else {\n+      movptr(tmp, (intptr_t)CompressedKlassPointers::base());\n+    }\n@@ -5442,0 +5452,1 @@\n+  BLOCK_COMMENT(\"} decode_klass_not_null\");\n@@ -5445,0 +5456,1 @@\n+  BLOCK_COMMENT(\"decode_and_move_klass_not_null {\");\n@@ -5460,1 +5472,1 @@\n-        mov64(dst, (int64_t)CompressedKlassPointers::base());\n+        movptr(dst, (intptr_t)CompressedKlassPointers::base());\n@@ -5472,3 +5484,3 @@\n-        const uint64_t base_right_shifted =\n-            (uint64_t)CompressedKlassPointers::base() >> CompressedKlassPointers::shift();\n-        mov64(dst, base_right_shifted);\n+        const intptr_t base_right_shifted =\n+            (intptr_t)CompressedKlassPointers::base() >> CompressedKlassPointers::shift();\n+        movptr(dst, base_right_shifted);\n@@ -5482,0 +5494,1 @@\n+  BLOCK_COMMENT(\"} decode_and_move_klass_not_null\");\n@@ -8831,0 +8844,4 @@\n+    case T_FLOAT:\n+      evminmaxps(dst, mask, nds, src, merge, AVX10_MINMAX_MIN_COMPARE_SIGN, vector_len); break;\n+    case T_DOUBLE:\n+      evminmaxpd(dst, mask, nds, src, merge, AVX10_MINMAX_MIN_COMPARE_SIGN, vector_len); break;\n@@ -8846,0 +8863,4 @@\n+    case T_FLOAT:\n+      evminmaxps(dst, mask, nds, src, merge, AVX10_MINMAX_MAX_COMPARE_SIGN, vector_len); break;\n+    case T_DOUBLE:\n+      evminmaxpd(dst, mask, nds, src, merge, AVX10_MINMAX_MAX_COMPARE_SIGN, vector_len); break;\n@@ -8861,0 +8882,4 @@\n+    case T_FLOAT:\n+      evminmaxps(dst, mask, nds, src, merge, AVX10_MINMAX_MIN_COMPARE_SIGN, vector_len); break;\n+    case T_DOUBLE:\n+      evminmaxpd(dst, mask, nds, src, merge, AVX10_MINMAX_MIN_COMPARE_SIGN, vector_len); break;\n@@ -8876,0 +8901,4 @@\n+    case T_FLOAT:\n+      evminmaxps(dst, mask, nds, src, merge, AVX10_MINMAX_MAX_COMPARE_SIGN, vector_len); break;\n+    case T_DOUBLE:\n+      evminmaxps(dst, mask, nds, src, merge, AVX10_MINMAX_MAX_COMPARE_SIGN, vector_len); break;\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":49,"deletions":20,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -1690,2 +1690,1 @@\n-  __ profile_taken_branch(rax, rbx); \/\/ rax holds updated MDP, rbx\n-                                     \/\/ holds bumped taken count\n+  __ profile_taken_branch(rax); \/\/ rax holds updated MDP\n@@ -1742,1 +1741,0 @@\n-    \/\/ rbx: MDO bumped taken-count\n@@ -1828,0 +1826,2 @@\n+      JFR_ONLY(__ enter_jfr_critical_section();)\n+\n@@ -1842,0 +1842,1 @@\n+      JFR_ONLY(__ leave_jfr_critical_section();)\n@@ -1843,1 +1844,1 @@\n-      __ mov(rsp, sender_sp);                   \/\/ set sp to sender sp\n+      __ mov(rsp, sender_sp);                    \/\/ set sp to sender sp\n@@ -1847,3 +1848,0 @@\n-      \/\/ unlike x86 we need no specialized return from compiled code\n-      \/\/ to the interpreter or the call stub.\n-\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1862,2 +1862,1 @@\n-    \/\/ No relocation needed\n-    __ mov64(r10, (int64_t) $meth$$method);\n+    __ lea(r10, RuntimeAddress((address)$meth$$method));\n@@ -2059,0 +2058,4 @@\n+\/\/ Whether this node is expanded during code emission into a sequence of\n+\/\/ instructions and the first instruction can perform an implicit null check.\n+ins_attrib ins_is_late_expanded_null_check_candidate(false);\n+\n@@ -4453,0 +4456,11 @@\n+\/\/ max = java.lang.Math.max(float a, float b)\n+instruct maxF_avx10_reg(regF dst, regF a, regF b) %{\n+  predicate(VM_Version::supports_avx10_2());\n+  match(Set dst (MaxF a b));\n+  format %{ \"maxF $dst, $a, $b\" %}\n+  ins_encode %{\n+    __ eminmaxss($dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, AVX10_MINMAX_MAX_COMPARE_SIGN);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -4455,1 +4469,1 @@\n-  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4466,1 +4480,1 @@\n-  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4478,0 +4492,11 @@\n+\/\/ max = java.lang.Math.max(double a, double b)\n+instruct maxD_avx10_reg(regD dst, regD a, regD b) %{\n+  predicate(VM_Version::supports_avx10_2());\n+  match(Set dst (MaxD a b));\n+  format %{ \"maxD $dst, $a, $b\" %}\n+  ins_encode %{\n+    __ eminmaxsd($dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, AVX10_MINMAX_MAX_COMPARE_SIGN);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -4480,1 +4505,1 @@\n-  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4491,1 +4516,1 @@\n-  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4503,0 +4528,11 @@\n+\/\/ max = java.lang.Math.min(float a, float b)\n+instruct minF_avx10_reg(regF dst, regF a, regF b) %{\n+  predicate(VM_Version::supports_avx10_2());\n+  match(Set dst (MinF a b));\n+  format %{ \"minF $dst, $a, $b\" %}\n+  ins_encode %{\n+    __ eminmaxss($dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, AVX10_MINMAX_MIN_COMPARE_SIGN);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -4505,1 +4541,1 @@\n-  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4516,1 +4552,1 @@\n-  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4528,0 +4564,11 @@\n+\/\/ max = java.lang.Math.min(double a, double b)\n+instruct minD_avx10_reg(regD dst, regD a, regD b) %{\n+  predicate(VM_Version::supports_avx10_2());\n+  match(Set dst (MinD a b));\n+  format %{ \"minD $dst, $a, $b\" %}\n+  ins_encode %{\n+    __ eminmaxsd($dst$$XMMRegister, $a$$XMMRegister, $b$$XMMRegister, AVX10_MINMAX_MIN_COMPARE_SIGN);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -4530,1 +4577,1 @@\n-  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4541,1 +4588,1 @@\n-  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n+  predicate(!VM_Version::supports_avx10_2() && UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -6382,1 +6429,1 @@\n-instruct cmovI_rReg_rReg_memUCF_ndd(rRegI dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegI src1, memory src2) \n+instruct cmovI_rReg_rReg_memUCF_ndd(rRegI dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegI src1, memory src2)\n@@ -6765,1 +6812,1 @@\n-instruct cmovL_regUCF_ndd(rRegL dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegL src1, rRegL src2) \n+instruct cmovL_regUCF_ndd(rRegL dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegL src1, rRegL src2)\n@@ -6872,1 +6919,1 @@\n-instruct cmovL_rReg_rReg_memUCF_ndd(rRegL dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegL src1, memory src2) \n+instruct cmovL_rReg_rReg_memUCF_ndd(rRegL dst, cmpOpUCF cop, rFlagsRegUCF cr, rRegL src1, memory src2)\n@@ -7059,15 +7106,0 @@\n-instruct addI_rReg_mem_rReg_ndd(rRegI dst, memory src1, rRegI src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (AddI (LoadI src1) src2));\n-  effect(KILL cr);\n-  flag(PD::Flag_sets_overflow_flag, PD::Flag_sets_sign_flag, PD::Flag_sets_zero_flag, PD::Flag_sets_carry_flag, PD::Flag_sets_parity_flag);\n-\n-  ins_cost(150);\n-  format %{ \"eaddl    $dst, $src1, $src2\\t# int ndd\" %}\n-  ins_encode %{\n-    __ eaddl($dst$$Register, $src1$$Address, $src2$$Register, false);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n@@ -7377,15 +7409,0 @@\n-instruct addL_rReg_mem_rReg_ndd(rRegL dst, memory src1, rRegL src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (AddL (LoadL src1) src2));\n-  effect(KILL cr);\n-  flag(PD::Flag_sets_overflow_flag, PD::Flag_sets_sign_flag, PD::Flag_sets_zero_flag, PD::Flag_sets_carry_flag, PD::Flag_sets_parity_flag);\n-\n-  ins_cost(150);\n-  format %{ \"eaddq    $dst, $src1, $src2\\t# long ndd\" %}\n-  ins_encode %{\n-    __ eaddq($dst$$Register, $src1$$Address, $src2$$Register, false);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n@@ -8603,1 +8620,0 @@\n-  predicate(!UseAPX);\n@@ -8615,14 +8631,0 @@\n-instruct mulI_rReg_rReg_imm_ndd(rRegI dst, rRegI src1, immI src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (MulI src1 src2));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"eimull   $dst, $src1, $src2\\t# int ndd\" %}\n-  ins_encode %{\n-    __ eimull($dst$$Register, $src1$$Register, $src2$$constant, false);\n-  %}\n-  ins_pipe(ialu_reg_reg_alu0);\n-%}\n-\n@@ -8659,1 +8661,0 @@\n-  predicate(!UseAPX);\n@@ -8671,14 +8672,0 @@\n-instruct mulI_rReg_mem_imm(rRegI dst, memory src1, immI src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (MulI (LoadI src1) src2));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"eimull   $dst, $src1, $src2\\t# int ndd\" %}\n-  ins_encode %{\n-    __ eimull($dst$$Register, $src1$$Address, $src2$$constant, false);\n-  %}\n-  ins_pipe(ialu_reg_mem_alu0);\n-%}\n-\n@@ -8725,1 +8712,0 @@\n-  predicate(!UseAPX);\n@@ -8737,14 +8723,0 @@\n-instruct mulL_rReg_rReg_imm_ndd(rRegL dst, rRegL src1, immL32 src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (MulL src1 src2));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"eimulq   $dst, $src1, $src2\\t# long ndd\" %}\n-  ins_encode %{\n-    __ eimulq($dst$$Register, $src1$$Register, $src2$$constant, false);\n-  %}\n-  ins_pipe(ialu_reg_reg_alu0);\n-%}\n-\n@@ -8781,1 +8753,0 @@\n-  predicate(!UseAPX);\n@@ -8793,14 +8764,0 @@\n-instruct mulL_rReg_mem_imm_ndd(rRegL dst, memory src1, immL32 src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (MulL (LoadL src1) src2));\n-  effect(KILL cr);\n-\n-  ins_cost(300);\n-  format %{ \"eimulq   $dst, $src1, $src2\\t# long ndd\" %}\n-  ins_encode %{\n-    __ eimulq($dst$$Register, $src1$$Address, $src2$$constant, false);\n-  %}\n-  ins_pipe(ialu_reg_mem_alu0);\n-%}\n-\n@@ -10624,1 +10581,2 @@\n-  predicate(!UseAPX);\n+  \/\/ Strict predicate check to make selection of xorI_rReg_im1 cost agnostic if immI src is -1.\n+  predicate(!UseAPX && n->in(2)->bottom_type()->is_int()->get_con() != -1);\n@@ -10638,1 +10596,2 @@\n-  predicate(UseAPX);\n+  \/\/ Strict predicate check to make selection of xorI_rReg_im1_ndd cost agnostic if immI src2 is -1.\n+  predicate(UseAPX && n->in(2)->bottom_type()->is_int()->get_con() != -1);\n@@ -10656,0 +10615,1 @@\n+  ins_cost(150);\n@@ -10696,15 +10656,0 @@\n-instruct xorI_rReg_mem_rReg_ndd(rRegI dst, memory src1, rRegI src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (XorI (LoadI src1) src2));\n-  effect(KILL cr);\n-  flag(PD::Flag_sets_sign_flag, PD::Flag_sets_zero_flag, PD::Flag_sets_parity_flag, PD::Flag_clears_overflow_flag, PD::Flag_clears_carry_flag);\n-\n-  ins_cost(150);\n-  format %{ \"exorl    $dst, $src1, $src2\\t# int ndd\" %}\n-  ins_encode %{\n-    __ exorl($dst$$Register, $src1$$Address, $src2$$Register, false);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n@@ -10890,15 +10835,0 @@\n-instruct andL_rReg_mem_rReg_ndd(rRegL dst, memory src1, rRegL src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (AndL (LoadL src1) src2));\n-  effect(KILL cr);\n-  flag(PD::Flag_sets_sign_flag, PD::Flag_sets_zero_flag, PD::Flag_sets_parity_flag, PD::Flag_clears_overflow_flag, PD::Flag_clears_carry_flag);\n-\n-  ins_cost(150);\n-  format %{ \"eandq    $dst, $src1, $src2\\t# long ndd\" %}\n-  ins_encode %{\n-    __ eandq($dst$$Register, $src1$$Address, $src2$$Register, false);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n@@ -11328,1 +11258,2 @@\n-  predicate(!UseAPX);\n+  \/\/ Strict predicate check to make selection of xorL_rReg_im1 cost agnostic if immL32 src is -1.\n+  predicate(!UseAPX && n->in(2)->bottom_type()->is_long()->get_con() != -1L);\n@@ -11342,1 +11273,2 @@\n-  predicate(UseAPX);\n+  \/\/ Strict predicate check to make selection of xorL_rReg_im1_ndd cost agnostic if immL32 src2 is -1.\n+  predicate(UseAPX && n->in(2)->bottom_type()->is_long()->get_con() != -1L);\n@@ -11361,0 +11293,1 @@\n+  ins_cost(150);\n@@ -11400,15 +11333,0 @@\n-instruct xorL_rReg_mem_rReg_ndd(rRegL dst, memory src1, rRegL src2, rFlagsReg cr)\n-%{\n-  predicate(UseAPX);\n-  match(Set dst (XorL (LoadL src1) src2));\n-  effect(KILL cr);\n-  flag(PD::Flag_sets_sign_flag, PD::Flag_sets_zero_flag, PD::Flag_sets_parity_flag, PD::Flag_clears_overflow_flag, PD::Flag_clears_carry_flag);\n-\n-  ins_cost(150);\n-  format %{ \"exorq    $dst, $src1, $src2\\t# long ndd\" %}\n-  ins_encode %{\n-    __ exorq($dst$$Register, $src1$$Address, $src2$$Register, false);\n-  %}\n-  ins_pipe(ialu_reg_mem);\n-%}\n-\n@@ -14725,0 +14643,18 @@\n+peephole\n+%{\n+  peepmatch (leaPCompressedOopOffset);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n+peephole\n+%{\n+  peepmatch (leaP8Narrow);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n+peephole\n+%{\n+  peepmatch (leaP32Narrow);\n+  peepprocedure (lea_remove_redundant);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":88,"deletions":152,"binary":false,"changes":240,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/aotLogging.hpp\"\n@@ -56,0 +57,2 @@\n+#include \"oops\/methodCounters.hpp\"\n+#include \"oops\/methodData.hpp\"\n@@ -59,0 +62,1 @@\n+#include \"oops\/trainingData.hpp\"\n@@ -133,1 +137,5 @@\n-    address old_p = *ptr_loc;\n+    address old_p_with_tags = *ptr_loc;\n+    assert(old_p_with_tags != nullptr, \"null ptrs shouldn't have been marked\");\n+\n+    address old_p = MetaspaceClosure::strip_tags(old_p_with_tags);\n+    uintx tags = MetaspaceClosure::decode_tags(old_p_with_tags);\n@@ -136,2 +144,11 @@\n-    log_trace(cds)(\"Ref: [\" PTR_FORMAT \"] -> \" PTR_FORMAT \" => \" PTR_FORMAT,\n-                   p2i(ptr_loc), p2i(old_p), p2i(new_p));\n+    bool nulled;\n+    if (new_p == nullptr) {\n+      \/\/ old_p had a FollowMode of set_to_null\n+      nulled = true;\n+    } else {\n+      new_p = MetaspaceClosure::add_tags(new_p, tags);\n+      nulled = false;\n+    }\n+\n+    log_trace(aot)(\"Ref: [\" PTR_FORMAT \"] -> \" PTR_FORMAT \" => \" PTR_FORMAT \" %zu\",\n+                   p2i(ptr_loc), p2i(old_p) + tags, p2i(new_p), tags);\n@@ -140,0 +157,1 @@\n+    ArchiveBuilder::current()->count_relocated_pointer(tags != 0, nulled);\n@@ -180,0 +198,3 @@\n+  _relocated_ptr_info._num_ptrs = 0;\n+  _relocated_ptr_info._num_tagged_ptrs = 0;\n+  _relocated_ptr_info._num_nulled_ptrs = 0;\n@@ -254,1 +275,1 @@\n-  log_info(cds)(\"Gathering classes and symbols ... \");\n+  aot_log_info(aot)(\"Gathering classes and symbols ... \");\n@@ -284,1 +305,1 @@\n-    log_info(cds)(\"Sorting symbols ... \");\n+    aot_log_info(aot)(\"Sorting symbols ... \");\n@@ -306,1 +327,1 @@\n-  log_info(cds)(\"Sorting classes ... \");\n+  aot_log_info(aot)(\"Sorting classes ... \");\n@@ -318,1 +339,1 @@\n-    log_error(cds)(\"Failed to reserve %zu bytes of output buffer.\", buffer_size);\n+    aot_log_error(aot)(\"Failed to reserve %zu bytes of output buffer.\", buffer_size);\n@@ -325,1 +346,1 @@\n-  log_info(cds)(\"Reserved output buffer space at \" PTR_FORMAT \" [%zu bytes]\",\n+  aot_log_info(aot)(\"Reserved output buffer space at \" PTR_FORMAT \" [%zu bytes]\",\n@@ -367,3 +388,3 @@\n-    log_error(cds)(\"my_archive_requested_bottom = \" INTPTR_FORMAT, p2i(my_archive_requested_bottom));\n-    log_error(cds)(\"my_archive_requested_top    = \" INTPTR_FORMAT, p2i(my_archive_requested_top));\n-    log_error(cds)(\"SharedBaseAddress (\" INTPTR_FORMAT \") is too high. \"\n+    aot_log_error(aot)(\"my_archive_requested_bottom = \" INTPTR_FORMAT, p2i(my_archive_requested_bottom));\n+    aot_log_error(aot)(\"my_archive_requested_top    = \" INTPTR_FORMAT, p2i(my_archive_requested_top));\n+    aot_log_error(aot)(\"SharedBaseAddress (\" INTPTR_FORMAT \") is too high. \"\n@@ -427,1 +448,1 @@\n-      log_info(cds, hashtables)(\"Expanded _src_obj_table table to %d\", _src_obj_table.table_size());\n+      log_info(aot, hashtables)(\"Expanded _src_obj_table table to %d\", _src_obj_table.table_size());\n@@ -439,0 +460,5 @@\n+  if (ref->msotype() == MetaspaceObj::MethodDataType) {\n+    MethodData* md = (MethodData*)ref->obj();\n+    md->clean_method_data(false \/* always_clean *\/);\n+  }\n+\n@@ -506,1 +532,1 @@\n-  log_info(cds)(\"Gathering all archivable objects ... \");\n+  aot_log_info(aot)(\"Gathering all archivable objects ... \");\n@@ -536,2 +562,5 @@\n-             ref->msotype() == MetaspaceObj::MethodCountersType) {\n-    return set_to_null;\n+             ref->msotype() == MetaspaceObj::MethodCountersType ||\n+             ref->msotype() == MetaspaceObj::KlassTrainingDataType ||\n+             ref->msotype() == MetaspaceObj::MethodTrainingDataType ||\n+             ref->msotype() == MetaspaceObj::CompileTrainingDataType) {\n+    return (TrainingData::need_data() || TrainingData::assembling_data()) ? make_a_copy : set_to_null;\n@@ -539,1 +568,1 @@\n-    if (AOTCodeCache::is_dumping_adapters()) {\n+    if (CDSConfig::is_dumping_adapters()) {\n@@ -549,0 +578,3 @@\n+      if (RegeneratedClasses::has_been_regenerated(klass)) {\n+        klass = RegeneratedClasses::get_regenerated_object(klass);\n+      }\n@@ -593,1 +625,1 @@\n-  log_info(cds)(\"Allocating RW objects ... \");\n+  aot_log_info(aot)(\"Allocating RW objects ... \");\n@@ -608,1 +640,1 @@\n-  log_info(cds)(\"Allocating RO objects ... \");\n+  aot_log_info(aot)(\"Allocating RO objects ... \");\n@@ -629,1 +661,1 @@\n-  log_info(cds)(\"done (%d objects)\", src_objs->objs()->length());\n+  aot_log_info(aot)(\"done (%d objects)\", src_objs->objs()->length());\n@@ -679,1 +711,1 @@\n-      log_info(cds, hashtables)(\"Expanded _buffered_to_src_table table to %d\", _buffered_to_src_table.table_size());\n+      log_info(aot, hashtables)(\"Expanded _buffered_to_src_table table to %d\", _buffered_to_src_table.table_size());\n@@ -689,1 +721,1 @@\n-  log_trace(cds)(\"Copy: \" PTR_FORMAT \" ==> \" PTR_FORMAT \" %d\", p2i(src), p2i(dest), bytes);\n+  log_trace(aot)(\"Copy: \" PTR_FORMAT \" ==> \" PTR_FORMAT \" %d\", p2i(src), p2i(dest), bytes);\n@@ -755,1 +787,1 @@\n-  log_info(cds)(\"Relocating embedded pointers in core regions ... \");\n+  aot_log_info(aot)(\"Relocating embedded pointers in core regions ... \");\n@@ -758,0 +790,4 @@\n+  log_info(cds)(\"Relocating %zu pointers, %zu tagged, %zu nulled\",\n+                _relocated_ptr_info._num_ptrs,\n+                _relocated_ptr_info._num_tagged_ptrs,\n+                _relocated_ptr_info._num_nulled_ptrs);\n@@ -836,4 +872,0 @@\n-      if (CDSConfig::is_dumping_dynamic_archive()) {\n-        \/\/ For static dump, class loader type are already set.\n-        ik->assign_class_loader_type();\n-      }\n@@ -863,1 +895,1 @@\n-      } else if (ik->is_shared_boot_class()) {\n+      } else if (ik->defined_by_boot_loader()) {\n@@ -866,1 +898,1 @@\n-      } else if (ik->is_shared_platform_class()) {\n+      } else if (ik->defined_by_platform_loader()) {\n@@ -869,1 +901,1 @@\n-      } else if (ik->is_shared_app_class()) {\n+      } else if (ik->defined_by_app_loader()) {\n@@ -873,1 +905,1 @@\n-        assert(ik->is_shared_unregistered_class(), \"must be\");\n+        assert(ik->defined_by_other_loaders(), \"must be\");\n@@ -885,1 +917,1 @@\n-        if (ik->is_shared_boot_class()) {\n+        if (ik->defined_by_boot_loader()) {\n@@ -887,1 +919,1 @@\n-        } else if (ik->is_shared_platform_class()) {\n+        } else if (ik->defined_by_platform_loader()) {\n@@ -889,1 +921,1 @@\n-        } else if (ik->is_shared_app_class()) {\n+        } else if (ik->defined_by_app_loader()) {\n@@ -926,1 +958,1 @@\n-    if (log_is_enabled(Debug, cds, class)) {\n+    if (aot_log_is_enabled(Debug, aot, class)) {\n@@ -928,1 +960,1 @@\n-      log_debug(cds, class)(\"klasses[%5d] = \" PTR_FORMAT \" %-5s %s%s%s%s%s%s%s%s\", i,\n+      aot_log_debug(aot, class)(\"klasses[%5d] = \" PTR_FORMAT \" %-5s %s%s%s%s%s%s%s%s\", i,\n@@ -937,11 +969,11 @@\n-  log_info(cds)(\"Number of classes %d\", num_instance_klasses + num_obj_array_klasses + num_type_array_klasses);\n-  log_info(cds)(\"    instance classes   \" STATS_FORMAT, STATS_PARAMS(instance_klasses));\n-  log_info(cds)(\"      boot             \" STATS_FORMAT, STATS_PARAMS(boot_klasses));\n-  log_info(cds)(\"        vm             \" STATS_FORMAT, STATS_PARAMS(vm_klasses));\n-  log_info(cds)(\"      platform         \" STATS_FORMAT, STATS_PARAMS(platform_klasses));\n-  log_info(cds)(\"      app              \" STATS_FORMAT, STATS_PARAMS(app_klasses));\n-  log_info(cds)(\"      unregistered     \" STATS_FORMAT, STATS_PARAMS(unregistered_klasses));\n-  log_info(cds)(\"      (enum)           \" STATS_FORMAT, STATS_PARAMS(enum_klasses));\n-  log_info(cds)(\"      (hidden)         \" STATS_FORMAT, STATS_PARAMS(hidden_klasses));\n-  log_info(cds)(\"      (old)            \" STATS_FORMAT, STATS_PARAMS(old_klasses));\n-  log_info(cds)(\"      (unlinked)       = %5d, boot = %d, plat = %d, app = %d, unreg = %d\",\n+  aot_log_info(aot)(\"Number of classes %d\", num_instance_klasses + num_obj_array_klasses + num_type_array_klasses);\n+  aot_log_info(aot)(\"    instance classes   \" STATS_FORMAT, STATS_PARAMS(instance_klasses));\n+  aot_log_info(aot)(\"      boot             \" STATS_FORMAT, STATS_PARAMS(boot_klasses));\n+  aot_log_info(aot)(\"        vm             \" STATS_FORMAT, STATS_PARAMS(vm_klasses));\n+  aot_log_info(aot)(\"      platform         \" STATS_FORMAT, STATS_PARAMS(platform_klasses));\n+  aot_log_info(aot)(\"      app              \" STATS_FORMAT, STATS_PARAMS(app_klasses));\n+  aot_log_info(aot)(\"      unregistered     \" STATS_FORMAT, STATS_PARAMS(unregistered_klasses));\n+  aot_log_info(aot)(\"      (enum)           \" STATS_FORMAT, STATS_PARAMS(enum_klasses));\n+  aot_log_info(aot)(\"      (hidden)         \" STATS_FORMAT, STATS_PARAMS(hidden_klasses));\n+  aot_log_info(aot)(\"      (old)            \" STATS_FORMAT, STATS_PARAMS(old_klasses));\n+  aot_log_info(aot)(\"      (unlinked)       = %5d, boot = %d, plat = %d, app = %d, unreg = %d\",\n@@ -949,3 +981,3 @@\n-  log_info(cds)(\"    obj array classes  = %5d\", num_obj_array_klasses);\n-  log_info(cds)(\"    type array classes = %5d\", num_type_array_klasses);\n-  log_info(cds)(\"               symbols = %5d\", _symbols->length());\n+  aot_log_info(aot)(\"    obj array classes  = %5d\", num_obj_array_klasses);\n+  aot_log_info(aot)(\"    type array classes = %5d\", num_type_array_klasses);\n+  aot_log_info(aot)(\"               symbols = %5d\", _symbols->length());\n@@ -959,0 +991,22 @@\n+void ArchiveBuilder::make_training_data_shareable() {\n+  auto clean_td = [&] (address& src_obj,  SourceObjInfo& info) {\n+    if (!is_in_buffer_space(info.buffered_addr())) {\n+      return;\n+    }\n+\n+    if (info.msotype() == MetaspaceObj::KlassTrainingDataType ||\n+        info.msotype() == MetaspaceObj::MethodTrainingDataType ||\n+        info.msotype() == MetaspaceObj::CompileTrainingDataType) {\n+      TrainingData* buffered_td = (TrainingData*)info.buffered_addr();\n+      buffered_td->remove_unshareable_info();\n+    } else if (info.msotype() == MetaspaceObj::MethodDataType) {\n+      MethodData* buffered_mdo = (MethodData*)info.buffered_addr();\n+      buffered_mdo->remove_unshareable_info();\n+    } else if (info.msotype() == MetaspaceObj::MethodCountersType) {\n+      MethodCounters* buffered_mc = (MethodCounters*)info.buffered_addr();\n+      buffered_mc->remove_unshareable_info();\n+    }\n+  };\n+  _src_obj_table.iterate_all(clean_td);\n+}\n+\n@@ -1053,1 +1107,1 @@\n-    log_debug(cds)(\"Relocating archive from [\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \"] to \"\n+    aot_log_debug(aot)(\"Relocating archive from [\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \"] to \"\n@@ -1157,1 +1211,1 @@\n-    log_debug(cds, map)(_LOG_PREFIX \" %s\",\n+    log_debug(aot, map)(_LOG_PREFIX \" %s\",\n@@ -1162,1 +1216,1 @@\n-    log_debug(cds, map)(_LOG_PREFIX \" %s\",\n+    log_debug(aot, map)(_LOG_PREFIX \" %s\",\n@@ -1205,1 +1259,1 @@\n-          log_debug(cds, map)(_LOG_PREFIX \" %s\", p2i(runtime_dest), type_name, bytes,\n+          log_debug(aot, map)(_LOG_PREFIX \" %s\", p2i(runtime_dest), type_name, bytes,\n@@ -1210,1 +1264,1 @@\n-        log_debug(cds, map)(_LOG_PREFIX, p2i(runtime_dest), type_name, bytes);\n+        log_debug(aot, map)(_LOG_PREFIX, p2i(runtime_dest), type_name, bytes);\n@@ -1220,1 +1274,1 @@\n-      log_debug(cds, map)(PTR_FORMAT \": @@ Misc data %zu bytes\",\n+      log_debug(aot, map)(PTR_FORMAT \": @@ Misc data %zu bytes\",\n@@ -1244,1 +1298,1 @@\n-    log_info(cds, map)(\"[%-18s \" PTR_FORMAT \" - \" PTR_FORMAT \" %9zu bytes]\",\n+    log_info(aot, map)(\"[%-18s \" PTR_FORMAT \" - \" PTR_FORMAT \" %9zu bytes]\",\n@@ -1255,1 +1309,1 @@\n-    LogStreamHandle(Info, cds, map) st;\n+    LogStreamHandle(Info, aot, map) st;\n@@ -1366,1 +1420,1 @@\n-    LogStreamHandle(Trace, cds, map, oops) st;\n+    LogStreamHandle(Trace, aot, map, oops) st;\n@@ -1434,1 +1488,1 @@\n-    LogStreamHandle(Trace, cds, map, oops) st;\n+    LogStreamHandle(Trace, aot, map, oops) st;\n@@ -1495,1 +1549,1 @@\n-    LogStreamHandle(Trace, cds, map) lsh;\n+    LogStreamHandle(Trace, aot, map) lsh;\n@@ -1508,1 +1562,1 @@\n-    LogStreamHandle(Info, cds, map) lsh;\n+    LogStreamHandle(Info, aot, map) lsh;\n@@ -1518,1 +1572,1 @@\n-    log_info(cds, map)(\"%s CDS archive map for %s\", CDSConfig::is_dumping_static_archive() ? \"Static\" : \"Dynamic\", mapinfo->full_path());\n+    log_info(aot, map)(\"%s CDS archive map for %s\", CDSConfig::is_dumping_static_archive() ? \"Static\" : \"Dynamic\", mapinfo->full_path());\n@@ -1542,1 +1596,1 @@\n-    log_info(cds, map)(\"[End of CDS archive map]\");\n+    log_info(aot, map)(\"[End of CDS archive map]\");\n@@ -1579,2 +1633,2 @@\n-  if (log_is_enabled(Info, cds)) {\n-    log_info(cds)(\"Full module graph = %s\", CDSConfig::is_dumping_full_module_graph() ? \"enabled\" : \"disabled\");\n+  if (log_is_enabled(Info, aot)) {\n+    log_info(aot)(\"Full module graph = %s\", CDSConfig::is_dumping_full_module_graph() ? \"enabled\" : \"disabled\");\n@@ -1584,1 +1638,1 @@\n-  if (log_is_enabled(Info, cds, map)) {\n+  if (log_is_enabled(Info, aot, map)) {\n@@ -1596,0 +1650,6 @@\n+void ArchiveBuilder::count_relocated_pointer(bool tagged, bool nulled) {\n+  _relocated_ptr_info._num_ptrs ++;\n+  _relocated_ptr_info._num_tagged_ptrs += tagged ? 1 : 0;\n+  _relocated_ptr_info._num_nulled_ptrs += nulled ? 1 : 0;\n+}\n+\n@@ -1618,1 +1678,1 @@\n-  log_debug(cds)(\"total   : %9zu [100.0%% of total] out of %9zu bytes [%5.1f%% used]\",\n+  aot_log_debug(aot)(\"total   : %9zu [100.0%% of total] out of %9zu bytes [%5.1f%% used]\",\n@@ -1623,1 +1683,1 @@\n-  log_debug(cds)(\"bm space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used]\",\n+  aot_log_debug(aot)(\"bm space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used]\",\n@@ -1631,1 +1691,1 @@\n-  log_debug(cds)(\"hp space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used] at \" INTPTR_FORMAT,\n+  aot_log_debug(aot)(\"hp space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used] at \" INTPTR_FORMAT,\n@@ -1642,1 +1702,1 @@\n-  log_error(cds)(\"Unable to allocate from '%s' region: Please reduce the number of shared classes.\", name);\n+  log_error(aot)(\"Unable to allocate from '%s' region: Please reduce the number of shared classes.\", name);\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":130,"deletions":70,"binary":false,"changes":200,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"cds\/regeneratedClasses.hpp\"\n@@ -250,1 +251,1 @@\n-    log_info(cds, heap)(\"archived obj root segment [%d] = %zu bytes, obj = \" PTR_FORMAT,\n+    log_info(aot, heap)(\"archived obj root segment [%d] = %zu bytes, obj = \" PTR_FORMAT,\n@@ -296,1 +297,1 @@\n-  log_info(cds)(\"sorting heap objects\");\n+  log_info(aot)(\"sorting heap objects\");\n@@ -306,1 +307,1 @@\n-  log_info(cds)(\"computed ranks\");\n+  log_info(aot)(\"computed ranks\");\n@@ -308,1 +309,1 @@\n-  log_info(cds)(\"sorting heap objects done\");\n+  log_info(aot)(\"sorting heap objects done\");\n@@ -333,1 +334,1 @@\n-  log_info(cds)(\"Size of heap region = %zu bytes, %d objects, %d roots, %d native ptrs\",\n+  log_info(aot)(\"Size of heap region = %zu bytes, %d objects, %d roots, %d native ptrs\",\n@@ -399,1 +400,1 @@\n-    log_info(cds, heap)(\"Inserting filler obj array of %d elements (%zu bytes total) @ buffer offset %zu\",\n+    log_info(aot, heap)(\"Inserting filler obj array of %d elements (%zu bytes total) @ buffer offset %zu\",\n@@ -479,1 +480,1 @@\n-      log_info(cds, heap)(\"Heap end = %p\", heap_end);\n+      log_info(aot, heap)(\"Heap end = %p\", heap_end);\n@@ -548,0 +549,4 @@\n+      Klass* k = java_lang_Class::as_Klass(source_referent);\n+      if (RegeneratedClasses::has_been_regenerated(k)) {\n+        source_referent = RegeneratedClasses::get_regenerated_object(k)->java_mirror();\n+      }\n@@ -647,1 +652,1 @@\n-  log_info(cds)(\"%s = %7zu ... %7zu (%3zu%% ... %3zu%% = %3zu%%)\", which,\n+  log_info(aot)(\"%s = %7zu ... %7zu (%3zu%% ... %3zu%% = %3zu%%)\", which,\n@@ -765,0 +770,5 @@\n+\n+    if (RegeneratedClasses::has_been_regenerated(native_ptr)) {\n+      native_ptr = RegeneratedClasses::get_regenerated_object(native_ptr);\n+    }\n+\n@@ -774,1 +784,1 @@\n-  log_info(cds, heap)(\"calculate_ptrmap: marked %d non-null native pointers for heap region (%zu bits)\",\n+  log_info(aot, heap)(\"calculate_ptrmap: marked %d non-null native pointers for heap region (%zu bits)\",\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":19,"deletions":9,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/aotLogging.hpp\"\n@@ -38,0 +39,1 @@\n+#include \"cds\/regeneratedClasses.hpp\"\n@@ -177,1 +179,1 @@\n-      if (log_is_enabled(Debug, cds)) {\n+      if (log_is_enabled(Debug, aot)) {\n@@ -179,1 +181,1 @@\n-        log_debug(cds)(\"  calling %s\", method->name_and_sig_as_C_string());\n+        log_debug(aot)(\"  calling %s\", method->name_and_sig_as_C_string());\n@@ -191,1 +193,1 @@\n-  log_debug(cds)(\"Resetting platform loader\");\n+  log_debug(aot)(\"Resetting platform loader\");\n@@ -193,1 +195,1 @@\n-  log_debug(cds)(\"Resetting system loader\");\n+  log_debug(aot)(\"Resetting system loader\");\n@@ -203,1 +205,1 @@\n-  log_debug(cds)(\"Resetting boot loader\");\n+  log_debug(aot)(\"Resetting boot loader\");\n@@ -280,1 +282,1 @@\n-    if (log_is_enabled(Debug, cds, heap)) {\n+    if (log_is_enabled(Debug, aot, heap)) {\n@@ -282,1 +284,1 @@\n-      log_debug(cds, heap)(\"Clearing root %d: was \" PTR_FORMAT, index, p2i(old));\n+      log_debug(aot, heap)(\"Clearing root %d: was \" PTR_FORMAT, index, p2i(old));\n@@ -297,1 +299,1 @@\n-    log_debug(cds, heap)(\"Cannot archive, object (\" PTR_FORMAT \") is too large: %zu\",\n+    log_debug(aot, heap)(\"Cannot archive, object (\" PTR_FORMAT \") is too large: %zu\",\n@@ -339,0 +341,3 @@\n+          if (RegeneratedClasses::has_been_regenerated(m)) {\n+            m = RegeneratedClasses::get_regenerated_object(m);\n+          }\n@@ -345,1 +350,1 @@\n-    if (log_is_enabled(Debug, cds, heap)) {\n+    if (log_is_enabled(Debug, aot, heap)) {\n@@ -347,1 +352,1 @@\n-      LogTarget(Debug, cds, heap) log;\n+      LogTarget(Debug, aot, heap) log;\n@@ -508,3 +513,9 @@\n-  oop orig_mirror = ik->java_mirror();\n-  oop m = scratch_java_mirror(ik);\n-  assert(ik->is_initialized(), \"must be\");\n+  oop orig_mirror;\n+  if (RegeneratedClasses::is_regenerated_object(ik)) {\n+    InstanceKlass* orig_ik = RegeneratedClasses::get_original_object(ik);\n+    precond(orig_ik->is_initialized());\n+    orig_mirror = orig_ik->java_mirror();\n+  } else {\n+    precond(ik->is_initialized());\n+    orig_mirror = ik->java_mirror();\n+  }\n@@ -512,0 +523,1 @@\n+  oop m = scratch_java_mirror(ik);\n@@ -572,1 +584,1 @@\n-  if (log_is_enabled(Debug, cds, init)) {\n+  if (log_is_enabled(Debug, aot, init)) {\n@@ -574,1 +586,1 @@\n-    log_debug(cds, init)(\"copied %3d field(s) in aot-initialized mirror %s%s%s\", nfields, ik->external_name(),\n+    log_debug(aot, init)(\"copied %3d field(s) in aot-initialized mirror %s%s%s\", nfields, ik->external_name(),\n@@ -673,1 +685,1 @@\n-      log_info(cds)(\"Heap range = [\" PTR_FORMAT \" - \"  PTR_FORMAT \"]\",\n+      aot_log_info(aot)(\"Heap range = [\" PTR_FORMAT \" - \"  PTR_FORMAT \"]\",\n@@ -821,1 +833,1 @@\n-      assert(InstanceKlass::cast(abk)->is_shared_boot_class(),\n+      assert(InstanceKlass::cast(abk)->defined_by_boot_loader(),\n@@ -836,1 +848,1 @@\n-  if (log_is_enabled(Debug, cds, heap)) {\n+  if (log_is_enabled(Debug, aot, heap)) {\n@@ -839,1 +851,1 @@\n-      log_debug(cds, heap)(\"Adding klass %s\", orig_k->external_name());\n+      log_debug(aot, heap)(\"Adding klass %s\", orig_k->external_name());\n@@ -882,1 +894,1 @@\n-  log_error(cds, heap)(\"Class %s not allowed in archive heap. Must be in java.base%s%s\",\n+  log_error(aot, heap)(\"Class %s not allowed in archive heap. Must be in java.base%s%s\",\n@@ -894,1 +906,1 @@\n-      log_info(cds, heap)(\"non-early: %s\", k->external_name());\n+      log_info(aot, heap)(\"non-early: %s\", k->external_name());\n@@ -922,1 +934,1 @@\n-    log_info(cds, heap)(\n+    log_info(aot, heap)(\n@@ -961,1 +973,1 @@\n-      if (log_is_enabled(Info, cds, heap)) {\n+      if (log_is_enabled(Info, aot, heap)) {\n@@ -967,1 +979,1 @@\n-        log_info(cds, heap)(\n+        log_info(aot, heap)(\n@@ -1036,1 +1048,1 @@\n-  if (log_is_enabled(Info, cds, heap)) {\n+  if (log_is_enabled(Info, aot, heap)) {\n@@ -1071,1 +1083,1 @@\n-    log_info(cds, heap)(\"Verify heap %s initializing static field(s) in %s\",\n+    log_info(aot, heap)(\"Verify heap %s initializing static field(s) in %s\",\n@@ -1085,1 +1097,1 @@\n-      log_info(cds, heap)(\"Trigger GC %s initializing static field(s) in %s\",\n+      log_info(aot, heap)(\"Trigger GC %s initializing static field(s) in %s\",\n@@ -1115,1 +1127,1 @@\n-    assert(k != nullptr && k->is_shared_boot_class(), \"sanity\");\n+    assert(k != nullptr && k->defined_by_boot_loader(), \"sanity\");\n@@ -1204,1 +1216,1 @@\n-    log_info(cds, heap)(\"Skip initializing ArchivedModuleGraph subgraph: is_using_optimized_module_handling=%s num_module_paths=%d\",\n+    log_info(aot, heap)(\"Skip initializing ArchivedModuleGraph subgraph: is_using_optimized_module_handling=%s num_module_paths=%d\",\n@@ -1247,1 +1259,1 @@\n-    if (log_is_enabled(Info, cds, heap)) {\n+    if (log_is_enabled(Info, aot, heap)) {\n@@ -1249,1 +1261,1 @@\n-      log_info(cds, heap)(\"subgraph %s is not recorded\",\n+      log_info(aot, heap)(\"subgraph %s is not recorded\",\n@@ -1255,1 +1267,1 @@\n-      if (log_is_enabled(Info, cds, heap)) {\n+      if (log_is_enabled(Info, aot, heap)) {\n@@ -1257,1 +1269,1 @@\n-        log_info(cds, heap)(\"subgraph %s cannot be used because full module graph is disabled\",\n+        log_info(aot, heap)(\"subgraph %s cannot be used because full module graph is disabled\",\n@@ -1264,1 +1276,1 @@\n-      if (log_is_enabled(Info, cds, heap)) {\n+      if (log_is_enabled(Info, aot, heap)) {\n@@ -1266,1 +1278,1 @@\n-        log_info(cds, heap)(\"subgraph %s cannot be used because JVMTI ClassFileLoadHook is enabled\",\n+        log_info(aot, heap)(\"subgraph %s cannot be used because JVMTI ClassFileLoadHook is enabled\",\n@@ -1272,1 +1284,1 @@\n-    if (log_is_enabled(Info, cds, heap)) {\n+    if (log_is_enabled(Info, aot, heap)) {\n@@ -1274,1 +1286,1 @@\n-      log_info(cds, heap)(\"%s subgraph %s \", do_init ? \"init\" : \"resolve\", k->external_name());\n+      log_info(aot, heap)(\"%s subgraph %s \", do_init ? \"init\" : \"resolve\", k->external_name());\n@@ -1302,1 +1314,1 @@\n-  assert(k->is_shared_boot_class(), \"sanity\");\n+  assert(k->defined_by_boot_loader(), \"sanity\");\n@@ -1346,1 +1358,1 @@\n-      log_debug(cds, heap)(\"  \" PTR_FORMAT \" init field @ %2d = \" PTR_FORMAT, p2i(k), field_offset, p2i(v));\n+      log_debug(aot, heap)(\"  \" PTR_FORMAT \" init field @ %2d = \" PTR_FORMAT, p2i(k), field_offset, p2i(v));\n@@ -1351,1 +1363,1 @@\n-    if (log_is_enabled(Info, cds, heap)) {\n+    if (log_is_enabled(Info, aot, heap)) {\n@@ -1353,1 +1365,1 @@\n-      log_info(cds, heap)(\"initialize_from_archived_subgraph %s \" PTR_FORMAT \"%s%s\",\n+      log_info(aot, heap)(\"initialize_from_archived_subgraph %s \" PTR_FORMAT \"%s%s\",\n@@ -1425,1 +1437,1 @@\n-      if (!_record_klasses_only && log_is_enabled(Debug, cds, heap)) {\n+      if (!_record_klasses_only && log_is_enabled(Debug, aot, heap)) {\n@@ -1427,1 +1439,1 @@\n-        log_debug(cds, heap)(\"(%d) %s[%d] ==> \" PTR_FORMAT \" size %zu %s\", _level,\n+        log_debug(aot, heap)(\"(%d) %s[%d] ==> \" PTR_FORMAT \" size %zu %s\", _level,\n@@ -1430,2 +1442,2 @@\n-        if (log_is_enabled(Trace, cds, heap)) {\n-          LogTarget(Trace, cds, heap) log;\n+        if (log_is_enabled(Trace, aot, heap)) {\n+          LogTarget(Trace, aot, heap) log;\n@@ -1518,1 +1530,1 @@\n-    log_error(cds, heap)(\"Cannot archive object \" PTR_FORMAT \" of class %s\", p2i(orig_obj), orig_obj->klass()->external_name());\n+    log_error(aot, heap)(\"Cannot archive object \" PTR_FORMAT \" of class %s\", p2i(orig_obj), orig_obj->klass()->external_name());\n@@ -1523,1 +1535,1 @@\n-  if (log_is_enabled(Debug, cds, heap) && java_lang_Class::is_instance(orig_obj)) {\n+  if (log_is_enabled(Debug, aot, heap) && java_lang_Class::is_instance(orig_obj)) {\n@@ -1525,1 +1537,1 @@\n-    LogTarget(Debug, cds, heap) log;\n+    LogTarget(Debug, aot, heap) log;\n@@ -1538,0 +1550,7 @@\n+  if (java_lang_Class::is_instance(orig_obj)) {\n+    Klass* k = java_lang_Class::as_Klass(orig_obj);\n+    if (RegeneratedClasses::has_been_regenerated(k)) {\n+      orig_obj = RegeneratedClasses::get_regenerated_object(k)->java_mirror();\n+    }\n+  }\n+\n@@ -1564,1 +1583,1 @@\n-      log_error(cds, heap)(\"(%d) Unknown java.lang.Class object is in the archived sub-graph\", level);\n+      log_error(aot, heap)(\"(%d) Unknown java.lang.Class object is in the archived sub-graph\", level);\n@@ -1584,1 +1603,1 @@\n-      log_error(cds, heap)(\n+      log_error(aot, heap)(\n@@ -1662,1 +1681,1 @@\n-  assert(k->is_shared_boot_class(), \"must be boot class\");\n+  assert(k->defined_by_boot_loader(), \"must be boot class\");\n@@ -1669,1 +1688,1 @@\n-  log_debug(cds, heap)(\"Start archiving from: %s::%s (\" PTR_FORMAT \")\", klass_name, field_name, p2i(f));\n+  log_debug(aot, heap)(\"Start archiving from: %s::%s (\" PTR_FORMAT \")\", klass_name, field_name, p2i(f));\n@@ -1672,2 +1691,2 @@\n-    if (log_is_enabled(Trace, cds, heap)) {\n-      LogTarget(Trace, cds, heap) log;\n+    if (log_is_enabled(Trace, aot, heap)) {\n+      LogTarget(Trace, aot, heap) log;\n@@ -1680,1 +1699,1 @@\n-      log_error(cds, heap)(\"Archiving failed %s::%s (some reachable objects cannot be archived)\",\n+      log_error(aot, heap)(\"Archiving failed %s::%s (some reachable objects cannot be archived)\",\n@@ -1687,1 +1706,1 @@\n-      log_info(cds, heap)(\"Archived field %s::%s => \" PTR_FORMAT, klass_name, field_name, p2i(f));\n+      log_info(aot, heap)(\"Archived field %s::%s => \" PTR_FORMAT, klass_name, field_name, p2i(f));\n@@ -1713,1 +1732,1 @@\n-  assert(k->is_shared_boot_class(), \"must be boot class\");\n+  assert(k->defined_by_boot_loader(), \"must be boot class\");\n@@ -1806,1 +1825,1 @@\n-  log_info(cds, heap)(\"Start recording subgraph(s) for archived fields in %s\", class_name);\n+  log_info(aot, heap)(\"Start recording subgraph(s) for archived fields in %s\", class_name);\n@@ -1817,1 +1836,1 @@\n-  log_info(cds, heap)(\"Done recording subgraph(s) for archived fields in %s: \"\n+  log_info(aot, heap)(\"Done recording subgraph(s) for archived fields in %s: \"\n@@ -1869,1 +1888,1 @@\n-      log_warning(cds)(\"Loading ArchiveHeapTestClass %s ...\", test_class_name);\n+      log_warning(aot)(\"Loading ArchiveHeapTestClass %s ...\", test_class_name);\n@@ -1887,1 +1906,1 @@\n-    assert(InstanceKlass::cast(ik)->is_shared_boot_class(),\n+    assert(InstanceKlass::cast(ik)->defined_by_boot_loader(),\n@@ -1917,1 +1936,1 @@\n-      log_warning(cds)(\"Initializing ArchiveHeapTestClass %s ...\", test_class_name);\n+      log_warning(aot)(\"Initializing ArchiveHeapTestClass %s ...\", test_class_name);\n@@ -2066,1 +2085,1 @@\n-  log_info(cds, heap)(\"Archived subgraph records = %d\",\n+  log_info(aot, heap)(\"Archived subgraph records = %d\",\n@@ -2068,3 +2087,3 @@\n-  log_info(cds, heap)(\"  Walked %d objects\", _num_total_walked_objs);\n-  log_info(cds, heap)(\"  Archived %d objects\", _num_total_archived_objs);\n-  log_info(cds, heap)(\"  Recorded %d klasses\", _num_total_recorded_klasses);\n+  log_info(aot, heap)(\"  Walked %d objects\", _num_total_walked_objs);\n+  log_info(aot, heap)(\"  Archived %d objects\", _num_total_archived_objs);\n+  log_info(aot, heap)(\"  Recorded %d klasses\", _num_total_recorded_klasses);\n@@ -2077,1 +2096,1 @@\n-  log_info(cds, heap)(\"  Verified %d references\", _num_total_verifications);\n+  log_info(aot, heap)(\"  Verified %d references\", _num_total_verifications);\n@@ -2104,1 +2123,1 @@\n-    LogStream ls(Log(cds, heap)::error());\n+    LogStream ls(Log(aot, heap)::error());\n@@ -2177,1 +2196,1 @@\n-    log_info(cds, heap)(\"%8zu objects are <= %-6zu\"\n+    log_info(aot, heap)(\"%8zu objects are <= %-6zu\"\n@@ -2184,1 +2203,1 @@\n-  log_info(cds, heap)(\"%8zu huge  objects               (total %8zu bytes\"\n+  log_info(aot, heap)(\"%8zu huge  objects               (total %8zu bytes\"\n@@ -2188,1 +2207,1 @@\n-  log_info(cds, heap)(\"%8zu total objects               (total %8zu bytes\"\n+  log_info(aot, heap)(\"%8zu total objects               (total %8zu bytes\"\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":90,"deletions":71,"binary":false,"changes":161,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+  friend class CompileTrainingData;\n@@ -233,0 +234,2 @@\n+  bool has_class_initializer();\n+\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -157,0 +157,2 @@\n+#define JAVA_26_VERSION                   70\n+\n@@ -3741,0 +3743,1 @@\n+  this_klass->set_fieldinfo_search_table(_fieldinfo_search_table);\n@@ -3750,0 +3753,2 @@\n+  DEBUG_ONLY(FieldInfoStream::validate_search_table(_cp, _fieldinfo_stream, _fieldinfo_search_table));\n+\n@@ -5022,0 +5027,1 @@\n+  ik->set_class_loader_type();\n@@ -5060,0 +5066,1 @@\n+  assert(nullptr == _fieldinfo_search_table, \"invariant\");\n@@ -5280,0 +5287,1 @@\n+  _fieldinfo_search_table(nullptr),\n@@ -5356,0 +5364,1 @@\n+  _fieldinfo_search_table = nullptr;\n@@ -5378,0 +5387,1 @@\n+  MetadataFactory::free_array<u1>(_loader_data, _fieldinfo_search_table);\n@@ -5778,0 +5788,1 @@\n+  _fieldinfo_search_table = FieldInfoStream::create_search_table(_cp, _fieldinfo_stream, _loader_data, CHECK);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -127,0 +127,1 @@\n+  Array<u1>* _fieldinfo_search_table;\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -321,1 +321,1 @@\n-    for (AllFieldStream fs(ik->fieldinfo_stream(), ik->constants()); !fs.done(); fs.next()) {\n+    for (AllFieldStream fs(ik); !fs.done(); fs.next()) {\n@@ -481,1 +481,1 @@\n-          for (AllFieldStream fs(ik->fieldinfo_stream(), ik->constants()); !fs.done(); fs.next()) {\n+          for (AllFieldStream fs(ik); !fs.done(); fs.next()) {\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -970,0 +970,7 @@\n+\n+      Array<u1>* old_table = ik->fieldinfo_search_table();\n+      Array<u1>* search_table = FieldInfoStream::create_search_table(ik->constants(), new_fis, k->class_loader_data(), CHECK);\n+      ik->set_fieldinfo_search_table(search_table);\n+      MetadataFactory::free_array<u1>(k->class_loader_data(), old_table);\n+\n+      DEBUG_ONLY(FieldInfoStream::validate_search_table(ik->constants(), new_fis, search_table));\n@@ -1209,1 +1216,1 @@\n-  log_debug(cds, mirror)(\"Archived mirror is: \" PTR_FORMAT, p2i(m));\n+  log_debug(aot, mirror)(\"Archived mirror is: \" PTR_FORMAT, p2i(m));\n@@ -1234,1 +1241,1 @@\n-  if (log_is_enabled(Trace, cds, heap, mirror)) {\n+  if (log_is_enabled(Trace, aot, heap, mirror)) {\n@@ -1236,1 +1243,1 @@\n-    log_trace(cds, heap, mirror)(\n+    log_trace(aot, heap, mirror)(\n@@ -1875,1 +1882,1 @@\n-  return java_thread->obj_field(_park_blocker_offset);\n+  return java_thread->obj_field_access<MO_RELAXED>(_park_blocker_offset);\n@@ -1895,1 +1902,1 @@\n-  class GetStackTraceClosure : public HandshakeClosure {\n+  class GetStackTraceHandshakeClosure : public HandshakeClosure {\n@@ -1903,2 +1910,2 @@\n-    GetStackTraceClosure(Handle java_thread) :\n-        HandshakeClosure(\"GetStackTraceClosure\"), _java_thread(java_thread), _depth(0), _retry_handshake(false),\n+    GetStackTraceHandshakeClosure(Handle java_thread) :\n+        HandshakeClosure(\"GetStackTraceHandshakeClosure\"), _java_thread(java_thread), _depth(0), _retry_handshake(false),\n@@ -1907,1 +1914,1 @@\n-    ~GetStackTraceClosure() {\n+    ~GetStackTraceHandshakeClosure() {\n@@ -1973,1 +1980,1 @@\n-  GetStackTraceClosure gstc(Handle(THREAD, java_thread));\n+  GetStackTraceHandshakeClosure gsthc(Handle(THREAD, java_thread));\n@@ -1975,2 +1982,2 @@\n-   Handshake::execute(&gstc, &tlh, thread);\n-  } while (gstc.read_reset_retry());\n+   Handshake::execute(&gsthc, &tlh, thread);\n+  } while (gsthc.read_reset_retry());\n@@ -1979,1 +1986,1 @@\n-  if (gstc._depth == 0) {\n+  if (gsthc._depth == 0) {\n@@ -1989,1 +1996,1 @@\n-  objArrayHandle trace = oopFactory::new_objArray_handle(k, gstc._depth, CHECK_NULL);\n+  objArrayHandle trace = oopFactory::new_objArray_handle(k, gsthc._depth, CHECK_NULL);\n@@ -1991,2 +1998,2 @@\n-  for (int i = 0; i < gstc._depth; i++) {\n-    methodHandle method(THREAD, gstc._methods->at(i));\n+  for (int i = 0; i < gsthc._depth; i++) {\n+    methodHandle method(THREAD, gsthc._methods->at(i));\n@@ -1994,1 +2001,1 @@\n-                                                      gstc._bcis->at(i),\n+                                                      gsthc._bcis->at(i),\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":23,"deletions":16,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-  uint max_wasted_regions_allowed = ((heap->num_regions() * G1HeapWastePercent) \/ 100);\n+  uint max_wasted_regions_allowed = ((heap->num_committed_regions() * G1HeapWastePercent) \/ 100);\n@@ -136,3 +136,3 @@\n-  _live_stats = NEW_C_HEAP_ARRAY(G1RegionMarkStats, _heap->max_regions(), mtGC);\n-  _compaction_tops = NEW_C_HEAP_ARRAY(HeapWord*, _heap->max_regions(), mtGC);\n-  for (uint j = 0; j < heap->max_regions(); j++) {\n+  _live_stats = NEW_C_HEAP_ARRAY(G1RegionMarkStats, _heap->max_num_regions(), mtGC);\n+  _compaction_tops = NEW_C_HEAP_ARRAY(HeapWord*, _heap->max_num_regions(), mtGC);\n+  for (uint j = 0; j < heap->max_num_regions(); j++) {\n@@ -235,1 +235,1 @@\n-void G1FullCollector::complete_collection() {\n+void G1FullCollector::complete_collection(size_t allocation_word_size) {\n@@ -249,1 +249,1 @@\n-  _heap->prepare_for_mutator_after_full_collection();\n+  _heap->prepare_for_mutator_after_full_collection(allocation_word_size);\n@@ -306,2 +306,0 @@\n-    uint old_active_mt_degree = reference_processor()->num_queues();\n-    reference_processor()->set_active_mt_degree(workers());\n@@ -312,1 +310,1 @@\n-    const ReferenceProcessorStats& stats = reference_processor()->process_discovered_references(task, pt);\n+    const ReferenceProcessorStats& stats = reference_processor()->process_discovered_references(task, _heap->workers(), pt);\n@@ -316,2 +314,0 @@\n-\n-    reference_processor()->set_active_mt_degree(old_active_mt_degree);\n@@ -422,1 +418,1 @@\n-  assert(start_serial < _heap->max_reserved_regions(), \"Called on empty parallel compaction queues\");\n+  assert(start_serial < _heap->max_num_regions(), \"Called on empty parallel compaction queues\");\n@@ -434,1 +430,1 @@\n-  for (uint i = start_serial + 1; i < _heap->max_reserved_regions(); i++) {\n+  for (uint i = start_serial + 1; i < _heap->max_num_regions(); i++) {\n@@ -452,1 +448,1 @@\n-  uint max_reserved_regions = _heap->max_reserved_regions();\n+  uint max_num_regions = _heap->max_num_regions();\n@@ -456,1 +452,1 @@\n-  while (region_index < max_reserved_regions) {\n+  while (region_index < max_num_regions) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":11,"deletions":15,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -83,1 +83,1 @@\n-    _partial_array_splitter(g1h->partial_array_state_manager(), num_workers),\n+    _partial_array_splitter(g1h->partial_array_state_manager(), num_workers, ParGCArrayScanChunk),\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -72,1 +72,1 @@\n-          \"Inconsistent MinSurvivorRatio vs InitialSurvivorRatio: %d vs %d\\n\", MinSurvivorRatio, InitialSurvivorRatio);\n+          \"Inconsistent MinSurvivorRatio vs InitialSurvivorRatio: %zu vs %zu\\n\", MinSurvivorRatio, InitialSurvivorRatio);\n@@ -98,2 +98,2 @@\n-\/\/ The alignment used for boundary between young gen and old gen\n-static size_t default_gen_alignment() {\n+\/\/ The alignment used for spaces in young gen and old gen\n+static size_t default_space_alignment() {\n@@ -106,1 +106,1 @@\n-  SpaceAlignment = GenAlignment = default_gen_alignment();\n+  SpaceAlignment = default_space_alignment();\n@@ -123,3 +123,2 @@\n-  size_t new_alignment = align_up(page_sz, GenAlignment);\n-  if (new_alignment != GenAlignment) {\n-    GenAlignment = new_alignment;\n+  size_t new_alignment = align_up(page_sz, SpaceAlignment);\n+  if (new_alignment != SpaceAlignment) {\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelArguments.cpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -73,2 +73,2 @@\n-  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize, GenAlignment);\n-  ReservedSpace young_rs = heap_rs.last_part(MaxOldSize, GenAlignment);\n+  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize, SpaceAlignment);\n+  ReservedSpace young_rs = heap_rs.last_part(MaxOldSize, SpaceAlignment);\n@@ -97,2 +97,1 @@\n-      MaxOldSize,\n-      \"old\", 1);\n+      MaxOldSize);\n@@ -112,1 +111,1 @@\n-                             GenAlignment,\n+                             SpaceAlignment,\n@@ -222,6 +221,0 @@\n-bool ParallelScavengeHeap::is_maximal_no_gc() const {\n-  \/\/ We don't expand young-gen except at a GC.\n-  return old_gen()->is_maximal_no_gc();\n-}\n-\n-\n@@ -342,1 +335,1 @@\n-      if (op.prologue_succeeded()) {\n+      if (op.gc_succeeded()) {\n@@ -533,15 +526,2 @@\n-  while (true) {\n-    VM_ParallelGCCollect op(gc_count, full_gc_count, cause);\n-    VMThread::execute(&op);\n-\n-    if (!GCCause::is_explicit_full_gc(cause)) {\n-      return;\n-    }\n-\n-    {\n-      MutexLocker ml(Heap_lock);\n-      if (full_gc_count != total_full_collections()) {\n-        return;\n-      }\n-    }\n-  }\n+  VM_ParallelGCCollect op(gc_count, full_gc_count, cause);\n+  VMThread::execute(&op);\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":7,"deletions":27,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -51,1 +51,1 @@\n-  :_partial_array_splitter(_partial_array_state_manager, parallel_gc_threads),\n+  :_partial_array_splitter(_partial_array_state_manager, parallel_gc_threads, ObjArrayMarkingStride),\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManagerNew.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -667,1 +667,1 @@\n-  heap->print_heap_before_gc();\n+  heap->print_before_gc();\n@@ -1174,1 +1174,1 @@\n-  heap->print_heap_after_gc();\n+  heap->print_after_gc();\n@@ -1317,2 +1317,1 @@\n-    ref_processor()->set_active_mt_degree(active_gc_threads);\n-    stats = ref_processor()->process_discovered_references(task, pt);\n+    stats = ref_processor()->process_discovered_references(task, &ParallelScavengeHeap::heap()->workers(), pt);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -210,1 +210,1 @@\n-  heap->print_heap_before_gc();\n+  heap->print_before_gc();\n@@ -687,1 +687,1 @@\n-  heap->print_heap_after_gc();\n+  heap->print_after_gc();\n@@ -821,1 +821,0 @@\n-    ref_processor()->set_active_mt_degree(active_gc_threads);\n@@ -823,1 +822,1 @@\n-    stats = ref_processor()->process_discovered_references(task, pt);\n+    stats = ref_processor()->process_discovered_references(task, &ParallelScavengeHeap::heap()->workers(), pt);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompactNew.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -298,1 +298,1 @@\n-    Threads::possibly_parallel_threads_do(true \/* is_par *\/, &closure);\n+    Threads::possibly_parallel_threads_do(_active_workers > 1 \/* is_par *\/, &closure);\n@@ -356,1 +356,1 @@\n-  heap->print_heap_before_gc();\n+  heap->print_before_gc();\n@@ -414,1 +414,0 @@\n-      reference_processor()->set_active_mt_degree(active_workers);\n@@ -419,1 +418,1 @@\n-      stats = reference_processor()->process_discovered_references(task, pt);\n+      stats = reference_processor()->process_discovered_references(task, &ParallelScavengeHeap::heap()->workers(), pt);\n@@ -591,1 +590,1 @@\n-  heap->print_heap_after_gc();\n+  heap->print_after_gc();\n","filename":"src\/hotspot\/share\/gc\/parallel\/psScavenge.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -634,1 +634,1 @@\n-    const ReferenceProcessorStats& stats = rp->process_discovered_references(task, pt);\n+    const ReferenceProcessorStats& stats = rp->process_discovered_references(task, nullptr, pt);\n@@ -815,1 +815,1 @@\n-    _gen_counters->update_all(_virtual_space.committed_size());\n+    _gen_counters->update_capacity(_virtual_space.committed_size());\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -232,1 +232,1 @@\n-  static void forward_obj(oop obj, HeapWord* new_addr) {\n+  static void forward_obj(oop obj, HeapWord* new_addr, bool after_first_dead) {\n@@ -238,2 +238,7 @@\n-      \/\/ This obj will stay in-place. Fix the markword.\n-      obj->init_mark();\n+      if (!after_first_dead) {\n+        \/\/ This obj will stay in-place and we'll not see it during relocation.\n+        \/\/ Fix the markword.\n+        obj->init_mark();\n+      } else {\n+        FullGCForwarding::forward_to(obj, cast_to_oop(new_addr));\n+      }\n@@ -310,1 +315,1 @@\n-          forward_obj(obj, new_addr);\n+          forward_obj(obj, new_addr, record_first_dead_done);\n@@ -510,1 +515,1 @@\n-    const ReferenceProcessorStats& stats = ref_processor()->process_discovered_references(task, pt);\n+    const ReferenceProcessorStats& stats = ref_processor()->process_discovered_references(task, nullptr, pt);\n","filename":"src\/hotspot\/share\/gc\/serial\/serialFullGC.cpp","additions":10,"deletions":5,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -371,1 +371,1 @@\n-    _gen_counters->update_all(_virtual_space.committed_size());\n+    _gen_counters->update_capacity(_virtual_space.committed_size());\n","filename":"src\/hotspot\/share\/gc\/serial\/tenuredGeneration.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -51,0 +51,2 @@\n+class GCMemoryManager;\n+class GCMetaspaceLog;\n@@ -53,1 +55,0 @@\n-class GCMemoryManager;\n@@ -97,1 +98,2 @@\n-  GCHeapLog* _gc_heap_log;\n+  GCHeapLog*      _heap_log;\n+  GCMetaspaceLog* _metaspace_log;\n@@ -260,5 +262,0 @@\n-  \/\/ Return \"true\" if the part of the heap that allocates Java\n-  \/\/ objects has reached the maximal committed limit that it can\n-  \/\/ reach, without a garbage collection.\n-  virtual bool is_maximal_no_gc() const = 0;\n-\n@@ -423,0 +420,2 @@\n+  void print_relative_to_gc(GCWhen::Type when) const;\n+\n@@ -438,0 +437,2 @@\n+  void print_invocation_on(outputStream* st, const char* type, GCWhen::Type when) const;\n+\n@@ -457,2 +458,2 @@\n-  void print_heap_before_gc();\n-  void print_heap_after_gc();\n+  void print_before_gc() const;\n+  void print_after_gc() const;\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":10,"deletions":9,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -54,1 +54,0 @@\n-  bool                _tlab_end_reset_for_sample;\n@@ -77,2 +76,1 @@\n-      _allocated_tlab_size(0),\n-      _tlab_end_reset_for_sample(false)\n+      _allocated_tlab_size(0)\n@@ -177,5 +175,2 @@\n-  if (!_allocated_outside_tlab && _allocated_tlab_size == 0 && !_tlab_end_reset_for_sample) {\n-    \/\/ Sample if it's a non-TLAB allocation, or a TLAB allocation that either refills the TLAB\n-    \/\/ or expands it due to taking a sampler induced slow path.\n-    return;\n-  }\n+  ThreadHeapSampler& heap_sampler = _thread->heap_sampler();\n+  ThreadLocalAllocBuffer& tlab = _thread->tlab();\n@@ -183,4 +178,2 @@\n-  \/\/ If we want to be sampling, protect the allocated object with a Handle\n-  \/\/ before doing the callback. The callback is done in the destructor of\n-  \/\/ the JvmtiSampledObjectAllocEventCollector.\n-  size_t bytes_since_last = 0;\n+  \/\/ Log sample decision\n+  heap_sampler.log_sample_decision(tlab.top());\n@@ -188,1 +181,4 @@\n-  {\n+  if (heap_sampler.should_sample(tlab.top())) {\n+    \/\/ If we want to be sampling, protect the allocated object with a Handle\n+    \/\/ before doing the callback. The callback is done in the destructor of\n+    \/\/ the JvmtiSampledObjectAllocEventCollector.\n@@ -191,5 +187,2 @@\n-    size_t size_in_bytes = _allocator._word_size * HeapWordSize;\n-    ThreadLocalAllocBuffer& tlab = _thread->tlab();\n-    if (!_allocated_outside_tlab) {\n-      bytes_since_last = tlab.bytes_since_last_sample_point();\n-    }\n+    \/\/ Perform the sampling\n+    heap_sampler.sample(obj_h(), tlab.top());\n@@ -198,1 +191,3 @@\n-    _thread->heap_sampler().check_for_sampling(obj_h(), size_in_bytes, bytes_since_last);\n+    \/\/ Note that after this point all the TLAB can have been retired, and agent\n+    \/\/ code can run and allocate, don't rely on earlier calculations involving\n+    \/\/ the TLAB.\n@@ -201,3 +196,4 @@\n-  if (_tlab_end_reset_for_sample || _allocated_tlab_size != 0) {\n-    \/\/ Tell tlab to forget bytes_since_last if we passed it to the heap sampler.\n-    _thread->tlab().set_sample_end(bytes_since_last != 0);\n+  \/\/ Set a new sampling point in the TLAB if it fits in the current TLAB\n+  const size_t words_until_sample = heap_sampler.bytes_until_sample(tlab.top()) \/ HeapWordSize;\n+  if (words_until_sample <= tlab.free()) {\n+    tlab.set_sampling_point(tlab.top() + words_until_sample);\n@@ -252,0 +248,1 @@\n+  _thread->heap_sampler().inc_outside_tlab_bytes(size_in_bytes);\n@@ -265,0 +262,6 @@\n+    \/\/ When sampling we artificially set the TLAB end to the sample point.\n+    \/\/ When we hit that point it looks like the TLAB is full, but it's\n+    \/\/ not necessarily the case. Set the real end and retry the allocation.\n+\n+    \/\/ Undo previous adjustment of end.\n+    \/\/ Note that notify_allocation_jvmti_sampler will set a new sample point.\n@@ -266,4 +269,2 @@\n-    mem = tlab.allocate(_word_size);\n-    \/\/ We set back the allocation sample point to try to allocate this, reset it\n-    \/\/ when done.\n-    allocation._tlab_end_reset_for_sample = true;\n+    \/\/ Retry the TLAB allocation with the proper end\n+    mem = tlab.allocate(_word_size);\n@@ -285,0 +286,7 @@\n+\n+  \/\/ Record the amount wasted\n+  tlab.record_refill_waste();\n+\n+  \/\/ Retire the current TLAB\n+  _thread->retire_tlab();\n+\n@@ -288,2 +296,0 @@\n-  tlab.retire_before_allocation();\n-\n@@ -320,1 +326,2 @@\n-  tlab.fill(mem, mem + _word_size, allocation._allocated_tlab_size);\n+  _thread->fill_tlab(mem, _word_size, allocation._allocated_tlab_size);\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":36,"deletions":29,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -186,1 +186,1 @@\n-  if (FLAG_IS_DEFAULT(TLABAllocationWeight)) {\n+  if (strcmp(ShenandoahGCMode, \"generational\") && FLAG_IS_DEFAULT(TLABAllocationWeight)) {\n@@ -189,0 +189,1 @@\n+  \/\/ In generational mode, let TLABAllocationWeight keeps its default value of 35.\n@@ -217,0 +218,4 @@\n+\n+  if (FLAG_IS_DEFAULT(TLABSize)) {\n+    TLABSize = MAX2(ShenandoahHeapRegion::region_size_bytes() \/ 256, (size_t) 32 * 1024);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahArguments.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -186,0 +186,23 @@\n+bool ShenandoahGenerationalHeap::requires_barriers(stackChunkOop obj) const {\n+  if (is_idle()) {\n+    return false;\n+  }\n+\n+  if (is_concurrent_young_mark_in_progress() && is_in_young(obj) && !marking_context()->allocated_after_mark_start(obj)) {\n+    \/\/ We are marking young, this object is in young, and it is below the TAMS\n+    return true;\n+  }\n+\n+  if (is_in_old(obj)) {\n+    \/\/ Card marking barriers are required for objects in the old generation\n+    return true;\n+  }\n+\n+  if (has_forwarded_objects()) {\n+    \/\/ Object may have pointers that need to be updated\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -1248,1 +1248,1 @@\n-class ShenandoahGCStatePropagator : public HandshakeClosure {\n+class ShenandoahGCStatePropagatorHandshakeClosure : public HandshakeClosure {\n@@ -1250,1 +1250,1 @@\n-  explicit ShenandoahGCStatePropagator(char gc_state) :\n+  explicit ShenandoahGCStatePropagatorHandshakeClosure(char gc_state) :\n@@ -1261,1 +1261,1 @@\n-class ShenandoahPrepareForUpdateRefs : public HandshakeClosure {\n+class ShenandoahPrepareForUpdateRefsHandshakeClosure : public HandshakeClosure {\n@@ -1263,1 +1263,1 @@\n-  explicit ShenandoahPrepareForUpdateRefs(char gc_state) :\n+  explicit ShenandoahPrepareForUpdateRefsHandshakeClosure(char gc_state) :\n@@ -1275,1 +1275,1 @@\n-  ShenandoahGCStatePropagator _propagator;\n+  ShenandoahGCStatePropagatorHandshakeClosure _propagator;\n@@ -1298,1 +1298,1 @@\n-  ShenandoahPrepareForUpdateRefs prepare_for_update_refs(_gc_state.raw_value());\n+  ShenandoahPrepareForUpdateRefsHandshakeClosure prepare_for_update_refs(_gc_state.raw_value());\n@@ -1330,1 +1330,1 @@\n-  ShenandoahGCStatePropagator propagator(_gc_state.raw_value());\n+  ShenandoahGCStatePropagatorHandshakeClosure propagator(_gc_state.raw_value());\n@@ -1509,0 +1509,3 @@\n+    if (ZeroTLAB) {\n+      t->retire_tlab();\n+    }\n@@ -1526,2 +1529,1 @@\n-    ThreadLocalAllocBuffer& tlab = t->tlab();\n-    tlab.retire(&stats);\n+    t->retire_tlab(&stats);\n@@ -1529,1 +1531,1 @@\n-      tlab.resize();\n+      t->tlab().resize();\n@@ -2028,1 +2030,1 @@\n-class ShenandoahRendezvousClosure : public HandshakeClosure {\n+class ShenandoahRendezvousHandshakeClosure : public HandshakeClosure {\n@@ -2030,1 +2032,1 @@\n-  inline ShenandoahRendezvousClosure(const char* name) : HandshakeClosure(name) {}\n+  inline ShenandoahRendezvousHandshakeClosure(const char* name) : HandshakeClosure(name) {}\n@@ -2035,1 +2037,1 @@\n-  ShenandoahRendezvousClosure cl(name);\n+  ShenandoahRendezvousHandshakeClosure cl(name);\n@@ -2077,1 +2079,1 @@\n-    ShenandoahGCStatePropagator propagator(_gc_state.raw_value());\n+    ShenandoahGCStatePropagatorHandshakeClosure propagator(_gc_state.raw_value());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":16,"deletions":14,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -494,1 +494,1 @@\n-    return _shared[static_cast<uint>(age) - 1];\n+    return _shared[untype(age - 1)];\n@@ -498,1 +498,1 @@\n-    _shared[static_cast<uint>(age) - 1] = page;\n+    _shared[untype(age - 1)] = page;\n@@ -576,1 +576,1 @@\n-    return _target[static_cast<uint>(age) - 1];\n+    return _target[untype(age - 1)];\n@@ -580,1 +580,1 @@\n-    _target[static_cast<uint>(age) - 1] = page;\n+    _target[untype(age - 1)] = page;\n@@ -1246,1 +1246,1 @@\n-  const uint age = static_cast<uint>(from_age);\n+  const uint age = untype(from_age);\n@@ -1251,1 +1251,1 @@\n-  return static_cast<ZPageAge>(age + 1);\n+  return to_zpageage(age + 1);\n","filename":"src\/hotspot\/share\/gc\/z\/zRelocate.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"code\/nmethod.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"oops\/trainingData.hpp\"\n@@ -508,2 +510,5 @@\n-      klass = *((Klass**) (intptr_t) (base_address + offset));\n-      if (klass == nullptr || !klass->is_loader_alive()) {\n+      Klass* k = *((Klass**) (intptr_t) (base_address + offset));\n+      if (k == nullptr || k->class_loader_data() == nullptr || !TrainingData::is_klass_loaded(k)) {\n+        return nullptr;\n+      }\n+      if (!k->is_loader_alive()) {\n@@ -513,0 +518,1 @@\n+      klass = k;\n@@ -811,0 +817,8 @@\n+C2V_VMENTRY_0(jint, getNumIndyEntries, (JNIEnv* env, jobject, ARGUMENT_PAIR(cp)))\n+  constantPoolHandle cp(THREAD, UNPACK_PAIR(ConstantPool, cp));\n+  if (cp->cache()->resolved_indy_entries() == nullptr) {\n+    return 0;\n+  }\n+  return cp->resolved_indy_entries_length();\n+C2V_END\n+\n@@ -1196,1 +1210,1 @@\n-        JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, true, JVMCI_CHECK_0);\n+        JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, true, nmethod::InvalidationReason::JVMCI_REPLACED_WITH_NEW_CODE, JVMCI_CHECK_0);\n@@ -1207,0 +1221,8 @@\n+C2V_VMENTRY_0(jobject, getInvalidationReasonDescription, (JNIEnv *env, jobject, jint invalidation_reason))\n+  HandleMark hm(THREAD);\n+  JNIHandleMark jni_hm(thread);\n+  nmethod::InvalidationReason reason = static_cast<nmethod::InvalidationReason>(invalidation_reason);\n+  JVMCIObject desc = JVMCIENV->create_string(nmethod::invalidation_reason_to_string(reason), JVMCI_CHECK_NULL);\n+  return JVMCIENV->get_jobject(desc);\n+C2V_END\n+\n@@ -1372,1 +1394,1 @@\n-    code->make_not_entrant(\"JVMCI reprofile\");\n+    code->make_not_entrant(nmethod::InvalidationReason::JVMCI_REPROFILE);\n@@ -1385,1 +1407,6 @@\n-C2V_VMENTRY(void, invalidateHotSpotNmethod, (JNIEnv* env, jobject, jobject hs_nmethod, jboolean deoptimize))\n+C2V_VMENTRY(void, invalidateHotSpotNmethod, (JNIEnv* env, jobject, jobject hs_nmethod, jboolean deoptimize, jint invalidation_reason))\n+  int first = static_cast<int>(nmethod::InvalidationReason::C1_CODEPATCH);\n+  int last = static_cast<int>(nmethod::InvalidationReason::INVALIDATION_REASONS_COUNT);\n+  if (invalidation_reason < first || invalidation_reason >= last) {\n+    JVMCI_THROW_MSG(IllegalArgumentException, err_msg(\"Invalid invalidation_reason: %d\", invalidation_reason));\n+  }\n@@ -1387,1 +1414,1 @@\n-  JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, deoptimize, JVMCI_CHECK);\n+  JVMCIENV->invalidate_nmethod_mirror(nmethod_mirror, deoptimize, static_cast<nmethod::InvalidationReason>(invalidation_reason), JVMCI_CHECK);\n@@ -1812,1 +1839,1 @@\n-    fst.current()->cb()->as_nmethod()->make_not_entrant(\"JVMCI materialize virtual objects\");\n+    fst.current()->cb()->as_nmethod()->make_not_entrant(nmethod::InvalidationReason::JVMCI_MATERIALIZE_VIRTUAL_OBJECT);\n@@ -2222,0 +2249,20 @@\n+C2V_VMENTRY_NULL(jobjectArray, getAllMethods, (JNIEnv* env, jobject, ARGUMENT_PAIR(klass)))\n+  Klass* klass = UNPACK_PAIR(Klass, klass);\n+  if (klass == nullptr) {\n+    JVMCI_THROW_NULL(NullPointerException);\n+  }\n+  if (!klass->is_instance_klass()) {\n+    JVMCIObjectArray methods = JVMCIENV->new_ResolvedJavaMethod_array(0, JVMCI_CHECK_NULL);\n+    return JVMCIENV->get_jobjectArray(methods);\n+  }\n+\n+  InstanceKlass* iklass = InstanceKlass::cast(klass);\n+  JVMCIObjectArray methods = JVMCIENV->new_ResolvedJavaMethod_array(iklass->methods()->length(), JVMCI_CHECK_NULL);\n+  for (int i = 0; i < iklass->methods()->length(); i++) {\n+    methodHandle mh(THREAD, iklass->methods()->at(i));\n+    JVMCIObject method = JVMCIENV->get_jvmci_method(mh, JVMCI_CHECK_NULL);\n+    JVMCIENV->put_object_at(methods, i, method);\n+  }\n+  return JVMCIENV->get_jobjectArray(methods);\n+C2V_END\n+\n@@ -2834,1 +2881,1 @@\n-          oop nmethod_mirror = data->get_nmethod_mirror(nm, \/* phantom_ref *\/ true);\n+          oop nmethod_mirror = data->get_nmethod_mirror(nm);\n@@ -2866,1 +2913,1 @@\n-          if (data->get_nmethod_mirror(nm, \/* phantom_ref *\/ false) != nullptr) {\n+          if (data->get_nmethod_mirror(nm) != nullptr) {\n@@ -3298,0 +3345,1 @@\n+  {CC \"getNumIndyEntries\",                            CC \"(\" HS_CONSTANT_POOL2 \")I\",                                                        FN_PTR(getNumIndyEntries)},\n@@ -3320,0 +3368,1 @@\n+  {CC \"getInvalidationReasonDescription\",             CC \"(I)\" STRING,                                                                      FN_PTR(getInvalidationReasonDescription)},\n@@ -3328,1 +3377,1 @@\n-  {CC \"invalidateHotSpotNmethod\",                     CC \"(\" HS_NMETHOD \"Z)V\",                                                              FN_PTR(invalidateHotSpotNmethod)},\n+  {CC \"invalidateHotSpotNmethod\",                     CC \"(\" HS_NMETHOD \"ZI)V\",                                                             FN_PTR(invalidateHotSpotNmethod)},\n@@ -3357,0 +3406,1 @@\n+  {CC \"getAllMethods\",                                CC \"(\" HS_KLASS2 \")[\" RESOLVED_METHOD,                                                FN_PTR(getAllMethods)},\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":60,"deletions":10,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -148,0 +148,1 @@\n+address CompilerToVM::Data::dcbrt;\n@@ -290,0 +291,1 @@\n+  SET_TRIGFUNC_OR_NULL(dcbrt);\n@@ -344,1 +346,1 @@\n-#define PREDEFINED_CONFIG_FLAGS(do_bool_flag, do_int_flag, do_intx_flag, do_uintx_flag) \\\n+#define PREDEFINED_CONFIG_FLAGS(do_bool_flag, do_int_flag, do_size_t_flag, do_intx_flag, do_uintx_flag) \\\n@@ -355,1 +357,1 @@\n-  do_uintx_flag(CodeCacheSegmentSize)                                      \\\n+  do_size_t_flag(CodeCacheSegmentSize)                                     \\\n@@ -542,4 +544,5 @@\n-#define ADD_BOOL_FLAG(name)  ADD_FLAG(bool, name, BOXED_BOOLEAN)\n-#define ADD_INT_FLAG(name)   ADD_FLAG(int, name, BOXED_LONG)\n-#define ADD_INTX_FLAG(name)  ADD_FLAG(intx, name, BOXED_LONG)\n-#define ADD_UINTX_FLAG(name) ADD_FLAG(uintx, name, BOXED_LONG)\n+#define ADD_BOOL_FLAG(name)   ADD_FLAG(bool, name, BOXED_BOOLEAN)\n+#define ADD_INT_FLAG(name)    ADD_FLAG(int, name, BOXED_LONG)\n+#define ADD_SIZE_T_FLAG(name) ADD_FLAG(size_t, name, BOXED_LONG)\n+#define ADD_INTX_FLAG(name)   ADD_FLAG(intx, name, BOXED_LONG)\n+#define ADD_UINTX_FLAG(name)  ADD_FLAG(uintx, name, BOXED_LONG)\n@@ -547,1 +550,1 @@\n-  len = 0 + PREDEFINED_CONFIG_FLAGS(COUNT_FLAG, COUNT_FLAG, COUNT_FLAG, COUNT_FLAG);\n+  len = 0 + PREDEFINED_CONFIG_FLAGS(COUNT_FLAG, COUNT_FLAG, COUNT_FLAG, COUNT_FLAG, COUNT_FLAG);\n@@ -551,1 +554,1 @@\n-  PREDEFINED_CONFIG_FLAGS(ADD_BOOL_FLAG, ADD_INT_FLAG, ADD_INTX_FLAG, ADD_UINTX_FLAG)\n+  PREDEFINED_CONFIG_FLAGS(ADD_BOOL_FLAG, ADD_INT_FLAG, ADD_SIZE_T_FLAG, ADD_INTX_FLAG, ADD_UINTX_FLAG)\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVMInit.cpp","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -131,0 +131,1 @@\n+  LOG_TAG(methodtrace) \\\n@@ -209,0 +210,1 @@\n+  LOG_TAG(training) \\\n@@ -218,0 +220,1 @@\n+  LOG_TAG(vmatree) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+#include \"oops\/jmethodIDTable.hpp\"\n@@ -439,0 +440,3 @@\n+    \/\/ Initialize table for matching jmethodID, before SystemDictionary.\n+    JmethodIDTable::initialize();\n+\n@@ -447,1 +451,0 @@\n-\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -210,1 +210,1 @@\n-  log_trace(cds)(\"Iter(ArrayKlass): %p (%s)\", this, external_name());\n+  log_trace(aot)(\"Iter(ArrayKlass): %p (%s)\", this, external_name());\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -193,0 +193,4 @@\n+char* CompressedKlassPointers::reserve_address_space_below_4G(size_t size, bool aslr) {\n+  return reserve_address_space_X(0, nth_bit(32), size, Metaspace::reserve_alignment(), aslr);\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -142,0 +142,1 @@\n+  static char* reserve_address_space_below_4G(size_t size, bool aslr);\n@@ -216,0 +217,1 @@\n+  static address  base_addr()        { return (address)&_base; }\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -690,0 +690,5 @@\n+  if (fieldinfo_search_table() != nullptr && !fieldinfo_search_table()->is_shared()) {\n+    MetadataFactory::free_array<u1>(loader_data, fieldinfo_search_table());\n+  }\n+  set_fieldinfo_search_table(nullptr);\n+\n@@ -870,1 +875,1 @@\n-  if (log_is_enabled(Info, cds, init)) {\n+  if (log_is_enabled(Info, aot, init)) {\n@@ -872,1 +877,1 @@\n-    log_info(cds, init)(\"%s (aot-inited)\", external_name());\n+    log_info(aot, init)(\"%s (aot-inited)\", external_name());\n@@ -1331,0 +1336,1 @@\n+    CompilationPolicy::replay_training_at_init(this, THREAD);\n@@ -1789,7 +1795,6 @@\n-  for (JavaFieldStream fs(this); !fs.done(); fs.next()) {\n-    Symbol* f_name = fs.name();\n-    Symbol* f_sig  = fs.signature();\n-    if (f_name == name && f_sig == sig) {\n-      fd->reinitialize(const_cast<InstanceKlass*>(this), fs.to_FieldInfo());\n-      return true;\n-    }\n+  JavaFieldStream fs(this);\n+  if (fs.lookup(name, sig)) {\n+    assert(fs.name() == name, \"name must match\");\n+    assert(fs.signature() == sig, \"signature must match\");\n+    fd->reinitialize(const_cast<InstanceKlass*>(this), fs.to_FieldInfo());\n+    return true;\n@@ -2394,0 +2399,18 @@\n+\/\/ Allocate the jmethodID cache.\n+static jmethodID* create_jmethod_id_cache(size_t size) {\n+  jmethodID* jmeths = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n+  memset(jmeths, 0, (size + 1) * sizeof(jmethodID));\n+  \/\/ cache size is stored in element[0], other elements offset by one\n+  jmeths[0] = (jmethodID)size;\n+  return jmeths;\n+}\n+\n+\/\/ When reading outside a lock, use this.\n+jmethodID* InstanceKlass::methods_jmethod_ids_acquire() const {\n+  return Atomic::load_acquire(&_methods_jmethod_ids);\n+}\n+\n+void InstanceKlass::release_set_methods_jmethod_ids(jmethodID* jmeths) {\n+  Atomic::release_store(&_methods_jmethod_ids, jmeths);\n+}\n+\n@@ -2395,6 +2418,1 @@\n-\/\/ This code is called by the VMThread and JavaThreads so the\n-\/\/ locking has to be done very carefully to avoid deadlocks\n-\/\/ and\/or other cache consistency problems.\n-\/\/\n-jmethodID InstanceKlass::get_jmethod_id(const methodHandle& method_h) {\n-  Method* method = method_h();\n+jmethodID InstanceKlass::get_jmethod_id(Method* method) {\n@@ -2421,1 +2439,1 @@\n-    jmeths = methods_jmethod_ids_acquire();\n+    jmeths = _methods_jmethod_ids;\n@@ -2426,4 +2444,1 @@\n-      jmeths = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n-      memset(jmeths, 0, (size + 1) * sizeof(jmethodID));\n-      \/\/ cache size is stored in element[0], other elements offset by one\n-      jmeths[0] = (jmethodID)size;\n+      jmeths = create_jmethod_id_cache(size);\n@@ -2459,4 +2474,1 @@\n-      jmethodID* new_cache = NEW_C_HEAP_ARRAY(jmethodID, size + 1, mtClass);\n-      memset(new_cache, 0, (size + 1) * sizeof(jmethodID));\n-      \/\/ The cache size is stored in element[0]; the other elements are offset by one.\n-      new_cache[0] = (jmethodID)size;\n+      jmethodID* new_cache = create_jmethod_id_cache(size);\n@@ -2473,3 +2485,2 @@\n-\/\/ Figure out how many jmethodIDs haven't been allocated, and make\n-\/\/ sure space for them is pre-allocated.  This makes getting all\n-\/\/ method ids much, much faster with classes with more than 8\n+\/\/ Make a jmethodID for all methods in this class.  This makes getting all method\n+\/\/ ids much, much faster with classes with more than 8\n@@ -2478,2 +2489,8 @@\n-void InstanceKlass::ensure_space_for_methodids(int start_offset) {\n-  int new_jmeths = 0;\n+void InstanceKlass::make_methods_jmethod_ids() {\n+  MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);\n+  jmethodID* jmeths = _methods_jmethod_ids;\n+  if (jmeths == nullptr) {\n+    jmeths = create_jmethod_id_cache(idnum_allocated_count());\n+    release_set_methods_jmethod_ids(jmeths);\n+  }\n+\n@@ -2481,1 +2498,1 @@\n-  for (int index = start_offset; index < length; index++) {\n+  for (int index = 0; index < length; index++) {\n@@ -2483,3 +2500,7 @@\n-    jmethodID id = m->find_jmethod_id_or_null();\n-    if (id == nullptr) {\n-      new_jmeths++;\n+    int idnum = m->method_idnum();\n+    assert(!m->is_old(), \"should not have old methods or I'm confused\");\n+    jmethodID id = Atomic::load_acquire(&jmeths[idnum + 1]);\n+    if (!m->is_overpass() &&  \/\/ skip overpasses\n+        id == nullptr) {\n+      id = Method::make_jmethod_id(class_loader_data(), m);\n+      Atomic::release_store(&jmeths[idnum + 1], id);\n@@ -2488,3 +2509,0 @@\n-  if (new_jmeths != 0) {\n-    Method::ensure_jmethod_ids(class_loader_data(), new_jmeths);\n-  }\n@@ -2571,1 +2589,1 @@\n-  if (log_is_enabled(Trace, cds)) {\n+  if (log_is_enabled(Trace, aot)) {\n@@ -2573,1 +2591,1 @@\n-    log_trace(cds)(\"Iter(InstanceKlass): %p (%s)\", this, external_name());\n+    log_trace(aot)(\"Iter(InstanceKlass): %p (%s)\", this, external_name());\n@@ -2613,0 +2631,1 @@\n+  it->push(&_fieldinfo_search_table);\n@@ -2651,0 +2670,2 @@\n+  _misc_flags.set_has_init_deps_processed(false);\n+\n@@ -2711,0 +2732,2 @@\n+\n+  DEBUG_ONLY(FieldInfoStream::validate_search_table(_constants, _fieldinfo_stream, _fieldinfo_search_table));\n@@ -2738,1 +2761,1 @@\n-    if (is_shared_unregistered_class()) {\n+    if (defined_by_other_loaders()) {\n@@ -2817,0 +2840,2 @@\n+\n+  DEBUG_ONLY(FieldInfoStream::validate_search_table(_constants, _fieldinfo_stream, _fieldinfo_search_table));\n@@ -2846,11 +2871,0 @@\n-int InstanceKlass::shared_class_loader_type() const {\n-  if (is_shared_boot_class()) {\n-    return ClassLoader::BOOT_LOADER;\n-  } else if (is_shared_platform_class()) {\n-    return ClassLoader::PLATFORM_LOADER;\n-  } else if (is_shared_app_class()) {\n-    return ClassLoader::APP_LOADER;\n-  } else {\n-    return ClassLoader::OTHER;\n-  }\n-}\n@@ -2926,1 +2940,1 @@\n-  jmethodID* jmeths = methods_jmethod_ids_acquire();\n+  jmethodID* jmeths = _methods_jmethod_ids;\n@@ -2972,2 +2986,2 @@\n-InstanceKlass* InstanceKlass::get_klass_version(int version) {\n-  for (InstanceKlass* ik = this; ik != nullptr; ik = ik->previous_versions()) {\n+const InstanceKlass* InstanceKlass::get_klass_version(int version) const {\n+  for (const InstanceKlass* ik = this; ik != nullptr; ik = ik->previous_versions()) {\n@@ -3504,1 +3518,1 @@\n-      inv->make_not_entrant(\"OSR invalidation of lower levels\");\n+      inv->make_not_entrant(nmethod::InvalidationReason::OSR_INVALIDATION_OF_LOWER_LEVEL);\n@@ -3772,0 +3786,5 @@\n+\n+  if (fieldinfo_search_table() != nullptr) {\n+    st->print_cr(BULLET\"---- field info search table:\");\n+    FieldInfoStream::print_search_table(st, _constants, _fieldinfo_stream, _fieldinfo_search_table);\n+  }\n@@ -4273,8 +4292,4 @@\n-\/\/ This nulls out jmethodIDs for all methods in 'klass'\n-\/\/ It needs to be called explicitly for all previous versions of a class because these may not be cleaned up\n-\/\/ during class unloading.\n-\/\/ We can not use the jmethodID cache associated with klass directly because the 'previous' versions\n-\/\/ do not have the jmethodID cache filled in. Instead, we need to lookup jmethodID for each method and this\n-\/\/ is expensive - O(n) for one jmethodID lookup. For all contained methods it is O(n^2).\n-\/\/ The reason for expensive jmethodID lookup for each method is that there is no direct link between method and jmethodID.\n-void InstanceKlass::clear_jmethod_ids(InstanceKlass* klass) {\n+\/\/ This nulls out the jmethodID for all obsolete methods in the previous version of the 'klass'.\n+\/\/ These obsolete methods only exist in the previous version and we're about to delete the memory for them.\n+\/\/ The jmethodID for these are deallocated when we unload the class, so this doesn't remove them from the table.\n+void InstanceKlass::clear_obsolete_jmethod_ids(InstanceKlass* klass) {\n@@ -4284,0 +4299,1 @@\n+    \/\/ Only need to clear obsolete methods.\n@@ -4333,1 +4349,1 @@\n-      clear_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n+      clear_obsolete_jmethod_ids(pv_node); \/\/ jmethodID maintenance for the unloaded class\n@@ -4471,1 +4487,1 @@\n-Method* InstanceKlass::method_with_idnum(int idnum) {\n+Method* InstanceKlass::method_with_idnum(int idnum) const {\n@@ -4490,1 +4506,1 @@\n-Method* InstanceKlass::method_with_orig_idnum(int idnum) {\n+Method* InstanceKlass::method_with_orig_idnum(int idnum) const {\n@@ -4510,2 +4526,2 @@\n-Method* InstanceKlass::method_with_orig_idnum(int idnum, int version) {\n-  InstanceKlass* holder = get_klass_version(version);\n+Method* InstanceKlass::method_with_orig_idnum(int idnum, int version) const {\n+  const InstanceKlass* holder = get_klass_version(version);\n@@ -4515,2 +4531,1 @@\n-  Method* method = holder->method_with_orig_idnum(idnum);\n-  return method;\n+  return holder->method_with_orig_idnum(idnum);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":84,"deletions":69,"binary":false,"changes":153,"status":"modified"},{"patch":"@@ -281,0 +281,1 @@\n+  Array<u1>*          _fieldinfo_search_table;\n@@ -311,6 +312,6 @@\n-  \/\/ The three BUILTIN class loader types\n-  bool is_shared_boot_class() const { return _misc_flags.is_shared_boot_class(); }\n-  bool is_shared_platform_class() const { return _misc_flags.is_shared_platform_class(); }\n-  bool is_shared_app_class() const {  return _misc_flags.is_shared_app_class(); }\n-  \/\/ The UNREGISTERED class loader type\n-  bool is_shared_unregistered_class() const { return _misc_flags.is_shared_unregistered_class(); }\n+  \/\/ Quick checks for the loader that defined this class (without switching on this->class_loader())\n+  bool defined_by_boot_loader() const      { return _misc_flags.defined_by_boot_loader(); }\n+  bool defined_by_platform_loader() const  { return _misc_flags.defined_by_platform_loader(); }\n+  bool defined_by_app_loader() const       { return _misc_flags.defined_by_app_loader(); }\n+  bool defined_by_other_loaders() const    { return _misc_flags.defined_by_other_loaders(); }\n+  void set_class_loader_type()             { _misc_flags.set_class_loader_type(_class_loader_data); }\n@@ -325,6 +326,0 @@\n-#if INCLUDE_CDS\n-  int  shared_class_loader_type() const;\n-  void set_shared_class_loader_type(s2 loader_type) { _misc_flags.set_shared_class_loader_type(loader_type); }\n-  void assign_class_loader_type() { _misc_flags.assign_class_loader_type(_class_loader_data); }\n-#endif\n-\n@@ -360,3 +355,3 @@\n-  Method* method_with_idnum(int idnum);\n-  Method* method_with_orig_idnum(int idnum);\n-  Method* method_with_orig_idnum(int idnum, int version);\n+  Method* method_with_idnum(int idnum) const;\n+  Method* method_with_orig_idnum(int idnum) const;\n+  Method* method_with_orig_idnum(int idnum, int version) const;\n@@ -409,0 +404,3 @@\n+  Array<u1>* fieldinfo_search_table() const { return _fieldinfo_search_table; }\n+  void set_fieldinfo_search_table(Array<u1>* table) { _fieldinfo_search_table = table; }\n+\n@@ -451,0 +449,3 @@\n+  InstanceKlass* nest_host_or_null() {\n+    return _nest_host;\n+  }\n@@ -699,1 +700,1 @@\n-  InstanceKlass* get_klass_version(int version);\n+  const InstanceKlass* get_klass_version(int version) const;\n@@ -788,2 +789,2 @@\n-  jmethodID get_jmethod_id(const methodHandle& method_h);\n-  void ensure_space_for_methodids(int start_offset = 0);\n+  jmethodID get_jmethod_id(Method* method);\n+  void make_methods_jmethod_ids();\n@@ -1072,4 +1073,4 @@\n-  inline jmethodID* methods_jmethod_ids_acquire() const;\n-  inline void release_set_methods_jmethod_ids(jmethodID* jmeths);\n-  \/\/ This nulls out jmethodIDs for all methods in 'klass'\n-  static void clear_jmethod_ids(InstanceKlass* klass);\n+  jmethodID* methods_jmethod_ids_acquire() const;\n+  void release_set_methods_jmethod_ids(jmethodID* jmeths);\n+  \/\/ This nulls out obsolete jmethodIDs for all methods in 'klass'.\n+  static void clear_obsolete_jmethod_ids(InstanceKlass* klass);\n@@ -1138,0 +1139,6 @@\n+  bool     has_init_deps_processed() const { return _misc_flags.has_init_deps_processed(); }\n+  void set_has_init_deps_processed() {\n+    assert(is_initialized(), \"\");\n+    assert(!has_init_deps_processed(), \"already set\"); \/\/ one-off action\n+    _misc_flags.set_has_init_deps_processed(true);\n+  }\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":29,"deletions":22,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -765,1 +765,1 @@\n-  if (log_is_enabled(Trace, cds)) {\n+  if (log_is_enabled(Trace, aot)) {\n@@ -767,1 +767,1 @@\n-    log_trace(cds)(\"Iter(Klass): %p (%s)\", this, external_name());\n+    log_trace(aot)(\"Iter(Klass): %p (%s)\", this, external_name());\n@@ -796,1 +796,1 @@\n-  if (log_is_enabled(Trace, cds, unshareable)) {\n+  if (log_is_enabled(Trace, aot, unshareable)) {\n@@ -798,1 +798,1 @@\n-    log_trace(cds, unshareable)(\"remove: %s\", external_name());\n+    log_trace(aot, unshareable)(\"remove: %s\", external_name());\n@@ -814,4 +814,12 @@\n-  \/\/ FIXME: validation in Klass::hash_secondary_supers() may fail for shared klasses.\n-  \/\/ Even though the bitmaps always match, the canonical order of elements in the table\n-  \/\/ is not guaranteed to stay the same (see tie breaker during Robin Hood hashing in Klass::hash_insert).\n-  \/\/assert(compute_secondary_supers_bitmap(secondary_supers()) == _secondary_supers_bitmap, \"broken table\");\n+  if (CDSConfig::is_dumping_classic_static_archive()) {\n+    \/\/ \"Classic\" static archives are required to have deterministic contents.\n+    \/\/ The elements in _secondary_supers are addresses in the ArchiveBuilder\n+    \/\/ output buffer, so they should have deterministic values. If we rehash\n+    \/\/ _secondary_supers, its elements will appear in a deterministic order.\n+    \/\/\n+    \/\/ Note that the bitmap is guaranteed to be deterministic, regardless of the\n+    \/\/ actual addresses of the elements in _secondary_supers. So rehashing shouldn't\n+    \/\/ change it.\n+    uintx bitmap = hash_secondary_supers(secondary_supers(), true);\n+    assert(bitmap == _secondary_supers_bitmap, \"bitmap should not be changed due to rehashing\");\n+  }\n@@ -822,1 +830,1 @@\n-  if (log_is_enabled(Trace, cds, unshareable)) {\n+  if (log_is_enabled(Trace, aot, unshareable)) {\n@@ -824,1 +832,1 @@\n-    log_trace(cds, unshareable)(\"remove java_mirror: %s\", external_name());\n+    log_trace(aot, unshareable)(\"remove java_mirror: %s\", external_name());\n@@ -835,1 +843,1 @@\n-        assert(InstanceKlass::cast(this)->is_shared_unregistered_class(), \"sanity\");\n+        assert(InstanceKlass::cast(this)->defined_by_other_loaders(), \"sanity\");\n@@ -840,1 +848,1 @@\n-        assert(InstanceKlass::cast(k)->is_shared_unregistered_class(), \"sanity\");\n+        assert(InstanceKlass::cast(k)->defined_by_other_loaders(), \"sanity\");\n@@ -860,1 +868,1 @@\n-  if (log_is_enabled(Trace, cds, unshareable)) {\n+  if (log_is_enabled(Trace, aot, unshareable)) {\n@@ -863,1 +871,1 @@\n-    log_trace(cds, unshareable)(\"restore: %s with class loader: %s\", external_name(),\n+    log_trace(aot, unshareable)(\"restore: %s with class loader: %s\", external_name(),\n@@ -896,1 +904,1 @@\n-    log_debug(cds, mirror)(\"%s has raw archived mirror\", external_name());\n+    log_debug(aot, mirror)(\"%s has raw archived mirror\", external_name());\n@@ -907,1 +915,1 @@\n-    log_debug(cds, mirror)(\"No archived mirror data for %s\", external_name());\n+    log_debug(aot, mirror)(\"No archived mirror data for %s\", external_name());\n@@ -916,1 +924,1 @@\n-    log_trace(cds, mirror)(\"Recreate mirror for %s\", external_name());\n+    log_trace(aot, mirror)(\"Recreate mirror for %s\", external_name());\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":25,"deletions":17,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -734,0 +734,1 @@\n+  inline bool is_loader_present_and_alive() const;\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -62,0 +62,5 @@\n+inline bool Klass::is_loader_present_and_alive() const {\n+  ClassLoaderData* cld = class_loader_data();\n+  return (cld != nullptr) ? cld->is_alive() : false;\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/klass.inline.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-ObjArrayKlass* ObjArrayKlass::allocate(ClassLoaderData* loader_data, int n, Klass* k, Symbol* name, TRAPS) {\n+ObjArrayKlass* ObjArrayKlass::allocate_klass(ClassLoaderData* loader_data, int n, Klass* k, Symbol* name, TRAPS) {\n@@ -103,1 +103,1 @@\n-  ObjArrayKlass* oak = ObjArrayKlass::allocate(loader_data, n, element_klass, name, CHECK_NULL);\n+  ObjArrayKlass* oak = ObjArrayKlass::allocate_klass(loader_data, n, element_klass, name, CHECK_NULL);\n@@ -153,1 +153,1 @@\n-objArrayOop ObjArrayKlass::allocate(int length, TRAPS) {\n+objArrayOop ObjArrayKlass::allocate_instance(int length, TRAPS) {\n@@ -164,1 +164,1 @@\n-  objArrayOop array = allocate(length, CHECK_NULL);\n+  objArrayOop array = allocate_instance(length, CHECK_NULL);\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  friend class VMStructs;\n+  friend class Deoptimization;\n@@ -38,0 +38,2 @@\n+  friend class oopFactory;\n+  friend class VMStructs;\n@@ -50,1 +52,3 @@\n-  static ObjArrayKlass* allocate(ClassLoaderData* loader_data, int n, Klass* k, Symbol* name, TRAPS);\n+  static ObjArrayKlass* allocate_klass(ClassLoaderData* loader_data, int n, Klass* k, Symbol* name, TRAPS);\n+\n+  objArrayOop allocate_instance(int length, TRAPS);\n@@ -81,1 +85,0 @@\n-  objArrayOop allocate(int length, TRAPS);\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  TypeArrayKlass* ak = TypeArrayKlass::allocate(null_loader_data, type, sym, CHECK_NULL);\n+  TypeArrayKlass* ak = TypeArrayKlass::allocate_klass(null_loader_data, type, sym, CHECK_NULL);\n@@ -68,1 +68,1 @@\n-TypeArrayKlass* TypeArrayKlass::allocate(ClassLoaderData* loader_data, BasicType type, Symbol* name, TRAPS) {\n+TypeArrayKlass* TypeArrayKlass::allocate_klass(ClassLoaderData* loader_data, BasicType type, Symbol* name, TRAPS) {\n@@ -104,1 +104,1 @@\n-  return allocate(length, THREAD);\n+  return allocate_instance(length, THREAD);\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -36,0 +36,2 @@\n+  friend class Deoptimization;\n+  friend class oopFactory;\n@@ -46,1 +48,4 @@\n-  static TypeArrayKlass* allocate(ClassLoaderData* loader_data, BasicType type, Symbol* name, TRAPS);\n+  static TypeArrayKlass* allocate_klass(ClassLoaderData* loader_data, BasicType type, Symbol* name, TRAPS);\n+\n+  typeArrayOop allocate_common(int length, bool do_zero, TRAPS);\n+  typeArrayOop allocate_instance(int length, TRAPS) { return allocate_common(length, true, THREAD); }\n@@ -69,2 +74,0 @@\n-  typeArrayOop allocate_common(int length, bool do_zero, TRAPS);\n-  typeArrayOop allocate(int length, TRAPS) { return allocate_common(length, true, THREAD); }\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -35,1 +36,2 @@\n-#include \"compiler\/compilerOracle.hpp\"\n+#include \"compiler\/compilerDefinitions.hpp\"\n+#include \"compiler\/compilerOracle.hpp\"\n@@ -578,0 +580,4 @@\n+void Compile::print_phase(const char* phase_name) {\n+  tty->print_cr(\"%u.\\t%s\", ++_phase_counter, phase_name);\n+}\n+\n@@ -633,0 +639,1 @@\n+      _stub_id(-1),\n@@ -732,1 +739,3 @@\n-      StressIncrementalInlining || StressMacroExpansion || StressUnstableIfTraps || StressBailout) {\n+      StressIncrementalInlining || StressMacroExpansion ||\n+      StressMacroElimination || StressUnstableIfTraps ||\n+      StressBailout || StressLoopPeeling) {\n@@ -778,13 +787,3 @@\n-      if (method()->intrinsic_id() == vmIntrinsics::_Reference_get) {\n-        \/\/ With java.lang.ref.reference.get() we must go through the\n-        \/\/ intrinsic - even when get() is the root\n-        \/\/ method of the compile - so that, if necessary, the value in\n-        \/\/ the referent field of the reference object gets recorded by\n-        \/\/ the pre-barrier code.\n-        cg = find_intrinsic(method(), false);\n-      }\n-      if (cg == nullptr) {\n-        float past_uses = method()->interpreter_invocation_count();\n-        float expected_uses = past_uses;\n-        cg = CallGenerator::for_inline(method(), expected_uses);\n-      }\n+      float past_uses = method()->interpreter_invocation_count();\n+      float expected_uses = past_uses;\n+      cg = CallGenerator::for_inline(method(), expected_uses);\n@@ -902,0 +901,1 @@\n+                 int stub_id,\n@@ -913,0 +913,1 @@\n+      _stub_id(stub_id),\n@@ -964,0 +965,10 @@\n+  \/\/ try to reuse an existing stub\n+  {\n+    CodeBlob* blob = AOTCodeCache::load_code_blob(AOTCodeEntry::C2Blob, _stub_id, stub_name);\n+    if (blob != nullptr) {\n+      RuntimeStub* rs = blob->as_runtime_stub();\n+      _stub_entry_point = rs->entry_point();\n+      return;\n+    }\n+  }\n+\n@@ -1057,0 +1068,1 @@\n+  _phase_counter = 0;\n@@ -2413,0 +2425,1 @@\n+        print_method(PHASE_AFTER_MACRO_ELIMINATION, 2);\n@@ -2512,0 +2525,12 @@\n+    \/\/ Do not allow new macro nodes once we start to eliminate and expand\n+    C->reset_allow_macro_nodes();\n+    \/\/ Last attempt to eliminate macro nodes before expand\n+    mex.eliminate_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+    mex.eliminate_opaque_looplimit_macro_nodes();\n+    if (failing()) {\n+      return;\n+    }\n+    print_method(PHASE_AFTER_MACRO_ELIMINATION, 2);\n@@ -4503,1 +4528,3 @@\n-  if (sizetype != nullptr) index_max = sizetype->_hi - 1;\n+  if (sizetype != nullptr && sizetype->_hi > 0) {\n+    index_max = sizetype->_hi - 1;\n+  }\n@@ -4531,1 +4558,1 @@\n-    log()->head(\"late_inline method='%d'  inline_id='\" JLONG_FORMAT \"'\", log()->identify(cg->method()),\n+    log()->head(\"late_inline method='%d' inline_id='\" JLONG_FORMAT \"'\", log()->identify(cg->method()),\n@@ -5137,1 +5164,4 @@\n-  if (should_print_phase(cpt)) {\n+  if (should_print_phase(level)) {\n+    print_phase(name);\n+  }\n+  if (should_print_ideal_phase(cpt)) {\n@@ -5168,6 +5198,7 @@\n-bool Compile::should_print_phase(CompilerPhaseType cpt) {\n-  if (_directive->should_print_phase(cpt)) {\n-    return true;\n-  }\n-#endif\n-  return false;\n+bool Compile::should_print_phase(const int level) const {\n+  return PrintPhaseLevel > 0 && directive()->PhasePrintLevelOption >= level &&\n+         _method != nullptr; \/\/ Do not print phases for stubs.\n+}\n+\n+bool Compile::should_print_ideal_phase(CompilerPhaseType cpt) const {\n+  return _directive->should_print_ideal_phase(cpt);\n@@ -5177,1 +5208,0 @@\n-#ifndef PRODUCT\n@@ -5184,1 +5214,0 @@\n-#endif\n@@ -5187,1 +5216,2 @@\n-#ifndef PRODUCT\n+  PRODUCT_RETURN_(return false;);\n+\n@@ -5197,3 +5227,0 @@\n-#else\n-  return false;\n-#endif\n@@ -5202,1 +5229,0 @@\n-#ifndef PRODUCT\n@@ -5291,1 +5317,1 @@\n-#endif\n+#endif \/\/ !PRODUCT\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":58,"deletions":32,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-#include \"opto\/c2compiler.hpp\"\n+#include \"opto\/c2compiler.hpp\"\n@@ -35,0 +35,1 @@\n+#include \"opto\/castnode.hpp\"\n@@ -38,2 +39,1 @@\n-#include \"opto\/macro.hpp\"\n-#include \"opto\/phaseX.hpp\"\n+#include \"opto\/macro.hpp\"\n@@ -43,1 +43,1 @@\n-#include \"opto\/castnode.hpp\"\n+#include \"opto\/phaseX.hpp\"\n@@ -2263,8 +2263,4 @@\n-            if (arg_ptn != src_ptn) {\n-              \/\/ Special arraycopy edge:\n-              \/\/ A destination object's field can't have the source object\n-              \/\/ as base since objects escape states are not related.\n-              \/\/ Only escape state of destination object's fields affects\n-              \/\/ escape state of fields in source object.\n-              add_arraycopy(call, es, src_ptn, arg_ptn);\n-            }\n+            \/\/ Special arraycopy edge:\n+            \/\/ Only escape state of destination object's fields affects\n+            \/\/ escape state of fields in source object.\n+            add_arraycopy(call, es, src_ptn, arg_ptn);\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":8,"deletions":12,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+#include \"asm\/register.hpp\"\n+#include \"ci\/ciObjArray.hpp\"\n@@ -27,2 +29,0 @@\n-#include \"ci\/ciObjArray.hpp\"\n-#include \"asm\/register.hpp\"\n@@ -50,1 +50,1 @@\n-#include \"utilities\/powerOfTwo.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n@@ -3806,0 +3806,2 @@\n+    assert(fast_size_limit == 0 || count_leading_zeros(fast_size_limit) > static_cast<unsigned>(LogBytesPerLong - log2_esize),\n+           \"fast_size_limit (%d) overflow when shifted left by %d\", fast_size_limit, LogBytesPerLong - log2_esize);\n@@ -3856,1 +3858,3 @@\n-      if (size_max > tilen->_hi)  size_max = tilen->_hi;\n+      if (size_max > tilen->_hi && tilen->_hi >= 0) {\n+        size_max = tilen->_hi;\n+      }\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"ci\/ciUtilities.inline.hpp\"\n+#include \"ci\/ciUtilities.inline.hpp\"\n@@ -50,1 +50,1 @@\n-#include \"opto\/runtime.hpp\"\n+#include \"opto\/runtime.hpp\"\n@@ -248,0 +248,1 @@\n+  case vmIntrinsics::_dcbrt:\n@@ -566,1 +567,1 @@\n-  case vmIntrinsics::_Reference_get:            return inline_reference_get();\n+  case vmIntrinsics::_Reference_get0:           return inline_reference_get0();\n@@ -1577,3 +1578,8 @@\n-    \/\/ Check if src array address is aligned to HeapWordSize (dst is always aligned)\n-    const TypeInt* toffset = gvn().type(offset)->is_int();\n-    bool aligned = toffset->is_con() && ((toffset->get_con() * type2aelembytes(T_CHAR)) % HeapWordSize == 0);\n+    \/\/ Check if dst array address is aligned to HeapWordSize\n+    bool aligned = (arrayOopDesc::base_offset_in_bytes(T_BYTE) % HeapWordSize == 0);\n+    \/\/ If true, then check if src array address is aligned to HeapWordSize\n+    if (aligned) {\n+      const TypeInt* toffset = gvn().type(offset)->is_int();\n+      aligned = toffset->is_con() && ((arrayOopDesc::base_offset_in_bytes(T_CHAR) +\n+                                       toffset->get_con() * type2aelembytes(T_CHAR)) % HeapWordSize == 0);\n+    }\n@@ -1660,2 +1666,2 @@\n-    bool aligned = tsrc->is_con() && ((tsrc->get_con() * type2aelembytes(T_BYTE)) % HeapWordSize == 0) &&\n-                   tdst->is_con() && ((tdst->get_con() * type2aelembytes(T_CHAR)) % HeapWordSize == 0);\n+    bool aligned = tsrc->is_con() && ((arrayOopDesc::base_offset_in_bytes(T_BYTE) + tsrc->get_con() * type2aelembytes(T_BYTE)) % HeapWordSize == 0) &&\n+                   tdst->is_con() && ((arrayOopDesc::base_offset_in_bytes(T_CHAR) + tdst->get_con() * type2aelembytes(T_CHAR)) % HeapWordSize == 0);\n@@ -1889,0 +1895,3 @@\n+  case vmIntrinsics::_dcbrt:\n+    return StubRoutines::dcbrt() != nullptr ?\n+      runtime_math(OptoRuntime::Math_D_D_Type(), StubRoutines::dcbrt(), \"dcbrt\") : false;\n@@ -4817,51 +4826,51 @@\n-    \/\/ Our constants.\n-    Node* M = _gvn.intcon(0x337954D5);\n-    Node* A = _gvn.intcon(0xAAAAAAAA);\n-    \/\/ Split object address into lo and hi 32 bits.\n-    Node* obj_addr = _gvn.transform(new CastP2XNode(nullptr, obj));\n-    Node* x = _gvn.transform(new ConvL2INode(obj_addr));\n-    Node* upper_addr = _gvn.transform(new URShiftLNode(obj_addr, _gvn.intcon(32)));\n-    Node* y = _gvn.transform(new ConvL2INode(upper_addr));\n-\n-    Node* H0 = _gvn.transform(new XorINode(x, y));\n-    Node* L0 = _gvn.transform(new XorINode(x, A));\n-\n-    \/\/ Full multiplication of two 32 bit values L0 and M into a hi\/lo result in two 32 bit values V0 and U0.\n-    Node* L0_64 = _gvn.transform(new ConvI2LNode(L0));\n-    L0_64 = _gvn.transform(new AndLNode(L0_64, _gvn.longcon(0xFFFFFFFF)));\n-    Node* M_64 = _gvn.transform(new ConvI2LNode(M));\n-    \/\/ M_64 = _gvn.transform(new AndLNode(M_64, _gvn.longcon(0xFFFFFFFF)));\n-    Node* prod64 = _gvn.transform(new MulLNode(L0_64, M_64));\n-    Node* V0 = _gvn.transform(new ConvL2INode(prod64));\n-    Node* prod_upper = _gvn.transform(new URShiftLNode(prod64, _gvn.intcon(32)));\n-    Node* U0 = _gvn.transform(new ConvL2INode(prod_upper));\n-\n-    Node* Q0 = _gvn.transform(new MulINode(H0, M));\n-    Node* L1 = _gvn.transform(new XorINode(Q0, U0));\n-\n-    \/\/ Full multiplication of two 32 bit values L1 and M into a hi\/lo result in two 32 bit values V1 and U1.\n-    Node* L1_64 = _gvn.transform(new ConvI2LNode(L1));\n-    L1_64 = _gvn.transform(new AndLNode(L1_64, _gvn.longcon(0xFFFFFFFF)));\n-    prod64 = _gvn.transform(new MulLNode(L1_64, M_64));\n-    Node* V1 = _gvn.transform(new ConvL2INode(prod64));\n-    prod_upper = _gvn.transform(new URShiftLNode(prod64, _gvn.intcon(32)));\n-    Node* U1 = _gvn.transform(new ConvL2INode(prod_upper));\n-\n-    Node* P1 = _gvn.transform(new XorINode(V0, M));\n-\n-    \/\/ Right rotate P1 by distance L1.\n-    Node* distance = _gvn.transform(new AndINode(L1, _gvn.intcon(32 - 1)));\n-    Node* inverse_distance = _gvn.transform(new SubINode(_gvn.intcon(32), distance));\n-    Node* ror_part1 = _gvn.transform(new URShiftINode(P1, distance));\n-    Node* ror_part2 = _gvn.transform(new LShiftINode(P1, inverse_distance));\n-    Node* Q1 = _gvn.transform(new OrINode(ror_part1, ror_part2));\n-\n-    Node* L2 = _gvn.transform(new XorINode(Q1, U1));\n-    Node* hash = _gvn.transform(new XorINode(V1, L2));\n-    Node* hash_truncated = _gvn.transform(new AndINode(hash, _gvn.intcon(markWord::hash_mask)));\n-\n-    \/\/ TODO: We could generate a fast case here under the following conditions:\n-    \/\/ - The hashctrl is set to hash_is_copied (see markWord::hash_is_copied())\n-    \/\/ - The type of the object is known\n-    \/\/ Then we can load the identity hashcode from the int field at Klass::hash_offset_in_bytes() of the object.\n-    result_val->init_req(_fast_path, hash_truncated);\n+    if (hashCode == 6) {\n+      \/\/ Our constants.\n+      Node* M = _gvn.intcon(0x337954D5);\n+      Node* A = _gvn.intcon(0xAAAAAAAA);\n+      \/\/ Split object address into lo and hi 32 bits.\n+      Node* obj_addr = _gvn.transform(new CastP2XNode(nullptr, obj));\n+      Node* x = _gvn.transform(new ConvL2INode(obj_addr));\n+      Node* upper_addr = _gvn.transform(new URShiftLNode(obj_addr, _gvn.intcon(32)));\n+      Node* y = _gvn.transform(new ConvL2INode(upper_addr));\n+\n+      Node* H0 = _gvn.transform(new XorINode(x, y));\n+      Node* L0 = _gvn.transform(new XorINode(x, A));\n+\n+      \/\/ Full multiplication of two 32 bit values L0 and M into a hi\/lo result in two 32 bit values V0 and U0.\n+      Node* L0_64 = _gvn.transform(new ConvI2LNode(L0));\n+      L0_64 = _gvn.transform(new AndLNode(L0_64, _gvn.longcon(0xFFFFFFFF)));\n+      Node* M_64 = _gvn.transform(new ConvI2LNode(M));\n+      \/\/ M_64 = _gvn.transform(new AndLNode(M_64, _gvn.longcon(0xFFFFFFFF)));\n+      Node* prod64 = _gvn.transform(new MulLNode(L0_64, M_64));\n+      Node* V0 = _gvn.transform(new ConvL2INode(prod64));\n+      Node* prod_upper = _gvn.transform(new URShiftLNode(prod64, _gvn.intcon(32)));\n+      Node* U0 = _gvn.transform(new ConvL2INode(prod_upper));\n+\n+      Node* Q0 = _gvn.transform(new MulINode(H0, M));\n+      Node* L1 = _gvn.transform(new XorINode(Q0, U0));\n+\n+      \/\/ Full multiplication of two 32 bit values L1 and M into a hi\/lo result in two 32 bit values V1 and U1.\n+      Node* L1_64 = _gvn.transform(new ConvI2LNode(L1));\n+      L1_64 = _gvn.transform(new AndLNode(L1_64, _gvn.longcon(0xFFFFFFFF)));\n+      prod64 = _gvn.transform(new MulLNode(L1_64, M_64));\n+      Node* V1 = _gvn.transform(new ConvL2INode(prod64));\n+      prod_upper = _gvn.transform(new URShiftLNode(prod64, _gvn.intcon(32)));\n+      Node* U1 = _gvn.transform(new ConvL2INode(prod_upper));\n+\n+      Node* P1 = _gvn.transform(new XorINode(V0, M));\n+\n+      \/\/ Right rotate P1 by distance L1.\n+      Node* distance = _gvn.transform(new AndINode(L1, _gvn.intcon(32 - 1)));\n+      Node* inverse_distance = _gvn.transform(new SubINode(_gvn.intcon(32), distance));\n+      Node* ror_part1 = _gvn.transform(new URShiftINode(P1, distance));\n+      Node* ror_part2 = _gvn.transform(new LShiftINode(P1, inverse_distance));\n+      Node* Q1 = _gvn.transform(new OrINode(ror_part1, ror_part2));\n+\n+      Node* L2 = _gvn.transform(new XorINode(Q1, U1));\n+      Node* hash = _gvn.transform(new XorINode(V1, L2));\n+      Node* hash_truncated = _gvn.transform(new AndINode(hash, _gvn.intcon(markWord::hash_mask)));\n+\n+      result_val->init_req(_fast_path, hash_truncated);\n+    } else if (hashCode == 2) {\n+      result_val->init_req(_fast_path, _gvn.intcon(1));\n+    }\n@@ -6725,0 +6734,4 @@\n+  record_for_igvn(exit_block);\n+  record_for_igvn(memory_phi);\n+  record_for_igvn(result_phi);\n+\n@@ -7059,1 +7072,1 @@\n-\/\/----------------------------inline_reference_get----------------------------\n+\/\/----------------------------inline_reference_get0----------------------------\n@@ -7061,1 +7074,1 @@\n-bool LibraryCallKit::inline_reference_get() {\n+bool LibraryCallKit::inline_reference_get0() {\n@@ -7890,0 +7903,1 @@\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":75,"deletions":61,"binary":false,"changes":136,"status":"modified"},{"patch":"@@ -2368,0 +2368,4 @@\n+\n+  if (StressMacroElimination) {\n+    C->shuffle_macro_nodes();\n+  }\n@@ -2407,0 +2411,3 @@\n+      if (success) {\n+        C->print_method(PHASE_AFTER_MACRO_ELIMINATION_STEP, 5, n);\n+      }\n@@ -2410,1 +2417,0 @@\n-  _has_locks = false;\n@@ -2434,1 +2440,0 @@\n-        _has_locks = true;\n@@ -2457,0 +2462,3 @@\n+      if (success) {\n+        C->print_method(PHASE_AFTER_MACRO_ELIMINATION_STEP, 5, n);\n+      }\n@@ -2467,8 +2475,3 @@\n-\/\/------------------------------expand_macro_nodes----------------------\n-\/\/  Returns true if a failure occurred.\n-bool PhaseMacroExpand::expand_macro_nodes() {\n-  refine_strip_mined_loop_macro_nodes();\n-  \/\/ Do not allow new macro nodes once we started to expand\n-  C->reset_allow_macro_nodes();\n-  if (StressMacroExpansion) {\n-    C->shuffle_macro_nodes();\n+void PhaseMacroExpand::eliminate_opaque_looplimit_macro_nodes() {\n+  if (C->macro_count() == 0) {\n+    return;\n@@ -2476,4 +2479,1 @@\n-  \/\/ Last attempt to eliminate macro nodes.\n-  eliminate_macro_nodes();\n-  if (C->failing())  return true;\n-\n+  refine_strip_mined_loop_macro_nodes();\n@@ -2541,1 +2541,1 @@\n-        C->print_method(PHASE_AFTER_MACRO_EXPANSION_STEP, 5, n);\n+        C->print_method(PHASE_AFTER_MACRO_ELIMINATION_STEP, 5, n);\n@@ -2545,0 +2545,8 @@\n+}\n+\n+\/\/------------------------------expand_macro_nodes----------------------\n+\/\/  Returns true if a failure occurred.\n+bool PhaseMacroExpand::expand_macro_nodes() {\n+  if (StressMacroExpansion) {\n+    C->shuffle_macro_nodes();\n+  }\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":23,"deletions":15,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-#include \"opto\/regalloc.hpp\"\n@@ -49,0 +48,1 @@\n+#include \"opto\/regalloc.hpp\"\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-#include \"oops\/objArrayKlass.hpp\"\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -75,1 +75,1 @@\n-#include \"runtime\/vframeArray.hpp\"\n+#include \"runtime\/vframeArray.hpp\"\n@@ -143,0 +143,1 @@\n+#define C2_STUB_ID(name) OptoStubId::name ## _id\n@@ -155,1 +156,1 @@\n-    generate_stub(env,                                                  \\\n+    generate_stub(env,                                                \\\n@@ -159,3 +160,4 @@\n-                  fancy_jump,                                           \\\n-                  pass_tls,                                             \\\n-                  pass_retpc);                                          \\\n+                  (int)C2_STUB_ID(name),                              \\\n+                  fancy_jump,                                         \\\n+                  pass_tls,                                           \\\n+                  pass_retpc);                                        \\\n@@ -167,3 +169,3 @@\n-  STUB_FIELD_NAME(name) =                                               \\\n-    generate_stub(env,                                                  \\\n-                  notify_jvmti_vthread_Type,                            \\\n+  STUB_FIELD_NAME(name) =                                             \\\n+    generate_stub(env,                                                \\\n+                  notify_jvmti_vthread_Type,                          \\\n@@ -172,4 +174,5 @@\n-                  0,                                                    \\\n-                  true,                                                 \\\n-                  false);                                               \\\n-  if (STUB_FIELD_NAME(name) == nullptr) { return false; }               \\\n+                  (int)C2_STUB_ID(name),                              \\\n+                  0,                                                  \\\n+                  true,                                               \\\n+                  false);                                             \\\n+  if (STUB_FIELD_NAME(name) == nullptr) { return false; }             \\\n@@ -279,2 +282,2 @@\n-                                   const char *name, int is_fancy_jump,\n-                                   bool pass_tls,\n+                                   const char *name, int stub_id,\n+                                   int is_fancy_jump, bool pass_tls,\n@@ -287,1 +290,1 @@\n-  Compile C(env, gen, C_function, name, is_fancy_jump, pass_tls, return_pc, directive);\n+  Compile C(env, gen, C_function, name, stub_id, is_fancy_jump, pass_tls, return_pc, directive);\n@@ -1474,0 +1477,1 @@\n+\n@@ -1546,0 +1550,1 @@\n+\n@@ -2037,1 +2042,1 @@\n-  if (!StressCompiledExceptionHandlers && doit) {\n+  if (DeoptimizeOnAllocationException && doit) {\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":22,"deletions":17,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -563,2 +563,4 @@\n-  \/\/ no folding if one of operands is infinity or NaN, do not do constant folding\n-  if(g_isfinite(t1->getf()) && g_isfinite(t2->getf())) {\n+  \/\/ Half precision floating point subtraction follows the rules of IEEE 754\n+  \/\/ applicable to other floating point types.\n+  if (t1->isa_half_float_constant() != nullptr &&\n+      t2->isa_half_float_constant() != nullptr)  {\n@@ -566,8 +568,1 @@\n-  }\n-  else if(g_isnan(t1->getf())) {\n-    return t1;\n-  }\n-  else if(g_isnan(t2->getf())) {\n-    return t2;\n-  }\n-  else {\n+  } else {\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-#include \"opto\/callnode.hpp\"\n+#include \"opto\/callnode.hpp\"\n@@ -43,0 +43,1 @@\n+#include \"opto\/rangeinference.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"runtime\/stubRoutines.hpp\"\n@@ -48,1 +50,0 @@\n-#include \"runtime\/stubRoutines.hpp\"\n@@ -431,1 +432,0 @@\n-#define SMALLINT ((juint)3)  \/\/ a value too insignificant to consider widening\n@@ -490,19 +490,21 @@\n-  TypeInt::MINUS_1 = TypeInt::make(-1);  \/\/ -1\n-  TypeInt::ZERO    = TypeInt::make( 0);  \/\/  0\n-  TypeInt::ONE     = TypeInt::make( 1);  \/\/  1\n-  TypeInt::BOOL    = TypeInt::make(0,1,   WidenMin);  \/\/ 0 or 1, FALSE or TRUE.\n-  TypeInt::CC      = TypeInt::make(-1, 1, WidenMin);  \/\/ -1, 0 or 1, condition codes\n-  TypeInt::CC_LT   = TypeInt::make(-1,-1, WidenMin);  \/\/ == TypeInt::MINUS_1\n-  TypeInt::CC_GT   = TypeInt::make( 1, 1, WidenMin);  \/\/ == TypeInt::ONE\n-  TypeInt::CC_EQ   = TypeInt::make( 0, 0, WidenMin);  \/\/ == TypeInt::ZERO\n-  TypeInt::CC_LE   = TypeInt::make(-1, 0, WidenMin);\n-  TypeInt::CC_GE   = TypeInt::make( 0, 1, WidenMin);  \/\/ == TypeInt::BOOL\n-  TypeInt::BYTE    = TypeInt::make(-128,127,     WidenMin); \/\/ Bytes\n-  TypeInt::UBYTE   = TypeInt::make(0, 255,       WidenMin); \/\/ Unsigned Bytes\n-  TypeInt::CHAR    = TypeInt::make(0,65535,      WidenMin); \/\/ Java chars\n-  TypeInt::SHORT   = TypeInt::make(-32768,32767, WidenMin); \/\/ Java shorts\n-  TypeInt::POS     = TypeInt::make(0,max_jint,   WidenMin); \/\/ Non-neg values\n-  TypeInt::POS1    = TypeInt::make(1,max_jint,   WidenMin); \/\/ Positive values\n-  TypeInt::INT     = TypeInt::make(min_jint,max_jint, WidenMax); \/\/ 32-bit integers\n-  TypeInt::SYMINT  = TypeInt::make(-max_jint,max_jint,WidenMin); \/\/ symmetric range\n-  TypeInt::TYPE_DOMAIN  = TypeInt::INT;\n+  TypeInt::MINUS_1  = TypeInt::make(-1);  \/\/ -1\n+  TypeInt::ZERO     = TypeInt::make( 0);  \/\/  0\n+  TypeInt::ONE      = TypeInt::make( 1);  \/\/  1\n+  TypeInt::BOOL     = TypeInt::make( 0, 1, WidenMin);  \/\/ 0 or 1, FALSE or TRUE.\n+  TypeInt::CC       = TypeInt::make(-1, 1, WidenMin);  \/\/ -1, 0 or 1, condition codes\n+  TypeInt::CC_LT    = TypeInt::make(-1,-1, WidenMin);  \/\/ == TypeInt::MINUS_1\n+  TypeInt::CC_GT    = TypeInt::make( 1, 1, WidenMin);  \/\/ == TypeInt::ONE\n+  TypeInt::CC_EQ    = TypeInt::make( 0, 0, WidenMin);  \/\/ == TypeInt::ZERO\n+  TypeInt::CC_NE    = TypeInt::make_or_top(TypeIntPrototype<jint, juint>{{-1, 1}, {1, max_juint}, {0, 1}}, WidenMin)->is_int();\n+  TypeInt::CC_LE    = TypeInt::make(-1, 0, WidenMin);\n+  TypeInt::CC_GE    = TypeInt::make( 0, 1, WidenMin);  \/\/ == TypeInt::BOOL\n+  TypeInt::BYTE     = TypeInt::make(-128, 127,     WidenMin); \/\/ Bytes\n+  TypeInt::UBYTE    = TypeInt::make(0, 255,        WidenMin); \/\/ Unsigned Bytes\n+  TypeInt::CHAR     = TypeInt::make(0, 65535,      WidenMin); \/\/ Java chars\n+  TypeInt::SHORT    = TypeInt::make(-32768, 32767, WidenMin); \/\/ Java shorts\n+  TypeInt::NON_ZERO = TypeInt::make_or_top(TypeIntPrototype<jint, juint>{{min_jint, max_jint}, {1, max_juint}, {0, 0}}, WidenMin)->is_int();\n+  TypeInt::POS      = TypeInt::make(0, max_jint,   WidenMin); \/\/ Non-neg values\n+  TypeInt::POS1     = TypeInt::make(1, max_jint,   WidenMin); \/\/ Positive values\n+  TypeInt::INT      = TypeInt::make(min_jint, max_jint, WidenMax); \/\/ 32-bit integers\n+  TypeInt::SYMINT   = TypeInt::make(-max_jint, max_jint, WidenMin); \/\/ symmetric range\n+  TypeInt::TYPE_DOMAIN = TypeInt::INT;\n@@ -510,1 +512,1 @@\n-  \/\/ a trinary (-1,0,+1) integer result AND as an efficient long\n+  \/\/ a trinary (-1, 0, +1) integer result AND as an efficient long\n@@ -512,16 +514,17 @@\n-  assert( TypeInt::CC_LT == TypeInt::MINUS_1, \"types must match for CmpL to work\" );\n-  assert( TypeInt::CC_GT == TypeInt::ONE,     \"types must match for CmpL to work\" );\n-  assert( TypeInt::CC_EQ == TypeInt::ZERO,    \"types must match for CmpL to work\" );\n-  assert( TypeInt::CC_GE == TypeInt::BOOL,    \"types must match for CmpL to work\" );\n-  assert( (juint)(TypeInt::CC->_hi - TypeInt::CC->_lo) <= SMALLINT, \"CC is truly small\");\n-\n-  TypeLong::MAX = TypeLong::make(max_jlong);  \/\/ Long MAX\n-  TypeLong::MIN = TypeLong::make(min_jlong);  \/\/ Long MIN\n-  TypeLong::MINUS_1 = TypeLong::make(-1);        \/\/ -1\n-  TypeLong::ZERO    = TypeLong::make( 0);        \/\/  0\n-  TypeLong::ONE     = TypeLong::make( 1);        \/\/  1\n-  TypeLong::POS     = TypeLong::make(0,max_jlong, WidenMin); \/\/ Non-neg values\n-  TypeLong::LONG    = TypeLong::make(min_jlong,max_jlong,WidenMax); \/\/ 64-bit integers\n-  TypeLong::INT     = TypeLong::make((jlong)min_jint,(jlong)max_jint,WidenMin);\n-  TypeLong::UINT    = TypeLong::make(0,(jlong)max_juint,WidenMin);\n-  TypeLong::TYPE_DOMAIN  = TypeLong::LONG;\n+  assert(TypeInt::CC_LT == TypeInt::MINUS_1, \"types must match for CmpL to work\" );\n+  assert(TypeInt::CC_GT == TypeInt::ONE,     \"types must match for CmpL to work\" );\n+  assert(TypeInt::CC_EQ == TypeInt::ZERO,    \"types must match for CmpL to work\" );\n+  assert(TypeInt::CC_GE == TypeInt::BOOL,    \"types must match for CmpL to work\" );\n+\n+  TypeLong::MAX = TypeLong::make(max_jlong); \/\/ Long MAX\n+  TypeLong::MIN = TypeLong::make(min_jlong); \/\/ Long MIN\n+  TypeLong::MINUS_1  = TypeLong::make(-1);   \/\/ -1\n+  TypeLong::ZERO     = TypeLong::make( 0);   \/\/  0\n+  TypeLong::ONE      = TypeLong::make( 1);   \/\/  1\n+  TypeLong::NON_ZERO = TypeLong::make_or_top(TypeIntPrototype<jlong, julong>{{min_jlong, max_jlong}, {1, max_julong}, {0, 0}}, WidenMin)->is_long();\n+  TypeLong::POS      = TypeLong::make(0, max_jlong, WidenMin); \/\/ Non-neg values\n+  TypeLong::NEG      = TypeLong::make(min_jlong, -1, WidenMin);\n+  TypeLong::LONG     = TypeLong::make(min_jlong, max_jlong, WidenMax); \/\/ 64-bit integers\n+  TypeLong::INT      = TypeLong::make((jlong)min_jint, (jlong)max_jint,WidenMin);\n+  TypeLong::UINT     = TypeLong::make(0, (jlong)max_juint, WidenMin);\n+  TypeLong::TYPE_DOMAIN = TypeLong::LONG;\n@@ -1748,25 +1751,23 @@\n-const TypeInt *TypeInt::MAX;    \/\/ INT_MAX\n-const TypeInt *TypeInt::MIN;    \/\/ INT_MIN\n-const TypeInt *TypeInt::MINUS_1;\/\/ -1\n-const TypeInt *TypeInt::ZERO;   \/\/ 0\n-const TypeInt *TypeInt::ONE;    \/\/ 1\n-const TypeInt *TypeInt::BOOL;   \/\/ 0 or 1, FALSE or TRUE.\n-const TypeInt *TypeInt::CC;     \/\/ -1,0 or 1, condition codes\n-const TypeInt *TypeInt::CC_LT;  \/\/ [-1]  == MINUS_1\n-const TypeInt *TypeInt::CC_GT;  \/\/ [1]   == ONE\n-const TypeInt *TypeInt::CC_EQ;  \/\/ [0]   == ZERO\n-const TypeInt *TypeInt::CC_LE;  \/\/ [-1,0]\n-const TypeInt *TypeInt::CC_GE;  \/\/ [0,1] == BOOL (!)\n-const TypeInt *TypeInt::BYTE;   \/\/ Bytes, -128 to 127\n-const TypeInt *TypeInt::UBYTE;  \/\/ Unsigned Bytes, 0 to 255\n-const TypeInt *TypeInt::CHAR;   \/\/ Java chars, 0-65535\n-const TypeInt *TypeInt::SHORT;  \/\/ Java shorts, -32768-32767\n-const TypeInt *TypeInt::POS;    \/\/ Positive 32-bit integers or zero\n-const TypeInt *TypeInt::POS1;   \/\/ Positive 32-bit integers\n-const TypeInt *TypeInt::INT;    \/\/ 32-bit integers\n-const TypeInt *TypeInt::SYMINT; \/\/ symmetric range [-max_jint..max_jint]\n-const TypeInt *TypeInt::TYPE_DOMAIN; \/\/ alias for TypeInt::INT\n-\n-\/\/------------------------------TypeInt----------------------------------------\n-TypeInt::TypeInt( jint lo, jint hi, int w ) : TypeInteger(Int, w), _lo(lo), _hi(hi) {\n-}\n+const TypeInt* TypeInt::MAX;    \/\/ INT_MAX\n+const TypeInt* TypeInt::MIN;    \/\/ INT_MIN\n+const TypeInt* TypeInt::MINUS_1;\/\/ -1\n+const TypeInt* TypeInt::ZERO;   \/\/ 0\n+const TypeInt* TypeInt::ONE;    \/\/ 1\n+const TypeInt* TypeInt::BOOL;   \/\/ 0 or 1, FALSE or TRUE.\n+const TypeInt* TypeInt::CC;     \/\/ -1,0 or 1, condition codes\n+const TypeInt* TypeInt::CC_LT;  \/\/ [-1]  == MINUS_1\n+const TypeInt* TypeInt::CC_GT;  \/\/ [1]   == ONE\n+const TypeInt* TypeInt::CC_EQ;  \/\/ [0]   == ZERO\n+const TypeInt* TypeInt::CC_NE;\n+const TypeInt* TypeInt::CC_LE;  \/\/ [-1,0]\n+const TypeInt* TypeInt::CC_GE;  \/\/ [0,1] == BOOL (!)\n+const TypeInt* TypeInt::BYTE;   \/\/ Bytes, -128 to 127\n+const TypeInt* TypeInt::UBYTE;  \/\/ Unsigned Bytes, 0 to 255\n+const TypeInt* TypeInt::CHAR;   \/\/ Java chars, 0-65535\n+const TypeInt* TypeInt::SHORT;  \/\/ Java shorts, -32768-32767\n+const TypeInt* TypeInt::NON_ZERO;\n+const TypeInt* TypeInt::POS;    \/\/ Positive 32-bit integers or zero\n+const TypeInt* TypeInt::POS1;   \/\/ Positive 32-bit integers\n+const TypeInt* TypeInt::INT;    \/\/ 32-bit integers\n+const TypeInt* TypeInt::SYMINT; \/\/ symmetric range [-max_jint..max_jint]\n+const TypeInt* TypeInt::TYPE_DOMAIN; \/\/ alias for TypeInt::INT\n@@ -1774,3 +1775,4 @@\n-\/\/------------------------------make-------------------------------------------\n-const TypeInt *TypeInt::make( jint lo ) {\n-  return (TypeInt*)(new TypeInt(lo,lo,WidenMin))->hashcons();\n+TypeInt::TypeInt(const TypeIntPrototype<jint, juint>& t, int widen, bool dual)\n+  : TypeInteger(Int, t.normalize_widen(widen), dual), _lo(t._srange._lo), _hi(t._srange._hi),\n+    _ulo(t._urange._lo), _uhi(t._urange._hi), _bits(t._bits) {\n+  DEBUG_ONLY(t.verify_constraints());\n@@ -1779,9 +1781,4 @@\n-static int normalize_int_widen( jint lo, jint hi, int w ) {\n-  \/\/ Certain normalizations keep us sane when comparing types.\n-  \/\/ The 'SMALLINT' covers constants and also CC and its relatives.\n-  if (lo <= hi) {\n-    if (((juint)hi - lo) <= SMALLINT)  w = Type::WidenMin;\n-    if (((juint)hi - lo) >= max_juint) w = Type::WidenMax; \/\/ TypeInt::INT\n-  } else {\n-    if (((juint)lo - hi) <= SMALLINT)  w = Type::WidenMin;\n-    if (((juint)lo - hi) >= max_juint) w = Type::WidenMin; \/\/ dual TypeInt::INT\n+const Type* TypeInt::make_or_top(const TypeIntPrototype<jint, juint>& t, int widen, bool dual) {\n+  auto canonicalized_t = t.canonicalize_constraints();\n+  if (canonicalized_t.empty()) {\n+    return dual ? Type::BOTTOM : Type::TOP;\n@@ -1789,1 +1786,1 @@\n-  return w;\n+  return (new TypeInt(canonicalized_t._data, widen, dual))->hashcons()->is_int();\n@@ -1792,3 +1789,4 @@\n-const TypeInt *TypeInt::make( jint lo, jint hi, int w ) {\n-  w = normalize_int_widen(lo, hi, w);\n-  return (TypeInt*)(new TypeInt(lo,hi,w))->hashcons();\n+const TypeInt* TypeInt::make(jint con) {\n+  juint ucon = con;\n+  return (new TypeInt(TypeIntPrototype<jint, juint>{{con, con}, {ucon, ucon}, {~ucon, ucon}},\n+                      WidenMin, false))->hashcons()->is_int();\n@@ -1797,44 +1795,3 @@\n-\/\/------------------------------meet-------------------------------------------\n-\/\/ Compute the MEET of two types.  It returns a new Type representation object\n-\/\/ with reference count equal to the number of Types pointing at it.\n-\/\/ Caller should wrap a Types around it.\n-const Type *TypeInt::xmeet( const Type *t ) const {\n-  \/\/ Perform a fast test for common case; meeting the same types together.\n-  if( this == t ) return this;  \/\/ Meeting same type?\n-\n-  \/\/ Currently \"this->_base\" is a TypeInt\n-  switch (t->base()) {          \/\/ Switch on original type\n-  case AnyPtr:                  \/\/ Mixing with oops happens when javac\n-  case RawPtr:                  \/\/ reuses local variables\n-  case OopPtr:\n-  case InstPtr:\n-  case AryPtr:\n-  case MetadataPtr:\n-  case KlassPtr:\n-  case InstKlassPtr:\n-  case AryKlassPtr:\n-  case NarrowOop:\n-  case NarrowKlass:\n-  case Long:\n-  case HalfFloatTop:\n-  case HalfFloatCon:\n-  case HalfFloatBot:\n-  case FloatTop:\n-  case FloatCon:\n-  case FloatBot:\n-  case DoubleTop:\n-  case DoubleCon:\n-  case DoubleBot:\n-  case Bottom:                  \/\/ Ye Olde Default\n-    return Type::BOTTOM;\n-  default:                      \/\/ All else is a mistake\n-    typerr(t);\n-  case Top:                     \/\/ No change\n-    return this;\n-  case Int:                     \/\/ Int vs Int?\n-    break;\n-  }\n-\n-  \/\/ Expand covered set\n-  const TypeInt *r = t->is_int();\n-  return make( MIN2(_lo,r->_lo), MAX2(_hi,r->_hi), MAX2(_widen,r->_widen) );\n+const TypeInt* TypeInt::make(jint lo, jint hi, int widen) {\n+  assert(lo <= hi, \"must be legal bounds\");\n+  return make_or_top(TypeIntPrototype<jint, juint>{{lo, hi}, {0, max_juint}, {0, 0}}, widen)->is_int();\n@@ -1843,55 +1800,3 @@\n-\/\/------------------------------xdual------------------------------------------\n-\/\/ Dual: reverse hi & lo; flip widen\n-const Type *TypeInt::xdual() const {\n-  int w = normalize_int_widen(_hi,_lo, WidenMax-_widen);\n-  return new TypeInt(_hi,_lo,w);\n-}\n-\n-\/\/------------------------------widen------------------------------------------\n-\/\/ Only happens for optimistic top-down optimizations.\n-const Type *TypeInt::widen( const Type *old, const Type* limit ) const {\n-  \/\/ Coming from TOP or such; no widening\n-  if( old->base() != Int ) return this;\n-  const TypeInt *ot = old->is_int();\n-\n-  \/\/ If new guy is equal to old guy, no widening\n-  if( _lo == ot->_lo && _hi == ot->_hi )\n-    return old;\n-\n-  \/\/ If new guy contains old, then we widened\n-  if( _lo <= ot->_lo && _hi >= ot->_hi ) {\n-    \/\/ New contains old\n-    \/\/ If new guy is already wider than old, no widening\n-    if( _widen > ot->_widen ) return this;\n-    \/\/ If old guy was a constant, do not bother\n-    if (ot->_lo == ot->_hi)  return this;\n-    \/\/ Now widen new guy.\n-    \/\/ Check for widening too far\n-    if (_widen == WidenMax) {\n-      int max = max_jint;\n-      int min = min_jint;\n-      if (limit->isa_int()) {\n-        max = limit->is_int()->_hi;\n-        min = limit->is_int()->_lo;\n-      }\n-      if (min < _lo && _hi < max) {\n-        \/\/ If neither endpoint is extremal yet, push out the endpoint\n-        \/\/ which is closer to its respective limit.\n-        if (_lo >= 0 ||                 \/\/ easy common case\n-            ((juint)_lo - min) >= ((juint)max - _hi)) {\n-          \/\/ Try to widen to an unsigned range type of 31 bits:\n-          return make(_lo, max, WidenMax);\n-        } else {\n-          return make(min, _hi, WidenMax);\n-        }\n-      }\n-      return TypeInt::INT;\n-    }\n-    \/\/ Returned widened new guy\n-    return make(_lo,_hi,_widen+1);\n-  }\n-\n-  \/\/ If old guy contains new, then we probably widened too far & dropped to\n-  \/\/ bottom.  Return the wider fellow.\n-  if ( ot->_lo <= _lo && ot->_hi >= _hi )\n-    return old;\n+const Type* TypeInt::make_or_top(const TypeIntPrototype<jint, juint>& t, int widen) {\n+  return make_or_top(t, widen, false);\n+}\n@@ -1899,3 +1804,6 @@\n-  \/\/fatal(\"Integer value range is not subset\");\n-  \/\/return this;\n-  return TypeInt::INT;\n+bool TypeInt::contains(jint i) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  juint u = i;\n+  return i >= _lo && i <= _hi &&\n+         u >= _ulo && u <= _uhi &&\n+         _bits.is_satisfied_by(u);\n@@ -1904,9 +1812,4 @@\n-\/\/------------------------------narrow---------------------------------------\n-\/\/ Only happens for pessimistic optimizations.\n-const Type *TypeInt::narrow( const Type *old ) const {\n-  if (_lo >= _hi)  return this;   \/\/ already narrow enough\n-  if (old == nullptr)  return this;\n-  const TypeInt* ot = old->isa_int();\n-  if (ot == nullptr)  return this;\n-  jint olo = ot->_lo;\n-  jint ohi = ot->_hi;\n+bool TypeInt::contains(const TypeInt* t) const {\n+  assert(!_is_dual && !t->_is_dual, \"dual types should only be used for join calculation\");\n+  return TypeIntHelper::int_type_is_subset(this, t);\n+}\n@@ -1914,2 +1817,3 @@\n-  \/\/ If new guy is equal to old guy, no narrowing\n-  if (_lo == olo && _hi == ohi)  return old;\n+const Type* TypeInt::xmeet(const Type* t) const {\n+  return TypeIntHelper::int_type_xmeet(this, t);\n+}\n@@ -1917,2 +1821,4 @@\n-  \/\/ If old guy was maximum range, allow the narrowing\n-  if (olo == min_jint && ohi == max_jint)  return this;\n+const Type* TypeInt::xdual() const {\n+  return new TypeInt(TypeIntPrototype<jint, juint>{{_lo, _hi}, {_ulo, _uhi}, _bits},\n+                     _widen, !_is_dual);\n+}\n@@ -1920,2 +1826,4 @@\n-  if (_lo < olo || _hi > ohi)\n-    return this;                \/\/ doesn't narrow; pretty weird\n+const Type* TypeInt::widen(const Type* old, const Type* limit) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  return TypeIntHelper::int_type_widen(this, old->isa_int(), limit->isa_int());\n+}\n@@ -1923,8 +1831,4 @@\n-  \/\/ The new type narrows the old type, so look for a \"death march\".\n-  \/\/ See comments on PhaseTransform::saturate.\n-  juint nrange = (juint)_hi - _lo;\n-  juint orange = (juint)ohi - olo;\n-  if (nrange < max_juint - 1 && nrange > (orange >> 1) + (SMALLINT*2)) {\n-    \/\/ Use the new type only if the range shrinks a lot.\n-    \/\/ We do not want the optimizer computing 2^31 point by point.\n-    return old;\n+const Type* TypeInt::narrow(const Type* old) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  if (old == nullptr) {\n+    return this;\n@@ -1933,1 +1837,1 @@\n-  return this;\n+  return TypeIntHelper::int_type_narrow(this, old->isa_int());\n@@ -1937,1 +1841,2 @@\n-const Type *TypeInt::filter_helper(const Type *kills, bool include_speculative) const {\n+const Type* TypeInt::filter_helper(const Type* kills, bool include_speculative) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n@@ -1939,1 +1844,1 @@\n-  if (ft == nullptr || ft->empty())\n+  if (ft == nullptr) {\n@@ -1941,0 +1846,2 @@\n+  }\n+  assert(!ft->_is_dual, \"dual types should only be used for join calculation\");\n@@ -1944,1 +1851,2 @@\n-    ft = TypeInt::make(ft->_lo, ft->_hi, this->_widen);\n+    return (new TypeInt(TypeIntPrototype<jint, juint>{{ft->_lo, ft->_hi}, {ft->_ulo, ft->_uhi}, ft->_bits},\n+                        this->_widen, false))->hashcons();\n@@ -1951,3 +1859,3 @@\n-bool TypeInt::eq( const Type *t ) const {\n-  const TypeInt *r = t->is_int(); \/\/ Handy access\n-  return r->_lo == _lo && r->_hi == _hi && r->_widen == _widen;\n+bool TypeInt::eq(const Type* t) const {\n+  const TypeInt* r = t->is_int();\n+  return TypeIntHelper::int_type_is_equal(this, r) && _widen == r->_widen && _is_dual == r->_is_dual;\n@@ -1959,1 +1867,2 @@\n-  return (uint)_lo + (uint)_hi + (uint)_widen + (uint)Type::Int;\n+  return (uint)_lo + (uint)_hi + (uint)_ulo + (uint)_uhi +\n+         (uint)_bits._zeros + (uint)_bits._ones + (uint)_widen + (uint)_is_dual + (uint)Type::Int;\n@@ -1968,43 +1877,0 @@\n-\/\/------------------------------dump2------------------------------------------\n-\/\/ Dump TypeInt\n-#ifndef PRODUCT\n-static const char* intname(char* buf, size_t buf_size, jint n) {\n-  if (n == min_jint)\n-    return \"min\";\n-  else if (n < min_jint + 10000)\n-    os::snprintf_checked(buf, buf_size, \"min+\" INT32_FORMAT, n - min_jint);\n-  else if (n == max_jint)\n-    return \"max\";\n-  else if (n > max_jint - 10000)\n-    os::snprintf_checked(buf, buf_size, \"max-\" INT32_FORMAT, max_jint - n);\n-  else\n-    os::snprintf_checked(buf, buf_size, INT32_FORMAT, n);\n-  return buf;\n-}\n-\n-void TypeInt::dump2( Dict &d, uint depth, outputStream *st ) const {\n-  char buf[40], buf2[40];\n-  if (_lo == min_jint && _hi == max_jint)\n-    st->print(\"int\");\n-  else if (is_con())\n-    st->print(\"int:%s\", intname(buf, sizeof(buf), get_con()));\n-  else if (_lo == BOOL->_lo && _hi == BOOL->_hi)\n-    st->print(\"bool\");\n-  else if (_lo == BYTE->_lo && _hi == BYTE->_hi)\n-    st->print(\"byte\");\n-  else if (_lo == CHAR->_lo && _hi == CHAR->_hi)\n-    st->print(\"char\");\n-  else if (_lo == SHORT->_lo && _hi == SHORT->_hi)\n-    st->print(\"short\");\n-  else if (_hi == max_jint)\n-    st->print(\"int:>=%s\", intname(buf, sizeof(buf), _lo));\n-  else if (_lo == min_jint)\n-    st->print(\"int:<=%s\", intname(buf, sizeof(buf), _hi));\n-  else\n-    st->print(\"int:%s..%s\", intname(buf, sizeof(buf), _lo), intname(buf2, sizeof(buf2), _hi));\n-\n-  if (_widen != 0 && this != TypeInt::INT)\n-    st->print(\":%.*s\", _widen, \"wwww\");\n-}\n-#endif\n-\n@@ -2015,1 +1881,1 @@\n-  return _lo >= _hi;\n+  return _lo == _hi;\n@@ -2019,1 +1885,1 @@\n-  return _lo > _hi;\n+  return false;\n@@ -2024,10 +1890,12 @@\n-const TypeLong *TypeLong::MAX;\n-const TypeLong *TypeLong::MIN;\n-const TypeLong *TypeLong::MINUS_1;\/\/ -1\n-const TypeLong *TypeLong::ZERO; \/\/ 0\n-const TypeLong *TypeLong::ONE;  \/\/ 1\n-const TypeLong *TypeLong::POS;  \/\/ >=0\n-const TypeLong *TypeLong::LONG; \/\/ 64-bit integers\n-const TypeLong *TypeLong::INT;  \/\/ 32-bit subrange\n-const TypeLong *TypeLong::UINT; \/\/ 32-bit unsigned subrange\n-const TypeLong *TypeLong::TYPE_DOMAIN; \/\/ alias for TypeLong::LONG\n+const TypeLong* TypeLong::MAX;\n+const TypeLong* TypeLong::MIN;\n+const TypeLong* TypeLong::MINUS_1;\/\/ -1\n+const TypeLong* TypeLong::ZERO; \/\/ 0\n+const TypeLong* TypeLong::ONE;  \/\/ 1\n+const TypeLong* TypeLong::NON_ZERO;\n+const TypeLong* TypeLong::POS;  \/\/ >=0\n+const TypeLong* TypeLong::NEG;\n+const TypeLong* TypeLong::LONG; \/\/ 64-bit integers\n+const TypeLong* TypeLong::INT;  \/\/ 32-bit subrange\n+const TypeLong* TypeLong::UINT; \/\/ 32-bit unsigned subrange\n+const TypeLong* TypeLong::TYPE_DOMAIN; \/\/ alias for TypeLong::LONG\n@@ -2035,2 +1903,4 @@\n-\/\/------------------------------TypeLong---------------------------------------\n-TypeLong::TypeLong(jlong lo, jlong hi, int w) : TypeInteger(Long, w), _lo(lo), _hi(hi) {\n+TypeLong::TypeLong(const TypeIntPrototype<jlong, julong>& t, int widen, bool dual)\n+  : TypeInteger(Long, t.normalize_widen(widen), dual), _lo(t._srange._lo), _hi(t._srange._hi),\n+    _ulo(t._urange._lo), _uhi(t._urange._hi), _bits(t._bits) {\n+  DEBUG_ONLY(t.verify_constraints());\n@@ -2039,14 +1909,4 @@\n-\/\/------------------------------make-------------------------------------------\n-const TypeLong *TypeLong::make( jlong lo ) {\n-  return (TypeLong*)(new TypeLong(lo,lo,WidenMin))->hashcons();\n-}\n-\n-static int normalize_long_widen( jlong lo, jlong hi, int w ) {\n-  \/\/ Certain normalizations keep us sane when comparing types.\n-  \/\/ The 'SMALLINT' covers constants.\n-  if (lo <= hi) {\n-    if (((julong)hi - lo) <= SMALLINT)   w = Type::WidenMin;\n-    if (((julong)hi - lo) >= max_julong) w = Type::WidenMax; \/\/ TypeLong::LONG\n-  } else {\n-    if (((julong)lo - hi) <= SMALLINT)   w = Type::WidenMin;\n-    if (((julong)lo - hi) >= max_julong) w = Type::WidenMin; \/\/ dual TypeLong::LONG\n+const Type* TypeLong::make_or_top(const TypeIntPrototype<jlong, julong>& t, int widen, bool dual) {\n+  auto canonicalized_t = t.canonicalize_constraints();\n+  if (canonicalized_t.empty()) {\n+    return dual ? Type::BOTTOM : Type::TOP;\n@@ -2054,1 +1914,1 @@\n-  return w;\n+  return (new TypeLong(canonicalized_t._data, widen, dual))->hashcons()->is_long();\n@@ -2057,3 +1917,4 @@\n-const TypeLong *TypeLong::make( jlong lo, jlong hi, int w ) {\n-  w = normalize_long_widen(lo, hi, w);\n-  return (TypeLong*)(new TypeLong(lo,hi,w))->hashcons();\n+const TypeLong* TypeLong::make(jlong con) {\n+  julong ucon = con;\n+  return (new TypeLong(TypeIntPrototype<jlong, julong>{{con, con}, {ucon, ucon}, {~ucon, ucon}},\n+                       WidenMin, false))->hashcons()->is_long();\n@@ -2062,45 +1923,3 @@\n-\n-\/\/------------------------------meet-------------------------------------------\n-\/\/ Compute the MEET of two types.  It returns a new Type representation object\n-\/\/ with reference count equal to the number of Types pointing at it.\n-\/\/ Caller should wrap a Types around it.\n-const Type *TypeLong::xmeet( const Type *t ) const {\n-  \/\/ Perform a fast test for common case; meeting the same types together.\n-  if( this == t ) return this;  \/\/ Meeting same type?\n-\n-  \/\/ Currently \"this->_base\" is a TypeLong\n-  switch (t->base()) {          \/\/ Switch on original type\n-  case AnyPtr:                  \/\/ Mixing with oops happens when javac\n-  case RawPtr:                  \/\/ reuses local variables\n-  case OopPtr:\n-  case InstPtr:\n-  case AryPtr:\n-  case MetadataPtr:\n-  case KlassPtr:\n-  case InstKlassPtr:\n-  case AryKlassPtr:\n-  case NarrowOop:\n-  case NarrowKlass:\n-  case Int:\n-  case HalfFloatTop:\n-  case HalfFloatCon:\n-  case HalfFloatBot:\n-  case FloatTop:\n-  case FloatCon:\n-  case FloatBot:\n-  case DoubleTop:\n-  case DoubleCon:\n-  case DoubleBot:\n-  case Bottom:                  \/\/ Ye Olde Default\n-    return Type::BOTTOM;\n-  default:                      \/\/ All else is a mistake\n-    typerr(t);\n-  case Top:                     \/\/ No change\n-    return this;\n-  case Long:                    \/\/ Long vs Long?\n-    break;\n-  }\n-\n-  \/\/ Expand covered set\n-  const TypeLong *r = t->is_long(); \/\/ Turn into a TypeLong\n-  return make( MIN2(_lo,r->_lo), MAX2(_hi,r->_hi), MAX2(_widen,r->_widen) );\n+const TypeLong* TypeLong::make(jlong lo, jlong hi, int widen) {\n+  assert(lo <= hi, \"must be legal bounds\");\n+  return make_or_top(TypeIntPrototype<jlong, julong>{{lo, hi}, {0, max_julong}, {0, 0}}, widen)->is_long();\n@@ -2109,58 +1928,3 @@\n-\/\/------------------------------xdual------------------------------------------\n-\/\/ Dual: reverse hi & lo; flip widen\n-const Type *TypeLong::xdual() const {\n-  int w = normalize_long_widen(_hi,_lo, WidenMax-_widen);\n-  return new TypeLong(_hi,_lo,w);\n-}\n-\n-\/\/------------------------------widen------------------------------------------\n-\/\/ Only happens for optimistic top-down optimizations.\n-const Type *TypeLong::widen( const Type *old, const Type* limit ) const {\n-  \/\/ Coming from TOP or such; no widening\n-  if( old->base() != Long ) return this;\n-  const TypeLong *ot = old->is_long();\n-\n-  \/\/ If new guy is equal to old guy, no widening\n-  if( _lo == ot->_lo && _hi == ot->_hi )\n-    return old;\n-\n-  \/\/ If new guy contains old, then we widened\n-  if( _lo <= ot->_lo && _hi >= ot->_hi ) {\n-    \/\/ New contains old\n-    \/\/ If new guy is already wider than old, no widening\n-    if( _widen > ot->_widen ) return this;\n-    \/\/ If old guy was a constant, do not bother\n-    if (ot->_lo == ot->_hi)  return this;\n-    \/\/ Now widen new guy.\n-    \/\/ Check for widening too far\n-    if (_widen == WidenMax) {\n-      jlong max = max_jlong;\n-      jlong min = min_jlong;\n-      if (limit->isa_long()) {\n-        max = limit->is_long()->_hi;\n-        min = limit->is_long()->_lo;\n-      }\n-      if (min < _lo && _hi < max) {\n-        \/\/ If neither endpoint is extremal yet, push out the endpoint\n-        \/\/ which is closer to its respective limit.\n-        if (_lo >= 0 ||                 \/\/ easy common case\n-            ((julong)_lo - min) >= ((julong)max - _hi)) {\n-          \/\/ Try to widen to an unsigned range type of 32\/63 bits:\n-          if (max >= max_juint && _hi < max_juint)\n-            return make(_lo, max_juint, WidenMax);\n-          else\n-            return make(_lo, max, WidenMax);\n-        } else {\n-          return make(min, _hi, WidenMax);\n-        }\n-      }\n-      return TypeLong::LONG;\n-    }\n-    \/\/ Returned widened new guy\n-    return make(_lo,_hi,_widen+1);\n-  }\n-\n-  \/\/ If old guy contains new, then we probably widened too far & dropped to\n-  \/\/ bottom.  Return the wider fellow.\n-  if ( ot->_lo <= _lo && ot->_hi >= _hi )\n-    return old;\n+const Type* TypeLong::make_or_top(const TypeIntPrototype<jlong, julong>& t, int widen) {\n+  return make_or_top(t, widen, false);\n+}\n@@ -2168,3 +1932,6 @@\n-  \/\/  fatal(\"Long value range is not subset\");\n-  \/\/ return this;\n-  return TypeLong::LONG;\n+bool TypeLong::contains(jlong i) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  julong u = i;\n+  return i >= _lo && i <= _hi &&\n+         u >= _ulo && u <= _uhi &&\n+         _bits.is_satisfied_by(u);\n@@ -2173,9 +1940,4 @@\n-\/\/------------------------------narrow----------------------------------------\n-\/\/ Only happens for pessimistic optimizations.\n-const Type *TypeLong::narrow( const Type *old ) const {\n-  if (_lo >= _hi)  return this;   \/\/ already narrow enough\n-  if (old == nullptr)  return this;\n-  const TypeLong* ot = old->isa_long();\n-  if (ot == nullptr)  return this;\n-  jlong olo = ot->_lo;\n-  jlong ohi = ot->_hi;\n+bool TypeLong::contains(const TypeLong* t) const {\n+  assert(!_is_dual && !t->_is_dual, \"dual types should only be used for join calculation\");\n+  return TypeIntHelper::int_type_is_subset(this, t);\n+}\n@@ -2183,2 +1945,3 @@\n-  \/\/ If new guy is equal to old guy, no narrowing\n-  if (_lo == olo && _hi == ohi)  return old;\n+const Type* TypeLong::xmeet(const Type* t) const {\n+  return TypeIntHelper::int_type_xmeet(this, t);\n+}\n@@ -2186,2 +1949,4 @@\n-  \/\/ If old guy was maximum range, allow the narrowing\n-  if (olo == min_jlong && ohi == max_jlong)  return this;\n+const Type* TypeLong::xdual() const {\n+  return new TypeLong(TypeIntPrototype<jlong, julong>{{_lo, _hi}, {_ulo, _uhi}, _bits},\n+                      _widen, !_is_dual);\n+}\n@@ -2189,2 +1954,4 @@\n-  if (_lo < olo || _hi > ohi)\n-    return this;                \/\/ doesn't narrow; pretty weird\n+const Type* TypeLong::widen(const Type* old, const Type* limit) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  return TypeIntHelper::int_type_widen(this, old->isa_long(), limit->isa_long());\n+}\n@@ -2192,8 +1959,4 @@\n-  \/\/ The new type narrows the old type, so look for a \"death march\".\n-  \/\/ See comments on PhaseTransform::saturate.\n-  julong nrange = (julong)_hi - _lo;\n-  julong orange = (julong)ohi - olo;\n-  if (nrange < max_julong - 1 && nrange > (orange >> 1) + (SMALLINT*2)) {\n-    \/\/ Use the new type only if the range shrinks a lot.\n-    \/\/ We do not want the optimizer computing 2^31 point by point.\n-    return old;\n+const Type* TypeLong::narrow(const Type* old) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n+  if (old == nullptr) {\n+    return this;\n@@ -2202,1 +1965,1 @@\n-  return this;\n+  return TypeIntHelper::int_type_narrow(this, old->isa_long());\n@@ -2206,1 +1969,2 @@\n-const Type *TypeLong::filter_helper(const Type *kills, bool include_speculative) const {\n+const Type* TypeLong::filter_helper(const Type* kills, bool include_speculative) const {\n+  assert(!_is_dual, \"dual types should only be used for join calculation\");\n@@ -2208,1 +1972,1 @@\n-  if (ft == nullptr || ft->empty())\n+  if (ft == nullptr) {\n@@ -2210,0 +1974,2 @@\n+  }\n+  assert(!ft->_is_dual, \"dual types should only be used for join calculation\");\n@@ -2213,1 +1979,2 @@\n-    ft = TypeLong::make(ft->_lo, ft->_hi, this->_widen);\n+    return (new TypeLong(TypeIntPrototype<jlong, julong>{{ft->_lo, ft->_hi}, {ft->_ulo, ft->_uhi}, ft->_bits},\n+                         this->_widen, false))->hashcons();\n@@ -2220,3 +1987,3 @@\n-bool TypeLong::eq( const Type *t ) const {\n-  const TypeLong *r = t->is_long(); \/\/ Handy access\n-  return r->_lo == _lo &&  r->_hi == _hi  && r->_widen == _widen;\n+bool TypeLong::eq(const Type* t) const {\n+  const TypeLong* r = t->is_long();\n+  return TypeIntHelper::int_type_is_equal(this, r) && _widen == r->_widen && _is_dual == r->_is_dual;\n@@ -2228,1 +1995,2 @@\n-  return (uint)_lo + (uint)_hi + (uint)_widen + (uint)Type::Long;\n+  return (uint)_lo + (uint)_hi + (uint)_ulo + (uint)_uhi +\n+         (uint)_bits._zeros + (uint)_bits._ones + (uint)_widen + (uint)_is_dual + (uint)Type::Long;\n@@ -2237,55 +2005,0 @@\n-\/\/------------------------------dump2------------------------------------------\n-\/\/ Dump TypeLong\n-#ifndef PRODUCT\n-static const char* longnamenear(jlong x, const char* xname, char* buf, size_t buf_size, jlong n) {\n-  if (n > x) {\n-    if (n >= x + 10000)  return nullptr;\n-    os::snprintf_checked(buf, buf_size, \"%s+\" JLONG_FORMAT, xname, n - x);\n-  } else if (n < x) {\n-    if (n <= x - 10000)  return nullptr;\n-    os::snprintf_checked(buf, buf_size, \"%s-\" JLONG_FORMAT, xname, x - n);\n-  } else {\n-    return xname;\n-  }\n-  return buf;\n-}\n-\n-static const char* longname(char* buf, size_t buf_size, jlong n) {\n-  const char* str;\n-  if (n == min_jlong)\n-    return \"min\";\n-  else if (n < min_jlong + 10000)\n-    os::snprintf_checked(buf, buf_size, \"min+\" JLONG_FORMAT, n - min_jlong);\n-  else if (n == max_jlong)\n-    return \"max\";\n-  else if (n > max_jlong - 10000)\n-    os::snprintf_checked(buf, buf_size, \"max-\" JLONG_FORMAT, max_jlong - n);\n-  else if ((str = longnamenear(max_juint, \"maxuint\", buf, buf_size, n)) != nullptr)\n-    return str;\n-  else if ((str = longnamenear(max_jint, \"maxint\", buf, buf_size, n)) != nullptr)\n-    return str;\n-  else if ((str = longnamenear(min_jint, \"minint\", buf, buf_size, n)) != nullptr)\n-    return str;\n-  else\n-    os::snprintf_checked(buf, buf_size, JLONG_FORMAT, n);\n-  return buf;\n-}\n-\n-void TypeLong::dump2( Dict &d, uint depth, outputStream *st ) const {\n-  char buf[80], buf2[80];\n-  if (_lo == min_jlong && _hi == max_jlong)\n-    st->print(\"long\");\n-  else if (is_con())\n-    st->print(\"long:%s\", longname(buf, sizeof(buf), get_con()));\n-  else if (_hi == max_jlong)\n-    st->print(\"long:>=%s\", longname(buf, sizeof(buf), _lo));\n-  else if (_lo == min_jlong)\n-    st->print(\"long:<=%s\", longname(buf, sizeof(buf), _hi));\n-  else\n-    st->print(\"long:%s..%s\", longname(buf, sizeof(buf), _lo), longname(buf2,sizeof(buf2),  _hi));\n-\n-  if (_widen != 0 && this != TypeLong::LONG)\n-    st->print(\":%.*s\", _widen, \"wwww\");\n-}\n-#endif\n-\n@@ -2296,1 +2009,1 @@\n-  return _lo >= _hi;\n+  return _lo == _hi;\n@@ -2300,1 +2013,11 @@\n-  return _lo > _hi;\n+  return false;\n+}\n+\n+\/\/------------------------------dump2------------------------------------------\n+#ifndef PRODUCT\n+void TypeInt::dump2(Dict& d, uint depth, outputStream* st) const {\n+  TypeIntHelper::int_type_dump(this, st, false);\n+}\n+\n+void TypeInt::dump_verbose() const {\n+  TypeIntHelper::int_type_dump(this, tty, true);\n@@ -2303,0 +2026,9 @@\n+void TypeLong::dump2(Dict& d, uint depth, outputStream* st) const {\n+  TypeIntHelper::int_type_dump(this, st, false);\n+}\n+\n+void TypeLong::dump_verbose() const {\n+  TypeIntHelper::int_type_dump(this, tty, true);\n+}\n+#endif\n+\n@@ -2554,1 +2286,7 @@\n-    const TypeAry *a = t->is_ary();\n+    const TypeAry* a = t->is_ary();\n+    const Type* size = _size->xmeet(a->_size);\n+    const TypeInt* isize = size->isa_int();\n+    if (isize == nullptr) {\n+      assert(size == Type::TOP || size == Type::BOTTOM, \"\");\n+      return size;\n+    }\n@@ -2556,2 +2294,1 @@\n-                         _size->xmeet(a->_size)->is_int(),\n-                         _stable && a->_stable);\n+                         isize, _stable && a->_stable);\n@@ -4987,1 +4724,1 @@\n-  if (lo > hi)\n+  if (lo > hi) {\n@@ -4989,1 +4726,2 @@\n-  if (!chg)\n+  }\n+  if (!chg) {\n@@ -4991,0 +4729,1 @@\n+  }\n@@ -5155,1 +4894,6 @@\n-    const TypeAry *tary = _ary->meet_speculative(tap->_ary)->is_ary();\n+    const Type* tm = _ary->meet_speculative(tap->_ary);\n+    const TypeAry* tary = tm->isa_ary();\n+    if (tary == nullptr) {\n+      assert(tm == Type::TOP || tm == Type::BOTTOM, \"\");\n+      return tm;\n+    }\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":232,"deletions":488,"binary":false,"changes":720,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+#include \"opto\/compile.hpp\"\n+#include \"opto\/rangeinference.hpp\"\n@@ -76,0 +78,3 @@\n+template <class T, class U>\n+class TypeIntPrototype;\n+\n@@ -298,0 +303,4 @@\n+  \/\/ This has the same semantics as std::dynamic_cast<TypeClass*>(this)\n+  template <typename TypeClass>\n+  const TypeClass* try_cast() const;\n+\n@@ -307,3 +316,3 @@\n-  const TypeH      *isa_half_float() const;          \/\/ Returns null if not a Float{Top,Con,Bot}\n-  const TypeH      *is_half_float_constant() const;  \/\/ Asserts it is a FloatCon\n-  const TypeH      *isa_half_float_constant() const; \/\/ Returns null if not a FloatCon\n+  const TypeH      *isa_half_float() const;          \/\/ Returns null if not a HalfFloat{Top,Con,Bot}\n+  const TypeH      *is_half_float_constant() const;  \/\/ Asserts it is a HalfFloatCon\n+  const TypeH      *isa_half_float_constant() const; \/\/ Returns null if not a HalfFloatCon\n@@ -608,1 +617,6 @@\n-  TypeInteger(TYPES t, int w) : Type(t), _widen(w) {}\n+  TypeInteger(TYPES t, int w, bool dual) : Type(t), _is_dual(dual), _widen(w) {}\n+\n+  \/\/ Denote that a set is a dual set.\n+  \/\/ Dual sets are only used to compute the join of 2 sets, and not used\n+  \/\/ outside.\n+  const bool _is_dual;\n@@ -628,0 +642,148 @@\n+\/**\n+ * Definition:\n+ *\n+ * A TypeInt represents a set of non-empty jint values. A jint v is an element\n+ * of a TypeInt iff:\n+ *\n+ *   v >= _lo && v <= _hi &&\n+ *   juint(v) >= _ulo && juint(v) <= _uhi &&\n+ *   _bits.is_satisfied_by(v)\n+ *\n+ * Multiple sets of parameters can represent the same set.\n+ * E.g: consider 2 TypeInt t1, t2\n+ *\n+ * t1._lo = 2, t1._hi = 7, t1._ulo = 0, t1._uhi = 5, t1._bits._zeros = 0x00000000, t1._bits._ones = 0x1\n+ * t2._lo = 3, t2._hi = 5, t2._ulo = 3, t2._uhi = 5, t2._bits._zeros = 0xFFFFFFF8, t2._bits._ones = 0x1\n+ *\n+ * Then, t1 and t2 both represent the set {3, 5}. We can also see that the\n+ * constraints of t2 are the tightest possible. I.e there exists no TypeInt t3\n+ * which also represents {3, 5} such that any of these would be true:\n+ *\n+ *  1)  t3._lo  > t2._lo\n+ *  2)  t3._hi  < t2._hi\n+ *  3)  t3._ulo > t2._ulo\n+ *  4)  t3._uhi < t2._uhi\n+ *  5)  (t3._bits._zeros &~ t2._bis._zeros) != 0\n+ *  6)  (t3._bits._ones  &~ t2._bits._ones) != 0\n+ *\n+ * The 5-th condition mean that the subtraction of the bitsets represented by\n+ * t3._bits._zeros and t2._bits._zeros is not empty, which means that the\n+ * bits in t3._bits._zeros is not a subset of those in t2._bits._zeros, the\n+ * same applies to _bits._ones\n+ *\n+ * To simplify reasoning about the types in optimizations, we canonicalize\n+ * every TypeInt to its tightest form, already at construction. E.g a TypeInt\n+ * t with t._lo < 0 will definitely contain negative values. It also makes it\n+ * trivial to determine if a TypeInt instance is a subset of another.\n+ *\n+ * Lemmas:\n+ *\n+ * 1. Since every TypeInt instance is non-empty and canonicalized, all the\n+ *   bounds must also be elements of such TypeInt. Or else, we can tighten the\n+ *   bounds by narrowing it by one, which contradicts the assumption of the\n+ *   TypeInt being canonical.\n+ *\n+ * 2.\n+ *   2.1.  _lo <= jint(_ulo)\n+ *   2.2.  _lo <= _hi\n+ *   2.3.  _lo <= jint(_uhi)\n+ *   2.4.  _ulo <= juint(_lo)\n+ *   2.5.  _ulo <= juint(_hi)\n+ *   2.6.  _ulo <= _uhi\n+ *   2.7.  _hi >= _lo\n+ *   2.8.  _hi >= jint(_ulo)\n+ *   2.9.  _hi >= jint(_uhi)\n+ *   2.10. _uhi >= juint(_lo)\n+ *   2.11. _uhi >= _ulo\n+ *   2.12. _uhi >= juint(_hi)\n+ *\n+ *   Proof of lemma 2:\n+ *\n+ *   2.1. _lo <= jint(_ulo):\n+ *     According the lemma 1, _ulo is an element of the TypeInt, so in the\n+ *     signed domain, it must not be less than the smallest element of that\n+ *     TypeInt, which is _lo. Which means that _lo <= _ulo in the signed\n+ *     domain, or in a more programmatical way, _lo <= jint(_ulo).\n+ *   2.2. _lo <= _hi:\n+ *     According the lemma 1, _hi is an element of the TypeInt, so in the\n+ *     signed domain, it must not be less than the smallest element of that\n+ *     TypeInt, which is _lo. Which means that _lo <= _hi.\n+ *\n+ *   The other inequalities can be proved in a similar manner.\n+ *\n+ * 3. Given 2 jint values x, y where either both >= 0 or both < 0. Then:\n+ *\n+ *   x <= y iff juint(x) <= juint(y)\n+ *   I.e. x <= y in the signed domain iff x <= y in the unsigned domain\n+ *\n+ * 4. Either _lo == jint(_ulo) and _hi == jint(_uhi), or each element of a\n+ *   TypeInt lies in either interval [_lo, jint(_uhi)] or [jint(_ulo), _hi]\n+ *   (note that these intervals are disjoint in this case).\n+ *\n+ *   Proof of lemma 4:\n+ *\n+ *   For a TypeInt t, there are 3 possible cases:\n+ *\n+ *   a. t._lo >= 0, we have:\n+ *\n+ *     0 <= t_lo <= jint(t._ulo)           (lemma 2.1)\n+ *     juint(t._lo) <= juint(jint(t._ulo)) (lemma 3)\n+ *                  == t._ulo              (juint(jint(v)) == v with juint v)\n+ *                  <= juint(t._lo)        (lemma 2.4)\n+ *\n+ *     Which means that t._lo == jint(t._ulo).\n+ *\n+ *     Furthermore,\n+ *\n+ *     0 <= t._lo <= t._hi                 (lemma 2.2)\n+ *     0 <= t._lo <= jint(t._uhi)          (lemma 2.3)\n+ *     t._hi >= jint(t._uhi)               (lemma 2.9)\n+ *\n+ *     juint(t._hi) >= juint(jint(t._uhi)) (lemma 3)\n+ *                  == t._uhi              (juint(jint(v)) == v with juint v)\n+ *                  >= juint(t._hi)        (lemma 2.12)\n+ *\n+ *     Which means that t._hi == jint(t._uhi).\n+ *     In this case, t._lo == jint(t._ulo) and t._hi == jint(t._uhi)\n+ *\n+ *   b. t._hi < 0. Similarly, we can conclude that:\n+ *     t._lo == jint(t._ulo) and t._hi == jint(t._uhi)\n+ *\n+ *   c. t._lo < 0, t._hi >= 0.\n+ *\n+ *     Since t._ulo <= juint(t._hi) (lemma 2.5), we must have jint(t._ulo) >= 0\n+ *     because all negative values is larger than all non-negative values in the\n+ *     unsigned domain.\n+ *\n+ *     Since t._uhi >= juint(t._lo) (lemma 2.10), we must have jint(t._uhi) < 0\n+ *     similar to the reasoning above.\n+ *\n+ *     In this case, each element of t belongs to either [t._lo, jint(t._uhi)] or\n+ *     [jint(t._ulo), t._hi].\n+ *\n+ *     Below is an illustration of the TypeInt in this case, the intervals that\n+ *     the elements can be in are marked using the = symbol. Note how the\n+ *     negative range in the signed domain wrap around in the unsigned domain.\n+ *\n+ *     Signed:\n+ *     -----lo=========uhi---------0--------ulo==========hi-----\n+ *     Unsigned:\n+ *                                 0--------ulo==========hi----------lo=========uhi---------\n+ *\n+ *   This property is useful for our analysis of TypeInt values. Additionally,\n+ *   it can be seen that _lo and jint(_uhi) are both < 0 or both >= 0, and the\n+ *   same applies to jint(_ulo) and _hi.\n+ *\n+ *   We call [_lo, jint(_uhi)] and [jint(_ulo), _hi] \"simple intervals\". Then,\n+ *   a TypeInt consists of 2 simple intervals, each of which has its bounds\n+ *   being both >= 0 or both < 0. If both simple intervals lie in the same half\n+ *   of the integer domain, they must be the same (i.e _lo == jint(_ulo) and\n+ *   _hi == jint(_uhi)). Otherwise, [_lo, jint(_uhi)] must lie in the negative\n+ *   half and [jint(_ulo), _hi] must lie in the non-negative half of the signed\n+ *   domain (equivalently, [_lo, jint(_uhi)] must lie in the upper half and\n+ *   [jint(_ulo), _hi] must lie in the lower half of the unsigned domain).\n+ *\/\n+class TypeInt : public TypeInteger {\n+private:\n+  TypeInt(const TypeIntPrototype<jint, juint>& t, int w, bool dual);\n+  static const Type* make_or_top(const TypeIntPrototype<jint, juint>& t, int widen, bool dual);\n@@ -629,0 +791,1 @@\n+  friend class TypeIntHelper;\n@@ -630,6 +793,1 @@\n-\/\/------------------------------TypeInt----------------------------------------\n-\/\/ Class of integer ranges, the set of integers between a lower bound and an\n-\/\/ upper bound, inclusive.\n-class TypeInt : public TypeInteger {\n-  TypeInt( jint lo, jint hi, int w );\n-  virtual const Type *filter_helper(const Type *kills, bool include_speculative) const;\n+  virtual const Type* filter_helper(const Type* kills, bool include_speculative) const;\n@@ -640,1 +798,1 @@\n-  virtual bool eq( const Type *t ) const;\n+  virtual bool eq(const Type* t) const;\n@@ -644,1 +802,5 @@\n-  const jint _lo, _hi;          \/\/ Lower bound, upper bound\n+  \/\/ A value is in the set represented by this TypeInt if it satisfies all\n+  \/\/ the below constraints, see contains(jint)\n+  const jint _lo, _hi;       \/\/ Lower bound, upper bound in the signed domain\n+  const juint _ulo, _uhi;    \/\/ Lower bound, upper bound in the unsigned domain\n+  const KnownBits<juint> _bits;\n@@ -646,1 +808,1 @@\n-  static const TypeInt *make(jint lo);\n+  static const TypeInt* make(jint con);\n@@ -648,1 +810,2 @@\n-  static const TypeInt *make(jint lo, jint hi, int w);\n+  static const TypeInt* make(jint lo, jint hi, int widen);\n+  static const Type* make_or_top(const TypeIntPrototype<jint, juint>& t, int widen);\n@@ -651,1 +814,1 @@\n-  bool is_con() const { return _lo==_hi; }\n+  bool is_con() const { return _lo == _hi; }\n@@ -653,1 +816,5 @@\n-  jint get_con() const { assert(is_con(), \"\" );  return _lo; }\n+  jint get_con() const { assert(is_con(), \"\");  return _lo; }\n+  \/\/ Check if a jint\/TypeInt is a subset of this TypeInt (i.e. all elements of the\n+  \/\/ argument are also elements of this type)\n+  bool contains(jint i) const;\n+  bool contains(const TypeInt* t) const;\n@@ -655,1 +822,1 @@\n-  virtual bool        is_finite() const;  \/\/ Has a finite value\n+  virtual bool is_finite() const;  \/\/ Has a finite value\n@@ -657,4 +824,4 @@\n-  virtual const Type *xmeet( const Type *t ) const;\n-  virtual const Type *xdual() const;    \/\/ Compute dual right now.\n-  virtual const Type *widen( const Type *t, const Type* limit_type ) const;\n-  virtual const Type *narrow( const Type *t ) const;\n+  virtual const Type* xmeet(const Type* t) const;\n+  virtual const Type* xdual() const;    \/\/ Compute dual right now.\n+  virtual const Type* widen(const Type* t, const Type* limit_type) const;\n+  virtual const Type* narrow(const Type* t) const;\n@@ -667,23 +834,25 @@\n-  static const TypeInt *MAX;\n-  static const TypeInt *MIN;\n-  static const TypeInt *MINUS_1;\n-  static const TypeInt *ZERO;\n-  static const TypeInt *ONE;\n-  static const TypeInt *BOOL;\n-  static const TypeInt *CC;\n-  static const TypeInt *CC_LT;  \/\/ [-1]  == MINUS_1\n-  static const TypeInt *CC_GT;  \/\/ [1]   == ONE\n-  static const TypeInt *CC_EQ;  \/\/ [0]   == ZERO\n-  static const TypeInt *CC_LE;  \/\/ [-1,0]\n-  static const TypeInt *CC_GE;  \/\/ [0,1] == BOOL (!)\n-  static const TypeInt *BYTE;\n-  static const TypeInt *UBYTE;\n-  static const TypeInt *CHAR;\n-  static const TypeInt *SHORT;\n-  static const TypeInt *POS;\n-  static const TypeInt *POS1;\n-  static const TypeInt *INT;\n-  static const TypeInt *SYMINT; \/\/ symmetric range [-max_jint..max_jint]\n-  static const TypeInt *TYPE_DOMAIN; \/\/ alias for TypeInt::INT\n-\n-  static const TypeInt *as_self(const Type *t) { return t->is_int(); }\n+  static const TypeInt* MAX;\n+  static const TypeInt* MIN;\n+  static const TypeInt* MINUS_1;\n+  static const TypeInt* ZERO;\n+  static const TypeInt* ONE;\n+  static const TypeInt* BOOL;\n+  static const TypeInt* CC;\n+  static const TypeInt* CC_LT;  \/\/ [-1]  == MINUS_1\n+  static const TypeInt* CC_GT;  \/\/ [1]   == ONE\n+  static const TypeInt* CC_EQ;  \/\/ [0]   == ZERO\n+  static const TypeInt* CC_NE;  \/\/ [-1, 1]\n+  static const TypeInt* CC_LE;  \/\/ [-1,0]\n+  static const TypeInt* CC_GE;  \/\/ [0,1] == BOOL (!)\n+  static const TypeInt* BYTE;\n+  static const TypeInt* UBYTE;\n+  static const TypeInt* CHAR;\n+  static const TypeInt* SHORT;\n+  static const TypeInt* NON_ZERO;\n+  static const TypeInt* POS;\n+  static const TypeInt* POS1;\n+  static const TypeInt* INT;\n+  static const TypeInt* SYMINT; \/\/ symmetric range [-max_jint..max_jint]\n+  static const TypeInt* TYPE_DOMAIN; \/\/ alias for TypeInt::INT\n+\n+  static const TypeInt* as_self(const Type* t) { return t->is_int(); }\n@@ -691,1 +860,2 @@\n-  virtual void dump2( Dict &d, uint depth, outputStream *st ) const;\n+  virtual void dump2(Dict& d, uint depth, outputStream* st) const;\n+  void dump_verbose() const;\n@@ -695,4 +865,1 @@\n-\n-\/\/------------------------------TypeLong---------------------------------------\n-\/\/ Class of long integer ranges, the set of integers between a lower bound and\n-\/\/ an upper bound, inclusive.\n+\/\/ Similar to TypeInt\n@@ -700,1 +867,6 @@\n-  TypeLong( jlong lo, jlong hi, int w );\n+private:\n+  TypeLong(const TypeIntPrototype<jlong, julong>& t, int w, bool dual);\n+  static const Type* make_or_top(const TypeIntPrototype<jlong, julong>& t, int widen, bool dual);\n+\n+  friend class TypeIntHelper;\n+\n@@ -703,1 +875,1 @@\n-  virtual const Type *filter_helper(const Type *kills, bool include_speculative) const;\n+  virtual const Type* filter_helper(const Type* kills, bool include_speculative) const;\n@@ -711,1 +883,5 @@\n-  const jlong _lo, _hi;         \/\/ Lower bound, upper bound\n+  \/\/ A value is in the set represented by this TypeLong if it satisfies all\n+  \/\/ the below constraints, see contains(jlong)\n+  const jlong _lo, _hi;       \/\/ Lower bound, upper bound in the signed domain\n+  const julong _ulo, _uhi;    \/\/ Lower bound, upper bound in the unsigned domain\n+  const KnownBits<julong> _bits;\n@@ -713,1 +889,1 @@\n-  static const TypeLong *make(jlong lo);\n+  static const TypeLong* make(jlong con);\n@@ -715,1 +891,2 @@\n-  static const TypeLong *make(jlong lo, jlong hi, int w);\n+  static const TypeLong* make(jlong lo, jlong hi, int widen);\n+  static const Type* make_or_top(const TypeIntPrototype<jlong, julong>& t, int widen);\n@@ -718,1 +895,1 @@\n-  bool is_con() const { return _lo==_hi; }\n+  bool is_con() const { return _lo == _hi; }\n@@ -721,0 +898,4 @@\n+  \/\/ Check if a jlong\/TypeLong is a subset of this TypeLong (i.e. all elements of the\n+  \/\/ argument are also elements of this type)\n+  bool contains(jlong i) const;\n+  bool contains(const TypeLong* t) const;\n@@ -730,4 +911,4 @@\n-  virtual const Type *xmeet( const Type *t ) const;\n-  virtual const Type *xdual() const;    \/\/ Compute dual right now.\n-  virtual const Type *widen( const Type *t, const Type* limit_type ) const;\n-  virtual const Type *narrow( const Type *t ) const;\n+  virtual const Type* xmeet(const Type* t) const;\n+  virtual const Type* xdual() const;    \/\/ Compute dual right now.\n+  virtual const Type* widen(const Type* t, const Type* limit_type) const;\n+  virtual const Type* narrow(const Type* t) const;\n@@ -735,10 +916,12 @@\n-  static const TypeLong *MAX;\n-  static const TypeLong *MIN;\n-  static const TypeLong *MINUS_1;\n-  static const TypeLong *ZERO;\n-  static const TypeLong *ONE;\n-  static const TypeLong *POS;\n-  static const TypeLong *LONG;\n-  static const TypeLong *INT;    \/\/ 32-bit subrange [min_jint..max_jint]\n-  static const TypeLong *UINT;   \/\/ 32-bit unsigned [0..max_juint]\n-  static const TypeLong *TYPE_DOMAIN; \/\/ alias for TypeLong::LONG\n+  static const TypeLong* MAX;\n+  static const TypeLong* MIN;\n+  static const TypeLong* MINUS_1;\n+  static const TypeLong* ZERO;\n+  static const TypeLong* ONE;\n+  static const TypeLong* NON_ZERO;\n+  static const TypeLong* POS;\n+  static const TypeLong* NEG;\n+  static const TypeLong* LONG;\n+  static const TypeLong* INT;    \/\/ 32-bit subrange [min_jint..max_jint]\n+  static const TypeLong* UINT;   \/\/ 32-bit unsigned [0..max_juint]\n+  static const TypeLong* TYPE_DOMAIN; \/\/ alias for TypeLong::LONG\n@@ -747,1 +930,1 @@\n-  static const TypeLong *as_self(const Type *t) { return t->is_long(); }\n+  static const TypeLong* as_self(const Type* t) { return t->is_long(); }\n@@ -750,1 +933,2 @@\n-  virtual void dump2( Dict &d, uint, outputStream *st  ) const;\/\/ Specialized per-Type dumping\n+  virtual void dump2(Dict& d, uint, outputStream* st) const;\/\/ Specialized per-Type dumping\n+  void dump_verbose() const;\n@@ -2260,0 +2444,10 @@\n+template <>\n+inline const TypeInt* Type::try_cast<TypeInt>() const {\n+  return isa_int();\n+}\n+\n+template <>\n+inline const TypeLong* Type::try_cast<TypeLong>() const {\n+  return isa_long();\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":265,"deletions":71,"binary":false,"changes":336,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"cds\/aotLogging.hpp\"\n@@ -88,0 +89,3 @@\n+#if INCLUDE_JVMCI\n+bool   Arguments::_jvmci_module_added           = false;\n+#endif\n@@ -135,0 +139,5 @@\n+struct VMInitArgsGroup {\n+  const JavaVMInitArgs* _args;\n+  JVMFlagOrigin _origin;\n+};\n+\n@@ -334,2 +343,1 @@\n-    if (matches_property_suffix(property_suffix, ADDREADS, ADDREADS_LEN) ||\n-        matches_property_suffix(property_suffix, PATCH, PATCH_LEN) ||\n+    if (matches_property_suffix(property_suffix, PATCH, PATCH_LEN) ||\n@@ -346,0 +354,1 @@\n+          matches_property_suffix(property_suffix, ADDREADS, ADDREADS_LEN) ||\n@@ -522,4 +531,0 @@\n-#ifdef LINUX\n-  { \"UseLinuxPosixThreadCPUClocks\", JDK_Version::jdk(24), JDK_Version::jdk(25), JDK_Version::jdk(26) },\n-  { \"UseOprofile\",                  JDK_Version::jdk(25), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n-#endif\n@@ -530,0 +535,3 @@\n+  { \"ParallelRefProcEnabled\",       JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"ParallelRefProcBalancingEnabled\", JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n+  { \"PSChunkLargeArrays\",           JDK_Version::jdk(26),  JDK_Version::jdk(27), JDK_Version::jdk(28) },\n@@ -535,0 +543,3 @@\n+#ifdef LINUX\n+  { \"UseOprofile\",                  JDK_Version::jdk(25), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n+#endif\n@@ -538,0 +549,3 @@\n+#if defined(AARCH64)\n+  { \"NearCpool\",                    JDK_Version::undefined(), JDK_Version::jdk(25), JDK_Version::undefined() },\n+#endif\n@@ -1365,1 +1379,1 @@\n-    log_error(cds)(\"%s is incompatible with other specified options.\",\n+    aot_log_error(aot)(\"%s is incompatible with other specified options.\",\n@@ -1374,1 +1388,1 @@\n-      log_warning(cds)(\"Unable to use AOT cache: %s\", message);\n+      log_warning(aot)(\"Unable to use AOT cache: %s\", message);\n@@ -1376,1 +1390,1 @@\n-      log_info(cds)(\"Unable to use shared archive: %s\", message);\n+      aot_log_info(aot)(\"Unable to use shared archive: %s\", message);\n@@ -1565,1 +1579,1 @@\n-          log_info(cds)(\"UseCompressedOops and UseCompressedClassPointers have been disabled due to\"\n+          aot_log_info(aot)(\"UseCompressedOops and UseCompressedClassPointers have been disabled due to\"\n@@ -1801,3 +1815,3 @@\n-    PropertyList_unique_add(&_system_properties, \"jdk.internal.vm.ci.enabled\", \"true\",\n-        AddProperty, UnwriteableProperty, InternalProperty);\n-    if (ClassLoader::is_module_observable(\"jdk.internal.vm.ci\")) {\n+    \/\/ Add the JVMCI module if not using libjvmci or EnableJVMCI\n+    \/\/ was explicitly set on the command line or in the jimage.\n+    if ((!UseJVMCINativeLibrary || FLAG_IS_CMDLINE(EnableJVMCI) || FLAG_IS_JIMAGE_RESOURCE(EnableJVMCI)) && ClassLoader::is_module_observable(\"jdk.internal.vm.ci\") && !_jvmci_module_added) {\n@@ -1826,9 +1840,0 @@\n-#ifndef _LP64\n-  if (LockingMode == LM_LEGACY) {\n-    FLAG_SET_CMDLINE(LockingMode, LM_LIGHTWEIGHT);\n-    \/\/ Self-forwarding in bit 3 of the mark-word conflicts\n-    \/\/ with 4-byte-aligned stack-locks.\n-    warning(\"Legacy locking not supported on this platform\");\n-  }\n-#endif\n-\n@@ -1948,6 +1953,1 @@\n-\/\/ Parse JavaVMInitArgs structure\n-\n-jint Arguments::parse_vm_init_args(const JavaVMInitArgs *vm_options_args,\n-                                   const JavaVMInitArgs *java_tool_options_args,\n-                                   const JavaVMInitArgs *java_options_args,\n-                                   const JavaVMInitArgs *cmd_line_args) {\n+jint Arguments::parse_vm_init_args(GrowableArrayCHeap<VMInitArgsGroup, mtArguments>* all_args) {\n@@ -1966,24 +1966,6 @@\n-  \/\/ Parse args structure generated from java.base vm options resource\n-  jint result = parse_each_vm_init_arg(vm_options_args, JVMFlagOrigin::JIMAGE_RESOURCE);\n-  if (result != JNI_OK) {\n-    return result;\n-  }\n-\n-  \/\/ Parse args structure generated from JAVA_TOOL_OPTIONS environment\n-  \/\/ variable (if present).\n-  result = parse_each_vm_init_arg(java_tool_options_args, JVMFlagOrigin::ENVIRON_VAR);\n-  if (result != JNI_OK) {\n-    return result;\n-  }\n-\n-  \/\/ Parse args structure generated from the command line flags.\n-  result = parse_each_vm_init_arg(cmd_line_args, JVMFlagOrigin::COMMAND_LINE);\n-  if (result != JNI_OK) {\n-    return result;\n-  }\n-\n-  \/\/ Parse args structure generated from the _JAVA_OPTIONS environment\n-  \/\/ variable (if present) (mimics classic VM)\n-  result = parse_each_vm_init_arg(java_options_args, JVMFlagOrigin::ENVIRON_VAR);\n-  if (result != JNI_OK) {\n-    return result;\n+  jint result;\n+  for (int i = 0; i < all_args->length(); i++) {\n+    result = parse_each_vm_init_arg(all_args->at(i)._args, all_args->at(i)._origin);\n+    if (result != JNI_OK) {\n+      return result;\n+    }\n@@ -2250,0 +2232,13 @@\n+#if INCLUDE_JVMCI\n+      if (!_jvmci_module_added) {\n+        const char *jvmci_module = strstr(tail, \"jdk.internal.vm.ci\");\n+        if (jvmci_module != nullptr) {\n+          char before = *(jvmci_module - 1);\n+          char after  = *(jvmci_module + strlen(\"jdk.internal.vm.ci\"));\n+          if ((before == '=' || before == ',') && (after == '\\0' || after == ',')) {\n+            FLAG_SET_DEFAULT(EnableJVMCI, true);\n+            _jvmci_module_added = true;\n+          }\n+        }\n+      }\n+#endif\n@@ -2450,1 +2445,1 @@\n-      if (FLAG_SET_CMDLINE(ReservedCodeCacheSize, (uintx)long_ReservedCodeCacheSize) != JVMFlag::SUCCESS) {\n+      if (FLAG_SET_CMDLINE(ReservedCodeCacheSize, (size_t)long_ReservedCodeCacheSize) != JVMFlag::SUCCESS) {\n@@ -3078,0 +3073,44 @@\n+static JavaVMOption* get_last_aotmode_arg(const JavaVMInitArgs* args) {\n+  for (int index = args->nOptions - 1; index >= 0; index--) {\n+    JavaVMOption* option = args->options + index;\n+    if (strstr(option->optionString, \"-XX:AOTMode=\") == option->optionString) {\n+      return option;\n+    }\n+  }\n+\n+  return nullptr;\n+}\n+\n+jint Arguments::parse_jdk_aot_vm_options_environment_variable(GrowableArrayCHeap<VMInitArgsGroup, mtArguments>* all_args,\n+                                                            ScopedVMInitArgs* jdk_aot_vm_options_args) {\n+  \/\/ Don't bother scanning all the args if this env variable is not set\n+  if (::getenv(\"JDK_AOT_VM_OPTIONS\") == nullptr) {\n+    return JNI_OK;\n+  }\n+\n+  \/\/ Scan backwards and find the last occurrence of -XX:AOTMode=xxx, which will decide the value\n+  \/\/ of AOTMode.\n+  JavaVMOption* option = nullptr;\n+  for (int i = all_args->length() - 1; i >= 0; i--) {\n+    if ((option = get_last_aotmode_arg(all_args->at(i)._args)) != nullptr) {\n+      break;\n+    }\n+  }\n+\n+  if (option != nullptr) {\n+    \/\/ We have found the last -XX:AOTMode=xxx. At this point <option> has NOT been parsed yet,\n+    \/\/ so its value is not reflected inside the global variable AOTMode.\n+    if (strcmp(option->optionString, \"-XX:AOTMode=create\") != 0) {\n+      return JNI_OK; \/\/ Do not parse JDK_AOT_VM_OPTIONS\n+    }\n+  } else {\n+    \/\/ -XX:AOTMode is not specified in any of 4 options_args, let's check AOTMode,\n+    \/\/ which would have been set inside process_settings_file();\n+    if (AOTMode == nullptr || strcmp(AOTMode, \"create\") != 0) {\n+      return JNI_OK; \/\/ Do not parse JDK_AOT_VM_OPTIONS\n+    }\n+  }\n+\n+  return parse_options_environment_variable(\"JDK_AOT_VM_OPTIONS\", jdk_aot_vm_options_args);\n+}\n+\n@@ -3456,0 +3495,1 @@\n+  ScopedVMInitArgs initial_jdk_aot_vm_options_args(\"env_var='JDK_AOT_VM_OPTIONS'\");\n@@ -3462,0 +3502,1 @@\n+  JavaVMInitArgs* cur_jdk_aot_vm_options_args;\n@@ -3468,0 +3509,1 @@\n+  ScopedVMInitArgs mod_jdk_aot_vm_options_args(\"env_var='_JDK_AOT_VM_OPTIONS'\");\n@@ -3469,0 +3511,1 @@\n+  GrowableArrayCHeap<VMInitArgsGroup, mtArguments> all_args;\n@@ -3476,0 +3519,2 @@\n+  \/\/ Yet another environment variable: _JAVA_OPTIONS. This mimics the classic VM.\n+  \/\/ This is an undocumented feature.\n@@ -3522,7 +3567,1 @@\n-  if (IgnoreUnrecognizedVMOptions) {\n-    cur_cmd_args->ignoreUnrecognized = true;\n-    cur_java_tool_options_args->ignoreUnrecognized = true;\n-    cur_java_options_args->ignoreUnrecognized = true;\n-  }\n-\n-  \/\/ Parse specified settings file\n+  \/\/ Parse specified settings file (s) -- the effects are applied immediately into the JVM global flags.\n@@ -3531,1 +3570,1 @@\n-                               cur_cmd_args->ignoreUnrecognized)) {\n+                               IgnoreUnrecognizedVMOptions)) {\n@@ -3538,1 +3577,1 @@\n-                               cur_cmd_args->ignoreUnrecognized)) {\n+                               IgnoreUnrecognizedVMOptions)) {\n@@ -3549,0 +3588,43 @@\n+  \/\/ The settings in the args are applied in this order to the the JVM global flags.\n+  \/\/ For historical reasons, the order is DIFFERENT than the scanning order of\n+  \/\/ the above expand_vm_options_as_needed() calls.\n+  all_args.append({cur_vm_options_args, JVMFlagOrigin::JIMAGE_RESOURCE});\n+  all_args.append({cur_java_tool_options_args, JVMFlagOrigin::ENVIRON_VAR});\n+  all_args.append({cur_cmd_args, JVMFlagOrigin::COMMAND_LINE});\n+  all_args.append({cur_java_options_args, JVMFlagOrigin::ENVIRON_VAR});\n+\n+  \/\/ JDK_AOT_VM_OPTIONS are parsed only if -XX:AOTMode=create has been detected from all\n+  \/\/ the options that have been gathered above.\n+  code = parse_jdk_aot_vm_options_environment_variable(&all_args, &initial_jdk_aot_vm_options_args);\n+  if (code != JNI_OK) {\n+    return code;\n+  }\n+  code = expand_vm_options_as_needed(initial_jdk_aot_vm_options_args.get(),\n+                                     &mod_jdk_aot_vm_options_args,\n+                                     &cur_jdk_aot_vm_options_args);\n+  if (code != JNI_OK) {\n+    return code;\n+  }\n+\n+  for (int index = 0; index < cur_jdk_aot_vm_options_args->nOptions; index++) {\n+    JavaVMOption* option = cur_jdk_aot_vm_options_args->options + index;\n+    const char* optionString = option->optionString;\n+    if (strstr(optionString, \"-XX:AOTMode=\") == optionString &&\n+        strcmp(optionString, \"-XX:AOTMode=create\") != 0) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"Option %s cannot be specified in JDK_AOT_VM_OPTIONS\\n\", optionString);\n+      return JNI_ERR;\n+    }\n+  }\n+\n+  all_args.append({cur_jdk_aot_vm_options_args, JVMFlagOrigin::ENVIRON_VAR});\n+\n+  if (IgnoreUnrecognizedVMOptions) {\n+    \/\/ Note: unrecognized options in cur_vm_options_arg cannot be ignored. They are part of\n+    \/\/ the JDK so it shouldn't have bad options.\n+    cur_cmd_args->ignoreUnrecognized = true;\n+    cur_java_tool_options_args->ignoreUnrecognized = true;\n+    cur_java_options_args->ignoreUnrecognized = true;\n+    cur_jdk_aot_vm_options_args->ignoreUnrecognized = true;\n+  }\n+\n@@ -3550,0 +3632,1 @@\n+    \/\/ For historical reasons, options specified in cur_vm_options_arg and -XX:Flags are not printed.\n@@ -3553,0 +3636,1 @@\n+    print_options(cur_jdk_aot_vm_options_args);\n@@ -3555,5 +3639,2 @@\n-  \/\/ Parse JavaVMInitArgs structure passed in, as well as JAVA_TOOL_OPTIONS and _JAVA_OPTIONS\n-  jint result = parse_vm_init_args(cur_vm_options_args,\n-                                   cur_java_tool_options_args,\n-                                   cur_java_options_args,\n-                                   cur_cmd_args);\n+  \/\/ Apply the settings in these args to the JVM global flags.\n+  jint result = parse_vm_init_args(&all_args);\n@@ -3618,1 +3699,1 @@\n-      log_is_enabled(Info, cds)) {\n+      log_is_enabled(Info, cds) || log_is_enabled(Info, aot)) {\n@@ -3622,0 +3703,1 @@\n+    LogConfiguration::configure_stdout(LogLevel::Off, true, LOG_TAGS(aot));\n@@ -3683,3 +3765,0 @@\n-  if (UseCompactObjectHeaders && LockingMode != LM_LIGHTWEIGHT) {\n-    FLAG_SET_DEFAULT(LockingMode, LM_LIGHTWEIGHT);\n-  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":150,"deletions":71,"binary":false,"changes":221,"status":"modified"},{"patch":"@@ -131,1 +131,1 @@\n-  product(bool, UseCompactObjectHeaders, false, EXPERIMENTAL,               \\\n+  product(bool, UseCompactObjectHeaders, false,                             \\\n@@ -296,0 +296,3 @@\n+  develop(bool, VerifyInlineCaches, true,                                   \\\n+          \"Verify Inline Caches\")                                           \\\n+                                                                            \\\n@@ -330,0 +333,1 @@\n+                                                                            \\\n@@ -653,0 +657,4 @@\n+  product(bool, DeoptimizeOnAllocationException, false, DIAGNOSTIC,         \\\n+          \"Deoptimize on exception during allocation instead of using the \" \\\n+          \"compiled exception handlers\")                                    \\\n+                                                                            \\\n@@ -1092,0 +1100,3 @@\n+  \/* This value is later shifted left by up to LogBytesPerLong bits       *\/\\\n+  \/* (to convert from element count to size in bytes), so we must ensure  *\/\\\n+  \/* it does not overflow during the shift.                               *\/\\\n@@ -1095,0 +1106,1 @@\n+          range(0, (1 << (BitsPerInt - LogBytesPerLong - 1)) - 1)           \\\n@@ -1499,1 +1511,1 @@\n-  product_pd(uintx, CodeCacheSegmentSize, EXPERIMENTAL,                     \\\n+  product_pd(size_t, CodeCacheSegmentSize, EXPERIMENTAL,                    \\\n@@ -1514,1 +1526,1 @@\n-  product_pd(uintx, InitialCodeCacheSize,                                   \\\n+  product_pd(size_t, InitialCodeCacheSize,                                  \\\n@@ -1518,1 +1530,1 @@\n-  develop_pd(uintx, CodeCacheMinimumUseSpace,                               \\\n+  develop_pd(size_t, CodeCacheMinimumUseSpace,                              \\\n@@ -1520,1 +1532,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1525,1 +1537,1 @@\n-  product_pd(uintx, ReservedCodeCacheSize,                                  \\\n+  product_pd(size_t, ReservedCodeCacheSize,                                 \\\n@@ -1529,1 +1541,1 @@\n-  product_pd(uintx, NonProfiledCodeHeapSize,                                \\\n+  product_pd(size_t, NonProfiledCodeHeapSize,                               \\\n@@ -1531,1 +1543,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1533,1 +1545,1 @@\n-  product_pd(uintx, ProfiledCodeHeapSize,                                   \\\n+  product_pd(size_t, ProfiledCodeHeapSize,                                  \\\n@@ -1535,1 +1547,1 @@\n-          range(0, max_uintx)                                               \\\n+          range(0, SIZE_MAX)                                                \\\n@@ -1537,1 +1549,1 @@\n-  product_pd(uintx, NonNMethodCodeHeapSize,                                 \\\n+  product_pd(size_t, NonNMethodCodeHeapSize,                                \\\n@@ -1541,1 +1553,1 @@\n-  product_pd(uintx, CodeCacheExpansionSize,                                 \\\n+  product_pd(size_t, CodeCacheExpansionSize,                                \\\n@@ -1543,1 +1555,1 @@\n-          range(32*K, max_uintx)                                            \\\n+          range(32*K, SIZE_MAX)                                             \\\n@@ -1545,1 +1557,1 @@\n-  product_pd(uintx, CodeCacheMinBlockLength, DIAGNOSTIC,                    \\\n+  product_pd(size_t, CodeCacheMinBlockLength, DIAGNOSTIC,                   \\\n@@ -1726,5 +1738,0 @@\n-  product(int, PerfDataSamplingInterval, 50,                                \\\n-          \"Data sampling interval (in milliseconds)\")                       \\\n-          range(PeriodicTask::min_interval, max_jint)                       \\\n-          constraint(PerfDataSamplingIntervalFunc, AfterErgo)               \\\n-                                                                            \\\n@@ -1956,7 +1963,0 @@\n-  product(int, LockingMode, LM_LIGHTWEIGHT,                                 \\\n-          \"(Deprecated) Select locking mode: \"                              \\\n-          \"0: (Deprecated) monitors only (LM_MONITOR), \"                    \\\n-          \"1: (Deprecated) monitors & legacy stack-locking (LM_LEGACY), \"   \\\n-          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT, default)\") \\\n-          range(0, 2)                                                       \\\n-                                                                            \\\n@@ -2008,0 +2008,4 @@\n+                                                                            \\\n+  develop(uint, BinarySearchThreshold, 16,                                  \\\n+          \"Minimal number of elements in a sorted collection to prefer\"     \\\n+          \"binary search over simple linear search.\" )                      \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":30,"deletions":26,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -1698,1 +1698,1 @@\n-class HandshakeForDeflation : public HandshakeClosure {\n+class DeflationHandshakeClosure : public HandshakeClosure {\n@@ -1700,1 +1700,1 @@\n-  HandshakeForDeflation() : HandshakeClosure(\"HandshakeForDeflation\") {}\n+  DeflationHandshakeClosure() : HandshakeClosure(\"DeflationHandshakeClosure\") {}\n@@ -1703,1 +1703,1 @@\n-    log_trace(monitorinflation)(\"HandshakeForDeflation::do_thread: thread=\"\n+    log_trace(monitorinflation)(\"DeflationHandshakeClosure::do_thread: thread=\"\n@@ -1868,2 +1868,2 @@\n-    HandshakeForDeflation hfd_hc;\n-    Handshake::execute(&hfd_hc);\n+    DeflationHandshakeClosure dhc;\n+    Handshake::execute(&dhc);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"jfr\/recorder\/service\/jfrRecorderThread.hpp\"\n@@ -1028,0 +1029,1 @@\n+        declare_type(TrainingReplayThread, JavaThread)                    \\\n@@ -1030,0 +1032,1 @@\n+        declare_type(JfrRecorderThread, JavaThread)                       \\\n@@ -1486,3 +1489,3 @@\n-  \/***********************************************\/                       \\\n-  \/* ConstantPool* layout enum for InvokeDynamic *\/                       \\\n-  \/***********************************************\/                       \\\n+  \/******************************************************\/                \\\n+  \/* BSMAttributeEntry* - layout enum for InvokeDynamic *\/                \\\n+  \/******************************************************\/                \\\n@@ -1490,3 +1493,3 @@\n-  declare_constant(ConstantPool::_indy_bsm_offset)                        \\\n-  declare_constant(ConstantPool::_indy_argc_offset)                       \\\n-  declare_constant(ConstantPool::_indy_argv_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_bsmi_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_argc_offset)                       \\\n+  declare_constant(BSMAttributeEntry::_argv_offset)                       \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":9,"deletions":6,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -51,1 +51,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -54,1 +54,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n@@ -57,1 +57,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/TestCastX2NotProcessedIGVN.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -48,1 +48,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n+                                   \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n@@ -50,1 +50,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n+                                   \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n@@ -52,1 +52,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n+                                   \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n@@ -54,1 +54,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n+                                   \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestVectorConditionalMove.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -58,1 +58,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -61,1 +61,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n@@ -64,1 +64,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestVectorizationMismatchedAccess.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -46,1 +46,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -49,1 +49,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\",\n+                                   \"-XX:-UseCompactObjectHeaders\",\n@@ -52,1 +52,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n@@ -55,1 +55,1 @@\n-                                   \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\",\n+                                   \"-XX:+UseCompactObjectHeaders\",\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestVectorizationNotRun.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -117,5 +117,5 @@\n-            case \"NoAlignVector\"         -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"AlignVector\"           -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"VerifyAlignVector\"     -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\", \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+VerifyAlignVector\"); }\n-            case \"NoAlignVector-COH\"     -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"VerifyAlignVector-COH\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\", \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+VerifyAlignVector\"); }\n+            case \"NoAlignVector\"         -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"AlignVector\"           -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"VerifyAlignVector\"     -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\", \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+VerifyAlignVector\"); }\n+            case \"NoAlignVector-COH\"     -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"VerifyAlignVector-COH\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\", \"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+VerifyAlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestAlignVector.java","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -85,4 +85,4 @@\n-            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -80,4 +80,4 @@\n-        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-AlignVector\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaers\");\n-        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+AlignVector\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaers\");\n-        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-AlignVector\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaers\");\n-        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+AlignVector\", \"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaers\");\n+        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-AlignVector\", \"-XX:-UseCompactObjectHeaers\");\n+        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+AlignVector\", \"-XX:-UseCompactObjectHeaers\");\n+        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:-AlignVector\", \"-XX:+UseCompactObjectHeaers\");\n+        TestFramework.runWithFlags(\"-XX:+IgnoreUnrecognizedVMOptions\", \"-XX:+AlignVector\", \"-XX:+UseCompactObjectHeaers\");\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestMulAddS2I.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -64,4 +64,4 @@\n-            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestScheduleReordersScalarMemops.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -79,4 +79,4 @@\n-            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestSplitPacks.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -42,4 +42,4 @@\n-        TestFramework.runWithFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n-        TestFramework.runWithFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n-        TestFramework.runWithFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n-        TestFramework.runWithFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n+        TestFramework.runWithFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n+        TestFramework.runWithFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n+        TestFramework.runWithFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\");\n+        TestFramework.runWithFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\");\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestUnorderedReductionPartialVectorization.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -53,4 +53,4 @@\n-            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloatConversionsVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -56,4 +56,4 @@\n-            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n-            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n-            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"nCOH_nAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"nCOH_yAV\" -> { framework.addFlags(\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n+            case \"yCOH_nAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"); }\n+            case \"yCOH_yAV\" -> { framework.addFlags(\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"); }\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestFloatConversionsVectorNaN.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -72,4 +72,4 @@\n-            case \"nCOH_nAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n-            case \"nCOH_yAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n-            case \"yCOH_nAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n-            case \"yCOH_yAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n+            case \"nCOH_nAV\" -> new String[]{\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n+            case \"nCOH_yAV\" -> new String[]{\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n+            case \"yCOH_nAV\" -> new String[]{\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n+            case \"yCOH_yAV\" -> new String[]{\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayTypeConvertTest.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -70,4 +70,4 @@\n-            case \"nCOH_nAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n-            case \"nCOH_yAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n-            case \"yCOH_nAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n-            case \"yCOH_yAV\" -> new String[]{\"-XX:+UnlockExperimentalVMOptions\", \"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n+            case \"nCOH_nAV\" -> new String[]{\"-XX:-UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n+            case \"nCOH_yAV\" -> new String[]{\"-XX:-UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n+            case \"yCOH_nAV\" -> new String[]{\"-XX:+UseCompactObjectHeaders\", \"-XX:-AlignVector\"};\n+            case \"yCOH_yAV\" -> new String[]{\"-XX:+UseCompactObjectHeaders\", \"-XX:+AlignVector\"};\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopCombinedOpTest.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n@@ -42,1 +42,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:-UseCompressedOops -XX:+UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:+UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n@@ -52,1 +52,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:+UseCompressedOops -XX:-UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:-UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n@@ -62,1 +62,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:-UseCompressedOops -XX:-UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:-UseCompressedClassPointers -XX:-UseCompactObjectHeaders BaseOffsets\n@@ -72,1 +72,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:+UseCompressedOops -XX:+UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:+UseCompactObjectHeaders BaseOffsets\n@@ -82,1 +82,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UnlockExperimentalVMOptions -XX:-UseCompressedOops -XX:+UseCompactObjectHeaders BaseOffsets\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:+UseCompactObjectHeaders BaseOffsets\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/BaseOffsets.java","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -105,1 +105,1 @@\n-            .addPrefix(\"-Xlog:cds+map*=trace:file=\" + mapName + \":none:filesize=0\")\n+            .addPrefix(\"-Xlog:aot+map*=trace:file=\" + mapName + \":none:filesize=0\")\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/DeterministicDump.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}