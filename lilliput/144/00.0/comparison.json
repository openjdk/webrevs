{"files":[{"patch":"@@ -206,0 +206,6 @@\n+    int base_offset = arrayOopDesc::length_offset_in_bytes() + BytesPerInt;\n+    if (!is_aligned(base_offset, BytesPerWord)) {\n+      assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+      \/\/ Clear gap\/first 4 bytes following the length field.\n+      strw(zr, Address(obj, base_offset));\n+    }\n@@ -305,11 +311,3 @@\n-  \/\/ Clear leading 4 bytes, if necessary.\n-  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n-  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n-  int base_offset = base_offset_in_bytes;\n-  if (!is_aligned(base_offset, BytesPerWord)) {\n-    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n-    strw(zr, Address(obj, base_offset));\n-    base_offset += BytesPerInt;\n-  }\n-  assert(is_aligned(base_offset, BytesPerWord), \"must be word-aligned\");\n-\n+  \/\/ Align-up to word boundary, because we clear the 4 bytes potentially\n+  \/\/ following the length field in initialize_header().\n+  int base_offset = align_up(base_offset_in_bytes, BytesPerWord);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":9,"deletions":11,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -463,0 +463,3 @@\n+  if (ce->compilation()->bailed_out()) {\n+    return; \/\/ CodeCache is full\n+  }\n","filename":"src\/hotspot\/cpu\/ppc\/c1_CodeStubs_ppc.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2016, 2018 SAP SE. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024 SAP SE. All rights reserved.\n@@ -436,0 +436,1 @@\n+  CHECK_BAILOUT();\n","filename":"src\/hotspot\/cpu\/s390\/c1_CodeStubs_s390.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -214,0 +214,9 @@\n+#ifdef _LP64\n+    int base_offset = arrayOopDesc::length_offset_in_bytes() + BytesPerInt;\n+    if (!is_aligned(base_offset, BytesPerWord)) {\n+      assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+      \/\/ Clear gap\/first 4 bytes following the length field.\n+      xorl(t1, t1);\n+      movl(Address(obj, base_offset), t1);\n+    }\n+#endif\n@@ -312,1 +321,1 @@\n-  movptr(arr_size, (int32_t)base_offset_in_bytes + MinObjAlignmentInBytesMask);\n+  movptr(arr_size, base_offset_in_bytes + MinObjAlignmentInBytesMask);\n@@ -320,13 +329,0 @@\n-  \/\/ Clear leading 4 bytes, if necessary.\n-  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n-  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n-  int base_offset = base_offset_in_bytes;\n-#ifdef _LP64\n-  if (!is_aligned(base_offset, BytesPerWord)) {\n-    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n-    movl(Address(obj, base_offset), 0);\n-    base_offset += BytesPerInt;\n-  }\n-#endif\n-  assert(is_aligned(base_offset, BytesPerWord), \"must be word aligned\");\n-\n@@ -335,0 +331,3 @@\n+  \/\/ Align-up to word boundary, because we clear the 4 bytes potentially\n+  \/\/ following the length field in initialize_header().\n+  int base_offset = align_up(base_offset_in_bytes, BytesPerWord);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":13,"deletions":14,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -4478,1 +4478,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4489,1 +4489,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4503,1 +4503,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4514,1 +4514,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4528,1 +4528,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4539,1 +4539,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n@@ -4553,1 +4553,1 @@\n-  predicate(UseAVX > 0 && !SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && !VLoopReductions::is_reduction(n));\n@@ -4564,1 +4564,1 @@\n-  predicate(UseAVX > 0 && SuperWord::is_reduction(n));\n+  predicate(UseAVX > 0 && VLoopReductions::is_reduction(n));\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.hpp\"\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.hpp\"\n@@ -1695,3 +1695,6 @@\n-  char *base = os::remap_memory(_fd, _full_path, r->file_offset(),\n-                                addr, size, false \/* !read_only *\/,\n-                                r->allow_exec());\n+  \/\/ This path should not be reached for Windows; see JDK-8222379.\n+  assert(WINDOWS_ONLY(false) NOT_WINDOWS(true), \"Don't call on Windows\");\n+  \/\/ Replace old mapping with new one that is writable.\n+  char *base = os::map_memory(_fd, _full_path, r->file_offset(),\n+                              addr, size, false \/* !read_only *\/,\n+                              r->allow_exec());\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1336,0 +1336,3 @@\n+    \/\/ NMT: fix up the space tags\n+    MemTracker::record_virtual_memory_type(archive_space_rs.base(), mtClassShared);\n+    MemTracker::record_virtual_memory_type(class_space_rs.base(), mtClass);\n@@ -1365,1 +1368,1 @@\n-                                                     ccs_begin_offset);\n+                                                     ccs_begin_offset, mtClassShared, mtClass);\n@@ -1372,3 +1375,0 @@\n-  \/\/ NMT: fix up the space tags\n-  MemTracker::record_virtual_memory_type(archive_space_rs.base(), mtClassShared);\n-  MemTracker::record_virtual_memory_type(class_space_rs.base(), mtClass);\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -49,0 +49,3 @@\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionRemSet.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionSet.inline.hpp\"\n@@ -74,3 +77,0 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n-#include \"gc\/g1\/heapRegionSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -320,0 +320,7 @@\n+  {\n+    GCTraceTime(Debug, gc, phases) debug(\"Phase 1: Flush Mark Stats Cache\", scope()->timer());\n+    for (uint i = 0; i < workers(); i++) {\n+      marker(i)->flush_mark_stats_cache();\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/g1\/g1HeapRegionManager.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"gc\/g1\/heapRegionManager.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCAdjustTask.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/g1\/heapRegionManager.hpp\"\n+#include \"gc\/g1\/g1HeapRegionManager.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/g1\/g1FullCollector.inline.hpp\"\n+#include \"gc\/g1\/g1FullCollector.inline.hpp\"\n@@ -34,1 +34,0 @@\n-#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -36,0 +35,1 @@\n+#include \"gc\/g1\/g1HeapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/g1HeapRegion.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n@@ -36,0 +35,1 @@\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -32,0 +32,2 @@\n+#include \"gc\/g1\/g1HeapRegion.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionRemSet.inline.hpp\"\n@@ -34,2 +36,0 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1OopClosures.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -195,1 +195,1 @@\n-  _rem_set = create_rem_set(heap_rs.region());\n+  _rem_set = new CardTableRS(heap_rs.region());\n@@ -212,5 +212,0 @@\n-\n-CardTableRS* SerialHeap::create_rem_set(const MemRegion& reserved_region) {\n-  return new CardTableRS(reserved_region);\n-}\n-\n@@ -527,1 +522,1 @@\n-    if (run_verification && VerifyGCLevel <= 0 && VerifyBeforeGC) {\n+    if (run_verification && VerifyBeforeGC) {\n@@ -539,1 +534,1 @@\n-                       run_verification && VerifyGCLevel <= 0,\n+                       run_verification,\n@@ -577,2 +572,1 @@\n-    if (!prepared_for_verification && run_verification &&\n-        VerifyGCLevel <= 1 && VerifyBeforeGC) {\n+    if (!prepared_for_verification && run_verification && VerifyBeforeGC) {\n@@ -604,1 +598,1 @@\n-                       run_verification && VerifyGCLevel <= 1,\n+                       run_verification,\n@@ -957,11 +951,0 @@\n-void SerialHeap::generation_iterate(GenClosure* cl,\n-                                    bool old_to_young) {\n-  if (old_to_young) {\n-    cl->do_generation(_old_gen);\n-    cl->do_generation(_young_gen);\n-  } else {\n-    cl->do_generation(_young_gen);\n-    cl->do_generation(_old_gen);\n-  }\n-}\n-\n@@ -1065,8 +1048,0 @@\n-class GenGCSaveTopsBeforeGCClosure: public SerialHeap::GenClosure {\n- private:\n- public:\n-  void do_generation(Generation* gen) {\n-    gen->record_spaces_top();\n-  }\n-};\n-\n@@ -1075,2 +1050,2 @@\n-    GenGCSaveTopsBeforeGCClosure blk;\n-    generation_iterate(&blk, false);  \/\/ not old-to-young.\n+    _young_gen->record_spaces_top();\n+    _old_gen->record_spaces_top();\n","filename":"src\/hotspot\/share\/gc\/serial\/serialHeap.cpp","additions":7,"deletions":32,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -49,3 +49,0 @@\n-class WorkerTask;\n-class AdaptiveSizePolicy;\n-class BarrierSet;\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -216,2 +216,2 @@\n-          \"Maximum size of marking stack\")                                  \\\n-          range(1, (INT_MAX - 1))                                          \\\n+          \"Maximum size of marking stack in bytes.\")                        \\\n+          range(1, (INT_MAX - 1))                                           \\\n@@ -220,1 +220,1 @@\n-          \"Size of marking stack\")                                          \\\n+          \"Size of marking stack in bytes.\")                                \\\n@@ -222,1 +222,1 @@\n-          range(1, (INT_MAX - 1))                                          \\\n+          range(1, (INT_MAX - 1))                                           \\\n@@ -348,4 +348,0 @@\n-  develop(intx, PSAdaptiveSizePolicyResizeVirtualSpaceAlot, -1,             \\\n-          \"Resize the virtual spaces of the young or old generations\")      \\\n-          range(-1, 1)                                                      \\\n-                                                                            \\\n@@ -620,4 +616,0 @@\n-  product(int, VerifyGCLevel,     0, DIAGNOSTIC,                            \\\n-          \"Generation level at which to start +VerifyBefore\/AfterGC\")       \\\n-          range(0, 1)                                                       \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":4,"deletions":12,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -44,0 +44,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -416,0 +417,1 @@\n+    mem_zap_end_padding(mem);\n@@ -421,0 +423,18 @@\n+#ifndef PRODUCT\n+void ObjArrayAllocator::mem_zap_end_padding(HeapWord* mem) const {\n+  const size_t length_in_bytes = static_cast<size_t>(_length) << ArrayKlass::cast(_klass)->log2_element_size();\n+  const BasicType element_type = ArrayKlass::cast(_klass)->element_type();\n+  const size_t base_offset_in_bytes = arrayOopDesc::base_offset_in_bytes(element_type);\n+  const size_t size_in_bytes = _word_size * BytesPerWord;\n+\n+  const address obj_end = reinterpret_cast<address>(mem) + size_in_bytes;\n+  const address base = reinterpret_cast<address>(mem) + base_offset_in_bytes;\n+  const address elements_end = base + length_in_bytes;\n+  assert(elements_end <= obj_end, \"payload must fit in object\");\n+  if (elements_end < obj_end) {\n+    const size_t padding_in_bytes = obj_end - elements_end;\n+    Copy::fill_to_bytes(elements_end, padding_in_bytes, heapPaddingByteVal);\n+  }\n+}\n+#endif\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":21,"deletions":1,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -241,5 +241,1 @@\n-  }\n-  {\n-    \/\/ Epilogue\n-    _preserved_marks->restore(heap->workers());\n-    _preserved_marks->reclaim();\n+    phase5_epilog();\n@@ -287,0 +283,2 @@\n+\n+  bool is_thread_safe() { return true; }\n@@ -296,1 +294,1 @@\n-  heap->heap_region_iterate(&cl);\n+  heap->parallel_heap_region_iterate(&cl);\n@@ -336,1 +334,1 @@\n-  void finish_region() {\n+  void finish() {\n@@ -356,1 +354,1 @@\n-      finish_region();\n+      finish();\n@@ -408,1 +406,1 @@\n-  void work(uint worker_id) {\n+  void work(uint worker_id) override {\n@@ -417,14 +415,9 @@\n-  template <bool ALT_FWD>\n-  void work_impl(uint worker_id) {\n-    ShenandoahParallelWorkerSession worker_session(worker_id);\n-    ShenandoahHeapRegionSet* slice = _worker_slices[worker_id];\n-    ShenandoahHeapRegionSetIterator it(slice);\n-    ShenandoahHeapRegion* from_region = it.next();\n-    \/\/ No work?\n-    if (from_region == nullptr) {\n-       return;\n-    }\n-\n-    \/\/ Sliding compaction. Walk all regions in the slice, and compact them.\n-    \/\/ Remember empty regions and reuse them as needed.\n-    ResourceMark rm;\n+  template<bool ALT_FWD>\n+  void work_impl(uint worker_id);\n+\n+  template<typename ClosureType>\n+  void prepare_for_compaction(ClosureType& cl,\n+                              GrowableArray<ShenandoahHeapRegion*>& empty_regions,\n+                              ShenandoahHeapRegionSetIterator& it,\n+                              ShenandoahHeapRegion* from_region);\n+};\n@@ -432,1 +425,10 @@\n-    GrowableArray<ShenandoahHeapRegion*> empty_regions((int)_heap->num_regions());\n+template<bool ALT_FWD>\n+void ShenandoahPrepareForCompactionTask::work_impl(uint worker_id) {\n+  ShenandoahParallelWorkerSession worker_session(worker_id);\n+  ShenandoahHeapRegionSet* slice = _worker_slices[worker_id];\n+  ShenandoahHeapRegionSetIterator it(slice);\n+  ShenandoahHeapRegion* from_region = it.next();\n+  \/\/ No work?\n+  if (from_region == nullptr) {\n+    return;\n+  }\n@@ -434,1 +436,3 @@\n-    ShenandoahPrepareForCompactionObjectClosure<ALT_FWD> cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n+  \/\/ Sliding compaction. Walk all regions in the slice, and compact them.\n+  \/\/ Remember empty regions and reuse them as needed.\n+  ResourceMark rm;\n@@ -436,2 +440,1 @@\n-    while (from_region != nullptr) {\n-      assert(is_candidate_region(from_region), \"Sanity\");\n+  GrowableArray<ShenandoahHeapRegion*> empty_regions((int)_heap->num_regions());\n@@ -439,4 +442,3 @@\n-      cl.set_from_region(from_region);\n-      if (from_region->has_live()) {\n-        _heap->marked_object_iterate(from_region, &cl);\n-      }\n+  ShenandoahPrepareForCompactionObjectClosure<ALT_FWD> cl(_preserved_marks->get(worker_id), empty_regions, from_region);\n+  prepare_for_compaction(cl, empty_regions, it, from_region);\n+}\n@@ -444,5 +446,10 @@\n-      \/\/ Compacted the region to somewhere else? From-region is empty then.\n-      if (!cl.is_compact_same_region()) {\n-        empty_regions.append(from_region);\n-      }\n-      from_region = it.next();\n+template<typename ClosureType>\n+void ShenandoahPrepareForCompactionTask::prepare_for_compaction(ClosureType& cl,\n+                                                                GrowableArray<ShenandoahHeapRegion*>& empty_regions,\n+                                                                ShenandoahHeapRegionSetIterator& it,\n+                                                                ShenandoahHeapRegion* from_region) {\n+  while (from_region != nullptr) {\n+    assert(is_candidate_region(from_region), \"Sanity\");\n+    cl.set_from_region(from_region);\n+    if (from_region->has_live()) {\n+      _heap->marked_object_iterate(from_region, &cl);\n@@ -450,5 +457,3 @@\n-    cl.finish_region();\n-    \/\/ Mark all remaining regions as empty\n-    for (int pos = cl.empty_regions_pos(); pos < empty_regions.length(); ++pos) {\n-      ShenandoahHeapRegion* r = empty_regions.at(pos);\n-      r->set_new_top(r->bottom());\n+    \/\/ Compacted the region to somewhere else? From-region is empty then.\n+    if (!cl.is_compact_same_region()) {\n+      empty_regions.append(from_region);\n@@ -457,0 +462,1 @@\n+    from_region = it.next();\n@@ -458,1 +464,1 @@\n-};\n+  cl.finish();\n@@ -460,1 +466,8 @@\n-template <bool ALT_FWD>\n+  \/\/ Mark all remaining regions as empty\n+  for (int pos = cl.empty_regions_pos(); pos < empty_regions.length(); ++pos) {\n+    ShenandoahHeapRegion* r = empty_regions.at(pos);\n+    r->set_new_top(r->bottom());\n+  }\n+}\n+\n+template<bool ALT_FWD>\n@@ -1013,1 +1026,1 @@\n-  \/\/ sliding costs. We may consider doing this in parallel in future.\n+  \/\/ sliding costs. We may consider doing this in parallel in the future.\n@@ -1127,0 +1140,5 @@\n+}\n+\n+void ShenandoahFullGC::phase5_epilog() {\n+  GCTraceTime(Info, gc, phases) time(\"Phase 5: Full GC epilog\", _gc_timer);\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n@@ -1139,1 +1157,0 @@\n-\n@@ -1146,0 +1163,1 @@\n+    heap->clear_cancelled_gc();\n@@ -1148,1 +1166,2 @@\n-  heap->clear_cancelled_gc();\n+  _preserved_marks->restore(heap->workers());\n+  _preserved_marks->reclaim();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":65,"deletions":46,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+  void phase5_epilog();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -666,1 +666,1 @@\n-  JFR_ONLY(ShenandoahJFRSupport::register_jfr_type_serializers());\n+  JFR_ONLY(ShenandoahJFRSupport::register_jfr_type_serializers();)\n@@ -1009,1 +1009,5 @@\n-  ShenandoahHeapLocker locker(lock());\n+  \/\/ If we are dealing with mutator allocation, then we may need to block for safepoint.\n+  \/\/ We cannot block for safepoint for GC allocations, because there is a high chance\n+  \/\/ we are already running at safepoint or from stack watermark machinery, and we cannot\n+  \/\/ block again.\n+  ShenandoahHeapLocker locker(lock(), req.is_mutator_alloc());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,0 +65,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/x\/xObjArrayAllocator.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -65,0 +65,1 @@\n+\n@@ -148,0 +149,2 @@\n+  mem_zap_end_padding(mem);\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zObjArrayAllocator.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -185,1 +185,1 @@\n-  JNIEXPORT result_type JNICALL c2v_ ## name signature { \\\n+  result_type JNICALL c2v_ ## name signature {           \\\n@@ -196,1 +196,1 @@\n-  JNIEXPORT result_type JNICALL c2v_ ## name signature { \\\n+  result_type JNICALL c2v_ ## name signature {           \\\n@@ -212,1 +212,1 @@\n-  JNIEXPORT result_type JNICALL c2v_ ## name signature { \\\n+  result_type JNICALL c2v_ ## name signature {           \\\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,3 +56,1 @@\n-  \/\/ Check whether an element of an arrayOop with the given type must be\n-  \/\/ aligned 0 mod 8.  The arrayOop itself must be aligned at least this\n-  \/\/ strongly.\n+  \/\/ Given a type, return true if elements of that type must be aligned to 64-bit.\n","filename":"src\/hotspot\/share\/oops\/arrayOop.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -46,2 +46,0 @@\n-  } else if (*((juint*)this) == badMetaWordVal) {\n-    st->print_cr(\"BAD META WORD\");\n@@ -61,2 +59,0 @@\n-  } else if (*((juint*)this) == badMetaWordVal) {\n-    st->print_cr(\"BAD META WORD\");\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2011,1 +2011,1 @@\n-    if (cgr != nullptr && cgr->not_global_escape(obj_node())) {\n+    if (cgr != nullptr && cgr->can_eliminate_lock(this)) {\n@@ -2174,0 +2174,1 @@\n+        box->set_nested();\n@@ -2207,1 +2208,1 @@\n-    if (cgr != nullptr && cgr->not_global_escape(obj_node())) {\n+    if (cgr != nullptr && cgr->can_eliminate_lock(this)) {\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -59,0 +59,1 @@\n+#include \"opto\/locknode.hpp\"\n@@ -4874,0 +4875,2 @@\n+    AbstractLockNode* alock = locks.at(0);\n+    BoxLockNode* box = alock->box_node()->as_BoxLock();\n@@ -4878,0 +4881,13 @@\n+      BoxLockNode* this_box = lock->box_node()->as_BoxLock();\n+      if (this_box != box) {\n+        \/\/ Locking regions (BoxLock) could be Unbalanced here:\n+        \/\/  - its coarsened locks were eliminated in earlier\n+        \/\/    macro nodes elimination followed by loop unroll\n+        \/\/ Preserve Unbalanced status in such cases.\n+        if (!this_box->is_unbalanced()) {\n+          this_box->set_coarsened();\n+        }\n+        if (!box->is_unbalanced()) {\n+          box->set_coarsened();\n+        }\n+      }\n@@ -4955,0 +4971,32 @@\n+\/\/ Mark locking regions (identified by BoxLockNode) as unbalanced if\n+\/\/ locks coarsening optimization removed Lock\/Unlock nodes from them.\n+\/\/ Such regions become unbalanced because coarsening only removes part\n+\/\/ of Lock\/Unlock nodes in region. As result we can't execute other\n+\/\/ locks elimination optimizations which assume all code paths have\n+\/\/ corresponding pair of Lock\/Unlock nodes - they are balanced.\n+void Compile::mark_unbalanced_boxes() const {\n+  int count = coarsened_count();\n+  for (int i = 0; i < count; i++) {\n+    Node_List* locks_list = _coarsened_locks.at(i);\n+    uint size = locks_list->size();\n+    if (size > 0) {\n+      AbstractLockNode* alock = locks_list->at(0)->as_AbstractLock();\n+      BoxLockNode* box = alock->box_node()->as_BoxLock();\n+      if (alock->is_coarsened()) {\n+        \/\/ coarsened_locks_consistent(), which is called before this method, verifies\n+        \/\/ that the rest of Lock\/Unlock nodes on locks_list are also coarsened.\n+        assert(!box->is_eliminated(), \"regions with coarsened locks should not be marked as eliminated\");\n+        for (uint j = 1; j < size; j++) {\n+          assert(locks_list->at(j)->as_AbstractLock()->is_coarsened(), \"only coarsened locks are expected here\");\n+          BoxLockNode* this_box = locks_list->at(j)->as_AbstractLock()->box_node()->as_BoxLock();\n+          if (box != this_box) {\n+            assert(!this_box->is_eliminated(), \"regions with coarsened locks should not be marked as eliminated\");\n+            box->set_unbalanced();\n+            this_box->set_unbalanced();\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -1948,2 +1948,3 @@\n-void PhaseMacroExpand::mark_eliminated_box(Node* oldbox, Node* obj) {\n-  if (oldbox->as_BoxLock()->is_eliminated()) {\n+void PhaseMacroExpand::mark_eliminated_box(Node* box, Node* obj) {\n+  BoxLockNode* oldbox = box->as_BoxLock();\n+  if (oldbox->is_eliminated()) {\n@@ -1952,0 +1953,1 @@\n+  assert(!oldbox->is_unbalanced(), \"this should not be called for unbalanced region\");\n@@ -1959,0 +1961,1 @@\n+    oldbox->set_local();      \/\/ This verifies correct state of BoxLock\n@@ -1960,1 +1963,1 @@\n-    oldbox->as_BoxLock()->set_eliminated(); \/\/ This changes box's hash value\n+    oldbox->set_eliminated(); \/\/ This changes box's hash value\n@@ -1987,0 +1990,1 @@\n+  newbox->set_local(); \/\/ This verifies correct state of BoxLock\n@@ -2042,0 +2046,3 @@\n+  if (alock->box_node()->as_BoxLock()->is_unbalanced()) {\n+    return; \/\/ Can't do any more elimination for this locking region\n+  }\n@@ -2358,0 +2365,5 @@\n+  } else {\n+    \/\/ After coarsened locks are eliminated locking regions\n+    \/\/ become unbalanced. We should not execute any more\n+    \/\/ locks elimination optimizations on them.\n+    C->mark_unbalanced_boxes();\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":15,"deletions":3,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -3425,0 +3425,1 @@\n+          assert(!trailing_load_store(), \"load store node can't be eliminated\");\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -2014,1 +2014,1 @@\n-  product(uint, TrimNativeHeapInterval, 0, EXPERIMENTAL,                    \\\n+  product(uint, TrimNativeHeapInterval, 0,                                  \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1552,1 +1552,1 @@\n-  JFR_ONLY(return vmSymbols::jfr_chunk_rotation_monitor() == monitor_klass->name());\n+  JFR_ONLY(return vmSymbols::jfr_chunk_rotation_monitor() == monitor_klass->name();)\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -584,0 +584,2 @@\n+#include CPU_HEADER(globalDefinitions)\n+\n@@ -585,0 +587,1 @@\n+#ifndef CODE_CACHE_SIZE_LIMIT\n@@ -586,0 +589,2 @@\n+#endif\n+\n@@ -589,2 +594,0 @@\n-#include CPU_HEADER(globalDefinitions)\n-\n@@ -1030,13 +1033,13 @@\n-const jint     badInt           = -3;                       \/\/ generic \"bad int\" value\n-const intptr_t badAddressVal    = -2;                       \/\/ generic \"bad address\" value\n-const intptr_t badOopVal        = -1;                       \/\/ generic \"bad oop\" value\n-const intptr_t badHeapOopVal    = (intptr_t) CONST64(0x2BAD4B0BBAADBABE); \/\/ value used to zap heap after GC\n-const int      badStackSegVal   = 0xCA;                     \/\/ value used to zap stack segments\n-const int      badHandleValue   = 0xBC;                     \/\/ value used to zap vm handle area\n-const int      badResourceValue = 0xAB;                     \/\/ value used to zap resource area\n-const int      freeBlockPad     = 0xBA;                     \/\/ value used to pad freed blocks.\n-const int      uninitBlockPad   = 0xF1;                     \/\/ value used to zap newly malloc'd blocks.\n-const juint    uninitMetaWordVal= 0xf7f7f7f7;               \/\/ value used to zap newly allocated metachunk\n-const juint    badHeapWordVal   = 0xBAADBABE;               \/\/ value used to zap heap after GC\n-const juint    badMetaWordVal   = 0xBAADFADE;               \/\/ value used to zap metadata heap after GC\n-const int      badCodeHeapNewVal= 0xCC;                     \/\/ value used to zap Code heap at allocation\n+const jint     badInt             = -3;                     \/\/ generic \"bad int\" value\n+const intptr_t badAddressVal      = -2;                     \/\/ generic \"bad address\" value\n+const intptr_t badOopVal          = -1;                     \/\/ generic \"bad oop\" value\n+const intptr_t badHeapOopVal      = (intptr_t) CONST64(0x2BAD4B0BBAADBABE); \/\/ value used to zap heap after GC\n+const int      badStackSegVal     = 0xCA;                   \/\/ value used to zap stack segments\n+const int      badHandleValue     = 0xBC;                   \/\/ value used to zap vm handle area\n+const int      badResourceValue   = 0xAB;                   \/\/ value used to zap resource area\n+const int      freeBlockPad       = 0xBA;                   \/\/ value used to pad freed blocks.\n+const int      uninitBlockPad     = 0xF1;                   \/\/ value used to zap newly malloc'd blocks.\n+const juint    uninitMetaWordVal  = 0xf7f7f7f7;             \/\/ value used to zap newly allocated metachunk\n+const jubyte   heapPaddingByteVal = 0xBD;                   \/\/ value used to zap object padding in the heap\n+const juint    badHeapWordVal     = 0xBAADBABE;             \/\/ value used to zap heap after GC\n+const int      badCodeHeapNewVal  = 0xCC;                   \/\/ value used to zap Code heap at allocation\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":19,"deletions":16,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -492,0 +492,4 @@\n+#ifdef LINUX\n+  st->print_cr(\"#   This process has exceeded the maximum number of memory mappings (check below\");\n+  st->print_cr(\"#     for `\/proc\/sys\/vm\/max_map_count` and `Total number of mappings`)\");\n+#endif\n","filename":"src\/hotspot\/share\/utilities\/vmError.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -60,2 +60,2 @@\n-  \/\/ Check whether an element of a typeArrayOop with the given type must be\n-  \/\/ aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this\n+  \/\/ Check whether an element of a arrayOop with the given type must be\n+  \/\/ aligned 0 mod 8.  The arrayOop itself must be aligned at least this\n@@ -76,8 +76,1 @@\n-    if (VM.getVM().isCompactObjectHeadersEnabled()) {\n-      headerSize = lengthOffsetInBytes() + VM.getVM().getIntSize();\n-    } else if (VM.getVM().isCompressedKlassPointersEnabled()) {\n-      headerSize = typeSize;\n-    } else {\n-      headerSize = VM.getVM().alignUp(typeSize + VM.getVM().getIntSize(),\n-                                      VM.getVM().getHeapWordSize());\n-    }\n+    headerSize = lengthOffsetInBytes() + VM.getVM().getIntSize();\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Array.java","additions":4,"deletions":11,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"test\/hotspot\/gtest\/oops\/test_arrayOop.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -29,1 +29,1 @@\n- * @requires !vm.flightRecorder\n+ * @requires vm.flagless\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/plab\/TestPLABPromotion.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,157 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * @test id=with-coops-no-ccp-no-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:-UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:-UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=with-coops-with-ccp-no-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @requires vm.opt.UseCompressedClassPointers != false\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:-UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=no-coops-no-ccp-no-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:-UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:-UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=no-coops-with-ccp-no-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @requires vm.opt.UseCompressedClassPointers != false\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:+UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:-UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=with-coops-no-ccp-with-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:-UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=with-coops-with-ccp-with-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @requires vm.opt.UseCompressedClassPointers != false\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:+UseCompressedOops -XX:+UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=no-coops-no-ccp-with-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:-UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=no-coops-with-ccp-with-ucoh\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"64\"\n+ * @requires vm.opt.UseCompressedClassPointers != false\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -XX:-UseCompressedOops -XX:+UseCompressedClassPointers -XX:+UnlockExperimentalVMOptions -XX:+UseCompactObjectHeaders ArrayBaseOffsets\n+ *\/\n+\/*\n+ * @test id=32bit\n+ * @library \/test\/lib \/\n+ * @requires vm.bits == \"32\"\n+ * @modules java.base\/jdk.internal.misc\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI ArrayBaseOffsets\n+ *\/\n+\n+import jdk.internal.misc.Unsafe;\n+\n+import java.lang.management.ManagementFactory;\n+import java.lang.management.RuntimeMXBean;\n+import java.util.List;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Platform;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class ArrayBaseOffsets {\n+\n+    static final long INT_OFFSET;\n+    static final int  INT_ARRAY_OFFSET;\n+    static final int  LONG_ARRAY_OFFSET;\n+    static {\n+        WhiteBox WB = WhiteBox.getWhiteBox();\n+        if (!Platform.is64bit() || WB.getBooleanVMFlag(\"UseCompactObjectHeaders\")) {\n+            INT_OFFSET = 8;\n+            INT_ARRAY_OFFSET = 12;\n+            LONG_ARRAY_OFFSET = 16;\n+        } else if (WB.getBooleanVMFlag(\"UseCompressedClassPointers\")) {\n+            INT_OFFSET = 12;\n+            INT_ARRAY_OFFSET = 16;\n+            LONG_ARRAY_OFFSET = 16;\n+        } else {\n+            INT_OFFSET = 16;\n+            INT_ARRAY_OFFSET = 20;\n+            LONG_ARRAY_OFFSET = 24;\n+        }\n+    }\n+\n+    static public void main(String[] args) {\n+        Unsafe unsafe = Unsafe.getUnsafe();\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(boolean[].class), INT_ARRAY_OFFSET,  \"Misplaced boolean array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(byte[].class),    INT_ARRAY_OFFSET,  \"Misplaced byte    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(char[].class),    INT_ARRAY_OFFSET,  \"Misplaced char    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(short[].class),   INT_ARRAY_OFFSET,  \"Misplaced short   array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(int[].class),     INT_ARRAY_OFFSET,  \"Misplaced int     array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(long[].class),    LONG_ARRAY_OFFSET, \"Misplaced long    array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(float[].class),   INT_ARRAY_OFFSET,  \"Misplaced float   array base\");\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(double[].class),  LONG_ARRAY_OFFSET, \"Misplaced double  array base\");\n+        boolean narrowOops = System.getProperty(\"java.vm.compressedOopsMode\") != null ||\n+                             !Platform.is64bit();\n+        int expectedObjArrayOffset = narrowOops ? INT_ARRAY_OFFSET : LONG_ARRAY_OFFSET;\n+        Asserts.assertEquals(unsafe.arrayBaseOffset(Object[].class),  expectedObjArrayOffset, \"Misplaced object  array base\");\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/ArrayBaseOffsets.java","additions":157,"deletions":0,"binary":false,"changes":157,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2022, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2020, 2024, Red Hat, Inc. All rights reserved.\n@@ -317,0 +317,3 @@\n+    static final boolean CCP = WhiteBox.getWhiteBox().getBooleanVMFlag(\"UseCompressedClassPointers\");\n+    static final int ARRAY_HEADER_SIZE = CCP ? 16 : (Platform.is64bit() ? 20 : 16);\n+\n@@ -410,1 +413,1 @@\n-        long expected = roundUp(4L*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(4L*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -418,1 +421,1 @@\n-        long expected = roundUp(4L*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(4L*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -427,1 +430,1 @@\n-        long expected = roundUp(4L*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(4L*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -434,1 +437,1 @@\n-        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -442,1 +445,1 @@\n-        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -451,1 +454,1 @@\n-        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(REF_SIZE*SMALL_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -459,1 +462,1 @@\n-        long expected = roundUp(4L*LARGE_INT_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(4L*LARGE_INT_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n@@ -467,1 +470,1 @@\n-        long expected = roundUp(REF_SIZE*LARGE_OBJ_ARRAY_SIZE + 16, OBJ_ALIGN);\n+        long expected = roundUp(REF_SIZE*LARGE_OBJ_ARRAY_SIZE + ARRAY_HEADER_SIZE, OBJ_ALIGN);\n","filename":"test\/jdk\/java\/lang\/instrument\/GetObjectSizeIntrinsicsTest.java","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -50,1 +50,0 @@\n-import java.util.stream.Collectors;\n@@ -87,4 +86,0 @@\n-\n-        public void putAll(Map<String, String> map) {\n-            map.entrySet().forEach(e -> put(e.getKey(), () -> e.getValue()));\n-        }\n@@ -143,1 +138,0 @@\n-        map.putAll(xOptFlags()); \/\/ -Xmx4g -> @requires vm.opt.x.Xmx == \"4g\" )\n@@ -661,1 +655,1 @@\n-     * method to return true and allow any flags.\n+     * method to return true or false and allow or reject any flags.\n@@ -667,2 +661,3 @@\n-        if (System.getenv(\"TEST_VM_FLAGLESS\") != null) {\n-            return \"\" + result;\n+        String flagless = System.getenv(\"TEST_VM_FLAGLESS\");\n+        if (flagless != null) {\n+            return \"\" + \"true\".equalsIgnoreCase(flagless);\n@@ -726,21 +721,0 @@\n-    \/**\n-     * Parses extra options, options that start with -X excluding the\n-     * bare -X option (as it is not considered an extra option).\n-     * Ignores extra options not starting with -X\n-     *\n-     * This could be improved to handle extra options not starting\n-     * with -X as well as \"standard\" options.\n-     *\/\n-    private Map<String, String> xOptFlags() {\n-        return allFlags()\n-            .filter(s -> s.startsWith(\"-X\") && !s.startsWith(\"-XX:\") && !s.equals(\"-X\"))\n-            .map(s -> s.replaceFirst(\"-\", \"\"))\n-            .map(flag -> flag.splitWithDelimiters(\"[:0123456789]\", 2))\n-            .collect(Collectors.toMap(a -> \"vm.opt.x.\" + a[0],\n-                                      a -> (a.length == 1)\n-                                      ? \"true\" \/\/ -Xnoclassgc\n-                                      : (a[1].equals(\":\")\n-                                         ? a[2]            \/\/ [\"-XshowSettings\", \":\", \"system\"]\n-                                         : a[1] + a[2]))); \/\/ [\"-Xmx\", \"4\", \"g\"]\n-    }\n-\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":5,"deletions":31,"binary":false,"changes":36,"status":"modified"}]}