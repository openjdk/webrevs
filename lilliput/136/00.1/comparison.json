{"files":[{"patch":"@@ -2,1 +2,1 @@\n-project=jdk\n+project=lilliput\n@@ -7,1 +7,1 @@\n-error=author,committer,reviewers,merge,issues,executable,symlink,message,hg-tag,whitespace,problemlists\n+error=author,committer,reviewers,issues,executable,symlink,message,hg-tag,whitespace,problemlists\n@@ -21,4 +21,1 @@\n-[checks \"merge\"]\n-message=Merge\n-\n-reviewers=1\n+committers=1\n","filename":".jcheck\/conf","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -7127,1 +7127,1 @@\n-  predicate(!needs_acquiring_load(n));\n+  predicate(!needs_acquiring_load(n) && !UseCompactObjectHeaders);\n@@ -7137,0 +7137,14 @@\n+instruct loadNKlassCompactHeaders(iRegNNoSp dst, memory4 mem, rFlagsReg cr)\n+%{\n+  match(Set dst (LoadNKlass mem));\n+  effect(KILL cr);\n+  predicate(!needs_acquiring_load(n) && UseCompactObjectHeaders);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrw  $dst, $mem\\t# compressed class ptr\" %}\n+  ins_encode %{\n+    __ load_nklass_compact($dst$$Register, $mem$$base$$Register, $mem$$index$$Register, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -1212,1 +1214,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n@@ -2248,2 +2250,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -2310,9 +2310,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(tmp, src_klass_addr);\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(tmp, src_klass_addr);\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(src, dst, tmp, rscratch1);\n@@ -2440,3 +2432,0 @@\n-    if (UseCompressedClassPointers) {\n-      __ encode_klass_not_null(tmp);\n-    }\n@@ -2445,8 +2434,1 @@\n-\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(dst, tmp, rscratch1);\n@@ -2454,7 +2436,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, src_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, src_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(src, tmp, rscratch1);\n@@ -2463,7 +2439,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ ldrw(rscratch1, dst_klass_addr);\n-        __ cmpw(tmp, rscratch1);\n-      } else {\n-        __ ldr(rscratch1, dst_klass_addr);\n-        __ cmp(tmp, rscratch1);\n-      }\n+      __ cmp_klass(dst, tmp, rscratch1);\n@@ -2551,1 +2521,14 @@\n-    __ ldrw(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+    if (UseCompactObjectHeaders) {\n+      \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+      __ ldr(result, Address(obj, oopDesc::mark_offset_in_bytes()));\n+      if (LockingMode != LM_PLACEHOLDER) {\n+        __ tst(result, markWord::monitor_value);\n+        __ br(Assembler::NE, *op->stub()->entry());\n+        __ bind(*op->stub()->continuation());\n+      }\n+\n+      \/\/ Shift to get proper narrow Klass*.\n+      __ lsr(result, result, markWord::klass_shift);\n+    } else {\n+      __ ldrw(result, Address (obj, oopDesc::klass_offset_in_bytes()));\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":21,"deletions":38,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -188,7 +188,3 @@\n-  \/\/ This assumes that all prototype bits fit in an int32_t\n-  mov(t1, (int32_t)(intptr_t)markWord::prototype().value());\n-  str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n-\n-  if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n-    encode_klass_not_null(t1, klass);\n-    strw(t1, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  if (UseCompactObjectHeaders) {\n+    ldr(t1, Address(klass, Klass::prototype_header_offset()));\n+    str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n@@ -196,1 +192,10 @@\n-    str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    \/\/ This assumes that all prototype bits fit in an int32_t\n+    mov(t1, (int32_t)(intptr_t)markWord::prototype().value());\n+    str(t1, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+      encode_klass_not_null(t1, klass);\n+      strw(t1, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    } else {\n+      str(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+    }\n@@ -201,1 +206,1 @@\n-  } else if (UseCompressedClassPointers) {\n+  } else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n@@ -279,1 +284,1 @@\n-void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int header_size, int f, Register klass, Label& slow_case) {\n+void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int base_offset_in_bytes, int f, Register klass, Label& slow_case) {\n@@ -292,1 +297,1 @@\n-  mov(arr_size, (int32_t)header_size * BytesPerWord + MinObjAlignmentInBytesMask);\n+  mov(arr_size, (int32_t)base_offset_in_bytes + MinObjAlignmentInBytesMask);\n@@ -300,0 +305,11 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    strw(zr, Address(obj, base_offset));\n+    base_offset += BytesPerInt;\n+  }\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word-aligned\");\n+\n@@ -301,1 +317,1 @@\n-  initialize_body(obj, arr_size, header_size * BytesPerWord, t1, t2);\n+  initialize_body(obj, arr_size, base_offset, t1, t2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":28,"deletions":12,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -2832,0 +2833,31 @@\n+\n+void C2_MacroAssembler::load_nklass_compact(Register dst, Register obj, Register index, int scale, int disp) {\n+  \/\/ Note: Don't clobber obj anywhere in that method!\n+\n+  \/\/ The incoming address is pointing into obj-start + klass_offset_in_bytes. We need to extract\n+  \/\/ obj-start, so that we can load from the object's mark-word instead. Usually the address\n+  \/\/ comes as obj-start in obj and klass_offset_in_bytes in disp. However, sometimes C2\n+  \/\/ emits code that pre-computes obj-start + klass_offset_in_bytes into a register, and\n+  \/\/ then passes that register as obj and 0 in disp. The following code extracts the base\n+  \/\/ and offset to load the mark-word.\n+  int offset = oopDesc::mark_offset_in_bytes() + disp - oopDesc::klass_offset_in_bytes();\n+  if (index == noreg) {\n+    ldr(dst, Address(obj, offset));\n+  } else {\n+    lea(dst, Address(obj, index, Address::lsl(scale)));\n+    ldr(dst, Address(dst, offset));\n+  }\n+\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+    Compile::current()->output()->add_stub(stub);\n+\n+    \/\/ NOTE: We can't use tbnz here, because the target is sometimes too far away\n+    \/\/ and cannot be encoded.\n+    tst(dst, markWord::monitor_value);\n+    br(Assembler::NE, stub->entry());\n+    bind(stub->continuation());\n+  }\n+\n+  lsr(dst, dst, markWord::klass_shift);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -185,0 +185,2 @@\n+  void load_nklass_compact(Register dst, Register obj, Register index, int scale, int disp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4481,0 +4481,21 @@\n+\/\/ Loads the obj's Klass* into dst.\n+\/\/ Preserves all registers (incl src, rscratch1 and rscratch2).\n+void MacroAssembler::load_nklass(Register dst, Register src) {\n+  assert(UseCompactObjectHeaders, \"expects UseCompactObjectHeaders\");\n+\n+\n+  \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+  ldr(dst, Address(src, oopDesc::mark_offset_in_bytes()));\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    Label fast;\n+    tbz(dst, exact_log2(markWord::monitor_value), fast);\n+\n+    \/\/ Fetch displaced header\n+    ldr(dst, Address(dst, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+\n+    \/\/ Fast-path: shift and decode Klass*.\n+    bind(fast);\n+  }\n+  lsr(dst, dst, markWord::klass_shift);\n+}\n+\n@@ -4482,1 +4503,4 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(dst, src);\n+    decode_klass_not_null(dst);\n+  } else if (UseCompressedClassPointers) {\n@@ -4538,0 +4562,1 @@\n+  assert_different_registers(oop, trial_klass, tmp);\n@@ -4539,1 +4564,5 @@\n-    ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));\n+    if (UseCompactObjectHeaders) {\n+      load_nklass(tmp, oop);\n+    } else {\n+      ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));\n+    }\n@@ -4556,0 +4585,16 @@\n+void MacroAssembler::cmp_klass(Register src, Register dst, Register tmp1, Register tmp2) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass(tmp1, src);\n+    load_nklass(tmp2, dst);\n+    cmpw(tmp1, tmp2);\n+  } else if (UseCompressedClassPointers) {\n+    ldrw(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldrw(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmpw(tmp1, tmp2);\n+  } else {\n+    ldr(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    ldr(tmp2, Address(dst, oopDesc::klass_offset_in_bytes()));\n+    cmp(tmp1, tmp2);\n+  }\n+}\n+\n@@ -4559,0 +4604,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n@@ -4568,0 +4614,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":49,"deletions":2,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -867,0 +867,1 @@\n+  void load_nklass(Register dst, Register src);\n@@ -870,0 +871,1 @@\n+  void cmp_klass(Register src, Register dst, Register tmp1, Register tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -971,1 +971,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -156,1 +156,1 @@\n-                                       int header_size, int element_size,\n+                                       int header_size_in_bytes, int element_size,\n@@ -159,1 +159,0 @@\n-  const int header_size_in_bytes = header_size * BytesPerWord;\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1623,1 +1623,1 @@\n-                      arrayOopDesc::header_size(op->type()),\n+                      arrayOopDesc::base_offset_in_bytes(op->type()),\n@@ -3052,0 +3052,1 @@\n+  Register tmp2 = UseCompactObjectHeaders ? rscratch2 : noreg;\n@@ -3176,2 +3177,0 @@\n-  Address src_klass_addr = Address(src, oopDesc::klass_offset_in_bytes());\n-  Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3243,7 +3242,1 @@\n-      if (UseCompressedClassPointers) {\n-        __ movl(tmp, src_klass_addr);\n-        __ cmpl(tmp, dst_klass_addr);\n-      } else {\n-        __ movptr(tmp, src_klass_addr);\n-        __ cmpptr(tmp, dst_klass_addr);\n-      }\n+      __ cmp_klass(src, dst, tmp, tmp2);\n@@ -3308,0 +3301,1 @@\n+        Address dst_klass_addr = Address(dst, oopDesc::klass_offset_in_bytes());\n@@ -3409,4 +3403,1 @@\n-\n-\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);\n-      else                   __ cmpptr(tmp, dst_klass_addr);\n+      __ cmp_klass(tmp, dst, tmp2);\n@@ -3415,2 +3406,1 @@\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, src_klass_addr);\n-      else                   __ cmpptr(tmp, src_klass_addr);\n+      __ cmp_klass(tmp, src, tmp2);\n@@ -3419,2 +3409,1 @@\n-      if (UseCompressedClassPointers)          __ cmpl(tmp, dst_klass_addr);\n-      else                   __ cmpptr(tmp, dst_klass_addr);\n+      __ cmp_klass(tmp, dst, tmp2);\n@@ -3516,1 +3505,16 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    Register tmp = rscratch1;\n+    assert_different_registers(tmp, obj);\n+    assert_different_registers(tmp, result);\n+\n+    \/\/ Check if we can take the (common) fast path, if obj is unlocked.\n+    __ movq(result, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    if (LockingMode != LM_PLACEHOLDER) {\n+      __ testb(result, markWord::monitor_value);\n+      __ jcc(Assembler::notZero, *op->stub()->entry());\n+      __ bind(*op->stub()->continuation());\n+    }\n+    \/\/ Fast-path: shift and decode Klass*.\n+    __ shrq(result, markWord::klass_shift);\n+    __ decode_klass_not_null(result, tmp);\n+  } else if (UseCompressedClassPointers) {\n@@ -3521,0 +3525,1 @@\n+  {\n@@ -3522,0 +3527,1 @@\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":25,"deletions":19,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -196,2 +196,1 @@\n-  assert_different_registers(obj, klass, len);\n-  movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n+  assert_different_registers(obj, klass, len, t1, t2);\n@@ -199,1 +198,5 @@\n-  if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+  if (UseCompactObjectHeaders) {\n+    movptr(t1, Address(klass, Klass::prototype_header_offset()));\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), t1);\n+  } else if (UseCompressedClassPointers) { \/\/ Take care not to kill klass\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n@@ -206,0 +209,1 @@\n+    movptr(Address(obj, oopDesc::mark_offset_in_bytes()), checked_cast<int32_t>(markWord::prototype().value()));\n@@ -208,1 +212,0 @@\n-\n@@ -213,1 +216,1 @@\n-  else if (UseCompressedClassPointers) {\n+  else if (UseCompressedClassPointers && !UseCompactObjectHeaders) {\n@@ -247,1 +250,3 @@\n-\n+  if (UseCompactObjectHeaders) {\n+    assert(hdr_size_in_bytes == 8, \"check object headers size\");\n+  }\n@@ -294,1 +299,1 @@\n-void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int header_size, Address::ScaleFactor f, Register klass, Label& slow_case) {\n+void C1_MacroAssembler::allocate_array(Register obj, Register len, Register t1, Register t2, int base_offset_in_bytes, Address::ScaleFactor f, Register klass, Label& slow_case) {\n@@ -307,1 +312,1 @@\n-  movptr(arr_size, header_size * BytesPerWord + MinObjAlignmentInBytesMask);\n+  movptr(arr_size, (int32_t)base_offset_in_bytes + MinObjAlignmentInBytesMask);\n@@ -315,0 +320,13 @@\n+  \/\/ Clear leading 4 bytes, if necessary.\n+  \/\/ TODO: This could perhaps go into initialize_body() and also clear the leading 4 bytes\n+  \/\/ for non-array objects, thereby replacing the klass-gap clearing code in initialize_header().\n+  int base_offset = base_offset_in_bytes;\n+#ifdef _LP64\n+  if (!is_aligned(base_offset, BytesPerWord)) {\n+    assert(is_aligned(base_offset, BytesPerInt), \"must be 4-byte aligned\");\n+    movl(Address(obj, base_offset), 0);\n+    base_offset += BytesPerInt;\n+  }\n+#endif\n+  assert(is_aligned(base_offset, BytesPerWord), \"must be word aligned\");\n+\n@@ -317,1 +335,1 @@\n-  initialize_body(obj, arr_size, header_size * BytesPerWord, len_zero);\n+  initialize_body(obj, arr_size, base_offset, len_zero);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":27,"deletions":9,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -150,0 +150,13 @@\n+#ifdef _LP64\n+int C2LoadNKlassStub::max_size() const {\n+  return 10;\n+}\n+\n+void C2LoadNKlassStub::emit(C2_MacroAssembler& masm) {\n+  __ bind(entry());\n+  Register d = dst();\n+  __ movq(d, Address(d, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+  __ jmp(continuation());\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -6812,0 +6812,25 @@\n+\n+#ifdef _LP64\n+void C2_MacroAssembler::load_nklass_compact_c2(Register dst, Register obj, Register index, Address::ScaleFactor scale, int disp) {\n+  \/\/ Note: Don't clobber obj anywhere in that method!\n+\n+  \/\/ The incoming address is pointing into obj-start + klass_offset_in_bytes. We need to extract\n+  \/\/ obj-start, so that we can load from the object's mark-word instead. Usually the address\n+  \/\/ comes as obj-start in obj and klass_offset_in_bytes in disp. However, sometimes C2\n+  \/\/ emits code that pre-computes obj-start + klass_offset_in_bytes into a register, and\n+  \/\/ then passes that register as obj and 0 in disp. The following code extracts the base\n+  \/\/ and offset to load the mark-word.\n+  int offset = oopDesc::mark_offset_in_bytes() + disp - oopDesc::klass_offset_in_bytes();\n+  movq(dst, Address(obj, index, scale, offset));\n+\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+    Compile::current()->output()->add_stub(stub);\n+\n+    testb(dst, markWord::monitor_value);\n+    jcc(Assembler::notZero, stub->entry());\n+    bind(stub->continuation());\n+  }\n+  shrq(dst, markWord::klass_shift);\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -507,0 +507,2 @@\n+  void load_nklass_compact_c2(Register dst, Register obj, Register index, Address::ScaleFactor scale, int disp);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5328,0 +5328,19 @@\n+#ifdef _LP64\n+void MacroAssembler::load_nklass_compact(Register dst, Register src) {\n+  assert(UseCompactObjectHeaders, \"expect compact object headers\");\n+\n+  Label fast;\n+  movq(dst, Address(src, oopDesc::mark_offset_in_bytes()));\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    testb(dst, markWord::monitor_value);\n+    jccb(Assembler::zero, fast);\n+\n+    \/\/ Fetch displaced header\n+    movq(dst, Address(dst, OM_OFFSET_NO_MONITOR_VALUE_TAG(header)));\n+\n+    bind(fast);\n+  }\n+  shrq(dst, markWord::klass_shift);\n+}\n+#endif\n+\n@@ -5332,1 +5351,4 @@\n-  if (UseCompressedClassPointers) {\n+  if (UseCompactObjectHeaders) {\n+    load_nklass_compact(dst, src);\n+    decode_klass_not_null(dst, tmp);\n+  } else if (UseCompressedClassPointers) {\n@@ -5337,0 +5359,1 @@\n+  {\n@@ -5338,0 +5361,1 @@\n+  }\n@@ -5341,0 +5365,1 @@\n+  assert(!UseCompactObjectHeaders, \"not with compact headers\");\n@@ -5352,0 +5377,33 @@\n+void MacroAssembler::cmp_klass(Register klass, Register obj, Register tmp) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    load_nklass_compact(tmp, obj);\n+    cmpl(klass, tmp);\n+  } else if (UseCompressedClassPointers) {\n+    cmpl(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  } else\n+#endif\n+  {\n+    cmpptr(klass, Address(obj, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n+void MacroAssembler::cmp_klass(Register src, Register dst, Register tmp1, Register tmp2) {\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    assert(tmp2 != noreg, \"need tmp2\");\n+    assert_different_registers(src, dst, tmp1, tmp2);\n+    load_nklass_compact(tmp1, src);\n+    load_nklass_compact(tmp2, dst);\n+    cmpl(tmp1, tmp2);\n+  } else if (UseCompressedClassPointers) {\n+    movl(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    cmpl(tmp1, Address(dst, oopDesc::klass_offset_in_bytes()));\n+  } else\n+#endif\n+  {\n+    movptr(tmp1, Address(src, oopDesc::klass_offset_in_bytes()));\n+    cmpptr(tmp1, Address(dst, oopDesc::klass_offset_in_bytes()));\n+  }\n+}\n+\n@@ -5399,0 +5457,1 @@\n+  assert(!UseCompactObjectHeaders, \"Don't use with compact headers\");\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":60,"deletions":1,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -367,0 +367,3 @@\n+#ifdef _LP64\n+  void load_nklass_compact(Register dst, Register src);\n+#endif\n@@ -370,0 +373,8 @@\n+  \/\/ Compares the Klass pointer of an object to a given Klass (which might be narrow,\n+  \/\/ depending on UseCompressedClassPointers).\n+  void cmp_klass(Register klass, Register dst, Register tmp);\n+\n+  \/\/ Compares the Klass pointer of two objects o1 and o2. Result is in the condition flags.\n+  \/\/ Uses t1 and t2 as temporary registers.\n+  void cmp_klass(Register src, Register dst, Register tmp1, Register tmp2);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -4410,0 +4410,1 @@\n+  predicate(!UseCompactObjectHeaders);\n@@ -4420,0 +4421,15 @@\n+instruct loadNKlassCompactHeaders(rRegN dst, memory mem, rFlagsReg cr)\n+%{\n+  predicate(UseCompactObjectHeaders);\n+  match(Set dst (LoadNKlass mem));\n+  effect(KILL cr);\n+  ins_cost(125); \/\/ XXX\n+  format %{ \"movl    $dst, $mem\\t# compressed klass ptr\" %}\n+  ins_encode %{\n+    Register index = $mem$$index != 4 ? $mem$$index$$Register : noreg;\n+    Address::ScaleFactor sf = (index != noreg) ? static_cast<Address::ScaleFactor>($mem$$scale) : Address::no_scale;\n+    __ load_nklass_compact_c2($dst$$Register, $mem$$base$$Register, index, sf, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow); \/\/ XXX\n+%}\n+\n@@ -11740,0 +11756,1 @@\n+  predicate(!UseCompactObjectHeaders);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -207,0 +207,1 @@\n+  _compact_headers = UseCompactObjectHeaders;\n@@ -273,0 +274,1 @@\n+  st->print_cr(\"- compact_headers:                %d\", _compact_headers);\n@@ -1999,1 +2001,1 @@\n-  \/\/ ArchiveHeapWriter::precomputed_narrow_klass_shift. We enforce this encoding at runtime (see\n+  \/\/ ArchiveBuilder::precomputed_narrow_klass_shift. We enforce this encoding at runtime (see\n@@ -2003,1 +2005,1 @@\n-  const int archive_narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+  const int archive_narrow_klass_shift = ArchiveBuilder::precomputed_narrow_klass_shift;\n@@ -2392,0 +2394,8 @@\n+  if (compact_headers() != UseCompactObjectHeaders) {\n+    log_info(cds)(\"The shared archive file's UseCompactObjectHeaders setting (%s)\"\n+                  \" does not equal the current UseCompactObjectHeaders setting (%s).\",\n+                  _compact_headers          ? \"enabled\" : \"disabled\",\n+                  UseCompactObjectHeaders   ? \"enabled\" : \"disabled\");\n+    return false;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n-  static const int first_vtableStub_size =  64;\n+  static const int first_vtableStub_size = 64;\n","filename":"src\/hotspot\/share\/code\/vtableStubs.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -89,0 +89,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -1443,0 +1444,2 @@\n+  SlidingForwarding::initialize(heap_rs.region(), HeapRegion::GrainWords);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -236,1 +236,2 @@\n-void MutableSpace::object_iterate(ObjectClosure* cl) {\n+template<bool COMPACT_HEADERS>\n+void MutableSpace::object_iterate_impl(ObjectClosure* cl) {\n@@ -245,3 +246,2 @@\n-    }\n-#ifdef ASSERT\n-    else {\n+      p += obj->size();\n+    } else {\n@@ -249,0 +249,8 @@\n+      if (COMPACT_HEADERS) {\n+        \/\/ It is safe to use the forwardee here. Parallel GC only uses\n+        \/\/ header-based forwarding during promotion. Full GC doesn't\n+        \/\/ use the object header for forwarding at all.\n+        p += obj->forwardee()->size();\n+      } else {\n+        p += obj->size();\n+      }\n@@ -250,2 +258,8 @@\n-#endif\n-    p += obj->size();\n+  }\n+}\n+\n+void MutableSpace::object_iterate(ObjectClosure* cl) {\n+  if (UseCompactObjectHeaders) {\n+    object_iterate_impl<true>(cl);\n+  } else {\n+    object_iterate_impl<false>(cl);\n","filename":"src\/hotspot\/share\/gc\/parallel\/mutableSpace.cpp","additions":20,"deletions":6,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -810,1 +810,1 @@\n-        obj->init_mark();\n+        obj->forward_safe_init_mark();\n@@ -834,1 +834,1 @@\n-  old->forward_to(old);\n+  old->forward_to_self();\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -198,0 +199,1 @@\n+  template <bool ALT_FWD>\n@@ -201,1 +203,1 @@\n-      obj->forward_to(cast_to_oop(new_addr));\n+      SlidingForwarding::forward_to<ALT_FWD>(obj, cast_to_oop(new_addr));\n@@ -221,0 +223,1 @@\n+  template <bool ALT_FWD>\n@@ -226,1 +229,1 @@\n-    oop new_obj = obj->forwardee();\n+    oop new_obj = SlidingForwarding::forwardee<ALT_FWD>(obj);\n@@ -255,0 +258,1 @@\n+  template <bool ALT_FWD>\n@@ -270,1 +274,1 @@\n-          forward_obj(obj, new_addr);\n+          forward_obj<ALT_FWD>(obj, new_addr);\n@@ -295,0 +299,9 @@\n+  void phase2_calculate_new_addr() {\n+    if (UseAltGCForwarding) {\n+      phase2_calculate_new_addr<true>();\n+    } else {\n+      phase2_calculate_new_addr<false>();\n+    }\n+  }\n+\n+  template <bool ALT_FWD>\n@@ -305,1 +318,1 @@\n-          size_t size = MarkSweep::adjust_pointers(cast_to_oop(cur_addr));\n+          size_t size = MarkSweep::adjust_pointers<ALT_FWD>(cast_to_oop(cur_addr));\n@@ -315,0 +328,9 @@\n+  void phase3_adjust_pointers() {\n+    if (UseAltGCForwarding) {\n+      phase3_adjust_pointers<true>();\n+    } else {\n+      phase3_adjust_pointers<false>();\n+    }\n+  }\n+\n+  template <bool ALT_FWD>\n@@ -322,1 +344,1 @@\n-      if (!cast_to_oop(cur_addr)->is_forwarded()) {\n+      if (SlidingForwarding::is_not_forwarded(cast_to_oop(cur_addr))) {\n@@ -328,1 +350,1 @@\n-        if (!cast_to_oop(cur_addr)->is_forwarded()) {\n+        if (SlidingForwarding::is_not_forwarded(cast_to_oop(cur_addr))) {\n@@ -332,1 +354,1 @@\n-        cur_addr += relocate(cur_addr);\n+        cur_addr += relocate<ALT_FWD>(cur_addr);\n@@ -342,0 +364,8 @@\n+\n+  void phase4_compact() {\n+    if (UseAltGCForwarding) {\n+      phase4_compact<true>();\n+    } else {\n+      phase4_compact<false>();\n+    }\n+  }\n@@ -451,0 +481,2 @@\n+  SlidingForwarding::begin();\n+\n@@ -472,8 +504,23 @@\n-    CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n-    gch->process_roots(SerialHeap::SO_AllCodeCache,\n-                       &adjust_pointer_closure,\n-                       &adjust_cld_closure,\n-                       &adjust_cld_closure,\n-                       &code_closure);\n-\n-    WeakProcessor::oops_do(&adjust_pointer_closure);\n+    if (UseAltGCForwarding) {\n+      AdjustPointerClosure<true> adjust_pointer_closure;\n+      CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+      CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+      gch->process_roots(SerialHeap::SO_AllCodeCache,\n+                         &adjust_pointer_closure,\n+                         &adjust_cld_closure,\n+                         &adjust_cld_closure,\n+                         &code_closure);\n+\n+      WeakProcessor::oops_do(&adjust_pointer_closure);\n+    } else {\n+      AdjustPointerClosure<false> adjust_pointer_closure;\n+      CLDToOopClosure adjust_cld_closure(&adjust_pointer_closure, ClassLoaderData::_claim_stw_fullgc_adjust);\n+      CodeBlobToOopClosure code_closure(&adjust_pointer_closure, CodeBlobToOopClosure::FixRelocations);\n+      gch->process_roots(SerialHeap::SO_AllCodeCache,\n+                         &adjust_pointer_closure,\n+                         &adjust_cld_closure,\n+                         &adjust_cld_closure,\n+                         &code_closure);\n+\n+      WeakProcessor::oops_do(&adjust_pointer_closure);\n+    }\n@@ -492,0 +539,2 @@\n+  SlidingForwarding::end();\n+\n","filename":"src\/hotspot\/share\/gc\/serial\/genMarkSweep.cpp","additions":64,"deletions":15,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -58,0 +58,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -206,0 +207,2 @@\n+  SlidingForwarding::initialize(_reserved, SpaceAlignment \/ HeapWordSize);\n+\n","filename":"src\/hotspot\/share\/gc\/serial\/serialHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -232,1 +232,3 @@\n-  if (!Metaspace::contains(object->klass_raw())) {\n+  \/\/ With compact headers, we can't safely access the class, due\n+  \/\/ to possibly forwarded objects.\n+  if (!UseCompactObjectHeaders && !Metaspace::contains(object->klass_raw())) {\n@@ -405,0 +407,7 @@\n+\/\/ Returns the header size in words aligned to the requirements of the\n+\/\/ array object type.\n+static int int_array_header_size() {\n+  size_t typesize_in_bytes = arrayOopDesc::header_size_in_bytes();\n+  return (int)align_up(typesize_in_bytes, HeapWordSize)\/HeapWordSize;\n+}\n+\n@@ -414,1 +423,1 @@\n-  size_t max_int_size = typeArrayOopDesc::header_size(T_INT) +\n+  size_t max_int_size = int_array_header_size() +\n@@ -421,1 +430,1 @@\n-  return align_object_offset(arrayOopDesc::header_size(T_INT)); \/\/ align to Long\n+  return align_object_offset(int_array_header_size()); \/\/ align to Long\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.cpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -314,1 +314,1 @@\n-  static constexpr size_t min_dummy_object_size() {\n+  static size_t min_dummy_object_size() {\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -441,0 +442,2 @@\n+  SlidingForwarding::initialize(_heap_region, ShenandoahHeapRegion::region_size_words());\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -440,1 +440,5 @@\n-  if (offset == oopDesc::klass_offset_in_bytes()) {\n+\n+  \/\/ With compact object headers, we can test for the explicit offset within\n+  \/\/ the header to figure out if compiler code is accessing the class.\n+  int klass_offset = UseCompactObjectHeaders ? 4 : oopDesc::klass_offset_in_bytes();\n+  if (offset == klass_offset) {\n@@ -2445,1 +2449,1 @@\n-  return arrayOopDesc::header_size(type) * HeapWordSize;\n+  return arrayOopDesc::base_offset_in_bytes(type);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -325,2 +325,7 @@\n-  assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n-         \"Klass offset is expected to be less than the page size\");\n+  if (UseCompactObjectHeaders) {\n+    assert(oopDesc::mark_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Mark offset is expected to be less than the page size\");\n+  } else {\n+    assert(oopDesc::klass_offset_in_bytes() < static_cast<intptr_t>(os::vm_page_size()),\n+           \"Klass offset is expected to be less than the page size\");\n+  }\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -133,0 +133,10 @@\n+\n+class C2LoadNKlassStub : public C2CodeStub {\n+private:\n+  Register _dst;\n+public:\n+  C2LoadNKlassStub(Register dst) : C2CodeStub(), _dst(dst) {}\n+  Register dst() { return _dst; }\n+  int max_size() const;\n+  void emit(C2_MacroAssembler& masm);\n+};\n","filename":"src\/hotspot\/share\/opto\/c2_CodeStubs.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1620,2 +1620,8 @@\n-  \/\/ For now only enable fast locking for non-array types\n-  mark_node = phase->MakeConX(markWord::prototype().value());\n+  if (UseCompactObjectHeaders) {\n+    Node* klass_node = in(AllocateNode::KlassNode);\n+    Node* proto_adr = phase->transform(new AddPNode(klass_node, klass_node, phase->MakeConX(in_bytes(Klass::prototype_header_offset()))));\n+    mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n+  } else {\n+    \/\/ For now only enable fast locking for non-array types\n+    mark_node = phase->MakeConX(markWord::prototype().value());\n+  }\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1717,0 +1717,4 @@\n+      if (UseCompactObjectHeaders) {\n+        if (flat->offset() == in_bytes(Klass::prototype_header_offset()))\n+          alias_type(idx)->set_rewritable(false);\n+      }\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4595,2 +4595,2 @@\n-  Node *hash_mask      = _gvn.intcon(markWord::hash_mask);\n-  Node *hash_shift     = _gvn.intcon(markWord::hash_shift);\n+  Node *hash_mask      = _gvn.intcon(UseCompactObjectHeaders ? markWord::hash_mask_compact  : markWord::hash_mask);\n+  Node *hash_shift     = _gvn.intcon(UseCompactObjectHeaders ? markWord::hash_shift_compact : markWord::hash_shift);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1704,1 +1704,4 @@\n-  rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  if (!UseCompactObjectHeaders) {\n+    rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -322,3 +322,2 @@\n-    const size_t hs = arrayOopDesc::header_size(elem_type);\n-    \/\/ Align to next 8 bytes to avoid trashing arrays's length.\n-    const size_t aligned_hs = align_object_offset(hs);\n+    size_t hs_bytes = arrayOopDesc::base_offset_in_bytes(elem_type);\n+    assert(is_aligned(hs_bytes, BytesPerInt), \"must be 4 byte aligned\");\n@@ -326,2 +325,3 @@\n-    if (aligned_hs > hs) {\n-      Copy::zero_to_words(obj+hs, aligned_hs-hs);\n+    if (!is_aligned(hs_bytes, BytesPerLong)) {\n+      *reinterpret_cast<jint*>(reinterpret_cast<char*>(obj) + hs_bytes) = 0;\n+      hs_bytes += BytesPerInt;\n@@ -329,0 +329,1 @@\n+\n@@ -330,0 +331,2 @@\n+    assert(is_aligned(hs_bytes, BytesPerLong), \"must be 8-byte aligned\");\n+    const size_t aligned_hs = hs_bytes \/ BytesPerLong;\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2954,0 +2954,22 @@\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders && UseZGC && !ZGenerational) {\n+    if (FLAG_IS_CMDLINE(UseCompactObjectHeaders)) {\n+      warning(\"Single-generational ZGC does not work with compact object headers, disabling UseCompactObjectHeaders\");\n+    }\n+    FLAG_SET_DEFAULT(UseCompactObjectHeaders, false);\n+  }\n+  if (UseCompactObjectHeaders && FLAG_IS_CMDLINE(UseCompressedClassPointers) && !UseCompressedClassPointers) {\n+    warning(\"Compact object headers require compressed class pointers. Disabling compact object headers.\");\n+    FLAG_SET_DEFAULT(UseCompactObjectHeaders, false);\n+  }\n+  if (UseCompactObjectHeaders && LockingMode == LM_LEGACY) {\n+    FLAG_SET_DEFAULT(LockingMode, LM_LIGHTWEIGHT);\n+  }\n+  if (UseCompactObjectHeaders && !UseAltGCForwarding) {\n+    FLAG_SET_DEFAULT(UseAltGCForwarding, true);\n+  }\n+  if (UseCompactObjectHeaders && !UseCompressedClassPointers) {\n+    FLAG_SET_DEFAULT(UseCompressedClassPointers, true);\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -133,0 +133,3 @@\n+  product(bool, UseCompactObjectHeaders, false, EXPERIMENTAL,               \\\n+          \"Use compact 64-bit object headers in 64-bit VM\")                 \\\n+                                                                            \\\n@@ -150,0 +153,1 @@\n+const bool UseCompactObjectHeaders = false;\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -223,0 +223,1 @@\n+  static ByteSize header_offset()      { return byte_offset_of(ObjectMonitor, _header); }\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1067,1 +1067,1 @@\n-  value &= markWord::hash_mask;\n+  value &= UseCompactObjectHeaders ? markWord::hash_mask_compact : markWord::hash_mask;\n@@ -1513,0 +1513,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"placeholder does not use inflate\");\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -117,0 +117,3 @@\n+#if INCLUDE_VM_STRUCTS\n+#include \"runtime\/vmStructs.hpp\"\n+#endif\n@@ -503,0 +506,7 @@\n+  \/\/ Should happen before any agent attaches and pokes into vmStructs\n+#if INCLUDE_VM_STRUCTS\n+  if (UseCompactObjectHeaders) {\n+    VMStructs::compact_headers_overrides();\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -150,0 +150,10 @@\n+\/\/ Used by VMStructs when CompactObjectHeaders are enabled.\n+\/\/ Must match the relevant parts from the real oopDesc.\n+class fakeOopDesc {\n+private:\n+  union _metadata {\n+    Klass*      _klass;\n+    narrowKlass _compressed_klass;\n+  } _metadata;\n+};\n+\n@@ -1159,0 +1169,2 @@\n+  declare_toplevel_type(fakeOopDesc)                                      \\\n+                                                                          \\\n@@ -2513,0 +2525,1 @@\n+  declare_constant(markWord::hash_bits_compact)                           \\\n@@ -2517,0 +2530,2 @@\n+  declare_constant(markWord::hash_shift_compact)                          \\\n+  LP64_ONLY(declare_constant(markWord::klass_shift))                      \\\n@@ -2524,0 +2539,2 @@\n+  declare_constant(markWord::hash_mask_compact)                           \\\n+  declare_constant(markWord::hash_mask_compact_in_place)                  \\\n@@ -3060,0 +3077,26 @@\n+\n+void VMStructs::compact_headers_overrides() {\n+  assert(UseCompactObjectHeaders, \"Should have been checked before\");\n+\n+  \/\/ We cannot allow SA and other facilities to poke into VM internal fields\n+  \/\/ expecting the class pointers there. This will crash in the best case,\n+  \/\/ or yield incorrect execution in the worst case. This code hides the\n+  \/\/ risky fields from external code by replacing their original container\n+  \/\/ type to a fake one. The fake type should exist for VMStructs verification\n+  \/\/ code to work.\n+\n+  size_t len = localHotSpotVMStructsLength();\n+  for (size_t off = 0; off < len; off++) {\n+    VMStructEntry* e = &localHotSpotVMStructs[off];\n+    if (e == nullptr) continue;\n+    if (e->typeName == nullptr) continue;\n+    if (e->fieldName == nullptr) continue;\n+\n+    if (strcmp(e->typeName, \"oopDesc\") == 0) {\n+      if ((strcmp(e->fieldName, \"_metadata._klass\") == 0) ||\n+          (strcmp(e->fieldName, \"_metadata._compressed_klass\") == 0)) {\n+        e->typeName = \"fakeOopDesc\";\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":43,"deletions":0,"binary":false,"changes":43,"status":"modified"}]}