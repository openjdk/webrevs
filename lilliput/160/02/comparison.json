{"files":[{"patch":"@@ -761,10 +761,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      \/\/ TODO[OMWorld]: Clean this monitorenter_obj up. We still want to use the lock_reg for lightweight\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-              obj_reg);\n-    } else {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-              lock_reg);\n-    }\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+            lock_reg);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":3,"deletions":10,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -993,9 +993,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      \/\/ Pass oop, not lock, in fast lock case. call_VM wants R1 though.\n-      push(R1);\n-      mov(R1, Robj);\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj), R1);\n-      pop(R1);\n-    } else {\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n-    }\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n","filename":"src\/hotspot\/cpu\/arm\/interp_masm_arm.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1048,5 +1048,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj), object);\n-    } else {\n-      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-    }\n+    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -802,9 +802,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-              obj_reg);\n-    } else {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-              lock_reg);\n-    }\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+            lock_reg);\n","filename":"src\/hotspot\/cpu\/riscv\/interp_masm_riscv.cpp","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1081,10 +1081,3 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n-    \/\/ for lightweight locking we need to use monitorenter_obj, see interpreterRuntime.cpp\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-            object);\n-  } else {\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            monitor);\n-  }\n+  call_VM(noreg,\n+          CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+          monitor);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":3,"deletions":10,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"utilities\/macros.hpp\"\n@@ -69,0 +70,1 @@\n+    lightweight_lock(disp_hdr, obj, hdr, thread, tmp, slow_case);\n@@ -70,1 +72,3 @@\n-    const Register thread = disp_hdr;\n+    movptr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+    jmp(slow_case);\n@@ -72,1 +76,0 @@\n-    lightweight_lock(disp_hdr, obj, hdr, thread, tmp, slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1211,6 +1211,0 @@\n-#ifndef _LP64\n-        \/\/ TODO[OMWorld]: Unify 32 with 64. Should just be a straight up use 64 on 32. We have the registers here.\n-        \/\/ Check if recursive.\n-        xorptr(reg_rax, reg_rax);\n-        orptr(reg_rax, Address(monitor, ObjectMonitor::recursions_offset()));\n-        jcc(Assembler::notZero, check_successor);\n@@ -1218,4 +1212,1 @@\n-        \/\/ Check if the entry lists are empty.\n-        movptr(reg_rax, Address(monitor, ObjectMonitor::EntryList_offset()));\n-        orptr(reg_rax, Address(monitor, ObjectMonitor::cxq_offset()));\n-        jcc(Assembler::notZero, check_successor);\n+      Label recursive;\n@@ -1223,4 +1214,3 @@\n-        \/\/ Release lock.\n-        movptr(Address(monitor, ObjectMonitor::owner_offset()), NULL_WORD);\n-#else \/\/ _LP64\n-        Label recursive;\n+      \/\/ Check if recursive.\n+      cmpptr(Address(monitor,ObjectMonitor::recursions_offset()), 0);\n+      jccb(Assembler::notEqual, recursive);\n@@ -1228,18 +1218,13 @@\n-        \/\/ Check if recursive.\n-        cmpptr(Address(monitor,ObjectMonitor::recursions_offset()),0);\n-        jccb(Assembler::notEqual, recursive);\n-\n-        \/\/ Check if the entry lists are empty.\n-        movptr(reg_rax, Address(monitor, ObjectMonitor::cxq_offset()));\n-        orptr(reg_rax, Address(monitor, ObjectMonitor::EntryList_offset()));\n-        jcc(Assembler::notZero, check_successor);\n-\n-        \/\/ Release lock.\n-        movptr(Address(monitor, ObjectMonitor::owner_offset()), NULL_WORD);\n-        jmpb(unlocked);\n-\n-        \/\/ Recursive unlock.\n-        bind(recursive);\n-        decrement(Address(monitor, ObjectMonitor::recursions_offset()));\n-        xorl(t, t);\n-#endif\n+      \/\/ Check if the entry lists are empty.\n+      movptr(reg_rax, Address(monitor, ObjectMonitor::cxq_offset()));\n+      orptr(reg_rax, Address(monitor, ObjectMonitor::EntryList_offset()));\n+      jcc(Assembler::notZero, check_successor);\n+\n+      \/\/ Release lock.\n+      movptr(Address(monitor, ObjectMonitor::owner_offset()), NULL_WORD);\n+      jmpb(unlocked);\n+\n+      \/\/ Recursive unlock.\n+      bind(recursive);\n+      decrement(Address(monitor, ObjectMonitor::recursions_offset()));\n+      xorl(t, t);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":17,"deletions":32,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -1191,0 +1191,1 @@\n+      lightweight_lock(lock_reg, obj_reg, swap_reg, thread, tmp_reg, slow_case);\n@@ -1192,1 +1193,2 @@\n-      const Register thread = lock_reg;\n+      \/\/ Lacking registers and thread on x86_32. Always take slow path.\n+      jmp(slow_case);\n@@ -1194,1 +1196,0 @@\n-      lightweight_lock(lock_reg, obj_reg, swap_reg, thread, tmp_reg, slow_case);\n@@ -1256,10 +1257,3 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n-      \/\/ TODO[OMWorld]: Clean this monitorenter_obj up. We still want to use the lock_reg for lightweight\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n-              obj_reg);\n-    } else {\n-      call_VM(noreg,\n-              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-              lock_reg);\n-    }\n+    call_VM(noreg,\n+            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+            lock_reg);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":6,"deletions":12,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -761,3 +761,2 @@\n-  const bool no_lock = NOT_LP64(LockingMode == LM_LIGHTWEIGHT) LP64_ONLY(false);\n-  assert(no_lock || obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, no_lock ? nullptr : lock->lock(), current);\n+  assert(obj == lock->obj(), \"must match: \" PTR_FORMAT, p2i(lock));\n+  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -738,1 +738,0 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Should call monitorenter_obj() when using the new lightweight locking\");\n@@ -753,17 +752,0 @@\n-\/\/ NOTE: We provide a separate implementation for the new lightweight locking to workaround a limitation\n-\/\/ of registers in x86_32. This entry point accepts an oop instead of a BasicObjectLock*.\n-\/\/ The problem is that we would need to preserve the register that holds the BasicObjectLock,\n-\/\/ but we are using that register to hold the thread. We don't have enough registers to\n-\/\/ also keep the BasicObjectLock, but we don't really need it anyway, we only need\n-\/\/ the object. See also InterpreterMacroAssembler::lock_object().\n-\/\/ As soon as legacy stack-locking goes away we could remove the other monitorenter() entry\n-\/\/ point, and only use oop-accepting entries (same for monitorexit() below).\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter_obj(JavaThread* current, oopDesc* obj))\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Should call monitorenter() when not using the new lightweight locking\");\n-  Handle h_obj(current, cast_to_oop(obj));\n-  assert(Universe::heap()->is_in_or_null(h_obj()),\n-         \"must be null or an object\");\n-  ObjectSynchronizer::enter(h_obj, nullptr, current);\n-  return;\n-JRT_END\n-\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":0,"deletions":18,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -527,3 +527,1 @@\n-      if (_lock != nullptr) {\n-        _lock->set_displaced_header(_monitor);\n-      }\n+      _lock->set_displaced_header(_monitor);\n@@ -531,3 +529,1 @@\n-      if (_lock != nullptr) {\n-        _lock->clear_displaced_header();\n-      }\n+      _lock->clear_displaced_header();\n","filename":"src\/hotspot\/share\/runtime\/lightweightSynchronizer.cpp","additions":2,"deletions":6,"binary":false,"changes":8,"status":"modified"}]}