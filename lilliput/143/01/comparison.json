{"files":[{"patch":"@@ -16436,1 +16436,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER);\n@@ -16452,1 +16452,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER);\n@@ -16497,0 +16497,31 @@\n+instruct cmpFastLockPlaceholder(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2, iRegPNoSp tmp3)\n+%{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP tmp2, TEMP tmp3);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastlock $object,$box\\t! kills $tmp,$tmp2,$tmp3\" %}\n+\n+  ins_encode %{\n+    __ fast_lock_placeholder($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register, $tmp3$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n+\n+instruct cmpFastUnlockPlaceholder(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)\n+%{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, TEMP tmp2);\n+\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"fastunlock $object,$box\\t! kills $tmp, $tmp2\" %}\n+\n+  ins_encode %{\n+    __ fast_unlock_placeholder($object$$Register, $box$$Register, $tmp$$Register, $tmp2$$Register);\n+  %}\n+\n+  ins_pipe(pipe_serial);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":33,"deletions":2,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -81,0 +83,3 @@\n+  } else if (LockingMode == LM_PLACEHOLDER) {\n+    \/\/ null check obj. load_klass performs load if DiagnoseSyncOnValueBasedClasses != 0.\n+    ldr(hdr, Address(obj));\n@@ -83,1 +88,4 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    str(zr, Address(disp_hdr, BasicObjectLock::lock_offset() + in_ByteSize((BasicLock::displaced_header_offset_in_bytes()))));\n+    placeholder_lock(obj, hdr, temp, rscratch2, slow_case);\n+  } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -134,1 +142,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n+  if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER) {\n@@ -146,1 +154,3 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    placeholder_unlock(obj, hdr, temp, rscratch2, slow_case);\n+  } else if (LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"uses fast_lock_placeholder\");\n@@ -466,0 +467,356 @@\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with Flags == EQ.\n+  Label flag_correct;\n+  br(Assembler::EQ, flag_correct);\n+  stop(\"Fast Unlock Flag != EQ\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with Flags == NE.\n+  br(Assembler::NE, flag_correct);\n+  stop(\"Fast Unlock Flag != NE\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of Flags (NE vs EQ) to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_lock_placeholder(Register obj, Register box, Register t1,\n+                                              Register t2, Register t3) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert_different_registers(obj, box, t1, t2, t3);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated;\n+  \/\/ Finish fast lock successfully. MUST reach to with flag == EQ\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. MUST branch to with flag == NE\n+  Label slow_path;\n+\n+  \/\/ Clear box. TODO: Is this neccesarry? May also defer this to not write twice.\n+  str(zr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(t1, obj);\n+    ldrw(t1, Address(t1, Klass::access_flags_offset()));\n+    tstw(t1, JVM_ACC_IS_VALUE_BASED_CLASS);\n+    br(Assembler::NE, slow_path);\n+  }\n+\n+  const Register mark = t1;\n+  const Register t = t3;\n+\n+  { \/\/ Lightweight locking\n+\n+    \/\/ Push lock to the lock stack and finish successfully. MUST reach to with flag == EQ\n+    Label push;\n+\n+    const Register top = t2;\n+\n+    \/\/ Check if lock-stack is full.\n+    ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    cmpw(top, (unsigned)LockStack::end_offset() - 1);\n+    br(Assembler::GT, slow_path);\n+\n+    \/\/ Check if recursive.\n+    subw(t, top, oopSize);\n+    ldr(t, Address(rthread, t));\n+    cmp(obj, t);\n+    br(Assembler::EQ, push);\n+\n+    \/\/ Relaxed normal load to check for monitor. Optimization for monitor case.\n+    ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+\n+    \/\/ Not inflated\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid a lea\");\n+    \/\/ Load-Acquire Exclusive Register to match Store Exclusive Register below.\n+    \/\/ Acquire to satisfy the JMM.\n+    ldaxr(mark, obj);\n+\n+    \/\/ Recheck for monitor (0b10).\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+\n+    \/\/ Check that obj is unlocked (0b01).\n+    orr(t, mark, markWord::unlocked_value);\n+    cmp(mark, t);\n+    br(Assembler::NE, slow_path);\n+\n+    \/\/ Clear unlock bit (0b01 => 0b00).\n+    andr(mark, mark, ~markWord::unlocked_value);\n+\n+    \/\/ Try to lock. Transition lock-bits 0b01 => 0b00\n+    stxr(t, mark, obj);\n+    cmpw(t, zr);\n+    br(Assembler::NE, slow_path);\n+\n+    bind(push);\n+    \/\/ After successful lock, push object on lock-stack.\n+    str(obj, Address(rthread, top));\n+    addw(top, top, oopSize);\n+    strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    b(locked);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated);\n+\n+    if (!OMUseC2Cache) {\n+      \/\/ Set Flags == NE\n+      cmp(zr, obj);\n+      b(slow_path);\n+    } else {\n+\n+      if (OMCacheHitRate) increment(Address(rthread, JavaThread::lock_lookup_offset()));\n+\n+      Label monitor_found;\n+\n+      \/\/ Load cache address\n+      lea(t, Address(rthread, JavaThread::om_cache_oops_offset()));\n+\n+      const int num_unrolled = MIN2(OMC2UnrollCacheEntries, OMCacheSize);\n+      for (int i = 0; i < num_unrolled; i++) {\n+        ldr(t1, Address(t));\n+        cmp(obj, t1);\n+        br(Assembler::EQ, monitor_found);\n+        if (i + 1 != num_unrolled) {\n+          increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        }\n+      }\n+\n+      if (num_unrolled == 0 || (OMC2UnrollCacheLookupLoopTail && num_unrolled != OMCacheSize)) {\n+        if (num_unrolled != 0) {\n+          \/\/ Loop after unrolling, advance iterator.\n+          increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        }\n+\n+        Label loop;\n+\n+        \/\/ Search for obj in cache.\n+        bind(loop);\n+\n+        \/\/ Check for match.\n+        ldr(t1, Address(t));\n+        cmp(obj, t1);\n+        br(Assembler::EQ, monitor_found);\n+\n+        \/\/ Search until null encountered, guaranteed _null_sentinel at end.\n+        increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        cbnz(t1, loop);\n+        \/\/ Cache Miss, NE set from cmp above, cbnz does not set flags\n+        b(slow_path);\n+      } else {\n+        b(slow_path);\n+      }\n+\n+      bind(monitor_found);\n+      ldr(t1, Address(t, OMCache::oop_to_monitor_difference()));\n+      if (OMCacheHitRate) increment(Address(rthread, JavaThread::lock_hit_offset()));\n+\n+      \/\/ ObjectMonitor* is in t1\n+      const Register monitor = t1;\n+      const Register owner_addr = t2;\n+      const Register owner = t3;\n+\n+      Label recursive;\n+      Label monitor_locked;\n+\n+      \/\/ Compute owner address.\n+      lea(owner_addr, Address(monitor, ObjectMonitor::owner_offset()));\n+\n+      if (OMRecursiveFastPath) {\n+        ldr(owner, Address(owner_addr));\n+        cmp(owner, rthread);\n+        br(Assembler::EQ, recursive);\n+      }\n+\n+      \/\/ CAS owner (null => current thread).\n+      cmpxchg(owner_addr, zr, rthread, Assembler::xword, \/*acquire*\/ true,\n+              \/*release*\/ false, \/*weak*\/ false, owner);\n+      br(Assembler::EQ, monitor_locked);\n+\n+      if (OMRecursiveFastPath) {\n+        b(slow_path);\n+      } else {\n+        \/\/ Check if recursive.\n+        cmp(owner, rthread);\n+        br(Assembler::NE, slow_path);\n+      }\n+\n+      \/\/ Recursive.\n+      bind(recursive);\n+      increment(Address(monitor, ObjectMonitor::recursions_offset()), 1);\n+\n+      bind(monitor_locked);\n+      str(monitor, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    }\n+\n+  }\n+\n+  bind(locked);\n+  increment(Address(rthread, JavaThread::held_monitor_count_offset()));\n+\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with Flags == EQ.\n+  Label flag_correct;\n+  br(Assembler::EQ, flag_correct);\n+  stop(\"Fast Lock Flag != EQ\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with Flags == NE.\n+  br(Assembler::NE, flag_correct);\n+  stop(\"Fast Lock Flag != NE\");\n+  bind(flag_correct);\n+#endif\n+  \/\/ C2 uses the value of Flags (NE vs EQ) to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_unlock_placeholder(Register obj, Register box, Register t1,\n+                                                Register t2) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert_different_registers(obj, box, t1, t2);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated, inflated_check_stack;\n+  \/\/ Finish fast unlock successfully. MUST reach to with flag == EQ\n+  Label unlocked;\n+  \/\/ Finish fast unlock unsuccessfully. MUST branch to with flag == NE\n+  Label slow_path;\n+\n+  \/\/ TODO: Cleanup the registers, using rscratch2 for now because we need the box.\n+  const Register mark = rscratch2;\n+  const Register top = t1;\n+  const Register t = t2;\n+\n+  { \/\/ Lightweight unlock\n+\n+    Label push_and_slow_path;\n+\n+    \/\/ Check if obj is top of lock-stack.\n+    ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    subw(top, top, oopSize);\n+    ldr(t, Address(rthread, top));\n+    cmp(obj, t);\n+    \/\/ Top of lock stack was not obj. Must be monitor.\n+    br(Assembler::NE, inflated_check_stack);\n+\n+    \/\/ Pop lock-stack.\n+    DEBUG_ONLY(str(zr, Address(rthread, top));)\n+    strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check if recursive.\n+    subw(t, top, oopSize);\n+    ldr(t, Address(rthread, t));\n+    cmp(obj, t);\n+    br(Assembler::EQ, unlocked);\n+\n+    \/\/ Not recursive.\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid a lea\");\n+    \/\/ Load Exclusive Register to match Store-Release Exclusive Register below.\n+    ldxr(mark, obj);\n+\n+    \/\/ Check header for monitor (0b10).\n+    \/\/ Because we got here by popping (meaning we pushed in locked)\n+    \/\/ there will be no monitor in the box. So we need to push back the obj\n+    \/\/ so that the runtime can fix any potential anonymous owner.\n+    tbnz(mark, exact_log2(markWord::monitor_value), push_and_slow_path);\n+\n+    \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+    orr(t, mark, markWord::unlocked_value);\n+    \/\/ Release to satisfy the JMM.\n+    stlxr(rscratch1, t, obj);\n+    cmpw(rscratch1, 0u);\n+    br(Assembler::EQ, unlocked);\n+\n+    bind(push_and_slow_path);\n+    \/\/ Load link store conditional exclusive failed.\n+    \/\/ Restore lock-stack and handle the unlock in runtime.\n+    DEBUG_ONLY(str(obj, Address(rthread, top));)\n+    addw(top, top, oopSize);\n+    str(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    b(slow_path);\n+  }\n+\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated_check_stack);\n+    ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+#ifdef ASSERT\n+    tbnz(mark, exact_log2(markWord::monitor_value), inflated);\n+    stop(\"Fast Unlock not monitor\");\n+#endif\n+\n+    bind(inflated);\n+\n+#ifdef ASSERT\n+    Label check_done;\n+    subw(top, top, oopSize);\n+    cmpw(top, in_bytes(JavaThread::lock_stack_base_offset()));\n+    br(Assembler::LT, check_done);\n+    ldr(t, Address(rthread, top));\n+    cmp(obj, t);\n+    br(Assembler::NE, inflated);\n+    stop(\"Fast Unlock lock on stack\");\n+    bind(check_done);\n+#endif\n+\n+    if (!OMUseC2Cache) {\n+      b(slow_path);\n+    } else {\n+      const Register monitor = box;\n+\n+      if (OMCacheHitRate) increment(Address(rthread, JavaThread::unlock_lookup_offset()));\n+      ldr(monitor, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+      \/\/ TODO: Cleanup these constants (with an enum and asserts)\n+      cmp(monitor, (uint8_t)2);\n+      \/\/ Non symmetrical, take slow path monitor == 0 or 1, 0 and 1 < 2, both LS and NE\n+      br(Assembler::LO, slow_path);\n+      if (OMCacheHitRate) increment(Address(rthread, JavaThread::unlock_hit_offset()));\n+\n+      const Register recursions = t1;\n+      Label not_recursive;\n+\n+      \/\/ Check if recursive.\n+      ldr(recursions, Address(monitor, ObjectMonitor::recursions_offset()));\n+      cbz(recursions, not_recursive);\n+\n+      \/\/ Recursive unlock.\n+      sub(recursions, recursions, 1u);\n+      str(recursions, Address(monitor, ObjectMonitor::recursions_offset()));\n+      \/\/ Set flag == EQ\n+      cmp(recursions, recursions);\n+      b(unlocked);\n+\n+      bind(not_recursive);\n+\n+      Label release;\n+      const Register owner_addr = t1;\n+\n+      \/\/ Compute owner address.\n+      lea(owner_addr, Address(monitor, ObjectMonitor::owner_offset()));\n+\n+      \/\/ Check if the entry lists are empty.\n+      ldr(rscratch1, Address(monitor, ObjectMonitor::EntryList_offset()));\n+      ldr(t, Address(monitor, ObjectMonitor::cxq_offset()));\n+      orr(rscratch1, rscratch1, t);\n+      cmp(rscratch1, zr);\n+      br(Assembler::EQ, release);\n+\n+      \/\/ The owner may be anonymous and we removed the last obj entry in\n+      \/\/ the lock-stack. This loses the information about the owner.\n+      \/\/ Write the thread to the owner field so the runtime knows the owner.\n+      str(rthread, Address(owner_addr));\n+      b(slow_path);\n+\n+      bind(release);\n+      \/\/ Set owner to null.\n+      \/\/ Release to satisfy the JMM\n+      stlr(zr, owner_addr);\n+    }\n+  }\n+\n+  bind(unlocked);\n+  decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":357,"deletions":0,"binary":false,"changes":357,"status":"modified"},{"patch":"@@ -44,0 +44,3 @@\n+  \/\/ Code used by cmpFastLockPlaceholder and cmpFastUnlockPlaceholder mach instructions in .ad file.\n+  void fast_lock_placeholder(Register object, Register box, Register t1, Register t2, Register t3);\n+  void fast_unlock_placeholder(Register object, Register box, Register t1, Register t2);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -703,1 +704,5 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      str(zr, Address(lock_reg, mark_offset));\n+      placeholder_lock(obj_reg, tmp, tmp2, tmp3, slow_case);\n+      b(count);\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -760,1 +765,2 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n+      \/\/ TODO: Clean this monitorenter_obj up. We still want to use the lock_reg for placeholder\n@@ -806,1 +812,2 @@\n-    if (LockingMode != LM_LIGHTWEIGHT) {\n+    if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER) {\n+      \/\/ TODO: Cleanup lock_reg usage for placeholder\n@@ -818,1 +825,6 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      Label slow_case;\n+      placeholder_unlock(obj_reg, header_reg, swap_reg, tmp_reg, slow_case);\n+      b(count);\n+      bind(slow_case);\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":16,"deletions":4,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -6442,0 +6442,115 @@\n+#ifdef ASSERT\n+  {\n+    \/\/ Check for lock-stack underflow.\n+    Label stack_ok;\n+    ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    cmpw(t1, (unsigned)LockStack::start_offset());\n+    br(Assembler::GE, stack_ok);\n+    STOP(\"Lock-stack underflow\");\n+    bind(stack_ok);\n+  }\n+#endif\n+\n+  Label unlocked, push_and_slow;\n+  const Register top = t1;\n+  const Register mark = t2;\n+  const Register t = t3;\n+\n+  \/\/ Check if obj is top of lock-stack.\n+  ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  subw(top, top, oopSize);\n+  ldr(t, Address(rthread, top));\n+  cmp(obj, t);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ Pop lock-stack.\n+  DEBUG_ONLY(str(zr, Address(rthread, top));)\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Check if recursive.\n+  subw(t, top, oopSize);\n+  ldr(t, Address(rthread, t));\n+  cmp(obj, t);\n+  br(Assembler::EQ, unlocked);\n+\n+  \/\/ Not recursive. Check header for monitor (0b10).\n+  ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  tbnz(mark, log2i_exact(markWord::monitor_value), push_and_slow);\n+\n+#ifdef ASSERT\n+  \/\/ Check header not unlocked (0b01).\n+  Label not_unlocked;\n+  tbz(mark, log2i_exact(markWord::unlocked_value), not_unlocked);\n+  stop(\"lightweight_unlock already unlocked\");\n+  bind(not_unlocked);\n+#endif\n+\n+  \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+  orr(t, mark, markWord::unlocked_value);\n+  cmpxchg(obj, mark, t, Assembler::xword,\n+          \/*acquire*\/ false, \/*release*\/ true, \/*weak*\/ false, noreg);\n+  br(Assembler::EQ, unlocked);\n+\n+  bind(push_and_slow);\n+  \/\/ Restore lock-stack and handle the unlock in runtime.\n+  DEBUG_ONLY(str(obj, Address(rthread, top));)\n+  addw(top, top, oopSize);\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  b(slow);\n+\n+  bind(unlocked);\n+}\n+\n+\/\/ Implements placeholder-locking.\n+\/\/\n+\/\/  - obj: the object to be locked\n+\/\/  - t1, t2, t3: temporary registers, will be destroyed\n+void MacroAssembler::placeholder_lock(Register obj, Register t1, Register t2, Register t3, Label& slow) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"only used with new placeholder locking\");\n+  assert_different_registers(obj, t1, t2, t3, rscratch1);\n+\n+  Label push;\n+  const Register top = t1;\n+  const Register mark = t2;\n+  const Register t = t3;\n+\n+  \/\/ Check if the lock-stack is full.\n+  ldrw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  cmpw(top, (unsigned)LockStack::end_offset());\n+  br(Assembler::GE, slow);\n+\n+  \/\/ Check for recursion.\n+  subw(t, top, oopSize);\n+  ldr(t, Address(rthread, t));\n+  cmp(obj, t);\n+  br(Assembler::EQ, push);\n+\n+  \/\/ Check header for monitor (0b10).\n+  ldr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  tst(mark, markWord::monitor_value);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ Try to lock. Transition lock bits 0b01 => 0b00\n+  assert(oopDesc::mark_offset_in_bytes() == 0, \"required to avoid lea\");\n+  orr(mark, mark, markWord::unlocked_value);\n+  eor(t, mark, markWord::unlocked_value);\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ mark, \/*new*\/ t, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ false, \/*weak*\/ false, noreg);\n+  br(Assembler::NE, slow);\n+\n+  bind(push);\n+  \/\/ After successful lock, push object on lock-stack.\n+  str(obj, Address(rthread, top));\n+  addw(top, top, oopSize);\n+  strw(top, Address(rthread, JavaThread::lock_stack_top_offset()));\n+}\n+\n+\/\/ Implements placeholder-unlocking.\n+\/\/\n+\/\/ - obj: the object to be unlocked\n+\/\/ - t1, t2, t3: temporary registers\n+void MacroAssembler::placeholder_unlock(Register obj, Register t1, Register t2, Register t3, Label& slow) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"only used with new placeholder locking\");\n+  assert_different_registers(obj, t1, t2, t3, rscratch1);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":115,"deletions":0,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -1608,0 +1608,3 @@\n+  void placeholder_lock(Register obj, Register t1, Register t2, Register t3, Label& slow);\n+  void placeholder_unlock(Register obj, Register t1, Register t2, Register t3, Label& slow);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -1797,2 +1798,1 @@\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1800,0 +1800,4 @@\n+    } else {\n+      assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+      __ str(zr, Address(lock_reg, mark_word_offset));\n+      __ placeholder_lock(obj_reg, swap_reg, tmp, lock_tmp, slow_path_lock);\n@@ -1939,2 +1943,1 @@\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1943,0 +1946,4 @@\n+    }  else {\n+      assert(LockingMode == LM_PLACEHOLDER, \"\");\n+      __ placeholder_unlock(obj_reg, old_hdr, swap_reg, lock_tmp, slow_path_unlock);\n+      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -45,0 +46,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -3488,1 +3490,1 @@\n-    Register tmp = LockingMode == LM_LIGHTWEIGHT ? op->scratch_opr()->as_register() : noreg;\n+    Register tmp = LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER ? op->scratch_opr()->as_register() : noreg;\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -322,1 +322,1 @@\n-  LIR_Opr tmp = LockingMode == LM_LIGHTWEIGHT ? new_register(T_ADDRESS) : LIR_OprFact::illegalOpr;\n+  LIR_Opr tmp = LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER ? new_register(T_ADDRESS) : LIR_OprFact::illegalOpr;\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -64,0 +64,3 @@\n+  } else if (LockingMode == LM_PLACEHOLDER) {\n+    \/\/ null check obj. load_klass performs load if DiagnoseSyncOnValueBasedClasses != 0.\n+    testptr(hdr, Address(obj));\n@@ -66,1 +69,10 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    movptr(Address(disp_hdr), 0);\n+#ifdef _LP64\n+    const Register thread = r15_thread;\n+#else\n+    const Register thread = disp_hdr;\n+    get_thread(thread);\n+#endif\n+    placeholder_lock(obj, hdr, thread, tmp, slow_case);\n+  } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -121,0 +133,1 @@\n+  assert(LockingMode != LM_MONITOR, \"not handled\");\n@@ -125,1 +138,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LEGACY) {\n@@ -138,1 +151,10 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_PLACEHOLDER) {\n+#ifdef _LP64\n+    placeholder_unlock(obj, disp_hdr, r15_thread, hdr, slow_case);\n+#else\n+    \/\/ This relies on the implementation of paceholder_unlock knowing that it\n+    \/\/ will clobber its thread when using EAX.\n+    get_thread(disp_hdr);\n+    placeholder_unlock(obj, disp_hdr, disp_hdr, hdr, slow_case);\n+#endif\n+  } else if (LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":25,"deletions":3,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -26,1 +26,0 @@\n-#include \"opto\/c2_MacroAssembler.hpp\"\n@@ -28,0 +27,3 @@\n+#include \"opto\/c2_MacroAssembler.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n@@ -31,0 +33,2 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/macros.hpp\"\n@@ -146,0 +150,78 @@\n+int C2FastUnlockPlaceholderStub::max_size() const {\n+  return 128;\n+}\n+\n+void C2FastUnlockPlaceholderStub::emit(C2_MacroAssembler& masm) {\n+  assert(_t == rax, \"must be\");\n+\n+  Label restore_held_monitor_count_and_slow_path;\n+\n+  { \/\/ Restore lock-stack and handle the unlock in runtime.\n+\n+    __ bind(_push_and_slow_path);\n+#ifdef ASSERT\n+    \/\/ The obj was only cleared in debug.\n+    __ movl(_t, Address(_thread, JavaThread::lock_stack_top_offset()));\n+    __ movptr(Address(_thread, _t), _obj);\n+#endif\n+    __ addl(Address(_thread, JavaThread::lock_stack_top_offset()), oopSize);\n+  }\n+\n+  { \/\/ Restore held monitor and slow path.\n+\n+    __ bind(restore_held_monitor_count_and_slow_path);\n+    __ bind(_slow_path);\n+    \/\/ Restore held monitor count.\n+    __ increment(Address(_thread, JavaThread::held_monitor_count_offset()));\n+    \/\/ increment will always result in ZF = 0 (no overflows).\n+    \/\/ continuation is the slow_path.\n+    __ jmp(continuation());\n+  }\n+\n+  { \/\/ Handle monitor medium path.\n+\n+    __ bind(_check_successor);\n+\n+    Label fix_zf_and_unlocked;\n+    const Register monitor = _monitor;\n+\n+#ifndef _LP64\n+    \/\/ The owner may be anonymous, see comment in x86_64 section.\n+    __ movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), _thread);\n+    __ jmpb(restore_held_monitor_count_and_slow_path);\n+#else \/\/ _LP64\n+    \/\/ The owner may be anonymous and we removed the last obj entry in\n+    \/\/ the lock-stack. This loses the information about the owner.\n+    \/\/ Write the thread to the owner field so the runtime knows the owner.\n+    __ movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), _thread);\n+\n+    \/\/ successor null check.\n+    __ cmpptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), NULL_WORD);\n+    __ jccb(Assembler::equal, restore_held_monitor_count_and_slow_path);\n+\n+    \/\/ Release lock.\n+    __ movptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+\n+    \/\/ Fence.\n+    __ lock(); __ addl(Address(rsp, 0), 0);\n+\n+    \/\/ Recheck successor.\n+    __ cmpptr(Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), NULL_WORD);\n+    \/\/ Seen a successor after the release -> fence we have handed of the monitor\n+    __ jccb(Assembler::notEqual, fix_zf_and_unlocked);\n+\n+    \/\/ Try to relock, if it fail the monitor has been handed over\n+    \/\/ TODO: Caveat, this may fail due to deflation, which does\n+    \/\/       not handle the monitor handoff. Currently only works\n+    \/\/       due to the responsible thread.\n+    __ xorptr(rax, rax);\n+    __ lock(); __ cmpxchgptr(_thread, Address(monitor, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+    __ jccb  (Assembler::equal, restore_held_monitor_count_and_slow_path);\n+#endif\n+\n+    __ bind(fix_zf_and_unlocked);\n+    __ xorl(rax, rax);\n+    __ jmp(unlocked());\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":83,"deletions":1,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"runtime\/basicLock.hpp\"\n@@ -37,0 +38,2 @@\n+#include \"runtime\/javaThread.inline.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n@@ -39,0 +42,1 @@\n+#include \"runtime\/synchronizer.hpp\"\n@@ -43,0 +47,1 @@\n+#include \"utilities\/macros.hpp\"\n@@ -562,0 +567,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"uses fast_lock_placeholder\");\n@@ -760,0 +766,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"uses fast_unlock_placeholder\");\n@@ -1180,0 +1187,329 @@\n+void C2_MacroAssembler::fast_lock_placeholder(Register obj, Register box, Register rax_reg,\n+                                              Register t, Register thread) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(rax_reg == rax, \"Used for CAS\");\n+  assert_different_registers(obj, box, rax_reg, t, thread);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated;\n+  \/\/ Finish fast lock successfully. ZF value is irrelevant.\n+  Label locked;\n+  \/\/ Finish fast lock unsuccessfully. MUST jump with ZF == 0\n+  Label slow_path;\n+\n+  \/\/ Clear box. TODO: Is this neccesarry? May also defer this to not write twice.\n+  movptr(Address(box, BasicLock::displaced_header_offset_in_bytes()), 0);\n+\n+  if (DiagnoseSyncOnValueBasedClasses != 0) {\n+    load_klass(rax_reg, obj, t);\n+    movl(rax_reg, Address(rax_reg, Klass::access_flags_offset()));\n+    testl(rax_reg, JVM_ACC_IS_VALUE_BASED_CLASS);\n+    jcc(Assembler::notZero, slow_path);\n+  }\n+\n+  const Register mark = t;\n+\n+  { \/\/ Placeholder Lock\n+\n+    Label push;\n+\n+    const Register top = box;\n+\n+    \/\/ Load the mark.\n+    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Check for monitor (0b10).\n+    testptr(mark, markWord::monitor_value);\n+    jcc(Assembler::notZero, inflated);\n+\n+    \/\/ Prefetch top.\n+    movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check if lock-stack is full.\n+    cmpl(top, LockStack::end_offset() - 1);\n+    jcc(Assembler::greater, slow_path);\n+\n+    \/\/ Check if recursive.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+    jccb(Assembler::equal, push);\n+\n+    \/\/ Try to lock. Transition lock bits 0b01 => 0b00\n+    movptr(rax_reg, mark);\n+    orptr(rax_reg, markWord::unlocked_value);\n+    andptr(mark, ~(int32_t)markWord::unlocked_value);\n+    lock(); cmpxchgptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    jcc(Assembler::notEqual, slow_path);\n+\n+    bind(push);\n+    \/\/ After successful lock, push object on lock-stack.\n+    movptr(Address(thread, top), obj);\n+    addl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+    jmpb(locked);\n+  }\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated);\n+\n+    const Register monitor = t;\n+\n+    if (!OMUseC2Cache) {\n+      jmp(slow_path);\n+    } else {\n+      if (OMCacheHitRate) increment(Address(thread, JavaThread::lock_lookup_offset()));\n+\n+      \/\/ Fetch ObjectMonitor* from the cache or take the slow-path.\n+      Label monitor_found;\n+\n+      \/\/ Load cache address\n+      lea(t, Address(thread, JavaThread::om_cache_oops_offset()));\n+\n+      const int num_unrolled = MIN2(OMC2UnrollCacheEntries, OMCacheSize);\n+      for (int i = 0; i < num_unrolled; i++) {\n+        cmpptr(obj, Address(t));\n+        jccb(Assembler::equal, monitor_found);\n+        if (i + 1 != num_unrolled) {\n+          increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        }\n+      }\n+\n+      if (num_unrolled == 0 || (OMC2UnrollCacheLookupLoopTail && num_unrolled != OMCacheSize)) {\n+        if (num_unrolled != 0) {\n+          \/\/ Loop after unrolling, advance iterator.\n+          increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        }\n+\n+        Label loop;\n+\n+        \/\/ Search for obj in cache.\n+        bind(loop);\n+\n+        \/\/ Check for match.\n+        cmpptr(obj, Address(t));\n+        jccb(Assembler::equal, monitor_found);\n+\n+        \/\/ Search until null encountered, guaranteed _null_sentinel at end.\n+        cmpptr(Address(t), 1);\n+        jcc(Assembler::below, slow_path); \/\/ 0 check, but with ZF=0 when *t == 0\n+        increment(t, in_bytes(OMCache::oop_to_oop_difference()));\n+        jmpb(loop);\n+      } else {\n+        jmp(slow_path);\n+      }\n+\n+      \/\/ Cache hit.\n+      bind(monitor_found);\n+      movptr(monitor, Address(t, OMCache::oop_to_monitor_difference()));\n+      if (OMCacheHitRate) increment(Address(thread, JavaThread::lock_hit_offset()));\n+\n+      Label monitor_locked;\n+      \/\/ Lock the monitor.\n+      Label recursion;\n+      if (OMRecursiveFastPath) {\n+        \/\/ Check owner for recursion first.\n+        cmpptr(thread, Address(monitor, ObjectMonitor::owner_offset()));\n+        jccb(Assembler::equal, recursion);\n+      }\n+\n+      \/\/ CAS owner (null => current thread).\n+      xorptr(rax, rax);\n+      lock(); cmpxchgptr(thread, Address(monitor, ObjectMonitor::owner_offset()));\n+      jccb(Assembler::equal, monitor_locked);\n+\n+      if (OMRecursiveFastPath) {\n+        \/\/ Recursion already checked.\n+        jmpb(slow_path);\n+      } else {\n+        \/\/ Check if recursive.\n+        cmpptr(thread, rax);\n+        jccb(Assembler::notEqual, slow_path);\n+      }\n+\n+      \/\/ Recursive.\n+      bind(recursion);\n+      increment(Address(monitor, ObjectMonitor::recursions_offset()));\n+\n+      bind(monitor_locked);\n+      \/\/ Cache the monitor for unlock\n+      movptr(Address(box, BasicLock::displaced_header_offset_in_bytes()), monitor);\n+    }\n+  }\n+\n+  bind(locked);\n+  increment(Address(thread, JavaThread::held_monitor_count_offset()));\n+  \/\/ Set ZF = 1\n+  xorl(rax_reg, rax_reg);\n+\n+#ifdef ASSERT\n+  \/\/ Check that locked label is reached with ZF set.\n+  Label zf_correct;\n+  jccb(Assembler::zero, zf_correct);\n+  stop(\"Fast Lock ZF != 1\");\n+#endif\n+\n+  bind(slow_path);\n+#ifdef ASSERT\n+  \/\/ Check that slow_path label is reached with ZF not set.\n+  jccb(Assembler::notZero, zf_correct);\n+  stop(\"Fast Lock ZF != 0\");\n+  bind(zf_correct);\n+#endif\n+  \/\/ C2 uses the value of ZF to determine the continuation.\n+}\n+\n+void C2_MacroAssembler::fast_unlock_placeholder(Register obj, Register reg_rax, Register t, Register thread) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(reg_rax == rax, \"Used for CAS\");\n+  assert_different_registers(obj, reg_rax, t);\n+\n+  \/\/ Handle inflated monitor.\n+  Label inflated, inflated_check_lock_stack;\n+  \/\/ Finish fast unlock successfully.  MUST jump with ZF == 1\n+  Label unlocked;\n+\n+  \/\/ Assume success.\n+  decrement(Address(thread, JavaThread::held_monitor_count_offset()));\n+\n+  const Register mark = t;\n+  const Register monitor = t;\n+  const Register top = t;\n+  const Register box = reg_rax;\n+\n+  Label dummy;\n+  C2FastUnlockPlaceholderStub* stub = nullptr;\n+\n+  if (!Compile::current()->output()->in_scratch_emit_size()) {\n+    stub = new (Compile::current()->comp_arena()) C2FastUnlockPlaceholderStub(obj, monitor, reg_rax, thread);\n+    Compile::current()->output()->add_stub(stub);\n+  }\n+\n+  Label& push_and_slow_path = stub == nullptr ? dummy : stub->push_and_slow_path();\n+  Label& check_successor = stub == nullptr ? dummy : stub->check_successor();\n+  Label& slow_path = stub == nullptr ? dummy : stub->slow_path();\n+\n+  { \/\/ Placeholder Unlock\n+\n+    \/\/ Load top.\n+    movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+    \/\/ Check if obj is top of lock-stack.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+    \/\/ Top of lock stack was not obj. Must be monitor.\n+    jcc(Assembler::notEqual, inflated_check_lock_stack);\n+\n+    \/\/ Pop lock-stack.\n+    DEBUG_ONLY(movptr(Address(thread, top, Address::times_1, -oopSize), 0);)\n+    subl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+\n+    \/\/ Check if recursive.\n+    cmpptr(obj, Address(thread, top, Address::times_1, -2 * oopSize));\n+    jcc(Assembler::equal, unlocked);\n+\n+    \/\/ We elide the monitor check, let the CAS fail instead.\n+\n+    \/\/ Load mark.\n+    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+\n+    \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+    movptr(reg_rax, mark);\n+    andptr(reg_rax, ~(int32_t)markWord::lock_mask);\n+    orptr(mark, markWord::unlocked_value);\n+    lock(); cmpxchgptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    jcc(Assembler::notEqual, push_and_slow_path);\n+    jmp(unlocked);\n+  }\n+\n+\n+  { \/\/ Handle inflated monitor.\n+    bind(inflated_check_lock_stack);\n+#ifdef ASSERT\n+    Label check_done;\n+    subl(top, oopSize);\n+    cmpl(top, in_bytes(JavaThread::lock_stack_base_offset()));\n+    jcc(Assembler::below, check_done);\n+    cmpptr(obj, Address(thread, top));\n+    jccb(Assembler::notEqual, inflated_check_lock_stack);\n+    stop(\"Fast Unlock lock on stack\");\n+    bind(check_done);\n+    const Register mark = t;\n+    movptr(mark, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    testptr(mark, markWord::monitor_value);\n+    jccb(Assembler::notZero, inflated);\n+    stop(\"Fast Unlock not monitor\");\n+#endif\n+\n+    bind(inflated);\n+\n+    if (!OMUseC2Cache) {\n+      jmp(slow_path);\n+    } else {\n+      if (OMCacheHitRate) increment(Address(thread, JavaThread::unlock_lookup_offset()));\n+      movptr(monitor, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+      \/\/ TODO: Figure out the correctness surrounding the owner field here. Obj is not on the lock stack\n+      \/\/       but this means this thread must have locked on the inflated monitor at some point. So it\n+      \/\/       should not be anonymous.\n+      cmpptr(monitor, 2);\n+      jcc(Assembler::below, slow_path);\n+\n+      if (OMCacheHitRate) increment(Address(thread, JavaThread::unlock_hit_offset()));\n+#ifndef _LP64\n+        \/\/ TODO: Unify 32 with 64. Should just be a straight up use 64 on 32. We have the registers here.\n+        \/\/ Check if recursive.\n+        xorptr(reg_rax, reg_rax);\n+        orptr(reg_rax, Address(monitor, ObjectMonitor::recursions_offset()));\n+        jcc(Assembler::notZero, check_successor);\n+\n+        \/\/ Check if the entry lists are empty.\n+        movptr(reg_rax, Address(monitor, ObjectMonitor::EntryList_offset()));\n+        orptr(reg_rax, Address(monitor, ObjectMonitor::cxq_offset()));\n+        jcc(Assembler::notZero, check_successor);\n+\n+        \/\/ Release lock.\n+        movptr(Address(monitor, ObjectMonitor::owner_offset()), NULL_WORD);\n+#else \/\/ _LP64\n+        Label recursive;\n+\n+        \/\/ Check if recursive.\n+        cmpptr(Address(monitor,ObjectMonitor::recursions_offset()),0);\n+        jccb(Assembler::notEqual, recursive);\n+\n+        \/\/ Check if the entry lists are empty.\n+        movptr(reg_rax, Address(monitor, ObjectMonitor::cxq_offset()));\n+        orptr(reg_rax, Address(monitor, ObjectMonitor::EntryList_offset()));\n+        jcc(Assembler::notZero, check_successor);\n+\n+        \/\/ Release lock.\n+        movptr(Address(monitor, ObjectMonitor::owner_offset()), NULL_WORD);\n+        jmpb(unlocked);\n+\n+        \/\/ Recursive unlock.\n+        bind(recursive);\n+        decrement(Address(monitor, ObjectMonitor::recursions_offset()));\n+        xorl(t, t);\n+#endif\n+    }\n+  }\n+\n+  bind(unlocked);\n+  if (stub != nullptr) {\n+    bind(stub->unlocked());\n+  }\n+\n+#ifdef ASSERT\n+  \/\/ Check that unlocked label is reached with ZF set.\n+  Label zf_correct;\n+  jccb(Assembler::zero, zf_correct);\n+  stop(\"Fast Unlock ZF != 1\");\n+#endif\n+\n+  if (stub != nullptr) {\n+    bind(stub->continuation());\n+  }\n+#ifdef ASSERT\n+  \/\/ Check that stub->continuation() label is reached with ZF not set.\n+  jccb(Assembler::notZero, zf_correct);\n+  stop(\"Fast Unlock ZF != 0\");\n+  bind(zf_correct);\n+#endif\n+  \/\/ C2 uses the value of ZF to determine the continuation.\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":336,"deletions":0,"binary":false,"changes":336,"status":"modified"},{"patch":"@@ -50,0 +50,4 @@\n+  void fast_lock_placeholder(Register obj, Register box, Register rax_reg,\n+                             Register t, Register thread);\n+  void fast_unlock_placeholder(Register obj, Register reg_rax, Register t, Register thread);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -1188,1 +1189,10 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      movptr(Address(lock_reg, mark_offset), 0);\n+#ifdef _LP64\n+      const Register thread = r15_thread;\n+#else\n+      const Register thread = lock_reg;\n+      get_thread(thread);\n+#endif\n+      placeholder_lock(obj_reg, swap_reg, thread, tmp_reg, slow_case);\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1257,1 +1267,1 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -1310,1 +1320,10 @@\n-    if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (LockingMode == LM_PLACEHOLDER) {\n+#ifdef _LP64\n+      placeholder_unlock(obj_reg, swap_reg, r15_thread, header_reg, slow_case);\n+#else\n+      \/\/ This relies on the implementation of placeholder_unlock knowing that it\n+      \/\/ will clobber its thread when using EAX.\n+      get_thread(swap_reg);\n+      placeholder_unlock(obj_reg, swap_reg, swap_reg, header_reg, slow_case);\n+#endif\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":22,"deletions":3,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -9994,0 +9994,109 @@\n+  testptr(reg_rax, markWord::monitor_value);\n+  jcc(Assembler::notZero, push_and_slow);\n+\n+#ifdef ASSERT\n+  \/\/ Check header not unlocked (0b01).\n+  Label not_unlocked;\n+  testptr(reg_rax, markWord::unlocked_value);\n+  jcc(Assembler::zero, not_unlocked);\n+  stop(\"lightweight_unlock already unlocked\");\n+  bind(not_unlocked);\n+#endif\n+\n+  \/\/ Try to unlock. Transition lock bits 0b00 => 0b01\n+  movptr(tmp, reg_rax);\n+  orptr(tmp, markWord::unlocked_value);\n+  lock(); cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::equal, unlocked);\n+\n+  bind(push_and_slow);\n+  \/\/ Restore lock-stack and handle the unlock in runtime.\n+  if (thread == reg_rax) {\n+    \/\/ On x86_32 we may lose the thread.\n+    get_thread(thread);\n+  }\n+#ifdef ASSERT\n+  movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+  movptr(Address(thread, top), obj);\n+#endif\n+  addl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+  jmp(slow);\n+\n+  bind(unlocked);\n+}\n+\n+\/\/ Implements placeholder-locking.\n+\/\/\n+\/\/ obj: the object to be locked\n+\/\/ reg_rax: rax\n+\/\/ thread: the thread which attempts to lock obj\n+\/\/ tmp: a temporary register\n+void MacroAssembler::placeholder_lock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow) {\n+  assert(reg_rax == rax, \"\");\n+  assert_different_registers(obj, reg_rax, thread, tmp);\n+\n+  Label push;\n+  const Register top = tmp;\n+\n+  \/\/ Load top.\n+  movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+  \/\/ Check if the lock-stack is full.\n+  cmpl(top, LockStack::end_offset());\n+  jcc(Assembler::greaterEqual, slow);\n+\n+  \/\/ Check for recursion.\n+  cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+  jcc(Assembler::equal, push);\n+\n+  \/\/ Check header for monitor (0b10).\n+  movptr(reg_rax, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  testptr(reg_rax, markWord::monitor_value);\n+  jcc(Assembler::notZero, slow);\n+\n+  \/\/ Try to lock. Transition lock bits 0b01 => 0b00\n+  movptr(tmp, reg_rax);\n+  andptr(tmp, ~(int32_t)markWord::unlocked_value);\n+  orptr(reg_rax, markWord::unlocked_value);\n+  lock(); cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notEqual, slow);\n+\n+  \/\/ Restore top, CAS clobbers register.\n+  movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+\n+  bind(push);\n+  \/\/ After successful lock, push object on lock-stack.\n+  movptr(Address(thread, top), obj);\n+  incrementl(top, oopSize);\n+  movl(Address(thread, JavaThread::lock_stack_top_offset()), top);\n+}\n+\n+\/\/ Implements placeholder-unlocking.\n+\/\/\n+\/\/ obj: the object to be unlocked\n+\/\/ reg_rax: rax\n+\/\/ thread: the thread, may be EAX on x86_32\n+\/\/ tmp: a temporary register\n+void MacroAssembler::placeholder_unlock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow) {\n+  assert(reg_rax == rax, \"\");\n+  assert_different_registers(obj, reg_rax, tmp);\n+  LP64_ONLY(assert_different_registers(obj, reg_rax, thread, tmp);)\n+\n+  Label unlocked, push_and_slow;\n+  const Register top = tmp;\n+\n+  \/\/ Check if obj is top of lock-stack.\n+  movl(top, Address(thread, JavaThread::lock_stack_top_offset()));\n+  cmpptr(obj, Address(thread, top, Address::times_1, -oopSize));\n+  jcc(Assembler::notEqual, slow);\n+\n+  \/\/ Pop lock-stack.\n+  DEBUG_ONLY(movptr(Address(thread, top, Address::times_1, -oopSize), 0);)\n+  subl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+\n+  \/\/ Check if recursive.\n+  cmpptr(obj, Address(thread, top, Address::times_1, -2 * oopSize));\n+  jcc(Assembler::equal, unlocked);\n+\n+  \/\/ Not recursive. Check header for monitor (0b10).\n+  movptr(reg_rax, Address(obj, oopDesc::mark_offset_in_bytes()));\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":109,"deletions":0,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -2038,0 +2038,3 @@\n+\n+  void placeholder_lock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow);\n+  void placeholder_unlock(Register obj, Register reg_rax, Register thread, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -64,1 +64,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -49,0 +50,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -1695,0 +1697,3 @@\n+    } else if (LockingMode == LM_PLACEHOLDER){\n+      __ movptr(Address(lock_reg, mark_word_offset), 0);\n+      __ placeholder_lock(obj_reg, swap_reg, thread, lock_reg, slow_path_lock);\n@@ -1852,0 +1857,3 @@\n+    } else if (LockingMode == LM_PLACEHOLDER) {\n+      __ placeholder_unlock(obj_reg, swap_reg, thread, lock_reg, slow_path_unlock);\n+      __ dec_held_monitor_count();\n@@ -1936,0 +1944,5 @@\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      \/\/ Reload the lock addr. Clobbered by lightweight_lock.\n+      __ lea(lock_reg, Address(rbp, lock_slot_rbp_offset));\n+    }\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -2171,2 +2172,1 @@\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -2174,0 +2174,4 @@\n+    } else {\n+      assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+      __ movptr(Address(lock_reg, mark_word_offset), 0);\n+      __ placeholder_lock(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n@@ -2313,2 +2317,1 @@\n-    } else {\n-      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+    } else if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -2316,0 +2319,4 @@\n+      __ dec_held_monitor_count();\n+    } else {\n+      assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+      __ placeholder_unlock(obj_reg, swap_reg, r15_thread, lock_reg, slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":11,"deletions":4,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -13767,1 +13767,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT && !Compile::current()->use_rtm());\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && !Compile::current()->use_rtm());\n@@ -13781,1 +13781,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER);\n@@ -13818,0 +13818,26 @@\n+instruct cmpFastLockPlaceholder(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, eRegP thread) %{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, USE_KILL box, TEMP thread);\n+  ins_cost(300);\n+  format %{ \"FASTLOCK $object,$box\\t! kills $box,$tmp,$scr\" %}\n+  ins_encode %{\n+    __ get_thread($thread$$Register);\n+    __ fast_lock_placeholder($object$$Register, $box$$Register, $tmp$$Register, $scr$$Register, $thread$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct cmpFastUnlockPlaceholder(eFlagsReg cr, eRegP object, eAXRegP box, eRegP tmp, eRegP thread) %{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, USE_KILL box, TEMP thread);\n+  ins_cost(300);\n+  format %{ \"FASTUNLOCK $object,$box\\t! kills $box,$tmp\" %}\n+  ins_encode %{\n+    __ get_thread($thread$$Register);\n+    __ fast_unlock_placeholder($object$$Register, $box$$Register, $tmp$$Register, $thread$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":28,"deletions":2,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -12386,1 +12386,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT && !Compile::current()->use_rtm());\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && !Compile::current()->use_rtm());\n@@ -12399,1 +12399,1 @@\n-  predicate(LockingMode != LM_LIGHTWEIGHT);\n+  predicate(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER);\n@@ -12434,0 +12434,24 @@\n+instruct cmpFastLockPlaceholder(rFlagsReg cr, rRegP object, rbx_RegP box, rax_RegI tmp, rRegP scr) %{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastLock object box));\n+  effect(TEMP tmp, TEMP scr, USE_KILL box);\n+  ins_cost(300);\n+  format %{ \"fastlock $object,$box\\t! kills $box,$tmp,$scr\" %}\n+  ins_encode %{\n+    __ fast_lock_placeholder($object$$Register, $box$$Register, $tmp$$Register, $scr$$Register, r15_thread);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct cmpFastUnlockPlaceholder(rFlagsReg cr, rRegP object, rax_RegP box, rRegP tmp) %{\n+  predicate(LockingMode == LM_PLACEHOLDER);\n+  match(Set cr (FastUnlock object box));\n+  effect(TEMP tmp, USE_KILL box);\n+  ins_cost(300);\n+  format %{ \"fastunlock $object,$box\\t! kills $box,$tmp\" %}\n+  ins_encode %{\n+    __ fast_unlock_placeholder($object$$Register, $box$$Register, $tmp$$Register, r15_thread);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":26,"deletions":2,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -76,0 +76,2 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/macros.hpp\"\n@@ -760,2 +762,2 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT || obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, LockingMode == LM_LIGHTWEIGHT ? nullptr : lock->lock(), current);\n+  assert(LockingMode == LM_LIGHTWEIGHT NOT_LP64(|| LockingMode == LM_PLACEHOLDER) || obj == lock->obj(), \"must match\");\n+  SharedRuntime::monitor_enter_helper(obj, LockingMode == LM_LIGHTWEIGHT NOT_LP64(|| LockingMode == LM_PLACEHOLDER) ? nullptr : lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -738,1 +739,1 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Should call monitorenter_obj() when using the new lightweight locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER, \"Should call monitorenter_obj() when using the new lightweight locking\");\n@@ -762,1 +763,1 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Should call monitorenter() when not using the new lightweight locking\");\n+  assert(LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER, \"Should call monitorenter() when not using the new lightweight locking\");\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -133,0 +133,1 @@\n+  f(mtOMWorld,        \"OM World\")                                                    \\\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -70,1 +71,1 @@\n-    if (print_monitor_info) {\n+    if (print_monitor_info && LockingMode != LM_PLACEHOLDER) {\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -184,1 +185,1 @@\n-    assert(LockingMode == LM_LIGHTWEIGHT, \"should only be called with new lightweight locking\");\n+    assert(LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER, \"should only be called with new lightweight locking\");\n@@ -197,0 +198,1 @@\n+    assert(LockingMode != LM_PLACEHOLDER, \"Placeholder locking does not use markWord for monitors\");\n@@ -202,2 +204,3 @@\n-    return LockingMode == LM_LIGHTWEIGHT  ? lockbits == monitor_value   \/\/ monitor?\n-                                          : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n+    return LockingMode == LM_PLACEHOLDER ? false :                           \/\/ no displaced mark\n+           LockingMode == LM_LIGHTWEIGHT ? lockbits == monitor_value         \/\/ monitor?\n+                                         : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n@@ -223,0 +226,1 @@\n+    assert(LockingMode != LM_PLACEHOLDER, \"Placeholder locking does not use markWord for monitors\");\n@@ -227,0 +231,4 @@\n+  markWord set_has_monitor() const {\n+    return markWord((value() & ~lock_mask_in_place) | monitor_value);\n+  }\n+\n@@ -228,1 +236,1 @@\n-  markWord clear_lock_bits() { return markWord(value() & ~lock_mask_in_place); }\n+  markWord clear_lock_bits() const { return markWord(value() & ~lock_mask_in_place); }\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -129,1 +129,1 @@\n-  return LockingMode == LM_LIGHTWEIGHT || !SafepointSynchronize::is_at_safepoint();\n+  return LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER || !SafepointSynchronize::is_at_safepoint();\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -135,0 +135,21 @@\n+class C2FastUnlockPlaceholderStub : public C2CodeStub {\n+private:\n+  Register _obj;\n+  Register _monitor;\n+  Register _t;\n+  Register _thread;\n+  Label _slow_path;\n+  Label _push_and_slow_path;\n+  Label _check_successor;\n+  Label _unlocked;\n+public:\n+  C2FastUnlockPlaceholderStub(Register obj, Register monitor, Register t, Register thread) : C2CodeStub(),\n+    _obj(obj), _monitor(monitor), _t(t), _thread(thread) {}\n+  int max_size() const;\n+  void emit(C2_MacroAssembler& masm);\n+  Label& slow_path() { return _slow_path; }\n+  Label& push_and_slow_path() { return _push_and_slow_path; }\n+  Label& check_successor() { return _check_successor; }\n+  Label& unlocked() { return _unlocked; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/c2_CodeStubs.hpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -4577,1 +4577,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1460,1 +1460,0 @@\n-  ObjectMonitor *mon = nullptr;\n@@ -1482,3 +1481,6 @@\n-  if (mark.has_monitor()) {\n-    mon = mark.monitor();\n-    assert(mon != nullptr, \"must have monitor\");\n+\n+  ObjectMonitor* mon = mark.has_monitor()\n+      ? ObjectSynchronizer::read_monitor(current_thread, hobj(), mark)\n+      : nullptr;\n+\n+  if (mon != nullptr) {\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1829,0 +1829,7 @@\n+#if !defined(X86) && !defined(AARCH64)\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    FLAG_SET_CMDLINE(LockingMode, LM_LEGACY);\n+    warning(\"New placeholder locking not supported on this platform\");\n+  }\n+#endif\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -85,0 +86,7 @@\n+  } else if (LockingMode == LM_PLACEHOLDER) {\n+    \/\/ Placeholder locking uses the displace header to store a cache which\n+    \/\/ must contain either an ObjectMonitor* associated with this lock or null.\n+    \/\/ Preserve the ObjectMonitor*, the cache is cleared when a box is reused\n+    \/\/ and only read while the lock is held, so no stale ObjectMonitor* is\n+    \/\/ encountered.\n+    dest->set_displaced_header(displaced_header());\n","filename":"src\/hotspot\/share\/runtime\/basicLock.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -47,0 +47,8 @@\n+  void clear_displaced_header() {\n+    Atomic::store(&_displaced_header, markWord(0));\n+  }\n+\n+  void set_displaced_header(ObjectMonitor* mon) {\n+    Atomic::store(&_displaced_header, markWord::from_pointer(mon));\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/basicLock.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -79,0 +80,1 @@\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n@@ -95,0 +97,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -1645,0 +1648,1 @@\n+        BasicLock* lock = mon_info->lock();\n@@ -1653,0 +1657,13 @@\n+        } else if (LockingMode == LM_PLACEHOLDER && exec_mode == Unpack_none) {\n+          \/\/ We have lost information about the correct state of the lock stack.\n+          \/\/ Entering may create an invalid lock stack. Inflate the lock if it\n+          \/\/ was fast_locked to restore the valid lock stack.\n+          ObjectSynchronizer::enter_for(obj, lock, deoptee_thread);\n+          if (obj->mark().is_fast_locked()) {\n+            PlaceholderSynchronizer::inflate_fast_locked_object(obj(), deoptee_thread, thread,\n+                                                                ObjectSynchronizer::InflateCause::inflate_cause_vm_internal);\n+          }\n+          assert(mon_info->owner()->is_locked(), \"object must be locked now\");\n+          assert(obj->mark().has_monitor(), \"must be\");\n+          assert(!deoptee_thread->lock_stack().contains(obj()), \"must be\");\n+          assert(PlaceholderSynchronizer::read_monitor(thread, obj())->owner() == deoptee_thread, \"must be\");\n@@ -1654,1 +1671,0 @@\n-          BasicLock* lock = mon_info->lock();\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1983,1 +1983,1 @@\n-  product(int, LockingMode, LM_LEGACY,                                      \\\n+  product(int, LockingMode, LM_PLACEHOLDER,                                 \\\n@@ -1987,2 +1987,27 @@\n-          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT)\")         \\\n-          range(0, 2)                                                       \\\n+          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT), \"        \\\n+          \"3: placeholder (LM_PLACEHOLDER)\")                                \\\n+          range(0, 3)                                                       \\\n+                                                                            \\\n+  product(bool, OMUseC2Cache, true, \"\")                                     \\\n+                                                                            \\\n+  product(bool, OMC2UnrollCacheLookupLoopTail, true, \"\")                    \\\n+                                                                            \\\n+  product(int, OMC2UnrollCacheEntries, 0, \"\")                               \\\n+          range(0, OMCache::CAPACITY)                                       \\\n+                                                                            \\\n+  product(int, OMCacheSize, 8, \"\")                                          \\\n+          range(0, OMCache::CAPACITY)                                       \\\n+                                                                            \\\n+  product(bool, OMShrinkCHT, false, \"\")                                     \\\n+                                                                            \\\n+  product(int, OMSpins, 20, \"\")                                             \\\n+                                                                            \\\n+  product(int, OMYields, 5, \"\")                                             \\\n+                                                                            \\\n+  product(bool, OMDeflateAfterWait, false, \"\")                              \\\n+                                                                            \\\n+  product(bool, OMDeflateBeforeExit, false, \"\")                             \\\n+                                                                            \\\n+  product(bool, OMCacheHitRate, false, \"\")                                  \\\n+                                                                            \\\n+  product(bool, OMRecursiveFastPath, true, \"Inflated recursion check first\")\\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":28,"deletions":3,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -101,0 +101,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -498,1 +499,2 @@\n-  _lock_stack(this) {\n+  _lock_stack(this),\n+  _om_cache(this) {\n@@ -770,0 +772,2 @@\n+  om_clear_monitor_cache();\n+\n@@ -1001,1 +1005,1 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER, \"should not be called with new lightweight locking\");\n@@ -1399,1 +1403,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+class ObjectMonitor;\n@@ -1155,0 +1156,1 @@\n+  OMCache _om_cache;\n@@ -1158,0 +1160,19 @@\n+  size_t _unlocked_inflation = 0;\n+  size_t _recursive_inflation = 0;\n+  size_t _contended_recursive_inflation = 0;\n+  size_t _contended_inflation = 0;\n+  size_t _wait_inflation = 0;\n+  size_t _lock_stack_inflation = 0;\n+\n+  size_t _wait_deflation = 0;\n+  size_t _exit_deflation = 0;\n+\n+  size_t _lock_lookup = 0;\n+  size_t _lock_hit = 0;\n+  size_t _unlock_lookup = 0;\n+  size_t _unlock_hit = 0;\n+\n+  static ByteSize lock_lookup_offset() { return byte_offset_of(JavaThread, _lock_lookup); }\n+  static ByteSize lock_hit_offset() { return byte_offset_of(JavaThread, _lock_hit); }\n+  static ByteSize unlock_lookup_offset() { return byte_offset_of(JavaThread, _unlock_lookup); }\n+  static ByteSize unlock_hit_offset() { return byte_offset_of(JavaThread, _unlock_hit); }\n@@ -1166,0 +1187,8 @@\n+\n+  static ByteSize om_cache_offset()        { return byte_offset_of(JavaThread, _om_cache); }\n+  static ByteSize om_cache_oops_offset()   { return om_cache_offset() + OMCache::entries(); }\n+\n+  void om_set_monitor_cache(ObjectMonitor* monitor);\n+  void om_clear_monitor_cache();\n+  ObjectMonitor* om_get_from_monitor_cache(oop obj);\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+#include \"logging\/log.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n@@ -40,0 +42,1 @@\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -42,0 +45,3 @@\n+#include \"runtime\/synchronizer.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/sizes.hpp\"\n@@ -242,0 +248,75 @@\n+inline void JavaThread::om_set_monitor_cache(ObjectMonitor* monitor) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(monitor != nullptr, \"use om_clear_monitor_cache to clear\");\n+  assert(this == current(), \"only set own thread locals\");\n+\n+  _om_cache.set_monitor(monitor);\n+}\n+\n+inline void JavaThread::om_clear_monitor_cache() {\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    return;\n+  }\n+\n+  _om_cache.clear();\n+\n+  LogTarget(Info, monitorinflation) lt;\n+  if (!lt.is_enabled()) {\n+    return;\n+  }\n+\n+  ResourceMark rm;\n+\n+  if (_unlocked_inflation != 0 ||\n+      _recursive_inflation != 0 ||\n+      _contended_recursive_inflation != 0 ||\n+      _contended_inflation != 0 ||\n+      _wait_inflation != 0 ||\n+      _lock_stack_inflation != 0) {\n+    log_info(monitorinflation)(\"Mon: %8zu Rec: %8zu CRec: %8zu Cont: %8zu Wait: %8zu Stack: %8zu Thread: %s\",\n+                              _unlocked_inflation,\n+                              _recursive_inflation,\n+                              _contended_recursive_inflation,\n+                              _contended_inflation,\n+                              _wait_inflation,\n+                              _lock_stack_inflation,\n+                              name());\n+  }\n+  _unlocked_inflation            = 0;\n+  _recursive_inflation           = 0;\n+  _contended_recursive_inflation = 0;\n+  _contended_inflation           = 0;\n+  _wait_inflation                = 0;\n+  _lock_stack_inflation          = 0;\n+\n+  if (_wait_deflation != 0 ||\n+      _exit_deflation != 0) {\n+    log_info(monitorinflation)(\"Wait: %8zu Exit: %8zu Thread: %s\",\n+                              _wait_deflation,\n+                              _exit_deflation,\n+                              name());\n+  }\n+  _wait_deflation = 0;\n+  _exit_deflation = 0;\n+\n+  if (_lock_lookup != 0 ||\n+      _unlock_lookup != 0) {\n+    const double lock_hit_rate = (double)_lock_hit \/ (double)_lock_lookup * 100;\n+    const double unlock_hit_rate = (double)_unlock_hit \/ (double)_unlock_lookup * 100;\n+    log_info(monitorinflation)(\"Lock: %3.2lf %% [%6zu \/ %6zu] Unlock: %3.2lf %% [%6zu \/ %6zu] Thread: %s\",\n+                              lock_hit_rate, _lock_hit, _lock_lookup,\n+                              unlock_hit_rate, _unlock_hit, _unlock_lookup,\n+                              name());\n+  }\n+  _lock_hit = 0;\n+  _lock_lookup = 0;\n+  _unlock_hit = 0;\n+  _unlock_lookup = 0;\n+}\n+\n+inline ObjectMonitor* JavaThread::om_get_from_monitor_cache(oop obj) {\n+  assert(obj != nullptr, \"do not look for null objects\");\n+  assert(this == current(), \"only get own thread locals\");\n+  return _om_cache.get_monitor(obj);\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/javaThread.inline.hpp","additions":81,"deletions":0,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"utilities\/sizes.hpp\"\n@@ -74,1 +75,1 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"never use lock-stack when light weight locking is disabled\");\n+  assert(LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER, \"never use lock-stack when light weight locking is disabled\");\n@@ -113,0 +114,8 @@\n+\n+OMCache::OMCache(JavaThread* jt) : _entries() {\n+  STATIC_ASSERT(std::is_standard_layout<OMCache>::value);\n+  STATIC_ASSERT(std::is_standard_layout<OMCache::OMCacheEntry>::value);\n+  STATIC_ASSERT(offsetof(OMCache, _null_sentinel) == offsetof(OMCache, _entries) +\n+                offsetof(OMCache::OMCacheEntry, _oop) +\n+                OMCache::CAPACITY * in_bytes(oop_to_oop_difference()));\n+}\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+class ObjectMonitor;\n@@ -37,0 +38,1 @@\n+class Thread;\n@@ -57,0 +59,1 @@\n+  bool _wait_was_inflated;\n@@ -84,0 +87,3 @@\n+  \/\/ Return true if we have room to push n oops onto this lock-stack, false otherwise.\n+  inline bool can_push(int n = 1) const;\n+\n@@ -97,0 +103,3 @@\n+  \/\/ Get the oldest oop in the stack\n+  inline oop top();\n+\n@@ -120,0 +129,4 @@\n+  bool wait_was_inflated() const { return _wait_was_inflated; };\n+  void set_wait_was_inflated() { _wait_was_inflated = true; };\n+  void clear_wait_was_inflated() { _wait_was_inflated = false; };\n+\n@@ -124,0 +137,25 @@\n+class OMCache {\n+  friend class VMStructs;\n+public:\n+  static constexpr int CAPACITY = 8;\n+\n+private:\n+  struct OMCacheEntry {\n+    oop _oop = nullptr;\n+    ObjectMonitor* _monitor = nullptr;\n+  } _entries[CAPACITY];\n+  const oop _null_sentinel = nullptr;\n+\n+public:\n+  static ByteSize entries() { return byte_offset_of(OMCache, _entries); }\n+  static constexpr ByteSize oop_to_oop_difference() { return in_ByteSize(sizeof(OMCacheEntry)); }\n+  static constexpr ByteSize oop_to_monitor_difference() { return in_ByteSize(sizeof(oop)); }\n+\n+  explicit OMCache(JavaThread* jt);\n+\n+  inline ObjectMonitor* get_monitor(oop o);\n+  inline void set_monitor(ObjectMonitor* monitor);\n+  inline void clear();\n+\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -33,0 +33,2 @@\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/globals.hpp\"\n@@ -34,0 +36,1 @@\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -39,0 +42,2 @@\n+#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n@@ -56,0 +61,4 @@\n+inline bool LockStack::can_push(int n) const {\n+  return (CAPACITY - to_index(_top)) >= n;\n+}\n+\n@@ -83,0 +92,5 @@\n+inline oop LockStack::top() {\n+  assert(to_index(_top) > 0, \"may only call with at least one element in the stack\");\n+  return _base[to_index(_top) - 1];\n+}\n+\n@@ -200,0 +214,1 @@\n+  assert(o != nullptr, \"Catch me!\");\n@@ -225,0 +240,53 @@\n+inline void OMCache::set_monitor(ObjectMonitor *monitor) {\n+  const int end = OMCacheSize - 1;\n+  if (end < 0) {\n+    return;\n+  }\n+\n+  oop obj = monitor->object_peek();\n+  assert(obj != nullptr, \"must be alive\");\n+  assert(monitor == PlaceholderSynchronizer::read_monitor(JavaThread::current(), obj), \"must be exist in table\");\n+\n+  OMCacheEntry to_insert = {obj, monitor};\n+\n+  for (int i = 0; i < end; ++i) {\n+    if (_entries[i]._oop == obj ||\n+        _entries[i]._monitor == nullptr ||\n+        _entries[i]._monitor->is_being_async_deflated()) {\n+      \/\/ Use stale slot.\n+      _entries[i] = to_insert;\n+      return;\n+    }\n+    \/\/ Swap with the most recent value.\n+    ::swap(to_insert, _entries[i]);\n+  }\n+  _entries[end] = to_insert;\n+}\n+\n+inline ObjectMonitor* OMCache::get_monitor(oop o) {\n+  for (int i = 0; i < OMCacheSize; ++i) {\n+    if (_entries[i]._oop == o) {\n+      assert(_entries[i]._monitor != nullptr, \"monitor must exist\");\n+      if (_entries[i]._monitor->is_being_async_deflated()) {\n+        \/\/ Bad monitor\n+        \/\/ Shift down rest\n+        for (; i < OMCacheSize - 1; ++i) {\n+          _entries[i] = _entries[i + 1];\n+        }\n+        \/\/ Clear end\n+        _entries[i] = {};\n+        return nullptr;\n+      }\n+      return _entries[i]._monitor;\n+    }\n+  }\n+  return nullptr;\n+}\n+\n+inline void OMCache::clear() {\n+  for (size_t i = 0 , r = 0; i < CAPACITY; ++i) {\n+    \/\/ Clear\n+    _entries[i] = {};\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":68,"deletions":0,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -36,0 +36,2 @@\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n+#include \"utilities\/checkedCast.hpp\"\n@@ -63,1 +65,1 @@\n-  intx wait_time = max_intx;\n+  intx deflation_interval = max_intx;\n@@ -65,1 +67,1 @@\n-    wait_time = MIN2(wait_time, GuaranteedSafepointInterval);\n+    deflation_interval = MIN2(deflation_interval, GuaranteedSafepointInterval);\n@@ -68,1 +70,1 @@\n-    wait_time = MIN2(wait_time, AsyncDeflationInterval);\n+    deflation_interval = MIN2(deflation_interval, AsyncDeflationInterval);\n@@ -71,1 +73,1 @@\n-    wait_time = MIN2(wait_time, GuaranteedAsyncDeflationInterval);\n+    deflation_interval = MIN2(deflation_interval, GuaranteedAsyncDeflationInterval);\n@@ -77,1 +79,1 @@\n-  if (wait_time == max_intx) {\n+  if (deflation_interval == max_intx) {\n@@ -79,0 +81,1 @@\n+    PlaceholderSynchronizer::set_table_max(jt);\n@@ -82,0 +85,1 @@\n+    intx time_to_wait = deflation_interval;\n@@ -83,0 +87,1 @@\n+    bool resize = false;\n@@ -93,1 +98,28 @@\n-        ml.wait(wait_time);\n+        ml.wait(time_to_wait);\n+\n+        \/\/ Handle LightweightSynchronizer Hash Table Resizing\n+        if (PlaceholderSynchronizer::needs_resize(jt)) {\n+          resize = true;\n+          break;\n+        }\n+      }\n+    }\n+\n+    if (resize) {\n+      \/\/ TODO: Recheck this logic, especially !resize_successful and PlaceholderSynchronizer::needs_resize when is_max_size_reached == true\n+      const intx time_since_last_deflation = checked_cast<intx>(ObjectSynchronizer::time_since_last_async_deflation_ms());\n+      const bool resize_successful = PlaceholderSynchronizer::resize_table(jt);\n+      const bool deflation_interval_passed = time_since_last_deflation >= deflation_interval;\n+      const bool deflation_needed = deflation_interval_passed && ObjectSynchronizer::is_async_deflation_needed();\n+\n+      if (!resize_successful) {\n+        \/\/ Resize failed, try again in 250 ms\n+        time_to_wait = 250;\n+      } else if (deflation_interval_passed) {\n+        time_to_wait = deflation_interval;\n+      } else {\n+        time_to_wait = deflation_interval - time_since_last_deflation;\n+      }\n+\n+      if (!deflation_needed) {\n+        continue;\n@@ -95,0 +127,2 @@\n+    } else {\n+      time_to_wait = deflation_interval;\n@@ -97,0 +131,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/monitorDeflationThread.cpp","additions":41,"deletions":6,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -52,0 +52,1 @@\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n@@ -55,0 +56,1 @@\n+#include \"runtime\/synchronizer.hpp\"\n@@ -56,0 +58,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -289,4 +292,0 @@\n-oop ObjectMonitor::object_peek() const {\n-  return _object.peek();\n-}\n-\n@@ -314,0 +313,6 @@\n+#define assert_mark_word_concistency()                                                 \\\n+  assert(LockingMode == LM_PLACEHOLDER || object()->mark() == markWord::encode(this),  \\\n+         \"object mark must match encoded this: mark=\" INTPTR_FORMAT                    \\\n+         \", encoded this=\" INTPTR_FORMAT, object()->mark().value(),                    \\\n+         markWord::encode(this).value());\n+\n@@ -316,0 +321,14 @@\n+bool ObjectMonitor::try_enter(JavaThread* current) {\n+  void* cur = try_set_owner_from(nullptr, current);\n+  if (cur == nullptr) {\n+    assert(_recursions == 0, \"invariant\");\n+    return true;\n+  }\n+\n+  if (cur == current) {\n+    _recursions++;\n+    return true;\n+  }\n+\n+  return false;\n+}\n@@ -396,1 +415,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n+  if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && current->is_lock_owned((address)cur)) {\n@@ -415,4 +434,1 @@\n-    assert(object()->mark() == markWord::encode(this),\n-           \"object mark must match encoded this: mark=\" INTPTR_FORMAT\n-           \", encoded this=\" INTPTR_FORMAT, object()->mark().value(),\n-           markWord::encode(this).value());\n+    assert_mark_word_concistency();\n@@ -435,1 +451,1 @@\n-    if (l_object != nullptr) {\n+    if (LockingMode != LM_PLACEHOLDER && l_object != nullptr) {\n@@ -509,1 +525,1 @@\n-  assert(object()->mark() == markWord::encode(this), \"invariant\");\n+  assert_mark_word_concistency();\n@@ -571,1 +587,1 @@\n-bool ObjectMonitor::deflate_monitor() {\n+bool ObjectMonitor::deflate_monitor(Thread* current) {\n@@ -577,0 +593,7 @@\n+  if (LockingMode == LM_PLACEHOLDER && is_being_async_deflated()) {\n+    \/\/ This happens when a locked monitor is deflated by a java thread\n+    \/\/ returning itself to fast_locked\n+    assert(is_owner_anonymous(), \"must stay anonymous when the java thread deflates\");\n+    return true;\n+  }\n+\n@@ -642,0 +665,1 @@\n+  }\n@@ -643,2 +667,7 @@\n-    \/\/ Install the old mark word if nobody else has already done it.\n-    install_displaced_markword_in_object(obj);\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    PlaceholderSynchronizer::deflate_monitor(current, obj, this);\n+  } else {\n+    if (obj != nullptr) {\n+      \/\/ Install the old mark word if nobody else has already done it.\n+      install_displaced_markword_in_object(obj);\n+    }\n@@ -652,0 +681,71 @@\n+bool ObjectMonitor::deflate_anon_monitor(JavaThread* current) {\n+  assert(owner_raw() == current, \"must be\");\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+\n+  LockStack& lock_stack = current->lock_stack();\n+\n+  if (!lock_stack.can_push(1 + _recursions)) {\n+    \/\/ Will not be able to push the oop on the lock stack.\n+    return false;\n+  }\n+\n+  if (is_contended()) {\n+    \/\/ Easy checks are first - the ObjectMonitor is busy so no deflation.\n+    return false;\n+  }\n+\n+  \/\/ Make sure if a thread sees contentions() < 0 they also see owner == ANONYMOUS_OWNER\n+  set_owner_from(current, reinterpret_cast<void*>(ANONYMOUS_OWNER));\n+\n+    \/\/ Recheck after setting owner\n+  bool cleanup = is_contended();\n+\n+\n+  if (!cleanup) {\n+    \/\/ Make a zero contentions field negative to force any contending threads\n+    \/\/ to retry. Because this is only called while holding the lock, the owner\n+    \/\/ is anonymous and contentions is held over enter in inflate_and_enter\n+    \/\/ it means that if the cas succeeds then we can have no other thread\n+    \/\/ racily inserting themselves on the _waiters or _cxq lists, the\n+    \/\/ entry list is protected by the lock (_waiter technically too, only\n+    \/\/ removals are done outside the lock)\n+    \/\/ TODO: Double check _succ and _responsible invariants\n+    if (Atomic::cmpxchg(&_contentions, 0, INT_MIN) != 0) {\n+      \/\/ Contentions was no longer 0 so we lost the race.\n+      cleanup = true;\n+    }\n+  }\n+\n+  if (cleanup) {\n+    \/\/ Could not deflate\n+    set_owner_from_anonymous(current);\n+    return false;\n+  }\n+\n+  \/\/ Sanity checks for the races:\n+  guarantee(is_owner_anonymous(), \"must be\");\n+  guarantee(contentions() < 0, \"must be negative: contentions=%d\",\n+            contentions());\n+  guarantee(_waiters == 0, \"must be 0: waiters=%d\", _waiters);\n+  guarantee(_cxq == nullptr, \"must be no contending threads: cxq=\"\n+            INTPTR_FORMAT, p2i(_cxq));\n+  guarantee(_EntryList == nullptr,\n+            \"must be no entering threads: EntryList=\" INTPTR_FORMAT,\n+            p2i(_EntryList));\n+\n+  oop obj = object();\n+\n+  PlaceholderSynchronizer::deflate_anon_monitor(current, obj, this);\n+\n+  \/\/ We are deflated, restore the correct lock_stack\n+  lock_stack.push(obj);\n+  for (int i = 0; i < _recursions; i++) {\n+    bool entered = lock_stack.try_recursive_enter(obj);\n+    assert(entered, \"must have entered here\");\n+  }\n+\n+  \/\/ We leave owner == ANONYMOUS_OWNER and contentions < 0\n+  \/\/ to force any racing threads to retry.\n+  return true;  \/\/ Success, ObjectMonitor has been deflated.\n+}\n+\n@@ -658,0 +758,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"Placeholder has no dmw\");\n@@ -990,0 +1091,1 @@\n+  assert(current->thread_state() != _thread_blocked, \"invariant\");\n@@ -993,3 +1095,1 @@\n-  assert(object()->mark() == markWord::encode(this), \"invariant\");\n-\n-  assert(current->thread_state() != _thread_blocked, \"invariant\");\n+  assert_mark_word_concistency();\n@@ -1052,1 +1152,1 @@\n-  assert(object()->mark() == markWord::encode(this), \"invariant\");\n+  assert_mark_word_concistency();\n@@ -1186,1 +1286,1 @@\n-    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n+    if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && current->is_lock_owned((address)cur)) {\n@@ -1401,1 +1501,1 @@\n-    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n+    if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && current->is_lock_owned((address)cur)) {\n@@ -1440,1 +1540,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n+  if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER && current->is_lock_owned((address)cur)) {\n@@ -1680,0 +1780,9 @@\n+  bool deflated = false;\n+\n+  if (LockingMode == LM_PLACEHOLDER && OMDeflateAfterWait && current->lock_stack().wait_was_inflated()) {\n+    if (deflate_anon_monitor(current)) {\n+      current->_wait_deflation++;\n+      deflated = true;\n+    }\n+  }\n+\n@@ -1681,1 +1790,1 @@\n-  assert(owner_raw() == current, \"invariant\");\n+  assert(deflated || owner_raw() == current, \"invariant\");\n@@ -1683,1 +1792,1 @@\n-  assert(object()->mark() == markWord::encode(this), \"invariant\");\n+  assert_mark_word_concistency();\n@@ -2203,1 +2312,1 @@\n-  st->print_cr(\"  _header = \" INTPTR_FORMAT, header().value());\n+  st->print_cr(\"  _header = \" INTPTR_FORMAT, header_value());\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":133,"deletions":24,"binary":false,"changes":157,"status":"modified"},{"patch":"@@ -124,0 +124,3 @@\n+#ifndef OM_CACHE_LINE_SIZE\n+\/\/ Use DEFAULT_CACHE_LINE_SIZE if not already specified for\n+\/\/ the current build platform.\n@@ -125,0 +128,1 @@\n+#endif\n@@ -152,1 +156,2 @@\n-  #define DEFLATER_MARKER reinterpret_cast<void*>(2)\n+  static const uintptr_t DEFLATER_MARKER_VALUE = 2;\n+  #define DEFLATER_MARKER reinterpret_cast<void*>(DEFLATER_MARKER_VALUE)\n@@ -156,0 +161,1 @@\n+  static const uintptr_t ANONYMOUS_OWNER_OR_DEFLATER_MARKER = ANONYMOUS_OWNER | DEFLATER_MARKER_VALUE;\n@@ -234,0 +240,3 @@\n+  \/\/ Placeholder locking fetches ObjectMonitor references from a cache\n+  \/\/ instead of the markWord and doesn't work with tagged values.\n+  \/\/\n@@ -235,1 +244,1 @@\n-    ((in_bytes(ObjectMonitor::f ## _offset())) - checked_cast<int>(markWord::monitor_value))\n+    ((in_bytes(ObjectMonitor::f ## _offset())) - (LockingMode == LM_PLACEHOLDER ? 0 : checked_cast<int>(markWord::monitor_value)))\n@@ -238,0 +247,1 @@\n+  uintptr_t          header_value() const;\n@@ -241,0 +251,3 @@\n+  intptr_t           hash_placeholder() const;\n+  void               set_hash_placeholder(intptr_t hash);\n+\n@@ -253,0 +266,8 @@\n+  bool is_contended() const {\n+    intptr_t ret_code = intptr_t(_waiters) | intptr_t(_cxq) | intptr_t(_EntryList);\n+    int cnts = contentions();\n+    if (cnts > 0) {\n+      ret_code |= intptr_t(cnts);\n+    }\n+    return ret_code != 0;\n+  }\n@@ -310,0 +331,3 @@\n+  bool      object_is_cleared() const;\n+  bool      object_is_dead() const;\n+  bool      object_refers_to(oop obj) const;\n@@ -333,0 +357,1 @@\n+  bool      try_enter(JavaThread* current);\n@@ -362,1 +387,4 @@\n-  bool      deflate_monitor();\n+  bool      deflate_monitor(Thread* current);\n+public:\n+  bool      deflate_anon_monitor(JavaThread* current);\n+private:\n@@ -366,0 +394,10 @@\n+\/\/ RAII object to ensure that ObjectMonitor::is_being_async_deflated() is\n+\/\/ stable within the context of this mark.\n+class ObjectMonitorContentionMark {\n+  ObjectMonitor* _monitor;\n+\n+public:\n+  ObjectMonitorContentionMark(ObjectMonitor* monitor);\n+  ~ObjectMonitorContentionMark();\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":41,"deletions":3,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"oops\/markWord.hpp\"\n@@ -33,0 +34,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -35,0 +37,2 @@\n+#include \"utilities\/checkedCast.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -37,1 +41,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -53,0 +57,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"Placeholder locking does not use header\");\n@@ -56,0 +61,4 @@\n+inline uintptr_t ObjectMonitor::header_value() const {\n+  return Atomic::load(&_header).value();\n+}\n+\n@@ -61,0 +70,1 @@\n+  assert(LockingMode != LM_PLACEHOLDER, \"Placeholder locking does not use header\");\n@@ -64,0 +74,10 @@\n+inline intptr_t ObjectMonitor::hash_placeholder() const {\n+  assert(LockingMode == LM_PLACEHOLDER, \"Only used by placeholder locking\");\n+  return Atomic::load(&_header).hash();\n+}\n+\n+inline void ObjectMonitor::set_hash_placeholder(intptr_t hash) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"Only used by placeholder locking\");\n+  Atomic::store(&_header, markWord::zero().copy_set_hash(hash));\n+}\n+\n@@ -183,0 +203,31 @@\n+inline ObjectMonitorContentionMark::ObjectMonitorContentionMark(ObjectMonitor* monitor)\n+  : _monitor(monitor) {\n+  _monitor->add_to_contentions(1);\n+}\n+\n+inline ObjectMonitorContentionMark::~ObjectMonitorContentionMark() {\n+  _monitor->add_to_contentions(-1);\n+}\n+\n+inline oop ObjectMonitor::object_peek() const {\n+  if (_object.is_null()) {\n+    return nullptr;\n+  }\n+  return _object.peek();\n+}\n+\n+inline bool ObjectMonitor::object_is_dead() const {\n+  return object_peek() == nullptr;\n+}\n+\n+inline bool ObjectMonitor::object_is_cleared() const {\n+  return _object.is_null();\n+}\n+\n+inline bool ObjectMonitor::object_refers_to(oop obj) const {\n+  if (_object.is_null()) {\n+    return false;\n+  }\n+  return _object.peek() == obj;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":52,"deletions":1,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -0,0 +1,996 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"classfile\/vmSymbols.hpp\"\n+#include \"javaThread.inline.hpp\"\n+#include \"jfrfiles\/jfrEventClasses.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n+#include \"runtime\/lockStack.inline.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+#include \"runtime\/objectMonitor.inline.hpp\"\n+#include \"runtime\/perfData.inline.hpp\"\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n+#include \"runtime\/safepointVerifiers.hpp\"\n+#include \"runtime\/synchronizer.hpp\"\n+#include \"utilities\/concurrentHashTable.inline.hpp\"\n+\n+\n+\/\/\n+\/\/ Placeholder synchronization.\n+\/\/\n+\/\/ When the lightweight synchronization needs to use a monitor the link\n+\/\/ between the object and the monitor is stored in a concurrent hash table\n+\/\/ instead of in the mark word. This has the benefit that it further decouples\n+\/\/ the mark word from the synchronization code.\n+\/\/\n+\n+\/\/ ConcurrentHashTable storing links from objects to ObjectMonitors\n+class ObjectMonitorWorld : public CHeapObj<mtOMWorld> {\n+  struct Config {\n+    using Value = ObjectMonitor*;\n+    static uintx get_hash(Value const& value, bool* is_dead) {\n+      return (uintx)value->hash_placeholder();\n+    }\n+    static void* allocate_node(void* context, size_t size, Value const& value) {\n+      return AllocateHeap(size, mtOMWorld);\n+    };\n+    static void free_node(void* context, void* memory, Value const& value) {\n+      FreeHeap(memory);\n+    }\n+  };\n+  using ConcurrentTable = ConcurrentHashTable<Config, mtOMWorld>;\n+\n+  ConcurrentTable* _table;\n+  volatile bool _resize;\n+  uint32_t _shrink_count;\n+\n+  class Lookup : public StackObj {\n+    oop _obj;\n+\n+  public:\n+    Lookup(oop obj) : _obj(obj) {}\n+\n+    uintx get_hash() const {\n+      uintx hash = _obj->mark().hash();\n+      assert(hash != 0, \"should have a hash\");\n+      return hash;\n+    }\n+\n+    bool equals(ObjectMonitor** value) {\n+      \/\/ The entry is going to be removed soon.\n+      assert(*value != nullptr, \"must be\");\n+      return (*value)->object_refers_to(_obj);\n+    }\n+\n+    bool is_dead(ObjectMonitor** value) {\n+      assert(*value != nullptr, \"must be\");\n+      return (*value)->object_is_cleared();\n+    }\n+  };\n+\n+  class LookupMonitor : public StackObj {\n+    ObjectMonitor* _monitor;\n+\n+  public:\n+    LookupMonitor(ObjectMonitor* monitor) : _monitor(monitor) {}\n+\n+    uintx get_hash() const {\n+      return _monitor->hash_placeholder();\n+    }\n+\n+    bool equals(ObjectMonitor** value) {\n+      return (*value) == _monitor;\n+    }\n+\n+    bool is_dead(ObjectMonitor** value) {\n+      assert(*value != nullptr, \"must be\");\n+      return (*value)->object_is_dead();\n+    }\n+  };\n+\n+  static size_t max_log_size() {\n+    \/\/ TODO: Evaluate the max size, is 2 ** 21 to small.\n+    \/\/       Given the AvgMonitorsPerThreadEstimate default estimate\n+    \/\/\n+    return ConcurrentTable::DEFAULT_MAX_SIZE_LOG2;\n+  }\n+\n+  static size_t min_log_size() {\n+    \/\/ TODO: Evaluate the min size, currently ~= log(AvgMonitorsPerThreadEstimate default)\n+    return 10;\n+  }\n+\n+  template<typename V>\n+  static size_t clamp_log_size(V log_size) {\n+    return MAX2(MIN2(log_size, checked_cast<V>(max_log_size())), checked_cast<V>(min_log_size()));\n+  }\n+\n+  static size_t initial_log_size() {\n+    const size_t estimate = log2i(MAX2(os::processor_count(), 1)) + log2i(MAX2(AvgMonitorsPerThreadEstimate, size_t(1)));\n+    return clamp_log_size(estimate);\n+  }\n+\n+  static size_t grow_hint () {\n+    \/\/ TODO: Evaluate why 4 is a good grow hint.\n+    \/\/       Have seen grow hint hits when lower with a\n+    \/\/       load factor as low as 0.1. (Grow Hint = 3)\n+    \/\/ TODO: Evaluate the hash code used, are large buckets\n+    \/\/       expected even with a low load factor. Or is it\n+    \/\/       something with the hashing used.\n+    return ConcurrentTable::DEFAULT_GROW_HINT;\n+  }\n+\n+  static size_t log_shrink_difference() {\n+    \/\/ TODO: Evaluate shrink heuristics, currently disabled by\n+    \/\/       default, and only really shrinks if AvgMonitorsPerThreadEstimate\n+    \/\/       is also set to a none default value\n+    return 2;\n+  }\n+\n+public:\n+  ObjectMonitorWorld()\n+  : _table(new ConcurrentTable(initial_log_size(), max_log_size(), grow_hint())),\n+    _resize(false),\n+    _shrink_count(0) {}\n+\n+  void verify_monitor_get_result(oop obj, ObjectMonitor* monitor) {\n+#ifdef ASSERT\n+    if (SafepointSynchronize::is_at_safepoint()) {\n+      bool has_monitor = obj->mark().has_monitor();\n+      assert(has_monitor == (monitor != nullptr),\n+          \"Inconsistency between markWord and OMW table has_monitor: %s monitor: \" PTR_FORMAT,\n+          BOOL_TO_STR(has_monitor), p2i(monitor));\n+    }\n+#endif\n+  }\n+\n+  ObjectMonitor* monitor_get(Thread* current, oop obj) {\n+    ObjectMonitor* result = nullptr;\n+    Lookup lookup_f(obj);\n+    auto found_f = [&](ObjectMonitor** found) {\n+      assert((*found)->object_peek() == obj, \"must be\");\n+      result = *found;\n+    };\n+    _table->get(current, lookup_f, found_f);\n+    verify_monitor_get_result(obj, result);\n+    return result;\n+  }\n+\n+  void try_notify_grow() {\n+    if (!_table->is_max_size_reached() && !Atomic::load(&_resize)) {\n+      Atomic::store(&_resize, true);\n+      if (MonitorDeflation_lock->try_lock()) {\n+        MonitorDeflation_lock->notify();\n+        MonitorDeflation_lock->unlock();\n+      }\n+    }\n+  }\n+\n+  void set_table_max(JavaThread* current) {\n+    while (!_table->is_max_size_reached()) {\n+      _table->grow(current);\n+    }\n+  }\n+\n+  bool needs_shrink(size_t log_target, size_t log_size) {\n+    return OMShrinkCHT && log_target + log_shrink_difference() <= log_size;\n+  }\n+\n+  bool needs_grow(size_t log_target, size_t log_size) {\n+    return log_size < log_target;\n+  }\n+\n+  bool needs_resize(JavaThread* current, size_t ceiling, size_t count, size_t max) {\n+    const size_t log_size = _table->get_size_log2(current);\n+    const int log_ceiling = log2i_graceful(ceiling);\n+    const int log_max = log2i_graceful(max);\n+    const size_t log_count = log2i(MAX2(count, size_t(1)));\n+    const size_t log_target = clamp_log_size(MAX2(log_ceiling, log_max) + 2);\n+\n+    return needs_grow(log_target, log_size) || needs_shrink(log_target, log_size) || Atomic::load(&_resize);\n+  }\n+\n+  bool resize(JavaThread* current, size_t ceiling, size_t count, size_t max) {\n+    const size_t log_size = _table->get_size_log2(current);\n+    const int log_ceiling = log2i_graceful(ceiling);\n+    const int log_max = log2i_graceful(max);\n+    const size_t log_count = log2i(MAX2(count, size_t(1)));\n+    const size_t log_target = clamp_log_size(MAX2(log_ceiling, log_max) + 2);\n+    LogTarget(Info, monitorinflation) lt;\n+\n+    auto print_table_stats = [&]() {\n+      ResourceMark rm;\n+      LogStream ls(lt);\n+      auto vs_f = [](Config::Value* v) { return sizeof(Config::Value); };\n+      _table->statistics_to(current, vs_f, &ls, \"ObjectMonitorWorld\");\n+    };\n+\n+    bool success = true;\n+\n+    if (needs_grow(log_target, log_size)) {\n+      \/\/ Grow\n+      lt.print(\"Growing to %02zu->%02zu\", log_size, log_target);\n+      success = _table->grow(current, log_target);\n+      print_table_stats();\n+    } else if (!_table->is_max_size_reached() && Atomic::load(&_resize)) {\n+      lt.print(\"WARNING: Getting resize hints with Size: %02zu Ceiling: %2i Target: %02zu\", log_size, log_ceiling, log_target);\n+      print_table_stats();\n+      success = false;\n+    }\n+\n+    if (needs_shrink(log_target, log_size)) {\n+      _shrink_count++;\n+      \/\/ Shrink\n+      lt.print(\"Shrinking to %02zu->%02zu\", log_size, log_target);\n+      success = _table->shrink(current, log_target);\n+      print_table_stats();\n+    }\n+\n+    if (success) {\n+      Atomic::store(&_resize, _table->is_max_size_reached());\n+    }\n+\n+    return success;\n+  }\n+\n+  ObjectMonitor* monitor_put_get(Thread* current, ObjectMonitor* monitor, oop obj) {\n+    \/\/ Enter the monitor into the concurrent hashtable.\n+    ObjectMonitor* result = monitor;\n+    Lookup lookup_f(obj);\n+    auto found_f = [&](ObjectMonitor** found) {\n+      assert((*found)->object_peek() == obj, \"must be\");\n+      result = *found;\n+    };\n+    bool grow;\n+    _table->insert_get(current, lookup_f, monitor, found_f, &grow);\n+    verify_monitor_get_result(obj, result);\n+    if (grow) {\n+      try_notify_grow();\n+    }\n+    return result;\n+  }\n+\n+  bool remove_monitor_entry(Thread* current, ObjectMonitor* monitor) {\n+    LookupMonitor lookup_f(monitor);\n+    return _table->remove(current, lookup_f);\n+  }\n+\n+  bool contains_monitor(Thread* current, ObjectMonitor* monitor) {\n+    LookupMonitor lookup_f(monitor);\n+    bool result = false;\n+    auto found_f = [&](ObjectMonitor** found) {\n+      result = true;\n+    };\n+    _table->get(current, lookup_f, found_f);\n+    return result;\n+  }\n+\n+  void print_on(outputStream* st) {\n+    auto printer = [&] (ObjectMonitor** entry) {\n+       ObjectMonitor* om = *entry;\n+       oop obj = om->object_peek();\n+       st->print(\"monitor \" PTR_FORMAT \" \", p2i(om));\n+       st->print(\"object \" PTR_FORMAT, p2i(obj));\n+       assert(obj->mark().hash() == om->hash_placeholder(), \"hash must match\");\n+       st->cr();\n+       return true;\n+    };\n+    if (SafepointSynchronize::is_at_safepoint()) {\n+      _table->do_safepoint_scan(printer);\n+    } else {\n+      _table->do_scan(Thread::current(), printer);\n+    }\n+  }\n+};\n+\n+ObjectMonitorWorld* PlaceholderSynchronizer::_omworld = nullptr;\n+\n+ObjectMonitor* PlaceholderSynchronizer::get_or_insert_monitor_from_table(oop object, JavaThread* current, bool try_read, bool* inserted) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+\n+  if (try_read) {\n+    ObjectMonitor* monitor = read_monitor(current, object);\n+    if (monitor != nullptr) {\n+      *inserted = false;\n+      return monitor;\n+    }\n+  }\n+\n+  ObjectMonitor* alloced_monitor = new ObjectMonitor(object);\n+  alloced_monitor->set_owner_anonymous();\n+\n+  \/\/ Try insert monitor\n+  ObjectMonitor* monitor = add_monitor(current, alloced_monitor, object);\n+\n+  *inserted = alloced_monitor == monitor;\n+  if (!*inserted) {\n+    delete alloced_monitor;\n+  }\n+\n+  return monitor;\n+}\n+\n+static void log_inflate(Thread* current, oop object, const ObjectSynchronizer::InflateCause cause) {\n+  if (log_is_enabled(Trace, monitorinflation)) {\n+    ResourceMark rm(current);\n+    log_info(monitorinflation)(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n+                               INTPTR_FORMAT \", type='%s' cause %s\", p2i(object),\n+                               object->mark().value(), object->klass()->external_name(),\n+                               ObjectSynchronizer::inflate_cause_name(cause));\n+  }\n+}\n+\n+static void post_monitor_inflate_event(EventJavaMonitorInflate* event,\n+                                       const oop obj,\n+                                       ObjectSynchronizer::InflateCause cause) {\n+  assert(event != nullptr, \"invariant\");\n+  event->set_monitorClass(obj->klass());\n+  event->set_address((uintptr_t)(void*)obj);\n+  event->set_cause((u1)cause);\n+  event->commit();\n+}\n+\n+ObjectMonitor* PlaceholderSynchronizer::get_or_insert_monitor(oop object, JavaThread* current, const ObjectSynchronizer::InflateCause cause, bool try_read) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+\n+  EventJavaMonitorInflate event;\n+\n+  bool inserted;\n+  ObjectMonitor* monitor = get_or_insert_monitor_from_table(object, current, try_read, &inserted);\n+\n+  if (inserted) {\n+    \/\/ Hopefully the performance counters are allocated on distinct\n+    \/\/ cache lines to avoid false sharing on MP systems ...\n+    OM_PERFDATA_OP(Inflations, inc());\n+    log_inflate(current, object, cause);\n+    if (event.should_commit()) {\n+      post_monitor_inflate_event(&event, object, cause);\n+    }\n+\n+    \/\/ The monitor has an anonymous owner so it is safe from async deflation.\n+    ObjectSynchronizer::_in_use_list.add(monitor);\n+  }\n+\n+  return monitor;\n+}\n+\n+\/\/ Add the hashcode to the monitor to match the object and put it in the hashtable.\n+ObjectMonitor* PlaceholderSynchronizer::add_monitor(JavaThread* current, ObjectMonitor* monitor, oop obj) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(obj == monitor->object(), \"must be\");\n+\n+  intptr_t hash = obj->mark().hash();\n+  assert(hash != 0, \"must be set when claiming the object monitor\");\n+  monitor->set_hash_placeholder(hash);\n+\n+  return _omworld->monitor_put_get(current, monitor, obj);\n+}\n+\n+bool PlaceholderSynchronizer::remove_monitor(Thread* current, oop obj, ObjectMonitor* monitor) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(monitor->object_peek() == obj, \"must be, cleared objects are removed by is_dead\");\n+\n+  return _omworld->remove_monitor_entry(current, monitor);\n+}\n+\n+void PlaceholderSynchronizer::deflate_mark_word(oop obj) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must use lightweight locking\");\n+\n+  markWord mark = obj->mark_acquire();\n+  assert(!mark.has_no_hash(), \"obj with inflated monitor must have had a hash\");\n+\n+  while (mark.has_monitor()) {\n+    const markWord new_mark = mark.clear_lock_bits().set_unlocked();\n+    mark = obj->cas_set_mark(new_mark, mark);\n+  }\n+}\n+\n+void PlaceholderSynchronizer::initialize() {\n+  _omworld = new ObjectMonitorWorld();\n+\n+  if (!FLAG_IS_CMDLINE(AvgMonitorsPerThreadEstimate)) {\n+    \/\/ This is updated after ceiling is set and ObjectMonitorWorld is created;\n+    \/\/ TODO: Clean this up and find a good initial ceiling,\n+    \/\/       and initial HashTable size\n+    FLAG_SET_ERGO(AvgMonitorsPerThreadEstimate, 0);\n+  }\n+}\n+\n+void PlaceholderSynchronizer::set_table_max(JavaThread* current) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    return;\n+  }\n+  _omworld->set_table_max(current);\n+}\n+\n+bool PlaceholderSynchronizer::needs_resize(JavaThread *current) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    return false;\n+  }\n+  return _omworld->needs_resize(current,\n+                                  ObjectSynchronizer::in_use_list_ceiling(),\n+                                  ObjectSynchronizer::_in_use_list.count(),\n+                                  ObjectSynchronizer::_in_use_list.max());\n+}\n+\n+bool PlaceholderSynchronizer::resize_table(JavaThread* current) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    return true;\n+  }\n+  return _omworld->resize(current,\n+                          ObjectSynchronizer::in_use_list_ceiling(),\n+                          ObjectSynchronizer::_in_use_list.count(),\n+                          ObjectSynchronizer::_in_use_list.max());\n+}\n+\n+class LockStackInflateContendedLocks : private OopClosure {\n+ private:\n+  oop _contended_oops[LockStack::CAPACITY];\n+  int _length;\n+\n+  void do_oop(oop* o) final {\n+    oop obj = *o;\n+    if (obj->mark_acquire().has_monitor()) {\n+      if (_length > 0 && _contended_oops[_length-1] == obj) {\n+        \/\/ assert(VM_Version::supports_recursive_lightweight_locking(), \"must be\");\n+        \/\/ Recursive\n+        return;\n+      }\n+      _contended_oops[_length++] = obj;\n+    }\n+  }\n+\n+  void do_oop(narrowOop* o) final {\n+    ShouldNotReachHere();\n+  }\n+\n+ public:\n+  LockStackInflateContendedLocks() :\n+    _contended_oops(),\n+    _length(0) {};\n+\n+  void inflate(JavaThread* locking_thread, JavaThread* current) {\n+    locking_thread->lock_stack().oops_do(this);\n+    for (int i = 0; i < _length; i++) {\n+      PlaceholderSynchronizer::\n+        inflate_fast_locked_object(_contended_oops[i], locking_thread, current, ObjectSynchronizer::inflate_cause_vm_internal);\n+    }\n+  }\n+};\n+\n+void PlaceholderSynchronizer::ensure_lock_stack_space(JavaThread* locking_thread, JavaThread* current) {\n+  LockStack& lock_stack = locking_thread->lock_stack();\n+\n+  \/\/ Make room on lock_stack\n+  if (lock_stack.is_full()) {\n+    \/\/ Inflate contented objects\n+    LockStackInflateContendedLocks().inflate(locking_thread, current);\n+    if (lock_stack.is_full()) {\n+      \/\/ Inflate the oldest object\n+      inflate_fast_locked_object(lock_stack.bottom(), locking_thread, current, ObjectSynchronizer::inflate_cause_vm_internal);\n+    }\n+  }\n+}\n+\n+class VerifyThreadState {\n+  bool _no_safepoint;\n+  union {\n+    struct {} _dummy;\n+    NoSafepointVerifier _nsv;\n+  };\n+\n+public:\n+  VerifyThreadState(JavaThread* locking_thread, JavaThread* current) : _no_safepoint(locking_thread != current) {\n+    assert(current == Thread::current(), \"must be\");\n+    assert(locking_thread == current || locking_thread->is_obj_deopt_suspend(), \"locking_thread may not run concurrently\");\n+    if (_no_safepoint) {\n+      ::new (&_nsv) NoSafepointVerifier();\n+    }\n+  }\n+  ~VerifyThreadState() {\n+    if (_no_safepoint){\n+      _nsv.~NoSafepointVerifier();\n+    }\n+  }\n+};\n+\n+void PlaceholderSynchronizer::enter_for(Handle obj, BasicLock* lock, JavaThread* locking_thread) {\n+  enter(obj, lock, locking_thread, JavaThread::current());\n+}\n+\n+void PlaceholderSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* locking_thread, JavaThread* current) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  VerifyThreadState vts(locking_thread, current);\n+\n+  if (obj->klass()->is_value_based()) {\n+    ObjectSynchronizer::handle_sync_on_value_based_class(obj, locking_thread);\n+  }\n+\n+  locking_thread->inc_held_monitor_count();\n+\n+  if (lock != nullptr) {\n+    \/\/ This is cleared in the interpreter\n+    \/\/ TODO: All paths should have cleared this, assert it is 0\n+    \/\/       instead of clearing it here. Should maybe only be for\n+    \/\/       c++ ObjectLocks and compiler re-lock (check this)\n+    \/\/       Also double check JNI interactions, JNI does not have\n+    \/\/       a slot, so no cache, but is there a problem if JNI first\n+    \/\/       followed by recursive monitor enter exit\n+    lock->clear_displaced_header();\n+  }\n+\n+  SpinYield spin_yield(0, 2);\n+  bool first_time = true;\n+\n+  LockStack& lock_stack = locking_thread->lock_stack();\n+\n+  if (locking_thread != current) {\n+    \/\/ Relock objects from compiler thread\n+    oop o = obj();\n+    \/\/ Would like to fast lock here, but cannot ensure lock order\n+    \/\/ Inflate the relocked lock.\n+    bool entered = inflate_and_enter(o, lock, locking_thread, current, ObjectSynchronizer::inflate_cause_monitor_enter);\n+    assert(entered, \"relock must lock the object, without races\");\n+    return;\n+  }\n+\n+  if (!lock_stack.is_full() && lock_stack.try_recursive_enter(obj())) {\n+    \/\/ TODO: Maybe guard this by the value in the markWord (only is fast locked)\n+    \/\/       Currently this is done when exiting. Doing it early could remove,\n+    \/\/       LockStack::CAPACITY - 1 slow paths in the best case. But need to fix\n+    \/\/       some of the inflation counters for this change.\n+\n+    \/\/ Recursively fast locked\n+    return;\n+  }\n+\n+  if (lock_stack.contains(obj())) {\n+    ObjectMonitor* mon = inflate_fast_locked_object(obj(), locking_thread, current, ObjectSynchronizer::inflate_cause_monitor_enter);\n+    bool entered = mon->enter(locking_thread);\n+    locking_thread->om_set_monitor_cache(mon);\n+    if (lock != nullptr) {\n+      lock->set_displaced_header(mon);\n+    }\n+    assert(entered, \"recursive ObjectMonitor::enter must succeed\");\n+    return;\n+  }\n+\n+  const int spins = OMSpins;\n+  const int yields = OMYields;\n+\n+  while (true) {\n+\n+    SpinYield fast_lock_spin_yield(spins, yields);\n+    \/\/ Fast-locking does not use the 'lock' argument.\n+    markWord mark = obj()->mark_acquire();\n+    const bool try_spin = !first_time || !mark.has_monitor();\n+    for (int attempts = spins + yields; try_spin && attempts > 0; attempts--) {\n+      while (mark.is_unlocked()) {\n+        ensure_lock_stack_space(locking_thread, current);\n+        assert(!lock_stack.is_full(), \"must have made room on the lock stack\");\n+        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+        \/\/ Try to swing into 'fast-locked' state.\n+        markWord locked_mark = mark.set_fast_locked();\n+        markWord old_mark = mark;\n+        mark = obj()->cas_set_mark(locked_mark, old_mark);\n+        if (old_mark == mark) {\n+          \/\/ Successfully fast-locked, push object to lock-stack and return.\n+          lock_stack.push(obj());\n+          return;\n+        }\n+      }\n+\n+      fast_lock_spin_yield.wait();\n+      mark = obj()->mark_acquire();\n+    }\n+\n+    if (!first_time) {\n+      spin_yield.wait();\n+    }\n+\n+    if (inflate_and_enter(obj(), lock, locking_thread, current, ObjectSynchronizer::inflate_cause_monitor_enter)) {\n+      return;\n+    }\n+\n+    first_time = false;\n+  }\n+}\n+\n+void PlaceholderSynchronizer::exit(oop object, JavaThread* current) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  assert(current == Thread::current(), \"must be\");\n+\n+  bool first_try = true;\n+\n+  markWord mark = object->mark();\n+  assert(!mark.is_unlocked(), \"must be unlocked\");\n+\n+  LockStack& lock_stack = current->lock_stack();\n+  if (mark.is_fast_locked()) {\n+    if (lock_stack.try_recursive_exit(object)) {\n+      \/\/ This is a recursive exit which succeeded\n+      return;\n+    }\n+    if (lock_stack.is_recursive(object)) {\n+      \/\/ Must inflate recursive locks if try_recursive_exit fails\n+      \/\/ This happens for un-structured unlocks, could potentially\n+      \/\/ fix try_recursive_exit to handle these.\n+      inflate_fast_locked_object(object, current, current, ObjectSynchronizer::inflate_cause_vm_internal);\n+    }\n+  }\n+\n+retry:\n+  \/\/ Fast-locking does not use the 'lock' argument.\n+  while (mark.is_fast_locked()) {\n+    markWord unlocked_mark = mark.set_unlocked();\n+    markWord old_mark = mark;\n+    mark = object->cas_set_mark(unlocked_mark, old_mark);\n+    if (old_mark == mark) {\n+      \/\/ CAS successful, remove from lock_stack\n+      size_t recursion = lock_stack.remove(object) - 1;\n+      assert(recursion == 0, \"Should not have unlocked here\");\n+      return;\n+    }\n+  }\n+\n+  assert(mark.has_monitor(), \"must be\");\n+  \/\/ The monitor is\n+  ObjectMonitor* monitor = read_monitor(current, object);\n+  if (monitor->is_owner_anonymous()) {\n+    assert(current->lock_stack().contains(object), \"current must have object on its lock stack\");\n+    monitor->set_owner_from_anonymous(current);\n+    monitor->set_recursions(current->lock_stack().remove(object) - 1);\n+    current->_contended_inflation++;\n+  }\n+\n+  if (OMDeflateBeforeExit && first_try && monitor->recursions() == 0) {\n+    \/\/ Only deflate if recursions are 0 or the lock stack may become\n+    \/\/ imbalanced.\n+    first_try = false;\n+    if (monitor->deflate_anon_monitor(current)) {\n+      mark = object->mark();\n+      current->_exit_deflation++;\n+      goto retry;\n+    }\n+  }\n+\n+  monitor->exit(current);\n+}\n+\n+\/\/ TODO: Rename this. No idea what to call it, used by notify\/notifyall\/wait and jni exit\n+ObjectMonitor* PlaceholderSynchronizer::inflate_locked_or_imse(oop obj, const ObjectSynchronizer::InflateCause cause, TRAPS) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  JavaThread* current = THREAD;\n+\n+  for(;;) {\n+    markWord mark = obj->mark_acquire();\n+    if (mark.is_unlocked()) {\n+      \/\/ No lock, IMSE.\n+      THROW_MSG_(vmSymbols::java_lang_IllegalMonitorStateException(),\n+                \"current thread is not owner\", nullptr);\n+    }\n+\n+    if (mark.is_fast_locked()) {\n+      if (!current->lock_stack().contains(obj)) {\n+        \/\/ Fast locked by other thread, IMSE.\n+        THROW_MSG_(vmSymbols::java_lang_IllegalMonitorStateException(),\n+                  \"current thread is not owner\", nullptr);\n+      } else {\n+        \/\/ Current thread owns the lock, must inflate\n+        return inflate_fast_locked_object(obj, current, current, cause);\n+      }\n+    }\n+\n+    assert(mark.has_monitor(), \"must be\");\n+    ObjectMonitor* monitor = read_monitor(current, obj);\n+    if (monitor != nullptr) {\n+      if (monitor->is_owner_anonymous()) {\n+        LockStack& lock_stack = current->lock_stack();\n+        if (lock_stack.contains(obj)) {\n+          \/\/ Current thread owns the lock but someone else inflated\n+          \/\/ fix owner and pop lock stack\n+          monitor->set_owner_from_anonymous(current);\n+          monitor->set_recursions(lock_stack.remove(obj) - 1);\n+          current->_contended_inflation++;\n+        } else {\n+          \/\/ Fast locked (and inflated) by other thread, or deflation in progress, IMSE.\n+          THROW_MSG_(vmSymbols::java_lang_IllegalMonitorStateException(),\n+                    \"current thread is not owner\", nullptr);\n+        }\n+      }\n+      return monitor;\n+    }\n+  }\n+}\n+\n+ObjectMonitor* PlaceholderSynchronizer::inflate_fast_locked_object(oop object, JavaThread* locking_thread, JavaThread* current, const ObjectSynchronizer::InflateCause cause) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"only used for lightweight\");\n+  VerifyThreadState vts(locking_thread, current);\n+  assert(locking_thread->lock_stack().contains(object), \"locking_thread must have object on its lock stack\");\n+\n+  \/\/ Inflating requires a hash code\n+  FastHashCode(current, object);\n+\n+  markWord mark = object->mark_acquire();\n+  assert(!mark.is_unlocked(), \"Cannot be unlocked\");\n+\n+  ObjectMonitor* monitor;\n+\n+  for (;;) {\n+  \/\/ Fetch the monitor from the table\n+    monitor = get_or_insert_monitor(object, current, cause, true \/* try_read *\/);\n+\n+    if (monitor->is_owner_anonymous()) {\n+      assert(monitor == read_monitor(current, object), \"The monitor must be in the table\");\n+      \/\/ New fresh monitor\n+      break;\n+    }\n+\n+    os::naked_yield();\n+    assert(monitor->is_being_async_deflated(), \"Should be the reason\");\n+  }\n+\n+  \/\/ Set the mark word; loop to handle concurrent updates to other parts of the mark word\n+  while (mark.is_fast_locked()) {\n+    mark = object->cas_set_mark(mark.set_has_monitor(), mark);\n+  }\n+\n+  \/\/ Indicate that the monitor now has a known owner\n+  monitor->set_owner_from_anonymous(locking_thread);\n+\n+  \/\/ Remove the entry from the thread's lock stack\n+  monitor->set_recursions(locking_thread->lock_stack().remove(object) - 1);\n+\n+  locking_thread->om_set_monitor_cache(monitor);\n+\n+  if (cause == ObjectSynchronizer::inflate_cause_wait) {\n+    locking_thread->lock_stack().set_wait_was_inflated();\n+    locking_thread->_wait_inflation++;\n+  } else if (cause == ObjectSynchronizer::inflate_cause_monitor_enter) {\n+    locking_thread->_recursive_inflation++;\n+  } else if (cause == ObjectSynchronizer::inflate_cause_vm_internal) {\n+    locking_thread->_lock_stack_inflation++;\n+  }\n+\n+  return monitor;\n+}\n+\n+bool PlaceholderSynchronizer::inflate_and_enter(oop object, BasicLock* lock, JavaThread* locking_thread, JavaThread* current, const ObjectSynchronizer::InflateCause cause) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"only used for lightweight\");\n+  VerifyThreadState vts(locking_thread, current);\n+  NoSafepointVerifier nsv;\n+\n+  \/\/ Note: In some paths (deoptimization) the 'current' thread inflates and\n+  \/\/ enters the lock on behalf of the 'locking_thread' thread.\n+\n+  \/\/ Placeholder monitors require that hash codes are installed first\n+  FastHashCode(locking_thread, object);\n+\n+  ObjectMonitor* monitor = nullptr;\n+\n+  \/\/ Try to get the monitor from the thread-local cache.\n+  \/\/ There's no need to use the cache if we are locking\n+  \/\/ on behalf of another thread.\n+  if (current == locking_thread) {\n+    monitor = current->om_get_from_monitor_cache(object);\n+  }\n+\n+  \/\/ Get or create the monitor\n+  if (monitor == nullptr) {\n+    monitor = get_or_insert_monitor(object, current, cause, true \/* try_read *\/);\n+  }\n+\n+  if (monitor->try_enter(locking_thread)) {\n+    current->om_set_monitor_cache(monitor);\n+    if (lock != nullptr) {\n+      lock->set_displaced_header(monitor);\n+    }\n+    return true;\n+  }\n+\n+  \/\/ Holds is_being_async_deflated() stable throughout this function.\n+  ObjectMonitorContentionMark mark(monitor);\n+\n+  \/\/\/ First handle the case where the monitor from the table is deflated\n+  if (monitor->is_being_async_deflated()) {\n+    \/\/ The MonitorDeflation thread is deflating the monitor. The locking thread\n+    \/\/ can either help transition the mark word or yield \/ spin until further\n+    \/\/ progress have been made.\n+\n+    const markWord mark = object->mark_acquire();\n+\n+    if (mark.has_monitor()) {\n+      \/\/ Waiting on the deflation thread to remove the deflated monitor from the table.\n+      os::naked_yield();\n+\n+    } else if (mark.is_fast_locked()) {\n+      \/\/ Some other thread managed to fast-lock the lock, or this is a\n+      \/\/ recursive lock from the same thread; yield for the deflation\n+      \/\/ thread to remove the deflated monitor from the table.\n+      os::naked_yield();\n+\n+    } else {\n+      assert(mark.is_unlocked(), \"Implied\");\n+      \/\/ Retry immediately\n+    }\n+\n+    \/\/ Retry\n+    return false;\n+  }\n+\n+  for (;;) {\n+    const markWord mark = object->mark_acquire();\n+    \/\/ The mark can be in one of the following states:\n+    \/\/ *  inflated     - If the ObjectMonitor owner is anonymous\n+    \/\/                   and the locking_thread thread owns the object\n+    \/\/                   lock, then we make the locking_thread thread\n+    \/\/                   the ObjectMonitor owner and remove the\n+    \/\/                   lock from the locking_thread thread's lock stack.\n+    \/\/ *  fast-locked  - Coerce it to inflated from fast-locked.\n+    \/\/ *  neutral      - Inflate the object. Successful CAS is locked\n+\n+    \/\/ CASE: inflated\n+    if (mark.has_monitor()) {\n+      LockStack& lock_stack = locking_thread->lock_stack();\n+      if (monitor->is_owner_anonymous() && lock_stack.contains(object)) {\n+        \/\/ The lock is fast-locked by the locking thread,\n+        \/\/ convert it to a held monitor with a known owner.\n+        monitor->set_owner_from_anonymous(locking_thread);\n+        monitor->set_recursions(lock_stack.remove(object) - 1);\n+        locking_thread->_contended_recursive_inflation++;\n+      }\n+\n+      break; \/\/ Success\n+    }\n+\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by locking_thread or by some other thread.\n+    \/\/\n+    if (mark.is_fast_locked()) {\n+      markWord old_mark = object->cas_set_mark(mark.set_has_monitor(), mark);\n+      if (old_mark != mark) {\n+        \/\/ CAS failed\n+        continue;\n+      }\n+\n+      \/\/ Success! Return inflated monitor.\n+      LockStack& lock_stack = locking_thread->lock_stack();\n+      if (lock_stack.contains(object)) {\n+        \/\/ The lock is fast-locked by the locking thread,\n+        \/\/ convert it to a held monitor with a known owner.\n+        monitor->set_owner_from_anonymous(locking_thread);\n+        monitor->set_recursions(lock_stack.remove(object) - 1);\n+        locking_thread->_recursive_inflation++;\n+      }\n+\n+      break; \/\/ Success\n+    }\n+\n+    \/\/ CASE: neutral (unlocked)\n+\n+    \/\/ Catch if the object's header is not neutral (not locked and\n+    \/\/ not marked is what we care about here).\n+    assert(mark.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n+    markWord old_mark = object->cas_set_mark(mark.set_has_monitor(), mark);\n+    if (old_mark != mark) {\n+      \/\/ CAS failed\n+      continue;\n+    }\n+\n+    \/\/ Transitioned from unlocked to monitor means locking_thread owns the lock.\n+    monitor->set_owner_from_anonymous(locking_thread);\n+\n+    \/\/ Update the thread-local cache\n+    if (current == locking_thread) {\n+      current->om_set_monitor_cache(monitor);\n+      current->_unlocked_inflation++;\n+    }\n+\n+    return true;\n+  }\n+\n+  if (current == locking_thread && monitor->has_owner() && monitor->owner_raw() != locking_thread) {\n+    \/\/ Someone else owns the lock, take the time befor entering to fix the lock stack\n+    LockStackInflateContendedLocks().inflate(locking_thread, current);\n+  }\n+\n+  \/\/ enter can block for safepoints; clear the unhandled object oop\n+  PauseNoSafepointVerifier pnsv(&nsv);\n+  object = nullptr;\n+\n+  if (monitor->enter(locking_thread)) {\n+    \/\/ Update the thread-local cache\n+    if (current == locking_thread) {\n+      current->om_set_monitor_cache(monitor);\n+    }\n+    if (lock != nullptr) {\n+      lock->set_displaced_header(monitor);\n+    }\n+\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n+void PlaceholderSynchronizer::deflate_monitor(Thread* current, oop obj, ObjectMonitor* monitor) {\n+  if (obj != nullptr) {\n+    deflate_mark_word(obj);\n+  }\n+  bool removed = remove_monitor(current, obj, monitor);\n+  if (obj != nullptr) {\n+    assert(removed, \"Should have removed the entry if obj was alive\");\n+  }\n+}\n+\n+void PlaceholderSynchronizer::deflate_anon_monitor(Thread* current, oop obj, ObjectMonitor* monitor) {\n+  markWord mark = obj->mark_acquire();\n+  assert(!mark.has_no_hash(), \"obj with inflated monitor must have had a hash\");\n+\n+  while (mark.has_monitor()) {\n+    const markWord new_mark = mark.set_fast_locked();\n+    mark = obj->cas_set_mark(new_mark, mark);\n+  }\n+\n+  bool removed = remove_monitor(current, obj, monitor);\n+  assert(removed, \"Should have removed the entry\");\n+}\n+\n+ObjectMonitor* PlaceholderSynchronizer::read_monitor(Thread* current, oop obj) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  return _omworld->monitor_get(current, obj);\n+}\n+\n+bool PlaceholderSynchronizer::contains_monitor(Thread* current, ObjectMonitor* monitor) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+  return _omworld->contains_monitor(current, monitor);\n+}\n+\n+intptr_t PlaceholderSynchronizer::FastHashCode(Thread* current, oop obj) {\n+  assert(LockingMode == LM_PLACEHOLDER, \"must be\");\n+\n+  markWord mark = obj->mark_acquire();\n+  for(;;) {\n+    intptr_t hash = mark.hash();\n+    if (hash != 0) {\n+      return hash;\n+    }\n+\n+    hash = ObjectSynchronizer::get_next_hash(current, obj);\n+    const markWord old_mark = mark;\n+    const markWord new_mark = old_mark.copy_set_hash(hash);\n+\n+    mark = obj->cas_set_mark(new_mark, old_mark);\n+    if (old_mark == mark) {\n+      return hash;\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/runtime\/placeholderSynchronizer.cpp","additions":996,"deletions":0,"binary":false,"changes":996,"status":"added"},{"patch":"@@ -0,0 +1,75 @@\n+\/*\n+ * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_PLACEHOLDERSYNCHRONIZER_HPP\n+#define SHARE_RUNTIME_PLACEHOLDERSYNCHRONIZER_HPP\n+\n+#include \"memory\/allStatic.hpp\"\n+#include \"runtime\/objectMonitor.hpp\"\n+#include \"runtime\/synchronizer.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n+\n+class ObjectMonitorWorld;\n+\n+class PlaceholderSynchronizer : AllStatic {\n+private:\n+  static ObjectMonitorWorld* _omworld;\n+\n+  static ObjectMonitor* get_or_insert_monitor_from_table(oop object, JavaThread* current, bool try_read, bool* inserted);\n+  static ObjectMonitor* get_or_insert_monitor(oop object, JavaThread* current, const ObjectSynchronizer::InflateCause cause, bool try_read);\n+\n+  static ObjectMonitor* add_monitor(JavaThread* current, ObjectMonitor* monitor, oop obj);\n+  static bool remove_monitor(Thread* current, oop obj, ObjectMonitor* monitor);\n+\n+  static void deflate_mark_word(oop object);\n+\n+  static void ensure_lock_stack_space(JavaThread* locking_thread, JavaThread* current);\n+\n+ public:\n+  static void initialize();\n+\n+  static bool needs_resize(JavaThread* current);\n+  static bool resize_table(JavaThread* current);\n+  static void set_table_max(JavaThread* current);\n+\n+  static void enter_for(Handle obj, BasicLock* lock, JavaThread* locking_thread);\n+  static void enter(Handle obj, BasicLock* lock,  JavaThread* locking_thread, JavaThread* current);\n+  static void exit(oop object, JavaThread* current);\n+\n+  static ObjectMonitor* inflate_locked_or_imse(oop object, const ObjectSynchronizer::InflateCause cause, TRAPS);\n+  static ObjectMonitor* inflate_fast_locked_object(oop object, JavaThread* locking_thread, JavaThread* current, const ObjectSynchronizer::InflateCause cause);\n+  static bool inflate_and_enter(oop object, BasicLock* lock, JavaThread* locking_thread, JavaThread* current, const ObjectSynchronizer::InflateCause cause);\n+\n+  static void deflate_monitor(Thread* current, oop obj, ObjectMonitor* monitor);\n+  static void deflate_anon_monitor(Thread* current, oop obj, ObjectMonitor* monitor);\n+\n+  static ObjectMonitor* read_monitor(Thread* current, oop obj);\n+\n+  static bool contains_monitor(Thread* current, ObjectMonitor* monitor);\n+\n+  \/\/ NOTE: May not cause monitor inflation\n+  static intptr_t FastHashCode(Thread* current, oop obj);\n+};\n+\n+#endif \/\/ SHARE_RUNTIME_PLACEHOLDERSYNCHRONIZER_HPP\n","filename":"src\/hotspot\/share\/runtime\/placeholderSynchronizer.hpp","additions":75,"deletions":0,"binary":false,"changes":75,"status":"added"},{"patch":"@@ -879,0 +879,5 @@\n+\n+  \/\/ The oops in the monitor cache is cleared to prevent stale cache entries\n+  \/\/ from keeping dead objects alive. Because these oops are always cleared\n+  \/\/ before safepoint operations they are not visited in JavaThread::oops_do.\n+  _thread->om_clear_monitor_cache();\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -60,0 +60,1 @@\n+#include \"runtime\/globals.hpp\"\n@@ -76,0 +77,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -2956,0 +2958,2 @@\n+      } else if (LockingMode == LM_PLACEHOLDER) {\n+        buf[i] = (intptr_t)lock->displaced_header().value();\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"runtime\/placeholderSynchronizer.hpp\"\n@@ -70,0 +71,12 @@\n+ObjectMonitor* ObjectSynchronizer::read_monitor(markWord mark) {\n+  assert(LockingMode != LM_PLACEHOLDER, \"placeholder locking uses table\");\n+  return mark.monitor();\n+}\n+\n+ObjectMonitor* ObjectSynchronizer::read_monitor(Thread* current, oop obj, markWord mark) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n+    return read_monitor(mark);\n+  }\n+  return PlaceholderSynchronizer::read_monitor(current, obj);\n+}\n+\n@@ -279,0 +292,4 @@\n+\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    PlaceholderSynchronizer::initialize();\n+  }\n@@ -337,1 +354,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -352,1 +369,5 @@\n-    ObjectMonitor* const mon = mark.monitor();\n+    ObjectMonitor* const mon = read_monitor(current, obj, mark);\n+    if (LockingMode == LM_PLACEHOLDER && mon == nullptr) {\n+      \/\/ Racing with inflation\/deflation go slow path\n+      return false;\n+    }\n@@ -388,0 +409,4 @@\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    \/\/ Not using quick_enter for now.\n+    return false;\n+  }\n@@ -527,0 +552,5 @@\n+\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    return PlaceholderSynchronizer::enter_for(obj, lock, locking_thread);\n+  }\n+\n@@ -545,0 +575,5 @@\n+\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    return PlaceholderSynchronizer::enter(obj, lock, current, current);\n+  }\n+\n@@ -662,0 +697,4 @@\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    return PlaceholderSynchronizer::exit(object, current);\n+  }\n+\n@@ -711,1 +750,1 @@\n-            ObjectMonitor* m = mark.monitor();\n+            ObjectMonitor* m = read_monitor(mark);\n@@ -755,2 +794,10 @@\n-    ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_jni_enter);\n-    if (monitor->enter(current)) {\n+    ObjectMonitor* monitor;\n+    bool entered;\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      entered = PlaceholderSynchronizer::inflate_and_enter(obj(), nullptr, current, current, inflate_cause_jni_enter);\n+    } else {\n+      monitor = inflate(current, obj(), inflate_cause_jni_enter);\n+      entered = monitor->enter(current);\n+    }\n+\n+    if (entered) {\n@@ -768,3 +815,8 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, obj, inflate_cause_jni_exit);\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    monitor = PlaceholderSynchronizer::inflate_locked_or_imse(obj, inflate_cause_jni_exit, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n+    monitor = inflate(current, obj, inflate_cause_jni_exit);\n+  }\n@@ -803,0 +855,1 @@\n+\n@@ -808,4 +861,11 @@\n-  \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n-  \/\/ field is incremented before ownership is dropped and decremented\n-  \/\/ after ownership is regained.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_wait);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    current->lock_stack().clear_wait_was_inflated();\n+    monitor = PlaceholderSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_wait, CHECK_0);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated because the _waiters\n+    \/\/ field is incremented before ownership is dropped and decremented\n+    \/\/ after ownership is regained.\n+    monitor = inflate(current, obj(), inflate_cause_wait);\n+  }\n@@ -828,1 +888,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -839,3 +899,9 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped by the calling thread.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    monitor = PlaceholderSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped by the calling thread.\n+    monitor = inflate(current, obj(), inflate_cause_notify);\n+  }\n@@ -850,1 +916,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -861,3 +927,9 @@\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped by the calling thread.\n-  ObjectMonitor* monitor = inflate(current, obj(), inflate_cause_notify);\n+\n+  ObjectMonitor* monitor;\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    monitor = PlaceholderSynchronizer::inflate_locked_or_imse(obj(), inflate_cause_notify, CHECK);\n+  } else {\n+    \/\/ The ObjectMonitor* can't be async deflated until ownership is\n+    \/\/ dropped by the calling thread.\n+    monitor = inflate(current, obj(), inflate_cause_notify);\n+  }\n@@ -885,1 +957,1 @@\n-  if (!mark.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT) {\n+  if (!mark.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n@@ -1001,0 +1073,5 @@\n+intptr_t ObjectSynchronizer::get_next_hash(Thread* current, oop obj) {\n+  \/\/ CLEANUP[Axel]: hack for PlaceholderSynchronizer being in different translation unit\n+  return ::get_next_hash(current, obj);\n+}\n+\n@@ -1002,0 +1079,3 @@\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    return PlaceholderSynchronizer::FastHashCode(current, obj);\n+  }\n@@ -1129,1 +1209,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+  if ((LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) && mark.is_fast_locked()) {\n@@ -1134,1 +1214,15 @@\n-  if (mark.has_monitor()) {\n+  while (LockingMode == LM_PLACEHOLDER && mark.has_monitor()) {\n+    ObjectMonitor* monitor = PlaceholderSynchronizer::read_monitor(current, obj);\n+    if (monitor != nullptr) {\n+      return monitor->is_entered(current) != 0;\n+    }\n+    \/\/ Racing with inflation\/deflation, retry\n+    mark = obj->mark_acquire();\n+\n+    if (mark.is_fast_locked()) {\n+      \/\/ Some other thread fast_locked, current could not have held the lock\n+      return false;\n+    }\n+  }\n+\n+  if (LockingMode != LM_PLACEHOLDER && mark.has_monitor()) {\n@@ -1138,1 +1232,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1156,1 +1250,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+  if ((LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) && mark.is_fast_locked()) {\n@@ -1162,1 +1256,15 @@\n-  if (mark.has_monitor()) {\n+  while (LockingMode == LM_PLACEHOLDER && mark.has_monitor()) {\n+    ObjectMonitor* monitor = PlaceholderSynchronizer::read_monitor(Thread::current(), obj);\n+    if (monitor != nullptr) {\n+      return Threads::owning_thread_from_monitor(t_list, monitor);\n+    }\n+    \/\/ Racing with inflation\/deflation, retry\n+    mark = obj->mark_acquire();\n+\n+    if (mark.is_fast_locked()) {\n+      \/\/ Some other thread fast_locked\n+      return Threads::owning_thread_from_object(t_list, h_obj());\n+    }\n+  }\n+\n+  if (LockingMode != LM_PLACEHOLDER && mark.has_monitor()) {\n@@ -1166,1 +1274,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1242,1 +1350,1 @@\n-    size_t new_ceiling = ceiling + (size_t)((double)ceiling * remainder) + 1;\n+    size_t new_ceiling = ceiling \/ remainder + 1;\n@@ -1378,0 +1486,3 @@\n+  if (LockingMode == LM_PLACEHOLDER) {\n+    return;\n+  }\n@@ -1380,1 +1491,1 @@\n-    ObjectMonitor* monitor = mark.monitor();\n+    ObjectMonitor* monitor = read_monitor(mark);\n@@ -1655,0 +1766,1 @@\n+  Thread* current = Thread::current();\n@@ -1661,1 +1773,1 @@\n-    if (mid->deflate_monitor()) {\n+    if (mid->deflate_monitor(current)) {\n@@ -1679,0 +1791,5 @@\n+    if (thread->is_Java_thread()) {\n+      \/\/ Clear OM cache\n+      JavaThread* jt = JavaThread::cast(thread);\n+      jt->om_clear_monitor_cache();\n+    }\n@@ -1825,0 +1942,8 @@\n+#ifdef ASSERT\n+    if (LockingMode == LM_PLACEHOLDER) {\n+      for (ObjectMonitor* monitor : delete_list) {\n+        assert(!PlaceholderSynchronizer::contains_monitor(current, monitor), \"Should have been removed\");\n+      }\n+    }\n+#endif\n+\n@@ -2051,1 +2176,2 @@\n-  if (n->header().value() == 0) {\n+\n+  if (n->header_value() == 0) {\n@@ -2056,0 +2182,1 @@\n+\n@@ -2057,17 +2184,21 @@\n-  if (obj != nullptr) {\n-    const markWord mark = obj->mark();\n-    if (!mark.has_monitor()) {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n-                    \"object does not think it has a monitor: obj=\"\n-                    INTPTR_FORMAT \", mark=\" INTPTR_FORMAT, p2i(n),\n-                    p2i(obj), mark.value());\n-      *error_cnt_p = *error_cnt_p + 1;\n-    }\n-    ObjectMonitor* const obj_mon = mark.monitor();\n-    if (n != obj_mon) {\n-      out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n-                    \"object does not refer to the same monitor: obj=\"\n-                    INTPTR_FORMAT \", mark=\" INTPTR_FORMAT \", obj_mon=\"\n-                    INTPTR_FORMAT, p2i(n), p2i(obj), mark.value(), p2i(obj_mon));\n-      *error_cnt_p = *error_cnt_p + 1;\n-    }\n+  if (obj == nullptr) {\n+    return;\n+  }\n+\n+  const markWord mark = obj->mark();\n+  if (!mark.has_monitor()) {\n+    out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                  \"object does not think it has a monitor: obj=\"\n+                  INTPTR_FORMAT \", mark=\" INTPTR_FORMAT, p2i(n),\n+                  p2i(obj), mark.value());\n+    *error_cnt_p = *error_cnt_p + 1;\n+    return;\n+  }\n+\n+  ObjectMonitor* const obj_mon = read_monitor(Thread::current(), obj, mark);\n+  if (n != obj_mon) {\n+    out->print_cr(\"ERROR: monitor=\" INTPTR_FORMAT \": in-use monitor's \"\n+                  \"object does not refer to the same monitor: obj=\"\n+                  INTPTR_FORMAT \", mark=\" INTPTR_FORMAT \", obj_mon=\"\n+                  INTPTR_FORMAT, p2i(n), p2i(obj), mark.value(), p2i(obj_mon));\n+    *error_cnt_p = *error_cnt_p + 1;\n@@ -2096,1 +2227,1 @@\n-        const markWord mark = monitor->header();\n+        const intptr_t hash = LockingMode == LM_PLACEHOLDER ? monitor->hash_placeholder() : monitor->header().hash();\n@@ -2099,1 +2230,1 @@\n-                   monitor->is_busy(), mark.hash() != 0, monitor->owner() != nullptr,\n+                   monitor->is_busy(), hash != 0, monitor->owner() != nullptr,\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":181,"deletions":50,"binary":false,"changes":231,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/javaThread.hpp\"\n@@ -136,0 +137,3 @@\n+  static ObjectMonitor* read_monitor(markWord mark);\n+  static ObjectMonitor* read_monitor(Thread* current, oop obj, markWord mark);\n+\n@@ -197,0 +201,3 @@\n+  friend class PlaceholderSynchronizer;\n+\n+  static intptr_t get_next_hash(Thread* current, oop obj);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -534,1 +534,1 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER, \"should not be called with new lightweight locking\");\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1209,1 +1209,1 @@\n-  assert(LockingMode != LM_LIGHTWEIGHT, \"Not with new lightweight locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER, \"Not with new lightweight locking\");\n@@ -1240,1 +1240,1 @@\n-  assert(LockingMode == LM_LIGHTWEIGHT, \"Only with new lightweight locking\");\n+  assert(LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER, \"Only with new lightweight locking\");\n@@ -1256,1 +1256,1 @@\n-  if (LockingMode == LM_LIGHTWEIGHT) {\n+  if (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER) {\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -249,3 +249,5 @@\n-          if (mark.has_monitor() &&\n-              ( \/\/ we have marked ourself as pending on this monitor\n-                mark.monitor() == thread()->current_pending_monitor() ||\n+          if (mark.has_monitor()) {\n+            \/\/ TODO: Fix\n+            ObjectMonitor* mon = ObjectSynchronizer::read_monitor(current, monitor->owner(), mark);\n+            if ( \/\/ we have marked ourself as pending on this monitor\n+                mon == thread()->current_pending_monitor() ||\n@@ -253,3 +255,3 @@\n-                !mark.monitor()->is_entered(thread())\n-              )) {\n-            lock_state = \"waiting to lock\";\n+                !mon->is_entered(thread())) {\n+              lock_state = \"waiting to lock\";\n+            }\n","filename":"src\/hotspot\/share\/runtime\/vframe.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2351,0 +2351,1 @@\n+  declare_constant(LM_PLACEHOLDER)                                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1025,1 +1025,3 @@\n-  LM_LIGHTWEIGHT = 2\n+  LM_LIGHTWEIGHT = 2,\n+  \/\/ New PLACEHOLDER locking based on lightweigh, with monitors as 2nd tier using OMWorld\n+  LM_PLACEHOLDER = 3\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -578,1 +578,1 @@\n-   st->print_cr(\"# Java VM: %s%s%s (%s%s, %s%s%s%s%s%s, %s, %s)\",\n+   st->print_cr(\"# Java VM: %s%s%s (%s%s, %s%s%s%s%s%s%s, %s, %s)\",\n@@ -593,0 +593,4 @@\n+                 LockingMode == LM_MONITOR ? \", lm_monitors\" :\n+                 LockingMode == LM_LEGACY ? \", lm_legacy\" :\n+                 LockingMode == LM_LIGHTWEIGHT ? \", lm_lightweight\" :\n+                 LockingMode == LM_PLACEHOLDER ? \", lm_placeholder\" : \"\",\n@@ -1119,1 +1123,1 @@\n-  STEP_IF(\"printing lock stack\", _verbose && _thread != nullptr && _thread->is_Java_thread() && LockingMode == LM_LIGHTWEIGHT);\n+  STEP_IF(\"printing lock stack\", _verbose && _thread != nullptr && _thread->is_Java_thread() && (LockingMode == LM_LIGHTWEIGHT || LockingMode == LM_PLACEHOLDER));\n","filename":"src\/hotspot\/share\/utilities\/vmError.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -159,0 +159,10 @@\n+    if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getPlaceholder()) {\n+      Iterator it = ObjectSynchronizer.objectMonitorIterator();\n+      while (it != null && it.hasNext()) {\n+        ObjectMonitor mon = (ObjectMonitor)it.next();\n+        if (getAddress().equals(mon.object())) {\n+          return mon;\n+        }\n+      }\n+      return null;\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+  private static int placeholder;\n@@ -47,0 +48,1 @@\n+    placeholder = db.lookupIntConstant(\"LM_PLACEHOLDER\").intValue();\n@@ -60,0 +62,4 @@\n+\n+  public static int getPlaceholder() {\n+    return placeholder;\n+  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/LockingMode.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -58,0 +58,3 @@\n+      if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getPlaceholder()) {\n+        return mark.hash();\n+      }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectSynchronizer.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -218,0 +218,1 @@\n+        assert(VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() != LockingMode.getPlaceholder());\n@@ -235,1 +236,2 @@\n-        if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLightweight()) {\n+        if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLightweight() ||\n+            VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getPlaceholder()) {\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT || !VM_Version::supports_recursive_lightweight_locking()) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n@@ -134,1 +134,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT || !VM_Version::supports_recursive_lightweight_locking()) {\n+  if (LockingMode != LM_PLACEHOLDER) {\n@@ -201,1 +201,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n+  if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER) {\n@@ -205,1 +205,1 @@\n-  const bool test_recursive = VM_Version::supports_recursive_lightweight_locking();\n+  const bool test_recursive = LockingMode == LM_PLACEHOLDER;\n@@ -267,1 +267,1 @@\n-  if (LockingMode != LM_LIGHTWEIGHT) {\n+  if (LockingMode != LM_LIGHTWEIGHT && LockingMode != LM_PLACEHOLDER) {\n@@ -271,1 +271,1 @@\n-  const bool test_recursive = VM_Version::supports_recursive_lightweight_locking();\n+  const bool test_recursive = LockingMode == LM_PLACEHOLDER;\n","filename":"test\/hotspot\/gtest\/runtime\/test_lockStack.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -33,0 +33,9 @@\n+\n+\/* @test\n+ * @summary Run LockStack gtests with LockingMode=3\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.xml\n+ * @requires vm.flagless\n+ * @run main\/native GTestWrapper --gtest_filter=LockStackTest* -XX:LockingMode=3\n+ *\/\n","filename":"test\/hotspot\/jtreg\/gtest\/LockStackGtests.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -57,0 +57,2 @@\n+    public volatile Object lockObject3Inflated;\n+    public volatile Object lockObject4Inflated;\n@@ -65,0 +67,15 @@\n+        lockObject3Inflated = new Object();\n+        lockObject4Inflated = new Object();\n+\n+        \/\/ Inflate the lock to use an ObjectMonitor\n+        try {\n+          synchronized (lockObject3Inflated) {\n+            lockObject3Inflated.wait(1);\n+          }\n+          synchronized (lockObject4Inflated) {\n+            lockObject4Inflated.wait(1);\n+          }\n+        } catch (InterruptedException e) {\n+          throw new RuntimeException(e);\n+        }\n+\n@@ -71,1 +88,1 @@\n-    public void testSimpleLockUnlock() {\n+    public void testBasicSimpleLockUnlockLocal() {\n@@ -81,0 +98,34 @@\n+    \/** Perform a synchronized on an object within a loop. *\/\n+    @Benchmark\n+    public void testBasicSimpleLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject1) {\n+                dummyInt1++;\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+    \/** Perform a synchronized on a local object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedSimpleLockUnlockLocal() {\n+        Object localObject = lockObject3Inflated;\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (localObject) {\n+                dummyInt1++;\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+    \/** Perform a synchronized on an object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedSimpleLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject3Inflated) {\n+                dummyInt1++;\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n@@ -83,1 +134,1 @@\n-    public void testRecursiveLockUnlock() {\n+    public void testBasicRecursiveLockUnlockLocal() {\n@@ -95,0 +146,13 @@\n+    \/** Perform a recursive synchronized on an object within a loop. *\/\n+    @Benchmark\n+    public void testBasicRecursiveLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject1) {\n+                synchronized (lockObject1) {\n+                    dummyInt1++;\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -97,1 +161,1 @@\n-    public void testSerialLockUnlock() {\n+    public void testBasicSerialLockUnlockLocal() {\n@@ -109,0 +173,120 @@\n+  \/** Perform two synchronized after each other on the same object. *\/\n+    @Benchmark\n+    public void testBasicSerialLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject1) {\n+                dummyInt1++;\n+            }\n+            synchronized (lockObject1) {\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+    \/** Perform two synchronized after each other on the same local object. *\/\n+    @Benchmark\n+    public void testInflatedSerialLockUnlockLocal() {\n+        Object localObject = lockObject3Inflated;\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (localObject) {\n+                dummyInt1++;\n+            }\n+            synchronized (localObject) {\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+  \/** Perform two synchronized after each other on the same object. *\/\n+    @Benchmark\n+    public void testInflatedSerialLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject3Inflated) {\n+                dummyInt1++;\n+            }\n+            synchronized (lockObject3Inflated) {\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+    \/** Perform two synchronized after each other on the same object. *\/\n+    @Benchmark\n+    public void testInflatedMultipleSerialLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject3Inflated) {\n+                dummyInt1++;\n+            }\n+            synchronized (lockObject4Inflated) {\n+                dummyInt2++;\n+            }\n+        }\n+    }\n+\n+    \/** Perform two synchronized after each other on the same object. *\/\n+    @Benchmark\n+    public void testInflatedMultipleRecursiveLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject3Inflated) {\n+                dummyInt1++;\n+                synchronized (lockObject4Inflated) {\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n+      \/** Perform a recursive-only synchronized on a local object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedRecursiveOnlyLockUnlockLocal() {\n+        Object localObject = lockObject3Inflated;\n+        synchronized (localObject) {\n+            for (int i = 0; i < innerCount; i++) {\n+                synchronized (localObject) {\n+                    dummyInt1++;\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n+    \/** Perform a recursive-only synchronized on an object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedRecursiveOnlyLockUnlock() {\n+        synchronized (lockObject3Inflated) {\n+            for (int i = 0; i < innerCount; i++) {\n+                synchronized (lockObject3Inflated) {\n+                    dummyInt1++;\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n+    \/** Perform a recursive-only synchronized on a local object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedRecursiveLockUnlockLocal() {\n+        Object localObject = lockObject3Inflated;\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (localObject) {\n+                synchronized (localObject) {\n+                    dummyInt1++;\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n+    \/** Perform a recursive-only synchronized on an object within a loop. *\/\n+    @Benchmark\n+    public void testInflatedRecursiveLockUnlock() {\n+        for (int i = 0; i < innerCount; i++) {\n+            synchronized (lockObject3Inflated) {\n+                synchronized (lockObject3Inflated) {\n+                    dummyInt1++;\n+                    dummyInt2++;\n+                }\n+            }\n+        }\n+    }\n+\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/lang\/LockUnlock.java","additions":187,"deletions":3,"binary":false,"changes":190,"status":"modified"}]}