{"files":[{"patch":"@@ -3997,29 +3997,7 @@\n-      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n-\n-      \/\/ Initialize the box. (Must happen before we update the object mark!)\n-      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ Compare object markWord with an unlocked value (tmp) and if\n-      \/\/ equal exchange the stack address of our box with object markWord.\n-      \/\/ On failure disp_hdr contains the possibly locked markWord.\n-      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n-                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n-      __ br(Assembler::EQ, cont);\n-\n-      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-      \/\/ object, will have now locked it will continue at label cont\n-\n-      \/\/ Check if the owner is self by comparing the value in the\n-      \/\/ markWord of object (disp_hdr) with the stack pointer.\n-      __ mov(rscratch1, sp);\n-      __ sub(disp_hdr, disp_hdr, rscratch1);\n-      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-      \/\/ If condition is true we are cont and hence we can store 0 as the\n-      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n-      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-    } else {\n-      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      Label slow;\n+      __ fast_lock(oop, disp_hdr, box, tmp, rscratch1, slow);\n+\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+      __ b(cont);\n+      __ bind(slow);\n@@ -4027,0 +4005,1 @@\n+    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -4040,7 +4019,0 @@\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n-    __ mov(tmp, (address)markWord::unused_mark().value());\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n@@ -4078,9 +4050,0 @@\n-    if (!UseHeavyMonitors) {\n-      \/\/ Find the lock address and load the displaced header from the stack.\n-      __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-      \/\/ If the displaced header is 0, we have a recursive unlock.\n-      __ cmp(disp_hdr, zr);\n-      __ br(Assembler::EQ, cont);\n-    }\n-\n@@ -4089,1 +4052,2 @@\n-    __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);\n+\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n@@ -4092,3 +4056,2 @@\n-      \/\/ Check if it is still a light weight lock, this is is true if we\n-      \/\/ see the stack address of the basicLock in the markWord of the\n-      \/\/ object.\n+      Label slow;\n+      __ tbnz(tmp, exact_log2(markWord::monitor_value), object_has_monitor);\n@@ -4096,4 +4059,7 @@\n-      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n-                 \/*release*\/ true, \/*weak*\/ false, tmp);\n-    } else {\n-      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      __ fast_unlock(oop, tmp, box, disp_hdr, slow);\n+\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+      __ b(cont);\n+\n+      __ bind(slow);\n@@ -4101,0 +4067,1 @@\n+    __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n@@ -4103,2 +4070,0 @@\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n@@ -4109,1 +4074,13 @@\n-    __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));\n+\n+    \/\/ If the owner is anonymous, we need to fix it -- in the slow-path.\n+    {\n+      Label L;\n+      __ ldr(disp_hdr, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n+      __ cmp(disp_hdr, (unsigned char)(intptr_t) ANONYMOUS_OWNER);\n+      __ br(Assembler::NE, L);\n+      __ tst(oop, oop); \/\/ Indicate failure at cont -- dive into slow-path.\n+      __ b(cont);\n+      __ bind(L);\n+    }\n+\n+   __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));\n@@ -16789,2 +16766,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP tmp2);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP tmp2, TEMP box);\n@@ -16804,2 +16781,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, TEMP tmp2);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP box, TEMP tmp, TEMP tmp2);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":37,"deletions":60,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -213,2 +213,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -223,2 +223,1 @@\n-  ce->store_parameter(_obj_reg->as_register(),  1);\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(),  0);\n@@ -240,5 +239,1 @@\n-  if (_compute_lock) {\n-    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(), 0);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_CodeStubs_aarch64.cpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -274,1 +274,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -279,1 +279,1 @@\n-        __ ldr(rscratch1, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+        __ ldr(rscratch1, Address(OSR_buf, slot_offset));\n@@ -285,3 +285,1 @@\n-      __ ldp(r19, r20, Address(OSR_buf, slot_offset));\n-      __ str(r19, frame_map()->address_for_monitor_lock(i));\n-      __ str(r20, frame_map()->address_for_monitor_object(i));\n+      __ ldr(r19, Address(OSR_buf, slot_offset));\n@@ -433,1 +431,2 @@\n-    stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);\n+    __ ldr(r4, Address(r0, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::r4_opr);\n@@ -2546,1 +2545,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2554,1 +2552,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -2669,1 +2666,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -315,1 +315,1 @@\n-  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n@@ -324,2 +324,2 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n-                        x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n+                x->monitor_no(), info_for_exception, info);\n@@ -335,1 +335,1 @@\n-  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n@@ -338,1 +338,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), new_register(T_INT), x->monitor_no());\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -72,3 +72,0 @@\n-  \/\/ save object being locked into the BasicObjectLock\n-  str(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-\n@@ -84,35 +81,2 @@\n-  \/\/ Load object header\n-  ldr(hdr, Address(obj, hdr_offset));\n-  \/\/ and mark it as unlocked\n-  orr(hdr, hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  lea(rscratch2, Address(obj, hdr_offset));\n-  cmpxchgptr(hdr, disp_hdr, rscratch2, rscratch1, done, \/*fallthough*\/NULL);\n-  \/\/ if the object header was the same, we're done\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) sp <= hdr\n-  \/\/ 3) hdr <= sp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - sp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  mov(rscratch1, sp);\n-  sub(hdr, hdr, rscratch1);\n-  ands(hdr, hdr, aligned_mask - os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  str(hdr, Address(disp_hdr, 0));\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  cbnz(hdr, slow_case);\n-  \/\/ done\n-  bind(done);\n+  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  fast_lock(obj, hdr, disp_hdr, rscratch1, rscratch2, slow_case);\n@@ -127,2 +91,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr);\n@@ -130,7 +93,0 @@\n-  \/\/ load displaced header\n-  ldr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  \/\/ if we had recursive locking, we are done\n-  cbz(hdr, done);\n-  \/\/ load object\n-  ldr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -138,13 +94,3 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  if (hdr_offset) {\n-    lea(rscratch1, Address(obj, hdr_offset));\n-    cmpxchgptr(disp_hdr, hdr, rscratch1, rscratch2, done, &slow_case);\n-  } else {\n-    cmpxchgptr(disp_hdr, hdr, obj, rscratch2, done, &slow_case);\n-  }\n-  \/\/ done\n-  bind(done);\n+\n+  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  fast_unlock(obj, hdr, rscratch1, rscratch2, slow_case);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":6,"deletions":60,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -876,2 +876,1 @@\n-        f.load_argument(1, r0); \/\/ r0,: object\n-        f.load_argument(0, r1); \/\/ r1,: lock address\n+        f.load_argument(0, r0); \/\/ r0,: object\n@@ -879,1 +878,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0, r1);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), r0);\n@@ -897,1 +896,1 @@\n-        f.load_argument(0, r0); \/\/ r0,: lock address\n+        f.load_argument(0, r0); \/\/ r0: object\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -733,0 +733,7 @@\n+\n+  const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+\n+  \/\/ Load object pointer into obj_reg %c_rarg3\n+  ldr(obj_reg, Address(lock_reg, obj_offset));\n+\n@@ -736,1 +743,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -742,6 +749,0 @@\n-    const Register obj_reg = c_rarg3; \/\/ Will contain the oop\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n@@ -751,3 +752,0 @@\n-    \/\/ Load object pointer into obj_reg %c_rarg3\n-    ldr(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -761,49 +759,3 @@\n-    \/\/ Load (object->mark() | 1) into swap_reg\n-    ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    orr(swap_reg, rscratch1, 1);\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-\n-    assert(lock_offset == 0,\n-           \"displached header must be first word in BasicObjectLock\");\n-\n-    Label fail;\n-    cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 7) == 0, and\n-    \/\/  2) sp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: sp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from sp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - sp) & (7 - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant 3 bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %r0 as the result of cmpxchg\n-    \/\/ NOTE2: aarch64 does not like to subtract sp from rn so take a\n-    \/\/ copy\n-    mov(rscratch1, sp);\n-    sub(swap_reg, swap_reg, rscratch1);\n-    ands(swap_reg, swap_reg, (uint64_t)(7 - os::vm_page_size()));\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    str(swap_reg, Address(lock_reg, mark_offset));\n-    br(Assembler::EQ, count);\n+    ldr(tmp, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_lock(obj_reg, tmp, rscratch1, swap_reg, rscratch2, slow_case);\n+    b(count);\n@@ -816,1 +768,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -842,0 +794,8 @@\n+  const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n+\n+  \/\/ Load oop into obj_reg(%c_rarg3)\n+  ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+  \/\/ Free entry\n+  str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n@@ -843,1 +803,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n@@ -845,1 +805,1 @@\n-    Label count, done;\n+    Label count, done, slow_case;\n@@ -849,1 +809,0 @@\n-    const Register obj_reg    = c_rarg3;  \/\/ Will contain the oop\n@@ -853,19 +812,3 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %r0\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n-    \/\/ Load oop into obj_reg(%c_rarg3)\n-    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Free entry\n-    str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(header_reg, Address(swap_reg,\n-                            BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    cbz(header_reg, count);\n-\n-    \/\/ Atomic swap back the old header\n-    cmpxchg_obj_header(swap_reg, header_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n+    ldr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_unlock(obj_reg, header_reg, swap_reg, rscratch1, slow_case);\n+    b(count);\n@@ -874,2 +817,2 @@\n-    str(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes())); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    bind(slow_case);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":27,"deletions":84,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -5956,0 +5956,46 @@\n+\n+\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n+\/\/ on failure.\n+\/\/ Registers:\n+\/\/  - obj: the object to be locked\n+\/\/  - hdr: the header, already loaded from obj, will be destroyed\n+\/\/  - t1, t2, t3: temporary registers, will be destroyed\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow) {\n+  \/\/ Check if we would have space on lock-stack for the object.\n+  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+  ldr(t2, Address(rthread, Thread::lock_stack_limit_offset()));\n+  cmp(t1, t2);\n+  br(Assembler::GE, slow);\n+\n+  \/\/ Load (object->mark() | 1) into hdr\n+  orr(hdr, hdr, markWord::unlocked_value);\n+  \/\/ Clear lock-bits, into t2\n+  eor(t2, hdr, markWord::unlocked_value);\n+  \/\/ Try to swing header from unlocked to locked\n+  cmpxchg(\/*addr*\/ obj, \/*expected*\/ hdr, \/*new*\/ t2, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t3);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful lock, push object on lock-stack\n+  str(obj, Address(t1, 0));\n+  add(t1, t1, oopSize);\n+  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+}\n+\n+void MacroAssembler::fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n+  andr(hdr, hdr, ~markWord::lock_mask_in_place);\n+\n+  \/\/ Load the new header (unlocked) into t1\n+  orr(t1, hdr, markWord::unlocked_value);\n+\n+  \/\/ Try to swing header from locked to unlocked\n+  cmpxchg(obj, hdr, t1, Assembler::xword,\n+          \/*acquire*\/ true, \/*release*\/ true, \/*weak*\/ false, t2);\n+  br(Assembler::NE, slow);\n+\n+  \/\/ After successful unlock, pop object from lock-stack\n+  ldr(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+  sub(t1, t1, oopSize);\n+  str(t1, Address(rthread, Thread::lock_stack_current_offset()));\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":46,"deletions":0,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -1567,0 +1567,3 @@\n+public:\n+  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Register t3, Label& slow);\n+  void fast_unlock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1238,1 +1238,0 @@\n-                                              in_ByteSize(-1),\n@@ -1266,1 +1265,0 @@\n-                                       in_ByteSize(-1),\n@@ -1326,1 +1324,0 @@\n-  int lock_slot_offset = 0;\n@@ -1339,1 +1336,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1354,2 +1350,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset\n@@ -1613,1 +1607,0 @@\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n@@ -1618,4 +1611,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -1626,28 +1615,2 @@\n-      \/\/ Load (object->mark() | 1) into swap_reg %r0\n-      __ ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ orr(swap_reg, rscratch1, 1);\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-\n-      \/\/ src -> dest iff dest == r0 else r0 <- dest\n-      __ cmpxchg_obj_header(r0, lock_reg, obj_reg, rscratch1, count, \/*fallthrough*\/NULL);\n-\n-      \/\/ Hmm should this move to the slow path code area???\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) sp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - sp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %r0 as the result of cmpxchg\n-\n-      __ sub(swap_reg, sp, swap_reg);\n-      __ neg(swap_reg, swap_reg);\n-      __ ands(swap_reg, swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ str(swap_reg, Address(lock_reg, mark_word_offset));\n-      __ br(Assembler::NE, slow_path_lock);\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock(obj_reg, old_hdr, swap_reg, tmp, rscratch1, slow_path_lock);\n@@ -1760,11 +1723,1 @@\n-    Label done, not_recursive;\n-\n-    if (!UseHeavyMonitors) {\n-      \/\/ Simple recursive lock?\n-      __ ldr(rscratch1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      __ cbnz(rscratch1, not_recursive);\n-      __ decrement(Address(rthread, JavaThread::held_monitor_count_offset()));\n-      __ b(done);\n-    }\n-\n-    __ bind(not_recursive);\n+    Label done;\n@@ -1778,9 +1731,2 @@\n-      \/\/ get address of the stack lock\n-      __ lea(r0, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ ldr(old_hdr, Address(r0, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      Label count;\n-      __ cmpxchg_obj_header(r0, old_hdr, obj_reg, rscratch1, count, &slow_path_unlock);\n-      __ bind(count);\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n@@ -1856,2 +1802,1 @@\n-    __ mov(c_rarg1, lock_reg);\n-    __ mov(c_rarg2, rthread);\n+    __ mov(c_rarg1, rthread);\n@@ -1885,2 +1830,1 @@\n-    __ mov(c_rarg2, rthread);\n-    __ lea(c_rarg1, Address(sp, lock_slot_offset * VMRegImpl::stack_slot_size));\n+    __ mov(c_rarg1, rthread);\n@@ -1990,1 +1934,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":7,"deletions":64,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -198,2 +198,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -208,1 +208,0 @@\n-  const Register lock_reg = _lock_reg->as_pointer_register();\n@@ -211,6 +210,1 @@\n-  if (obj_reg < lock_reg) {\n-    __ stmia(SP, RegisterSet(obj_reg) | RegisterSet(lock_reg));\n-  } else {\n-    __ str(obj_reg, Address(SP));\n-    __ str(lock_reg, Address(SP, BytesPerWord));\n-  }\n+  __ str(obj_reg, Address(SP));\n@@ -230,4 +224,1 @@\n-  if (_compute_lock) {\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  const Register lock_reg = _lock_reg->as_pointer_register();\n+  const Register obj_reg = _obj_reg->as_pointer_register();\n@@ -236,1 +227,1 @@\n-  __ str(lock_reg, Address(SP));\n+  __ str(obj_reg, Address(SP));\n","filename":"src\/hotspot\/cpu\/arm\/c1_CodeStubs_arm.cpp","additions":5,"deletions":14,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -152,1 +152,1 @@\n-  int monitor_offset = (method()->max_locals() + 2 * (number_of_locks - 1)) * BytesPerWord;\n+  int monitor_offset = (method()->max_locals() + (number_of_locks - 1)) * BytesPerWord;\n@@ -154,5 +154,3 @@\n-    int slot_offset = monitor_offset - (i * 2 * BytesPerWord);\n-    __ ldr(R1, Address(OSR_buf, slot_offset + 0*BytesPerWord));\n-    __ ldr(R2, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n-    __ str(R1, frame_map()->address_for_monitor_lock(i));\n-    __ str(R2, frame_map()->address_for_monitor_object(i));\n+    int slot_offset = monitor_offset - (i * BytesPerWord);\n+    __ ldr(R1, Address(OSR_buf, slot_offset));\n+    __ str(R1, frame_map()->address_for_monitor_object(i));\n@@ -246,2 +244,3 @@\n-    stub = new MonitorExitStub(FrameMap::R0_opr, true, 0);\n-    __ unlock_object(R2, R1, R0, *stub->entry());\n+    __ ldr(R1, Address(R0, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::R1_opr);\n+    __ b(*stub->entry());\n@@ -2434,17 +2433,2 @@\n-  if (UseHeavyMonitors) {\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check_here(op->info());\n-      __ null_check(obj);\n-    }\n-    __ b(*op->stub()->entry());\n-  } else if (op->code() == lir_lock) {\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check(null_check_offset, op->info());\n-    }\n-  } else if (op->code() == lir_unlock) {\n-    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n-  } else {\n-    ShouldNotReachHere();\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  __ b(*op->stub()->entry());\n@@ -2577,1 +2561,1 @@\n-  Address mon_addr = frame_map()->address_for_monitor_lock(monitor_no);\n+  Address mon_addr = frame_map()->address_for_monitor_object(monitor_no);\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRAssembler_arm.cpp","additions":10,"deletions":26,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -413,1 +413,0 @@\n-  LIR_Opr hdr  = new_pointer_register();\n@@ -421,1 +420,1 @@\n-  monitor_enter(obj.result(), lock, hdr, LIR_OprFact::illegalOpr,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n","filename":"src\/hotspot\/cpu\/arm\/c1_LIRGenerator_arm.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -184,88 +184,0 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  Label done, fast_lock, fast_lock_done;\n-  int null_check_offset = 0;\n-\n-  const Register tmp2 = Rtemp; \/\/ Rtemp should be free at c1 LIR level\n-  assert_different_registers(hdr, obj, disp_hdr, tmp2);\n-\n-  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n-  str(obj, Address(disp_hdr, obj_offset));\n-\n-  null_check_offset = offset();\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(tmp2, obj);\n-    ldr_u32(tmp2, Address(tmp2, Klass::access_flags_offset()));\n-    tst(tmp2, JVM_ACC_IS_VALUE_BASED_CLASS);\n-    b(slow_case, ne);\n-  }\n-\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n-\n-  \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-  \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n-\n-  \/\/ Must be the first instruction here, because implicit null check relies on it\n-  ldr(hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n-\n-  tst(hdr, markWord::unlocked_value);\n-  b(fast_lock, ne);\n-\n-  \/\/ Check for recursive locking\n-  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-  \/\/ explanations on the fast recursive locking check.\n-  \/\/ -1- test low 2 bits\n-  movs(tmp2, AsmOperand(hdr, lsl, 30));\n-  \/\/ -2- test (hdr - SP) if the low two bits are 0\n-  sub(tmp2, hdr, SP, eq);\n-  movs(tmp2, AsmOperand(tmp2, lsr, exact_log2(os::vm_page_size())), eq);\n-  \/\/ If still 'eq' then recursive locking OK\n-  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n-  str(tmp2, Address(disp_hdr, mark_offset));\n-  b(fast_lock_done, eq);\n-  \/\/ else need slow case\n-  b(slow_case);\n-\n-\n-  bind(fast_lock);\n-  \/\/ Save previous object header in BasicLock structure and update the header\n-  str(hdr, Address(disp_hdr, mark_offset));\n-\n-  cas_for_lock_acquire(hdr, disp_hdr, obj, tmp2, slow_case);\n-\n-  bind(fast_lock_done);\n-  bind(done);\n-\n-  return null_check_offset;\n-}\n-\n-void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  assert_different_registers(hdr, obj, disp_hdr, Rtemp);\n-  Register tmp2 = Rtemp;\n-\n-  assert(BasicObjectLock::lock_offset_in_bytes() == 0, \"adjust this code\");\n-  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-  const int mark_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n-  Label done;\n-\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"Required by atomic instructions\");\n-\n-  \/\/ Load displaced header and object from the lock\n-  ldr(hdr, Address(disp_hdr, mark_offset));\n-  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n-  cbz(hdr, done);\n-\n-  \/\/ load object\n-  ldr(obj, Address(disp_hdr, obj_offset));\n-\n-  \/\/ Restore the object header\n-  cas_for_lock_release(disp_hdr, hdr, obj, tmp2, slow_case);\n-\n-  bind(done);\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.cpp","additions":0,"deletions":88,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -62,4 +62,0 @@\n-  int lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n-\n-  void unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n-\n","filename":"src\/hotspot\/cpu\/arm\/c1_MacroAssembler_arm.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -629,1 +629,0 @@\n-        const Register lock = R2;\n@@ -632,2 +631,1 @@\n-        __ ldr(lock, Address(SP, arg2_offset));\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj, lock);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), obj);\n@@ -646,1 +644,1 @@\n-        const Register lock = R1;\n+        const Register obj = R1;\n@@ -648,2 +646,2 @@\n-        __ ldr(lock, Address(SP, arg1_offset));\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), lock);\n+        __ ldr(obj, Address(SP, arg1_offset));\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorexit), obj);\n","filename":"src\/hotspot\/cpu\/arm\/c1_Runtime1_arm.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -100,24 +100,2 @@\n-  ldr(Rmark, Address(Roop, oopDesc::mark_offset_in_bytes()));\n-  tst(Rmark, markWord::unlocked_value);\n-  b(fast_lock, ne);\n-\n-  \/\/ Check for recursive lock\n-  \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-  \/\/ explanations on the fast recursive locking check.\n-  \/\/ -1- test low 2 bits\n-  movs(Rscratch, AsmOperand(Rmark, lsl, 30));\n-  \/\/ -2- test (hdr - SP) if the low two bits are 0\n-  sub(Rscratch, Rmark, SP, eq);\n-  movs(Rscratch, AsmOperand(Rscratch, lsr, exact_log2(os::vm_page_size())), eq);\n-  \/\/ If still 'eq' then recursive locking OK\n-  \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8153107)\n-  str(Rscratch, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-  b(done);\n-\n-  bind(fast_lock);\n-  str(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-\n-  bool allow_fallthrough_on_failure = true;\n-  bool one_shot = true;\n-  cas_for_lock_acquire(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n-\n+  \/\/ TODO: Implement fast-locking.\n+  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n@@ -143,10 +121,2 @@\n-  ldr(Rmark, Address(Rbox, BasicLock::displaced_header_offset_in_bytes()));\n-  \/\/ If hdr is NULL, we've got recursive locking and there's nothing more to do\n-  cmp(Rmark, 0);\n-  b(done, eq);\n-\n-  \/\/ Restore the object header\n-  bool allow_fallthrough_on_failure = true;\n-  bool one_shot = true;\n-  cas_for_lock_release(Rmark, Rbox, Roop, Rscratch, done, allow_fallthrough_on_failure, one_shot);\n-\n+  \/\/ TODO: Implement fast-unlocking.\n+  tst(Roop, Roop); \/\/ Indicate failure -> take slow path\n","filename":"src\/hotspot\/cpu\/arm\/c2_MacroAssembler_arm.cpp","additions":4,"deletions":34,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -866,0 +866,3 @@\n+  const Register Robj = R2;\n+  assert_different_registers(Robj, Rlock);\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -867,24 +870,2 @@\n-  if (UseHeavyMonitors) {\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n-  } else {\n-    Label done;\n-\n-    const Register Robj = R2;\n-    const Register Rmark = R3;\n-    assert_different_registers(Robj, Rmark, Rlock, R0, Rtemp);\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n-\n-    Label already_locked, slow_case;\n-\n-    \/\/ Load object pointer\n-    ldr(Robj, Address(Rlock, obj_offset));\n-\n-    if (DiagnoseSyncOnValueBasedClasses != 0) {\n-      load_klass(R0, Robj);\n-      ldr_u32(R0, Address(R0, Klass::access_flags_offset()));\n-      tst(R0, JVM_ACC_IS_VALUE_BASED_CLASS);\n-      b(slow_case, ne);\n-    }\n+  \/\/ Load object pointer\n+  ldr(Robj, Address(Rlock, obj_offset));\n@@ -892,70 +873,3 @@\n-    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-    \/\/ That would be acceptable as ether CAS or slow case path is taken in that case.\n-    \/\/ Exception to that is if the object is locked by the calling thread, then the recursive test will pass (guaranteed as\n-    \/\/ loads are satisfied from a store queue if performed on the same processor).\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"must be\");\n-    ldr(Rmark, Address(Robj, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Test if object is already locked\n-    tst(Rmark, markWord::unlocked_value);\n-    b(already_locked, eq);\n-\n-    \/\/ Save old object->mark() into BasicLock's displaced header\n-    str(Rmark, Address(Rlock, mark_offset));\n-\n-    cas_for_lock_acquire(Rmark, Rlock, Robj, Rtemp, slow_case);\n-\n-    b(done);\n-\n-    \/\/ If we got here that means the object is locked by ether calling thread or another thread.\n-    bind(already_locked);\n-    \/\/ Handling of locked objects: recursive locks and slow case.\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & 3) == 0\n-    \/\/  2) SP <= mark < SP + os::pagesize()\n-    \/\/\n-    \/\/ Warning: SP + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from SP is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ Note: assuming SP is aligned, we can check the low bits of\n-    \/\/ (mark-SP) instead of the low bits of mark. In that case,\n-    \/\/ assuming page size is a power of 2, we can merge the two\n-    \/\/ conditions into a single test:\n-    \/\/ => ((mark - SP) & (3 - os::pagesize())) == 0\n-\n-    \/\/ (3 - os::pagesize()) cannot be encoded as an ARM immediate operand.\n-    \/\/ Check independently the low bits and the distance to SP.\n-    \/\/ -1- test low 2 bits\n-    movs(R0, AsmOperand(Rmark, lsl, 30));\n-    \/\/ -2- test (mark - SP) if the low two bits are 0\n-    sub(R0, Rmark, SP, eq);\n-    movs(R0, AsmOperand(R0, lsr, exact_log2(os::vm_page_size())), eq);\n-    \/\/ If still 'eq' then recursive locking OK: store 0 into lock record\n-    str(R0, Address(Rlock, mark_offset), eq);\n-\n-    b(done, eq);\n-\n-    bind(slow_case);\n-\n-    \/\/ Call the runtime routine for slow case\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), Rlock);\n-\n-    bind(done);\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  mov(R0, Robj);\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), R0);\n@@ -972,0 +886,3 @@\n+  const Register Robj = R2;\n+  assert_different_registers(Robj, Rlock);\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n@@ -973,38 +890,2 @@\n-  if (UseHeavyMonitors) {\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n-  } else {\n-    Label done, slow_case;\n-\n-    const Register Robj = R2;\n-    const Register Rmark = R3;\n-    assert_different_registers(Robj, Rmark, Rlock, Rtemp);\n-\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset + BasicLock::displaced_header_offset_in_bytes();\n-\n-    const Register Rzero = zero_register(Rtemp);\n-\n-    \/\/ Load oop into Robj\n-    ldr(Robj, Address(Rlock, obj_offset));\n-\n-    \/\/ Free entry\n-    str(Rzero, Address(Rlock, obj_offset));\n-\n-    \/\/ Load the old header from BasicLock structure\n-    ldr(Rmark, Address(Rlock, mark_offset));\n-\n-    \/\/ Test for recursion (zero mark in BasicLock)\n-    cbz(Rmark, done);\n-\n-    bool allow_fallthrough_on_failure = true;\n-\n-    cas_for_lock_release(Rlock, Rmark, Robj, Rtemp, slow_case, allow_fallthrough_on_failure);\n-\n-    b(done, eq);\n-\n-    bind(slow_case);\n-\n-    \/\/ Call the runtime routine for slow case.\n-    str(Robj, Address(Rlock, obj_offset)); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), Rlock);\n+  \/\/ Load oop into Robj\n+  ldr(Robj, Address(Rlock, obj_offset));\n@@ -1012,2 +893,3 @@\n-    bind(done);\n-  }\n+  \/\/ TODO: Implement fast-locking.\n+  mov(R0, Robj);\n+  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), R0);\n","filename":"src\/hotspot\/cpu\/arm\/interp_masm_arm.cpp","additions":16,"deletions":134,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -772,1 +772,0 @@\n-                                       in_ByteSize(-1),\n@@ -806,8 +805,0 @@\n-  \/\/ Plus a lock if needed\n-  int lock_slot_offset = 0;\n-  if (method->is_synchronized()) {\n-    lock_slot_offset = stack_slots;\n-    assert(sizeof(BasicLock) == wordSize, \"adjust this code\");\n-    stack_slots += VMRegImpl::slots_per_word;\n-  }\n-\n@@ -820,2 +811,0 @@\n-  int lock_slot_fp_offset = stack_size - 2 * wordSize -\n-    lock_slot_offset * VMRegImpl::stack_slot_size;\n@@ -1152,22 +1141,1 @@\n-    const Register mark = tmp;\n-    \/\/ On MP platforms the next load could return a 'stale' value if the memory location has been modified by another thread.\n-    \/\/ That would be acceptable as either CAS or slow case path is taken in that case\n-\n-    __ ldr(mark, Address(sync_obj, oopDesc::mark_offset_in_bytes()));\n-    __ sub(disp_hdr, FP, lock_slot_fp_offset);\n-    __ tst(mark, markWord::unlocked_value);\n-    __ b(fast_lock, ne);\n-\n-    \/\/ Check for recursive lock\n-    \/\/ See comments in InterpreterMacroAssembler::lock_object for\n-    \/\/ explanations on the fast recursive locking check.\n-    \/\/ Check independently the low bits and the distance to SP\n-    \/\/ -1- test low 2 bits\n-    __ movs(Rtemp, AsmOperand(mark, lsl, 30));\n-    \/\/ -2- test (hdr - SP) if the low two bits are 0\n-    __ sub(Rtemp, mark, SP, eq);\n-    __ movs(Rtemp, AsmOperand(Rtemp, lsr, exact_log2(os::vm_page_size())), eq);\n-    \/\/ If still 'eq' then recursive locking OK\n-    \/\/ set to zero if recursive lock, set to non zero otherwise (see discussion in JDK-8267042)\n-    __ str(Rtemp, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-    __ b(lock_done, eq);\n+    \/\/ TODO: Implement fast-locking.\n@@ -1175,6 +1143,0 @@\n-\n-    __ bind(fast_lock);\n-    __ str(mark, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    __ cas_for_lock_acquire(mark, disp_hdr, sync_obj, Rtemp, slow_lock);\n-\n@@ -1232,7 +1194,2 @@\n-\n-    \/\/ See C1_MacroAssembler::unlock_object() for more comments\n-    __ ldr(R2, Address(disp_hdr, BasicLock::displaced_header_offset_in_bytes()));\n-    __ cbz(R2, unlock_done);\n-\n-    __ cas_for_lock_release(disp_hdr, R2, sync_obj, Rtemp, slow_unlock);\n-\n+    \/\/ TODO: Implement fast-unlocking.\n+    __ b(slow_unlock);\n@@ -1294,2 +1251,1 @@\n-    __ mov(R1, disp_hdr);\n-    __ mov(R2, Rthread);\n+    __ mov(R1, Rthread);\n@@ -1314,2 +1270,1 @@\n-    __ mov(R1, disp_hdr);\n-    __ mov(R2, Rthread);\n+    __ mov(R1, Rthread);\n@@ -1332,1 +1287,0 @@\n-                                     in_ByteSize(lock_slot_offset * VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":5,"deletions":51,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -287,2 +287,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-  : MonitorAccessStub(obj_reg, lock_reg) {\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+  : MonitorAccessStub(obj_reg) {\n@@ -298,1 +298,0 @@\n-  assert(_lock_reg->as_register() == R5_ARG3, \"\");\n@@ -308,3 +307,0 @@\n-  if (_compute_lock) {\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n@@ -314,1 +310,1 @@\n-  assert(_lock_reg->as_register() == R4_ARG2, \"\");\n+  __ mr_if_needed(\/*scratch_opr()->as_register()*\/ R4_ARG2, _obj_reg->as_register());\n","filename":"src\/hotspot\/cpu\/ppc\/c1_CodeStubs_ppc.cpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -139,1 +139,1 @@\n-      (2 * BytesPerWord) * (number_of_locks - 1);\n+      BytesPerWord * (number_of_locks - 1);\n@@ -144,1 +144,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -157,3 +157,2 @@\n-      Address ml = frame_map()->address_for_monitor_lock(i),\n-              mo = frame_map()->address_for_monitor_object(i);\n-      assert(ml.index() == noreg && mo.index() == noreg, \"sanity\");\n+      Address mo = frame_map()->address_for_monitor_object(i);\n+      assert(mo.index() == noreg, \"sanity\");\n@@ -161,2 +160,0 @@\n-      __ std(R0, ml.disp(), ml.base());\n-      __ ld(R0, slot_offset + 1*BytesPerWord, OSR_buf);\n@@ -216,2 +213,3 @@\n-    stub = new MonitorExitStub(FrameMap::R4_opr, true, 0);\n-    __ unlock_object(R5, R6, R4, *stub->entry());\n+    __ ld(R4, BasicObjectLock::obj_offset_in_bytes(), R4);\n+    stub = new MonitorExitStub(FrameMap::R4_opr);\n+    __ b(*stub->entry());\n@@ -2665,1 +2663,1 @@\n-  Address mon_addr = frame_map()->address_for_monitor_lock(monitor_no);\n+  Address mon_addr = frame_map()->address_for_monitor_object(monitor_no);\n@@ -2682,23 +2680,9 @@\n-    if (!UseHeavyMonitors) {\n-      assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-      \/\/ Add debug info for NullPointerException only if one is possible.\n-      if (op->info() != NULL) {\n-        if (!os::zero_page_read_protected() || !ImplicitNullChecks) {\n-          explicit_null_check(obj, op->info());\n-        } else {\n-          add_debug_info_for_null_check_here(op->info());\n-        }\n-      }\n-      __ lock_object(hdr, obj, lock, op->scratch_opr()->as_register(), *op->stub()->entry());\n-    } else {\n-      \/\/ always do slow locking\n-      \/\/ note: The slow locking code could be inlined here, however if we use\n-      \/\/       slow locking, speed doesn't matter anyway and this solution is\n-      \/\/       simpler and requires less duplicated code - additionally, the\n-      \/\/       slow locking code is the same in either case which simplifies\n-      \/\/       debugging.\n-      if (op->info() != NULL) {\n-        add_debug_info_for_null_check_here(op->info());\n-        __ null_check(obj);\n-      }\n-      __ b(*op->stub()->entry());\n+    \/\/ always do slow locking\n+    \/\/ note: The slow locking code could be inlined here, however if we use\n+    \/\/       slow locking, speed doesn't matter anyway and this solution is\n+    \/\/       simpler and requires less duplicated code - additionally, the\n+    \/\/       slow locking code is the same in either case which simplifies\n+    \/\/       debugging.\n+    if (op->info() != NULL) {\n+      add_debug_info_for_null_check_here(op->info());\n+      __ null_check(obj);\n@@ -2706,0 +2690,1 @@\n+    __ b(*op->stub()->entry());\n@@ -2708,12 +2693,7 @@\n-    if (!UseHeavyMonitors) {\n-      assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-      __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n-    } else {\n-      \/\/ always do slow unlocking\n-      \/\/ note: The slow unlocking code could be inlined here, however if we use\n-      \/\/       slow unlocking, speed doesn't matter anyway and this solution is\n-      \/\/       simpler and requires less duplicated code - additionally, the\n-      \/\/       slow unlocking code is the same in either case which simplifies\n-      \/\/       debugging.\n-      __ b(*op->stub()->entry());\n-    }\n+    \/\/ always do slow unlocking\n+    \/\/ note: The slow unlocking code could be inlined here, however if we use\n+    \/\/       slow unlocking, speed doesn't matter anyway and this solution is\n+    \/\/       simpler and requires less duplicated code - additionally, the\n+    \/\/       slow unlocking code is the same in either case which simplifies\n+    \/\/       debugging.\n+    __ b(*op->stub()->entry());\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":25,"deletions":45,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -349,1 +349,1 @@\n-  monitor_enter(obj.result(), lock, hdr, scratch, x->monitor_no(), info_for_exception, info);\n+  monitor_enter(obj.result(), lock, hdr, scratch, new_register(T_INT), x->monitor_no(), info_for_exception, info);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRGenerator_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -95,97 +95,0 @@\n-\n-void C1_MacroAssembler::lock_object(Register Rmark, Register Roop, Register Rbox, Register Rscratch, Label& slow_case) {\n-  assert_different_registers(Rmark, Roop, Rbox, Rscratch);\n-\n-  Label done, cas_failed, slow_int;\n-\n-  \/\/ The following move must be the first instruction of emitted since debug\n-  \/\/ information may be generated for it.\n-  \/\/ Load object header.\n-  ld(Rmark, oopDesc::mark_offset_in_bytes(), Roop);\n-\n-  verify_oop(Roop, FILE_AND_LINE);\n-\n-  \/\/ Save object being locked into the BasicObjectLock...\n-  std(Roop, BasicObjectLock::obj_offset_in_bytes(), Rbox);\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(Rscratch, Roop);\n-    lwz(Rscratch, in_bytes(Klass::access_flags_offset()), Rscratch);\n-    testbitdi(CCR0, R0, Rscratch, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n-    bne(CCR0, slow_int);\n-  }\n-\n-  \/\/ ... and mark it unlocked.\n-  ori(Rmark, Rmark, markWord::unlocked_value);\n-\n-  \/\/ Save unlocked object header into the displaced header location on the stack.\n-  std(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-\n-  \/\/ Compare object markWord with Rmark and if equal exchange Rscratch with object markWord.\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"cas must take a zero displacement\");\n-  cmpxchgd(\/*flag=*\/CCR0,\n-           \/*current_value=*\/Rscratch,\n-           \/*compare_value=*\/Rmark,\n-           \/*exchange_value=*\/Rbox,\n-           \/*where=*\/Roop\/*+0==mark_offset_in_bytes*\/,\n-           MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n-           MacroAssembler::cmpxchgx_hint_acquire_lock(),\n-           noreg,\n-           &cas_failed,\n-           \/*check without membar and ldarx first*\/true);\n-  \/\/ If compare\/exchange succeeded we found an unlocked object and we now have locked it\n-  \/\/ hence we are done.\n-  b(done);\n-\n-  bind(slow_int);\n-  b(slow_case); \/\/ far\n-\n-  bind(cas_failed);\n-  \/\/ We did not find an unlocked object so see if this is a recursive case.\n-  sub(Rscratch, Rscratch, R1_SP);\n-  load_const_optimized(R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-  and_(R0\/*==0?*\/, Rscratch, R0);\n-  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-  bne(CCR0, slow_int);\n-\n-  bind(done);\n-}\n-\n-\n-void C1_MacroAssembler::unlock_object(Register Rmark, Register Roop, Register Rbox, Label& slow_case) {\n-  assert_different_registers(Rmark, Roop, Rbox);\n-\n-  Label slow_int, done;\n-\n-  Address mark_addr(Roop, oopDesc::mark_offset_in_bytes());\n-  assert(mark_addr.disp() == 0, \"cas must take a zero displacement\");\n-\n-  \/\/ Test first it it is a fast recursive unlock.\n-  ld(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-  cmpdi(CCR0, Rmark, 0);\n-  beq(CCR0, done);\n-\n-  \/\/ Load object.\n-  ld(Roop, BasicObjectLock::obj_offset_in_bytes(), Rbox);\n-  verify_oop(Roop, FILE_AND_LINE);\n-\n-  \/\/ Check if it is still a light weight lock, this is is true if we see\n-  \/\/ the stack address of the basicLock in the markWord of the object.\n-  cmpxchgd(\/*flag=*\/CCR0,\n-           \/*current_value=*\/R0,\n-           \/*compare_value=*\/Rbox,\n-           \/*exchange_value=*\/Rmark,\n-           \/*where=*\/Roop,\n-           MacroAssembler::MemBarRel,\n-           MacroAssembler::cmpxchgx_hint_release_lock(),\n-           noreg,\n-           &slow_int);\n-  b(done);\n-  bind(slow_int);\n-  b(slow_case); \/\/ far\n-\n-  \/\/ Done\n-  bind(done);\n-}\n-\n-\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":0,"deletions":97,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -45,4 +45,0 @@\n-  \/\/ locking\/unlocking\n-  void lock_object  (Register Rmark, Register Roop, Register Rbox, Register Rscratch, Label& slow_case);\n-  void unlock_object(Register Rmark, Register Roop, Register Rbox,                    Label& slow_case);\n-\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -612,1 +612,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), R4_ARG2, R5_ARG3);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), R4_ARG2);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_Runtime1_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -908,103 +908,1 @@\n-  if (UseHeavyMonitors) {\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-  } else {\n-    \/\/ template code:\n-    \/\/\n-    \/\/ markWord displaced_header = obj->mark().set_unlocked();\n-    \/\/ monitor->lock()->set_displaced_header(displaced_header);\n-    \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n-    \/\/   \/\/ We stored the monitor address into the object's mark word.\n-    \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n-    \/\/   \/\/ Simple recursive case.\n-    \/\/   monitor->lock()->set_displaced_header(NULL);\n-    \/\/ } else {\n-    \/\/   \/\/ Slow path.\n-    \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n-    \/\/ }\n-\n-    const Register displaced_header = R7_ARG5;\n-    const Register object_mark_addr = R8_ARG6;\n-    const Register current_header   = R9_ARG7;\n-    const Register tmp              = R10_ARG8;\n-\n-    Label done;\n-    Label cas_failed, slow_case;\n-\n-    assert_different_registers(displaced_header, object_mark_addr, current_header, tmp);\n-\n-    \/\/ markWord displaced_header = obj->mark().set_unlocked();\n-\n-    \/\/ Load markWord from object into displaced_header.\n-    ld(displaced_header, oopDesc::mark_offset_in_bytes(), object);\n-\n-    if (DiagnoseSyncOnValueBasedClasses != 0) {\n-      load_klass(tmp, object);\n-      lwz(tmp, in_bytes(Klass::access_flags_offset()), tmp);\n-      testbitdi(CCR0, R0, tmp, exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n-      bne(CCR0, slow_case);\n-    }\n-\n-    \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n-    ori(displaced_header, displaced_header, markWord::unlocked_value);\n-\n-    \/\/ monitor->lock()->set_displaced_header(displaced_header);\n-\n-    \/\/ Initialize the box (Must happen before we update the object mark!).\n-    std(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n-        BasicLock::displaced_header_offset_in_bytes(), monitor);\n-\n-    \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n-\n-    \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n-    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n-\n-    \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n-    \/\/ CmpxchgX sets CCR0 to cmpX(current, displaced).\n-    cmpxchgd(\/*flag=*\/CCR0,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/displaced_header, \/*exchange_value=*\/monitor,\n-             \/*where=*\/object_mark_addr,\n-             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n-             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n-             noreg,\n-             &cas_failed,\n-             \/*check without membar and ldarx first*\/true);\n-\n-    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-    \/\/ object and we have now locked it.\n-    b(done);\n-    bind(cas_failed);\n-\n-    \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n-    \/\/   \/\/ Simple recursive case.\n-    \/\/   monitor->lock()->set_displaced_header(NULL);\n-\n-    \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-    \/\/ Check if owner is self by comparing the value in the markWord of object\n-    \/\/ (current_header) with the stack pointer.\n-    sub(current_header, current_header, R1_SP);\n-\n-    assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n-    load_const_optimized(tmp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n-\n-    and_(R0\/*==0?*\/, current_header, tmp);\n-    \/\/ If condition is true we are done and hence we can store 0 in the displaced\n-    \/\/ header indicating it is a recursive lock.\n-    bne(CCR0, slow_case);\n-    std(R0\/*==0!*\/, BasicObjectLock::lock_offset_in_bytes() +\n-        BasicLock::displaced_header_offset_in_bytes(), monitor);\n-    b(done);\n-\n-    \/\/ } else {\n-    \/\/   \/\/ Slow path.\n-    \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n-\n-    \/\/ None of the above fast optimizations worked so we have to get into the\n-    \/\/ slow case of monitor enter.\n-    bind(slow_case);\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-    \/\/ }\n-    align(32, 12);\n-    bind(done);\n-  }\n+  call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n@@ -1021,79 +919,1 @@\n-  if (UseHeavyMonitors) {\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n-  } else {\n-\n-    \/\/ template code:\n-    \/\/\n-    \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n-    \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n-    \/\/   monitor->set_obj(NULL);\n-    \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n-    \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n-    \/\/   monitor->set_obj(NULL);\n-    \/\/ } else {\n-    \/\/   \/\/ Slow path.\n-    \/\/   InterpreterRuntime::monitorexit(monitor);\n-    \/\/ }\n-\n-    const Register object           = R7_ARG5;\n-    const Register displaced_header = R8_ARG6;\n-    const Register object_mark_addr = R9_ARG7;\n-    const Register current_header   = R10_ARG8;\n-\n-    Label free_slot;\n-    Label slow_case;\n-\n-    assert_different_registers(object, displaced_header, object_mark_addr, current_header);\n-\n-    \/\/ Test first if we are in the fast recursive case.\n-    ld(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n-           BasicLock::displaced_header_offset_in_bytes(), monitor);\n-\n-    \/\/ If the displaced header is zero, we have a recursive unlock.\n-    cmpdi(CCR0, displaced_header, 0);\n-    beq(CCR0, free_slot); \/\/ recursive unlock\n-\n-    \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n-    \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n-    \/\/   monitor->set_obj(NULL);\n-\n-    \/\/ If we still have a lightweight lock, unlock the object and be done.\n-\n-    \/\/ The object address from the monitor is in object.\n-    ld(object, BasicObjectLock::obj_offset_in_bytes(), monitor);\n-    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n-\n-    \/\/ We have the displaced header in displaced_header. If the lock is still\n-    \/\/ lightweight, it will contain the monitor address and we'll store the\n-    \/\/ displaced header back into the object's mark word.\n-    \/\/ CmpxchgX sets CCR0 to cmpX(current, monitor).\n-    cmpxchgd(\/*flag=*\/CCR0,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/monitor, \/*exchange_value=*\/displaced_header,\n-             \/*where=*\/object_mark_addr,\n-             MacroAssembler::MemBarRel,\n-             MacroAssembler::cmpxchgx_hint_release_lock(),\n-             noreg,\n-             &slow_case);\n-    b(free_slot);\n-\n-    \/\/ } else {\n-    \/\/   \/\/ Slow path.\n-    \/\/   InterpreterRuntime::monitorexit(monitor);\n-\n-    \/\/ The lock has been converted into a heavy lock and hence\n-    \/\/ we need to get into the slow case.\n-    bind(slow_case);\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n-    \/\/ }\n-\n-    Label done;\n-    b(done); \/\/ Monitor register may be overwritten! Runtime has already freed the slot.\n-\n-    \/\/ Exchange worked, do monitor->set_obj(NULL);\n-    align(32, 12);\n-    bind(free_slot);\n-    li(R0, 0);\n-    std(R0, BasicObjectLock::obj_offset_in_bytes(), monitor);\n-    bind(done);\n-  }\n+  call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":2,"deletions":182,"binary":false,"changes":184,"status":"modified"},{"patch":"@@ -2544,1 +2544,0 @@\n-  std(boxReg, BasicLock::displaced_header_offset_in_bytes(), boxReg);\n@@ -2652,26 +2651,2 @@\n-  if (!UseHeavyMonitors) {\n-    \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n-    ori(displaced_header, displaced_header, markWord::unlocked_value);\n-\n-    \/\/ Load Compare Value application register.\n-\n-    \/\/ Initialize the box. (Must happen before we update the object mark!)\n-    std(displaced_header, BasicLock::displaced_header_offset_in_bytes(), box);\n-\n-    \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n-    \/\/ Compare object markWord with mark and if equal exchange scratch1 with object markWord.\n-    cmpxchgd(\/*flag=*\/flag,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/displaced_header,\n-             \/*exchange_value=*\/box,\n-             \/*where=*\/oop,\n-             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n-             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n-             noreg,\n-             &cas_failed,\n-             \/*check without membar and ldarx first*\/true);\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-  } else {\n-    \/\/ Set NE to indicate 'failure' -> take slow-path.\n-    crandc(flag, Assembler::equal, flag, Assembler::equal);\n-  }\n+  \/\/ Set NE to indicate 'failure' -> take slow-path.\n+  crandc(flag, Assembler::equal, flag, Assembler::equal);\n@@ -2695,1 +2670,0 @@\n-  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -2722,2 +2696,0 @@\n-  \/\/ Store a non-null value into the box.\n-  std(box, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -2765,9 +2737,0 @@\n-  if (!UseHeavyMonitors) {\n-    \/\/ Find the lock address and load the displaced header from the stack.\n-    ld(displaced_header, BasicLock::displaced_header_offset_in_bytes(), box);\n-\n-    \/\/ If the displaced header is 0, we have a recursive unlock.\n-    cmpdi(flag, displaced_header, 0);\n-    beq(flag, cont);\n-  }\n-\n@@ -2781,18 +2744,2 @@\n-  if (!UseHeavyMonitors) {\n-    \/\/ Check if it is still a light weight lock, this is is true if we see\n-    \/\/ the stack address of the basicLock in the markWord of the object.\n-    \/\/ Cmpxchg sets flag to cmpd(current_header, box).\n-    cmpxchgd(\/*flag=*\/flag,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/box,\n-             \/*exchange_value=*\/displaced_header,\n-             \/*where=*\/oop,\n-             MacroAssembler::MemBarRel,\n-             MacroAssembler::cmpxchgx_hint_release_lock(),\n-             noreg,\n-             &cont);\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-  } else {\n-    \/\/ Set NE to indicate 'failure' -> take slow-path.\n-    crandc(flag, Assembler::equal, flag, Assembler::equal);\n-  }\n+  \/\/ Set NE to indicate 'failure' -> take slow-path.\n+  crandc(flag, Assembler::equal, flag, Assembler::equal);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":4,"deletions":57,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -1660,1 +1660,0 @@\n-                                       in_ByteSize(-1),\n@@ -1757,8 +1756,0 @@\n-  int lock_slot_offset = 0;\n-  int lock_offset      = -1;\n-  if (method->is_synchronized()) {                                                \/\/ 5)\n-    lock_slot_offset   = stack_slots;\n-    lock_offset        = lock_slot_offset * VMRegImpl::stack_slot_size;\n-    stack_slots       += VMRegImpl::slots_per_word;\n-  }\n-\n@@ -2016,3 +2007,0 @@\n-    \/\/ Get the lock box slot's address.\n-    __ addi(r_box, R1_SP, lock_offset);\n-\n@@ -2228,1 +2216,0 @@\n-    __ addi(r_box, R1_SP, lock_offset);\n@@ -2342,1 +2329,0 @@\n-                                            in_ByteSize(lock_offset),\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":0,"deletions":14,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -230,2 +230,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-  : MonitorAccessStub(obj_reg, lock_reg) {\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+  : MonitorAccessStub(obj_reg) {\n@@ -244,1 +244,0 @@\n-  __ lgr_if_needed(Z_R13, _lock_reg->as_register()); \/\/ See LIRGenerator::syncTempOpr().\n@@ -255,6 +254,1 @@\n-  if (_compute_lock) {\n-    \/\/ Lock_reg was destroyed by fast unlocking attempt => recompute it.\n-    ce->monitor_address(_monitor_ix, FrameMap::as_opr(Z_R1_scratch));\n-  } else {\n-    __ lgr_if_needed(Z_R1_scratch, _lock_reg->as_register());\n-  }\n+  __ lgr_if_needed(Z_R1_scratch, _obj_reg->as_register());\n","filename":"src\/hotspot\/cpu\/s390\/c1_CodeStubs_s390.cpp","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -139,1 +139,1 @@\n-      (2 * BytesPerWord) * (number_of_locks - 1);\n+      BytesPerWord * (number_of_locks - 1);\n@@ -144,1 +144,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -148,3 +148,1 @@\n-      __ z_lg(Z_R1_scratch, slot_offset + 0, OSR_buf);\n-      __ z_stg(Z_R1_scratch, frame_map()->address_for_monitor_lock(i));\n-      __ z_lg(Z_R1_scratch, slot_offset + 1*BytesPerWord, OSR_buf);\n+      __ z_lg(Z_R1_scratch, slot_offset, OSR_buf);\n@@ -221,2 +219,3 @@\n-    stub = new MonitorExitStub(lock, true, 0);\n-    __ unlock_object(Rtmp1, Rtmp2, lock->as_register(), *stub->entry());\n+    __ z_lg(Z_R1_scratch, Address(Z_R1_scratch, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(lock);\n+    __ branch_optimized(Assembler::bcondAlways, *stub->entry());\n@@ -2715,1 +2714,1 @@\n-  Address addr = frame_map()->address_for_monitor_lock(monitor_no);\n+  Address addr = frame_map()->address_for_monitor_object(monitor_no);\n@@ -2723,19 +2722,3 @@\n-  if (UseHeavyMonitors) {\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check_here(op->info());\n-      __ null_check(obj);\n-    }\n-    __ branch_optimized(Assembler::bcondAlways, *op->stub()->entry());\n-  } else if (op->code() == lir_lock) {\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    \/\/ Add debug info for NullPointerException only if one is possible.\n-    if (op->info() != NULL) {\n-      add_debug_info_for_null_check_here(op->info());\n-    }\n-    __ lock_object(hdr, obj, lock, *op->stub()->entry());\n-    \/\/ done\n-  } else if (op->code() == lir_unlock) {\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n-  } else {\n-    ShouldNotReachHere();\n+  if (op->info() != NULL) {\n+    add_debug_info_for_null_check_here(op->info());\n+    __ null_check(obj);\n@@ -2743,0 +2726,1 @@\n+  __ branch_optimized(Assembler::bcondAlways, *op->stub()->entry());\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRAssembler_s390.cpp","additions":11,"deletions":27,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -277,1 +277,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), new_register(T_INT), new_register(T_INT),\n","filename":"src\/hotspot\/cpu\/s390\/c1_LIRGenerator_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -81,79 +81,0 @@\n-void C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n-  assert_different_registers(hdr, obj, disp_hdr);\n-  NearLabel done;\n-\n-  verify_oop(obj, FILE_AND_LINE);\n-\n-  \/\/ Load object header.\n-  z_lg(hdr, Address(obj, hdr_offset));\n-\n-  \/\/ Save object being locked into the BasicObjectLock...\n-  z_stg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(Z_R1_scratch, obj);\n-    testbit(Address(Z_R1_scratch, Klass::access_flags_offset()), exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n-    z_btrue(slow_case);\n-  }\n-\n-  \/\/ and mark it as unlocked.\n-  z_oill(hdr, markWord::unlocked_value);\n-  \/\/ Save unlocked object header into the displaced header location on the stack.\n-  z_stg(hdr, Address(disp_hdr, (intptr_t)0));\n-  \/\/ Test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header. If it is not the same, get the\n-  \/\/ object header instead.\n-  z_csg(hdr, disp_hdr, hdr_offset, obj);\n-  \/\/ If the object header was the same, we're done.\n-  branch_optimized(Assembler::bcondEqual, done);\n-  \/\/ If the object header was not the same, it is now in the hdr register.\n-  \/\/ => Test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & markWord::lock_mask_in_place) == 0\n-  \/\/ 2) rsp <= hdr\n-  \/\/ 3) hdr <= rsp + page_size\n-  \/\/\n-  \/\/ These 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - Z_SP) & (~(page_size-1) | markWord::lock_mask_in_place)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  z_sgr(hdr, Z_SP);\n-\n-  load_const_optimized(Z_R0_scratch, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-  z_ngr(hdr, Z_R0_scratch); \/\/ AND sets CC (result eq\/ne 0).\n-  \/\/ For recursive locking, the result is zero. => Save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking).\n-  z_stg(hdr, Address(disp_hdr, (intptr_t)0));\n-  \/\/ Otherwise we don't care about the result and handle locking via runtime call.\n-  branch_optimized(Assembler::bcondNotZero, slow_case);\n-  \/\/ done\n-  bind(done);\n-}\n-\n-void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  const int aligned_mask = BytesPerWord -1;\n-  const int hdr_offset = oopDesc::mark_offset_in_bytes();\n-  assert_different_registers(hdr, obj, disp_hdr);\n-  NearLabel done;\n-\n-  \/\/ Load displaced header.\n-  z_ltg(hdr, Address(disp_hdr, (intptr_t)0));\n-  \/\/ If the loaded hdr is NULL we had recursive locking, and we are done.\n-  z_bre(done);\n-  \/\/ Load object.\n-  z_lg(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-  verify_oop(obj, FILE_AND_LINE);\n-  \/\/ Test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object. If the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead.\n-  z_csg(disp_hdr, hdr, hdr_offset, obj);\n-  \/\/ If the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call.\n-  branch_optimized(Assembler::bcondNotEqual, slow_case);\n-  \/\/ done\n-  bind(done);\n-}\n-\n","filename":"src\/hotspot\/cpu\/s390\/c1_MacroAssembler_s390.cpp","additions":0,"deletions":79,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -43,13 +43,0 @@\n-  \/\/ locking\n-  \/\/ hdr     : Used to hold locked markWord to be CASed into obj, contents destroyed.\n-  \/\/ obj     : Must point to the object to lock, contents preserved.\n-  \/\/ disp_hdr: Must point to the displaced header location, contents preserved.\n-  \/\/ Returns code offset at which to add null check debug information.\n-  void lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case);\n-\n-  \/\/ unlocking\n-  \/\/ hdr     : Used to hold original markWord to be CASed back into obj, contents destroyed.\n-  \/\/ obj     : Must point to the object to lock, contents preserved.\n-  \/\/ disp_hdr: Must point to the displaced header location, contents destroyed.\n-  void unlock_object(Register hdr, Register obj, Register lock, Label& slow_case);\n-\n","filename":"src\/hotspot\/cpu\/s390\/c1_MacroAssembler_s390.hpp","additions":0,"deletions":13,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -588,1 +588,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), Z_R1_scratch, Z_R13);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), Z_R1_scratch);\n","filename":"src\/hotspot\/cpu\/s390\/c1_Runtime1_s390.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -970,89 +970,0 @@\n-\n-  if (UseHeavyMonitors) {\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n-    return;\n-  }\n-\n-  \/\/ template code:\n-  \/\/\n-  \/\/ markWord displaced_header = obj->mark().set_unlocked();\n-  \/\/ monitor->lock()->set_displaced_header(displaced_header);\n-  \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n-  \/\/   \/\/ We stored the monitor address into the object's mark word.\n-  \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n-  \/\/   \/\/ Simple recursive case.\n-  \/\/   monitor->lock()->set_displaced_header(NULL);\n-  \/\/ } else {\n-  \/\/   \/\/ Slow path.\n-  \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n-  \/\/ }\n-\n-  const Register displaced_header = Z_ARG5;\n-  const Register object_mark_addr = Z_ARG4;\n-  const Register current_header   = Z_ARG5;\n-\n-  NearLabel done;\n-  NearLabel slow_case;\n-\n-  \/\/ markWord displaced_header = obj->mark().set_unlocked();\n-\n-  \/\/ Load markWord from object into displaced_header.\n-  z_lg(displaced_header, oopDesc::mark_offset_in_bytes(), object);\n-\n-  if (DiagnoseSyncOnValueBasedClasses != 0) {\n-    load_klass(Z_R1_scratch, object);\n-    testbit(Address(Z_R1_scratch, Klass::access_flags_offset()), exact_log2(JVM_ACC_IS_VALUE_BASED_CLASS));\n-    z_btrue(slow_case);\n-  }\n-\n-  \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n-  z_oill(displaced_header, markWord::unlocked_value);\n-\n-  \/\/ monitor->lock()->set_displaced_header(displaced_header);\n-\n-  \/\/ Initialize the box (Must happen before we update the object mark!).\n-  z_stg(displaced_header, BasicObjectLock::lock_offset_in_bytes() +\n-                          BasicLock::displaced_header_offset_in_bytes(), monitor);\n-\n-  \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n-\n-  \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n-  add2reg(object_mark_addr, oopDesc::mark_offset_in_bytes(), object);\n-\n-  z_csg(displaced_header, monitor, 0, object_mark_addr);\n-  assert(current_header==displaced_header, \"must be same register\"); \/\/ Identified two registers from z\/Architecture.\n-\n-  z_bre(done);\n-\n-  \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n-  \/\/   \/\/ Simple recursive case.\n-  \/\/   monitor->lock()->set_displaced_header(NULL);\n-\n-  \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-  \/\/ Check if owner is self by comparing the value in the markWord of object\n-  \/\/ (current_header) with the stack pointer.\n-  z_sgr(current_header, Z_SP);\n-\n-  assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n-\n-  \/\/ The prior sequence \"LGR, NGR, LTGR\" can be done better\n-  \/\/ (Z_R1 is temp and not used after here).\n-  load_const_optimized(Z_R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-  z_ngr(Z_R0, current_header); \/\/ AND sets CC (result eq\/ne 0)\n-\n-  \/\/ If condition is true we are done and hence we can store 0 in the displaced\n-  \/\/ header indicating it is a recursive lock and be done.\n-  z_brne(slow_case);\n-  z_release();  \/\/ Membar unnecessary on zarch AND because the above csg does a sync before and after.\n-  z_stg(Z_R0\/*==0!*\/, BasicObjectLock::lock_offset_in_bytes() +\n-                      BasicLock::displaced_header_offset_in_bytes(), monitor);\n-  z_bru(done);\n-\n-  \/\/ } else {\n-  \/\/   \/\/ Slow path.\n-  \/\/   InterpreterRuntime::monitorenter(THREAD, monitor);\n-\n-  \/\/ None of the above fast optimizations worked so we have to get into the\n-  \/\/ slow case of monitor enter.\n-  bind(slow_case);\n@@ -1060,4 +971,0 @@\n-\n-  \/\/ }\n-\n-  bind(done);\n@@ -1074,70 +981,0 @@\n-\n-  if (UseHeavyMonitors) {\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), monitor);\n-    return;\n-  }\n-\n-\/\/ else {\n-  \/\/ template code:\n-  \/\/\n-  \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n-  \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n-  \/\/   monitor->set_obj(NULL);\n-  \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n-  \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n-  \/\/   monitor->set_obj(NULL);\n-  \/\/ } else {\n-  \/\/   \/\/ Slow path.\n-  \/\/   InterpreterRuntime::monitorexit(monitor);\n-  \/\/ }\n-\n-  const Register displaced_header = Z_ARG4;\n-  const Register current_header   = Z_R1;\n-  Address obj_entry(monitor, BasicObjectLock::obj_offset_in_bytes());\n-  Label done;\n-\n-  if (object == noreg) {\n-    \/\/ In the template interpreter, we must assure that the object\n-    \/\/ entry in the monitor is cleared on all paths. Thus we move\n-    \/\/ loading up to here, and clear the entry afterwards.\n-    object = Z_ARG3; \/\/ Use Z_ARG3 if caller didn't pass object.\n-    z_lg(object, obj_entry);\n-  }\n-\n-  assert_different_registers(monitor, object, displaced_header, current_header);\n-\n-  \/\/ if ((displaced_header = monitor->displaced_header()) == NULL) {\n-  \/\/   \/\/ Recursive unlock. Mark the monitor unlocked by setting the object field to NULL.\n-  \/\/   monitor->set_obj(NULL);\n-\n-  clear_mem(obj_entry, sizeof(oop));\n-\n-  \/\/ Test first if we are in the fast recursive case.\n-  MacroAssembler::load_and_test_long(displaced_header,\n-                                     Address(monitor, BasicObjectLock::lock_offset_in_bytes() +\n-                                                      BasicLock::displaced_header_offset_in_bytes()));\n-  z_bre(done); \/\/ displaced_header == 0 -> goto done\n-\n-  \/\/ } else if (Atomic::cmpxchg(obj->mark_addr(), monitor, displaced_header) == monitor) {\n-  \/\/   \/\/ We swapped the unlocked mark in displaced_header into the object's mark word.\n-  \/\/   monitor->set_obj(NULL);\n-\n-  \/\/ If we still have a lightweight lock, unlock the object and be done.\n-\n-  \/\/ The markword is expected to be at offset 0.\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"unlock_object: review code below\");\n-\n-  \/\/ We have the displaced header in displaced_header. If the lock is still\n-  \/\/ lightweight, it will contain the monitor address and we'll store the\n-  \/\/ displaced header back into the object's mark word.\n-  z_lgr(current_header, monitor);\n-  z_csg(current_header, displaced_header, 0, object);\n-  z_bre(done);\n-\n-  \/\/ } else {\n-  \/\/   \/\/ Slow path.\n-  \/\/   InterpreterRuntime::monitorexit(monitor);\n-\n-  \/\/ The lock has been converted into a heavy lock and hence\n-  \/\/ we need to get into the slow case.\n-  z_stg(object, obj_entry);   \/\/ Restore object entry, has been cleared above.\n@@ -1145,4 +982,0 @@\n-\n-  \/\/ }\n-\n-  bind(done);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":0,"deletions":167,"binary":false,"changes":167,"status":"modified"},{"patch":"@@ -3162,3 +3162,0 @@\n-  \/\/ Initialize the box (must happen before we update the object mark).\n-  z_stg(displacedHeader, BasicLock::displaced_header_offset_in_bytes(), box);\n-\n@@ -3182,1 +3179,0 @@\n-  z_stg(currentHeader\/*==0 or not 0*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -3196,2 +3192,0 @@\n-  \/\/ Store a non-null value into the box.\n-  z_stg(box, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -3224,5 +3218,0 @@\n-  \/\/ Find the lock address and load the displaced header from the stack.\n-  \/\/ if the displaced header is zero, we have a recursive unlock.\n-  load_and_test_long(displacedHeader, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-  z_bre(done);\n-\n","filename":"src\/hotspot\/cpu\/s390\/macroAssembler_s390.cpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1325,1 +1325,0 @@\n-                                       in_ByteSize(-1),\n@@ -1432,2 +1431,0 @@\n-  \/\/     5| lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset\n@@ -1476,8 +1473,0 @@\n-  int lock_slot_offset = 0;\n-  int lock_offset      = -1;\n-  if (method->is_synchronized()) {                                        \/\/ 5)\n-    lock_slot_offset   = stack_slots;\n-    lock_offset        = lock_slot_offset * VMRegImpl::stack_slot_size;\n-    stack_slots       += VMRegImpl::slots_per_word;\n-  }\n-\n@@ -1712,4 +1701,0 @@\n-    lock_offset = (lock_slot_offset * VMRegImpl::stack_slot_size);\n-    \/\/ Get the lock box slot's address.\n-    __ add2reg(r_box, lock_offset, Z_SP);\n-\n@@ -1735,1 +1720,0 @@\n-    __ add2reg(Z_ARG2, lock_offset, oldSP);\n@@ -1910,3 +1894,0 @@\n-    \/\/ ... and address of lock object box.\n-    __ add2reg(r_box, lock_offset, Z_SP);\n-\n@@ -1936,2 +1917,1 @@\n-    __ add2reg(Z_ARG2, lock_offset, Z_SP);\n-    __ z_lgr(Z_ARG3, Z_thread);\n+    __ z_lgr(Z_ARG2, Z_thread);\n@@ -2044,1 +2024,0 @@\n-                                            in_ByteSize(lock_offset),\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":1,"deletions":22,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -260,2 +260,2 @@\n-MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info)\n-: MonitorAccessStub(obj_reg, lock_reg)\n+MonitorEnterStub::MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info)\n+: MonitorAccessStub(obj_reg)\n@@ -270,2 +270,1 @@\n-  ce->store_parameter(_obj_reg->as_register(),  1);\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(),  0);\n@@ -287,5 +286,1 @@\n-  if (_compute_lock) {\n-    \/\/ lock_reg was destroyed by fast unlocking attempt => recompute it\n-    ce->monitor_address(_monitor_ix, _lock_reg);\n-  }\n-  ce->store_parameter(_lock_reg->as_register(), 0);\n+  ce->store_parameter(_obj_reg->as_register(), 0);\n","filename":"src\/hotspot\/cpu\/x86\/c1_CodeStubs_x86.cpp","additions":4,"deletions":9,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -314,2 +314,1 @@\n-    \/\/ the OSR buffer using 2 word entries: first the lock and then\n-    \/\/ the oop.\n+    \/\/ the OSR buffer using a single word entries for the oop.\n@@ -317,1 +316,1 @@\n-      int slot_offset = monitor_offset - ((i * 2) * BytesPerWord);\n+      int slot_offset = monitor_offset - (i * BytesPerWord);\n@@ -322,1 +321,1 @@\n-        __ cmpptr(Address(OSR_buf, slot_offset + 1*BytesPerWord), (int32_t)NULL_WORD);\n+        __ cmpptr(Address(OSR_buf, slot_offset), (int32_t)NULL_WORD);\n@@ -328,3 +327,1 @@\n-      __ movptr(rbx, Address(OSR_buf, slot_offset + 0));\n-      __ movptr(frame_map()->address_for_monitor_lock(i), rbx);\n-      __ movptr(rbx, Address(OSR_buf, slot_offset + 1*BytesPerWord));\n+      __ movptr(rbx, Address(OSR_buf, slot_offset));\n@@ -455,2 +452,3 @@\n-    monitor_address(0, FrameMap::rax_opr);\n-    stub = new MonitorExitStub(FrameMap::rax_opr, true, 0);\n+    monitor_address(0, FrameMap::rdi_opr);\n+    __ movptr(rsi, Address(rdi, BasicObjectLock::obj_offset_in_bytes()));\n+    stub = new MonitorExitStub(FrameMap::rsi_oop_opr);\n@@ -460,1 +458,1 @@\n-      __ unlock_object(rdi, rsi, rax, *stub->entry());\n+      __ unlock_object(rax, rsi, rdi, *stub->entry());\n@@ -3504,0 +3502,1 @@\n+  Register tmp = op->scratch_opr()->as_register();\n@@ -3511,1 +3510,0 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n@@ -3513,1 +3511,1 @@\n-    int null_check_offset = __ lock_object(hdr, obj, lock, *op->stub()->entry());\n+    int null_check_offset = __ lock_object(hdr, obj, lock, tmp, *op->stub()->entry());\n@@ -3519,2 +3517,1 @@\n-    assert(BasicLock::displaced_header_offset_in_bytes() == 0, \"lock_reg must point to the displaced header\");\n-    __ unlock_object(hdr, obj, lock, *op->stub()->entry());\n+    __ unlock_object(hdr, obj, tmp, *op->stub()->entry());\n@@ -3789,1 +3786,1 @@\n-  __ lea(dst->as_register(), frame_map()->address_for_monitor_lock(monitor_no));\n+  __ lea(dst->as_register(), frame_map()->address_for_monitor_object(monitor_no));\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":12,"deletions":15,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -313,1 +313,3 @@\n-  LIR_Opr lock = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr tmp1 = new_register(T_INT);\n+  LIR_Opr tmp2 = new_register(T_INT);\n@@ -322,1 +324,1 @@\n-  monitor_enter(obj.result(), lock, syncTempOpr(), LIR_OprFact::illegalOpr,\n+  monitor_enter(obj.result(), lock, syncTempOpr(), tmp1, tmp2,\n@@ -333,2 +335,3 @@\n-  LIR_Opr lock = new_register(T_INT);\n-  LIR_Opr obj_temp = new_register(T_INT);\n+  LIR_Opr lock = new_register(T_ADDRESS);\n+  LIR_Opr obj_temp = new_register(T_ADDRESS);\n+  LIR_Opr tmp = new_register(T_INT);\n@@ -336,1 +339,1 @@\n-  monitor_exit(obj_temp, lock, syncTempOpr(), LIR_OprFact::illegalOpr, x->monitor_no());\n+  monitor_exit(obj_temp, lock, syncTempOpr(), tmp, x->monitor_no());\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n+int C1_MacroAssembler::lock_object(Register hdr, Register obj, Register disp_hdr, Register tmp, Label& slow_case) {\n@@ -42,1 +42,0 @@\n-  const int aligned_mask = BytesPerWord -1;\n@@ -45,2 +44,1 @@\n-  assert(hdr != obj && hdr != disp_hdr && obj != disp_hdr, \"registers must be different\");\n-  Label done;\n+  assert_different_registers(hdr, obj, disp_hdr, tmp);\n@@ -51,3 +49,0 @@\n-  \/\/ save object being locked into the BasicObjectLock\n-  movptr(Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()), obj);\n-\n@@ -63,1 +58,8 @@\n-  \/\/ Load object header\n+#ifdef _LP64\n+  const Register thread = r15_thread;\n+  const Register tmp2 = disp_hdr;\n+#else\n+  const Register thread = disp_hdr;\n+  get_thread(thread);\n+  const Register tmp2 = noreg;\n+#endif\n@@ -65,34 +67,1 @@\n-  \/\/ and mark it as unlocked\n-  orptr(hdr, markWord::unlocked_value);\n-  \/\/ save unlocked object header into the displaced header location on the stack\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ test if object header is still the same (i.e. unlocked), and if so, store the\n-  \/\/ displaced header address in the object header - if it is not the same, get the\n-  \/\/ object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(disp_hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was the same, we're done\n-  jcc(Assembler::equal, done);\n-  \/\/ if the object header was not the same, it is now in the hdr register\n-  \/\/ => test if it is a stack pointer into the same stack (recursive locking), i.e.:\n-  \/\/\n-  \/\/ 1) (hdr & aligned_mask) == 0\n-  \/\/ 2) rsp <= hdr\n-  \/\/ 3) hdr <= rsp + page_size\n-  \/\/\n-  \/\/ these 3 tests can be done by evaluating the following expression:\n-  \/\/\n-  \/\/ (hdr - rsp) & (aligned_mask - page_size)\n-  \/\/\n-  \/\/ assuming both the stack pointer and page_size have their least\n-  \/\/ significant 2 bits cleared and page_size is a power of 2\n-  subptr(hdr, rsp);\n-  andptr(hdr, aligned_mask - os::vm_page_size());\n-  \/\/ for recursive locking, the result is zero => save it in the displaced header\n-  \/\/ location (NULL in the displaced hdr location indicates recursive locking)\n-  movptr(Address(disp_hdr, 0), hdr);\n-  \/\/ otherwise we don't care about the result and handle locking via runtime call\n-  jcc(Assembler::notZero, slow_case);\n-  \/\/ done\n-  bind(done);\n-\n+  fast_lock_impl(obj, hdr, thread, tmp, tmp2, slow_case);\n@@ -100,1 +69,0 @@\n-\n@@ -104,2 +72,2 @@\n-void C1_MacroAssembler::unlock_object(Register hdr, Register obj, Register disp_hdr, Label& slow_case) {\n-  const int aligned_mask = BytesPerWord -1;\n+\n+void C1_MacroAssembler::unlock_object(Register disp_hdr, Register obj, Register hdr, Label& slow_case) {\n@@ -109,10 +77,0 @@\n-  Label done;\n-\n-  \/\/ load displaced header\n-  movptr(hdr, Address(disp_hdr, 0));\n-  \/\/ if the loaded hdr is NULL we had recursive locking\n-  testptr(hdr, hdr);\n-  \/\/ if we had recursive locking, we are done\n-  jcc(Assembler::zero, done);\n-  \/\/ load object\n-  movptr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n@@ -121,10 +79,0 @@\n-  \/\/ test if object header is pointing to the displaced header, and if so, restore\n-  \/\/ the displaced header in the object - if the object header is not pointing to\n-  \/\/ the displaced header, get the object header instead\n-  MacroAssembler::lock(); \/\/ must be immediately before cmpxchg!\n-  cmpxchgptr(hdr, Address(obj, hdr_offset));\n-  \/\/ if the object header was not pointing to the displaced header,\n-  \/\/ we do unlocking via runtime call\n-  jcc(Assembler::notEqual, slow_case);\n-  \/\/ done\n-  bind(done);\n@@ -132,0 +80,3 @@\n+  movptr(disp_hdr, Address(obj, hdr_offset));\n+  andptr(disp_hdr, ~(int32_t)markWord::lock_mask_in_place);\n+  fast_unlock_impl(obj, disp_hdr, hdr, slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":16,"deletions":65,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-  int lock_object  (Register swap, Register obj, Register disp_hdr, Label& slow_case);\n+  int lock_object  (Register swap, Register obj, Register disp_hdr, Register tmp, Label& slow_case);\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1311,1 +1311,1 @@\n-        OopMap* map = save_live_registers(sasm, 3, save_fpu_registers);\n+        OopMap* map = save_live_registers(sasm, 2, save_fpu_registers);\n@@ -1315,2 +1315,1 @@\n-        f.load_argument(1, rax); \/\/ rax,: object\n-        f.load_argument(0, rbx); \/\/ rbx,: lock address\n+        f.load_argument(0, rax); \/\/ rax,: object\n@@ -1318,1 +1317,1 @@\n-        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax, rbx);\n+        int call_offset = __ call_RT(noreg, noreg, CAST_FROM_FN_PTR(address, monitorenter), rax);\n@@ -1336,1 +1335,1 @@\n-        f.load_argument(0, rax); \/\/ rax,: lock address\n+        f.load_argument(0, rax); \/\/ rax: obj\n","filename":"src\/hotspot\/cpu\/x86\/c1_Runtime1_x86.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -414,2 +414,0 @@\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(boxReg, 0), (int32_t)intptr_t(markWord::unused_mark().value()));\n@@ -561,1 +559,1 @@\n-                                 Register scrReg, Register cx1Reg, Register cx2Reg,\n+                                 Register scrReg, Register cx1Reg, Register cx2Reg, Register thread,\n@@ -573,1 +571,1 @@\n-    assert_different_registers(objReg, boxReg, tmpReg, scrReg);\n+    assert_different_registers(objReg, boxReg, tmpReg, scrReg, cx1Reg);\n@@ -591,1 +589,1 @@\n-  Label IsInflated, DONE_LABEL, NO_COUNT, COUNT;\n+  Label IsInflated, DONE_LABEL, slow_path, NO_COUNT, COUNT;\n@@ -614,17 +612,3 @@\n-    \/\/ Attempt stack-locking ...\n-    orptr (tmpReg, markWord::unlocked_value);\n-    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n-    lock();\n-    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n-    jcc(Assembler::equal, COUNT);           \/\/ Success\n-\n-    \/\/ Recursive locking.\n-    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n-    \/\/ Locked by current thread if difference with current SP is less than one page.\n-    subptr(tmpReg, rsp);\n-    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n-    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n-    movptr(Address(boxReg, 0), tmpReg);\n-  } else {\n-    \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n-    testptr(objReg, objReg);\n+    fast_lock_impl(objReg, tmpReg, thread, scrReg, cx1Reg, slow_path);\n+    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n+    jmp(COUNT);\n@@ -632,0 +616,3 @@\n+  bind(slow_path);\n+  \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n+  testptr(objReg, objReg);\n@@ -671,3 +658,2 @@\n-  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  movptr(Address(scrReg, 0), 3);          \/\/ box->_displaced_header = 3\n-  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n+  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  \/\/ If we weren't able to swing _owner from NULL to the thread\n@@ -676,3 +662,0 @@\n-  \/\/ update _owner from BasicLock to thread\n-  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n@@ -693,4 +676,1 @@\n-  cmpxchgptr(r15_thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n-  \/\/ Unconditionally set box->_displaced_header = markWord::unused_mark().\n-  \/\/ Without cast to int32_t this style of movptr will destroy r10 which is typically obj.\n-  movptr(Address(boxReg, 0), (int32_t)intptr_t(markWord::unused_mark().value()));\n+  cmpxchgptr(thread, Address(scrReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -700,1 +680,1 @@\n-  cmpptr(r15_thread, rax);                \/\/ Check if we are already the owner (recursive lock)\n+  cmpptr(thread, rax);                     \/\/ Check if we are already the owner (recursive lock)\n@@ -790,0 +770,1 @@\n+  movptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Examine the object's markword\n@@ -791,7 +772,10 @@\n-    cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n-    jcc   (Assembler::zero, COUNT);                                   \/\/ 0 indicates recursive stack-lock\n-  }\n-  movptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes()));   \/\/ Examine the object's markword\n-  if (!UseHeavyMonitors) {\n-    testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n-    jccb   (Assembler::zero, Stacked);\n+    testptr(boxReg, markWord::monitor_value);\n+    jcc(Assembler::zero, Stacked);\n+\n+    \/\/ If the owner is ANONYMOUS, we need to fix it - in the slow-path.\n+    Label L;\n+    cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t) (intptr_t) ANONYMOUS_OWNER);\n+    jccb(Assembler::notEqual, L);\n+    testptr(objReg, objReg); \/\/ Clear ZF to indicate failure at DONE_LABEL.\n+    jmp(DONE_LABEL);\n+    bind(L);\n@@ -805,2 +789,2 @@\n-    movptr(boxReg, Address(tmpReg, owner_offset));\n-    testptr(boxReg, boxReg);\n+    movptr(tmpReg, Address(boxReg, owner_offset));\n+    testptr(tmpReg, tmpReg);\n@@ -809,1 +793,1 @@\n-    jmpb(DONE_LABEL);\n+    jmp(DONE_LABEL);\n@@ -833,2 +817,0 @@\n-  get_thread (boxReg);\n-\n@@ -839,2 +821,2 @@\n-  xorptr(boxReg, boxReg);\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  xorptr(tmpReg, tmpReg);\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -842,4 +824,4 @@\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  jccb  (Assembler::notZero, CheckSucc);\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n+  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  jccb  (Assembler::notZero, DONE_LABEL);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), NULL_WORD);\n@@ -847,18 +829,0 @@\n-\n-  bind (Stacked);\n-  \/\/ It's not inflated and it's not recursively stack-locked.\n-  \/\/ It must be stack-locked.\n-  \/\/ Try to reset the header to displaced header.\n-  \/\/ The \"box\" value on the stack is stable, so we can reload\n-  \/\/ and be assured we observe the same value as above.\n-  movptr(tmpReg, Address(boxReg, 0));\n-  lock();\n-  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-  \/\/ Intention fall-thru into DONE_LABEL\n-\n-  \/\/ DONE_LABEL is a hot target - we'd really like to place it at the\n-  \/\/ start of cache line by padding with NOPs.\n-  \/\/ See the AMD and Intel software optimization manuals for the\n-  \/\/ most efficient \"long\" NOP encodings.\n-  \/\/ Unfortunately none of our alignment mechanisms suffice.\n-  bind (CheckSucc);\n@@ -869,1 +833,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)), 0);\n@@ -873,1 +837,1 @@\n-  decq(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n+  decq(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(recursions)));\n@@ -877,2 +841,2 @@\n-  movptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n-  orptr(boxReg, Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n+  movptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(cxq)));\n+  orptr(tmpReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(EntryList)));\n@@ -881,1 +845,1 @@\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n@@ -891,1 +855,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n@@ -894,1 +858,0 @@\n-  xorptr(boxReg, boxReg);\n@@ -896,1 +859,1 @@\n-  movptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int32_t)NULL_WORD);\n@@ -907,1 +870,1 @@\n-  cmpptr(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n+  cmpptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(succ)), (int32_t)NULL_WORD);\n@@ -910,0 +873,3 @@\n+  mov(tmpReg, boxReg);\n+  xorptr(boxReg, boxReg);\n+\n@@ -940,0 +906,1 @@\n+#endif\n@@ -941,4 +908,4 @@\n-    bind  (Stacked);\n-    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-    lock();\n-    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+    bind(Stacked);\n+    \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n+    xorptr(rax, rax); \/\/ Set ZF = 1 (success)\n@@ -946,1 +913,0 @@\n-#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":49,"deletions":83,"binary":false,"changes":132,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-                 Register scr, Register cx1, Register cx2,\n+                 Register scr, Register cx1, Register cx2, Register thread,\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1200,0 +1200,4 @@\n+  const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n+  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n+  \/\/ Load object pointer into obj_reg\n+  movptr(obj_reg, Address(lock_reg, obj_offset));\n@@ -1203,1 +1207,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -1205,1 +1209,1 @@\n-    Label count_locking, done, slow_case;\n+    Label done, slow_case;\n@@ -1209,1 +1213,0 @@\n-    const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx); \/\/ Will contain the oop\n@@ -1212,8 +1215,0 @@\n-    const int obj_offset = BasicObjectLock::obj_offset_in_bytes();\n-    const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n-\n-    \/\/ Load object pointer into obj_reg\n-    movptr(obj_reg, Address(lock_reg, obj_offset));\n-\n@@ -1227,53 +1222,11 @@\n-    \/\/ Load immediate 1 into swap_reg %rax\n-    movl(swap_reg, (int32_t)1);\n-\n-    \/\/ Load (object->mark() | 1) into swap_reg %rax\n-    orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-\n-    assert(lock_offset == 0,\n-           \"displaced header must be first word in BasicObjectLock\");\n-\n-    lock();\n-    cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-    jcc(Assembler::zero, count_locking);\n-\n-    const int zero_bits = LP64_ONLY(7) NOT_LP64(3);\n-\n-    \/\/ Fast check for recursive lock.\n-    \/\/\n-    \/\/ Can apply the optimization only if this is a stack lock\n-    \/\/ allocated in this thread. For efficiency, we can focus on\n-    \/\/ recently allocated stack locks (instead of reading the stack\n-    \/\/ base and checking whether 'mark' points inside the current\n-    \/\/ thread stack):\n-    \/\/  1) (mark & zero_bits) == 0, and\n-    \/\/  2) rsp <= mark < mark + os::pagesize()\n-    \/\/\n-    \/\/ Warning: rsp + os::pagesize can overflow the stack base. We must\n-    \/\/ neither apply the optimization for an inflated lock allocated\n-    \/\/ just above the thread stack (this is why condition 1 matters)\n-    \/\/ nor apply the optimization if the stack lock is inside the stack\n-    \/\/ of another thread. The latter is avoided even in case of overflow\n-    \/\/ because we have guard pages at the end of all stacks. Hence, if\n-    \/\/ we go over the stack base and hit the stack of another thread,\n-    \/\/ this should not be in a writeable area that could contain a\n-    \/\/ stack lock allocated by that thread. As a consequence, a stack\n-    \/\/ lock less than page size away from rsp is guaranteed to be\n-    \/\/ owned by the current thread.\n-    \/\/\n-    \/\/ These 3 tests can be done by evaluating the following\n-    \/\/ expression: ((mark - rsp) & (zero_bits - os::vm_page_size())),\n-    \/\/ assuming both stack pointer and pagesize have their\n-    \/\/ least significant bits clear.\n-    \/\/ NOTE: the mark is in swap_reg %rax as the result of cmpxchg\n-    subptr(swap_reg, rsp);\n-    andptr(swap_reg, zero_bits - os::vm_page_size());\n-\n-    \/\/ Save the test result, for recursive case, the result is zero\n-    movptr(Address(lock_reg, mark_offset), swap_reg);\n-    jcc(Assembler::notZero, slow_case);\n-\n-    bind(count_locking);\n+#ifdef _LP64\n+    const Register thread = r15_thread;\n+    const Register tmp2 = rscratch1;\n+#else\n+    const Register thread = lock_reg;\n+    get_thread(thread);\n+    const Register tmp2 = noreg;\n+#endif\n+    \/\/ Load object header, prepare for CAS from unlocked to locked.\n+    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    fast_lock_impl(obj_reg, swap_reg, thread, tmp_reg, tmp2, slow_case);\n@@ -1288,1 +1241,1 @@\n-            lock_reg);\n+            obj_reg);\n@@ -1311,0 +1264,7 @@\n+  const Register obj_reg = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n+  \/\/ Load oop into obj_reg(%c_rarg3)\n+  movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+  \/\/ Free entry\n+  movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL_WORD);\n+\n@@ -1312,1 +1272,1 @@\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n@@ -1314,1 +1274,1 @@\n-    Label count_locking, done, slow_case;\n+    Label done, slow_case;\n@@ -1318,1 +1278,0 @@\n-    const Register obj_reg    = LP64_ONLY(c_rarg3) NOT_LP64(rcx);  \/\/ Will contain the oop\n@@ -1322,28 +1281,4 @@\n-    \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-    \/\/ structure Store the BasicLock address into %rax\n-    lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n-    \/\/ Load oop into obj_reg(%c_rarg3)\n-    movptr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-    \/\/ Free entry\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), (int32_t)NULL_WORD);\n-\n-    \/\/ Load the old header from BasicLock structure\n-    movptr(header_reg, Address(swap_reg,\n-                               BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Test for recursion\n-    testptr(header_reg, header_reg);\n-\n-    \/\/ zero for recursive case\n-    jcc(Assembler::zero, count_locking);\n-\n-    \/\/ Atomic swap back the old header\n-    lock();\n-    cmpxchgptr(header_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-    \/\/ zero for simple unlock of a stack-lock case\n-    jcc(Assembler::notZero, slow_case);\n-\n-    bind(count_locking);\n+    \/\/ Try to swing header from locked to unlock.\n+    movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+    andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+    fast_unlock_impl(obj_reg, swap_reg, header_reg, slow_case);\n@@ -1355,2 +1290,2 @@\n-    movptr(Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()), obj_reg); \/\/ restore obj\n-    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), lock_reg);\n+    bind(slow_case);\n+    call_VM_leaf(CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorexit), obj_reg);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":33,"deletions":98,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -9548,0 +9548,50 @@\n+\n+void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, thread, tmp1, tmp2);\n+\n+  \/\/ First we need to check if the lock-stack has room for pushing the object reference.\n+  movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n+  cmpptr(tmp1, Address(thread, Thread::lock_stack_limit_offset()));\n+  jcc(Assembler::greaterEqual, slow);\n+\n+  Register locked_hdr = tmp2->is_valid() ? tmp2 : tmp1;\n+  \/\/ Now we attempt to take the fast-lock.\n+  \/\/ Clear lowest two header bits (locked state).\n+  andptr(hdr, ~(int32_t )markWord::lock_mask_in_place);\n+  movptr(locked_hdr, hdr);\n+  \/\/ Set lowest bit (unlocked state).\n+  orptr(hdr, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(locked_hdr, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notEqual, slow);\n+\n+  \/\/ Success: push object to lock-stack.\n+  if (!tmp2->is_valid()) {\n+    \/\/ If we did not have a valid tmp2, we used tmp1 instead, and we must re-load the current offset.\n+    movptr(tmp1, Address(thread, Thread::lock_stack_current_offset()));\n+  }\n+  movptr(Address(tmp1, 0), obj);\n+  increment(tmp1, oopSize);\n+  movptr(Address(thread, Thread::lock_stack_current_offset()), tmp1);\n+}\n+\n+void MacroAssembler::fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow) {\n+  assert(hdr == rax, \"header must be in rax for cmpxchg\");\n+  assert_different_registers(obj, hdr, tmp);\n+\n+  \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+  movptr(tmp, hdr); \/\/ The expected old value\n+  orptr(tmp, markWord::unlocked_value);\n+  lock();\n+  cmpxchgptr(tmp, Address(obj, oopDesc::mark_offset_in_bytes()));\n+  jcc(Assembler::notZero, slow);\n+  \/\/ Pop the lock object from the lock-stack.\n+#ifdef _LP64\n+  const Register thread = r15_thread;\n+#else\n+  const Register thread = rax;\n+  get_thread(rax);\n+#endif\n+  subptr(Address(thread, Thread::lock_stack_current_offset()), oopSize);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -871,0 +871,1 @@\n+  void xorptr(Register dst, int32_t src) { LP64_ONLY(xorq(dst, src)) NOT_LP64(xorl(dst, src)); }\n@@ -2096,0 +2097,3 @@\n+\n+  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp1, Register tmp2, Label& slow);\n+  void fast_unlock_impl(Register obj, Register hdr, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1360,1 +1360,0 @@\n-                                       in_ByteSize(-1),\n@@ -1415,1 +1414,0 @@\n-  int lock_slot_offset = 0;\n@@ -1428,1 +1426,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1443,2 +1440,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset  (-lock_slot_rbp_offset)\n@@ -1550,4 +1545,0 @@\n-  \/\/ Compute the rbp, offset for any slots used after the jni call\n-\n-  int lock_slot_rbp_offset = (lock_slot_offset*VMRegImpl::stack_slot_size) - fp_adjustment;\n-\n@@ -1688,1 +1679,1 @@\n-  const Register lock_reg = rdx;  \/\/ Address of compiler lock object (BasicLock)\n+  const Register tmp      = rdx;\n@@ -1695,4 +1686,0 @@\n-    Label count_mon;\n-\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1702,4 +1689,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(rbp, lock_slot_rbp_offset));\n-\n@@ -1710,30 +1693,3 @@\n-      \/\/ Load immediate 1 into swap_reg %rax,\n-      __ movptr(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax,\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = lock_reg iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, count_mon);\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax, as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, thread, tmp, noreg, slow_path_lock);\n@@ -1743,1 +1699,0 @@\n-    __ bind(count_mon);\n@@ -1863,10 +1818,0 @@\n-    if (!UseHeavyMonitors) {\n-      Label not_recur;\n-      \/\/ Simple recursive lock?\n-      __ cmpptr(Address(rbp, lock_slot_rbp_offset), (int32_t)NULL_WORD);\n-      __ jcc(Assembler::notEqual, not_recur);\n-      __ dec_held_monitor_count();\n-      __ jmpb(fast_done);\n-      __ bind(not_recur);\n-    }\n-\n@@ -1879,12 +1824,3 @@\n-      \/\/  get old displaced header\n-      __ movptr(rbx, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      \/\/ src -> dest iff dest == rax, else rax, <- dest\n-      \/\/ *obj_reg = rbx, iff *obj_reg == rax, else rax, = *(obj_reg)\n-      __ lock();\n-      __ cmpxchgptr(rbx, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n@@ -1977,1 +1913,0 @@\n-    __ push(lock_reg);\n@@ -1980,1 +1915,1 @@\n-    __ addptr(rsp, 3*wordSize);\n+    __ addptr(rsp, 2*wordSize);\n@@ -2012,2 +1947,0 @@\n-    __ lea(rax, Address(rbp, lock_slot_rbp_offset));\n-    __ push(rax);\n@@ -2017,1 +1950,1 @@\n-    __ addptr(rsp, 3*wordSize);\n+    __ addptr(rsp, 2*wordSize);\n@@ -2072,1 +2005,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":9,"deletions":77,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -1557,1 +1557,0 @@\n-                                              in_ByteSize(-1),\n@@ -1582,1 +1581,0 @@\n-                                       in_ByteSize(-1),\n@@ -1638,1 +1636,0 @@\n-  int lock_slot_offset = 0;\n@@ -1651,1 +1648,0 @@\n-    lock_slot_offset = stack_slots;\n@@ -1666,2 +1662,0 @@\n-  \/\/      | lock box (if sync)  |\n-  \/\/      |---------------------| <- lock_slot_offset\n@@ -1952,2 +1946,1 @@\n-  const Register lock_reg = r13;  \/\/ Address of compiler lock object (BasicLock)\n-  const Register old_hdr  = r13;  \/\/ value of old header at unlock time\n+  const Register tmp      = r13;\n@@ -1959,4 +1952,0 @@\n-    Label count_mon;\n-\n-    const int mark_word_offset = BasicLock::displaced_header_offset_in_bytes();\n-\n@@ -1966,4 +1955,0 @@\n-    \/\/ Get address of the box\n-\n-    __ lea(lock_reg, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -1974,32 +1959,3 @@\n-\n-      \/\/ Load immediate 1 into swap_reg %rax\n-      __ movl(swap_reg, 1);\n-\n-      \/\/ Load (object->mark() | 1) into swap_reg %rax\n-      __ orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-\n-      \/\/ Save (object->mark() | 1) into BasicLock's displaced header\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-\n-      \/\/ src -> dest iff dest == rax else rax <- dest\n-      __ lock();\n-      __ cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::equal, count_mon);\n-\n-      \/\/ Hmm should this move to the slow path code area???\n-\n-      \/\/ Test if the oopMark is an obvious stack pointer, i.e.,\n-      \/\/  1) (mark & 3) == 0, and\n-      \/\/  2) rsp <= mark < mark + os::pagesize()\n-      \/\/ These 3 tests can be done by evaluating the following\n-      \/\/ expression: ((mark - rsp) & (3 - os::vm_page_size())),\n-      \/\/ assuming both stack pointer and pagesize have their\n-      \/\/ least significant 2 bits clear.\n-      \/\/ NOTE: the oopMark is in swap_reg %rax as the result of cmpxchg\n-\n-      __ subptr(swap_reg, rsp);\n-      __ andptr(swap_reg, 3 - os::vm_page_size());\n-\n-      \/\/ Save the test result, for recursive case, the result is zero\n-      __ movptr(Address(lock_reg, mark_word_offset), swap_reg);\n-      __ jcc(Assembler::notEqual, slow_path_lock);\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, tmp, rscratch1, slow_path_lock);\n@@ -2009,1 +1965,0 @@\n-    __ bind(count_mon);\n@@ -2117,10 +2072,0 @@\n-    if (!UseHeavyMonitors) {\n-      Label not_recur;\n-      \/\/ Simple recursive lock?\n-      __ cmpptr(Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size), (int32_t)NULL_WORD);\n-      __ jcc(Assembler::notEqual, not_recur);\n-      __ dec_held_monitor_count();\n-      __ jmpb(fast_done);\n-      __ bind(not_recur);\n-    }\n-\n@@ -2133,9 +2078,3 @@\n-      \/\/ get address of the stack lock\n-      __ lea(rax, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-      \/\/  get old displaced header\n-      __ movptr(old_hdr, Address(rax, 0));\n-\n-      \/\/ Atomic swap old header if oop still contains the stack lock\n-      __ lock();\n-      __ cmpxchgptr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ jcc(Assembler::notEqual, slow_path_unlock);\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, tmp, slow_path_unlock);\n@@ -2216,2 +2155,1 @@\n-    __ mov(c_rarg1, lock_reg);\n-    __ mov(c_rarg2, r15_thread);\n+    __ mov(c_rarg1, r15_thread);\n@@ -2245,2 +2183,0 @@\n-    __ lea(c_rarg1, Address(rsp, lock_slot_offset * VMRegImpl::stack_slot_size));\n-\n@@ -2248,1 +2184,1 @@\n-    __ mov(c_rarg2, r15_thread);\n+    __ mov(c_rarg1, r15_thread);\n@@ -2309,1 +2245,0 @@\n-                                            in_ByteSize(lock_slot_offset*VMRegImpl::stack_slot_size),\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":9,"deletions":74,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -13857,1 +13857,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2) %{\n+instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n@@ -13859,2 +13859,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box, TEMP thread);\n@@ -13864,0 +13864,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13865,1 +13866,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n@@ -13873,1 +13874,1 @@\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr) %{\n+instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, rRegI cx1, eRegP thread) %{\n@@ -13875,2 +13876,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP box, TEMP cx1, TEMP thread);\n@@ -13880,0 +13881,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13881,1 +13883,1 @@\n-                 $scr$$Register, noreg, noreg, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, $cx1$$Register, noreg, $thread$$Register, NULL, NULL, NULL, false, false);\n@@ -13887,2 +13889,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, USE_KILL box);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP tmp, TEMP box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":12,"deletions":10,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -13595,2 +13595,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, TEMP box);\n@@ -13601,1 +13601,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n@@ -13609,1 +13609,1 @@\n-instruct cmpFastLock(rFlagsReg cr, rRegP object, rbx_RegP box, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n+instruct cmpFastLock(rFlagsReg cr, rRegP object, rax_RegI tmp, rRegP scr, rRegP cx1) %{\n@@ -13611,2 +13611,2 @@\n-  match(Set cr (FastLock object box));\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, USE_KILL box);\n+  match(Set cr (FastLock object));\n+  effect(TEMP tmp, TEMP scr, TEMP cx1);\n@@ -13614,1 +13614,1 @@\n-  format %{ \"fastlock $object,$box\\t! kills $box,$tmp,$scr\" %}\n+  format %{ \"fastlock $object\\t! kills $tmp,$scr\" %}\n@@ -13616,2 +13616,2 @@\n-    __ fast_lock($object$$Register, $box$$Register, $tmp$$Register,\n-                 $scr$$Register, $cx1$$Register, noreg, NULL, NULL, NULL, false, false);\n+    __ fast_lock($object$$Register, noreg, $tmp$$Register,\n+                 $scr$$Register, $cx1$$Register, noreg, r15_thread, NULL, NULL, NULL, false, false);\n@@ -13623,2 +13623,2 @@\n-  match(Set cr (FastUnlock object box));\n-  effect(TEMP tmp, USE_KILL box);\n+  match(Set cr (FastUnlock object));\n+  effect(TEMP tmp, TEMP box);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":11,"deletions":11,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -397,2 +397,0 @@\n-    else if (offset ==  BasicObjectLock::lock_offset_in_bytes())\n-      snprintf(fieldbuf, buflen, \"monitor[%d]->_lock\", index);\n","filename":"src\/hotspot\/cpu\/zero\/frame_zero.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -334,18 +334,4 @@\n-    markWord disp = lockee->mark().set_unlocked();\n-    monitor->lock()->set_displaced_header(disp);\n-    bool call_vm = UseHeavyMonitors;\n-    bool inc_monitor_count = true;\n-    if (call_vm || lockee->cas_set_mark(markWord::from_pointer(monitor), disp) != disp) {\n-      \/\/ Is it simple recursive case?\n-      if (!call_vm && thread->is_lock_owned((address) disp.clear_lock_bits().to_pointer())) {\n-        monitor->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-      } else {\n-        inc_monitor_count = false;\n-        CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, monitor));\n-        if (HAS_PENDING_EXCEPTION)\n-          goto unwind_and_return;\n-      }\n-    }\n-    if (inc_monitor_count) {\n-      THREAD->inc_held_monitor_count();\n-    }\n+\n+    CALL_VM_NOCHECK(InterpreterRuntime::monitorenter(thread, lockee));\n+    if (HAS_PENDING_EXCEPTION)\n+      goto unwind_and_return;\n@@ -482,2 +468,0 @@\n-    BasicLock *lock = monitor->lock();\n-    markWord header = lock->displaced_header();\n@@ -486,13 +470,1 @@\n-\n-    bool dec_monitor_count = true;\n-    if (header.to_pointer() != NULL) {\n-      markWord old_header = markWord::encode(lock);\n-      if (rcvr->cas_set_mark(header, old_header) != old_header) {\n-        monitor->set_obj(rcvr);\n-        dec_monitor_count = false;\n-        InterpreterRuntime::monitorexit(monitor);\n-      }\n-    }\n-    if (dec_monitor_count) {\n-      THREAD->dec_held_monitor_count();\n-    }\n+    InterpreterRuntime::monitorexit(rcvr);\n","filename":"src\/hotspot\/cpu\/zero\/zeroInterpreter_zero.cpp","additions":5,"deletions":33,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -319,1 +319,0 @@\n-  LIR_Opr _lock_reg;\n@@ -322,1 +321,1 @@\n-  MonitorAccessStub(LIR_Opr obj_reg, LIR_Opr lock_reg) {\n+  MonitorAccessStub(LIR_Opr obj_reg) {\n@@ -324,1 +323,0 @@\n-    _lock_reg  = lock_reg;\n@@ -338,1 +336,1 @@\n-  MonitorEnterStub(LIR_Opr obj_reg, LIR_Opr lock_reg, CodeEmitInfo* info);\n+  MonitorEnterStub(LIR_Opr obj_reg, CodeEmitInfo* info);\n@@ -344,1 +342,1 @@\n-    visitor->do_input(_lock_reg);\n+    visitor->do_temp(_obj_reg);\n@@ -354,4 +352,0 @@\n- private:\n-  bool _compute_lock;\n-  int  _monitor_ix;\n-\n@@ -359,3 +353,2 @@\n-  MonitorExitStub(LIR_Opr lock_reg, bool compute_lock, int monitor_ix)\n-    : MonitorAccessStub(LIR_OprFact::illegalOpr, lock_reg),\n-      _compute_lock(compute_lock), _monitor_ix(monitor_ix) { }\n+  MonitorExitStub(LIR_Opr obj_reg)\n+    : MonitorAccessStub(obj_reg) { }\n@@ -364,6 +357,2 @@\n-    assert(_obj_reg->is_illegal(), \"unused\");\n-    if (_compute_lock) {\n-      visitor->do_temp(_lock_reg);\n-    } else {\n-      visitor->do_input(_lock_reg);\n-    }\n+    visitor->do_input(_obj_reg);\n+    visitor->do_temp(_obj_reg);\n","filename":"src\/hotspot\/share\/c1\/c1_CodeStubs.hpp","additions":7,"deletions":18,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -286,5 +286,0 @@\n-ByteSize FrameMap::sp_offset_for_monitor_lock(int index) const {\n-  check_monitor_index(index);\n-  return sp_offset_for_monitor_base(index) + in_ByteSize(BasicObjectLock::lock_offset_in_bytes());;\n-}\n-\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -144,1 +144,0 @@\n-  ByteSize sp_offset_for_monitor_lock(int monitor_index) const;\n@@ -209,3 +208,0 @@\n-  Address address_for_monitor_lock(int monitor_index) const {\n-    return make_new_address(sp_offset_for_monitor_lock(monitor_index));\n-  }\n@@ -223,3 +219,0 @@\n-  bool location_for_monitor_lock  (int monitor_index, Location* loc) const {\n-    return location_for_sp_offset(sp_offset_for_monitor_lock(monitor_index), Location::normal, loc);\n-  }\n","filename":"src\/hotspot\/share\/c1\/c1_FrameMap.hpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -798,1 +798,1 @@\n-      assert(opLock->_obj->is_valid(),  \"used\");  do_temp(opLock->_obj);\n+      assert(opLock->_obj->is_valid(),  \"used\");  do_input(opLock->_obj); do_temp(opLock->_obj);\n","filename":"src\/hotspot\/share\/c1\/c1_LIR.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -608,1 +608,1 @@\n-void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n+void LIRGenerator::monitor_enter(LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info) {\n@@ -611,1 +611,1 @@\n-  CodeStub* slow_path = new MonitorEnterStub(object, lock, info);\n+  CodeStub* slow_path = new MonitorEnterStub(object, info);\n@@ -613,0 +613,1 @@\n+  __ move(object, new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(), T_ADDRESS));\n@@ -614,1 +615,1 @@\n-  __ lock_object(hdr, object, lock, scratch, slow_path, info_for_exception);\n+  __ lock_object(hdr, object, tmp1, tmp2, slow_path, info_for_exception);\n@@ -621,3 +622,1 @@\n-  LIR_Opr hdr = lock;\n-  lock = new_hdr;\n-  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(object);\n@@ -625,1 +624,2 @@\n-  __ unlock_object(hdr, object, lock, scratch, slow_path);\n+  __ move(new LIR_Address(lock, BasicObjectLock::obj_offset_in_bytes(),T_ADDRESS), object);\n+  __ unlock_object(new_hdr, object, lock, scratch, slow_path);\n@@ -2676,3 +2676,1 @@\n-      LIR_Opr lock = syncLockOpr();\n-      __ load_stack_address_monitor(0, lock);\n-\n+      LIR_Opr lock = new_register(T_ADDRESS);\n@@ -2680,4 +2678,1 @@\n-      CodeStub* slow_path = new MonitorEnterStub(obj, lock, info);\n-\n-      \/\/ receiver is guaranteed non-NULL so don't need CodeEmitInfo\n-      __ lock_object(syncTempOpr(), obj, lock, new_register(T_OBJECT), slow_path, NULL);\n+      monitor_enter(obj, lock, syncTempOpr(), new_register(T_INT), new_register(T_INT), 0, NULL, info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":9,"deletions":14,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -366,1 +366,1 @@\n-  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr scratch, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n+  void monitor_enter (LIR_Opr object, LIR_Opr lock, LIR_Opr hdr, LIR_Opr tmp1, LIR_Opr tmp2, int monitor_no, CodeEmitInfo* info_for_exception, CodeEmitInfo* info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2535,3 +2535,0 @@\n-  if (!frame_map()->location_for_monitor_lock(monitor_index, &loc)) {\n-    bailout(\"too large frame\");\n-  }\n","filename":"src\/hotspot\/share\/c1\/c1_LinearScan.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -753,1 +753,1 @@\n-JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock))\n+JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* current, oopDesc* obj))\n@@ -759,5 +759,1 @@\n-  if (UseHeavyMonitors) {\n-    lock->set_obj(obj);\n-  }\n-  assert(obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, lock->lock(), current);\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -767,1 +763,1 @@\n-JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, BasicObjectLock* lock))\n+JRT_LEAF(void, Runtime1::monitorexit(JavaThread* current, oopDesc* obj))\n@@ -774,3 +770,2 @@\n-  oop obj = lock->obj();\n-  assert(oopDesc::is_oop(obj), \"must be NULL or an object\");\n-  SharedRuntime::monitor_exit_helper(obj, lock->lock(), current);\n+  assert(oopDesc::is_oop(oop(obj)), \"must be NULL or an object: \" PTR_FORMAT, p2i(obj));\n+  SharedRuntime::monitor_exit_helper(obj, current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -156,2 +156,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj, BasicObjectLock* lock);\n-  static void monitorexit (JavaThread* current, BasicObjectLock* lock);\n+  static void monitorenter(JavaThread* current, oopDesc* obj);\n+  static void monitorexit (JavaThread* current, oopDesc* obj);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -467,1 +467,0 @@\n-  ByteSize basic_lock_sp_offset,\n@@ -488,1 +487,0 @@\n-            basic_lock_sp_offset,\n@@ -611,1 +609,0 @@\n-  ByteSize basic_lock_sp_offset,\n@@ -615,2 +612,1 @@\n-  _native_receiver_sp_offset(basic_lock_owner_sp_offset),\n-  _native_basic_lock_sp_offset(basic_lock_sp_offset)\n+  _native_receiver_sp_offset(basic_lock_owner_sp_offset)\n@@ -750,2 +746,1 @@\n-  _native_receiver_sp_offset(in_ByteSize(-1)),\n-  _native_basic_lock_sp_offset(in_ByteSize(-1))\n+  _native_receiver_sp_offset(in_ByteSize(-1))\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -274,1 +274,1 @@\n-  \/\/ locate the owner and stack slot for the BasicLock. They are\n+  \/\/ locate the owner for the lock. They are\n@@ -282,1 +282,0 @@\n-  ByteSize _native_basic_lock_sp_offset;\n@@ -295,1 +294,0 @@\n-          ByteSize basic_lock_sp_offset,       \/* synchronized natives only *\/\n@@ -376,2 +374,1 @@\n-      _native_receiver_sp_offset(in_ByteSize(-1)),\n-      _native_basic_lock_sp_offset(in_ByteSize(-1)) {}\n+      _native_receiver_sp_offset(in_ByteSize(-1)) {}\n@@ -387,1 +384,0 @@\n-                                     ByteSize basic_lock_sp_offset,\n@@ -738,3 +734,0 @@\n-  ByteSize native_basic_lock_sp_offset() {\n-    return _native_basic_lock_sp_offset;\n-  }\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":2,"deletions":9,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -80,3 +80,1 @@\n-  markWord old_mark = ObjectSynchronizer::read_stable_mark(obj);\n-  assert(!old_mark.is_being_inflated(), \"must not see INFLATING marker here\");\n-\n+  markWord old_mark = obj->mark_acquire();\n@@ -92,12 +90,6 @@\n-  while (true) {\n-    markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n-    if (prev_mark == old_mark) {\n-      return update;\n-    } else if (prev_mark == markWord::INFLATING()) {\n-      \/\/ This happens when we encounter a stack-locked object in from-space.\n-      \/\/ Busy-wait for completion.\n-      SpinPause();\n-    } else {\n-      assert(prev_mark.is_marked(), \"must be forwarded\");\n-      return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n-    }\n+  markWord prev_mark = obj->cas_set_mark(new_mark, old_mark, memory_order_conservative);\n+  if (prev_mark == old_mark) {\n+    return update;\n+  } else {\n+    assert(prev_mark.is_marked(), \"must be forwarded\");\n+    return cast_to_oop(prev_mark.clear_lock_bits().to_pointer());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahForwarding.inline.hpp","additions":7,"deletions":15,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -42,3 +42,0 @@\n-  for (;;) {\n-    assert(heap->is_in(obj), \"object not in heap: \" PTR_FORMAT, p2i(obj));\n-    markWord mark = obj->mark_acquire();\n@@ -46,6 +43,2 @@\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  Inflated     - just return mark from inflated monitor\n-    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n-    \/\/ *  Neutral      - return mark\n-    \/\/ *  Marked       - object is forwarded, try again on forwardee\n+  assert(heap->is_in(obj), \"object not in heap: \" PTR_FORMAT, p2i(obj));\n+  markWord mark = obj->mark_acquire();\n@@ -53,4 +46,5 @@\n-    \/\/ Most common case first.\n-    if (mark.is_neutral()) {\n-      return mark;\n-    }\n+  \/\/ The mark can be in one of the following states:\n+  \/\/ *  Inflated     - just return mark from inflated monitor\n+  \/\/ *  Fast-locked  - return mark\n+  \/\/ *  Neutral      - return mark\n+  \/\/ *  Marked       - object is forwarded, try again on forwardee\n@@ -58,0 +52,4 @@\n+  \/\/ Most common case first.\n+  if (mark.is_neutral() || mark.is_fast_locked()) {\n+    return mark;\n+  } else if (mark.is_marked()) {\n@@ -59,7 +57,3 @@\n-    if (mark.is_marked()) {\n-      if (heap->is_full_gc_move_in_progress()) {\n-        \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n-        return mark;\n-      }\n-      obj = cast_to_oop(mark.decode_pointer());\n-      continue;\n+    if (heap->is_full_gc_move_in_progress()) {\n+      \/\/ In these cases, we want to return the header as-is: the Klass* would not be overloaded.\n+      return mark;\n@@ -67,1 +61,2 @@\n-\n+    return stable_mark(cast_to_oop(mark.decode_pointer()));\n+  } else {\n@@ -69,53 +64,8 @@\n-    if (mark.has_monitor()) {\n-      \/\/ It is safe to access the object monitor because all Java and GC worker threads\n-      \/\/ participate in the monitor deflation protocol (i.e, they react to handshakes and STS requests).\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: inflating\n-    if (mark.is_being_inflated()) {\n-      \/\/ Interference, try again.\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    if (mark.has_locker()) {\n-      if (Thread::current()->is_lock_owned((address)mark.locker())) {\n-        \/\/ This thread owns the lock. We can safely access it.\n-        markWord dmw = mark.displaced_mark_helper();\n-        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(), mark.value());\n-        return dmw;\n-      }\n-\n-      \/\/ Else we try to install INFLATING into the header. This will (temporarily) prevent other\n-      \/\/ threads from stack-locking or evacuating the object.\n-      markWord cmp = obj->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can fetch the stack-lock and safely read the displaced header.\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either. No other thread can do evacuation, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(obj->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      obj->release_set_mark(mark);\n-\n-      return dmw;\n-    }\n+    assert(mark.has_monitor(), \"Must be inflated here\");\n+    \/\/ It is safe to access the object monitor because all Java and GC worker threads\n+    \/\/ participate in the monitor deflation protocol (i.e, they react to handshakes and STS requests).\n+    ObjectMonitor* inf = mark.monitor();\n+    markWord dmw = inf->header();\n+    assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT \", original mark: \" INTPTR_FORMAT, dmw.value(),\n+           mark.value());\n+    return dmw;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.inline.hpp","additions":24,"deletions":74,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -49,4 +49,4 @@\n-    const markWord mark = obj->mark();\n-    \/\/ Having\/had displaced header, too risk to deal with them, skip\n-    if (mark == markWord::INFLATING() || mark.has_displaced_mark_helper()) {\n-      return false;\n+    markWord mark = obj->mark();\n+    \/\/ Fetch displaced header from monitor\n+    if (mark.has_displaced_mark_helper()) {\n+      mark = mark.displaced_mark_helper();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahStringDedup.inline.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -730,5 +730,2 @@\n-JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, BasicObjectLock* elem))\n-#ifdef ASSERT\n-  current->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n-  Handle h_obj(current, elem->obj());\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n+  Handle h_obj(current, obj);\n@@ -737,2 +734,2 @@\n-  ObjectSynchronizer::enter(h_obj, elem->lock(), current);\n-  assert(Universe::heap()->is_in_or_null(elem->obj()),\n+  ObjectSynchronizer::enter(h_obj, current);\n+  assert(Universe::heap()->is_in_or_null(h_obj()),\n@@ -740,3 +737,0 @@\n-#ifdef ASSERT\n-  current->last_frame().interpreter_frame_verify_monitor(elem);\n-#endif\n@@ -746,2 +740,2 @@\n-JRT_LEAF(void, InterpreterRuntime::monitorexit(BasicObjectLock* elem))\n-  oop obj = elem->obj();\n+JRT_LEAF(void, InterpreterRuntime::monitorexit(oopDesc* o))\n+  oop obj = oop(o);\n@@ -757,4 +751,1 @@\n-  ObjectSynchronizer::exit(obj, elem->lock(), JavaThread::current());\n-  \/\/ Free entry. If it is not cleared, the exception handling code will try to unlock the monitor\n-  \/\/ again at method exit or in the case of an exception.\n-  elem->set_obj(NULL);\n+  ObjectSynchronizer::exit(obj, JavaThread::current());\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":7,"deletions":16,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -108,2 +108,2 @@\n-  static void    monitorenter(JavaThread* current, BasicObjectLock* elem);\n-  static void    monitorexit (BasicObjectLock* elem);\n+  static void    monitorenter(JavaThread* current, oopDesc* obj);\n+  static void    monitorexit (oopDesc* obj);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -626,16 +626,1 @@\n-        markWord displaced = rcvr->mark().set_unlocked();\n-        mon->lock()->set_displaced_header(displaced);\n-        bool call_vm = UseHeavyMonitors;\n-        bool inc_monitor_count = true;\n-        if (call_vm || rcvr->cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {\n-          \/\/ Is it simple recursive case?\n-          if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-            mon->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-          } else {\n-            inc_monitor_count = false;\n-            CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);\n-          }\n-        }\n-        if (inc_monitor_count) {\n-          THREAD->inc_held_monitor_count();\n-        }\n+        CALL_VM(InterpreterRuntime::monitorenter(THREAD, rcvr), handle_exception);\n@@ -725,16 +710,1 @@\n-      markWord displaced = lockee->mark().set_unlocked();\n-      entry->lock()->set_displaced_header(displaced);\n-      bool call_vm = UseHeavyMonitors;\n-      bool inc_monitor_count = true;\n-      if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n-        \/\/ Is it simple recursive case?\n-        if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-          entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-        } else {\n-          inc_monitor_count = false;\n-          CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n-        }\n-      }\n-      if (inc_monitor_count) {\n-        THREAD->inc_held_monitor_count();\n-      }\n+      CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n@@ -1638,16 +1608,1 @@\n-          markWord displaced = lockee->mark().set_unlocked();\n-          entry->lock()->set_displaced_header(displaced);\n-          bool call_vm = UseHeavyMonitors;\n-          bool inc_monitor_count = true;\n-          if (call_vm || lockee->cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {\n-            \/\/ Is it simple recursive case?\n-            if (!call_vm && THREAD->is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {\n-              entry->lock()->set_displaced_header(markWord::from_pointer(NULL));\n-            } else {\n-              inc_monitor_count = false;\n-              CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);\n-            }\n-          }\n-          if (inc_monitor_count) {\n-            THREAD->inc_held_monitor_count();\n-          }\n+          CALL_VM(InterpreterRuntime::monitorenter(THREAD, lockee), handle_exception);\n@@ -1670,2 +1625,0 @@\n-            BasicLock* lock = most_recent->lock();\n-            markWord header = lock->displaced_header();\n@@ -1673,16 +1626,1 @@\n-\n-            \/\/ If it isn't recursive we either must swap old header or call the runtime\n-            bool dec_monitor_count = true;\n-            bool call_vm = UseHeavyMonitors;\n-            if (header.to_pointer() != NULL || call_vm) {\n-              markWord old_header = markWord::encode(lock);\n-              if (call_vm || lockee->cas_set_mark(header, old_header) != old_header) {\n-                \/\/ restore object for the slow case\n-                most_recent->set_obj(lockee);\n-                dec_monitor_count = false;\n-                InterpreterRuntime::monitorexit(most_recent);\n-              }\n-            }\n-            if (dec_monitor_count) {\n-              THREAD->dec_held_monitor_count();\n-            }\n+            InterpreterRuntime::monitorexit(lockee);\n@@ -3101,2 +3039,0 @@\n-          BasicLock* lock = end->lock();\n-          markWord header = lock->displaced_header();\n@@ -3104,15 +3040,1 @@\n-\n-          \/\/ If it isn't recursive we either must swap old header or call the runtime\n-          bool dec_monitor_count = true;\n-          if (header.to_pointer() != NULL) {\n-            markWord old_header = markWord::encode(lock);\n-            if (lockee->cas_set_mark(header, old_header) != old_header) {\n-              \/\/ restore object for the slow case\n-              end->set_obj(lockee);\n-              dec_monitor_count = false;\n-              InterpreterRuntime::monitorexit(end);\n-            }\n-          }\n-          if (dec_monitor_count) {\n-            THREAD->dec_held_monitor_count();\n-          }\n+          InterpreterRuntime::monitorexit(lockee);\n@@ -3165,2 +3087,2 @@\n-          } else if (UseHeavyMonitors) {\n-            InterpreterRuntime::monitorexit(base);\n+          } else {\n+            InterpreterRuntime::monitorexit(rcvr);\n@@ -3171,23 +3093,0 @@\n-          } else {\n-            BasicLock* lock = base->lock();\n-            markWord header = lock->displaced_header();\n-            base->set_obj(NULL);\n-\n-            \/\/ If it isn't recursive we either must swap old header or call the runtime\n-            bool dec_monitor_count = true;\n-            if (header.to_pointer() != NULL) {\n-              markWord old_header = markWord::encode(lock);\n-              if (rcvr->cas_set_mark(header, old_header) != old_header) {\n-                \/\/ restore object for the slow case\n-                base->set_obj(rcvr);\n-                dec_monitor_count = false;\n-                InterpreterRuntime::monitorexit(base);\n-                if (THREAD->has_pending_exception()) {\n-                  if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD->pending_exception());\n-                  THREAD->clear_pending_exception();\n-                }\n-              }\n-            }\n-            if (dec_monitor_count) {\n-              THREAD->dec_held_monitor_count();\n-            }\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":7,"deletions":108,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -81,1 +81,0 @@\n-    static int sizeof_BasicLock;\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-int CompilerToVM::Data::sizeof_BasicLock = sizeof(BasicLock);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVMInit.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -407,2 +407,2 @@\n-JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock))\n-  SharedRuntime::monitor_enter_helper(obj, lock, current);\n+JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* current, oopDesc* obj))\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -411,1 +411,1 @@\n-JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj, BasicLock* lock))\n+JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* current, oopDesc* obj))\n@@ -414,1 +414,1 @@\n-  SharedRuntime::monitor_exit_helper(obj, lock, current);\n+  SharedRuntime::monitor_exit_helper(obj, current);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -504,2 +504,2 @@\n-  static void monitorenter(JavaThread* current, oopDesc* obj, BasicLock* lock);\n-  static void monitorexit (JavaThread* current, oopDesc* obj, BasicLock* lock);\n+  static void monitorenter(JavaThread* current, oopDesc* obj);\n+  static void monitorexit (JavaThread* current, oopDesc* obj);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -90,1 +90,0 @@\n-  static_field(CompilerToVM::Data,             sizeof_BasicLock,                       int)                                          \\\n@@ -113,2 +112,0 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                      markWord)                                     \\\n-                                                                                                                                     \\\n@@ -369,1 +366,0 @@\n-  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -39,4 +39,0 @@\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    return locker->displaced_header();\n-  }\n@@ -56,5 +52,0 @@\n-  if (has_locker()) {  \/\/ has a stack lock\n-    BasicLock* locker = this->locker();\n-    locker->set_displaced_header(m);\n-    return;\n-  }\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -52,1 +52,1 @@\n-\/\/    [ptr             | 00]  locked             ptr points to real header on stack\n+\/\/    [header          | 00]  locked             object is fast-locked\n@@ -56,7 +56,0 @@\n-\/\/    [0 ............ 0| 00]  inflating          inflation in progress\n-\/\/\n-\/\/    We assume that stack\/thread pointers have the lowest two bits cleared.\n-\/\/\n-\/\/  - INFLATING() is a distinguished markword value of all zeros that is\n-\/\/    used when inflating an existing stack-lock into an ObjectMonitor.\n-\/\/    See below for is_being_inflated() and INFLATING().\n@@ -64,1 +57,0 @@\n-class BasicLock;\n@@ -161,12 +153,0 @@\n-  \/\/ Special temporary state of the markWord while being inflated.\n-  \/\/ Code that looks at mark outside a lock need to take this into account.\n-  bool is_being_inflated() const { return (value() == 0); }\n-\n-  \/\/ Distinguished markword value - used when inflating over\n-  \/\/ an existing stack-lock.  0 indicates the markword is \"BUSY\".\n-  \/\/ Lockword mutators that use a LD...CAS idiom should always\n-  \/\/ check for and avoid overwriting a 0 value installed by some\n-  \/\/ other thread.  (They should spin or block instead.  The 0 value\n-  \/\/ is transient and *should* be short-lived).\n-  static markWord INFLATING() { return zero(); }    \/\/ inflate-in-progress\n-\n@@ -184,2 +164,2 @@\n-  bool has_locker() const {\n-    return ((value() & lock_mask_in_place) == locked_value);\n+  markWord set_fast_locked() const {\n+    return markWord(value() & ~lock_mask_in_place);\n@@ -187,3 +167,2 @@\n-  BasicLock* locker() const {\n-    assert(has_locker(), \"check\");\n-    return (BasicLock*) value();\n+  bool is_fast_locked() const {\n+    return ((value() & lock_mask_in_place) == locked_value);\n@@ -200,1 +179,1 @@\n-    return ((value() & unlocked_value) == 0);\n+    return has_monitor();\n@@ -209,10 +188,1 @@\n-  \/\/ it is only used to be stored into BasicLock as the\n-  \/\/ indicator that the lock is using heavyweight monitor\n-  static markWord unused_mark() {\n-    return markWord(marked_value);\n-  }\n-  \/\/ the following two functions create the markWord to be\n-  \/\/ stored into object header, it encodes monitor info\n-  static markWord encode(BasicLock* lock) {\n-    return from_pointer(lock);\n-  }\n+  \/\/ create the markWord to be stored into object header, it encodes monitor info\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":7,"deletions":37,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -111,15 +111,1 @@\n-  if (!Universe::heap()->is_oop(obj)) {\n-    return false;\n-  }\n-\n-  \/\/ Header verification: the mark is typically non-zero. If we're\n-  \/\/ at a safepoint, it must not be zero.\n-  \/\/ Outside of a safepoint, the header could be changing (for example,\n-  \/\/ another thread could be inflating a lock on this object).\n-  if (ignore_mark_word) {\n-    return true;\n-  }\n-  if (obj->mark().value() != 0) {\n-    return true;\n-  }\n-  return !SafepointSynchronize::is_at_safepoint();\n+  return Universe::heap()->is_oop(obj);\n@@ -182,1 +168,1 @@\n-  assert(header.is_neutral(), \"expect neutral header here\");\n+  assert(header.is_neutral() || header.is_fast_locked(), \"expect neutral header here\");\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":2,"deletions":16,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n@@ -122,0 +123,1 @@\n+  virtual uint match_edge(uint idx) const { return idx < 2; \/* Don't match box *\/ }\n","filename":"src\/hotspot\/share\/opto\/locknode.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2177,1 +2177,1 @@\n-                                  obj, box, NULL);\n+                                  obj, NULL, NULL);\n@@ -2237,1 +2237,1 @@\n-                                  \"complete_monitor_unlocking_C\", slow_path, obj, box, thread);\n+                                  \"complete_monitor_unlocking_C\", slow_path, obj, thread, NULL);\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -225,1 +225,1 @@\n-  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt*2-1)*wordSize);\n+  Node *monitors_addr = basic_plus_adr(osr_buf, osr_buf, (max_locals+mcnt-1)*wordSize);\n@@ -234,6 +234,1 @@\n-    Node *lock_object = fetch_interpreter_state(index*2, T_OBJECT, monitors_addr, osr_buf);\n-    \/\/ Try and copy the displaced header to the BoxNode\n-    Node *displaced_hdr = fetch_interpreter_state((index*2) + 1, T_ADDRESS, monitors_addr, osr_buf);\n-\n-\n-    store_to_memory(control(), box, displaced_hdr, T_ADDRESS, Compile::AliasIdxRaw, MemNode::unordered);\n+    Node *lock_object = fetch_interpreter_state(index, T_OBJECT, monitors_addr, osr_buf);\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -566,1 +566,1 @@\n-  const Type **fields = TypeTuple::fields(2);\n+  const Type **fields = TypeTuple::fields(1);\n@@ -568,2 +568,1 @@\n-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;   \/\/ Address of stack location for lock\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2,fields);\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+1,fields);\n@@ -583,1 +582,1 @@\n-  const Type **fields = TypeTuple::fields(3);\n+  const Type **fields = TypeTuple::fields(2);\n@@ -585,3 +584,2 @@\n-  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Address of stack location for lock - BasicLock\n-  fields[TypeFunc::Parms+2] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n-  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+3, fields);\n+  fields[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM;    \/\/ Thread pointer (Self)\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+2, fields);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":5,"deletions":7,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1371,1 +1371,1 @@\n-  ObjectMonitor *mon = NULL;\n+  ObjectMonitor* mon = NULL;\n@@ -1378,43 +1378,11 @@\n-  {\n-    address owner = NULL;\n-    {\n-      markWord mark = hobj()->mark();\n-\n-      if (!mark.has_monitor()) {\n-        \/\/ this object has a lightweight monitor\n-\n-        if (mark.has_locker()) {\n-          owner = (address)mark.locker(); \/\/ save the address of the Lock word\n-        }\n-        \/\/ implied else: no owner\n-      } else {\n-        \/\/ this object has a heavyweight monitor\n-        mon = mark.monitor();\n-\n-        \/\/ The owner field of a heavyweight monitor may be NULL for no\n-        \/\/ owner, a JavaThread * or it may still be the address of the\n-        \/\/ Lock word in a JavaThread's stack. A monitor can be inflated\n-        \/\/ by a non-owning JavaThread, but only the owning JavaThread\n-        \/\/ can change the owner field from the Lock word to the\n-        \/\/ JavaThread * and it may not have done that yet.\n-        owner = (address)mon->owner();\n-      }\n-    }\n-\n-    if (owner != NULL) {\n-      \/\/ This monitor is owned so we have to find the owning JavaThread.\n-      owning_thread = Threads::owning_thread_from_monitor_owner(tlh.list(), owner);\n-      assert(owning_thread != NULL, \"owning JavaThread must not be NULL\");\n-      Handle th(current_thread, get_vthread_or_thread_oop(owning_thread));\n-      ret.owner = (jthread)jni_reference(calling_thread, th);\n-    }\n-\n-    if (owning_thread != NULL) {  \/\/ monitor is owned\n-      \/\/ The recursions field of a monitor does not reflect recursions\n-      \/\/ as lightweight locks before inflating the monitor are not included.\n-      \/\/ We have to count the number of recursive monitor entries the hard way.\n-      \/\/ We pass a handle to survive any GCs along the way.\n-      ret.entry_count = count_locked_objects(owning_thread, hobj);\n-    }\n-    \/\/ implied else: entry_count == 0\n-  }\n+  owning_thread = Threads::owning_thread_from_object(tlh.list(), hobj(), &mon);\n+  if (owning_thread != NULL) {\n+    Handle th(current_thread, get_vthread_or_thread_oop(owning_thread));\n+    ret.owner = (jthread)jni_reference(calling_thread, th);\n+    \/\/ The recursions field of a monitor does not reflect recursions\n+    \/\/ as lightweight locks before inflating the monitor are not included.\n+    \/\/ We have to count the number of recursive monitor entries the hard way.\n+    \/\/ We pass a handle to survive any GCs along the way.\n+    ret.entry_count = count_locked_objects(owning_thread, hobj);\n+  }\n+  \/\/ implied else: entry_count == 0\n","filename":"src\/hotspot\/share\/prims\/jvmtiEnvBase.cpp","additions":12,"deletions":44,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -1,84 +0,0 @@\n-\/*\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/basicLock.hpp\"\n-#include \"runtime\/synchronizer.hpp\"\n-\n-void BasicLock::print_on(outputStream* st, oop owner) const {\n-  st->print(\"monitor\");\n-  markWord mark_word = displaced_header();\n-  if (mark_word.value() != 0) {\n-    \/\/ Print monitor info if there's an owning oop and it refers to this BasicLock.\n-    bool print_monitor_info = (owner != NULL) && (owner->mark() == markWord::from_pointer((void*)this));\n-    mark_word.print_on(st, print_monitor_info);\n-  }\n-}\n-\n-void BasicLock::move_to(oop obj, BasicLock* dest) {\n-  \/\/ Check to see if we need to inflate the lock. This is only needed\n-  \/\/ if an object is locked using \"this\" lightweight monitor. In that\n-  \/\/ case, the displaced_header() is unlocked\/is_neutral, because the\n-  \/\/ displaced_header() contains the header for the originally unlocked\n-  \/\/ object. However the lock could have already been inflated. But it\n-  \/\/ does not matter, this inflation will just a no-op. For other cases,\n-  \/\/ the displaced header will be either 0x0 or 0x3, which are location\n-  \/\/ independent, therefore the BasicLock is free to move.\n-  \/\/\n-  \/\/ During OSR we may need to relocate a BasicLock (which contains a\n-  \/\/ displaced word) from a location in an interpreter frame to a\n-  \/\/ new location in a compiled frame.  \"this\" refers to the source\n-  \/\/ BasicLock in the interpreter frame.  \"dest\" refers to the destination\n-  \/\/ BasicLock in the new compiled frame.  We *always* inflate in move_to()\n-  \/\/ when the object is locked using \"this\" lightweight monitor.\n-  \/\/\n-  \/\/ The always-Inflate policy works properly, but it depends on the\n-  \/\/ inflated fast-path operations in fast_lock and fast_unlock to avoid\n-  \/\/ performance problems. See x86\/macroAssembler_x86.cpp: fast_lock()\n-  \/\/ and fast_unlock() for examples.\n-  \/\/\n-  \/\/ Note that there is a way to safely swing the object's markword from\n-  \/\/ one stack location to another.  This avoids inflation.  Obviously,\n-  \/\/ we need to ensure that both locations refer to the current thread's stack.\n-  \/\/ There are some subtle concurrency issues, however, and since the benefit is\n-  \/\/ is small (given the support for inflated fast-path locking in the fast_lock, etc)\n-  \/\/ we'll leave that optimization for another time.\n-\n-  if (displaced_header().is_neutral()) {\n-    \/\/ The object is locked and the resulting ObjectMonitor* will also be\n-    \/\/ locked so it can't be async deflated until ownership is dropped.\n-    ObjectSynchronizer::inflate_helper(obj);\n-    \/\/ WARNING: We cannot put a check here, because the inflation\n-    \/\/ will not update the displaced header. Once BasicLock is inflated,\n-    \/\/ no one should ever look at its content.\n-  } else {\n-    \/\/ Typically the displaced header will be 0 (recursive stack lock) or\n-    \/\/ unused_mark.  Naively we'd like to assert that the displaced mark\n-    \/\/ value is either 0, neutral, or 3.  But with the advent of the\n-    \/\/ store-before-CAS avoidance in fast_lock\/compiler_lock_object\n-    \/\/ we can find any flavor mark in the displaced mark.\n-  }\n-  dest->set_displaced_header(displaced_header());\n-}\n","filename":"src\/hotspot\/share\/runtime\/basicLock.cpp","additions":0,"deletions":84,"binary":false,"changes":84,"status":"deleted"},{"patch":"@@ -32,23 +32,1 @@\n-class BasicLock {\n-  friend class VMStructs;\n-  friend class JVMCIVMStructs;\n- private:\n-  volatile markWord _displaced_header;\n- public:\n-  markWord displaced_header() const {\n-    return Atomic::load(&_displaced_header);\n-  }\n-\n-  void set_displaced_header(markWord header) {\n-    Atomic::store(&_displaced_header, header);\n-  }\n-\n-  void print_on(outputStream* st, oop owner) const;\n-\n-  \/\/ move a basic lock (used during deoptimization\n-  void move_to(oop obj, BasicLock* dest);\n-\n-  static int displaced_header_offset_in_bytes()       { return offset_of(BasicLock, _displaced_header); }\n-};\n-\n-\/\/ A BasicObjectLock associates a specific Java object with a BasicLock.\n+\/\/ A BasicObjectLock represents a locked object.\n@@ -59,3 +37,1 @@\n-\/\/ after the end of the BasicObjectLock.  Also, in order to guarantee\n-\/\/ alignment of the embedded BasicLock objects on such machines, we\n-\/\/ put the embedded BasicLock at the beginning of the struct.\n+\/\/ after the end of the BasicObjectLock.\n@@ -66,1 +42,0 @@\n-  BasicLock _lock;                                    \/\/ the lock, must be double word aligned\n@@ -68,0 +43,5 @@\n+#ifdef AARCH64\n+  \/\/ Stack needs to be 16-byte-aligned. Inserting a dummy field here is\n+  \/\/ the simplest way to achieve that.\n+  intptr_t _dummy;\n+#endif\n@@ -73,1 +53,0 @@\n-  BasicLock* lock()                                   { return &_lock; }\n@@ -83,1 +62,0 @@\n-  static int lock_offset_in_bytes()                   { return offset_of(BasicObjectLock, _lock); }\n","filename":"src\/hotspot\/share\/runtime\/basicLock.hpp","additions":7,"deletions":29,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1512,17 +1512,7 @@\n-        if (exec_mode == Unpack_none) {\n-          if (mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n-            \/\/ With exec_mode == Unpack_none obj may be thread local and locked in\n-            \/\/ a callee frame. Make the lock in the callee a recursive lock and restore the displaced header.\n-            markWord dmw = mark.displaced_mark_helper();\n-            mark.locker()->set_displaced_header(markWord::encode((BasicLock*) NULL));\n-            obj->set_mark(dmw);\n-          }\n-          if (mark.has_monitor()) {\n-            \/\/ defer relocking if the deoptee thread is currently waiting for obj\n-            ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n-            if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n-              assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n-              mon_info->lock()->set_displaced_header(markWord::unused_mark());\n-              JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n-              continue;\n-            }\n+        if (exec_mode == Unpack_none && mark.has_monitor()) {\n+          \/\/ defer relocking if the deoptee thread is currently waiting for obj\n+          ObjectMonitor* waiting_monitor = deoptee_thread->current_waiting_monitor();\n+          if (waiting_monitor != NULL && waiting_monitor->object() == obj()) {\n+            assert(fr.is_deoptimized_frame(), \"frame must be scheduled for deoptimization\");\n+            JvmtiDeferredUpdates::inc_relock_count_after_wait(deoptee_thread);\n+            continue;\n@@ -1531,2 +1521,1 @@\n-        BasicLock* lock = mon_info->lock();\n-        ObjectSynchronizer::enter(obj, lock, deoptee_thread);\n+        ObjectSynchronizer::enter(obj, deoptee_thread);\n@@ -1607,1 +1596,1 @@\n-          ObjectSynchronizer::exit(src->obj(), src->lock(), thread);\n+          ObjectSynchronizer::exit(src->obj(), thread);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":9,"deletions":20,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -591,3 +591,0 @@\n-    st->print(\" - lock   [\");\n-    current->lock()->print_on(st, current->obj());\n-    st->print_cr(\"]\");\n@@ -1102,9 +1099,0 @@\n-BasicLock* frame::get_native_monitor() {\n-  nmethod* nm = (nmethod*)_cb;\n-  assert(_cb != NULL && _cb->is_nmethod() && nm->method()->is_native(),\n-         \"Should not call this unless it's a native nmethod\");\n-  int byte_offset = in_bytes(nm->native_basic_lock_sp_offset());\n-  assert(byte_offset >= 0, \"should not see invalid offset\");\n-  return (BasicLock*) &sp()[byte_offset \/ wordSize];\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -342,1 +342,1 @@\n-  \/\/ Return the monitor owner and BasicLock for compiled synchronized\n+  \/\/ Return the monitor owner for compiled synchronized\n@@ -345,1 +345,0 @@\n-  BasicLock* get_native_monitor();\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -727,1 +727,1 @@\n-  product(intx, hashCode, 5, EXPERIMENTAL,                                  \\\n+  product(intx, hashCode, 6, EXPERIMENTAL,                                  \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -978,34 +978,0 @@\n-bool JavaThread::is_lock_owned(address adr) const {\n-  if (Thread::is_lock_owned(adr)) return true;\n-\n-  for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk->next()) {\n-    if (chunk->contains(adr)) return true;\n-  }\n-\n-  return false;\n-}\n-\n-bool JavaThread::is_lock_owned_current(address adr) const {\n-  address stack_end = _stack_base - _stack_size;\n-  const ContinuationEntry* ce = vthread_continuation();\n-  address stack_base = ce != nullptr ? (address)ce->entry_sp() : _stack_base;\n-  if (stack_base > adr && adr >= stack_end) {\n-    return true;\n-  }\n-\n-  for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk->next()) {\n-    if (chunk->contains(adr)) {\n-      return true;\n-    }\n-  }\n-\n-  return false;\n-}\n-\n-bool JavaThread::is_lock_owned_carrier(address adr) const {\n-  assert(is_vthread_mounted(), \"\");\n-  address stack_end = _stack_base - _stack_size;\n-  address stack_base = (address)vthread_continuation()->entry_sp();\n-  return stack_base > adr && adr >= stack_end;\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":0,"deletions":34,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -659,5 +659,0 @@\n-  \/\/ Fast-locking support\n-  bool is_lock_owned(address adr) const;\n-  bool is_lock_owned_current(address adr) const; \/\/ virtual if mounted, otherwise whole thread\n-  bool is_lock_owned_carrier(address adr) const;\n-\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -0,0 +1,71 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/thread.hpp\"\n+#include \"utilities\/copy.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+LockStack::LockStack() :\n+        _base(UseHeavyMonitors ? NULL : NEW_C_HEAP_ARRAY(oop, INITIAL_CAPACITY, mtSynchronizer)),\n+        _limit(_base + INITIAL_CAPACITY),\n+        _current(_base) {\n+}\n+\n+LockStack::~LockStack() {\n+  if (!UseHeavyMonitors) {\n+    FREE_C_HEAP_ARRAY(oop, _base);\n+  }\n+}\n+\n+#ifndef PRODUCT\n+void LockStack::validate(const char* msg) const {\n+  assert(!UseHeavyMonitors, \"never use lock-stack when fast-locking is disabled\");\n+  for (oop* loc1 = _base; loc1 < _current - 1; loc1++) {\n+    for (oop* loc2 = loc1 + 1; loc2 < _current; loc2++) {\n+      assert(*loc1 != *loc2, \"entries must be unique: %s\", msg);\n+    }\n+  }\n+}\n+#endif\n+\n+void LockStack::grow() {\n+  \/\/ Grow stack.\n+  assert(_limit > _base, \"invariant\");\n+  size_t capacity = _limit - _base;\n+  size_t index = _current - _base;\n+  size_t new_capacity = capacity * 2;\n+  oop* new_stack = NEW_C_HEAP_ARRAY(oop, new_capacity, mtSynchronizer);\n+  for (size_t i = 0; i < index; i++) {\n+    *(new_stack + i) = *(_base + i);\n+  }\n+  FREE_C_HEAP_ARRAY(oop, _base);\n+  _base = new_stack;\n+  _limit = _base + new_capacity;\n+  _current = _base + index;\n+  assert(_current < _limit, \"must fit after growing\");\n+}\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"added"},{"patch":"@@ -0,0 +1,64 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_HPP\n+\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/sizes.hpp\"\n+\n+class Thread;\n+class OopClosure;\n+\n+class LockStack {\n+  friend class VMStructs;\n+private:\n+  static const size_t INITIAL_CAPACITY = 4;\n+  oop* _base;\n+  oop* _limit;\n+  oop* _current;\n+\n+  void grow();\n+  void validate(const char* msg) const PRODUCT_RETURN;\n+public:\n+  static ByteSize current_offset()    { return byte_offset_of(LockStack, _current); }\n+  static ByteSize base_offset()       { return byte_offset_of(LockStack, _base); }\n+  static ByteSize limit_offset()      { return byte_offset_of(LockStack, _limit); }\n+\n+  LockStack();\n+  ~LockStack();\n+\n+  inline void push(oop o);\n+  inline oop pop();\n+  inline void remove(oop o);\n+\n+  inline bool contains(oop o) const;\n+\n+  \/\/ GC support\n+  inline void oops_do(OopClosure* cl);\n+\n+};\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":64,"deletions":0,"binary":false,"changes":64,"status":"added"},{"patch":"@@ -0,0 +1,92 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+#define SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"runtime\/lockStack.hpp\"\n+\n+inline void LockStack::push(oop o) {\n+  validate(\"pre-push\");\n+  assert(!contains(o), \"entries must be unique\");\n+  if (_current >= _limit) {\n+    grow();\n+  }\n+  *_current = o;\n+  _current++;\n+  validate(\"post-push\");\n+}\n+\n+inline oop LockStack::pop() {\n+  validate(\"pre-pop\");\n+  oop* new_loc = _current - 1;\n+  assert(new_loc < _current, \"underflow, probably unbalanced push\/pop\");\n+  _current = new_loc;\n+  oop o = *_current;\n+  assert(!contains(o), \"entries must be unique\");\n+  validate(\"post-pop\");\n+  return o;\n+}\n+\n+inline void LockStack::remove(oop o) {\n+  validate(\"pre-remove\");\n+  assert(contains(o), \"entry must be present\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    if (*loc == o) {\n+      oop* last = _current - 1;\n+      for (; loc < last; loc++) {\n+        *loc = *(loc + 1);\n+      }\n+      _current--;\n+      break;\n+    }\n+  }\n+  assert(!contains(o), \"entries must be unique: \" PTR_FORMAT, p2i(o));\n+  validate(\"post-remove\");\n+}\n+\n+inline bool LockStack::contains(oop o) const {\n+  validate(\"pre-contains\");\n+  bool found = false;\n+  size_t i = 0;\n+  size_t found_i = 0;\n+  for (oop* loc = _current - 1; loc >= _base; loc--) {\n+    if (*loc == o) {\n+      return true;\n+    }\n+  }\n+  validate(\"post-contains\");\n+  return false;\n+}\n+\n+inline void LockStack::oops_do(OopClosure* cl) {\n+  validate(\"pre-oops-do\");\n+  for (oop* loc = _base; loc < _current; loc++) {\n+    cl->do_oop(loc);\n+  }\n+  validate(\"post-oops-do\");\n+}\n+\n+#endif \/\/ SHARE_RUNTIME_LOCKSTACK_INLINE_HPP\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":92,"deletions":0,"binary":false,"changes":92,"status":"added"},{"patch":"@@ -337,6 +337,1 @@\n-  if (current->is_lock_owned((address)cur)) {\n-    assert(_recursions == 0, \"internal state error\");\n-    _recursions = 1;\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    return true;\n-  }\n+  assert(cur == ANONYMOUS_OWNER || !current->is_lock_owned((address)cur), \"precondition\");\n@@ -1154,14 +1149,10 @@\n-    if (current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"invariant\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    } else {\n-      \/\/ Apparent unbalanced locking ...\n-      \/\/ Naively we'd like to throw IllegalMonitorStateException.\n-      \/\/ As a practical matter we can neither allocate nor throw an\n-      \/\/ exception as ::exit() can be called from leaf routines.\n-      \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n-      \/\/ Upon deeper reflection, however, in a properly run JVM the only\n-      \/\/ way we should encounter this situation is in the presence of\n-      \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n-      \/\/ See also: CR4414101\n+    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n+    \/\/ Apparent unbalanced locking ...\n+    \/\/ Naively we'd like to throw IllegalMonitorStateException.\n+    \/\/ As a practical matter we can neither allocate nor throw an\n+    \/\/ exception as ::exit() can be called from leaf routines.\n+    \/\/ see x86_32.ad Fast_Unlock() and the I1 and I2 properties.\n+    \/\/ Upon deeper reflection, however, in a properly run JVM the only\n+    \/\/ way we should encounter this situation is in the presence of\n+    \/\/ unbalanced JNI locking. TODO: CheckJNICalls.\n+    \/\/ See also: CR4414101\n@@ -1169,6 +1160,6 @@\n-      LogStreamHandle(Error, monitorinflation) lsh;\n-      lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n-                    \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n-      lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n-      print_debug_style_on(&lsh);\n-      assert(false, \"Non-balanced monitor enter\/exit!\");\n+    LogStreamHandle(Error, monitorinflation) lsh;\n+    lsh.print_cr(\"ERROR: ObjectMonitor::exit(): thread=\" INTPTR_FORMAT\n+                  \" is exiting an ObjectMonitor it does not own.\", p2i(current));\n+    lsh.print_cr(\"The imbalance is possibly caused by JNI locking.\");\n+    print_debug_style_on(&lsh);\n+    assert(false, \"Non-balanced monitor enter\/exit! \" PTR_FORMAT, p2i(object()));\n@@ -1176,2 +1167,1 @@\n-      return;\n-    }\n+    return;\n@@ -1374,5 +1364,1 @@\n-    if (current->is_lock_owned((address)cur)) {\n-      assert(_recursions == 0, \"internal state error\");\n-      set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-      _recursions = 0;\n-    }\n+    assert(!current->is_lock_owned((address)cur), \"no stack-locking\");\n@@ -1423,0 +1409,1 @@\n+  assert(cur != ANONYMOUS_OWNER, \"no anon owner here\");\n@@ -1426,5 +1413,0 @@\n-  if (current->is_lock_owned((address)cur)) {\n-    set_owner_from_BasicLock(cur, current);  \/\/ Convert from BasicLock* to Thread*.\n-    _recursions = 0;\n-    return true;\n-  }\n@@ -2032,6 +2014,0 @@\n-\/\/ Beware too, that _owner is sometimes a BasicLock address and sometimes\n-\/\/ a thread pointer.\n-\/\/ Alternately, we might tag the type (thread pointer vs basiclock pointer)\n-\/\/ with the LSB of _owner.  Another option would be to probabilistically probe\n-\/\/ the putative _owner->TypeTag value.\n-\/\/\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":20,"deletions":44,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-\/\/ JavaMonitor. The lightweight BasicLock\/stack lock version has been\n+\/\/ JavaMonitor. The lightweight fast-lock version has been\n@@ -149,1 +149,2 @@\n-  void* volatile _owner;            \/\/ pointer to owning thread OR BasicLock\n+  #define ANONYMOUS_OWNER reinterpret_cast<void*>(1)\n+  void* volatile _owner;            \/\/ pointer to owning thread\n@@ -259,2 +260,0 @@\n-  \/\/ Simply set _owner field to current; current value must match basic_lock_p.\n-  void      set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current);\n@@ -279,0 +278,12 @@\n+  void set_owner_anonymous() {\n+    set_owner_from(NULL, ANONYMOUS_OWNER);\n+  }\n+\n+  bool is_owner_anonymous() const {\n+    return _owner == ANONYMOUS_OWNER;\n+  }\n+\n+  void set_owner_from_anonymous(Thread* owner) {\n+    set_owner_from(ANONYMOUS_OWNER, owner);\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -119,16 +119,0 @@\n-\/\/ Simply set _owner field to self; current value must match basic_lock_p.\n-inline void ObjectMonitor::set_owner_from_BasicLock(void* basic_lock_p, JavaThread* current) {\n-#ifdef ASSERT\n-  void* prev = Atomic::load(&_owner);\n-  assert(prev == basic_lock_p, \"unexpected prev owner=\" INTPTR_FORMAT\n-         \", expected=\" INTPTR_FORMAT, p2i(prev), p2i(basic_lock_p));\n-#endif\n-  \/\/ Non-null owner field to non-null owner field is safe without\n-  \/\/ cmpxchg() as long as all readers can tolerate either flavor.\n-  Atomic::store(&_owner, current);\n-  log_trace(monitorinflation, owner)(\"set_owner_from_BasicLock(): mid=\"\n-                                     INTPTR_FORMAT \", basic_lock_p=\"\n-                                     INTPTR_FORMAT \", new_value=\" INTPTR_FORMAT,\n-                                     p2i(this), p2i(basic_lock_p), p2i(current));\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2199,1 +2199,1 @@\n-void SharedRuntime::monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n+void SharedRuntime::monitor_enter_helper(oopDesc* obj, JavaThread* current) {\n@@ -2203,1 +2203,1 @@\n-    if (ObjectSynchronizer::quick_enter(obj, current, lock)) {\n+    if (ObjectSynchronizer::quick_enter(obj, current)) {\n@@ -2213,1 +2213,1 @@\n-  ObjectSynchronizer::enter(h_obj, lock, current);\n+  ObjectSynchronizer::enter(h_obj, current);\n@@ -2219,2 +2219,2 @@\n-JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n-  SharedRuntime::monitor_enter_helper(obj, lock, current);\n+JRT_BLOCK_ENTRY(void, SharedRuntime::complete_monitor_locking_C(oopDesc* obj, JavaThread* current))\n+  SharedRuntime::monitor_enter_helper(obj, current);\n@@ -2223,1 +2223,1 @@\n-void SharedRuntime::monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current) {\n+void SharedRuntime::monitor_exit_helper(oopDesc* obj, JavaThread* current) {\n@@ -2235,1 +2235,1 @@\n-  ObjectSynchronizer::exit(obj, lock, current);\n+  ObjectSynchronizer::exit(obj, current);\n@@ -2239,2 +2239,2 @@\n-JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current))\n-  SharedRuntime::monitor_exit_helper(obj, lock, current);\n+JRT_LEAF(void, SharedRuntime::complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current))\n+  SharedRuntime::monitor_exit_helper(obj, current);\n@@ -3321,11 +3321,0 @@\n-      BasicLock *lock = kptr2->lock();\n-      \/\/ Inflate so the object's header no longer refers to the BasicLock.\n-      if (lock->displaced_header().is_unlocked()) {\n-        \/\/ The object is locked and the resulting ObjectMonitor* will also be\n-        \/\/ locked so it can't be async deflated until ownership is dropped.\n-        \/\/ See the big comment in basicLock.cpp: BasicLock::move_to().\n-        ObjectSynchronizer::inflate_helper(kptr2->obj());\n-      }\n-      \/\/ Now the displaced header is free to move because the\n-      \/\/ object's header no longer refers to it.\n-      buf[i++] = (intptr_t)lock->displaced_header().value();\n@@ -3335,1 +3324,1 @@\n-  assert(i - max_locals == active_monitor_count*2, \"found the expected number of monitors\");\n+  assert(i - max_locals == active_monitor_count, \"found the expected number of monitors\");\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":10,"deletions":21,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -341,1 +341,1 @@\n-  static void monitor_enter_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n+  static void monitor_enter_helper(oopDesc* obj, JavaThread* thread);\n@@ -343,1 +343,1 @@\n-  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void monitor_exit_helper(oopDesc* obj, JavaThread* current);\n@@ -489,2 +489,2 @@\n-  static void complete_monitor_locking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n-  static void complete_monitor_unlocking_C(oopDesc* obj, BasicLock* lock, JavaThread* current);\n+  static void complete_monitor_locking_C(oopDesc* obj, JavaThread* current);\n+  static void complete_monitor_unlocking_C(oopDesc* obj, JavaThread* current);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -250,15 +250,0 @@\n-BasicLock* StackValue::resolve_monitor_lock(const frame* fr, Location location) {\n-  assert(location.is_stack(), \"for now we only look at the stack\");\n-  int word_offset = location.stack_offset() \/ wordSize;\n-  \/\/ (stack picture)\n-  \/\/ high: [     ]  word_offset + 1\n-  \/\/ low   [     ]  word_offset\n-  \/\/\n-  \/\/ sp->  [     ]  0\n-  \/\/ the word_offset is the distance from the stack pointer to the lowest address\n-  \/\/ The frame's original stack pointer, before any extension by its callee\n-  \/\/ (due to Compiler1 linkage on SPARC), must be used.\n-  return (BasicLock*) (fr->unextended_sp() + word_offset);\n-}\n-\n-\n","filename":"src\/hotspot\/share\/runtime\/stackValue.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-class BasicLock;\n@@ -110,2 +109,0 @@\n-  static BasicLock*  resolve_monitor_lock(const frame* fr, Location location);\n-\n","filename":"src\/hotspot\/share\/runtime\/stackValue.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -309,1 +310,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) {\n@@ -350,2 +351,1 @@\n-bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current,\n-                                     BasicLock * lock) {\n+bool ObjectSynchronizer::quick_enter(oop obj, JavaThread* current) {\n@@ -383,11 +383,0 @@\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ stack-locking in the object's header, the second check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    lock->set_displaced_header(markWord::unused_mark());\n-\n@@ -473,1 +462,1 @@\n-void ObjectSynchronizer::enter(Handle obj, BasicLock* lock, JavaThread* current) {\n+void ObjectSynchronizer::enter(Handle obj, JavaThread* current) {\n@@ -481,7 +470,19 @@\n-    markWord mark = obj->mark();\n-    if (mark.is_neutral()) {\n-      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-      \/\/ be visible <= the ST performed by the CAS.\n-      lock->set_displaced_header(mark);\n-      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n-        return;\n+    LockStack& lock_stack = current->lock_stack();\n+\n+    markWord header = obj()->mark_acquire();\n+    while (true) {\n+      if (header.is_neutral()) {\n+        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+        \/\/ Try to swing into 'fast-locked' state without inflating.\n+        markWord locked_header = header.set_fast_locked();\n+        markWord witness = obj()->cas_set_mark(locked_header, header);\n+        if (witness == header) {\n+          \/\/ Successfully fast-locked, push object to lock-stack and return.\n+          lock_stack.push(obj());\n+          return;\n+        }\n+        \/\/ Otherwise retry.\n+        header = witness;\n+      } else {\n+        \/\/ Fall-through to inflate-enter.\n+        break;\n@@ -489,7 +490,0 @@\n-      \/\/ Fall through to inflate() ...\n-    } else if (mark.has_locker() &&\n-               current->is_lock_owned((address)mark.locker())) {\n-      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-      assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-      lock->set_displaced_header(markWord::from_pointer(NULL));\n-      return;\n@@ -497,6 +491,0 @@\n-\n-    \/\/ The object header will never be displaced to this lock,\n-    \/\/ so it does not matter what the value is, except that it\n-    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-    \/\/ and must not look locked either.\n-    lock->set_displaced_header(markWord::unused_mark());\n@@ -504,1 +492,1 @@\n-    guarantee(!obj->mark().has_locker(), \"must not be stack-locked\");\n+    guarantee(!obj->mark().is_fast_locked(), \"must not be stack-locked\");\n@@ -518,1 +506,1 @@\n-void ObjectSynchronizer::exit(oop object, BasicLock* lock, JavaThread* current) {\n+void ObjectSynchronizer::exit(oop object, JavaThread* current) {\n@@ -520,32 +508,12 @@\n-\n-  if (!useHeavyMonitors()) {\n-    markWord mark = object->mark();\n-\n-    markWord dhw = lock->displaced_header();\n-    if (dhw.value() == 0) {\n-      \/\/ If the displaced header is NULL, then this exit matches up with\n-      \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-      if (mark != markWord::INFLATING()) {\n-        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-        \/\/ exiting a recursive enter of a Java Monitor that is being\n-        \/\/ inflated is safe; see the has_monitor() comment below.\n-        assert(!mark.is_neutral(), \"invariant\");\n-        assert(!mark.has_locker() ||\n-        current->is_lock_owned((address)mark.locker()), \"invariant\");\n-        if (mark.has_monitor()) {\n-          \/\/ The BasicLock's displaced_header is marked as a recursive\n-          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-          \/\/ This is a special case where the Java Monitor was inflated\n-          \/\/ after this thread entered the stack-lock recursively. When a\n-          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-          \/\/ Monitor owner's stack and update the BasicLocks because a\n-          \/\/ Java Monitor can be asynchronously inflated by a thread that\n-          \/\/ does not own the Java Monitor.\n-          ObjectMonitor* m = mark.monitor();\n-          assert(m->object()->mark() == mark, \"invariant\");\n-          assert(m->is_entered(current), \"invariant\");\n-        }\n-      }\n-#endif\n-      return;\n+  markWord header = object->mark_acquire();\n+  if (!useHeavyMonitors() && header.is_fast_locked()) {\n+    markWord unlocked_header = header.set_unlocked();\n+    markWord witness = object->cas_set_mark(unlocked_header, header);\n+    if (witness != header) {\n+      \/\/ Another thread beat us, it can only have installed an anonymously locked monitor at this point.\n+      \/\/ Fetch that monitor, set owner correctly to this thread, and exit it (allowing waiting threads to enter).\n+      assert(witness.has_monitor(), \"must have monitor\");\n+      ObjectMonitor* monitor = witness.monitor();\n+      assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n+      monitor->set_owner_from_anonymous(current);\n+      monitor->exit(current);\n@@ -553,11 +521,5 @@\n-\n-    if (mark == markWord::from_pointer(lock)) {\n-      \/\/ If the object is stack-locked by the current thread, try to\n-      \/\/ swing the displaced header from the BasicLock back to the mark.\n-      assert(dhw.is_neutral(), \"invariant\");\n-      if (object->cas_set_mark(dhw, mark) == mark) {\n-        return;\n-      }\n-    }\n-  } else if (VerifyHeavyMonitors) {\n-    guarantee(!object->mark().has_locker(), \"must not be stack-locked\");\n+    LockStack& lock_stack = current->lock_stack();\n+    oop top_lock = lock_stack.pop();\n+    assert(top_lock == object, \"unbalanced monitorenter\/exit: top_lock: \" PTR_FORMAT \", object: \" PTR_FORMAT,\n+           p2i(top_lock), p2i(object));\n+    return;\n@@ -566,4 +528,10 @@\n-  \/\/ We have to take the slow-path of possible inflation and then exit.\n-  \/\/ The ObjectMonitor* can't be async deflated until ownership is\n-  \/\/ dropped inside exit() and the ObjectMonitor* must be !is_busy().\n-  ObjectMonitor* monitor = inflate(current, object, inflate_cause_vm_internal);\n+  assert(header.has_monitor(), \"must have monitor\");\n+  log_trace(monitorinflation)(\"monitor unlocking object: \" PTR_FORMAT, p2i(object));\n+  ObjectMonitor* monitor = header.monitor();\n+  if (!useHeavyMonitors() && monitor->is_owner_anonymous()) {\n+    \/\/ It must be us. Pop lock object from lock stack.\n+    LockStack& lock_stack = current->lock_stack();\n+    oop popped = lock_stack.pop();\n+    assert(popped == object, \"must be owned by this thread\");\n+    monitor->set_owner_from_anonymous(current);\n+  }\n@@ -657,1 +625,1 @@\n-    ObjectSynchronizer::enter(_obj, &_lock, _thread);\n+    ObjectSynchronizer::enter(_obj, _thread);\n@@ -663,1 +631,1 @@\n-    ObjectSynchronizer::exit(_obj(), &_lock, _thread);\n+    ObjectSynchronizer::exit(_obj(), _thread);\n@@ -706,1 +674,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n@@ -721,1 +689,1 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if (mark.is_fast_locked() && current->lock_stack().contains(obj())) {\n@@ -747,65 +715,2 @@\n-markWord ObjectSynchronizer::read_stable_mark(oop obj) {\n-  markWord mark = obj->mark_acquire();\n-  if (!mark.is_being_inflated()) {\n-    return mark;       \/\/ normal fast-path return\n-  }\n-\n-  int its = 0;\n-  for (;;) {\n-    markWord mark = obj->mark_acquire();\n-    if (!mark.is_being_inflated()) {\n-      return mark;    \/\/ normal fast-path return\n-    }\n-\n-    \/\/ The object is being inflated by some other thread.\n-    \/\/ The caller of read_stable_mark() must wait for inflation to complete.\n-    \/\/ Avoid live-lock.\n-\n-    ++its;\n-    if (its > 10000 || !os::is_MP()) {\n-      if (its & 1) {\n-        os::naked_yield();\n-      } else {\n-        \/\/ Note that the following code attenuates the livelock problem but is not\n-        \/\/ a complete remedy.  A more complete solution would require that the inflating\n-        \/\/ thread hold the associated inflation lock.  The following code simply restricts\n-        \/\/ the number of spinners to at most one.  We'll have N-2 threads blocked\n-        \/\/ on the inflationlock, 1 thread holding the inflation lock and using\n-        \/\/ a yield\/park strategy, and 1 thread in the midst of inflation.\n-        \/\/ A more refined approach would be to change the encoding of INFLATING\n-        \/\/ to allow encapsulation of a native thread pointer.  Threads waiting for\n-        \/\/ inflation to complete would use CAS to push themselves onto a singly linked\n-        \/\/ list rooted at the markword.  Once enqueued, they'd loop, checking a per-thread flag\n-        \/\/ and calling park().  When inflation was complete the thread that accomplished inflation\n-        \/\/ would detach the list and set the markword to inflated with a single CAS and\n-        \/\/ then for each thread on the list, set the flag and unpark() the thread.\n-\n-        \/\/ Index into the lock array based on the current object address.\n-        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n-        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (NINFLATIONLOCKS-1);\n-        int YieldThenBlock = 0;\n-        assert(ix >= 0 && ix < NINFLATIONLOCKS, \"invariant\");\n-        gInflationLocks[ix]->lock();\n-        while (obj->mark_acquire() == markWord::INFLATING()) {\n-          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n-          \/\/ so we periodically call current->_ParkEvent->park(1).\n-          \/\/ We use a mixed spin\/yield\/block mechanism.\n-          if ((YieldThenBlock++) >= 16) {\n-            Thread::current()->_ParkEvent->park(1);\n-          } else {\n-            os::naked_yield();\n-          }\n-        }\n-        gInflationLocks[ix]->unlock();\n-      }\n-    } else {\n-      SpinPause();       \/\/ SMP-polite spinning\n-    }\n-  }\n-}\n-\n-\/\/ Safely load a mark word from an object, even with racing stack-locking or monitor inflation.\n-\/\/ The protocol is a partial inflation-protocol: it installs INFLATING into the object's mark\n-\/\/ word in order to prevent an stack-locks or inflations from interferring (or detect such\n-\/\/ interference and retry), but then, instead of creating and installing a monitor, simply\n-\/\/ read and return the real mark word.\n+\/\/ Safely load a mark word from an object. If the mark word is displaced by an ObjectMonitor,\n+\/\/ load the diplaced mark word from the monitor.\n@@ -813,58 +718,6 @@\n-  for (;;) {\n-    const markWord mark = read_stable_mark(object);\n-    assert(!mark.is_being_inflated(), \"read_stable_mark must prevent inflating mark\");\n-\n-    \/\/ The mark can be in one of the following states:\n-    \/\/ *  Inflated     - just return mark from inflated monitor\n-    \/\/ *  Stack-locked - coerce it to inflating, and then return displaced mark\n-    \/\/ *  Neutral      - return mark\n-    \/\/ *  Marked       - return mark\n-\n-    \/\/ CASE: inflated\n-    if (mark.has_monitor()) {\n-      ObjectMonitor* inf = mark.monitor();\n-      markWord dmw = inf->header();\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n-    if (mark.has_locker()) {\n-      BasicLock* lock = mark.locker();\n-      if (Thread::current()->is_lock_owned((address)lock)) {\n-        \/\/ If locked by this thread, it is safe to access the displaced header.\n-        markWord dmw = lock->displaced_header();\n-        assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-        return dmw;\n-      }\n-\n-      \/\/ Otherwise, attempt to temporarily install INFLATING into the mark-word,\n-      \/\/ to prevent inflation or unlocking by competing thread.\n-      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      assert(object->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      object->release_set_mark(mark);\n-\n-      return dmw;\n-    }\n-\n-    \/\/ CASE: neutral or marked (for GC)\n-    \/\/ Catch if the object's header is not neutral or marked (it must not be locked).\n-    assert(mark.is_neutral() || mark.is_marked(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n-    return mark;\n+  const markWord mark = object->mark_acquire();\n+  if (mark.has_monitor()) {\n+    ObjectMonitor* inf = mark.monitor();\n+    markWord dmw = inf->header();\n+    assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n+    return dmw;\n@@ -872,0 +725,3 @@\n+  \/\/ CASE: neutral, fast-locked or marked (for GC)\n+  assert(mark.is_neutral() || mark.is_marked() || mark.is_fast_locked(), \"invariant: header=\" INTPTR_FORMAT, mark.value());\n+  return mark;\n@@ -937,1 +793,1 @@\n-    markWord mark = read_stable_mark(obj);\n+    markWord mark = obj->mark_acquire();\n@@ -940,1 +796,1 @@\n-      guarantee(!mark.has_locker(), \"must not be stack locked\");\n+      guarantee(!mark.is_fast_locked(), \"must not be fast-locked\");\n@@ -985,6 +841,5 @@\n-    } else if (current->is_lock_owned((address)mark.locker())) {\n-      \/\/ This is a stack lock owned by the calling thread so fetch the\n-      \/\/ displaced markWord from the BasicLock on the stack.\n-      temp = mark.displaced_mark_helper();\n-      assert(temp.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n-      hash = temp.hash();\n+    } else if (current->lock_stack().contains(obj)) {\n+      \/\/ This is a fast lock owned by the calling thread so use the\n+      \/\/ markWord from the object.\n+      assert(mark.is_fast_locked(), \"invariant: header=\" INTPTR_FORMAT, temp.value());\n+      hash = mark.hash();\n@@ -994,8 +849,0 @@\n-      \/\/ WARNING:\n-      \/\/ The displaced header in the BasicLock on a thread's stack\n-      \/\/ is strictly immutable. It CANNOT be changed in ANY cases.\n-      \/\/ So we have to inflate the stack lock into an ObjectMonitor\n-      \/\/ even if the current thread owns the lock. The BasicLock on\n-      \/\/ a thread's stack can be asynchronously read by other threads\n-      \/\/ during an inflate() call so any change to that stack memory\n-      \/\/ may not propagate to other threads correctly.\n@@ -1055,1 +902,1 @@\n-  markWord mark = read_stable_mark(obj);\n+  markWord mark = obj->mark_acquire();\n@@ -1057,3 +904,2 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n-    return current->is_lock_owned((address)mark.locker());\n+  if (mark.is_fast_locked()) {\n+    return current->lock_stack().contains(h_obj());\n@@ -1066,1 +912,5 @@\n-    return monitor->is_entered(current) != 0;\n+    if (monitor->is_owner_anonymous()) {\n+      return current->lock_stack().contains(h_obj());\n+    } else {\n+      return monitor->is_entered(current) != 0;\n+    }\n@@ -1076,29 +926,2 @@\n-  address owner = NULL;\n-\n-  markWord mark = read_stable_mark(obj);\n-\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n-    owner = (address) mark.locker();\n-  }\n-\n-  \/\/ Contended case, header points to ObjectMonitor (tagged pointer)\n-  else if (mark.has_monitor()) {\n-    \/\/ The first stage of async deflation does not affect any field\n-    \/\/ used by this comparison so the ObjectMonitor* is usable here.\n-    ObjectMonitor* monitor = mark.monitor();\n-    assert(monitor != NULL, \"monitor should be non-null\");\n-    owner = (address) monitor->owner();\n-  }\n-\n-  if (owner != NULL) {\n-    \/\/ owning_thread_from_monitor_owner() may also return NULL here\n-    return Threads::owning_thread_from_monitor_owner(t_list, owner);\n-  }\n-\n-  \/\/ Unlocked case, header in place\n-  \/\/ Cannot have assertion since this object may have been\n-  \/\/ locked by another thread when reaching here.\n-  \/\/ assert(mark.is_neutral(), \"sanity check\");\n-\n-  return NULL;\n+  ObjectMonitor* monitor_dummy;\n+  return Threads::owning_thread_from_object(t_list, obj, &monitor_dummy);\n@@ -1292,3 +1115,2 @@\n-    \/\/ *  Inflated     - just return\n-    \/\/ *  Stack-locked - coerce it to inflated\n-    \/\/ *  INFLATING    - busy wait for conversion to complete\n+    \/\/ *  Inflated     - just return, maybe fix anon owner\n+    \/\/ *  Fast-locked  - coerce it to inflated\n@@ -1302,0 +1124,6 @@\n+      if (inf->is_owner_anonymous()) {\n+        if (current->lock_stack().contains(object)) {\n+          inf->set_owner_from_anonymous(current);\n+          current->lock_stack().remove(object);\n+        }\n+      }\n@@ -1305,21 +1133,2 @@\n-    \/\/ CASE: inflation in progress - inflating over a stack-lock.\n-    \/\/ Some other thread is converting from stack-locked to inflated.\n-    \/\/ Only that thread can complete inflation -- other threads must wait.\n-    \/\/ The INFLATING value is transient.\n-    \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n-    \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n-    if (mark == markWord::INFLATING()) {\n-      read_stable_mark(object);\n-      continue;\n-    }\n-\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n-    \/\/\n-    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n-    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n-    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n-    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n-    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n-    \/\/ the odds of inflation contention.\n-\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by this thread or by some other thread.\n@@ -1328,76 +1137,11 @@\n-    if (mark.has_locker()) {\n-      ObjectMonitor* m = new ObjectMonitor(object);\n-      \/\/ Optimistically prepare the ObjectMonitor - anticipate successful CAS\n-      \/\/ We do this before the CAS in order to minimize the length of time\n-      \/\/ in which INFLATING appears in the mark.\n-\n-      markWord cmp = object->cas_set_mark(markWord::INFLATING(), mark);\n-      if (cmp != mark) {\n-        delete m;\n-        continue;       \/\/ Interference -- just retry\n-      }\n-\n-      \/\/ We've successfully installed INFLATING (0) into the mark-word.\n-      \/\/ This is the only case where 0 will appear in a mark-word.\n-      \/\/ Only the singular thread that successfully swings the mark-word\n-      \/\/ to 0 can perform (or more precisely, complete) inflation.\n-      \/\/\n-      \/\/ Why do we CAS a 0 into the mark-word instead of just CASing the\n-      \/\/ mark-word from the stack-locked value directly to the new inflated state?\n-      \/\/ Consider what happens when a thread unlocks a stack-locked object.\n-      \/\/ It attempts to use CAS to swing the displaced header value from the\n-      \/\/ on-stack BasicLock back into the object header.  Recall also that the\n-      \/\/ header value (hash code, etc) can reside in (a) the object header, or\n-      \/\/ (b) a displaced header associated with the stack-lock, or (c) a displaced\n-      \/\/ header in an ObjectMonitor.  The inflate() routine must copy the header\n-      \/\/ value from the BasicLock on the owner's stack to the ObjectMonitor, all\n-      \/\/ the while preserving the hashCode stability invariants.  If the owner\n-      \/\/ decides to release the lock while the value is 0, the unlock will fail\n-      \/\/ and control will eventually pass from slow_exit() to inflate.  The owner\n-      \/\/ will then spin, waiting for the 0 value to disappear.   Put another way,\n-      \/\/ the 0 causes the owner to stall if the owner happens to try to\n-      \/\/ drop the lock (restoring the header from the BasicLock to the object)\n-      \/\/ while inflation is in-progress.  This protocol avoids races that might\n-      \/\/ would otherwise permit hashCode values to change or \"flicker\" for an object.\n-      \/\/ Critically, while object->mark is 0 mark.displaced_mark_helper() is stable.\n-      \/\/ 0 serves as a \"BUSY\" inflate-in-progress indicator.\n-\n-\n-      \/\/ fetch the displaced mark from the owner's stack.\n-      \/\/ The owner can't die or unwind past the lock while our INFLATING\n-      \/\/ object is in the mark.  Furthermore the owner can't complete\n-      \/\/ an unlock on the object, either.\n-      markWord dmw = mark.displaced_mark_helper();\n-      \/\/ Catch if the object's header is not neutral (not locked and\n-      \/\/ not marked is what we care about here).\n-      assert(dmw.is_neutral(), \"invariant: header=\" INTPTR_FORMAT, dmw.value());\n-\n-      \/\/ Setup monitor fields to proper values -- prepare the monitor\n-      m->set_header(dmw);\n-\n-      \/\/ Optimization: if the mark.locker stack address is associated\n-      \/\/ with this thread we could simply set m->_owner = current.\n-      \/\/ Note that a thread can inflate an object\n-      \/\/ that it has stack-locked -- as might happen in wait() -- directly\n-      \/\/ with CAS.  That is, we can avoid the xchg-NULL .... ST idiom.\n-      m->set_owner_from(NULL, mark.locker());\n-      \/\/ TODO-FIXME: assert BasicLock->dhw != 0.\n-\n-      \/\/ Must preserve store ordering. The monitor state must\n-      \/\/ be stable at the time of publishing the monitor address.\n-      guarantee(object->mark() == markWord::INFLATING(), \"invariant\");\n-      \/\/ Release semantics so that above set_object() is seen first.\n-      object->release_set_mark(markWord::encode(m));\n-\n-      \/\/ Once ObjectMonitor is configured and the object is associated\n-      \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n-      _in_use_list.add(m);\n-\n-      \/\/ Hopefully the performance counters are allocated on distinct cache lines\n-      \/\/ to avoid false sharing on MP systems ...\n-      OM_PERFDATA_OP(Inflations, inc());\n-      if (log_is_enabled(Trace, monitorinflation)) {\n-        ResourceMark rm(current);\n-        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n-                     INTPTR_FORMAT \", type='%s'\", p2i(object),\n-                     object->mark().value(), object->klass()->external_name());\n+    if (mark.is_fast_locked()) {\n+      ObjectMonitor* monitor = new ObjectMonitor(object);\n+      monitor->set_header(mark.set_unlocked());\n+      LockStack& lock_stack = current->lock_stack();\n+      bool own = lock_stack.contains(object);\n+      if (own) {\n+        \/\/ Owned by us.\n+        monitor->set_owner_from(NULL, current);\n+      } else {\n+        \/\/ Owned by somebody else.\n+        monitor->set_owner_anonymous();\n@@ -1405,2 +1149,24 @@\n-      if (event.should_commit()) {\n-        post_monitor_inflate_event(&event, object, cause);\n+      markWord monitor_mark = markWord::encode(monitor);\n+      markWord witness = object->cas_set_mark(monitor_mark, mark);\n+      if (witness == mark) {\n+        \/\/ Success! Return inflated monitor.\n+        if (own) {\n+          lock_stack.remove(object);\n+        }\n+        \/\/ Once the ObjectMonitor is configured and object is associated\n+        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+        _in_use_list.add(monitor);\n+\n+        \/\/ Hopefully the performance counters are allocated on distinct\n+        \/\/ cache lines to avoid false sharing on MP systems ...\n+        OM_PERFDATA_OP(Inflations, inc());\n+        if (log_is_enabled(Trace, monitorinflation)) {\n+          ResourceMark rm(current);\n+          lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n+                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                       object->mark().value(), object->klass()->external_name());\n+        }\n+        if (event.should_commit()) {\n+          post_monitor_inflate_event(&event, object, cause);\n+        }\n+        return monitor;\n@@ -1408,1 +1174,3 @@\n-      return m;\n+      \/\/ Otherwise, discard the monitor and retry.\n+      delete monitor;\n+      continue;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":132,"deletions":364,"binary":false,"changes":496,"status":"modified"},{"patch":"@@ -149,2 +149,2 @@\n-  static void enter(Handle obj, BasicLock* lock, JavaThread* current);\n-  static void exit(oop obj, BasicLock* lock, JavaThread* current);\n+  static void enter(Handle obj, JavaThread* current);\n+  static void exit(oop obj, JavaThread* current);\n@@ -163,1 +163,1 @@\n-  static bool quick_enter(oop obj, JavaThread* current, BasicLock* Lock);\n+  static bool quick_enter(oop obj, JavaThread* current);\n@@ -187,3 +187,0 @@\n-  \/\/ Read mark-word and spin-wait as long as INFLATING is observed.\n-  static markWord read_stable_mark(oop obj);\n-\n@@ -270,1 +267,0 @@\n-  BasicLock   _lock;\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":3,"deletions":7,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -75,1 +76,2 @@\n-Thread::Thread() {\n+Thread::Thread():\n+  _lock_stack() {\n@@ -417,0 +419,3 @@\n+  if (!UseHeavyMonitors) {\n+    lock_stack().oops_do(f);\n+  }\n@@ -544,1 +549,2 @@\n-  return is_in_full_stack(adr);\n+  assert(adr != ANONYMOUS_OWNER, \"must convert to lock object\");\n+  return !UseHeavyMonitors && lock_stack().contains(cast_to_oop(adr));\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"runtime\/lockStack.hpp\"\n@@ -611,2 +612,1 @@\n-  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors, JVMTI raw monitors,\n-                                              \/\/ and ObjectSynchronizer::read_stable_mark\n+  ParkEvent * volatile _ParkEvent;            \/\/ for Object monitors and JVMTI raw monitors\n@@ -624,0 +624,10 @@\n+private:\n+  LockStack _lock_stack;\n+\n+public:\n+  LockStack& lock_stack() { return _lock_stack; }\n+  const LockStack& lock_stack() const { return _lock_stack; }\n+\n+  static ByteSize lock_stack_current_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::current_offset(); }\n+  static ByteSize lock_stack_limit_offset()    { return byte_offset_of(Thread, _lock_stack) + LockStack::limit_offset(); }\n+\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -72,1 +73,1 @@\n-#include \"runtime\/objectMonitor.hpp\"\n+#include \"runtime\/objectMonitor.inline.hpp\"\n@@ -1360,21 +1361,1 @@\n-\n-JavaThread *Threads::owning_thread_from_monitor_owner(ThreadsList * t_list,\n-                                                      address owner) {\n-  \/\/ NULL owner means not locked so we can skip the search\n-  if (owner == NULL) return NULL;\n-\n-  for (JavaThread* p : *t_list) {\n-    \/\/ first, see if owner is the address of a Java thread\n-    if (owner == (address)p) return p;\n-  }\n-\n-  \/\/ Cannot assert on lack of success here since this function may be\n-  \/\/ used by code that is trying to report useful problem information\n-  \/\/ like deadlock detection.\n-  if (UseHeavyMonitors) return NULL;\n-\n-  \/\/ If we didn't find a matching Java thread and we didn't force use of\n-  \/\/ heavyweight monitors, then the owner is the stack address of the\n-  \/\/ Lock Word in the owning Java thread's stack.\n-  \/\/\n-  JavaThread* the_owner = NULL;\n+JavaThread* Threads::owning_thread_impl(ThreadsList * t_list, oop obj) {\n@@ -1382,3 +1363,2 @@\n-    if (q->is_lock_owned(owner)) {\n-      the_owner = q;\n-      break;\n+    if (q->lock_stack().contains(obj)) {\n+      return q;\n@@ -1387,0 +1367,14 @@\n+  return NULL;\n+}\n+\n+JavaThread* Threads::owning_thread_from_object(ThreadsList * t_list, oop obj, ObjectMonitor** monitor_out) {\n+  markWord header = obj->mark();\n+  if (header.is_fast_locked()) {\n+    return owning_thread_impl(t_list, obj);\n+  } else if (header.has_monitor()) {\n+    *monitor_out = header.monitor();\n+    return owning_thread_from_monitor(t_list, *monitor_out);\n+  } else {\n+    return NULL;\n+  }\n+}\n@@ -1388,2 +1382,12 @@\n-  \/\/ cannot assert on lack of success here; see above comment\n-  return the_owner;\n+JavaThread *Threads::owning_thread_from_monitor(ThreadsList * t_list,\n+                                                ObjectMonitor* monitor) {\n+  if (monitor->is_owner_anonymous()) {\n+    return owning_thread_impl(t_list, monitor->object());\n+  } else {\n+    \/\/ TODO: owner could return Thread* or even JavaThread* already.\n+    Thread* owner = reinterpret_cast<Thread*>(monitor->owner());\n+    \/\/ NULL owner means not locked.\n+    if (owner == NULL) return NULL;\n+    assert(owner->is_Java_thread(), \"only JavaThreads own monitors\");\n+    return reinterpret_cast<JavaThread*>(owner);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":31,"deletions":27,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -136,2 +136,5 @@\n-  static JavaThread *owning_thread_from_monitor_owner(ThreadsList * t_list,\n-                                                      address owner);\n+private:\n+  static JavaThread* owning_thread_impl(ThreadsList * t_list, oop obj);\n+public:\n+  static JavaThread* owning_thread_from_object(ThreadsList * t_list, oop obj, ObjectMonitor** monitor_out);\n+  static JavaThread* owning_thread_from_monitor(ThreadsList * t_list, ObjectMonitor* owner);\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -274,7 +275,11 @@\n-          if (mark.has_monitor() &&\n-              ( \/\/ we have marked ourself as pending on this monitor\n-                mark.monitor() == thread()->current_pending_monitor() ||\n-                \/\/ we are not the owner of this monitor\n-                !mark.monitor()->is_entered(thread())\n-              )) {\n-            lock_state = \"waiting to lock\";\n+          if (mark.has_monitor()) {\n+            if (mark.monitor()->is_owner_anonymous()) {\n+              if (!thread()->lock_stack().contains(monitor->owner())) {\n+                lock_state = \"waiting to lock\";\n+              }\n+            } else if (\/\/ we have marked ourself as pending on this monitor\n+                    mark.monitor() == thread()->current_pending_monitor() ||\n+                    \/\/ we are not the owner of this monitor\n+                    !mark.monitor()->is_entered(thread())) {\n+              lock_state = \"waiting to lock\";\n+            }\n@@ -315,1 +320,1 @@\n-      result->push(new MonitorInfo(current->obj(), current->lock(), false, false));\n+      result->push(new MonitorInfo(current->obj(), false, false));\n@@ -508,1 +513,1 @@\n-MonitorInfo::MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced) {\n+MonitorInfo::MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced) {\n@@ -518,1 +523,0 @@\n-  _lock = lock;\n@@ -745,3 +749,0 @@\n-    tty->print(\"\\t  \");\n-    monitor->lock()->print_on(tty, monitor->owner());\n-    tty->cr();\n","filename":"src\/hotspot\/share\/runtime\/vframe.cpp","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -53,2 +53,0 @@\n-\/\/ - BasicLock\n-\n@@ -258,1 +256,0 @@\n-  BasicLock* _lock;\n@@ -264,1 +261,1 @@\n-  MonitorInfo(oop owner, BasicLock* lock, bool eliminated, bool owner_is_scalar_replaced);\n+  MonitorInfo(oop owner, bool eliminated, bool owner_is_scalar_replaced);\n@@ -274,1 +271,0 @@\n-  BasicLock* lock()  const { return _lock;  }\n","filename":"src\/hotspot\/share\/runtime\/vframe.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-      \/\/ Migrate the BasicLocks from the stack to the monitor chunk\n+      \/\/ Migrate the BasicObjectLocks from the stack to the monitor chunk\n@@ -100,1 +100,0 @@\n-          monitor->lock()->move_to(monitor->owner(), dest->lock());\n@@ -311,1 +310,0 @@\n-    src->lock()->move_to(src->obj(), top->lock());\n","filename":"src\/hotspot\/share\/runtime\/vframeArray.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -237,4 +237,0 @@\n-BasicLock* compiledVFrame::resolve_monitor_lock(Location location) const {\n-  return StackValue::resolve_monitor_lock(&_fr, location);\n-}\n-\n@@ -257,1 +253,1 @@\n-        fr.get_native_receiver(), fr.get_native_monitor(), false, false);\n+        fr.get_native_receiver(), false, false);\n@@ -277,2 +273,1 @@\n-      result->push(new MonitorInfo(k(), resolve_monitor_lock(mv->basic_lock()),\n-                                   mv->eliminated(), true));\n+      result->push(new MonitorInfo(k(), mv->eliminated(), true));\n@@ -280,2 +275,1 @@\n-      result->push(new MonitorInfo(owner_sv->get_obj()(), resolve_monitor_lock(mv->basic_lock()),\n-                                   mv->eliminated(), false));\n+      result->push(new MonitorInfo(owner_sv->get_obj()(), mv->eliminated(), false));\n@@ -515,2 +509,1 @@\n-      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->lock(),\n-                                              info->eliminated(), false);\n+      MonitorInfo* new_info = new MonitorInfo((oopDesc*)val->value().l, info->eliminated(), false);\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.cpp","additions":4,"deletions":11,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -96,1 +96,0 @@\n-  BasicLock* resolve_monitor_lock(Location location) const;\n","filename":"src\/hotspot\/share\/runtime\/vframe_hp.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -711,0 +711,3 @@\n+  nonstatic_field(Thread,                      _lock_stack,                                   LockStack)                             \\\n+  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n+  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n@@ -858,1 +861,0 @@\n-  volatile_nonstatic_field(BasicLock,          _displaced_header,                             markWord)                              \\\n@@ -862,1 +864,0 @@\n-  nonstatic_field(BasicObjectLock,             _lock,                                         BasicLock)                             \\\n@@ -1326,0 +1327,1 @@\n+  declare_toplevel_type(LockStack)                                        \\\n@@ -1444,1 +1446,0 @@\n-  declare_toplevel_type(BasicLock)                                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -458,4 +458,2 @@\n-        address currentOwner = (address)waitingToLockMonitor->owner();\n-        if (currentOwner != NULL) {\n-          currentThread = Threads::owning_thread_from_monitor_owner(t_list,\n-                                                                    currentOwner);\n+        if (waitingToLockMonitor->is_owner_anonymous() || waitingToLockMonitor->owner() != NULL) {\n+          currentThread = Threads::owning_thread_from_monitor(t_list, waitingToLockMonitor);\n@@ -1055,2 +1053,1 @@\n-      currentThread = Threads::owning_thread_from_monitor_owner(t_list,\n-                                                                (address)waitingToLockMonitor->owner());\n+      currentThread = Threads::owning_thread_from_monitor(t_list, waitingToLockMonitor);\n","filename":"src\/hotspot\/share\/services\/threadService.cpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -151,6 +151,0 @@\n-  public BasicLock locker() {\n-    if (Assert.ASSERTS_ENABLED) {\n-      Assert.that(hasLocker(), \"check\");\n-    }\n-    return new BasicLock(valueAsAddress());\n-  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1,58 +0,0 @@\n-\/*\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-package sun.jvm.hotspot.runtime;\n-\n-import java.util.*;\n-\n-import sun.jvm.hotspot.debugger.*;\n-import sun.jvm.hotspot.oops.*;\n-import sun.jvm.hotspot.types.*;\n-import sun.jvm.hotspot.utilities.Observable;\n-import sun.jvm.hotspot.utilities.Observer;\n-\n-public class BasicLock extends VMObject {\n-  static {\n-    VM.registerVMInitializedObserver(new Observer() {\n-        public void update(Observable o, Object data) {\n-          initialize(VM.getVM().getTypeDataBase());\n-        }\n-      });\n-  }\n-\n-  private static synchronized void initialize(TypeDataBase db) throws WrongTypeException {\n-    Type type  = db.lookupType(\"BasicLock\");\n-    displacedHeaderField = type.getCIntegerField(\"_displaced_header\");\n-  }\n-\n-  private static CIntegerField displacedHeaderField;\n-\n-  public BasicLock(Address addr) {\n-    super(addr);\n-  }\n-\n-  public Mark displacedHeader() {\n-    return new Mark(addr.addOffsetTo(displacedHeaderField.getOffset()));\n-  }\n-}\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicLock.java","additions":0,"deletions":58,"binary":false,"changes":58,"status":"deleted"},{"patch":"@@ -45,1 +45,0 @@\n-    lockField  = type.getField(\"_lock\");\n@@ -50,1 +49,0 @@\n-  private static sun.jvm.hotspot.types.Field    lockField;\n@@ -59,1 +57,0 @@\n-  public BasicLock lock() { return new BasicLock(addr.addOffsetTo(lockField.getOffset())); }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/BasicObjectLock.java","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-        result.add(new MonitorInfo(k, resolveMonitorLock(mv.basicLock()), mv.eliminated(), true));\n+        result.add(new MonitorInfo(k, mv.eliminated(), true));\n@@ -150,1 +150,1 @@\n-        result.add(new MonitorInfo(ownerSV.getObject(), resolveMonitorLock(mv.basicLock()), mv.eliminated(), false));\n+        result.add(new MonitorInfo(ownerSV.getObject(), mv.eliminated(), false));\n@@ -313,16 +313,0 @@\n-\n-  private BasicLock resolveMonitorLock(Location location) {\n-    if (Assert.ASSERTS_ENABLED) {\n-      Assert.that(location.isStack(), \"for now we only look at the stack\");\n-    }\n-    int byteOffset = location.getStackOffset();\n-    \/\/ (stack picture)\n-    \/\/ high: [     ]  byte_offset + wordSize\n-    \/\/ low   [     ]  byte_offset\n-    \/\/\n-    \/\/ sp->  [     ]  0\n-    \/\/ the byte_offset is the distance from the stack pointer to the lowest address\n-    \/\/ The frame's original stack pointer, before any extension by its callee\n-    \/\/ (due to Compiler1 linkage on SPARC), must be used.\n-    return new BasicLock(getFrame().getUnextendedSP().addOffsetTo(byteOffset));\n-  }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/CompiledVFrame.java","additions":2,"deletions":18,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-      result.add(new MonitorInfo(current.obj(), current.lock(), false, false));\n+      result.add(new MonitorInfo(current.obj(), false, false));\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/InterpretedVFrame.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -397,9 +397,0 @@\n-  public boolean isLockOwned(Address a) {\n-    Address stackBase = getStackBase();\n-    Address stackLimit = stackBase.addOffsetTo(-getStackSize());\n-\n-    return stackBase.greaterThan(a) && stackLimit.lessThanOrEqual(a);\n-\n-    \/\/ FIXME: should traverse MonitorArray\/MonitorChunks as in VM\n-  }\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+          mark.monitor().isOwnedAnonymous() ||\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaVFrame.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-  private BasicLock lock;\n@@ -37,1 +36,1 @@\n-  public MonitorInfo(OopHandle owner, BasicLock lock, boolean eliminated, boolean ownerIsScalarReplaced) {\n+  public MonitorInfo(OopHandle owner, boolean eliminated, boolean ownerIsScalarReplaced) {\n@@ -60,1 +59,0 @@\n-  public BasicLock lock()  { return lock; }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/MonitorInfo.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -75,2 +75,2 @@\n-    if (current.threadObjectAddress().equals(o) ||\n-        current.isLockOwned(o)) {\n+    if (o.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n+    if (current.threadObjectAddress().equals(o)) {\n@@ -82,1 +82,10 @@\n-  public Address owner() { return addr.getAddressAt(ownerFieldOffset); }\n+  public boolean isOwnedAnonymous() {\n+    return addr.getAddressAt(ownerFieldOffset).asLongValue() == 1;\n+  }\n+\n+  public Address owner() {\n+    Address owner = addr.getAddressAt(ownerFieldOffset);\n+    if (owner.asLongValue() == 1) throw new InternalError(\"Check anonymous owner before calling isEntered()\");\n+    return owner;\n+  }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -36,0 +36,3 @@\n+  private static long lockStackCurrentOffset;\n+  private static long lockStackBaseOffset;\n+\n@@ -43,0 +46,2 @@\n+  private static long oopPtrSize;\n+\n@@ -54,0 +59,1 @@\n+    Type typeLockStack = db.lookupType(\"LockStack\");\n@@ -61,0 +67,4 @@\n+\n+    lockStackCurrentOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_current\").getOffset();\n+    lockStackBaseOffset = typeThread.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base\").getOffset();\n+    oopPtrSize = VM.getVM().getAddressSize();\n@@ -111,2 +121,10 @@\n-  public boolean isLockOwned(Address lock) {\n-    if (isInStack(lock)) return true;\n+  public boolean isLockOwned(OopHandle obj) {\n+    Address current = addr.getAddressAt(lockStackCurrentOffset);\n+    Address base = addr.getAddressAt(lockStackBaseOffset);\n+    while (base.lessThan(current)) {\n+        Address oop = base.getAddressAt(0);\n+        if (oop.equals(obj)) {\n+            return true;\n+        }\n+        base = base.addOffsetTo(oopPtrSize);\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Thread.java","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -213,1 +213,12 @@\n-    public JavaThread owningThreadFromMonitor(Address o) {\n+    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n+        if (monitor.isOwnedAnonymous()) {\n+            OopHandle object = monitor.object();\n+            for (int i = 0; i < getNumberOfThreads(); i++) {\n+                JavaThread thread = getJavaThreadAt(i);\n+                if (thread.isLockOwned(object)) {\n+                    return thread;\n+                }\n+            }\n+            throw new InternalError(\"We should have found a thread that owns the anonymous lock\");\n+        }\n+        Address o = monitor.owner();\n@@ -221,6 +232,0 @@\n-\n-        for (int i = 0; i < getNumberOfThreads(); i++) {\n-            JavaThread thread = getJavaThreadAt(i);\n-            if (thread.isLockOwned(o))\n-                return thread;\n-        }\n@@ -230,4 +235,0 @@\n-    public JavaThread owningThreadFromMonitor(ObjectMonitor monitor) {\n-        return owningThreadFromMonitor(monitor.owner());\n-    }\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":12,"deletions":11,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -78,6 +78,0 @@\n-        if (!thread.getAddress().equals(owner)) {\n-          if (!thread.isLockOwned(owner)) {\n-            tty.println(\"    WARNING! _owner doesn't fall in \" + thread +\n-                        \"'s stack space\");\n-          }\n-        }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/ui\/MonitorCacheDumpPanel.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,60 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\/*\n+ * @test\n+ * @summary Check that monitorenter A; monitorenter B; monitorexit A; monitorexit B; works\n+ * @compile TestUnstructuredLocking.jasm\n+ * @run main\/othervm -Xint TestUnstructuredLocking\n+ *\/\n+\n+super public class TestUnstructuredLocking version 64:0 {\n+\n+    public static Method main:\"([Ljava\/lang\/String;)V\" stack 2 locals 4 {\n+        new class java\/lang\/Object;\n+        dup;\n+        invokespecial Method java\/lang\/Object.\"<init>\":\"()V\";\n+        astore_1;\n+        new class java\/lang\/Object;\n+        dup;\n+        invokespecial Method java\/lang\/Object.\"<init>\":\"()V\";\n+        astore_2;\n+        aload_1;\n+        monitorenter;\n+        aload_2;\n+        monitorenter;\n+        aload_1;\n+        monitorexit;\n+        \/\/ At this point, we should have exited monitor#1, but still hold monitor#2.\n+        \/\/ Attempt to call notify will inflate the monitor. If we blindly pop\n+        \/\/ the top monitor in the first monitorexit, then the lock-stack will\n+        \/\/ no longer have monitor#2 on it, and fail inflation.\n+        aload_2;\n+        invokevirtual Method java\/lang\/Object.notify:\"()V\";\n+        aload_2;\n+        monitorexit;\n+        return;\n+    }\n+\n+}\n","filename":"test\/hotspot\/jtreg\/runtime\/locking\/TestUnstructuredLocking.jasm","additions":60,"deletions":0,"binary":false,"changes":60,"status":"added"},{"patch":"@@ -41,1 +41,1 @@\n-        output.shouldContain(\"inflate(has_locker):\");\n+        output.shouldContain(\"inflate(locked):\");\n","filename":"test\/hotspot\/jtreg\/runtime\/logging\/MonitorInflationTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}