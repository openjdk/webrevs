{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"precompiled.hpp\"\n@@ -5294,1 +5293,3 @@\n-  assert(UseCompressedClassPointers, \"not using compressed class pointers\");\n+  assert(_klass_decode_mode != KlassDecodeNone, \"should be initialized\");\n+  return _klass_decode_mode;\n+}\n@@ -5297,3 +5298,5 @@\n-  if (_klass_decode_mode != KlassDecodeNone) {\n-    return _klass_decode_mode;\n-  }\n+MacroAssembler::KlassDecodeMode  MacroAssembler::klass_decode_mode(address base, int shift, const size_t range) {\n+  assert(UseCompressedClassPointers, \"not using compressed class pointers\");\n+\n+  \/\/ KlassDecodeMode shouldn't be set already.\n+  assert(_klass_decode_mode == KlassDecodeNone, \"set once\");\n@@ -5301,2 +5304,2 @@\n-  if (CompressedKlassPointers::base() == nullptr) {\n-    return (_klass_decode_mode = KlassDecodeZero);\n+  if (base == nullptr) {\n+    return KlassDecodeZero;\n@@ -5306,2 +5309,1 @@\n-        \/*is32*\/false, (uint64_t)CompressedKlassPointers::base())) {\n-    const size_t range = CompressedKlassPointers::klass_range_end() - CompressedKlassPointers::base();\n+        \/*is32*\/false, (uint64_t)base)) {\n@@ -5309,2 +5311,2 @@\n-    if (((uint64_t)CompressedKlassPointers::base() & range_mask) == 0) {\n-      return (_klass_decode_mode = KlassDecodeXor);\n+    if (((uint64_t)base & range_mask) == 0) {\n+      return KlassDecodeXor;\n@@ -5315,3 +5317,13 @@\n-    (uint64_t)CompressedKlassPointers::base() >> CompressedKlassPointers::shift();\n-  guarantee((shifted_base & 0xffff0000ffffffff) == 0,\n-            \"compressed class base bad alignment\");\n+    (uint64_t)base >> shift;\n+  if ((shifted_base & 0xffff0000ffffffff) == 0) {\n+    return KlassDecodeMovk;\n+  }\n+\n+  \/\/ No valid encoding.\n+  return KlassDecodeNone;\n+}\n+\n+\/\/ Check if one of the above decoding modes will work for given base, shift and range.\n+bool MacroAssembler::check_klass_decode_mode(address base, int shift, const size_t range) {\n+  return klass_decode_mode(base, shift, range) != KlassDecodeNone;\n+}\n@@ -5319,1 +5331,3 @@\n-  return (_klass_decode_mode = KlassDecodeMovk);\n+bool MacroAssembler::set_klass_decode_mode(address base, int shift, const size_t range) {\n+  _klass_decode_mode = klass_decode_mode(base, shift, range);\n+  return _klass_decode_mode != KlassDecodeNone;\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":30,"deletions":16,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1629,1 +1629,1 @@\n-            __ zero_extend(as_Register(Matcher::_regEncode[dst_lo]), as_Register(Matcher::_regEncode[src_lo]), 32);\n+            __ zext(as_Register(Matcher::_regEncode[dst_lo]), as_Register(Matcher::_regEncode[src_lo]), 32);\n@@ -1921,1 +1921,1 @@\n-      return UseZfh;\n+      return UseZfh || UseZfhmin;\n@@ -2367,1 +2367,1 @@\n-                                     nullptr, &miss);\n+                                     nullptr, &miss, \/*set_cond_codes*\/ true);\n@@ -4924,1 +4924,5 @@\n-    __ flw(as_FloatRegister($dst$$reg), $constantaddress($con));\n+      if (MacroAssembler::can_fp_imm_load($con$$constant)) {\n+        __ fli_s(as_FloatRegister($dst$$reg), $con$$constant);\n+      } else {\n+        __ flw(as_FloatRegister($dst$$reg), $constantaddress($con));\n+      }\n@@ -4954,1 +4958,5 @@\n-    __ fld(as_FloatRegister($dst$$reg), $constantaddress($con));\n+      if (MacroAssembler::can_dp_imm_load($con$$constant)) {\n+        __ fli_d(as_FloatRegister($dst$$reg), $con$$constant);\n+      } else {\n+        __ fld(as_FloatRegister($dst$$reg), $constantaddress($con));\n+      }\n@@ -6486,3 +6494,3 @@\n-    __ add(as_Register($dst$$reg),\n-           as_Register($src1$$reg),\n-           $src2$$constant);\n+    __ addi(as_Register($dst$$reg),\n+            as_Register($src1$$reg),\n+            $src2$$constant);\n@@ -6517,3 +6525,3 @@\n-    __ add(as_Register($dst$$reg),\n-           as_Register($src1$$reg),\n-           $src2$$constant);\n+    __ addi(as_Register($dst$$reg),\n+            as_Register($src1$$reg),\n+            $src2$$constant);\n@@ -6550,3 +6558,3 @@\n-    __ subw(as_Register($dst$$reg),\n-            as_Register($src1$$reg),\n-            $src2$$constant);\n+    __ subiw(as_Register($dst$$reg),\n+             as_Register($src1$$reg),\n+             $src2$$constant);\n@@ -6581,3 +6589,3 @@\n-    __ sub(as_Register($dst$$reg),\n-           as_Register($src1$$reg),\n-           $src2$$constant);\n+    __ subi(as_Register($dst$$reg),\n+            as_Register($src1$$reg),\n+            $src2$$constant);\n@@ -7352,1 +7360,1 @@\n-    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::fclass_mask::inf);\n+    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::FClassBits::inf);\n@@ -7367,1 +7375,1 @@\n-    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::fclass_mask::inf);\n+    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::FClassBits::inf);\n@@ -7382,1 +7390,1 @@\n-    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::fclass_mask::finite);\n+    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::FClassBits::finite);\n@@ -7397,1 +7405,1 @@\n-    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::fclass_mask::finite);\n+    __ andi(as_Register($dst$$reg), as_Register($dst$$reg), Assembler::FClassBits::finite);\n@@ -8083,1 +8091,1 @@\n-    __ sign_extend(as_Register($dst$$reg), as_Register($src$$reg), 32);\n+    __ sext(as_Register($dst$$reg), as_Register($src$$reg), 32);\n@@ -8095,1 +8103,1 @@\n-    __ sign_extend(as_Register($dst$$reg), as_Register($src$$reg), 32);\n+    __ sext(as_Register($dst$$reg), as_Register($src$$reg), 32);\n@@ -8107,1 +8115,1 @@\n-  format %{ \"zero_extend $dst, $src, 32\\t# i2ul, #@convI2UL_reg_reg\" %}\n+  format %{ \"zext $dst, $src, 32\\t# i2ul, #@convI2UL_reg_reg\" %}\n@@ -8110,1 +8118,1 @@\n-    __ zero_extend(as_Register($dst$$reg), as_Register($src$$reg), 32);\n+    __ zext(as_Register($dst$$reg), as_Register($src$$reg), 32);\n@@ -8287,1 +8295,1 @@\n-  format %{ \"zero_extend $dst, $src, 32\\t# ptr -> int, #@convP2I\" %}\n+  format %{ \"zext $dst, $src, 32\\t# ptr -> int, #@convP2I\" %}\n@@ -8290,1 +8298,1 @@\n-    __ zero_extend($dst$$Register, $src$$Register, 32);\n+    __ zext($dst$$Register, $src$$Register, 32);\n@@ -10023,0 +10031,1 @@\n+  predicate(!UseSecondarySupersTable);\n@@ -10026,1 +10035,1 @@\n-  ins_cost(11 * DEFAULT_COST);\n+  ins_cost(20 * DEFAULT_COST);\n@@ -10036,0 +10045,27 @@\n+\/\/ Two versions of partialSubtypeCheck, both used when we need to\n+\/\/ search for a super class in the secondary supers array. The first\n+\/\/ is used when we don't know _a priori_ the class being searched\n+\/\/ for. The second, far more common, is used when we do know: this is\n+\/\/ used for instanceof, checkcast, and any case where C2 can determine\n+\/\/ it by constant propagation.\n+\n+instruct partialSubtypeCheckVarSuper(iRegP_R14 sub, iRegP_R10 super, iRegP_R15 result,\n+                                     iRegP_R11 tmpR11, iRegP_R12 tmpR12, iRegP_R13 tmpR13,\n+                                     iRegP_R16 tmpR16, rFlagsReg cr)\n+%{\n+  predicate(UseSecondarySupersTable);\n+  match(Set result (PartialSubtypeCheck sub super));\n+  effect(TEMP tmpR11, TEMP tmpR12, TEMP tmpR13, TEMP tmpR16, KILL cr);\n+\n+  ins_cost(10 * DEFAULT_COST);  \/\/ slightly larger than the next version\n+  format %{ \"partialSubtypeCheck $result, $sub, $super\" %}\n+\n+  ins_encode %{\n+    __ lookup_secondary_supers_table_var($sub$$Register, $super$$Register, $result$$Register,\n+                                         $tmpR11$$Register, $tmpR12$$Register, $tmpR13$$Register,\n+                                         $tmpR16$$Register, nullptr \/*L_success*\/);\n+  %}\n+\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -10043,1 +10079,1 @@\n-  ins_cost(7 * DEFAULT_COST); \/\/ needs to be less than competing nodes\n+  ins_cost(5 * DEFAULT_COST); \/\/ needs to be less than competing nodes\n@@ -10050,3 +10086,3 @@\n-      success = __ lookup_secondary_supers_table($sub$$Register, $super_reg$$Register, $result$$Register,\n-                                                 $tmpR11$$Register, $tmpR12$$Register, $tmpR13$$Register,\n-                                                 $tmpR16$$Register, super_klass_slot);\n+      success = __ lookup_secondary_supers_table_const($sub$$Register, $super_reg$$Register, $result$$Register,\n+                                                       $tmpR11$$Register, $tmpR12$$Register, $tmpR13$$Register,\n+                                                       $tmpR16$$Register, super_klass_slot);\n@@ -10066,16 +10102,0 @@\n-instruct partialSubtypeCheckVsZero(iRegP_R15 result, iRegP_R14 sub, iRegP_R10 super, iRegP_R12 tmp,\n-                                   immP0 zero, rFlagsReg cr)\n-%{\n-  match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));\n-  effect(KILL tmp, KILL result);\n-\n-  ins_cost(11 * DEFAULT_COST);\n-  format %{ \"partialSubtypeCheck $result, $sub, $super == 0\\t#@partialSubtypeCheckVsZero\" %}\n-\n-  ins_encode(riscv_enc_partial_subtype_check(sub, super, tmp, result));\n-\n-  opcode(0x0); \/\/ Don't zero result reg on hit\n-\n-  ins_pipe(pipe_class_memory);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":68,"deletions":48,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -1197,1 +1196,5 @@\n-  if (reachable(src)) {\n+  if (UseAVX > 2 &&\n+      (!VM_Version::supports_avx512dq() || !VM_Version::supports_avx512vl()) &&\n+      (dst->encoding() >= 16)) {\n+    vpand(dst, dst, src, AVX_512bit, rscratch);\n+  } else if (reachable(src)) {\n@@ -3335,1 +3338,6 @@\n-  if (reachable(src)) {\n+\n+  if (UseAVX > 2 &&\n+      (!VM_Version::supports_avx512dq() || !VM_Version::supports_avx512vl()) &&\n+      (dst->encoding() >= 16)) {\n+    vpxor(dst, dst, src, Assembler::AVX_512bit, rscratch);\n+  } else if (reachable(src)) {\n@@ -3344,1 +3352,3 @@\n-  if (UseAVX > 2 && !VM_Version::supports_avx512dq() && (dst->encoding() == src->encoding())) {\n+  if (UseAVX > 2 &&\n+      (!VM_Version::supports_avx512dq() || !VM_Version::supports_avx512vl()) &&\n+      ((dst->encoding() >= 16) || (src->encoding() >= 16))) {\n@@ -3346,2 +3356,1 @@\n-  }\n-  else {\n+  } else {\n@@ -3353,1 +3362,3 @@\n-  if (UseAVX > 2 && !VM_Version::supports_avx512dq() && (dst->encoding() == src->encoding())) {\n+  if (UseAVX > 2 &&\n+      (!VM_Version::supports_avx512dq() || !VM_Version::supports_avx512vl()) &&\n+      ((dst->encoding() >= 16) || (src->encoding() >= 16))) {\n@@ -3365,1 +3376,6 @@\n-  if (reachable(src)) {\n+\n+  if (UseAVX > 2 &&\n+      (!VM_Version::supports_avx512dq() || !VM_Version::supports_avx512vl()) &&\n+      (dst->encoding() >= 16)) {\n+    vpxor(dst, dst, src, Assembler::AVX_512bit, rscratch);\n+  } else if (reachable(src)) {\n@@ -9123,2 +9139,2 @@\n-    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::_crc32c_table_addr;\n-    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::_crc32c_table_addr+1);\n+    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::crc32c_table_addr();\n+    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 1);\n@@ -9126,2 +9142,2 @@\n-    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 2);\n-    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 3);\n+    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 2);\n+    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 3);\n@@ -9129,2 +9145,2 @@\n-    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 4);\n-    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 5);\n+    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 4);\n+    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 5);\n@@ -9203,2 +9219,2 @@\n-    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::_crc32c_table_addr;\n-    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 1);\n+    const_or_pre_comp_const_index[1] = *(uint32_t *)StubRoutines::crc32c_table_addr();\n+    const_or_pre_comp_const_index[0] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 1);\n@@ -9206,2 +9222,2 @@\n-    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 2);\n-    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 3);\n+    const_or_pre_comp_const_index[3] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 2);\n+    const_or_pre_comp_const_index[2] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 3);\n@@ -9209,2 +9225,2 @@\n-    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 4);\n-    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::_crc32c_table_addr + 5);\n+    const_or_pre_comp_const_index[5] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 4);\n+    const_or_pre_comp_const_index[4] = *((uint32_t *)StubRoutines::crc32c_table_addr() + 5);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":37,"deletions":21,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,1 @@\n-#include \"precompiled.hpp\"\n+#include \"cds\/aotArtifactFinder.hpp\"\n@@ -50,0 +50,1 @@\n+#include \"memory\/memoryReserver.hpp\"\n@@ -155,2 +156,0 @@\n-  _last_verified_top(nullptr),\n-  _other_region_used_bytes(0),\n@@ -174,3 +173,1 @@\n-  _total_heap_region_size(0),\n-  _estimated_metaspaceobj_bytes(0),\n-  _estimated_hashtable_bytes(0)\n+  _total_heap_region_size(0)\n@@ -196,1 +193,1 @@\n-    _shared_rs.release();\n+    MemoryReserver::release(_shared_rs);\n@@ -198,0 +195,2 @@\n+\n+  AOTArtifactFinder::dispose();\n@@ -235,1 +234,0 @@\n-        assert(SystemDictionaryShared::should_hidden_class_be_archived(InstanceKlass::cast(klass)), \"must be\");\n@@ -238,4 +236,0 @@\n-    \/\/ See RunTimeClassInfo::get_for(): make sure we have enough space for both maximum\n-    \/\/ Klass alignment as well as the RuntimeInfo* pointer we will embed in front of a Klass.\n-    _estimated_metaspaceobj_bytes += align_up(BytesPerWord, CompressedKlassPointers::klass_alignment_in_bytes()) +\n-        align_up(sizeof(void*), SharedSpaceObjectAlignment);\n@@ -249,3 +243,0 @@\n-  int bytes = ref->size() * BytesPerWord;\n-  _estimated_metaspaceobj_bytes += align_up(bytes, SharedSpaceObjectAlignment);\n-\n@@ -257,0 +248,4 @@\n+\n+  AOTArtifactFinder::initialize();\n+  AOTArtifactFinder::find_artifacts();\n+\n@@ -290,4 +285,0 @@\n-\n-    \/\/ TODO -- we need a proper estimate for the archived modules, etc,\n-    \/\/ but this should be enough for now\n-    _estimated_metaspaceobj_bytes += 200 * 1024 * 1024;\n@@ -317,33 +308,4 @@\n-size_t ArchiveBuilder::estimate_archive_size() {\n-  \/\/ size of the symbol table and two dictionaries, plus the RunTimeClassInfo's\n-  size_t symbol_table_est = SymbolTable::estimate_size_for_archive();\n-  size_t dictionary_est = SystemDictionaryShared::estimate_size_for_archive();\n-  _estimated_hashtable_bytes = symbol_table_est + dictionary_est;\n-\n-  if (CDSConfig::is_dumping_aot_linked_classes()) {\n-    \/\/ This is difficult to estimate when dumping the dynamic archive, as the\n-    \/\/ AOTLinkedClassTable may need to contain classes in the static archive as well.\n-    \/\/\n-    \/\/ Just give a generous estimate for now. We will remove estimate_archive_size()\n-    \/\/ in JDK-8340416\n-    _estimated_hashtable_bytes += 20 * 1024 * 1024;\n-  }\n-\n-  size_t total = 0;\n-\n-  total += _estimated_metaspaceobj_bytes;\n-  total += _estimated_hashtable_bytes;\n-\n-  \/\/ allow fragmentation at the end of each dump region\n-  total += _total_dump_regions * MetaspaceShared::core_region_alignment();\n-\n-  log_info(cds)(\"_estimated_hashtable_bytes = \" SIZE_FORMAT \" + \" SIZE_FORMAT \" = \" SIZE_FORMAT,\n-                symbol_table_est, dictionary_est, _estimated_hashtable_bytes);\n-  log_info(cds)(\"_estimated_metaspaceobj_bytes = \" SIZE_FORMAT, _estimated_metaspaceobj_bytes);\n-  log_info(cds)(\"total estimate bytes = \" SIZE_FORMAT, total);\n-\n-  return align_up(total, MetaspaceShared::core_region_alignment());\n-}\n-\n-  size_t buffer_size = estimate_archive_size();\n-  ReservedSpace rs(buffer_size, MetaspaceShared::core_region_alignment(), os::vm_page_size());\n+  size_t buffer_size = LP64_ONLY(CompressedClassSpaceSize) NOT_LP64(256 * M);\n+  ReservedSpace rs = MemoryReserver::reserve(buffer_size,\n+                                             MetaspaceShared::core_region_alignment(),\n+                                             os::vm_page_size());\n@@ -352,1 +314,1 @@\n-    log_error(cds)(\"Failed to reserve \" SIZE_FORMAT \" bytes of output buffer.\", buffer_size);\n+    log_error(cds)(\"Failed to reserve %zu bytes of output buffer.\", buffer_size);\n@@ -359,1 +321,1 @@\n-  log_info(cds)(\"Reserved output buffer space at \" PTR_FORMAT \" [\" SIZE_FORMAT \" bytes]\",\n+  log_info(cds)(\"Reserved output buffer space at \" PTR_FORMAT \" [%zu bytes]\",\n@@ -364,1 +326,0 @@\n-  _last_verified_top = buffer_bottom;\n@@ -367,1 +328,0 @@\n-  _other_region_used_bytes = 0;\n@@ -586,4 +546,0 @@\n-  address bottom = _last_verified_top;\n-  address top = (address)(current_dump_region()->top());\n-  _other_region_used_bytes += size_t(top - bottom);\n-\n@@ -593,15 +549,0 @@\n-\n-  _last_verified_top = (address)(current_dump_region()->top());\n-}\n-\n-void ArchiveBuilder::verify_estimate_size(size_t estimate, const char* which) {\n-  address bottom = _last_verified_top;\n-  address top = (address)(current_dump_region()->top());\n-  size_t used = size_t(top - bottom) + _other_region_used_bytes;\n-  int diff = int(estimate) - int(used);\n-\n-  log_info(cds)(\"%s estimate = \" SIZE_FORMAT \" used = \" SIZE_FORMAT \"; diff = %d bytes\", which, estimate, used, diff);\n-  assert(diff >= 0, \"Estimate is too small\");\n-\n-  _last_verified_top = top;\n-  _other_region_used_bytes = 0;\n@@ -1245,1 +1186,1 @@\n-      log_debug(cds, map)(PTR_FORMAT \": @@ Misc data \" SIZE_FORMAT \" bytes\",\n+      log_debug(cds, map)(PTR_FORMAT \": @@ Misc data %zu bytes\",\n@@ -1265,1 +1206,1 @@\n-    log_info(cds, map)(\"[%-18s \" PTR_FORMAT \" - \" PTR_FORMAT \" \" SIZE_FORMAT_W(9) \" bytes]\",\n+    log_info(cds, map)(\"[%-18s \" PTR_FORMAT \" - \" PTR_FORMAT \" %9zu bytes]\",\n@@ -1308,1 +1249,1 @@\n-        st.print_cr(\"filler \" SIZE_FORMAT \" bytes\", byte_size);\n+        st.print_cr(\"filler %zu bytes\", byte_size);\n@@ -1411,1 +1352,1 @@\n-        st.print_cr(\" - fields (\" SIZE_FORMAT \" words):\", source_oop->size());\n+        st.print_cr(\" - fields (%zu words):\", source_oop->size());\n@@ -1636,1 +1577,1 @@\n-  log_debug(cds)(\"total   : \" SIZE_FORMAT_W(9) \" [100.0%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [%5.1f%% used]\",\n+  log_debug(cds)(\"total   : %9zu [100.0%% of total] out of %9zu bytes [%5.1f%% used]\",\n@@ -1641,1 +1582,1 @@\n-  log_debug(cds)(\"bm space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used]\",\n+  log_debug(cds)(\"bm space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used]\",\n@@ -1649,1 +1590,1 @@\n-  log_debug(cds)(\"hp space: \" SIZE_FORMAT_W(9) \" [ %4.1f%% of total] out of \" SIZE_FORMAT_W(9) \" bytes [100.0%% used] at \" INTPTR_FORMAT,\n+  log_debug(cds)(\"hp space: %9zu [ %4.1f%% of total] out of %9zu bytes [100.0%% used] at \" INTPTR_FORMAT,\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":24,"deletions":83,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -31,0 +30,1 @@\n+#include \"classfile\/modules.hpp\"\n@@ -81,1 +81,1 @@\n-  if (HeapShared::can_write()) {\n+  if (CDSConfig::is_dumping_heap()) {\n@@ -102,1 +102,1 @@\n-  assert(HeapShared::can_write(), \"sanity\");\n+  assert(CDSConfig::is_dumping_heap(), \"sanity\");\n@@ -220,1 +220,1 @@\n-         \"Pre-condition: Roots start at aligned boundary: \" SIZE_FORMAT, _buffer_used);\n+         \"Pre-condition: Roots start at aligned boundary: %zu\", _buffer_used);\n@@ -241,1 +241,1 @@\n-           \"Roots segment \" SIZE_FORMAT \" start is not aligned: \" SIZE_FORMAT,\n+           \"Roots segment %zu start is not aligned: %zu\",\n@@ -249,1 +249,1 @@\n-    log_info(cds, heap)(\"archived obj root segment [%d] = \" SIZE_FORMAT \" bytes, obj = \" PTR_FORMAT,\n+    log_info(cds, heap)(\"archived obj root segment [%d] = %zu bytes, obj = \" PTR_FORMAT,\n@@ -326,0 +326,4 @@\n+\n+    if (java_lang_Module::is_instance(src_obj)) {\n+      Modules::check_archived_module_oop(src_obj);\n+    }\n@@ -328,1 +332,1 @@\n-  log_info(cds)(\"Size of heap region = \" SIZE_FORMAT \" bytes, %d objects, %d roots, %d native ptrs\",\n+  log_info(cds)(\"Size of heap region = %zu bytes, %d objects, %d roots, %d native ptrs\",\n@@ -394,1 +398,1 @@\n-    log_info(cds, heap)(\"Inserting filler obj array of %d elements (\" SIZE_FORMAT \" bytes total) @ buffer offset \" SIZE_FORMAT,\n+    log_info(cds, heap)(\"Inserting filler obj array of %d elements (%zu bytes total) @ buffer offset %zu\",\n@@ -633,1 +637,1 @@\n-  log_info(cds)(\"%s = \" SIZE_FORMAT_W(7) \" ... \" SIZE_FORMAT_W(7) \" (%3zu%% ... %3zu%% = %3zu%%)\", which,\n+  log_info(cds)(\"%s = %7zu ... %7zu (%3zu%% ... %3zu%% = %3zu%%)\", which,\n@@ -760,1 +764,1 @@\n-  log_info(cds, heap)(\"calculate_ptrmap: marked %d non-null native pointers for heap region (\" SIZE_FORMAT \" bits)\",\n+  log_info(cds, heap)(\"calculate_ptrmap: marked %d non-null native pointers for heap region (%zu bits)\",\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.cpp","additions":15,"deletions":11,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,1 @@\n-#include \"precompiled.hpp\"\n+#include \"cds\/aotArtifactFinder.hpp\"\n@@ -89,1 +89,0 @@\n-bool HeapShared::_disable_writing = false;\n@@ -223,1 +222,3 @@\n-\n+  if (obj != nullptr) {\n+    assert(has_been_archived(obj), \"must be\");\n+  }\n@@ -237,3 +238,0 @@\n-    if (!HeapShared::can_write()) {\n-      return nullptr;\n-    }\n@@ -293,1 +291,1 @@\n-bool HeapShared::archive_object(oop obj) {\n+bool HeapShared::archive_object(oop obj, KlassSubGraphInfo* subgraph_info) {\n@@ -302,1 +300,1 @@\n-    log_debug(cds, heap)(\"Cannot archive, object (\" PTR_FORMAT \") is too large: \" SIZE_FORMAT,\n+    log_debug(cds, heap)(\"Cannot archive, object (\" PTR_FORMAT \") is too large: %zu\",\n@@ -314,0 +312,30 @@\n+    Klass* k = obj->klass();\n+    if (k->is_instance_klass()) {\n+      \/\/ Whenever we see a non-array Java object of type X, we mark X to be aot-initialized.\n+      \/\/ This ensures that during the production run, whenever Java code sees a cached object\n+      \/\/ of type X, we know that X is already initialized. (see TODO comment below ...)\n+\n+      if (InstanceKlass::cast(k)->is_enum_subclass()\n+          \/\/ We can't rerun <clinit> of enum classes (see cdsEnumKlass.cpp) so\n+          \/\/ we must store them as AOT-initialized.\n+          || (subgraph_info == _dump_time_special_subgraph))\n+          \/\/ TODO: we do this only for the special subgraph for now. Extending this to\n+          \/\/ other subgraphs would require more refactoring of the core library (such as\n+          \/\/ move some initialization logic into runtimeSetup()).\n+          \/\/\n+          \/\/ For the other subgraphs, we have a weaker mechanism to ensure that\n+          \/\/ all classes in a subgraph are initialized before the subgraph is programmatically\n+          \/\/ returned from jdk.internal.misc.CDS::initializeFromArchive().\n+          \/\/ See HeapShared::initialize_from_archived_subgraph().\n+      {\n+        AOTArtifactFinder::add_aot_inited_class(InstanceKlass::cast(k));\n+      }\n+\n+      if (java_lang_Class::is_instance(obj)) {\n+        Klass* mirror_k = java_lang_Class::as_Klass(obj);\n+        if (mirror_k != nullptr) {\n+          AOTArtifactFinder::add_cached_class(mirror_k);\n+        }\n+      }\n+    }\n+\n@@ -331,4 +359,0 @@\n-    if (java_lang_Module::is_instance(obj) && Modules::check_archived_module_oop(obj)) {\n-      Modules::update_oops_in_archived_module(obj, append_root(obj));\n-    }\n-\n@@ -370,1 +394,3 @@\n-  _scratch_references_table->set_oop(src, dest);\n+  if (SystemDictionaryShared::is_builtin_loader(src->pool_holder()->class_loader_data())) {\n+    _scratch_references_table->set_oop(src, dest);\n+  }\n@@ -469,4 +495,8 @@\n-void HeapShared::copy_aot_initialized_mirror(Klass* orig_k, oop orig_mirror, oop m) {\n-  assert(orig_k->is_instance_klass(), \"sanity\");\n-  InstanceKlass* ik = InstanceKlass::cast(orig_k);\n-  InstanceKlass* buffered_ik = ArchiveBuilder::current()->get_buffered_addr(ik);\n+void HeapShared::copy_and_rescan_aot_inited_mirror(InstanceKlass* ik) {\n+  ik->set_has_aot_initialized_mirror();\n+  if (AOTClassInitializer::is_runtime_setup_required(ik)) {\n+    ik->set_is_runtime_setup_required();\n+  }\n+\n+  oop orig_mirror = ik->java_mirror();\n+  oop m = scratch_java_mirror(ik);\n@@ -484,1 +514,13 @@\n-        m->obj_field_put(offset, orig_mirror->obj_field(offset));\n+        {\n+          oop field_obj = orig_mirror->obj_field(offset);\n+          if (offset == java_lang_Class::reflection_data_offset()) {\n+            \/\/ Class::reflectData use SoftReference, which cannot be archived. Set it\n+            \/\/ to null and it will be recreated at runtime.\n+            field_obj = nullptr;\n+          }\n+          m->obj_field_put(offset, field_obj);\n+          if (field_obj != nullptr) {\n+            bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, field_obj);\n+            assert(success, \"sanity\");\n+          }\n+        }\n@@ -517,5 +559,6 @@\n-  java_lang_Class::set_class_data(m, java_lang_Class::class_data(orig_mirror));\n-\n-  \/\/ Class::reflectData use SoftReference, which cannot be archived. Set it\n-  \/\/ to null and it will be recreated at runtime.\n-  java_lang_Class::set_reflection_data(m, nullptr);\n+  oop class_data = java_lang_Class::class_data(orig_mirror);\n+  java_lang_Class::set_class_data(m, class_data);\n+  if (class_data != nullptr) {\n+    bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, class_data);\n+    assert(success, \"sanity\");\n+  }\n@@ -525,2 +568,3 @@\n-    log_debug(cds, init)(\"copied %3d field(s) in aot-initialized mirror %s%s\", nfields, ik->external_name(),\n-                         ik->is_hidden() ? \" (hidden)\" : \"\");\n+    log_debug(cds, init)(\"copied %3d field(s) in aot-initialized mirror %s%s%s\", nfields, ik->external_name(),\n+                         ik->is_hidden() ? \" (hidden)\" : \"\",\n+                         ik->is_enum_subclass() ? \" (enum)\" : \"\");\n@@ -565,4 +609,1 @@\n-  InstanceKlass* buffered_ik = ArchiveBuilder::current()->get_buffered_addr(src_ik);\n-  if (buffered_ik->is_shared_boot_class() ||\n-      buffered_ik->is_shared_platform_class() ||\n-      buffered_ik->is_shared_app_class()) {\n+  if (SystemDictionaryShared::is_builtin_loader(src_ik->class_loader_data())) {\n@@ -577,61 +618,1 @@\n-void HeapShared::archive_java_mirrors() {\n-  for (int i = T_BOOLEAN; i < T_VOID+1; i++) {\n-    BasicType bt = (BasicType)i;\n-    if (!is_reference_type(bt)) {\n-      oop orig_mirror = Universe::java_mirror(bt);\n-      oop m = _scratch_basic_type_mirrors[i].resolve();\n-      assert(m != nullptr, \"sanity\");\n-      copy_java_mirror_hashcode(orig_mirror, m);\n-      bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, m);\n-      assert(success, \"sanity\");\n-\n-      log_trace(cds, heap, mirror)(\n-        \"Archived %s mirror object from \" PTR_FORMAT,\n-        type2name(bt), p2i(m));\n-\n-      Universe::set_archived_basic_type_mirror_index(bt, append_root(m));\n-    }\n-  }\n-\n-  GrowableArray<Klass*>* klasses = ArchiveBuilder::current()->klasses();\n-  assert(klasses != nullptr, \"sanity\");\n-\n-  for (int i = 0; i < klasses->length(); i++) {\n-    Klass* orig_k = klasses->at(i);\n-    oop orig_mirror = orig_k->java_mirror();\n-    oop m = scratch_java_mirror(orig_k);\n-    if (m != nullptr) {\n-      copy_java_mirror_hashcode(orig_mirror, m);\n-    }\n-  }\n-\n-  for (int i = 0; i < klasses->length(); i++) {\n-    Klass* orig_k = klasses->at(i);\n-    oop orig_mirror = orig_k->java_mirror();\n-    oop m = scratch_java_mirror(orig_k);\n-    if (m != nullptr) {\n-      Klass* buffered_k = ArchiveBuilder::get_buffered_klass(orig_k);\n-      bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, m);\n-      guarantee(success, \"scratch mirrors must point to only archivable objects\");\n-      buffered_k->set_archived_java_mirror(append_root(m));\n-      ResourceMark rm;\n-      log_trace(cds, heap, mirror)(\n-        \"Archived %s mirror object from \" PTR_FORMAT,\n-        buffered_k->external_name(), p2i(m));\n-\n-      \/\/ archive the resolved_referenes array\n-      if (buffered_k->is_instance_klass()) {\n-        InstanceKlass* ik = InstanceKlass::cast(buffered_k);\n-        objArrayOop rr = get_archived_resolved_references(InstanceKlass::cast(orig_k));\n-        if (rr != nullptr) {\n-          bool success = HeapShared::archive_reachable_objects_from(1, _dump_time_special_subgraph, rr);\n-          assert(success, \"must be\");\n-          int root_index = append_root(rr);\n-          ik->constants()->cache()->set_archived_references(root_index);\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-  oop shared_strings_array = StringTable::init_shared_table(_dumped_interned_strings);\n+  oop shared_strings_array = StringTable::init_shared_strings_array(_dumped_interned_strings);\n@@ -675,109 +656,3 @@\n-void HeapShared::start_finding_required_hidden_classes() {\n-  if (!CDSConfig::is_dumping_invokedynamic()) {\n-    return;\n-  }\n-  NoSafepointVerifier nsv;\n-\n-  init_seen_objects_table();\n-\n-  \/\/ We first scan the objects that are known to be archived (from the archive_subgraph\n-  \/\/ tables)\n-  find_required_hidden_classes_helper(archive_subgraph_entry_fields);\n-  if (CDSConfig::is_dumping_full_module_graph()) {\n-    find_required_hidden_classes_helper(fmg_archive_subgraph_entry_fields);\n-  }\n-\n-  \/\/ Later, SystemDictionaryShared::find_all_archivable_classes_impl() will start\n-  \/\/ scanning the constant pools of all classes that it decides to archive.\n-}\n-\n-void HeapShared::end_finding_required_hidden_classes() {\n-  if (!CDSConfig::is_dumping_invokedynamic()) {\n-    return;\n-  }\n-  NoSafepointVerifier nsv;\n-\n-  delete_seen_objects_table();\n-}\n-\n-void HeapShared::find_required_hidden_classes_helper(ArchivableStaticFieldInfo fields[]) {\n-  if (!CDSConfig::is_dumping_heap()) {\n-    return;\n-  }\n-  for (int i = 0; fields[i].valid(); i++) {\n-    ArchivableStaticFieldInfo* f = &fields[i];\n-    InstanceKlass* k = f->klass;\n-    oop m = k->java_mirror();\n-    oop o = m->obj_field(f->offset);\n-    if (o != nullptr) {\n-      find_required_hidden_classes_in_object(o);\n-    }\n-  }\n-}\n-\n-class HeapShared::FindRequiredHiddenClassesOopClosure: public BasicOopIterateClosure {\n-  GrowableArray<oop> _stack;\n-  template <class T> void do_oop_work(T *p) {\n-    \/\/ Recurse on a GrowableArray to avoid overflowing the C stack.\n-    oop o = RawAccess<>::oop_load(p);\n-    if (o != nullptr) {\n-      _stack.append(o);\n-    }\n-  }\n-\n- public:\n-\n-  void do_oop(narrowOop *p) { FindRequiredHiddenClassesOopClosure::do_oop_work(p); }\n-  void do_oop(      oop *p) { FindRequiredHiddenClassesOopClosure::do_oop_work(p); }\n-\n-  FindRequiredHiddenClassesOopClosure(oop o) {\n-    _stack.append(o);\n-  }\n-  oop pop() {\n-    if (_stack.length() == 0) {\n-      return nullptr;\n-    } else {\n-      return _stack.pop();\n-    }\n-  }\n-};\n-\n-static void mark_required_if_hidden_class(Klass* k) {\n-  if (k != nullptr && k->is_instance_klass()) {\n-    InstanceKlass* ik = InstanceKlass::cast(k);\n-    if (ik->is_hidden()) {\n-      SystemDictionaryShared::mark_required_hidden_class(ik);\n-    }\n-  }\n-}\n-\n-\n-void HeapShared::find_required_hidden_classes_in_object(oop root) {\n-  ResourceMark rm;\n-  FindRequiredHiddenClassesOopClosure c(root);\n-  oop o;\n-  while ((o = c.pop()) != nullptr) {\n-    if (!has_been_seen_during_subgraph_recording(o)) {\n-      set_has_been_seen_during_subgraph_recording(o);\n-\n-      \/\/ Mark the klass of this object\n-      mark_required_if_hidden_class(o->klass());\n-\n-      \/\/ For special objects, mark the klass that they contain information about.\n-      \/\/ - a Class that refers to an hidden class\n-      \/\/ - a ResolvedMethodName that refers to a method declared in a hidden class\n-      if (java_lang_Class::is_instance(o)) {\n-        mark_required_if_hidden_class(java_lang_Class::as_Klass(o));\n-      } else if (java_lang_invoke_ResolvedMethodName::is_instance(o)) {\n-        Method* m = java_lang_invoke_ResolvedMethodName::vmtarget(o);\n-        if (m != nullptr) {\n-          mark_required_if_hidden_class(m->method_holder());\n-        }\n-      }\n-\n-      o->oop_iterate(&c);\n-    }\n-  }\n-}\n-\n-void HeapShared::archive_objects(ArchiveHeapInfo *heap_info) {\n+\/\/ Between start_scanning_for_oops() and end_scanning_for_oops(), we discover all Java heap objects that\n+\/\/ should be stored in the AOT cache. The scanning is coordinated by AOTArtifactFinder.\n+void HeapShared::start_scanning_for_oops() {\n@@ -801,3 +676,1 @@\n-    copy_objects();\n-    CDSHeapVerifier::verify();\n-    check_special_subgraph_classes();\n+    archive_subgraphs();\n@@ -807,17 +680,1 @@\n-  ArchiveHeapWriter::write(_pending_roots, heap_info);\n-}\n-\n-void HeapShared::copy_interned_strings() {\n-\n-  auto copier = [&] (oop s, bool value_ignored) {\n-    assert(s != nullptr, \"sanity\");\n-    assert(!ArchiveHeapWriter::is_string_too_large_to_archive(s), \"large strings must have been filtered\");\n-    bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, s);\n-    assert(success, \"must be\");\n-    \/\/ Prevent string deduplication from changing the value field to\n-    \/\/ something not in the archive.\n-    java_lang_String::set_deduplication_forbidden(s);\n-  };\n-  _dumped_interned_strings->iterate_all(copier);\n-\n-  delete_seen_objects_table();\n+  Universe::archive_exception_instances();\n@@ -827,9 +684,2 @@\n-void HeapShared::copy_special_subgraph() {\n-  copy_interned_strings();\n-\n-  init_seen_objects_table();\n-  {\n-    archive_java_mirrors();\n-    archive_strings();\n-    Universe::archive_exception_instances();\n-  }\n+void HeapShared::end_scanning_for_oops() {\n+  archive_strings();\n@@ -839,8 +689,5 @@\n-void HeapShared::prepare_resolved_references() {\n-  GrowableArray<Klass*>* klasses = ArchiveBuilder::current()->klasses();\n-  for (int i = 0; i < klasses->length(); i++) {\n-    Klass* src_k = klasses->at(i);\n-    if (src_k->is_instance_klass()) {\n-      InstanceKlass* buffered_ik = ArchiveBuilder::current()->get_buffered_addr(InstanceKlass::cast(src_k));\n-      buffered_ik->constants()->prepare_resolved_references_for_archiving();\n-    }\n+void HeapShared::write_heap(ArchiveHeapInfo *heap_info) {\n+  {\n+    NoSafepointVerifier nsv;\n+    CDSHeapVerifier::verify();\n+    check_special_subgraph_classes();\n@@ -848,10 +695,2 @@\n-}\n-void HeapShared::copy_objects() {\n-  assert(HeapShared::can_write(), \"must be\");\n-\n-  prepare_resolved_references();\n-  find_all_aot_initialized_classes();\n-  copy_special_subgraph();\n-\n-  archive_object_subgraphs(archive_subgraph_entry_fields,\n-                           false \/* is_full_module_graph *\/);\n+  StringTable::write_shared_table(_dumped_interned_strings);\n+  ArchiveHeapWriter::write(_pending_roots, heap_info);\n@@ -860,5 +699,2 @@\n-  if (CDSConfig::is_dumping_full_module_graph()) {\n-    archive_object_subgraphs(fmg_archive_subgraph_entry_fields,\n-                             true \/* is_full_module_graph *\/);\n-    Modules::verify_archived_modules();\n-  }\n+  ArchiveBuilder::OtherROAllocMark mark;\n+  write_subgraph_info_table();\n@@ -867,38 +703,6 @@\n-\/\/ Closure used by HeapShared::scan_for_aot_initialized_classes() to look for all objects\n-\/\/ that are reachable from a given root.\n-class HeapShared::AOTInitializedClassScanner : public BasicOopIterateClosure {\n-  bool _made_progress;\n-\n-  template <class T> void check(T *p) {\n-    oop obj = HeapAccess<>::oop_load(p);\n-    if (!java_lang_Class::is_instance(obj)) {\n-      \/\/ Don't scan the mirrors, as we may see an orig_mirror while scanning\n-      \/\/ the object graph, .... TODO more info\n-      _made_progress |= HeapShared::scan_for_aot_initialized_classes(obj);\n-    }\n-  }\n-\n-public:\n-  AOTInitializedClassScanner() : _made_progress(false) {}\n-  void do_oop(narrowOop *p) { check(p); }\n-  void do_oop(      oop *p) { check(p); }\n-  bool made_progress() { return _made_progress; }\n-};\n-\n-\/\/ If <buffered_ik> has been initialized during the assembly phase, mark its\n-\/\/ has_aot_initialized_mirror bit. And then do the same for all supertypes of\n-\/\/ <buffered_ik>.\n-\/\/\n-\/\/ Note: a super interface <intf> of <buffered_ik> may not have been initialized, if\n-\/\/ <intf> has not declared any default methods.\n-\/\/\n-\/\/ Note: this function doesn not call InstanceKlass::initialize() -- we are inside\n-\/\/ a safepoint.\n-\/\/\n-\/\/ Returns true if one or more classes have been newly marked.\n-static bool mark_for_aot_initialization(InstanceKlass* buffered_ik) {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"sanity\");\n-  assert(ArchiveBuilder::current()->is_in_buffer_space(buffered_ik), \"sanity\");\n-\n-  if (buffered_ik->has_aot_initialized_mirror()) { \/\/ already marked\n-    return false;\n+void HeapShared::scan_java_mirror(oop orig_mirror) {\n+  oop m = scratch_java_mirror(orig_mirror);\n+  if (m != nullptr) { \/\/ nullptr if for custom class loader\n+    copy_java_mirror_hashcode(orig_mirror, m);\n+    bool success = archive_reachable_objects_from(1, _dump_time_special_subgraph, m);\n+    assert(success, \"sanity\");\n@@ -906,0 +710,1 @@\n+}\n@@ -907,41 +712,2 @@\n-  bool made_progress = false;\n-  if (buffered_ik->is_initialized()) {\n-    if (log_is_enabled(Info, cds, init)) {\n-      ResourceMark rm;\n-      log_info(cds, init)(\"Mark class for aot-init: %s\", buffered_ik->external_name());\n-    }\n-\n-    InstanceKlass* src_ik = ArchiveBuilder::current()->get_source_addr(buffered_ik);\n-\n-    \/\/ If we get here with a \"wild\" user class, which may have\n-    \/\/ uncontrolled <clinit> code, exit with an error.  Obviously\n-    \/\/ filtering logic upstream needs to detect APP classes and not mark\n-    \/\/ them for aot-init in the first place, but this will be the final\n-    \/\/ firewall.\n-\n-#ifndef PRODUCT\n-    \/\/ ArchiveHeapTestClass is used for a very small number of internal regression\n-    \/\/ tests (non-product builds only). It may initialize some unexpected classes.\n-    if (ArchiveHeapTestClass == nullptr)\n-#endif\n-    {\n-      if (!src_ik->in_javabase_module()) {\n-        \/\/ Class\/interface types in the boot loader may have been initialized as side effects\n-        \/\/ of JVM bootstrap code, so they are fine. But we need to check all other classes.\n-        if (buffered_ik->is_interface()) {\n-          \/\/ This probably means a bug in AOTConstantPoolResolver.::is_indy_resolution_deterministic()\n-          guarantee(!buffered_ik->interface_needs_clinit_execution_as_super(),\n-                    \"should not have initialized an interface whose <clinit> might have unpredictable side effects\");\n-        } else {\n-          \/\/ \"normal\" classes\n-          guarantee(HeapShared::is_archivable_hidden_klass(buffered_ik),\n-                    \"should not have initialized any non-interface, non-hidden classes outside of java.base\");\n-        }\n-      }\n-    }\n-\n-    buffered_ik->set_has_aot_initialized_mirror();\n-    if (AOTClassInitializer::is_runtime_setup_required(src_ik)) {\n-      buffered_ik->set_is_runtime_setup_required();\n-    }\n-    made_progress = true;\n+void HeapShared::scan_java_class(Klass* orig_k) {\n+  scan_java_mirror(orig_k->java_mirror());\n@@ -949,3 +715,7 @@\n-    InstanceKlass* super = buffered_ik->java_super();\n-    if (super != nullptr) {\n-      mark_for_aot_initialization(super);\n+  if (orig_k->is_instance_klass()) {\n+    InstanceKlass* orig_ik = InstanceKlass::cast(orig_k);\n+    orig_ik->constants()->prepare_resolved_references_for_archiving();\n+    objArrayOop rr = get_archived_resolved_references(orig_ik);\n+    if (rr != nullptr) {\n+      bool success = HeapShared::archive_reachable_objects_from(1, _dump_time_special_subgraph, rr);\n+      assert(success, \"must be\");\n@@ -954,9 +724,1 @@\n-    Array<InstanceKlass*>* interfaces = buffered_ik->transitive_interfaces();\n-    for (int i = 0; i < interfaces->length(); i++) {\n-      InstanceKlass* intf = interfaces->at(i);\n-      mark_for_aot_initialization(intf);\n-      if (!intf->is_initialized()) {\n-        assert(!intf->interface_needs_clinit_execution_as_super(\/*also_check_supers*\/false), \"sanity\");\n-        assert(!intf->has_aot_initialized_mirror(), \"must not be marked\");\n-      }\n-    }\n+    orig_ik->constants()->add_dumped_interned_strings();\n@@ -964,2 +726,0 @@\n-\n-  return made_progress;\n@@ -968,70 +728,2 @@\n-void HeapShared::find_all_aot_initialized_classes() {\n-  if (!CDSConfig::is_dumping_aot_linked_classes()) {\n-    return;\n-  }\n-\n-  init_seen_objects_table();\n-  find_all_aot_initialized_classes_helper();\n-  delete_seen_objects_table();\n-}\n-\n-\/\/ Recursively find all class that should be aot-initialized:\n-\/\/ - the class has at least one instance that can be reachable from the special subgraph; or\n-\/\/ - the class is hard-coded in AOTClassInitializer::can_archive_initialized_mirror()\n-void HeapShared::find_all_aot_initialized_classes_helper() {\n-  GrowableArray<Klass*>* klasses = ArchiveBuilder::current()->klasses();\n-  assert(klasses != nullptr, \"sanity\");\n-\n-  \/\/ First scan all resolved constant pools references.\n-  for (int i = 0; i < klasses->length(); i++) {\n-    Klass* src_k = klasses->at(i);\n-    if (src_k->is_instance_klass()) {\n-      InstanceKlass* src_ik = InstanceKlass::cast(src_k);\n-      InstanceKlass* buffered_ik = ArchiveBuilder::current()->get_buffered_addr(src_ik);\n-      objArrayOop rr = get_archived_resolved_references(src_ik);\n-      if (rr != nullptr) {\n-        objArrayOop scratch_rr = scratch_resolved_references(src_ik->constants());\n-        for (int i = 0; i < scratch_rr->length(); i++) {\n-          scan_for_aot_initialized_classes(scratch_rr->obj_at(i));\n-        }\n-      }\n-\n-      \/\/ If a class is hard-coded to be aot-initialize, mark it as such.\n-      if (AOTClassInitializer::can_archive_initialized_mirror(src_ik)) {\n-        mark_for_aot_initialization(buffered_ik);\n-      }\n-    }\n-  }\n-\n-  \/\/ These objects also belong to the special subgraph\n-  scan_for_aot_initialized_classes(Universe::null_ptr_exception_instance());\n-  scan_for_aot_initialized_classes(Universe::arithmetic_exception_instance());\n-  scan_for_aot_initialized_classes(Universe::internal_error_instance());\n-  scan_for_aot_initialized_classes(Universe::array_index_out_of_bounds_exception_instance());\n-  scan_for_aot_initialized_classes(Universe::array_store_exception_instance());\n-  scan_for_aot_initialized_classes(Universe::class_cast_exception_instance());\n-\n-  bool made_progress;\n-  do {\n-    \/\/ In each pass, we copy the scratch mirrors of the classes that were marked\n-    \/\/ as aot-init in the previous pass. We then scan these mirrors, which may\n-    \/\/ mark more classes. Keep iterating until no more progress can be made.\n-    made_progress = false;\n-    for (int i = 0; i < klasses->length(); i++) {\n-      Klass* orig_k = klasses->at(i);\n-      if (orig_k->is_instance_klass()) {\n-        InstanceKlass* orig_ik = InstanceKlass::cast(orig_k);\n-        if (ArchiveBuilder::current()->get_buffered_addr(orig_ik)->has_aot_initialized_mirror()) {\n-          oop orig_mirror = orig_ik->java_mirror();\n-          oop scratch_mirror = scratch_java_mirror(orig_k);\n-          if (!has_been_seen_during_subgraph_recording(scratch_mirror)) {\n-            \/\/ Scan scratch_mirror instead of orig_mirror (which has fields like ClassLoader that\n-            \/\/ are not archived).\n-            copy_aot_initialized_mirror(orig_k, orig_mirror, scratch_mirror);\n-            made_progress |= scan_for_aot_initialized_classes(scratch_mirror);\n-          }\n-        }\n-      }\n-    }\n-  } while (made_progress);\n-}\n+void HeapShared::archive_subgraphs() {\n+  assert(CDSConfig::is_dumping_heap(), \"must be\");\n@@ -1039,5 +731,2 @@\n-bool HeapShared::scan_for_aot_initialized_classes(oop obj) {\n-  if (obj == nullptr || has_been_seen_during_subgraph_recording(obj)) {\n-    return false;\n-  }\n-  set_has_been_seen_during_subgraph_recording(obj);\n+  archive_object_subgraphs(archive_subgraph_entry_fields,\n+                           false \/* is_full_module_graph *\/);\n@@ -1045,6 +734,4 @@\n-  bool made_progress = false;\n-  Klass* k = obj->klass();\n-  if (k->is_instance_klass()) {\n-    InstanceKlass* orig_ik = InstanceKlass::cast(k);\n-    InstanceKlass* buffered_ik = ArchiveBuilder::current()->get_buffered_addr(orig_ik);\n-    made_progress = mark_for_aot_initialization(buffered_ik);\n+  if (CDSConfig::is_dumping_full_module_graph()) {\n+    archive_object_subgraphs(fmg_archive_subgraph_entry_fields,\n+                             true \/* is_full_module_graph *\/);\n+    Modules::verify_archived_modules();\n@@ -1052,5 +739,0 @@\n-\n-  AOTInitializedClassScanner scanner;\n-  obj->oop_iterate(&scanner);\n-  made_progress |= scanner.made_progress();\n-  return made_progress;\n@@ -1071,2 +753,1 @@\n-  Klass* buffered_k = ArchiveBuilder::get_buffered_klass(k);\n-    _dump_time_subgraph_info_table->put_if_absent(k, KlassSubGraphInfo(buffered_k, is_full_module_graph),\n+    _dump_time_subgraph_info_table->put_if_absent(k, KlassSubGraphInfo(k, is_full_module_graph),\n@@ -1101,1 +782,0 @@\n-  Klass* buffered_k = ArchiveBuilder::get_buffered_klass(orig_k);\n@@ -1108,3 +788,1 @@\n-  assert(ArchiveBuilder::current()->is_in_buffer_space(buffered_k), \"must be a shared class\");\n-\n-  if (_k == buffered_k) {\n+  if (_k == orig_k) {\n@@ -1116,1 +794,3 @@\n-  if (buffered_k->is_instance_klass()) {\n+  if (orig_k->is_instance_klass()) {\n+#ifdef ASSERT\n+    InstanceKlass* ik = InstanceKlass::cast(orig_k);\n@@ -1118,2 +798,2 @@\n-      assert(InstanceKlass::cast(buffered_k)->is_shared_boot_class() ||\n-             HeapShared::is_lambda_proxy_klass(InstanceKlass::cast(buffered_k)),\n+      assert(ik->class_loader() == nullptr ||\n+             HeapShared::is_lambda_proxy_klass(ik),\n@@ -1122,2 +802,1 @@\n-      assert(InstanceKlass::cast(buffered_k)->is_shared_boot_class(),\n-             \"must be boot class\");\n+      assert(ik->class_loader() == nullptr, \"must be boot class\");\n@@ -1125,0 +804,1 @@\n+#endif\n@@ -1133,6 +813,2 @@\n-    if (buffered_k->has_aot_initialized_mirror()) {\n-      \/\/ No need to add to the runtime-init list.\n-      return;\n-    }\n-  } else if (buffered_k->is_objArray_klass()) {\n-    Klass* abk = ObjArrayKlass::cast(buffered_k)->bottom_klass();\n+  } else if (orig_k->is_objArray_klass()) {\n+    Klass* abk = ObjArrayKlass::cast(orig_k)->bottom_klass();\n@@ -1145,1 +821,1 @@\n-    if (buffered_k == Universe::objectArrayKlass()) {\n+    if (orig_k == Universe::objectArrayKlass()) {\n@@ -1151,1 +827,1 @@\n-    assert(buffered_k->is_typeArray_klass(), \"must be\");\n+    assert(orig_k->is_typeArray_klass(), \"must be\");\n@@ -1157,1 +833,1 @@\n-    if (!_subgraph_object_klasses->contains(buffered_k)) {\n+    if (!_subgraph_object_klasses->contains(orig_k)) {\n@@ -1163,1 +839,1 @@\n-  _subgraph_object_klasses->append_if_missing(buffered_k);\n+  _subgraph_object_klasses->append_if_missing(orig_k);\n@@ -1219,1 +895,1 @@\n-  _k = info->klass();\n+  _k = ArchiveBuilder::get_buffered_klass(info->klass());\n@@ -1252,6 +928,16 @@\n-  \/\/ the Klasses of the objects in the sub-graphs\n-  GrowableArray<Klass*>* subgraph_object_klasses = info->subgraph_object_klasses();\n-  if (subgraph_object_klasses != nullptr) {\n-    int num_subgraphs_klasses = subgraph_object_klasses->length();\n-    _subgraph_object_klasses =\n-      ArchiveBuilder::new_ro_array<Klass*>(num_subgraphs_klasses);\n+  \/\/ <recorded_klasses> has the Klasses of all the objects that are referenced by this subgraph.\n+  \/\/ Copy those that need to be explicitly initialized into <_subgraph_object_klasses>.\n+  GrowableArray<Klass*>* recorded_klasses = info->subgraph_object_klasses();\n+  if (recorded_klasses != nullptr) {\n+    \/\/ AOT-inited classes are automatically marked as \"initialized\" during bootstrap. When\n+    \/\/ programmatically loading a subgraph, we only need to explicitly initialize the classes\n+    \/\/ that are not aot-inited.\n+    int num_to_copy = 0;\n+    for (int i = 0; i < recorded_klasses->length(); i++) {\n+      Klass* subgraph_k = ArchiveBuilder::get_buffered_klass(recorded_klasses->at(i));\n+      if (!subgraph_k->has_aot_initialized_mirror()) {\n+        num_to_copy ++;\n+      }\n+    }\n+\n+    _subgraph_object_klasses = ArchiveBuilder::new_ro_array<Klass*>(num_to_copy);\n@@ -1259,2 +945,5 @@\n-    for (int i = 0; i < num_subgraphs_klasses; i++) {\n-      Klass* subgraph_k = subgraph_object_klasses->at(i);\n+    for (int i = 0, n = 0; i < recorded_klasses->length(); i++) {\n+      Klass* subgraph_k = ArchiveBuilder::get_buffered_klass(recorded_klasses->at(i));\n+      if (subgraph_k->has_aot_initialized_mirror()) {\n+        continue;\n+      }\n@@ -1269,1 +958,1 @@\n-          owner_name, i, subgraph_k->external_name());\n+          owner_name, n, subgraph_k->external_name());\n@@ -1271,2 +960,3 @@\n-      _subgraph_object_klasses->at_put(i, subgraph_k);\n-      ArchivePtrMarker::mark_pointer(_subgraph_object_klasses->adr_at(i));\n+      _subgraph_object_klasses->at_put(n, subgraph_k);\n+      ArchivePtrMarker::mark_pointer(_subgraph_object_klasses->adr_at(n));\n+      n++;\n@@ -1712,1 +1402,1 @@\n-        log_debug(cds, heap)(\"(%d) %s[\" SIZE_FORMAT \"] ==> \" PTR_FORMAT \" size \" SIZE_FORMAT \" %s\", _level,\n+        log_debug(cds, heap)(\"(%d) %s[%zu] ==> \" PTR_FORMAT \" size %zu %s\", _level,\n@@ -1850,1 +1540,1 @@\n-    if (!archive_object(orig_obj)) {\n+    if (!archive_object(orig_obj, subgraph_info)) {\n@@ -1855,1 +1545,1 @@\n-        PTR_FORMAT \") size \" SIZE_FORMAT \", skipped.\",\n+        PTR_FORMAT \") size %zu, skipped.\",\n@@ -2030,1 +1720,1 @@\n-      Symbol* name = ArchiveBuilder::current()->get_source_addr(subgraph_k->name());\n+      Symbol* name = subgraph_k->name();\n@@ -2199,1 +1889,1 @@\n-  assert(HeapShared::can_write(), \"must be\");\n+  assert(CDSConfig::is_dumping_heap(), \"must be\");\n@@ -2288,1 +1978,1 @@\n-  if (HeapShared::can_write()) {\n+  if (CDSConfig::is_dumping_heap()) {\n@@ -2356,0 +2046,3 @@\n+    \/\/ Prevent string deduplication from changing the value field to\n+    \/\/ something not in the archive.\n+    java_lang_String::set_deduplication_forbidden(string);\n@@ -2360,0 +2053,4 @@\n+bool HeapShared::is_dumped_interned_string(oop o) {\n+  return _dumped_interned_strings->get(o) != nullptr;\n+}\n+\n@@ -2436,2 +2133,2 @@\n-    log_info(cds, heap)(SIZE_FORMAT_W(8) \" objects are <= \" SIZE_FORMAT_W(-6)\n-                        \" bytes (total \" SIZE_FORMAT_W(8) \" bytes, avg %8.1f bytes)\",\n+    log_info(cds, heap)(\"%8zu objects are <= %-6zu\"\n+                        \" bytes (total %8zu bytes, avg %8.1f bytes)\",\n@@ -2443,1 +2140,1 @@\n-  log_info(cds, heap)(SIZE_FORMAT_W(8) \" huge  objects               (total \"  SIZE_FORMAT_W(8) \" bytes\"\n+  log_info(cds, heap)(\"%8zu huge  objects               (total %8zu bytes\"\n@@ -2447,1 +2144,1 @@\n-  log_info(cds, heap)(SIZE_FORMAT_W(8) \" total objects               (total \"  SIZE_FORMAT_W(8) \" bytes\"\n+  log_info(cds, heap)(\"%8zu total objects               (total %8zu bytes\"\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":171,"deletions":474,"binary":false,"changes":645,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,1 +46,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/altHashing.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-#include \"precompiled.hpp\"\n@@ -2130,1 +2129,1 @@\n-  int flags = cfs->get_u2_fast();\n+  u2 flags = cfs->get_u2_fast();\n@@ -2984,1 +2983,1 @@\n-    jint flags;\n+    u2 flags;\n@@ -3001,1 +3000,1 @@\n-    inner_classes->at_put(index++, inner_access_flags.as_short());\n+    inner_classes->at_put(index++, inner_access_flags.as_unsigned_short());\n@@ -3750,0 +3749,6 @@\n+\n+  \/\/ Initialize cached modifier_flags to support Class.getModifiers().\n+  \/\/ This must follow setting inner_class attributes.\n+  u2 computed_modifiers = this_klass->compute_modifier_flags();\n+  this_klass->set_modifier_flags(computed_modifiers);\n+\n@@ -4067,3 +4072,7 @@\n-    if (super_ik->is_sealed() && !super_ik->has_as_permitted_subclass(this_klass)) {\n-      classfile_icce_error(\"class %s cannot inherit from sealed class %s\", super_ik, THREAD);\n-      return;\n+    if (super_ik->is_sealed()) {\n+      stringStream ss;\n+      ResourceMark rm(THREAD);\n+      if (!super_ik->has_as_permitted_subclass(this_klass, ss)) {\n+        classfile_icce_error(ss.as_string(), THREAD);\n+        return;\n+      }\n@@ -4114,6 +4123,7 @@\n-    if (k->is_sealed() && !k->has_as_permitted_subclass(this_klass)) {\n-      classfile_icce_error(this_klass->is_interface() ?\n-                             \"class %s cannot extend sealed interface %s\" :\n-                             \"class %s cannot implement sealed interface %s\",\n-                           k, THREAD);\n-      return;\n+    if (k->is_sealed()) {\n+      stringStream ss;\n+      ResourceMark rm(THREAD);\n+      if (!k->has_as_permitted_subclass(this_klass, ss)) {\n+        classfile_icce_error(ss.as_string(), THREAD);\n+        return;\n+      }\n@@ -5174,1 +5184,0 @@\n-  \/\/ The create_mirror() call will also call compute_modifiers()\n@@ -5333,1 +5342,1 @@\n-  assert(0 == _access_flags.as_int(), \"invariant\");\n+  assert(0 == _access_flags.as_unsigned_short(), \"invariant\");\n@@ -5485,1 +5494,1 @@\n-  jint flags;\n+  u2 flags;\n@@ -5660,1 +5669,1 @@\n-    jio_snprintf(addr_buf, 20, SIZE_FORMAT_X, new_id);\n+    jio_snprintf(addr_buf, 20, \"0x%zx\", new_id);\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.cpp","additions":27,"deletions":18,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -371,0 +371,4 @@\n+  \/\/ Uses msg directly in the ICCE, with no additional content\n+  void classfile_icce_error(const char* msg,\n+                            TRAPS) const;\n+\n","filename":"src\/hotspot\/share\/classfile\/classFileParser.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/fieldLayoutBuilder.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -1116,6 +1115,0 @@\n-  \/\/ Use this moment of initialization to cache modifier_flags also,\n-  \/\/ to support Class.getModifiers().  Instance classes recalculate\n-  \/\/ the cached flags after the class file is parsed, but before the\n-  \/\/ class is put into the system dictionary.\n-  int computed_modifiers = k->compute_modifier_flags();\n-  k->set_modifier_flags(computed_modifiers);\n@@ -1251,2 +1244,2 @@\n-  assert(size > 0, \"Oop size must be greater than zero, not \" SIZE_FORMAT, size);\n-  assert(size <= INT_MAX, \"Lossy conversion: \" SIZE_FORMAT, size);\n+  assert(size > 0, \"Oop size must be greater than zero, not %zu\", size);\n+  assert(size <= INT_MAX, \"Lossy conversion: %zu\", size);\n@@ -3178,1 +3171,1 @@\n-  int flags = (jushort)( m->access_flags().as_short() & JVM_RECOGNIZED_METHOD_MODIFIERS );\n+  int flags = m->access_flags().as_method_flags();\n@@ -4677,1 +4670,2 @@\n-int java_lang_invoke_CallSite::_context_offset;\n+int java_lang_invoke_CallSite::_vmdependencies_offset;\n+int java_lang_invoke_CallSite::_last_cleanup_offset;\n@@ -4681,1 +4675,0 @@\n-  macro(_context_offset, k, \"context\", java_lang_invoke_MethodHandleNatives_CallSiteContext_signature, false)\n@@ -4686,0 +4679,1 @@\n+  CALLSITE_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n@@ -4691,0 +4685,1 @@\n+  CALLSITE_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n@@ -4694,1 +4689,1 @@\n-oop java_lang_invoke_CallSite::context_no_keepalive(oop call_site) {\n+DependencyContext java_lang_invoke_CallSite::vmdependencies(oop call_site) {\n@@ -4696,3 +4691,4 @@\n-\n-  oop dep_oop = call_site->obj_field_access<AS_NO_KEEPALIVE>(_context_offset);\n-  return dep_oop;\n+  nmethodBucket* volatile* vmdeps_addr = call_site->field_addr<nmethodBucket* volatile>(_vmdependencies_offset);\n+  volatile uint64_t* last_cleanup_addr = call_site->field_addr<volatile uint64_t>(_last_cleanup_offset);\n+  DependencyContext dep_ctx(vmdeps_addr, last_cleanup_addr);\n+  return dep_ctx;\n@@ -4719,24 +4715,0 @@\n-\/\/ Support for java_lang_invoke_MethodHandleNatives_CallSiteContext\n-\n-int java_lang_invoke_MethodHandleNatives_CallSiteContext::_vmdependencies_offset;\n-int java_lang_invoke_MethodHandleNatives_CallSiteContext::_last_cleanup_offset;\n-\n-void java_lang_invoke_MethodHandleNatives_CallSiteContext::compute_offsets() {\n-  InstanceKlass* k = vmClasses::Context_klass();\n-  CALLSITECONTEXT_INJECTED_FIELDS(INJECTED_FIELD_COMPUTE_OFFSET);\n-}\n-\n-#if INCLUDE_CDS\n-void java_lang_invoke_MethodHandleNatives_CallSiteContext::serialize_offsets(SerializeClosure* f) {\n-  CALLSITECONTEXT_INJECTED_FIELDS(INJECTED_FIELD_SERIALIZE_OFFSET);\n-}\n-#endif\n-\n-DependencyContext java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(oop call_site) {\n-  assert(java_lang_invoke_MethodHandleNatives_CallSiteContext::is_instance(call_site), \"\");\n-  nmethodBucket* volatile* vmdeps_addr = call_site->field_addr<nmethodBucket* volatile>(_vmdependencies_offset);\n-  volatile uint64_t* last_cleanup_addr = call_site->field_addr<volatile uint64_t>(_last_cleanup_offset);\n-  DependencyContext dep_ctx(vmdeps_addr, last_cleanup_addr);\n-  return dep_ctx;\n-}\n-\n@@ -5392,1 +5364,0 @@\n-  f(java_lang_invoke_MethodHandleNatives_CallSiteContext) \\\n@@ -5458,2 +5429,1 @@\n-        klass == vmClasses::MemberName_klass() ||\n-        klass == vmClasses::Context_klass()) {\n+        klass == vmClasses::MemberName_klass()) {\n@@ -5546,1 +5516,1 @@\n-    tty->print_cr(\"  name: %s, sig: %s, flags: %08x\", fs.name()->as_C_string(), fs.signature()->as_C_string(), fs.access_flags().as_int());\n+    tty->print_cr(\"  name: %s, sig: %s, flags: %08x\", fs.name()->as_C_string(), fs.signature()->as_C_string(), fs.access_flags().as_field_flags());\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":15,"deletions":45,"binary":false,"changes":60,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -324,0 +324,1 @@\n+  static int component_mirror_offset() { return _component_mirror_offset; }\n@@ -328,2 +329,1 @@\n-\n-  static int component_mirror_offset() { return _component_mirror_offset; }\n+  static int reflection_data_offset() { return _reflectionData_offset; }\n@@ -1412,0 +1412,3 @@\n+#define CALLSITE_INJECTED_FIELDS(macro) \\\n+  macro(java_lang_invoke_CallSite, vmdependencies, intptr_signature, false) \\\n+  macro(java_lang_invoke_CallSite, last_cleanup, long_signature, false)\n@@ -1418,1 +1421,2 @@\n-  static int _context_offset;\n+  static int _vmdependencies_offset;\n+  static int _last_cleanup_offset;\n@@ -1429,1 +1433,1 @@\n-  static oop context_no_keepalive(oop site);\n+  static DependencyContext vmdependencies(oop call_site);\n@@ -1439,1 +1443,0 @@\n-  static int context_offset() { CHECK_INIT(_context_offset); }\n@@ -1464,29 +1467,0 @@\n-\/\/ Interface to java.lang.invoke.MethodHandleNatives$CallSiteContext objects\n-\n-#define CALLSITECONTEXT_INJECTED_FIELDS(macro) \\\n-  macro(java_lang_invoke_MethodHandleNatives_CallSiteContext, vmdependencies, intptr_signature, false) \\\n-  macro(java_lang_invoke_MethodHandleNatives_CallSiteContext, last_cleanup, long_signature, false)\n-\n-class DependencyContext;\n-\n-class java_lang_invoke_MethodHandleNatives_CallSiteContext : AllStatic {\n-  friend class JavaClasses;\n-\n-private:\n-  static int _vmdependencies_offset;\n-  static int _last_cleanup_offset;\n-\n-  static void compute_offsets();\n-\n-public:\n-  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n-  \/\/ Accessors\n-  static DependencyContext vmdependencies(oop context);\n-\n-  \/\/ Testers\n-  static bool is_subclass(Klass* klass) {\n-    return klass->is_subclass_of(vmClasses::Context_klass());\n-  }\n-  static bool is_instance(oop obj);\n-};\n-\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":9,"deletions":35,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -264,4 +264,0 @@\n-}\n-\n-inline bool java_lang_invoke_MethodHandleNatives_CallSiteContext::is_instance(oop obj) {\n-  return obj != nullptr && is_subclass(obj->klass());\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.inline.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Arguments.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -38,0 +37,1 @@\n+#include \"gc\/shared\/partialArraySplitter.inline.hpp\"\n@@ -39,1 +39,1 @@\n-#include \"gc\/shared\/partialArrayTaskStepper.inline.hpp\"\n+#include \"gc\/shared\/partialArrayTaskStats.hpp\"\n@@ -83,2 +83,1 @@\n-    _partial_array_state_allocator(g1h->partial_array_state_manager()),\n-    _partial_array_stepper(num_workers, ParGCArrayScanChunk),\n+    _partial_array_splitter(g1h->partial_array_state_manager(), num_workers),\n@@ -172,3 +171,6 @@\n-  \/\/ Must be in the collection set--it's already been copied.\n-  oop p = task->source();\n-  assert(_g1h->is_in_cset(p), \"p=\" PTR_FORMAT, p2i(p));\n+  assert(task != nullptr, \"invariant\");\n+  \/\/ Source isn't used for processing, so not recorded in task.\n+  assert(task->source() == nullptr, \"invariant\");\n+  oop p = task->destination();\n+  assert(_g1h->is_in_reserved(p),\n+         \"task=\" PTR_FORMAT \" dest=\" PTR_FORMAT, p2i(task), p2i(p));\n@@ -225,24 +227,5 @@\n-void G1ParScanThreadState::do_partial_array(PartialArrayState* state) {\n-  oop to_obj = state->destination();\n-\n-#ifdef ASSERT\n-  oop from_obj = state->source();\n-  assert(_g1h->is_in_reserved(from_obj), \"must be in heap.\");\n-  assert(from_obj->is_forwarded(), \"must be forwarded\");\n-  assert(from_obj != to_obj, \"should not be chunking self-forwarded objects\");\n-  assert(to_obj->is_objArray(), \"must be obj array\");\n-#endif \/\/ ASSERT\n-\n-  objArrayOop to_array = objArrayOop(to_obj);\n-\n-  \/\/ Claim a chunk and get number of additional tasks to enqueue.\n-  PartialArrayTaskStepper::Step step = _partial_array_stepper.next(state);\n-  \/\/ Push any additional partial scan tasks needed.  Pushed before processing\n-  \/\/ the claimed chunk to allow other workers to steal while we're processing.\n-  if (step._ncreate > 0) {\n-    state->add_references(step._ncreate);\n-    for (uint i = 0; i < step._ncreate; ++i) {\n-      push_on_queue(ScannerTask(state));\n-    }\n-  }\n-\n+void G1ParScanThreadState::do_partial_array(PartialArrayState* state, bool stolen) {\n+  \/\/ Access state before release by claim().\n+  objArrayOop to_array = objArrayOop(state->destination());\n+  PartialArraySplitter::Claim claim =\n+    _partial_array_splitter.claim(state, _task_queue, stolen);\n@@ -253,4 +236,2 @@\n-                              checked_cast<int>(step._index),\n-                              checked_cast<int>(step._index + _partial_array_stepper.chunk_size()));\n-  \/\/ Release reference to the state, now that we're done with it.\n-  _partial_array_state_allocator.release(state);\n+                              checked_cast<int>(claim._start),\n+                              checked_cast<int>(claim._end));\n@@ -268,20 +249,3 @@\n-\n-  PartialArrayTaskStepper::Step step = _partial_array_stepper.start(array_length);\n-\n-  \/\/ Push any needed partial scan tasks.  Pushed before processing the\n-  \/\/ initial chunk to allow other workers to steal while we're processing.\n-  if (step._ncreate > 0) {\n-    assert(step._index < array_length, \"invariant\");\n-    assert(((array_length - step._index) % _partial_array_stepper.chunk_size()) == 0,\n-           \"invariant\");\n-    PartialArrayState* state =\n-      _partial_array_state_allocator.allocate(from_obj, to_obj,\n-                                              step._index,\n-                                              array_length,\n-                                              step._ncreate);\n-    for (uint i = 0; i < step._ncreate; ++i) {\n-      push_on_queue(ScannerTask(state));\n-    }\n-  } else {\n-    assert(step._index == array_length, \"invariant\");\n-  }\n+  size_t initial_chunk_size =\n+    \/\/ The source array is unused when processing states.\n+    _partial_array_splitter.start(_task_queue, nullptr, to_array, array_length);\n@@ -299,1 +263,1 @@\n-  to_array->oop_iterate_range(&_scanner, 0, checked_cast<int>(step._index));\n+  to_array->oop_iterate_range(&_scanner, 0, checked_cast<int>(initial_chunk_size));\n@@ -303,1 +267,1 @@\n-void G1ParScanThreadState::dispatch_task(ScannerTask task) {\n+void G1ParScanThreadState::dispatch_task(ScannerTask task, bool stolen) {\n@@ -310,1 +274,1 @@\n-    do_partial_array(task.to_partial_array_state());\n+    do_partial_array(task.to_partial_array_state(), stolen);\n@@ -323,1 +287,1 @@\n-        dispatch_task(task);\n+        dispatch_task(task, false);\n@@ -327,1 +291,1 @@\n-      dispatch_task(task);\n+      dispatch_task(task, false);\n@@ -336,1 +300,1 @@\n-    dispatch_task(stolen_task);\n+    dispatch_task(stolen_task, true);\n@@ -723,0 +687,8 @@\n+#if TASKQUEUE_STATS\n+\n+PartialArrayTaskStats* G1ParScanThreadState::partial_array_task_stats() {\n+  return _partial_array_splitter.stats();\n+}\n+\n+#endif \/\/ TASKQUEUE_STATS\n+\n@@ -750,0 +722,12 @@\n+\n+#if TASKQUEUE_STATS\n+\n+void G1ParScanThreadStateSet::print_partial_array_task_stats() {\n+  auto get_stats = [&](uint i) {\n+    return state_for_worker(i)->partial_array_task_stats();\n+  };\n+  PartialArrayTaskStats::log_set(_num_workers, get_stats,\n+                                 \"Partial Array Task Stats\");\n+}\n+\n+#endif \/\/ TASKQUEUE_STATS\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":46,"deletions":62,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelArguments.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -73,0 +72,1 @@\n+#include \"memory\/memoryReserver.hpp\"\n@@ -243,1 +243,12 @@\n-  _reserved_byte_size = align_up(raw_bytes, MAX2(page_sz, granularity));\n+  const size_t rs_align = MAX2(page_sz, granularity);\n+\n+  _reserved_byte_size = align_up(raw_bytes, rs_align);\n+\n+  ReservedSpace rs = MemoryReserver::reserve(_reserved_byte_size,\n+                                             rs_align,\n+                                             page_sz);\n+\n+  if (!rs.is_reserved()) {\n+    \/\/ Failed to reserve memory.\n+    return nullptr;\n+  }\n@@ -245,3 +256,0 @@\n-  const size_t rs_align = page_sz == os::vm_page_size() ? 0 :\n-    MAX2(page_sz, granularity);\n-  ReservedSpace rs(_reserved_byte_size, rs_align, page_sz);\n@@ -254,4 +262,4 @@\n-  if (vspace != nullptr) {\n-    if (vspace->expand_by(_reserved_byte_size)) {\n-      return vspace;\n-    }\n+\n+  if (!vspace->expand_by(_reserved_byte_size)) {\n+    \/\/ Failed to commit memory.\n+\n@@ -259,0 +267,1 @@\n+\n@@ -260,1 +269,3 @@\n-    rs.release();\n+    MemoryReserver::release(rs);\n+\n+    return nullptr;\n@@ -263,1 +274,1 @@\n-  return nullptr;\n+  return vspace;\n@@ -580,2 +591,2 @@\n-      err_msg(\"Unable to allocate \" SIZE_FORMAT \"KB bitmaps for parallel \"\n-      \"garbage collection for the requested \" SIZE_FORMAT \"KB heap.\",\n+      err_msg(\"Unable to allocate %zuKB bitmaps for parallel \"\n+      \"garbage collection for the requested %zuKB heap.\",\n@@ -588,2 +599,2 @@\n-      err_msg(\"Unable to allocate \" SIZE_FORMAT \"KB card tables for parallel \"\n-      \"garbage collection for the requested \" SIZE_FORMAT \"KB heap.\",\n+      err_msg(\"Unable to allocate %zuKB card tables for parallel \"\n+      \"garbage collection for the requested %zuKB heap.\",\n@@ -1075,1 +1086,1 @@\n-      log_trace(gc, ergo)(\"old_gen_capacity: \" SIZE_FORMAT \" young_gen_capacity: \" SIZE_FORMAT,\n+      log_trace(gc, ergo)(\"old_gen_capacity: %zu young_gen_capacity: %zu\",\n@@ -1210,6 +1221,3 @@\n-    oop obj = nullptr;\n-    ObjArrayTask task;\n-    if (ParCompactionManager::steal_objarray(worker_id,  task)) {\n-      cm->follow_array((objArrayOop)task.obj(), task.index());\n-    } else if (ParCompactionManager::steal(worker_id, obj)) {\n-      cm->follow_contents(obj);\n+    ScannerTask task;\n+    if (ParCompactionManager::steal(worker_id, task)) {\n+      cm->follow_contents(task, true);\n@@ -1231,1 +1239,1 @@\n-      _terminator(active_workers, ParCompactionManager::oop_task_queues()),\n+      _terminator(active_workers, ParCompactionManager::marking_stacks()),\n@@ -1269,1 +1277,1 @@\n-      _terminator(_max_workers, ParCompactionManager::oop_task_queues()) {}\n+      _terminator(_max_workers, ParCompactionManager::marking_stacks()) {}\n@@ -1379,2 +1387,1 @@\n-  ParCompactionManager::oop_task_queues()->print_and_reset_taskqueue_stats(\"Oop Queue\");\n-  ParCompactionManager::_objarray_task_queues->print_and_reset_taskqueue_stats(\"ObjArrayOop Queue\");\n+  ParCompactionManager::print_and_reset_taskqueue_stats();\n@@ -1688,1 +1695,1 @@\n-    log.trace(SIZE_FORMAT \" initially fillable regions\", _total_regions);\n+    log.trace(\"%zu initially fillable regions\", _total_regions);\n@@ -1697,1 +1704,1 @@\n-      line.append(\" \" SIZE_FORMAT_W(7), _regions[i]);\n+      line.append(\" %7zu\", _regions[i]);\n@@ -2144,2 +2151,1 @@\n-    \/\/ The next source region is in the current space.  Update src_region_idx\n-    \/\/ and the source address to match src_region_ptr.\n+    \/\/ Found the first non-empty region in the same space.\n@@ -2147,4 +2153,1 @@\n-    HeapWord* const src_region_addr = sd.region_to_addr(src_region_idx);\n-    if (src_region_addr > closure.source()) {\n-      closure.set_source(src_region_addr);\n-    }\n+    closure.set_source(sd.region_to_addr(src_region_idx));\n@@ -2174,3 +2177,0 @@\n-        HeapWord* region_end_addr = region_start_addr + ParallelCompactData::RegionSize;\n-        HeapWord* first_live_word = mark_bitmap()->find_obj_beg(region_start_addr, region_end_addr);\n-        assert(first_live_word < region_end_addr, \"inv\");\n@@ -2180,1 +2180,1 @@\n-        closure.set_source(first_live_word);\n+        closure.set_source(region_start_addr);\n@@ -2485,1 +2485,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":39,"deletions":40,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -335,1 +335,2 @@\n-inline void PSPromotionManager::process_popped_location_depth(ScannerTask task) {\n+inline void PSPromotionManager::process_popped_location_depth(ScannerTask task,\n+                                                              bool stolen) {\n@@ -338,1 +339,1 @@\n-    process_array_chunk(task.to_partial_array_state());\n+    process_array_chunk(task.to_partial_array_state(), stolen);\n@@ -353,8 +354,0 @@\n-#if TASKQUEUE_STATS\n-void PSPromotionManager::record_steal(ScannerTask task) {\n-  if (task.is_partial_array_state()) {\n-    ++_array_chunk_steals;\n-  }\n-}\n-#endif \/\/ TASKQUEUE_STATS\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.inline.hpp","additions":3,"deletions":10,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -50,0 +49,1 @@\n+#include \"memory\/reservedSpace.hpp\"\n@@ -482,1 +482,1 @@\n-        \"New generation size \" SIZE_FORMAT \"K->\" SIZE_FORMAT \"K [eden=\" SIZE_FORMAT \"K,survivor=\" SIZE_FORMAT \"K]\",\n+        \"New generation size %zuK->%zuK [eden=%zuK,survivor=%zuK]\",\n@@ -486,1 +486,1 @@\n-        \"  [allowed \" SIZE_FORMAT \"K extra for %d threads]\",\n+        \"  [allowed %zuK extra for %d threads]\",\n@@ -717,1 +717,1 @@\n-  log_debug(gc, promotion)(\"Promotion failure size = \" SIZE_FORMAT \") \", old->size());\n+  log_debug(gc, promotion)(\"Promotion failure size = %zu) \", old->size());\n@@ -846,1 +846,1 @@\n-  st->print(\" total \" SIZE_FORMAT \"K, used \" SIZE_FORMAT \"K\",\n+  st->print(\" total %zuK, used %zuK\",\n","filename":"src\/hotspot\/share\/gc\/serial\/defNewGeneration.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/serial\/serialArguments.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -136,1 +135,1 @@\n-      log_develop_trace(gc, compaction)(\"Inserting object to dead space: \" PTR_FORMAT \", \" PTR_FORMAT \", \" SIZE_FORMAT \"b\",\n+      log_develop_trace(gc, compaction)(\"Inserting object to dead space: \" PTR_FORMAT \", \" PTR_FORMAT \", %zub\",\n@@ -663,1 +662,1 @@\n-  log_trace(gc)(\"Restoring \" SIZE_FORMAT \" marks\", _preserved_count + _preserved_overflow_stack_set.get()->size());\n+  log_trace(gc)(\"Restoring %zu marks\", _preserved_count + _preserved_overflow_stack_set.get()->size());\n","filename":"src\/hotspot\/share\/gc\/serial\/serialFullGC.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -72,1 +71,1 @@\n-    log_trace(gc, heap)(\"Expanding %s from \" SIZE_FORMAT \"K by \" SIZE_FORMAT \"K to \" SIZE_FORMAT \"K\",\n+    log_trace(gc, heap)(\"Expanding %s from %zuK by %zuK to %zuK\",\n@@ -83,1 +82,1 @@\n-  size_t aligned_bytes  = ReservedSpace::page_align_size_up(bytes);\n+  size_t aligned_bytes = os::align_up_vm_page_size(bytes);\n@@ -91,1 +90,1 @@\n-    aligned_bytes = ReservedSpace::page_align_size_down(bytes);\n+    aligned_bytes = os::align_down_vm_page_size(bytes);\n@@ -93,1 +92,1 @@\n-  size_t aligned_expand_bytes = ReservedSpace::page_align_size_up(expand_bytes);\n+  size_t aligned_expand_bytes = os::align_up_vm_page_size(expand_bytes);\n@@ -125,1 +124,1 @@\n-  size_t size = ReservedSpace::page_align_size_down(bytes);\n+  size_t size = os::align_down_vm_page_size(bytes);\n@@ -143,1 +142,1 @@\n-  log_trace(gc, heap)(\"Shrinking %s from \" SIZE_FORMAT \"K to \" SIZE_FORMAT \"K\",\n+  log_trace(gc, heap)(\"Shrinking %s from %zuK to %zuK\",\n@@ -239,1 +238,1 @@\n-      log_trace(gc, heap)(\"    shrink_bytes: %.1fK  current_shrink_factor: \" SIZE_FORMAT \"  new shrink factor: \" SIZE_FORMAT \"  _min_heap_delta_bytes: %.1fK\",\n+      log_trace(gc, heap)(\"    shrink_bytes: %.1fK  current_shrink_factor: %zu  new shrink factor: %zu  _min_heap_delta_bytes: %.1fK\",\n@@ -357,2 +356,2 @@\n-         \"used: \" SIZE_FORMAT \" used_after_gc: \" SIZE_FORMAT\n-         \" capacity: \" SIZE_FORMAT, used(), used_after_gc, capacity());\n+         \"used: %zu used_after_gc: %zu\"\n+         \" capacity: %zu\", used(), used_after_gc, capacity());\n@@ -387,1 +386,1 @@\n-  log_trace(gc)(\"Tenured: promo attempt is%s safe: available(\" SIZE_FORMAT \") %s av_promo(\" SIZE_FORMAT \"), max_promo(\" SIZE_FORMAT \")\",\n+  log_trace(gc)(\"Tenured: promo attempt is%s safe: available(%zu) %s av_promo(%zu), max_promo(%zu)\",\n@@ -448,1 +447,1 @@\n-  st->print(\" total \" SIZE_FORMAT \"K, used \" SIZE_FORMAT \"K\",\n+  st->print(\" total %zuK, used %zuK\",\n","filename":"src\/hotspot\/share\/gc\/serial\/tenuredGeneration.cpp","additions":12,"deletions":13,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/shared\/c2\/barrierSetC2.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -386,1 +386,1 @@\n-      increment_total_full_collections();\n+      _total_full_collections++;\n@@ -390,2 +390,0 @@\n-  void increment_total_full_collections() { _total_full_collections++; }\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -133,1 +132,1 @@\n-                \", ratio: %f, memory used by fallback table: \" SIZE_FORMAT \"%s, memory used by bases table: \" SIZE_FORMAT \"%s\",\n+                \", ratio: %f, memory used by fallback table: %zu%s, memory used by bases table: %zu%s\",\n@@ -171,1 +170,1 @@\n-    tty->print_cr(\"grow fallback table to size: \" SIZE_FORMAT \" bytes\",\n+    tty->print_cr(\"grow fallback table to size: %zu bytes\",\n","filename":"src\/hotspot\/share\/gc\/shared\/fullGCForwarding.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -297,2 +296,2 @@\n-           \"Allocation failed, but actual size was updated. min: \" SIZE_FORMAT\n-           \", desired: \" SIZE_FORMAT \", actual: \" SIZE_FORMAT,\n+           \"Allocation failed, but actual size was updated. min: %zu\"\n+           \", desired: %zu, actual: %zu\",\n@@ -303,1 +302,1 @@\n-         PTR_FORMAT \" min: \" SIZE_FORMAT \", desired: \" SIZE_FORMAT,\n+         PTR_FORMAT \" min: %zu, desired: %zu\",\n","filename":"src\/hotspot\/share\/gc\/shared\/memAllocator.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2016, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +27,0 @@\n-#include \"precompiled.hpp\"\n@@ -62,1 +62,1 @@\n-      warning(\"Large pages size (\" SIZE_FORMAT \"K) is too large to afford page-sized regions, disabling uncommit\",\n+      warning(\"Large pages size (%zuK) is too large to afford page-sized regions, disabling uncommit\",\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahArguments.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +27,0 @@\n-#include \"precompiled.hpp\"\n@@ -511,1 +511,1 @@\n-  log_debug(gc)(\"Full GC calculating target humongous objects from end \" SIZE_FORMAT, to_end);\n+  log_debug(gc)(\"Full GC calculating target humongous objects from end %zu\", to_end);\n@@ -551,1 +551,1 @@\n-      r->recycle();\n+      r->try_recycle_under_lock();\n@@ -560,1 +560,1 @@\n-    assert (r->is_committed(), \"only committed regions in heap now, see region \" SIZE_FORMAT, r->index());\n+    assert (r->is_committed(), \"only committed regions in heap now, see region %zu\", r->index());\n@@ -582,1 +582,1 @@\n-        assert(!r->has_live(), \"Region \" SIZE_FORMAT \" is not marked, should not have live\", r->index());\n+        assert(!r->has_live(), \"Region %zu is not marked, should not have live\", r->index());\n@@ -585,1 +585,1 @@\n-        assert(r->has_live(), \"Region \" SIZE_FORMAT \" should have live\", r->index());\n+        assert(r->has_live(), \"Region %zu should have live\", r->index());\n@@ -589,1 +589,1 @@\n-      assert(r->humongous_start_region()->has_live(), \"Region \" SIZE_FORMAT \" should have live\", r->index());\n+      assert(r->humongous_start_region()->has_live(), \"Region %zu should have live\", r->index());\n@@ -725,2 +725,2 @@\n-      assert(ShenandoahPrepareForCompactionTask::is_candidate_region(r), \"Sanity: \" SIZE_FORMAT, idx);\n-      assert(!map.at(idx), \"No region distributed twice: \" SIZE_FORMAT, idx);\n+      assert(ShenandoahPrepareForCompactionTask::is_candidate_region(r), \"Sanity: %zu\", idx);\n+      assert(!map.at(idx), \"No region distributed twice: %zu\", idx);\n@@ -735,1 +735,1 @@\n-    assert(is_distributed || !is_candidate, \"All candidates are distributed: \" SIZE_FORMAT, rid);\n+    assert(is_distributed || !is_candidate, \"All candidates are distributed: %zu\", rid);\n@@ -1001,1 +1001,1 @@\n-      r->recycle();\n+      r->try_recycle_under_lock();\n@@ -1056,1 +1056,1 @@\n-      assert(r->is_stw_move_allowed(), \"Region \" SIZE_FORMAT \" should be movable\", r->index());\n+      assert(r->is_stw_move_allowed(), \"Region %zu should be movable\", r->index());\n@@ -1058,1 +1058,1 @@\n-      log_debug(gc)(\"Full GC compaction moves humongous object from region \" SIZE_FORMAT \" to region \" SIZE_FORMAT, old_start, new_start);\n+      log_debug(gc)(\"Full GC compaction moves humongous object from region %zu to region %zu\", old_start, new_start);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahFullGC.cpp","additions":13,"deletions":13,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,3 +26,0 @@\n-\n-#include \"precompiled.hpp\"\n-\n@@ -222,1 +220,1 @@\n-  log_debug(gc)(\"Worker %u compacting %s Region \" SIZE_FORMAT \" which had used \" SIZE_FORMAT \" and %s live\",\n+  log_debug(gc)(\"Worker %u compacting %s Region %zu which had used %zu and %s live\",\n@@ -251,1 +249,1 @@\n-    log_debug(gc)(\"Planned compaction into Old Region \" SIZE_FORMAT \", used: \" SIZE_FORMAT \" tabulated by worker %u\",\n+    log_debug(gc)(\"Planned compaction into Old Region %zu, used: %zu tabulated by worker %u\",\n@@ -260,1 +258,1 @@\n-    log_debug(gc)(\"Worker %u planned compaction into Young Region \" SIZE_FORMAT \", used: \" SIZE_FORMAT,\n+    log_debug(gc)(\"Worker %u planned compaction into Young Region %zu, used: %zu\",\n@@ -312,1 +310,1 @@\n-      log_debug(gc)(\"Worker %u finishing old region \" SIZE_FORMAT \", compact_point: \" PTR_FORMAT \", obj_size: \" SIZE_FORMAT\n+      log_debug(gc)(\"Worker %u finishing old region %zu, compact_point: \" PTR_FORMAT \", obj_size: %zu\"\n@@ -361,1 +359,1 @@\n-      log_debug(gc)(\"Worker %u finishing young region \" SIZE_FORMAT \", compact_point: \" PTR_FORMAT \", obj_size: \" SIZE_FORMAT\n+      log_debug(gc)(\"Worker %u finishing young region %zu, compact_point: \" PTR_FORMAT \", obj_size: %zu\"\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalFullGC.cpp","additions":6,"deletions":8,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,2 +26,0 @@\n-#include \"precompiled.hpp\"\n-\n@@ -183,1 +182,1 @@\n-  regulator_thread()->stop();\n+  regulator_thread()->stop();\n@@ -471,2 +470,2 @@\n-  assert(is_aligned(future_size, CardTable::card_size_in_words()), \"Card multiple by construction, future_size: \" SIZE_FORMAT\n-          \", card_size: \" SIZE_FORMAT \", cur_size: \" SIZE_FORMAT \", max: \" SIZE_FORMAT,\n+  assert(is_aligned(future_size, CardTable::card_size_in_words()), \"Card multiple by construction, future_size: %zu\"\n+          \", card_size: %zu, cur_size: %zu, max: %zu\",\n@@ -479,1 +478,1 @@\n-  log_debug(gc, free)(\"Set new PLAB size: \" SIZE_FORMAT, future_size);\n+  log_debug(gc, free)(\"Set new PLAB size: %zu\", future_size);\n@@ -484,1 +483,1 @@\n-    log_debug(gc, free)(\"Current PLAB size (\" SIZE_FORMAT \") is too small for \" SIZE_FORMAT, cur_size, size);\n+    log_debug(gc, free)(\"Current PLAB size (%zu) is too small for %zu\", cur_size, size);\n@@ -581,1 +580,1 @@\n-    log_debug(gc)(\"retire_plab() is registering remnant of size \" SIZE_FORMAT \" at \" PTR_FORMAT,\n+    log_debug(gc)(\"retire_plab() is registering remnant of size %zu at \" PTR_FORMAT,\n@@ -725,1 +724,1 @@\n-  ss->print_cr(\"After %s, %s \" SIZE_FORMAT \" regions to %s to prepare for next gc, old available: \"\n+  ss->print_cr(\"After %s, %s %zu regions to %s to prepare for next gc, old available: \"\n@@ -830,1 +829,1 @@\n-      log_debug(gc)(\"Update refs worker \" UINT32_FORMAT \", looking at region \" SIZE_FORMAT, worker_id, r->index());\n+      log_debug(gc)(\"Update refs worker \" UINT32_FORMAT \", looking at region %zu\", worker_id, r->index());\n@@ -856,1 +855,1 @@\n-                 \"%s Region \" SIZE_FORMAT \" is_active but not recognized as YOUNG or OLD so must be newly transitioned from FREE\",\n+                 \"%s Region %zu is_active but not recognized as YOUNG or OLD so must be newly transitioned from FREE\",\n@@ -862,1 +861,1 @@\n-        _heap->pacer()->report_updaterefs(pointer_delta(update_watermark, r->bottom()));\n+        _heap->pacer()->report_update_refs(pointer_delta(update_watermark, r->bottom()));\n@@ -922,1 +921,1 @@\n-          _heap->pacer()->report_updaterefs(pointer_delta(end_of_range, start_of_range));\n+          _heap->pacer()->report_update_refs(pointer_delta(end_of_range, start_of_range));\n@@ -1082,1 +1081,1 @@\n-    \/\/ after final mark of the young generation. See ShenandoahConcurrentGC::op_final_updaterefs for\n+    \/\/ after final mark of the young generation. See ShenandoahConcurrentGC::op_final_update_refs for\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahGenerationalHeap.cpp","additions":13,"deletions":14,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-#include \"precompiled.hpp\"\n@@ -31,1 +30,0 @@\n-#include \"code\/codeCache.hpp\"\n@@ -89,1 +87,1 @@\n-\n+#include \"memory\/allocation.hpp\"\n@@ -92,0 +90,1 @@\n+#include \"memory\/memoryReserver.hpp\"\n@@ -105,0 +104,1 @@\n+#include \"runtime\/threads.hpp\"\n@@ -148,1 +148,1 @@\n-      assert (end <= _bitmap_size, \"end is sane: \" SIZE_FORMAT \" < \" SIZE_FORMAT, end, _bitmap_size);\n+      assert (end <= _bitmap_size, \"end is sane: %zu < %zu\", end, _bitmap_size);\n@@ -159,0 +159,17 @@\n+static ReservedSpace reserve(size_t size, size_t preferred_page_size) {\n+  \/\/ When a page size is given we don't want to mix large\n+  \/\/ and normal pages. If the size is not a multiple of the\n+  \/\/ page size it will be aligned up to achieve this.\n+  size_t alignment = os::vm_allocation_granularity();\n+  if (preferred_page_size != os::vm_page_size()) {\n+    alignment = MAX2(preferred_page_size, alignment);\n+    size = align_up(size, alignment);\n+  }\n+\n+  const ReservedSpace reserved = MemoryReserver::reserve(size, alignment, preferred_page_size);\n+  if (!reserved.is_reserved()) {\n+    vm_exit_during_initialization(\"Could not reserve space\");\n+  }\n+  return reserved;\n+}\n+\n@@ -176,1 +193,1 @@\n-         \"Regions should cover entire heap exactly: \" SIZE_FORMAT \" != \" SIZE_FORMAT \"\/\" SIZE_FORMAT,\n+         \"Regions should cover entire heap exactly: %zu != %zu\/%zu\",\n@@ -266,1 +283,1 @@\n-            \"Bitmap bytes per region should be power of two: \" SIZE_FORMAT, bitmap_bytes_per_region);\n+            \"Bitmap bytes per region should be power of two: %zu\", bitmap_bytes_per_region);\n@@ -277,1 +294,1 @@\n-            \"Should have at least one region per slice: \" SIZE_FORMAT,\n+            \"Should have at least one region per slice: %zu\",\n@@ -281,1 +298,1 @@\n-            \"Bitmap slices should be page-granular: bps = \" SIZE_FORMAT \", page size = \" SIZE_FORMAT,\n+            \"Bitmap slices should be page-granular: bps = %zu, page size = %zu\",\n@@ -284,1 +301,1 @@\n-  ReservedSpace bitmap(_bitmap_size, bitmap_page_size);\n+  ReservedSpace bitmap = reserve(_bitmap_size, bitmap_page_size);\n@@ -304,1 +321,1 @@\n-    ReservedSpace verify_bitmap(_bitmap_size, bitmap_page_size);\n+    ReservedSpace verify_bitmap = reserve(_bitmap_size, bitmap_page_size);\n@@ -322,1 +339,1 @@\n-  ReservedSpace aux_bitmap(_bitmap_size, aux_bitmap_page_size);\n+  ReservedSpace aux_bitmap = reserve(_bitmap_size, aux_bitmap_page_size);\n@@ -340,1 +357,1 @@\n-  ReservedSpace region_storage(region_storage_size, region_page_size);\n+  ReservedSpace region_storage = reserve(region_storage_size, region_page_size);\n@@ -366,1 +383,1 @@\n-      cset_rs = ReservedSpace(cset_size, cset_align, cset_page_size, req_addr);\n+      cset_rs = MemoryReserver::reserve(req_addr, cset_size, cset_align, cset_page_size);\n@@ -375,1 +392,5 @@\n-      cset_rs = ReservedSpace(cset_size, cset_align, os::vm_page_size());\n+      cset_rs = MemoryReserver::reserve(cset_size, cset_align, os::vm_page_size());\n+      if (!cset_rs.is_reserved()) {\n+        vm_exit_during_initialization(\"Cannot reserve memory for collection set\");\n+      }\n+\n@@ -548,1 +569,0 @@\n-  _mmu_tracker(),\n@@ -574,1 +594,1 @@\n-  st->print_cr(\" \" SIZE_FORMAT \"%s max, \" SIZE_FORMAT \"%s soft max, \" SIZE_FORMAT \"%s committed, \" SIZE_FORMAT \"%s used\",\n+  st->print_cr(\" %zu%s max, %zu%s soft max, %zu%s committed, %zu%s used\",\n@@ -579,1 +599,1 @@\n-  st->print_cr(\" \" SIZE_FORMAT \" x \" SIZE_FORMAT\"%s regions\",\n+  st->print_cr(\" %zu x %zu %s regions\",\n@@ -635,1 +655,0 @@\n-    assert(thread->is_Worker_thread(), \"Only worker thread expected\");\n@@ -642,0 +661,2 @@\n+\n+  \/\/ Schedule periodic task to report on gc thread CPU utilization\n@@ -652,0 +673,3 @@\n+\n+  \/\/ Note that the safepoint workers may require gclabs if the threads are used to create a heap dump\n+  \/\/ during a concurrent evacuation phase.\n@@ -775,1 +799,1 @@\n-         \"Should be in bounds: \" SIZE_FORMAT \" <= \" SIZE_FORMAT \" <= \" SIZE_FORMAT,\n+         \"Should be in bounds: %zu <= %zu <= %zu\",\n@@ -782,1 +806,1 @@\n-         \"Should be in bounds: \" SIZE_FORMAT \" <= \" SIZE_FORMAT \" <= \" SIZE_FORMAT,\n+         \"Should be in bounds: %zu <= %zu <= %zu\",\n@@ -829,1 +853,1 @@\n-      log_info(gc)(\"Soft Max Heap Size: \" SIZE_FORMAT \"%s -> \" SIZE_FORMAT \"%s\",\n+      log_info(gc)(\"Soft Max Heap Size: %zu%s -> %zu%s\",\n@@ -868,1 +892,1 @@\n-  log_debug(gc, free)(\"Set new GCLAB size: \" SIZE_FORMAT, new_size);\n+  log_debug(gc, free)(\"Set new GCLAB size: %zu\", new_size);\n@@ -874,1 +898,1 @@\n-    log_debug(gc, free)(\"New gclab size (\" SIZE_FORMAT \") is too small for \" SIZE_FORMAT, new_size, size);\n+    log_debug(gc, free)(\"New gclab size (%zu) is too small for %zu\", new_size, size);\n@@ -983,2 +1007,2 @@\n-        log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: \" SIZE_FORMAT\n-                             \", Original: \" SIZE_FORMAT \", Latest: \" SIZE_FORMAT,\n+        log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: %zu\"\n+                             \", Original: %zu, Latest: %zu\",\n@@ -1013,1 +1037,1 @@\n-            \"Only LAB allocations are elastic: %s, requested = \" SIZE_FORMAT \", actual = \" SIZE_FORMAT,\n+            \"Only LAB allocations are elastic: %s, requested = %zu, actual = %zu\",\n@@ -1165,1 +1189,1 @@\n-      assert(r->has_live(), \"Region \" SIZE_FORMAT \" should have been reclaimed early\", r->index());\n+      assert(r->has_live(), \"Region %zu should have been reclaimed early\", r->index());\n@@ -1179,0 +1203,56 @@\n+class ShenandoahRetireGCLABClosure : public ThreadClosure {\n+private:\n+  bool const _resize;\n+public:\n+  explicit ShenandoahRetireGCLABClosure(bool resize) : _resize(resize) {}\n+  void do_thread(Thread* thread) override {\n+    PLAB* gclab = ShenandoahThreadLocalData::gclab(thread);\n+    assert(gclab != nullptr, \"GCLAB should be initialized for %s\", thread->name());\n+    gclab->retire();\n+    if (_resize && ShenandoahThreadLocalData::gclab_size(thread) > 0) {\n+      ShenandoahThreadLocalData::set_gclab_size(thread, 0);\n+    }\n+\n+    if (ShenandoahHeap::heap()->mode()->is_generational()) {\n+      PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n+      assert(plab != nullptr, \"PLAB should be initialized for %s\", thread->name());\n+\n+      \/\/ There are two reasons to retire all plabs between old-gen evacuation passes.\n+      \/\/  1. We need to make the plab memory parsable by remembered-set scanning.\n+      \/\/  2. We need to establish a trustworthy UpdateWaterMark value within each old-gen heap region\n+      ShenandoahGenerationalHeap::heap()->retire_plab(plab, thread);\n+      if (_resize && ShenandoahThreadLocalData::plab_size(thread) > 0) {\n+        ShenandoahThreadLocalData::set_plab_size(thread, 0);\n+      }\n+    }\n+  }\n+};\n+\n+class ShenandoahGCStatePropagator : public ThreadClosure {\n+public:\n+  explicit ShenandoahGCStatePropagator(char gc_state) : _gc_state(gc_state) {}\n+\n+  void do_thread(Thread* thread) override {\n+    ShenandoahThreadLocalData::set_gc_state(thread, _gc_state);\n+  }\n+private:\n+  char _gc_state;\n+};\n+\n+class ShenandoahPrepareForUpdateRefs : public HandshakeClosure {\n+public:\n+  explicit ShenandoahPrepareForUpdateRefs(char gc_state) :\n+    HandshakeClosure(\"Shenandoah Prepare for Update Refs\"),\n+    _retire(ResizeTLAB), _propagator(gc_state) {}\n+\n+  void do_thread(Thread* thread) override {\n+    _propagator.do_thread(thread);\n+    if (ShenandoahThreadLocalData::gclab(thread) != nullptr) {\n+      _retire.do_thread(thread);\n+    }\n+  }\n+private:\n+  ShenandoahRetireGCLABClosure _retire;\n+  ShenandoahGCStatePropagator _propagator;\n+};\n+\n@@ -1184,0 +1264,19 @@\n+void ShenandoahHeap::concurrent_prepare_for_update_refs() {\n+  \/\/ It's possible that evacuation succeeded, but we could still be cancelled when we get here.\n+  \/\/ A cancellation at this point means the degenerated cycle must resume from update-refs.\n+  set_gc_state_concurrent(EVACUATION, false);\n+  set_gc_state_concurrent(WEAK_ROOTS, false);\n+  set_gc_state_concurrent(UPDATE_REFS, true);\n+\n+  \/\/ This will propagate the gc state and retire gclabs and plabs for threads that require it.\n+  ShenandoahPrepareForUpdateRefs prepare_for_update_refs(_gc_state.raw_value());\n+\n+  \/\/ The handshake won't touch worker threads (or control thread, or VM thread), so do those separately.\n+  Threads::non_java_threads_do(&prepare_for_update_refs);\n+\n+  \/\/ Now retire gclabs and plabs and propagate gc_state for mutator threads\n+  Handshake::execute(&prepare_for_update_refs);\n+\n+  _update_refs_iterator.reset();\n+}\n+\n@@ -1345,28 +1444,0 @@\n-class ShenandoahRetireGCLABClosure : public ThreadClosure {\n-private:\n-  bool const _resize;\n-public:\n-  ShenandoahRetireGCLABClosure(bool resize) : _resize(resize) {}\n-  void do_thread(Thread* thread) {\n-    PLAB* gclab = ShenandoahThreadLocalData::gclab(thread);\n-    assert(gclab != nullptr, \"GCLAB should be initialized for %s\", thread->name());\n-    gclab->retire();\n-    if (_resize && ShenandoahThreadLocalData::gclab_size(thread) > 0) {\n-      ShenandoahThreadLocalData::set_gclab_size(thread, 0);\n-    }\n-\n-    if (ShenandoahHeap::heap()->mode()->is_generational()) {\n-      PLAB* plab = ShenandoahThreadLocalData::plab(thread);\n-      assert(plab != nullptr, \"PLAB should be initialized for %s\", thread->name());\n-\n-      \/\/ There are two reasons to retire all plabs between old-gen evacuation passes.\n-      \/\/  1. We need to make the plab memory parsable by remembered-set scanning.\n-      \/\/  2. We need to establish a trustworthy UpdateWaterMark value within each old-gen heap region\n-      ShenandoahGenerationalHeap::heap()->retire_plab(plab, thread);\n-      if (_resize && ShenandoahThreadLocalData::plab_size(thread) > 0) {\n-        ShenandoahThreadLocalData::set_plab_size(thread, 0);\n-      }\n-    }\n-  }\n-};\n-\n@@ -1385,0 +1456,4 @@\n+\n+  if (safepoint_workers() != nullptr) {\n+    safepoint_workers()->threads_do(&cl);\n+  }\n@@ -1420,0 +1495,1 @@\n+\n@@ -1439,0 +1515,12 @@\n+void ShenandoahHeap::collect_as_vm_thread(GCCause::Cause cause) {\n+  \/\/ These requests are ignored because we can't easily have Shenandoah jump into\n+  \/\/ a synchronous (degenerated or full) cycle while it is in the middle of a concurrent\n+  \/\/ cycle. We _could_ cancel the concurrent cycle and then try to run a cycle directly\n+  \/\/ on the VM thread, but this would confuse the control thread mightily and doesn't\n+  \/\/ seem worth the trouble. Instead, we will have the caller thread run (and wait for) a\n+  \/\/ concurrent cycle in the prologue of the heap inspect\/dump operation. This is how\n+  \/\/ other concurrent collectors in the JVM handle this scenario as well.\n+  assert(Thread::current()->is_VM_thread(), \"Should be the VM thread\");\n+  guarantee(cause == GCCause::_heap_dump || cause == GCCause::_heap_inspection, \"Invalid cause\");\n+}\n+\n@@ -1523,1 +1611,3 @@\n-  assert(gc_cause()  == GCCause::_no_gc, \"Over-writing cause\");\n+  const GCCause::Cause current = gc_cause();\n+  assert(current == GCCause::_no_gc, \"Over-writing cause: %s, with: %s\",\n+         GCCause::to_string(current), GCCause::to_string(cause));\n@@ -1929,1 +2019,1 @@\n-void ShenandoahHeap::propagate_gc_state_to_java_threads() {\n+void ShenandoahHeap::propagate_gc_state_to_all_threads() {\n@@ -1932,0 +2022,2 @@\n+    ShenandoahGCStatePropagator propagator(_gc_state.raw_value());\n+    Threads::threads_do(&propagator);\n@@ -1933,4 +2025,0 @@\n-    char state = gc_state();\n-    for (JavaThreadIteratorWithHandle jtiwh; JavaThread *t = jtiwh.next(); ) {\n-      ShenandoahThreadLocalData::set_gc_state(t, state);\n-    }\n@@ -1940,1 +2028,1 @@\n-void ShenandoahHeap::set_gc_state(uint mask, bool value) {\n+void ShenandoahHeap::set_gc_state_at_safepoint(uint mask, bool value) {\n@@ -1946,0 +2034,4 @@\n+void ShenandoahHeap::set_gc_state_concurrent(uint mask, bool value) {\n+  _gc_state.set_cond(mask, value);\n+}\n+\n@@ -1957,1 +2049,1 @@\n-  set_gc_state(mask, in_progress);\n+  set_gc_state_at_safepoint(mask, in_progress);\n@@ -1963,1 +2055,1 @@\n-  \/\/ has_forwarded_objects() iff UPDATEREFS or EVACUATION\n+  \/\/ has_forwarded_objects() iff UPDATE_REFS or EVACUATION\n@@ -1965,1 +2057,1 @@\n-  bool updating_or_evacuating = _gc_state.is_set(UPDATEREFS | EVACUATION);\n+  bool updating_or_evacuating = _gc_state.is_set(UPDATE_REFS | EVACUATION);\n@@ -1973,1 +2065,1 @@\n-    set_gc_state(OLD_MARKING, in_progress);\n+    set_gc_state_at_safepoint(OLD_MARKING, in_progress);\n@@ -1975,1 +2067,1 @@\n-    set_gc_state(MARKING | OLD_MARKING, in_progress);\n+    set_gc_state_at_safepoint(MARKING | OLD_MARKING, in_progress);\n@@ -2002,1 +2094,1 @@\n-  set_gc_state(EVACUATION, in_progress);\n+  set_gc_state_at_safepoint(EVACUATION, in_progress);\n@@ -2014,1 +2106,1 @@\n-  set_gc_state(WEAK_ROOTS, cond);\n+  set_gc_state_at_safepoint(WEAK_ROOTS, cond);\n@@ -2060,0 +2152,3 @@\n+  \/\/ Step 0a. Stop reporting on gc thread cpu utilization\n+  mmu_tracker()->stop();\n+\n@@ -2114,1 +2209,1 @@\n-\/\/ Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),\n+\/\/ Weak roots are either pre-evacuated (final mark) or updated (final update refs),\n@@ -2158,1 +2253,1 @@\n-  set_gc_state(HAS_FORWARDED, cond);\n+  set_gc_state_at_safepoint(HAS_FORWARDED, cond);\n@@ -2198,1 +2293,1 @@\n-  set_gc_state(UPDATEREFS, in_progress);\n+  set_gc_state_at_safepoint(UPDATE_REFS, in_progress);\n@@ -2216,1 +2311,1 @@\n-  assert(r->pin_count() > 0, \"Region \" SIZE_FORMAT \" should have non-zero pins\", r->index());\n+  assert(r->pin_count() > 0, \"Region %zu should have non-zero pins\", r->index());\n@@ -2248,1 +2343,1 @@\n-             \"Region \" SIZE_FORMAT \" pinning status is inconsistent\", i);\n+             \"Region %zu pinning status is inconsistent\", i);\n@@ -2344,1 +2439,1 @@\n-          _heap->pacer()->report_updaterefs(pointer_delta(update_watermark, r->bottom()));\n+          _heap->pacer()->report_update_refs(pointer_delta(update_watermark, r->bottom()));\n@@ -2406,1 +2501,1 @@\n-         \"sanity: old_region_count: \" SIZE_FORMAT \", first_old_region: \" SIZE_FORMAT \", last_old_region: \" SIZE_FORMAT,\n+         \"sanity: old_region_count: %zu, first_old_region: %zu, last_old_region: %zu\",\n@@ -2603,0 +2698,8 @@\n+bool ShenandoahHeap::is_gc_state(GCState state) const {\n+  \/\/ If the global gc state has been changed, but hasn't yet been propagated to all threads, then\n+  \/\/ the global gc state is the correct value. Once the gc state has been synchronized with all threads,\n+  \/\/ _gc_state_changed will be toggled to false and we need to use the thread local state.\n+  return _gc_state_changed ? _gc_state.is_set(state) : ShenandoahThreadLocalData::is_gc_state(state);\n+}\n+\n+\n@@ -2744,1 +2847,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":180,"deletions":78,"binary":false,"changes":258,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/gc\/z\/zRelocate.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-#include \"precompiled.hpp\"\n@@ -1003,1 +1002,1 @@\n-  JVMCIENV->put_int_at(info, 0, fd.access_flags().as_int());\n+  JVMCIENV->put_int_at(info, 0, fd.access_flags().as_field_flags());\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVM.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-\/\/ no precompiled headers\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCompilerToVMInit.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -53,0 +52,1 @@\n+#include \"memory\/memoryReserver.hpp\"\n@@ -373,1 +373,1 @@\n-      err_msg(\"Size of %s (\" UINTX_FORMAT \" bytes) must be aligned to \" UINTX_FORMAT \" bytes\", name, size, alignment));\n+      err_msg(\"Size of %s (%zu bytes) must be aligned to %zu bytes\", name, size, alignment));\n@@ -942,1 +942,1 @@\n-         \"actual alignment \" SIZE_FORMAT \" must be within maximum heap alignment \" SIZE_FORMAT,\n+         \"actual alignment %zu must be within maximum heap alignment %zu\",\n@@ -959,1 +959,1 @@\n-  ReservedHeapSpace total_rs(total_reserved, alignment, page_size, AllocateHeapAt);\n+  ReservedHeapSpace rhs = HeapReserver::reserve(total_reserved, alignment, page_size, AllocateHeapAt);\n@@ -961,4 +961,5 @@\n-  if (total_rs.is_reserved()) {\n-    assert((total_reserved == total_rs.size()) && ((uintptr_t)total_rs.base() % alignment == 0),\n-           \"must be exactly of required size and alignment\");\n-    \/\/ We are good.\n+  if (!rhs.is_reserved()) {\n+    vm_exit_during_initialization(\n+      err_msg(\"Could not reserve enough space for %zu KB object heap\",\n+              total_reserved\/K));\n+  }\n@@ -966,3 +967,2 @@\n-    if (AllocateHeapAt != nullptr) {\n-      log_info(gc,heap)(\"Successfully allocated Java heap at location %s\", AllocateHeapAt);\n-    }\n+  assert(total_reserved == rhs.size(),    \"must be exactly of required size\");\n+  assert(is_aligned(rhs.base(),alignment),\"must be exactly of required alignment\");\n@@ -970,3 +970,7 @@\n-    if (UseCompressedOops) {\n-      CompressedOops::initialize(total_rs);\n-    }\n+  assert(markWord::encode_pointer_as_mark(rhs.base()).decode_pointer() == rhs.base(),\n+      \"area must be distinguishable from marks for mark-sweep\");\n+  assert(markWord::encode_pointer_as_mark(&rhs.base()[rhs.size()]).decode_pointer() ==\n+      &rhs.base()[rhs.size()],\n+      \"area must be distinguishable from marks for mark-sweep\");\n+\n+  \/\/ We are good.\n@@ -974,1 +978,3 @@\n-    Universe::calculate_verify_data((HeapWord*)total_rs.base(), (HeapWord*)total_rs.end());\n+  if (AllocateHeapAt != nullptr) {\n+    log_info(gc,heap)(\"Successfully allocated Java heap at location %s\", AllocateHeapAt);\n+  }\n@@ -976,1 +982,2 @@\n-    return total_rs;\n+  if (UseCompressedOops) {\n+    CompressedOops::initialize(rhs);\n@@ -979,3 +986,1 @@\n-  vm_exit_during_initialization(\n-    err_msg(\"Could not reserve enough space for \" SIZE_FORMAT \"KB object heap\",\n-            total_reserved\/K));\n+  Universe::calculate_verify_data((HeapWord*)rhs.base(), (HeapWord*)rhs.end());\n@@ -983,3 +988,1 @@\n-  \/\/ satisfy compiler\n-  ShouldNotReachHere();\n-  return ReservedHeapSpace(0, 0, os::vm_page_size());\n+  return rhs;\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":26,"deletions":23,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -199,4 +198,0 @@\n-}\n-\n-jint ArrayKlass::compute_modifier_flags() const {\n-  return JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC;\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -121,4 +121,0 @@\n-\n-  \/\/ jvm support\n-  jint compute_modifier_flags() const;\n-\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -33,0 +32,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -102,1 +102,1 @@\n-  const address encoding_end = _base + nth_bit(narrow_klass_pointer_bits() + _shift);\n+  const address encoding_end = (address)(p2u(_base) + (uintptr_t)nth_bit(narrow_klass_pointer_bits() + _shift));\n@@ -183,0 +183,6 @@\n+  \/\/ This has already been checked for SharedBaseAddress and if this fails, it's a bug in the allocation code.\n+  if (!set_klass_decode_mode()) {\n+    fatal(\"base=\" PTR_FORMAT \" given with shift %d, cannot be used to encode class pointers\",\n+          p2i(_base), _shift);\n+  }\n+\n@@ -226,1 +232,1 @@\n-           \"klass range size exceeds encoding, len: \" SIZE_FORMAT \", narrow_klass_pointer_bits: %d, max_shift: %d\", len, narrow_klass_pointer_bits(), max_shift());\n+           \"klass range size exceeds encoding, len: %zu, narrow_klass_pointer_bits: %d, max_shift: %d\", len, narrow_klass_pointer_bits(), max_shift());\n@@ -279,0 +285,14 @@\n+  \/\/ Initialize klass decode mode and check compability with decode instructions\n+  if (!set_klass_decode_mode()) {\n+\n+    \/\/ Give fatal error if this is a specified address\n+    if (CompressedClassSpaceBaseAddress == (size_t)_base) {\n+      vm_exit_during_initialization(\n+            err_msg(\"CompressedClassSpaceBaseAddress=\" PTR_FORMAT \" given with shift %d, cannot be used to encode class pointers\",\n+                    CompressedClassSpaceBaseAddress, _shift));\n+    } else {\n+      \/\/ If this fails, it's a bug in the allocation code.\n+      fatal(\"CompressedClassSpaceBaseAddress=\" PTR_FORMAT \" given with shift %d, cannot be used to encode class pointers\",\n+            p2i(_base), _shift);\n+    }\n+  }\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.cpp","additions":24,"deletions":4,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -261,0 +261,9 @@\n+#if defined(AARCH64) && !defined(ZERO)\n+  \/\/ Check that with the given base, shift and range, aarch64 code can encode and decode the klass pointer.\n+  static bool check_klass_decode_mode(address base, int shift, const size_t range);\n+  \/\/ Called after initialization.\n+  static bool set_klass_decode_mode();\n+#else\n+  static bool check_klass_decode_mode(address base, int shift, const size_t range) { return true; }\n+  static bool set_klass_decode_mode() { return true; }\n+#endif\n","filename":"src\/hotspot\/share\/oops\/compressedKlass.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -100,1 +99,1 @@\n-#include \"utilities\/stringUtils.hpp\"\n+#include \"utilities\/nativeStackPrinter.hpp\"\n@@ -102,0 +101,1 @@\n+#include \"utilities\/stringUtils.hpp\"\n@@ -214,2 +214,4 @@\n-\/\/ Called to verify that k is a permitted subclass of this class\n-bool InstanceKlass::has_as_permitted_subclass(const InstanceKlass* k) const {\n+\/\/ Called to verify that k is a permitted subclass of this class.\n+\/\/ The incoming stringStream is used to format the messages for error logging and for the caller\n+\/\/ to use for exception throwing.\n+bool InstanceKlass::has_as_permitted_subclass(const InstanceKlass* k, stringStream& ss) const {\n@@ -223,1 +225,1 @@\n-    log_trace(class, sealed)(\"Checking for permitted subclass of %s in %s\",\n+    log_trace(class, sealed)(\"Checking for permitted subclass %s in %s\",\n@@ -229,3 +231,9 @@\n-    ResourceMark rm(current);\n-    log_trace(class, sealed)(\"Check failed for same module of permitted subclass %s and sealed class %s\",\n-                             k->external_name(), this->external_name());\n+    ss.print(\"Failed same module check: subclass %s is in module '%s' with loader %s, \"\n+             \"and sealed class %s is in module '%s' with loader %s\",\n+             k->external_name(),\n+             k->module()->name_as_C_string(),\n+             k->module()->loader_data()->loader_name_and_id(),\n+             this->external_name(),\n+             this->module()->name_as_C_string(),\n+             this->module()->loader_data()->loader_name_and_id());\n+    log_trace(class, sealed)(\" - %s\", ss.as_string());\n@@ -236,3 +244,9 @@\n-    ResourceMark rm(current);\n-    log_trace(class, sealed)(\"Check failed, subclass %s not public and not in the same package as sealed class %s\",\n-                             k->external_name(), this->external_name());\n+    ss.print(\"Failed same package check: non-public subclass %s is in package '%s' with classloader %s, \"\n+             \"and sealed class %s is in package '%s' with classloader %s\",\n+             k->external_name(),\n+             k->package() != nullptr ? k->package()->name()->as_C_string() : \"unnamed\",\n+             k->module()->loader_data()->loader_name_and_id(),\n+             this->external_name(),\n+             this->package() != nullptr ? this->package()->name()->as_C_string() : \"unnamed\",\n+             this->module()->loader_data()->loader_name_and_id());\n+    log_trace(class, sealed)(\" - %s\", ss.as_string());\n@@ -250,1 +264,4 @@\n-  log_trace(class, sealed)(\"- class is NOT a permitted subclass!\");\n+\n+  ss.print(\"Failed listed permitted subclass check: class %s is not a permitted subclass of %s\",\n+           k->external_name(), this->external_name());\n+  log_trace(class, sealed)(\" - %s\", ss.as_string());\n@@ -3325,2 +3342,2 @@\n-jint InstanceKlass::compute_modifier_flags() const {\n-  jint access = access_flags().as_int();\n+u2 InstanceKlass::compute_modifier_flags() const {\n+  u2 access = access_flags().as_unsigned_short();\n@@ -3346,1 +3363,1 @@\n-  return (access & (~JVM_ACC_SUPER)) & JVM_ACC_WRITTEN_FLAGS;\n+  return (access & (~JVM_ACC_SUPER));\n@@ -3640,1 +3657,1 @@\n-  if (n >= MaxSubklassPrintSize) st->print(\"(\" INTX_FORMAT \" more klasses...)\", n - MaxSubklassPrintSize);\n+  if (n >= MaxSubklassPrintSize) st->print(\"(%zd more klasses...)\", n - MaxSubklassPrintSize);\n@@ -3792,1 +3809,1 @@\n-  st->print_cr(BULLET\"---- fields (total size \" SIZE_FORMAT \" words):\", oop_size(obj, obj->mark()));\n+  st->print_cr(BULLET\"---- fields (total size %zu words):\", oop_size(obj, obj->mark()));\n@@ -4013,8 +4030,3 @@\n-      if (os::platform_print_native_stack(&stack_stream, nullptr, buf, O_BUFLEN, lastpc)) {\n-        \/\/ We have printed the native stack in platform-specific code,\n-        \/\/ so nothing else to do in this case.\n-      } else {\n-        frame f = os::current_frame();\n-        VMError::print_native_stack(&stack_stream, f, current, true \/*print_source_info *\/,\n-                                    -1 \/* max stack_stream *\/, buf, O_BUFLEN);\n-      }\n+      NativeStackPrinter nsp(current);\n+      nsp.print_stack(&stack_stream, buf, sizeof(buf), lastpc,\n+                      true \/* print_source_info *\/, -1 \/* max stack *\/);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":38,"deletions":26,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -396,1 +396,1 @@\n-  int     field_access_flags(int index) const { return field(index).access_flags().as_int(); }\n+  int     field_access_flags(int index) const { return field(index).access_flags().as_field_flags(); }\n@@ -461,2 +461,4 @@\n-  \/\/ Called to verify that k is a permitted subclass of this class\n-  bool has_as_permitted_subclass(const InstanceKlass* k) const;\n+  \/\/ Called to verify that k is a permitted subclass of this class.\n+  \/\/ The incoming stringStream is used for logging, and for the caller to create\n+  \/\/ a detailed exception message on failure.\n+  bool has_as_permitted_subclass(const InstanceKlass* k, stringStream& ss) const;\n@@ -685,2 +687,0 @@\n-  \/\/ The flag is in access_flags so that it can be set and reset using atomic\n-  \/\/ operations, and not be reset by other misc_flag settings.\n@@ -1139,1 +1139,1 @@\n-  jint compute_modifier_flags() const;\n+  u2 compute_modifier_flags() const;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2011, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2011, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -61,1 +60,1 @@\n-  assert(base_size > 0, \"base object size must be non-zero: \" SIZE_FORMAT, base_size);\n+  assert(base_size > 0, \"base object size must be non-zero: %zu\", base_size);\n","filename":"src\/hotspot\/share\/oops\/instanceMirrorKlass.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/oops\/instanceStackChunkKlass.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -821,0 +820,13 @@\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+  _archived_mirror_index = -1;\n+  if (CDSConfig::is_dumping_heap()) {\n+    Klass* src_k = ArchiveBuilder::current()->get_source_addr(this);\n+    oop orig_mirror = src_k->java_mirror();\n+    oop scratch_mirror = HeapShared::scratch_java_mirror(orig_mirror);\n+    if (scratch_mirror != nullptr) {\n+      _archived_mirror_index = HeapShared::append_root(scratch_mirror);\n+    }\n+  }\n+#endif\n+\n@@ -904,6 +916,0 @@\n-\n-\/\/ No GC barrier\n-void Klass::set_archived_java_mirror(int mirror_index) {\n-  assert(CDSConfig::is_dumping_heap(), \"sanity\");\n-  _archived_mirror_index = mirror_index;\n-}\n@@ -1309,1 +1315,1 @@\n-    st->print_cr(\" bitmap: \" UINTX_FORMAT_X_0 \";\", _secondary_supers_bitmap);\n+    st->print_cr(\" bitmap: \" UINTX_FORMAT_X_0, _secondary_supers_bitmap);\n@@ -1335,1 +1341,1 @@\n-  assert((size_t)hash_offset_in_bytes(obj) <= (obj->base_size_given_klass(obj->mark(), this) * HeapWordSize), \"hash offset must be eq or lt base size: hash offset: %d, base size: \" SIZE_FORMAT, hash_offset_in_bytes(obj), obj->base_size_given_klass(obj->mark(), this) * HeapWordSize);\n+  assert((size_t)hash_offset_in_bytes(obj) <= (obj->base_size_given_klass(obj->mark(), this) * HeapWordSize), \"hash offset must be eq or lt base size: hash offset: %d, base size: %zu\", hash_offset_in_bytes(obj), obj->base_size_given_klass(obj->mark(), this) * HeapWordSize);\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":16,"deletions":10,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -69,1 +69,1 @@\n-  enum KlassKind {\n+  enum KlassKind : u2 {\n@@ -116,1 +116,1 @@\n-  jint        _layout_helper;\n+  jint _layout_helper;\n@@ -123,0 +123,3 @@\n+  AccessFlags _access_flags;    \/\/ Access flags. The class\/interface distinction is stored here.\n+                                \/\/ Some flags created by the JVM, not in the class file itself,\n+                                \/\/ are in _misc_flags below.\n@@ -124,1 +127,3 @@\n-  jint        _modifier_flags;\n+  u2          _modifier_flags;\n+\n+  KlassFlags  _misc_flags;\n@@ -160,0 +165,2 @@\n+  markWord _prototype_header;   \/\/ Used to initialize objects' header\n+\n@@ -164,12 +171,0 @@\n-  markWord _prototype_header;   \/\/ Used to initialize objects' header\n-\n-  int _vtable_len;              \/\/ vtable length. This field may be read very often when we\n-                                \/\/ have lots of itable dispatches (e.g., lambdas and streams).\n-                                \/\/ Keep it away from the beginning of a Klass to avoid cacheline\n-                                \/\/ contention that may happen when a nearby object is modified.\n-  AccessFlags _access_flags;    \/\/ Access flags. The class\/interface distinction is stored here.\n-                                \/\/ Some flags created by the JVM, not in the class file itself,\n-                                \/\/ are in _misc_flags below.\n-\n-  JFR_ONLY(DEFINE_TRACE_ID_FIELD;)\n-\n@@ -203,1 +198,4 @@\n-  KlassFlags  _misc_flags;\n+  int _vtable_len;              \/\/ vtable length. This field may be read very often when we\n+                                \/\/ have lots of itable dispatches (e.g., lambdas and streams).\n+                                \/\/ Keep it away from the beginning of a Klass to avoid cacheline\n+                                \/\/ contention that may happen when a nearby object is modified.\n@@ -207,0 +205,4 @@\n+public:\n+\n+  JFR_ONLY(DEFINE_TRACE_ID_FIELD;)\n+\n@@ -284,1 +286,0 @@\n-  void set_archived_java_mirror(int mirror_index) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -295,2 +296,2 @@\n-  jint modifier_flags() const          { return _modifier_flags; }\n-  void set_modifier_flags(jint flags)  { _modifier_flags = flags; }\n+  u2 modifier_flags() const          { return _modifier_flags; }\n+  void set_modifier_flags(u2 flags)  { _modifier_flags = flags; }\n@@ -760,1 +761,1 @@\n-  virtual jint compute_modifier_flags() const = 0;\n+  virtual u2 compute_modifier_flags() const = 0;\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":22,"deletions":21,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/oops\/markWord.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -209,1 +209,1 @@\n-  bool must_be_preserved(const oopDesc* obj) const {\n+  bool must_be_preserved() const {\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -143,0 +142,3 @@\n+\n+  \/\/ Compute modifier flags after bottom_klass and element_klass are initialized.\n+  set_modifier_flags(compute_modifier_flags());\n@@ -342,1 +344,1 @@\n-jint ObjArrayKlass::compute_modifier_flags() const {\n+u2 ObjArrayKlass::compute_modifier_flags() const {\n@@ -344,4 +346,2 @@\n-  if (element_klass() == nullptr) {\n-    assert(Universe::is_bootstrapping(), \"partial objArray only at startup\");\n-    return JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC;\n-  }\n+  assert (element_klass() != nullptr, \"should be initialized\");\n+\n@@ -349,1 +349,1 @@\n-  jint element_flags = bottom_klass()->compute_modifier_flags();\n+  u2 element_flags = bottom_klass()->compute_modifier_flags();\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -146,1 +146,1 @@\n-  jint compute_modifier_flags() const;\n+  u2 compute_modifier_flags() const;\n","filename":"src\/hotspot\/share\/oops\/objArrayKlass.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/oops\/objLayout.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -220,1 +220,1 @@\n-  assert(is_object_aligned(size), \"Oop size is not properly aligned: \" SIZE_FORMAT, size);\n+  assert(is_object_aligned(size), \"Oop size is not properly aligned: %zu\", size);\n@@ -235,1 +235,1 @@\n-  assert(is_object_aligned(size), \"Oop size is not properly aligned: \" SIZE_FORMAT, size);\n+  assert(is_object_aligned(size), \"Oop size is not properly aligned: %zu\", size);\n@@ -287,1 +287,1 @@\n-        tty->print_cr(\"length: \" SIZE_FORMAT, array_length);\n+        tty->print_cr(\"length: %zu\", array_length);\n@@ -291,1 +291,1 @@\n-      assert(s == klass->oop_size(this, mrk), \"wrong array object size, s: \" SIZE_FORMAT \", oop_size: \" SIZE_FORMAT, s, klass->oop_size(this, mrk));\n+      assert(s == klass->oop_size(this, mrk), \"wrong array object size, s: %zu, oop_size: %zu\", s, klass->oop_size(this, mrk));\n@@ -298,2 +298,2 @@\n-  assert(s > 0, \"Oop size must be greater than zero, not \" SIZE_FORMAT, s);\n-  assert(is_object_aligned(s), \"Oop size is not properly aligned: \" SIZE_FORMAT, s);\n+  assert(s > 0, \"Oop size must be greater than zero, not %zu\", s);\n+  assert(is_object_aligned(s), \"Oop size is not properly aligned: %zu\", s);\n@@ -539,1 +539,1 @@\n-  return m.must_be_preserved(this);\n+  return m.must_be_preserved();\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -78,0 +77,4 @@\n+u2 TypeArrayKlass::compute_modifier_flags() const {\n+  return JVM_ACC_ABSTRACT | JVM_ACC_FINAL | JVM_ACC_PUBLIC;\n+}\n+\n@@ -87,0 +90,3 @@\n+\n+  \/\/ Compute modifier flags.\n+  set_modifier_flags(compute_modifier_flags());\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -76,0 +76,2 @@\n+  u2 compute_modifier_flags() const;\n+\n","filename":"src\/hotspot\/share\/oops\/typeArrayKlass.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -614,18 +613,18 @@\n-Compile::Compile( ciEnv* ci_env, ciMethod* target, int osr_bci,\n-                  Options options, DirectiveSet* directive)\n-                : Phase(Compiler),\n-                  _compile_id(ci_env->compile_id()),\n-                  _options(options),\n-                  _method(target),\n-                  _entry_bci(osr_bci),\n-                  _ilt(nullptr),\n-                  _stub_function(nullptr),\n-                  _stub_name(nullptr),\n-                  _stub_entry_point(nullptr),\n-                  _max_node_limit(MaxNodeLimit),\n-                  _post_loop_opts_phase(false),\n-                  _allow_macro_nodes(true),\n-                  _inlining_progress(false),\n-                  _inlining_incrementally(false),\n-                  _do_cleanup(false),\n-                  _has_reserved_stack_access(target->has_reserved_stack_access()),\n+Compile::Compile(ciEnv* ci_env, ciMethod* target, int osr_bci,\n+                 Options options, DirectiveSet* directive)\n+    : Phase(Compiler),\n+      _compile_id(ci_env->compile_id()),\n+      _options(options),\n+      _method(target),\n+      _entry_bci(osr_bci),\n+      _ilt(nullptr),\n+      _stub_function(nullptr),\n+      _stub_name(nullptr),\n+      _stub_entry_point(nullptr),\n+      _max_node_limit(MaxNodeLimit),\n+      _post_loop_opts_phase(false),\n+      _allow_macro_nodes(true),\n+      _inlining_progress(false),\n+      _inlining_incrementally(false),\n+      _do_cleanup(false),\n+      _has_reserved_stack_access(target->has_reserved_stack_access()),\n@@ -633,2 +632,2 @@\n-                  _igv_idx(0),\n-                  _trace_opto_output(directive->TraceOptoOutputOption),\n+      _igv_idx(0),\n+      _trace_opto_output(directive->TraceOptoOutputOption),\n@@ -636,47 +635,44 @@\n-                  _has_method_handle_invokes(false),\n-                  _clinit_barrier_on_entry(false),\n-                  _stress_seed(0),\n-                  _comp_arena(mtCompiler),\n-                  _barrier_set_state(BarrierSet::barrier_set()->barrier_set_c2()->create_barrier_state(comp_arena())),\n-                  _env(ci_env),\n-                  _directive(directive),\n-                  _log(ci_env->log()),\n-                  _first_failure_details(nullptr),\n-                  _intrinsics        (comp_arena(), 0, 0, nullptr),\n-                  _macro_nodes       (comp_arena(), 8, 0, nullptr),\n-                  _parse_predicates  (comp_arena(), 8, 0, nullptr),\n-                  _template_assertion_predicate_opaqs (comp_arena(), 8, 0, nullptr),\n-                  _expensive_nodes   (comp_arena(), 8, 0, nullptr),\n-                  _for_post_loop_igvn(comp_arena(), 8, 0, nullptr),\n-                  _unstable_if_traps (comp_arena(), 8, 0, nullptr),\n-                  _coarsened_locks   (comp_arena(), 8, 0, nullptr),\n-                  _congraph(nullptr),\n-                  NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n-                  _unique(0),\n-                  _dead_node_count(0),\n-                  _dead_node_list(comp_arena()),\n-                  _node_arena_one(mtCompiler, Arena::Tag::tag_node),\n-                  _node_arena_two(mtCompiler, Arena::Tag::tag_node),\n-                  _node_arena(&_node_arena_one),\n-                  _mach_constant_base_node(nullptr),\n-                  _Compile_types(mtCompiler),\n-                  _initial_gvn(nullptr),\n-                  _igvn_worklist(nullptr),\n-                  _types(nullptr),\n-                  _node_hash(nullptr),\n-                  _late_inlines(comp_arena(), 2, 0, nullptr),\n-                  _string_late_inlines(comp_arena(), 2, 0, nullptr),\n-                  _boxing_late_inlines(comp_arena(), 2, 0, nullptr),\n-                  _vector_reboxing_late_inlines(comp_arena(), 2, 0, nullptr),\n-                  _late_inlines_pos(0),\n-                  _number_of_mh_late_inlines(0),\n-                  _oom(false),\n-                  _print_inlining_stream(new (mtCompiler) stringStream()),\n-                  _print_inlining_list(nullptr),\n-                  _print_inlining_idx(0),\n-                  _print_inlining_output(nullptr),\n-                  _replay_inline_data(nullptr),\n-                  _java_calls(0),\n-                  _inner_loops(0),\n-                  _interpreter_frame_size(0),\n-                  _output(nullptr)\n+      _has_method_handle_invokes(false),\n+      _clinit_barrier_on_entry(false),\n+      _stress_seed(0),\n+      _comp_arena(mtCompiler),\n+      _barrier_set_state(BarrierSet::barrier_set()->barrier_set_c2()->create_barrier_state(comp_arena())),\n+      _env(ci_env),\n+      _directive(directive),\n+      _log(ci_env->log()),\n+      _first_failure_details(nullptr),\n+      _intrinsics(comp_arena(), 0, 0, nullptr),\n+      _macro_nodes(comp_arena(), 8, 0, nullptr),\n+      _parse_predicates(comp_arena(), 8, 0, nullptr),\n+      _template_assertion_predicate_opaqs(comp_arena(), 8, 0, nullptr),\n+      _expensive_nodes(comp_arena(), 8, 0, nullptr),\n+      _for_post_loop_igvn(comp_arena(), 8, 0, nullptr),\n+      _unstable_if_traps(comp_arena(), 8, 0, nullptr),\n+      _coarsened_locks(comp_arena(), 8, 0, nullptr),\n+      _congraph(nullptr),\n+      NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n+          _unique(0),\n+      _dead_node_count(0),\n+      _dead_node_list(comp_arena()),\n+      _node_arena_one(mtCompiler, Arena::Tag::tag_node),\n+      _node_arena_two(mtCompiler, Arena::Tag::tag_node),\n+      _node_arena(&_node_arena_one),\n+      _mach_constant_base_node(nullptr),\n+      _Compile_types(mtCompiler),\n+      _initial_gvn(nullptr),\n+      _igvn_worklist(nullptr),\n+      _types(nullptr),\n+      _node_hash(nullptr),\n+      _late_inlines(comp_arena(), 2, 0, nullptr),\n+      _string_late_inlines(comp_arena(), 2, 0, nullptr),\n+      _boxing_late_inlines(comp_arena(), 2, 0, nullptr),\n+      _vector_reboxing_late_inlines(comp_arena(), 2, 0, nullptr),\n+      _late_inlines_pos(0),\n+      _number_of_mh_late_inlines(0),\n+      _oom(false),\n+      _replay_inline_data(nullptr),\n+      _inline_printer(this),\n+      _java_calls(0),\n+      _inner_loops(0),\n+      _interpreter_frame_size(0),\n+      _output(nullptr)\n@@ -684,1 +680,2 @@\n-                  , _in_dump_cnt(0)\n+      ,\n+      _in_dump_cnt(0)\n@@ -747,1 +744,0 @@\n-  print_inlining_init();\n@@ -890,22 +886,22 @@\n-Compile::Compile( ciEnv* ci_env,\n-                  TypeFunc_generator generator,\n-                  address stub_function,\n-                  const char *stub_name,\n-                  int is_fancy_jump,\n-                  bool pass_tls,\n-                  bool return_pc,\n-                  DirectiveSet* directive)\n-  : Phase(Compiler),\n-    _compile_id(0),\n-    _options(Options::for_runtime_stub()),\n-    _method(nullptr),\n-    _entry_bci(InvocationEntryBci),\n-    _stub_function(stub_function),\n-    _stub_name(stub_name),\n-    _stub_entry_point(nullptr),\n-    _max_node_limit(MaxNodeLimit),\n-    _post_loop_opts_phase(false),\n-    _allow_macro_nodes(true),\n-    _inlining_progress(false),\n-    _inlining_incrementally(false),\n-    _has_reserved_stack_access(false),\n+Compile::Compile(ciEnv* ci_env,\n+                 TypeFunc_generator generator,\n+                 address stub_function,\n+                 const char* stub_name,\n+                 int is_fancy_jump,\n+                 bool pass_tls,\n+                 bool return_pc,\n+                 DirectiveSet* directive)\n+    : Phase(Compiler),\n+      _compile_id(0),\n+      _options(Options::for_runtime_stub()),\n+      _method(nullptr),\n+      _entry_bci(InvocationEntryBci),\n+      _stub_function(stub_function),\n+      _stub_name(stub_name),\n+      _stub_entry_point(nullptr),\n+      _max_node_limit(MaxNodeLimit),\n+      _post_loop_opts_phase(false),\n+      _allow_macro_nodes(true),\n+      _inlining_progress(false),\n+      _inlining_incrementally(false),\n+      _has_reserved_stack_access(false),\n@@ -913,2 +909,2 @@\n-    _igv_idx(0),\n-    _trace_opto_output(directive->TraceOptoOutputOption),\n+      _igv_idx(0),\n+      _trace_opto_output(directive->TraceOptoOutputOption),\n@@ -916,35 +912,32 @@\n-    _has_method_handle_invokes(false),\n-    _clinit_barrier_on_entry(false),\n-    _stress_seed(0),\n-    _comp_arena(mtCompiler),\n-    _barrier_set_state(BarrierSet::barrier_set()->barrier_set_c2()->create_barrier_state(comp_arena())),\n-    _env(ci_env),\n-    _directive(directive),\n-    _log(ci_env->log()),\n-    _first_failure_details(nullptr),\n-    _for_post_loop_igvn(comp_arena(), 8, 0, nullptr),\n-    _congraph(nullptr),\n-    NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n-    _unique(0),\n-    _dead_node_count(0),\n-    _dead_node_list(comp_arena()),\n-    _node_arena_one(mtCompiler),\n-    _node_arena_two(mtCompiler),\n-    _node_arena(&_node_arena_one),\n-    _mach_constant_base_node(nullptr),\n-    _Compile_types(mtCompiler),\n-    _initial_gvn(nullptr),\n-    _igvn_worklist(nullptr),\n-    _types(nullptr),\n-    _node_hash(nullptr),\n-    _number_of_mh_late_inlines(0),\n-    _oom(false),\n-    _print_inlining_stream(new (mtCompiler) stringStream()),\n-    _print_inlining_list(nullptr),\n-    _print_inlining_idx(0),\n-    _print_inlining_output(nullptr),\n-    _replay_inline_data(nullptr),\n-    _java_calls(0),\n-    _inner_loops(0),\n-    _interpreter_frame_size(0),\n-    _output(nullptr),\n+      _has_method_handle_invokes(false),\n+      _clinit_barrier_on_entry(false),\n+      _stress_seed(0),\n+      _comp_arena(mtCompiler),\n+      _barrier_set_state(BarrierSet::barrier_set()->barrier_set_c2()->create_barrier_state(comp_arena())),\n+      _env(ci_env),\n+      _directive(directive),\n+      _log(ci_env->log()),\n+      _first_failure_details(nullptr),\n+      _for_post_loop_igvn(comp_arena(), 8, 0, nullptr),\n+      _congraph(nullptr),\n+      NOT_PRODUCT(_igv_printer(nullptr) COMMA)\n+          _unique(0),\n+      _dead_node_count(0),\n+      _dead_node_list(comp_arena()),\n+      _node_arena_one(mtCompiler),\n+      _node_arena_two(mtCompiler),\n+      _node_arena(&_node_arena_one),\n+      _mach_constant_base_node(nullptr),\n+      _Compile_types(mtCompiler),\n+      _initial_gvn(nullptr),\n+      _igvn_worklist(nullptr),\n+      _types(nullptr),\n+      _node_hash(nullptr),\n+      _number_of_mh_late_inlines(0),\n+      _oom(false),\n+      _replay_inline_data(nullptr),\n+      _inline_printer(this),\n+      _java_calls(0),\n+      _inner_loops(0),\n+      _interpreter_frame_size(0),\n+      _output(nullptr),\n@@ -952,1 +945,1 @@\n-    _in_dump_cnt(0),\n+      _in_dump_cnt(0),\n@@ -954,1 +947,1 @@\n-    _allowed_reasons(0) {\n+      _allowed_reasons(0) {\n@@ -995,1 +988,0 @@\n-  delete _print_inlining_stream;\n@@ -2116,1 +2108,1 @@\n-              cg->print_inlining_late(InliningResult::FAILURE, msg);\n+              inline_printer()->record(cg->method(), cg->call_node()->jvms(), InliningResult::FAILURE, msg);\n@@ -2236,2 +2228,0 @@\n-  print_inlining_reinit();\n-\n@@ -2488,2 +2478,0 @@\n- process_print_inlining();\n-\n@@ -2972,0 +2960,3 @@\n+    if (failing()) {\n+      return;\n+    }\n@@ -3146,0 +3137,7 @@\n+    \/\/ If the divisor input for a Div (or Mod etc.) is not zero, then the control input of the Div is set to zero.\n+    \/\/ It could be that the divisor input is found not zero because its type is narrowed down by a CastII in the\n+    \/\/ subgraph for that input. Range check CastIIs are removed during final graph reshape. To preserve the dependency\n+    \/\/ carried by a CastII, precedence edges are added to the Div node. We need to transfer the precedence edges to the\n+    \/\/ DivMod node so the dependency is not lost.\n+    divmod->add_prec_from(n);\n+    divmod->add_prec_from(d);\n@@ -3431,0 +3429,4 @@\n+  case Op_CastII: {\n+    n->as_CastII()->remove_range_check_cast(this);\n+    break;\n+  }\n@@ -3582,10 +3584,0 @@\n-#ifdef ASSERT\n-  case Op_CastII:\n-    \/\/ Verify that all range check dependent CastII nodes were removed.\n-    if (n->isa_CastII()->has_range_check()) {\n-      n->dump(3);\n-      assert(false, \"Range check dependent CastII node was not removed\");\n-    }\n-    break;\n-#endif\n-\n@@ -4439,119 +4431,1 @@\n-\/\/ The message about the current inlining is accumulated in\n-\/\/ _print_inlining_stream and transferred into the _print_inlining_list\n-\/\/ once we know whether inlining succeeds or not. For regular\n-\/\/ inlining, messages are appended to the buffer pointed by\n-\/\/ _print_inlining_idx in the _print_inlining_list. For late inlining,\n-\/\/ a new buffer is added after _print_inlining_idx in the list. This\n-\/\/ way we can update the inlining message for late inlining call site\n-\/\/ when the inlining is attempted again.\n-void Compile::print_inlining_init() {\n-  if (print_inlining() || print_intrinsics()) {\n-    \/\/ print_inlining_init is actually called several times.\n-    print_inlining_reset();\n-    _print_inlining_list = new (comp_arena())GrowableArray<PrintInliningBuffer*>(comp_arena(), 1, 1, new PrintInliningBuffer());\n-  }\n-}\n-\n-void Compile::print_inlining_reinit() {\n-  if (print_inlining() || print_intrinsics()) {\n-    print_inlining_reset();\n-  }\n-}\n-\n-void Compile::print_inlining_reset() {\n-  _print_inlining_stream->reset();\n-}\n-\n-void Compile::print_inlining_commit() {\n-  assert(print_inlining() || print_intrinsics(), \"PrintInlining off?\");\n-  \/\/ Transfer the message from _print_inlining_stream to the current\n-  \/\/ _print_inlining_list buffer and clear _print_inlining_stream.\n-  _print_inlining_list->at(_print_inlining_idx)->ss()->write(_print_inlining_stream->base(), _print_inlining_stream->size());\n-  print_inlining_reset();\n-}\n-\n-void Compile::print_inlining_push() {\n-  \/\/ Add new buffer to the _print_inlining_list at current position\n-  _print_inlining_idx++;\n-  _print_inlining_list->insert_before(_print_inlining_idx, new PrintInliningBuffer());\n-}\n-\n-Compile::PrintInliningBuffer* Compile::print_inlining_current() {\n-  return _print_inlining_list->at(_print_inlining_idx);\n-}\n-\n-void Compile::print_inlining_update(CallGenerator* cg) {\n-  if (print_inlining() || print_intrinsics()) {\n-    if (cg->is_late_inline()) {\n-      if (print_inlining_current()->cg() != cg &&\n-          (print_inlining_current()->cg() != nullptr ||\n-           print_inlining_current()->ss()->size() != 0)) {\n-        print_inlining_push();\n-      }\n-      print_inlining_commit();\n-      print_inlining_current()->set_cg(cg);\n-    } else {\n-      if (print_inlining_current()->cg() != nullptr) {\n-        print_inlining_push();\n-      }\n-      print_inlining_commit();\n-    }\n-  }\n-}\n-\n-void Compile::print_inlining_move_to(CallGenerator* cg) {\n-  \/\/ We resume inlining at a late inlining call site. Locate the\n-  \/\/ corresponding inlining buffer so that we can update it.\n-  if (print_inlining() || print_intrinsics()) {\n-    for (int i = 0; i < _print_inlining_list->length(); i++) {\n-      if (_print_inlining_list->at(i)->cg() == cg) {\n-        _print_inlining_idx = i;\n-        return;\n-      }\n-    }\n-    ShouldNotReachHere();\n-  }\n-}\n-\n-void Compile::print_inlining_update_delayed(CallGenerator* cg) {\n-  if (print_inlining() || print_intrinsics()) {\n-    assert(_print_inlining_stream->size() > 0, \"missing inlining msg\");\n-    assert(print_inlining_current()->cg() == cg, \"wrong entry\");\n-    \/\/ replace message with new message\n-    _print_inlining_list->at_put(_print_inlining_idx, new PrintInliningBuffer());\n-    print_inlining_commit();\n-    print_inlining_current()->set_cg(cg);\n-  }\n-}\n-\n-void Compile::print_inlining_assert_ready() {\n-  assert(!_print_inlining || _print_inlining_stream->size() == 0, \"losing data\");\n-}\n-\n-void Compile::process_print_inlining() {\n-  assert(_late_inlines.length() == 0, \"not drained yet\");\n-  if (print_inlining() || print_intrinsics()) {\n-    ResourceMark rm;\n-    stringStream ss;\n-    assert(_print_inlining_list != nullptr, \"process_print_inlining should be called only once.\");\n-    for (int i = 0; i < _print_inlining_list->length(); i++) {\n-      PrintInliningBuffer* pib = _print_inlining_list->at(i);\n-      ss.print(\"%s\", pib->ss()->freeze());\n-      delete pib;\n-      DEBUG_ONLY(_print_inlining_list->at_put(i, nullptr));\n-    }\n-    \/\/ Reset _print_inlining_list, it only contains destructed objects.\n-    \/\/ It is on the arena, so it will be freed when the arena is reset.\n-    _print_inlining_list = nullptr;\n-    \/\/ _print_inlining_stream won't be used anymore, either.\n-    print_inlining_reset();\n-    size_t end = ss.size();\n-    _print_inlining_output = NEW_ARENA_ARRAY(comp_arena(), char, end+1);\n-    strncpy(_print_inlining_output, ss.freeze(), end+1);\n-    _print_inlining_output[end] = 0;\n-  }\n-}\n-\n-  if (_print_inlining_output != nullptr) {\n-    tty->print_raw(_print_inlining_output);\n-  }\n+  inline_printer()->print_on(tty);\n@@ -5044,1 +4918,0 @@\n-  assert(failing_internal(), \"should be failing\");\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":141,"deletions":268,"binary":false,"changes":409,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -53,2 +52,5 @@\n-static void print_trace_type_profile(outputStream* out, int depth, ciKlass* prof_klass, int site_count, int receiver_count) {\n-  CompileTask::print_inline_indent(depth, out);\n+static void print_trace_type_profile(outputStream* out, int depth, ciKlass* prof_klass, int site_count, int receiver_count,\n+                                     bool with_deco) {\n+  if (with_deco) {\n+    CompileTask::print_inline_indent(depth, out);\n+  }\n@@ -57,1 +59,3 @@\n-  out->cr();\n+  if (with_deco) {\n+    out->cr();\n+  }\n@@ -60,2 +64,4 @@\n-static void trace_type_profile(Compile* C, ciMethod* method, int depth, int bci, ciMethod* prof_method,\n-                               ciKlass* prof_klass, int site_count, int receiver_count) {\n+static void trace_type_profile(Compile* C, ciMethod* method, JVMState* jvms,\n+                               ciMethod* prof_method, ciKlass* prof_klass, int site_count, int receiver_count) {\n+  int depth = jvms->depth() - 1;\n+  int bci = jvms->bci();\n@@ -63,1 +69,0 @@\n-    outputStream* out = tty;\n@@ -70,0 +75,1 @@\n+      print_trace_type_profile(tty, depth, prof_klass, site_count, receiver_count, true);\n@@ -71,1 +77,2 @@\n-      out = C->print_inlining_stream();\n+      auto stream = C->inline_printer()->record(method, jvms, InliningResult::SUCCESS);\n+      print_trace_type_profile(stream, depth, prof_klass, site_count, receiver_count, false);\n@@ -73,1 +80,0 @@\n-    print_trace_type_profile(out, depth, prof_klass, site_count, receiver_count);\n@@ -79,1 +85,1 @@\n-    print_trace_type_profile(&ls, depth, prof_klass, site_count, receiver_count);\n+    print_trace_type_profile(&ls, depth, prof_klass, site_count, receiver_count, true);\n@@ -298,1 +304,1 @@\n-              trace_type_profile(C, jvms->method(), jvms->depth() - 1, jvms->bci(), next_receiver_method, profile.receiver(1), site_count, profile.receiver_count(1));\n+              trace_type_profile(C, jvms->method(), jvms, next_receiver_method, profile.receiver(1), site_count, profile.receiver_count(1));\n@@ -305,1 +311,1 @@\n-              trace_type_profile(C, jvms->method(), jvms->depth() - 1, jvms->bci(), receiver_method, k, site_count, receiver_count);\n+              trace_type_profile(C, jvms->method(), jvms, receiver_method, k, site_count, receiver_count);\n@@ -308,1 +314,3 @@\n-              if (cg != nullptr)  return cg;\n+              if (cg != nullptr) {\n+                return cg;\n+              }\n@@ -375,3 +383,1 @@\n-    if (C->print_inlining()) {\n-      print_inlining(callee, jvms->depth() - 1, jvms->bci(), InliningResult::FAILURE, msg);\n-    }\n+    C->inline_printer()->record(callee, jvms, InliningResult::FAILURE, msg);\n@@ -516,2 +522,0 @@\n-  C->print_inlining_assert_ready();\n-\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":23,"deletions":19,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -985,0 +984,1 @@\n+  Node* one = _igvn->intcon(1);\n@@ -988,1 +988,1 @@\n-  Node* res_phi  = _igvn->transform(PhiNode::make(ophi->in(0), zero, TypeInt::INT));\n+  Node* res_phi = PhiNode::make(ophi->in(0), zero, TypeInt::INT);\n@@ -996,1 +996,6 @@\n-      res_phi_input = _igvn->makecon(tcmp);\n+      if ((mask == BoolTest::mask::eq && tcmp == TypeInt::CC_EQ) ||\n+          (mask == BoolTest::mask::ne && tcmp == TypeInt::CC_GT)) {\n+        res_phi_input = one;\n+      } else {\n+        res_phi_input = zero;\n+      }\n@@ -1008,1 +1013,2 @@\n-  Node* new_cmp = _igvn->transform(new CmpINode(res_phi, zero));\n+  \/\/ This CMP always compares whether the output of \"res_phi\" is TRUE as far as the \"mask\".\n+  Node* new_cmp = _igvn->transform(new CmpINode(_igvn->transform(res_phi), (mask == BoolTest::mask::eq) ? one : zero));\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -53,0 +52,1 @@\n+#include \"opto\/vectornode.hpp\"\n@@ -122,3 +122,1 @@\n-    if (C->print_intrinsics() || C->print_inlining()) {\n-      C->print_inlining(callee, jvms->depth() - 1, bci, InliningResult::SUCCESS, inline_msg);\n-    }\n+    C->inline_printer()->record(callee, jvms, InliningResult::SUCCESS, inline_msg);\n@@ -134,1 +132,0 @@\n-    C->print_inlining_update(this);\n@@ -150,3 +147,1 @@\n-    if (C->print_intrinsics() || C->print_inlining()) {\n-      C->print_inlining(callee, jvms->depth() - 1, bci, InliningResult::FAILURE, msg);\n-    }\n+    C->inline_printer()->record(callee, jvms, InliningResult::FAILURE, msg);\n@@ -167,1 +162,0 @@\n-  C->print_inlining_update(this);\n@@ -193,3 +187,2 @@\n-    if (C->print_intrinsics() || C->print_inlining()) {\n-      C->print_inlining(callee, jvms->depth() - 1, bci, InliningResult::SUCCESS, inline_msg);\n-    }\n+    C->inline_printer()->record(callee, jvms, InliningResult::SUCCESS, inline_msg);\n+\n@@ -211,3 +204,1 @@\n-    if (C->print_intrinsics() || C->print_inlining()) {\n-      C->print_inlining(kit.callee(), jvms->depth() - 1, bci, InliningResult::FAILURE, msg);\n-    }\n+    C->inline_printer()->record(kit.callee(), jvms, InliningResult::FAILURE, msg);\n@@ -223,3 +214,1 @@\n-    if (C->print_intrinsics() || C->print_inlining()) {\n-      C->print_inlining_stream()->print(\"%s\", msg);\n-    }\n+    C->inline_printer()->record(kit.callee(), jvms, InliningResult::FAILURE, msg);\n@@ -715,2 +704,0 @@\n-  case vmIntrinsics::_VectorShuffleIota:\n-    return inline_vector_shuffle_iota();\n@@ -719,4 +706,0 @@\n-  case vmIntrinsics::_VectorShuffleToVector:\n-    return inline_vector_shuffle_to_vector();\n-  case vmIntrinsics::_VectorWrapShuffleIndexes:\n-    return inline_vector_wrap_shuffle_indexes();\n@@ -2148,12 +2131,12 @@\n-  case vmIntrinsics::_numberOfLeadingZeros_i:   n = new CountLeadingZerosINode( arg);  break;\n-  case vmIntrinsics::_numberOfLeadingZeros_l:   n = new CountLeadingZerosLNode( arg);  break;\n-  case vmIntrinsics::_numberOfTrailingZeros_i:  n = new CountTrailingZerosINode(arg);  break;\n-  case vmIntrinsics::_numberOfTrailingZeros_l:  n = new CountTrailingZerosLNode(arg);  break;\n-  case vmIntrinsics::_bitCount_i:               n = new PopCountINode(          arg);  break;\n-  case vmIntrinsics::_bitCount_l:               n = new PopCountLNode(          arg);  break;\n-  case vmIntrinsics::_reverseBytes_c:           n = new ReverseBytesUSNode(nullptr, arg);  break;\n-  case vmIntrinsics::_reverseBytes_s:           n = new ReverseBytesSNode( nullptr, arg);  break;\n-  case vmIntrinsics::_reverseBytes_i:           n = new ReverseBytesINode( nullptr, arg);  break;\n-  case vmIntrinsics::_reverseBytes_l:           n = new ReverseBytesLNode( nullptr, arg);  break;\n-  case vmIntrinsics::_reverse_i:                n = new ReverseINode(nullptr, arg); break;\n-  case vmIntrinsics::_reverse_l:                n = new ReverseLNode(nullptr, arg); break;\n+  case vmIntrinsics::_numberOfLeadingZeros_i:   n = new CountLeadingZerosINode( arg); break;\n+  case vmIntrinsics::_numberOfLeadingZeros_l:   n = new CountLeadingZerosLNode( arg); break;\n+  case vmIntrinsics::_numberOfTrailingZeros_i:  n = new CountTrailingZerosINode(arg); break;\n+  case vmIntrinsics::_numberOfTrailingZeros_l:  n = new CountTrailingZerosLNode(arg); break;\n+  case vmIntrinsics::_bitCount_i:               n = new PopCountINode(          arg); break;\n+  case vmIntrinsics::_bitCount_l:               n = new PopCountLNode(          arg); break;\n+  case vmIntrinsics::_reverseBytes_c:           n = new ReverseBytesUSNode(     arg); break;\n+  case vmIntrinsics::_reverseBytes_s:           n = new ReverseBytesSNode(      arg); break;\n+  case vmIntrinsics::_reverseBytes_i:           n = new ReverseBytesINode(      arg); break;\n+  case vmIntrinsics::_reverseBytes_l:           n = new ReverseBytesLNode(      arg); break;\n+  case vmIntrinsics::_reverse_i:                n = new ReverseINode(           arg); break;\n+  case vmIntrinsics::_reverse_l:                n = new ReverseLNode(           arg); break;\n@@ -3781,0 +3764,14 @@\n+  \/\/ True branch, pin count over\/underflow.\n+  Node* pin_count_over_underflow = _gvn.transform(new IfTrueNode(iff_pin_count_over_underflow));\n+  {\n+    \/\/ Trap (but not deoptimize (Action_none)) and continue in the interpreter\n+    \/\/ which will throw IllegalStateException for pin count over\/underflow.\n+    \/\/ No memory changed so far - we can use memory create by reset_memory()\n+    \/\/ at the beginning of this intrinsic. No need to call reset_memory() again.\n+    PreserveJVMState pjvms(this);\n+    set_control(pin_count_over_underflow);\n+    uncommon_trap(Deoptimization::Reason_intrinsic,\n+                  Deoptimization::Action_none);\n+    assert(stopped(), \"invariant\");\n+  }\n+\n@@ -3792,14 +3789,1 @@\n-  Node* updated_pin_count_memory = store_to_memory(control(), pin_count_offset, next_pin_count, T_INT, MemNode::unordered);\n-\n-  \/\/ True branch, pin count over\/underflow.\n-  Node* pin_count_over_underflow = _gvn.transform(new IfTrueNode(iff_pin_count_over_underflow));\n-  {\n-    \/\/ Trap (but not deoptimize (Action_none)) and continue in the interpreter\n-    \/\/ which will throw IllegalStateException for pin count over\/underflow.\n-    PreserveJVMState pjvms(this);\n-    set_control(pin_count_over_underflow);\n-    set_all_memory(input_memory_state);\n-    uncommon_trap_exact(Deoptimization::Reason_intrinsic,\n-                        Deoptimization::Action_none);\n-    assert(stopped(), \"invariant\");\n-  }\n+  store_to_memory(control(), pin_count_offset, next_pin_count, T_INT, MemNode::unordered);\n@@ -3815,1 +3799,1 @@\n-  result_mem->init_req(_true_path, _gvn.transform(updated_pin_count_memory));\n+  result_mem->init_req(_true_path, _gvn.transform(reset_memory()));\n@@ -3879,1 +3863,1 @@\n-                                    Klass::access_flags_offset(), TypeInt::INT, T_INT);\n+                                    Klass::access_flags_offset(), TypeInt::CHAR, T_CHAR);\n@@ -3912,2 +3896,1 @@\n-    assert(is_power_of_2((int)JVM_ACC_WRITTEN_FLAGS+1), \"change next line\");\n-    return_type = TypeInt::make(0, JVM_ACC_WRITTEN_FLAGS, Type::WidenMin);\n+    return_type = TypeInt::CHAR;\n@@ -3935,1 +3918,1 @@\n-    return_type = TypeInt::INT;  \/\/ not bool!  6297094\n+    return_type = TypeInt::CHAR;\n@@ -3996,1 +3979,1 @@\n-    query_value = make_load(nullptr, p, TypeInt::INT, T_INT, MemNode::unordered);\n+    query_value = make_load(nullptr, p, TypeInt::CHAR, T_CHAR, MemNode::unordered);\n@@ -4061,1 +4044,1 @@\n-    query_value = make_load(nullptr, p, TypeInt::INT, T_INT, MemNode::unordered);\n+    query_value = make_load(nullptr, p, TypeInt::CHAR, T_CHAR, MemNode::unordered);\n@@ -4265,1 +4248,1 @@\n-                                                  bool obj_array, bool not_array) {\n+                                                  bool obj_array, bool not_array, Node** obj) {\n@@ -4307,1 +4290,13 @@\n-  return generate_fair_guard(bol, region);\n+  Node* ctrl = generate_fair_guard(bol, region);\n+  Node* is_array_ctrl = not_array ? control() : ctrl;\n+  if (obj != nullptr && is_array_ctrl != nullptr && is_array_ctrl != top()) {\n+    \/\/ Keep track of the fact that 'obj' is an array to prevent\n+    \/\/ array specific accesses from floating above the guard.\n+    Node* cast = _gvn.transform(new CastPPNode(is_array_ctrl, *obj, TypeAryPtr::BOTTOM));\n+    \/\/ Check for top because in rare cases, the type system can determine that\n+    \/\/ the object can't be an array but the layout helper check is not folded.\n+    if (!cast->is_top()) {\n+      *obj = cast;\n+    }\n+  }\n+  return ctrl;\n@@ -4402,1 +4397,1 @@\n-  Node* non_array = generate_non_array_guard(load_object_klass(array), nullptr);\n+  Node* non_array = generate_non_array_guard(load_object_klass(array), nullptr, &array);\n@@ -5285,1 +5280,1 @@\n-                    OptoRuntime::make_setmemory_Type(),\n+                    OptoRuntime::unsafe_setmemory_Type(),\n@@ -5408,1 +5403,2 @@\n-    Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)nullptr);\n+    Node* array_obj = obj;\n+    Node* array_ctl = generate_array_guard(obj_klass, (RegionNode*)nullptr, &array_obj);\n@@ -5413,1 +5409,1 @@\n-      Node* obj_length = load_array_length(obj);\n+      Node* obj_length = load_array_length(array_obj);\n@@ -5427,1 +5423,1 @@\n-          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n+          ArrayCopyNode* ac = ArrayCopyNode::make(this, true, array_obj, intcon(0), alloc_obj, intcon(0), obj_length, true, false);\n@@ -5448,1 +5444,1 @@\n-        copy_to_clone(obj, alloc_obj, array_size, true);\n+        copy_to_clone(array_obj, alloc_obj, array_size, true);\n@@ -6069,2 +6065,2 @@\n-    generate_non_array_guard(load_object_klass(src), slow_region);\n-    generate_non_array_guard(load_object_klass(dest), slow_region);\n+    generate_non_array_guard(load_object_klass(src), slow_region, &src);\n+    generate_non_array_guard(load_object_klass(dest), slow_region, &dest);\n@@ -8418,1 +8414,1 @@\n-    result = _gvn.transform(new FmaDNode(control(), a, b, c));\n+    result = _gvn.transform(new FmaDNode(a, b, c));\n@@ -8425,1 +8421,1 @@\n-    result = _gvn.transform(new FmaFNode(control(), a, b, c));\n+    result = _gvn.transform(new FmaFNode(a, b, c));\n@@ -8686,1 +8682,1 @@\n-    Node* array_ctl = generate_array_guard(klass_node, nullptr);\n+    Node* array_ctl = generate_array_guard(klass_node, nullptr, &obj);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":67,"deletions":71,"binary":false,"changes":138,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -433,0 +432,4 @@\n+      } else if (val->is_top()) {\n+        \/\/ This indicates that this path into the phi is dead. Top will eventually also propagate into the Region.\n+        \/\/ IGVN will clean this up later.\n+        values.at_put(j, val);\n@@ -2224,1 +2227,1 @@\n-  CallNode *call = make_slow_call((CallNode *) lock, OptoRuntime::complete_monitor_enter_Type(),\n+  CallNode* call = make_slow_call(lock, OptoRuntime::complete_monitor_enter_Type(),\n@@ -2433,0 +2436,2 @@\n+               n->Opcode() == Op_ModD ||\n+               n->Opcode() == Op_ModF ||\n@@ -2584,1 +2589,24 @@\n-      assert(false, \"unknown node type in macro list\");\n+      switch (n->Opcode()) {\n+      case Op_ModD:\n+      case Op_ModF: {\n+        bool is_drem = n->Opcode() == Op_ModD;\n+        CallNode* mod_macro = n->as_Call();\n+        CallNode* call = new CallLeafNode(mod_macro->tf(),\n+                                          is_drem ? CAST_FROM_FN_PTR(address, SharedRuntime::drem)\n+                                                  : CAST_FROM_FN_PTR(address, SharedRuntime::frem),\n+                                          is_drem ? \"drem\" : \"frem\", TypeRawPtr::BOTTOM);\n+        call->init_req(TypeFunc::Control, mod_macro->in(TypeFunc::Control));\n+        call->init_req(TypeFunc::I_O, mod_macro->in(TypeFunc::I_O));\n+        call->init_req(TypeFunc::Memory, mod_macro->in(TypeFunc::Memory));\n+        call->init_req(TypeFunc::ReturnAdr, mod_macro->in(TypeFunc::ReturnAdr));\n+        call->init_req(TypeFunc::FramePtr, mod_macro->in(TypeFunc::FramePtr));\n+        for (unsigned int i = 0; i < mod_macro->tf()->domain()->cnt() - TypeFunc::Parms; i++) {\n+          call->init_req(TypeFunc::Parms + i, mod_macro->in(TypeFunc::Parms + i));\n+        }\n+        _igvn.replace_node(mod_macro, call);\n+        transform_later(call);\n+        break;\n+      }\n+      default:\n+        assert(false, \"unknown node type in macro list\");\n+      }\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,0 @@\n-#include \"precompiled.hpp\"\n@@ -1979,1 +1978,1 @@\n-    assert(this->Opcode() == Op_LoadI, \"must load an int from _modifier_flags\");\n+    assert(Opcode() == Op_LoadUS, \"must load an unsigned short from _modifier_flags\");\n@@ -1985,1 +1984,1 @@\n-    assert(this->Opcode() == Op_LoadI, \"must load an int from _access_flags\");\n+    assert(Opcode() == Op_LoadUS, \"must load an unsigned short from _access_flags\");\n@@ -1991,1 +1990,1 @@\n-    assert(this->Opcode() == Op_LoadUB, \"must load an unsigned byte from _misc_flags\");\n+    assert(Opcode() == Op_LoadUB, \"must load an unsigned byte from _misc_flags\");\n@@ -1996,1 +1995,1 @@\n-    assert(this->Opcode() == Op_LoadI, \"must load an int from _layout_helper\");\n+    assert(Opcode() == Op_LoadI, \"must load an int from _layout_helper\");\n@@ -2017,0 +2016,11 @@\n+  \/\/ If we are loading from a freshly-allocated object, produce a zero,\n+  \/\/ if the load is provably beyond the header of the object.\n+  \/\/ (Also allow a variable load from a fresh array to produce zero.)\n+  const TypeOopPtr* tinst = tp->isa_oopptr();\n+  bool is_instance = (tinst != nullptr) && tinst->is_known_instance_field();\n+  Node* value = can_see_stored_value(mem, phase);\n+  if (value != nullptr && value->is_Con()) {\n+    assert(value->bottom_type()->higher_equal(_type), \"sanity\");\n+    return value->bottom_type();\n+  }\n+\n@@ -2223,14 +2233,0 @@\n-  \/\/ If we are loading from a freshly-allocated object, produce a zero,\n-  \/\/ if the load is provably beyond the header of the object.\n-  \/\/ (Also allow a variable load from a fresh array to produce zero.)\n-  const TypeOopPtr *tinst = tp->isa_oopptr();\n-  bool is_instance = (tinst != nullptr) && tinst->is_known_instance_field();\n-  bool is_boxed_value = (tinst != nullptr) && tinst->is_ptr_to_boxed_value();\n-  if (ReduceFieldZeroing || is_instance || is_boxed_value) {\n-    Node* value = can_see_stored_value(mem,phase);\n-    if (value != nullptr && value->is_Con()) {\n-      assert(value->bottom_type()->higher_equal(_type),\"sanity\");\n-      return value->bottom_type();\n-    }\n-  }\n-\n@@ -2865,2 +2861,2 @@\n-  bool is_trace_pointer() const {\n-    return is_trace(TraceMergeStores::Tag::POINTER);\n+  bool is_trace_pointer_parsing() const {\n+    return is_trace(TraceMergeStores::Tag::POINTER_PARSING);\n@@ -2869,2 +2865,2 @@\n-  bool is_trace_aliasing() const {\n-    return is_trace(TraceMergeStores::Tag::ALIASING);\n+  bool is_trace_pointer_aliasing() const {\n+    return is_trace(TraceMergeStores::Tag::POINTER_ALIASING);\n@@ -2873,2 +2869,2 @@\n-  bool is_trace_adjacency() const {\n-    return is_trace(TraceMergeStores::Tag::ADJACENCY);\n+  bool is_trace_pointer_adjacency() const {\n+    return is_trace(TraceMergeStores::Tag::POINTER_ADJACENCY);\n@@ -2945,3 +2941,4 @@\n-  const TraceMemPointer trace(is_trace_pointer(),\n-                              is_trace_aliasing(),\n-                              is_trace_adjacency());\n+  const TraceMemPointer trace(is_trace_pointer_parsing(),\n+                              is_trace_pointer_aliasing(),\n+                              is_trace_pointer_adjacency(),\n+                              true);\n@@ -2949,2 +2946,2 @@\n-  const MemPointer pointer_use(use_store NOT_PRODUCT( COMMA trace ));\n-  const MemPointer pointer_def(def_store NOT_PRODUCT( COMMA trace ));\n+  const MemPointer pointer_use(use_store NOT_PRODUCT(COMMA trace));\n+  const MemPointer pointer_def(def_store NOT_PRODUCT(COMMA trace));\n@@ -5197,1 +5194,1 @@\n-      tty->print_cr(\"*** bad store offset at %d: \" INTX_FORMAT \" > \" INTX_FORMAT, i, last_off, st_off);\n+      tty->print_cr(\"*** bad store offset at %d: %zd > %zd\", i, last_off, st_off);\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":29,"deletions":32,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -645,1 +644,1 @@\n-  if (log)  log->done(\"parse nodes='%d' live='%d' memory='\" SIZE_FORMAT \"'\",\n+  if (log)  log->done(\"parse nodes='%d' live='%d' memory='%zu'\",\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -1099,11 +1098,3 @@\n-void Parse::modf() {\n-  Node *f2 = pop();\n-  Node *f1 = pop();\n-  Node* c = make_runtime_call(RC_LEAF, OptoRuntime::modf_Type(),\n-                              CAST_FROM_FN_PTR(address, SharedRuntime::frem),\n-                              \"frem\", nullptr, \/\/no memory effects\n-                              f1, f2);\n-  Node* res = _gvn.transform(new ProjNode(c, TypeFunc::Parms + 0));\n-\n-  push(res);\n-}\n+Node* Parse::floating_point_mod(Node* a, Node* b, BasicType type) {\n+  assert(type == BasicType::T_FLOAT || type == BasicType::T_DOUBLE, \"only float and double are floating points\");\n+  CallNode* mod = type == BasicType::T_DOUBLE ? static_cast<CallNode*>(new ModDNode(C, a, b)) : new ModFNode(C, a, b);\n@@ -1111,15 +1102,6 @@\n-void Parse::modd() {\n-  Node *d2 = pop_pair();\n-  Node *d1 = pop_pair();\n-  Node* c = make_runtime_call(RC_LEAF, OptoRuntime::Math_DD_D_Type(),\n-                              CAST_FROM_FN_PTR(address, SharedRuntime::drem),\n-                              \"drem\", nullptr, \/\/no memory effects\n-                              d1, top(), d2, top());\n-  Node* res_d   = _gvn.transform(new ProjNode(c, TypeFunc::Parms + 0));\n-\n-#ifdef ASSERT\n-  Node* res_top = _gvn.transform(new ProjNode(c, TypeFunc::Parms + 1));\n-  assert(res_top == top(), \"second value must be top\");\n-#endif\n-\n-  push_pair(res_d);\n+  Node* prev_mem = set_predefined_input_for_runtime_call(mod);\n+  mod = _gvn.transform(mod)->as_Call();\n+  set_predefined_output_for_runtime_call(mod, prev_mem, TypeRawPtr::BOTTOM);\n+  Node* result = _gvn.transform(new ProjNode(mod, TypeFunc::Parms + 0));\n+  record_for_igvn(mod);\n+  return result;\n@@ -2306,12 +2288,4 @@\n-    if (Matcher::has_match_rule(Op_ModF)) {\n-      \/\/ Generate a ModF node.\n-      b = pop();\n-      a = pop();\n-      c = _gvn.transform( new ModFNode(nullptr,a,b) );\n-      d = precision_rounding(c);\n-      push( d );\n-    }\n-    else {\n-      \/\/ Generate a call.\n-      modf();\n-    }\n+    \/\/ Generate a ModF node.\n+    b = pop();\n+    a = pop();\n+    push(floating_point_mod(a, b, BasicType::T_FLOAT));\n@@ -2439,14 +2413,4 @@\n-    if (Matcher::has_match_rule(Op_ModD)) {\n-      \/\/ Generate a ModD node.\n-      b = pop_pair();\n-      a = pop_pair();\n-      \/\/ a % b\n-\n-      c = _gvn.transform( new ModDNode(nullptr,a,b) );\n-      d = dprecision_rounding(c);\n-      push_pair( d );\n-    }\n-    else {\n-      \/\/ Generate a call.\n-      modd();\n-    }\n+    \/\/ Generate a ModD node.\n+    b = pop_pair();\n+    a = pop_pair();\n+    push_pair(floating_point_mod(a, b, BasicType::T_DOUBLE));\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":18,"deletions":54,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/opto\/parseHelper.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -195,0 +194,66 @@\n+const TypeFunc* OptoRuntime::_new_instance_Type                   = nullptr;\n+const TypeFunc* OptoRuntime::_new_array_Type                      = nullptr;\n+const TypeFunc* OptoRuntime::_multianewarray2_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_multianewarray3_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_multianewarray4_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_multianewarray5_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_multianewarrayN_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_complete_monitor_enter_Type         = nullptr;\n+const TypeFunc* OptoRuntime::_complete_monitor_exit_Type          = nullptr;\n+const TypeFunc* OptoRuntime::_monitor_notify_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_uncommon_trap_Type                  = nullptr;\n+const TypeFunc* OptoRuntime::_athrow_Type                         = nullptr;\n+const TypeFunc* OptoRuntime::_rethrow_Type                        = nullptr;\n+const TypeFunc* OptoRuntime::_Math_D_D_Type                       = nullptr;\n+const TypeFunc* OptoRuntime::_Math_DD_D_Type                      = nullptr;\n+const TypeFunc* OptoRuntime::_modf_Type                           = nullptr;\n+const TypeFunc* OptoRuntime::_l2f_Type                            = nullptr;\n+const TypeFunc* OptoRuntime::_void_long_Type                      = nullptr;\n+const TypeFunc* OptoRuntime::_void_void_Type                      = nullptr;\n+const TypeFunc* OptoRuntime::_jfr_write_checkpoint_Type           = nullptr;\n+const TypeFunc* OptoRuntime::_flush_windows_Type                  = nullptr;\n+const TypeFunc* OptoRuntime::_fast_arraycopy_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_checkcast_arraycopy_Type            = nullptr;\n+const TypeFunc* OptoRuntime::_generic_arraycopy_Type              = nullptr;\n+const TypeFunc* OptoRuntime::_slow_arraycopy_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_unsafe_setmemory_Type               = nullptr;\n+const TypeFunc* OptoRuntime::_array_fill_Type                     = nullptr;\n+const TypeFunc* OptoRuntime::_array_sort_Type                     = nullptr;\n+const TypeFunc* OptoRuntime::_array_partition_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_aescrypt_block_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_cipherBlockChaining_aescrypt_Type   = nullptr;\n+const TypeFunc* OptoRuntime::_electronicCodeBook_aescrypt_Type    = nullptr;\n+const TypeFunc* OptoRuntime::_counterMode_aescrypt_Type           = nullptr;\n+const TypeFunc* OptoRuntime::_galoisCounterMode_aescrypt_Type     = nullptr;\n+const TypeFunc* OptoRuntime::_digestBase_implCompress_with_sha3_Type      = nullptr;\n+const TypeFunc* OptoRuntime::_digestBase_implCompress_without_sha3_Type   = nullptr;\n+const TypeFunc* OptoRuntime::_digestBase_implCompressMB_with_sha3_Type    = nullptr;\n+const TypeFunc* OptoRuntime::_digestBase_implCompressMB_without_sha3_Type = nullptr;\n+const TypeFunc* OptoRuntime::_multiplyToLen_Type                  = nullptr;\n+const TypeFunc* OptoRuntime::_montgomeryMultiply_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_montgomerySquare_Type               = nullptr;\n+const TypeFunc* OptoRuntime::_squareToLen_Type                    = nullptr;\n+const TypeFunc* OptoRuntime::_mulAdd_Type                         = nullptr;\n+const TypeFunc* OptoRuntime::_bigIntegerShift_Type                = nullptr;\n+const TypeFunc* OptoRuntime::_vectorizedMismatch_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_ghash_processBlocks_Type            = nullptr;\n+const TypeFunc* OptoRuntime::_chacha20Block_Type                  = nullptr;\n+const TypeFunc* OptoRuntime::_base64_encodeBlock_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_base64_decodeBlock_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_string_IndexOf_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_poly1305_processBlocks_Type         = nullptr;\n+const TypeFunc* OptoRuntime::_intpoly_montgomeryMult_P256_Type    = nullptr;\n+const TypeFunc* OptoRuntime::_intpoly_assign_Type                 = nullptr;\n+const TypeFunc* OptoRuntime::_updateBytesCRC32_Type               = nullptr;\n+const TypeFunc* OptoRuntime::_updateBytesCRC32C_Type              = nullptr;\n+const TypeFunc* OptoRuntime::_updateBytesAdler32_Type             = nullptr;\n+const TypeFunc* OptoRuntime::_osr_end_Type                        = nullptr;\n+const TypeFunc* OptoRuntime::_register_finalizer_Type             = nullptr;\n+#if INCLUDE_JFR\n+const TypeFunc* OptoRuntime::_class_id_load_barrier_Type          = nullptr;\n+#endif \/\/ INCLUDE_JFR\n+#if INCLUDE_JVMTI\n+const TypeFunc* OptoRuntime::_notify_jvmti_vthread_Type           = nullptr;\n+#endif \/\/ INCLUDE_JVMTI\n+const TypeFunc* OptoRuntime::_dtrace_method_entry_exit_Type       = nullptr;\n+const TypeFunc* OptoRuntime::_dtrace_object_alloc_Type            = nullptr;\n@@ -501,1 +566,1 @@\n-const TypeFunc *OptoRuntime::new_instance_Type() {\n+static const TypeFunc* make_new_instance_Type() {\n@@ -517,1 +582,1 @@\n-const TypeFunc *OptoRuntime::notify_jvmti_vthread_Type() {\n+static const TypeFunc* make_notify_jvmti_vthread_Type() {\n@@ -533,1 +598,1 @@\n-const TypeFunc *OptoRuntime::athrow_Type() {\n+static const TypeFunc* make_athrow_Type() {\n@@ -547,2 +612,1 @@\n-\n-const TypeFunc *OptoRuntime::new_array_Type() {\n+static const TypeFunc* make_new_array_Type() {\n@@ -564,5 +628,1 @@\n-const TypeFunc *OptoRuntime::new_array_nozero_Type() {\n-  return new_array_Type();\n-}\n-\n-const TypeFunc *OptoRuntime::multianewarray_Type(int ndim) {\n+const TypeFunc* OptoRuntime::multianewarray_Type(int ndim) {\n@@ -585,17 +645,1 @@\n-const TypeFunc *OptoRuntime::multianewarray2_Type() {\n-  return multianewarray_Type(2);\n-}\n-\n-const TypeFunc *OptoRuntime::multianewarray3_Type() {\n-  return multianewarray_Type(3);\n-}\n-\n-const TypeFunc *OptoRuntime::multianewarray4_Type() {\n-  return multianewarray_Type(4);\n-}\n-\n-const TypeFunc *OptoRuntime::multianewarray5_Type() {\n-  return multianewarray_Type(5);\n-}\n-\n-const TypeFunc *OptoRuntime::multianewarrayN_Type() {\n+static const TypeFunc* make_multianewarrayN_Type() {\n@@ -616,1 +660,1 @@\n-const TypeFunc *OptoRuntime::uncommon_trap_Type() {\n+static const TypeFunc* make_uncommon_trap_Type() {\n@@ -631,1 +675,2 @@\n-const TypeFunc *OptoRuntime::complete_monitor_enter_Type() {\n+\n+static const TypeFunc* make_complete_monitor_enter_Type() {\n@@ -646,5 +691,2 @@\n-const TypeFunc *OptoRuntime::complete_monitor_locking_Type() {\n-  return complete_monitor_enter_Type();\n-}\n-\n-const TypeFunc *OptoRuntime::complete_monitor_exit_Type() {\n+\n+static const TypeFunc* make_complete_monitor_exit_Type() {\n@@ -667,1 +709,1 @@\n-const TypeFunc *OptoRuntime::monitor_notify_Type() {\n+static const TypeFunc* make_monitor_notify_Type() {\n@@ -679,5 +721,1 @@\n-const TypeFunc *OptoRuntime::monitor_notifyAll_Type() {\n-  return monitor_notify_Type();\n-}\n-\n-const TypeFunc* OptoRuntime::flush_windows_Type() {\n+static const TypeFunc* make_flush_windows_Type() {\n@@ -697,1 +735,1 @@\n-const TypeFunc* OptoRuntime::l2f_Type() {\n+static const TypeFunc* make_l2f_Type() {\n@@ -712,1 +750,1 @@\n-const TypeFunc* OptoRuntime::modf_Type() {\n+static const TypeFunc* make_modf_Type() {\n@@ -727,1 +765,1 @@\n-const TypeFunc *OptoRuntime::Math_D_D_Type() {\n+static const TypeFunc* make_Math_D_D_Type() {\n@@ -744,1 +782,1 @@\n-const TypeFunc *OptoRuntime::Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type) {\n+const TypeFunc* OptoRuntime::Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type) {\n@@ -763,1 +801,1 @@\n-const TypeFunc* OptoRuntime::Math_DD_D_Type() {\n+static const TypeFunc* make_Math_DD_D_Type() {\n@@ -782,1 +820,1 @@\n-const TypeFunc* OptoRuntime::void_long_Type() {\n+static const TypeFunc* make_void_long_Type() {\n@@ -796,4 +834,4 @@\n-const TypeFunc* OptoRuntime::void_void_Type() {\n-   \/\/ create input type (domain)\n-   const Type **fields = TypeTuple::fields(0);\n-   const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+0, fields);\n+static const TypeFunc* make_void_void_Type() {\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(0);\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+0, fields);\n@@ -801,5 +839,5 @@\n-   \/\/ create result type (range)\n-   fields = TypeTuple::fields(0);\n-   const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+0, fields);\n-   return TypeFunc::make(domain, range);\n- }\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+0, fields);\n+  return TypeFunc::make(domain, range);\n+}\n@@ -807,4 +845,4 @@\n- const TypeFunc* OptoRuntime::jfr_write_checkpoint_Type() {\n-   \/\/ create input type (domain)\n-   const Type **fields = TypeTuple::fields(0);\n-   const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms, fields);\n+static const TypeFunc* make_jfr_write_checkpoint_Type() {\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(0);\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms, fields);\n@@ -812,5 +850,5 @@\n-   \/\/ create result type (range)\n-   fields = TypeTuple::fields(0);\n-   const TypeTuple *range = TypeTuple::make(TypeFunc::Parms, fields);\n-   return TypeFunc::make(domain, range);\n- }\n+  \/\/ create result type (range)\n+  fields = TypeTuple::fields(0);\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms, fields);\n+  return TypeFunc::make(domain, range);\n+}\n@@ -823,1 +861,2 @@\n-const TypeFunc* OptoRuntime::make_setmemory_Type() {\n+\n+static const TypeFunc* make_setmemory_Type() {\n@@ -888,23 +927,1 @@\n-const TypeFunc* OptoRuntime::fast_arraycopy_Type() {\n-  \/\/ This signature is simple:  Two base pointers and a size_t.\n-  return make_arraycopy_Type(ac_fast);\n-}\n-\n-const TypeFunc* OptoRuntime::checkcast_arraycopy_Type() {\n-  \/\/ An extension of fast_arraycopy_Type which adds type checking.\n-  return make_arraycopy_Type(ac_checkcast);\n-}\n-\n-const TypeFunc* OptoRuntime::slow_arraycopy_Type() {\n-  \/\/ This signature is exactly the same as System.arraycopy.\n-  \/\/ There are no intptr_t (int\/long) arguments.\n-  return make_arraycopy_Type(ac_slow);\n-}\n-\n-const TypeFunc* OptoRuntime::generic_arraycopy_Type() {\n-  \/\/ This signature is like System.arraycopy, except that it returns status.\n-  return make_arraycopy_Type(ac_generic);\n-}\n-\n-\n-const TypeFunc* OptoRuntime::array_fill_Type() {\n+static const TypeFunc* make_array_fill_Type() {\n@@ -929,1 +946,1 @@\n-const TypeFunc* OptoRuntime::array_partition_Type() {\n+static const TypeFunc* make_array_partition_Type() {\n@@ -952,1 +969,1 @@\n-const TypeFunc* OptoRuntime::array_sort_Type() {\n+static const TypeFunc* make_array_sort_Type() {\n@@ -972,2 +989,1 @@\n-\/\/ for aescrypt encrypt\/decrypt operations, just three pointers returning void (length is constant)\n-const TypeFunc* OptoRuntime::aescrypt_block_Type() {\n+static const TypeFunc* make_aescrypt_block_Type() {\n@@ -992,4 +1008,1 @@\n-\/**\n- * int updateBytesCRC32(int crc, byte* b, int len)\n- *\/\n-const TypeFunc* OptoRuntime::updateBytesCRC32_Type() {\n+static const TypeFunc* make_updateBytesCRC32_Type() {\n@@ -1014,4 +1027,1 @@\n-\/**\n- * int updateBytesCRC32C(int crc, byte* buf, int len, int* table)\n- *\/\n-const TypeFunc* OptoRuntime::updateBytesCRC32C_Type() {\n+static const TypeFunc* make_updateBytesCRC32C_Type() {\n@@ -1037,4 +1047,1 @@\n-\/**\n-*  int updateBytesAdler32(int adler, bytes* b, int off, int len)\n-*\/\n-const TypeFunc* OptoRuntime::updateBytesAdler32_Type() {\n+static const TypeFunc* make_updateBytesAdler32_Type() {\n@@ -1059,2 +1066,1 @@\n-\/\/ for cipherBlockChaining calls of aescrypt encrypt\/decrypt, four pointers and a length, returning int\n-const TypeFunc* OptoRuntime::cipherBlockChaining_aescrypt_Type() {\n+static const TypeFunc* make_cipherBlockChaining_aescrypt_Type() {\n@@ -1081,2 +1087,1 @@\n-\/\/ for electronicCodeBook calls of aescrypt encrypt\/decrypt, three pointers and a length, returning int\n-const TypeFunc* OptoRuntime::electronicCodeBook_aescrypt_Type() {\n+static const TypeFunc* make_electronicCodeBook_aescrypt_Type() {\n@@ -1102,2 +1107,1 @@\n-\/\/for counterMode calls of aescrypt encrypt\/decrypt, four pointers and a length, returning int\n-const TypeFunc* OptoRuntime::counterMode_aescrypt_Type() {\n+static const TypeFunc* make_counterMode_aescrypt_Type() {\n@@ -1125,2 +1129,1 @@\n-\/\/for counterMode calls of aescrypt encrypt\/decrypt, four pointers and a length, returning int\n-const TypeFunc* OptoRuntime::galoisCounterMode_aescrypt_Type() {\n+static const TypeFunc* make_galoisCounterMode_aescrypt_Type() {\n@@ -1150,4 +1153,1 @@\n-\/*\n- * void implCompress(byte[] buf, int ofs)\n- *\/\n-const TypeFunc* OptoRuntime::digestBase_implCompress_Type(bool is_sha3) {\n+static const TypeFunc* make_digestBase_implCompress_Type(bool is_sha3) {\n@@ -1172,4 +1172,1 @@\n-\/*\n- * int implCompressMultiBlock(byte[] b, int ofs, int limit)\n- *\/\n-const TypeFunc* OptoRuntime::digestBase_implCompressMB_Type(bool is_sha3) {\n+static const TypeFunc* make_digestBase_implCompressMB_Type(bool is_sha3) {\n@@ -1196,1 +1193,1 @@\n-const TypeFunc* OptoRuntime::multiplyToLen_Type() {\n+static const TypeFunc* make_multiplyToLen_Type() {\n@@ -1217,1 +1214,1 @@\n-const TypeFunc* OptoRuntime::squareToLen_Type() {\n+static const TypeFunc* make_squareToLen_Type() {\n@@ -1237,2 +1234,1 @@\n-\/\/ for mulAdd calls, 2 pointers and 3 ints, returning int\n-const TypeFunc* OptoRuntime::mulAdd_Type() {\n+static const TypeFunc* make_mulAdd_Type() {\n@@ -1259,1 +1255,1 @@\n-const TypeFunc* OptoRuntime::montgomeryMultiply_Type() {\n+static const TypeFunc* make_montgomeryMultiply_Type() {\n@@ -1283,1 +1279,1 @@\n-const TypeFunc* OptoRuntime::montgomerySquare_Type() {\n+static const TypeFunc* make_montgomerySquare_Type() {\n@@ -1306,1 +1302,1 @@\n-const TypeFunc * OptoRuntime::bigIntegerShift_Type() {\n+static const TypeFunc* make_bigIntegerShift_Type() {\n@@ -1325,1 +1321,1 @@\n-const TypeFunc* OptoRuntime::vectorizedMismatch_Type() {\n+static const TypeFunc* make_vectorizedMismatch_Type() {\n@@ -1345,3 +1341,2 @@\n-\/\/ GHASH block processing\n-const TypeFunc* OptoRuntime::ghash_processBlocks_Type() {\n-    int argcnt = 4;\n+static const TypeFunc* make_ghash_processBlocks_Type() {\n+  int argcnt = 4;\n@@ -1349,8 +1344,8 @@\n-    const Type** fields = TypeTuple::fields(argcnt);\n-    int argp = TypeFunc::Parms;\n-    fields[argp++] = TypePtr::NOTNULL;    \/\/ state\n-    fields[argp++] = TypePtr::NOTNULL;    \/\/ subkeyH\n-    fields[argp++] = TypePtr::NOTNULL;    \/\/ data\n-    fields[argp++] = TypeInt::INT;        \/\/ blocks\n-    assert(argp == TypeFunc::Parms+argcnt, \"correct decoding\");\n-    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ state\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ subkeyH\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ data\n+  fields[argp++] = TypeInt::INT;        \/\/ blocks\n+  assert(argp == TypeFunc::Parms+argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n@@ -1358,5 +1353,5 @@\n-    \/\/ result type needed\n-    fields = TypeTuple::fields(1);\n-    fields[TypeFunc::Parms+0] = nullptr; \/\/ void\n-    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n-    return TypeFunc::make(domain, range);\n+  \/\/ result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms+0] = nullptr; \/\/ void\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+  return TypeFunc::make(domain, range);\n@@ -1365,3 +1360,2 @@\n-\/\/ ChaCha20 Block function\n-const TypeFunc* OptoRuntime::chacha20Block_Type() {\n-    int argcnt = 2;\n+static const TypeFunc* make_chacha20Block_Type() {\n+  int argcnt = 2;\n@@ -1369,4 +1363,4 @@\n-    const Type** fields = TypeTuple::fields(argcnt);\n-    int argp = TypeFunc::Parms;\n-    fields[argp++] = TypePtr::NOTNULL;      \/\/ state\n-    fields[argp++] = TypePtr::NOTNULL;      \/\/ result\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;      \/\/ state\n+  fields[argp++] = TypePtr::NOTNULL;      \/\/ result\n@@ -1374,2 +1368,2 @@\n-    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n-    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+  assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n@@ -1377,5 +1371,5 @@\n-    \/\/ result type needed\n-    fields = TypeTuple::fields(1);\n-    fields[TypeFunc::Parms + 0] = TypeInt::INT;     \/\/ key stream outlen as int\n-    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n-    return TypeFunc::make(domain, range);\n+  \/\/ result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms + 0] = TypeInt::INT;     \/\/ key stream outlen as int\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+  return TypeFunc::make(domain, range);\n@@ -1384,2 +1378,1 @@\n-\/\/ Base64 encode function\n-const TypeFunc* OptoRuntime::base64_encodeBlock_Type() {\n+static const TypeFunc* make_base64_encodeBlock_Type() {\n@@ -1406,2 +1399,1 @@\n-\/\/ String IndexOf function\n-const TypeFunc* OptoRuntime::string_IndexOf_Type() {\n+static const TypeFunc* make_string_IndexOf_Type() {\n@@ -1426,2 +1418,1 @@\n-\/\/ Base64 decode function\n-const TypeFunc* OptoRuntime::base64_decodeBlock_Type() {\n+static const TypeFunc* make_base64_decodeBlock_Type() {\n@@ -1449,2 +1440,1 @@\n-\/\/ Poly1305 processMultipleBlocks function\n-const TypeFunc* OptoRuntime::poly1305_processBlocks_Type() {\n+static const TypeFunc* make_poly1305_processBlocks_Type() {\n@@ -1469,2 +1459,1 @@\n-\/\/ MontgomeryIntegerPolynomialP256 multiply function\n-const TypeFunc* OptoRuntime::intpoly_montgomeryMult_P256_Type() {\n+static const TypeFunc* make_intpoly_montgomeryMult_P256_Type() {\n@@ -1488,2 +1477,1 @@\n-\/\/ IntegerPolynomial constant time assignment function\n-const TypeFunc* OptoRuntime::intpoly_assign_Type() {\n+static const TypeFunc* make_intpoly_assign_Type() {\n@@ -1508,2 +1496,2 @@\n-\/\/------------- Interpreter state access for on stack replacement\n-const TypeFunc* OptoRuntime::osr_end_Type() {\n+\/\/------------- Interpreter state for on stack replacement\n+static const TypeFunc* make_osr_end_Type() {\n@@ -1755,2 +1743,1 @@\n-\n-const TypeFunc *OptoRuntime::rethrow_Type() {\n+static const TypeFunc* make_rethrow_Type() {\n@@ -1806,2 +1793,1 @@\n-\n-const TypeFunc *OptoRuntime::register_finalizer_Type() {\n+static const TypeFunc* make_register_finalizer_Type() {\n@@ -1824,1 +1810,1 @@\n-const TypeFunc *OptoRuntime::class_id_load_barrier_Type() {\n+static const TypeFunc* make_class_id_load_barrier_Type() {\n@@ -1837,1 +1823,1 @@\n-#endif\n+#endif \/\/ INCLUDE_JFR\n@@ -1840,2 +1826,1 @@\n-\/\/ Dtrace support.  entry and exit probes have the same signature\n-const TypeFunc *OptoRuntime::dtrace_method_entry_exit_Type() {\n+static const TypeFunc* make_dtrace_method_entry_exit_Type() {\n@@ -1856,1 +1841,1 @@\n-const TypeFunc *OptoRuntime::dtrace_object_alloc_Type() {\n+static const TypeFunc* make_dtrace_object_alloc_Type() {\n@@ -1872,1 +1857,0 @@\n-\n@@ -1958,0 +1942,69 @@\n+void OptoRuntime::initialize_types() {\n+  _new_instance_Type                  = make_new_instance_Type();\n+  _new_array_Type                     = make_new_array_Type();\n+  _multianewarray2_Type               = multianewarray_Type(2);\n+  _multianewarray3_Type               = multianewarray_Type(3);\n+  _multianewarray4_Type               = multianewarray_Type(4);\n+  _multianewarray5_Type               = multianewarray_Type(5);\n+  _multianewarrayN_Type               = make_multianewarrayN_Type();\n+  _complete_monitor_enter_Type        = make_complete_monitor_enter_Type();\n+  _complete_monitor_exit_Type         = make_complete_monitor_exit_Type();\n+  _monitor_notify_Type                = make_monitor_notify_Type();\n+  _uncommon_trap_Type                 = make_uncommon_trap_Type();\n+  _athrow_Type                        = make_athrow_Type();\n+  _rethrow_Type                       = make_rethrow_Type();\n+  _Math_D_D_Type                      = make_Math_D_D_Type();\n+  _Math_DD_D_Type                     = make_Math_DD_D_Type();\n+  _modf_Type                          = make_modf_Type();\n+  _l2f_Type                           = make_l2f_Type();\n+  _void_long_Type                     = make_void_long_Type();\n+  _void_void_Type                     = make_void_void_Type();\n+  _jfr_write_checkpoint_Type          = make_jfr_write_checkpoint_Type();\n+  _flush_windows_Type                 = make_flush_windows_Type();\n+  _fast_arraycopy_Type                = make_arraycopy_Type(ac_fast);\n+  _checkcast_arraycopy_Type           = make_arraycopy_Type(ac_checkcast);\n+  _generic_arraycopy_Type             = make_arraycopy_Type(ac_generic);\n+  _slow_arraycopy_Type                = make_arraycopy_Type(ac_slow);\n+  _unsafe_setmemory_Type              = make_setmemory_Type();\n+  _array_fill_Type                    = make_array_fill_Type();\n+  _array_sort_Type                    = make_array_sort_Type();\n+  _array_partition_Type               = make_array_partition_Type();\n+  _aescrypt_block_Type                = make_aescrypt_block_Type();\n+  _cipherBlockChaining_aescrypt_Type  = make_cipherBlockChaining_aescrypt_Type();\n+  _electronicCodeBook_aescrypt_Type   = make_electronicCodeBook_aescrypt_Type();\n+  _counterMode_aescrypt_Type          = make_counterMode_aescrypt_Type();\n+  _galoisCounterMode_aescrypt_Type    = make_galoisCounterMode_aescrypt_Type();\n+  _digestBase_implCompress_with_sha3_Type      = make_digestBase_implCompress_Type(  \/* is_sha3= *\/ true);\n+  _digestBase_implCompress_without_sha3_Type   = make_digestBase_implCompress_Type(  \/* is_sha3= *\/ false);;\n+  _digestBase_implCompressMB_with_sha3_Type    = make_digestBase_implCompressMB_Type(\/* is_sha3= *\/ true);\n+  _digestBase_implCompressMB_without_sha3_Type = make_digestBase_implCompressMB_Type(\/* is_sha3= *\/ false);\n+  _multiplyToLen_Type                 = make_multiplyToLen_Type();\n+  _montgomeryMultiply_Type            = make_montgomeryMultiply_Type();\n+  _montgomerySquare_Type              = make_montgomerySquare_Type();\n+  _squareToLen_Type                   = make_squareToLen_Type();\n+  _mulAdd_Type                        = make_mulAdd_Type();\n+  _bigIntegerShift_Type               = make_bigIntegerShift_Type();\n+  _vectorizedMismatch_Type            = make_vectorizedMismatch_Type();\n+  _ghash_processBlocks_Type           = make_ghash_processBlocks_Type();\n+  _chacha20Block_Type                 = make_chacha20Block_Type();\n+  _base64_encodeBlock_Type            = make_base64_encodeBlock_Type();\n+  _base64_decodeBlock_Type            = make_base64_decodeBlock_Type();\n+  _string_IndexOf_Type                = make_string_IndexOf_Type();\n+  _poly1305_processBlocks_Type        = make_poly1305_processBlocks_Type();\n+  _intpoly_montgomeryMult_P256_Type   = make_intpoly_montgomeryMult_P256_Type();\n+  _intpoly_assign_Type                = make_intpoly_assign_Type();\n+  _updateBytesCRC32_Type              = make_updateBytesCRC32_Type();\n+  _updateBytesCRC32C_Type             = make_updateBytesCRC32C_Type();\n+  _updateBytesAdler32_Type            = make_updateBytesAdler32_Type();\n+  _osr_end_Type                       = make_osr_end_Type();\n+  _register_finalizer_Type            = make_register_finalizer_Type();\n+  JFR_ONLY(\n+    _class_id_load_barrier_Type       = make_class_id_load_barrier_Type();\n+  )\n+#if INCLUDE_JVMTI\n+  _notify_jvmti_vthread_Type          = make_notify_jvmti_vthread_Type();\n+#endif \/\/ INCLUDE_JVMTI\n+  _dtrace_method_entry_exit_Type      = make_dtrace_method_entry_exit_Type();\n+  _dtrace_object_alloc_Type           = make_dtrace_object_alloc_Type();\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":237,"deletions":184,"binary":false,"changes":421,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -1419,3 +1418,1 @@\n-  Node* cmov = CMoveNode::make(nullptr, this,\n-                               phase->intcon(0), phase->intcon(1),\n-                               TypeInt::BOOL);\n+  Node* cmov = CMoveNode::make(this, phase->intcon(0), phase->intcon(1), TypeInt::BOOL);\n@@ -1626,21 +1623,11 @@\n-  \/\/ Change ((x & (m - 1)) u< m) into (m > 0)\n-  \/\/ This is the off-by-one variant of ((x & m) u<= m)\n-  if (cop == Op_CmpU &&\n-      _test._test == BoolTest::lt &&\n-      cmp1_op == Op_AndI) {\n-    Node* l = cmp1->in(1);\n-    Node* r = cmp1->in(2);\n-    for (int repeat = 0; repeat < 2; repeat++) {\n-      bool match = r->Opcode() == Op_AddI && r->in(2)->find_int_con(0) == -1 &&\n-                   r->in(1) == cmp2;\n-      if (match) {\n-        \/\/ arraylength known to be non-negative, so a (arraylength != 0) is sufficient,\n-        \/\/ but to be compatible with the array range check pattern, use (arraylength u> 0)\n-        Node* ncmp = cmp2->Opcode() == Op_LoadRange\n-                     ? phase->transform(new CmpUNode(cmp2, phase->intcon(0)))\n-                     : phase->transform(new CmpINode(cmp2, phase->intcon(0)));\n-        return new BoolNode(ncmp, BoolTest::gt);\n-      } else {\n-        \/\/ commute and try again\n-        l = cmp1->in(2);\n-        r = cmp1->in(1);\n+  \/\/ Transform: \"((x & (m - 1)) <u m)\" or \"(((m - 1) & x) <u m)\" into \"(m >u 0)\"\n+  \/\/ This is case [CMPU_MASK] which is further described at the method comment of BoolNode::Value_cmpu_and_mask().\n+  if (cop == Op_CmpU && _test._test == BoolTest::lt && cmp1_op == Op_AndI) {\n+    Node* m = cmp2; \/\/ RHS: m\n+    for (int add_idx = 1; add_idx <= 2; add_idx++) { \/\/ LHS: \"(m + (-1)) & x\" or \"x & (m + (-1))\"?\n+      Node* maybe_m_minus_1 = cmp1->in(add_idx);\n+      if (maybe_m_minus_1->Opcode() == Op_AddI &&\n+          maybe_m_minus_1->in(2)->find_int_con(0) == -1 &&\n+          maybe_m_minus_1->in(1) == m) {\n+        Node* m_cmpu_0 = phase->transform(new CmpUNode(m, phase->intcon(0)));\n+        return new BoolNode(m_cmpu_0, BoolTest::gt);\n@@ -1812,3 +1799,51 @@\n-\/\/------------------------------Value------------------------------------------\n-\/\/ Change ((x & m) u<= m) or ((m & x) u<= m) to always true\n-\/\/ Same with ((x & m) u< m+1) and ((m & x) u< m+1)\n+\/\/ We use the following Lemmas\/insights for the following two transformations (1) and (2):\n+\/\/   x & y <=u y, for any x and y           (Lemma 1, masking always results in a smaller unsigned number)\n+\/\/   y <u y + 1 is always true if y != -1   (Lemma 2, (uint)(-1 + 1) == (uint)(UINT_MAX + 1) which overflows)\n+\/\/   y <u 0 is always false for any y       (Lemma 3, 0 == UINT_MIN and nothing can be smaller than that)\n+\/\/\n+\/\/ (1a) Always:     Change ((x & m) <=u m  ) or ((m & x) <=u m  ) to always true   (true by Lemma 1)\n+\/\/ (1b) If m != -1: Change ((x & m) <u  m + 1) or ((m & x) <u  m + 1) to always true:\n+\/\/    x & m <=u m          is always true   \/\/ (Lemma 1)\n+\/\/    x & m <=u m <u m + 1 is always true   \/\/ (Lemma 2: m <u m + 1, if m != -1)\n+\/\/\n+\/\/ A counter example for (1b), if we allowed m == -1:\n+\/\/     (x & m)  <u m + 1\n+\/\/     (x & -1) <u 0\n+\/\/      x       <u 0\n+\/\/   which is false for any x (Lemma 3)\n+\/\/\n+\/\/ (2) Change ((x & (m - 1)) <u m) or (((m - 1) & x) <u m) to (m >u 0)\n+\/\/ This is the off-by-one variant of the above.\n+\/\/\n+\/\/ We now prove that this replacement is correct. This is the same as proving\n+\/\/   \"m >u 0\" if and only if \"x & (m - 1) <u m\", i.e. \"m >u 0 <=> x & (m - 1) <u m\"\n+\/\/\n+\/\/ We use (Lemma 1) and (Lemma 3) from above.\n+\/\/\n+\/\/ Case \"x & (m - 1) <u m => m >u 0\":\n+\/\/   We prove this by contradiction:\n+\/\/     Assume m <=u 0 which is equivalent to m == 0:\n+\/\/   and thus\n+\/\/     x & (m - 1) <u m = 0               \/\/ m == 0\n+\/\/     y           <u     0               \/\/ y = x & (m - 1)\n+\/\/   by Lemma 3, this is always false, i.e. a contradiction to our assumption.\n+\/\/\n+\/\/ Case \"m >u 0 => x & (m - 1) <u m\":\n+\/\/   x & (m - 1) <=u (m - 1)              \/\/ (Lemma 1)\n+\/\/   x & (m - 1) <=u (m - 1) <u m         \/\/ Using assumption m >u 0, no underflow of \"m - 1\"\n+\/\/\n+\/\/\n+\/\/ Note that the signed version of \"m > 0\":\n+\/\/   m > 0 <=> x & (m - 1) <u m\n+\/\/ does not hold:\n+\/\/   Assume m == -1 and x == -1:\n+\/\/     x  & (m - 1) <u m\n+\/\/     -1 & -2      <u -1\n+\/\/     -2           <u -1\n+\/\/     UINT_MAX - 1 <u UINT_MAX           \/\/ Signed to unsigned numbers\n+\/\/ which is true while\n+\/\/   m > 0\n+\/\/ is false which is a contradiction.\n+\/\/\n+\/\/ (1a) and (1b) is covered by this method since we can directly return a true value as type while (2) is covered\n+\/\/ in BoolNode::Ideal since we create a new non-constant node (see [CMPU_MASK]).\n@@ -1822,1 +1857,1 @@\n-      Node* bound = nullptr;\n+      Node* m = nullptr;\n@@ -1824,1 +1859,2 @@\n-        bound = cmp2;\n+        \/\/ (1a) \"((x & m) <=u m)\", cmp2 = m\n+        m = cmp2;\n@@ -1826,1 +1862,7 @@\n-        bound = cmp2->in(1);\n+        \/\/ (1b) \"(x & m) <u m + 1\" and \"(m & x) <u m + 1\", cmp2 = m + 1\n+        Node* rhs_m = cmp2->in(1);\n+        const TypeInt* rhs_m_type = phase->type(rhs_m)->isa_int();\n+        if (rhs_m_type->_lo > -1 || rhs_m_type->_hi < -1) {\n+          \/\/ Exclude any case where m == -1 is possible.\n+          m = rhs_m;\n+        }\n@@ -1829,1 +1871,1 @@\n-      if (cmp1->in(2) == bound || cmp1->in(1) == bound) {\n+      if (cmp1->in(2) == m || cmp1->in(1) == m) {\n","filename":"src\/hotspot\/share\/opto\/subnode.cpp","additions":75,"deletions":33,"binary":false,"changes":108,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n","filename":"src\/hotspot\/share\/opto\/subtypenode.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -38,0 +37,2 @@\n+#include \"opto\/callnode.hpp\"\n+#include \"opto\/arraycopynode.hpp\"\n@@ -41,0 +42,1 @@\n+#include \"opto\/runtime.hpp\"\n@@ -585,0 +587,1 @@\n+  TypeAryPtr::BOTTOM = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM, TypeInt::POS), nullptr, false, Type::OffsetBot);\n@@ -713,0 +716,4 @@\n+  LockNode::initialize_lock_Type();\n+  ArrayCopyNode::initialize_arraycopy_Type();\n+  OptoRuntime::initialize_types();\n+\n@@ -4685,10 +4692,11 @@\n-const TypeAryPtr *TypeAryPtr::RANGE;\n-const TypeAryPtr *TypeAryPtr::OOPS;\n-const TypeAryPtr *TypeAryPtr::NARROWOOPS;\n-const TypeAryPtr *TypeAryPtr::BYTES;\n-const TypeAryPtr *TypeAryPtr::SHORTS;\n-const TypeAryPtr *TypeAryPtr::CHARS;\n-const TypeAryPtr *TypeAryPtr::INTS;\n-const TypeAryPtr *TypeAryPtr::LONGS;\n-const TypeAryPtr *TypeAryPtr::FLOATS;\n-const TypeAryPtr *TypeAryPtr::DOUBLES;\n+const TypeAryPtr* TypeAryPtr::BOTTOM;\n+const TypeAryPtr* TypeAryPtr::RANGE;\n+const TypeAryPtr* TypeAryPtr::OOPS;\n+const TypeAryPtr* TypeAryPtr::NARROWOOPS;\n+const TypeAryPtr* TypeAryPtr::BYTES;\n+const TypeAryPtr* TypeAryPtr::SHORTS;\n+const TypeAryPtr* TypeAryPtr::CHARS;\n+const TypeAryPtr* TypeAryPtr::INTS;\n+const TypeAryPtr* TypeAryPtr::LONGS;\n+const TypeAryPtr* TypeAryPtr::FLOATS;\n+const TypeAryPtr* TypeAryPtr::DOUBLES;\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":20,"deletions":12,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -328,0 +328,3 @@\n+  template <typename TypeClass>\n+  const TypeClass* cast() const;\n+\n@@ -1484,10 +1487,11 @@\n-  static const TypeAryPtr *RANGE;\n-  static const TypeAryPtr *OOPS;\n-  static const TypeAryPtr *NARROWOOPS;\n-  static const TypeAryPtr *BYTES;\n-  static const TypeAryPtr *SHORTS;\n-  static const TypeAryPtr *CHARS;\n-  static const TypeAryPtr *INTS;\n-  static const TypeAryPtr *LONGS;\n-  static const TypeAryPtr *FLOATS;\n-  static const TypeAryPtr *DOUBLES;\n+  static const TypeAryPtr* BOTTOM;\n+  static const TypeAryPtr* RANGE;\n+  static const TypeAryPtr* OOPS;\n+  static const TypeAryPtr* NARROWOOPS;\n+  static const TypeAryPtr* BYTES;\n+  static const TypeAryPtr* SHORTS;\n+  static const TypeAryPtr* CHARS;\n+  static const TypeAryPtr* INTS;\n+  static const TypeAryPtr* LONGS;\n+  static const TypeAryPtr* FLOATS;\n+  static const TypeAryPtr* DOUBLES;\n@@ -2180,0 +2184,9 @@\n+template <>\n+inline const TypeInt* Type::cast<TypeInt>() const {\n+  return is_int();\n+}\n+\n+template <>\n+inline const TypeLong* Type::cast<TypeLong>() const {\n+  return is_long();\n+}\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":24,"deletions":11,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -106,0 +105,1 @@\n+bool   Arguments::_has_jdwp_agent               = false;\n@@ -525,1 +525,0 @@\n-  { \"DontYieldALot\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n@@ -528,0 +527,1 @@\n+  { \"UseOprofile\",                  JDK_Version::jdk(25), JDK_Version::jdk(26), JDK_Version::jdk(27) },\n@@ -537,14 +537,1 @@\n-  { \"UseNotificationThread\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"PreserveAllAnnotations\",       JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"UseEmptySlotsInSupers\",        JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"OldSize\",                      JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-#if defined(X86)\n-  { \"UseRTMLocking\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"UseRTMDeopt\",                  JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"RTMRetryCount\",                JDK_Version::jdk(23), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-#endif \/\/ X86\n-\n-\n-  { \"BaseFootPrintEstimate\",           JDK_Version::undefined(), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"HeapFirstMaximumCompactionCount\", JDK_Version::undefined(), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n-  { \"UseVtableBasedCHA\",               JDK_Version::undefined(), JDK_Version::jdk(24), JDK_Version::jdk(25) },\n+\n@@ -1548,2 +1535,2 @@\n-          log_debug(gc, heap, coops)(\"HeapBaseMinAddress must be at least \" SIZE_FORMAT\n-                                     \" (\" SIZE_FORMAT \"G) which is greater than value given \" SIZE_FORMAT,\n+          log_debug(gc, heap, coops)(\"HeapBaseMinAddress must be at least %zu\"\n+                                     \" (%zuG) which is greater than value given %zu\",\n@@ -1574,1 +1561,1 @@\n-            \" max heap \" SIZE_FORMAT \" > compressed oop heap \" SIZE_FORMAT \". \"\n+            \" max heap %zu > compressed oop heap %zu. \"\n@@ -1585,1 +1572,1 @@\n-    log_trace(gc, heap)(\"  Maximum heap size \" SIZE_FORMAT, (size_t) reasonable_max);\n+    log_trace(gc, heap)(\"  Maximum heap size %zu\", (size_t) reasonable_max);\n@@ -1606,1 +1593,1 @@\n-      log_trace(gc, heap)(\"  Initial heap size \" SIZE_FORMAT, InitialHeapSize);\n+      log_trace(gc, heap)(\"  Initial heap size %zu\", InitialHeapSize);\n@@ -1612,1 +1599,1 @@\n-      log_trace(gc, heap)(\"  Minimum heap size \" SIZE_FORMAT, MinHeapSize);\n+      log_trace(gc, heap)(\"  Minimum heap size %zu\", MinHeapSize);\n@@ -1747,1 +1734,1 @@\n-    jio_snprintf(buffer, 1024, \"java.lang.Integer.IntegerCache.high=\" INTX_FORMAT, AutoBoxCacheMax);\n+    jio_snprintf(buffer, 1024, \"java.lang.Integer.IntegerCache.high=%zd\", AutoBoxCacheMax);\n@@ -1801,1 +1788,1 @@\n-                \"not \" SIZE_FORMAT \"\\n\",\n+                \"not %zu\\n\",\n@@ -2024,1 +2011,1 @@\n-#if !INCLUDE_JVMTI\n+#if !INCLUDE_JVMTI || INCLUDE_CDS\n@@ -2322,0 +2309,4 @@\n+#elif INCLUDE_CDS\n+        if (valid_jdwp_agent(name, is_absolute_path)) {\n+          _has_jdwp_agent = true;\n+        }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":17,"deletions":26,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,2 +25,0 @@\n-#include \"precompiled.hpp\"\n-\n","filename":"src\/hotspot\/share\/runtime\/lightweightSynchronizer.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -66,0 +65,1 @@\n+#include \"utilities\/globalCounter.inline.hpp\"\n@@ -1298,7 +1298,0 @@\n-  \/\/ Start with ceiling based on a per-thread estimate:\n-  size_t ceiling = ObjectSynchronizer::in_use_list_ceiling();\n-  size_t old_ceiling = ceiling;\n-  if (ceiling < list->max()) {\n-    \/\/ The max used by the system has exceeded the ceiling so use that:\n-    ceiling = list->max();\n-  }\n@@ -1309,11 +1302,6 @@\n-  if (NoAsyncDeflationProgressMax != 0 &&\n-      _no_progress_cnt >= NoAsyncDeflationProgressMax) {\n-    double remainder = (100.0 - MonitorUsedDeflationThreshold) \/ 100.0;\n-    size_t new_ceiling = ceiling + (size_t)((double)ceiling * remainder) + 1;\n-    ObjectSynchronizer::set_in_use_list_ceiling(new_ceiling);\n-    log_info(monitorinflation)(\"Too many deflations without progress; \"\n-                               \"bumping in_use_list_ceiling from \" SIZE_FORMAT\n-                               \" to \" SIZE_FORMAT, old_ceiling, new_ceiling);\n-    _no_progress_cnt = 0;\n-    ceiling = new_ceiling;\n-  }\n+  size_t old_ceiling = ObjectSynchronizer::in_use_list_ceiling();\n+  \/\/ Make sure that we use a ceiling value that is not lower than\n+  \/\/ previous, not lower than the recorded max used by the system, and\n+  \/\/ not lower than the current number of monitors in use (which can\n+  \/\/ race ahead of max). The result is guaranteed > 0.\n+  size_t ceiling = MAX3(old_ceiling, list->max(), monitors_used);\n@@ -1324,2 +1312,27 @@\n-    log_info(monitorinflation)(\"monitors_used=\" SIZE_FORMAT \", ceiling=\" SIZE_FORMAT\n-                               \", monitor_usage=\" SIZE_FORMAT \", threshold=%d\",\n+    \/\/ Deflate monitors if over the threshold percentage, unless no\n+    \/\/ progress on previous deflations.\n+    bool is_above_threshold = true;\n+\n+    \/\/ Check if it's time to adjust the in_use_list_ceiling up, due\n+    \/\/ to too many async deflation attempts without any progress.\n+    if (NoAsyncDeflationProgressMax != 0 &&\n+        _no_progress_cnt >= NoAsyncDeflationProgressMax) {\n+      double remainder = (100.0 - MonitorUsedDeflationThreshold) \/ 100.0;\n+      size_t delta = (size_t)(ceiling * remainder) + 1;\n+      size_t new_ceiling = (ceiling > SIZE_MAX - delta)\n+        ? SIZE_MAX         \/\/ Overflow, let's clamp new_ceiling.\n+        : ceiling + delta;\n+\n+      ObjectSynchronizer::set_in_use_list_ceiling(new_ceiling);\n+      log_info(monitorinflation)(\"Too many deflations without progress; \"\n+                                 \"bumping in_use_list_ceiling from %zu\"\n+                                 \" to %zu\", old_ceiling, new_ceiling);\n+      _no_progress_cnt = 0;\n+      ceiling = new_ceiling;\n+\n+      \/\/ Check if our monitor usage is still above the threshold:\n+      monitor_usage = (monitors_used * 100LL) \/ ceiling;\n+      is_above_threshold = int(monitor_usage) > MonitorUsedDeflationThreshold;\n+    }\n+    log_info(monitorinflation)(\"monitors_used=%zu, ceiling=%zu\"\n+                               \", monitor_usage=%zu, threshold=%d\",\n@@ -1327,1 +1340,1 @@\n-    return true;\n+    return is_above_threshold;\n@@ -1375,1 +1388,1 @@\n-    log_info(monitorinflation)(\"Async deflation needed: guaranteed interval (\" INTX_FORMAT \" ms) \"\n+    log_info(monitorinflation)(\"Async deflation needed: guaranteed interval (%zd ms) \"\n@@ -1746,1 +1759,1 @@\n-      _stream->print_cr(\"begin deflating: in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+      _stream->print_cr(\"begin deflating: in_use_list stats: ceiling=%zu, count=%zu, max=%zu\",\n@@ -1755,3 +1768,3 @@\n-      _stream->print_cr(\"before handshaking: unlinked_count=\" SIZE_FORMAT\n-                        \", in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\"\n-                        SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+      _stream->print_cr(\"before handshaking: unlinked_count=%zu\"\n+                        \", in_use_list stats: ceiling=%zu, count=\"\n+                        \"%zu, max=%zu\",\n@@ -1765,1 +1778,1 @@\n-                        SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+                        \"%zu, count=%zu, max=%zu\",\n@@ -1775,1 +1788,1 @@\n-        _stream->print_cr(\"deflated_count=\" SIZE_FORMAT \", {unlinked,deleted}_count=\" SIZE_FORMAT \" monitors in %3.7f secs\",\n+        _stream->print_cr(\"deflated_count=%zu, {unlinked,deleted}_count=%zu monitors in %3.7f secs\",\n@@ -1778,1 +1791,1 @@\n-      _stream->print_cr(\"end deflating: in_use_list stats: ceiling=\" SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+      _stream->print_cr(\"end deflating: in_use_list stats: ceiling=%zu, count=%zu, max=%zu\",\n@@ -1786,2 +1799,2 @@\n-      _stream->print_cr(\"pausing %s: %s=\" SIZE_FORMAT \", in_use_list stats: ceiling=\"\n-                        SIZE_FORMAT \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT,\n+      _stream->print_cr(\"pausing %s: %s=%zu, in_use_list stats: ceiling=\"\n+                        \"%zu, count=%zu, max=%zu\",\n@@ -1794,2 +1807,2 @@\n-      _stream->print_cr(\"resuming %s: in_use_list stats: ceiling=\" SIZE_FORMAT\n-                        \", count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT, op_name,\n+      _stream->print_cr(\"resuming %s: in_use_list stats: ceiling=%zu\"\n+                        \", count=%zu, max=%zu\", op_name,\n@@ -2022,1 +2035,1 @@\n-  out->print_cr(\"count=\" SIZE_FORMAT \", max=\" SIZE_FORMAT, l_in_use_count,\n+  out->print_cr(\"count=%zu, max=%zu\", l_in_use_count,\n@@ -2034,2 +2047,2 @@\n-    out->print_cr(\"in_use_count=\" SIZE_FORMAT \" equals ck_in_use_count=\"\n-                  SIZE_FORMAT, l_in_use_count, ck_in_use_count);\n+    out->print_cr(\"in_use_count=%zu equals ck_in_use_count=%zu\",\n+                  l_in_use_count, ck_in_use_count);\n@@ -2037,2 +2050,2 @@\n-    out->print_cr(\"WARNING: in_use_count=\" SIZE_FORMAT \" is not equal to \"\n-                  \"ck_in_use_count=\" SIZE_FORMAT, l_in_use_count,\n+    out->print_cr(\"WARNING: in_use_count=%zu is not equal to \"\n+                  \"ck_in_use_count=%zu\", l_in_use_count,\n@@ -2044,2 +2057,2 @@\n-    out->print_cr(\"in_use_max=\" SIZE_FORMAT \" equals ck_in_use_max=\"\n-                  SIZE_FORMAT, l_in_use_max, ck_in_use_max);\n+    out->print_cr(\"in_use_max=%zu equals ck_in_use_max=%zu\",\n+                  l_in_use_max, ck_in_use_max);\n@@ -2047,2 +2060,2 @@\n-    out->print_cr(\"WARNING: in_use_max=\" SIZE_FORMAT \" is not equal to \"\n-                  \"ck_in_use_max=\" SIZE_FORMAT, l_in_use_max, ck_in_use_max);\n+    out->print_cr(\"WARNING: in_use_max=%zu is not equal to \"\n+                  \"ck_in_use_max=%zu\", l_in_use_max, ck_in_use_max);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":57,"deletions":44,"binary":false,"changes":101,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,1 +25,0 @@\n-#include \"precompiled.hpp\"\n@@ -267,1 +266,1 @@\n-  nonstatic_field(Klass,                       _modifier_flags,                               jint)                                  \\\n+  nonstatic_field(Klass,                       _modifier_flags,                               u2)                                    \\\n@@ -1021,1 +1020,1 @@\n-  nonstatic_field(AccessFlags,                 _flags,                                        jint)                                  \\\n+  nonstatic_field(AccessFlags,                 _flags,                                        u2)                                    \\\n@@ -1266,0 +1265,2 @@\n+        DEBUG_ONLY(COMPILER2_OR_JVMCI_PRESENT(                            \\\n+          declare_type(DeoptimizeObjectsALotThread, JavaThread)))         \\\n@@ -2033,2 +2034,0 @@\n-  declare_constant(JVM_ACC_WRITTEN_FLAGS)                                 \\\n-                                                                          \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":6,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/debugger\/DebuggerBase.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n@@ -448,40 +448,0 @@\n-  \/\/ refer to compute_modifier_flags in VM code.\n-  public long computeModifierFlags() {\n-    long access = getAccessFlags();\n-    \/\/ But check if it happens to be member class.\n-    U2Array innerClassList = getInnerClasses();\n-    int length = (innerClassList == null)? 0 : innerClassList.length();\n-    if (length > 0) {\n-       if (Assert.ASSERTS_ENABLED) {\n-          Assert.that(length % InnerClassAttributeOffset.innerClassNextOffset == 0 ||\n-                      length % InnerClassAttributeOffset.innerClassNextOffset == EnclosingMethodAttributeOffset.enclosingMethodAttributeSize,\n-                      \"just checking\");\n-       }\n-       for (int i = 0; i < length; i += InnerClassAttributeOffset.innerClassNextOffset) {\n-          if (i == length - EnclosingMethodAttributeOffset.enclosingMethodAttributeSize) {\n-              break;\n-          }\n-          int ioff = innerClassList.at(i +\n-                         InnerClassAttributeOffset.innerClassInnerClassInfoOffset);\n-          \/\/ 'ioff' can be zero.\n-          \/\/ refer to JVM spec. section 4.7.5.\n-          if (ioff != 0) {\n-             \/\/ only look at classes that are already loaded\n-             \/\/ since we are looking for the flags for our self.\n-             Symbol name = getConstants().getKlassNameAt(ioff);\n-\n-             if (name.equals(getName())) {\n-                \/\/ This is really a member class\n-                access = innerClassList.at(i +\n-                        InnerClassAttributeOffset.innerClassAccessFlagsOffset);\n-                break;\n-             }\n-          }\n-       } \/\/ for inner classes\n-    }\n-\n-    \/\/ Remember to strip ACC_SUPER bit\n-    return (access & (~JVM_ACC_SUPER)) & JVM_ACC_WRITTEN_FLAGS;\n-  }\n-\n-\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/InstanceKlass.java","additions":1,"deletions":41,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Mark.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/oops\/Oop.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-#include \"precompiled.hpp\"\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_preservedMarks.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -24,1 +24,0 @@\n-#include \"precompiled.hpp\"\n","filename":"test\/hotspot\/gtest\/oops\/test_markWord.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -990,3 +990,3 @@\n-    @IR(counts = {IRNode.LOAD_VECTOR_B, \"= 0\",\n-                  IRNode.AND_VB, \"= 0\",\n-                  IRNode.STORE_VECTOR, \"= 0\"},\n+    @IR(counts = {IRNode.LOAD_VECTOR_B, IRNode.VECTOR_SIZE + \"min(max_byte, 4)\", \"> 0\",\n+                  IRNode.AND_VB,        IRNode.VECTOR_SIZE + \"min(max_byte, 4)\", \"> 0\",\n+                  IRNode.STORE_VECTOR,                                           \"> 0\"},\n@@ -994,0 +994,1 @@\n+        applyIf = {\"AlignVector\", \"false\"},\n@@ -997,1 +998,1 @@\n-            \/\/ Currently does not vectorize at all\n+            \/\/ Non-power-of-2 stride. Vectorization of 4 bytes, then 2-bytes gap.\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestAlignVector.java","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestIndependentPacksWithCyclicDependency.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023, 2024, Oracle and\/or its affiliates. All rights reserved.\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestScheduleReordersScalarMemops.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2024, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -37,1 +37,1 @@\n- * @bug 8326139\n+ * @bug 8326139 8348659\n@@ -701,1 +701,11 @@\n-        applyIfCPUFeatureOr = {\"sse4.1\", \"true\", \"asimd\", \"true\"})\n+        applyIfCPUFeature = {\"sse4.1\", \"true\"})\n+    \/\/ aarch64 limits minimum vector size to 8B, thus a vector size of\n+    \/\/ length 2 for type \"short\" will not be generated\n+    @IR(counts = {IRNode.LOAD_VECTOR_S, IRNode.VECTOR_SIZE_4, \"> 0\",\n+                  IRNode.LOAD_VECTOR_S, IRNode.VECTOR_SIZE_8, \"> 0\",\n+                  IRNode.ADD_VS,        IRNode.VECTOR_SIZE_8, \"> 0\",\n+                  IRNode.ADD_VS,        IRNode.VECTOR_SIZE_4, \"> 0\",\n+                  IRNode.STORE_VECTOR, \"> 0\"},\n+        applyIfAnd = {\"MaxVectorSize\", \">=32\", \"AlignVector\", \"false\"},\n+        applyIfPlatform = {\"64-bit\", \"true\"},\n+        applyIfCPUFeature = {\"sve\", \"true\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/loopopts\/superword\/TestSplitPacks.java","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -74,0 +74,27 @@\n+    private static void testFailure(String forceAddressString) throws IOException {\n+        ProcessBuilder pb = ProcessTools.createLimitedTestJavaProcessBuilder(\n+                \"-Xshare:off\", \/\/ to make CompressedClassSpaceBaseAddress work\n+                \"-XX:+UnlockDiagnosticVMOptions\",\n+                \"-XX:CompressedClassSpaceBaseAddress=\" + forceAddressString,\n+                \"-Xmx128m\",\n+                \"-Xlog:metaspace*\",\n+                \"-version\");\n+        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+\n+        output.reportDiagnosticSummary();\n+\n+        \/\/ We ignore cases where we were not able to map at the force address\n+        if (!output.contains(\"Successfully forced class space address to \" + forceAddressString)) {\n+            throw new SkippedException(\"Skipping because we cannot force ccs to \" + forceAddressString);\n+        }\n+\n+        if (Platform.isAArch64()) {\n+            output.shouldHaveExitValue(1);\n+            output.shouldContain(\"Error occurred during initialization of VM\");\n+            output.shouldContain(\"CompressedClassSpaceBaseAddress=\" + forceAddressString +\n+                                 \" given with shift 0, cannot be used to encode class pointers\");\n+        } else {\n+            output.shouldHaveExitValue(0);\n+        }\n+    }\n+\n@@ -126,0 +153,4 @@\n+\n+        \/\/ Test failure for -XX:CompressedClassBaseAddress and -Xshare:off\n+        testFailure(\"0x0000040001000000\");\n+\n","filename":"test\/hotspot\/jtreg\/runtime\/CompressedOops\/CompressedClassPointersEncodingScheme.java","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2022, 2024, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, 2025, Oracle and\/or its affiliates. All rights reserved.\n@@ -113,2 +113,2 @@\n-    static final int  INT_ARRAY_OFFSET;\n-    static final int  LONG_ARRAY_OFFSET;\n+    static final long INT_ARRAY_OFFSET;\n+    static final long LONG_ARRAY_OFFSET;\n@@ -154,1 +154,1 @@\n-        int expected_objary_offset = narrowOops ? INT_ARRAY_OFFSET : LONG_ARRAY_OFFSET;\n+        long expected_objary_offset = narrowOops ? INT_ARRAY_OFFSET : LONG_ARRAY_OFFSET;\n","filename":"test\/hotspot\/jtreg\/runtime\/FieldLayout\/BaseOffsets.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}