{"files":[{"patch":"@@ -50,0 +50,1 @@\n+import java.util.concurrent.ForkJoinWorkerThread;\n@@ -110,1 +111,5 @@\n-     * dictated by callers.\n+     * dictated by callers. All enqueue\/dequeue operations can be\n+     * handled by a single method (here, \"xfer\") with parameters\n+     * indicating whether to act as some form of offer, put, poll,\n+     * take, or transfer (each possibly with timeout), as described\n+     * below.\n@@ -129,7 +134,4 @@\n-     * tail pointers. This has led to the development of\n-     * contention-reducing variants such as elimination arrays (see\n-     * Moir et al http:\/\/portal.acm.org\/citation.cfm?id=1074013) and\n-     * optimistic back pointers (see Ladan-Mozes & Shavit\n-     * http:\/\/people.csail.mit.edu\/edya\/publications\/OptimisticFIFOQueue-journal.pdf).\n-     * However, the nature of dual queues enables a simpler tactic for\n-     * improving M&S-style implementations when dual-ness is needed.\n+     * tail pointers. To address these, dual queues with slack differ\n+     * from plain M&S dual queues by virtue of only sometimes updating\n+     * head or tail pointers when matching, appending, or even\n+     * traversing nodes.\n@@ -138,29 +140,21 @@\n-     * status. While there are other possible variants, we implement\n-     * this here as: for a data-mode node, matching entails CASing an\n-     * \"item\" field from a non-null data value to null upon match, and\n-     * vice-versa for request nodes, CASing from null to a data\n-     * value. (Note that the linearization properties of this style of\n-     * queue are easy to verify -- elements are made available by\n-     * linking, and unavailable by matching.) Compared to plain M&S\n-     * queues, this property of dual queues requires one additional\n-     * successful atomic operation per enq\/deq pair. But it also\n-     * enables lower cost variants of queue maintenance mechanics. (A\n-     * variation of this idea applies even for non-dual queues that\n-     * support deletion of interior elements, such as\n-     * j.u.c.ConcurrentLinkedQueue.)\n-     *\n-     * Once a node is matched, its match status can never again\n-     * change.  We may thus arrange that the linked list of them\n-     * contain a prefix of zero or more matched nodes, followed by a\n-     * suffix of zero or more unmatched nodes. (Note that we allow\n-     * both the prefix and suffix to be zero length, which in turn\n-     * means that we do not use a dummy header.)  If we were not\n-     * concerned with either time or space efficiency, we could\n-     * correctly perform enqueue and dequeue operations by traversing\n-     * from a pointer to the initial node; CASing the item of the\n-     * first unmatched node on match and CASing the next field of the\n-     * trailing node on appends.  While this would be a terrible idea\n-     * in itself, it does have the benefit of not requiring ANY atomic\n-     * updates on head\/tail fields.\n-     *\n-     * We introduce here an approach that lies between the extremes of\n+     * status. Matching entails CASing an \"item\" field from a non-null\n+     * data value to null upon match, and vice-versa for request\n+     * nodes, CASing from null to a data value.  (To reduce the need\n+     * for re-reads, we use the compareAndExchange forms of CAS for\n+     * pointer updates, that provide the current value to continue\n+     * with on failure.)  Note that the linearization properties of\n+     * this style of queue are easy to verify -- elements are made\n+     * available by linking, and unavailable by matching. Compared to\n+     * plain M&S queues, this property of dual queues requires one\n+     * additional successful atomic operation per enq\/deq pair. But it\n+     * also enables lower cost variants of queue maintenance\n+     * mechanics.\n+     *\n+     * Once a node is matched, it is no longer live -- its match\n+     * status can never again change.  We may thus arrange that the\n+     * linked list of them contain a prefix of zero or more dead\n+     * nodes, followed by a suffix of zero or more live nodes. Note\n+     * that we allow both the prefix and suffix to be zero length,\n+     * which in turn means that we do not require a dummy header.\n+     *\n+     * We use here an approach that lies between the extremes of\n@@ -181,34 +175,13 @@\n-     * similarly for \"tail\") is an empirical matter. We have found\n-     * that using very small constants in the range of 1-3 work best\n-     * over a range of platforms. Larger values introduce increasing\n-     * costs of cache misses and risks of long traversal chains, while\n-     * smaller values increase CAS contention and overhead.\n-     *\n-     * Dual queues with slack differ from plain M&S dual queues by\n-     * virtue of only sometimes updating head or tail pointers when\n-     * matching, appending, or even traversing nodes; in order to\n-     * maintain a targeted slack.  The idea of \"sometimes\" may be\n-     * operationalized in several ways. The simplest is to use a\n-     * per-operation counter incremented on each traversal step, and\n-     * to try (via CAS) to update the associated queue pointer\n-     * whenever the count exceeds a threshold. Another, that requires\n-     * more overhead, is to use random number generators to update\n-     * with a given probability per traversal step.\n-     *\n-     * In any strategy along these lines, because CASes updating\n-     * fields may fail, the actual slack may exceed targeted slack.\n-     * However, they may be retried at any time to maintain targets.\n-     * Even when using very small slack values, this approach works\n-     * well for dual queues because it allows all operations up to the\n-     * point of matching or appending an item (hence potentially\n-     * allowing progress by another thread) to be read-only, thus not\n-     * introducing any further contention.  As described below, we\n-     * implement this by performing slack maintenance retries only\n-     * after these points.\n-     *\n-     * As an accompaniment to such techniques, traversal overhead can\n-     * be further reduced without increasing contention of head\n-     * pointer updates: Threads may sometimes shortcut the \"next\" link\n-     * path from the current \"head\" node to be closer to the currently\n-     * known first unmatched node, and similarly for tail. Again, this\n-     * may be triggered with using thresholds or randomization.\n+     * similarly for \"tail\") is an empirical matter. Larger values\n+     * introduce increasing costs of cache misses and risks of long\n+     * traversal chains and out-of-order updates, while smaller values\n+     * increase CAS contention and overhead. Using the smallest\n+     * non-zero value of one is both simple and empirically a good\n+     * choice in most applicatkions.  The slack value is hard-wired: a\n+     * path greater than one is usually implemented by checking\n+     * equality of traversal pointers.  Because CASes updating fields\n+     * attempting to do so may stall, the writes may appear out of\n+     * order (an older CAS from the same head or tail may execute\n+     * after a newer one), the actual slack may exceed targeted\n+     * slack. To reduce impact, other threads may help update by\n+     * unsplicing dead nodes while traversing.\n@@ -220,2 +193,2 @@\n-     * (http:\/\/portal.acm.org\/citation.cfm?doid=503272.503282), if a GC\n-     * delays noticing that any arbitrarily old node has become\n+     * (http:\/\/portal.acm.org\/citation.cfm?doid=503272.503282), if a\n+     * GC delays noticing that any arbitrarily old node has become\n@@ -224,94 +197,15 @@\n-     * this in our implementation, upon CASing to advance the head\n-     * pointer, we set the \"next\" link of the previous head to point\n-     * only to itself; thus limiting the length of chains of dead nodes.\n-     * (We also take similar care to wipe out possibly garbage\n-     * retaining values held in other Node fields.)  However, doing so\n-     * adds some further complexity to traversal: If any \"next\"\n-     * pointer links to itself, it indicates that the current thread\n-     * has lagged behind a head-update, and so the traversal must\n-     * continue from the \"head\".  Traversals trying to find the\n-     * current tail starting from \"tail\" may also encounter\n-     * self-links, in which case they also continue at \"head\".\n-     *\n-     * It is tempting in slack-based scheme to not even use CAS for\n-     * updates (similarly to Ladan-Mozes & Shavit). However, this\n-     * cannot be done for head updates under the above link-forgetting\n-     * mechanics because an update may leave head at a detached node.\n-     * And while direct writes are possible for tail updates, they\n-     * increase the risk of long retraversals, and hence long garbage\n-     * chains, which can be much more costly than is worthwhile\n-     * considering that the cost difference of performing a CAS vs\n-     * write is smaller when they are not triggered on each operation\n-     * (especially considering that writes and CASes equally require\n-     * additional GC bookkeeping (\"write barriers\") that are sometimes\n-     * more costly than the writes themselves because of contention).\n-     *\n-     * *** Overview of implementation ***\n-     *\n-     * We use a threshold-based approach to updates, with a slack\n-     * threshold of two -- that is, we update head\/tail when the\n-     * current pointer appears to be two or more steps away from the\n-     * first\/last node. The slack value is hard-wired: a path greater\n-     * than one is naturally implemented by checking equality of\n-     * traversal pointers except when the list has only one element,\n-     * in which case we keep slack threshold at one. Avoiding tracking\n-     * explicit counts across method calls slightly simplifies an\n-     * already-messy implementation. Using randomization would\n-     * probably work better if there were a low-quality dirt-cheap\n-     * per-thread one available, but even ThreadLocalRandom is too\n-     * heavy for these purposes.\n-     *\n-     * With such a small slack threshold value, it is not worthwhile\n-     * to augment this with path short-circuiting (i.e., unsplicing\n-     * interior nodes) except in the case of cancellation\/removal (see\n-     * below).\n-     *\n-     * All enqueue\/dequeue operations are handled by the single method\n-     * \"xfer\" with parameters indicating whether to act as some form\n-     * of offer, put, poll, take, or transfer (each possibly with\n-     * timeout). The relative complexity of using one monolithic\n-     * method outweighs the code bulk and maintenance problems of\n-     * using separate methods for each case.\n-     *\n-     * Operation consists of up to two phases. The first is implemented\n-     * in method xfer, the second in method awaitMatch.\n-     *\n-     * 1. Traverse until matching or appending (method xfer)\n-     *\n-     *    Conceptually, we simply traverse all nodes starting from head.\n-     *    If we encounter an unmatched node of opposite mode, we match\n-     *    it and return, also updating head (by at least 2 hops) to\n-     *    one past the matched node (or the node itself if it's the\n-     *    pinned trailing node).  Traversals also check for the\n-     *    possibility of falling off-list, in which case they restart.\n-     *\n-     *    If the trailing node of the list is reached, a match is not\n-     *    possible.  If this call was untimed poll or tryTransfer\n-     *    (argument \"how\" is NOW), return empty-handed immediately.\n-     *    Else a new node is CAS-appended.  On successful append, if\n-     *    this call was ASYNC (e.g. offer), an element was\n-     *    successfully added to the end of the queue and we return.\n-     *\n-     *    Of course, this naive traversal is O(n) when no match is\n-     *    possible.  We optimize the traversal by maintaining a tail\n-     *    pointer, which is expected to be \"near\" the end of the list.\n-     *    It is only safe to fast-forward to tail (in the presence of\n-     *    arbitrary concurrent changes) if it is pointing to a node of\n-     *    the same mode, even if it is dead (in this case no preceding\n-     *    node could still be matchable by this traversal).  If we\n-     *    need to restart due to falling off-list, we can again\n-     *    fast-forward to tail, but only if it has changed since the\n-     *    last traversal (else we might loop forever).  If tail cannot\n-     *    be used, traversal starts at head (but in this case we\n-     *    expect to be able to match near head).  As with head, we\n-     *    CAS-advance the tail pointer by at least two hops.\n-     *\n-     * 2. Await match or cancellation (method awaitMatch)\n-     *\n-     *    Wait for another thread to match node; instead cancelling if\n-     *    the current thread was interrupted or the wait timed out. To\n-     *    improve performance in common single-source \/ single-sink\n-     *    usages when there are more tasks that cores, an initial\n-     *    Thread.yield is tried when there is apparently only one\n-     *    waiter.  In other cases, waiters may help with some\n-     *    bookkeeping, then park\/unpark.\n+     * this in our implementation, upon advancing the head pointer, we\n+     * set the \"next\" link of the previous head to point only to\n+     * itself; thus limiting the length of chains of dead nodes.  (We\n+     * also take similar care to wipe out possibly garbage retaining\n+     * values held in other node fields.) This is easy to accommodate\n+     * in the primary xfer method, but adds a lot of complexity to\n+     * Collection operations including traversal; mainly because if\n+     * any \"next\" pointer links to itself, the current thread has\n+     * lagged behind a head-update, and so must restart.\n+     *\n+     * *** Blocking ***\n+     *\n+     * The DualNode class is shared with class SynchronousQueue. It\n+     * houses method await, which is used for all blocking control, as\n+     * described below in DualNode internal documentation.\n@@ -333,9 +227,7 @@\n-     * appended. (2) We cannot necessarily unlink s given a\n-     * predecessor node that is matched (including the case of being\n-     * cancelled): the predecessor may already be unspliced, in which\n-     * case some previous reachable node may still point to s.\n-     * (For further explanation see Herlihy & Shavit \"The Art of\n-     * Multiprocessor Programming\" chapter 9).  Although, in both\n-     * cases, we can rule out the need for further action if either s\n-     * or its predecessor are (or can be made to be) at, or fall off\n-     * from, the head of list.\n+     * appended. (2) Unless we know it is already off-list, we cannot\n+     * necessarily unlink s given a predecessor node that is matched\n+     * (including the case of being cancelled): the predecessor may\n+     * already be unspliced, in which case some previous reachable\n+     * node may still point to s.  (For further explanation see\n+     * Herlihy & Shavit \"The Art of Multiprocessor Programming\"\n+     * chapter 9).\n@@ -353,8 +245,18 @@\n-     * won't help for case (1) anyway), we record the need to sweep the\n-     * next time any thread would otherwise block in awaitMatch. Also,\n-     * because traversal operations on the linked list of nodes are a\n-     * natural opportunity to sweep dead nodes, we generally do so,\n-     * including all the operations that might remove elements as they\n-     * traverse, such as removeIf and Iterator.remove.  This largely\n-     * eliminates long chains of dead interior nodes, except from\n-     * cancelled or timed out blocking operations.\n+     * won't help for case (1) anyway), we record a conservative\n+     * estimate of possible unsplice failures (in \"sweepVotes\").\n+     * We trigger a full sweep when the estimate exceeds a threshold\n+     * (\"SWEEP_THRESHOLD\") indicating the maximum number of estimated\n+     * removal failures to tolerate before sweeping through, unlinking\n+     * cancelled nodes that were not unlinked upon initial removal.\n+     * We perform sweeps by the thread hitting threshold (rather than\n+     * background threads or by spreading work to other threads)\n+     * because in the main contexts in which removal occurs, the\n+     * caller is timed-out or cancelled, which are not time-critical\n+     * enough to warrant the overhead that alternatives would impose\n+     * on other threads.\n+     *\n+     * Because the sweepVotes estimate is conservative, and because\n+     * nodes become unlinked \"naturally\" as they fall off the head of\n+     * the queue, and because we allow votes to accumulate even while\n+     * sweeps are in progress, there are typically significantly fewer\n+     * such nodes than estimated.\n@@ -366,0 +268,18 @@\n+     *\n+     * *** Revision notes ***\n+     *\n+     * This version differs from previous releases as follows:\n+     *\n+     * * Class DualNode replaces Qnode, with fields and methods\n+     *   that apply to any match-based dual data structure, and now\n+     *   usable in other j.u.c classes. in particular, SynchronousQueue.\n+     * * Blocking control (in class DualNode) accommodates\n+     *   VirtualThreads and (perhaps virtualized) uniprocessors.\n+     * * All fields of this class (LinkedTransferQueue) are\n+     *   default-initializable (to null), allowing further extension\n+     *   (in particular, SynchronousQueue.Transferer)\n+     * * Head and tail fields are lazily initialized rather than set\n+     *   to a dummy node, while also reducing retries under heavy\n+     *   contention and misorderings, and relaxing some accesses,\n+     *   requiring accommodation in many places (as well as\n+     *   adjustments in WhiteBox tests).\n@@ -369,19 +289,68 @@\n-     * The number of nanoseconds for which it is faster to spin\n-     * rather than to use timed park. A rough estimate suffices.\n-     * Using a power of two minus one simplifies some comparisons.\n-     *\/\n-    static final long SPIN_FOR_TIMEOUT_THRESHOLD = 1023L;\n-\n-    \/**\n-     * The maximum number of estimated removal failures (sweepVotes)\n-     * to tolerate before sweeping through the queue unlinking\n-     * cancelled nodes that were not unlinked upon initial\n-     * removal. See above for explanation. The value must be at least\n-     * two to avoid useless sweeps when removing trailing nodes.\n-     *\/\n-    static final int SWEEP_THRESHOLD = 32;\n-\n-    \/**\n-     * Queue nodes. Uses Object, not E, for items to allow forgetting\n-     * them after use.  Writes that are intrinsically ordered wrt\n-     * other accesses or CASes use simple relaxed forms.\n+     * Node for linked dual data structures. Uses type Object, not E,\n+     * for items to allow cancellation and forgetting after use. Only\n+     * field \"item\" is declared volatile (with bypasses for\n+     * pre-publication and post-match writes), although field \"next\"\n+     * is also CAS-able. Other accesses are constrained by context\n+     * (including dependent chains of next's headed by a volatile\n+     * read).\n+     *\n+     * This class also arranges blocking while awaiting matches.\n+     * Control of blocking (and thread scheduling in general) for\n+     * possibly-synchronous queues (and channels etc constructed\n+     * from them) must straddle two extremes: If there are too few\n+     * underlying cores for a fulfilling party to continue, then\n+     * the caller must park to cause a context switch. On the\n+     * other hand, if the queue is busy with approximately the\n+     * same number of independent producers and consumers, then\n+     * that context switch may cause an order-of-magnitude\n+     * slowdown. Many cases are somewhere in-between, in which\n+     * case threads should try spinning and then give up and\n+     * block. We deal with this as follows:\n+     *\n+     * 1. Callers to method await indicate eligibility for\n+     * spinning when the node is either the only waiting node, or\n+     * the next matchable node is still spinning.  Otherwise, the\n+     * caller may block (almost) immediately.\n+     *\n+     * 2. Even if eligible to spin, a caller blocks anyway in two\n+     * cases where it is normally best: If the thread isVirtual,\n+     * or the system is a uniprocessor. Uniprocessor status can\n+     * vary over time (due to virtualization at other system\n+     * levels), but checking Runtime availableProcessors can be\n+     * slow and may itself acquire blocking locks, so we only\n+     * occasionally (using ThreadLocalRandom) update when an\n+     * otherwise-eligible spin elapses.\n+     *\n+     * 3. When enabled, spins should be long enough to cover\n+     * bookeeping overhead of almost-immediate fulfillments, but\n+     * much less than the expected time of a (non-virtual)\n+     * park\/unpark context switch.  The optimal value is\n+     * unknowable, in part because the relative costs of\n+     * Thread.onSpinWait versus park\/unpark vary across platforms.\n+     * The current value is an empirical compromise across tested\n+     * platforms.\n+     *\n+     * 4. When using timed waits, callers spin instead of invoking\n+     * timed park if the remaining time is less than the likely cost\n+     * of park\/unpark. This also avoids re-parks when timed park\n+     * returns just barely too soon. As is the case in most j.u.c\n+     * blocking support, untimed waits use ManagedBlockers when\n+     * callers are ForkJoin threads, but timed waits use plain\n+     * parkNanos, under the rationale that known-to-be transient\n+     * blocking doesn't require compensation. (This decision should be\n+     * revisited here and elsewhere to deal with very long timeouts.)\n+     *\n+     * 5. Park\/unpark signalling otherwise relies on a Dekker-like\n+     * scheme in which the caller advertises the need to unpark by\n+     * setting its waiter field, followed by a full fence and recheck\n+     * before actually parking. An explicit fence in used here rather\n+     * than unnecessarily requiring volatile accesses elsewhere. This\n+     * fence also separates accesses to field isUniprocessor.\n+     *\n+     * 6. To make the above work, callers must precheck that\n+     * timeouts are not already elapsed, and that interruptible\n+     * operations were not already interrupted on call to the\n+     * corresponding queue operation.  Cancellation on timeout or\n+     * interrupt otherwise proceeds by trying to fulfill with an\n+     * impossible value (which is one reason that we use Object\n+     * types here rather than typed fields).\n@@ -389,2 +358,1 @@\n-    static final class Node implements ForkJoinPool.ManagedBlocker {\n-        final boolean isData;   \/\/ false if this is a request node\n+    static final class DualNode implements ForkJoinPool.ManagedBlocker {\n@@ -392,2 +360,3 @@\n-        volatile Node next;\n-        volatile Thread waiter; \/\/ null when not waiting for a match\n+        DualNode next;          \/\/ accessed only in chains of volatile ops\n+        Thread waiter;          \/\/ access order constrained by context\n+        final boolean isData;   \/\/ false if this is a request node\n@@ -395,8 +364,3 @@\n-        \/**\n-         * Constructs a data node holding item if item is non-null,\n-         * else a request node.  Uses relaxed write because item can\n-         * only be seen after piggy-backing publication via CAS.\n-         *\/\n-        Node(Object item) {\n-            ITEM.set(this, item);\n-            isData = (item != null);\n+        DualNode(Object item, boolean isData) {\n+            ITEM.set(this, item); \/\/ relaxed write before publication\n+            this.isData = isData;\n@@ -405,3 +369,3 @@\n-        \/** Constructs a (matched data) dummy node. *\/\n-        Node() {\n-            isData = true;\n+        \/\/ Atomic updates\n+        final Object cmpExItem(Object cmp, Object val) { \/\/ try to match\n+            return ITEM.compareAndExchange(this, cmp, val);\n@@ -409,4 +373,2 @@\n-\n-        final boolean casNext(Node cmp, Node val) {\n-            \/\/ assert val != null;\n-            return NEXT.compareAndSet(this, cmp, val);\n+        final DualNode cmpExNext(DualNode cmp, DualNode val) {\n+            return (DualNode)NEXT.compareAndExchange(this, cmp, val);\n@@ -415,5 +377,3 @@\n-        final boolean casItem(Object cmp, Object val) {\n-            \/\/ assert isData == (cmp != null);\n-            \/\/ assert isData == (val == null);\n-            \/\/ assert !(cmp instanceof Node);\n-            return ITEM.compareAndSet(this, cmp, val);\n+        \/** Returns true if this node has been matched or cancelled  *\/\n+        final boolean matched() {\n+            return isData != (item != null);\n@@ -423,2 +383,3 @@\n-         * Links node to itself to avoid garbage retention.  Called\n-         * only after CASing head field, so uses relaxed write.\n+         * Relaxed write to replace reference to user data with\n+         * self-link. Can be used only if not already null after\n+         * match.\n@@ -426,3 +387,2 @@\n-        final void selfLink() {\n-            \/\/ assert isMatched();\n-            NEXT.setRelease(this, this);\n+        final void selfLinkItem() {\n+            ITEM.set(this, this);\n@@ -431,5 +391,2 @@\n-        final void appendRelaxed(Node next) {\n-            \/\/ assert next != null;\n-            \/\/ assert this.next == null;\n-            NEXT.setOpaque(this, next);\n-        }\n+        \/** The number of times to spin when eligible *\/\n+        private static final int SPINS = 1 << 7;\n@@ -438,2 +395,2 @@\n-         * Returns true if this node has been matched, including the\n-         * case of artificial matches due to cancellation.\n+         * The number of nanoseconds for which it is faster to spin\n+         * rather than to use timed park. A rough estimate suffices.\n@@ -441,3 +398,1 @@\n-        final boolean isMatched() {\n-            return isData == (item == null);\n-        }\n+        private static final long SPIN_FOR_TIMEOUT_THRESHOLD = 1L << 10;\n@@ -445,8 +400,5 @@\n-        \/** Tries to CAS-match this node; if successful, wakes waiter. *\/\n-        final boolean tryMatch(Object cmp, Object val) {\n-            if (casItem(cmp, val)) {\n-                LockSupport.unpark(waiter);\n-                return true;\n-            }\n-            return false;\n-        }\n+        \/**\n+         * True if system is a uniprocessor, occasionally rechecked.\n+         *\/\n+        private static boolean isUniprocessor =\n+            (Runtime.getRuntime().availableProcessors() == 1);\n@@ -455,3 +407,4 @@\n-         * Returns true if a node with the given mode cannot be\n-         * appended to this node because this node is unmatched and\n-         * has opposite data mode.\n+         * Refresh rate (probablility) for updating isUniprocessor\n+         * field, to reduce the likeihood that multiple calls to await\n+         * will contend invoking Runtime.availableProcessors.  Must be\n+         * a power of two minus one.\n@@ -459,3 +412,53 @@\n-        final boolean cannotPrecede(boolean haveData) {\n-            boolean d = isData;\n-            return d != haveData && d != (item == null);\n+        private static final int UNIPROCESSOR_REFRESH_RATE = (1 << 5) - 1;\n+\n+        \/**\n+         * Possibly blocks until matched or caller gives up.\n+         *\n+         * @param e the comparison value for checking match\n+         * @param ns timeout, or Long.MAX_VALUE if untimed\n+         * @param blocker the LockSupport.setCurrentBlocker argument\n+         * @param spin true if should spin when enabled\n+         * @return matched item, or e if unmatched on interrupt or timeout\n+         *\/\n+        final Object await(Object e, long ns, Object blocker, boolean spin) {\n+            Object m;                      \/\/ the match or e if none\n+            boolean timed = (ns != Long.MAX_VALUE);\n+            long deadline = (timed) ? System.nanoTime() + ns : 0L;\n+            boolean upc = isUniprocessor;  \/\/ don't spin but later recheck\n+            Thread w = Thread.currentThread();\n+            if (w.isVirtual())             \/\/ don't spin\n+                spin = false;\n+            int spins = (spin & !upc) ? SPINS : 0; \/\/ negative when may park\n+            while ((m = item) == e) {\n+                if (spins >= 0) {\n+                    if (--spins >= 0)\n+                        Thread.onSpinWait();\n+                    else {                 \/\/ prepare to park\n+                        if (spin)          \/\/ occasionally recheck\n+                            checkForUniprocessor(upc);\n+                        LockSupport.setCurrentBlocker(blocker);\n+                        waiter = w;        \/\/ ensure ordering\n+                        VarHandle.fullFence();\n+                    }\n+                } else if (w.isInterrupted() ||\n+                           (timed &&       \/\/ try to cancel with impossible match\n+                            ((ns = deadline - System.nanoTime()) <= 0L))) {\n+                    m = cmpExItem(e, (e == null) ? this : null);\n+                    break;\n+                } else if (timed) {\n+                    if (ns < SPIN_FOR_TIMEOUT_THRESHOLD)\n+                        Thread.onSpinWait();\n+                    else\n+                        LockSupport.parkNanos(ns);\n+                } else if (w instanceof ForkJoinWorkerThread) {\n+                    try {\n+                        ForkJoinPool.managedBlock(this);\n+                    } catch (InterruptedException cannotHappen) { }\n+                } else\n+                    LockSupport.park();\n+            }\n+            if (spins < 0) {\n+                LockSupport.setCurrentBlocker(null);\n+                waiter = null;\n+            }\n+            return m;\n@@ -464,3 +467,8 @@\n-        public final boolean isReleasable() {\n-            return (isData == (item == null)) ||\n-                Thread.currentThread().isInterrupted();\n+        \/** Occasionally updates isUniprocessor field *\/\n+        private void checkForUniprocessor(boolean prev) {\n+            int r = ThreadLocalRandom.nextSecondarySeed();\n+            if ((r & UNIPROCESSOR_REFRESH_RATE) == 0) {\n+                boolean u = (Runtime.getRuntime().availableProcessors() == 1);\n+                if (u != prev)\n+                    isUniprocessor = u;\n+            }\n@@ -469,0 +477,4 @@\n+        \/\/ ManagedBlocker support\n+        public final boolean isReleasable() {\n+            return (matched() || Thread.currentThread().isInterrupted());\n+        }\n@@ -474,1 +486,16 @@\n-        private static final long serialVersionUID = -3375979862319811754L;\n+        \/\/ VarHandle mechanics\n+        static final VarHandle ITEM;\n+        static final VarHandle NEXT;\n+        static {\n+            try {\n+                Class<?> tn = DualNode.class;\n+                MethodHandles.Lookup l = MethodHandles.lookup();\n+                ITEM = l.findVarHandle(tn, \"item\", Object.class);\n+                NEXT = l.findVarHandle(tn, \"next\", tn);\n+            } catch (ReflectiveOperationException e) {\n+                throw new ExceptionInInitializerError(e);\n+            }\n+            \/\/ Reduce the risk of rare disastrous classloading in first call to\n+            \/\/ LockSupport.park: https:\/\/bugs.openjdk.org\/browse\/JDK-8074773\n+            Class<?> ensureLoaded = LockSupport.class;\n+        }\n@@ -478,2 +505,2 @@\n-     * A node from which the first live (non-matched) node (if any)\n-     * can be reached in O(1) time.\n+     * Unless empty (in which case possibly null), a node from which\n+     * all live nodes are reachable.\n@@ -481,3 +508,1 @@\n-     * - all live nodes are reachable from head via .next\n-     * - head != null\n-     * - (tmp = head).next != tmp || tmp != head\n+     * - head is never self-linked\n@@ -486,2 +511,4 @@\n-     * - it is permitted for tail to lag behind head, that is, for tail\n-     *   to not be reachable from head!\n+     *\n+     * This field is used by subclass SynchronousQueue.Transferer to\n+     * record the top of a Lifo stack, with tail always null, but\n+     * otherwise maintaining the same properties.\n@@ -489,1 +516,1 @@\n-    transient volatile Node head;\n+    transient volatile DualNode head;\n@@ -492,5 +519,3 @@\n-     * A node from which the last node on list (that is, the unique\n-     * node with node.next == null) can be reached in O(1) time.\n-     * Invariants:\n-     * - the last node is always reachable from tail via .next\n-     * - tail != null\n+     * Unless null, a node from which the last node on list (that is,\n+     * the unique node with node.next == null), if one exists, can be\n+     * reached.\n@@ -499,3 +524,3 @@\n-     * - it is permitted for tail to lag behind head, that is, for tail\n-     *   to not be reachable from head!\n-     * - tail.next may or may not be self-linked.\n+     * - tail may be the same as head\n+     * - tail may or may not be self-linked.\n+     * - tail may lag behind head, so need not be reachable from head\n@@ -503,1 +528,1 @@\n-    private transient volatile Node tail;\n+    transient volatile DualNode tail;\n@@ -506,1 +531,1 @@\n-    private transient volatile boolean needSweep;\n+    transient volatile int sweepVotes;\n@@ -508,5 +533,1 @@\n-    private boolean casTail(Node cmp, Node val) {\n-        \/\/ assert cmp != null;\n-        \/\/ assert val != null;\n-        return TAIL.compareAndSet(this, cmp, val);\n-    }\n+    \/\/ Atomic updates\n@@ -514,2 +535,5 @@\n-    private boolean casHead(Node cmp, Node val) {\n-        return HEAD.compareAndSet(this, cmp, val);\n+    final DualNode cmpExTail(DualNode cmp, DualNode val) {\n+        return (DualNode)TAIL.compareAndExchange(this, cmp, val);\n+    }\n+    final DualNode cmpExHead(DualNode cmp, DualNode val) {\n+        return (DualNode)HEAD.compareAndExchange(this, cmp, val);\n@@ -519,2 +543,4 @@\n-     * Tries to CAS pred.next (or head, if pred is null) from c to p.\n-     * Caller must ensure that we're not unlinking the trailing node.\n+     * The maximum number of estimated removal failures (sweepVotes)\n+     * to tolerate before sweeping through the queue unlinking\n+     * dead nodes that were initially pinned.  Must be a power of\n+     * two minus one, at least 3.\n@@ -522,11 +548,8 @@\n-    private boolean tryCasSuccessor(Node pred, Node c, Node p) {\n-        \/\/ assert p != null;\n-        \/\/ assert c.isData != (c.item != null);\n-        \/\/ assert c != p;\n-        if (pred != null)\n-            return pred.casNext(c, p);\n-        if (casHead(c, p)) {\n-            c.selfLink();\n-            return true;\n-        }\n-        return false;\n+    static final int SWEEP_THRESHOLD = (1 << 4) - 1;\n+\n+    \/**\n+     * Adds a sweepVote and returns true if triggered threshold.\n+     *\/\n+    final boolean sweepNow() {\n+        return (SWEEP_THRESHOLD ==\n+                ((int)SWEEPVOTES.getAndAdd(this, 1) & (SWEEP_THRESHOLD)));\n@@ -536,6 +559,14 @@\n-     * Collapses dead (matched) nodes between pred and q.\n-     * @param pred the last known live node, or null if none\n-     * @param c the first dead node\n-     * @param p the last dead node\n-     * @param q p.next: the next live node, or null if at end\n-     * @return pred if pred still alive and CAS succeeded; else p\n+     * Implements all queuing methods. Loops, trying:\n+     *\n+     * * If not initialized, try to add new node (unless immediate) and exit\n+     * * If tail has same mode, start traversing at tail for a likely\n+     *   append, else at head for a likely match\n+     * * Traverse over dead or wrong-mode nodes until finding a spot\n+     *   to match\/append, or falling off the list because of self-links.\n+     * * On success, update head or tail if slacked, and possibly wait,\n+     *   depending on ns argument\n+     *\n+     * @param e the item or null for take\n+     * @param ns timeout or negative if async, 0 if immediate,\n+     *        Long.MAX_VALUE if untimed\n+     * @return an item if matched, else e\n@@ -543,9 +574,36 @@\n-    private Node skipDeadNodes(Node pred, Node c, Node p, Node q) {\n-        \/\/ assert pred != c;\n-        \/\/ assert p != q;\n-        \/\/ assert c.isMatched();\n-        \/\/ assert p.isMatched();\n-        if (q == null) {\n-            \/\/ Never unlink trailing node.\n-            if (c == p) return pred;\n-            q = p;\n+    final Object xfer(Object e, long ns) {\n+        boolean haveData = (e != null);\n+        Object m;                           \/\/ the match or e if none\n+        DualNode s = null, p;               \/\/ enqueued node and its predecessor\n+        restart: for (DualNode prevp = null;;) {\n+            DualNode h, t, q;\n+            if ((h = head) == null &&       \/\/ initialize unless immediate\n+                (ns == 0L ||\n+                 (h = cmpExHead(null, s = new DualNode(e, haveData))) == null)) {\n+                p = null;                   \/\/ no predecessor\n+                break;                      \/\/ else lost init race\n+            }\n+            p = (t = tail) != null && t.isData == haveData && t != prevp ? t : h;\n+            prevp = p;                      \/\/ avoid known self-linked tail path\n+            do {\n+                m = p.item;\n+                q = p.next;\n+                if (p.isData != haveData && haveData != (m != null) &&\n+                    p.cmpExItem(m, e) == m) {\n+                    Thread w = p.waiter;    \/\/ matched complementary node\n+                    if (p != h && h == cmpExHead(h, (q == null) ? p : q))\n+                        h.next = h;         \/\/ advance head; self-link old\n+                    LockSupport.unpark(w);\n+                    return m;\n+                } else if (q == null) {\n+                    if (ns == 0L)           \/\/ try to append unless immediate\n+                        break restart;\n+                    if (s == null)\n+                        s = new DualNode(e, haveData);\n+                    if ((q = p.cmpExNext(null, s)) == null) {\n+                        if (p != t)\n+                            cmpExTail(t, s);\n+                        break restart;\n+                    }\n+                }\n+            } while (p != (p = q));         \/\/ restart if self-linked\n@@ -553,3 +611,9 @@\n-        return (tryCasSuccessor(pred, c, q)\n-                && (pred == null || !pred.isMatched()))\n-            ? pred : p;\n+        if (s == null || ns <= 0L)\n+            m = e;                          \/\/ don't wait\n+        else if ((m = s.await(e, ns, this,  \/\/ spin if at or near head\n+                              p == null || p.waiter == null)) == e)\n+            unsplice(p, s);                 \/\/ cancelled\n+        else if (m != null)\n+            s.selfLinkItem();\n+\n+        return m;\n@@ -558,0 +622,2 @@\n+    \/* --------------  Removals -------------- *\/\n+\n@@ -559,2 +625,6 @@\n-     * Collapses dead (matched) nodes from h (which was once head) to p.\n-     * Caller ensures all nodes from h up to and including p are dead.\n+     * Unlinks (now or later) the given (non-live) node with given\n+     * predecessor. See above for rationale.\n+     *\n+     * @param pred if nonnull, a node that was at one time known to be the\n+     * predecessor of s (else s may have been head)\n+     * @param s the node to be unspliced\n@@ -562,9 +632,29 @@\n-    private void skipDeadNodesNearHead(Node h, Node p) {\n-        \/\/ assert h != null;\n-        \/\/ assert h != p;\n-        \/\/ assert p.isMatched();\n-        for (;;) {\n-            final Node q;\n-            if ((q = p.next) == null) break;\n-            else if (!q.isMatched()) { p = q; break; }\n-            else if (p == (p = q)) return;\n+    private void unsplice(DualNode pred, DualNode s) {\n+        boolean seen = false; \/\/ try removing by collapsing head\n+        for (DualNode h = head, p = h, f; p != null;) {\n+            boolean matched;\n+            if (p == s)\n+                matched = seen = true;\n+            else\n+                matched = p.matched();\n+            if ((f = p.next) == p)\n+                p = h = head;\n+            else if (f != null && matched)\n+                p = f;\n+            else {\n+                if (p != h && cmpExHead(h, p) == h)\n+                    h.next = h; \/\/ self-link\n+                break;\n+            }\n+        }\n+        DualNode sn;      \/\/ try to unsplice if not pinned\n+        if (!seen &&\n+            pred != null && pred.next == s && s != null && (sn = s.next) != s &&\n+            (sn == null || pred.cmpExNext(s, sn) != s || pred.matched()) &&\n+            sweepNow()) { \/\/ occasionally sweep if might not have been removed\n+            for (DualNode p = head, f, n, u;\n+                 p != null && (f = p.next) != null && (n = f.next) != null;) {\n+                p = (f == p                       ? head :  \/\/ stale\n+                     !f.matched()                 ? f :     \/\/ skip\n+                     f == (u = p.cmpExNext(f, n)) ? n : u); \/\/ unspliced\n+            }\n@@ -572,2 +662,0 @@\n-        if (casHead(h, p))\n-            h.selfLink();\n@@ -576,1 +664,12 @@\n-    \/* Possible values for \"how\" argument in xfer method. *\/\n+    \/**\n+     * Tries to CAS pred.next (or head, if pred is null) from c to p.\n+     * Caller must ensure that we're not unlinking the trailing node.\n+     *\/\n+    final boolean tryCasSuccessor(DualNode pred, DualNode c, DualNode p) {\n+        \/\/ assert p != null && c.matched() && c != p;\n+        if (pred != null)\n+            return pred.cmpExNext(c, p) == c;\n+        else if (cmpExHead(c, p) != c)\n+            return false;\n+        if (c != null)\n+            c.next = c;\n@@ -578,4 +677,2 @@\n-    private static final int NOW   = 0; \/\/ for untimed poll, tryTransfer\n-    private static final int ASYNC = 1; \/\/ for offer, put, add\n-    private static final int SYNC  = 2; \/\/ for transfer, take\n-    private static final int TIMED = 3; \/\/ for timed poll, tryTransfer\n+        return true;\n+    }\n@@ -584,8 +681,6 @@\n-     * Implements all queuing methods. See above for explanation.\n-     *\n-     * @param e the item or null for take\n-     * @param haveData true if this is a put, else a take\n-     * @param how NOW, ASYNC, SYNC, or TIMED\n-     * @param nanos timeout in nanosecs, used only if mode is TIMED\n-     * @return an item if matched, else e\n-     * @throws NullPointerException if haveData mode but e is null\n+     * Collapses dead (matched) nodes between pred and q.\n+     * @param pred the last known live node, or null if none\n+     * @param c the first dead node\n+     * @param p the last dead node\n+     * @param q p.next: the next live node, or null if at end\n+     * @return pred if pred still alive and CAS succeeded; else p\n@@ -593,27 +688,7 @@\n-    @SuppressWarnings(\"unchecked\")\n-    private E xfer(E e, boolean haveData, int how, long nanos) {\n-        if (haveData && (e == null))\n-            throw new NullPointerException();\n-\n-        restart: for (Node s = null, t = null, h = null;;) {\n-            for (Node p = (t != (t = tail) && t.isData == haveData) ? t\n-                     : (h = head);; ) {\n-                final Node q; final Object item;\n-                if (p.isData != haveData\n-                    && haveData == ((item = p.item) == null)) {\n-                    if (h == null) h = head;\n-                    if (p.tryMatch(item, e)) {\n-                        if (h != p) skipDeadNodesNearHead(h, p);\n-                        return (E) item;\n-                    }\n-                }\n-                if ((q = p.next) == null) {\n-                    if (how == NOW) return e;\n-                    if (s == null) s = new Node(e);\n-                    if (!p.casNext(null, s)) continue;\n-                    if (p != t) casTail(t, s);\n-                    if (how == ASYNC) return e;\n-                    return awaitMatch(s, p, e, (how == TIMED), nanos);\n-                }\n-                if (p == (p = q)) continue restart;\n-            }\n+    final DualNode skipDeadNodes(DualNode pred, DualNode c,\n+                                 DualNode p, DualNode q) {\n+        \/\/ assert pred != c && p != q; && c.matched() && p.matched();\n+        if (q == null) { \/\/ Never unlink trailing node.\n+            if (c == p)\n+                return pred;\n+            q = p;\n@@ -621,0 +696,2 @@\n+        return (tryCasSuccessor(pred, c, q) && (pred == null || !pred.matched()))\n+            ? pred : p;\n@@ -624,10 +701,2 @@\n-     * Possibly blocks until node s is matched or caller gives up.\n-     *\n-     * @param s the waiting node\n-     * @param pred the predecessor of s, or null if unknown (the null\n-     * case does not occur in any current calls but may in possible\n-     * future extensions)\n-     * @param e the comparison value for checking match\n-     * @param timed if true, wait only until timeout elapses\n-     * @param nanos timeout in nanosecs, used only if timed is true\n-     * @return matched item, or e if unmatched on interrupt or timeout\n+     * Tries to match the given object only if p is a data\n+     * node. Signals waiter on success.\n@@ -635,43 +704,5 @@\n-    @SuppressWarnings(\"unchecked\")\n-    private E awaitMatch(Node s, Node pred, E e, boolean timed, long nanos) {\n-        final boolean isData = s.isData;\n-        final long deadline = timed ? System.nanoTime() + nanos : 0L;\n-        final Thread w = Thread.currentThread();\n-        int stat = -1;                   \/\/ -1: may yield, +1: park, else 0\n-        Object item;\n-        while ((item = s.item) == e) {\n-            if (needSweep)               \/\/ help clean\n-                sweep();\n-            else if ((timed && nanos <= 0L) || w.isInterrupted()) {\n-                if (s.casItem(e, (e == null) ? s : null)) {\n-                    unsplice(pred, s);   \/\/ cancelled\n-                    return e;\n-                }\n-            }\n-            else if (stat <= 0) {\n-                if (pred != null && pred.next == s) {\n-                    if (stat < 0 &&\n-                        (pred.isData != isData || pred.isMatched())) {\n-                        stat = 0;        \/\/ yield once if first\n-                        Thread.yield();\n-                    }\n-                    else {\n-                        stat = 1;\n-                        s.waiter = w;    \/\/ enable unpark\n-                    }\n-                }                        \/\/ else signal in progress\n-            }\n-            else if ((item = s.item) != e)\n-                break;                   \/\/ recheck\n-            else if (!timed) {\n-                LockSupport.setCurrentBlocker(this);\n-                try {\n-                    ForkJoinPool.managedBlock(s);\n-                } catch (InterruptedException cannotHappen) { }\n-                LockSupport.setCurrentBlocker(null);\n-            }\n-            else {\n-                nanos = deadline - System.nanoTime();\n-                if (nanos > SPIN_FOR_TIMEOUT_THRESHOLD)\n-                    LockSupport.parkNanos(this, nanos);\n-            }\n+    final boolean tryMatchData(DualNode p, Object x) {\n+        if (p != null && p.isData &&\n+            x != null && p.cmpExItem(x, null) == x) {\n+            LockSupport.unpark(p.waiter);\n+            return true;\n@@ -679,5 +710,1 @@\n-        if (stat == 1)\n-            WAITER.set(s, null);\n-        if (!isData)\n-            ITEM.set(s, s);              \/\/ self-link to avoid garbage\n-        return (E) item;\n+        return false;\n@@ -693,18 +720,19 @@\n-    final Node firstDataNode() {\n-        Node first = null;\n-        restartFromHead: for (;;) {\n-            Node h = head, p = h;\n-            while (p != null) {\n-                if (p.item != null) {\n-                    if (p.isData) {\n-                        first = p;\n-                        break;\n-                    }\n-                }\n-                else if (!p.isData)\n-                    break;\n-                final Node q;\n-                if ((q = p.next) == null)\n-                    break;\n-                if (p == (p = q))\n-                    continue restartFromHead;\n+    final DualNode firstDataNode() {\n+        for (DualNode h = head, p = h, q, u; p != null;) {\n+            boolean isData = p.isData;\n+            Object item = p.item;\n+            if (isData && item != null)       \/\/ is live data\n+                return p;\n+            else if (!isData && item == null) \/\/ is live request\n+                break;\n+            else if ((q = p.next) == null)    \/\/ end of list\n+                break;\n+            else if (p == q)                  \/\/ self-link; restart\n+                p = h = head;\n+            else if (p == h)                  \/\/ traverse past header\n+                p = q;\n+            else if ((u = cmpExHead(h, q)) != h)\n+                p = h = u;                    \/\/ lost update race\n+            else {\n+                h.next = h;                   \/\/ collapse; self-link\n+                p = h = q;\n@@ -712,3 +740,0 @@\n-            if (p != h && casHead(h, p))\n-                h.selfLink();\n-            return first;\n@@ -716,0 +741,1 @@\n+        return null;\n@@ -722,1 +748,1 @@\n-    private int countOfMode(boolean data) {\n+    final int countOfMode(boolean data) {\n@@ -725,2 +751,2 @@\n-            for (Node p = head; p != null;) {\n-                if (!p.isMatched()) {\n+            for (DualNode p = head; p != null;) {\n+                if (!p.matched()) {\n@@ -744,1 +770,1 @@\n-            for (Node p = head; p != null;) {\n+            for (DualNode p = head; p != null;) {\n@@ -773,1 +799,1 @@\n-            for (Node p = head; p != null;) {\n+            for (DualNode p = head; p != null;) {\n@@ -866,4 +892,4 @@\n-        private Node nextNode;   \/\/ next node to return item for\n-        private E nextItem;      \/\/ the corresponding item\n-        private Node lastRet;    \/\/ last returned node, to support remove\n-        private Node ancestor;   \/\/ Helps unlink lastRet on remove()\n+        private DualNode nextNode;   \/\/ next node to return item for\n+        private E nextItem;          \/\/ the corresponding item\n+        private DualNode lastRet;    \/\/ last returned node, to support remove\n+        private DualNode ancestor;   \/\/ Helps unlink lastRet on remove()\n@@ -875,2 +901,2 @@\n-        private void advance(Node pred) {\n-            for (Node p = (pred == null) ? head : pred.next, c = p;\n+        private void advance(DualNode pred) {\n+            for (DualNode p = (pred == null) ? head : pred.next, c = p;\n@@ -878,2 +904,3 @@\n-                final Object item;\n-                if ((item = p.item) != null && p.isData) {\n+                boolean isData = p.isData;\n+                Object item = p.item;\n+                if (isData && item != null) {\n@@ -886,1 +913,1 @@\n-                else if (!p.isData && item == null)\n+                else if (!isData && item == null)\n@@ -910,1 +937,1 @@\n-            final Node p;\n+            DualNode p;\n@@ -919,2 +946,2 @@\n-            Node q = null;\n-            for (Node p; (p = nextNode) != null; advance(q = p))\n+            DualNode q = null;\n+            for (DualNode p; (p = nextNode) != null; advance(q = p))\n@@ -927,1 +954,1 @@\n-            final Node lastRet = this.lastRet;\n+            final DualNode lastRet = this.lastRet;\n@@ -934,2 +961,2 @@\n-            Node pred = ancestor;\n-            for (Node p = (pred == null) ? head : pred.next, c = p, q;\n+            DualNode pred = ancestor;\n+            for (DualNode p = (pred == null) ? head : pred.next, c = p, q;\n@@ -938,3 +965,1 @@\n-                    final Object item;\n-                    if ((item = p.item) != null)\n-                        p.tryMatch(item, null);\n+                    tryMatchData(p, p.item);\n@@ -965,1 +990,1 @@\n-            \/\/ assert lastRet.isMatched();\n+            \/\/ assert lastRet.matched();\n@@ -972,1 +997,1 @@\n-        Node current;       \/\/ current node; null until initialized\n+        DualNode current;   \/\/ current node; null until initialized\n@@ -978,1 +1003,1 @@\n-            Node p, q;\n+            DualNode p, q;\n@@ -1007,1 +1032,1 @@\n-            final Node p;\n+            final DualNode p;\n@@ -1018,1 +1043,1 @@\n-            Node p;\n+            DualNode p;\n@@ -1022,2 +1047,2 @@\n-                    final Object item = p.item;\n-                    final boolean isData = p.isData;\n+                    boolean isData = p.isData;\n+                    Object item = p.item;\n@@ -1044,1 +1069,1 @@\n-        private void setCurrent(Node p) {\n+        private void setCurrent(DualNode p) {\n@@ -1049,2 +1074,2 @@\n-        private Node current() {\n-            Node p;\n+        private DualNode current() {\n+            DualNode p;\n@@ -1085,65 +1110,0 @@\n-    \/* -------------- Removal methods -------------- *\/\n-\n-    \/**\n-     * Unsplices (now or later) the given deleted\/cancelled node with\n-     * the given predecessor.\n-     *\n-     * @param pred a node that was at one time known to be the\n-     * predecessor of s\n-     * @param s the node to be unspliced\n-     *\/\n-    final void unsplice(Node pred, Node s) {\n-        \/\/ assert pred != null;\n-        \/\/ assert pred != s;\n-        \/\/ assert s != null;\n-        \/\/ assert s.isMatched();\n-        \/\/ assert (SWEEP_THRESHOLD & (SWEEP_THRESHOLD - 1)) == 0;\n-        s.waiter = null; \/\/ disable signals\n-        \/*\n-         * See above for rationale. Briefly: if pred still points to\n-         * s, try to unlink s.  If s cannot be unlinked, because it is\n-         * trailing node or pred might be unlinked, and neither pred\n-         * nor s are head or offlist, set needSweep;\n-         *\/\n-        if (pred != null && pred.next == s) {\n-            Node n = s.next;\n-            if (n == null ||\n-                (n != s && pred.casNext(s, n) && pred.isMatched())) {\n-                for (;;) {               \/\/ check if at, or could be, head\n-                    Node h = head;\n-                    if (h == pred || h == s)\n-                        return;          \/\/ at head or list empty\n-                    if (!h.isMatched())\n-                        break;\n-                    Node hn = h.next;\n-                    if (hn == null)\n-                        return;          \/\/ now empty\n-                    if (hn != h && casHead(h, hn))\n-                        h.selfLink();  \/\/ advance head\n-                }\n-                if (pred.next != pred && s.next != s)\n-                    needSweep = true;\n-            }\n-        }\n-    }\n-\n-    \/**\n-     * Unlinks matched (typically cancelled) nodes encountered in a\n-     * traversal from head.\n-     *\/\n-    private void sweep() {\n-        needSweep = false;\n-        for (Node p = head, s, n; p != null && (s = p.next) != null; ) {\n-            if (!s.isMatched())\n-                \/\/ Unmatched nodes are never self-linked\n-                p = s;\n-            else if ((n = s.next) == null) \/\/ trailing node is pinned\n-                break;\n-            else if (s == n)    \/\/ stale\n-                \/\/ No need to also check for p == s, since that implies s == n\n-                p = head;\n-            else\n-                p.casNext(s, n);\n-        }\n-    }\n-\n@@ -1154,1 +1114,0 @@\n-        head = tail = new Node();\n@@ -1167,1 +1126,1 @@\n-        Node h = null, t = null;\n+        DualNode h = null, t = null;\n@@ -1169,3 +1128,3 @@\n-            Node newNode = new Node(Objects.requireNonNull(e));\n-            if (h == null)\n-                h = t = newNode;\n+            DualNode newNode = new DualNode(Objects.requireNonNull(e), true);\n+            if (t == null)\n+                h = newNode;\n@@ -1173,1 +1132,2 @@\n-                t.appendRelaxed(t = newNode);\n+                t.next = newNode;\n+            t = newNode;\n@@ -1175,2 +1135,0 @@\n-        if (h == null)\n-            h = t = new Node();\n@@ -1188,1 +1146,1 @@\n-        xfer(e, true, ASYNC, 0L);\n+        offer(e);\n@@ -1201,2 +1159,1 @@\n-        xfer(e, true, ASYNC, 0L);\n-        return true;\n+        return offer(e);\n@@ -1213,1 +1170,2 @@\n-        xfer(e, true, ASYNC, 0L);\n+        Objects.requireNonNull(e);\n+        xfer(e, -1L);\n@@ -1226,2 +1184,1 @@\n-        xfer(e, true, ASYNC, 0L);\n-        return true;\n+        return offer(e);\n@@ -1241,1 +1198,2 @@\n-        return xfer(e, true, NOW, 0L) == null;\n+        Objects.requireNonNull(e);\n+        return xfer(e, 0L) == null;\n@@ -1256,1 +1214,4 @@\n-        if (xfer(e, true, SYNC, 0L) != null) {\n+        Objects.requireNonNull(e);\n+        if (!Thread.interrupted()) {\n+            if (xfer(e, Long.MAX_VALUE) == null)\n+                return;\n@@ -1258,1 +1219,0 @@\n-            throw new InterruptedException();\n@@ -1260,0 +1220,1 @@\n+        throw new InterruptedException();\n@@ -1278,1 +1239,3 @@\n-        if (xfer(e, true, TIMED, unit.toNanos(timeout)) == null)\n+        Objects.requireNonNull(e);\n+        long nanos = Math.max(unit.toNanos(timeout), 0L);\n+        if (xfer(e, nanos) == null)\n@@ -1285,0 +1248,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -1286,4 +1250,6 @@\n-        E e = xfer(null, false, SYNC, 0L);\n-        if (e != null)\n-            return e;\n-        Thread.interrupted();\n+        Object e;\n+        if (!Thread.interrupted()) {\n+            if ((e = xfer(null, Long.MAX_VALUE)) != null)\n+                return (E) e;\n+            Thread.interrupted();\n+        }\n@@ -1293,0 +1259,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -1294,3 +1261,4 @@\n-        E e = xfer(null, false, TIMED, unit.toNanos(timeout));\n-        if (e != null || !Thread.interrupted())\n-            return e;\n+        Object e;\n+        long nanos = Math.max(unit.toNanos(timeout), 0L);\n+        if ((e = xfer(null, nanos)) != null || !Thread.interrupted())\n+            return (E) e;\n@@ -1300,0 +1268,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -1301,1 +1270,1 @@\n-        return xfer(null, false, NOW, 0L);\n+        return (E) xfer(null, 0L);\n@@ -1347,1 +1316,1 @@\n-            for (Node p = head; p != null;) {\n+            for (DualNode p = head; p != null;) {\n@@ -1375,1 +1344,1 @@\n-            for (Node p = head; p != null;) {\n+            for (DualNode p = head; p != null;) {\n@@ -1424,6 +1393,7 @@\n-            for (Node p = head, pred = null; p != null; ) {\n-                Node q = p.next;\n-                final Object item;\n-                if ((item = p.item) != null) {\n-                    if (p.isData) {\n-                        if (o.equals(item) && p.tryMatch(item, null)) {\n+            for (DualNode p = head, pred = null; p != null; ) {\n+                boolean isData = p.isData;\n+                Object item = p.item;\n+                DualNode q = p.next;\n+                if (item != null) {\n+                    if (isData) {\n+                        if (o.equals(item) && tryMatchData(p, item)) {\n@@ -1436,1 +1406,1 @@\n-                else if (!p.isData)\n+                else if (!isData)\n@@ -1438,2 +1408,2 @@\n-                for (Node c = p;; q = p.next) {\n-                    if (q == null || !q.isMatched()) {\n+                for (DualNode c = p;; q = p.next) {\n+                    if (q == null || !q.matched()) {\n@@ -1460,5 +1430,6 @@\n-            for (Node p = head, pred = null; p != null; ) {\n-                Node q = p.next;\n-                final Object item;\n-                if ((item = p.item) != null) {\n-                    if (p.isData) {\n+            for (DualNode p = head, pred = null; p != null; ) {\n+                boolean isData = p.isData;\n+                Object item = p.item;\n+                DualNode q = p.next;\n+                if (item != null) {\n+                    if (isData) {\n@@ -1470,1 +1441,1 @@\n-                else if (!p.isData)\n+                else if (!isData)\n@@ -1472,2 +1443,2 @@\n-                for (Node c = p;; q = p.next) {\n-                    if (q == null || !q.isMatched()) {\n+                for (DualNode c = p;; q = p.next) {\n+                    if (q == null || !q.matched()) {\n@@ -1522,1 +1493,1 @@\n-        Node h = null, t = null;\n+        DualNode h = null, t = null;\n@@ -1524,3 +1495,3 @@\n-            Node newNode = new Node(item);\n-            if (h == null)\n-                h = t = newNode;\n+            DualNode newNode = new DualNode(item, true);\n+            if (t == null)\n+                h = newNode;\n@@ -1528,1 +1499,2 @@\n-                t.appendRelaxed(t = newNode);\n+                t.next = newNode;\n+            t = newNode;\n@@ -1530,2 +1502,0 @@\n-        if (h == null)\n-            h = t = new Node();\n@@ -1570,0 +1540,1 @@\n+\n@@ -1578,1 +1549,3 @@\n-            for (Node p = head, c = p, pred = null, q; p != null; p = q) {\n+            for (DualNode p = head, c = p, pred = null, q; p != null; p = q) {\n+                boolean isData = p.isData, pAlive;\n+                Object item = p.item;\n@@ -1580,2 +1553,1 @@\n-                final Object item; boolean pAlive;\n-                if (pAlive = ((item = p.item) != null && p.isData)) {\n+                if (pAlive = (item != null && isData)) {\n@@ -1583,1 +1555,1 @@\n-                        if (p.tryMatch(item, null))\n+                        if (tryMatchData(p, item))\n@@ -1588,1 +1560,1 @@\n-                else if (!p.isData && item == null)\n+                else if (!isData && item == null)\n@@ -1594,2 +1566,1 @@\n-                    if ((c != p && !tryCasSuccessor(pred, c, c = p))\n-                        || pAlive) {\n+                    if ((c != p && !tryCasSuccessor(pred, c, c = p)) || pAlive) {\n@@ -1613,6 +1584,7 @@\n-    void forEachFrom(Consumer<? super E> action, Node p) {\n-        for (Node pred = null; p != null; ) {\n-            Node q = p.next;\n-            final Object item;\n-            if ((item = p.item) != null) {\n-                if (p.isData) {\n+    void forEachFrom(Consumer<? super E> action, DualNode p) {\n+        for (DualNode pred = null; p != null; ) {\n+            boolean isData = p.isData;\n+            Object item = p.item;\n+            DualNode q = p.next;\n+            if (item != null) {\n+                if (isData) {\n@@ -1623,1 +1595,1 @@\n-            else if (!p.isData)\n+            else if (!isData)\n@@ -1625,2 +1597,2 @@\n-            for (Node c = p;; q = p.next) {\n-                if (q == null || !q.isMatched()) {\n+            for (DualNode c = p;; q = p.next) {\n+                if (q == null || !q.matched()) {\n@@ -1643,5 +1615,3 @@\n-    private static final VarHandle HEAD;\n-    private static final VarHandle TAIL;\n-    static final VarHandle ITEM;\n-    static final VarHandle NEXT;\n-    static final VarHandle WAITER;\n+    static final VarHandle HEAD;\n+    static final VarHandle TAIL;\n+    static final VarHandle SWEEPVOTES;\n@@ -1650,0 +1620,1 @@\n+            Class<?> ltq = LinkedTransferQueue.class, tn = DualNode.class;\n@@ -1651,7 +1622,3 @@\n-            HEAD = l.findVarHandle(LinkedTransferQueue.class, \"head\",\n-                                   Node.class);\n-            TAIL = l.findVarHandle(LinkedTransferQueue.class, \"tail\",\n-                                   Node.class);\n-            ITEM = l.findVarHandle(Node.class, \"item\", Object.class);\n-            NEXT = l.findVarHandle(Node.class, \"next\", Node.class);\n-            WAITER = l.findVarHandle(Node.class, \"waiter\", Thread.class);\n+            HEAD = l.findVarHandle(ltq, \"head\", tn);\n+            TAIL = l.findVarHandle(ltq, \"tail\", tn);\n+            SWEEPVOTES = l.findVarHandle(ltq, \"sweepVotes\", int.class);\n@@ -1661,4 +1628,0 @@\n-\n-        \/\/ Reduce the risk of rare disastrous classloading in first call to\n-        \/\/ LockSupport.park: https:\/\/bugs.openjdk.org\/browse\/JDK-8074773\n-        Class<?> ensureLoaded = LockSupport.class;\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/LinkedTransferQueue.java","additions":593,"deletions":630,"binary":false,"changes":1223,"status":"modified"},{"patch":"@@ -50,0 +50,3 @@\n+import java.util.concurrent.ForkJoinWorkerThread;\n+import java.util.concurrent.LinkedTransferQueue;\n+import java.util.concurrent.TransferQueue;\n@@ -101,5 +104,8 @@\n-     * The (Lifo) stack is used for non-fair mode, and the (Fifo)\n-     * queue for fair mode. The performance of the two is generally\n-     * similar. Fifo usually supports higher throughput under\n-     * contention but Lifo maintains higher thread locality in common\n-     * applications.\n+     * The queue is treated as a Lifo stack in non-fair mode, and a\n+     * Fifo queue in fair mode. In most contexts, transfer performance\n+     * is roughly comparable across them. Lifo is usually faster under\n+     * low contention, but slower under high contention.  Performance\n+     * of applications using them also varies. Lifo is generally\n+     * preferable in resource management settings (for example cached\n+     * thread pools) because of better temporal locality, but\n+     * inappropriate for message-passing applications.\n@@ -107,21 +113,10 @@\n-     * A dual queue (and similarly stack) is one that at any given\n-     * time either holds \"data\" -- items provided by put operations,\n-     * or \"requests\" -- slots representing take operations, or is\n-     * empty. A call to \"fulfill\" (i.e., a call requesting an item\n-     * from a queue holding data or vice versa) dequeues a\n-     * complementary node.  The most interesting feature of these\n-     * queues is that any operation can figure out which mode the\n-     * queue is in, and act accordingly without needing locks.\n-     *\n-     * Both the queue and stack extend abstract class Transferer\n-     * defining the single method transfer that does a put or a\n-     * take. These are unified into a single method because in dual\n-     * data structures, the put and take operations are symmetrical,\n-     * so nearly all code can be combined. The resulting transfer\n-     * methods are on the long side, but are easier to follow than\n-     * they would be if broken up into nearly-duplicated parts.\n-     *\n-     * The queue and stack data structures share many conceptual\n-     * similarities but very few concrete details. For simplicity,\n-     * they are kept distinct so that they can later evolve\n-     * separately.\n+     * A dual queue is one that at any given time either holds \"data\"\n+     * -- items provided by put operations, or \"requests\" -- slots\n+     * representing take operations, or is empty. A fulfilling\n+     * operation (i.e., a call requesting an item from a queue holding\n+     * data or vice versa) \"matches\" the item of and then dequeues a\n+     * complementary node.  Any operation can figure out which mode\n+     * the queue is in, and act accordingly without needing locks.  So\n+     * put and take operations are symmetrical, and all transfer\n+     * methods invoke a single \"xfer\" method that does a put or a take\n+     * in either fifo or lifo mode.\n@@ -130,27 +125,1 @@\n-     * in extending them for use in synchronous queues, as well as\n-     * dealing with cancellation. The main differences include:\n-     *\n-     *  1. The original algorithms used bit-marked pointers, but\n-     *     the ones here use mode bits in nodes, leading to a number\n-     *     of further adaptations.\n-     *  2. SynchronousQueues must block threads waiting to become\n-     *     fulfilled.\n-     *  3. Support for cancellation via timeout and interrupts,\n-     *     including cleaning out cancelled nodes\/threads\n-     *     from lists to avoid garbage retention and memory depletion.\n-     *\n-     * Blocking is mainly accomplished using LockSupport park\/unpark,\n-     * except that nodes that appear to be the next ones to become\n-     * fulfilled first spin a bit (on multiprocessors only). On very\n-     * busy synchronous queues, spinning can dramatically improve\n-     * throughput. And on less busy ones, the amount of spinning is\n-     * small enough not to be noticeable.\n-     *\n-     * Cleaning is done in different ways in queues vs stacks.  For\n-     * queues, we can almost always remove a node immediately in O(1)\n-     * time (modulo retries for consistency checks) when it is\n-     * cancelled. But if it may be pinned as the current tail, it must\n-     * wait until some subsequent cancellation. For stacks, we need a\n-     * potentially O(n) traversal to be sure that we can remove the\n-     * node, but this can run concurrently with other threads\n-     * accessing the stack.\n+     * in ways including:\n@@ -158,23 +127,14 @@\n-     * While garbage collection takes care of most node reclamation\n-     * issues that otherwise complicate nonblocking algorithms, care\n-     * is taken to \"forget\" references to data, other nodes, and\n-     * threads that might be held on to long-term by blocked\n-     * threads. In cases where setting to null would otherwise\n-     * conflict with main algorithms, this is done by changing a\n-     * node's link to now point to the node itself. This doesn't arise\n-     * much for Stack nodes (because blocked threads do not hang on to\n-     * old head pointers), but references in Queue nodes must be\n-     * aggressively forgotten to avoid reachability of everything any\n-     * node has ever referred to since arrival.\n-     *\n-     * The above steps improve throughput when many threads produce\n-     * and\/or consume data. But they don't help much with\n-     * single-source \/ single-sink usages in which one side or the\n-     * other is always transiently blocked, and so throughput is\n-     * mainly a function of thread scheduling. This is not usually\n-     * noticeably improved with bounded short spin-waits. Instead both\n-     * forms of transfer try Thread.yield if apparently the sole\n-     * waiter. This works well when there are more tasks that cores,\n-     * which is expected to be the main usage context of this mode. In\n-     * other cases, waiters may help with some bookkeeping, then\n-     * park\/unpark.\n+     *  * The original algorithms used bit-marked pointers, but the\n+     *     ones here use a bit (isData) in nodes, and usually avoid\n+     *     creating nodes when fulfilling. They also use the\n+     *     compareAndExchange form of CAS for pointer updates to\n+     *     reduce memory traffic.\n+     *  * Fifo mode is based on LinkedTransferQueue operations, but\n+     *     Lifo mode support is added in subclass Transferer.\n+     *  * The Fifo version accommodates lazy updates and slack as\n+     *     described in LinkedTransferQueue internal documentation.\n+     *  * Threads may block when waiting to become fulfilled,\n+     *     sometimes preceded by brief spins.\n+     *  * Support for cancellation via timeout and interrupts,\n+     *     including cleaning out cancelled nodes\/threads from lists\n+     *     to avoid garbage retention and memory depletion.\n@@ -184,1 +144,6 @@\n-     * Shared internal API for dual stacks and queues.\n+     * Extension of LinkedTransferQueue to support Lifo (stack) mode.\n+     * Methods use the \"head\" field as head (top) of stack (versus\n+     * queue). Note that popped nodes are not self-linked because they\n+     * are not prone to unbounded garbage chains. Also note that\n+     * \"async\" mode is never used and not supported for synchronous\n+     * transfers.\n@@ -186,1 +151,3 @@\n-    abstract static class Transferer<E> {\n+    @SuppressWarnings(\"serial\") \/\/ never serialized\n+    static final class Transferer<E> extends LinkedTransferQueue<E> {\n+\n@@ -188,1 +155,7 @@\n-         * Performs a put or take.\n+         * Puts or takes an item with lifo ordering. Loops trying:\n+         * * If top (var p) exists and is already matched, pop and continue\n+         * * If top has complementary type, try to fulfill by CASing item,\n+         *    On success pop (which will succeed unless already helped),\n+         *    otherwise restart.\n+         * * If no possible match, unless immediate mode, push a\n+         *    node and wait, later unsplicing if cancelled.\n@@ -190,9 +163,3 @@\n-         * @param e if non-null, the item to be handed to a consumer;\n-         *          if null, requests that transfer return an item\n-         *          offered by producer.\n-         * @param timed if this operation should timeout\n-         * @param nanos the timeout, in nanoseconds\n-         * @return if non-null, the item provided or received; if null,\n-         *         the operation failed due to timeout or interrupt --\n-         *         the caller can distinguish which of these occurred\n-         *         by checking Thread.interrupted.\n+         * @param e the item or null for take\n+         * @param ns timeout or 0 if immediate, Long.MAX_VALUE if untimed\n+         * @return an item if matched, else e\n@@ -200,65 +167,17 @@\n-        abstract E transfer(E e, boolean timed, long nanos);\n-    }\n-\n-    \/**\n-     * The number of nanoseconds for which it is faster to spin\n-     * rather than to use timed park. A rough estimate suffices.\n-     *\/\n-    static final long SPIN_FOR_TIMEOUT_THRESHOLD = 1023L;\n-\n-    \/** Dual stack *\/\n-    static final class TransferStack<E> extends Transferer<E> {\n-        \/*\n-         * This extends Scherer-Scott dual stack algorithm, differing,\n-         * among other ways, by using \"covering\" nodes rather than\n-         * bit-marked pointers: Fulfilling operations push on marker\n-         * nodes (with FULFILLING bit set in mode) to reserve a spot\n-         * to match a waiting node.\n-         *\/\n-\n-        \/* Modes for SNodes, ORed together in node fields *\/\n-        \/** Node represents an unfulfilled consumer *\/\n-        static final int REQUEST    = 0;\n-        \/** Node represents an unfulfilled producer *\/\n-        static final int DATA       = 1;\n-        \/** Node is fulfilling another unfulfilled DATA or REQUEST *\/\n-        static final int FULFILLING = 2;\n-\n-        \/** Returns true if m has fulfilling bit set. *\/\n-        static boolean isFulfilling(int m) { return (m & FULFILLING) != 0; }\n-\n-        \/** Node class for TransferStacks. *\/\n-        static final class SNode implements ForkJoinPool.ManagedBlocker {\n-            volatile SNode next;        \/\/ next node in stack\n-            volatile SNode match;       \/\/ the node matched to this\n-            volatile Thread waiter;     \/\/ to control park\/unpark\n-            Object item;                \/\/ data; or null for REQUESTs\n-            int mode;\n-            \/\/ Note: item and mode fields don't need to be volatile\n-            \/\/ since they are always written before, and read after,\n-            \/\/ other volatile\/atomic operations.\n-\n-            SNode(Object item) {\n-                this.item = item;\n-            }\n-\n-            boolean casNext(SNode cmp, SNode val) {\n-                return cmp == next &&\n-                    SNEXT.compareAndSet(this, cmp, val);\n-            }\n-\n-            \/**\n-             * Tries to match node s to this node, if so, waking up thread.\n-             * Fulfillers call tryMatch to identify their waiters.\n-             * Waiters block until they have been matched.\n-             *\n-             * @param s the node to match\n-             * @return true if successfully matched to s\n-             *\/\n-            boolean tryMatch(SNode s) {\n-                SNode m; Thread w;\n-                if ((m = match) == null) {\n-                    if (SMATCH.compareAndSet(this, null, s)) {\n-                        if ((w = waiter) != null)\n-                            LockSupport.unpark(w);\n-                        return true;\n+        final Object xferLifo(Object e, long ns) {\n+            boolean haveData = (e != null);\n+            Object m;                              \/\/ the match or e if none\n+            outer: for (DualNode s = null, p = head;;) {\n+                while (p != null) {\n+                    boolean isData; DualNode n, u; \/\/ help collapse\n+                    if ((isData = p.isData) != ((m = p.item) != null))\n+                        p = (p == (u = cmpExHead(p, (n = p.next)))) ? n : u;\n+                    else if (isData == haveData)   \/\/ same mode; push below\n+                        break;\n+                    else if (p.cmpExItem(m, e) != m)\n+                        p = head;                  \/\/ missed; restart\n+                    else {                         \/\/ matched complementary node\n+                        Thread w = p.waiter;\n+                        cmpExHead(p, p.next);\n+                        LockSupport.unpark(w);\n+                        break outer;\n@@ -266,42 +185,0 @@\n-                    else\n-                        m = match;\n-                }\n-                return m == s;\n-            }\n-\n-            \/**\n-             * Tries to cancel a wait by matching node to itself.\n-             *\/\n-            boolean tryCancel() {\n-                return SMATCH.compareAndSet(this, null, this);\n-            }\n-\n-            boolean isCancelled() {\n-                return match == this;\n-            }\n-\n-            public final boolean isReleasable() {\n-                return match != null || Thread.currentThread().isInterrupted();\n-            }\n-\n-            public final boolean block() {\n-                while (!isReleasable()) LockSupport.park();\n-                return true;\n-            }\n-\n-            void forgetWaiter() {\n-                SWAITER.setOpaque(this, null);\n-            }\n-\n-            \/\/ VarHandle mechanics\n-            private static final VarHandle SMATCH;\n-            private static final VarHandle SNEXT;\n-            private static final VarHandle SWAITER;\n-            static {\n-                try {\n-                    MethodHandles.Lookup l = MethodHandles.lookup();\n-                    SMATCH = l.findVarHandle(SNode.class, \"match\", SNode.class);\n-                    SNEXT = l.findVarHandle(SNode.class, \"next\", SNode.class);\n-                    SWAITER = l.findVarHandle(SNode.class, \"waiter\", Thread.class);\n-                } catch (ReflectiveOperationException e) {\n-                    throw new ExceptionInInitializerError(e);\n@@ -309,131 +186,3 @@\n-            }\n-        }\n-\n-        \/** The head (top) of the stack *\/\n-        volatile SNode head;\n-\n-        boolean casHead(SNode h, SNode nh) {\n-            return h == head &&\n-                SHEAD.compareAndSet(this, h, nh);\n-        }\n-\n-        \/**\n-         * Creates or resets fields of a node. Called only from transfer\n-         * where the node to push on stack is lazily created and\n-         * reused when possible to help reduce intervals between reads\n-         * and CASes of head and to avoid surges of garbage when CASes\n-         * to push nodes fail due to contention.\n-         *\/\n-        static SNode snode(SNode s, Object e, SNode next, int mode) {\n-            if (s == null) s = new SNode(e);\n-            s.mode = mode;\n-            s.next = next;\n-            return s;\n-        }\n-\n-        \/**\n-         * Puts or takes an item.\n-         *\/\n-        @SuppressWarnings(\"unchecked\")\n-        E transfer(E e, boolean timed, long nanos) {\n-            \/*\n-             * Basic algorithm is to loop trying one of three actions:\n-             *\n-             * 1. If apparently empty or already containing nodes of same\n-             *    mode, try to push node on stack and wait for a match,\n-             *    returning it, or null if cancelled.\n-             *\n-             * 2. If apparently containing node of complementary mode,\n-             *    try to push a fulfilling node on to stack, match\n-             *    with corresponding waiting node, pop both from\n-             *    stack, and return matched item. The matching or\n-             *    unlinking might not actually be necessary because of\n-             *    other threads performing action 3:\n-             *\n-             * 3. If top of stack already holds another fulfilling node,\n-             *    help it out by doing its match and\/or pop\n-             *    operations, and then continue. The code for helping\n-             *    is essentially the same as for fulfilling, except\n-             *    that it doesn't return the item.\n-             *\/\n-\n-            SNode s = null; \/\/ constructed\/reused as needed\n-            int mode = (e == null) ? REQUEST : DATA;\n-\n-            for (;;) {\n-                SNode h = head;\n-                if (h == null || h.mode == mode) {  \/\/ empty or same-mode\n-                    if (timed && nanos <= 0L) {     \/\/ can't wait\n-                        if (h != null && h.isCancelled())\n-                            casHead(h, h.next);     \/\/ pop cancelled node\n-                        else\n-                            return null;\n-                    } else if (casHead(h, s = snode(s, e, h, mode))) {\n-                        long deadline = timed ? System.nanoTime() + nanos : 0L;\n-                        Thread w = Thread.currentThread();\n-                        int stat = -1; \/\/ -1: may yield, +1: park, else 0\n-                        SNode m;                    \/\/ await fulfill or cancel\n-                        while ((m = s.match) == null) {\n-                            if ((timed &&\n-                                 (nanos = deadline - System.nanoTime()) <= 0) ||\n-                                w.isInterrupted()) {\n-                                if (s.tryCancel()) {\n-                                    clean(s);       \/\/ wait cancelled\n-                                    return null;\n-                                }\n-                            } else if ((m = s.match) != null) {\n-                                break;              \/\/ recheck\n-                            } else if (stat <= 0) {\n-                                if (stat < 0 && h == null && head == s) {\n-                                    stat = 0;       \/\/ yield once if was empty\n-                                    Thread.yield();\n-                                } else {\n-                                    stat = 1;\n-                                    s.waiter = w;   \/\/ enable signal\n-                                }\n-                            } else if (!timed) {\n-                                LockSupport.setCurrentBlocker(this);\n-                                try {\n-                                    ForkJoinPool.managedBlock(s);\n-                                } catch (InterruptedException cannotHappen) { }\n-                                LockSupport.setCurrentBlocker(null);\n-                            } else if (nanos > SPIN_FOR_TIMEOUT_THRESHOLD)\n-                                LockSupport.parkNanos(this, nanos);\n-                        }\n-                        if (stat == 1)\n-                            s.forgetWaiter();\n-                        Object result = (mode == REQUEST) ? m.item : s.item;\n-                        if (h != null && h.next == s)\n-                            casHead(h, s.next);     \/\/ help fulfiller\n-                        return (E) result;\n-                    }\n-                } else if (!isFulfilling(h.mode)) { \/\/ try to fulfill\n-                    if (h.isCancelled())            \/\/ already cancelled\n-                        casHead(h, h.next);         \/\/ pop and retry\n-                    else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {\n-                        for (;;) { \/\/ loop until matched or waiters disappear\n-                            SNode m = s.next;       \/\/ m is s's match\n-                            if (m == null) {        \/\/ all waiters are gone\n-                                casHead(s, null);   \/\/ pop fulfill node\n-                                s = null;           \/\/ use new node next time\n-                                break;              \/\/ restart main loop\n-                            }\n-                            SNode mn = m.next;\n-                            if (m.tryMatch(s)) {\n-                                casHead(s, mn);     \/\/ pop both s and m\n-                                return (E) ((mode == REQUEST) ? m.item : s.item);\n-                            } else                  \/\/ lost match\n-                                s.casNext(m, mn);   \/\/ help unlink\n-                        }\n-                    }\n-                } else {                            \/\/ help a fulfiller\n-                    SNode m = h.next;               \/\/ m is h's match\n-                    if (m == null)                  \/\/ waiter is gone\n-                        casHead(h, null);           \/\/ pop fulfilling node\n-                    else {\n-                        SNode mn = m.next;\n-                        if (m.tryMatch(h))          \/\/ help match\n-                            casHead(h, mn);         \/\/ pop both h and m\n-                        else                        \/\/ lost match\n-                            h.casNext(m, mn);       \/\/ help unlink\n-                    }\n+                if (ns == 0L) {                    \/\/ no match, no wait\n+                    m = e;\n+                    break;\n@@ -441,137 +190,8 @@\n-            }\n-        }\n-\n-        \/**\n-         * Unlinks s from the stack.\n-         *\/\n-        void clean(SNode s) {\n-            s.item = null;   \/\/ forget item\n-            s.forgetWaiter();\n-\n-            \/*\n-             * At worst we may need to traverse entire stack to unlink\n-             * s. If there are multiple concurrent calls to clean, we\n-             * might not see s if another thread has already removed\n-             * it. But we can stop when we see any node known to\n-             * follow s. We use s.next unless it too is cancelled, in\n-             * which case we try the node one past. We don't check any\n-             * further because we don't want to doubly traverse just to\n-             * find sentinel.\n-             *\/\n-\n-            SNode past = s.next;\n-            if (past != null && past.isCancelled())\n-                past = past.next;\n-\n-            \/\/ Absorb cancelled nodes at head\n-            SNode p;\n-            while ((p = head) != null && p != past && p.isCancelled())\n-                casHead(p, p.next);\n-\n-            \/\/ Unsplice embedded nodes\n-            while (p != null && p != past) {\n-                SNode n = p.next;\n-                if (n != null && n.isCancelled())\n-                    p.casNext(n, n.next);\n-                else\n-                    p = n;\n-            }\n-        }\n-\n-        \/\/ VarHandle mechanics\n-        private static final VarHandle SHEAD;\n-        static {\n-            try {\n-                MethodHandles.Lookup l = MethodHandles.lookup();\n-                SHEAD = l.findVarHandle(TransferStack.class, \"head\", SNode.class);\n-            } catch (ReflectiveOperationException e) {\n-                throw new ExceptionInInitializerError(e);\n-            }\n-        }\n-    }\n-\n-    \/** Dual Queue *\/\n-    static final class TransferQueue<E> extends Transferer<E> {\n-        \/*\n-         * This extends Scherer-Scott dual queue algorithm, differing,\n-         * among other ways, by using modes within nodes rather than\n-         * marked pointers. The algorithm is a little simpler than\n-         * that for stacks because fulfillers do not need explicit\n-         * nodes, and matching is done by CAS'ing QNode.item field\n-         * from non-null to null (for put) or vice versa (for take).\n-         *\/\n-\n-        \/** Node class for TransferQueue. *\/\n-        static final class QNode implements ForkJoinPool.ManagedBlocker {\n-            volatile QNode next;          \/\/ next node in queue\n-            volatile Object item;         \/\/ CAS'ed to or from null\n-            volatile Thread waiter;       \/\/ to control park\/unpark\n-            final boolean isData;\n-\n-            QNode(Object item, boolean isData) {\n-                this.item = item;\n-                this.isData = isData;\n-            }\n-\n-            boolean casNext(QNode cmp, QNode val) {\n-                return next == cmp &&\n-                    QNEXT.compareAndSet(this, cmp, val);\n-            }\n-\n-            boolean casItem(Object cmp, Object val) {\n-                return item == cmp &&\n-                    QITEM.compareAndSet(this, cmp, val);\n-            }\n-\n-            \/**\n-             * Tries to cancel by CAS'ing ref to this as item.\n-             *\/\n-            boolean tryCancel(Object cmp) {\n-                return QITEM.compareAndSet(this, cmp, this);\n-            }\n-\n-            boolean isCancelled() {\n-                return item == this;\n-            }\n-\n-            \/**\n-             * Returns true if this node is known to be off the queue\n-             * because its next pointer has been forgotten due to\n-             * an advanceHead operation.\n-             *\/\n-            boolean isOffList() {\n-                return next == this;\n-            }\n-\n-            void forgetWaiter() {\n-                QWAITER.setOpaque(this, null);\n-            }\n-\n-            boolean isFulfilled() {\n-                Object x;\n-                return isData == ((x = item) == null) || x == this;\n-            }\n-\n-            public final boolean isReleasable() {\n-                Object x;\n-                return isData == ((x = item) == null) || x == this ||\n-                    Thread.currentThread().isInterrupted();\n-            }\n-\n-            public final boolean block() {\n-                while (!isReleasable()) LockSupport.park();\n-                return true;\n-            }\n-\n-            \/\/ VarHandle mechanics\n-            private static final VarHandle QITEM;\n-            private static final VarHandle QNEXT;\n-            private static final VarHandle QWAITER;\n-            static {\n-                try {\n-                    MethodHandles.Lookup l = MethodHandles.lookup();\n-                    QITEM = l.findVarHandle(QNode.class, \"item\", Object.class);\n-                    QNEXT = l.findVarHandle(QNode.class, \"next\", QNode.class);\n-                    QWAITER = l.findVarHandle(QNode.class, \"waiter\", Thread.class);\n-                } catch (ReflectiveOperationException e) {\n-                    throw new ExceptionInInitializerError(e);\n+                if (s == null)                     \/\/ try to push node and wait\n+                    s = new DualNode(e, haveData);\n+                s.next = p;\n+                if (p == (p = cmpExHead(p, s))) {\n+                    if ((m = s.await(e, ns, this,  \/\/ spin if (nearly) empty\n+                                     p == null || p.waiter == null)) == e)\n+                        unspliceLifo(s);           \/\/ cancelled\n+                    break;\n@@ -580,27 +200,1 @@\n-        }\n-\n-        \/** Head of queue *\/\n-        transient volatile QNode head;\n-        \/** Tail of queue *\/\n-        transient volatile QNode tail;\n-        \/**\n-         * Reference to a cancelled node that might not yet have been\n-         * unlinked from queue because it was the last inserted node\n-         * when it was cancelled.\n-         *\/\n-        transient volatile QNode cleanMe;\n-\n-        TransferQueue() {\n-            QNode h = new QNode(null, false); \/\/ initialize to dummy node.\n-            head = h;\n-            tail = h;\n-        }\n-\n-        \/**\n-         * Tries to cas nh as new head; if successful, unlink\n-         * old head's next node to avoid garbage retention.\n-         *\/\n-        void advanceHead(QNode h, QNode nh) {\n-            if (h == head &&\n-                QHEAD.compareAndSet(this, h, nh))\n-                h.next = h; \/\/ forget old next\n+            return m;\n@@ -610,1 +204,1 @@\n-         * Tries to cas nt as new tail.\n+         * Unlinks node s. Same idea as Fifo version.\n@@ -612,116 +206,7 @@\n-        void advanceTail(QNode t, QNode nt) {\n-            if (tail == t)\n-                QTAIL.compareAndSet(this, t, nt);\n-        }\n-\n-        \/**\n-         * Tries to CAS cleanMe slot.\n-         *\/\n-        boolean casCleanMe(QNode cmp, QNode val) {\n-            return cleanMe == cmp &&\n-                QCLEANME.compareAndSet(this, cmp, val);\n-        }\n-\n-        \/**\n-         * Puts or takes an item.\n-         *\/\n-        @SuppressWarnings(\"unchecked\")\n-        E transfer(E e, boolean timed, long nanos) {\n-            \/* Basic algorithm is to loop trying to take either of\n-             * two actions:\n-             *\n-             * 1. If queue apparently empty or holding same-mode nodes,\n-             *    try to add node to queue of waiters, wait to be\n-             *    fulfilled (or cancelled) and return matching item.\n-             *\n-             * 2. If queue apparently contains waiting items, and this\n-             *    call is of complementary mode, try to fulfill by CAS'ing\n-             *    item field of waiting node and dequeuing it, and then\n-             *    returning matching item.\n-             *\n-             * In each case, along the way, check for and try to help\n-             * advance head and tail on behalf of other stalled\/slow\n-             * threads.\n-             *\n-             * The loop starts off with a null check guarding against\n-             * seeing uninitialized head or tail values. This never\n-             * happens in current SynchronousQueue, but could if\n-             * callers held non-volatile\/final ref to the\n-             * transferer. The check is here anyway because it places\n-             * null checks at top of loop, which is usually faster\n-             * than having them implicitly interspersed.\n-             *\/\n-\n-            QNode s = null;                  \/\/ constructed\/reused as needed\n-            boolean isData = (e != null);\n-            for (;;) {\n-                QNode t = tail, h = head, m, tn;         \/\/ m is node to fulfill\n-                if (t == null || h == null)\n-                    ;                                    \/\/ inconsistent\n-                else if (h == t || t.isData == isData) { \/\/ empty or same-mode\n-                    if (t != tail)                       \/\/ inconsistent\n-                        ;\n-                    else if ((tn = t.next) != null)      \/\/ lagging tail\n-                        advanceTail(t, tn);\n-                    else if (timed && nanos <= 0L)       \/\/ can't wait\n-                        return null;\n-                    else if (t.casNext(null, (s != null) ? s :\n-                                       (s = new QNode(e, isData)))) {\n-                        advanceTail(t, s);\n-                        long deadline = timed ? System.nanoTime() + nanos : 0L;\n-                        Thread w = Thread.currentThread();\n-                        int stat = -1; \/\/ same idea as TransferStack\n-                        Object item;\n-                        while ((item = s.item) == e) {\n-                            if ((timed &&\n-                                 (nanos = deadline - System.nanoTime()) <= 0) ||\n-                                w.isInterrupted()) {\n-                                if (s.tryCancel(e)) {\n-                                    clean(t, s);\n-                                    return null;\n-                                }\n-                            } else if ((item = s.item) != e) {\n-                                break;                   \/\/ recheck\n-                            } else if (stat <= 0) {\n-                                if (t.next == s) {\n-                                    if (stat < 0 && t.isFulfilled()) {\n-                                        stat = 0;        \/\/ yield once if first\n-                                        Thread.yield();\n-                                    }\n-                                    else {\n-                                        stat = 1;\n-                                        s.waiter = w;\n-                                    }\n-                                }\n-                            } else if (!timed) {\n-                                LockSupport.setCurrentBlocker(this);\n-                                try {\n-                                    ForkJoinPool.managedBlock(s);\n-                                } catch (InterruptedException cannotHappen) { }\n-                                LockSupport.setCurrentBlocker(null);\n-                            }\n-                            else if (nanos > SPIN_FOR_TIMEOUT_THRESHOLD)\n-                                LockSupport.parkNanos(this, nanos);\n-                        }\n-                        if (stat == 1)\n-                            s.forgetWaiter();\n-                        if (!s.isOffList()) {            \/\/ not already unlinked\n-                            advanceHead(t, s);           \/\/ unlink if head\n-                            if (item != null)            \/\/ and forget fields\n-                                s.item = s;\n-                        }\n-                        return (item != null) ? (E)item : e;\n-                    }\n-\n-                } else if ((m = h.next) != null && t == tail && h == head) {\n-                    Thread waiter;\n-                    Object x = m.item;\n-                    boolean fulfilled = ((isData == (x == null)) &&\n-                                         x != m && m.casItem(x, e));\n-                    advanceHead(h, m);                    \/\/ (help) dequeue\n-                    if (fulfilled) {\n-                        if ((waiter = m.waiter) != null)\n-                            LockSupport.unpark(waiter);\n-                        return (x != null) ? (E)x : e;\n-                    }\n-                }\n+        private void unspliceLifo(DualNode s) {\n+            boolean seen = false; \/\/ try removing by collapsing head\n+            DualNode p = head;\n+            for (DualNode f, u; p != null && p.matched();) {\n+                if (p == s)\n+                    seen = true;\n+                p = (p == (u = cmpExHead(p, (f = p.next)))) ? f : u;\n@@ -729,21 +214,4 @@\n-        }\n-\n-        \/**\n-         * Gets rid of cancelled node s with original predecessor pred.\n-         *\/\n-        void clean(QNode pred, QNode s) {\n-            s.forgetWaiter();\n-            \/*\n-             * At any given time, exactly one node on list cannot be\n-             * deleted -- the last inserted node. To accommodate this,\n-             * if we cannot delete s, we save its predecessor as\n-             * \"cleanMe\", deleting the previously saved version\n-             * first. At least one of node s or the node previously\n-             * saved can always be deleted, so this always terminates.\n-             *\/\n-            while (pred.next == s) { \/\/ Return early if already unlinked\n-                QNode h = head;\n-                QNode hn = h.next;   \/\/ Absorb cancelled first node as head\n-                if (hn != null && hn.isCancelled()) {\n-                    advanceHead(h, hn);\n-                    continue;\n+            if (p != null && !seen && sweepNow()) { \/\/ occasionally sweep\n+                for (DualNode f, n, u; p != null && (f = p.next) != null; ) {\n+                    p = (!f.matched() ? f :\n+                         f == (u = p.cmpExNext(f, n = f.next)) ? n : u);\n@@ -751,49 +219,0 @@\n-                QNode t = tail;      \/\/ Ensure consistent read for tail\n-                if (t == h)\n-                    return;\n-                QNode tn = t.next;\n-                if (t != tail)\n-                    continue;\n-                if (tn != null) {\n-                    advanceTail(t, tn);\n-                    continue;\n-                }\n-                if (s != t) {        \/\/ If not tail, try to unsplice\n-                    QNode sn = s.next;\n-                    if (sn == s || pred.casNext(s, sn))\n-                        return;\n-                }\n-                QNode dp = cleanMe;\n-                if (dp != null) {    \/\/ Try unlinking previous cancelled node\n-                    QNode d = dp.next;\n-                    QNode dn;\n-                    if (d == null ||               \/\/ d is gone or\n-                        d == dp ||                 \/\/ d is off list or\n-                        !d.isCancelled() ||        \/\/ d not cancelled or\n-                        (d != t &&                 \/\/ d not tail and\n-                         (dn = d.next) != null &&  \/\/   has successor\n-                         dn != d &&                \/\/   that is on list\n-                         dp.casNext(d, dn)))       \/\/ d unspliced\n-                        casCleanMe(dp, null);\n-                    if (dp == pred)\n-                        return;      \/\/ s is already saved node\n-                } else if (casCleanMe(null, pred))\n-                    return;          \/\/ Postpone cleaning s\n-            }\n-        }\n-\n-        \/\/ VarHandle mechanics\n-        private static final VarHandle QHEAD;\n-        private static final VarHandle QTAIL;\n-        private static final VarHandle QCLEANME;\n-        static {\n-            try {\n-                MethodHandles.Lookup l = MethodHandles.lookup();\n-                QHEAD = l.findVarHandle(TransferQueue.class, \"head\",\n-                                        QNode.class);\n-                QTAIL = l.findVarHandle(TransferQueue.class, \"tail\",\n-                                        QNode.class);\n-                QCLEANME = l.findVarHandle(TransferQueue.class, \"cleanMe\",\n-                                           QNode.class);\n-            } catch (ReflectiveOperationException e) {\n-                throw new ExceptionInInitializerError(e);\n@@ -805,5 +224,1 @@\n-     * The transferer. Set only in constructor, but cannot be declared\n-     * as final without further complicating serialization.  Since\n-     * this is accessed only at most once per public method, there\n-     * isn't a noticeable performance penalty for using volatile\n-     * instead of final here.\n+     * The transferer. (See below about serialization.)\n@@ -811,1 +226,9 @@\n-    private transient volatile Transferer<E> transferer;\n+    private final transient Transferer<E> transferer;\n+\n+    private final transient boolean fair;\n+\n+    \/** Invokes fair or lifo transfer *\/\n+    private Object xfer(Object e, long nanos) {\n+        Transferer<E> x = transferer;\n+        return (fair) ? x.xfer(e, nanos) : x.xferLifo(e, nanos);\n+    }\n@@ -827,1 +250,2 @@\n-        transferer = fair ? new TransferQueue<E>() : new TransferStack<E>();\n+        this.fair = fair;\n+        transferer = new Transferer<E>();\n@@ -838,4 +262,5 @@\n-        if (e == null) throw new NullPointerException();\n-        if (transferer.transfer(e, false, 0) == null) {\n-            Thread.interrupted();\n-            throw new InterruptedException();\n+        Objects.requireNonNull(e);\n+        if (!Thread.interrupted()) {\n+            if (xfer(e, Long.MAX_VALUE) == null)\n+                return;\n+            Thread.interrupted(); \/\/ failure possible only due to interrupt\n@@ -843,0 +268,1 @@\n+        throw new InterruptedException();\n@@ -856,2 +282,3 @@\n-        if (e == null) throw new NullPointerException();\n-        if (transferer.transfer(e, true, unit.toNanos(timeout)) != null)\n+        Objects.requireNonNull(e);\n+        long nanos = Math.max(unit.toNanos(timeout), 0L);\n+        if (xfer(e, nanos) == null)\n@@ -874,2 +301,2 @@\n-        if (e == null) throw new NullPointerException();\n-        return transferer.transfer(e, true, 0) != null;\n+        Objects.requireNonNull(e);\n+        return xfer(e, 0L) == null;\n@@ -885,0 +312,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -886,4 +314,6 @@\n-        E e = transferer.transfer(null, false, 0);\n-        if (e != null)\n-            return e;\n-        Thread.interrupted();\n+        Object e;\n+        if (!Thread.interrupted()) {\n+            if ((e = xfer(null, Long.MAX_VALUE)) != null)\n+                return (E) e;\n+            Thread.interrupted();\n+        }\n@@ -902,0 +332,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -903,3 +334,4 @@\n-        E e = transferer.transfer(null, true, unit.toNanos(timeout));\n-        if (e != null || !Thread.interrupted())\n-            return e;\n+        Object e;\n+        long nanos = Math.max(unit.toNanos(timeout), 0L);\n+        if ((e = xfer(null, nanos)) != null || !Thread.interrupted())\n+            return (E) e;\n@@ -916,0 +348,1 @@\n+    @SuppressWarnings(\"unchecked\")\n@@ -917,1 +350,1 @@\n-        return transferer.transfer(null, true, 0);\n+        return (E) xfer(null, 0L);\n@@ -1107,5 +540,7 @@\n-     * To cope with serialization strategy in the 1.5 version of\n-     * SynchronousQueue, we declare some unused classes and fields\n-     * that exist solely to enable serializability across versions.\n-     * These fields are never used, so are initialized only if this\n-     * object is ever serialized or deserialized.\n+     * To cope with serialization across multiple implementation\n+     * overhauls, we declare some unused classes and fields that exist\n+     * solely to enable serializability across versions.  These fields\n+     * are never used, so are initialized only if this object is ever\n+     * serialized. We use readResolve to replace a deserialized queue\n+     * with a fresh one. Note that no queue elements are serialized,\n+     * since any existing ones are only transient.\n@@ -1133,1 +568,0 @@\n-        boolean fair = transferer instanceof TransferQueue;\n@@ -1148,5 +582,2 @@\n-     * Reconstitutes this queue from a stream (that is, deserializes it).\n-     * @param s the stream\n-     * @throws ClassNotFoundException if the class of a serialized object\n-     *         could not be found\n-     * @throws java.io.IOException if an I\/O error occurs\n+     * Replaces a deserialized SynchronousQueue with a fresh one with\n+     * the associated fairness\n@@ -1154,13 +585,2 @@\n-    private void readObject(java.io.ObjectInputStream s)\n-        throws java.io.IOException, ClassNotFoundException {\n-        s.defaultReadObject();\n-        if (waitingProducers instanceof FifoWaitQueue)\n-            transferer = new TransferQueue<E>();\n-        else\n-            transferer = new TransferStack<E>();\n-    }\n-\n-    static {\n-        \/\/ Reduce the risk of rare disastrous classloading in first call to\n-        \/\/ LockSupport.park: https:\/\/bugs.openjdk.org\/browse\/JDK-8074773\n-        Class<?> ensureLoaded = LockSupport.class;\n+    private Object readResolve() {\n+        return new SynchronousQueue<E>(waitingProducers instanceof FifoWaitQueue);\n","filename":"src\/java.base\/share\/classes\/java\/util\/concurrent\/SynchronousQueue.java","additions":144,"deletions":724,"binary":false,"changes":868,"status":"modified"},{"patch":"@@ -62,0 +62,1 @@\n+\n@@ -65,9 +66,14 @@\n-    public WhiteBox() throws ReflectiveOperationException {\n-        Class<?> qClass = LinkedTransferQueue.class;\n-        Class<?> nodeClass = Class.forName(qClass.getName() + \"$Node\");\n-        MethodHandles.Lookup lookup\n-            = MethodHandles.privateLookupIn(qClass, MethodHandles.lookup());\n-        HEAD = lookup.findVarHandle(qClass, \"head\", nodeClass);\n-        TAIL = lookup.findVarHandle(qClass, \"tail\", nodeClass);\n-        NEXT = lookup.findVarHandle(nodeClass, \"next\", nodeClass);\n-        ITEM = lookup.findVarHandle(nodeClass, \"item\", Object.class);\n+    public WhiteBox() throws Throwable { \/\/ throws ReflectiveOperationException {\n+        try {\n+            Class<?> qClass = LinkedTransferQueue.class;\n+            Class<?> nodeClass = Class.forName(qClass.getName() + \"$DualNode\");\n+            MethodHandles.Lookup lookup\n+                = MethodHandles.privateLookupIn(qClass, MethodHandles.lookup());\n+            HEAD = lookup.findVarHandle(qClass, \"head\", nodeClass);\n+            TAIL = lookup.findVarHandle(qClass, \"tail\", nodeClass);\n+            NEXT = lookup.findVarHandle(nodeClass, \"next\", nodeClass);\n+            ITEM = lookup.findVarHandle(nodeClass, \"item\", Object.class);\n+        } catch (Throwable ex) {\n+            ex.printStackTrace();\n+            throw ex;\n+        }\n@@ -81,0 +87,10 @@\n+    \/*\n+     * Modified for jdk22: Accommodate lazy initialization, so counts\n+     * may vary by 1, and some nodes become headers vs unlinked,\n+     * compared to previous versions.\n+     *\/\n+\n+    static void checkCount(int val, int expect) {\n+        assertTrue(val == expect || val == expect - 1);\n+    }\n+\n@@ -127,2 +143,4 @@\n-        assertNull(next(head(q)));\n-        assertNull(item(head(q)));\n+        if (head(q) != null) {\n+            assertNull(next(head(q)));\n+            assertNull(item(head(q)));\n+        }\n@@ -130,1 +148,1 @@\n-        assertEquals(nodeCount(q), 2);\n+        checkCount(nodeCount(q), 2);\n@@ -133,1 +151,1 @@\n-        assertEquals(nodeCount(q), 1);\n+        checkCount(nodeCount(q), 1);\n@@ -161,1 +179,1 @@\n-        assertEquals(nodeCount(q), n + 1);\n+        checkCount(nodeCount(q), n + 1);\n@@ -165,2 +183,2 @@\n-        assertEquals(nodeCount(q), n);\n-        assertIsSelfLinked(oldHead);\n+        checkCount(nodeCount(q), n);\n+        \/\/        assertIsSelfLinked(oldHead);\n@@ -207,1 +225,1 @@\n-        assertEquals(nodeCount(q), c - 1);\n+        checkCount(nodeCount(q), c - 1);\n@@ -220,1 +238,1 @@\n-        assertEquals(nodeCount(q), c - 1);\n+        checkCount(nodeCount(q), c - 1);\n@@ -231,1 +249,1 @@\n-        int n = rnd.nextInt(6);\n+        int n = 1 + rnd.nextInt(6);\n@@ -241,1 +259,1 @@\n-        assertEquals(q.size(), c - (q.contains(n - 1) ? 0 : 1));\n+        checkCount(c - (q.contains(n - 1) ? 0 : 1), q.size() + 1);\n@@ -266,1 +284,1 @@\n-        assertEquals(nodeCount(q), 1);\n+        checkCount(nodeCount(q), 1);\n@@ -292,1 +310,1 @@\n-        assertEquals(nodeCount(q), n + 1);\n+        checkCount(nodeCount(q), n + 1);\n@@ -298,1 +316,1 @@\n-            assertEquals(nodeCount(q), q.isEmpty() ? 1 : c - (slack ? 2 : 0));\n+            checkCount(nodeCount(q), q.isEmpty() ? 1 : c - (slack ? 2 : 0));\n@@ -321,1 +339,2 @@\n-            boolean slack = next(tail(q)) != null;\n+            boolean empty = (tail(q) == null);\n+            boolean slack = !empty && (next(tail(q)) != null);\n@@ -325,1 +344,1 @@\n-            else {\n+            else if (!empty) {\n@@ -368,2 +387,0 @@\n-        assertNotNull(head(q));\n-        assertNotNull(tail(q));\n@@ -371,2 +388,3 @@\n-        for (Object h; next(h = head(q)) == h; )\n-            assertNotSame(h, head(q)); \/\/ must be update race\n+        Object h;\n+        if ((h = head(q)) != null)\n+            assertNotSame(h, next(h));\n","filename":"test\/jdk\/java\/util\/concurrent\/LinkedTransferQueue\/WhiteBox.java","additions":47,"deletions":29,"binary":false,"changes":76,"status":"modified"}]}