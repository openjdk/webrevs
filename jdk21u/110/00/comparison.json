{"files":[{"patch":"@@ -26,0 +26,7 @@\n+#include \"asm\/macroAssembler.inline.hpp\"\n+#include \"code\/codeBlob.hpp\"\n+#include \"code\/codeCache.hpp\"\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"compiler\/oopMap.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n@@ -27,1 +34,62 @@\n-#include \"utilities\/debug.hpp\"\n+#include \"runtime\/globals.hpp\"\n+#include \"runtime\/stubCodeGenerator.hpp\"\n+\n+#define __ _masm->\n+\n+class DowncallStubGenerator : public StubCodeGenerator {\n+  BasicType* _signature;\n+  int _num_args;\n+  BasicType _ret_bt;\n+  const ABIDescriptor& _abi;\n+\n+  const GrowableArray<VMStorage>&  _input_registers;\n+  const GrowableArray<VMStorage>&  _output_registers;\n+\n+  bool _needs_return_buffer;\n+  int _captured_state_mask;\n+  bool _needs_transition;\n+\n+  int _frame_complete;\n+  int _frame_size_slots;\n+  OopMapSet* _oop_maps;\n+  public:\n+  DowncallStubGenerator(CodeBuffer* buffer,\n+                         BasicType* signature,\n+                         int num_args,\n+                         BasicType ret_bt,\n+                         const ABIDescriptor& abi,\n+                         const GrowableArray<VMStorage>& input_registers,\n+                         const GrowableArray<VMStorage>& output_registers,\n+                         bool needs_return_buffer,\n+                         int captured_state_mask,\n+                         bool needs_transition)\n+    :StubCodeGenerator(buffer, PrintMethodHandleStubs),\n+    _signature(signature),\n+    _num_args(num_args),\n+    _ret_bt(ret_bt),\n+    _abi(abi),\n+    _input_registers(input_registers),\n+    _output_registers(output_registers),\n+    _needs_return_buffer(needs_return_buffer),\n+    _captured_state_mask(captured_state_mask),\n+    _needs_transition(needs_transition),\n+    _frame_complete(0),\n+    _frame_size_slots(0),\n+    _oop_maps(nullptr) {\n+    }\n+  void generate();\n+  int frame_complete() const {\n+    return _frame_complete;\n+  }\n+\n+  int framesize() const {\n+    return (_frame_size_slots >> (LogBytesPerWord - LogBytesPerInt));\n+  }\n+\n+  OopMapSet* oop_maps() const {\n+    return _oop_maps;\n+  }\n+};\n+\n+static const int native_invoker_code_base_size = 512;\n+static const int native_invoker_size_per_args = 8;\n@@ -38,2 +106,193 @@\n-  Unimplemented();\n-  return nullptr;\n+\n+  int code_size = native_invoker_code_base_size + (num_args * native_invoker_size_per_args);\n+  int locs_size = 1; \/\/must be non zero\n+  CodeBuffer code(\"nep_invoker_blob\", code_size, locs_size);\n+\n+  DowncallStubGenerator g(&code, signature, num_args, ret_bt, abi,\n+                          input_registers, output_registers,\n+                          needs_return_buffer, captured_state_mask,\n+                          needs_transition);\n+  g.generate();\n+  code.log_section_sizes(\"nep_invoker_blob\");\n+\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n+                                  &code,\n+                                  g.frame_complete(),\n+                                  g.framesize(),\n+                                  g.oop_maps(), false);\n+\n+#ifndef PRODUCT\n+  LogTarget(Trace, foreign, downcall) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm;\n+    LogStream ls(lt);\n+    stub->print_on(&ls);\n+  }\n+#endif\n+\n+  return stub;\n+}\n+\n+void DowncallStubGenerator::generate() {\n+  Register call_target_address = Z_R1_scratch,\n+           tmp = Z_R0_scratch;\n+\n+  VMStorage shuffle_reg = _abi._scratch1;\n+\n+  JavaCallingConvention in_conv;\n+  NativeCallingConvention out_conv(_input_registers);\n+  ArgumentShuffle arg_shuffle(_signature, _num_args, _signature, _num_args, &in_conv, &out_conv, shuffle_reg);\n+\n+#ifndef PRODUCT\n+  LogTarget(Trace, foreign, downcall) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm;\n+    LogStream ls(lt);\n+    arg_shuffle.print_on(&ls);\n+  }\n+#endif\n+\n+  assert(_abi._shadow_space_bytes == frame::z_abi_160_size, \"expected space according to ABI\");\n+  int allocated_frame_size = _abi._shadow_space_bytes;\n+  allocated_frame_size += arg_shuffle.out_arg_bytes();\n+\n+  assert(!_needs_return_buffer, \"unexpected needs_return_buffer\");\n+  RegSpiller out_reg_spiller(_output_registers);\n+  int spill_offset = allocated_frame_size;\n+  allocated_frame_size += BytesPerWord;\n+\n+  StubLocations locs;\n+  locs.set(StubLocations::TARGET_ADDRESS, _abi._scratch2);\n+\n+  if (_captured_state_mask != 0) {\n+    __ block_comment(\"{ _captured_state_mask is set\");\n+    locs.set_frame_data(StubLocations::CAPTURED_STATE_BUFFER, allocated_frame_size);\n+    allocated_frame_size += BytesPerWord;\n+    __ block_comment(\"} _captured_state_mask is set\");\n+  }\n+\n+  allocated_frame_size = align_up(allocated_frame_size, StackAlignmentInBytes);\n+  _frame_size_slots = allocated_frame_size >> LogBytesPerInt;\n+\n+  _oop_maps  = _needs_transition ? new OopMapSet() : nullptr;\n+  address start = __ pc();\n+\n+  __ save_return_pc();\n+  __ push_frame(allocated_frame_size, Z_R11); \/\/ Create a new frame for the wrapper.\n+\n+  _frame_complete = __ pc() - start;  \/\/ frame build complete.\n+\n+  if (_needs_transition) {\n+    __ block_comment(\"{ thread java2native\");\n+    __ get_PC(Z_R1_scratch);\n+    address the_pc = __ pc();\n+    __ set_last_Java_frame(Z_SP, Z_R1_scratch);\n+\n+    OopMap* map = new OopMap(_frame_size_slots, 0);\n+    _oop_maps->add_gc_map(the_pc - start, map);\n+\n+    \/\/ State transition\n+    __ set_thread_state(_thread_in_native);\n+    __ block_comment(\"} thread java2native\");\n+  }\n+  __ block_comment(\"{ argument shuffle\");\n+  arg_shuffle.generate(_masm, shuffle_reg, frame::z_jit_out_preserve_size, _abi._shadow_space_bytes, locs);\n+  __ block_comment(\"} argument shuffle\");\n+\n+  __ call(as_Register(locs.get(StubLocations::TARGET_ADDRESS)));\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  if (_captured_state_mask != 0) {\n+    __ block_comment(\"{ save thread local\");\n+\n+      out_reg_spiller.generate_spill(_masm, spill_offset);\n+\n+    __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, DowncallLinker::capture_state));\n+    __ z_lg(Z_ARG1, Address(Z_SP, locs.data_offset(StubLocations::CAPTURED_STATE_BUFFER)));\n+    __ load_const_optimized(Z_ARG2, _captured_state_mask);\n+    __ call(call_target_address);\n+\n+      out_reg_spiller.generate_fill(_masm, spill_offset);\n+\n+    __ block_comment(\"} save thread local\");\n+  }\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  Label L_after_safepoint_poll;\n+  Label L_safepoint_poll_slow_path;\n+  Label L_reguard;\n+  Label L_after_reguard;\n+\n+  if (_needs_transition) {\n+    __ block_comment(\"{ thread native2java\");\n+    __ set_thread_state(_thread_in_native_trans);\n+\n+    if (!UseSystemMemoryBarrier) {\n+      __ z_fence(); \/\/ Order state change wrt. safepoint poll.\n+    }\n+\n+    __ safepoint_poll(L_safepoint_poll_slow_path, tmp);\n+\n+    __ load_and_test_int(tmp, Address(Z_thread, JavaThread::suspend_flags_offset()));\n+    __ z_brne(L_safepoint_poll_slow_path);\n+\n+    __ bind(L_after_safepoint_poll);\n+\n+    \/\/ change thread state\n+    __ set_thread_state(_thread_in_Java);\n+\n+    __ block_comment(\"reguard stack check\");\n+    __ z_cli(Address(Z_thread, JavaThread::stack_guard_state_offset() + in_ByteSize(sizeof(StackOverflow::StackGuardState) - 1)),\n+        StackOverflow::stack_guard_yellow_reserved_disabled);\n+    __ z_bre(L_reguard);\n+    __ bind(L_after_reguard);\n+\n+    __ reset_last_Java_frame();\n+    __ block_comment(\"} thread native2java\");\n+  }\n+\n+  __ pop_frame();\n+  __ restore_return_pc();             \/\/ This is the way back to the caller.\n+  __ z_br(Z_R14);\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  if (_needs_transition) {\n+    __ block_comment(\"{ L_safepoint_poll_slow_path\");\n+    __ bind(L_safepoint_poll_slow_path);\n+\n+      \/\/ Need to save the native result registers around any runtime calls.\n+      out_reg_spiller.generate_spill(_masm, spill_offset);\n+\n+    __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, JavaThread::check_special_condition_for_native_trans));\n+    __ z_lgr(Z_ARG1, Z_thread);\n+    __ call(call_target_address);\n+\n+      out_reg_spiller.generate_fill(_masm, spill_offset);\n+\n+    __ z_bru(L_after_safepoint_poll);\n+    __ block_comment(\"} L_safepoint_poll_slow_path\");\n+\n+    \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+    __ block_comment(\"{ L_reguard\");\n+    __ bind(L_reguard);\n+\n+      \/\/ Need to save the native result registers around any runtime calls.\n+      out_reg_spiller.generate_spill(_masm, spill_offset);\n+\n+    __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, SharedRuntime::reguard_yellow_pages));\n+    __ call(call_target_address);\n+\n+      out_reg_spiller.generate_fill(_masm, spill_offset);\n+\n+    __ z_bru(L_after_reguard);\n+\n+    __ block_comment(\"} L_reguard\");\n+  }\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ flush();\n","filename":"src\/hotspot\/cpu\/s390\/downcallLinker_s390.cpp","additions":262,"deletions":3,"binary":false,"changes":265,"status":"modified"},{"patch":"@@ -26,1 +26,6 @@\n-#include \"code\/vmreg.hpp\"\n+#include \"asm\/macroAssembler.inline.hpp\"\n+#include \"code\/vmreg.inline.hpp\"\n+#include \"runtime\/jniHandles.hpp\"\n+#include \"runtime\/jniHandles.inline.hpp\"\n+#include \"oops\/typeArrayOop.inline.hpp\"\n+#include \"oops\/oopCast.inline.hpp\"\n@@ -28,1 +33,3 @@\n-#include \"utilities\/debug.hpp\"\n+#include \"prims\/foreignGlobals.inline.hpp\"\n+#include \"prims\/vmstorage.hpp\"\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -30,1 +37,10 @@\n-class MacroAssembler;\n+#define __ masm->\n+\n+bool ABIDescriptor::is_volatile_reg(Register reg) const {\n+  return _integer_volatile_registers.contains(reg);\n+}\n+\n+bool ABIDescriptor::is_volatile_reg(FloatRegister reg) const {\n+  return _float_argument_registers.contains(reg)\n+          || _float_additional_volatile_registers.contains(reg);\n+}\n@@ -33,1 +49,1 @@\n-  return false;\n+  return true;\n@@ -37,2 +53,22 @@\n-  Unimplemented();\n-  return {};\n+  oop abi_oop = JNIHandles::resolve_non_null(jabi);\n+  ABIDescriptor abi;\n+\n+  objArrayOop inputStorage = jdk_internal_foreign_abi_ABIDescriptor::inputStorage(abi_oop);\n+  parse_register_array(inputStorage, StorageType::INTEGER, abi._integer_argument_registers, as_Register);\n+  parse_register_array(inputStorage, StorageType::FLOAT, abi._float_argument_registers, as_FloatRegister);\n+\n+  objArrayOop outputStorage = jdk_internal_foreign_abi_ABIDescriptor::outputStorage(abi_oop);\n+  parse_register_array(outputStorage, StorageType::INTEGER, abi._integer_return_registers, as_Register);\n+  parse_register_array(outputStorage, StorageType::FLOAT, abi._float_return_registers, as_FloatRegister);\n+\n+  objArrayOop volatileStorage = jdk_internal_foreign_abi_ABIDescriptor::volatileStorage(abi_oop);\n+  parse_register_array(volatileStorage, StorageType::INTEGER, abi._integer_volatile_registers, as_Register);\n+  parse_register_array(volatileStorage, StorageType::FLOAT, abi._float_additional_volatile_registers, as_FloatRegister);\n+\n+  abi._stack_alignment_bytes = jdk_internal_foreign_abi_ABIDescriptor::stackAlignment(abi_oop);\n+  abi._shadow_space_bytes = jdk_internal_foreign_abi_ABIDescriptor::shadowSpace(abi_oop);\n+\n+  abi._scratch1 = parse_vmstorage(jdk_internal_foreign_abi_ABIDescriptor::scratch1(abi_oop));\n+  abi._scratch2 = parse_vmstorage(jdk_internal_foreign_abi_ABIDescriptor::scratch2(abi_oop));\n+\n+  return abi;\n@@ -42,2 +78,4 @@\n-  Unimplemented();\n-  return -1;\n+  if (reg.type() == StorageType::INTEGER || reg.type() == StorageType::FLOAT) {\n+    return 8;\n+  }\n+  return 0; \/\/ stack and BAD\n@@ -47,1 +85,7 @@\n-  Unimplemented();\n+  if (reg.type() == StorageType::INTEGER) {\n+    __ reg2mem_opt(as_Register(reg), Address(Z_SP, offset), true);\n+  } else if (reg.type() == StorageType::FLOAT) {\n+    __ freg2mem_opt(as_FloatRegister(reg), Address(Z_SP, offset), true);\n+  } else {\n+    \/\/ stack and BAD\n+  }\n@@ -51,1 +95,106 @@\n-  Unimplemented();\n+  if (reg.type() == StorageType::INTEGER) {\n+    __ mem2reg_opt(as_Register(reg), Address(Z_SP, offset), true);\n+  } else if (reg.type() == StorageType::FLOAT) {\n+    __ mem2freg_opt(as_FloatRegister(reg), Address(Z_SP, offset), true);\n+  } else {\n+    \/\/ stack and BAD\n+  }\n+}\n+\n+static int reg2offset(VMStorage vms, int stk_bias) {\n+  assert(!vms.is_reg(), \"wrong usage\");\n+  return vms.index_or_offset() + stk_bias;\n+}\n+\n+static void move_reg(MacroAssembler* masm, int out_stk_bias,\n+                       VMStorage from_reg, VMStorage to_reg) {\n+  int out_bias = 0;\n+  switch (to_reg.type()) {\n+    case StorageType::INTEGER:\n+      if (to_reg.segment_mask() == REG64_MASK && from_reg.segment_mask() == REG32_MASK ) {\n+        \/\/ see CCallingConventionRequiresIntsAsLongs\n+        __ z_lgfr(as_Register(to_reg), as_Register(from_reg));\n+      } else {\n+        __ lgr_if_needed(as_Register(to_reg), as_Register(from_reg));\n+      }\n+      break;\n+    case StorageType::STACK:\n+      out_bias = out_stk_bias;  \/\/fallthrough\n+    case StorageType::FRAME_DATA: {\n+      \/\/ Integer types always get a 64 bit slot in C.\n+      if (from_reg.segment_mask() == REG32_MASK) {\n+        \/\/ see CCallingConventionRequiresIntsAsLongs\n+        __ z_lgfr(as_Register(from_reg), as_Register(from_reg));\n+      }\n+      switch (to_reg.stack_size()) {\n+        case 8: __ reg2mem_opt(as_Register(from_reg), Address(Z_SP, reg2offset(to_reg, out_bias)), true); break;\n+        case 4: __ reg2mem_opt(as_Register(from_reg), Address(Z_SP, reg2offset(to_reg, out_bias)), false); break;\n+        default: ShouldNotReachHere();\n+      }\n+    } break;\n+    default: ShouldNotReachHere();\n+  }\n+}\n+\n+static void move_float(MacroAssembler* masm, int out_stk_bias,\n+                       VMStorage from_reg, VMStorage to_reg) {\n+  switch (to_reg.type()) {\n+    case StorageType::FLOAT:\n+      if (from_reg.segment_mask() == REG64_MASK)\n+        __ move_freg_if_needed(as_FloatRegister(to_reg), T_DOUBLE, as_FloatRegister(from_reg), T_DOUBLE);\n+      else\n+        __ move_freg_if_needed(as_FloatRegister(to_reg), T_FLOAT, as_FloatRegister(from_reg), T_FLOAT);\n+      break;\n+    case StorageType::STACK:\n+      if (from_reg.segment_mask() == REG64_MASK) {\n+        assert(to_reg.stack_size() == 8, \"size should match\");\n+        __ freg2mem_opt(as_FloatRegister(from_reg), Address(Z_SP, reg2offset(to_reg, out_stk_bias)), true);\n+      } else {\n+        assert(to_reg.stack_size() == 4, \"size should match\");\n+        __ freg2mem_opt(as_FloatRegister(from_reg), Address(Z_SP, reg2offset(to_reg, out_stk_bias)), false);\n+      }\n+      break;\n+    default: ShouldNotReachHere();\n+  }\n+}\n+\n+static void move_stack(MacroAssembler* masm, Register tmp_reg, int in_stk_bias, int out_stk_bias,\n+                       VMStorage from_reg, VMStorage to_reg) {\n+  int out_bias = 0;\n+  Address from_addr(Z_R11, reg2offset(from_reg, in_stk_bias));\n+  switch (to_reg.type()) {\n+    case StorageType::INTEGER:\n+      switch (from_reg.stack_size()) {\n+        case 8: __ mem2reg_opt(as_Register(to_reg), from_addr, true);break;\n+        case 4: __ mem2reg_opt(as_Register(to_reg), from_addr, false);break;\n+        default: ShouldNotReachHere();\n+      }\n+      break;\n+    case StorageType::FLOAT:\n+      switch (from_reg.stack_size()) {\n+        case 8: __ mem2freg_opt(as_FloatRegister(to_reg), from_addr, true);break;\n+        case 4: __ mem2freg_opt(as_FloatRegister(to_reg), from_addr, false);break;\n+        default: ShouldNotReachHere();\n+      }\n+      break;\n+    case StorageType::STACK:\n+      out_bias = out_stk_bias; \/\/ fallthrough\n+    case StorageType::FRAME_DATA: {\n+      switch (from_reg.stack_size()) {\n+        case 8: __ mem2reg_opt(tmp_reg, from_addr, true); break;\n+        case 4: if (to_reg.stack_size() == 8) {\n+                  __ mem2reg_signed_opt(tmp_reg, from_addr);\n+                } else {\n+                  __ mem2reg_opt(tmp_reg, from_addr, false);\n+                }\n+                break;\n+        default: ShouldNotReachHere();\n+      }\n+      switch (to_reg.stack_size()) {\n+        case 8: __ reg2mem_opt(tmp_reg, Address (Z_SP, reg2offset(to_reg, out_bias)), true); break;\n+        case 4: __ reg2mem_opt(tmp_reg, Address (Z_SP, reg2offset(to_reg, out_bias)), false); break;\n+        default: ShouldNotReachHere();\n+      }\n+    } break;\n+    default: ShouldNotReachHere();\n+  }\n@@ -55,1 +204,27 @@\n-  Unimplemented();\n+  Register tmp_reg = as_Register(tmp);\n+  for (int i = 0; i < _moves.length(); i++) {\n+    Move move = _moves.at(i);\n+    VMStorage from_reg = move.from;\n+    VMStorage to_reg   = move.to;\n+\n+    \/\/ replace any placeholders\n+    if (from_reg.type() == StorageType::PLACEHOLDER) {\n+      from_reg = locs.get(from_reg);\n+    }\n+    if (to_reg.type() == StorageType::PLACEHOLDER) {\n+      to_reg = locs.get(to_reg);\n+    }\n+\n+    switch (from_reg.type()) {\n+      case StorageType::INTEGER:\n+        move_reg(masm, out_stk_bias, from_reg, to_reg);\n+        break;\n+      case StorageType::FLOAT:\n+        move_float(masm, out_stk_bias, from_reg, to_reg);\n+        break;\n+      case StorageType::STACK:\n+        move_stack(masm, tmp_reg, in_stk_bias, out_stk_bias, from_reg, to_reg);\n+        break;\n+      default: ShouldNotReachHere();\n+    }\n+  }\n","filename":"src\/hotspot\/cpu\/s390\/foreignGlobals_s390.cpp","additions":186,"deletions":11,"binary":false,"changes":197,"status":"modified"},{"patch":"@@ -27,1 +27,18 @@\n-class ABIDescriptor {};\n+struct ABIDescriptor {\n+  GrowableArray<Register> _integer_argument_registers;\n+  GrowableArray<Register> _integer_return_registers;\n+  GrowableArray<FloatRegister> _float_argument_registers;\n+  GrowableArray<FloatRegister> _float_return_registers;\n+\n+  GrowableArray<Register> _integer_volatile_registers;\n+  GrowableArray<FloatRegister> _float_additional_volatile_registers;\n+\n+  int32_t _stack_alignment_bytes;\n+  int32_t _shadow_space_bytes;\n+\n+  VMStorage _scratch1;\n+  VMStorage _scratch2;\n+\n+  bool is_volatile_reg(Register reg) const;\n+  bool is_volatile_reg(FloatRegister reg) const;\n+};\n","filename":"src\/hotspot\/cpu\/s390\/foreignGlobals_s390.hpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -221,2 +221,4 @@\n-  ShouldNotCallThis();\n-  return nullptr;\n+  assert(frame.is_upcall_stub_frame(), \"wrong frame\");\n+  \/\/ need unextended_sp here, since normal sp is wrong for interpreter callees\n+  return reinterpret_cast<UpcallStub::FrameData*>(\n+    reinterpret_cast<address>(frame.unextended_sp()) + in_bytes(_frame_data_offset));\n@@ -226,2 +228,19 @@\n-  ShouldNotCallThis();\n-  return false;\n+  assert(is_upcall_stub_frame(), \"must be optimized entry frame\");\n+  UpcallStub* blob = _cb->as_upcall_stub();\n+  JavaFrameAnchor* jfa = blob->jfa_for_frame(*this);\n+  return jfa->last_Java_sp() == nullptr;\n+}\n+\n+frame frame::sender_for_upcall_stub_frame(RegisterMap* map) const {\n+  assert(map != nullptr, \"map must be set\");\n+  UpcallStub* blob = _cb->as_upcall_stub();\n+  \/\/ Java frame called from C; skip all C frames and return top C\n+  \/\/ frame of that chunk as the sender\n+  JavaFrameAnchor* jfa = blob->jfa_for_frame(*this);\n+  assert(!upcall_stub_frame_is_first(), \"must have a frame anchor to go back to\");\n+  assert(jfa->last_Java_sp() > sp(), \"must be above this frame on stack\");\n+  map->clear();\n+  assert(map->include_argument_oops(), \"should be set by clear\");\n+  frame fr(jfa->last_Java_sp(), jfa->last_Java_pc());\n+\n+  return fr;\n","filename":"src\/hotspot\/cpu\/s390\/frame_s390.cpp","additions":23,"deletions":4,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -355,6 +355,4 @@\n-  if (is_entry_frame()) {\n-    return sender_for_entry_frame(map);\n-  }\n-  if (is_interpreted_frame()) {\n-    return sender_for_interpreter_frame(map);\n-  }\n+  if (is_entry_frame())       return sender_for_entry_frame(map);\n+  if (is_upcall_stub_frame()) return sender_for_upcall_stub_frame(map);\n+  if (is_interpreted_frame()) return sender_for_interpreter_frame(map);\n+\n","filename":"src\/hotspot\/cpu\/s390\/frame_s390.inline.hpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-const int StackAlignmentInBytes = 16;\n+const int StackAlignmentInBytes = 8;\n","filename":"src\/hotspot\/cpu\/s390\/globalDefinitions_s390.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -352,1 +352,10 @@\n-  __ should_not_reach_here();\n+  assert(nep_reg != noreg, \"required register\");\n+\n+  \/\/ Load the invoker, as NEP -> .invoker\n+  __ verify_oop(nep_reg);\n+\n+  __ z_lg(temp_target, Address(nep_reg,\n+        NONZERO(jdk_internal_foreign_abi_NativeEntryPoint::downcall_stub_address_offset_in_bytes())));\n+\n+  __ z_br(temp_target);\n+\n","filename":"src\/hotspot\/cpu\/s390\/methodHandles_s390.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -25,0 +25,3 @@\n+#include \"asm\/macroAssembler.inline.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n@@ -26,1 +29,5 @@\n-#include \"utilities\/debug.hpp\"\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"runtime\/signature.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n+#include \"utilities\/formatBuffer.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -28,0 +35,84 @@\n+#define __ _masm->\n+\n+\/\/ for callee saved regs, according to the caller's ABI\n+static int compute_reg_save_area_size(const ABIDescriptor& abi) {\n+  int size = 0;\n+  for (int i = 0; i < Register::number_of_registers; i++) {\n+    Register reg = as_Register(i);\n+    \/\/ Z_SP saved\/restored by prologue\/epilogue\n+    if (reg == Z_SP) continue;\n+    if (!abi.is_volatile_reg(reg)) {\n+      size += 8; \/\/ bytes\n+    }\n+  }\n+\n+  for (int i = 0; i < FloatRegister::number_of_registers; i++) {\n+    FloatRegister reg = as_FloatRegister(i);\n+    if (!abi.is_volatile_reg(reg)) {\n+      size += 8; \/\/ bytes\n+    }\n+  }\n+\n+  return size;\n+}\n+\n+static void preserve_callee_saved_registers(MacroAssembler* _masm, const ABIDescriptor& abi, int reg_save_area_offset) {\n+  \/\/ 1. iterate all registers in the architecture\n+  \/\/     - check if they are volatile or not for the given abi\n+  \/\/     - if NOT, we need to save it here\n+\n+  int offset = reg_save_area_offset;\n+\n+  __ block_comment(\"{ preserve_callee_saved_regs \");\n+  for (int i = 0; i < Register::number_of_registers; i++) {\n+    Register reg = as_Register(i);\n+    \/\/ Z_SP saved\/restored by prologue\/epilogue\n+    if (reg == Z_SP) continue;\n+    if (!abi.is_volatile_reg(reg)) {\n+      __ z_stg(reg, Address(Z_SP, offset));\n+      offset += 8;\n+    }\n+  }\n+\n+  for (int i = 0; i < FloatRegister::number_of_registers; i++) {\n+    FloatRegister reg = as_FloatRegister(i);\n+    if (!abi.is_volatile_reg(reg)) {\n+      __ z_std(reg, Address(Z_SP, offset));\n+      offset += 8;\n+    }\n+  }\n+\n+  __ block_comment(\"} preserve_callee_saved_regs \");\n+}\n+\n+static void restore_callee_saved_registers(MacroAssembler* _masm, const ABIDescriptor& abi, int reg_save_area_offset) {\n+  \/\/ 1. iterate all registers in the architecture\n+  \/\/     - check if they are volatile or not for the given abi\n+  \/\/     - if NOT, we need to restore it here\n+\n+  int offset = reg_save_area_offset;\n+\n+  __ block_comment(\"{ restore_callee_saved_regs \");\n+  for (int i = 0; i < Register::number_of_registers; i++) {\n+    Register reg = as_Register(i);\n+    \/\/ Z_SP saved\/restored by prologue\/epilogue\n+    if (reg == Z_SP) continue;\n+    if (!abi.is_volatile_reg(reg)) {\n+      __ z_lg(reg, Address(Z_SP, offset));\n+      offset += 8;\n+    }\n+  }\n+\n+  for (int i = 0; i < FloatRegister::number_of_registers; i++) {\n+    FloatRegister reg = as_FloatRegister(i);\n+    if (!abi.is_volatile_reg(reg)) {\n+      __ z_ld(reg, Address(Z_SP, offset));\n+      offset += 8;\n+    }\n+  }\n+\n+  __ block_comment(\"} restore_callee_saved_regs \");\n+}\n+\n+static const int upcall_stub_code_base_size = 1024; \/\/ depends on GC (resolve_jobject)\n+static const int upcall_stub_size_per_arg = 16; \/\/ arg save & restore + move\n@@ -34,2 +125,183 @@\n-  ShouldNotCallThis();\n-  return nullptr;\n+  ResourceMark rm;\n+  const ABIDescriptor abi = ForeignGlobals::parse_abi_descriptor(jabi);\n+  const CallRegs call_regs = ForeignGlobals::parse_call_regs(jconv);\n+  int code_size = upcall_stub_code_base_size + (total_in_args * upcall_stub_size_per_arg);\n+  CodeBuffer buffer(\"upcall_stub\", code_size, \/* locs_size = *\/ 0);\n+\n+  Register call_target_address = Z_R1_scratch;\n+\n+  VMStorage shuffle_reg = abi._scratch1;\n+  JavaCallingConvention out_conv;\n+  NativeCallingConvention in_conv(call_regs._arg_regs);\n+  ArgumentShuffle arg_shuffle(in_sig_bt, total_in_args, out_sig_bt, total_out_args, &in_conv, &out_conv, shuffle_reg);\n+\n+  \/\/ The Java call uses the JIT ABI, but we also call C.\n+  int out_arg_area = MAX2(frame::z_jit_out_preserve_size + arg_shuffle.out_arg_bytes(), (int)frame::z_abi_160_size);\n+\n+#ifndef PRODUCT\n+  LogTarget(Trace, foreign, upcall) lt;\n+  if (lt.is_enabled()) {\n+    ResourceMark rm;\n+    LogStream ls(lt);\n+    arg_shuffle.print_on(&ls);\n+  }\n+#endif\n+\n+\n+  int reg_save_area_size = compute_reg_save_area_size(abi);\n+  RegSpiller arg_spiller(call_regs._arg_regs);\n+  RegSpiller result_spiller(call_regs._ret_regs);\n+\n+  int res_save_area_offset  = out_arg_area;\n+  int arg_save_area_offset  = res_save_area_offset  + result_spiller.spill_size_bytes();\n+  int reg_save_area_offset  = arg_save_area_offset  + arg_spiller.spill_size_bytes();\n+  int frame_data_offset     = reg_save_area_offset  + reg_save_area_size;\n+  int frame_bottom_offset   = frame_data_offset     + sizeof(UpcallStub::FrameData);\n+\n+  int frame_size = align_up(frame_bottom_offset, StackAlignmentInBytes);\n+  StubLocations locs;\n+\n+  \/\/ The space we have allocated will look like:\n+  \/\/\n+  \/\/\n+  \/\/ FP-> |                     |\n+  \/\/      |---------------------| = frame_bottom_offset = frame_size\n+  \/\/      |                     |\n+  \/\/      | FrameData           |\n+  \/\/      |---------------------| = frame_data_offset\n+  \/\/      |                     |\n+  \/\/      | reg_save_area       |\n+  \/\/      |---------------------| = reg_save_are_offset\n+  \/\/      |                     |\n+  \/\/      | arg_save_area       |\n+  \/\/      |---------------------| = arg_save_are_offset\n+  \/\/      |                     |\n+  \/\/      | res_save_area       |\n+  \/\/      |---------------------| = res_save_are_offset\n+  \/\/      |                     |\n+  \/\/ SP-> | out_arg_area        |   needs to be at end for shadow space\n+  \/\/\n+  \/\/\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  MacroAssembler* _masm = new MacroAssembler(&buffer);\n+  address start = __ pc();\n+\n+  __ save_return_pc();\n+  assert((abi._stack_alignment_bytes % StackAlignmentInBytes) == 0, \"must be 8 byte aligned\");\n+  \/\/ allocate frame (frame_size is also aligned, so stack is still aligned)\n+  __ push_frame(frame_size);\n+\n+  \/\/ we have to always spill args since we need to do a call to get the thread\n+  \/\/ (and maybe attach it).\n+  arg_spiller.generate_spill(_masm, arg_save_area_offset);\n+  \/\/ Java methods won't preserve them, so save them here:\n+  preserve_callee_saved_registers(_masm, abi, reg_save_area_offset);\n+\n+  __ block_comment(\"{ on_entry\");\n+  __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, UpcallLinker::on_entry));\n+  __ z_aghik(Z_ARG1, Z_SP, frame_data_offset);\n+  __ call(call_target_address);\n+  __ z_lgr(Z_thread, Z_RET);\n+  __ block_comment(\"} on_entry\");\n+\n+  arg_spiller.generate_fill(_masm, arg_save_area_offset);\n+  __ block_comment(\"{ argument shuffle\");\n+  arg_shuffle.generate(_masm, shuffle_reg, abi._shadow_space_bytes, frame::z_jit_out_preserve_size, locs);\n+  __ block_comment(\"} argument shuffle\");\n+\n+  __ block_comment(\"{ receiver \");\n+  __ load_const_optimized(Z_ARG1, (intptr_t)receiver);\n+  __ resolve_jobject(Z_ARG1, Z_tmp_1, Z_tmp_2);\n+  __ block_comment(\"} receiver \");\n+\n+  __ load_const_optimized(Z_method, (intptr_t)entry);\n+  __ z_stg(Z_method, Address(Z_thread, in_bytes(JavaThread::callee_target_offset())));\n+\n+  __ z_lg(call_target_address, Address(Z_method, in_bytes(Method::from_compiled_offset())));\n+  __ call(call_target_address);\n+\n+  \/\/ return value shuffle\n+  assert(!needs_return_buffer, \"unexpected needs_return_buffer\");\n+  \/\/ CallArranger can pick a return type that goes in the same reg for both CCs.\n+  if (call_regs._ret_regs.length() > 0) { \/\/ 0 or 1\n+    VMStorage ret_reg = call_regs._ret_regs.at(0);\n+    \/\/ Check if the return reg is as expected.\n+    switch (ret_type) {\n+      case T_BOOLEAN:\n+      case T_BYTE:\n+      case T_SHORT:\n+      case T_CHAR:\n+      case T_INT:\n+        __ z_lgfr(Z_RET, Z_RET); \/\/ Clear garbage in high half.\n+                                 \/\/ fallthrough\n+      case T_LONG:\n+        assert(as_Register(ret_reg) == Z_RET, \"unexpected result register\");\n+        break;\n+      case T_FLOAT:\n+      case T_DOUBLE:\n+        assert(as_FloatRegister(ret_reg) == Z_FRET, \"unexpected result register\");\n+        break;\n+      default:\n+        fatal(\"unexpected return type: %s\", type2name(ret_type));\n+    }\n+  }\n+\n+  result_spiller.generate_spill(_masm, res_save_area_offset);\n+\n+  __ block_comment(\"{ on_exit\");\n+  __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, UpcallLinker::on_exit));\n+  __ z_aghik(Z_ARG1, Z_SP, frame_data_offset);\n+  __ call(call_target_address);\n+  __ block_comment(\"} on_exit\");\n+\n+  restore_callee_saved_registers(_masm, abi, reg_save_area_offset);\n+\n+  result_spiller.generate_fill(_masm, res_save_area_offset);\n+\n+  __ pop_frame();\n+  __ restore_return_pc();\n+  __ z_br(Z_R14);\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ exception handler\");\n+\n+  intptr_t exception_handler_offset = __ pc() - start;\n+\n+  \/\/ Native caller has no idea how to handle exceptions,\n+  \/\/ so we just crash here. Up to callee to catch exceptions.\n+  __ verify_oop(Z_ARG1);\n+  __ load_const_optimized(call_target_address, CAST_FROM_FN_PTR(uint64_t, UpcallLinker::handle_uncaught_exception));\n+  __ call_c(call_target_address);\n+  __ should_not_reach_here();\n+\n+  __ block_comment(\"} exception handler\");\n+\n+  _masm->flush();\n+\n+#ifndef PRODUCT\n+  stringStream ss;\n+  ss.print(\"upcall_stub_%s\", entry->signature()->as_C_string());\n+  const char* name = _masm->code_string(ss.as_string());\n+#else \/\/ PRODUCT\n+  const char* name = \"upcall_stub\";\n+#endif \/\/ PRODUCT\n+\n+  buffer.log_section_sizes(name);\n+  UpcallStub* blob\n+    = UpcallStub::create(name,\n+                         &buffer,\n+                         exception_handler_offset,\n+                         receiver,\n+                         in_ByteSize(frame_data_offset));\n+#ifndef PRODUCT\n+  if (lt.is_enabled()) {\n+    ResourceMark rm;\n+    LogStream ls(lt);\n+    blob->print_on(&ls);\n+  }\n+#endif\n+\n+  return blob->code_begin();\n","filename":"src\/hotspot\/cpu\/s390\/upcallLinker_s390.cpp","additions":275,"deletions":3,"binary":false,"changes":278,"status":"modified"},{"patch":"@@ -32,4 +32,6 @@\n-  STACK = 0,\n-  PLACEHOLDER = 1,\n-\/\/ special locations used only by native code\n-  FRAME_DATA = PLACEHOLDER + 1,\n+  INTEGER = 0,\n+  FLOAT = 1,\n+  STACK = 2,\n+  PLACEHOLDER = 3,\n+  \/\/ special locations used only by native code\n+  FRAME_DATA = 4,\n@@ -41,1 +43,1 @@\n-   return false;\n+  return type == StorageType::INTEGER || type == StorageType::FLOAT;\n@@ -47,0 +49,22 @@\n+\/\/ Needs to be consistent with S390Architecture.java.\n+constexpr uint16_t REG32_MASK = 0b0000000000000001;\n+constexpr uint16_t REG64_MASK = 0b0000000000000011;\n+\n+inline Register as_Register(VMStorage vms) {\n+  assert(vms.type() == StorageType::INTEGER, \"not the right type\");\n+  return ::as_Register(vms.index());\n+}\n+\n+inline FloatRegister as_FloatRegister(VMStorage vms) {\n+  assert(vms.type() == StorageType::FLOAT, \"not the right type\");\n+  return ::as_FloatRegister(vms.index());\n+}\n+\n+inline VMStorage as_VMStorage(Register reg, uint16_t segment_mask = REG64_MASK) {\n+  return VMStorage::reg_storage(StorageType::INTEGER, segment_mask, reg->encoding());\n+}\n+\n+inline VMStorage as_VMStorage(FloatRegister reg, uint16_t segment_mask = REG64_MASK) {\n+  return VMStorage::reg_storage(StorageType::FLOAT, segment_mask, reg->encoding());\n+}\n+\n@@ -48,0 +72,31 @@\n+  if (reg->is_Register()) {\n+    uint16_t segment_mask = 0;\n+    switch (bt) {\n+      case T_BOOLEAN:\n+      case T_CHAR   :\n+      case T_BYTE   :\n+      case T_SHORT  :\n+      case T_INT    : segment_mask = REG32_MASK; break;\n+      default       : segment_mask = REG64_MASK; break;\n+    }\n+    return as_VMStorage(reg->as_Register(), segment_mask);\n+  } else if (reg->is_FloatRegister()) {\n+    \/\/ FP regs always use double format. However, we need the correct format for loads \/stores.\n+    return as_VMStorage(reg->as_FloatRegister(), (bt == T_FLOAT) ? REG32_MASK : REG64_MASK);\n+  } else if (reg->is_stack()) {\n+    uint16_t size = 0;\n+    switch (bt) {\n+      case T_BOOLEAN:\n+      case T_CHAR   :\n+      case T_BYTE   :\n+      case T_SHORT  :\n+      case T_INT    :\n+      case T_FLOAT  : size = 4; break;\n+      default       : size = 8; break;\n+    }\n+    return VMStorage(StorageType::STACK, size,\n+        checked_cast<uint16_t>(reg->reg2stack() * VMRegImpl::stack_slot_size));\n+  } else if (!reg->is_valid()) {\n+    return VMStorage::invalid();\n+  }\n+\n@@ -52,1 +107,1 @@\n-#endif \/\/ CPU_S390_VMSTORAGE_S390_INLINE_HPP\n\\ No newline at end of file\n+#endif \/\/ CPU_S390_VMSTORAGE_S390_INLINE_HPP\n","filename":"src\/hotspot\/cpu\/s390\/vmstorage_s390.hpp","additions":61,"deletions":6,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+    LINUX_S390,\n@@ -84,1 +85,5 @@\n-            }\n+            } else if (arch.equals(\"s390x\")) {\n+                if (OperatingSystem.isLinux()) {\n+                    return LINUX_S390;\n+                }\n+        }\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/CABI.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+import jdk.internal.foreign.abi.s390.linux.LinuxS390Linker;\n@@ -63,1 +64,2 @@\n-                                                                      LinuxRISCV64Linker, FallbackLinker {\n+                                                                      LinuxRISCV64Linker, LinuxS390Linker,\n+                                                                      FallbackLinker {\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/AbstractLinker.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+import jdk.internal.foreign.abi.s390.linux.LinuxS390Linker;\n@@ -245,0 +246,1 @@\n+            case LINUX_S390 -> LinuxS390Linker.getInstance();\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/SharedUtils.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -0,0 +1,151 @@\n+\/*\n+ * Copyright (c) 2020, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023 IBM Corp. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package jdk.internal.foreign.abi.s390;\n+\n+import jdk.internal.foreign.abi.ABIDescriptor;\n+import jdk.internal.foreign.abi.Architecture;\n+import jdk.internal.foreign.abi.StubLocations;\n+import jdk.internal.foreign.abi.VMStorage;\n+\n+public final class S390Architecture implements Architecture {\n+    public static final Architecture INSTANCE = new S390Architecture();\n+\n+    \/\/ Needs to be consistent with vmstorage_s390.hpp.\n+    public static final short REG32_MASK = 0b0000_0000_0000_0001;\n+    public static final short REG64_MASK = 0b0000_0000_0000_0011;\n+\n+    private static final int INTEGER_REG_SIZE = 8;\n+    private static final int FLOAT_REG_SIZE = 8;\n+    private static final int STACK_SLOT_SIZE = 8;\n+\n+    \/\/ Suppresses default constructor, ensuring non-instantiability.\n+    private S390Architecture() {\n+    }\n+\n+    @Override\n+    public boolean isStackType(int cls) {\n+        return cls == StorageType.STACK;\n+    }\n+\n+    @Override\n+    public int typeSize(int cls) {\n+        switch (cls) {\n+            case StorageType.INTEGER:\n+                return INTEGER_REG_SIZE;\n+            case StorageType.FLOAT:\n+                return FLOAT_REG_SIZE;\n+                \/\/ STACK is deliberately omitted\n+        }\n+\n+        throw new IllegalArgumentException(\"Invalid Storage Class: \" + cls);\n+    }\n+\n+    public interface StorageType {\n+        byte INTEGER = 0;\n+        byte FLOAT = 1;\n+        byte STACK = 2;\n+        byte PLACEHOLDER = 3;\n+    }\n+\n+    public static class Regs { \/\/ break circular dependency\n+        public static final VMStorage r0 = integerRegister(0);\n+        public static final VMStorage r1 = integerRegister(1);\n+        public static final VMStorage r2 = integerRegister(2);\n+        public static final VMStorage r3 = integerRegister(3);\n+        public static final VMStorage r4 = integerRegister(4);\n+        public static final VMStorage r5 = integerRegister(5);\n+        public static final VMStorage r6 = integerRegister(6);\n+        public static final VMStorage r7 = integerRegister(7);\n+        public static final VMStorage r8 = integerRegister(8);\n+        public static final VMStorage r9 = integerRegister(9);\n+        public static final VMStorage r10 = integerRegister(10);\n+        public static final VMStorage r11 = integerRegister(11);\n+        public static final VMStorage r12 = integerRegister(12);\n+        public static final VMStorage r13 = integerRegister(13);\n+        public static final VMStorage r14 = integerRegister(14);\n+        public static final VMStorage r15 = integerRegister(15);\n+\n+        public static final VMStorage f0 = floatRegister(0);\n+        public static final VMStorage f1 = floatRegister(1);\n+        public static final VMStorage f2 = floatRegister(2);\n+        public static final VMStorage f3 = floatRegister(3);\n+        public static final VMStorage f4 = floatRegister(4);\n+        public static final VMStorage f5 = floatRegister(5);\n+        public static final VMStorage f6 = floatRegister(6);\n+        public static final VMStorage f7 = floatRegister(7);\n+        public static final VMStorage f8 = floatRegister(8);\n+        public static final VMStorage f9 = floatRegister(9);\n+        public static final VMStorage f10 = floatRegister(10);\n+        public static final VMStorage f11 = floatRegister(11);\n+        public static final VMStorage f12 = floatRegister(12);\n+        public static final VMStorage f13 = floatRegister(13);\n+        public static final VMStorage f14 = floatRegister(14);\n+        public static final VMStorage f15 = floatRegister(15);\n+    }\n+\n+    private static VMStorage integerRegister(int index) {\n+        return new VMStorage(StorageType.INTEGER, REG64_MASK, index, \"r\" + index);\n+    }\n+\n+    private static VMStorage floatRegister(int index) {\n+        return new VMStorage(StorageType.FLOAT, REG64_MASK, index, \"f\" + index);\n+    }\n+\n+    public static VMStorage stackStorage(short size, int byteOffset) {\n+        return new VMStorage(StorageType.STACK, size, byteOffset);\n+    }\n+\n+    public static ABIDescriptor abiFor(VMStorage[] inputIntRegs,\n+                                       VMStorage[] inputFloatRegs,\n+                                       VMStorage[] outputIntRegs,\n+                                       VMStorage[] outputFloatRegs,\n+                                       VMStorage[] volatileIntRegs,\n+                                       VMStorage[] volatileFloatRegs,\n+                                       int stackAlignment,\n+                                       int shadowSpace,\n+                                       VMStorage scratch1, VMStorage scratch2) {\n+        return new ABIDescriptor(\n+            INSTANCE,\n+            new VMStorage[][] {\n+                inputIntRegs,\n+                inputFloatRegs,\n+            },\n+            new VMStorage[][] {\n+                outputIntRegs,\n+                outputFloatRegs,\n+            },\n+            new VMStorage[][] {\n+                volatileIntRegs,\n+                volatileFloatRegs,\n+            },\n+            stackAlignment,\n+            shadowSpace,\n+            scratch1, scratch2,\n+            StubLocations.TARGET_ADDRESS.storage(StorageType.PLACEHOLDER),\n+            StubLocations.RETURN_BUFFER.storage(StorageType.PLACEHOLDER),\n+            StubLocations.CAPTURED_STATE_BUFFER.storage(StorageType.PLACEHOLDER));\n+    }\n+}\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/s390\/S390Architecture.java","additions":151,"deletions":0,"binary":false,"changes":151,"status":"added"},{"patch":"@@ -0,0 +1,311 @@\n+\/*\n+ * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023 IBM Corp. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package jdk.internal.foreign.abi.s390.linux;\n+\n+import java.lang.foreign.AddressLayout;\n+import java.lang.foreign.FunctionDescriptor;\n+import java.lang.foreign.GroupLayout;\n+import java.lang.foreign.MemoryLayout;\n+import java.lang.foreign.MemorySegment;\n+import jdk.internal.foreign.abi.ABIDescriptor;\n+import jdk.internal.foreign.abi.AbstractLinker.UpcallStubFactory;\n+import jdk.internal.foreign.abi.Binding;\n+import jdk.internal.foreign.abi.CallingSequence;\n+import jdk.internal.foreign.abi.CallingSequenceBuilder;\n+import jdk.internal.foreign.abi.DowncallLinker;\n+import jdk.internal.foreign.abi.LinkerOptions;\n+import jdk.internal.foreign.abi.UpcallLinker;\n+import jdk.internal.foreign.abi.SharedUtils;\n+import jdk.internal.foreign.abi.VMStorage;\n+import jdk.internal.foreign.Utils;\n+\n+import java.lang.foreign.ValueLayout;\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodType;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import static jdk.internal.foreign.abi.s390.linux.TypeClass.*;\n+import static jdk.internal.foreign.abi.s390.S390Architecture.*;\n+import static jdk.internal.foreign.abi.s390.S390Architecture.Regs.*;\n+\n+\/**\n+ * For the S390 C ABI specifically, this class uses CallingSequenceBuilder\n+ * to translate a C FunctionDescriptor into a CallingSequence, which can then be turned into a MethodHandle.\n+ *\n+ * This includes taking care of synthetic arguments like pointers to return buffers for 'in-memory' returns.\n+ *\/\n+public class LinuxS390CallArranger {\n+\n+    private static final int STACK_SLOT_SIZE = 8;\n+    public static final int MAX_REGISTER_ARGUMENTS = 5;\n+    public static final int MAX_FLOAT_REGISTER_ARGUMENTS = 4;\n+\n+    private static final ABIDescriptor CLinux = abiFor(\n+            new VMStorage[] { r2, r3, r4, r5, r6, }, \/\/ GP input\n+            new VMStorage[] { f0, f2, f4, f6 }, \/\/ FP input\n+            new VMStorage[] { r2, }, \/\/ GP output\n+            new VMStorage[] { f0, }, \/\/ FP output\n+            new VMStorage[] { r0, r1, r2, r3, r4, r5, r14 }, \/\/ volatile GP\n+            new VMStorage[] { f1, f3, f5, f7 }, \/\/ volatile FP (excluding argument registers)\n+            8, \/\/ Stack is always 8 byte aligned on S390\n+            160, \/\/ ABI header\n+            r0, r1 \/\/ scratch reg r0 & r1\n+            );\n+\n+    public record Bindings(CallingSequence callingSequence, boolean isInMemoryReturn) {}\n+\n+    public static Bindings getBindings(MethodType mt, FunctionDescriptor cDesc, boolean forUpcall) {\n+        return getBindings(mt, cDesc, forUpcall, LinkerOptions.empty());\n+    }\n+\n+    public static Bindings getBindings(MethodType mt, FunctionDescriptor cDesc, boolean forUpcall, LinkerOptions options) {\n+        CallingSequenceBuilder csb = new CallingSequenceBuilder(CLinux, forUpcall, options);\n+\n+        BindingCalculator argCalc = forUpcall ? new BoxBindingCalculator(true) : new UnboxBindingCalculator(true);\n+        BindingCalculator retCalc = forUpcall ? new UnboxBindingCalculator(false) : new BoxBindingCalculator(false);\n+\n+        boolean returnInMemory = isInMemoryReturn(cDesc.returnLayout());\n+        if (returnInMemory) {\n+            Class<?> carrier = MemorySegment.class;\n+            MemoryLayout layout =SharedUtils.C_POINTER;\n+            csb.addArgumentBindings(carrier, layout, argCalc.getBindings(carrier, layout));\n+        } else if (cDesc.returnLayout().isPresent()) {\n+            Class<?> carrier = mt.returnType();\n+            MemoryLayout layout = cDesc.returnLayout().get();\n+            csb.setReturnBindings(carrier, layout, retCalc.getBindings(carrier, layout));\n+        }\n+\n+        for (int i = 0; i < mt.parameterCount(); i++) {\n+            Class<?> carrier = mt.parameterType(i);\n+            MemoryLayout layout = cDesc.argumentLayouts().get(i);\n+            csb.addArgumentBindings(carrier, layout, argCalc.getBindings(carrier, layout));\n+        }\n+\n+        return new Bindings(csb.build(), returnInMemory);\n+    }\n+\n+    public static MethodHandle arrangeDowncall(MethodType mt, FunctionDescriptor cDesc, LinkerOptions options) {\n+        Bindings bindings = getBindings(mt, cDesc, false, options);\n+\n+        MethodHandle handle = new DowncallLinker(CLinux, bindings.callingSequence).getBoundMethodHandle();\n+\n+        if (bindings.isInMemoryReturn) {\n+            handle = SharedUtils.adaptDowncallForIMR(handle, cDesc, bindings.callingSequence);\n+        }\n+\n+        return handle;\n+    }\n+\n+    public static UpcallStubFactory arrangeUpcall(MethodType mt, FunctionDescriptor cDesc, LinkerOptions options) {\n+        Bindings bindings = getBindings(mt, cDesc, true, options);\n+\n+        final boolean dropReturn = true; \/* drop return, since we don't have bindings for it *\/\n+        return SharedUtils.arrangeUpcallHelper(mt, bindings.isInMemoryReturn, dropReturn, CLinux,\n+                bindings.callingSequence);\n+    }\n+\n+    private static boolean isInMemoryReturn(Optional<MemoryLayout> returnLayout) {\n+        return returnLayout\n+            .filter(layout -> layout instanceof GroupLayout)\n+            .isPresent();\n+    }\n+\n+    static class StorageCalculator {\n+        private final boolean forArguments;\n+\n+        private final int[] nRegs = new int[] { 0, 0 };\n+        private long stackOffset = 0;\n+\n+        public StorageCalculator(boolean forArguments) {\n+            this.forArguments = forArguments;\n+        }\n+\n+        VMStorage stackAlloc(long size, long alignment) {\n+            long alignedStackOffset = Utils.alignUp(stackOffset, alignment);\n+\n+            short encodedSize = (short) size;\n+            assert (encodedSize & 0xFFFF) == size;\n+\n+            VMStorage storage = stackStorage(encodedSize, (int) alignedStackOffset);\n+            stackOffset = alignedStackOffset + size;\n+            return storage;\n+        }\n+\n+        VMStorage regAlloc(int type) {\n+            int gpRegCnt = (type == StorageType.INTEGER) ? 1 : 0;\n+            int fpRegCnt = (type == StorageType.FLOAT) ? 1 : 0;\n+\n+            \/\/ Use stack if not enough registers available.\n+            if ((type == StorageType.FLOAT && (nRegs[StorageType.FLOAT] + fpRegCnt) > MAX_FLOAT_REGISTER_ARGUMENTS)\n+                    || (type == StorageType.INTEGER && (nRegs[StorageType.INTEGER] + gpRegCnt) > MAX_REGISTER_ARGUMENTS)) return null;\n+\n+            VMStorage[] source = (forArguments ? CLinux.inputStorage : CLinux.outputStorage)[type];\n+            VMStorage result = source[nRegs[type]];\n+\n+            nRegs[StorageType.INTEGER] += gpRegCnt;\n+            nRegs[StorageType.FLOAT] += fpRegCnt;\n+            return result;\n+\n+        }\n+        VMStorage getStorage(int type, boolean is32Bit) {\n+            VMStorage reg = regAlloc(type);\n+            if (reg != null) {\n+                if (is32Bit) {\n+                    reg = new VMStorage(reg.type(), REG32_MASK, reg.indexOrOffset());\n+                }\n+                return reg;\n+            }\n+            VMStorage stack;\n+            if (is32Bit) {\n+                stackAlloc(4, STACK_SLOT_SIZE); \/\/ Skip first half of stack slot.\n+                stack = stackAlloc(4, 4);\n+            } else\n+                stack = stackAlloc(8, STACK_SLOT_SIZE);\n+\n+            return stack;\n+        }\n+    }\n+\n+    abstract static class BindingCalculator {\n+        protected final StorageCalculator storageCalculator;\n+\n+        protected BindingCalculator(boolean forArguments) {\n+            this.storageCalculator = new LinuxS390CallArranger.StorageCalculator(forArguments);\n+        }\n+\n+        abstract List<Binding> getBindings(Class<?> carrier, MemoryLayout layout);\n+    }\n+\n+    \/\/ Compute recipe for transferring arguments \/ return values to C from Java.\n+    static class UnboxBindingCalculator extends BindingCalculator {\n+        UnboxBindingCalculator(boolean forArguments) {\n+            super(forArguments);\n+        }\n+\n+        @Override\n+        List<Binding> getBindings(Class<?> carrier, MemoryLayout layout) {\n+            TypeClass argumentClass = TypeClass.classifyLayout(layout);\n+            Binding.Builder bindings = Binding.builder();\n+            switch (argumentClass) {\n+                case STRUCT_REGISTER -> {\n+                    assert carrier == MemorySegment.class;\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);\n+                    bindings.bufferLoad(0, type)\n+                            .vmStore(storage, type);\n+                }\n+                case STRUCT_SFA -> {\n+                    assert carrier == MemorySegment.class;\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, layout.byteSize() == 4);\n+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), true);\n+                    bindings.bufferLoad(0, type)\n+                            .vmStore(storage, type);\n+                }\n+                case STRUCT_REFERENCE -> {\n+                    assert carrier == MemorySegment.class;\n+                    bindings.copy(layout)\n+                            .unboxAddress();\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.vmStore(storage, long.class);\n+                }\n+                case POINTER -> {\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.unboxAddress()\n+                            .vmStore(storage, long.class);\n+                }\n+                case INTEGER -> {\n+                    \/\/ ABI requires all int types to get extended to 64 bit.\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.vmStore(storage, carrier);\n+                }\n+                case FLOAT -> {\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);\n+                    bindings.vmStore(storage, carrier);\n+                }\n+                default -> throw new UnsupportedOperationException(\"Unhandled class \" + argumentClass);\n+            }\n+            return bindings.build();\n+        }\n+    }\n+\n+    \/\/ Compute recipe for transferring arguments \/ return values from C to Java.\n+    static class BoxBindingCalculator extends BindingCalculator {\n+        BoxBindingCalculator(boolean forArguments) {\n+            super(forArguments);\n+        }\n+\n+        @Override\n+        List<Binding> getBindings(Class<?> carrier, MemoryLayout layout) {\n+            TypeClass argumentClass = TypeClass.classifyLayout(layout);\n+            Binding.Builder bindings = Binding.builder();\n+            switch (argumentClass) {\n+                case STRUCT_REGISTER -> {\n+                    assert carrier == MemorySegment.class;\n+                    bindings.allocate(layout)\n+                            .dup();\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), false);\n+                    bindings.vmLoad(storage, type)\n+                            .bufferStore(0, type);\n+                }\n+                case STRUCT_SFA -> {\n+                    assert carrier == MemorySegment.class;\n+                    bindings.allocate(layout)\n+                            .dup();\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, layout.byteSize() == 4);\n+                    Class<?> type = SharedUtils.primitiveCarrierForSize(layout.byteSize(), true);\n+                    bindings.vmLoad(storage, type)\n+                            .bufferStore(0, type);\n+                }\n+                case STRUCT_REFERENCE -> {\n+                    assert carrier == MemorySegment.class;\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.vmLoad(storage, long.class)\n+                            .boxAddress(layout);\n+                }\n+                case POINTER -> {\n+                    AddressLayout addressLayout = (AddressLayout) layout;\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.vmLoad(storage, long.class)\n+                            .boxAddressRaw(Utils.pointeeByteSize(addressLayout), Utils.pointeeByteAlign(addressLayout));\n+                }\n+                case INTEGER -> {\n+                    \/\/ We could use carrier != long.class for BoxBindingCalculator, but C always uses 64 bit slots.\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.INTEGER, false);\n+                    bindings.vmLoad(storage, carrier);\n+                }\n+                case FLOAT -> {\n+                    VMStorage storage = storageCalculator.getStorage(StorageType.FLOAT, carrier == float.class);\n+                    bindings.vmLoad(storage, carrier);\n+                }\n+                default -> throw new UnsupportedOperationException(\"Unhandled class \" + argumentClass);\n+            }\n+            return bindings.build();\n+        }\n+    }\n+}\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/s390\/linux\/LinuxS390CallArranger.java","additions":311,"deletions":0,"binary":false,"changes":311,"status":"added"},{"patch":"@@ -0,0 +1,64 @@\n+\/*\n+ * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023 IBM Corp. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package jdk.internal.foreign.abi.s390.linux;\n+\n+import jdk.internal.foreign.abi.AbstractLinker;\n+import jdk.internal.foreign.abi.LinkerOptions;\n+\n+import java.lang.foreign.FunctionDescriptor;\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodType;\n+import java.nio.ByteOrder;\n+\n+public final class LinuxS390Linker extends AbstractLinker {\n+\n+    public static LinuxS390Linker getInstance() {\n+        final class Holder {\n+            private static final LinuxS390Linker INSTANCE = new LinuxS390Linker();\n+        }\n+\n+        return Holder.INSTANCE;\n+    }\n+\n+    private LinuxS390Linker() {\n+        \/\/ Ensure there is only one instance\n+    }\n+\n+    @Override\n+    protected MethodHandle arrangeDowncall(MethodType inferredMethodType, FunctionDescriptor function, LinkerOptions options) {\n+        return LinuxS390CallArranger.arrangeDowncall(inferredMethodType, function, options);\n+    }\n+\n+    @Override\n+    protected UpcallStubFactory arrangeUpcall(MethodType targetType, FunctionDescriptor function, LinkerOptions options) {\n+        return LinuxS390CallArranger.arrangeUpcall(targetType, function, options);\n+    }\n+\n+    @Override\n+    protected ByteOrder linkerByteOrder() {\n+        return ByteOrder.BIG_ENDIAN;\n+    }\n+}\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/s390\/linux\/LinuxS390Linker.java","additions":64,"deletions":0,"binary":false,"changes":64,"status":"added"},{"patch":"@@ -0,0 +1,126 @@\n+\/*\n+ * Copyright (c) 2022, 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2023 IBM Corp. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package jdk.internal.foreign.abi.s390.linux;\n+\n+import java.lang.foreign.GroupLayout;\n+import java.lang.foreign.MemoryLayout;\n+import java.lang.foreign.MemorySegment;\n+import java.lang.foreign.SequenceLayout;\n+import java.lang.foreign.ValueLayout;\n+import java.util.List;\n+import java.util.ArrayList;\n+\n+public enum TypeClass {\n+    STRUCT_REGISTER,\n+    STRUCT_SFA, \/\/ Single Float Aggregate\n+    STRUCT_REFERENCE,\n+    POINTER,\n+    INTEGER,\n+    FLOAT;\n+\n+    private static TypeClass classifyValueType(ValueLayout type) {\n+        Class<?> carrier = type.carrier();\n+        if (carrier == boolean.class || carrier == byte.class || carrier == char.class ||\n+                carrier == short.class || carrier == int.class || carrier == long.class) {\n+            return INTEGER;\n+        } else if (carrier == float.class || carrier == double.class) {\n+            return FLOAT;\n+        } else if (carrier == MemorySegment.class) {\n+            return POINTER;\n+        } else {\n+            throw new IllegalStateException(\"Cannot get here: \" + carrier.getName());\n+        }\n+    }\n+\n+    private static boolean isRegisterAggregate(MemoryLayout type) {\n+        long byteSize = type.byteSize();\n+        if (byteSize > 8 || byteSize == 3 || byteSize == 5 || byteSize == 6 || byteSize == 7)\n+            return false;\n+        return true;\n+    }\n+\n+    static List<MemoryLayout> scalarLayouts(GroupLayout gl) {\n+        List<MemoryLayout> out = new ArrayList<>();\n+        scalarLayoutsInternal(out, gl);\n+        return out;\n+    }\n+\n+    private static void scalarLayoutsInternal(List<MemoryLayout> out, GroupLayout gl) {\n+        for (MemoryLayout member : gl.memberLayouts()) {\n+            if (member instanceof GroupLayout memberGl) {\n+                scalarLayoutsInternal(out, memberGl);\n+            } else if (member instanceof SequenceLayout memberSl) {\n+                for (long i = 0; i < memberSl.elementCount(); i++) {\n+                    out.add(memberSl.elementLayout());\n+                }\n+            } else {\n+                \/\/ padding or value layouts\n+                out.add(member);\n+            }\n+        }\n+    }\n+\n+    static boolean isSingleFloatAggregate(MemoryLayout type) {\n+        List<MemoryLayout> scalarLayouts = scalarLayouts((GroupLayout) type);\n+\n+        final int numElements = scalarLayouts.size();\n+        if (numElements > 1 || numElements == 0)\n+            return false;\n+\n+        MemoryLayout baseType = scalarLayouts.get(0);\n+\n+        if (!(baseType instanceof ValueLayout))\n+            return false;\n+\n+        TypeClass baseArgClass = classifyValueType((ValueLayout) baseType);\n+        if (baseArgClass != FLOAT)\n+            return false;\n+\n+        return true;\n+    }\n+\n+    private static TypeClass classifyStructType(MemoryLayout layout) {\n+\n+        if (!isRegisterAggregate(layout)) {\n+            return TypeClass.STRUCT_REFERENCE;\n+        }\n+\n+        if (isSingleFloatAggregate(layout)) {\n+            return TypeClass.STRUCT_SFA;\n+        }\n+        return TypeClass.STRUCT_REGISTER;\n+    }\n+\n+    public static TypeClass classifyLayout(MemoryLayout type) {\n+        if (type instanceof ValueLayout) {\n+            return classifyValueType((ValueLayout) type);\n+        } else if (type instanceof GroupLayout) {\n+            return classifyStructType(type);\n+        } else {\n+            throw new IllegalArgumentException(\"Unsupported layout: \" + type);\n+        }\n+    }\n+}\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/s390\/linux\/TypeClass.java","additions":126,"deletions":0,"binary":false,"changes":126,"status":"added"},{"patch":"@@ -34,0 +34,1 @@\n+import java.nio.ByteOrder;\n@@ -36,1 +37,1 @@\n-import static java.lang.foreign.ValueLayout.JAVA_BYTE;\n+import static java.lang.foreign.ValueLayout.JAVA_INT;\n@@ -61,2 +62,2 @@\n-        MemorySegment segment = SymbolLookup.loaderLookup().find(\"c\").get().reinterpret(1);\n-        assertEquals(segment.get(JAVA_BYTE, 0), 42);\n+        MemorySegment segment = SymbolLookup.loaderLookup().find(\"c\").get().reinterpret(4);\n+        assertEquals(segment.get(JAVA_INT, 0), 42);\n","filename":"test\/jdk\/java\/foreign\/TestClassLoaderFindNative.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -57,0 +57,1 @@\n+    private static final boolean IS_LE = ByteOrder.nativeOrder() == ByteOrder.LITTLE_ENDIAN;\n@@ -116,1 +117,1 @@\n-                    \"Unsupported layout: [2:i4]\"\n+                    IS_LE ? \"Unsupported layout: [2:i4]\" : \"Unsupported layout: [2:I4]\"\n@@ -121,1 +122,1 @@\n-                    \"Unsupported layout: [2:i4]\"\n+                    IS_LE ? \"Unsupported layout: [2:i4]\" : \"Unsupported layout: [2:I4]\"\n@@ -126,1 +127,1 @@\n-                    \"Unsupported layout: 2%i4\"\n+                    IS_LE ? \"Unsupported layout: 2%i4\" : \"Unsupported layout: 2%I4\"\n@@ -131,1 +132,1 @@\n-                    \"Unsupported layout: 2%a8\"\n+                    IS_LE ? \"Unsupported layout: 2%a8\" : \"Unsupported layout: 2%A8\"\n@@ -136,1 +137,1 @@\n-                    \"Unsupported layout: 4%c2\"\n+                    IS_LE ? \"Unsupported layout: 4%c2\" : \"Unsupported layout: 4%C2\"\n@@ -145,1 +146,1 @@\n-                    \"Unsupported layout: 1%s2\"\n+                    IS_LE ? \"Unsupported layout: 1%s2\" : \"Unsupported layout: 1%S2\"\n@@ -155,1 +156,1 @@\n-                    \"Unsupported layout: 1%s2\"\n+                    IS_LE ? \"Unsupported layout: 1%s2\" : \"Unsupported layout: 1%S2\"\n@@ -163,1 +164,1 @@\n-                    \"Unsupported layout: 1%i4\"\n+                    IS_LE ? \"Unsupported layout: 1%i4\" : \"Unsupported layout: 1%I4\"\n@@ -176,1 +177,1 @@\n-                    \"Unsupported layout: I4\"\n+                    IS_LE ? \"Unsupported layout: I4\" : \"Unsupported layout: i4\"\n@@ -181,1 +182,1 @@\n-                    \"Unsupported layout: I4\"\n+                    IS_LE ? \"Unsupported layout: I4\" : \"Unsupported layout: i4\"\n@@ -186,1 +187,1 @@\n-                    \"Unsupported layout: I4\"\n+                    IS_LE ? \"Unsupported layout: I4\" : \"Unsupported layout: i4\"\n@@ -230,1 +231,0 @@\n-\n","filename":"test\/jdk\/java\/foreign\/TestIllegalLink.java","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -308,1 +308,0 @@\n-\n","filename":"test\/jdk\/java\/foreign\/callarranger\/platform\/PlatformLayouts.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}