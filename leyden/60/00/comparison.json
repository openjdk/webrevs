{"files":[{"patch":"@@ -131,1 +131,1 @@\n-      SCCache.cpp \\\n+      aotCodeCache.cpp \\\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -533,2 +533,2 @@\n-      if (SCCache::is_on_for_write()) {\n-        \/\/ SCA needs relocation info for card table base\n+      if (AOTCodeCache::is_on_for_write()) {\n+        \/\/ AOT code needs relocation info for card table base\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -217,1 +217,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n@@ -242,1 +242,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -31,3 +31,0 @@\n-#if INCLUDE_CDS\n-#include \"code\/SCCache.hpp\"\n-#endif\n@@ -702,1 +699,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n@@ -889,1 +886,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n@@ -3272,1 +3269,1 @@\n-  SCCache::add_C_string(msg);\n+  AOTCodeCache::add_C_string(msg);\n@@ -3370,1 +3367,1 @@\n-    if (Universe::is_fully_initialized() && !SCCache::is_on_for_write()) {\n+    if (Universe::is_fully_initialized() && !AOTCodeCache::is_on_for_write()) {\n@@ -5740,2 +5737,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ SCA needs relocation info for card table base\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ AOT code needs relocation info for card table base\n@@ -5754,2 +5751,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ all aotrc field addresses should be registered in the SCC address table\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ all aotrc field addresses should be registered in the AOTCodeCache address table\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":8,"deletions":11,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -1319,1 +1319,1 @@\n-    if (SCCache::is_on_for_write()) {\n+    if (AOTCodeCache::is_on_for_write()) {\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -5891,1 +5891,1 @@\n-    if (SCCache::load_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start)) {\n+    if (AOTCodeCache::load_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start)) {\n@@ -5915,1 +5915,1 @@\n-    SCCache::store_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start);\n+    AOTCodeCache::store_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start);\n@@ -5928,1 +5928,1 @@\n-    if (SCCache::load_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start)) {\n+    if (AOTCodeCache::load_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start)) {\n@@ -5957,1 +5957,1 @@\n-    SCCache::store_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start);\n+    AOTCodeCache::store_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start);\n@@ -5968,1 +5968,1 @@\n-    if (SCCache::load_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start)) {\n+    if (AOTCodeCache::load_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start)) {\n@@ -5983,1 +5983,1 @@\n-    SCCache::store_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start);\n+    AOTCodeCache::store_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start);\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -536,2 +536,2 @@\n-      if (SCCache::is_on_for_write()) {\n-        \/\/ SCA needs relocation info for card table base\n+      if (AOTCodeCache::is_on_for_write()) {\n+        \/\/ AOTCodeCache needs relocation info for card table base\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -310,1 +310,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n@@ -344,1 +344,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n@@ -363,2 +363,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ SCA needs relocation info for this address\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ AOT code needs relocation info for this address\n@@ -719,2 +719,2 @@\n-  if (SCCache::is_on()) {\n-    \/\/ SCA needs relocation info for this address\n+  if (AOTCodeCache::is_on()) {\n+    \/\/ AOT code needs relocation info for this address\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1BarrierSetAssembler_x86.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -68,2 +68,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ SCA needs relocation info for this address\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ AOT code needs relocation info for this address\n@@ -112,2 +112,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ SCA needs relocation info for this address\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ AOT code needs relocation info for this address\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/cardTableBarrierSetAssembler_x86.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -763,1 +763,1 @@\n-  SCCache::add_C_string(msg);\n+  AOTCodeCache::add_C_string(msg);\n@@ -10899,2 +10899,2 @@\n-  if (SCCache::is_on_for_write()) {\n-    \/\/ all aotrc field addresses should be registered in the SCC address table\n+  if (AOTCodeCache::is_on_for_write()) {\n+    \/\/ all aotrc field addresses should be registered in the AOTCodeCache address table\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -273,1 +273,1 @@\n-  if (SCCache::load_exception_blob(&buffer, &pc_offset)) {\n+  if (AOTCodeCache::load_exception_blob(&buffer, &pc_offset)) {\n@@ -370,1 +370,1 @@\n-  SCCache::store_exception_blob(&buffer, pc_offset);\n+  AOTCodeCache::store_exception_blob(&buffer, pc_offset);\n","filename":"src\/hotspot\/cpu\/x86\/runtime_x86_64.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -3163,1 +3163,1 @@\n-  if (SCCache::load_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start)) {\n+  if (AOTCodeCache::load_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start)) {\n@@ -3203,1 +3203,1 @@\n-  SCCache::store_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start);\n+  AOTCodeCache::store_stub(this, vmIntrinsics::_multiplyToLen, \"multiplyToLen\", start);\n@@ -3277,1 +3277,1 @@\n-  if (SCCache::load_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start)) {\n+  if (AOTCodeCache::load_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start)) {\n@@ -3308,1 +3308,1 @@\n-  SCCache::store_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start);\n+  AOTCodeCache::store_stub(this, vmIntrinsics::_squareToLen, \"squareToLen\", start);\n@@ -3408,1 +3408,1 @@\n-  if (SCCache::load_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start)) {\n+  if (AOTCodeCache::load_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start)) {\n@@ -3445,1 +3445,1 @@\n-  SCCache::store_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start);\n+  AOTCodeCache::store_stub(this, vmIntrinsics::_mulAdd, \"mulAdd\", start);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1853,1 +1853,1 @@\n-    if (SCCache::is_on_for_write()) {\n+    if (AOTCodeCache::is_on_for_write()) {\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-  AD.addInclude(AD._CPP_file, \"code\/SCCache.hpp\");\n+  AD.addInclude(AD._CPP_file, \"code\/aotCodeCache.hpp\");\n@@ -261,1 +261,1 @@\n-  AD.addInclude(AD._DFA_file, \"code\/SCCache.hpp\");\n+  AD.addInclude(AD._DFA_file, \"code\/aotCodeCache.hpp\");\n","filename":"src\/hotspot\/share\/adlc\/main.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -93,1 +93,1 @@\n-  friend class SCCReader;\n+  friend class AOTCodeReader;\n@@ -519,1 +519,1 @@\n-  friend class SCCReader;\n+  friend class AOTCodeReader;\n","filename":"src\/hotspot\/share\/asm\/codeBuffer.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -57,1 +57,1 @@\n-  SCCache::init_c1_table();\n+  AOTCodeCache::init_c1_table();\n@@ -257,1 +257,1 @@\n-  if (install_code && task->is_scc()) {\n+  if (install_code && task->is_aot()) {\n@@ -259,1 +259,1 @@\n-    bool success = SCCache::load_nmethod(env, method, entry_bci, this, CompLevel(task->comp_level()));\n+    bool success = AOTCodeCache::load_nmethod(env, method, entry_bci, this, CompLevel(task->comp_level()));\n@@ -264,2 +264,2 @@\n-    SCCache::invalidate(task->scc_entry()); \/\/ mark scc_entry as not entrant\n-    if (SCCache::is_code_load_thread_on() && !StoreCachedCode) {\n+    AOTCodeCache::invalidate(task->aot_code_entry()); \/\/ mark aot_code_entry as not entrant\n+    if (AOTCodeCache::is_code_load_thread_on() && !StoreCachedCode) {\n@@ -271,1 +271,1 @@\n-    task->clear_scc();\n+    task->clear_aot();\n","filename":"src\/hotspot\/share\/c1\/c1_Compiler.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -3196,7 +3196,7 @@\n-if (SCCache::is_on()) {\n-    counter_holder = new_register(T_METADATA);\n-    __ metadata2reg(counters_adr, counter_holder);\n-} else {\n-    counter_holder = new_pointer_register();\n-    __ move(LIR_OprFact::intptrConst(counters_adr), counter_holder);\n-}\n+    if (AOTCodeCache::is_on()) {\n+      counter_holder = new_register(T_METADATA);\n+      __ metadata2reg(counters_adr, counter_holder);\n+    } else {\n+      counter_holder = new_pointer_register();\n+      __ move(LIR_OprFact::intptrConst(counters_adr), counter_holder);\n+    }\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -46,1 +46,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -333,2 +333,2 @@\n-  \/\/ SCCache::max_aot_code_size() accounts for cached code region.\n-  size_t buffer_size = LP64_ONLY(CompressedClassSpaceSize) NOT_LP64(256 * M) + SCCache::max_aot_code_size();\n+  \/\/ AOTCodeCache::max_aot_code_size() accounts for cached code region.\n+  size_t buffer_size = LP64_ONLY(CompressedClassSpaceSize) NOT_LP64(256 * M) + AOTCodeCache::max_aot_code_size();\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-#include \"code\/SCCache.hpp\"\n","filename":"src\/hotspot\/share\/cds\/cdsConfig.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -64,1 +65,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -1101,2 +1101,2 @@\n-        \/\/ Write the contents to cached code region and close SCCache before packing the region\n-        SCCache::close();\n+        \/\/ Write the contents to cached code region and close AOTCodeCache before packing the region\n+        AOTCodeCache::close();\n@@ -2103,1 +2103,1 @@\n-  SCCache::initialize();\n+  AOTCodeCache::initialize();\n@@ -2158,1 +2158,1 @@\n-      SCCache::print_on(tty);\n+      AOTCodeCache::print_on(tty);\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -43,1 +44,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -181,1 +181,1 @@\n-  _scc_clinit_barriers_entry = nullptr;\n+  _aot_clinit_barriers_entry = nullptr;\n@@ -303,1 +303,1 @@\n-  _scc_clinit_barriers_entry = nullptr;\n+  _aot_clinit_barriers_entry = nullptr;\n@@ -981,2 +981,2 @@\n-\/\/ scc_entry != nullptr implies loading compiled code from AOT code cache\n-bool ciEnv::is_compilation_valid(JavaThread* thread, ciMethod* target, bool preload, bool install_code, CodeBuffer* code_buffer, SCCEntry* scc_entry) {\n+\/\/ aot_code_entry != nullptr implies loading compiled code from AOT code cache\n+bool ciEnv::is_compilation_valid(JavaThread* thread, ciMethod* target, bool preload, bool install_code, CodeBuffer* code_buffer, AOTCodeEntry* aot_code_entry) {\n@@ -994,1 +994,1 @@\n-  if (scc_entry != nullptr) {\n+  if (aot_code_entry != nullptr) {\n@@ -996,3 +996,3 @@\n-    \/\/  - SCCache is closed, SCC entry is garbage.\n-    \/\/  - SCC entry indicates this shared code was marked invalid while it was loaded.\n-    if (!SCCache::is_on() || scc_entry->not_entrant()) {\n+    \/\/  - AOTCodeCache is closed, AOTCode entry is garbage.\n+    \/\/  - AOTCode entry indicates this shared code was marked invalid while it was loaded.\n+    if (!AOTCodeCache::is_on() || aot_code_entry->not_entrant()) {\n@@ -1020,1 +1020,1 @@\n-  if (!failing() && (scc_entry == nullptr)) {\n+  if (!failing() && (aot_code_entry == nullptr)) {\n@@ -1036,1 +1036,1 @@\n-      log_info(scc)(\"preload code for '%s' failed dependency check\", method_name);\n+      log_info(aot, codecache)(\"preload code for '%s' failed dependency check\", method_name);\n@@ -1055,1 +1055,1 @@\n-void ciEnv::make_code_usable(JavaThread* thread, ciMethod* target, bool preload, int entry_bci, SCCEntry* scc_entry, nmethod* nm) {\n+void ciEnv::make_code_usable(JavaThread* thread, ciMethod* target, bool preload, int entry_bci, AOTCodeEntry* aot_code_entry, nmethod* nm) {\n@@ -1076,1 +1076,1 @@\n-      lt.print(\"Installing method (L%d) %s id=%d scc=%s%s%u\",\n+      lt.print(\"Installing method (L%d) %s id=%d aot=%s%s%u\",\n@@ -1078,2 +1078,2 @@\n-               task()->is_scc() ? \"A\" : \"\", preload ? \"P\" : \"\",\n-               (scc_entry != nullptr ? scc_entry->offset() : 0));\n+               task()->is_aot() ? \"A\" : \"\", preload ? \"P\" : \"\",\n+               (aot_code_entry != nullptr ? aot_code_entry->offset() : 0));\n@@ -1105,1 +1105,1 @@\n-      lt.print(\"Installing osr method (L%d) %s @ %d id=%u scc=%s%u\",\n+      lt.print(\"Installing osr method (L%d) %s @ %d id=%u aot=%s%u\",\n@@ -1107,2 +1107,2 @@\n-               task()->is_scc() ? \"A\" : \"\",\n-               (scc_entry != nullptr ? scc_entry->offset() : 0));\n+               task()->is_aot() ? \"A\" : \"\",\n+               (aot_code_entry != nullptr ? aot_code_entry->offset() : 0));\n@@ -1132,1 +1132,1 @@\n-                                SCCReader* scc_reader)\n+                                AOTCodeReader* aot_code_reader)\n@@ -1134,2 +1134,2 @@\n-  SCCEntry* scc_entry = task()->scc_entry();\n-  assert(scc_entry != nullptr, \"must be\");\n+  AOTCodeEntry* aot_code_entry = task()->aot_code_entry();\n+  assert(aot_code_entry != nullptr, \"must be\");\n@@ -1153,1 +1153,1 @@\n-    if (!is_compilation_valid(thread, target, preload, true \/*install_code*\/, nullptr \/*code_buffer*\/, scc_entry)) {\n+    if (!is_compilation_valid(thread, target, preload, true \/*install_code*\/, nullptr \/*code_buffer*\/, aot_code_entry)) {\n@@ -1170,1 +1170,1 @@\n-                              scc_reader);\n+                              aot_code_reader);\n@@ -1173,1 +1173,1 @@\n-      make_code_usable(thread, target, preload, InvocationEntryBci, scc_entry, nm);\n+      make_code_usable(thread, target, preload, InvocationEntryBci, aot_code_entry, nm);\n@@ -1209,1 +1209,1 @@\n-                            SCCEntry* scc_entry) {\n+                            AOTCodeEntry* aot_code_entry) {\n@@ -1228,1 +1228,1 @@\n-    if (!is_compilation_valid(THREAD, target, preload, install_code, code_buffer, scc_entry)) {\n+    if (!is_compilation_valid(THREAD, target, preload, install_code, code_buffer, aot_code_entry)) {\n@@ -1245,1 +1245,1 @@\n-                                 scc_entry);\n+                                 aot_code_entry);\n@@ -1259,4 +1259,4 @@\n-      if (scc_entry == nullptr) {\n-        scc_entry = SCCache::store_nmethod(nm, compiler, for_preload);\n-        if (scc_entry != nullptr) {\n-          scc_entry->set_inlined_bytecodes(num_inlined_bytecodes());\n+      if (aot_code_entry == nullptr) {\n+        aot_code_entry = AOTCodeCache::store_nmethod(nm, compiler, for_preload);\n+        if (aot_code_entry != nullptr) {\n+          aot_code_entry->set_inlined_bytecodes(num_inlined_bytecodes());\n@@ -1264,1 +1264,1 @@\n-            set_scc_clinit_barriers_entry(scc_entry); \/\/ Record it\n+            set_aot_clinit_barriers_entry(aot_code_entry); \/\/ Record it\n@@ -1267,2 +1267,2 @@\n-            SCCEntry* previous_entry = scc_clinit_barriers_entry();\n-            scc_entry->set_next(previous_entry); \/\/ Link it for case of deoptimization\n+            AOTCodeEntry* previous_entry = aot_clinit_barriers_entry();\n+            aot_code_entry->set_next(previous_entry); \/\/ Link it for case of deoptimization\n@@ -1272,1 +1272,1 @@\n-      make_code_usable(THREAD, target, preload, entry_bci, scc_entry, nm);\n+      make_code_usable(THREAD, target, preload, entry_bci, aot_code_entry, nm);\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":35,"deletions":35,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -42,2 +42,2 @@\n-class SCCEntry;\n-class SCCReader;\n+class AOTCodeEntry;\n+class AOTCodeReader;\n@@ -299,2 +299,2 @@\n-  bool is_compilation_valid(JavaThread* thread, ciMethod* target, bool preload, bool install_code, CodeBuffer* code_buffer, SCCEntry* scc_entry);\n-  void make_code_usable(JavaThread* thread, ciMethod* target, bool preload, int entry_bci, SCCEntry* scc_entry, nmethod* nm);\n+  bool is_compilation_valid(JavaThread* thread, ciMethod* target, bool preload, bool install_code, CodeBuffer* code_buffer, AOTCodeEntry* aot_code_entry);\n+  void make_code_usable(JavaThread* thread, ciMethod* target, bool preload, int entry_bci, AOTCodeEntry* aot_code_entry, nmethod* nm);\n@@ -390,1 +390,1 @@\n-                           SCCReader* scc_reader);\n+                           AOTCodeReader* aot_code_reader);\n@@ -411,1 +411,1 @@\n-                       SCCEntry*                 entry = nullptr);\n+                       AOTCodeEntry*             entry = nullptr);\n@@ -502,1 +502,1 @@\n-  SCCEntry* _scc_clinit_barriers_entry;\n+  AOTCodeEntry* _aot_clinit_barriers_entry;\n@@ -505,2 +505,2 @@\n-  void  set_scc_clinit_barriers_entry(SCCEntry* entry) { _scc_clinit_barriers_entry = entry; }\n-  SCCEntry* scc_clinit_barriers_entry()          const { return _scc_clinit_barriers_entry; }\n+  void  set_aot_clinit_barriers_entry(AOTCodeEntry* entry) { _aot_clinit_barriers_entry = entry; }\n+  AOTCodeEntry* aot_clinit_barriers_entry()          const { return _aot_clinit_barriers_entry; }\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -318,1 +318,1 @@\n-  if (!SCCache::allow_const_field(_constant_value)) {\n+  if (!AOTCodeCache::allow_const_field(_constant_value)) {\n@@ -334,1 +334,1 @@\n-  if (!SCCache::allow_const_field(field_value)) {\n+  if (!AOTCodeCache::allow_const_field(field_value)) {\n","filename":"src\/hotspot\/share\/ci\/ciField.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1236,1 +1236,1 @@\n-      if (code != nullptr && !code->is_scc() && (code->comp_level() == CompLevel_full_optimization)) {\n+      if (code != nullptr && !code->is_aot() && (code->comp_level() == CompLevel_full_optimization)) {\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -206,1 +206,1 @@\n-  if (ScavengeRootsInCode >= 2 && !(SCCache::is_on_for_write())) {\n+  if (ScavengeRootsInCode >= 2 && !(AOTCodeCache::is_on_for_write())) {\n@@ -223,1 +223,1 @@\n-      !(SCCache::is_on_for_write())) { \/\/ For now disable it when caching startup code.\n+      !(AOTCodeCache::is_on_for_write())) { \/\/ For now disable it when caching startup code.\n","filename":"src\/hotspot\/share\/ci\/ciObject.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1,4770 +0,0 @@\n-\/*\n- * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"asm\/macroAssembler.hpp\"\n-#include \"asm\/codeBuffer.hpp\"\n-#include \"cds\/cdsAccess.hpp\"\n-#include \"cds\/cdsConfig.hpp\"\n-#include \"cds\/heapShared.hpp\"\n-#include \"cds\/metaspaceShared.hpp\"\n-#include \"ci\/ciConstant.hpp\"\n-#include \"ci\/ciEnv.hpp\"\n-#include \"ci\/ciField.hpp\"\n-#include \"ci\/ciMethod.hpp\"\n-#include \"ci\/ciMethodData.hpp\"\n-#include \"ci\/ciObject.hpp\"\n-#include \"ci\/ciUtilities.inline.hpp\"\n-#include \"classfile\/javaAssertions.hpp\"\n-#include \"classfile\/stringTable.hpp\"\n-#include \"classfile\/symbolTable.hpp\"\n-#include \"classfile\/systemDictionary.hpp\"\n-#include \"classfile\/vmClasses.hpp\"\n-#include \"classfile\/vmIntrinsics.hpp\"\n-#include \"code\/codeBlob.hpp\"\n-#include \"code\/codeCache.hpp\"\n-#include \"code\/oopRecorder.inline.hpp\"\n-#include \"code\/SCCache.hpp\"\n-#include \"compiler\/abstractCompiler.hpp\"\n-#include \"compiler\/compilationPolicy.hpp\"\n-#include \"compiler\/compileBroker.hpp\"\n-#include \"compiler\/compileTask.hpp\"\n-#include \"gc\/g1\/g1BarrierSetRuntime.hpp\"\n-#include \"gc\/shared\/gcConfig.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"memory\/memoryReserver.hpp\"\n-#include \"memory\/universe.hpp\"\n-#include \"oops\/klass.inline.hpp\"\n-#include \"oops\/method.inline.hpp\"\n-#include \"oops\/trainingData.hpp\"\n-#include \"prims\/jvmtiThreadState.hpp\"\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/flags\/flagSetting.hpp\"\n-#include \"runtime\/globals_extension.hpp\"\n-#include \"runtime\/handles.inline.hpp\"\n-#include \"runtime\/java.hpp\"\n-#include \"runtime\/jniHandles.inline.hpp\"\n-#include \"runtime\/os.inline.hpp\"\n-#include \"runtime\/sharedRuntime.hpp\"\n-#include \"runtime\/stubCodeGenerator.hpp\"\n-#include \"runtime\/stubRoutines.hpp\"\n-#include \"runtime\/timerTrace.hpp\"\n-#include \"runtime\/threadIdentifier.hpp\"\n-#include \"utilities\/ostream.hpp\"\n-#include \"utilities\/spinYield.hpp\"\n-#ifdef COMPILER1\n-#include \"c1\/c1_Runtime1.hpp\"\n-#include \"c1\/c1_LIRAssembler.hpp\"\n-#include \"gc\/shared\/c1\/barrierSetC1.hpp\"\n-#include \"gc\/g1\/c1\/g1BarrierSetC1.hpp\"\n-#if INCLUDE_SHENANDOAHGC\n-#include \"gc\/shenandoah\/c1\/shenandoahBarrierSetC1.hpp\"\n-#endif\n-#include \"gc\/z\/c1\/zBarrierSetC1.hpp\"\n-#endif\n-#ifdef COMPILER2\n-#include \"opto\/runtime.hpp\"\n-#endif\n-#if INCLUDE_JVMCI\n-#include \"jvmci\/jvmci.hpp\"\n-#endif\n-#if INCLUDE_SHENANDOAHGC\n-#include \"gc\/shenandoah\/shenandoahRuntime.hpp\"\n-#endif\n-\n-#include <sys\/stat.h>\n-#include <errno.h>\n-\n-#ifndef O_BINARY       \/\/ if defined (Win32) use binary files.\n-#define O_BINARY 0     \/\/ otherwise do nothing.\n-#endif\n-\n-const char* sccentry_kind_name[] = {\n-#define DECL_KIND_STRING(kind) XSTR(kind),\n-  DO_SCCENTRY_KIND(DECL_KIND_STRING)\n-#undef DECL_KIND_STRING\n-};\n-\n-static elapsedTimer _t_totalLoad;\n-static elapsedTimer _t_totalRegister;\n-static elapsedTimer _t_totalFind;\n-static elapsedTimer _t_totalStore;\n-\n-SCCache* SCCache::_cache = nullptr;\n-\n-static bool enable_timers() {\n-  return CITime || log_is_enabled(Info, init);\n-}\n-\n-static void exit_vm_on_load_failure() {\n-  \/\/ Treat SCC warnings as error when RequireSharedSpaces is on.\n-  if (RequireSharedSpaces) {\n-    vm_exit_during_initialization(\"Unable to use AOT Code Cache.\", nullptr);\n-  }\n-}\n-\n-static void exit_vm_on_store_failure() {\n-  \/\/ Treat SCC warnings as error when RequireSharedSpaces is on.\n-  if (RequireSharedSpaces) {\n-    tty->print_cr(\"Unable to create startup cached code.\");\n-    \/\/ Failure during AOT code caching, we don't want to dump core\n-    vm_abort(false);\n-  }\n-}\n-\n-uint SCCache::max_aot_code_size() {\n-  return (uint)CachedCodeMaxSize;\n-}\n-\n-void SCCache::initialize() {\n-  if (LoadCachedCode && !UseSharedSpaces) {\n-    return;\n-  }\n-  if (LoadCachedCode && CDSAccess::get_cached_code_size() == 0) {\n-    LoadCachedCode = false;\n-    return;\n-  }\n-  if (StoreCachedCode || LoadCachedCode) {\n-    if (FLAG_IS_DEFAULT(ClassInitBarrierMode)) {\n-      FLAG_SET_DEFAULT(ClassInitBarrierMode, 1);\n-    }\n-  } else if (ClassInitBarrierMode > 0) {\n-    log_info(scc, init)(\"Set ClassInitBarrierMode to 0 because StoreCachedCode and LoadCachedCode are false.\");\n-    FLAG_SET_DEFAULT(ClassInitBarrierMode, 0);\n-  }\n-  if (LoadCachedCode || StoreCachedCode) {\n-    if (!open_cache()) {\n-      exit_vm_on_load_failure();\n-      return;\n-    }\n-    if (StoreCachedCode) {\n-      FLAG_SET_DEFAULT(FoldStableValues, false);\n-      FLAG_SET_DEFAULT(ForceUnreachable, true);\n-    }\n-    FLAG_SET_DEFAULT(DelayCompilerStubsGeneration, false);\n-  }\n-}\n-\n-void SCCache::init2() {\n-  if (!is_on()) {\n-    return;\n-  }\n-  \/\/ After Universe initialized\n-  BarrierSet* bs = BarrierSet::barrier_set();\n-  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n-    address byte_map_base = ci_card_table_address_as<address>();\n-    if (is_on_for_write() && !external_word_Relocation::can_be_relocated(byte_map_base)) {\n-      \/\/ Bail out since we can't encode card table base address with relocation\n-      log_warning(scc, init)(\"Can't create AOT Code Cache because card table base address is not relocatable: \" INTPTR_FORMAT, p2i(byte_map_base));\n-      close();\n-      exit_vm_on_load_failure();\n-    }\n-  }\n-  \/\/ initialize aot runtime constants as appropriate to this runtime\n-  AOTRuntimeConstants::initialize_from_runtime();\n-\n-  if (!verify_vm_config()) {\n-    close();\n-    exit_vm_on_load_failure();\n-  }\n-\n-  \/\/ initialize the table of external routines so we can save\n-  \/\/ generated code blobs that reference them\n-  init_extrs_table();\n-  \/\/ initialize the table of initial stubs so we can save\n-  \/\/ generated code blobs that reference them\n-  init_early_stubs_table();\n-}\n-\n-void SCCache::print_timers_on(outputStream* st) {\n-  if (LoadCachedCode) {\n-    st->print_cr (\"    SC Load Time:         %7.3f s\", _t_totalLoad.seconds());\n-    st->print_cr (\"      nmethod register:     %7.3f s\", _t_totalRegister.seconds());\n-    st->print_cr (\"      find cached code:     %7.3f s\", _t_totalFind.seconds());\n-  }\n-  if (StoreCachedCode) {\n-    st->print_cr (\"    SC Store Time:        %7.3f s\", _t_totalStore.seconds());\n-  }\n-}\n-\n-bool SCCache::is_C3_on() {\n-#if INCLUDE_JVMCI\n-  if (UseJVMCICompiler) {\n-    return (StoreCachedCode || LoadCachedCode) && UseC2asC3;\n-  }\n-#endif\n-  return false;\n-}\n-\n-bool SCCache::is_code_load_thread_on() {\n-  return UseCodeLoadThread && LoadCachedCode;\n-}\n-\n-bool SCCache::gen_preload_code(ciMethod* m, int entry_bci) {\n-  VM_ENTRY_MARK;\n-  return (entry_bci == InvocationEntryBci) && is_on() && _cache->gen_preload_code() &&\n-         CDSAccess::can_generate_cached_code(m->get_Method());\n-}\n-\n-static void print_helper(nmethod* nm, outputStream* st) {\n-  SCCache::iterate([&](SCCEntry* e) {\n-    if (e->method() == nm->method()) {\n-      ResourceMark rm;\n-      stringStream ss;\n-      ss.print(\"A%s%d\", (e->for_preload() ? \"P\" : \"\"), e->comp_level());\n-      if (e->decompile() > 0) {\n-        ss.print(\"+D%d\", e->decompile());\n-      }\n-      ss.print(\"[%s%s%s]\",\n-               (e->is_loaded()   ? \"L\" : \"\"),\n-               (e->load_fail()   ? \"F\" : \"\"),\n-               (e->not_entrant() ? \"I\" : \"\"));\n-      ss.print(\"#%d\", e->comp_id());\n-\n-      st->print(\" %s\", ss.freeze());\n-    }\n-  });\n-}\n-\n-void SCCache::close() {\n-  if (is_on()) {\n-    if (SCCache::is_on_for_read()) {\n-      LogStreamHandle(Info, init) log;\n-      if (log.is_enabled()) {\n-        log.print_cr(\"AOT Code Cache statistics (when closed): \");\n-        SCCache::print_statistics_on(&log);\n-        log.cr();\n-        SCCache::print_timers_on(&log);\n-\n-        LogStreamHandle(Info, scc, init) log1;\n-        if (log1.is_enabled()) {\n-          SCCache::print_unused_entries_on(&log1);\n-        }\n-\n-        LogStreamHandle(Info, scc, codecache) info_scc;\n-        \/\/ need a lock to traverse the code cache\n-        MutexLocker locker(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-        if (info_scc.is_enabled()) {\n-          NMethodIterator iter(NMethodIterator::all);\n-          while (iter.next()) {\n-            nmethod* nm = iter.method();\n-            if (nm->is_in_use() && !nm->is_native_method() && !nm->is_osr_method()) {\n-              info_scc.print(\"%5d:%c%c%c%d:\", nm->compile_id(),\n-                             (nm->method()->is_shared() ? 'S' : ' '),\n-                             (nm->is_scc() ? 'A' : ' '),\n-                             (nm->preloaded() ? 'P' : ' '),\n-                             nm->comp_level());\n-              print_helper(nm, &info_scc);\n-              info_scc.print(\": \");\n-              CompileTask::print(&info_scc, nm, nullptr, true \/*short_form*\/);\n-\n-              LogStreamHandle(Debug, scc, codecache) debug_scc;\n-              if (debug_scc.is_enabled()) {\n-                MethodTrainingData* mtd = MethodTrainingData::find(methodHandle(Thread::current(), nm->method()));\n-                if (mtd != nullptr) {\n-                  mtd->iterate_compiles([&](CompileTrainingData* ctd) {\n-                    debug_scc.print(\"     CTD: \"); ctd->print_on(&debug_scc); debug_scc.cr();\n-                  });\n-                }\n-              }\n-            }\n-          }\n-        }\n-      }\n-    }\n-\n-    delete _cache; \/\/ Free memory\n-    _cache = nullptr;\n-  }\n-}\n-\n-void SCCache::invalidate(SCCEntry* entry) {\n-  \/\/ This could be concurent execution\n-  if (entry != nullptr && is_on()) { \/\/ Request could come after cache is closed.\n-    _cache->invalidate_entry(entry);\n-  }\n-}\n-\n-bool SCCache::is_loaded(SCCEntry* entry) {\n-  if (is_on() && _cache->cache_buffer() != nullptr) {\n-    return (uint)((char*)entry - _cache->cache_buffer()) < _cache->load_size();\n-  }\n-  return false;\n-}\n-\n-void SCCache::preload_code(JavaThread* thread) {\n-  if ((ClassInitBarrierMode == 0) || !is_on_for_read()) {\n-    return;\n-  }\n-  if ((DisableCachedCode & (1 << 3)) != 0) {\n-    return; \/\/ no preloaded code (level 5);\n-  }\n-  _cache->preload_startup_code(thread);\n-}\n-\n-SCCEntry* SCCache::find_code_entry(const methodHandle& method, uint comp_level) {\n-  switch (comp_level) {\n-    case CompLevel_simple:\n-      if ((DisableCachedCode & (1 << 0)) != 0) {\n-        return nullptr;\n-      }\n-      break;\n-    case CompLevel_limited_profile:\n-      if ((DisableCachedCode & (1 << 1)) != 0) {\n-        return nullptr;\n-      }\n-      break;\n-    case CompLevel_full_optimization:\n-      if ((DisableCachedCode & (1 << 2)) != 0) {\n-        return nullptr;\n-      }\n-      break;\n-\n-    default: return nullptr; \/\/ Level 1, 2, and 4 only\n-  }\n-  TraceTime t1(\"SC total find code time\", &_t_totalFind, enable_timers(), false);\n-  if (is_on() && _cache->cache_buffer() != nullptr) {\n-    MethodData* md = method->method_data();\n-    uint decomp = (md == nullptr) ? 0 : md->decompile_count();\n-\n-    ResourceMark rm;\n-    const char* target_name = method->name_and_sig_as_C_string();\n-    uint hash = java_lang_String::hash_code((const jbyte*)target_name, (int)strlen(target_name));\n-    SCCEntry* entry = _cache->find_entry(SCCEntry::Code, hash, comp_level, decomp);\n-    if (entry == nullptr) {\n-      log_info(scc, nmethod)(\"Missing entry for '%s' (comp_level %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \")\", target_name, (uint)comp_level, decomp, hash);\n-#ifdef ASSERT\n-    } else {\n-      uint name_offset = entry->offset() + entry->name_offset();\n-      uint name_size   = entry->name_size(); \/\/ Includes '\/0'\n-      const char* name = _cache->cache_buffer() + name_offset;\n-      if (strncmp(target_name, name, name_size) != 0) {\n-        assert(false, \"SCA: saved nmethod's name '%s' is different from '%s', hash: \" UINT32_FORMAT_X_0, name, target_name, hash);\n-      }\n-#endif\n-    }\n-\n-    DirectiveSet* directives = DirectivesStack::getMatchingDirective(method, nullptr);\n-    if (directives->IgnorePrecompiledOption) {\n-      LogStreamHandle(Info, scc, compilation) log;\n-      if (log.is_enabled()) {\n-        log.print(\"Ignore cached code entry on level %d for \", comp_level);\n-        method->print_value_on(&log);\n-      }\n-      return nullptr;\n-    }\n-\n-    return entry;\n-  }\n-  return nullptr;\n-}\n-\n-void SCCache::add_C_string(const char* str) {\n-  if (is_on_for_write()) {\n-    _cache->add_new_C_string(str);\n-  }\n-}\n-\n-bool SCCache::allow_const_field(ciConstant& value) {\n-  return !is_on() || !StoreCachedCode \/\/ Restrict only when we generate cache\n-        \/\/ Can not trust primitive too   || !is_reference_type(value.basic_type())\n-        \/\/ May disable this too for now  || is_reference_type(value.basic_type()) && value.as_object()->should_be_constant()\n-        ;\n-}\n-\n-\n-bool SCCache::open_cache() {\n-  SCCache* cache = new SCCache();\n-  if (cache->failed()) {\n-    delete cache;\n-    _cache = nullptr;\n-    return false;\n-  }\n-  _cache = cache;\n-  return true;\n-}\n-\n-class CachedCodeDirectory : public CachedCodeDirectoryInternal {\n-public:\n-  uint _aot_code_size;\n-  char* _aot_code_data;\n-\n-  void set_aot_code_data(uint size, char* aot_data) {\n-    _aot_code_size = size;\n-    CDSAccess::set_pointer(&_aot_code_data, aot_data);\n-  }\n-\n-  static CachedCodeDirectory* create();\n-};\n-\n-\/\/ Storing AOT code in the cached code region of AOT Cache:\n-\/\/\n-\/\/ [1] Use CachedCodeDirectory to keep track of all of data related to cached code.\n-\/\/     E.g., you can build a hashtable to record what methods have been archived.\n-\/\/\n-\/\/ [2] Memory for all data for cached code, including CachedCodeDirectory, should be\n-\/\/     allocated using CDSAccess::allocate_from_code_cache().\n-\/\/\n-\/\/ [3] CachedCodeDirectory must be the very first allocation.\n-\/\/\n-\/\/ [4] Two kinds of pointer can be stored:\n-\/\/     - A pointer p that points to metadata. CDSAccess::can_generate_cached_code(p) must return true.\n-\/\/     - A pointer to a buffer returned by CDSAccess::allocate_from_code_cache().\n-\/\/       (It's OK to point to an interior location within this buffer).\n-\/\/     Such pointers must be stored using CDSAccess::set_pointer()\n-\/\/\n-\/\/ The buffers allocated by CDSAccess::allocate_from_code_cache() are in a contiguous region. At runtime, this\n-\/\/ region is mapped to the process address space. All the pointers in this buffer are relocated as necessary\n-\/\/ (e.g., to account for the runtime location of the CodeCache).\n-\/\/\n-\/\/ This is always at the very beginning of the mmaped CDS \"cc\" (cached code) region\n-static CachedCodeDirectory* _cached_code_directory = nullptr;\n-\n-CachedCodeDirectory* CachedCodeDirectory::create() {\n-  assert(CDSAccess::is_cached_code_region_empty(), \"must be\");\n-  CachedCodeDirectory* dir = (CachedCodeDirectory*)CDSAccess::allocate_from_code_cache(sizeof(CachedCodeDirectory));\n-  dir->dumptime_init_internal();\n-  return dir;\n-}\n-\n-#define DATA_ALIGNMENT HeapWordSize\n-\n-SCCache::SCCache() {\n-  _load_header = nullptr;\n-  _for_read  = LoadCachedCode;\n-  _for_write = StoreCachedCode;\n-  _load_size = 0;\n-  _store_size = 0;\n-  _write_position = 0;\n-  _closing  = false;\n-  _failed = false;\n-  _lookup_failed = false;\n-  _table = nullptr;\n-  _load_entries = nullptr;\n-  _store_entries  = nullptr;\n-  _C_strings_buf  = nullptr;\n-  _load_buffer = nullptr;\n-  _store_buffer = nullptr;\n-  _C_store_buffer = nullptr;\n-  _store_entries_cnt = 0;\n-  _gen_preload_code = false;\n-  _for_preload = false;       \/\/ changed while storing entry data\n-  _has_clinit_barriers = false;\n-\n-  _compile_id = 0;\n-  _comp_level = 0;\n-\n-  _use_meta_ptrs = UseSharedSpaces ? UseMetadataPointers : false;\n-\n-  if (_for_read) {\n-    \/\/ Read cache\n-    ReservedSpace rs = MemoryReserver::reserve(CDSAccess::get_cached_code_size(), mtCode);\n-    if (!rs.is_reserved()) {\n-      log_warning(scc, init)(\"Failed to reserved %u bytes of memory for mapping cached code region in AOT Cache\", (uint)CDSAccess::get_cached_code_size());\n-      set_failed();\n-      return;\n-    }\n-    if (!CDSAccess::map_cached_code(rs)) {\n-      log_warning(scc, init)(\"Failed to read\/mmap cached code region in AOT Cache\");\n-      set_failed();\n-      return;\n-    }\n-    _cached_code_directory = (CachedCodeDirectory*)rs.base();\n-    _cached_code_directory->runtime_init_internal();\n-\n-    _load_size = _cached_code_directory->_aot_code_size;\n-    _load_buffer = _cached_code_directory->_aot_code_data;\n-    assert(is_aligned(_load_buffer, DATA_ALIGNMENT), \"load_buffer is not aligned\");\n-    log_info(scc, init)(\"Mapped %u bytes at address \" INTPTR_FORMAT \" from AOT Code Cache\", _load_size, p2i(_load_buffer));\n-\n-    _load_header = (SCCHeader*)addr(0);\n-    if (!_load_header->verify_config(_load_size)) {\n-      set_failed();\n-      return;\n-    }\n-    log_info(scc, init)(\"Read header from AOT Code Cache\");\n-    if (_load_header->has_meta_ptrs()) {\n-      assert(UseSharedSpaces, \"should be verified already\");\n-      _use_meta_ptrs = true; \/\/ Regardless UseMetadataPointers\n-      UseMetadataPointers = true;\n-    }\n-    \/\/ Read strings\n-    load_strings();\n-  }\n-  if (_for_write) {\n-    _gen_preload_code = _use_meta_ptrs && (ClassInitBarrierMode > 0);\n-\n-    _C_store_buffer = NEW_C_HEAP_ARRAY(char, max_aot_code_size() + DATA_ALIGNMENT, mtCode);\n-    _store_buffer = align_up(_C_store_buffer, DATA_ALIGNMENT);\n-    \/\/ Entries allocated at the end of buffer in reverse (as on stack).\n-    _store_entries = (SCCEntry*)align_up(_C_store_buffer + max_aot_code_size(), DATA_ALIGNMENT);\n-    log_info(scc, init)(\"Allocated store buffer at address \" INTPTR_FORMAT \" of size \" UINT32_FORMAT \" bytes\", p2i(_store_buffer), max_aot_code_size());\n-  }\n-  _table = new SCAddressTable();\n-}\n-\n-void SCCache::init_extrs_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_extrs();\n-  }\n-}\n-void SCCache::init_early_stubs_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_early_stubs();\n-  }\n-}\n-void SCCache::init_shared_blobs_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_shared_blobs();\n-  }\n-}\n-void SCCache::init_stubs_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_stubs();\n-  }\n-}\n-\n-void SCCache::init_opto_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_opto();\n-  }\n-}\n-\n-void SCCache::init_c1_table() {\n-  SCAddressTable* table = addr_table();\n-  if (table != nullptr) {\n-    table->init_c1();\n-  }\n-}\n-\n-void SCConfig::record(bool use_meta_ptrs) {\n-  _flags = 0;\n-  if (use_meta_ptrs) {\n-    _flags |= metadataPointers;\n-  }\n-#ifdef ASSERT\n-  _flags |= debugVM;\n-#endif\n-  if (UseCompressedOops) {\n-    _flags |= compressedOops;\n-  }\n-  if (UseCompressedClassPointers) {\n-    _flags |= compressedClassPointers;\n-  }\n-  if (UseTLAB) {\n-    _flags |= useTLAB;\n-  }\n-  if (JavaAssertions::systemClassDefault()) {\n-    _flags |= systemClassAssertions;\n-  }\n-  if (JavaAssertions::userClassDefault()) {\n-    _flags |= userClassAssertions;\n-  }\n-  if (EnableContended) {\n-    _flags |= enableContendedPadding;\n-  }\n-  if (RestrictContended) {\n-    _flags |= restrictContendedPadding;\n-  }\n-  _compressedOopShift    = CompressedOops::shift();\n-  _compressedKlassShift  = CompressedKlassPointers::shift();\n-  _contendedPaddingWidth = ContendedPaddingWidth;\n-  _objectAlignment       = ObjectAlignmentInBytes;\n-  _gc                    = (uint)Universe::heap()->kind();\n-}\n-\n-bool SCConfig::verify() const {\n-#ifdef ASSERT\n-  if ((_flags & debugVM) == 0) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created by product VM, it can't be used by debug VM\");\n-    return false;\n-  }\n-#else\n-  if ((_flags & debugVM) != 0) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created by debug VM, it can't be used by product VM\");\n-    return false;\n-  }\n-#endif\n-\n-  CollectedHeap::Name scc_gc = (CollectedHeap::Name)_gc;\n-  if (scc_gc != Universe::heap()->kind()) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with different GC: %s vs current %s\", GCConfig::hs_err_name(scc_gc), GCConfig::hs_err_name());\n-    return false;\n-  }\n-\n-  if (((_flags & compressedOops) != 0) != UseCompressedOops) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with UseCompressedOops = %s\", UseCompressedOops ? \"false\" : \"true\");\n-    return false;\n-  }\n-  if (((_flags & compressedClassPointers) != 0) != UseCompressedClassPointers) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with UseCompressedClassPointers = %s\", UseCompressedClassPointers ? \"false\" : \"true\");\n-    return false;\n-  }\n-\n-  if (((_flags & systemClassAssertions) != 0) != JavaAssertions::systemClassDefault()) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with JavaAssertions::systemClassDefault() = %s\", JavaAssertions::systemClassDefault() ? \"disabled\" : \"enabled\");\n-    return false;\n-  }\n-  if (((_flags & userClassAssertions) != 0) != JavaAssertions::userClassDefault()) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with JavaAssertions::userClassDefault() = %s\", JavaAssertions::userClassDefault() ? \"disabled\" : \"enabled\");\n-    return false;\n-  }\n-\n-  if (((_flags & enableContendedPadding) != 0) != EnableContended) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with EnableContended = %s\", EnableContended ? \"false\" : \"true\");\n-    return false;\n-  }\n-  if (((_flags & restrictContendedPadding) != 0) != RestrictContended) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with RestrictContended = %s\", RestrictContended ? \"false\" : \"true\");\n-    return false;\n-  }\n-  if (_compressedOopShift != (uint)CompressedOops::shift()) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with CompressedOops::shift() = %d vs current %d\", _compressedOopShift, CompressedOops::shift());\n-    return false;\n-  }\n-  if (_compressedKlassShift != (uint)CompressedKlassPointers::shift()) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with CompressedKlassPointers::shift() = %d vs current %d\", _compressedKlassShift, CompressedKlassPointers::shift());\n-    return false;\n-  }\n-  if (_contendedPaddingWidth != (uint)ContendedPaddingWidth) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with ContendedPaddingWidth = %d vs current %d\", _contendedPaddingWidth, ContendedPaddingWidth);\n-    return false;\n-  }\n-  if (_objectAlignment != (uint)ObjectAlignmentInBytes) {\n-    log_warning(scc, init)(\"Disable AOT Code: it was created with ObjectAlignmentInBytes = %d vs current %d\", _objectAlignment, ObjectAlignmentInBytes);\n-    return false;\n-  }\n-  return true;\n-}\n-\n-bool SCCHeader::verify_config(uint load_size) const {\n-  if (_version != SCC_VERSION) {\n-    log_warning(scc, init)(\"Disable AOT Code: different SCC version %d vs %d recorded in AOT Cache\", SCC_VERSION, _version);\n-    return false;\n-  }\n-  if (_cache_size != load_size) {\n-    log_warning(scc, init)(\"Disable AOT Code: different cached code size %d vs %d recorded in AOT Cache\", load_size, _cache_size);\n-    return false;\n-  }\n-  return true;\n-}\n-\n-volatile int SCCache::_nmethod_readers = 0;\n-\n-SCCache::~SCCache() {\n-  if (_closing) {\n-    return; \/\/ Already closed\n-  }\n-  \/\/ Stop any further access to cache.\n-  \/\/ Checked on entry to load_nmethod() and store_nmethod().\n-  _closing = true;\n-  if (_for_read) {\n-    \/\/ Wait for all load_nmethod() finish.\n-    wait_for_no_nmethod_readers();\n-  }\n-  \/\/ Prevent writing code into cache while we are closing it.\n-  \/\/ This lock held by ciEnv::register_method() which calls store_nmethod().\n-  MutexLocker ml(Compile_lock);\n-  if (for_write()) { \/\/ Finalize cache\n-    finish_write();\n-  }\n-  _load_buffer = nullptr;\n-  if (_C_store_buffer != nullptr) {\n-    FREE_C_HEAP_ARRAY(char, _C_store_buffer);\n-    _C_store_buffer = nullptr;\n-    _store_buffer = nullptr;\n-  }\n-  if (_table != nullptr) {\n-    delete _table;\n-    _table = nullptr;\n-  }\n-}\n-\n-SCCache* SCCache::open_for_read() {\n-  if (SCCache::is_on_for_read()) {\n-    return SCCache::cache();\n-  }\n-  return nullptr;\n-}\n-\n-SCCache* SCCache::open_for_write() {\n-  if (SCCache::is_on_for_write()) {\n-    SCCache* cache = SCCache::cache();\n-    cache->clear_lookup_failed(); \/\/ Reset bit\n-    return cache;\n-  }\n-  return nullptr;\n-}\n-\n-bool SCCache::is_address_in_aot_cache(address p) {\n-  SCCache* cache = open_for_read();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  if ((p >= (address)cache->cache_buffer()) &&\n-      (p < (address)(cache->cache_buffer() + cache->load_size()))) {\n-    return true;\n-  }\n-  return false;\n-}\n-\n-static void copy_bytes(const char* from, address to, uint size) {\n-  assert(size > 0, \"sanity\");\n-  bool by_words = true;\n-  if ((size > 2 * HeapWordSize) && (((intptr_t)from | (intptr_t)to) & (HeapWordSize - 1)) == 0) {\n-    \/\/ Use wordwise copies if possible:\n-    Copy::disjoint_words((HeapWord*)from,\n-                         (HeapWord*)to,\n-                         ((size_t)size + HeapWordSize-1) \/ HeapWordSize);\n-  } else {\n-    by_words = false;\n-    Copy::conjoint_jbytes(from, to, (size_t)size);\n-  }\n-  log_trace(scc)(\"Copied %d bytes as %s from \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, size, (by_words ? \"HeapWord\" : \"bytes\"), p2i(from), p2i(to));\n-}\n-\n-void SCCReader::set_read_position(uint pos) {\n-  if (pos == _read_position) {\n-    return;\n-  }\n-  assert(pos < _cache->load_size(), \"offset:%d >= file size:%d\", pos, _cache->load_size());\n-  _read_position = pos;\n-}\n-\n-bool SCCache::set_write_position(uint pos) {\n-  if (pos == _write_position) {\n-    return true;\n-  }\n-  if (_store_size < _write_position) {\n-    _store_size = _write_position; \/\/ Adjust during write\n-  }\n-  assert(pos < _store_size, \"offset:%d >= file size:%d\", pos, _store_size);\n-  _write_position = pos;\n-  return true;\n-}\n-\n-static char align_buffer[256] = { 0 };\n-\n-bool SCCache::align_write() {\n-  \/\/ We are not executing code from cache - we copy it by bytes first.\n-  \/\/ No need for big alignment (or at all).\n-  uint padding = DATA_ALIGNMENT - (_write_position & (DATA_ALIGNMENT - 1));\n-  if (padding == DATA_ALIGNMENT) {\n-    return true;\n-  }\n-  uint n = write_bytes((const void*)&align_buffer, padding);\n-  if (n != padding) {\n-    return false;\n-  }\n-  log_trace(scc)(\"Adjust write alignment in AOT Code Cache\");\n-  return true;\n-}\n-\n-\/\/ Check to see if AOT code cache has required space to store \"nbytes\" of data\n-address SCCache::reserve_bytes(uint nbytes) {\n-  assert(for_write(), \"Code Cache file is not created\");\n-  uint new_position = _write_position + nbytes;\n-  if (new_position >= (uint)((char*)_store_entries - _store_buffer)) {\n-    log_warning(scc)(\"Failed to ensure %d bytes at offset %d in AOT Code Cache. Increase CachedCodeMaxSize.\",\n-                     nbytes, _write_position);\n-    set_failed();\n-    exit_vm_on_store_failure();\n-    return nullptr;\n-  }\n-  address buffer = (address)(_store_buffer + _write_position);\n-  _write_position += nbytes;\n-  if (_store_size < _write_position) {\n-    _store_size = _write_position;\n-  }\n-  return buffer;\n-}\n-\n-uint SCCache::write_bytes(const void* buffer, uint nbytes) {\n-  assert(for_write(), \"Code Cache file is not created\");\n-  if (nbytes == 0) {\n-    return 0;\n-  }\n-  uint new_position = _write_position + nbytes;\n-  if (new_position >= (uint)((char*)_store_entries - _store_buffer)) {\n-    log_warning(scc)(\"Failed to write %d bytes at offset %d to AOT Code Cache. Increase CachedCodeMaxSize.\",\n-                     nbytes, _write_position);\n-    set_failed();\n-    exit_vm_on_store_failure();\n-    return 0;\n-  }\n-  copy_bytes((const char* )buffer, (address)(_store_buffer + _write_position), nbytes);\n-  log_trace(scc)(\"Wrote %d bytes at offset %d to AOT Code Cache\", nbytes, _write_position);\n-  _write_position += nbytes;\n-  if (_store_size < _write_position) {\n-    _store_size = _write_position;\n-  }\n-  return nbytes;\n-}\n-\n-void SCCEntry::update_method_for_writing() {\n-  if (_method != nullptr) {\n-    _method = CDSAccess::method_in_cached_code(_method);\n-  }\n-}\n-\n-void SCCEntry::print(outputStream* st) const {\n-  st->print_cr(\" SCA entry \" INTPTR_FORMAT \" [kind: %d, id: \" UINT32_FORMAT_X_0 \", offset: %d, size: %d, comp_level: %d, comp_id: %d, decompiled: %d, %s%s%s%s%s]\",\n-               p2i(this), (int)_kind, _id, _offset, _size, _comp_level, _comp_id, _decompile,\n-               (_not_entrant? \"not_entrant\" : \"entrant\"),\n-               (_loaded ? \", loaded\" : \"\"),\n-               (_has_clinit_barriers ? \", has_clinit_barriers\" : \"\"),\n-               (_for_preload ? \", for_preload\" : \"\"),\n-               (_ignore_decompile ? \", ignore_decomp\" : \"\"));\n-}\n-\n-void* SCCEntry::operator new(size_t x, SCCache* cache) {\n-  return (void*)(cache->add_entry());\n-}\n-\n-bool skip_preload(methodHandle mh) {\n-  if (!mh->method_holder()->is_loaded()) {\n-    return true;\n-  }\n-  DirectiveSet* directives = DirectivesStack::getMatchingDirective(mh, nullptr);\n-  if (directives->DontPreloadOption) {\n-    LogStreamHandle(Info, scc, init) log;\n-    if (log.is_enabled()) {\n-      log.print(\"Exclude preloading code for \");\n-      mh->print_value_on(&log);\n-    }\n-    return true;\n-  }\n-  return false;\n-}\n-\n-void SCCache::preload_startup_code(TRAPS) {\n-  if (CompilationPolicy::compiler_count(CompLevel_full_optimization) == 0) {\n-    \/\/ Since we reuse the CompilerBroker API to install cached code, we're required to have a JIT compiler for the\n-    \/\/ level we want (that is CompLevel_full_optimization).\n-    return;\n-  }\n-  assert(_for_read, \"sanity\");\n-  uint count = _load_header->entries_count();\n-  if (_load_entries == nullptr) {\n-    \/\/ Read it\n-    _search_entries = (uint*)addr(_load_header->entries_offset()); \/\/ [id, index]\n-    _load_entries = (SCCEntry*)(_search_entries + 2 * count);\n-    log_info(scc, init)(\"Read %d entries table at offset %d from AOT Code Cache\", count, _load_header->entries_offset());\n-  }\n-  uint preload_entries_count = _load_header->preload_entries_count();\n-  if (preload_entries_count > 0) {\n-    uint* entries_index = (uint*)addr(_load_header->preload_entries_offset());\n-    log_info(scc, init)(\"Load %d preload entries from AOT Code Cache\", preload_entries_count);\n-    uint count = MIN2(preload_entries_count, SCLoadStop);\n-    for (uint i = SCLoadStart; i < count; i++) {\n-      uint index = entries_index[i];\n-      SCCEntry* entry = &(_load_entries[index]);\n-      if (entry->not_entrant()) {\n-        continue;\n-      }\n-      methodHandle mh(THREAD, entry->method());\n-      assert((mh.not_null() && MetaspaceShared::is_in_shared_metaspace((address)mh())), \"sanity\");\n-      if (skip_preload(mh)) {\n-        continue; \/\/ Exclude preloading for this method\n-      }\n-      assert(mh->method_holder()->is_loaded(), \"\");\n-      if (!mh->method_holder()->is_linked()) {\n-        assert(!HAS_PENDING_EXCEPTION, \"\");\n-        mh->method_holder()->link_class(THREAD);\n-        if (HAS_PENDING_EXCEPTION) {\n-          LogStreamHandle(Info, scc) log;\n-          if (log.is_enabled()) {\n-            ResourceMark rm;\n-            log.print(\"Linkage failed for %s: \", mh->method_holder()->external_name());\n-            THREAD->pending_exception()->print_value_on(&log);\n-            if (log_is_enabled(Debug, scc)) {\n-              THREAD->pending_exception()->print_on(&log);\n-            }\n-          }\n-          CLEAR_PENDING_EXCEPTION;\n-        }\n-      }\n-      if (mh->scc_entry() != nullptr) {\n-        \/\/ Second C2 compilation of the same method could happen for\n-        \/\/ different reasons without marking first entry as not entrant.\n-        continue; \/\/ Keep old entry to avoid issues\n-      }\n-      mh->set_scc_entry(entry);\n-      CompileBroker::compile_method(mh, InvocationEntryBci, CompLevel_full_optimization, methodHandle(), 0, false, CompileTask::Reason_Preload, CHECK);\n-    }\n-  }\n-}\n-\n-static bool check_entry(SCCEntry::Kind kind, uint id, uint comp_level, uint decomp, SCCEntry* entry) {\n-  if (entry->kind() == kind) {\n-    assert(entry->id() == id, \"sanity\");\n-    if (kind != SCCEntry::Code || (!entry->not_entrant() && !entry->has_clinit_barriers() &&\n-                                  (entry->comp_level() == comp_level) &&\n-                                  (entry->ignore_decompile() || entry->decompile() == decomp))) {\n-      return true; \/\/ Found\n-    }\n-  }\n-  return false;\n-}\n-\n-SCCEntry* SCCache::find_entry(SCCEntry::Kind kind, uint id, uint comp_level, uint decomp) {\n-  assert(_for_read, \"sanity\");\n-  uint count = _load_header->entries_count();\n-  if (_load_entries == nullptr) {\n-    \/\/ Read it\n-    _search_entries = (uint*)addr(_load_header->entries_offset()); \/\/ [id, index]\n-    _load_entries = (SCCEntry*)(_search_entries + 2 * count);\n-    log_info(scc, init)(\"Read %d entries table at offset %d from AOT Code Cache\", count, _load_header->entries_offset());\n-  }\n-  \/\/ Binary search\n-  int l = 0;\n-  int h = count - 1;\n-  while (l <= h) {\n-    int mid = (l + h) >> 1;\n-    int ix = mid * 2;\n-    uint is = _search_entries[ix];\n-    if (is == id) {\n-      int index = _search_entries[ix + 1];\n-      SCCEntry* entry = &(_load_entries[index]);\n-      if (check_entry(kind, id, comp_level, decomp, entry)) {\n-        return entry; \/\/ Found\n-      }\n-      \/\/ Leaner search around (could be the same nmethod with different decompile count)\n-      for (int i = mid - 1; i >= l; i--) { \/\/ search back\n-        ix = i * 2;\n-        is = _search_entries[ix];\n-        if (is != id) {\n-          break;\n-        }\n-        index = _search_entries[ix + 1];\n-        SCCEntry* entry = &(_load_entries[index]);\n-        if (check_entry(kind, id, comp_level, decomp, entry)) {\n-          return entry; \/\/ Found\n-        }\n-      }\n-      for (int i = mid + 1; i <= h; i++) { \/\/ search forward\n-        ix = i * 2;\n-        is = _search_entries[ix];\n-        if (is != id) {\n-          break;\n-        }\n-        index = _search_entries[ix + 1];\n-        SCCEntry* entry = &(_load_entries[index]);\n-        if (check_entry(kind, id, comp_level, decomp, entry)) {\n-          return entry; \/\/ Found\n-        }\n-      }\n-      break; \/\/ Not found match (different decompile count or not_entrant state).\n-    } else if (is < id) {\n-      l = mid + 1;\n-    } else {\n-      h = mid - 1;\n-    }\n-  }\n-  return nullptr;\n-}\n-\n-void SCCache::invalidate_entry(SCCEntry* entry) {\n-  assert(entry!= nullptr, \"all entries should be read already\");\n-  if (entry->not_entrant()) {\n-    return; \/\/ Someone invalidated it already\n-  }\n-#ifdef ASSERT\n-  bool found = false;\n-  if (_for_read) {\n-    uint count = _load_header->entries_count();\n-    uint i = 0;\n-    for(; i < count; i++) {\n-      if (entry == &(_load_entries[i])) {\n-        break;\n-      }\n-    }\n-    found = (i < count);\n-  }\n-  if (!found && _for_write) {\n-    uint count = _store_entries_cnt;\n-    uint i = 0;\n-    for(; i < count; i++) {\n-      if (entry == &(_store_entries[i])) {\n-        break;\n-      }\n-    }\n-    found = (i < count);\n-  }\n-  assert(found, \"entry should exist\");\n-#endif\n-  entry->set_not_entrant();\n-  {\n-    uint name_offset = entry->offset() + entry->name_offset();\n-    const char* name;\n-    if (SCCache::is_loaded(entry)) {\n-      name = _load_buffer + name_offset;\n-    } else {\n-      name = _store_buffer + name_offset;\n-    }\n-    uint level   = entry->comp_level();\n-    uint comp_id = entry->comp_id();\n-    uint decomp  = entry->decompile();\n-    bool clinit_brs = entry->has_clinit_barriers();\n-    log_info(scc, nmethod)(\"Invalidated entry for '%s' (comp_id %d, comp_level %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s)\",\n-                           name, comp_id, level, decomp, entry->id(), (clinit_brs ? \", has clinit barriers\" : \"\"));\n-  }\n-  if (entry->next() != nullptr) {\n-    entry = entry->next();\n-    assert(entry->has_clinit_barriers(), \"expecting only such entries here\");\n-    invalidate_entry(entry);\n-  }\n-}\n-\n-static int uint_cmp(const void *i, const void *j) {\n-  uint a = *(uint *)i;\n-  uint b = *(uint *)j;\n-  return a > b ? 1 : a < b ? -1 : 0;\n-}\n-\n-AOTCodeStats AOTCodeStats::add_cached_code_stats(AOTCodeStats stats1, AOTCodeStats stats2) {\n-  AOTCodeStats result;\n-  for (int kind = SCCEntry::None; kind < SCCEntry::Kind_count; kind++) {\n-    result.ccstats._kind_cnt[kind] = stats1.entry_count(kind) + stats2.entry_count(kind);\n-  }\n-\n-  for (int lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n-    result.ccstats._nmethod_cnt[lvl] = stats1.nmethod_count(lvl) + stats2.nmethod_count(lvl);\n-  }\n-  result.ccstats._clinit_barriers_cnt = stats1.clinit_barriers_count() + stats2.clinit_barriers_count();\n-  return result;\n-}\n-\n-void SCCache::log_stats_on_exit() {\n-  LogStreamHandle(Info, scc, exit) log;\n-  if (log.is_enabled()) {\n-    AOTCodeStats prev_stats;\n-    AOTCodeStats current_stats;\n-    AOTCodeStats total_stats;\n-    uint max_size = 0;\n-\n-    uint load_count = (_load_header != nullptr) ? _load_header->entries_count() : 0;\n-\n-    for (uint i = 0; i < load_count; i++) {\n-      prev_stats.collect_entry_stats(&_load_entries[i]);\n-      if (max_size < _load_entries[i].size()) {\n-        max_size = _load_entries[i].size();\n-      }\n-    }\n-    for (uint i = 0; i < _store_entries_cnt; i++) {\n-      current_stats.collect_entry_stats(&_store_entries[i]);\n-      if (max_size < _store_entries[i].size()) {\n-        max_size = _store_entries[i].size();\n-      }\n-    }\n-    total_stats = AOTCodeStats::add_cached_code_stats(prev_stats, current_stats);\n-\n-    log.print_cr(\"Wrote %d SCCEntry entries(%u max size) to AOT Code Cache\",\n-                 total_stats.total_count(), max_size);\n-    for (uint kind = SCCEntry::None; kind < SCCEntry::Kind_count; kind++) {\n-      if (total_stats.entry_count(kind) > 0) {\n-        log.print_cr(\"  %s: total=%u(old=%u+new=%u)\",\n-                     sccentry_kind_name[kind], total_stats.entry_count(kind), prev_stats.entry_count(kind), current_stats.entry_count(kind));\n-        if (kind == SCCEntry::Code) {\n-          for (uint lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n-            if (total_stats.nmethod_count(lvl) > 0) {\n-              log.print_cr(\"    Tier %d: total=%u(old=%u+new=%u)\",\n-                           lvl, total_stats.nmethod_count(lvl), prev_stats.nmethod_count(lvl), current_stats.nmethod_count(lvl));\n-            }\n-          }\n-        }\n-      }\n-    }\n-    log.print_cr(\"Total=%u(old=%u+new=%u)\", total_stats.total_count(), prev_stats.total_count(), current_stats.total_count());\n-  }\n-}\n-\n-bool SCCache::finish_write() {\n-  if (!align_write()) {\n-    return false;\n-  }\n-  uint strings_offset = _write_position;\n-  int strings_count = store_strings();\n-  if (strings_count < 0) {\n-    return false;\n-  }\n-  if (!align_write()) {\n-    return false;\n-  }\n-  uint strings_size = _write_position - strings_offset;\n-\n-  uint entries_count = 0; \/\/ Number of entrant (useful) code entries\n-  uint entries_offset = _write_position;\n-\n-  uint store_count = _store_entries_cnt;\n-  if (store_count > 0) {\n-    _cached_code_directory = CachedCodeDirectory::create();\n-    assert(_cached_code_directory != nullptr, \"Sanity check\");\n-\n-    uint header_size = (uint)align_up(sizeof(SCCHeader),  DATA_ALIGNMENT);\n-    uint load_count = (_load_header != nullptr) ? _load_header->entries_count() : 0;\n-    uint code_count = store_count + load_count;\n-    uint search_count = code_count * 2;\n-    uint search_size = search_count * sizeof(uint);\n-    uint entries_size = (uint)align_up(code_count * sizeof(SCCEntry), DATA_ALIGNMENT); \/\/ In bytes\n-    uint preload_entries_cnt = 0;\n-    uint* preload_entries = NEW_C_HEAP_ARRAY(uint, code_count, mtCode);\n-    uint preload_entries_size = code_count * sizeof(uint);\n-    \/\/ _write_position should include code and strings\n-    uint code_alignment = code_count * DATA_ALIGNMENT; \/\/ We align_up code size when storing it.\n-    uint total_size = _write_position + _load_size + header_size +\n-                     code_alignment + search_size + preload_entries_size + entries_size;\n-\n-    assert(total_size < max_aot_code_size(), \"Cached code region size (\" UINT32_FORMAT \" bytes) in AOT Code Cache is less than the required size (\" UINT32_FORMAT \" bytes).\",\n-           total_size, max_aot_code_size());\n-\n-    \/\/ Create ordered search table for entries [id, index];\n-    uint* search = NEW_C_HEAP_ARRAY(uint, search_count, mtCode);\n-\n-    char* buffer = (char *)CDSAccess::allocate_from_code_cache(total_size + DATA_ALIGNMENT); \/\/ NEW_C_HEAP_ARRAY(char, total_size + DATA_ALIGNMENT, mtCode);\n-    char* start = align_up(buffer, DATA_ALIGNMENT);\n-    char* current = start + header_size; \/\/ Skip header\n-\n-    SCCEntry* entries_address = _store_entries; \/\/ Pointer to latest entry\n-\n-    \/\/ Add old entries first\n-    if (_for_read && (_load_header != nullptr)) {\n-      for(uint i = 0; i < load_count; i++) {\n-        if (_load_entries[i].load_fail()) {\n-          continue;\n-        }\n-        if (_load_entries[i].not_entrant()) {\n-          log_info(scc, exit)(\"Not entrant load entry id: %d, decomp: %d, hash: \" UINT32_FORMAT_X_0, i, _load_entries[i].decompile(), _load_entries[i].id());\n-          if (_load_entries[i].for_preload()) {\n-            \/\/ Skip not entrant preload code:\n-            \/\/ we can't pre-load code which may have failing dependencies.\n-            continue;\n-          }\n-          _load_entries[i].set_entrant(); \/\/ Reset\n-        } else if (_load_entries[i].for_preload() && _load_entries[i].method() != nullptr) {\n-          \/\/ record entrant first version code for pre-loading\n-          preload_entries[preload_entries_cnt++] = entries_count;\n-        }\n-        {\n-          uint size = align_up(_load_entries[i].size(), DATA_ALIGNMENT);\n-          copy_bytes((_load_buffer + _load_entries[i].offset()), (address)current, size);\n-          _load_entries[i].set_offset(current - start); \/\/ New offset\n-          current += size;\n-          uint n = write_bytes(&(_load_entries[i]), sizeof(SCCEntry));\n-          if (n != sizeof(SCCEntry)) {\n-            FREE_C_HEAP_ARRAY(char, buffer);\n-            FREE_C_HEAP_ARRAY(uint, search);\n-            return false;\n-          }\n-          search[entries_count*2 + 0] = _load_entries[i].id();\n-          search[entries_count*2 + 1] = entries_count;\n-          entries_count++;\n-        }\n-      }\n-    }\n-    \/\/ SCCEntry entries were allocated in reverse in store buffer.\n-    \/\/ Process them in reverse order to cache first code first.\n-    for (int i = store_count - 1; i >= 0; i--) {\n-      if (entries_address[i].load_fail()) {\n-        continue;\n-      }\n-      if (entries_address[i].not_entrant()) {\n-        log_info(scc, exit)(\"Not entrant new entry comp_id: %d, comp_level: %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s\", entries_address[i].comp_id(), entries_address[i].comp_level(), entries_address[i].decompile(), entries_address[i].id(), (entries_address[i].has_clinit_barriers() ? \", has clinit barriers\" : \"\"));\n-        if (entries_address[i].for_preload()) {\n-          \/\/ Skip not entrant preload code:\n-          \/\/ we can't pre-load code which may have failing dependencies.\n-          continue;\n-        }\n-        entries_address[i].set_entrant(); \/\/ Reset\n-      } else if (entries_address[i].for_preload() && entries_address[i].method() != nullptr) {\n-        \/\/ record entrant first version code for pre-loading\n-        preload_entries[preload_entries_cnt++] = entries_count;\n-      }\n-      {\n-        entries_address[i].set_next(nullptr); \/\/ clear pointers before storing data\n-        uint size = align_up(entries_address[i].size(), DATA_ALIGNMENT);\n-        copy_bytes((_store_buffer + entries_address[i].offset()), (address)current, size);\n-        entries_address[i].set_offset(current - start); \/\/ New offset\n-        entries_address[i].update_method_for_writing();\n-        current += size;\n-        uint n = write_bytes(&(entries_address[i]), sizeof(SCCEntry));\n-        if (n != sizeof(SCCEntry)) {\n-          FREE_C_HEAP_ARRAY(char, buffer);\n-          FREE_C_HEAP_ARRAY(uint, search);\n-          return false;\n-        }\n-        search[entries_count*2 + 0] = entries_address[i].id();\n-        search[entries_count*2 + 1] = entries_count;\n-        entries_count++;\n-      }\n-    }\n-\n-    if (entries_count == 0) {\n-      log_info(scc, exit)(\"No entires written to AOT Code Cache\");\n-      FREE_C_HEAP_ARRAY(char, buffer);\n-      FREE_C_HEAP_ARRAY(uint, search);\n-      return true; \/\/ Nothing to write\n-    }\n-    assert(entries_count <= (store_count + load_count), \"%d > (%d + %d)\", entries_count, store_count, load_count);\n-    \/\/ Write strings\n-    if (strings_count > 0) {\n-      copy_bytes((_store_buffer + strings_offset), (address)current, strings_size);\n-      strings_offset = (current - start); \/\/ New offset\n-      current += strings_size;\n-    }\n-    uint preload_entries_offset = (current - start);\n-    preload_entries_size = preload_entries_cnt * sizeof(uint);\n-    if (preload_entries_size > 0) {\n-      copy_bytes((const char*)preload_entries, (address)current, preload_entries_size);\n-      current += preload_entries_size;\n-      log_info(scc, exit)(\"Wrote %d preload entries to AOT Code Cache\", preload_entries_cnt);\n-    }\n-    if (preload_entries != nullptr) {\n-      FREE_C_HEAP_ARRAY(uint, preload_entries);\n-    }\n-\n-    uint new_entries_offset = (current - start); \/\/ New offset\n-    \/\/ Sort and store search table\n-    qsort(search, entries_count, 2*sizeof(uint), uint_cmp);\n-    search_size = 2 * entries_count * sizeof(uint);\n-    copy_bytes((const char*)search, (address)current, search_size);\n-    FREE_C_HEAP_ARRAY(uint, search);\n-    current += search_size;\n-\n-    \/\/ Write entries\n-    entries_size = entries_count * sizeof(SCCEntry); \/\/ New size\n-    copy_bytes((_store_buffer + entries_offset), (address)current, entries_size);\n-    current += entries_size;\n-\n-    log_stats_on_exit();\n-\n-    uint size = (current - start);\n-    assert(size <= total_size, \"%d > %d\", size , total_size);\n-\n-    \/\/ Finalize header\n-    SCCHeader* header = (SCCHeader*)start;\n-    header->init(size,\n-                 (uint)strings_count, strings_offset,\n-                 entries_count, new_entries_offset,\n-                 preload_entries_cnt, preload_entries_offset,\n-                 _use_meta_ptrs);\n-    log_info(scc, init)(\"Wrote SCCache header to AOT Code Cache\");\n-    log_info(scc, exit)(\"Wrote %d bytes of data to AOT Code Cache\", size);\n-\n-    _cached_code_directory->set_aot_code_data(size, start);\n-  }\n-  return true;\n-}\n-\n-bool SCCache::load_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) {\n-  assert(start == cgen->assembler()->pc(), \"wrong buffer\");\n-  SCCache* cache = open_for_read();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  SCCEntry* entry = cache->find_entry(SCCEntry::Stub, (uint)id);\n-  if (entry == nullptr) {\n-    return false;\n-  }\n-  uint entry_position = entry->offset();\n-  \/\/ Read name\n-  uint name_offset = entry->name_offset() + entry_position;\n-  uint name_size   = entry->name_size(); \/\/ Includes '\/0'\n-  const char* saved_name = cache->addr(name_offset);\n-  if (strncmp(name, saved_name, (name_size - 1)) != 0) {\n-    log_warning(scc)(\"Saved stub's name '%s' is different from '%s' for id:%d\", saved_name, name, (int)id);\n-    cache->set_failed();\n-    exit_vm_on_load_failure();\n-    return false;\n-  }\n-  log_info(scc,stubs)(\"Reading stub '%s' id:%d from AOT Code Cache\", name, (int)id);\n-  \/\/ Read code\n-  uint code_offset = entry->code_offset() + entry_position;\n-  uint code_size   = entry->code_size();\n-  copy_bytes(cache->addr(code_offset), start, code_size);\n-  cgen->assembler()->code_section()->set_end(start + code_size);\n-  log_info(scc,stubs)(\"Read stub '%s' id:%d from AOT Code Cache\", name, (int)id);\n-  return true;\n-}\n-\n-bool SCCache::store_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) {\n-  SCCache* cache = open_for_write();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  log_info(scc, stubs)(\"Writing stub '%s' id:%d to AOT Code Cache\", name, (int)id);\n-  if (!cache->align_write()) {\n-    return false;\n-  }\n-#ifdef ASSERT\n-  CodeSection* cs = cgen->assembler()->code_section();\n-  if (cs->has_locs()) {\n-    uint reloc_count = cs->locs_count();\n-    tty->print_cr(\"======== write stubs code section relocations [%d]:\", reloc_count);\n-    \/\/ Collect additional data\n-    RelocIterator iter(cs);\n-    while (iter.next()) {\n-      switch (iter.type()) {\n-        case relocInfo::none:\n-          break;\n-        default: {\n-          iter.print_current_on(tty);\n-          fatal(\"stub's relocation %d unimplemented\", (int)iter.type());\n-          break;\n-        }\n-      }\n-    }\n-  }\n-#endif\n-  uint entry_position = cache->_write_position;\n-\n-  \/\/ Write code\n-  uint code_offset = 0;\n-  uint code_size = cgen->assembler()->pc() - start;\n-  uint n = cache->write_bytes(start, code_size);\n-  if (n != code_size) {\n-    return false;\n-  }\n-  \/\/ Write name\n-  uint name_offset = cache->_write_position - entry_position;\n-  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n-  n = cache->write_bytes(name, name_size);\n-  if (n != name_size) {\n-    return false;\n-  }\n-  uint entry_size = cache->_write_position - entry_position;\n-  SCCEntry* entry = new(cache) SCCEntry(entry_position, entry_size, name_offset, name_size,\n-                                        code_offset, code_size, 0, 0,\n-                                        SCCEntry::Stub, (uint32_t)id);\n-  log_info(scc, stubs)(\"Wrote stub '%s' id:%d to AOT Code Cache\", name, (int)id);\n-  return true;\n-}\n-\n-Klass* SCCReader::read_klass(const methodHandle& comp_method, bool shared) {\n-  uint code_offset = read_position();\n-  uint state = *(uint*)addr(code_offset);\n-  uint init_state = (state  & 1);\n-  uint array_dim  = (state >> 1);\n-  code_offset += sizeof(int);\n-  if (_cache->use_meta_ptrs() && shared) {\n-    uint klass_offset = *(uint*)addr(code_offset);\n-    code_offset += sizeof(uint);\n-    set_read_position(code_offset);\n-    Klass* k = (Klass*)((address)SharedBaseAddress + klass_offset);\n-    if (!MetaspaceShared::is_in_shared_metaspace((address)k)) {\n-      \/\/ Something changed in CDS\n-      set_lookup_failed();\n-      log_info(scc)(\"Lookup failed for shared klass: \" INTPTR_FORMAT \" is not in CDS \", p2i((address)k));\n-      return nullptr;\n-    }\n-    assert(k->is_klass(), \"sanity\");\n-    ResourceMark rm;\n-    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_loaded()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for klass %s: not loaded\",\n-                       compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n-      return nullptr;\n-    } else\n-    \/\/ Allow not initialized klass which was uninitialized during code caching or for preload\n-    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_initialized() && (init_state == 1) && !_preload) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for klass %s: not initialized\",\n-                       compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n-      return nullptr;\n-    }\n-    if (array_dim > 0) {\n-      assert(k->is_instance_klass() || k->is_typeArray_klass(), \"sanity check\");\n-      Klass* ak = k->array_klass_or_null(array_dim);\n-      \/\/ FIXME: what would it take to create an array class on the fly?\n-\/\/      Klass* ak = k->array_klass(dim, JavaThread::current());\n-\/\/      guarantee(JavaThread::current()->pending_exception() == nullptr, \"\");\n-      if (ak == nullptr) {\n-        set_lookup_failed();\n-        log_info(scc)(\"%d (L%d): %d-dimension array klass lookup failed: %s\",\n-                         compile_id(), comp_level(), array_dim, k->external_name());\n-      }\n-      log_info(scc)(\"%d (L%d): Klass lookup: %s (object array)\", compile_id(), comp_level(), k->external_name());\n-      return ak;\n-    } else {\n-      log_info(scc)(\"%d (L%d): Shared klass lookup: %s\",\n-                    compile_id(), comp_level(), k->external_name());\n-      return k;\n-    }\n-  }\n-  int name_length = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-  const char* dest = addr(code_offset);\n-  code_offset += name_length + 1;\n-  set_read_position(code_offset);\n-  TempNewSymbol klass_sym = SymbolTable::probe(&(dest[0]), name_length);\n-  if (klass_sym == nullptr) {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Probe failed for class %s\",\n-                     compile_id(), comp_level(), &(dest[0]));\n-    return nullptr;\n-  }\n-  \/\/ Use class loader of compiled method.\n-  Thread* thread = Thread::current();\n-  Handle loader(thread, comp_method->method_holder()->class_loader());\n-  Klass* k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, loader);\n-  assert(!thread->has_pending_exception(), \"should not throw\");\n-  if (k == nullptr && !loader.is_null()) {\n-    \/\/ Try default loader and domain\n-    k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, Handle());\n-    assert(!thread->has_pending_exception(), \"should not throw\");\n-  }\n-  if (k != nullptr) {\n-    \/\/ Allow not initialized klass which was uninitialized during code caching\n-    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_initialized() && (init_state == 1)) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d (L%d): Lookup failed for klass %s: not initialized\", compile_id(), comp_level(), &(dest[0]));\n-      return nullptr;\n-    }\n-    log_info(scc)(\"%d (L%d): Klass lookup %s\", compile_id(), comp_level(), k->external_name());\n-  } else {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Lookup failed for class %s\", compile_id(), comp_level(), &(dest[0]));\n-    return nullptr;\n-  }\n-  return k;\n-}\n-\n-Method* SCCReader::read_method(const methodHandle& comp_method, bool shared) {\n-  uint code_offset = read_position();\n-  if (_cache->use_meta_ptrs() && shared) {\n-    uint method_offset = *(uint*)addr(code_offset);\n-    code_offset += sizeof(uint);\n-    set_read_position(code_offset);\n-    Method* m = (Method*)((address)SharedBaseAddress + method_offset);\n-    if (!MetaspaceShared::is_in_shared_metaspace((address)m)) {\n-      \/\/ Something changed in CDS\n-      set_lookup_failed();\n-      log_info(scc)(\"Lookup failed for shared method: \" INTPTR_FORMAT \" is not in CDS \", p2i((address)m));\n-      return nullptr;\n-    }\n-    assert(m->is_method(), \"sanity\");\n-    ResourceMark rm;\n-    Klass* k = m->method_holder();\n-    if (!k->is_instance_klass()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for holder %s: not instance klass\",\n-                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n-      return nullptr;\n-    } else if (!MetaspaceShared::is_in_shared_metaspace((address)k)) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for holder %s: not in CDS\",\n-                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n-      return nullptr;\n-    } else if (!InstanceKlass::cast(k)->is_loaded()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for holder %s: not loaded\",\n-                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n-      return nullptr;\n-    } else if (!InstanceKlass::cast(k)->is_linked()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d '%s' (L%d): Lookup failed for holder %s: not linked%s\",\n-                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name(), (_preload ? \" for code preload\" : \"\"));\n-      return nullptr;\n-    }\n-    log_info(scc)(\"%d (L%d): Shared method lookup: %s\",\n-                  compile_id(), comp_level(), m->name_and_sig_as_C_string());\n-    return m;\n-  }\n-  int holder_length = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-  int name_length = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-  int signat_length = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-\n-  const char* dest = addr(code_offset);\n-  code_offset += holder_length + 1 + name_length + 1 + signat_length + 1;\n-  set_read_position(code_offset);\n-  TempNewSymbol klass_sym = SymbolTable::probe(&(dest[0]), holder_length);\n-  if (klass_sym == nullptr) {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Probe failed for class %s\", compile_id(), comp_level(), &(dest[0]));\n-    return nullptr;\n-  }\n-  \/\/ Use class loader of compiled method.\n-  Thread* thread = Thread::current();\n-  Handle loader(thread, comp_method->method_holder()->class_loader());\n-  Klass* k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, loader);\n-  assert(!thread->has_pending_exception(), \"should not throw\");\n-  if (k == nullptr && !loader.is_null()) {\n-    \/\/ Try default loader and domain\n-    k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, Handle());\n-    assert(!thread->has_pending_exception(), \"should not throw\");\n-  }\n-  if (k != nullptr) {\n-    if (!k->is_instance_klass()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d (L%d): Lookup failed for holder %s: not instance klass\",\n-                       compile_id(), comp_level(), &(dest[0]));\n-      return nullptr;\n-    } else if (!InstanceKlass::cast(k)->is_linked()) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d (L%d): Lookup failed for holder %s: not linked\",\n-                       compile_id(), comp_level(), &(dest[0]));\n-      return nullptr;\n-    }\n-    log_info(scc)(\"%d (L%d): Holder lookup: %s\", compile_id(), comp_level(), k->external_name());\n-  } else {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Lookup failed for holder %s\",\n-                  compile_id(), comp_level(), &(dest[0]));\n-    return nullptr;\n-  }\n-  TempNewSymbol name_sym = SymbolTable::probe(&(dest[holder_length + 1]), name_length);\n-  int pos = holder_length + 1 + name_length + 1;\n-  TempNewSymbol sign_sym = SymbolTable::probe(&(dest[pos]), signat_length);\n-  if (name_sym == nullptr) {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Probe failed for method name %s\",\n-                     compile_id(), comp_level(), &(dest[holder_length + 1]));\n-    return nullptr;\n-  }\n-  if (sign_sym == nullptr) {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Probe failed for method signature %s\",\n-                     compile_id(), comp_level(), &(dest[pos]));\n-    return nullptr;\n-  }\n-  Method* m = InstanceKlass::cast(k)->find_method(name_sym, sign_sym);\n-  if (m != nullptr) {\n-    ResourceMark rm;\n-    log_info(scc)(\"%d (L%d): Method lookup: %s\", compile_id(), comp_level(), m->name_and_sig_as_C_string());\n-  } else {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Lookup failed for method %s::%s%s\",\n-                     compile_id(), comp_level(), &(dest[0]), &(dest[holder_length + 1]), &(dest[pos]));\n-    return nullptr;\n-  }\n-  return m;\n-}\n-\n-bool SCCache::write_klass(Klass* klass) {\n-  bool can_use_meta_ptrs = _use_meta_ptrs;\n-  uint array_dim = 0;\n-  if (klass->is_objArray_klass()) {\n-    array_dim = ObjArrayKlass::cast(klass)->dimension();\n-    klass     = ObjArrayKlass::cast(klass)->bottom_klass(); \/\/ overwrites klass\n-  }\n-  uint init_state = 0;\n-  if (klass->is_instance_klass()) {\n-    InstanceKlass* ik = InstanceKlass::cast(klass);\n-    ClassLoaderData* cld = ik->class_loader_data();\n-    if (!cld->is_builtin_class_loader_data()) {\n-      set_lookup_failed();\n-      return false;\n-    }\n-    if (_for_preload && !CDSAccess::can_generate_cached_code(ik)) {\n-      _for_preload = false;\n-      \/\/ Bailout if code has clinit barriers:\n-      \/\/ method will be recompiled without them in any case\n-      if (_has_clinit_barriers) {\n-        set_lookup_failed();\n-        return false;\n-      }\n-      can_use_meta_ptrs = false;\n-    }\n-    init_state = (ik->is_initialized() ? 1 : 0);\n-  }\n-  ResourceMark rm;\n-  uint state = (array_dim << 1) | (init_state & 1);\n-  if (can_use_meta_ptrs && CDSAccess::can_generate_cached_code(klass)) {\n-    DataKind kind = DataKind::Klass_Shared;\n-    uint n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    \/\/ Record state of instance klass initialization.\n-    n = write_bytes(&state, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    uint klass_offset = CDSAccess::delta_from_shared_address_base((address)klass);\n-    n = write_bytes(&klass_offset, sizeof(uint));\n-    if (n != sizeof(uint)) {\n-      return false;\n-    }\n-    log_info(scc)(\"%d (L%d): Wrote shared klass: %s%s%s @ 0x%08x\", compile_id(), comp_level(), klass->external_name(),\n-                  (!klass->is_instance_klass() ? \"\" : (init_state == 1 ? \" (initialized)\" : \" (not-initialized)\")),\n-                  (array_dim > 0 ? \" (object array)\" : \"\"),\n-                  klass_offset);\n-    return true;\n-  }\n-  \/\/ Bailout if code has clinit barriers:\n-  \/\/ method will be recompiled without them in any case\n-  if (_for_preload && _has_clinit_barriers) {\n-    set_lookup_failed();\n-    return false;\n-  }\n-  _for_preload = false;\n-  log_info(scc,cds)(\"%d (L%d): Not shared klass: %s\", compile_id(), comp_level(), klass->external_name());\n-  if (klass->is_hidden()) { \/\/ Skip such nmethod\n-    set_lookup_failed();\n-    return false;\n-  }\n-  DataKind kind = DataKind::Klass;\n-  uint n = write_bytes(&kind, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  \/\/ Record state of instance klass initialization.\n-  n = write_bytes(&state, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  Symbol* name = klass->name();\n-  int name_length = name->utf8_length();\n-  int total_length = name_length + 1;\n-  char* dest = NEW_RESOURCE_ARRAY(char, total_length);\n-  name->as_C_string(dest, total_length);\n-  dest[total_length - 1] = '\\0';\n-  LogTarget(Info, scc, loader) log;\n-  if (log.is_enabled()) {\n-    LogStream ls(log);\n-    oop loader = klass->class_loader();\n-    oop domain = klass->protection_domain();\n-    ls.print(\"Class %s loader: \", dest);\n-    if (loader == nullptr) {\n-      ls.print(\"nullptr\");\n-    } else {\n-      loader->print_value_on(&ls);\n-    }\n-    ls.print(\" domain: \");\n-    if (domain == nullptr) {\n-      ls.print(\"nullptr\");\n-    } else {\n-      domain->print_value_on(&ls);\n-    }\n-    ls.cr();\n-  }\n-  n = write_bytes(&name_length, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  n = write_bytes(dest, total_length);\n-  if (n != (uint)total_length) {\n-    return false;\n-  }\n-  log_info(scc)(\"%d (L%d): Wrote klass: %s%s%s\",\n-                compile_id(), comp_level(),\n-                dest, (!klass->is_instance_klass() ? \"\" : (init_state == 1 ? \" (initialized)\" : \" (not-initialized)\")),\n-                (array_dim > 0 ? \" (object array)\" : \"\"));\n-  return true;\n-}\n-\n-bool SCCache::write_method(Method* method) {\n-  bool can_use_meta_ptrs = _use_meta_ptrs;\n-  Klass* klass = method->method_holder();\n-  if (klass->is_instance_klass()) {\n-    InstanceKlass* ik = InstanceKlass::cast(klass);\n-    ClassLoaderData* cld = ik->class_loader_data();\n-    if (!cld->is_builtin_class_loader_data()) {\n-      set_lookup_failed();\n-      return false;\n-    }\n-    if (_for_preload && !CDSAccess::can_generate_cached_code(ik)) {\n-      _for_preload = false;\n-      \/\/ Bailout if code has clinit barriers:\n-      \/\/ method will be recompiled without them in any case\n-      if (_has_clinit_barriers) {\n-        set_lookup_failed();\n-        return false;\n-      }\n-      can_use_meta_ptrs = false;\n-    }\n-  }\n-  ResourceMark rm;\n-  if (can_use_meta_ptrs && CDSAccess::can_generate_cached_code(method)) {\n-    DataKind kind = DataKind::Method_Shared;\n-    uint n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    uint method_offset = CDSAccess::delta_from_shared_address_base((address)method);\n-    n = write_bytes(&method_offset, sizeof(uint));\n-    if (n != sizeof(uint)) {\n-      return false;\n-    }\n-    log_info(scc)(\"%d (L%d): Wrote shared method: %s @ 0x%08x\", compile_id(), comp_level(), method->name_and_sig_as_C_string(), method_offset);\n-    return true;\n-  }\n-  \/\/ Bailout if code has clinit barriers:\n-  \/\/ method will be recompiled without them in any case\n-  if (_for_preload && _has_clinit_barriers) {\n-    set_lookup_failed();\n-    return false;\n-  }\n-  _for_preload = false;\n-  log_info(scc,cds)(\"%d (L%d): Not shared method: %s\", compile_id(), comp_level(), method->name_and_sig_as_C_string());\n-  if (method->is_hidden()) { \/\/ Skip such nmethod\n-    set_lookup_failed();\n-    return false;\n-  }\n-  DataKind kind = DataKind::Method;\n-  uint n = write_bytes(&kind, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  Symbol* name   = method->name();\n-  Symbol* holder = method->klass_name();\n-  Symbol* signat = method->signature();\n-  int name_length   = name->utf8_length();\n-  int holder_length = holder->utf8_length();\n-  int signat_length = signat->utf8_length();\n-\n-  \/\/ Write sizes and strings\n-  int total_length = holder_length + 1 + name_length + 1 + signat_length + 1;\n-  char* dest = NEW_RESOURCE_ARRAY(char, total_length);\n-  holder->as_C_string(dest, total_length);\n-  dest[holder_length] = '\\0';\n-  int pos = holder_length + 1;\n-  name->as_C_string(&(dest[pos]), (total_length - pos));\n-  pos += name_length;\n-  dest[pos++] = '\\0';\n-  signat->as_C_string(&(dest[pos]), (total_length - pos));\n-  dest[total_length - 1] = '\\0';\n-\n-  LogTarget(Info, scc, loader) log;\n-  if (log.is_enabled()) {\n-    LogStream ls(log);\n-    oop loader = klass->class_loader();\n-    oop domain = klass->protection_domain();\n-    ls.print(\"Holder %s loader: \", dest);\n-    if (loader == nullptr) {\n-      ls.print(\"nullptr\");\n-    } else {\n-      loader->print_value_on(&ls);\n-    }\n-    ls.print(\" domain: \");\n-    if (domain == nullptr) {\n-      ls.print(\"nullptr\");\n-    } else {\n-      domain->print_value_on(&ls);\n-    }\n-    ls.cr();\n-  }\n-\n-  n = write_bytes(&holder_length, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  n = write_bytes(&name_length, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  n = write_bytes(&signat_length, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  n = write_bytes(dest, total_length);\n-  if (n != (uint)total_length) {\n-    return false;\n-  }\n-  dest[holder_length] = ' ';\n-  dest[holder_length + 1 + name_length] = ' ';\n-  log_info(scc)(\"%d (L%d): Wrote method: %s\", compile_id(), comp_level(), dest);\n-  return true;\n-}\n-\n-\/\/ Repair the pc relative information in the code after load\n-bool SCCReader::read_relocations(CodeBuffer* buffer, CodeBuffer* orig_buffer,\n-                                 OopRecorder* oop_recorder, ciMethod* target) {\n-  bool success = true;\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    uint code_offset = read_position();\n-    int reloc_count = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    if (reloc_count == 0) {\n-      set_read_position(code_offset);\n-      continue;\n-    }\n-    \/\/ Read _locs_point (as offset from start)\n-    int locs_point_off = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    uint reloc_size = reloc_count * sizeof(relocInfo);\n-    CodeSection* cs  = buffer->code_section(i);\n-    if (cs->locs_capacity() < reloc_count) {\n-      cs->expand_locs(reloc_count);\n-    }\n-    relocInfo* reloc_start = cs->locs_start();\n-    copy_bytes(addr(code_offset), (address)reloc_start, reloc_size);\n-    code_offset += reloc_size;\n-    cs->set_locs_end(reloc_start + reloc_count);\n-    cs->set_locs_point(cs->start() + locs_point_off);\n-\n-    \/\/ Read additional relocation data: uint per relocation\n-    uint  data_size  = reloc_count * sizeof(uint);\n-    uint* reloc_data = (uint*)addr(code_offset);\n-    code_offset += data_size;\n-    set_read_position(code_offset);\n-    LogStreamHandle(Info, scc, reloc) log;\n-    if (log.is_enabled()) {\n-      log.print_cr(\"======== read code section %d relocations [%d]:\", i, reloc_count);\n-    }\n-    RelocIterator iter(cs);\n-    int j = 0;\n-    while (iter.next()) {\n-      switch (iter.type()) {\n-        case relocInfo::none:\n-          break;\n-        case relocInfo::oop_type: {\n-          VM_ENTRY_MARK;\n-          oop_Relocation* r = (oop_Relocation*)iter.reloc();\n-          if (r->oop_is_immediate()) {\n-            assert(reloc_data[j] == (uint)j, \"should be\");\n-            methodHandle comp_method(THREAD, target->get_Method());\n-            oop obj = read_oop(THREAD, comp_method);\n-            jobject jo = JNIHandles::make_local(THREAD, obj);\n-            if (lookup_failed()) {\n-              success = false;\n-              break;\n-            }\n-            r->set_value((address)jo);\n-          } else if (false) {\n-            \/\/ Get already updated value from OopRecorder.\n-            assert(oop_recorder != nullptr, \"sanity\");\n-            int index = r->oop_index();\n-            jobject jo = oop_recorder->oop_at(index);\n-            oop obj = JNIHandles::resolve(jo);\n-            r->set_value(*reinterpret_cast<address*>(&obj));\n-          }\n-          break;\n-        }\n-        case relocInfo::metadata_type: {\n-          VM_ENTRY_MARK;\n-          metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n-          Metadata* m;\n-          if (r->metadata_is_immediate()) {\n-            assert(reloc_data[j] == (uint)j, \"should be\");\n-            methodHandle comp_method(THREAD, target->get_Method());\n-            m = read_metadata(comp_method);\n-            if (lookup_failed()) {\n-              success = false;\n-              break;\n-            }\n-          } else {\n-            \/\/ Get already updated value from OopRecorder.\n-            assert(oop_recorder != nullptr, \"sanity\");\n-            int index = r->metadata_index();\n-            m = oop_recorder->metadata_at(index);\n-          }\n-          r->set_value((address)m);\n-          break;\n-        }\n-        case relocInfo::virtual_call_type:   \/\/ Fall through. They all call resolve_*_call blobs.\n-        case relocInfo::opt_virtual_call_type:\n-        case relocInfo::static_call_type: {\n-          address dest = _cache->address_for_id(reloc_data[j]);\n-          if (dest != (address)-1) {\n-            ((CallRelocation*)iter.reloc())->set_destination(dest);\n-          }\n-          break;\n-        }\n-        case relocInfo::trampoline_stub_type: {\n-          address dest = _cache->address_for_id(reloc_data[j]);\n-          if (dest != (address)-1) {\n-            ((trampoline_stub_Relocation*)iter.reloc())->set_destination(dest);\n-          }\n-          break;\n-        }\n-        case relocInfo::static_stub_type:\n-          break;\n-        case relocInfo::runtime_call_type: {\n-          address dest = _cache->address_for_id(reloc_data[j]);\n-          if (dest != (address)-1) {\n-            ((CallRelocation*)iter.reloc())->set_destination(dest);\n-          }\n-          break;\n-        }\n-        case relocInfo::runtime_call_w_cp_type:\n-          fatal(\"runtime_call_w_cp_type unimplemented\");\n-          \/\/address destination = iter.reloc()->value();\n-          break;\n-        case relocInfo::external_word_type: {\n-          address target = _cache->address_for_id(reloc_data[j]);\n-          \/\/ Add external address to global table\n-          int index = ExternalsRecorder::find_index(target);\n-          \/\/ Update index in relocation\n-          Relocation::add_jint(iter.data(), index);\n-          external_word_Relocation* reloc = (external_word_Relocation*)iter.reloc();\n-          assert(reloc->target() == target, \"sanity\");\n-          reloc->set_value(target); \/\/ Patch address in the code\n-          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n-          break;\n-        }\n-        case relocInfo::internal_word_type:\n-          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n-          break;\n-        case relocInfo::section_word_type:\n-          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n-          break;\n-        case relocInfo::poll_type:\n-          break;\n-        case relocInfo::poll_return_type:\n-          break;\n-        case relocInfo::post_call_nop_type:\n-          break;\n-        case relocInfo::entry_guard_type:\n-          break;\n-        default:\n-          fatal(\"relocation %d unimplemented\", (int)iter.type());\n-          break;\n-      }\n-      if (success && log.is_enabled()) {\n-        iter.print_current_on(&log);\n-      }\n-      j++;\n-    }\n-    assert(j <= (int)reloc_count, \"sanity\");\n-  }\n-  return success;\n-}\n-\n-bool SCCReader::read_code(CodeBuffer* buffer, CodeBuffer* orig_buffer, uint code_offset) {\n-  assert(code_offset == align_up(code_offset, DATA_ALIGNMENT), \"%d not aligned to %d\", code_offset, DATA_ALIGNMENT);\n-  SCCodeSection* scc_cs = (SCCodeSection*)addr(code_offset);\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    CodeSection* cs = buffer->code_section(i);\n-    \/\/ Read original section size and address.\n-    uint orig_size = scc_cs[i]._size;\n-    log_debug(scc)(\"======== read code section %d [%d]:\", i, orig_size);\n-    uint orig_size_align = align_up(orig_size, DATA_ALIGNMENT);\n-    if (i != (int)CodeBuffer::SECT_INSTS) {\n-      buffer->initialize_section_size(cs, orig_size_align);\n-    }\n-    if (orig_size_align > (uint)cs->capacity()) { \/\/ Will not fit\n-      log_info(scc)(\"%d (L%d): original code section %d size %d > current capacity %d\",\n-                       compile_id(), comp_level(), i, orig_size, cs->capacity());\n-      return false;\n-    }\n-    if (orig_size == 0) {\n-      assert(cs->size() == 0, \"should match\");\n-      continue;  \/\/ skip trivial section\n-    }\n-    address orig_start = scc_cs[i]._origin_address;\n-\n-    \/\/ Populate fake original buffer (no code allocation in CodeCache).\n-    \/\/ It is used for relocations to calculate sections addesses delta.\n-    CodeSection* orig_cs = orig_buffer->code_section(i);\n-    assert(!orig_cs->is_allocated(), \"This %d section should not be set\", i);\n-    orig_cs->initialize(orig_start, orig_size);\n-\n-    \/\/ Load code to new buffer.\n-    address code_start = cs->start();\n-    copy_bytes(addr(scc_cs[i]._offset + code_offset), code_start, orig_size_align);\n-    cs->set_end(code_start + orig_size);\n-  }\n-\n-  return true;\n-}\n-\n-bool SCCache::load_adapter(CodeBuffer* buffer, uint32_t id, const char* name, uint32_t offsets[4]) {\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, stubs) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-  }\n-#endif\n-  SCCache* cache = open_for_read();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  log_info(scc, stubs)(\"Looking up adapter %s (0x%x) in AOT Code Cache\", name, id);\n-  SCCEntry* entry = cache->find_entry(SCCEntry::Adapter, id);\n-  if (entry == nullptr) {\n-    return false;\n-  }\n-  SCCReader reader(cache, entry, nullptr);\n-  return reader.compile_adapter(buffer, name, offsets);\n-}\n-bool SCCReader::compile_adapter(CodeBuffer* buffer, const char* name, uint32_t offsets[4]) {\n-  uint entry_position = _entry->offset();\n-  \/\/ Read name\n-  uint name_offset = entry_position + _entry->name_offset();\n-  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n-  const char* stored_name = addr(name_offset);\n-  log_info(scc, stubs)(\"%d (L%d): Reading adapter '%s' from AOT Code Cache\",\n-                       compile_id(), comp_level(), name);\n-  if (strncmp(stored_name, name, (name_size - 1)) != 0) {\n-    log_warning(scc)(\"%d (L%d): Saved adapter's name '%s' is different from '%s'\",\n-                     compile_id(), comp_level(), stored_name, name);\n-    \/\/ n.b. this is not fatal -- we have just seen a hash id clash\n-    \/\/ so no need to call cache->set_failed()\n-    return false;\n-  }\n-  \/\/ Create fake original CodeBuffer\n-  CodeBuffer orig_buffer(name);\n-  \/\/ Read code\n-  uint code_offset = entry_position + _entry->code_offset();\n-  if (!read_code(buffer, &orig_buffer, code_offset)) {\n-    return false;\n-  }\n-  \/\/ Read relocations\n-  uint reloc_offset = entry_position + _entry->reloc_offset();\n-  set_read_position(reloc_offset);\n-  if (!read_relocations(buffer, &orig_buffer, nullptr, nullptr)) {\n-    return false;\n-  }\n-  uint offset = read_position();\n-  int offsets_count = *(int*)addr(offset);\n-  offset += sizeof(int);\n-  assert(offsets_count == 4, \"wrong caller expectations\");\n-  set_read_position(offset);\n-  for (int i = 0; i < offsets_count; i++) {\n-    uint32_t arg = *(uint32_t*)addr(offset);\n-    offset += sizeof(uint32_t);\n-    log_debug(scc, stubs)(\"%d (L%d): Reading adapter '%s'  offsets[%d] == 0x%x from AOT Code Cache\",\n-                         compile_id(), comp_level(), stored_name, i, arg);\n-    offsets[i] = arg;\n-  }\n-  log_debug(scc, stubs)(\"%d (L%d): Read adapter '%s' with '%d' args from AOT Code Cache\",\n-                       compile_id(), comp_level(), stored_name, offsets_count);\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, stubs) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-    buffer->decode();\n-  }\n-#endif\n-  \/\/ mark entry as loaded\n-  ((SCCEntry *)_entry)->set_loaded();\n-  return true;\n-}\n-\n-bool SCCache::load_exception_blob(CodeBuffer* buffer, int* pc_offset) {\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, nmethod) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-  }\n-#endif\n-  SCCache* cache = open_for_read();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  SCCEntry* entry = cache->find_entry(SCCEntry::Blob, 999);\n-  if (entry == nullptr) {\n-    return false;\n-  }\n-  SCCReader reader(cache, entry, nullptr);\n-  return reader.compile_blob(buffer, pc_offset);\n-}\n-\n-bool SCCReader::compile_blob(CodeBuffer* buffer, int* pc_offset) {\n-  uint entry_position = _entry->offset();\n-\n-  \/\/ Read pc_offset\n-  *pc_offset = *(int*)addr(entry_position);\n-\n-  \/\/ Read name\n-  uint name_offset = entry_position + _entry->name_offset();\n-  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n-  const char* name = addr(name_offset);\n-\n-  log_info(scc, stubs)(\"%d (L%d): Reading blob '%s' with pc_offset %d from AOT Code Cache\",\n-                       compile_id(), comp_level(), name, *pc_offset);\n-\n-  if (strncmp(buffer->name(), name, (name_size - 1)) != 0) {\n-    log_warning(scc)(\"%d (L%d): Saved blob's name '%s' is different from '%s'\",\n-                     compile_id(), comp_level(), name, buffer->name());\n-    ((SCCache*)_cache)->set_failed();\n-    exit_vm_on_load_failure();\n-    return false;\n-  }\n-\n-  \/\/ Create fake original CodeBuffer\n-  CodeBuffer orig_buffer(name);\n-\n-  \/\/ Read code\n-  uint code_offset = entry_position + _entry->code_offset();\n-  if (!read_code(buffer, &orig_buffer, code_offset)) {\n-    return false;\n-  }\n-\n-  \/\/ Read relocations\n-  uint reloc_offset = entry_position + _entry->reloc_offset();\n-  set_read_position(reloc_offset);\n-  if (!read_relocations(buffer, &orig_buffer, nullptr, nullptr)) {\n-    return false;\n-  }\n-\n-  log_info(scc, stubs)(\"%d (L%d): Read blob '%s' from AOT Code Cache\",\n-                       compile_id(), comp_level(), name);\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, nmethod) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-    buffer->decode();\n-  }\n-#endif\n-  return true;\n-}\n-\n-bool SCCache::write_relocations(CodeBuffer* buffer, uint& all_reloc_size) {\n-  uint all_reloc_count = 0;\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    CodeSection* cs = buffer->code_section(i);\n-    uint reloc_count = cs->has_locs() ? cs->locs_count() : 0;\n-    all_reloc_count += reloc_count;\n-  }\n-  all_reloc_size = all_reloc_count * sizeof(relocInfo);\n-  bool success = true;\n-  uint* reloc_data = NEW_C_HEAP_ARRAY(uint, all_reloc_count, mtCode);\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    CodeSection* cs = buffer->code_section(i);\n-    int reloc_count = cs->has_locs() ? cs->locs_count() : 0;\n-    uint n = write_bytes(&reloc_count, sizeof(int));\n-    if (n != sizeof(int)) {\n-      success = false;\n-      break;\n-    }\n-    if (reloc_count == 0) {\n-      continue;\n-    }\n-    \/\/ Write _locs_point (as offset from start)\n-    int locs_point_off = cs->locs_point_off();\n-    n = write_bytes(&locs_point_off, sizeof(int));\n-    if (n != sizeof(int)) {\n-      success = false;\n-      break;\n-    }\n-    relocInfo* reloc_start = cs->locs_start();\n-    uint reloc_size      = reloc_count * sizeof(relocInfo);\n-    n = write_bytes(reloc_start, reloc_size);\n-    if (n != reloc_size) {\n-      success = false;\n-      break;\n-    }\n-    LogStreamHandle(Info, scc, reloc) log;\n-    if (log.is_enabled()) {\n-      log.print_cr(\"======== write code section %d relocations [%d]:\", i, reloc_count);\n-    }\n-    \/\/ Collect additional data\n-    RelocIterator iter(cs);\n-    bool has_immediate = false;\n-    int j = 0;\n-    while (iter.next()) {\n-      reloc_data[j] = 0; \/\/ initialize\n-      switch (iter.type()) {\n-        case relocInfo::none:\n-          break;\n-        case relocInfo::oop_type: {\n-          oop_Relocation* r = (oop_Relocation*)iter.reloc();\n-          if (r->oop_is_immediate()) {\n-            reloc_data[j] = (uint)j; \/\/ Indication that we need to restore immediate\n-            has_immediate = true;\n-          }\n-          break;\n-        }\n-        case relocInfo::metadata_type: {\n-          metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n-          if (r->metadata_is_immediate()) {\n-            reloc_data[j] = (uint)j; \/\/ Indication that we need to restore immediate\n-            has_immediate = true;\n-          }\n-          break;\n-        }\n-        case relocInfo::virtual_call_type:  \/\/ Fall through. They all call resolve_*_call blobs.\n-        case relocInfo::opt_virtual_call_type:\n-        case relocInfo::static_call_type: {\n-          CallRelocation* r = (CallRelocation*)iter.reloc();\n-          address dest = r->destination();\n-          if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n-            dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n-          }\n-          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n-          break;\n-        }\n-        case relocInfo::trampoline_stub_type: {\n-          address dest = ((trampoline_stub_Relocation*)iter.reloc())->destination();\n-          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n-          break;\n-        }\n-        case relocInfo::static_stub_type:\n-          break;\n-        case relocInfo::runtime_call_type: {\n-          \/\/ Record offset of runtime destination\n-          CallRelocation* r = (CallRelocation*)iter.reloc();\n-          address dest = r->destination();\n-          if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n-            dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n-          }\n-          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n-          break;\n-        }\n-        case relocInfo::runtime_call_w_cp_type:\n-          fatal(\"runtime_call_w_cp_type unimplemented\");\n-          break;\n-        case relocInfo::external_word_type: {\n-          \/\/ Record offset of runtime target\n-          address target = ((external_word_Relocation*)iter.reloc())->target();\n-          reloc_data[j] = _table->id_for_address(target, iter, buffer);\n-          break;\n-        }\n-        case relocInfo::internal_word_type:\n-          break;\n-        case relocInfo::section_word_type:\n-          break;\n-        case relocInfo::poll_type:\n-          break;\n-        case relocInfo::poll_return_type:\n-          break;\n-        case relocInfo::post_call_nop_type:\n-          break;\n-        case relocInfo::entry_guard_type:\n-          break;\n-        default:\n-          fatal(\"relocation %d unimplemented\", (int)iter.type());\n-          break;\n-      }\n-      if (log.is_enabled()) {\n-        iter.print_current_on(&log);\n-      }\n-      j++;\n-    }\n-    assert(j <= (int)reloc_count, \"sanity\");\n-    \/\/ Write additional relocation data: uint per relocation\n-    uint data_size = reloc_count * sizeof(uint);\n-    n = write_bytes(reloc_data, data_size);\n-    if (n != data_size) {\n-      success = false;\n-      break;\n-    }\n-    if (has_immediate) {\n-      \/\/ Save information about immediates in this Code Section\n-      RelocIterator iter_imm(cs);\n-      int j = 0;\n-      while (iter_imm.next()) {\n-        switch (iter_imm.type()) {\n-          case relocInfo::oop_type: {\n-            oop_Relocation* r = (oop_Relocation*)iter_imm.reloc();\n-            if (r->oop_is_immediate()) {\n-              assert(reloc_data[j] == (uint)j, \"should be\");\n-              jobject jo = *(jobject*)(r->oop_addr()); \/\/ Handle currently\n-              if (!write_oop(jo)) {\n-                success = false;\n-              }\n-            }\n-            break;\n-          }\n-          case relocInfo::metadata_type: {\n-            metadata_Relocation* r = (metadata_Relocation*)iter_imm.reloc();\n-            if (r->metadata_is_immediate()) {\n-              assert(reloc_data[j] == (uint)j, \"should be\");\n-              Metadata* m = r->metadata_value();\n-              if (!write_metadata(m)) {\n-                success = false;\n-              }\n-            }\n-            break;\n-          }\n-          default:\n-            break;\n-        }\n-        if (!success) {\n-          break;\n-        }\n-        j++;\n-      } \/\/ while (iter_imm.next())\n-    } \/\/ if (has_immediate)\n-  } \/\/ for(i < SECT_LIMIT)\n-  FREE_C_HEAP_ARRAY(uint, reloc_data);\n-  return success;\n-}\n-\n-bool SCCache::store_adapter(CodeBuffer* buffer, uint32_t id, const char* name, uint32_t offsets[4]) {\n-  assert(CDSConfig::is_dumping_adapters(), \"must be\");\n-  SCCache* cache = open_for_write();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  log_info(scc, stubs)(\"Writing adapter '%s' (0x%x) to AOT Code Cache\", name, id);\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, stubs) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-    buffer->decode();\n-  }\n-#endif\n-  \/\/ we need to take a lock to stop main thread racing with C1 and C2 compiler threads to\n-  \/\/ write blobs in parallel with each other or with later nmethods\n-  MutexLocker ml(Compile_lock);\n-  if (!cache->align_write()) {\n-    return false;\n-  }\n-  uint entry_position = cache->_write_position;\n-  \/\/ Write name\n-  uint name_offset = cache->_write_position - entry_position;\n-  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n-  uint n = cache->write_bytes(name, name_size);\n-  if (n != name_size) {\n-    return false;\n-  }\n-  \/\/ Write code section\n-  if (!cache->align_write()) {\n-    return false;\n-  }\n-  uint code_offset = cache->_write_position - entry_position;\n-  uint code_size = 0;\n-  if (!cache->write_code(buffer, code_size)) {\n-    return false;\n-  }\n-  \/\/ Write relocInfo array\n-  uint reloc_offset = cache->_write_position - entry_position;\n-  uint reloc_size = 0;\n-  if (!cache->write_relocations(buffer, reloc_size)) {\n-    return false;\n-  }\n-  int extras_count = 4;\n-  n = cache->write_bytes(&extras_count, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  for (int i = 0; i < 4; i++) {\n-    uint32_t arg = offsets[i];\n-    log_debug(scc, stubs)(\"Writing adapter '%s' (0x%x) offsets[%d] == 0x%x to AOT Code Cache\", name, id, i, arg);\n-    n = cache->write_bytes(&arg, sizeof(uint32_t));\n-    if (n != sizeof(uint32_t)) {\n-      return false;\n-    }\n-  }\n-  uint entry_size = cache->_write_position - entry_position;\n-  SCCEntry* entry = new (cache) SCCEntry(entry_position, entry_size, name_offset, name_size,\n-                                         code_offset, code_size, reloc_offset, reloc_size,\n-                                         SCCEntry::Adapter, id);\n-  log_info(scc, stubs)(\"Wrote adapter '%s' (0x%x) to AOT Code Cache\", name, id);\n-  return true;\n-}\n-\n-bool SCCache::write_code(CodeBuffer* buffer, uint& code_size) {\n-  assert(_write_position == align_up(_write_position, DATA_ALIGNMENT), \"%d not aligned to %d\", _write_position, DATA_ALIGNMENT);\n-  \/\/assert(buffer->blob() != nullptr, \"sanity\");\n-  uint code_offset = _write_position;\n-  uint cb_total_size = (uint)buffer->total_content_size();\n-  \/\/ Write information about Code sections first.\n-  SCCodeSection scc_cs[CodeBuffer::SECT_LIMIT];\n-  uint scc_cs_size = (uint)(sizeof(SCCodeSection) * CodeBuffer::SECT_LIMIT);\n-  uint offset = align_up(scc_cs_size, DATA_ALIGNMENT);\n-  uint total_size = 0;\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    const CodeSection* cs = buffer->code_section(i);\n-    assert(cs->mark() == nullptr, \"CodeSection::_mark is not implemented\");\n-    uint cs_size = (uint)cs->size();\n-    scc_cs[i]._size = cs_size;\n-    scc_cs[i]._origin_address = (cs_size == 0) ? nullptr : cs->start();\n-    scc_cs[i]._offset = (cs_size == 0) ? 0 : (offset + total_size);\n-    assert(cs->mark() == nullptr, \"CodeSection::_mark is not implemented\");\n-    total_size += align_up(cs_size, DATA_ALIGNMENT);\n-  }\n-  uint n = write_bytes(scc_cs, scc_cs_size);\n-  if (n != scc_cs_size) {\n-    return false;\n-  }\n-  if (!align_write()) {\n-    return false;\n-  }\n-  assert(_write_position == (code_offset + offset), \"%d  != (%d + %d)\", _write_position, code_offset, offset);\n-  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n-    const CodeSection* cs = buffer->code_section(i);\n-    uint cs_size = (uint)cs->size();\n-    if (cs_size == 0) {\n-      continue;  \/\/ skip trivial section\n-    }\n-    assert((_write_position - code_offset) == scc_cs[i]._offset, \"%d != %d\", _write_position, scc_cs[i]._offset);\n-    \/\/ Write code\n-    n = write_bytes(cs->start(), cs_size);\n-    if (n != cs_size) {\n-      return false;\n-    }\n-    if (!align_write()) {\n-      return false;\n-    }\n-  }\n-  assert((_write_position - code_offset) == (offset + total_size), \"(%d - %d) != (%d + %d)\", _write_position, code_offset, offset, total_size);\n-  code_size = total_size;\n-  return true;\n-}\n-\n-bool SCCache::store_exception_blob(CodeBuffer* buffer, int pc_offset) {\n-  SCCache* cache = open_for_write();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  log_info(scc, stubs)(\"Writing blob '%s' to AOT Code Cache\", buffer->name());\n-\n-#ifdef ASSERT\n-  LogStreamHandle(Debug, scc, nmethod) log;\n-  if (log.is_enabled()) {\n-    FlagSetting fs(PrintRelocations, true);\n-    buffer->print_on(&log);\n-    buffer->decode();\n-  }\n-#endif\n-  \/\/ we need to take a lock to prevent race between compiler thread generating blob and the main thread generating adapter\n-  MutexLocker ml(Compile_lock);\n-  if (!cache->align_write()) {\n-    return false;\n-  }\n-  uint entry_position = cache->_write_position;\n-\n-  \/\/ Write pc_offset\n-  uint n = cache->write_bytes(&pc_offset, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-\n-  \/\/ Write name\n-  const char* name = buffer->name();\n-  uint name_offset = cache->_write_position - entry_position;\n-  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n-  n = cache->write_bytes(name, name_size);\n-  if (n != name_size) {\n-    return false;\n-  }\n-\n-  \/\/ Write code section\n-  if (!cache->align_write()) {\n-    return false;\n-  }\n-  uint code_offset = cache->_write_position - entry_position;\n-  uint code_size = 0;\n-  if (!cache->write_code(buffer, code_size)) {\n-    return false;\n-  }\n-  \/\/ Write relocInfo array\n-  uint reloc_offset = cache->_write_position - entry_position;\n-  uint reloc_size = 0;\n-  if (!cache->write_relocations(buffer, reloc_size)) {\n-    return false;\n-  }\n-\n-  uint entry_size = cache->_write_position - entry_position;\n-  SCCEntry* entry = new(cache) SCCEntry(entry_position, entry_size, name_offset, name_size,\n-                                        code_offset, code_size, reloc_offset, reloc_size,\n-                                        SCCEntry::Blob, (uint32_t)999);\n-  log_info(scc, stubs)(\"Wrote stub '%s' to AOT Code Cache\", name);\n-  return true;\n-}\n-\n-DebugInformationRecorder* SCCReader::read_debug_info(OopRecorder* oop_recorder) {\n-  uint code_offset = align_up(read_position(), DATA_ALIGNMENT);\n-  int data_size  = *(int*)addr(code_offset);\n-  code_offset   += sizeof(int);\n-  int pcs_length = *(int*)addr(code_offset);\n-  code_offset   += sizeof(int);\n-\n-  log_debug(scc)(\"======== read DebugInfo [%d, %d]:\", data_size, pcs_length);\n-\n-  \/\/ Aligned initial sizes\n-  int data_size_align  = align_up(data_size, DATA_ALIGNMENT);\n-  int pcs_length_align = pcs_length + 1;\n-  assert(sizeof(PcDesc) > DATA_ALIGNMENT, \"sanity\");\n-  DebugInformationRecorder* recorder = new DebugInformationRecorder(oop_recorder, data_size_align, pcs_length);\n-\n-  copy_bytes(addr(code_offset), recorder->stream()->buffer(), data_size_align);\n-  recorder->stream()->set_position(data_size);\n-  code_offset += data_size;\n-\n-  uint pcs_size = pcs_length * sizeof(PcDesc);\n-  copy_bytes(addr(code_offset), (address)recorder->pcs(), pcs_size);\n-  code_offset += pcs_size;\n-  set_read_position(code_offset);\n-  return recorder;\n-}\n-\n-bool SCCache::write_debug_info(DebugInformationRecorder* recorder) {\n-  if (!align_write()) {\n-    return false;\n-  }\n-  \/\/ Don't call data_size() and pcs_size(). They will freeze OopRecorder.\n-  int data_size = recorder->stream()->position(); \/\/ In bytes\n-  uint n = write_bytes(&data_size, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  int pcs_length = recorder->pcs_length(); \/\/ In bytes\n-  n = write_bytes(&pcs_length, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  n = write_bytes(recorder->stream()->buffer(), data_size);\n-  if (n != (uint)data_size) {\n-    return false;\n-  }\n-  uint pcs_size = pcs_length * sizeof(PcDesc);\n-  n = write_bytes(recorder->pcs(), pcs_size);\n-  if (n != pcs_size) {\n-    return false;\n-  }\n-  return true;\n-}\n-\n-OopMapSet* SCCReader::read_oop_maps() {\n-  uint code_offset = read_position();\n-  int om_count = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-\n-  log_debug(scc)(\"======== read oop maps [%d]:\", om_count);\n-\n-  OopMapSet* oop_maps = new OopMapSet(om_count);\n-  for (int i = 0; i < (int)om_count; i++) {\n-    int data_size = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-\n-    OopMap* oop_map = new OopMap(data_size);\n-    \/\/ Preserve allocated stream\n-    CompressedWriteStream* stream = oop_map->write_stream();\n-\n-    \/\/ Read data which overwrites default data\n-    copy_bytes(addr(code_offset), (address)oop_map, sizeof(OopMap));\n-    code_offset += sizeof(OopMap);\n-    stream->set_position(data_size);\n-    oop_map->set_write_stream(stream);\n-    if (data_size > 0) {\n-      copy_bytes(addr(code_offset), (address)(oop_map->data()), (uint)data_size);\n-      code_offset += data_size;\n-    }\n-#ifdef ASSERT\n-    oop_map->_locs_length = 0;\n-    oop_map->_locs_used   = nullptr;\n-#endif\n-    oop_maps->add(oop_map);\n-  }\n-  set_read_position(code_offset);\n-  return oop_maps;\n-}\n-\n-bool SCCache::write_oop_maps(OopMapSet* oop_maps) {\n-  uint om_count = oop_maps->size();\n-  uint n = write_bytes(&om_count, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  for (int i = 0; i < (int)om_count; i++) {\n-    OopMap* om = oop_maps->at(i);\n-    int data_size = om->data_size();\n-    n = write_bytes(&data_size, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    n = write_bytes(om, sizeof(OopMap));\n-    if (n != sizeof(OopMap)) {\n-      return false;\n-    }\n-    n = write_bytes(om->data(), (uint)data_size);\n-    if (n != (uint)data_size) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-oop SCCReader::read_oop(JavaThread* thread, const methodHandle& comp_method) {\n-  uint code_offset = read_position();\n-  oop obj = nullptr;\n-  DataKind kind = *(DataKind*)addr(code_offset);\n-  code_offset += sizeof(DataKind);\n-  set_read_position(code_offset);\n-  if (kind == DataKind::Null) {\n-    return nullptr;\n-  } else if (kind == DataKind::No_Data) {\n-    return cast_to_oop(Universe::non_oop_word());\n-  } else if (kind == DataKind::Klass || kind == DataKind::Klass_Shared) {\n-    Klass* k = read_klass(comp_method, (kind == DataKind::Klass_Shared));\n-    if (k == nullptr) {\n-      return nullptr;\n-    }\n-    obj = k->java_mirror();\n-    if (obj == nullptr) {\n-      set_lookup_failed();\n-      log_info(scc)(\"Lookup failed for java_mirror of klass %s\", k->external_name());\n-      return nullptr;\n-    }\n-  } else if (kind == DataKind::Primitive) {\n-    code_offset = read_position();\n-    int t = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    set_read_position(code_offset);\n-    BasicType bt = (BasicType)t;\n-    obj = java_lang_Class::primitive_mirror(bt);\n-    log_info(scc)(\"%d (L%d): Read primitive type klass: %s\", compile_id(), comp_level(), type2name(bt));\n-  } else if (kind == DataKind::String_Shared) {\n-    code_offset = read_position();\n-    int k = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    set_read_position(code_offset);\n-    obj = CDSAccess::get_archived_object(k);\n-  } else if (kind == DataKind::String) {\n-    code_offset = read_position();\n-    int length = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    set_read_position(code_offset);\n-    const char* dest = addr(code_offset);\n-    set_read_position(code_offset + length);\n-    obj = StringTable::intern(&(dest[0]), thread);\n-    if (obj == nullptr) {\n-      set_lookup_failed();\n-      log_info(scc)(\"%d (L%d): Lookup failed for String %s\",\n-                       compile_id(), comp_level(), &(dest[0]));\n-      return nullptr;\n-    }\n-    assert(java_lang_String::is_instance(obj), \"must be string\");\n-    log_info(scc)(\"%d (L%d): Read String: %s\", compile_id(), comp_level(), dest);\n-  } else if (kind == DataKind::SysLoader) {\n-    obj = SystemDictionary::java_system_loader();\n-    log_info(scc)(\"%d (L%d): Read java_system_loader\", compile_id(), comp_level());\n-  } else if (kind == DataKind::PlaLoader) {\n-    obj = SystemDictionary::java_platform_loader();\n-    log_info(scc)(\"%d (L%d): Read java_platform_loader\", compile_id(), comp_level());\n-  } else if (kind == DataKind::MH_Oop_Shared) {\n-    code_offset = read_position();\n-    int k = *(int*)addr(code_offset);\n-    code_offset += sizeof(int);\n-    set_read_position(code_offset);\n-    obj = CDSAccess::get_archived_object(k);\n-  } else {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Unknown oop's kind: %d\",\n-                     compile_id(), comp_level(), (int)kind);\n-    return nullptr;\n-  }\n-  return obj;\n-}\n-\n-bool SCCReader::read_oops(OopRecorder* oop_recorder, ciMethod* target) {\n-  uint code_offset = read_position();\n-  int oop_count = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-  set_read_position(code_offset);\n-  log_debug(scc)(\"======== read oops [%d]:\", oop_count);\n-  if (oop_count == 0) {\n-    return true;\n-  }\n-  {\n-    VM_ENTRY_MARK;\n-    methodHandle comp_method(THREAD, target->get_Method());\n-    for (int i = 1; i < oop_count; i++) {\n-      oop obj = read_oop(THREAD, comp_method);\n-      if (lookup_failed()) {\n-        return false;\n-      }\n-      jobject jo = JNIHandles::make_local(THREAD, obj);\n-      if (oop_recorder->is_real(jo)) {\n-        oop_recorder->find_index(jo);\n-      } else {\n-        oop_recorder->allocate_oop_index(jo);\n-      }\n-      LogStreamHandle(Debug, scc, oops) log;\n-      if (log.is_enabled()) {\n-        log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(jo));\n-        if (jo == (jobject)Universe::non_oop_word()) {\n-          log.print(\"non-oop word\");\n-        } else if (jo == nullptr) {\n-          log.print(\"nullptr-oop\");\n-        } else {\n-          JNIHandles::resolve(jo)->print_value_on(&log);\n-        }\n-        log.cr();\n-      }\n-    }\n-  }\n-  return true;\n-}\n-\n-Metadata* SCCReader::read_metadata(const methodHandle& comp_method) {\n-  uint code_offset = read_position();\n-  Metadata* m = nullptr;\n-  DataKind kind = *(DataKind*)addr(code_offset);\n-  code_offset += sizeof(DataKind);\n-  set_read_position(code_offset);\n-  if (kind == DataKind::Null) {\n-    m = (Metadata*)nullptr;\n-  } else if (kind == DataKind::No_Data) {\n-    m = (Metadata*)Universe::non_oop_word();\n-  } else if (kind == DataKind::Klass || kind == DataKind::Klass_Shared) {\n-    m = (Metadata*)read_klass(comp_method, (kind == DataKind::Klass_Shared));\n-  } else if (kind == DataKind::Method || kind == DataKind::Method_Shared) {\n-    m = (Metadata*)read_method(comp_method, (kind == DataKind::Method_Shared));\n-  } else if (kind == DataKind::MethodCnts) {\n-    kind = *(DataKind*)addr(code_offset);\n-    bool shared = (kind == DataKind::Method_Shared);\n-    assert(kind == DataKind::Method || shared, \"Sanity\");\n-    code_offset += sizeof(DataKind);\n-    set_read_position(code_offset);\n-    m = (Metadata*)read_method(comp_method, shared);\n-    if (m != nullptr) {\n-      Method* method = (Method*)m;\n-      m = method->get_method_counters(Thread::current());\n-      if (m == nullptr) {\n-        set_lookup_failed();\n-        log_info(scc)(\"%d (L%d): Failed to get MethodCounters\", compile_id(), comp_level());\n-      } else {\n-        log_info(scc)(\"%d (L%d): Read MethodCounters : \" INTPTR_FORMAT, compile_id(), comp_level(), p2i(m));\n-      }\n-    }\n-  } else {\n-    set_lookup_failed();\n-    log_info(scc)(\"%d (L%d): Unknown metadata's kind: %d\", compile_id(), comp_level(), (int)kind);\n-  }\n-  return m;\n-}\n-\n-bool SCCReader::read_metadata(OopRecorder* oop_recorder, ciMethod* target) {\n-  uint code_offset = read_position();\n-  int metadata_count = *(int*)addr(code_offset);\n-  code_offset += sizeof(int);\n-  set_read_position(code_offset);\n-\n-  log_debug(scc)(\"======== read metadata [%d]:\", metadata_count);\n-\n-  if (metadata_count == 0) {\n-    return true;\n-  }\n-  {\n-    VM_ENTRY_MARK;\n-    methodHandle comp_method(THREAD, target->get_Method());\n-\n-    for (int i = 1; i < metadata_count; i++) {\n-      Metadata* m = read_metadata(comp_method);\n-      if (lookup_failed()) {\n-        return false;\n-      }\n-      if (oop_recorder->is_real(m)) {\n-        oop_recorder->find_index(m);\n-      } else {\n-        oop_recorder->allocate_metadata_index(m);\n-      }\n-      LogTarget(Debug, scc, metadata) log;\n-      if (log.is_enabled()) {\n-        LogStream ls(log);\n-        ls.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n-        if (m == (Metadata*)Universe::non_oop_word()) {\n-          ls.print(\"non-metadata word\");\n-        } else if (m == nullptr) {\n-          ls.print(\"nullptr-oop\");\n-        } else {\n-          Metadata::print_value_on_maybe_null(&ls, m);\n-        }\n-        ls.cr();\n-      }\n-    }\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_oop(jobject& jo) {\n-  oop obj = JNIHandles::resolve(jo);\n-  return write_oop(obj);\n-}\n-\n-bool SCCache::write_oop(oop obj) {\n-  DataKind kind;\n-  uint n = 0;\n-  if (obj == nullptr) {\n-    kind = DataKind::Null;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-  } else if (cast_from_oop<void *>(obj) == Universe::non_oop_word()) {\n-    kind = DataKind::No_Data;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-  } else if (java_lang_Class::is_instance(obj)) {\n-    if (java_lang_Class::is_primitive(obj)) {\n-      int bt = (int)java_lang_Class::primitive_type(obj);\n-      kind = DataKind::Primitive;\n-      n = write_bytes(&kind, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      n = write_bytes(&bt, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      log_info(scc)(\"%d (L%d): Write primitive type klass: %s\", compile_id(), comp_level(), type2name((BasicType)bt));\n-    } else {\n-      Klass* klass = java_lang_Class::as_Klass(obj);\n-      if (!write_klass(klass)) {\n-        return false;\n-      }\n-    }\n-  } else if (java_lang_String::is_instance(obj)) { \/\/ herere\n-    int k = CDSAccess::get_archived_object_permanent_index(obj);  \/\/ k >= 0 means obj is a \"permanent heap object\"\n-    if (k >= 0) {\n-      kind = DataKind::String_Shared;\n-      n = write_bytes(&kind, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      n = write_bytes(&k, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      return true;\n-    }\n-    kind = DataKind::String;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    ResourceMark rm;\n-    size_t length_sz = 0;\n-    const char* string = java_lang_String::as_utf8_string(obj, length_sz);\n-    int length = (int)length_sz; \/\/ FIXME -- cast\n-    length++; \/\/ write tailing '\/0'\n-    n = write_bytes(&length, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    n = write_bytes(string, (uint)length);\n-    if (n != (uint)length) {\n-      return false;\n-    }\n-    log_info(scc)(\"%d (L%d): Write String: %s\", compile_id(), comp_level(), string);\n-  } else if (java_lang_Module::is_instance(obj)) {\n-    fatal(\"Module object unimplemented\");\n-  } else if (java_lang_ClassLoader::is_instance(obj)) {\n-    if (obj == SystemDictionary::java_system_loader()) {\n-      kind = DataKind::SysLoader;\n-      log_info(scc)(\"%d (L%d): Write ClassLoader: java_system_loader\", compile_id(), comp_level());\n-    } else if (obj == SystemDictionary::java_platform_loader()) {\n-      kind = DataKind::PlaLoader;\n-      log_info(scc)(\"%d (L%d): Write ClassLoader: java_platform_loader\", compile_id(), comp_level());\n-    } else {\n-      fatal(\"ClassLoader object unimplemented\");\n-      return false;\n-    }\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-  } else { \/\/ herere\n-    int k = CDSAccess::get_archived_object_permanent_index(obj);  \/\/ k >= 0 means obj is a \"permanent heap object\"\n-    if (k >= 0) {\n-      kind = DataKind::MH_Oop_Shared;\n-      n = write_bytes(&kind, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      n = write_bytes(&k, sizeof(int));\n-      if (n != sizeof(int)) {\n-        return false;\n-      }\n-      return true;\n-    }\n-    \/\/ Unhandled oop - bailout\n-    set_lookup_failed();\n-    log_info(scc, nmethod)(\"%d (L%d): Unhandled obj: \" PTR_FORMAT \" : %s\",\n-                              compile_id(), comp_level(), p2i(obj), obj->klass()->external_name());\n-    return false;\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_oops(OopRecorder* oop_recorder) {\n-  int oop_count = oop_recorder->oop_count();\n-  uint n = write_bytes(&oop_count, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-  log_debug(scc)(\"======== write oops [%d]:\", oop_count);\n-\n-  for (int i = 1; i < oop_count; i++) { \/\/ skip first virtual nullptr\n-    jobject jo = oop_recorder->oop_at(i);\n-    LogStreamHandle(Info, scc, oops) log;\n-    if (log.is_enabled()) {\n-      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(jo));\n-      if (jo == (jobject)Universe::non_oop_word()) {\n-        log.print(\"non-oop word\");\n-      } else if (jo == nullptr) {\n-        log.print(\"nullptr-oop\");\n-      } else {\n-        JNIHandles::resolve(jo)->print_value_on(&log);\n-      }\n-      log.cr();\n-    }\n-    if (!write_oop(jo)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_metadata(Metadata* m) {\n-  uint n = 0;\n-  if (m == nullptr) {\n-    DataKind kind = DataKind::Null;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-  } else if (m == (Metadata*)Universe::non_oop_word()) {\n-    DataKind kind = DataKind::No_Data;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-  } else if (m->is_klass()) {\n-    if (!write_klass((Klass*)m)) {\n-      return false;\n-    }\n-  } else if (m->is_method()) {\n-    if (!write_method((Method*)m)) {\n-      return false;\n-    }\n-  } else if (m->is_methodCounters()) {\n-    DataKind kind = DataKind::MethodCnts;\n-    n = write_bytes(&kind, sizeof(int));\n-    if (n != sizeof(int)) {\n-      return false;\n-    }\n-    if (!write_method(((MethodCounters*)m)->method())) {\n-      return false;\n-    }\n-    log_info(scc)(\"%d (L%d): Write MethodCounters : \" INTPTR_FORMAT, compile_id(), comp_level(), p2i(m));\n-  } else { \/\/ Not supported\n-    fatal(\"metadata : \" INTPTR_FORMAT \" unimplemented\", p2i(m));\n-    return false;\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_metadata(OopRecorder* oop_recorder) {\n-  int metadata_count = oop_recorder->metadata_count();\n-  uint n = write_bytes(&metadata_count, sizeof(int));\n-  if (n != sizeof(int)) {\n-    return false;\n-  }\n-\n-  log_debug(scc)(\"======== write metadata [%d]:\", metadata_count);\n-\n-  for (int i = 1; i < metadata_count; i++) { \/\/ skip first virtual nullptr\n-    Metadata* m = oop_recorder->metadata_at(i);\n-    LogStreamHandle(Debug, scc, metadata) log;\n-    if (log.is_enabled()) {\n-      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n-      if (m == (Metadata*)Universe::non_oop_word()) {\n-        log.print(\"non-metadata word\");\n-      } else if (m == nullptr) {\n-        log.print(\"nullptr-oop\");\n-      } else {\n-        Metadata::print_value_on_maybe_null(&log, m);\n-      }\n-      log.cr();\n-    }\n-    if (!write_metadata(m)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-bool SCCReader::read_dependencies(Dependencies* dependencies) {\n-  uint code_offset = read_position();\n-  int dependencies_size = *(int*)addr(code_offset);\n-\n-  log_debug(scc)(\"======== read dependencies [%d]:\", dependencies_size);\n-\n-  code_offset += sizeof(int);\n-  code_offset = align_up(code_offset, DATA_ALIGNMENT);\n-  if (dependencies_size > 0) {\n-    dependencies->set_content((u_char*)addr(code_offset), dependencies_size);\n-  }\n-  code_offset += dependencies_size;\n-  set_read_position(code_offset);\n-  return true;\n-}\n-\n-bool SCCache::load_nmethod(ciEnv* env, ciMethod* target, int entry_bci, AbstractCompiler* compiler, CompLevel comp_level) {\n-  assert(entry_bci == InvocationEntryBci, \"unexpected entry_bci=%d\", entry_bci);\n-  TraceTime t1(\"SC total load time\", &_t_totalLoad, enable_timers(), false);\n-  CompileTask* task = env->task();\n-  task->mark_aot_load_start(os::elapsed_counter());\n-  SCCEntry* entry = task->scc_entry();\n-  bool preload = task->preload();\n-  assert(entry != nullptr, \"sanity\");\n-  SCCache* cache = open_for_read();\n-  if (cache == nullptr) {\n-    return false;\n-  }\n-  if (log_is_enabled(Info, scc, nmethod)) {\n-    uint decomp = (target->method_data() == nullptr) ? 0 : target->method_data()->decompile_count();\n-    VM_ENTRY_MARK;\n-    ResourceMark rm;\n-    methodHandle method(THREAD, target->get_Method());\n-    const char* target_name = method->name_and_sig_as_C_string();\n-    uint hash = java_lang_String::hash_code((const jbyte*)target_name, (int)strlen(target_name));\n-    bool clinit_brs = entry->has_clinit_barriers();\n-    log_info(scc, nmethod)(\"%d (L%d): %s nmethod '%s' (decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s%s)\",\n-                           task->compile_id(), task->comp_level(), (preload ? \"Preloading\" : \"Reading\"),\n-                           target_name, decomp, hash, (clinit_brs ? \", has clinit barriers\" : \"\"),\n-                           (entry->ignore_decompile() ? \", ignore_decomp\" : \"\"));\n-  }\n-  ReadingMark rdmk;\n-  if (rdmk.failed()) {\n-    \/\/ Cache is closed, cannot touch anything.\n-    return false;\n-  }\n-\n-  SCCReader reader(cache, entry, task);\n-  bool success = reader.compile_nmethod(env, target, compiler);\n-  if (success) {\n-    task->set_num_inlined_bytecodes(entry->num_inlined_bytecodes());\n-  } else {\n-    entry->set_load_fail();\n-  }\n-  task->mark_aot_load_finish(os::elapsed_counter());\n-  return success;\n-}\n-\n-SCCReader::SCCReader(SCCache* cache, SCCEntry* entry, CompileTask* task) {\n-  _cache = cache;\n-  _entry   = entry;\n-  _load_buffer = cache->cache_buffer();\n-  _read_position = 0;\n-  if (task != nullptr) {\n-    _compile_id = task->compile_id();\n-    _comp_level = task->comp_level();\n-    _preload    = task->preload();\n-  } else {\n-    _compile_id = 0;\n-    _comp_level = 0;\n-    _preload    = false;\n-  }\n-  _lookup_failed = false;\n-}\n-\n-bool SCCReader::read_oop_metadata_list(JavaThread* thread, ciMethod* target, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list, OopRecorder* oop_recorder) {\n-  methodHandle comp_method(JavaThread::current(), target->get_Method());\n-  JavaThread* current = JavaThread::current();\n-  uint offset = read_position();\n-  int count = *(int *)addr(offset);\n-  offset += sizeof(int);\n-  set_read_position(offset);\n-  for (int i = 0; i < count; i++) {\n-    oop obj = read_oop(current, comp_method);\n-    if (lookup_failed()) {\n-      return false;\n-    }\n-    Handle h(thread, obj);\n-    oop_list.append(h);\n-    if (oop_recorder != nullptr) {\n-      jobject jo = JNIHandles::make_local(thread, obj);\n-      if (oop_recorder->is_real(jo)) {\n-        oop_recorder->find_index(jo);\n-      } else {\n-        oop_recorder->allocate_oop_index(jo);\n-      }\n-    }\n-    LogStreamHandle(Debug, scc, oops) log;\n-    if (log.is_enabled()) {\n-      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(obj));\n-      if (obj == Universe::non_oop_word()) {\n-        log.print(\"non-oop word\");\n-      } else if (obj == nullptr) {\n-        log.print(\"nullptr-oop\");\n-      } else {\n-        obj->print_value_on(&log);\n-      }\n-      log.cr();\n-    }\n-  }\n-\n-  offset = read_position();\n-  count = *(int *)addr(offset);\n-  offset += sizeof(int);\n-  set_read_position(offset);\n-  for (int i = 0; i < count; i++) {\n-    Metadata* m = read_metadata(comp_method);\n-    if (lookup_failed()) {\n-      return false;\n-    }\n-    metadata_list.append(m);\n-    if (oop_recorder != nullptr) {\n-      if (oop_recorder->is_real(m)) {\n-        oop_recorder->find_index(m);\n-      } else {\n-        oop_recorder->allocate_metadata_index(m);\n-      }\n-    }\n-    LogTarget(Debug, scc, metadata) log;\n-    if (log.is_enabled()) {\n-      LogStream ls(log);\n-      ls.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n-      if (m == (Metadata*)Universe::non_oop_word()) {\n-        ls.print(\"non-metadata word\");\n-      } else if (m == nullptr) {\n-        ls.print(\"nullptr-oop\");\n-      } else {\n-        Metadata::print_value_on_maybe_null(&ls, m);\n-      }\n-      ls.cr();\n-    }\n-  }\n-  return true;\n-}\n-\n-ImmutableOopMapSet* SCCReader::read_oop_map_set() {\n-  uint offset = read_position();\n-  int size = *(int *)addr(offset);\n-  offset += sizeof(int);\n-  ImmutableOopMapSet* oopmaps = (ImmutableOopMapSet *)addr(offset);\n-  offset += size;\n-  set_read_position(offset);\n-  return oopmaps;\n-}\n-\n-bool SCCReader::compile_nmethod(ciEnv* env, ciMethod* target, AbstractCompiler* compiler) {\n-  CompileTask* task = env->task();\n-  SCCEntry *scc_entry = (SCCEntry*)_entry;\n-  nmethod* nm = nullptr;\n-\n-  uint entry_position = scc_entry->offset();\n-  uint archived_nm_offset = entry_position + scc_entry->code_offset();\n-  nmethod* archived_nm = (nmethod*)addr(archived_nm_offset);\n-  set_read_position(archived_nm_offset + archived_nm->size());\n-\n-  OopRecorder* oop_recorder = new OopRecorder(env->arena());\n-  env->set_oop_recorder(oop_recorder);\n-\n-  uint offset;\n-\n-#ifndef PRODUCT\n-  \/\/ Read asm remarks\n-  offset = read_position();\n-  uint count = *(uint *)addr(offset);\n-  offset += sizeof(uint);\n-  AsmRemarks asm_remarks;\n-  for (uint i = 0; i < count; i++) {\n-    uint remark_offset = *(uint *)addr(offset);\n-    offset += sizeof(uint);\n-    const char* remark = (const char*)addr(offset);\n-    offset += (uint)strlen(remark)+1;\n-    asm_remarks.insert(remark_offset, remark);\n-  }\n-  set_read_position(offset);\n-\n-  \/\/ Read dbg strings\n-  count = *(uint *)addr(offset);\n-  offset += sizeof(uint);\n-  DbgStrings dbg_strings;\n-  for (uint i = 0; i < count; i++) {\n-    const char* str = (const char*)addr(offset);\n-    offset += (uint)strlen(str)+1;\n-    dbg_strings.insert(str);\n-  }\n-  set_read_position(offset);\n-#endif \/* PRODUCT *\/\n-\n-  offset = read_position();\n-  address reloc_data = (address)addr(offset);\n-  offset += archived_nm->relocation_size();\n-  set_read_position(offset);\n-\n-  \/\/ Read oops and metadata\n-  VM_ENTRY_MARK\n-  GrowableArray<Handle> oop_list;\n-  GrowableArray<Metadata*> metadata_list;\n-\n-  if (!read_oop_metadata_list(THREAD, target, oop_list, metadata_list, oop_recorder)) {\n-   return false;\n-  }\n-\n-  ImmutableOopMapSet* oopmaps = read_oop_map_set();\n-\n-  offset = read_position();\n-  address immutable_data = (address)addr(offset);\n-  offset += archived_nm->immutable_data_size();\n-  set_read_position(offset);\n-\n-  GrowableArray<Handle> reloc_immediate_oop_list;\n-  GrowableArray<Metadata*> reloc_immediate_metadata_list;\n-  if (!read_oop_metadata_list(THREAD, target, reloc_immediate_oop_list, reloc_immediate_metadata_list, nullptr)) {\n-   return false;\n-  }\n-\n-  \/\/ Read Dependencies (compressed already)\n-  Dependencies* dependencies = new Dependencies(env);\n-  dependencies->set_content(immutable_data, archived_nm->dependencies_size());\n-  env->set_dependencies(dependencies);\n-\n-  if (VerifyCachedCode) {\n-    return false;\n-  }\n-\n-  TraceTime t1(\"SC total nmethod register time\", &_t_totalRegister, enable_timers(), false);\n-  env->register_aot_method(THREAD,\n-                           target,\n-                           compiler,\n-                           archived_nm,\n-                           reloc_data,\n-                           oop_list,\n-                           metadata_list,\n-                           oopmaps,\n-                           immutable_data,\n-                           reloc_immediate_oop_list,\n-                           reloc_immediate_metadata_list,\n-                           NOT_PRODUCT_ARG(asm_remarks)\n-                           NOT_PRODUCT_ARG(dbg_strings)\n-                           this);\n-  bool success = task->is_success();\n-  if (success) {\n-    scc_entry->set_loaded();\n-  }\n-  return success;\n-}\n-\n-void SCCReader::apply_relocations(nmethod* nm, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list) {\n-  LogStreamHandle(Info, scc, reloc) log;\n-  uint buffer_offset = read_position();\n-  int count = *(int*)addr(buffer_offset);\n-  buffer_offset += sizeof(int);\n-  if (log.is_enabled()) {\n-    log.print_cr(\"======== extra relocations count=%d\", count);\n-  }\n-  uint* reloc_data = (uint*)addr(buffer_offset);\n-  buffer_offset += (count * sizeof(uint));\n-  set_read_position(buffer_offset);\n-\n-  RelocIterator iter(nm);\n-  int j = 0;\n-\n-  while (iter.next()) {\n-    switch (iter.type()) {\n-      case relocInfo::none:\n-        break;\n-      case relocInfo::oop_type: {\n-        oop_Relocation* r = (oop_Relocation*)iter.reloc();\n-        if (r->oop_is_immediate()) {\n-          Handle h = oop_list.at(reloc_data[j]);\n-          r->set_value(cast_from_oop<address>(h()));\n-        } else {\n-          r->fix_oop_relocation();\n-        }\n-        break;\n-      }\n-      case relocInfo::metadata_type: {\n-        metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n-        Metadata* m;\n-        if (r->metadata_is_immediate()) {\n-          m = metadata_list.at(reloc_data[j]);\n-        } else {\n-          \/\/ Get already updated value from nmethod.\n-          int index = r->metadata_index();\n-          m = nm->metadata_at(index);\n-        }\n-        r->set_value((address)m);\n-        break;\n-      }\n-      case relocInfo::virtual_call_type:   \/\/ Fall through. They all call resolve_*_call blobs.\n-      case relocInfo::opt_virtual_call_type:\n-      case relocInfo::static_call_type: {\n-        address dest = _cache->address_for_id(reloc_data[j]);\n-        if (dest != (address)-1) {\n-          ((CallRelocation*)iter.reloc())->set_destination(dest);\n-        }\n-        break;\n-      }\n-      case relocInfo::trampoline_stub_type: {\n-        address dest = _cache->address_for_id(reloc_data[j]);\n-        if (dest != (address)-1) {\n-          ((trampoline_stub_Relocation*)iter.reloc())->set_destination(dest);\n-        }\n-        break;\n-      }\n-      case relocInfo::static_stub_type:\n-        break;\n-      case relocInfo::runtime_call_type: {\n-        address dest = _cache->address_for_id(reloc_data[j]);\n-        if (dest != (address)-1) {\n-          ((CallRelocation*)iter.reloc())->set_destination(dest);\n-        }\n-        break;\n-      }\n-      case relocInfo::runtime_call_w_cp_type:\n-        fatal(\"runtime_call_w_cp_type unimplemented\");\n-        \/\/address destination = iter.reloc()->value();\n-        break;\n-      case relocInfo::external_word_type: {\n-        address target = _cache->address_for_id(reloc_data[j]);\n-        \/\/ Add external address to global table\n-        int index = ExternalsRecorder::find_index(target);\n-        \/\/ Update index in relocation\n-        Relocation::add_jint(iter.data(), index);\n-        external_word_Relocation* reloc = (external_word_Relocation*)iter.reloc();\n-        assert(reloc->target() == target, \"sanity\");\n-        reloc->set_value(target); \/\/ Patch address in the code\n-        break;\n-      }\n-      case relocInfo::internal_word_type: {\n-        internal_word_Relocation* r = (internal_word_Relocation*)iter.reloc();\n-        r->fix_relocation_after_aot_load(scc_entry()->dumptime_content_start_addr(), nm->content_begin());\n-        break;\n-      }\n-      case relocInfo::section_word_type: {\n-        section_word_Relocation* r = (section_word_Relocation*)iter.reloc();\n-        r->fix_relocation_after_aot_load(scc_entry()->dumptime_content_start_addr(), nm->content_begin());\n-        break;\n-      }\n-      case relocInfo::poll_type:\n-        break;\n-      case relocInfo::poll_return_type:\n-        break;\n-      case relocInfo::post_call_nop_type:\n-        break;\n-      case relocInfo::entry_guard_type:\n-        break;\n-      default:\n-        fatal(\"relocation %d unimplemented\", (int)iter.type());\n-        break;\n-    }\n-    if (log.is_enabled()) {\n-      iter.print_current_on(&log);\n-    }\n-    j++;\n-  }\n-  assert(j == count, \"must be\");\n-}\n-\n-SCCEntry* SCCache::store_nmethod(nmethod* nm, AbstractCompiler* compiler, bool for_preload) {\n-  if (!CDSConfig::is_dumping_cached_code()) {\n-    return nullptr; \/\/ The metadata and heap in the CDS image haven't been finalized yet.\n-  }\n-  if (nm->is_osr_method()) {\n-    return nullptr; \/\/ No OSR\n-  }\n-  if (!compiler->is_c1() && !compiler->is_c2()) {\n-    \/\/ Only c1 and c2 compilers\n-    return nullptr;\n-  }\n-  int comp_level = nm->comp_level();\n-  if (comp_level == CompLevel_full_profile) {\n-    \/\/ Do not cache C1 compiles with full profile i.e. tier3\n-    return nullptr;\n-  }\n-  assert(comp_level == CompLevel_simple || comp_level == CompLevel_limited_profile || comp_level == CompLevel_full_optimization, \"must be\");\n-\n-  TraceTime t1(\"SC total store time\", &_t_totalStore, enable_timers(), false);\n-  SCCache* cache = open_for_write();\n-  if (cache == nullptr) {\n-    return nullptr; \/\/ Cache file is closed\n-  }\n-  SCCEntry* entry = nullptr;\n-  entry = cache->write_nmethod(nm, for_preload);\n-  if (entry == nullptr) {\n-    log_info(scc, nmethod)(\"%d (L%d): nmethod store attempt failed\", nm->compile_id(), comp_level);\n-  }\n-  return entry;\n-}\n-\n-bool SCCache::write_oops(nmethod* nm) {\n-  int count = nm->oops_count()-1;\n-  if (!write_bytes(&count, sizeof(int))) {\n-    return false;\n-  }\n-  for (oop* p = nm->oops_begin(); p < nm->oops_end(); p++) {\n-    if (!write_oop(*p)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_metadata(nmethod* nm) {\n-  int count = nm->metadata_count()-1;\n-  if (!write_bytes(&count, sizeof(int))) {\n-    return false;\n-  }\n-  for (Metadata** p = nm->metadata_begin(); p < nm->metadata_end(); p++) {\n-    if (!write_metadata(*p)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-bool SCCache::write_oop_map_set(nmethod* nm) {\n-  ImmutableOopMapSet* oopmaps = nm->oop_maps();\n-  int oopmaps_size = oopmaps->nr_of_bytes();\n-  if (!write_bytes(&oopmaps_size, sizeof(int))) {\n-    return false;\n-  }\n-  uint n = write_bytes(oopmaps, oopmaps->nr_of_bytes());\n-  if (n != (uint)oopmaps->nr_of_bytes()) {\n-    return false;\n-  }\n-  return true;\n-}\n-\n-SCCEntry* SCCache::write_nmethod(nmethod* nm, bool for_preload) {\n-  assert(!nm->has_clinit_barriers() || _gen_preload_code, \"sanity\");\n-  uint comp_id = nm->compile_id();\n-  uint comp_level = nm->comp_level();\n-  Method* method = nm->method();\n-  bool method_in_cds = MetaspaceShared::is_in_shared_metaspace((address)method);\n-  InstanceKlass* holder = method->method_holder();\n-  bool klass_in_cds = holder->is_shared() && !holder->is_shared_unregistered_class();\n-  bool builtin_loader = holder->class_loader_data()->is_builtin_class_loader_data();\n-  if (!builtin_loader) {\n-    ResourceMark rm;\n-    log_info(scc, nmethod)(\"%d (L%d): Skip method '%s' loaded by custom class loader %s\", comp_id, (int)comp_level, method->name_and_sig_as_C_string(), holder->class_loader_data()->loader_name());\n-    return nullptr;\n-  }\n-  if (for_preload && !(method_in_cds && klass_in_cds)) {\n-    ResourceMark rm;\n-    log_info(scc, nmethod)(\"%d (L%d): Skip method '%s' for preload: not in CDS\", comp_id, (int)comp_level, method->name_and_sig_as_C_string());\n-    return nullptr;\n-  }\n-  assert(!for_preload || method_in_cds, \"sanity\");\n-  _for_preload = for_preload;\n-  _has_clinit_barriers = nm->has_clinit_barriers();\n-\n-  if (!align_write()) {\n-    return nullptr;\n-  }\n-\n-  uint entry_position = _write_position;\n-\n-  uint decomp = (method->method_data() == nullptr) ? 0 : method->method_data()->decompile_count();\n-\n-  \/\/ Is this one-step workflow assembly phase?\n-  \/\/ In this phase compilation is done based on saved profiling data\n-  \/\/ without application run. Ignore decompilation counters in such case.\n-  \/\/ Also ignore it for C1 code because it is decompiled unconditionally\n-  \/\/ when C2 generated code is published.\n-  bool ignore_decompile = (comp_level == CompLevel_limited_profile) ||\n-                          CDSConfig::is_dumping_final_static_archive();\n-\n-  \/\/ Write name\n-  uint name_offset = 0;\n-  uint name_size   = 0;\n-  uint hash = 0;\n-  uint n;\n-  {\n-    ResourceMark rm;\n-    const char* name = method->name_and_sig_as_C_string();\n-    log_info(scc, nmethod)(\"%d (L%d): Writing nmethod '%s' (comp level: %d, decomp: %d%s%s) to AOT Code Cache\",\n-                           comp_id, (int)comp_level, name, comp_level, decomp,\n-                           (ignore_decompile ? \", ignore_decomp\" : \"\"),\n-                           (nm->has_clinit_barriers() ? \", has clinit barriers\" : \"\"));\n-\n-    LogStreamHandle(Info, scc, loader) log;\n-    if (log.is_enabled()) {\n-      oop loader = holder->class_loader();\n-      oop domain = holder->protection_domain();\n-      log.print(\"Holder: \");\n-      holder->print_value_on(&log);\n-      log.print(\" loader: \");\n-      if (loader == nullptr) {\n-        log.print(\"nullptr\");\n-      } else {\n-        loader->print_value_on(&log);\n-      }\n-      log.print(\" domain: \");\n-      if (domain == nullptr) {\n-        log.print(\"nullptr\");\n-      } else {\n-        domain->print_value_on(&log);\n-      }\n-      log.cr();\n-    }\n-    name_offset = _write_position  - entry_position;\n-    name_size   = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n-    n = write_bytes(name, name_size);\n-    if (n != name_size) {\n-      return nullptr;\n-    }\n-    hash = java_lang_String::hash_code((const jbyte*)name, (int)strlen(name));\n-  }\n-\n-  uint archived_nm_offset = _write_position - entry_position;\n-  nmethod* archived_nm = (nmethod*)reserve_bytes(nm->size());\n-  if (archived_nm == nullptr) {\n-    return nullptr;\n-  }\n-  nm->copy_to((address)archived_nm);\n-\n-  archived_nm->prepare_for_archiving();\n-\n-#ifndef PRODUCT\n-  \/\/ Write asm remarks\n-  uint* count_ptr = (uint *)reserve_bytes(sizeof(uint));\n-  if (count_ptr == nullptr) {\n-    return nullptr;\n-  }\n-  uint count = 0;\n-  bool result = nm->asm_remarks().iterate([&] (uint offset, const char* str) -> bool {\n-    log_info(scc, nmethod)(\"asm remark offset=%d, str=%s\", offset, str);\n-    n = write_bytes(&offset, sizeof(uint));\n-    if (n != sizeof(uint)) {\n-      return false;\n-    }\n-    n = write_bytes(str, (uint)strlen(str) + 1);\n-    if (n != strlen(str) + 1) {\n-      return false;\n-    }\n-    count += 1;\n-    return true;\n-  });\n-  if (!result) {\n-    return nullptr;\n-  }\n-  *count_ptr = count;\n-\n-  \/\/ Write dbg strings\n-  count_ptr = (uint *)reserve_bytes(sizeof(uint));\n-  if (count_ptr == nullptr) {\n-    return nullptr;\n-  }\n-  count = 0;\n-  result = nm->dbg_strings().iterate([&] (const char* str) -> bool {\n-    log_info(scc, nmethod)(\"dbg string=%s\", str);\n-    n = write_bytes(str, (uint)strlen(str) + 1);\n-    if (n != strlen(str) + 1) {\n-      return false;\n-    }\n-    count += 1;\n-    return true;\n-  });\n-  if (!result) {\n-    return nullptr;\n-  }\n-  *count_ptr = count;\n-#endif \/* PRODUCT *\/\n-\n-  uint reloc_data_size = nm->relocation_size();\n-  n = write_bytes((address)nm->relocation_begin(), reloc_data_size);\n-  if (n != reloc_data_size) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Write oops and metadata present in the nmethod's data region\n-  if (!write_oops(nm)) {\n-    if (lookup_failed() && !failed()) {\n-      \/\/ Skip this method and reposition file\n-      set_write_position(entry_position);\n-    }\n-    return nullptr;\n-  }\n-  if (!write_metadata(nm)) {\n-    if (lookup_failed() && !failed()) {\n-      \/\/ Skip this method and reposition file\n-      set_write_position(entry_position);\n-    }\n-    return nullptr;\n-  }\n-\n-  if (!write_oop_map_set(nm)) {\n-    return nullptr;\n-  }\n-\n-  uint immutable_data_size = nm->immutable_data_size();\n-  n = write_bytes(nm->immutable_data_begin(), immutable_data_size);\n-  if (n != immutable_data_size) {\n-    return nullptr;\n-  }\n-\n-  JavaThread* thread = JavaThread::current();\n-  HandleMark hm(thread);\n-  GrowableArray<Handle> oop_list;\n-  GrowableArray<Metadata*> metadata_list;\n-\n-  nm->create_reloc_immediates_list(thread, oop_list, metadata_list);\n-  if (!write_nmethod_reloc_immediates(oop_list, metadata_list)) {\n-    if (lookup_failed() && !failed()) {\n-      \/\/ Skip this method and reposition file\n-      set_write_position(entry_position);\n-    }\n-    return nullptr;\n-  }\n-\n-  if (!write_nmethod_loadtime_relocations(thread, nm, oop_list, metadata_list)) {\n-    return nullptr;\n-  }\n-\n-  uint entry_size = _write_position - entry_position;\n-  SCCEntry* entry = new (this) SCCEntry(entry_position, entry_size, name_offset, name_size,\n-                                        archived_nm_offset, 0, 0, 0,\n-                                        SCCEntry::Code, hash, nm->content_begin(), comp_level, comp_id, decomp,\n-                                        nm->has_clinit_barriers(), for_preload, ignore_decompile);\n-  if (method_in_cds) {\n-    entry->set_method(method);\n-  }\n-#ifdef ASSERT\n-  if (nm->has_clinit_barriers() || for_preload) {\n-    assert(for_preload, \"sanity\");\n-    assert(entry->method() != nullptr, \"sanity\");\n-  }\n-#endif\n-  {\n-    ResourceMark rm;\n-    const char* name = nm->method()->name_and_sig_as_C_string();\n-    log_info(scc, nmethod)(\"%d (L%d): Wrote nmethod '%s'%s to AOT Code Cache\",\n-                           comp_id, (int)comp_level, name, (for_preload ? \" (for preload)\" : \"\"));\n-  }\n-  if (VerifyCachedCode) {\n-    return nullptr;\n-  }\n-  return entry;\n-}\n-\n-bool SCCache::write_nmethod_loadtime_relocations(JavaThread* thread, nmethod* nm, GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list) {\n-  LogStreamHandle(Info, scc, reloc) log;\n-  GrowableArray<uint> reloc_data;\n-  \/\/ Collect additional data\n-  RelocIterator iter(nm);\n-  bool has_immediate = false;\n-  while (iter.next()) {\n-    int idx = reloc_data.append(0); \/\/ default value\n-    switch (iter.type()) {\n-      case relocInfo::none:\n-      break;\n-      case relocInfo::oop_type: {\n-        oop_Relocation* r = (oop_Relocation*)iter.reloc();\n-        if (r->oop_is_immediate()) {\n-          \/\/ store index of oop in the reloc immediate oop list\n-          Handle h(thread, r->oop_value());\n-          int oop_idx = oop_list.find(h);\n-          assert(oop_idx != -1, \"sanity check\");\n-          reloc_data.at_put(idx, (uint)oop_idx);\n-          has_immediate = true;\n-        }\n-        break;\n-      }\n-      case relocInfo::metadata_type: {\n-        metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n-        if (r->metadata_is_immediate()) {\n-          \/\/ store index of metadata in the reloc immediate metadata list\n-          int metadata_idx = metadata_list.find(r->metadata_value());\n-          assert(metadata_idx != -1, \"sanity check\");\n-          reloc_data.at_put(idx, (uint)metadata_idx);\n-          has_immediate = true;\n-        }\n-        break;\n-      }\n-      case relocInfo::virtual_call_type:  \/\/ Fall through. They all call resolve_*_call blobs.\n-      case relocInfo::opt_virtual_call_type:\n-      case relocInfo::static_call_type: {\n-        CallRelocation* r = (CallRelocation*)iter.reloc();\n-        address dest = r->destination();\n-        if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n-          dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n-        }\n-        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n-        break;\n-      }\n-      case relocInfo::trampoline_stub_type: {\n-        address dest = ((trampoline_stub_Relocation*)iter.reloc())->destination();\n-        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n-        break;\n-      }\n-      case relocInfo::static_stub_type:\n-        break;\n-      case relocInfo::runtime_call_type: {\n-        \/\/ Record offset of runtime destination\n-        CallRelocation* r = (CallRelocation*)iter.reloc();\n-        address dest = r->destination();\n-        if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n-          dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n-        }\n-        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n-        break;\n-      }\n-      case relocInfo::runtime_call_w_cp_type:\n-        fatal(\"runtime_call_w_cp_type unimplemented\");\n-        break;\n-      case relocInfo::external_word_type: {\n-        \/\/ Record offset of runtime target\n-        address target = ((external_word_Relocation*)iter.reloc())->target();\n-        reloc_data.at_put(idx, _table->id_for_address(target, iter, nullptr));\n-        break;\n-      }\n-      case relocInfo::internal_word_type:\n-        break;\n-      case relocInfo::section_word_type:\n-        break;\n-      case relocInfo::poll_type:\n-        break;\n-      case relocInfo::poll_return_type:\n-        break;\n-      case relocInfo::post_call_nop_type:\n-        break;\n-      case relocInfo::entry_guard_type:\n-        break;\n-      default:\n-        fatal(\"relocation %d unimplemented\", (int)iter.type());\n-        break;\n-    }\n-    if (log.is_enabled()) {\n-      iter.print_current_on(&log);\n-    }\n-  }\n-\n-  \/\/ Write additional relocation data: uint per relocation\n-  \/\/ Write the count first\n-  int count = reloc_data.length();\n-  write_bytes(&count, sizeof(int));\n-  uint data_size = count * sizeof(uint);\n-  for (GrowableArrayIterator<uint> iter = reloc_data.begin();\n-       iter != reloc_data.end(); ++iter) {\n-    uint value = *iter;\n-    int n = write_bytes(&value, sizeof(uint));\n-    if (n != sizeof(uint)) {\n-      return false;\n-      break;\n-    }\n-  }\n-\n-  if (!align_write()) {\n-    return false;\n-  }\n-  return true; \/\/success;\n-}\n-\n-bool SCCache::write_nmethod_reloc_immediates(GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list) {\n-  int count = oop_list.length();\n-  if (!write_bytes(&count, sizeof(int))) {\n-    return false;\n-  }\n-  for (GrowableArrayIterator<Handle> iter = oop_list.begin();\n-       iter != oop_list.end(); ++iter) {\n-    Handle h = *iter;\n-    if (!write_oop(h())) {\n-      return false;\n-    }\n-  }\n-\n-  count = metadata_list.length();\n-  if (!write_bytes(&count, sizeof(int))) {\n-    return false;\n-  }\n-  for (GrowableArrayIterator<Metadata*> iter = metadata_list.begin();\n-       iter != metadata_list.end(); ++iter) {\n-    Metadata* m = *iter;\n-    if (!write_metadata(m)) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n-static void print_helper1(outputStream* st, const char* name, int count) {\n-  if (count > 0) {\n-    st->print(\" %s=%d\", name, count);\n-  }\n-}\n-\n-void SCCache::print_statistics_on(outputStream* st) {\n-  SCCache* cache = open_for_read();\n-  if (cache != nullptr) {\n-    ReadingMark rdmk;\n-    if (rdmk.failed()) {\n-      \/\/ Cache is closed, cannot touch anything.\n-      return;\n-    }\n-\n-    uint count = cache->_load_header->entries_count();\n-    uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n-    SCCEntry* load_entries = (SCCEntry*)(search_entries + 2 * count);\n-\n-    AOTCodeStats stats;\n-    for (uint i = 0; i < count; i++) {\n-      stats.collect_all_stats(&load_entries[i]);\n-    }\n-\n-    for (uint kind = SCCEntry::None; kind < SCCEntry::Kind_count; kind++) {\n-      if (stats.entry_count(kind) > 0) {\n-        st->print(\"  %s:\", sccentry_kind_name[kind]);\n-        print_helper1(st, \"total\", stats.entry_count(kind));\n-        print_helper1(st, \"loaded\", stats.entry_loaded_count(kind));\n-        print_helper1(st, \"invalidated\", stats.entry_invalidated_count(kind));\n-        print_helper1(st, \"failed\", stats.entry_load_failed_count(kind));\n-        st->cr();\n-      }\n-      if (kind == SCCEntry::Code) {\n-        for (uint lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n-          if (stats.nmethod_count(lvl) > 0) {\n-            st->print(\"    SC T%d\", lvl);\n-            print_helper1(st, \"total\", stats.nmethod_count(lvl));\n-            print_helper1(st, \"loaded\", stats.nmethod_loaded_count(lvl));\n-            print_helper1(st, \"invalidated\", stats.nmethod_invalidated_count(lvl));\n-            print_helper1(st, \"failed\", stats.nmethod_load_failed_count(lvl));\n-            if (lvl == AOTCompLevel_count-1) {\n-              print_helper1(st, \"has_clinit_barriers\", stats.clinit_barriers_count());\n-            }\n-            st->cr();\n-          }\n-        }\n-      }\n-    }\n-  } else {\n-    st->print_cr(\"failed to map code cache\");\n-  }\n-}\n-\n-void SCCache::print_on(outputStream* st) {\n-  SCCache* cache = open_for_read();\n-  if (cache != nullptr) {\n-    ReadingMark rdmk;\n-    if (rdmk.failed()) {\n-      \/\/ Cache is closed, cannot touch anything.\n-      return;\n-    }\n-\n-    uint count = cache->_load_header->entries_count();\n-    uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n-    SCCEntry* load_entries = (SCCEntry*)(search_entries + 2 * count);\n-\n-    for (uint i = 0; i < count; i++) {\n-      int index = search_entries[2*i + 1];\n-      SCCEntry* entry = &(load_entries[index]);\n-\n-      st->print_cr(\"%4u: %4u: K%u L%u offset=%u decompile=%u size=%u code_size=%u%s%s%s%s\",\n-                i, index, entry->kind(), entry->comp_level(), entry->offset(),\n-                entry->decompile(), entry->size(), entry->code_size(),\n-                entry->has_clinit_barriers() ? \" has_clinit_barriers\" : \"\",\n-                entry->for_preload()         ? \" for_preload\"         : \"\",\n-                entry->is_loaded()           ? \" loaded\"              : \"\",\n-                entry->not_entrant()         ? \" not_entrant\"         : \"\");\n-      st->print_raw(\"         \");\n-      SCCReader reader(cache, entry, nullptr);\n-      reader.print_on(st);\n-    }\n-  } else {\n-    st->print_cr(\"failed to map code cache\");\n-  }\n-}\n-\n-void SCCache::print_unused_entries_on(outputStream* st) {\n-  LogStreamHandle(Info, scc, init) info;\n-  if (info.is_enabled()) {\n-    SCCache::iterate([&](SCCEntry* entry) {\n-      if (entry->is_code() && !entry->is_loaded()) {\n-        MethodTrainingData* mtd = MethodTrainingData::find(methodHandle(Thread::current(), entry->method()));\n-        if (mtd != nullptr) {\n-          if (mtd->has_holder()) {\n-            if (mtd->holder()->method_holder()->is_initialized()) {\n-              ResourceMark rm;\n-              mtd->iterate_compiles([&](CompileTrainingData* ctd) {\n-                if ((uint)ctd->level() == entry->comp_level()) {\n-                  if (ctd->init_deps_left() == 0) {\n-                    nmethod* nm = mtd->holder()->code();\n-                    if (nm == nullptr) {\n-                      if (mtd->holder()->queued_for_compilation()) {\n-                        return; \/\/ scheduled for compilation\n-                      }\n-                    } else if ((uint)nm->comp_level() >= entry->comp_level()) {\n-                      return; \/\/ already online compiled and superseded by a more optimal method\n-                    }\n-                    info.print(\"SCC entry not loaded: \");\n-                    ctd->print_on(&info);\n-                    info.cr();\n-                  }\n-                }\n-              });\n-            } else {\n-              \/\/ not yet initialized\n-            }\n-          } else {\n-            info.print(\"SCC entry doesn't have a holder: \");\n-            mtd->print_on(&info);\n-            info.cr();\n-          }\n-        }\n-      }\n-    });\n-  }\n-}\n-\n-void SCCReader::print_on(outputStream* st) {\n-  uint entry_position = _entry->offset();\n-  set_read_position(entry_position);\n-\n-  \/\/ Read name\n-  uint name_offset = entry_position + _entry->name_offset();\n-  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n-  const char* name = addr(name_offset);\n-\n-  st->print_cr(\"  name: %s\", name);\n-}\n-\n-\/\/ address table ids for generated routines, external addresses and C\n-\/\/ string addresses are partitioned into positive integer ranges\n-\/\/ defined by the following positive base and max values\n-\/\/ i.e. [_extrs_base, _extrs_base + _extrs_max -1],\n-\/\/      [_stubs_base, _stubs_base + _stubs_max -1],\n-\/\/      ...\n-\/\/      [_c_str_base, _c_str_base + _c_str_max -1],\n-#define _extrs_max 80\n-#define _stubs_max 120\n-#define _all_blobs_max 100\n-#define _blobs_max 24\n-#define _C2_blobs_max 25\n-#define _C1_blobs_max (_all_blobs_max - _blobs_max - _C2_blobs_max)\n-#define _all_max 300\n-\n-#define _c_str_max MAX_STR_COUNT\n-#define _extrs_base 0\n-#define _stubs_base (_extrs_base + _extrs_max)\n-#define _blobs_base (_stubs_base + _stubs_max)\n-#define _C1_blobs_base (_blobs_base + _blobs_max)\n-#define _C2_blobs_base (_C1_blobs_base + _C1_blobs_max)\n-#if (_C2_blobs_base >= _all_max)\n-#error SCAddress table ranges need adjusting\n-#endif\n-#define _c_str_base _all_max\n-\n-#define SET_ADDRESS(type, addr)                           \\\n-  {                                                       \\\n-    type##_addr[type##_length++] = (address) (addr);      \\\n-    assert(type##_length <= type##_max, \"increase size\"); \\\n-  }\n-\n-static bool initializing_extrs = false;\n-void SCAddressTable::init_extrs() {\n-  if (_extrs_complete || initializing_extrs) return; \/\/ Done already\n-  initializing_extrs = true;\n-  _extrs_addr = NEW_C_HEAP_ARRAY(address, _extrs_max, mtCode);\n-\n-  _extrs_length = 0;\n-  _stubs_length = 0;\n-\n-  \/\/ Runtime methods\n-#ifdef COMPILER2\n-  SET_ADDRESS(_extrs, OptoRuntime::handle_exception_C);\n-#endif\n-#ifdef COMPILER1\n-  SET_ADDRESS(_extrs, Runtime1::is_instance_of);\n-  SET_ADDRESS(_extrs, Runtime1::trace_block_entry);\n-#endif\n-\n-  SET_ADDRESS(_extrs, CompressedOops::base_addr());\n-#if INCLUDE_G1GC\n-  SET_ADDRESS(_extrs, G1BarrierSetRuntime::write_ref_field_post_entry);\n-  SET_ADDRESS(_extrs, G1BarrierSetRuntime::write_ref_field_pre_entry);\n-#endif\n-\n-#if INCLUDE_SHENANDOAHGC\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::arraycopy_barrier_oop);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::arraycopy_barrier_narrow_oop);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::write_ref_field_pre);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::clone_barrier);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_strong);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_strong_narrow);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_weak);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_weak_narrow);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_phantom);\n-  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_phantom_narrow);\n-#endif\n-  SET_ADDRESS(_extrs, SharedRuntime::fixup_callers_callsite);\n-\n-  SET_ADDRESS(_extrs, SharedRuntime::log_jni_monitor_still_held);\n-  SET_ADDRESS(_extrs, SharedRuntime::rc_trace_method_entry);\n-  SET_ADDRESS(_extrs, SharedRuntime::reguard_yellow_pages);\n-  SET_ADDRESS(_extrs, SharedRuntime::dtrace_method_exit);\n-\n-  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method);\n-  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method_abstract);\n-  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method_ic_miss);\n-  SET_ADDRESS(_extrs, SharedRuntime::resolve_opt_virtual_call_C);\n-  SET_ADDRESS(_extrs, SharedRuntime::resolve_virtual_call_C);\n-  SET_ADDRESS(_extrs, SharedRuntime::resolve_static_call_C);\n-\n-  SET_ADDRESS(_extrs, SharedRuntime::complete_monitor_unlocking_C);\n-  SET_ADDRESS(_extrs, SharedRuntime::enable_stack_reserved_zone);\n-#if defined(AMD64) && !defined(ZERO)\n-  SET_ADDRESS(_extrs, SharedRuntime::montgomery_multiply);\n-  SET_ADDRESS(_extrs, SharedRuntime::montgomery_square);\n-#endif \/\/ AMD64\n-  SET_ADDRESS(_extrs, SharedRuntime::d2f);\n-  SET_ADDRESS(_extrs, SharedRuntime::d2i);\n-  SET_ADDRESS(_extrs, SharedRuntime::d2l);\n-  SET_ADDRESS(_extrs, SharedRuntime::dcos);\n-  SET_ADDRESS(_extrs, SharedRuntime::dexp);\n-  SET_ADDRESS(_extrs, SharedRuntime::dlog);\n-  SET_ADDRESS(_extrs, SharedRuntime::dlog10);\n-  SET_ADDRESS(_extrs, SharedRuntime::dpow);\n-  SET_ADDRESS(_extrs, SharedRuntime::dsin);\n-  SET_ADDRESS(_extrs, SharedRuntime::dtan);\n-  SET_ADDRESS(_extrs, SharedRuntime::f2i);\n-  SET_ADDRESS(_extrs, SharedRuntime::f2l);\n-#ifndef ZERO\n-  SET_ADDRESS(_extrs, SharedRuntime::drem);\n-  SET_ADDRESS(_extrs, SharedRuntime::frem);\n-#endif\n-  SET_ADDRESS(_extrs, SharedRuntime::l2d);\n-  SET_ADDRESS(_extrs, SharedRuntime::l2f);\n-  SET_ADDRESS(_extrs, SharedRuntime::ldiv);\n-  SET_ADDRESS(_extrs, SharedRuntime::lmul);\n-  SET_ADDRESS(_extrs, SharedRuntime::lrem);\n-#if INCLUDE_JVMTI\n-  SET_ADDRESS(_extrs, &JvmtiExport::_should_notify_object_alloc);\n-#endif \/* INCLUDE_JVMTI *\/\n-  BarrierSet* bs = BarrierSet::barrier_set();\n-  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n-    SET_ADDRESS(_extrs, ci_card_table_address_as<address>());\n-  }\n-  SET_ADDRESS(_extrs, ThreadIdentifier::unsafe_offset());\n-  SET_ADDRESS(_extrs, Thread::current);\n-\n-  SET_ADDRESS(_extrs, os::javaTimeMillis);\n-  SET_ADDRESS(_extrs, os::javaTimeNanos);\n-\n-#if INCLUDE_JVMTI\n-  SET_ADDRESS(_extrs, &JvmtiVTMSTransitionDisabler::_VTMS_notify_jvmti_events);\n-#endif \/* INCLUDE_JVMTI *\/\n-  SET_ADDRESS(_extrs, StubRoutines::crc_table_addr());\n-#ifndef PRODUCT\n-  SET_ADDRESS(_extrs, &SharedRuntime::_partial_subtype_ctr);\n-  SET_ADDRESS(_extrs, JavaThread::verify_cross_modify_fence_failure);\n-#endif\n-\n-#ifndef ZERO\n-#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n-  SET_ADDRESS(_extrs, MacroAssembler::debug64);\n-#endif\n-#if defined(AMD64)\n-  SET_ADDRESS(_extrs, StubRoutines::x86::arrays_hashcode_powers_of_31());\n-#endif\n-#endif\n-\n-#ifdef COMPILER1\n-#ifdef X86\n-  SET_ADDRESS(_extrs, LIR_Assembler::float_signmask_pool);\n-  SET_ADDRESS(_extrs, LIR_Assembler::double_signmask_pool);\n-  SET_ADDRESS(_extrs, LIR_Assembler::float_signflip_pool);\n-  SET_ADDRESS(_extrs, LIR_Assembler::double_signflip_pool);\n-#endif\n-#endif\n-\n-  \/\/ addresses of fields in AOT runtime constants area\n-  address* p = AOTRuntimeConstants::field_addresses_list();\n-  while (*p != nullptr) {\n-    SET_ADDRESS(_extrs, *p++);\n-  }\n-\n-  _extrs_complete = true;\n-  log_info(scc,init)(\"External addresses recorded\");\n-}\n-\n-static bool initializing_early_stubs = false;\n-void SCAddressTable::init_early_stubs() {\n-  if (_complete || initializing_early_stubs) return; \/\/ Done already\n-  initializing_early_stubs = true;\n-  _stubs_addr = NEW_C_HEAP_ARRAY(address, _stubs_max, mtCode);\n-  _stubs_length = 0;\n-  SET_ADDRESS(_stubs, StubRoutines::forward_exception_entry());\n-  _early_stubs_complete = true;\n-  log_info(scc,init)(\"early stubs recorded\");\n-}\n-\n-static bool initializing_shared_blobs = false;\n-void SCAddressTable::init_shared_blobs() {\n-  if (_complete || initializing_shared_blobs) return; \/\/ Done already\n-  initializing_shared_blobs = true;\n-  _blobs_addr = NEW_C_HEAP_ARRAY(address, _all_blobs_max, mtCode);\n-\n-  \/\/ Divide _blobs_addr array to chunks because they could be initialized in parrallel\n-  _C1_blobs_addr = _blobs_addr + _blobs_max;\/\/ C1 blobs addresses stored after shared blobs\n-  _C2_blobs_addr = _C1_blobs_addr + _C1_blobs_max; \/\/ C2 blobs addresses stored after C1 blobs\n-\n-  _blobs_length = 0;       \/\/ for shared blobs\n-  _C1_blobs_length = 0;\n-  _C2_blobs_length = 0;\n-\n-  \/\/ Blobs\n-  SET_ADDRESS(_blobs, SharedRuntime::get_handle_wrong_method_stub());\n-  SET_ADDRESS(_blobs, SharedRuntime::get_ic_miss_stub());\n-  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_opt_virtual_call_stub());\n-  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_virtual_call_stub());\n-  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_static_call_stub());\n-  SET_ADDRESS(_blobs, SharedRuntime::deopt_blob()->entry_point());\n-  SET_ADDRESS(_blobs, SharedRuntime::polling_page_safepoint_handler_blob()->entry_point());\n-  SET_ADDRESS(_blobs, SharedRuntime::polling_page_return_handler_blob()->entry_point());\n-#ifdef COMPILER2\n-  SET_ADDRESS(_blobs, SharedRuntime::polling_page_vectors_safepoint_handler_blob()->entry_point());\n-#endif\n-\n-  assert(_blobs_length <= _blobs_max, \"increase _blobs_max to %d\", _blobs_length);\n-  log_info(scc,init)(\"Early shared blobs recorded\");\n-}\n-\n-static bool initializing_stubs = false;\n-void SCAddressTable::init_stubs() {\n-  if (_complete || initializing_stubs) return; \/\/ Done already\n-  initializing_stubs = true;\n-  \/\/ final blobs\n-  SET_ADDRESS(_blobs, SharedRuntime::throw_AbstractMethodError_entry());\n-  SET_ADDRESS(_blobs, SharedRuntime::throw_IncompatibleClassChangeError_entry());\n-  SET_ADDRESS(_blobs, SharedRuntime::throw_NullPointerException_at_call_entry());\n-  SET_ADDRESS(_blobs, SharedRuntime::throw_StackOverflowError_entry());\n-  SET_ADDRESS(_blobs, SharedRuntime::throw_delayed_StackOverflowError_entry());\n-\n-  assert(_blobs_length <= _blobs_max, \"increase _blobs_max to %d\", _blobs_length);\n-\n-  _shared_blobs_complete = true;\n-  log_info(scc,init)(\"All shared blobs recorded\");\n-\n-  \/\/ Stubs\n-  SET_ADDRESS(_stubs, StubRoutines::method_entry_barrier());\n-\/*\n-  SET_ADDRESS(_stubs, StubRoutines::throw_AbstractMethodError_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::throw_IncompatibleClassChangeError_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::throw_NullPointerException_at_call_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::throw_StackOverflowError_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::throw_delayed_StackOverflowError_entry());\n-*\/\n-  SET_ADDRESS(_stubs, StubRoutines::atomic_xchg_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::atomic_cmpxchg_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::atomic_cmpxchg_long_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::atomic_add_entry());\n-  SET_ADDRESS(_stubs, StubRoutines::fence_entry());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::cont_thaw());\n-  SET_ADDRESS(_stubs, StubRoutines::cont_returnBarrier());\n-  SET_ADDRESS(_stubs, StubRoutines::cont_returnBarrierExc());\n-\n-  JFR_ONLY(SET_ADDRESS(_stubs, SharedRuntime::jfr_write_checkpoint());)\n-\n-\n-  SET_ADDRESS(_stubs, StubRoutines::jbyte_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jshort_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jlong_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::_oop_arraycopy);\n-  SET_ADDRESS(_stubs, StubRoutines::_oop_arraycopy_uninit);\n-\n-  SET_ADDRESS(_stubs, StubRoutines::jbyte_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jshort_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jint_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::jlong_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::_oop_disjoint_arraycopy);\n-  SET_ADDRESS(_stubs, StubRoutines::_oop_disjoint_arraycopy_uninit);\n-\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jlong_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_arraycopy);\n-  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_arraycopy_uninit);\n-\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jlong_disjoint_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_disjoint_arraycopy);\n-  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit);\n-\n-  SET_ADDRESS(_stubs, StubRoutines::_checkcast_arraycopy);\n-  SET_ADDRESS(_stubs, StubRoutines::_checkcast_arraycopy_uninit);\n-\n-  SET_ADDRESS(_stubs, StubRoutines::unsafe_arraycopy());\n-  SET_ADDRESS(_stubs, StubRoutines::generic_arraycopy());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::jbyte_fill());\n-  SET_ADDRESS(_stubs, StubRoutines::jshort_fill());\n-  SET_ADDRESS(_stubs, StubRoutines::jint_fill());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_fill());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_fill());\n-  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_fill());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::data_cache_writeback());\n-  SET_ADDRESS(_stubs, StubRoutines::data_cache_writeback_sync());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::aescrypt_encryptBlock());\n-  SET_ADDRESS(_stubs, StubRoutines::aescrypt_decryptBlock());\n-  SET_ADDRESS(_stubs, StubRoutines::cipherBlockChaining_encryptAESCrypt());\n-  SET_ADDRESS(_stubs, StubRoutines::cipherBlockChaining_decryptAESCrypt());\n-  SET_ADDRESS(_stubs, StubRoutines::electronicCodeBook_encryptAESCrypt());\n-  SET_ADDRESS(_stubs, StubRoutines::electronicCodeBook_decryptAESCrypt());\n-  SET_ADDRESS(_stubs, StubRoutines::poly1305_processBlocks());\n-  SET_ADDRESS(_stubs, StubRoutines::counterMode_AESCrypt());\n-  SET_ADDRESS(_stubs, StubRoutines::ghash_processBlocks());\n-  SET_ADDRESS(_stubs, StubRoutines::chacha20Block());\n-  SET_ADDRESS(_stubs, StubRoutines::base64_encodeBlock());\n-  SET_ADDRESS(_stubs, StubRoutines::base64_decodeBlock());\n-  SET_ADDRESS(_stubs, StubRoutines::md5_implCompress());\n-  SET_ADDRESS(_stubs, StubRoutines::md5_implCompressMB());\n-  SET_ADDRESS(_stubs, StubRoutines::sha1_implCompress());\n-  SET_ADDRESS(_stubs, StubRoutines::sha1_implCompressMB());\n-  SET_ADDRESS(_stubs, StubRoutines::sha256_implCompress());\n-  SET_ADDRESS(_stubs, StubRoutines::sha256_implCompressMB());\n-  SET_ADDRESS(_stubs, StubRoutines::sha512_implCompress());\n-  SET_ADDRESS(_stubs, StubRoutines::sha512_implCompressMB());\n-  SET_ADDRESS(_stubs, StubRoutines::sha3_implCompress());\n-  SET_ADDRESS(_stubs, StubRoutines::sha3_implCompressMB());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::updateBytesCRC32());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::crc32c_table_addr());\n-  SET_ADDRESS(_stubs, StubRoutines::updateBytesCRC32C());\n-  SET_ADDRESS(_stubs, StubRoutines::updateBytesAdler32());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::multiplyToLen());\n-  SET_ADDRESS(_stubs, StubRoutines::squareToLen());\n-  SET_ADDRESS(_stubs, StubRoutines::mulAdd());\n-  SET_ADDRESS(_stubs, StubRoutines::montgomeryMultiply());\n-  SET_ADDRESS(_stubs, StubRoutines::montgomerySquare());\n-  SET_ADDRESS(_stubs, StubRoutines::bigIntegerRightShift());\n-  SET_ADDRESS(_stubs, StubRoutines::bigIntegerLeftShift());\n-  SET_ADDRESS(_stubs, StubRoutines::galoisCounterMode_AESCrypt());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::vectorizedMismatch());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::dexp());\n-  SET_ADDRESS(_stubs, StubRoutines::dlog());\n-  SET_ADDRESS(_stubs, StubRoutines::dlog10());\n-  SET_ADDRESS(_stubs, StubRoutines::dpow());\n-  SET_ADDRESS(_stubs, StubRoutines::dsin());\n-  SET_ADDRESS(_stubs, StubRoutines::dcos());\n-  SET_ADDRESS(_stubs, StubRoutines::dlibm_reduce_pi04l());\n-  SET_ADDRESS(_stubs, StubRoutines::dlibm_sin_cos_huge());\n-  SET_ADDRESS(_stubs, StubRoutines::dlibm_tan_cot_huge());\n-  SET_ADDRESS(_stubs, StubRoutines::dtan());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::f2hf_adr());\n-  SET_ADDRESS(_stubs, StubRoutines::hf2f_adr());\n-\n-#if defined(AMD64) && !defined(ZERO)\n-  SET_ADDRESS(_stubs, StubRoutines::x86::d2i_fixup());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::f2i_fixup());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::d2l_fixup());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::f2l_fixup());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::float_sign_mask());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::float_sign_flip());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::double_sign_mask());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::double_sign_flip());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::vector_popcount_lut());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::vector_float_sign_mask());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::vector_float_sign_flip());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::vector_double_sign_mask());\n-  SET_ADDRESS(_stubs, StubRoutines::x86::vector_double_sign_flip());\n-  \/\/ The iota indices are ordered by type B\/S\/I\/L\/F\/D, and the offset between two types is 64.\n-  \/\/ See C2_MacroAssembler::load_iota_indices().\n-  for (int i = 0; i < 6; i++) {\n-    SET_ADDRESS(_stubs, StubRoutines::x86::vector_iota_indices() + i * 64);\n-  }\n-#endif\n-#if defined(AARCH64) && !defined(ZERO)\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::zero_blocks());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::count_positives());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::count_positives_long());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_array_equals());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_LL());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_UU());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_LU());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_UL());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_ul());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_ll());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_uu());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_byte_array_inflate());\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::spin_wait());\n-\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_BOOLEAN));\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_BYTE));\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_SHORT));\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_CHAR));\n-  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_INT));\n-#endif\n-\n-  _complete = true;\n-  log_info(scc,init)(\"Stubs recorded\");\n-}\n-\n-void SCAddressTable::init_opto() {\n-#ifdef COMPILER2\n-  \/\/ OptoRuntime Blobs\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::uncommon_trap_blob()->entry_point());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::exception_blob()->entry_point());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::new_instance_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::new_array_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::new_array_nozero_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray2_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray3_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray4_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray5_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarrayN_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::vtable_must_compile_stub());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::complete_monitor_locking_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::monitor_notify_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::monitor_notifyAll_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::rethrow_stub());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::slow_arraycopy_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::register_finalizer_Java());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::class_init_barrier_Java());\n-#if INCLUDE_JVMTI\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_start());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_end());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_mount());\n-  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_unmount());\n-#endif \/* INCLUDE_JVMTI *\/\n-#endif\n-\n-  assert(_C2_blobs_length <= _C2_blobs_max, \"increase _C2_blobs_max to %d\", _C2_blobs_length);\n-  _opto_complete = true;\n-  log_info(scc,init)(\"OptoRuntime Blobs recorded\");\n-}\n-\n-void SCAddressTable::init_c1() {\n-#ifdef COMPILER1\n-  \/\/ Runtime1 Blobs\n-  for (int i = 0; i < (int)(C1StubId::NUM_STUBIDS); i++) {\n-    C1StubId id = (C1StubId)i;\n-    if (Runtime1::blob_for(id) == nullptr) {\n-      log_info(scc, init)(\"C1 blob %s is missing\", Runtime1::name_for(id));\n-      continue;\n-    }\n-    if (Runtime1::entry_for(id) == nullptr) {\n-      log_info(scc, init)(\"C1 blob %s is missing entry\", Runtime1::name_for(id));\n-      continue;\n-    }\n-    address entry = Runtime1::entry_for(id);\n-    SET_ADDRESS(_C1_blobs, entry);\n-  }\n-#if INCLUDE_G1GC\n-  if (UseG1GC) {\n-    G1BarrierSetC1* bs = (G1BarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n-    address entry = bs->pre_barrier_c1_runtime_code_blob()->code_begin();\n-    SET_ADDRESS(_C1_blobs, entry);\n-    entry = bs->post_barrier_c1_runtime_code_blob()->code_begin();\n-    SET_ADDRESS(_C1_blobs, entry);\n-  }\n-#endif \/\/ INCLUDE_G1GC\n-#if INCLUDE_ZGC\n-  if (UseZGC) {\n-    ZBarrierSetC1* bs = (ZBarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n-    SET_ADDRESS(_C1_blobs, bs->_load_barrier_on_oop_field_preloaded_runtime_stub);\n-    SET_ADDRESS(_C1_blobs, bs->_load_barrier_on_weak_oop_field_preloaded_runtime_stub);\n-    SET_ADDRESS(_C1_blobs, bs->_store_barrier_on_oop_field_with_healing);\n-    SET_ADDRESS(_C1_blobs, bs->_store_barrier_on_oop_field_without_healing);\n-  }\n-#endif \/\/ INCLUDE_ZGC\n-#if INCLUDE_SHENANDOAHGC\n-  if (UseShenandoahGC) {\n-    ShenandoahBarrierSetC1* bs = (ShenandoahBarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n-    SET_ADDRESS(_C1_blobs, bs->pre_barrier_c1_runtime_code_blob()->code_begin());\n-    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_strong_rt_code_blob()->code_begin());\n-    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_strong_native_rt_code_blob()->code_begin());\n-    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_weak_rt_code_blob()->code_begin());\n-    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_phantom_rt_code_blob()->code_begin());\n-  }\n-#endif \/\/ INCLUDE_SHENANDOAHGC\n-#endif \/\/ COMPILER1\n-\n-  assert(_C1_blobs_length <= _C1_blobs_max, \"increase _C1_blobs_max to %d\", _C1_blobs_length);\n-  _c1_complete = true;\n-  log_info(scc,init)(\"Runtime1 Blobs recorded\");\n-}\n-\n-#undef SET_ADDRESS\n-\n-SCAddressTable::~SCAddressTable() {\n-  if (_extrs_addr != nullptr) {\n-    FREE_C_HEAP_ARRAY(address, _extrs_addr);\n-  }\n-  if (_stubs_addr != nullptr) {\n-    FREE_C_HEAP_ARRAY(address, _stubs_addr);\n-  }\n-  if (_blobs_addr != nullptr) {\n-    FREE_C_HEAP_ARRAY(address, _blobs_addr);\n-  }\n-}\n-\n-#ifdef PRODUCT\n-#define MAX_STR_COUNT 200\n-#else\n-#define MAX_STR_COUNT 500\n-#endif\n-static const char* _C_strings[MAX_STR_COUNT] = {nullptr};\n-static int _C_strings_count = 0;\n-static int _C_strings_s[MAX_STR_COUNT] = {0};\n-static int _C_strings_id[MAX_STR_COUNT] = {0};\n-static int _C_strings_len[MAX_STR_COUNT] = {0};\n-static int _C_strings_hash[MAX_STR_COUNT] = {0};\n-static int _C_strings_used = 0;\n-\n-void SCCache::load_strings() {\n-  uint strings_count  = _load_header->strings_count();\n-  if (strings_count == 0) {\n-    return;\n-  }\n-  uint strings_offset = _load_header->strings_offset();\n-  uint strings_size   = _load_header->entries_offset() - strings_offset;\n-  uint data_size = (uint)(strings_count * sizeof(uint));\n-  uint* sizes = (uint*)addr(strings_offset);\n-  uint* hashs = (uint*)addr(strings_offset + data_size);\n-  strings_size -= 2 * data_size;\n-  \/\/ We have to keep cached strings longer than _cache buffer\n-  \/\/ because they are refernced from compiled code which may\n-  \/\/ still be executed on VM exit after _cache is freed.\n-  char* p = NEW_C_HEAP_ARRAY(char, strings_size+1, mtCode);\n-  memcpy(p, addr(strings_offset + 2 * data_size), strings_size);\n-  _C_strings_buf = p;\n-  assert(strings_count <= MAX_STR_COUNT, \"sanity\");\n-  for (uint i = 0; i < strings_count; i++) {\n-    _C_strings[i] = p;\n-    uint len = sizes[i];\n-    _C_strings_s[i] = i;\n-    _C_strings_id[i] = i;\n-    _C_strings_len[i] = len;\n-    _C_strings_hash[i] = hashs[i];\n-    p += len;\n-  }\n-  assert((uint)(p - _C_strings_buf) <= strings_size, \"(\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \") = %d > %d \", p2i(p), p2i(_C_strings_buf), (uint)(p - _C_strings_buf), strings_size);\n-  _C_strings_count = strings_count;\n-  _C_strings_used  = strings_count;\n-  log_info(scc, init)(\"Load %d C strings at offset %d from AOT Code Cache\", _C_strings_count, strings_offset);\n-}\n-\n-int SCCache::store_strings() {\n-  uint offset = _write_position;\n-  uint length = 0;\n-  if (_C_strings_used > 0) {\n-    \/\/ Write sizes first\n-    for (int i = 0; i < _C_strings_used; i++) {\n-      uint len = _C_strings_len[i] + 1; \/\/ Include 0\n-      length += len;\n-      assert(len < 1000, \"big string: %s\", _C_strings[i]);\n-      uint n = write_bytes(&len, sizeof(uint));\n-      if (n != sizeof(uint)) {\n-        return -1;\n-      }\n-    }\n-    \/\/ Write hashs\n-    for (int i = 0; i < _C_strings_used; i++) {\n-      uint n = write_bytes(&(_C_strings_hash[i]), sizeof(uint));\n-      if (n != sizeof(uint)) {\n-        return -1;\n-      }\n-    }\n-    for (int i = 0; i < _C_strings_used; i++) {\n-      uint len = _C_strings_len[i] + 1; \/\/ Include 0\n-      uint n = write_bytes(_C_strings[_C_strings_s[i]], len);\n-      if (n != len) {\n-        return -1;\n-      }\n-    }\n-    log_info(scc, exit)(\"Wrote %d C strings of total length %d at offset %d to AOT Code Cache\",\n-                        _C_strings_used, length, offset);\n-  }\n-  return _C_strings_used;\n-}\n-\n-void SCCache::add_new_C_string(const char* str) {\n-  assert(for_write(), \"only when storing code\");\n-  _table->add_C_string(str);\n-}\n-\n-void SCAddressTable::add_C_string(const char* str) {\n-  if (str != nullptr && _extrs_complete) {\n-    \/\/ Check previous strings address\n-    for (int i = 0; i < _C_strings_count; i++) {\n-      if (_C_strings[i] == str) {\n-        return; \/\/ Found existing one\n-      }\n-    }\n-    \/\/ Add new one\n-    if (_C_strings_count < MAX_STR_COUNT) {\n-      log_trace(scc)(\"add_C_string: [%d] \" INTPTR_FORMAT \" %s\", _C_strings_count, p2i(str), str);\n-      _C_strings_id[_C_strings_count] = -1; \/\/ Init\n-      _C_strings[_C_strings_count++] = str;\n-    } else {\n-      if (Thread::current()->is_Compiler_thread()) {\n-        CompileTask* task = ciEnv::current()->task();\n-        log_info(scc)(\"%d (L%d): Number of C strings > max %d %s\",\n-                      task->compile_id(), task->comp_level(), MAX_STR_COUNT, str);\n-      }\n-    }\n-  }\n-}\n-\n-int SCAddressTable::id_for_C_string(address str) {\n-  for (int i = 0; i < _C_strings_count; i++) {\n-    if (_C_strings[i] == (const char*)str) { \/\/ found\n-      int id = _C_strings_id[i];\n-      if (id >= 0) {\n-        assert(id < _C_strings_used, \"%d >= %d\", id , _C_strings_used);\n-        return id; \/\/ Found recorded\n-      }\n-      \/\/ Search for the same string content\n-      int len = (int)strlen((const char*)str);\n-      int hash = java_lang_String::hash_code((const jbyte*)str, len);\n-      for (int j = 0; j < _C_strings_used; j++) {\n-        if ((_C_strings_len[j] == len) && (_C_strings_hash[j] == hash)) {\n-          _C_strings_id[i] = j; \/\/ Found match\n-          return j;\n-        }\n-      }\n-      \/\/ Not found in recorded, add new\n-      id = _C_strings_used++;\n-      _C_strings_s[id] = i;\n-      _C_strings_id[i] = id;\n-      _C_strings_len[id] = len;\n-      _C_strings_hash[id] = hash;\n-      return id;\n-    }\n-  }\n-  return -1;\n-}\n-\n-address SCAddressTable::address_for_C_string(int idx) {\n-  assert(idx < _C_strings_count, \"sanity\");\n-  return (address)_C_strings[idx];\n-}\n-\n-int search_address(address addr, address* table, uint length) {\n-  for (int i = 0; i < (int)length; i++) {\n-    if (table[i] == addr) {\n-      return i;\n-    }\n-  }\n-  return -1;\n-}\n-\n-address SCAddressTable::address_for_id(int idx) {\n-  if (!_extrs_complete) {\n-    fatal(\"SCA extrs table is not complete\");\n-  }\n-  if (idx == -1) {\n-    return (address)-1;\n-  }\n-  uint id = (uint)idx;\n-  \/\/ special case for symbols based relative to os::init\n-  if (id > (_c_str_base + _c_str_max)) {\n-    return (address)os::init + idx;\n-  }\n-  if (idx < 0) {\n-    fatal(\"Incorrect id %d for SCA table\", id);\n-  }\n-  \/\/ no need to compare unsigned id against 0\n-  if (\/* id >= _extrs_base && *\/ id < _extrs_length) {\n-    return _extrs_addr[id - _extrs_base];\n-  }\n-  if (id >= _stubs_base && id < _stubs_base + _stubs_length) {\n-    return _stubs_addr[id - _stubs_base];\n-  }\n-  if (id >= _blobs_base && id < _blobs_base + _blobs_length) {\n-    return _blobs_addr[id - _blobs_base];\n-  }\n-  if (id >= _C1_blobs_base && id < _C1_blobs_base + _C1_blobs_length) {\n-    return _C1_blobs_addr[id - _C1_blobs_base];\n-  }\n-  if (id >= _C2_blobs_base && id < _C2_blobs_base + _C2_blobs_length) {\n-    return _C2_blobs_addr[id - _C2_blobs_base];\n-  }\n-  if (id >= _c_str_base && id < (_c_str_base + (uint)_C_strings_count)) {\n-    return address_for_C_string(id - _c_str_base);\n-  }\n-  fatal(\"Incorrect id %d for SCA table\", id);\n-  return nullptr;\n-}\n-\n-int SCAddressTable::id_for_address(address addr, RelocIterator reloc, CodeBuffer* buffer) {\n-  int id = -1;\n-  if (addr == (address)-1) { \/\/ Static call stub has jump to itself\n-    return id;\n-  }\n-  if (!_extrs_complete) {\n-    fatal(\"SCA table is not complete\");\n-  }\n-  \/\/ Seach for C string\n-  id = id_for_C_string(addr);\n-  if (id >=0) {\n-    return id + _c_str_base;\n-  }\n-  if (StubRoutines::contains(addr)) {\n-    \/\/ Search in stubs\n-    id = search_address(addr, _stubs_addr, _stubs_length);\n-    if (id < 0) {\n-      StubCodeDesc* desc = StubCodeDesc::desc_for(addr);\n-      if (desc == nullptr) {\n-        desc = StubCodeDesc::desc_for(addr + frame::pc_return_offset);\n-      }\n-      const char* sub_name = (desc != nullptr) ? desc->name() : \"<unknown>\";\n-      fatal(\"Address \" INTPTR_FORMAT \" for Stub:%s is missing in SCA table\", p2i(addr), sub_name);\n-    } else {\n-      return _stubs_base + id;\n-    }\n-  } else {\n-    CodeBlob* cb = CodeCache::find_blob(addr);\n-    if (cb != nullptr) {\n-      int id_base = _blobs_base;\n-      \/\/ Search in code blobs\n-       id = search_address(addr, _blobs_addr, _blobs_length);\n-      if (id == -1) {\n-        id_base = _C1_blobs_base;\n-        \/\/ search C1 blobs\n-        id = search_address(addr, _C1_blobs_addr, _C1_blobs_length);\n-      }\n-      if (id == -1) {\n-        id_base = _C2_blobs_base;\n-        \/\/ search C2 blobs\n-        id = search_address(addr, _C2_blobs_addr, _C2_blobs_length);\n-      }\n-      if (id < 0) {\n-        fatal(\"Address \" INTPTR_FORMAT \" for Blob:%s is missing in SCA table\", p2i(addr), cb->name());\n-      } else {\n-        return id_base + id;\n-      }\n-    } else {\n-      \/\/ Search in runtime functions\n-      id = search_address(addr, _extrs_addr, _extrs_length);\n-      if (id < 0) {\n-        ResourceMark rm;\n-        const int buflen = 1024;\n-        char* func_name = NEW_RESOURCE_ARRAY(char, buflen);\n-        int offset = 0;\n-        if (os::dll_address_to_function_name(addr, func_name, buflen, &offset)) {\n-          if (offset > 0) {\n-            \/\/ Could be address of C string\n-            uint dist = (uint)pointer_delta(addr, (address)os::init, 1);\n-            CompileTask* task = ciEnv::current()->task();\n-            uint compile_id = 0;\n-            uint comp_level =0;\n-            if (task != nullptr) { \/\/ this could be called from compiler runtime initialization (compiler blobs)\n-              compile_id = task->compile_id();\n-              comp_level = task->comp_level();\n-            }\n-            log_info(scc)(\"%d (L%d): Address \" INTPTR_FORMAT \" (offset %d) for runtime target '%s' is missing in SCA table\",\n-                          compile_id, comp_level, p2i(addr), dist, (const char*)addr);\n-            assert(dist > (uint)(_all_max + MAX_STR_COUNT), \"change encoding of distance\");\n-            return dist;\n-          }\n-          fatal(\"Address \" INTPTR_FORMAT \" for runtime target '%s+%d' is missing in SCA table\", p2i(addr), func_name, offset);\n-        } else {\n-          os::print_location(tty, p2i(addr), true);\n-          reloc.print_current_on(tty);\n-#ifndef PRODUCT\n-          buffer->print_on(tty);\n-          buffer->decode();\n-#endif \/\/ !PRODUCT\n-          fatal(\"Address \" INTPTR_FORMAT \" for <unknown> is missing in SCA table\", p2i(addr));\n-        }\n-      } else {\n-        return _extrs_base + id;\n-      }\n-    }\n-  }\n-  return id;\n-}\n-\n-#undef _extrs_max\n-#undef _stubs_max\n-#undef _all_blobs_max\n-#undef _blobs_max\n-#undef _C1_blobs_max\n-#undef _C2_blobs_max\n-#undef _extrs_base\n-#undef _stubs_base\n-#undef _blobs_base\n-#undef _C1_blobs_base\n-#undef _C2_blobs_base\n-#undef _c_str_base\n-\n-void AOTRuntimeConstants::initialize_from_runtime() {\n-  BarrierSet* bs = BarrierSet::barrier_set();\n-  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n-    CardTableBarrierSet* ctbs = ((CardTableBarrierSet*)bs);\n-    _aot_runtime_constants._grain_shift = ctbs->grain_shift();\n-    _aot_runtime_constants._card_shift = ctbs->card_shift();\n-  }\n-}\n-\n-AOTRuntimeConstants AOTRuntimeConstants::_aot_runtime_constants;\n-\n-address AOTRuntimeConstants::_field_addresses_list[] = {\n-  grain_shift_address(),\n-  card_shift_address(),\n-  nullptr\n-};\n-\n-\n-void SCCache::wait_for_no_nmethod_readers() {\n-  while (true) {\n-    int cur = Atomic::load(&_nmethod_readers);\n-    int upd = -(cur + 1);\n-    if (cur >= 0 && Atomic::cmpxchg(&_nmethod_readers, cur, upd) == cur) {\n-      \/\/ Success, no new readers should appear.\n-      break;\n-    }\n-  }\n-\n-  \/\/ Now wait for all readers to leave.\n-  SpinYield w;\n-  while (Atomic::load(&_nmethod_readers) != -1) {\n-    w.wait();\n-  }\n-}\n-\n-SCCache::ReadingMark::ReadingMark() {\n-  while (true) {\n-    int cur = Atomic::load(&_nmethod_readers);\n-    if (cur < 0) {\n-      \/\/ Cache is already closed, cannot proceed.\n-      _failed = true;\n-      return;\n-    }\n-    if (Atomic::cmpxchg(&_nmethod_readers, cur, cur + 1) == cur) {\n-      \/\/ Successfully recorded ourselves as entered.\n-      _failed = false;\n-      return;\n-    }\n-  }\n-}\n-\n-SCCache::ReadingMark::~ReadingMark() {\n-  if (_failed) {\n-    return;\n-  }\n-  while (true) {\n-    int cur = Atomic::load(&_nmethod_readers);\n-    if (cur > 0) {\n-      \/\/ Cache is open, we are counting down towards 0.\n-      if (Atomic::cmpxchg(&_nmethod_readers, cur, cur - 1) == cur) {\n-        return;\n-      }\n-    } else {\n-      \/\/ Cache is closed, we are counting up towards -1.\n-      if (Atomic::cmpxchg(&_nmethod_readers, cur, cur + 1) == cur) {\n-        return;\n-      }\n-    }\n-  }\n-}\n","filename":"src\/hotspot\/share\/code\/SCCache.cpp","additions":0,"deletions":4770,"binary":false,"changes":4770,"status":"deleted"},{"patch":"@@ -1,783 +0,0 @@\n-\/*\n- * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_CODE_SCCACHE_HPP\n-#define SHARE_CODE_SCCACHE_HPP\n-\n-#include \"compiler\/compilerDefinitions.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"nmt\/memTag.hpp\"\n-#include \"oops\/oopsHierarchy.hpp\"\n-#include \"utilities\/exceptions.hpp\"\n-\n-\/*\n- * Startup Code Cache (SCC) collects compiled code and metadata during\n- * an application training runs.\n- * In following \"deployment\" runs this code can me loaded into\n- * Code Cache as normal nmethods skipping JIT compilation.\n- * In additoin special compiled code is generated with class initialization\n- * barriers which can be called on first Java method invocation.\n- *\/\n-\n-class AbstractCompiler;\n-class ciConstant;\n-class ciEnv;\n-class ciMethod;\n-class CodeBuffer;\n-class CodeOffsets;\n-class CompileTask;\n-class DebugInformationRecorder;\n-class Dependencies;\n-class ExceptionTable;\n-class ExceptionHandlerTable;\n-template<typename E>\n-class GrowableArray;\n-class ImmutableOopMapSet;\n-class ImplicitExceptionTable;\n-class JavaThread;\n-class Klass;\n-class methodHandle;\n-class Metadata;\n-class Method;\n-class nmethod;\n-class OopMapSet;\n-class OopRecorder;\n-class outputStream;\n-class RelocIterator;\n-class SCCache;\n-class StubCodeGenerator;\n-\n-enum class vmIntrinsicID : int;\n-\n-class SCConfig {\n-  uint _compressedOopShift;\n-  uint _compressedKlassShift;\n-  uint _contendedPaddingWidth;\n-  uint _objectAlignment;\n-  uint _gc;\n-  enum Flags {\n-    none                     = 0,\n-    metadataPointers         = 1,\n-    debugVM                  = 2,\n-    compressedOops           = 4,\n-    compressedClassPointers  = 8,\n-    useTLAB                  = 16,\n-    systemClassAssertions    = 32,\n-    userClassAssertions      = 64,\n-    enableContendedPadding   = 128,\n-    restrictContendedPadding = 256,\n-  };\n-  uint _flags;\n-\n-public:\n-  void record(bool use_meta_ptrs);\n-  bool verify() const;\n-\n-  bool has_meta_ptrs()  const { return (_flags & metadataPointers) != 0; }\n-};\n-\n-\/\/ Code Cache file header\n-class SCCHeader : public CHeapObj<mtCode> {\n-private:\n-  \/\/ Here should be version and other verification fields\n-  enum {\n-    SCC_VERSION = 1\n-  };\n-  uint _version;           \/\/ SCC version (should match when reading code cache)\n-  uint _cache_size;        \/\/ cache size in bytes\n-  uint _strings_count;\n-  uint _strings_offset;    \/\/ offset to recorded C strings\n-  uint _entries_count;     \/\/ number of recorded entries in cache\n-  uint _entries_offset;    \/\/ offset of SCCEntry array describing entries\n-  uint _preload_entries_count; \/\/ entries for pre-loading code\n-  uint _preload_entries_offset;\n-  SCConfig _config;\n-\n-public:\n-  void init(uint cache_size,\n-            uint strings_count, uint strings_offset,\n-            uint entries_count, uint entries_offset,\n-            uint preload_entries_count, uint preload_entries_offset,\n-            bool use_meta_ptrs) {\n-    _version        = SCC_VERSION;\n-    _cache_size     = cache_size;\n-    _strings_count  = strings_count;\n-    _strings_offset = strings_offset;\n-    _entries_count  = entries_count;\n-    _entries_offset = entries_offset;\n-    _preload_entries_count  = preload_entries_count;\n-    _preload_entries_offset = preload_entries_offset;\n-\n-    _config.record(use_meta_ptrs);\n-  }\n-\n-  uint cache_size()     const { return _cache_size; }\n-  uint strings_count()  const { return _strings_count; }\n-  uint strings_offset() const { return _strings_offset; }\n-  uint entries_count()  const { return _entries_count; }\n-  uint entries_offset() const { return _entries_offset; }\n-  uint preload_entries_count()  const { return _preload_entries_count; }\n-  uint preload_entries_offset() const { return _preload_entries_offset; }\n-  bool has_meta_ptrs()  const { return _config.has_meta_ptrs(); }\n-\n-  bool verify_config(uint load_size)  const;\n-  bool verify_vm_config() const { \/\/ Called after Universe initialized\n-    return _config.verify();\n-  }\n-};\n-\n-#define DO_SCCENTRY_KIND(Fn) \\\n-  Fn(None) \\\n-  Fn(Adapter) \\\n-  Fn(Stub) \\\n-  Fn(Blob) \\\n-  Fn(Code) \\\n-\n-\/\/ Code Cache's entry contain information from CodeBuffer\n-class SCCEntry {\n-public:\n-  enum Kind : s1 {\n-#define DECL_KIND_ENUM(kind) kind,\n-    DO_SCCENTRY_KIND(DECL_KIND_ENUM)\n-#undef DECL_KIND_ENUM\n-    Kind_count\n-  };\n-\n-private:\n-  SCCEntry* _next;\n-  Method*   _method;\n-  Kind   _kind;        \/\/\n-  uint   _id;          \/\/ vmIntrinsic::ID for stub or name's hash for nmethod\n-\n-  uint   _offset;      \/\/ Offset to entry\n-  uint   _size;        \/\/ Entry size\n-  uint   _name_offset; \/\/ Method's or intrinsic name\n-  uint   _name_size;\n-  uint   _code_offset; \/\/ Start of code in cache\n-  uint   _code_size;   \/\/ Total size of all code sections\n-  uint   _reloc_offset;\/\/ Relocations\n-  uint   _reloc_size;  \/\/ Max size of relocations per code section\n-  uint   _num_inlined_bytecodes;\n-\n-  uint   _comp_level;  \/\/ compilation level\n-  uint   _comp_id;     \/\/ compilation id\n-  uint   _decompile;   \/\/ Decompile count for this nmethod\n-  bool   _has_clinit_barriers; \/\/ Generated code has class init checks\n-  bool   _for_preload; \/\/ Code can be used for preload\n-  bool   _loaded;      \/\/ Code was loaded\n-  bool   _not_entrant; \/\/ Deoptimized\n-  bool   _load_fail;   \/\/ Failed to load due to some klass state\n-  bool   _ignore_decompile; \/\/ ignore decompile counter if compilation is done\n-                            \/\/ during \"assembly\" phase without running application\n-  address _dumptime_content_start_addr;\n-public:\n-  SCCEntry(uint offset, uint size, uint name_offset, uint name_size,\n-           uint code_offset, uint code_size,\n-           uint reloc_offset, uint reloc_size,\n-           Kind kind, uint id,\n-           address dumptime_content_start_addr = nullptr,\n-           uint comp_level = 0,\n-           uint comp_id = 0, uint decomp = 0,\n-           bool has_clinit_barriers = false,\n-           bool for_preload = false,\n-           bool ignore_decompile = false) {\n-    _next         = nullptr;\n-    _method       = nullptr;\n-    _kind         = kind;\n-    _id           = id;\n-\n-    _offset       = offset;\n-    _size         = size;\n-    _name_offset  = name_offset;\n-    _name_size    = name_size;\n-    _code_offset  = code_offset;\n-    _code_size    = code_size;\n-    _reloc_offset = reloc_offset;\n-    _reloc_size   = reloc_size;\n-\n-    _dumptime_content_start_addr = dumptime_content_start_addr;\n-\n-    _num_inlined_bytecodes = 0;\n-\n-    _comp_level   = comp_level;\n-    _comp_id      = comp_id;\n-    _decompile    = decomp;\n-    _has_clinit_barriers = has_clinit_barriers;\n-    _for_preload  = for_preload;\n-    _loaded       = false;\n-    _not_entrant  = false;\n-    _load_fail    = false;\n-    _ignore_decompile = ignore_decompile;\n-  }\n-  void* operator new(size_t x, SCCache* cache);\n-  \/\/ Delete is a NOP\n-  void operator delete( void *ptr ) {}\n-\n-  bool is_adapter() { return _kind == Adapter; }\n-  bool is_stub() { return _kind == Stub; }\n-  bool is_blob() { return _kind == Blob; }\n-  bool is_code() { return _kind == Code; }\n-\n-  SCCEntry* next()    const { return _next; }\n-  void set_next(SCCEntry* next) { _next = next; }\n-\n-  Method*   method()  const { return _method; }\n-  void set_method(Method* method) { _method = method; }\n-  void update_method_for_writing();\n-\n-  Kind kind()         const { return _kind; }\n-  uint id()           const { return _id; }\n-\n-  uint offset()       const { return _offset; }\n-  void set_offset(uint off) { _offset = off; }\n-\n-  uint size()         const { return _size; }\n-  uint name_offset()  const { return _name_offset; }\n-  uint name_size()    const { return _name_size; }\n-  uint code_offset()  const { return _code_offset; }\n-  uint code_size()    const { return _code_size; }\n-  uint reloc_offset() const { return _reloc_offset; }\n-  uint reloc_size()   const { return _reloc_size; }\n-\n-  address dumptime_content_start_addr() const { return _dumptime_content_start_addr; }\n-\n-  uint num_inlined_bytecodes() const { return _num_inlined_bytecodes; }\n-  void set_inlined_bytecodes(int bytes) { _num_inlined_bytecodes = bytes; }\n-\n-  uint comp_level()   const { return _comp_level; }\n-  uint comp_id()      const { return _comp_id; }\n-\n-  uint decompile()    const { return _decompile; }\n-  bool has_clinit_barriers() const { return _has_clinit_barriers; }\n-  bool for_preload()  const { return _for_preload; }\n-  bool is_loaded()    const { return _loaded; }\n-  void set_loaded()         { _loaded = true; }\n-  bool ignore_decompile() const { return _ignore_decompile; }\n-\n-  bool not_entrant()  const { return _not_entrant; }\n-  void set_not_entrant()    { _not_entrant = true; }\n-  void set_entrant()        { _not_entrant = false; }\n-\n-  bool load_fail()  const { return _load_fail; }\n-  void set_load_fail()    { _load_fail = true; }\n-\n-  void print(outputStream* st) const;\n-};\n-\n-\/\/ Addresses of stubs, blobs and runtime finctions called from compiled code.\n-class SCAddressTable : public CHeapObj<mtCode> {\n-private:\n-  address* _extrs_addr;\n-  address* _stubs_addr;\n-  address* _blobs_addr;\n-  address* _C1_blobs_addr;\n-  address* _C2_blobs_addr;\n-  uint     _extrs_length;\n-  uint     _stubs_length;\n-  uint     _blobs_length;\n-  uint     _C1_blobs_length;\n-  uint     _C2_blobs_length;\n-\n-  bool _extrs_complete;\n-  bool _early_stubs_complete;\n-  bool _shared_blobs_complete;\n-  bool _complete;\n-  bool _opto_complete;\n-  bool _c1_complete;\n-\n-public:\n-  SCAddressTable() {\n-    _extrs_addr = nullptr;\n-    _stubs_addr = nullptr;\n-    _blobs_addr = nullptr;\n-    _extrs_complete = false;\n-    _early_stubs_complete = false;\n-    _shared_blobs_complete = false;\n-    _complete = false;\n-    _opto_complete = false;\n-    _c1_complete = false;\n-  }\n-  ~SCAddressTable();\n-  void init_extrs();\n-  void init_early_stubs();\n-  void init_shared_blobs();\n-  void init_stubs();\n-  void init_opto();\n-  void init_c1();\n-  void add_C_string(const char* str);\n-  int  id_for_C_string(address str);\n-  address address_for_C_string(int idx);\n-  int  id_for_address(address addr, RelocIterator iter, CodeBuffer* buffer);\n-  address address_for_id(int id);\n-  bool opto_complete() const { return _opto_complete; }\n-  bool c1_complete() const { return _c1_complete; }\n-};\n-\n-struct SCCodeSection {\n-public:\n-  address _origin_address;\n-  uint _size;\n-  uint _offset;\n-};\n-\n-enum class DataKind: int {\n-  No_Data   = -1,\n-  Null      = 0,\n-  Klass     = 1,\n-  Method    = 2,\n-  String    = 3,\n-  Primitive = 4, \/\/ primitive Class object\n-  SysLoader = 5, \/\/ java_system_loader\n-  PlaLoader = 6, \/\/ java_platform_loader\n-  MethodCnts= 7,\n-  Klass_Shared  = 8,\n-  Method_Shared = 9,\n-  String_Shared = 10,\n-  MH_Oop_Shared = 11\n-};\n-\n-class SCCache;\n-\n-class SCCReader { \/\/ Concurent per compilation request\n-private:\n-  const SCCache*  _cache;\n-  const SCCEntry* _entry;\n-  const char*     _load_buffer; \/\/ Loaded cached code buffer\n-  uint  _read_position;            \/\/ Position in _load_buffer\n-  uint  read_position() const { return _read_position; }\n-  void  set_read_position(uint pos);\n-  const char* addr(uint offset) const { return _load_buffer + offset; }\n-\n-  uint _compile_id;\n-  uint _comp_level;\n-  uint compile_id() const { return _compile_id; }\n-  uint comp_level() const { return _comp_level; }\n-\n-  bool _preload;             \/\/ Preloading code before method execution\n-  bool _lookup_failed;       \/\/ Failed to lookup for info (skip only this code load)\n-  void set_lookup_failed()     { _lookup_failed = true; }\n-  void clear_lookup_failed()   { _lookup_failed = false; }\n-  bool lookup_failed()   const { return _lookup_failed; }\n-\n-public:\n-  SCCReader(SCCache* cache, SCCEntry* entry, CompileTask* task);\n-\n-  SCCEntry* scc_entry() { return (SCCEntry*)_entry; }\n-\n-  \/\/ convenience method to convert offset in SCCEntry data to its address\n-  bool compile_nmethod(ciEnv* env, ciMethod* target, AbstractCompiler* compiler);\n-  bool compile_blob(CodeBuffer* buffer, int* pc_offset);\n-\n-  bool compile_adapter(CodeBuffer* buffer, const char* name, uint32_t offsets[4]);\n-\n-  Klass* read_klass(const methodHandle& comp_method, bool shared);\n-  Method* read_method(const methodHandle& comp_method, bool shared);\n-\n-  bool read_code(CodeBuffer* buffer, CodeBuffer* orig_buffer, uint code_offset);\n-  bool read_relocations(CodeBuffer* buffer, CodeBuffer* orig_buffer, OopRecorder* oop_recorder, ciMethod* target);\n-  DebugInformationRecorder* read_debug_info(OopRecorder* oop_recorder);\n-  OopMapSet* read_oop_maps();\n-  bool read_dependencies(Dependencies* dependencies);\n-\n-  oop read_oop(JavaThread* thread, const methodHandle& comp_method);\n-  Metadata* read_metadata(const methodHandle& comp_method);\n-  bool read_oops(OopRecorder* oop_recorder, ciMethod* target);\n-  bool read_metadata(OopRecorder* oop_recorder, ciMethod* target);\n-\n-  bool read_oop_metadata_list(JavaThread* thread, ciMethod* target, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list, OopRecorder* oop_recorder);\n-  void apply_relocations(nmethod* nm, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list) NOT_CDS_RETURN;\n-\n-  ImmutableOopMapSet* read_oop_map_set();\n-\n-  void print_on(outputStream* st);\n-};\n-\n-class SCCache : public CHeapObj<mtCode> {\n-private:\n-  SCCHeader*  _load_header;\n-  char*       _load_buffer;    \/\/ Aligned buffer for loading cached code\n-  char*       _store_buffer;   \/\/ Aligned buffer for storing cached code\n-  char*       _C_store_buffer; \/\/ Original unaligned buffer\n-\n-  uint        _write_position; \/\/ Position in _store_buffer\n-  uint        _load_size;      \/\/ Used when reading cache\n-  uint        _store_size;     \/\/ Used when writing cache\n-  bool _for_read;              \/\/ Open for read\n-  bool _for_write;             \/\/ Open for write\n-  bool _use_meta_ptrs;         \/\/ Store metadata pointers\n-  bool _for_preload;           \/\/ Code for preload\n-  bool _gen_preload_code;      \/\/ Generate pre-loading code\n-  bool _has_clinit_barriers;   \/\/ Code with clinit barriers\n-  bool _closing;               \/\/ Closing cache file\n-  bool _failed;                \/\/ Failed read\/write to\/from cache (cache is broken?)\n-\n-  SCAddressTable* _table;\n-\n-  SCCEntry* _load_entries;     \/\/ Used when reading cache\n-  uint*     _search_entries;   \/\/ sorted by ID table [id, index]\n-  SCCEntry* _store_entries;    \/\/ Used when writing cache\n-  const char* _C_strings_buf;  \/\/ Loaded buffer for _C_strings[] table\n-  uint      _store_entries_cnt;\n-\n-  uint _compile_id;\n-  uint _comp_level;\n-  uint compile_id() const { return _compile_id; }\n-  uint comp_level() const { return _comp_level; }\n-\n-  static SCCache* open_for_read();\n-  static SCCache* open_for_write();\n-\n-  bool set_write_position(uint pos);\n-  bool align_write();\n-  uint write_bytes(const void* buffer, uint nbytes);\n-  const char* addr(uint offset) const { return _load_buffer + offset; }\n-\n-  static SCAddressTable* addr_table() {\n-    return is_on() && (cache()->_table != nullptr) ? cache()->_table : nullptr;\n-  }\n-\n-  bool _lookup_failed;       \/\/ Failed to lookup for info (skip only this code load)\n-  void set_lookup_failed()     { _lookup_failed = true; }\n-  void clear_lookup_failed()   { _lookup_failed = false; }\n-  bool lookup_failed()   const { return _lookup_failed; }\n-\n-  address reserve_bytes(uint nbytes);\n-\n-  SCCEntry* write_nmethod(nmethod* nm, bool for_preload);\n-\n-  \/\/ States:\n-  \/\/   S >= 0: allow new readers, S readers are currently active\n-  \/\/   S <  0: no new readers are allowed; (-S-1) readers are currently active\n-  \/\/     (special case: S = -1 means no readers are active, and would never be active again)\n-  static volatile int _nmethod_readers;\n-\n-  static void wait_for_no_nmethod_readers();\n-\n-  class ReadingMark {\n-  private:\n-    bool _failed;\n-  public:\n-    ReadingMark();\n-    ~ReadingMark();\n-    bool failed() {\n-      return _failed;\n-    }\n-  };\n-\n-public:\n-  SCCache();\n-  ~SCCache();\n-\n-  const char* cache_buffer() const { return _load_buffer; }\n-  bool failed() const { return _failed; }\n-  void set_failed()   { _failed = true; }\n-\n-  static bool is_address_in_aot_cache(address p) NOT_CDS_RETURN_(false);\n-  static uint max_aot_code_size();\n-\n-  uint load_size() const { return _load_size; }\n-  uint write_position() const { return _write_position; }\n-\n-  void load_strings();\n-  int store_strings();\n-\n-  static void init_extrs_table() NOT_CDS_RETURN;\n-  static void init_early_stubs_table() NOT_CDS_RETURN;\n-  static void init_shared_blobs_table() NOT_CDS_RETURN;\n-  static void init_stubs_table() NOT_CDS_RETURN;\n-  static void init_opto_table() NOT_CDS_RETURN;\n-  static void init_c1_table() NOT_CDS_RETURN;\n-  address address_for_id(int id) const { return _table->address_for_id(id); }\n-\n-  bool for_read()  const { return _for_read  && !_failed; }\n-  bool for_write() const { return _for_write && !_failed; }\n-\n-  bool closing()          const { return _closing; }\n-  bool use_meta_ptrs()    const { return _use_meta_ptrs; }\n-  bool gen_preload_code() const { return _gen_preload_code; }\n-\n-  void add_new_C_string(const char* str);\n-\n-  SCCEntry* add_entry() {\n-    _store_entries_cnt++;\n-    _store_entries -= 1;\n-    return _store_entries;\n-  }\n-  void preload_startup_code(TRAPS);\n-\n-  SCCEntry* find_entry(SCCEntry::Kind kind, uint id, uint comp_level = 0, uint decomp = 0);\n-  void invalidate_entry(SCCEntry* entry);\n-\n-  bool finish_write();\n-\n-  void log_stats_on_exit();\n-\n-  static bool load_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) NOT_CDS_RETURN_(false);\n-  static bool store_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) NOT_CDS_RETURN_(false);\n-\n-  bool write_klass(Klass* klass);\n-  bool write_method(Method* method);\n-\n-  bool write_code(CodeBuffer* buffer, uint& code_size);\n-  bool write_relocations(CodeBuffer* buffer, uint& reloc_size);\n-  bool write_debug_info(DebugInformationRecorder* recorder);\n-  bool write_oop_maps(OopMapSet* oop_maps);\n-\n-  bool write_oop_map_set(nmethod* nm);\n-  bool write_nmethod_reloc_immediates(GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list);\n-  bool write_nmethod_loadtime_relocations(JavaThread* thread, nmethod* nm, GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list);\n-\n-  jobject read_oop(JavaThread* thread, const methodHandle& comp_method);\n-  Metadata* read_metadata(const methodHandle& comp_method);\n-  bool read_oops(OopRecorder* oop_recorder, ciMethod* target);\n-  bool read_metadata(OopRecorder* oop_recorder, ciMethod* target);\n-\n-  bool write_oop(jobject& jo);\n-  bool write_oop(oop obj);\n-  bool write_oops(OopRecorder* oop_recorder);\n-  bool write_metadata(Metadata* m);\n-  bool write_metadata(OopRecorder* oop_recorder);\n-  bool write_oops(nmethod* nm);\n-  bool write_metadata(nmethod* nm);\n-\n-  static bool load_exception_blob(CodeBuffer* buffer, int* pc_offset) NOT_CDS_RETURN_(false);\n-  static bool store_exception_blob(CodeBuffer* buffer, int pc_offset) NOT_CDS_RETURN_(false);\n-\n-  static bool load_adapter(CodeBuffer* buffer, uint32_t id, const char* basic_sig, uint32_t offsets[4]) NOT_CDS_RETURN_(false);\n-  static bool store_adapter(CodeBuffer* buffer, uint32_t id, const char* basic_sig, uint32_t offsets[4]) NOT_CDS_RETURN_(false);\n-\n-  static bool load_nmethod(ciEnv* env, ciMethod* target, int entry_bci, AbstractCompiler* compiler, CompLevel comp_level) NOT_CDS_RETURN_(false);\n-  static SCCEntry* store_nmethod(nmethod* nm, AbstractCompiler* compiler, bool for_preload) NOT_CDS_RETURN_(nullptr);\n-\n-  static uint store_entries_cnt() {\n-    if (is_on_for_write()) {\n-      return cache()->_store_entries_cnt;\n-    }\n-    return -1;\n-  }\n-\n-\/\/ Static access\n-\n-private:\n-  static SCCache*  _cache;\n-\n-  static bool open_cache();\n-  static bool verify_vm_config() {\n-    if (is_on_for_read()) {\n-      return _cache->_load_header->verify_vm_config();\n-    }\n-    return true;\n-  }\n-public:\n-  static SCCache* cache() { return _cache; }\n-  static void initialize() NOT_CDS_RETURN;\n-  static void init2() NOT_CDS_RETURN;\n-  static void close() NOT_CDS_RETURN;\n-  static bool is_on() CDS_ONLY({ return _cache != nullptr && !_cache->closing(); }) NOT_CDS_RETURN_(false);\n-  static bool is_C3_on() NOT_CDS_RETURN_(false);\n-  static bool is_code_load_thread_on() NOT_CDS_RETURN_(false);\n-  static bool is_on_for_read()  { return is_on() && _cache->for_read(); }\n-  static bool is_on_for_write() { return is_on() && _cache->for_write(); }\n-  static bool gen_preload_code(ciMethod* m, int entry_bci);\n-  static bool allow_const_field(ciConstant& value) NOT_CDS_RETURN_(false);\n-  static void invalidate(SCCEntry* entry) NOT_CDS_RETURN;\n-  static bool is_loaded(SCCEntry* entry);\n-  static SCCEntry* find_code_entry(const methodHandle& method, uint comp_level);\n-  static void preload_code(JavaThread* thread);\n-\n-  template<typename Function>\n-  static void iterate(Function function) { \/\/ lambda enabled API\n-    SCCache* cache = open_for_read();\n-    if (cache != nullptr) {\n-      ReadingMark rdmk;\n-      if (rdmk.failed()) {\n-        \/\/ Cache is closed, cannot touch anything.\n-        return;\n-      }\n-\n-      uint count = cache->_load_header->entries_count();\n-      uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n-      SCCEntry* load_entries = (SCCEntry*)(search_entries + 2 * count);\n-\n-      for (uint i = 0; i < count; i++) {\n-        int index = search_entries[2*i + 1];\n-        SCCEntry* entry = &(load_entries[index]);\n-        function(entry);\n-      }\n-    }\n-  }\n-\n-  static void add_C_string(const char* str) NOT_CDS_RETURN;\n-\n-  static void print_on(outputStream* st) NOT_CDS_RETURN;\n-  static void print_statistics_on(outputStream* st) NOT_CDS_RETURN;\n-  static void print_timers_on(outputStream* st) NOT_CDS_RETURN;\n-  static void print_unused_entries_on(outputStream* st) NOT_CDS_RETURN;\n-};\n-\n-\/\/ +1 for preload code\n-const int AOTCompLevel_count = CompLevel_count + 1; \/\/ 6 levels indexed from 0 to 5\n-\n-struct AOTCodeStats {\n-private:\n-  struct {\n-    uint _kind_cnt[SCCEntry::Kind_count];\n-    uint _nmethod_cnt[AOTCompLevel_count];\n-    uint _clinit_barriers_cnt;\n-  } ccstats; \/\/ ccstats = cached code stats\n-\n-  void check_kind(uint kind) { assert(kind >= SCCEntry::None && kind < SCCEntry::Kind_count, \"Invalid SCCEntry kind %d\", kind); }\n-  void check_complevel(uint lvl) { assert(lvl >= CompLevel_none && lvl < AOTCompLevel_count, \"Invalid compilation level %d\", lvl); }\n-\n-public:\n-  void inc_entry_cnt(uint kind) { check_kind(kind); ccstats._kind_cnt[kind] += 1; }\n-  void inc_nmethod_cnt(uint lvl) { check_complevel(lvl); ccstats._nmethod_cnt[lvl] += 1; }\n-  void inc_preload_cnt() { ccstats._nmethod_cnt[AOTCompLevel_count-1] += 1; }\n-  void inc_clinit_barriers_cnt() { ccstats._clinit_barriers_cnt += 1; }\n-\n-  void collect_entry_stats(SCCEntry* entry) {\n-    inc_entry_cnt(entry->kind());\n-    if (entry->is_code()) {\n-      entry->for_preload() ? inc_nmethod_cnt(AOTCompLevel_count-1)\n-                           : inc_nmethod_cnt(entry->comp_level());\n-      if (entry->has_clinit_barriers()) {\n-        inc_clinit_barriers_cnt();\n-      }\n-    }\n-  }\n-\n-  uint entry_count(uint kind) { check_kind(kind); return ccstats._kind_cnt[kind]; }\n-  uint nmethod_count(uint lvl) { check_complevel(lvl); return ccstats._nmethod_cnt[lvl]; }\n-  uint preload_count() { return ccstats._nmethod_cnt[AOTCompLevel_count-1]; }\n-  uint clinit_barriers_count() { return ccstats._clinit_barriers_cnt; }\n-\n-  uint total_count() {\n-    uint total = 0;\n-    for (int kind = SCCEntry::None; kind < SCCEntry::Kind_count; kind++) {\n-      total += ccstats._kind_cnt[kind];\n-    }\n-    return total;\n-  }\n-\n-  static AOTCodeStats add_cached_code_stats(AOTCodeStats stats1, AOTCodeStats stats2);\n-\n-  \/\/ Runtime stats of the AOT code\n-private:\n-  struct {\n-    struct {\n-      uint _loaded_cnt;\n-      uint _invalidated_cnt;\n-      uint _load_failed_cnt;\n-    } _entry_kinds[SCCEntry::Kind_count],\n-      _nmethods[AOTCompLevel_count];\n-  } rs; \/\/ rs = runtime stats\n-\n-public:\n-  void inc_entry_loaded_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._loaded_cnt += 1; }\n-  void inc_entry_invalidated_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._invalidated_cnt += 1; }\n-  void inc_entry_load_failed_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._load_failed_cnt += 1; }\n-\n-  void inc_nmethod_loaded_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._loaded_cnt += 1; }\n-  void inc_nmethod_invalidated_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._invalidated_cnt += 1; }\n-  void inc_nmethod_load_failed_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._load_failed_cnt += 1; }\n-\n-  uint entry_loaded_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._loaded_cnt; }\n-  uint entry_invalidated_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._invalidated_cnt; }\n-  uint entry_load_failed_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._load_failed_cnt; }\n-\n-  uint nmethod_loaded_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._loaded_cnt; }\n-  uint nmethod_invalidated_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._invalidated_cnt; }\n-  uint nmethod_load_failed_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._load_failed_cnt; }\n-\n-  void inc_loaded_cnt(SCCEntry* entry) {\n-    inc_entry_loaded_cnt(entry->kind());\n-    if (entry->is_code()) {\n-      entry->for_preload() ? inc_nmethod_loaded_cnt(AOTCompLevel_count-1)\n-                           : inc_nmethod_loaded_cnt(entry->comp_level());\n-    }\n-  }\n-\n-  void inc_invalidated_cnt(SCCEntry* entry) {\n-    inc_entry_invalidated_cnt(entry->kind());\n-    if (entry->is_code()) {\n-      entry->for_preload() ? inc_nmethod_invalidated_cnt(AOTCompLevel_count-1)\n-                           : inc_nmethod_invalidated_cnt(entry->comp_level());\n-    }\n-  }\n-\n-  void inc_load_failed_cnt(SCCEntry* entry) {\n-    inc_entry_load_failed_cnt(entry->kind());\n-    if (entry->is_code()) {\n-      entry->for_preload() ? inc_nmethod_load_failed_cnt(AOTCompLevel_count-1)\n-                           : inc_nmethod_load_failed_cnt(entry->comp_level());\n-    }\n-  }\n-\n-  void collect_entry_runtime_stats(SCCEntry* entry) {\n-    if (entry->is_loaded()) {\n-      inc_loaded_cnt(entry);\n-    }\n-    if (entry->not_entrant()) {\n-      inc_invalidated_cnt(entry);\n-    }\n-    if (entry->load_fail()) {\n-      inc_load_failed_cnt(entry);\n-    }\n-  }\n-\n-  void collect_all_stats(SCCEntry* entry) {\n-    collect_entry_stats(entry);\n-    collect_entry_runtime_stats(entry);\n-  }\n-\n-  AOTCodeStats() {\n-    memset(this, 0, sizeof(AOTCodeStats));\n-  }\n-};\n-\n-\/\/ code cache internal runtime constants area used by AOT code\n-class AOTRuntimeConstants {\n- friend class SCCache;\n-  uint _grain_shift;\n-  uint _card_shift;\n-  static address _field_addresses_list[];\n-  static AOTRuntimeConstants _aot_runtime_constants;\n-  \/\/ private constructor for unique singleton\n-  AOTRuntimeConstants() { }\n-  \/\/ private for use by friend class SCCache\n-  static void initialize_from_runtime();\n- public:\n-  static bool contains(address adr) {\n-    address base = (address)&_aot_runtime_constants;\n-    address hi = base + sizeof(AOTRuntimeConstants);\n-    return (base <= adr && adr < hi);\n-  }\n-  static address grain_shift_address() { return (address)&_aot_runtime_constants._grain_shift; }\n-  static address card_shift_address() { return (address)&_aot_runtime_constants._card_shift; }\n-  static address* field_addresses_list() {\n-    return _field_addresses_list;\n-  }\n-};\n-\n-#endif \/\/ SHARE_CODE_SCCACHE_HPP\n","filename":"src\/hotspot\/share\/code\/SCCache.hpp","additions":0,"deletions":783,"binary":false,"changes":783,"status":"deleted"},{"patch":"@@ -0,0 +1,4770 @@\n+\/*\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"asm\/macroAssembler.hpp\"\n+#include \"asm\/codeBuffer.hpp\"\n+#include \"cds\/cdsAccess.hpp\"\n+#include \"cds\/cdsConfig.hpp\"\n+#include \"cds\/heapShared.hpp\"\n+#include \"cds\/metaspaceShared.hpp\"\n+#include \"ci\/ciConstant.hpp\"\n+#include \"ci\/ciEnv.hpp\"\n+#include \"ci\/ciField.hpp\"\n+#include \"ci\/ciMethod.hpp\"\n+#include \"ci\/ciMethodData.hpp\"\n+#include \"ci\/ciObject.hpp\"\n+#include \"ci\/ciUtilities.inline.hpp\"\n+#include \"classfile\/javaAssertions.hpp\"\n+#include \"classfile\/stringTable.hpp\"\n+#include \"classfile\/symbolTable.hpp\"\n+#include \"classfile\/systemDictionary.hpp\"\n+#include \"classfile\/vmClasses.hpp\"\n+#include \"classfile\/vmIntrinsics.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n+#include \"code\/codeBlob.hpp\"\n+#include \"code\/codeCache.hpp\"\n+#include \"code\/oopRecorder.inline.hpp\"\n+#include \"compiler\/abstractCompiler.hpp\"\n+#include \"compiler\/compilationPolicy.hpp\"\n+#include \"compiler\/compileBroker.hpp\"\n+#include \"compiler\/compileTask.hpp\"\n+#include \"gc\/g1\/g1BarrierSetRuntime.hpp\"\n+#include \"gc\/shared\/gcConfig.hpp\"\n+#include \"logging\/logStream.hpp\"\n+#include \"memory\/memoryReserver.hpp\"\n+#include \"memory\/universe.hpp\"\n+#include \"oops\/klass.inline.hpp\"\n+#include \"oops\/method.inline.hpp\"\n+#include \"oops\/trainingData.hpp\"\n+#include \"prims\/jvmtiThreadState.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/flags\/flagSetting.hpp\"\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/handles.inline.hpp\"\n+#include \"runtime\/java.hpp\"\n+#include \"runtime\/jniHandles.inline.hpp\"\n+#include \"runtime\/os.inline.hpp\"\n+#include \"runtime\/sharedRuntime.hpp\"\n+#include \"runtime\/stubCodeGenerator.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n+#include \"runtime\/timerTrace.hpp\"\n+#include \"runtime\/threadIdentifier.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+#include \"utilities\/spinYield.hpp\"\n+#ifdef COMPILER1\n+#include \"c1\/c1_Runtime1.hpp\"\n+#include \"c1\/c1_LIRAssembler.hpp\"\n+#include \"gc\/shared\/c1\/barrierSetC1.hpp\"\n+#include \"gc\/g1\/c1\/g1BarrierSetC1.hpp\"\n+#if INCLUDE_SHENANDOAHGC\n+#include \"gc\/shenandoah\/c1\/shenandoahBarrierSetC1.hpp\"\n+#endif\n+#include \"gc\/z\/c1\/zBarrierSetC1.hpp\"\n+#endif\n+#ifdef COMPILER2\n+#include \"opto\/runtime.hpp\"\n+#endif\n+#if INCLUDE_JVMCI\n+#include \"jvmci\/jvmci.hpp\"\n+#endif\n+#if INCLUDE_SHENANDOAHGC\n+#include \"gc\/shenandoah\/shenandoahRuntime.hpp\"\n+#endif\n+\n+#include <sys\/stat.h>\n+#include <errno.h>\n+\n+#ifndef O_BINARY       \/\/ if defined (Win32) use binary files.\n+#define O_BINARY 0     \/\/ otherwise do nothing.\n+#endif\n+\n+const char* aot_code_entry_kind_name[] = {\n+#define DECL_KIND_STRING(kind) XSTR(kind),\n+  DO_AOTCODEENTRY_KIND(DECL_KIND_STRING)\n+#undef DECL_KIND_STRING\n+};\n+\n+static elapsedTimer _t_totalLoad;\n+static elapsedTimer _t_totalRegister;\n+static elapsedTimer _t_totalFind;\n+static elapsedTimer _t_totalStore;\n+\n+AOTCodeCache* AOTCodeCache::_cache = nullptr;\n+\n+static bool enable_timers() {\n+  return CITime || log_is_enabled(Info, init);\n+}\n+\n+static void exit_vm_on_load_failure() {\n+  \/\/ Treat AOTCodeCache warnings as error when RequireSharedSpaces is on.\n+  if (RequireSharedSpaces) {\n+    vm_exit_during_initialization(\"Unable to use AOT Code Cache.\", nullptr);\n+  }\n+}\n+\n+static void exit_vm_on_store_failure() {\n+  \/\/ Treat AOTCodeCache warnings as error when RequireSharedSpaces is on.\n+  if (RequireSharedSpaces) {\n+    tty->print_cr(\"Unable to create startup cached code.\");\n+    \/\/ Failure during AOT code caching, we don't want to dump core\n+    vm_abort(false);\n+  }\n+}\n+\n+uint AOTCodeCache::max_aot_code_size() {\n+  return (uint)CachedCodeMaxSize;\n+}\n+\n+void AOTCodeCache::initialize() {\n+  if (LoadCachedCode && !UseSharedSpaces) {\n+    return;\n+  }\n+  if (LoadCachedCode && CDSAccess::get_cached_code_size() == 0) {\n+    LoadCachedCode = false;\n+    return;\n+  }\n+  if (StoreCachedCode || LoadCachedCode) {\n+    if (FLAG_IS_DEFAULT(ClassInitBarrierMode)) {\n+      FLAG_SET_DEFAULT(ClassInitBarrierMode, 1);\n+    }\n+  } else if (ClassInitBarrierMode > 0) {\n+    log_info(aot, codecache, init)(\"Set ClassInitBarrierMode to 0 because StoreCachedCode and LoadCachedCode are false.\");\n+    FLAG_SET_DEFAULT(ClassInitBarrierMode, 0);\n+  }\n+  if (LoadCachedCode || StoreCachedCode) {\n+    if (!open_cache()) {\n+      exit_vm_on_load_failure();\n+      return;\n+    }\n+    if (StoreCachedCode) {\n+      FLAG_SET_DEFAULT(FoldStableValues, false);\n+      FLAG_SET_DEFAULT(ForceUnreachable, true);\n+    }\n+    FLAG_SET_DEFAULT(DelayCompilerStubsGeneration, false);\n+  }\n+}\n+\n+void AOTCodeCache::init2() {\n+  if (!is_on()) {\n+    return;\n+  }\n+  \/\/ After Universe initialized\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n+    address byte_map_base = ci_card_table_address_as<address>();\n+    if (is_on_for_write() && !external_word_Relocation::can_be_relocated(byte_map_base)) {\n+      \/\/ Bail out since we can't encode card table base address with relocation\n+      log_warning(aot, codecache, init)(\"Can't create AOT Code Cache because card table base address is not relocatable: \" INTPTR_FORMAT, p2i(byte_map_base));\n+      close();\n+      exit_vm_on_load_failure();\n+    }\n+  }\n+  \/\/ initialize aot runtime constants as appropriate to this runtime\n+  AOTRuntimeConstants::initialize_from_runtime();\n+\n+  if (!verify_vm_config()) {\n+    close();\n+    exit_vm_on_load_failure();\n+  }\n+\n+  \/\/ initialize the table of external routines so we can save\n+  \/\/ generated code blobs that reference them\n+  init_extrs_table();\n+  \/\/ initialize the table of initial stubs so we can save\n+  \/\/ generated code blobs that reference them\n+  init_early_stubs_table();\n+}\n+\n+void AOTCodeCache::print_timers_on(outputStream* st) {\n+  if (LoadCachedCode) {\n+    st->print_cr (\"    SC Load Time:         %7.3f s\", _t_totalLoad.seconds());\n+    st->print_cr (\"      nmethod register:     %7.3f s\", _t_totalRegister.seconds());\n+    st->print_cr (\"      find cached code:     %7.3f s\", _t_totalFind.seconds());\n+  }\n+  if (StoreCachedCode) {\n+    st->print_cr (\"    SC Store Time:        %7.3f s\", _t_totalStore.seconds());\n+  }\n+}\n+\n+bool AOTCodeCache::is_C3_on() {\n+#if INCLUDE_JVMCI\n+  if (UseJVMCICompiler) {\n+    return (StoreCachedCode || LoadCachedCode) && UseC2asC3;\n+  }\n+#endif\n+  return false;\n+}\n+\n+bool AOTCodeCache::is_code_load_thread_on() {\n+  return UseCodeLoadThread && LoadCachedCode;\n+}\n+\n+bool AOTCodeCache::gen_preload_code(ciMethod* m, int entry_bci) {\n+  VM_ENTRY_MARK;\n+  return (entry_bci == InvocationEntryBci) && is_on() && _cache->gen_preload_code() &&\n+         CDSAccess::can_generate_cached_code(m->get_Method());\n+}\n+\n+static void print_helper(nmethod* nm, outputStream* st) {\n+  AOTCodeCache::iterate([&](AOTCodeEntry* e) {\n+    if (e->method() == nm->method()) {\n+      ResourceMark rm;\n+      stringStream ss;\n+      ss.print(\"A%s%d\", (e->for_preload() ? \"P\" : \"\"), e->comp_level());\n+      if (e->decompile() > 0) {\n+        ss.print(\"+D%d\", e->decompile());\n+      }\n+      ss.print(\"[%s%s%s]\",\n+               (e->is_loaded()   ? \"L\" : \"\"),\n+               (e->load_fail()   ? \"F\" : \"\"),\n+               (e->not_entrant() ? \"I\" : \"\"));\n+      ss.print(\"#%d\", e->comp_id());\n+\n+      st->print(\" %s\", ss.freeze());\n+    }\n+  });\n+}\n+\n+void AOTCodeCache::close() {\n+  if (is_on()) {\n+    if (AOTCodeCache::is_on_for_read()) {\n+      LogStreamHandle(Info, init) log;\n+      if (log.is_enabled()) {\n+        log.print_cr(\"AOT Code Cache statistics (when closed): \");\n+        AOTCodeCache::print_statistics_on(&log);\n+        log.cr();\n+        AOTCodeCache::print_timers_on(&log);\n+\n+        LogStreamHandle(Info, aot, codecache, init) log1;\n+        if (log1.is_enabled()) {\n+          AOTCodeCache::print_unused_entries_on(&log1);\n+        }\n+\n+        LogStreamHandle(Info, aot, codecache) aot_info;\n+        \/\/ need a lock to traverse the code cache\n+        MutexLocker locker(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+        if (aot_info.is_enabled()) {\n+          NMethodIterator iter(NMethodIterator::all);\n+          while (iter.next()) {\n+            nmethod* nm = iter.method();\n+            if (nm->is_in_use() && !nm->is_native_method() && !nm->is_osr_method()) {\n+              aot_info.print(\"%5d:%c%c%c%d:\", nm->compile_id(),\n+                             (nm->method()->is_shared() ? 'S' : ' '),\n+                             (nm->is_aot() ? 'A' : ' '),\n+                             (nm->preloaded() ? 'P' : ' '),\n+                             nm->comp_level());\n+              print_helper(nm, &aot_info);\n+              aot_info.print(\": \");\n+              CompileTask::print(&aot_info, nm, nullptr, true \/*short_form*\/);\n+\n+              LogStreamHandle(Debug, aot, codecache) aot_debug;\n+              if (aot_debug.is_enabled()) {\n+                MethodTrainingData* mtd = MethodTrainingData::find(methodHandle(Thread::current(), nm->method()));\n+                if (mtd != nullptr) {\n+                  mtd->iterate_compiles([&](CompileTrainingData* ctd) {\n+                    aot_debug.print(\"     CTD: \"); ctd->print_on(&aot_debug); aot_debug.cr();\n+                  });\n+                }\n+              }\n+            }\n+          }\n+        }\n+      }\n+    }\n+\n+    delete _cache; \/\/ Free memory\n+    _cache = nullptr;\n+  }\n+}\n+\n+void AOTCodeCache::invalidate(AOTCodeEntry* entry) {\n+  \/\/ This could be concurent execution\n+  if (entry != nullptr && is_on()) { \/\/ Request could come after cache is closed.\n+    _cache->invalidate_entry(entry);\n+  }\n+}\n+\n+bool AOTCodeCache::is_loaded(AOTCodeEntry* entry) {\n+  if (is_on() && _cache->cache_buffer() != nullptr) {\n+    return (uint)((char*)entry - _cache->cache_buffer()) < _cache->load_size();\n+  }\n+  return false;\n+}\n+\n+void AOTCodeCache::preload_code(JavaThread* thread) {\n+  if ((ClassInitBarrierMode == 0) || !is_on_for_read()) {\n+    return;\n+  }\n+  if ((DisableCachedCode & (1 << 3)) != 0) {\n+    return; \/\/ no preloaded code (level 5);\n+  }\n+  _cache->preload_startup_code(thread);\n+}\n+\n+AOTCodeEntry* AOTCodeCache::find_code_entry(const methodHandle& method, uint comp_level) {\n+  switch (comp_level) {\n+    case CompLevel_simple:\n+      if ((DisableCachedCode & (1 << 0)) != 0) {\n+        return nullptr;\n+      }\n+      break;\n+    case CompLevel_limited_profile:\n+      if ((DisableCachedCode & (1 << 1)) != 0) {\n+        return nullptr;\n+      }\n+      break;\n+    case CompLevel_full_optimization:\n+      if ((DisableCachedCode & (1 << 2)) != 0) {\n+        return nullptr;\n+      }\n+      break;\n+\n+    default: return nullptr; \/\/ Level 1, 2, and 4 only\n+  }\n+  TraceTime t1(\"SC total find code time\", &_t_totalFind, enable_timers(), false);\n+  if (is_on() && _cache->cache_buffer() != nullptr) {\n+    MethodData* md = method->method_data();\n+    uint decomp = (md == nullptr) ? 0 : md->decompile_count();\n+\n+    ResourceMark rm;\n+    const char* target_name = method->name_and_sig_as_C_string();\n+    uint hash = java_lang_String::hash_code((const jbyte*)target_name, (int)strlen(target_name));\n+    AOTCodeEntry* entry = _cache->find_entry(AOTCodeEntry::Code, hash, comp_level, decomp);\n+    if (entry == nullptr) {\n+      log_info(aot, codecache, nmethod)(\"Missing entry for '%s' (comp_level %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \")\", target_name, (uint)comp_level, decomp, hash);\n+#ifdef ASSERT\n+    } else {\n+      uint name_offset = entry->offset() + entry->name_offset();\n+      uint name_size   = entry->name_size(); \/\/ Includes '\/0'\n+      const char* name = _cache->cache_buffer() + name_offset;\n+      if (strncmp(target_name, name, name_size) != 0) {\n+        assert(false, \"SCA: saved nmethod's name '%s' is different from '%s', hash: \" UINT32_FORMAT_X_0, name, target_name, hash);\n+      }\n+#endif\n+    }\n+\n+    DirectiveSet* directives = DirectivesStack::getMatchingDirective(method, nullptr);\n+    if (directives->IgnorePrecompiledOption) {\n+      LogStreamHandle(Info, aot, codecache, compilation) log;\n+      if (log.is_enabled()) {\n+        log.print(\"Ignore cached code entry on level %d for \", comp_level);\n+        method->print_value_on(&log);\n+      }\n+      return nullptr;\n+    }\n+\n+    return entry;\n+  }\n+  return nullptr;\n+}\n+\n+void AOTCodeCache::add_C_string(const char* str) {\n+  if (is_on_for_write()) {\n+    _cache->add_new_C_string(str);\n+  }\n+}\n+\n+bool AOTCodeCache::allow_const_field(ciConstant& value) {\n+  return !is_on() || !StoreCachedCode \/\/ Restrict only when we generate cache\n+        \/\/ Can not trust primitive too   || !is_reference_type(value.basic_type())\n+        \/\/ May disable this too for now  || is_reference_type(value.basic_type()) && value.as_object()->should_be_constant()\n+        ;\n+}\n+\n+\n+bool AOTCodeCache::open_cache() {\n+  AOTCodeCache* cache = new AOTCodeCache();\n+  if (cache->failed()) {\n+    delete cache;\n+    _cache = nullptr;\n+    return false;\n+  }\n+  _cache = cache;\n+  return true;\n+}\n+\n+class CachedCodeDirectory : public CachedCodeDirectoryInternal {\n+public:\n+  uint _aot_code_size;\n+  char* _aot_code_data;\n+\n+  void set_aot_code_data(uint size, char* aot_data) {\n+    _aot_code_size = size;\n+    CDSAccess::set_pointer(&_aot_code_data, aot_data);\n+  }\n+\n+  static CachedCodeDirectory* create();\n+};\n+\n+\/\/ Storing AOT code in the cached code region of AOT Cache:\n+\/\/\n+\/\/ [1] Use CachedCodeDirectory to keep track of all of data related to cached code.\n+\/\/     E.g., you can build a hashtable to record what methods have been archived.\n+\/\/\n+\/\/ [2] Memory for all data for cached code, including CachedCodeDirectory, should be\n+\/\/     allocated using CDSAccess::allocate_from_code_cache().\n+\/\/\n+\/\/ [3] CachedCodeDirectory must be the very first allocation.\n+\/\/\n+\/\/ [4] Two kinds of pointer can be stored:\n+\/\/     - A pointer p that points to metadata. CDSAccess::can_generate_cached_code(p) must return true.\n+\/\/     - A pointer to a buffer returned by CDSAccess::allocate_from_code_cache().\n+\/\/       (It's OK to point to an interior location within this buffer).\n+\/\/     Such pointers must be stored using CDSAccess::set_pointer()\n+\/\/\n+\/\/ The buffers allocated by CDSAccess::allocate_from_code_cache() are in a contiguous region. At runtime, this\n+\/\/ region is mapped to the process address space. All the pointers in this buffer are relocated as necessary\n+\/\/ (e.g., to account for the runtime location of the CodeCache).\n+\/\/\n+\/\/ This is always at the very beginning of the mmaped CDS \"cc\" (cached code) region\n+static CachedCodeDirectory* _cached_code_directory = nullptr;\n+\n+CachedCodeDirectory* CachedCodeDirectory::create() {\n+  assert(CDSAccess::is_cached_code_region_empty(), \"must be\");\n+  CachedCodeDirectory* dir = (CachedCodeDirectory*)CDSAccess::allocate_from_code_cache(sizeof(CachedCodeDirectory));\n+  dir->dumptime_init_internal();\n+  return dir;\n+}\n+\n+#define DATA_ALIGNMENT HeapWordSize\n+\n+AOTCodeCache::AOTCodeCache() {\n+  _load_header = nullptr;\n+  _for_read  = LoadCachedCode;\n+  _for_write = StoreCachedCode;\n+  _load_size = 0;\n+  _store_size = 0;\n+  _write_position = 0;\n+  _closing  = false;\n+  _failed = false;\n+  _lookup_failed = false;\n+  _table = nullptr;\n+  _load_entries = nullptr;\n+  _store_entries  = nullptr;\n+  _C_strings_buf  = nullptr;\n+  _load_buffer = nullptr;\n+  _store_buffer = nullptr;\n+  _C_store_buffer = nullptr;\n+  _store_entries_cnt = 0;\n+  _gen_preload_code = false;\n+  _for_preload = false;       \/\/ changed while storing entry data\n+  _has_clinit_barriers = false;\n+\n+  _compile_id = 0;\n+  _comp_level = 0;\n+\n+  _use_meta_ptrs = UseSharedSpaces ? UseMetadataPointers : false;\n+\n+  if (_for_read) {\n+    \/\/ Read cache\n+    ReservedSpace rs = MemoryReserver::reserve(CDSAccess::get_cached_code_size(), mtCode);\n+    if (!rs.is_reserved()) {\n+      log_warning(aot, codecache, init)(\"Failed to reserved %u bytes of memory for mapping cached code region in AOT Cache\", (uint)CDSAccess::get_cached_code_size());\n+      set_failed();\n+      return;\n+    }\n+    if (!CDSAccess::map_cached_code(rs)) {\n+      log_warning(aot, codecache, init)(\"Failed to read\/mmap cached code region in AOT Cache\");\n+      set_failed();\n+      return;\n+    }\n+    _cached_code_directory = (CachedCodeDirectory*)rs.base();\n+    _cached_code_directory->runtime_init_internal();\n+\n+    _load_size = _cached_code_directory->_aot_code_size;\n+    _load_buffer = _cached_code_directory->_aot_code_data;\n+    assert(is_aligned(_load_buffer, DATA_ALIGNMENT), \"load_buffer is not aligned\");\n+    log_info(aot, codecache, init)(\"Mapped %u bytes at address \" INTPTR_FORMAT \" from AOT Code Cache\", _load_size, p2i(_load_buffer));\n+\n+    _load_header = (AOTCodeCache::Header*)addr(0);\n+    if (!_load_header->verify_config(_load_size)) {\n+      set_failed();\n+      return;\n+    }\n+    log_info(aot, codecache, init)(\"Read header from AOT Code Cache\");\n+    if (_load_header->has_meta_ptrs()) {\n+      assert(UseSharedSpaces, \"should be verified already\");\n+      _use_meta_ptrs = true; \/\/ Regardless UseMetadataPointers\n+      UseMetadataPointers = true;\n+    }\n+    \/\/ Read strings\n+    load_strings();\n+  }\n+  if (_for_write) {\n+    _gen_preload_code = _use_meta_ptrs && (ClassInitBarrierMode > 0);\n+\n+    _C_store_buffer = NEW_C_HEAP_ARRAY(char, max_aot_code_size() + DATA_ALIGNMENT, mtCode);\n+    _store_buffer = align_up(_C_store_buffer, DATA_ALIGNMENT);\n+    \/\/ Entries allocated at the end of buffer in reverse (as on stack).\n+    _store_entries = (AOTCodeEntry*)align_up(_C_store_buffer + max_aot_code_size(), DATA_ALIGNMENT);\n+    log_info(aot, codecache, init)(\"Allocated store buffer at address \" INTPTR_FORMAT \" of size \" UINT32_FORMAT \" bytes\", p2i(_store_buffer), max_aot_code_size());\n+  }\n+  _table = new AOTCodeAddressTable();\n+}\n+\n+void AOTCodeCache::init_extrs_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_extrs();\n+  }\n+}\n+void AOTCodeCache::init_early_stubs_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_early_stubs();\n+  }\n+}\n+void AOTCodeCache::init_shared_blobs_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_shared_blobs();\n+  }\n+}\n+void AOTCodeCache::init_stubs_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_stubs();\n+  }\n+}\n+\n+void AOTCodeCache::init_opto_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_opto();\n+  }\n+}\n+\n+void AOTCodeCache::init_c1_table() {\n+  AOTCodeAddressTable* table = addr_table();\n+  if (table != nullptr) {\n+    table->init_c1();\n+  }\n+}\n+\n+void AOTCodeCache::Config::record(bool use_meta_ptrs) {\n+  _flags = 0;\n+  if (use_meta_ptrs) {\n+    _flags |= metadataPointers;\n+  }\n+#ifdef ASSERT\n+  _flags |= debugVM;\n+#endif\n+  if (UseCompressedOops) {\n+    _flags |= compressedOops;\n+  }\n+  if (UseCompressedClassPointers) {\n+    _flags |= compressedClassPointers;\n+  }\n+  if (UseTLAB) {\n+    _flags |= useTLAB;\n+  }\n+  if (JavaAssertions::systemClassDefault()) {\n+    _flags |= systemClassAssertions;\n+  }\n+  if (JavaAssertions::userClassDefault()) {\n+    _flags |= userClassAssertions;\n+  }\n+  if (EnableContended) {\n+    _flags |= enableContendedPadding;\n+  }\n+  if (RestrictContended) {\n+    _flags |= restrictContendedPadding;\n+  }\n+  _compressedOopShift    = CompressedOops::shift();\n+  _compressedKlassShift  = CompressedKlassPointers::shift();\n+  _contendedPaddingWidth = ContendedPaddingWidth;\n+  _objectAlignment       = ObjectAlignmentInBytes;\n+  _gc                    = (uint)Universe::heap()->kind();\n+}\n+\n+bool AOTCodeCache::Config::verify() const {\n+#ifdef ASSERT\n+  if ((_flags & debugVM) == 0) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created by product VM, it can't be used by debug VM\");\n+    return false;\n+  }\n+#else\n+  if ((_flags & debugVM) != 0) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created by debug VM, it can't be used by product VM\");\n+    return false;\n+  }\n+#endif\n+\n+  CollectedHeap::Name aot_gc = (CollectedHeap::Name)_gc;\n+  if (aot_gc != Universe::heap()->kind()) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with different GC: %s vs current %s\", GCConfig::hs_err_name(aot_gc), GCConfig::hs_err_name());\n+    return false;\n+  }\n+\n+  if (((_flags & compressedOops) != 0) != UseCompressedOops) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with UseCompressedOops = %s\", UseCompressedOops ? \"false\" : \"true\");\n+    return false;\n+  }\n+  if (((_flags & compressedClassPointers) != 0) != UseCompressedClassPointers) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with UseCompressedClassPointers = %s\", UseCompressedClassPointers ? \"false\" : \"true\");\n+    return false;\n+  }\n+\n+  if (((_flags & systemClassAssertions) != 0) != JavaAssertions::systemClassDefault()) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with JavaAssertions::systemClassDefault() = %s\", JavaAssertions::systemClassDefault() ? \"disabled\" : \"enabled\");\n+    return false;\n+  }\n+  if (((_flags & userClassAssertions) != 0) != JavaAssertions::userClassDefault()) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with JavaAssertions::userClassDefault() = %s\", JavaAssertions::userClassDefault() ? \"disabled\" : \"enabled\");\n+    return false;\n+  }\n+\n+  if (((_flags & enableContendedPadding) != 0) != EnableContended) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with EnableContended = %s\", EnableContended ? \"false\" : \"true\");\n+    return false;\n+  }\n+  if (((_flags & restrictContendedPadding) != 0) != RestrictContended) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with RestrictContended = %s\", RestrictContended ? \"false\" : \"true\");\n+    return false;\n+  }\n+  if (_compressedOopShift != (uint)CompressedOops::shift()) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with CompressedOops::shift() = %d vs current %d\", _compressedOopShift, CompressedOops::shift());\n+    return false;\n+  }\n+  if (_compressedKlassShift != (uint)CompressedKlassPointers::shift()) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with CompressedKlassPointers::shift() = %d vs current %d\", _compressedKlassShift, CompressedKlassPointers::shift());\n+    return false;\n+  }\n+  if (_contendedPaddingWidth != (uint)ContendedPaddingWidth) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with ContendedPaddingWidth = %d vs current %d\", _contendedPaddingWidth, ContendedPaddingWidth);\n+    return false;\n+  }\n+  if (_objectAlignment != (uint)ObjectAlignmentInBytes) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: it was created with ObjectAlignmentInBytes = %d vs current %d\", _objectAlignment, ObjectAlignmentInBytes);\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::Header::verify_config(uint load_size) const {\n+  if (_version != AOT_CODE_VERSION) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: different AOT Code version %d vs %d recorded in AOT Cache\", AOT_CODE_VERSION, _version);\n+    return false;\n+  }\n+  if (_cache_size != load_size) {\n+    log_warning(aot, codecache, init)(\"Disable AOT Code: different cached code size %d vs %d recorded in AOT Cache\", load_size, _cache_size);\n+    return false;\n+  }\n+  return true;\n+}\n+\n+volatile int AOTCodeCache::_nmethod_readers = 0;\n+\n+AOTCodeCache::~AOTCodeCache() {\n+  if (_closing) {\n+    return; \/\/ Already closed\n+  }\n+  \/\/ Stop any further access to cache.\n+  \/\/ Checked on entry to load_nmethod() and store_nmethod().\n+  _closing = true;\n+  if (_for_read) {\n+    \/\/ Wait for all load_nmethod() finish.\n+    wait_for_no_nmethod_readers();\n+  }\n+  \/\/ Prevent writing code into cache while we are closing it.\n+  \/\/ This lock held by ciEnv::register_method() which calls store_nmethod().\n+  MutexLocker ml(Compile_lock);\n+  if (for_write()) { \/\/ Finalize cache\n+    finish_write();\n+  }\n+  _load_buffer = nullptr;\n+  if (_C_store_buffer != nullptr) {\n+    FREE_C_HEAP_ARRAY(char, _C_store_buffer);\n+    _C_store_buffer = nullptr;\n+    _store_buffer = nullptr;\n+  }\n+  if (_table != nullptr) {\n+    delete _table;\n+    _table = nullptr;\n+  }\n+}\n+\n+AOTCodeCache* AOTCodeCache::open_for_read() {\n+  if (AOTCodeCache::is_on_for_read()) {\n+    return AOTCodeCache::cache();\n+  }\n+  return nullptr;\n+}\n+\n+AOTCodeCache* AOTCodeCache::open_for_write() {\n+  if (AOTCodeCache::is_on_for_write()) {\n+    AOTCodeCache* cache = AOTCodeCache::cache();\n+    cache->clear_lookup_failed(); \/\/ Reset bit\n+    return cache;\n+  }\n+  return nullptr;\n+}\n+\n+bool AOTCodeCache::is_address_in_aot_cache(address p) {\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  if ((p >= (address)cache->cache_buffer()) &&\n+      (p < (address)(cache->cache_buffer() + cache->load_size()))) {\n+    return true;\n+  }\n+  return false;\n+}\n+\n+static void copy_bytes(const char* from, address to, uint size) {\n+  assert(size > 0, \"sanity\");\n+  bool by_words = true;\n+  if ((size > 2 * HeapWordSize) && (((intptr_t)from | (intptr_t)to) & (HeapWordSize - 1)) == 0) {\n+    \/\/ Use wordwise copies if possible:\n+    Copy::disjoint_words((HeapWord*)from,\n+                         (HeapWord*)to,\n+                         ((size_t)size + HeapWordSize-1) \/ HeapWordSize);\n+  } else {\n+    by_words = false;\n+    Copy::conjoint_jbytes(from, to, (size_t)size);\n+  }\n+  log_trace(aot, codecache)(\"Copied %d bytes as %s from \" INTPTR_FORMAT \" to \" INTPTR_FORMAT, size, (by_words ? \"HeapWord\" : \"bytes\"), p2i(from), p2i(to));\n+}\n+\n+void AOTCodeReader::set_read_position(uint pos) {\n+  if (pos == _read_position) {\n+    return;\n+  }\n+  assert(pos < _cache->load_size(), \"offset:%d >= file size:%d\", pos, _cache->load_size());\n+  _read_position = pos;\n+}\n+\n+bool AOTCodeCache::set_write_position(uint pos) {\n+  if (pos == _write_position) {\n+    return true;\n+  }\n+  if (_store_size < _write_position) {\n+    _store_size = _write_position; \/\/ Adjust during write\n+  }\n+  assert(pos < _store_size, \"offset:%d >= file size:%d\", pos, _store_size);\n+  _write_position = pos;\n+  return true;\n+}\n+\n+static char align_buffer[256] = { 0 };\n+\n+bool AOTCodeCache::align_write() {\n+  \/\/ We are not executing code from cache - we copy it by bytes first.\n+  \/\/ No need for big alignment (or at all).\n+  uint padding = DATA_ALIGNMENT - (_write_position & (DATA_ALIGNMENT - 1));\n+  if (padding == DATA_ALIGNMENT) {\n+    return true;\n+  }\n+  uint n = write_bytes((const void*)&align_buffer, padding);\n+  if (n != padding) {\n+    return false;\n+  }\n+  log_trace(aot, codecache)(\"Adjust write alignment in AOT Code Cache\");\n+  return true;\n+}\n+\n+\/\/ Check to see if AOT code cache has required space to store \"nbytes\" of data\n+address AOTCodeCache::reserve_bytes(uint nbytes) {\n+  assert(for_write(), \"Code Cache file is not created\");\n+  uint new_position = _write_position + nbytes;\n+  if (new_position >= (uint)((char*)_store_entries - _store_buffer)) {\n+    log_warning(aot, codecache)(\"Failed to ensure %d bytes at offset %d in AOT Code Cache. Increase CachedCodeMaxSize.\",\n+                     nbytes, _write_position);\n+    set_failed();\n+    exit_vm_on_store_failure();\n+    return nullptr;\n+  }\n+  address buffer = (address)(_store_buffer + _write_position);\n+  _write_position += nbytes;\n+  if (_store_size < _write_position) {\n+    _store_size = _write_position;\n+  }\n+  return buffer;\n+}\n+\n+uint AOTCodeCache::write_bytes(const void* buffer, uint nbytes) {\n+  assert(for_write(), \"Code Cache file is not created\");\n+  if (nbytes == 0) {\n+    return 0;\n+  }\n+  uint new_position = _write_position + nbytes;\n+  if (new_position >= (uint)((char*)_store_entries - _store_buffer)) {\n+    log_warning(aot, codecache)(\"Failed to write %d bytes at offset %d to AOT Code Cache. Increase CachedCodeMaxSize.\",\n+                     nbytes, _write_position);\n+    set_failed();\n+    exit_vm_on_store_failure();\n+    return 0;\n+  }\n+  copy_bytes((const char* )buffer, (address)(_store_buffer + _write_position), nbytes);\n+  log_trace(aot, codecache)(\"Wrote %d bytes at offset %d to AOT Code Cache\", nbytes, _write_position);\n+  _write_position += nbytes;\n+  if (_store_size < _write_position) {\n+    _store_size = _write_position;\n+  }\n+  return nbytes;\n+}\n+\n+void AOTCodeEntry::update_method_for_writing() {\n+  if (_method != nullptr) {\n+    _method = CDSAccess::method_in_cached_code(_method);\n+  }\n+}\n+\n+void AOTCodeEntry::print(outputStream* st) const {\n+  st->print_cr(\" AOT Code Cache entry \" INTPTR_FORMAT \" [kind: %d, id: \" UINT32_FORMAT_X_0 \", offset: %d, size: %d, comp_level: %d, comp_id: %d, decompiled: %d, %s%s%s%s%s]\",\n+               p2i(this), (int)_kind, _id, _offset, _size, _comp_level, _comp_id, _decompile,\n+               (_not_entrant? \"not_entrant\" : \"entrant\"),\n+               (_loaded ? \", loaded\" : \"\"),\n+               (_has_clinit_barriers ? \", has_clinit_barriers\" : \"\"),\n+               (_for_preload ? \", for_preload\" : \"\"),\n+               (_ignore_decompile ? \", ignore_decomp\" : \"\"));\n+}\n+\n+void* AOTCodeEntry::operator new(size_t x, AOTCodeCache* cache) {\n+  return (void*)(cache->add_entry());\n+}\n+\n+bool skip_preload(methodHandle mh) {\n+  if (!mh->method_holder()->is_loaded()) {\n+    return true;\n+  }\n+  DirectiveSet* directives = DirectivesStack::getMatchingDirective(mh, nullptr);\n+  if (directives->DontPreloadOption) {\n+    LogStreamHandle(Info, aot, codecache, init) log;\n+    if (log.is_enabled()) {\n+      log.print(\"Exclude preloading code for \");\n+      mh->print_value_on(&log);\n+    }\n+    return true;\n+  }\n+  return false;\n+}\n+\n+void AOTCodeCache::preload_startup_code(TRAPS) {\n+  if (CompilationPolicy::compiler_count(CompLevel_full_optimization) == 0) {\n+    \/\/ Since we reuse the CompilerBroker API to install cached code, we're required to have a JIT compiler for the\n+    \/\/ level we want (that is CompLevel_full_optimization).\n+    return;\n+  }\n+  assert(_for_read, \"sanity\");\n+  uint count = _load_header->entries_count();\n+  if (_load_entries == nullptr) {\n+    \/\/ Read it\n+    _search_entries = (uint*)addr(_load_header->entries_offset()); \/\/ [id, index]\n+    _load_entries = (AOTCodeEntry*)(_search_entries + 2 * count);\n+    log_info(aot, codecache, init)(\"Read %d entries table at offset %d from AOT Code Cache\", count, _load_header->entries_offset());\n+  }\n+  uint preload_entries_count = _load_header->preload_entries_count();\n+  if (preload_entries_count > 0) {\n+    uint* entries_index = (uint*)addr(_load_header->preload_entries_offset());\n+    log_info(aot, codecache, init)(\"Load %d preload entries from AOT Code Cache\", preload_entries_count);\n+    uint count = MIN2(preload_entries_count, SCLoadStop);\n+    for (uint i = SCLoadStart; i < count; i++) {\n+      uint index = entries_index[i];\n+      AOTCodeEntry* entry = &(_load_entries[index]);\n+      if (entry->not_entrant()) {\n+        continue;\n+      }\n+      methodHandle mh(THREAD, entry->method());\n+      assert((mh.not_null() && MetaspaceShared::is_in_shared_metaspace((address)mh())), \"sanity\");\n+      if (skip_preload(mh)) {\n+        continue; \/\/ Exclude preloading for this method\n+      }\n+      assert(mh->method_holder()->is_loaded(), \"\");\n+      if (!mh->method_holder()->is_linked()) {\n+        assert(!HAS_PENDING_EXCEPTION, \"\");\n+        mh->method_holder()->link_class(THREAD);\n+        if (HAS_PENDING_EXCEPTION) {\n+          LogStreamHandle(Info, aot, codecache) log;\n+          if (log.is_enabled()) {\n+            ResourceMark rm;\n+            log.print(\"Linkage failed for %s: \", mh->method_holder()->external_name());\n+            THREAD->pending_exception()->print_value_on(&log);\n+            if (log_is_enabled(Debug, aot, codecache)) {\n+              THREAD->pending_exception()->print_on(&log);\n+            }\n+          }\n+          CLEAR_PENDING_EXCEPTION;\n+        }\n+      }\n+      if (mh->aot_code_entry() != nullptr) {\n+        \/\/ Second C2 compilation of the same method could happen for\n+        \/\/ different reasons without marking first entry as not entrant.\n+        continue; \/\/ Keep old entry to avoid issues\n+      }\n+      mh->set_aot_code_entry(entry);\n+      CompileBroker::compile_method(mh, InvocationEntryBci, CompLevel_full_optimization, methodHandle(), 0, false, CompileTask::Reason_Preload, CHECK);\n+    }\n+  }\n+}\n+\n+static bool check_entry(AOTCodeEntry::Kind kind, uint id, uint comp_level, uint decomp, AOTCodeEntry* entry) {\n+  if (entry->kind() == kind) {\n+    assert(entry->id() == id, \"sanity\");\n+    if (kind != AOTCodeEntry::Code || (!entry->not_entrant() && !entry->has_clinit_barriers() &&\n+                                  (entry->comp_level() == comp_level) &&\n+                                  (entry->ignore_decompile() || entry->decompile() == decomp))) {\n+      return true; \/\/ Found\n+    }\n+  }\n+  return false;\n+}\n+\n+AOTCodeEntry* AOTCodeCache::find_entry(AOTCodeEntry::Kind kind, uint id, uint comp_level, uint decomp) {\n+  assert(_for_read, \"sanity\");\n+  uint count = _load_header->entries_count();\n+  if (_load_entries == nullptr) {\n+    \/\/ Read it\n+    _search_entries = (uint*)addr(_load_header->entries_offset()); \/\/ [id, index]\n+    _load_entries = (AOTCodeEntry*)(_search_entries + 2 * count);\n+    log_info(aot, codecache, init)(\"Read %d entries table at offset %d from AOT Code Cache\", count, _load_header->entries_offset());\n+  }\n+  \/\/ Binary search\n+  int l = 0;\n+  int h = count - 1;\n+  while (l <= h) {\n+    int mid = (l + h) >> 1;\n+    int ix = mid * 2;\n+    uint is = _search_entries[ix];\n+    if (is == id) {\n+      int index = _search_entries[ix + 1];\n+      AOTCodeEntry* entry = &(_load_entries[index]);\n+      if (check_entry(kind, id, comp_level, decomp, entry)) {\n+        return entry; \/\/ Found\n+      }\n+      \/\/ Leaner search around (could be the same nmethod with different decompile count)\n+      for (int i = mid - 1; i >= l; i--) { \/\/ search back\n+        ix = i * 2;\n+        is = _search_entries[ix];\n+        if (is != id) {\n+          break;\n+        }\n+        index = _search_entries[ix + 1];\n+        AOTCodeEntry* entry = &(_load_entries[index]);\n+        if (check_entry(kind, id, comp_level, decomp, entry)) {\n+          return entry; \/\/ Found\n+        }\n+      }\n+      for (int i = mid + 1; i <= h; i++) { \/\/ search forward\n+        ix = i * 2;\n+        is = _search_entries[ix];\n+        if (is != id) {\n+          break;\n+        }\n+        index = _search_entries[ix + 1];\n+        AOTCodeEntry* entry = &(_load_entries[index]);\n+        if (check_entry(kind, id, comp_level, decomp, entry)) {\n+          return entry; \/\/ Found\n+        }\n+      }\n+      break; \/\/ Not found match (different decompile count or not_entrant state).\n+    } else if (is < id) {\n+      l = mid + 1;\n+    } else {\n+      h = mid - 1;\n+    }\n+  }\n+  return nullptr;\n+}\n+\n+void AOTCodeCache::invalidate_entry(AOTCodeEntry* entry) {\n+  assert(entry!= nullptr, \"all entries should be read already\");\n+  if (entry->not_entrant()) {\n+    return; \/\/ Someone invalidated it already\n+  }\n+#ifdef ASSERT\n+  bool found = false;\n+  if (_for_read) {\n+    uint count = _load_header->entries_count();\n+    uint i = 0;\n+    for(; i < count; i++) {\n+      if (entry == &(_load_entries[i])) {\n+        break;\n+      }\n+    }\n+    found = (i < count);\n+  }\n+  if (!found && _for_write) {\n+    uint count = _store_entries_cnt;\n+    uint i = 0;\n+    for(; i < count; i++) {\n+      if (entry == &(_store_entries[i])) {\n+        break;\n+      }\n+    }\n+    found = (i < count);\n+  }\n+  assert(found, \"entry should exist\");\n+#endif\n+  entry->set_not_entrant();\n+  {\n+    uint name_offset = entry->offset() + entry->name_offset();\n+    const char* name;\n+    if (AOTCodeCache::is_loaded(entry)) {\n+      name = _load_buffer + name_offset;\n+    } else {\n+      name = _store_buffer + name_offset;\n+    }\n+    uint level   = entry->comp_level();\n+    uint comp_id = entry->comp_id();\n+    uint decomp  = entry->decompile();\n+    bool clinit_brs = entry->has_clinit_barriers();\n+    log_info(aot, codecache, nmethod)(\"Invalidated entry for '%s' (comp_id %d, comp_level %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s)\",\n+                           name, comp_id, level, decomp, entry->id(), (clinit_brs ? \", has clinit barriers\" : \"\"));\n+  }\n+  if (entry->next() != nullptr) {\n+    entry = entry->next();\n+    assert(entry->has_clinit_barriers(), \"expecting only such entries here\");\n+    invalidate_entry(entry);\n+  }\n+}\n+\n+static int uint_cmp(const void *i, const void *j) {\n+  uint a = *(uint *)i;\n+  uint b = *(uint *)j;\n+  return a > b ? 1 : a < b ? -1 : 0;\n+}\n+\n+AOTCodeStats AOTCodeStats::add_cached_code_stats(AOTCodeStats stats1, AOTCodeStats stats2) {\n+  AOTCodeStats result;\n+  for (int kind = AOTCodeEntry::None; kind < AOTCodeEntry::Kind_count; kind++) {\n+    result.ccstats._kind_cnt[kind] = stats1.entry_count(kind) + stats2.entry_count(kind);\n+  }\n+\n+  for (int lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n+    result.ccstats._nmethod_cnt[lvl] = stats1.nmethod_count(lvl) + stats2.nmethod_count(lvl);\n+  }\n+  result.ccstats._clinit_barriers_cnt = stats1.clinit_barriers_count() + stats2.clinit_barriers_count();\n+  return result;\n+}\n+\n+void AOTCodeCache::log_stats_on_exit() {\n+  LogStreamHandle(Info, aot, codecache, exit) log;\n+  if (log.is_enabled()) {\n+    AOTCodeStats prev_stats;\n+    AOTCodeStats current_stats;\n+    AOTCodeStats total_stats;\n+    uint max_size = 0;\n+\n+    uint load_count = (_load_header != nullptr) ? _load_header->entries_count() : 0;\n+\n+    for (uint i = 0; i < load_count; i++) {\n+      prev_stats.collect_entry_stats(&_load_entries[i]);\n+      if (max_size < _load_entries[i].size()) {\n+        max_size = _load_entries[i].size();\n+      }\n+    }\n+    for (uint i = 0; i < _store_entries_cnt; i++) {\n+      current_stats.collect_entry_stats(&_store_entries[i]);\n+      if (max_size < _store_entries[i].size()) {\n+        max_size = _store_entries[i].size();\n+      }\n+    }\n+    total_stats = AOTCodeStats::add_cached_code_stats(prev_stats, current_stats);\n+\n+    log.print_cr(\"Wrote %d AOTCodeEntry entries(%u max size) to AOT Code Cache\",\n+                 total_stats.total_count(), max_size);\n+    for (uint kind = AOTCodeEntry::None; kind < AOTCodeEntry::Kind_count; kind++) {\n+      if (total_stats.entry_count(kind) > 0) {\n+        log.print_cr(\"  %s: total=%u(old=%u+new=%u)\",\n+                     aot_code_entry_kind_name[kind], total_stats.entry_count(kind), prev_stats.entry_count(kind), current_stats.entry_count(kind));\n+        if (kind == AOTCodeEntry::Code) {\n+          for (uint lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n+            if (total_stats.nmethod_count(lvl) > 0) {\n+              log.print_cr(\"    Tier %d: total=%u(old=%u+new=%u)\",\n+                           lvl, total_stats.nmethod_count(lvl), prev_stats.nmethod_count(lvl), current_stats.nmethod_count(lvl));\n+            }\n+          }\n+        }\n+      }\n+    }\n+    log.print_cr(\"Total=%u(old=%u+new=%u)\", total_stats.total_count(), prev_stats.total_count(), current_stats.total_count());\n+  }\n+}\n+\n+bool AOTCodeCache::finish_write() {\n+  if (!align_write()) {\n+    return false;\n+  }\n+  uint strings_offset = _write_position;\n+  int strings_count = store_strings();\n+  if (strings_count < 0) {\n+    return false;\n+  }\n+  if (!align_write()) {\n+    return false;\n+  }\n+  uint strings_size = _write_position - strings_offset;\n+\n+  uint entries_count = 0; \/\/ Number of entrant (useful) code entries\n+  uint entries_offset = _write_position;\n+\n+  uint store_count = _store_entries_cnt;\n+  if (store_count > 0) {\n+    _cached_code_directory = CachedCodeDirectory::create();\n+    assert(_cached_code_directory != nullptr, \"Sanity check\");\n+\n+    uint header_size = (uint)align_up(sizeof(AOTCodeCache::Header),  DATA_ALIGNMENT);\n+    uint load_count = (_load_header != nullptr) ? _load_header->entries_count() : 0;\n+    uint code_count = store_count + load_count;\n+    uint search_count = code_count * 2;\n+    uint search_size = search_count * sizeof(uint);\n+    uint entries_size = (uint)align_up(code_count * sizeof(AOTCodeEntry), DATA_ALIGNMENT); \/\/ In bytes\n+    uint preload_entries_cnt = 0;\n+    uint* preload_entries = NEW_C_HEAP_ARRAY(uint, code_count, mtCode);\n+    uint preload_entries_size = code_count * sizeof(uint);\n+    \/\/ _write_position should include code and strings\n+    uint code_alignment = code_count * DATA_ALIGNMENT; \/\/ We align_up code size when storing it.\n+    uint total_size = _write_position + _load_size + header_size +\n+                     code_alignment + search_size + preload_entries_size + entries_size;\n+\n+    assert(total_size < max_aot_code_size(), \"Cached code region size (\" UINT32_FORMAT \" bytes) in AOT Code Cache is less than the required size (\" UINT32_FORMAT \" bytes).\",\n+           total_size, max_aot_code_size());\n+\n+    \/\/ Create ordered search table for entries [id, index];\n+    uint* search = NEW_C_HEAP_ARRAY(uint, search_count, mtCode);\n+\n+    char* buffer = (char *)CDSAccess::allocate_from_code_cache(total_size + DATA_ALIGNMENT); \/\/ NEW_C_HEAP_ARRAY(char, total_size + DATA_ALIGNMENT, mtCode);\n+    char* start = align_up(buffer, DATA_ALIGNMENT);\n+    char* current = start + header_size; \/\/ Skip header\n+\n+    AOTCodeEntry* entries_address = _store_entries; \/\/ Pointer to latest entry\n+\n+    \/\/ Add old entries first\n+    if (_for_read && (_load_header != nullptr)) {\n+      for(uint i = 0; i < load_count; i++) {\n+        if (_load_entries[i].load_fail()) {\n+          continue;\n+        }\n+        if (_load_entries[i].not_entrant()) {\n+          log_info(aot, codecache, exit)(\"Not entrant load entry id: %d, decomp: %d, hash: \" UINT32_FORMAT_X_0, i, _load_entries[i].decompile(), _load_entries[i].id());\n+          if (_load_entries[i].for_preload()) {\n+            \/\/ Skip not entrant preload code:\n+            \/\/ we can't pre-load code which may have failing dependencies.\n+            continue;\n+          }\n+          _load_entries[i].set_entrant(); \/\/ Reset\n+        } else if (_load_entries[i].for_preload() && _load_entries[i].method() != nullptr) {\n+          \/\/ record entrant first version code for pre-loading\n+          preload_entries[preload_entries_cnt++] = entries_count;\n+        }\n+        {\n+          uint size = align_up(_load_entries[i].size(), DATA_ALIGNMENT);\n+          copy_bytes((_load_buffer + _load_entries[i].offset()), (address)current, size);\n+          _load_entries[i].set_offset(current - start); \/\/ New offset\n+          current += size;\n+          uint n = write_bytes(&(_load_entries[i]), sizeof(AOTCodeEntry));\n+          if (n != sizeof(AOTCodeEntry)) {\n+            FREE_C_HEAP_ARRAY(char, buffer);\n+            FREE_C_HEAP_ARRAY(uint, search);\n+            return false;\n+          }\n+          search[entries_count*2 + 0] = _load_entries[i].id();\n+          search[entries_count*2 + 1] = entries_count;\n+          entries_count++;\n+        }\n+      }\n+    }\n+    \/\/ AOTCodeEntry entries were allocated in reverse in store buffer.\n+    \/\/ Process them in reverse order to cache first code first.\n+    for (int i = store_count - 1; i >= 0; i--) {\n+      if (entries_address[i].load_fail()) {\n+        continue;\n+      }\n+      if (entries_address[i].not_entrant()) {\n+        log_info(aot, codecache, exit)(\"Not entrant new entry comp_id: %d, comp_level: %d, decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s\", entries_address[i].comp_id(), entries_address[i].comp_level(), entries_address[i].decompile(), entries_address[i].id(), (entries_address[i].has_clinit_barriers() ? \", has clinit barriers\" : \"\"));\n+        if (entries_address[i].for_preload()) {\n+          \/\/ Skip not entrant preload code:\n+          \/\/ we can't pre-load code which may have failing dependencies.\n+          continue;\n+        }\n+        entries_address[i].set_entrant(); \/\/ Reset\n+      } else if (entries_address[i].for_preload() && entries_address[i].method() != nullptr) {\n+        \/\/ record entrant first version code for pre-loading\n+        preload_entries[preload_entries_cnt++] = entries_count;\n+      }\n+      {\n+        entries_address[i].set_next(nullptr); \/\/ clear pointers before storing data\n+        uint size = align_up(entries_address[i].size(), DATA_ALIGNMENT);\n+        copy_bytes((_store_buffer + entries_address[i].offset()), (address)current, size);\n+        entries_address[i].set_offset(current - start); \/\/ New offset\n+        entries_address[i].update_method_for_writing();\n+        current += size;\n+        uint n = write_bytes(&(entries_address[i]), sizeof(AOTCodeEntry));\n+        if (n != sizeof(AOTCodeEntry)) {\n+          FREE_C_HEAP_ARRAY(char, buffer);\n+          FREE_C_HEAP_ARRAY(uint, search);\n+          return false;\n+        }\n+        search[entries_count*2 + 0] = entries_address[i].id();\n+        search[entries_count*2 + 1] = entries_count;\n+        entries_count++;\n+      }\n+    }\n+\n+    if (entries_count == 0) {\n+      log_info(aot, codecache, exit)(\"No entires written to AOT Code Cache\");\n+      FREE_C_HEAP_ARRAY(char, buffer);\n+      FREE_C_HEAP_ARRAY(uint, search);\n+      return true; \/\/ Nothing to write\n+    }\n+    assert(entries_count <= (store_count + load_count), \"%d > (%d + %d)\", entries_count, store_count, load_count);\n+    \/\/ Write strings\n+    if (strings_count > 0) {\n+      copy_bytes((_store_buffer + strings_offset), (address)current, strings_size);\n+      strings_offset = (current - start); \/\/ New offset\n+      current += strings_size;\n+    }\n+    uint preload_entries_offset = (current - start);\n+    preload_entries_size = preload_entries_cnt * sizeof(uint);\n+    if (preload_entries_size > 0) {\n+      copy_bytes((const char*)preload_entries, (address)current, preload_entries_size);\n+      current += preload_entries_size;\n+      log_info(aot, codecache, exit)(\"Wrote %d preload entries to AOT Code Cache\", preload_entries_cnt);\n+    }\n+    if (preload_entries != nullptr) {\n+      FREE_C_HEAP_ARRAY(uint, preload_entries);\n+    }\n+\n+    uint new_entries_offset = (current - start); \/\/ New offset\n+    \/\/ Sort and store search table\n+    qsort(search, entries_count, 2*sizeof(uint), uint_cmp);\n+    search_size = 2 * entries_count * sizeof(uint);\n+    copy_bytes((const char*)search, (address)current, search_size);\n+    FREE_C_HEAP_ARRAY(uint, search);\n+    current += search_size;\n+\n+    \/\/ Write entries\n+    entries_size = entries_count * sizeof(AOTCodeEntry); \/\/ New size\n+    copy_bytes((_store_buffer + entries_offset), (address)current, entries_size);\n+    current += entries_size;\n+\n+    log_stats_on_exit();\n+\n+    uint size = (current - start);\n+    assert(size <= total_size, \"%d > %d\", size , total_size);\n+\n+    \/\/ Finalize header\n+    AOTCodeCache::Header* header = (AOTCodeCache::Header*)start;\n+    header->init(size,\n+                 (uint)strings_count, strings_offset,\n+                 entries_count, new_entries_offset,\n+                 preload_entries_cnt, preload_entries_offset,\n+                 _use_meta_ptrs);\n+    log_info(aot, codecache, init)(\"Wrote AOTCodeCache header to AOT Code Cache\");\n+    log_info(aot, codecache, exit)(\"Wrote %d bytes of data to AOT Code Cache\", size);\n+\n+    _cached_code_directory->set_aot_code_data(size, start);\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::load_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) {\n+  assert(start == cgen->assembler()->pc(), \"wrong buffer\");\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  AOTCodeEntry* entry = cache->find_entry(AOTCodeEntry::Stub, (uint)id);\n+  if (entry == nullptr) {\n+    return false;\n+  }\n+  uint entry_position = entry->offset();\n+  \/\/ Read name\n+  uint name_offset = entry->name_offset() + entry_position;\n+  uint name_size   = entry->name_size(); \/\/ Includes '\/0'\n+  const char* saved_name = cache->addr(name_offset);\n+  if (strncmp(name, saved_name, (name_size - 1)) != 0) {\n+    log_warning(aot, codecache)(\"Saved stub's name '%s' is different from '%s' for id:%d\", saved_name, name, (int)id);\n+    cache->set_failed();\n+    exit_vm_on_load_failure();\n+    return false;\n+  }\n+  log_info(aot, codecache,stubs)(\"Reading stub '%s' id:%d from AOT Code Cache\", name, (int)id);\n+  \/\/ Read code\n+  uint code_offset = entry->code_offset() + entry_position;\n+  uint code_size   = entry->code_size();\n+  copy_bytes(cache->addr(code_offset), start, code_size);\n+  cgen->assembler()->code_section()->set_end(start + code_size);\n+  log_info(aot, codecache,stubs)(\"Read stub '%s' id:%d from AOT Code Cache\", name, (int)id);\n+  return true;\n+}\n+\n+bool AOTCodeCache::store_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) {\n+  AOTCodeCache* cache = open_for_write();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  log_info(aot, codecache, stubs)(\"Writing stub '%s' id:%d to AOT Code Cache\", name, (int)id);\n+  if (!cache->align_write()) {\n+    return false;\n+  }\n+#ifdef ASSERT\n+  CodeSection* cs = cgen->assembler()->code_section();\n+  if (cs->has_locs()) {\n+    uint reloc_count = cs->locs_count();\n+    tty->print_cr(\"======== write stubs code section relocations [%d]:\", reloc_count);\n+    \/\/ Collect additional data\n+    RelocIterator iter(cs);\n+    while (iter.next()) {\n+      switch (iter.type()) {\n+        case relocInfo::none:\n+          break;\n+        default: {\n+          iter.print_current_on(tty);\n+          fatal(\"stub's relocation %d unimplemented\", (int)iter.type());\n+          break;\n+        }\n+      }\n+    }\n+  }\n+#endif\n+  uint entry_position = cache->_write_position;\n+\n+  \/\/ Write code\n+  uint code_offset = 0;\n+  uint code_size = cgen->assembler()->pc() - start;\n+  uint n = cache->write_bytes(start, code_size);\n+  if (n != code_size) {\n+    return false;\n+  }\n+  \/\/ Write name\n+  uint name_offset = cache->_write_position - entry_position;\n+  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n+  n = cache->write_bytes(name, name_size);\n+  if (n != name_size) {\n+    return false;\n+  }\n+  uint entry_size = cache->_write_position - entry_position;\n+  AOTCodeEntry* entry = new(cache) AOTCodeEntry(entry_position, entry_size, name_offset, name_size,\n+                                        code_offset, code_size, 0, 0,\n+                                        AOTCodeEntry::Stub, (uint32_t)id);\n+  log_info(aot, codecache, stubs)(\"Wrote stub '%s' id:%d to AOT Code Cache\", name, (int)id);\n+  return true;\n+}\n+\n+Klass* AOTCodeReader::read_klass(const methodHandle& comp_method, bool shared) {\n+  uint code_offset = read_position();\n+  uint state = *(uint*)addr(code_offset);\n+  uint init_state = (state  & 1);\n+  uint array_dim  = (state >> 1);\n+  code_offset += sizeof(int);\n+  if (_cache->use_meta_ptrs() && shared) {\n+    uint klass_offset = *(uint*)addr(code_offset);\n+    code_offset += sizeof(uint);\n+    set_read_position(code_offset);\n+    Klass* k = (Klass*)((address)SharedBaseAddress + klass_offset);\n+    if (!MetaspaceShared::is_in_shared_metaspace((address)k)) {\n+      \/\/ Something changed in CDS\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"Lookup failed for shared klass: \" INTPTR_FORMAT \" is not in CDS \", p2i((address)k));\n+      return nullptr;\n+    }\n+    assert(k->is_klass(), \"sanity\");\n+    ResourceMark rm;\n+    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_loaded()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for klass %s: not loaded\",\n+                       compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n+      return nullptr;\n+    } else\n+    \/\/ Allow not initialized klass which was uninitialized during code caching or for preload\n+    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_initialized() && (init_state == 1) && !_preload) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for klass %s: not initialized\",\n+                       compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n+      return nullptr;\n+    }\n+    if (array_dim > 0) {\n+      assert(k->is_instance_klass() || k->is_typeArray_klass(), \"sanity check\");\n+      Klass* ak = k->array_klass_or_null(array_dim);\n+      \/\/ FIXME: what would it take to create an array class on the fly?\n+\/\/      Klass* ak = k->array_klass(dim, JavaThread::current());\n+\/\/      guarantee(JavaThread::current()->pending_exception() == nullptr, \"\");\n+      if (ak == nullptr) {\n+        set_lookup_failed();\n+        log_info(aot, codecache)(\"%d (L%d): %d-dimension array klass lookup failed: %s\",\n+                         compile_id(), comp_level(), array_dim, k->external_name());\n+      }\n+      log_info(aot, codecache)(\"%d (L%d): Klass lookup: %s (object array)\", compile_id(), comp_level(), k->external_name());\n+      return ak;\n+    } else {\n+      log_info(aot, codecache)(\"%d (L%d): Shared klass lookup: %s\",\n+                    compile_id(), comp_level(), k->external_name());\n+      return k;\n+    }\n+  }\n+  int name_length = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+  const char* dest = addr(code_offset);\n+  code_offset += name_length + 1;\n+  set_read_position(code_offset);\n+  TempNewSymbol klass_sym = SymbolTable::probe(&(dest[0]), name_length);\n+  if (klass_sym == nullptr) {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Probe failed for class %s\",\n+                     compile_id(), comp_level(), &(dest[0]));\n+    return nullptr;\n+  }\n+  \/\/ Use class loader of compiled method.\n+  Thread* thread = Thread::current();\n+  Handle loader(thread, comp_method->method_holder()->class_loader());\n+  Klass* k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, loader);\n+  assert(!thread->has_pending_exception(), \"should not throw\");\n+  if (k == nullptr && !loader.is_null()) {\n+    \/\/ Try default loader and domain\n+    k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, Handle());\n+    assert(!thread->has_pending_exception(), \"should not throw\");\n+  }\n+  if (k != nullptr) {\n+    \/\/ Allow not initialized klass which was uninitialized during code caching\n+    if (k->is_instance_klass() && !InstanceKlass::cast(k)->is_initialized() && (init_state == 1)) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d (L%d): Lookup failed for klass %s: not initialized\", compile_id(), comp_level(), &(dest[0]));\n+      return nullptr;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Klass lookup %s\", compile_id(), comp_level(), k->external_name());\n+  } else {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Lookup failed for class %s\", compile_id(), comp_level(), &(dest[0]));\n+    return nullptr;\n+  }\n+  return k;\n+}\n+\n+Method* AOTCodeReader::read_method(const methodHandle& comp_method, bool shared) {\n+  uint code_offset = read_position();\n+  if (_cache->use_meta_ptrs() && shared) {\n+    uint method_offset = *(uint*)addr(code_offset);\n+    code_offset += sizeof(uint);\n+    set_read_position(code_offset);\n+    Method* m = (Method*)((address)SharedBaseAddress + method_offset);\n+    if (!MetaspaceShared::is_in_shared_metaspace((address)m)) {\n+      \/\/ Something changed in CDS\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"Lookup failed for shared method: \" INTPTR_FORMAT \" is not in CDS \", p2i((address)m));\n+      return nullptr;\n+    }\n+    assert(m->is_method(), \"sanity\");\n+    ResourceMark rm;\n+    Klass* k = m->method_holder();\n+    if (!k->is_instance_klass()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for holder %s: not instance klass\",\n+                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n+      return nullptr;\n+    } else if (!MetaspaceShared::is_in_shared_metaspace((address)k)) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for holder %s: not in CDS\",\n+                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n+      return nullptr;\n+    } else if (!InstanceKlass::cast(k)->is_loaded()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for holder %s: not loaded\",\n+                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name());\n+      return nullptr;\n+    } else if (!InstanceKlass::cast(k)->is_linked()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d '%s' (L%d): Lookup failed for holder %s: not linked%s\",\n+                    compile_id(), comp_method->name_and_sig_as_C_string(), comp_level(), k->external_name(), (_preload ? \" for code preload\" : \"\"));\n+      return nullptr;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Shared method lookup: %s\",\n+                  compile_id(), comp_level(), m->name_and_sig_as_C_string());\n+    return m;\n+  }\n+  int holder_length = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+  int name_length = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+  int signat_length = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+\n+  const char* dest = addr(code_offset);\n+  code_offset += holder_length + 1 + name_length + 1 + signat_length + 1;\n+  set_read_position(code_offset);\n+  TempNewSymbol klass_sym = SymbolTable::probe(&(dest[0]), holder_length);\n+  if (klass_sym == nullptr) {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Probe failed for class %s\", compile_id(), comp_level(), &(dest[0]));\n+    return nullptr;\n+  }\n+  \/\/ Use class loader of compiled method.\n+  Thread* thread = Thread::current();\n+  Handle loader(thread, comp_method->method_holder()->class_loader());\n+  Klass* k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, loader);\n+  assert(!thread->has_pending_exception(), \"should not throw\");\n+  if (k == nullptr && !loader.is_null()) {\n+    \/\/ Try default loader and domain\n+    k = SystemDictionary::find_instance_or_array_klass(thread, klass_sym, Handle());\n+    assert(!thread->has_pending_exception(), \"should not throw\");\n+  }\n+  if (k != nullptr) {\n+    if (!k->is_instance_klass()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d (L%d): Lookup failed for holder %s: not instance klass\",\n+                       compile_id(), comp_level(), &(dest[0]));\n+      return nullptr;\n+    } else if (!InstanceKlass::cast(k)->is_linked()) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d (L%d): Lookup failed for holder %s: not linked\",\n+                       compile_id(), comp_level(), &(dest[0]));\n+      return nullptr;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Holder lookup: %s\", compile_id(), comp_level(), k->external_name());\n+  } else {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Lookup failed for holder %s\",\n+                  compile_id(), comp_level(), &(dest[0]));\n+    return nullptr;\n+  }\n+  TempNewSymbol name_sym = SymbolTable::probe(&(dest[holder_length + 1]), name_length);\n+  int pos = holder_length + 1 + name_length + 1;\n+  TempNewSymbol sign_sym = SymbolTable::probe(&(dest[pos]), signat_length);\n+  if (name_sym == nullptr) {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Probe failed for method name %s\",\n+                     compile_id(), comp_level(), &(dest[holder_length + 1]));\n+    return nullptr;\n+  }\n+  if (sign_sym == nullptr) {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Probe failed for method signature %s\",\n+                     compile_id(), comp_level(), &(dest[pos]));\n+    return nullptr;\n+  }\n+  Method* m = InstanceKlass::cast(k)->find_method(name_sym, sign_sym);\n+  if (m != nullptr) {\n+    ResourceMark rm;\n+    log_info(aot, codecache)(\"%d (L%d): Method lookup: %s\", compile_id(), comp_level(), m->name_and_sig_as_C_string());\n+  } else {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Lookup failed for method %s::%s%s\",\n+                     compile_id(), comp_level(), &(dest[0]), &(dest[holder_length + 1]), &(dest[pos]));\n+    return nullptr;\n+  }\n+  return m;\n+}\n+\n+bool AOTCodeCache::write_klass(Klass* klass) {\n+  bool can_use_meta_ptrs = _use_meta_ptrs;\n+  uint array_dim = 0;\n+  if (klass->is_objArray_klass()) {\n+    array_dim = ObjArrayKlass::cast(klass)->dimension();\n+    klass     = ObjArrayKlass::cast(klass)->bottom_klass(); \/\/ overwrites klass\n+  }\n+  uint init_state = 0;\n+  if (klass->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    ClassLoaderData* cld = ik->class_loader_data();\n+    if (!cld->is_builtin_class_loader_data()) {\n+      set_lookup_failed();\n+      return false;\n+    }\n+    if (_for_preload && !CDSAccess::can_generate_cached_code(ik)) {\n+      _for_preload = false;\n+      \/\/ Bailout if code has clinit barriers:\n+      \/\/ method will be recompiled without them in any case\n+      if (_has_clinit_barriers) {\n+        set_lookup_failed();\n+        return false;\n+      }\n+      can_use_meta_ptrs = false;\n+    }\n+    init_state = (ik->is_initialized() ? 1 : 0);\n+  }\n+  ResourceMark rm;\n+  uint state = (array_dim << 1) | (init_state & 1);\n+  if (can_use_meta_ptrs && CDSAccess::can_generate_cached_code(klass)) {\n+    DataKind kind = DataKind::Klass_Shared;\n+    uint n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    \/\/ Record state of instance klass initialization.\n+    n = write_bytes(&state, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    uint klass_offset = CDSAccess::delta_from_shared_address_base((address)klass);\n+    n = write_bytes(&klass_offset, sizeof(uint));\n+    if (n != sizeof(uint)) {\n+      return false;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Wrote shared klass: %s%s%s @ 0x%08x\", compile_id(), comp_level(), klass->external_name(),\n+                  (!klass->is_instance_klass() ? \"\" : (init_state == 1 ? \" (initialized)\" : \" (not-initialized)\")),\n+                  (array_dim > 0 ? \" (object array)\" : \"\"),\n+                  klass_offset);\n+    return true;\n+  }\n+  \/\/ Bailout if code has clinit barriers:\n+  \/\/ method will be recompiled without them in any case\n+  if (_for_preload && _has_clinit_barriers) {\n+    set_lookup_failed();\n+    return false;\n+  }\n+  _for_preload = false;\n+  log_info(aot, codecache,cds)(\"%d (L%d): Not shared klass: %s\", compile_id(), comp_level(), klass->external_name());\n+  if (klass->is_hidden()) { \/\/ Skip such nmethod\n+    set_lookup_failed();\n+    return false;\n+  }\n+  DataKind kind = DataKind::Klass;\n+  uint n = write_bytes(&kind, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  \/\/ Record state of instance klass initialization.\n+  n = write_bytes(&state, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  Symbol* name = klass->name();\n+  int name_length = name->utf8_length();\n+  int total_length = name_length + 1;\n+  char* dest = NEW_RESOURCE_ARRAY(char, total_length);\n+  name->as_C_string(dest, total_length);\n+  dest[total_length - 1] = '\\0';\n+  LogTarget(Info, aot, codecache, loader) log;\n+  if (log.is_enabled()) {\n+    LogStream ls(log);\n+    oop loader = klass->class_loader();\n+    oop domain = klass->protection_domain();\n+    ls.print(\"Class %s loader: \", dest);\n+    if (loader == nullptr) {\n+      ls.print(\"nullptr\");\n+    } else {\n+      loader->print_value_on(&ls);\n+    }\n+    ls.print(\" domain: \");\n+    if (domain == nullptr) {\n+      ls.print(\"nullptr\");\n+    } else {\n+      domain->print_value_on(&ls);\n+    }\n+    ls.cr();\n+  }\n+  n = write_bytes(&name_length, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  n = write_bytes(dest, total_length);\n+  if (n != (uint)total_length) {\n+    return false;\n+  }\n+  log_info(aot, codecache)(\"%d (L%d): Wrote klass: %s%s%s\",\n+                compile_id(), comp_level(),\n+                dest, (!klass->is_instance_klass() ? \"\" : (init_state == 1 ? \" (initialized)\" : \" (not-initialized)\")),\n+                (array_dim > 0 ? \" (object array)\" : \"\"));\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_method(Method* method) {\n+  bool can_use_meta_ptrs = _use_meta_ptrs;\n+  Klass* klass = method->method_holder();\n+  if (klass->is_instance_klass()) {\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    ClassLoaderData* cld = ik->class_loader_data();\n+    if (!cld->is_builtin_class_loader_data()) {\n+      set_lookup_failed();\n+      return false;\n+    }\n+    if (_for_preload && !CDSAccess::can_generate_cached_code(ik)) {\n+      _for_preload = false;\n+      \/\/ Bailout if code has clinit barriers:\n+      \/\/ method will be recompiled without them in any case\n+      if (_has_clinit_barriers) {\n+        set_lookup_failed();\n+        return false;\n+      }\n+      can_use_meta_ptrs = false;\n+    }\n+  }\n+  ResourceMark rm;\n+  if (can_use_meta_ptrs && CDSAccess::can_generate_cached_code(method)) {\n+    DataKind kind = DataKind::Method_Shared;\n+    uint n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    uint method_offset = CDSAccess::delta_from_shared_address_base((address)method);\n+    n = write_bytes(&method_offset, sizeof(uint));\n+    if (n != sizeof(uint)) {\n+      return false;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Wrote shared method: %s @ 0x%08x\", compile_id(), comp_level(), method->name_and_sig_as_C_string(), method_offset);\n+    return true;\n+  }\n+  \/\/ Bailout if code has clinit barriers:\n+  \/\/ method will be recompiled without them in any case\n+  if (_for_preload && _has_clinit_barriers) {\n+    set_lookup_failed();\n+    return false;\n+  }\n+  _for_preload = false;\n+  log_info(aot, codecache,cds)(\"%d (L%d): Not shared method: %s\", compile_id(), comp_level(), method->name_and_sig_as_C_string());\n+  if (method->is_hidden()) { \/\/ Skip such nmethod\n+    set_lookup_failed();\n+    return false;\n+  }\n+  DataKind kind = DataKind::Method;\n+  uint n = write_bytes(&kind, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  Symbol* name   = method->name();\n+  Symbol* holder = method->klass_name();\n+  Symbol* signat = method->signature();\n+  int name_length   = name->utf8_length();\n+  int holder_length = holder->utf8_length();\n+  int signat_length = signat->utf8_length();\n+\n+  \/\/ Write sizes and strings\n+  int total_length = holder_length + 1 + name_length + 1 + signat_length + 1;\n+  char* dest = NEW_RESOURCE_ARRAY(char, total_length);\n+  holder->as_C_string(dest, total_length);\n+  dest[holder_length] = '\\0';\n+  int pos = holder_length + 1;\n+  name->as_C_string(&(dest[pos]), (total_length - pos));\n+  pos += name_length;\n+  dest[pos++] = '\\0';\n+  signat->as_C_string(&(dest[pos]), (total_length - pos));\n+  dest[total_length - 1] = '\\0';\n+\n+  LogTarget(Info, aot, codecache, loader) log;\n+  if (log.is_enabled()) {\n+    LogStream ls(log);\n+    oop loader = klass->class_loader();\n+    oop domain = klass->protection_domain();\n+    ls.print(\"Holder %s loader: \", dest);\n+    if (loader == nullptr) {\n+      ls.print(\"nullptr\");\n+    } else {\n+      loader->print_value_on(&ls);\n+    }\n+    ls.print(\" domain: \");\n+    if (domain == nullptr) {\n+      ls.print(\"nullptr\");\n+    } else {\n+      domain->print_value_on(&ls);\n+    }\n+    ls.cr();\n+  }\n+\n+  n = write_bytes(&holder_length, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  n = write_bytes(&name_length, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  n = write_bytes(&signat_length, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  n = write_bytes(dest, total_length);\n+  if (n != (uint)total_length) {\n+    return false;\n+  }\n+  dest[holder_length] = ' ';\n+  dest[holder_length + 1 + name_length] = ' ';\n+  log_info(aot, codecache)(\"%d (L%d): Wrote method: %s\", compile_id(), comp_level(), dest);\n+  return true;\n+}\n+\n+\/\/ Repair the pc relative information in the code after load\n+bool AOTCodeReader::read_relocations(CodeBuffer* buffer, CodeBuffer* orig_buffer,\n+                                 OopRecorder* oop_recorder, ciMethod* target) {\n+  bool success = true;\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    uint code_offset = read_position();\n+    int reloc_count = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    if (reloc_count == 0) {\n+      set_read_position(code_offset);\n+      continue;\n+    }\n+    \/\/ Read _locs_point (as offset from start)\n+    int locs_point_off = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    uint reloc_size = reloc_count * sizeof(relocInfo);\n+    CodeSection* cs  = buffer->code_section(i);\n+    if (cs->locs_capacity() < reloc_count) {\n+      cs->expand_locs(reloc_count);\n+    }\n+    relocInfo* reloc_start = cs->locs_start();\n+    copy_bytes(addr(code_offset), (address)reloc_start, reloc_size);\n+    code_offset += reloc_size;\n+    cs->set_locs_end(reloc_start + reloc_count);\n+    cs->set_locs_point(cs->start() + locs_point_off);\n+\n+    \/\/ Read additional relocation data: uint per relocation\n+    uint  data_size  = reloc_count * sizeof(uint);\n+    uint* reloc_data = (uint*)addr(code_offset);\n+    code_offset += data_size;\n+    set_read_position(code_offset);\n+    LogStreamHandle(Info, aot, codecache, reloc) log;\n+    if (log.is_enabled()) {\n+      log.print_cr(\"======== read code section %d relocations [%d]:\", i, reloc_count);\n+    }\n+    RelocIterator iter(cs);\n+    int j = 0;\n+    while (iter.next()) {\n+      switch (iter.type()) {\n+        case relocInfo::none:\n+          break;\n+        case relocInfo::oop_type: {\n+          VM_ENTRY_MARK;\n+          oop_Relocation* r = (oop_Relocation*)iter.reloc();\n+          if (r->oop_is_immediate()) {\n+            assert(reloc_data[j] == (uint)j, \"should be\");\n+            methodHandle comp_method(THREAD, target->get_Method());\n+            oop obj = read_oop(THREAD, comp_method);\n+            jobject jo = JNIHandles::make_local(THREAD, obj);\n+            if (lookup_failed()) {\n+              success = false;\n+              break;\n+            }\n+            r->set_value((address)jo);\n+          } else if (false) {\n+            \/\/ Get already updated value from OopRecorder.\n+            assert(oop_recorder != nullptr, \"sanity\");\n+            int index = r->oop_index();\n+            jobject jo = oop_recorder->oop_at(index);\n+            oop obj = JNIHandles::resolve(jo);\n+            r->set_value(*reinterpret_cast<address*>(&obj));\n+          }\n+          break;\n+        }\n+        case relocInfo::metadata_type: {\n+          VM_ENTRY_MARK;\n+          metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n+          Metadata* m;\n+          if (r->metadata_is_immediate()) {\n+            assert(reloc_data[j] == (uint)j, \"should be\");\n+            methodHandle comp_method(THREAD, target->get_Method());\n+            m = read_metadata(comp_method);\n+            if (lookup_failed()) {\n+              success = false;\n+              break;\n+            }\n+          } else {\n+            \/\/ Get already updated value from OopRecorder.\n+            assert(oop_recorder != nullptr, \"sanity\");\n+            int index = r->metadata_index();\n+            m = oop_recorder->metadata_at(index);\n+          }\n+          r->set_value((address)m);\n+          break;\n+        }\n+        case relocInfo::virtual_call_type:   \/\/ Fall through. They all call resolve_*_call blobs.\n+        case relocInfo::opt_virtual_call_type:\n+        case relocInfo::static_call_type: {\n+          address dest = _cache->address_for_id(reloc_data[j]);\n+          if (dest != (address)-1) {\n+            ((CallRelocation*)iter.reloc())->set_destination(dest);\n+          }\n+          break;\n+        }\n+        case relocInfo::trampoline_stub_type: {\n+          address dest = _cache->address_for_id(reloc_data[j]);\n+          if (dest != (address)-1) {\n+            ((trampoline_stub_Relocation*)iter.reloc())->set_destination(dest);\n+          }\n+          break;\n+        }\n+        case relocInfo::static_stub_type:\n+          break;\n+        case relocInfo::runtime_call_type: {\n+          address dest = _cache->address_for_id(reloc_data[j]);\n+          if (dest != (address)-1) {\n+            ((CallRelocation*)iter.reloc())->set_destination(dest);\n+          }\n+          break;\n+        }\n+        case relocInfo::runtime_call_w_cp_type:\n+          fatal(\"runtime_call_w_cp_type unimplemented\");\n+          \/\/address destination = iter.reloc()->value();\n+          break;\n+        case relocInfo::external_word_type: {\n+          address target = _cache->address_for_id(reloc_data[j]);\n+          \/\/ Add external address to global table\n+          int index = ExternalsRecorder::find_index(target);\n+          \/\/ Update index in relocation\n+          Relocation::add_jint(iter.data(), index);\n+          external_word_Relocation* reloc = (external_word_Relocation*)iter.reloc();\n+          assert(reloc->target() == target, \"sanity\");\n+          reloc->set_value(target); \/\/ Patch address in the code\n+          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n+          break;\n+        }\n+        case relocInfo::internal_word_type:\n+          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n+          break;\n+        case relocInfo::section_word_type:\n+          iter.reloc()->fix_relocation_after_move(orig_buffer, buffer);\n+          break;\n+        case relocInfo::poll_type:\n+          break;\n+        case relocInfo::poll_return_type:\n+          break;\n+        case relocInfo::post_call_nop_type:\n+          break;\n+        case relocInfo::entry_guard_type:\n+          break;\n+        default:\n+          fatal(\"relocation %d unimplemented\", (int)iter.type());\n+          break;\n+      }\n+      if (success && log.is_enabled()) {\n+        iter.print_current_on(&log);\n+      }\n+      j++;\n+    }\n+    assert(j <= (int)reloc_count, \"sanity\");\n+  }\n+  return success;\n+}\n+\n+bool AOTCodeReader::read_code(CodeBuffer* buffer, CodeBuffer* orig_buffer, uint code_offset) {\n+  assert(code_offset == align_up(code_offset, DATA_ALIGNMENT), \"%d not aligned to %d\", code_offset, DATA_ALIGNMENT);\n+  AOTCodeSection* aot_cs = (AOTCodeSection*)addr(code_offset);\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    CodeSection* cs = buffer->code_section(i);\n+    \/\/ Read original section size and address.\n+    uint orig_size = aot_cs[i]._size;\n+    log_debug(aot, codecache)(\"======== read code section %d [%d]:\", i, orig_size);\n+    uint orig_size_align = align_up(orig_size, DATA_ALIGNMENT);\n+    if (i != (int)CodeBuffer::SECT_INSTS) {\n+      buffer->initialize_section_size(cs, orig_size_align);\n+    }\n+    if (orig_size_align > (uint)cs->capacity()) { \/\/ Will not fit\n+      log_info(aot, codecache)(\"%d (L%d): original code section %d size %d > current capacity %d\",\n+                       compile_id(), comp_level(), i, orig_size, cs->capacity());\n+      return false;\n+    }\n+    if (orig_size == 0) {\n+      assert(cs->size() == 0, \"should match\");\n+      continue;  \/\/ skip trivial section\n+    }\n+    address orig_start = aot_cs[i]._origin_address;\n+\n+    \/\/ Populate fake original buffer (no code allocation in CodeCache).\n+    \/\/ It is used for relocations to calculate sections addesses delta.\n+    CodeSection* orig_cs = orig_buffer->code_section(i);\n+    assert(!orig_cs->is_allocated(), \"This %d section should not be set\", i);\n+    orig_cs->initialize(orig_start, orig_size);\n+\n+    \/\/ Load code to new buffer.\n+    address code_start = cs->start();\n+    copy_bytes(addr(aot_cs[i]._offset + code_offset), code_start, orig_size_align);\n+    cs->set_end(code_start + orig_size);\n+  }\n+\n+  return true;\n+}\n+\n+bool AOTCodeCache::load_adapter(CodeBuffer* buffer, uint32_t id, const char* name, uint32_t offsets[4]) {\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, stubs) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+  }\n+#endif\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  log_info(aot, codecache, stubs)(\"Looking up adapter %s (0x%x) in AOT Code Cache\", name, id);\n+  AOTCodeEntry* entry = cache->find_entry(AOTCodeEntry::Adapter, id);\n+  if (entry == nullptr) {\n+    return false;\n+  }\n+  AOTCodeReader reader(cache, entry, nullptr);\n+  return reader.compile_adapter(buffer, name, offsets);\n+}\n+bool AOTCodeReader::compile_adapter(CodeBuffer* buffer, const char* name, uint32_t offsets[4]) {\n+  uint entry_position = _entry->offset();\n+  \/\/ Read name\n+  uint name_offset = entry_position + _entry->name_offset();\n+  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n+  const char* stored_name = addr(name_offset);\n+  log_info(aot, codecache, stubs)(\"%d (L%d): Reading adapter '%s' from AOT Code Cache\",\n+                       compile_id(), comp_level(), name);\n+  if (strncmp(stored_name, name, (name_size - 1)) != 0) {\n+    log_warning(aot, codecache)(\"%d (L%d): Saved adapter's name '%s' is different from '%s'\",\n+                     compile_id(), comp_level(), stored_name, name);\n+    \/\/ n.b. this is not fatal -- we have just seen a hash id clash\n+    \/\/ so no need to call cache->set_failed()\n+    return false;\n+  }\n+  \/\/ Create fake original CodeBuffer\n+  CodeBuffer orig_buffer(name);\n+  \/\/ Read code\n+  uint code_offset = entry_position + _entry->code_offset();\n+  if (!read_code(buffer, &orig_buffer, code_offset)) {\n+    return false;\n+  }\n+  \/\/ Read relocations\n+  uint reloc_offset = entry_position + _entry->reloc_offset();\n+  set_read_position(reloc_offset);\n+  if (!read_relocations(buffer, &orig_buffer, nullptr, nullptr)) {\n+    return false;\n+  }\n+  uint offset = read_position();\n+  int offsets_count = *(int*)addr(offset);\n+  offset += sizeof(int);\n+  assert(offsets_count == 4, \"wrong caller expectations\");\n+  set_read_position(offset);\n+  for (int i = 0; i < offsets_count; i++) {\n+    uint32_t arg = *(uint32_t*)addr(offset);\n+    offset += sizeof(uint32_t);\n+    log_debug(aot, codecache, stubs)(\"%d (L%d): Reading adapter '%s'  offsets[%d] == 0x%x from AOT Code Cache\",\n+                         compile_id(), comp_level(), stored_name, i, arg);\n+    offsets[i] = arg;\n+  }\n+  log_debug(aot, codecache, stubs)(\"%d (L%d): Read adapter '%s' with '%d' args from AOT Code Cache\",\n+                       compile_id(), comp_level(), stored_name, offsets_count);\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, stubs) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+    buffer->decode();\n+  }\n+#endif\n+  \/\/ mark entry as loaded\n+  ((AOTCodeEntry *)_entry)->set_loaded();\n+  return true;\n+}\n+\n+bool AOTCodeCache::load_exception_blob(CodeBuffer* buffer, int* pc_offset) {\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, nmethod) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+  }\n+#endif\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  AOTCodeEntry* entry = cache->find_entry(AOTCodeEntry::Blob, 999);\n+  if (entry == nullptr) {\n+    return false;\n+  }\n+  AOTCodeReader reader(cache, entry, nullptr);\n+  return reader.compile_blob(buffer, pc_offset);\n+}\n+\n+bool AOTCodeReader::compile_blob(CodeBuffer* buffer, int* pc_offset) {\n+  uint entry_position = _entry->offset();\n+\n+  \/\/ Read pc_offset\n+  *pc_offset = *(int*)addr(entry_position);\n+\n+  \/\/ Read name\n+  uint name_offset = entry_position + _entry->name_offset();\n+  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n+  const char* name = addr(name_offset);\n+\n+  log_info(aot, codecache, stubs)(\"%d (L%d): Reading blob '%s' with pc_offset %d from AOT Code Cache\",\n+                       compile_id(), comp_level(), name, *pc_offset);\n+\n+  if (strncmp(buffer->name(), name, (name_size - 1)) != 0) {\n+    log_warning(aot, codecache)(\"%d (L%d): Saved blob's name '%s' is different from '%s'\",\n+                                compile_id(), comp_level(), name, buffer->name());\n+    ((AOTCodeCache*)_cache)->set_failed();\n+    exit_vm_on_load_failure();\n+    return false;\n+  }\n+\n+  \/\/ Create fake original CodeBuffer\n+  CodeBuffer orig_buffer(name);\n+\n+  \/\/ Read code\n+  uint code_offset = entry_position + _entry->code_offset();\n+  if (!read_code(buffer, &orig_buffer, code_offset)) {\n+    return false;\n+  }\n+\n+  \/\/ Read relocations\n+  uint reloc_offset = entry_position + _entry->reloc_offset();\n+  set_read_position(reloc_offset);\n+  if (!read_relocations(buffer, &orig_buffer, nullptr, nullptr)) {\n+    return false;\n+  }\n+\n+  log_info(aot, codecache, stubs)(\"%d (L%d): Read blob '%s' from AOT Code Cache\",\n+                       compile_id(), comp_level(), name);\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, nmethod) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+    buffer->decode();\n+  }\n+#endif\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_relocations(CodeBuffer* buffer, uint& all_reloc_size) {\n+  uint all_reloc_count = 0;\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    CodeSection* cs = buffer->code_section(i);\n+    uint reloc_count = cs->has_locs() ? cs->locs_count() : 0;\n+    all_reloc_count += reloc_count;\n+  }\n+  all_reloc_size = all_reloc_count * sizeof(relocInfo);\n+  bool success = true;\n+  uint* reloc_data = NEW_C_HEAP_ARRAY(uint, all_reloc_count, mtCode);\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    CodeSection* cs = buffer->code_section(i);\n+    int reloc_count = cs->has_locs() ? cs->locs_count() : 0;\n+    uint n = write_bytes(&reloc_count, sizeof(int));\n+    if (n != sizeof(int)) {\n+      success = false;\n+      break;\n+    }\n+    if (reloc_count == 0) {\n+      continue;\n+    }\n+    \/\/ Write _locs_point (as offset from start)\n+    int locs_point_off = cs->locs_point_off();\n+    n = write_bytes(&locs_point_off, sizeof(int));\n+    if (n != sizeof(int)) {\n+      success = false;\n+      break;\n+    }\n+    relocInfo* reloc_start = cs->locs_start();\n+    uint reloc_size      = reloc_count * sizeof(relocInfo);\n+    n = write_bytes(reloc_start, reloc_size);\n+    if (n != reloc_size) {\n+      success = false;\n+      break;\n+    }\n+    LogStreamHandle(Info, aot, codecache, reloc) log;\n+    if (log.is_enabled()) {\n+      log.print_cr(\"======== write code section %d relocations [%d]:\", i, reloc_count);\n+    }\n+    \/\/ Collect additional data\n+    RelocIterator iter(cs);\n+    bool has_immediate = false;\n+    int j = 0;\n+    while (iter.next()) {\n+      reloc_data[j] = 0; \/\/ initialize\n+      switch (iter.type()) {\n+        case relocInfo::none:\n+          break;\n+        case relocInfo::oop_type: {\n+          oop_Relocation* r = (oop_Relocation*)iter.reloc();\n+          if (r->oop_is_immediate()) {\n+            reloc_data[j] = (uint)j; \/\/ Indication that we need to restore immediate\n+            has_immediate = true;\n+          }\n+          break;\n+        }\n+        case relocInfo::metadata_type: {\n+          metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n+          if (r->metadata_is_immediate()) {\n+            reloc_data[j] = (uint)j; \/\/ Indication that we need to restore immediate\n+            has_immediate = true;\n+          }\n+          break;\n+        }\n+        case relocInfo::virtual_call_type:  \/\/ Fall through. They all call resolve_*_call blobs.\n+        case relocInfo::opt_virtual_call_type:\n+        case relocInfo::static_call_type: {\n+          CallRelocation* r = (CallRelocation*)iter.reloc();\n+          address dest = r->destination();\n+          if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n+            dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n+          }\n+          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n+          break;\n+        }\n+        case relocInfo::trampoline_stub_type: {\n+          address dest = ((trampoline_stub_Relocation*)iter.reloc())->destination();\n+          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n+          break;\n+        }\n+        case relocInfo::static_stub_type:\n+          break;\n+        case relocInfo::runtime_call_type: {\n+          \/\/ Record offset of runtime destination\n+          CallRelocation* r = (CallRelocation*)iter.reloc();\n+          address dest = r->destination();\n+          if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n+            dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n+          }\n+          reloc_data[j] = _table->id_for_address(dest, iter, buffer);\n+          break;\n+        }\n+        case relocInfo::runtime_call_w_cp_type:\n+          fatal(\"runtime_call_w_cp_type unimplemented\");\n+          break;\n+        case relocInfo::external_word_type: {\n+          \/\/ Record offset of runtime target\n+          address target = ((external_word_Relocation*)iter.reloc())->target();\n+          reloc_data[j] = _table->id_for_address(target, iter, buffer);\n+          break;\n+        }\n+        case relocInfo::internal_word_type:\n+          break;\n+        case relocInfo::section_word_type:\n+          break;\n+        case relocInfo::poll_type:\n+          break;\n+        case relocInfo::poll_return_type:\n+          break;\n+        case relocInfo::post_call_nop_type:\n+          break;\n+        case relocInfo::entry_guard_type:\n+          break;\n+        default:\n+          fatal(\"relocation %d unimplemented\", (int)iter.type());\n+          break;\n+      }\n+      if (log.is_enabled()) {\n+        iter.print_current_on(&log);\n+      }\n+      j++;\n+    }\n+    assert(j <= (int)reloc_count, \"sanity\");\n+    \/\/ Write additional relocation data: uint per relocation\n+    uint data_size = reloc_count * sizeof(uint);\n+    n = write_bytes(reloc_data, data_size);\n+    if (n != data_size) {\n+      success = false;\n+      break;\n+    }\n+    if (has_immediate) {\n+      \/\/ Save information about immediates in this Code Section\n+      RelocIterator iter_imm(cs);\n+      int j = 0;\n+      while (iter_imm.next()) {\n+        switch (iter_imm.type()) {\n+          case relocInfo::oop_type: {\n+            oop_Relocation* r = (oop_Relocation*)iter_imm.reloc();\n+            if (r->oop_is_immediate()) {\n+              assert(reloc_data[j] == (uint)j, \"should be\");\n+              jobject jo = *(jobject*)(r->oop_addr()); \/\/ Handle currently\n+              if (!write_oop(jo)) {\n+                success = false;\n+              }\n+            }\n+            break;\n+          }\n+          case relocInfo::metadata_type: {\n+            metadata_Relocation* r = (metadata_Relocation*)iter_imm.reloc();\n+            if (r->metadata_is_immediate()) {\n+              assert(reloc_data[j] == (uint)j, \"should be\");\n+              Metadata* m = r->metadata_value();\n+              if (!write_metadata(m)) {\n+                success = false;\n+              }\n+            }\n+            break;\n+          }\n+          default:\n+            break;\n+        }\n+        if (!success) {\n+          break;\n+        }\n+        j++;\n+      } \/\/ while (iter_imm.next())\n+    } \/\/ if (has_immediate)\n+  } \/\/ for(i < SECT_LIMIT)\n+  FREE_C_HEAP_ARRAY(uint, reloc_data);\n+  return success;\n+}\n+\n+bool AOTCodeCache::store_adapter(CodeBuffer* buffer, uint32_t id, const char* name, uint32_t offsets[4]) {\n+  assert(CDSConfig::is_dumping_adapters(), \"must be\");\n+  AOTCodeCache* cache = open_for_write();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  log_info(aot, codecache, stubs)(\"Writing adapter '%s' (0x%x) to AOT Code Cache\", name, id);\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, stubs) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+    buffer->decode();\n+  }\n+#endif\n+  \/\/ we need to take a lock to stop main thread racing with C1 and C2 compiler threads to\n+  \/\/ write blobs in parallel with each other or with later nmethods\n+  MutexLocker ml(Compile_lock);\n+  if (!cache->align_write()) {\n+    return false;\n+  }\n+  uint entry_position = cache->_write_position;\n+  \/\/ Write name\n+  uint name_offset = cache->_write_position - entry_position;\n+  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n+  uint n = cache->write_bytes(name, name_size);\n+  if (n != name_size) {\n+    return false;\n+  }\n+  \/\/ Write code section\n+  if (!cache->align_write()) {\n+    return false;\n+  }\n+  uint code_offset = cache->_write_position - entry_position;\n+  uint code_size = 0;\n+  if (!cache->write_code(buffer, code_size)) {\n+    return false;\n+  }\n+  \/\/ Write relocInfo array\n+  uint reloc_offset = cache->_write_position - entry_position;\n+  uint reloc_size = 0;\n+  if (!cache->write_relocations(buffer, reloc_size)) {\n+    return false;\n+  }\n+  int extras_count = 4;\n+  n = cache->write_bytes(&extras_count, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  for (int i = 0; i < 4; i++) {\n+    uint32_t arg = offsets[i];\n+    log_debug(aot, codecache, stubs)(\"Writing adapter '%s' (0x%x) offsets[%d] == 0x%x to AOT Code Cache\", name, id, i, arg);\n+    n = cache->write_bytes(&arg, sizeof(uint32_t));\n+    if (n != sizeof(uint32_t)) {\n+      return false;\n+    }\n+  }\n+  uint entry_size = cache->_write_position - entry_position;\n+  AOTCodeEntry* entry = new (cache) AOTCodeEntry(entry_position, entry_size, name_offset, name_size,\n+                                         code_offset, code_size, reloc_offset, reloc_size,\n+                                         AOTCodeEntry::Adapter, id);\n+  log_info(aot, codecache, stubs)(\"Wrote adapter '%s' (0x%x) to AOT Code Cache\", name, id);\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_code(CodeBuffer* buffer, uint& code_size) {\n+  assert(_write_position == align_up(_write_position, DATA_ALIGNMENT), \"%d not aligned to %d\", _write_position, DATA_ALIGNMENT);\n+  \/\/assert(buffer->blob() != nullptr, \"sanity\");\n+  uint code_offset = _write_position;\n+  uint cb_total_size = (uint)buffer->total_content_size();\n+  \/\/ Write information about Code sections first.\n+  AOTCodeSection aot_cs[CodeBuffer::SECT_LIMIT];\n+  uint aot_cs_size = (uint)(sizeof(AOTCodeSection) * CodeBuffer::SECT_LIMIT);\n+  uint offset = align_up(aot_cs_size, DATA_ALIGNMENT);\n+  uint total_size = 0;\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    const CodeSection* cs = buffer->code_section(i);\n+    assert(cs->mark() == nullptr, \"CodeSection::_mark is not implemented\");\n+    uint cs_size = (uint)cs->size();\n+    aot_cs[i]._size = cs_size;\n+    aot_cs[i]._origin_address = (cs_size == 0) ? nullptr : cs->start();\n+    aot_cs[i]._offset = (cs_size == 0) ? 0 : (offset + total_size);\n+    assert(cs->mark() == nullptr, \"CodeSection::_mark is not implemented\");\n+    total_size += align_up(cs_size, DATA_ALIGNMENT);\n+  }\n+  uint n = write_bytes(aot_cs, aot_cs_size);\n+  if (n != aot_cs_size) {\n+    return false;\n+  }\n+  if (!align_write()) {\n+    return false;\n+  }\n+  assert(_write_position == (code_offset + offset), \"%d  != (%d + %d)\", _write_position, code_offset, offset);\n+  for (int i = 0; i < (int)CodeBuffer::SECT_LIMIT; i++) {\n+    const CodeSection* cs = buffer->code_section(i);\n+    uint cs_size = (uint)cs->size();\n+    if (cs_size == 0) {\n+      continue;  \/\/ skip trivial section\n+    }\n+    assert((_write_position - code_offset) == aot_cs[i]._offset, \"%d != %d\", _write_position, aot_cs[i]._offset);\n+    \/\/ Write code\n+    n = write_bytes(cs->start(), cs_size);\n+    if (n != cs_size) {\n+      return false;\n+    }\n+    if (!align_write()) {\n+      return false;\n+    }\n+  }\n+  assert((_write_position - code_offset) == (offset + total_size), \"(%d - %d) != (%d + %d)\", _write_position, code_offset, offset, total_size);\n+  code_size = total_size;\n+  return true;\n+}\n+\n+bool AOTCodeCache::store_exception_blob(CodeBuffer* buffer, int pc_offset) {\n+  AOTCodeCache* cache = open_for_write();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  log_info(aot, codecache, stubs)(\"Writing blob '%s' to AOT Code Cache\", buffer->name());\n+\n+#ifdef ASSERT\n+  LogStreamHandle(Debug, aot, codecache, nmethod) log;\n+  if (log.is_enabled()) {\n+    FlagSetting fs(PrintRelocations, true);\n+    buffer->print_on(&log);\n+    buffer->decode();\n+  }\n+#endif\n+  \/\/ we need to take a lock to prevent race between compiler thread generating blob and the main thread generating adapter\n+  MutexLocker ml(Compile_lock);\n+  if (!cache->align_write()) {\n+    return false;\n+  }\n+  uint entry_position = cache->_write_position;\n+\n+  \/\/ Write pc_offset\n+  uint n = cache->write_bytes(&pc_offset, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+\n+  \/\/ Write name\n+  const char* name = buffer->name();\n+  uint name_offset = cache->_write_position - entry_position;\n+  uint name_size = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n+  n = cache->write_bytes(name, name_size);\n+  if (n != name_size) {\n+    return false;\n+  }\n+\n+  \/\/ Write code section\n+  if (!cache->align_write()) {\n+    return false;\n+  }\n+  uint code_offset = cache->_write_position - entry_position;\n+  uint code_size = 0;\n+  if (!cache->write_code(buffer, code_size)) {\n+    return false;\n+  }\n+  \/\/ Write relocInfo array\n+  uint reloc_offset = cache->_write_position - entry_position;\n+  uint reloc_size = 0;\n+  if (!cache->write_relocations(buffer, reloc_size)) {\n+    return false;\n+  }\n+\n+  uint entry_size = cache->_write_position - entry_position;\n+  AOTCodeEntry* entry = new(cache) AOTCodeEntry(entry_position, entry_size, name_offset, name_size,\n+                                        code_offset, code_size, reloc_offset, reloc_size,\n+                                        AOTCodeEntry::Blob, (uint32_t)999);\n+  log_info(aot, codecache, stubs)(\"Wrote stub '%s' to AOT Code Cache\", name);\n+  return true;\n+}\n+\n+DebugInformationRecorder* AOTCodeReader::read_debug_info(OopRecorder* oop_recorder) {\n+  uint code_offset = align_up(read_position(), DATA_ALIGNMENT);\n+  int data_size  = *(int*)addr(code_offset);\n+  code_offset   += sizeof(int);\n+  int pcs_length = *(int*)addr(code_offset);\n+  code_offset   += sizeof(int);\n+\n+  log_debug(aot, codecache)(\"======== read DebugInfo [%d, %d]:\", data_size, pcs_length);\n+\n+  \/\/ Aligned initial sizes\n+  int data_size_align  = align_up(data_size, DATA_ALIGNMENT);\n+  int pcs_length_align = pcs_length + 1;\n+  assert(sizeof(PcDesc) > DATA_ALIGNMENT, \"sanity\");\n+  DebugInformationRecorder* recorder = new DebugInformationRecorder(oop_recorder, data_size_align, pcs_length);\n+\n+  copy_bytes(addr(code_offset), recorder->stream()->buffer(), data_size_align);\n+  recorder->stream()->set_position(data_size);\n+  code_offset += data_size;\n+\n+  uint pcs_size = pcs_length * sizeof(PcDesc);\n+  copy_bytes(addr(code_offset), (address)recorder->pcs(), pcs_size);\n+  code_offset += pcs_size;\n+  set_read_position(code_offset);\n+  return recorder;\n+}\n+\n+bool AOTCodeCache::write_debug_info(DebugInformationRecorder* recorder) {\n+  if (!align_write()) {\n+    return false;\n+  }\n+  \/\/ Don't call data_size() and pcs_size(). They will freeze OopRecorder.\n+  int data_size = recorder->stream()->position(); \/\/ In bytes\n+  uint n = write_bytes(&data_size, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  int pcs_length = recorder->pcs_length(); \/\/ In bytes\n+  n = write_bytes(&pcs_length, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  n = write_bytes(recorder->stream()->buffer(), data_size);\n+  if (n != (uint)data_size) {\n+    return false;\n+  }\n+  uint pcs_size = pcs_length * sizeof(PcDesc);\n+  n = write_bytes(recorder->pcs(), pcs_size);\n+  if (n != pcs_size) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+OopMapSet* AOTCodeReader::read_oop_maps() {\n+  uint code_offset = read_position();\n+  int om_count = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+\n+  log_debug(aot, codecache)(\"======== read oop maps [%d]:\", om_count);\n+\n+  OopMapSet* oop_maps = new OopMapSet(om_count);\n+  for (int i = 0; i < (int)om_count; i++) {\n+    int data_size = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+\n+    OopMap* oop_map = new OopMap(data_size);\n+    \/\/ Preserve allocated stream\n+    CompressedWriteStream* stream = oop_map->write_stream();\n+\n+    \/\/ Read data which overwrites default data\n+    copy_bytes(addr(code_offset), (address)oop_map, sizeof(OopMap));\n+    code_offset += sizeof(OopMap);\n+    stream->set_position(data_size);\n+    oop_map->set_write_stream(stream);\n+    if (data_size > 0) {\n+      copy_bytes(addr(code_offset), (address)(oop_map->data()), (uint)data_size);\n+      code_offset += data_size;\n+    }\n+#ifdef ASSERT\n+    oop_map->_locs_length = 0;\n+    oop_map->_locs_used   = nullptr;\n+#endif\n+    oop_maps->add(oop_map);\n+  }\n+  set_read_position(code_offset);\n+  return oop_maps;\n+}\n+\n+bool AOTCodeCache::write_oop_maps(OopMapSet* oop_maps) {\n+  uint om_count = oop_maps->size();\n+  uint n = write_bytes(&om_count, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  for (int i = 0; i < (int)om_count; i++) {\n+    OopMap* om = oop_maps->at(i);\n+    int data_size = om->data_size();\n+    n = write_bytes(&data_size, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    n = write_bytes(om, sizeof(OopMap));\n+    if (n != sizeof(OopMap)) {\n+      return false;\n+    }\n+    n = write_bytes(om->data(), (uint)data_size);\n+    if (n != (uint)data_size) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+oop AOTCodeReader::read_oop(JavaThread* thread, const methodHandle& comp_method) {\n+  uint code_offset = read_position();\n+  oop obj = nullptr;\n+  DataKind kind = *(DataKind*)addr(code_offset);\n+  code_offset += sizeof(DataKind);\n+  set_read_position(code_offset);\n+  if (kind == DataKind::Null) {\n+    return nullptr;\n+  } else if (kind == DataKind::No_Data) {\n+    return cast_to_oop(Universe::non_oop_word());\n+  } else if (kind == DataKind::Klass || kind == DataKind::Klass_Shared) {\n+    Klass* k = read_klass(comp_method, (kind == DataKind::Klass_Shared));\n+    if (k == nullptr) {\n+      return nullptr;\n+    }\n+    obj = k->java_mirror();\n+    if (obj == nullptr) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"Lookup failed for java_mirror of klass %s\", k->external_name());\n+      return nullptr;\n+    }\n+  } else if (kind == DataKind::Primitive) {\n+    code_offset = read_position();\n+    int t = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    set_read_position(code_offset);\n+    BasicType bt = (BasicType)t;\n+    obj = java_lang_Class::primitive_mirror(bt);\n+    log_info(aot, codecache)(\"%d (L%d): Read primitive type klass: %s\", compile_id(), comp_level(), type2name(bt));\n+  } else if (kind == DataKind::String_Shared) {\n+    code_offset = read_position();\n+    int k = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    set_read_position(code_offset);\n+    obj = CDSAccess::get_archived_object(k);\n+  } else if (kind == DataKind::String) {\n+    code_offset = read_position();\n+    int length = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    set_read_position(code_offset);\n+    const char* dest = addr(code_offset);\n+    set_read_position(code_offset + length);\n+    obj = StringTable::intern(&(dest[0]), thread);\n+    if (obj == nullptr) {\n+      set_lookup_failed();\n+      log_info(aot, codecache)(\"%d (L%d): Lookup failed for String %s\",\n+                       compile_id(), comp_level(), &(dest[0]));\n+      return nullptr;\n+    }\n+    assert(java_lang_String::is_instance(obj), \"must be string\");\n+    log_info(aot, codecache)(\"%d (L%d): Read String: %s\", compile_id(), comp_level(), dest);\n+  } else if (kind == DataKind::SysLoader) {\n+    obj = SystemDictionary::java_system_loader();\n+    log_info(aot, codecache)(\"%d (L%d): Read java_system_loader\", compile_id(), comp_level());\n+  } else if (kind == DataKind::PlaLoader) {\n+    obj = SystemDictionary::java_platform_loader();\n+    log_info(aot, codecache)(\"%d (L%d): Read java_platform_loader\", compile_id(), comp_level());\n+  } else if (kind == DataKind::MH_Oop_Shared) {\n+    code_offset = read_position();\n+    int k = *(int*)addr(code_offset);\n+    code_offset += sizeof(int);\n+    set_read_position(code_offset);\n+    obj = CDSAccess::get_archived_object(k);\n+  } else {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Unknown oop's kind: %d\",\n+                     compile_id(), comp_level(), (int)kind);\n+    return nullptr;\n+  }\n+  return obj;\n+}\n+\n+bool AOTCodeReader::read_oops(OopRecorder* oop_recorder, ciMethod* target) {\n+  uint code_offset = read_position();\n+  int oop_count = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+  set_read_position(code_offset);\n+  log_debug(aot, codecache)(\"======== read oops [%d]:\", oop_count);\n+  if (oop_count == 0) {\n+    return true;\n+  }\n+  {\n+    VM_ENTRY_MARK;\n+    methodHandle comp_method(THREAD, target->get_Method());\n+    for (int i = 1; i < oop_count; i++) {\n+      oop obj = read_oop(THREAD, comp_method);\n+      if (lookup_failed()) {\n+        return false;\n+      }\n+      jobject jo = JNIHandles::make_local(THREAD, obj);\n+      if (oop_recorder->is_real(jo)) {\n+        oop_recorder->find_index(jo);\n+      } else {\n+        oop_recorder->allocate_oop_index(jo);\n+      }\n+      LogStreamHandle(Debug, aot, codecache, oops) log;\n+      if (log.is_enabled()) {\n+        log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(jo));\n+        if (jo == (jobject)Universe::non_oop_word()) {\n+          log.print(\"non-oop word\");\n+        } else if (jo == nullptr) {\n+          log.print(\"nullptr-oop\");\n+        } else {\n+          JNIHandles::resolve(jo)->print_value_on(&log);\n+        }\n+        log.cr();\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+Metadata* AOTCodeReader::read_metadata(const methodHandle& comp_method) {\n+  uint code_offset = read_position();\n+  Metadata* m = nullptr;\n+  DataKind kind = *(DataKind*)addr(code_offset);\n+  code_offset += sizeof(DataKind);\n+  set_read_position(code_offset);\n+  if (kind == DataKind::Null) {\n+    m = (Metadata*)nullptr;\n+  } else if (kind == DataKind::No_Data) {\n+    m = (Metadata*)Universe::non_oop_word();\n+  } else if (kind == DataKind::Klass || kind == DataKind::Klass_Shared) {\n+    m = (Metadata*)read_klass(comp_method, (kind == DataKind::Klass_Shared));\n+  } else if (kind == DataKind::Method || kind == DataKind::Method_Shared) {\n+    m = (Metadata*)read_method(comp_method, (kind == DataKind::Method_Shared));\n+  } else if (kind == DataKind::MethodCnts) {\n+    kind = *(DataKind*)addr(code_offset);\n+    bool shared = (kind == DataKind::Method_Shared);\n+    assert(kind == DataKind::Method || shared, \"Sanity\");\n+    code_offset += sizeof(DataKind);\n+    set_read_position(code_offset);\n+    m = (Metadata*)read_method(comp_method, shared);\n+    if (m != nullptr) {\n+      Method* method = (Method*)m;\n+      m = method->get_method_counters(Thread::current());\n+      if (m == nullptr) {\n+        set_lookup_failed();\n+        log_info(aot, codecache)(\"%d (L%d): Failed to get MethodCounters\", compile_id(), comp_level());\n+      } else {\n+        log_info(aot, codecache)(\"%d (L%d): Read MethodCounters : \" INTPTR_FORMAT, compile_id(), comp_level(), p2i(m));\n+      }\n+    }\n+  } else {\n+    set_lookup_failed();\n+    log_info(aot, codecache)(\"%d (L%d): Unknown metadata's kind: %d\", compile_id(), comp_level(), (int)kind);\n+  }\n+  return m;\n+}\n+\n+bool AOTCodeReader::read_metadata(OopRecorder* oop_recorder, ciMethod* target) {\n+  uint code_offset = read_position();\n+  int metadata_count = *(int*)addr(code_offset);\n+  code_offset += sizeof(int);\n+  set_read_position(code_offset);\n+\n+  log_debug(aot, codecache)(\"======== read metadata [%d]:\", metadata_count);\n+\n+  if (metadata_count == 0) {\n+    return true;\n+  }\n+  {\n+    VM_ENTRY_MARK;\n+    methodHandle comp_method(THREAD, target->get_Method());\n+\n+    for (int i = 1; i < metadata_count; i++) {\n+      Metadata* m = read_metadata(comp_method);\n+      if (lookup_failed()) {\n+        return false;\n+      }\n+      if (oop_recorder->is_real(m)) {\n+        oop_recorder->find_index(m);\n+      } else {\n+        oop_recorder->allocate_metadata_index(m);\n+      }\n+      LogTarget(Debug, aot, codecache, metadata) log;\n+      if (log.is_enabled()) {\n+        LogStream ls(log);\n+        ls.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n+        if (m == (Metadata*)Universe::non_oop_word()) {\n+          ls.print(\"non-metadata word\");\n+        } else if (m == nullptr) {\n+          ls.print(\"nullptr-oop\");\n+        } else {\n+          Metadata::print_value_on_maybe_null(&ls, m);\n+        }\n+        ls.cr();\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_oop(jobject& jo) {\n+  oop obj = JNIHandles::resolve(jo);\n+  return write_oop(obj);\n+}\n+\n+bool AOTCodeCache::write_oop(oop obj) {\n+  DataKind kind;\n+  uint n = 0;\n+  if (obj == nullptr) {\n+    kind = DataKind::Null;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+  } else if (cast_from_oop<void *>(obj) == Universe::non_oop_word()) {\n+    kind = DataKind::No_Data;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+  } else if (java_lang_Class::is_instance(obj)) {\n+    if (java_lang_Class::is_primitive(obj)) {\n+      int bt = (int)java_lang_Class::primitive_type(obj);\n+      kind = DataKind::Primitive;\n+      n = write_bytes(&kind, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      n = write_bytes(&bt, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      log_info(aot, codecache)(\"%d (L%d): Write primitive type klass: %s\", compile_id(), comp_level(), type2name((BasicType)bt));\n+    } else {\n+      Klass* klass = java_lang_Class::as_Klass(obj);\n+      if (!write_klass(klass)) {\n+        return false;\n+      }\n+    }\n+  } else if (java_lang_String::is_instance(obj)) { \/\/ herere\n+    int k = CDSAccess::get_archived_object_permanent_index(obj);  \/\/ k >= 0 means obj is a \"permanent heap object\"\n+    if (k >= 0) {\n+      kind = DataKind::String_Shared;\n+      n = write_bytes(&kind, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      n = write_bytes(&k, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      return true;\n+    }\n+    kind = DataKind::String;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    ResourceMark rm;\n+    size_t length_sz = 0;\n+    const char* string = java_lang_String::as_utf8_string(obj, length_sz);\n+    int length = (int)length_sz; \/\/ FIXME -- cast\n+    length++; \/\/ write tailing '\/0'\n+    n = write_bytes(&length, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    n = write_bytes(string, (uint)length);\n+    if (n != (uint)length) {\n+      return false;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Write String: %s\", compile_id(), comp_level(), string);\n+  } else if (java_lang_Module::is_instance(obj)) {\n+    fatal(\"Module object unimplemented\");\n+  } else if (java_lang_ClassLoader::is_instance(obj)) {\n+    if (obj == SystemDictionary::java_system_loader()) {\n+      kind = DataKind::SysLoader;\n+      log_info(aot, codecache)(\"%d (L%d): Write ClassLoader: java_system_loader\", compile_id(), comp_level());\n+    } else if (obj == SystemDictionary::java_platform_loader()) {\n+      kind = DataKind::PlaLoader;\n+      log_info(aot, codecache)(\"%d (L%d): Write ClassLoader: java_platform_loader\", compile_id(), comp_level());\n+    } else {\n+      fatal(\"ClassLoader object unimplemented\");\n+      return false;\n+    }\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+  } else { \/\/ herere\n+    int k = CDSAccess::get_archived_object_permanent_index(obj);  \/\/ k >= 0 means obj is a \"permanent heap object\"\n+    if (k >= 0) {\n+      kind = DataKind::MH_Oop_Shared;\n+      n = write_bytes(&kind, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      n = write_bytes(&k, sizeof(int));\n+      if (n != sizeof(int)) {\n+        return false;\n+      }\n+      return true;\n+    }\n+    \/\/ Unhandled oop - bailout\n+    set_lookup_failed();\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): Unhandled obj: \" PTR_FORMAT \" : %s\",\n+                              compile_id(), comp_level(), p2i(obj), obj->klass()->external_name());\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_oops(OopRecorder* oop_recorder) {\n+  int oop_count = oop_recorder->oop_count();\n+  uint n = write_bytes(&oop_count, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+  log_debug(aot, codecache)(\"======== write oops [%d]:\", oop_count);\n+\n+  for (int i = 1; i < oop_count; i++) { \/\/ skip first virtual nullptr\n+    jobject jo = oop_recorder->oop_at(i);\n+    LogStreamHandle(Info, aot, codecache, oops) log;\n+    if (log.is_enabled()) {\n+      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(jo));\n+      if (jo == (jobject)Universe::non_oop_word()) {\n+        log.print(\"non-oop word\");\n+      } else if (jo == nullptr) {\n+        log.print(\"nullptr-oop\");\n+      } else {\n+        JNIHandles::resolve(jo)->print_value_on(&log);\n+      }\n+      log.cr();\n+    }\n+    if (!write_oop(jo)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_metadata(Metadata* m) {\n+  uint n = 0;\n+  if (m == nullptr) {\n+    DataKind kind = DataKind::Null;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+  } else if (m == (Metadata*)Universe::non_oop_word()) {\n+    DataKind kind = DataKind::No_Data;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+  } else if (m->is_klass()) {\n+    if (!write_klass((Klass*)m)) {\n+      return false;\n+    }\n+  } else if (m->is_method()) {\n+    if (!write_method((Method*)m)) {\n+      return false;\n+    }\n+  } else if (m->is_methodCounters()) {\n+    DataKind kind = DataKind::MethodCnts;\n+    n = write_bytes(&kind, sizeof(int));\n+    if (n != sizeof(int)) {\n+      return false;\n+    }\n+    if (!write_method(((MethodCounters*)m)->method())) {\n+      return false;\n+    }\n+    log_info(aot, codecache)(\"%d (L%d): Write MethodCounters : \" INTPTR_FORMAT, compile_id(), comp_level(), p2i(m));\n+  } else { \/\/ Not supported\n+    fatal(\"metadata : \" INTPTR_FORMAT \" unimplemented\", p2i(m));\n+    return false;\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_metadata(OopRecorder* oop_recorder) {\n+  int metadata_count = oop_recorder->metadata_count();\n+  uint n = write_bytes(&metadata_count, sizeof(int));\n+  if (n != sizeof(int)) {\n+    return false;\n+  }\n+\n+  log_debug(aot, codecache)(\"======== write metadata [%d]:\", metadata_count);\n+\n+  for (int i = 1; i < metadata_count; i++) { \/\/ skip first virtual nullptr\n+    Metadata* m = oop_recorder->metadata_at(i);\n+    LogStreamHandle(Debug, aot, codecache, metadata) log;\n+    if (log.is_enabled()) {\n+      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n+      if (m == (Metadata*)Universe::non_oop_word()) {\n+        log.print(\"non-metadata word\");\n+      } else if (m == nullptr) {\n+        log.print(\"nullptr-oop\");\n+      } else {\n+        Metadata::print_value_on_maybe_null(&log, m);\n+      }\n+      log.cr();\n+    }\n+    if (!write_metadata(m)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeReader::read_dependencies(Dependencies* dependencies) {\n+  uint code_offset = read_position();\n+  int dependencies_size = *(int*)addr(code_offset);\n+\n+  log_debug(aot, codecache)(\"======== read dependencies [%d]:\", dependencies_size);\n+\n+  code_offset += sizeof(int);\n+  code_offset = align_up(code_offset, DATA_ALIGNMENT);\n+  if (dependencies_size > 0) {\n+    dependencies->set_content((u_char*)addr(code_offset), dependencies_size);\n+  }\n+  code_offset += dependencies_size;\n+  set_read_position(code_offset);\n+  return true;\n+}\n+\n+bool AOTCodeCache::load_nmethod(ciEnv* env, ciMethod* target, int entry_bci, AbstractCompiler* compiler, CompLevel comp_level) {\n+  assert(entry_bci == InvocationEntryBci, \"unexpected entry_bci=%d\", entry_bci);\n+  TraceTime t1(\"SC total load time\", &_t_totalLoad, enable_timers(), false);\n+  CompileTask* task = env->task();\n+  task->mark_aot_load_start(os::elapsed_counter());\n+  AOTCodeEntry* entry = task->aot_code_entry();\n+  bool preload = task->preload();\n+  assert(entry != nullptr, \"sanity\");\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache == nullptr) {\n+    return false;\n+  }\n+  if (log_is_enabled(Info, aot, codecache, nmethod)) {\n+    uint decomp = (target->method_data() == nullptr) ? 0 : target->method_data()->decompile_count();\n+    VM_ENTRY_MARK;\n+    ResourceMark rm;\n+    methodHandle method(THREAD, target->get_Method());\n+    const char* target_name = method->name_and_sig_as_C_string();\n+    uint hash = java_lang_String::hash_code((const jbyte*)target_name, (int)strlen(target_name));\n+    bool clinit_brs = entry->has_clinit_barriers();\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): %s nmethod '%s' (decomp: %d, hash: \" UINT32_FORMAT_X_0 \"%s%s)\",\n+                           task->compile_id(), task->comp_level(), (preload ? \"Preloading\" : \"Reading\"),\n+                           target_name, decomp, hash, (clinit_brs ? \", has clinit barriers\" : \"\"),\n+                           (entry->ignore_decompile() ? \", ignore_decomp\" : \"\"));\n+  }\n+  ReadingMark rdmk;\n+  if (rdmk.failed()) {\n+    \/\/ Cache is closed, cannot touch anything.\n+    return false;\n+  }\n+\n+  AOTCodeReader reader(cache, entry, task);\n+  bool success = reader.compile_nmethod(env, target, compiler);\n+  if (success) {\n+    task->set_num_inlined_bytecodes(entry->num_inlined_bytecodes());\n+  } else {\n+    entry->set_load_fail();\n+  }\n+  task->mark_aot_load_finish(os::elapsed_counter());\n+  return success;\n+}\n+\n+AOTCodeReader::AOTCodeReader(AOTCodeCache* cache, AOTCodeEntry* entry, CompileTask* task) {\n+  _cache = cache;\n+  _entry   = entry;\n+  _load_buffer = cache->cache_buffer();\n+  _read_position = 0;\n+  if (task != nullptr) {\n+    _compile_id = task->compile_id();\n+    _comp_level = task->comp_level();\n+    _preload    = task->preload();\n+  } else {\n+    _compile_id = 0;\n+    _comp_level = 0;\n+    _preload    = false;\n+  }\n+  _lookup_failed = false;\n+}\n+\n+bool AOTCodeReader::read_oop_metadata_list(JavaThread* thread, ciMethod* target, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list, OopRecorder* oop_recorder) {\n+  methodHandle comp_method(JavaThread::current(), target->get_Method());\n+  JavaThread* current = JavaThread::current();\n+  uint offset = read_position();\n+  int count = *(int *)addr(offset);\n+  offset += sizeof(int);\n+  set_read_position(offset);\n+  for (int i = 0; i < count; i++) {\n+    oop obj = read_oop(current, comp_method);\n+    if (lookup_failed()) {\n+      return false;\n+    }\n+    Handle h(thread, obj);\n+    oop_list.append(h);\n+    if (oop_recorder != nullptr) {\n+      jobject jo = JNIHandles::make_local(thread, obj);\n+      if (oop_recorder->is_real(jo)) {\n+        oop_recorder->find_index(jo);\n+      } else {\n+        oop_recorder->allocate_oop_index(jo);\n+      }\n+    }\n+    LogStreamHandle(Debug, aot, codecache, oops) log;\n+    if (log.is_enabled()) {\n+      log.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(obj));\n+      if (obj == Universe::non_oop_word()) {\n+        log.print(\"non-oop word\");\n+      } else if (obj == nullptr) {\n+        log.print(\"nullptr-oop\");\n+      } else {\n+        obj->print_value_on(&log);\n+      }\n+      log.cr();\n+    }\n+  }\n+\n+  offset = read_position();\n+  count = *(int *)addr(offset);\n+  offset += sizeof(int);\n+  set_read_position(offset);\n+  for (int i = 0; i < count; i++) {\n+    Metadata* m = read_metadata(comp_method);\n+    if (lookup_failed()) {\n+      return false;\n+    }\n+    metadata_list.append(m);\n+    if (oop_recorder != nullptr) {\n+      if (oop_recorder->is_real(m)) {\n+        oop_recorder->find_index(m);\n+      } else {\n+        oop_recorder->allocate_metadata_index(m);\n+      }\n+    }\n+    LogTarget(Debug, aot, codecache, metadata) log;\n+    if (log.is_enabled()) {\n+      LogStream ls(log);\n+      ls.print(\"%d: \" INTPTR_FORMAT \" \", i, p2i(m));\n+      if (m == (Metadata*)Universe::non_oop_word()) {\n+        ls.print(\"non-metadata word\");\n+      } else if (m == nullptr) {\n+        ls.print(\"nullptr-oop\");\n+      } else {\n+        Metadata::print_value_on_maybe_null(&ls, m);\n+      }\n+      ls.cr();\n+    }\n+  }\n+  return true;\n+}\n+\n+ImmutableOopMapSet* AOTCodeReader::read_oop_map_set() {\n+  uint offset = read_position();\n+  int size = *(int *)addr(offset);\n+  offset += sizeof(int);\n+  ImmutableOopMapSet* oopmaps = (ImmutableOopMapSet *)addr(offset);\n+  offset += size;\n+  set_read_position(offset);\n+  return oopmaps;\n+}\n+\n+bool AOTCodeReader::compile_nmethod(ciEnv* env, ciMethod* target, AbstractCompiler* compiler) {\n+  CompileTask* task = env->task();\n+  AOTCodeEntry *aot_code_entry = (AOTCodeEntry*)_entry;\n+  nmethod* nm = nullptr;\n+\n+  uint entry_position = aot_code_entry->offset();\n+  uint archived_nm_offset = entry_position + aot_code_entry->code_offset();\n+  nmethod* archived_nm = (nmethod*)addr(archived_nm_offset);\n+  set_read_position(archived_nm_offset + archived_nm->size());\n+\n+  OopRecorder* oop_recorder = new OopRecorder(env->arena());\n+  env->set_oop_recorder(oop_recorder);\n+\n+  uint offset;\n+\n+#ifndef PRODUCT\n+  \/\/ Read asm remarks\n+  offset = read_position();\n+  uint count = *(uint *)addr(offset);\n+  offset += sizeof(uint);\n+  AsmRemarks asm_remarks;\n+  for (uint i = 0; i < count; i++) {\n+    uint remark_offset = *(uint *)addr(offset);\n+    offset += sizeof(uint);\n+    const char* remark = (const char*)addr(offset);\n+    offset += (uint)strlen(remark)+1;\n+    asm_remarks.insert(remark_offset, remark);\n+  }\n+  set_read_position(offset);\n+\n+  \/\/ Read dbg strings\n+  count = *(uint *)addr(offset);\n+  offset += sizeof(uint);\n+  DbgStrings dbg_strings;\n+  for (uint i = 0; i < count; i++) {\n+    const char* str = (const char*)addr(offset);\n+    offset += (uint)strlen(str)+1;\n+    dbg_strings.insert(str);\n+  }\n+  set_read_position(offset);\n+#endif \/* PRODUCT *\/\n+\n+  offset = read_position();\n+  address reloc_data = (address)addr(offset);\n+  offset += archived_nm->relocation_size();\n+  set_read_position(offset);\n+\n+  \/\/ Read oops and metadata\n+  VM_ENTRY_MARK\n+  GrowableArray<Handle> oop_list;\n+  GrowableArray<Metadata*> metadata_list;\n+\n+  if (!read_oop_metadata_list(THREAD, target, oop_list, metadata_list, oop_recorder)) {\n+   return false;\n+  }\n+\n+  ImmutableOopMapSet* oopmaps = read_oop_map_set();\n+\n+  offset = read_position();\n+  address immutable_data = (address)addr(offset);\n+  offset += archived_nm->immutable_data_size();\n+  set_read_position(offset);\n+\n+  GrowableArray<Handle> reloc_immediate_oop_list;\n+  GrowableArray<Metadata*> reloc_immediate_metadata_list;\n+  if (!read_oop_metadata_list(THREAD, target, reloc_immediate_oop_list, reloc_immediate_metadata_list, nullptr)) {\n+   return false;\n+  }\n+\n+  \/\/ Read Dependencies (compressed already)\n+  Dependencies* dependencies = new Dependencies(env);\n+  dependencies->set_content(immutable_data, archived_nm->dependencies_size());\n+  env->set_dependencies(dependencies);\n+\n+  if (VerifyCachedCode) {\n+    return false;\n+  }\n+\n+  TraceTime t1(\"SC total nmethod register time\", &_t_totalRegister, enable_timers(), false);\n+  env->register_aot_method(THREAD,\n+                           target,\n+                           compiler,\n+                           archived_nm,\n+                           reloc_data,\n+                           oop_list,\n+                           metadata_list,\n+                           oopmaps,\n+                           immutable_data,\n+                           reloc_immediate_oop_list,\n+                           reloc_immediate_metadata_list,\n+                           NOT_PRODUCT_ARG(asm_remarks)\n+                           NOT_PRODUCT_ARG(dbg_strings)\n+                           this);\n+  bool success = task->is_success();\n+  if (success) {\n+    aot_code_entry->set_loaded();\n+  }\n+  return success;\n+}\n+\n+void AOTCodeReader::apply_relocations(nmethod* nm, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list) {\n+  LogStreamHandle(Info, aot, codecache, reloc) log;\n+  uint buffer_offset = read_position();\n+  int count = *(int*)addr(buffer_offset);\n+  buffer_offset += sizeof(int);\n+  if (log.is_enabled()) {\n+    log.print_cr(\"======== extra relocations count=%d\", count);\n+  }\n+  uint* reloc_data = (uint*)addr(buffer_offset);\n+  buffer_offset += (count * sizeof(uint));\n+  set_read_position(buffer_offset);\n+\n+  RelocIterator iter(nm);\n+  int j = 0;\n+\n+  while (iter.next()) {\n+    switch (iter.type()) {\n+      case relocInfo::none:\n+        break;\n+      case relocInfo::oop_type: {\n+        oop_Relocation* r = (oop_Relocation*)iter.reloc();\n+        if (r->oop_is_immediate()) {\n+          Handle h = oop_list.at(reloc_data[j]);\n+          r->set_value(cast_from_oop<address>(h()));\n+        } else {\n+          r->fix_oop_relocation();\n+        }\n+        break;\n+      }\n+      case relocInfo::metadata_type: {\n+        metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n+        Metadata* m;\n+        if (r->metadata_is_immediate()) {\n+          m = metadata_list.at(reloc_data[j]);\n+        } else {\n+          \/\/ Get already updated value from nmethod.\n+          int index = r->metadata_index();\n+          m = nm->metadata_at(index);\n+        }\n+        r->set_value((address)m);\n+        break;\n+      }\n+      case relocInfo::virtual_call_type:   \/\/ Fall through. They all call resolve_*_call blobs.\n+      case relocInfo::opt_virtual_call_type:\n+      case relocInfo::static_call_type: {\n+        address dest = _cache->address_for_id(reloc_data[j]);\n+        if (dest != (address)-1) {\n+          ((CallRelocation*)iter.reloc())->set_destination(dest);\n+        }\n+        break;\n+      }\n+      case relocInfo::trampoline_stub_type: {\n+        address dest = _cache->address_for_id(reloc_data[j]);\n+        if (dest != (address)-1) {\n+          ((trampoline_stub_Relocation*)iter.reloc())->set_destination(dest);\n+        }\n+        break;\n+      }\n+      case relocInfo::static_stub_type:\n+        break;\n+      case relocInfo::runtime_call_type: {\n+        address dest = _cache->address_for_id(reloc_data[j]);\n+        if (dest != (address)-1) {\n+          ((CallRelocation*)iter.reloc())->set_destination(dest);\n+        }\n+        break;\n+      }\n+      case relocInfo::runtime_call_w_cp_type:\n+        fatal(\"runtime_call_w_cp_type unimplemented\");\n+        \/\/address destination = iter.reloc()->value();\n+        break;\n+      case relocInfo::external_word_type: {\n+        address target = _cache->address_for_id(reloc_data[j]);\n+        \/\/ Add external address to global table\n+        int index = ExternalsRecorder::find_index(target);\n+        \/\/ Update index in relocation\n+        Relocation::add_jint(iter.data(), index);\n+        external_word_Relocation* reloc = (external_word_Relocation*)iter.reloc();\n+        assert(reloc->target() == target, \"sanity\");\n+        reloc->set_value(target); \/\/ Patch address in the code\n+        break;\n+      }\n+      case relocInfo::internal_word_type: {\n+        internal_word_Relocation* r = (internal_word_Relocation*)iter.reloc();\n+        r->fix_relocation_after_aot_load(aot_code_entry()->dumptime_content_start_addr(), nm->content_begin());\n+        break;\n+      }\n+      case relocInfo::section_word_type: {\n+        section_word_Relocation* r = (section_word_Relocation*)iter.reloc();\n+        r->fix_relocation_after_aot_load(aot_code_entry()->dumptime_content_start_addr(), nm->content_begin());\n+        break;\n+      }\n+      case relocInfo::poll_type:\n+        break;\n+      case relocInfo::poll_return_type:\n+        break;\n+      case relocInfo::post_call_nop_type:\n+        break;\n+      case relocInfo::entry_guard_type:\n+        break;\n+      default:\n+        fatal(\"relocation %d unimplemented\", (int)iter.type());\n+        break;\n+    }\n+    if (log.is_enabled()) {\n+      iter.print_current_on(&log);\n+    }\n+    j++;\n+  }\n+  assert(j == count, \"must be\");\n+}\n+\n+AOTCodeEntry* AOTCodeCache::store_nmethod(nmethod* nm, AbstractCompiler* compiler, bool for_preload) {\n+  if (!CDSConfig::is_dumping_cached_code()) {\n+    return nullptr; \/\/ The metadata and heap in the CDS image haven't been finalized yet.\n+  }\n+  if (nm->is_osr_method()) {\n+    return nullptr; \/\/ No OSR\n+  }\n+  if (!compiler->is_c1() && !compiler->is_c2()) {\n+    \/\/ Only c1 and c2 compilers\n+    return nullptr;\n+  }\n+  int comp_level = nm->comp_level();\n+  if (comp_level == CompLevel_full_profile) {\n+    \/\/ Do not cache C1 compiles with full profile i.e. tier3\n+    return nullptr;\n+  }\n+  assert(comp_level == CompLevel_simple || comp_level == CompLevel_limited_profile || comp_level == CompLevel_full_optimization, \"must be\");\n+\n+  TraceTime t1(\"SC total store time\", &_t_totalStore, enable_timers(), false);\n+  AOTCodeCache* cache = open_for_write();\n+  if (cache == nullptr) {\n+    return nullptr; \/\/ Cache file is closed\n+  }\n+  AOTCodeEntry* entry = nullptr;\n+  entry = cache->write_nmethod(nm, for_preload);\n+  if (entry == nullptr) {\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): nmethod store attempt failed\", nm->compile_id(), comp_level);\n+  }\n+  return entry;\n+}\n+\n+bool AOTCodeCache::write_oops(nmethod* nm) {\n+  int count = nm->oops_count()-1;\n+  if (!write_bytes(&count, sizeof(int))) {\n+    return false;\n+  }\n+  for (oop* p = nm->oops_begin(); p < nm->oops_end(); p++) {\n+    if (!write_oop(*p)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_metadata(nmethod* nm) {\n+  int count = nm->metadata_count()-1;\n+  if (!write_bytes(&count, sizeof(int))) {\n+    return false;\n+  }\n+  for (Metadata** p = nm->metadata_begin(); p < nm->metadata_end(); p++) {\n+    if (!write_metadata(*p)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+bool AOTCodeCache::write_oop_map_set(nmethod* nm) {\n+  ImmutableOopMapSet* oopmaps = nm->oop_maps();\n+  int oopmaps_size = oopmaps->nr_of_bytes();\n+  if (!write_bytes(&oopmaps_size, sizeof(int))) {\n+    return false;\n+  }\n+  uint n = write_bytes(oopmaps, oopmaps->nr_of_bytes());\n+  if (n != (uint)oopmaps->nr_of_bytes()) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+AOTCodeEntry* AOTCodeCache::write_nmethod(nmethod* nm, bool for_preload) {\n+  assert(!nm->has_clinit_barriers() || _gen_preload_code, \"sanity\");\n+  uint comp_id = nm->compile_id();\n+  uint comp_level = nm->comp_level();\n+  Method* method = nm->method();\n+  bool method_in_cds = MetaspaceShared::is_in_shared_metaspace((address)method);\n+  InstanceKlass* holder = method->method_holder();\n+  bool klass_in_cds = holder->is_shared() && !holder->is_shared_unregistered_class();\n+  bool builtin_loader = holder->class_loader_data()->is_builtin_class_loader_data();\n+  if (!builtin_loader) {\n+    ResourceMark rm;\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): Skip method '%s' loaded by custom class loader %s\", comp_id, (int)comp_level, method->name_and_sig_as_C_string(), holder->class_loader_data()->loader_name());\n+    return nullptr;\n+  }\n+  if (for_preload && !(method_in_cds && klass_in_cds)) {\n+    ResourceMark rm;\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): Skip method '%s' for preload: not in CDS\", comp_id, (int)comp_level, method->name_and_sig_as_C_string());\n+    return nullptr;\n+  }\n+  assert(!for_preload || method_in_cds, \"sanity\");\n+  _for_preload = for_preload;\n+  _has_clinit_barriers = nm->has_clinit_barriers();\n+\n+  if (!align_write()) {\n+    return nullptr;\n+  }\n+\n+  uint entry_position = _write_position;\n+\n+  uint decomp = (method->method_data() == nullptr) ? 0 : method->method_data()->decompile_count();\n+\n+  \/\/ Is this one-step workflow assembly phase?\n+  \/\/ In this phase compilation is done based on saved profiling data\n+  \/\/ without application run. Ignore decompilation counters in such case.\n+  \/\/ Also ignore it for C1 code because it is decompiled unconditionally\n+  \/\/ when C2 generated code is published.\n+  bool ignore_decompile = (comp_level == CompLevel_limited_profile) ||\n+                          CDSConfig::is_dumping_final_static_archive();\n+\n+  \/\/ Write name\n+  uint name_offset = 0;\n+  uint name_size   = 0;\n+  uint hash = 0;\n+  uint n;\n+  {\n+    ResourceMark rm;\n+    const char* name = method->name_and_sig_as_C_string();\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): Writing nmethod '%s' (comp level: %d, decomp: %d%s%s) to AOT Code Cache\",\n+                           comp_id, (int)comp_level, name, comp_level, decomp,\n+                           (ignore_decompile ? \", ignore_decomp\" : \"\"),\n+                           (nm->has_clinit_barriers() ? \", has clinit barriers\" : \"\"));\n+\n+    LogStreamHandle(Info, aot, codecache, loader) log;\n+    if (log.is_enabled()) {\n+      oop loader = holder->class_loader();\n+      oop domain = holder->protection_domain();\n+      log.print(\"Holder: \");\n+      holder->print_value_on(&log);\n+      log.print(\" loader: \");\n+      if (loader == nullptr) {\n+        log.print(\"nullptr\");\n+      } else {\n+        loader->print_value_on(&log);\n+      }\n+      log.print(\" domain: \");\n+      if (domain == nullptr) {\n+        log.print(\"nullptr\");\n+      } else {\n+        domain->print_value_on(&log);\n+      }\n+      log.cr();\n+    }\n+    name_offset = _write_position  - entry_position;\n+    name_size   = (uint)strlen(name) + 1; \/\/ Includes '\/0'\n+    n = write_bytes(name, name_size);\n+    if (n != name_size) {\n+      return nullptr;\n+    }\n+    hash = java_lang_String::hash_code((const jbyte*)name, (int)strlen(name));\n+  }\n+\n+  uint archived_nm_offset = _write_position - entry_position;\n+  nmethod* archived_nm = (nmethod*)reserve_bytes(nm->size());\n+  if (archived_nm == nullptr) {\n+    return nullptr;\n+  }\n+  nm->copy_to((address)archived_nm);\n+\n+  archived_nm->prepare_for_archiving();\n+\n+#ifndef PRODUCT\n+  \/\/ Write asm remarks\n+  uint* count_ptr = (uint *)reserve_bytes(sizeof(uint));\n+  if (count_ptr == nullptr) {\n+    return nullptr;\n+  }\n+  uint count = 0;\n+  bool result = nm->asm_remarks().iterate([&] (uint offset, const char* str) -> bool {\n+    log_info(aot, codecache, nmethod)(\"asm remark offset=%d, str=%s\", offset, str);\n+    n = write_bytes(&offset, sizeof(uint));\n+    if (n != sizeof(uint)) {\n+      return false;\n+    }\n+    n = write_bytes(str, (uint)strlen(str) + 1);\n+    if (n != strlen(str) + 1) {\n+      return false;\n+    }\n+    count += 1;\n+    return true;\n+  });\n+  if (!result) {\n+    return nullptr;\n+  }\n+  *count_ptr = count;\n+\n+  \/\/ Write dbg strings\n+  count_ptr = (uint *)reserve_bytes(sizeof(uint));\n+  if (count_ptr == nullptr) {\n+    return nullptr;\n+  }\n+  count = 0;\n+  result = nm->dbg_strings().iterate([&] (const char* str) -> bool {\n+    log_info(aot, codecache, nmethod)(\"dbg string=%s\", str);\n+    n = write_bytes(str, (uint)strlen(str) + 1);\n+    if (n != strlen(str) + 1) {\n+      return false;\n+    }\n+    count += 1;\n+    return true;\n+  });\n+  if (!result) {\n+    return nullptr;\n+  }\n+  *count_ptr = count;\n+#endif \/* PRODUCT *\/\n+\n+  uint reloc_data_size = nm->relocation_size();\n+  n = write_bytes((address)nm->relocation_begin(), reloc_data_size);\n+  if (n != reloc_data_size) {\n+    return nullptr;\n+  }\n+\n+  \/\/ Write oops and metadata present in the nmethod's data region\n+  if (!write_oops(nm)) {\n+    if (lookup_failed() && !failed()) {\n+      \/\/ Skip this method and reposition file\n+      set_write_position(entry_position);\n+    }\n+    return nullptr;\n+  }\n+  if (!write_metadata(nm)) {\n+    if (lookup_failed() && !failed()) {\n+      \/\/ Skip this method and reposition file\n+      set_write_position(entry_position);\n+    }\n+    return nullptr;\n+  }\n+\n+  if (!write_oop_map_set(nm)) {\n+    return nullptr;\n+  }\n+\n+  uint immutable_data_size = nm->immutable_data_size();\n+  n = write_bytes(nm->immutable_data_begin(), immutable_data_size);\n+  if (n != immutable_data_size) {\n+    return nullptr;\n+  }\n+\n+  JavaThread* thread = JavaThread::current();\n+  HandleMark hm(thread);\n+  GrowableArray<Handle> oop_list;\n+  GrowableArray<Metadata*> metadata_list;\n+\n+  nm->create_reloc_immediates_list(thread, oop_list, metadata_list);\n+  if (!write_nmethod_reloc_immediates(oop_list, metadata_list)) {\n+    if (lookup_failed() && !failed()) {\n+      \/\/ Skip this method and reposition file\n+      set_write_position(entry_position);\n+    }\n+    return nullptr;\n+  }\n+\n+  if (!write_nmethod_loadtime_relocations(thread, nm, oop_list, metadata_list)) {\n+    return nullptr;\n+  }\n+\n+  uint entry_size = _write_position - entry_position;\n+  AOTCodeEntry* entry = new (this) AOTCodeEntry(entry_position, entry_size, name_offset, name_size,\n+                                        archived_nm_offset, 0, 0, 0,\n+                                        AOTCodeEntry::Code, hash, nm->content_begin(), comp_level, comp_id, decomp,\n+                                        nm->has_clinit_barriers(), for_preload, ignore_decompile);\n+  if (method_in_cds) {\n+    entry->set_method(method);\n+  }\n+#ifdef ASSERT\n+  if (nm->has_clinit_barriers() || for_preload) {\n+    assert(for_preload, \"sanity\");\n+    assert(entry->method() != nullptr, \"sanity\");\n+  }\n+#endif\n+  {\n+    ResourceMark rm;\n+    const char* name = nm->method()->name_and_sig_as_C_string();\n+    log_info(aot, codecache, nmethod)(\"%d (L%d): Wrote nmethod '%s'%s to AOT Code Cache\",\n+                           comp_id, (int)comp_level, name, (for_preload ? \" (for preload)\" : \"\"));\n+  }\n+  if (VerifyCachedCode) {\n+    return nullptr;\n+  }\n+  return entry;\n+}\n+\n+bool AOTCodeCache::write_nmethod_loadtime_relocations(JavaThread* thread, nmethod* nm, GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list) {\n+  LogStreamHandle(Info, aot, codecache, reloc) log;\n+  GrowableArray<uint> reloc_data;\n+  \/\/ Collect additional data\n+  RelocIterator iter(nm);\n+  bool has_immediate = false;\n+  while (iter.next()) {\n+    int idx = reloc_data.append(0); \/\/ default value\n+    switch (iter.type()) {\n+      case relocInfo::none:\n+      break;\n+      case relocInfo::oop_type: {\n+        oop_Relocation* r = (oop_Relocation*)iter.reloc();\n+        if (r->oop_is_immediate()) {\n+          \/\/ store index of oop in the reloc immediate oop list\n+          Handle h(thread, r->oop_value());\n+          int oop_idx = oop_list.find(h);\n+          assert(oop_idx != -1, \"sanity check\");\n+          reloc_data.at_put(idx, (uint)oop_idx);\n+          has_immediate = true;\n+        }\n+        break;\n+      }\n+      case relocInfo::metadata_type: {\n+        metadata_Relocation* r = (metadata_Relocation*)iter.reloc();\n+        if (r->metadata_is_immediate()) {\n+          \/\/ store index of metadata in the reloc immediate metadata list\n+          int metadata_idx = metadata_list.find(r->metadata_value());\n+          assert(metadata_idx != -1, \"sanity check\");\n+          reloc_data.at_put(idx, (uint)metadata_idx);\n+          has_immediate = true;\n+        }\n+        break;\n+      }\n+      case relocInfo::virtual_call_type:  \/\/ Fall through. They all call resolve_*_call blobs.\n+      case relocInfo::opt_virtual_call_type:\n+      case relocInfo::static_call_type: {\n+        CallRelocation* r = (CallRelocation*)iter.reloc();\n+        address dest = r->destination();\n+        if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n+          dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n+        }\n+        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n+        break;\n+      }\n+      case relocInfo::trampoline_stub_type: {\n+        address dest = ((trampoline_stub_Relocation*)iter.reloc())->destination();\n+        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n+        break;\n+      }\n+      case relocInfo::static_stub_type:\n+        break;\n+      case relocInfo::runtime_call_type: {\n+        \/\/ Record offset of runtime destination\n+        CallRelocation* r = (CallRelocation*)iter.reloc();\n+        address dest = r->destination();\n+        if (dest == r->addr()) { \/\/ possible call via trampoline on Aarch64\n+          dest = (address)-1;    \/\/ do nothing in this case when loading this relocation\n+        }\n+        reloc_data.at_put(idx, _table->id_for_address(dest, iter, nullptr));\n+        break;\n+      }\n+      case relocInfo::runtime_call_w_cp_type:\n+        fatal(\"runtime_call_w_cp_type unimplemented\");\n+        break;\n+      case relocInfo::external_word_type: {\n+        \/\/ Record offset of runtime target\n+        address target = ((external_word_Relocation*)iter.reloc())->target();\n+        reloc_data.at_put(idx, _table->id_for_address(target, iter, nullptr));\n+        break;\n+      }\n+      case relocInfo::internal_word_type:\n+        break;\n+      case relocInfo::section_word_type:\n+        break;\n+      case relocInfo::poll_type:\n+        break;\n+      case relocInfo::poll_return_type:\n+        break;\n+      case relocInfo::post_call_nop_type:\n+        break;\n+      case relocInfo::entry_guard_type:\n+        break;\n+      default:\n+        fatal(\"relocation %d unimplemented\", (int)iter.type());\n+        break;\n+    }\n+    if (log.is_enabled()) {\n+      iter.print_current_on(&log);\n+    }\n+  }\n+\n+  \/\/ Write additional relocation data: uint per relocation\n+  \/\/ Write the count first\n+  int count = reloc_data.length();\n+  write_bytes(&count, sizeof(int));\n+  uint data_size = count * sizeof(uint);\n+  for (GrowableArrayIterator<uint> iter = reloc_data.begin();\n+       iter != reloc_data.end(); ++iter) {\n+    uint value = *iter;\n+    int n = write_bytes(&value, sizeof(uint));\n+    if (n != sizeof(uint)) {\n+      return false;\n+      break;\n+    }\n+  }\n+\n+  if (!align_write()) {\n+    return false;\n+  }\n+  return true; \/\/success;\n+}\n+\n+bool AOTCodeCache::write_nmethod_reloc_immediates(GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list) {\n+  int count = oop_list.length();\n+  if (!write_bytes(&count, sizeof(int))) {\n+    return false;\n+  }\n+  for (GrowableArrayIterator<Handle> iter = oop_list.begin();\n+       iter != oop_list.end(); ++iter) {\n+    Handle h = *iter;\n+    if (!write_oop(h())) {\n+      return false;\n+    }\n+  }\n+\n+  count = metadata_list.length();\n+  if (!write_bytes(&count, sizeof(int))) {\n+    return false;\n+  }\n+  for (GrowableArrayIterator<Metadata*> iter = metadata_list.begin();\n+       iter != metadata_list.end(); ++iter) {\n+    Metadata* m = *iter;\n+    if (!write_metadata(m)) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+static void print_helper1(outputStream* st, const char* name, int count) {\n+  if (count > 0) {\n+    st->print(\" %s=%d\", name, count);\n+  }\n+}\n+\n+void AOTCodeCache::print_statistics_on(outputStream* st) {\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache != nullptr) {\n+    ReadingMark rdmk;\n+    if (rdmk.failed()) {\n+      \/\/ Cache is closed, cannot touch anything.\n+      return;\n+    }\n+\n+    uint count = cache->_load_header->entries_count();\n+    uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n+    AOTCodeEntry* load_entries = (AOTCodeEntry*)(search_entries + 2 * count);\n+\n+    AOTCodeStats stats;\n+    for (uint i = 0; i < count; i++) {\n+      stats.collect_all_stats(&load_entries[i]);\n+    }\n+\n+    for (uint kind = AOTCodeEntry::None; kind < AOTCodeEntry::Kind_count; kind++) {\n+      if (stats.entry_count(kind) > 0) {\n+        st->print(\"  %s:\", aot_code_entry_kind_name[kind]);\n+        print_helper1(st, \"total\", stats.entry_count(kind));\n+        print_helper1(st, \"loaded\", stats.entry_loaded_count(kind));\n+        print_helper1(st, \"invalidated\", stats.entry_invalidated_count(kind));\n+        print_helper1(st, \"failed\", stats.entry_load_failed_count(kind));\n+        st->cr();\n+      }\n+      if (kind == AOTCodeEntry::Code) {\n+        for (uint lvl = CompLevel_none; lvl < AOTCompLevel_count; lvl++) {\n+          if (stats.nmethod_count(lvl) > 0) {\n+            st->print(\"    SC T%d\", lvl);\n+            print_helper1(st, \"total\", stats.nmethod_count(lvl));\n+            print_helper1(st, \"loaded\", stats.nmethod_loaded_count(lvl));\n+            print_helper1(st, \"invalidated\", stats.nmethod_invalidated_count(lvl));\n+            print_helper1(st, \"failed\", stats.nmethod_load_failed_count(lvl));\n+            if (lvl == AOTCompLevel_count-1) {\n+              print_helper1(st, \"has_clinit_barriers\", stats.clinit_barriers_count());\n+            }\n+            st->cr();\n+          }\n+        }\n+      }\n+    }\n+  } else {\n+    st->print_cr(\"failed to map code cache\");\n+  }\n+}\n+\n+void AOTCodeCache::print_on(outputStream* st) {\n+  AOTCodeCache* cache = open_for_read();\n+  if (cache != nullptr) {\n+    ReadingMark rdmk;\n+    if (rdmk.failed()) {\n+      \/\/ Cache is closed, cannot touch anything.\n+      return;\n+    }\n+\n+    uint count = cache->_load_header->entries_count();\n+    uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n+    AOTCodeEntry* load_entries = (AOTCodeEntry*)(search_entries + 2 * count);\n+\n+    for (uint i = 0; i < count; i++) {\n+      int index = search_entries[2*i + 1];\n+      AOTCodeEntry* entry = &(load_entries[index]);\n+\n+      st->print_cr(\"%4u: %4u: K%u L%u offset=%u decompile=%u size=%u code_size=%u%s%s%s%s\",\n+                i, index, entry->kind(), entry->comp_level(), entry->offset(),\n+                entry->decompile(), entry->size(), entry->code_size(),\n+                entry->has_clinit_barriers() ? \" has_clinit_barriers\" : \"\",\n+                entry->for_preload()         ? \" for_preload\"         : \"\",\n+                entry->is_loaded()           ? \" loaded\"              : \"\",\n+                entry->not_entrant()         ? \" not_entrant\"         : \"\");\n+      st->print_raw(\"         \");\n+      AOTCodeReader reader(cache, entry, nullptr);\n+      reader.print_on(st);\n+    }\n+  } else {\n+    st->print_cr(\"failed to map code cache\");\n+  }\n+}\n+\n+void AOTCodeCache::print_unused_entries_on(outputStream* st) {\n+  LogStreamHandle(Info, aot, codecache, init) info;\n+  if (info.is_enabled()) {\n+    AOTCodeCache::iterate([&](AOTCodeEntry* entry) {\n+      if (entry->is_code() && !entry->is_loaded()) {\n+        MethodTrainingData* mtd = MethodTrainingData::find(methodHandle(Thread::current(), entry->method()));\n+        if (mtd != nullptr) {\n+          if (mtd->has_holder()) {\n+            if (mtd->holder()->method_holder()->is_initialized()) {\n+              ResourceMark rm;\n+              mtd->iterate_compiles([&](CompileTrainingData* ctd) {\n+                if ((uint)ctd->level() == entry->comp_level()) {\n+                  if (ctd->init_deps_left() == 0) {\n+                    nmethod* nm = mtd->holder()->code();\n+                    if (nm == nullptr) {\n+                      if (mtd->holder()->queued_for_compilation()) {\n+                        return; \/\/ scheduled for compilation\n+                      }\n+                    } else if ((uint)nm->comp_level() >= entry->comp_level()) {\n+                      return; \/\/ already online compiled and superseded by a more optimal method\n+                    }\n+                    info.print(\"AOT Code Cache entry not loaded: \");\n+                    ctd->print_on(&info);\n+                    info.cr();\n+                  }\n+                }\n+              });\n+            } else {\n+              \/\/ not yet initialized\n+            }\n+          } else {\n+            info.print(\"AOT Code Cache entry doesn't have a holder: \");\n+            mtd->print_on(&info);\n+            info.cr();\n+          }\n+        }\n+      }\n+    });\n+  }\n+}\n+\n+void AOTCodeReader::print_on(outputStream* st) {\n+  uint entry_position = _entry->offset();\n+  set_read_position(entry_position);\n+\n+  \/\/ Read name\n+  uint name_offset = entry_position + _entry->name_offset();\n+  uint name_size = _entry->name_size(); \/\/ Includes '\/0'\n+  const char* name = addr(name_offset);\n+\n+  st->print_cr(\"  name: %s\", name);\n+}\n+\n+\/\/ address table ids for generated routines, external addresses and C\n+\/\/ string addresses are partitioned into positive integer ranges\n+\/\/ defined by the following positive base and max values\n+\/\/ i.e. [_extrs_base, _extrs_base + _extrs_max -1],\n+\/\/      [_stubs_base, _stubs_base + _stubs_max -1],\n+\/\/      ...\n+\/\/      [_c_str_base, _c_str_base + _c_str_max -1],\n+#define _extrs_max 80\n+#define _stubs_max 120\n+#define _all_blobs_max 100\n+#define _blobs_max 24\n+#define _C2_blobs_max 25\n+#define _C1_blobs_max (_all_blobs_max - _blobs_max - _C2_blobs_max)\n+#define _all_max 300\n+\n+#define _c_str_max MAX_STR_COUNT\n+#define _extrs_base 0\n+#define _stubs_base (_extrs_base + _extrs_max)\n+#define _blobs_base (_stubs_base + _stubs_max)\n+#define _C1_blobs_base (_blobs_base + _blobs_max)\n+#define _C2_blobs_base (_C1_blobs_base + _C1_blobs_max)\n+#if (_C2_blobs_base >= _all_max)\n+#error AOTCodeAddressTable ranges need adjusting\n+#endif\n+#define _c_str_base _all_max\n+\n+#define SET_ADDRESS(type, addr)                           \\\n+  {                                                       \\\n+    type##_addr[type##_length++] = (address) (addr);      \\\n+    assert(type##_length <= type##_max, \"increase size\"); \\\n+  }\n+\n+static bool initializing_extrs = false;\n+void AOTCodeAddressTable::init_extrs() {\n+  if (_extrs_complete || initializing_extrs) return; \/\/ Done already\n+  initializing_extrs = true;\n+  _extrs_addr = NEW_C_HEAP_ARRAY(address, _extrs_max, mtCode);\n+\n+  _extrs_length = 0;\n+  _stubs_length = 0;\n+\n+  \/\/ Runtime methods\n+#ifdef COMPILER2\n+  SET_ADDRESS(_extrs, OptoRuntime::handle_exception_C);\n+#endif\n+#ifdef COMPILER1\n+  SET_ADDRESS(_extrs, Runtime1::is_instance_of);\n+  SET_ADDRESS(_extrs, Runtime1::trace_block_entry);\n+#endif\n+\n+  SET_ADDRESS(_extrs, CompressedOops::base_addr());\n+#if INCLUDE_G1GC\n+  SET_ADDRESS(_extrs, G1BarrierSetRuntime::write_ref_field_post_entry);\n+  SET_ADDRESS(_extrs, G1BarrierSetRuntime::write_ref_field_pre_entry);\n+#endif\n+\n+#if INCLUDE_SHENANDOAHGC\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::arraycopy_barrier_oop);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::arraycopy_barrier_narrow_oop);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::write_ref_field_pre);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::clone_barrier);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_strong);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_strong_narrow);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_weak);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_weak_narrow);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_phantom);\n+  SET_ADDRESS(_extrs, ShenandoahRuntime::load_reference_barrier_phantom_narrow);\n+#endif\n+  SET_ADDRESS(_extrs, SharedRuntime::fixup_callers_callsite);\n+\n+  SET_ADDRESS(_extrs, SharedRuntime::log_jni_monitor_still_held);\n+  SET_ADDRESS(_extrs, SharedRuntime::rc_trace_method_entry);\n+  SET_ADDRESS(_extrs, SharedRuntime::reguard_yellow_pages);\n+  SET_ADDRESS(_extrs, SharedRuntime::dtrace_method_exit);\n+\n+  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method);\n+  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method_abstract);\n+  SET_ADDRESS(_extrs, SharedRuntime::handle_wrong_method_ic_miss);\n+  SET_ADDRESS(_extrs, SharedRuntime::resolve_opt_virtual_call_C);\n+  SET_ADDRESS(_extrs, SharedRuntime::resolve_virtual_call_C);\n+  SET_ADDRESS(_extrs, SharedRuntime::resolve_static_call_C);\n+\n+  SET_ADDRESS(_extrs, SharedRuntime::complete_monitor_unlocking_C);\n+  SET_ADDRESS(_extrs, SharedRuntime::enable_stack_reserved_zone);\n+#if defined(AMD64) && !defined(ZERO)\n+  SET_ADDRESS(_extrs, SharedRuntime::montgomery_multiply);\n+  SET_ADDRESS(_extrs, SharedRuntime::montgomery_square);\n+#endif \/\/ AMD64\n+  SET_ADDRESS(_extrs, SharedRuntime::d2f);\n+  SET_ADDRESS(_extrs, SharedRuntime::d2i);\n+  SET_ADDRESS(_extrs, SharedRuntime::d2l);\n+  SET_ADDRESS(_extrs, SharedRuntime::dcos);\n+  SET_ADDRESS(_extrs, SharedRuntime::dexp);\n+  SET_ADDRESS(_extrs, SharedRuntime::dlog);\n+  SET_ADDRESS(_extrs, SharedRuntime::dlog10);\n+  SET_ADDRESS(_extrs, SharedRuntime::dpow);\n+  SET_ADDRESS(_extrs, SharedRuntime::dsin);\n+  SET_ADDRESS(_extrs, SharedRuntime::dtan);\n+  SET_ADDRESS(_extrs, SharedRuntime::f2i);\n+  SET_ADDRESS(_extrs, SharedRuntime::f2l);\n+#ifndef ZERO\n+  SET_ADDRESS(_extrs, SharedRuntime::drem);\n+  SET_ADDRESS(_extrs, SharedRuntime::frem);\n+#endif\n+  SET_ADDRESS(_extrs, SharedRuntime::l2d);\n+  SET_ADDRESS(_extrs, SharedRuntime::l2f);\n+  SET_ADDRESS(_extrs, SharedRuntime::ldiv);\n+  SET_ADDRESS(_extrs, SharedRuntime::lmul);\n+  SET_ADDRESS(_extrs, SharedRuntime::lrem);\n+#if INCLUDE_JVMTI\n+  SET_ADDRESS(_extrs, &JvmtiExport::_should_notify_object_alloc);\n+#endif \/* INCLUDE_JVMTI *\/\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n+    SET_ADDRESS(_extrs, ci_card_table_address_as<address>());\n+  }\n+  SET_ADDRESS(_extrs, ThreadIdentifier::unsafe_offset());\n+  SET_ADDRESS(_extrs, Thread::current);\n+\n+  SET_ADDRESS(_extrs, os::javaTimeMillis);\n+  SET_ADDRESS(_extrs, os::javaTimeNanos);\n+\n+#if INCLUDE_JVMTI\n+  SET_ADDRESS(_extrs, &JvmtiVTMSTransitionDisabler::_VTMS_notify_jvmti_events);\n+#endif \/* INCLUDE_JVMTI *\/\n+  SET_ADDRESS(_extrs, StubRoutines::crc_table_addr());\n+#ifndef PRODUCT\n+  SET_ADDRESS(_extrs, &SharedRuntime::_partial_subtype_ctr);\n+  SET_ADDRESS(_extrs, JavaThread::verify_cross_modify_fence_failure);\n+#endif\n+\n+#ifndef ZERO\n+#if defined(AMD64) || defined(AARCH64) || defined(RISCV64)\n+  SET_ADDRESS(_extrs, MacroAssembler::debug64);\n+#endif\n+#if defined(AMD64)\n+  SET_ADDRESS(_extrs, StubRoutines::x86::arrays_hashcode_powers_of_31());\n+#endif\n+#endif\n+\n+#ifdef COMPILER1\n+#ifdef X86\n+  SET_ADDRESS(_extrs, LIR_Assembler::float_signmask_pool);\n+  SET_ADDRESS(_extrs, LIR_Assembler::double_signmask_pool);\n+  SET_ADDRESS(_extrs, LIR_Assembler::float_signflip_pool);\n+  SET_ADDRESS(_extrs, LIR_Assembler::double_signflip_pool);\n+#endif\n+#endif\n+\n+  \/\/ addresses of fields in AOT runtime constants area\n+  address* p = AOTRuntimeConstants::field_addresses_list();\n+  while (*p != nullptr) {\n+    SET_ADDRESS(_extrs, *p++);\n+  }\n+\n+  _extrs_complete = true;\n+  log_info(aot, codecache,init)(\"External addresses recorded\");\n+}\n+\n+static bool initializing_early_stubs = false;\n+void AOTCodeAddressTable::init_early_stubs() {\n+  if (_complete || initializing_early_stubs) return; \/\/ Done already\n+  initializing_early_stubs = true;\n+  _stubs_addr = NEW_C_HEAP_ARRAY(address, _stubs_max, mtCode);\n+  _stubs_length = 0;\n+  SET_ADDRESS(_stubs, StubRoutines::forward_exception_entry());\n+  _early_stubs_complete = true;\n+  log_info(aot, codecache,init)(\"early stubs recorded\");\n+}\n+\n+static bool initializing_shared_blobs = false;\n+void AOTCodeAddressTable::init_shared_blobs() {\n+  if (_complete || initializing_shared_blobs) return; \/\/ Done already\n+  initializing_shared_blobs = true;\n+  _blobs_addr = NEW_C_HEAP_ARRAY(address, _all_blobs_max, mtCode);\n+\n+  \/\/ Divide _blobs_addr array to chunks because they could be initialized in parrallel\n+  _C1_blobs_addr = _blobs_addr + _blobs_max;\/\/ C1 blobs addresses stored after shared blobs\n+  _C2_blobs_addr = _C1_blobs_addr + _C1_blobs_max; \/\/ C2 blobs addresses stored after C1 blobs\n+\n+  _blobs_length = 0;       \/\/ for shared blobs\n+  _C1_blobs_length = 0;\n+  _C2_blobs_length = 0;\n+\n+  \/\/ Blobs\n+  SET_ADDRESS(_blobs, SharedRuntime::get_handle_wrong_method_stub());\n+  SET_ADDRESS(_blobs, SharedRuntime::get_ic_miss_stub());\n+  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_opt_virtual_call_stub());\n+  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_virtual_call_stub());\n+  SET_ADDRESS(_blobs, SharedRuntime::get_resolve_static_call_stub());\n+  SET_ADDRESS(_blobs, SharedRuntime::deopt_blob()->entry_point());\n+  SET_ADDRESS(_blobs, SharedRuntime::polling_page_safepoint_handler_blob()->entry_point());\n+  SET_ADDRESS(_blobs, SharedRuntime::polling_page_return_handler_blob()->entry_point());\n+#ifdef COMPILER2\n+  SET_ADDRESS(_blobs, SharedRuntime::polling_page_vectors_safepoint_handler_blob()->entry_point());\n+#endif\n+\n+  assert(_blobs_length <= _blobs_max, \"increase _blobs_max to %d\", _blobs_length);\n+  log_info(aot, codecache,init)(\"Early shared blobs recorded\");\n+}\n+\n+static bool initializing_stubs = false;\n+void AOTCodeAddressTable::init_stubs() {\n+  if (_complete || initializing_stubs) return; \/\/ Done already\n+  initializing_stubs = true;\n+  \/\/ final blobs\n+  SET_ADDRESS(_blobs, SharedRuntime::throw_AbstractMethodError_entry());\n+  SET_ADDRESS(_blobs, SharedRuntime::throw_IncompatibleClassChangeError_entry());\n+  SET_ADDRESS(_blobs, SharedRuntime::throw_NullPointerException_at_call_entry());\n+  SET_ADDRESS(_blobs, SharedRuntime::throw_StackOverflowError_entry());\n+  SET_ADDRESS(_blobs, SharedRuntime::throw_delayed_StackOverflowError_entry());\n+\n+  assert(_blobs_length <= _blobs_max, \"increase _blobs_max to %d\", _blobs_length);\n+\n+  _shared_blobs_complete = true;\n+  log_info(aot, codecache,init)(\"All shared blobs recorded\");\n+\n+  \/\/ Stubs\n+  SET_ADDRESS(_stubs, StubRoutines::method_entry_barrier());\n+\/*\n+  SET_ADDRESS(_stubs, StubRoutines::throw_AbstractMethodError_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::throw_IncompatibleClassChangeError_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::throw_NullPointerException_at_call_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::throw_StackOverflowError_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::throw_delayed_StackOverflowError_entry());\n+*\/\n+  SET_ADDRESS(_stubs, StubRoutines::atomic_xchg_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::atomic_cmpxchg_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::atomic_cmpxchg_long_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::atomic_add_entry());\n+  SET_ADDRESS(_stubs, StubRoutines::fence_entry());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::cont_thaw());\n+  SET_ADDRESS(_stubs, StubRoutines::cont_returnBarrier());\n+  SET_ADDRESS(_stubs, StubRoutines::cont_returnBarrierExc());\n+\n+  JFR_ONLY(SET_ADDRESS(_stubs, SharedRuntime::jfr_write_checkpoint());)\n+\n+\n+  SET_ADDRESS(_stubs, StubRoutines::jbyte_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jshort_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jlong_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::_oop_arraycopy);\n+  SET_ADDRESS(_stubs, StubRoutines::_oop_arraycopy_uninit);\n+\n+  SET_ADDRESS(_stubs, StubRoutines::jbyte_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jshort_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jint_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::jlong_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::_oop_disjoint_arraycopy);\n+  SET_ADDRESS(_stubs, StubRoutines::_oop_disjoint_arraycopy_uninit);\n+\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jlong_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_arraycopy);\n+  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_arraycopy_uninit);\n+\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jlong_disjoint_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_disjoint_arraycopy);\n+  SET_ADDRESS(_stubs, StubRoutines::_arrayof_oop_disjoint_arraycopy_uninit);\n+\n+  SET_ADDRESS(_stubs, StubRoutines::_checkcast_arraycopy);\n+  SET_ADDRESS(_stubs, StubRoutines::_checkcast_arraycopy_uninit);\n+\n+  SET_ADDRESS(_stubs, StubRoutines::unsafe_arraycopy());\n+  SET_ADDRESS(_stubs, StubRoutines::generic_arraycopy());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::jbyte_fill());\n+  SET_ADDRESS(_stubs, StubRoutines::jshort_fill());\n+  SET_ADDRESS(_stubs, StubRoutines::jint_fill());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jbyte_fill());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jshort_fill());\n+  SET_ADDRESS(_stubs, StubRoutines::arrayof_jint_fill());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::data_cache_writeback());\n+  SET_ADDRESS(_stubs, StubRoutines::data_cache_writeback_sync());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::aescrypt_encryptBlock());\n+  SET_ADDRESS(_stubs, StubRoutines::aescrypt_decryptBlock());\n+  SET_ADDRESS(_stubs, StubRoutines::cipherBlockChaining_encryptAESCrypt());\n+  SET_ADDRESS(_stubs, StubRoutines::cipherBlockChaining_decryptAESCrypt());\n+  SET_ADDRESS(_stubs, StubRoutines::electronicCodeBook_encryptAESCrypt());\n+  SET_ADDRESS(_stubs, StubRoutines::electronicCodeBook_decryptAESCrypt());\n+  SET_ADDRESS(_stubs, StubRoutines::poly1305_processBlocks());\n+  SET_ADDRESS(_stubs, StubRoutines::counterMode_AESCrypt());\n+  SET_ADDRESS(_stubs, StubRoutines::ghash_processBlocks());\n+  SET_ADDRESS(_stubs, StubRoutines::chacha20Block());\n+  SET_ADDRESS(_stubs, StubRoutines::base64_encodeBlock());\n+  SET_ADDRESS(_stubs, StubRoutines::base64_decodeBlock());\n+  SET_ADDRESS(_stubs, StubRoutines::md5_implCompress());\n+  SET_ADDRESS(_stubs, StubRoutines::md5_implCompressMB());\n+  SET_ADDRESS(_stubs, StubRoutines::sha1_implCompress());\n+  SET_ADDRESS(_stubs, StubRoutines::sha1_implCompressMB());\n+  SET_ADDRESS(_stubs, StubRoutines::sha256_implCompress());\n+  SET_ADDRESS(_stubs, StubRoutines::sha256_implCompressMB());\n+  SET_ADDRESS(_stubs, StubRoutines::sha512_implCompress());\n+  SET_ADDRESS(_stubs, StubRoutines::sha512_implCompressMB());\n+  SET_ADDRESS(_stubs, StubRoutines::sha3_implCompress());\n+  SET_ADDRESS(_stubs, StubRoutines::sha3_implCompressMB());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::updateBytesCRC32());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::crc32c_table_addr());\n+  SET_ADDRESS(_stubs, StubRoutines::updateBytesCRC32C());\n+  SET_ADDRESS(_stubs, StubRoutines::updateBytesAdler32());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::multiplyToLen());\n+  SET_ADDRESS(_stubs, StubRoutines::squareToLen());\n+  SET_ADDRESS(_stubs, StubRoutines::mulAdd());\n+  SET_ADDRESS(_stubs, StubRoutines::montgomeryMultiply());\n+  SET_ADDRESS(_stubs, StubRoutines::montgomerySquare());\n+  SET_ADDRESS(_stubs, StubRoutines::bigIntegerRightShift());\n+  SET_ADDRESS(_stubs, StubRoutines::bigIntegerLeftShift());\n+  SET_ADDRESS(_stubs, StubRoutines::galoisCounterMode_AESCrypt());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::vectorizedMismatch());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::dexp());\n+  SET_ADDRESS(_stubs, StubRoutines::dlog());\n+  SET_ADDRESS(_stubs, StubRoutines::dlog10());\n+  SET_ADDRESS(_stubs, StubRoutines::dpow());\n+  SET_ADDRESS(_stubs, StubRoutines::dsin());\n+  SET_ADDRESS(_stubs, StubRoutines::dcos());\n+  SET_ADDRESS(_stubs, StubRoutines::dlibm_reduce_pi04l());\n+  SET_ADDRESS(_stubs, StubRoutines::dlibm_sin_cos_huge());\n+  SET_ADDRESS(_stubs, StubRoutines::dlibm_tan_cot_huge());\n+  SET_ADDRESS(_stubs, StubRoutines::dtan());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::f2hf_adr());\n+  SET_ADDRESS(_stubs, StubRoutines::hf2f_adr());\n+\n+#if defined(AMD64) && !defined(ZERO)\n+  SET_ADDRESS(_stubs, StubRoutines::x86::d2i_fixup());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::f2i_fixup());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::d2l_fixup());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::f2l_fixup());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::float_sign_mask());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::float_sign_flip());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::double_sign_mask());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::double_sign_flip());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::vector_popcount_lut());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::vector_float_sign_mask());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::vector_float_sign_flip());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::vector_double_sign_mask());\n+  SET_ADDRESS(_stubs, StubRoutines::x86::vector_double_sign_flip());\n+  \/\/ The iota indices are ordered by type B\/S\/I\/L\/F\/D, and the offset between two types is 64.\n+  \/\/ See C2_MacroAssembler::load_iota_indices().\n+  for (int i = 0; i < 6; i++) {\n+    SET_ADDRESS(_stubs, StubRoutines::x86::vector_iota_indices() + i * 64);\n+  }\n+#endif\n+#if defined(AARCH64) && !defined(ZERO)\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::zero_blocks());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::count_positives());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::count_positives_long());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_array_equals());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_LL());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_UU());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_LU());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::compare_long_string_UL());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_ul());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_ll());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::string_indexof_linear_uu());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_byte_array_inflate());\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::spin_wait());\n+\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_BOOLEAN));\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_BYTE));\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_SHORT));\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_CHAR));\n+  SET_ADDRESS(_stubs, StubRoutines::aarch64::large_arrays_hashcode(T_INT));\n+#endif\n+\n+  _complete = true;\n+  log_info(aot, codecache,init)(\"Stubs recorded\");\n+}\n+\n+void AOTCodeAddressTable::init_opto() {\n+#ifdef COMPILER2\n+  \/\/ OptoRuntime Blobs\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::uncommon_trap_blob()->entry_point());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::exception_blob()->entry_point());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::new_instance_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::new_array_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::new_array_nozero_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray2_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray3_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray4_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarray5_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::multianewarrayN_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::vtable_must_compile_stub());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::complete_monitor_locking_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::monitor_notify_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::monitor_notifyAll_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::rethrow_stub());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::slow_arraycopy_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::register_finalizer_Java());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::class_init_barrier_Java());\n+#if INCLUDE_JVMTI\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_start());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_end());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_mount());\n+  SET_ADDRESS(_C2_blobs, OptoRuntime::notify_jvmti_vthread_unmount());\n+#endif \/* INCLUDE_JVMTI *\/\n+#endif\n+\n+  assert(_C2_blobs_length <= _C2_blobs_max, \"increase _C2_blobs_max to %d\", _C2_blobs_length);\n+  _opto_complete = true;\n+  log_info(aot, codecache,init)(\"OptoRuntime Blobs recorded\");\n+}\n+\n+void AOTCodeAddressTable::init_c1() {\n+#ifdef COMPILER1\n+  \/\/ Runtime1 Blobs\n+  for (int i = 0; i < (int)(C1StubId::NUM_STUBIDS); i++) {\n+    C1StubId id = (C1StubId)i;\n+    if (Runtime1::blob_for(id) == nullptr) {\n+      log_info(aot, codecache, init)(\"C1 blob %s is missing\", Runtime1::name_for(id));\n+      continue;\n+    }\n+    if (Runtime1::entry_for(id) == nullptr) {\n+      log_info(aot, codecache, init)(\"C1 blob %s is missing entry\", Runtime1::name_for(id));\n+      continue;\n+    }\n+    address entry = Runtime1::entry_for(id);\n+    SET_ADDRESS(_C1_blobs, entry);\n+  }\n+#if INCLUDE_G1GC\n+  if (UseG1GC) {\n+    G1BarrierSetC1* bs = (G1BarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n+    address entry = bs->pre_barrier_c1_runtime_code_blob()->code_begin();\n+    SET_ADDRESS(_C1_blobs, entry);\n+    entry = bs->post_barrier_c1_runtime_code_blob()->code_begin();\n+    SET_ADDRESS(_C1_blobs, entry);\n+  }\n+#endif \/\/ INCLUDE_G1GC\n+#if INCLUDE_ZGC\n+  if (UseZGC) {\n+    ZBarrierSetC1* bs = (ZBarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n+    SET_ADDRESS(_C1_blobs, bs->_load_barrier_on_oop_field_preloaded_runtime_stub);\n+    SET_ADDRESS(_C1_blobs, bs->_load_barrier_on_weak_oop_field_preloaded_runtime_stub);\n+    SET_ADDRESS(_C1_blobs, bs->_store_barrier_on_oop_field_with_healing);\n+    SET_ADDRESS(_C1_blobs, bs->_store_barrier_on_oop_field_without_healing);\n+  }\n+#endif \/\/ INCLUDE_ZGC\n+#if INCLUDE_SHENANDOAHGC\n+  if (UseShenandoahGC) {\n+    ShenandoahBarrierSetC1* bs = (ShenandoahBarrierSetC1*)BarrierSet::barrier_set()->barrier_set_c1();\n+    SET_ADDRESS(_C1_blobs, bs->pre_barrier_c1_runtime_code_blob()->code_begin());\n+    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_strong_rt_code_blob()->code_begin());\n+    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_strong_native_rt_code_blob()->code_begin());\n+    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_weak_rt_code_blob()->code_begin());\n+    SET_ADDRESS(_C1_blobs, bs->load_reference_barrier_phantom_rt_code_blob()->code_begin());\n+  }\n+#endif \/\/ INCLUDE_SHENANDOAHGC\n+#endif \/\/ COMPILER1\n+\n+  assert(_C1_blobs_length <= _C1_blobs_max, \"increase _C1_blobs_max to %d\", _C1_blobs_length);\n+  _c1_complete = true;\n+  log_info(aot, codecache,init)(\"Runtime1 Blobs recorded\");\n+}\n+\n+#undef SET_ADDRESS\n+\n+AOTCodeAddressTable::~AOTCodeAddressTable() {\n+  if (_extrs_addr != nullptr) {\n+    FREE_C_HEAP_ARRAY(address, _extrs_addr);\n+  }\n+  if (_stubs_addr != nullptr) {\n+    FREE_C_HEAP_ARRAY(address, _stubs_addr);\n+  }\n+  if (_blobs_addr != nullptr) {\n+    FREE_C_HEAP_ARRAY(address, _blobs_addr);\n+  }\n+}\n+\n+#ifdef PRODUCT\n+#define MAX_STR_COUNT 200\n+#else\n+#define MAX_STR_COUNT 500\n+#endif\n+static const char* _C_strings[MAX_STR_COUNT] = {nullptr};\n+static int _C_strings_count = 0;\n+static int _C_strings_s[MAX_STR_COUNT] = {0};\n+static int _C_strings_id[MAX_STR_COUNT] = {0};\n+static int _C_strings_len[MAX_STR_COUNT] = {0};\n+static int _C_strings_hash[MAX_STR_COUNT] = {0};\n+static int _C_strings_used = 0;\n+\n+void AOTCodeCache::load_strings() {\n+  uint strings_count  = _load_header->strings_count();\n+  if (strings_count == 0) {\n+    return;\n+  }\n+  uint strings_offset = _load_header->strings_offset();\n+  uint strings_size   = _load_header->entries_offset() - strings_offset;\n+  uint data_size = (uint)(strings_count * sizeof(uint));\n+  uint* sizes = (uint*)addr(strings_offset);\n+  uint* hashs = (uint*)addr(strings_offset + data_size);\n+  strings_size -= 2 * data_size;\n+  \/\/ We have to keep cached strings longer than _cache buffer\n+  \/\/ because they are refernced from compiled code which may\n+  \/\/ still be executed on VM exit after _cache is freed.\n+  char* p = NEW_C_HEAP_ARRAY(char, strings_size+1, mtCode);\n+  memcpy(p, addr(strings_offset + 2 * data_size), strings_size);\n+  _C_strings_buf = p;\n+  assert(strings_count <= MAX_STR_COUNT, \"sanity\");\n+  for (uint i = 0; i < strings_count; i++) {\n+    _C_strings[i] = p;\n+    uint len = sizes[i];\n+    _C_strings_s[i] = i;\n+    _C_strings_id[i] = i;\n+    _C_strings_len[i] = len;\n+    _C_strings_hash[i] = hashs[i];\n+    p += len;\n+  }\n+  assert((uint)(p - _C_strings_buf) <= strings_size, \"(\" INTPTR_FORMAT \" - \" INTPTR_FORMAT \") = %d > %d \", p2i(p), p2i(_C_strings_buf), (uint)(p - _C_strings_buf), strings_size);\n+  _C_strings_count = strings_count;\n+  _C_strings_used  = strings_count;\n+  log_info(aot, codecache, init)(\"Load %d C strings at offset %d from AOT Code Cache\", _C_strings_count, strings_offset);\n+}\n+\n+int AOTCodeCache::store_strings() {\n+  uint offset = _write_position;\n+  uint length = 0;\n+  if (_C_strings_used > 0) {\n+    \/\/ Write sizes first\n+    for (int i = 0; i < _C_strings_used; i++) {\n+      uint len = _C_strings_len[i] + 1; \/\/ Include 0\n+      length += len;\n+      assert(len < 1000, \"big string: %s\", _C_strings[i]);\n+      uint n = write_bytes(&len, sizeof(uint));\n+      if (n != sizeof(uint)) {\n+        return -1;\n+      }\n+    }\n+    \/\/ Write hashs\n+    for (int i = 0; i < _C_strings_used; i++) {\n+      uint n = write_bytes(&(_C_strings_hash[i]), sizeof(uint));\n+      if (n != sizeof(uint)) {\n+        return -1;\n+      }\n+    }\n+    for (int i = 0; i < _C_strings_used; i++) {\n+      uint len = _C_strings_len[i] + 1; \/\/ Include 0\n+      uint n = write_bytes(_C_strings[_C_strings_s[i]], len);\n+      if (n != len) {\n+        return -1;\n+      }\n+    }\n+    log_info(aot, codecache, exit)(\"Wrote %d C strings of total length %d at offset %d to AOT Code Cache\",\n+                        _C_strings_used, length, offset);\n+  }\n+  return _C_strings_used;\n+}\n+\n+void AOTCodeCache::add_new_C_string(const char* str) {\n+  assert(for_write(), \"only when storing code\");\n+  _table->add_C_string(str);\n+}\n+\n+void AOTCodeAddressTable::add_C_string(const char* str) {\n+  if (str != nullptr && _extrs_complete) {\n+    \/\/ Check previous strings address\n+    for (int i = 0; i < _C_strings_count; i++) {\n+      if (_C_strings[i] == str) {\n+        return; \/\/ Found existing one\n+      }\n+    }\n+    \/\/ Add new one\n+    if (_C_strings_count < MAX_STR_COUNT) {\n+      log_trace(aot, codecache)(\"add_C_string: [%d] \" INTPTR_FORMAT \" %s\", _C_strings_count, p2i(str), str);\n+      _C_strings_id[_C_strings_count] = -1; \/\/ Init\n+      _C_strings[_C_strings_count++] = str;\n+    } else {\n+      if (Thread::current()->is_Compiler_thread()) {\n+        CompileTask* task = ciEnv::current()->task();\n+        log_info(aot, codecache)(\"%d (L%d): Number of C strings > max %d %s\",\n+                      task->compile_id(), task->comp_level(), MAX_STR_COUNT, str);\n+      }\n+    }\n+  }\n+}\n+\n+int AOTCodeAddressTable::id_for_C_string(address str) {\n+  for (int i = 0; i < _C_strings_count; i++) {\n+    if (_C_strings[i] == (const char*)str) { \/\/ found\n+      int id = _C_strings_id[i];\n+      if (id >= 0) {\n+        assert(id < _C_strings_used, \"%d >= %d\", id , _C_strings_used);\n+        return id; \/\/ Found recorded\n+      }\n+      \/\/ Search for the same string content\n+      int len = (int)strlen((const char*)str);\n+      int hash = java_lang_String::hash_code((const jbyte*)str, len);\n+      for (int j = 0; j < _C_strings_used; j++) {\n+        if ((_C_strings_len[j] == len) && (_C_strings_hash[j] == hash)) {\n+          _C_strings_id[i] = j; \/\/ Found match\n+          return j;\n+        }\n+      }\n+      \/\/ Not found in recorded, add new\n+      id = _C_strings_used++;\n+      _C_strings_s[id] = i;\n+      _C_strings_id[i] = id;\n+      _C_strings_len[id] = len;\n+      _C_strings_hash[id] = hash;\n+      return id;\n+    }\n+  }\n+  return -1;\n+}\n+\n+address AOTCodeAddressTable::address_for_C_string(int idx) {\n+  assert(idx < _C_strings_count, \"sanity\");\n+  return (address)_C_strings[idx];\n+}\n+\n+int search_address(address addr, address* table, uint length) {\n+  for (int i = 0; i < (int)length; i++) {\n+    if (table[i] == addr) {\n+      return i;\n+    }\n+  }\n+  return -1;\n+}\n+\n+address AOTCodeAddressTable::address_for_id(int idx) {\n+  if (!_extrs_complete) {\n+    fatal(\"AOT Code Cache VM runtime addresses table is not complete\");\n+  }\n+  if (idx == -1) {\n+    return (address)-1;\n+  }\n+  uint id = (uint)idx;\n+  \/\/ special case for symbols based relative to os::init\n+  if (id > (_c_str_base + _c_str_max)) {\n+    return (address)os::init + idx;\n+  }\n+  if (idx < 0) {\n+    fatal(\"Incorrect id %d for AOT Code Cache addresses table\", id);\n+  }\n+  \/\/ no need to compare unsigned id against 0\n+  if (\/* id >= _extrs_base && *\/ id < _extrs_length) {\n+    return _extrs_addr[id - _extrs_base];\n+  }\n+  if (id >= _stubs_base && id < _stubs_base + _stubs_length) {\n+    return _stubs_addr[id - _stubs_base];\n+  }\n+  if (id >= _blobs_base && id < _blobs_base + _blobs_length) {\n+    return _blobs_addr[id - _blobs_base];\n+  }\n+  if (id >= _C1_blobs_base && id < _C1_blobs_base + _C1_blobs_length) {\n+    return _C1_blobs_addr[id - _C1_blobs_base];\n+  }\n+  if (id >= _C2_blobs_base && id < _C2_blobs_base + _C2_blobs_length) {\n+    return _C2_blobs_addr[id - _C2_blobs_base];\n+  }\n+  if (id >= _c_str_base && id < (_c_str_base + (uint)_C_strings_count)) {\n+    return address_for_C_string(id - _c_str_base);\n+  }\n+  fatal(\"Incorrect id %d for AOT Code Cache addresses table\", id);\n+  return nullptr;\n+}\n+\n+int AOTCodeAddressTable::id_for_address(address addr, RelocIterator reloc, CodeBuffer* buffer) {\n+  if (!_extrs_complete) {\n+    fatal(\"AOT Code Cache VM runtime addresses table is not complete\");\n+  }\n+  int id = -1;\n+  if (addr == (address)-1) { \/\/ Static call stub has jump to itself\n+    return id;\n+  }\n+  \/\/ Seach for C string\n+  id = id_for_C_string(addr);\n+  if (id >=0) {\n+    return id + _c_str_base;\n+  }\n+  if (StubRoutines::contains(addr)) {\n+    \/\/ Search in stubs\n+    id = search_address(addr, _stubs_addr, _stubs_length);\n+    if (id < 0) {\n+      StubCodeDesc* desc = StubCodeDesc::desc_for(addr);\n+      if (desc == nullptr) {\n+        desc = StubCodeDesc::desc_for(addr + frame::pc_return_offset);\n+      }\n+      const char* sub_name = (desc != nullptr) ? desc->name() : \"<unknown>\";\n+      fatal(\"Address \" INTPTR_FORMAT \" for Stub:%s is missing in AOT Code Cache addresses table\", p2i(addr), sub_name);\n+    } else {\n+      return _stubs_base + id;\n+    }\n+  } else {\n+    CodeBlob* cb = CodeCache::find_blob(addr);\n+    if (cb != nullptr) {\n+      int id_base = _blobs_base;\n+      \/\/ Search in code blobs\n+       id = search_address(addr, _blobs_addr, _blobs_length);\n+      if (id == -1) {\n+        id_base = _C1_blobs_base;\n+        \/\/ search C1 blobs\n+        id = search_address(addr, _C1_blobs_addr, _C1_blobs_length);\n+      }\n+      if (id == -1) {\n+        id_base = _C2_blobs_base;\n+        \/\/ search C2 blobs\n+        id = search_address(addr, _C2_blobs_addr, _C2_blobs_length);\n+      }\n+      if (id < 0) {\n+        fatal(\"Address \" INTPTR_FORMAT \" for Blob:%s is missing in AOT Code Cache addresses table\", p2i(addr), cb->name());\n+      } else {\n+        return id_base + id;\n+      }\n+    } else {\n+      \/\/ Search in runtime functions\n+      id = search_address(addr, _extrs_addr, _extrs_length);\n+      if (id < 0) {\n+        ResourceMark rm;\n+        const int buflen = 1024;\n+        char* func_name = NEW_RESOURCE_ARRAY(char, buflen);\n+        int offset = 0;\n+        if (os::dll_address_to_function_name(addr, func_name, buflen, &offset)) {\n+          if (offset > 0) {\n+            \/\/ Could be address of C string\n+            uint dist = (uint)pointer_delta(addr, (address)os::init, 1);\n+            CompileTask* task = ciEnv::current()->task();\n+            uint compile_id = 0;\n+            uint comp_level =0;\n+            if (task != nullptr) { \/\/ this could be called from compiler runtime initialization (compiler blobs)\n+              compile_id = task->compile_id();\n+              comp_level = task->comp_level();\n+            }\n+            log_info(aot, codecache)(\"%d (L%d): Address \" INTPTR_FORMAT \" (offset %d) for runtime target '%s' is missing in AOT Code Cache addresses table\",\n+                          compile_id, comp_level, p2i(addr), dist, (const char*)addr);\n+            assert(dist > (uint)(_all_max + MAX_STR_COUNT), \"change encoding of distance\");\n+            return dist;\n+          }\n+          fatal(\"Address \" INTPTR_FORMAT \" for runtime target '%s+%d' is missing in AOT Code Cache addresses table\", p2i(addr), func_name, offset);\n+        } else {\n+          os::print_location(tty, p2i(addr), true);\n+          reloc.print_current_on(tty);\n+#ifndef PRODUCT\n+          buffer->print_on(tty);\n+          buffer->decode();\n+#endif \/\/ !PRODUCT\n+          fatal(\"Address \" INTPTR_FORMAT \" for <unknown> is missing in AOT Code Cache addresses table\", p2i(addr));\n+        }\n+      } else {\n+        return _extrs_base + id;\n+      }\n+    }\n+  }\n+  return id;\n+}\n+\n+#undef _extrs_max\n+#undef _stubs_max\n+#undef _all_blobs_max\n+#undef _blobs_max\n+#undef _C1_blobs_max\n+#undef _C2_blobs_max\n+#undef _extrs_base\n+#undef _stubs_base\n+#undef _blobs_base\n+#undef _C1_blobs_base\n+#undef _C2_blobs_base\n+#undef _c_str_base\n+\n+void AOTRuntimeConstants::initialize_from_runtime() {\n+  BarrierSet* bs = BarrierSet::barrier_set();\n+  if (bs->is_a(BarrierSet::CardTableBarrierSet)) {\n+    CardTableBarrierSet* ctbs = ((CardTableBarrierSet*)bs);\n+    _aot_runtime_constants._grain_shift = ctbs->grain_shift();\n+    _aot_runtime_constants._card_shift = ctbs->card_shift();\n+  }\n+}\n+\n+AOTRuntimeConstants AOTRuntimeConstants::_aot_runtime_constants;\n+\n+address AOTRuntimeConstants::_field_addresses_list[] = {\n+  grain_shift_address(),\n+  card_shift_address(),\n+  nullptr\n+};\n+\n+\n+void AOTCodeCache::wait_for_no_nmethod_readers() {\n+  while (true) {\n+    int cur = Atomic::load(&_nmethod_readers);\n+    int upd = -(cur + 1);\n+    if (cur >= 0 && Atomic::cmpxchg(&_nmethod_readers, cur, upd) == cur) {\n+      \/\/ Success, no new readers should appear.\n+      break;\n+    }\n+  }\n+\n+  \/\/ Now wait for all readers to leave.\n+  SpinYield w;\n+  while (Atomic::load(&_nmethod_readers) != -1) {\n+    w.wait();\n+  }\n+}\n+\n+AOTCodeCache::ReadingMark::ReadingMark() {\n+  while (true) {\n+    int cur = Atomic::load(&_nmethod_readers);\n+    if (cur < 0) {\n+      \/\/ Cache is already closed, cannot proceed.\n+      _failed = true;\n+      return;\n+    }\n+    if (Atomic::cmpxchg(&_nmethod_readers, cur, cur + 1) == cur) {\n+      \/\/ Successfully recorded ourselves as entered.\n+      _failed = false;\n+      return;\n+    }\n+  }\n+}\n+\n+AOTCodeCache::ReadingMark::~ReadingMark() {\n+  if (_failed) {\n+    return;\n+  }\n+  while (true) {\n+    int cur = Atomic::load(&_nmethod_readers);\n+    if (cur > 0) {\n+      \/\/ Cache is open, we are counting down towards 0.\n+      if (Atomic::cmpxchg(&_nmethod_readers, cur, cur - 1) == cur) {\n+        return;\n+      }\n+    } else {\n+      \/\/ Cache is closed, we are counting up towards -1.\n+      if (Atomic::cmpxchg(&_nmethod_readers, cur, cur + 1) == cur) {\n+        return;\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/share\/code\/aotCodeCache.cpp","additions":4770,"deletions":0,"binary":false,"changes":4770,"status":"added"},{"patch":"@@ -0,0 +1,785 @@\n+\/*\n+ * Copyright (c) 2023, 2025, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_CODE_AOTCODECACHE_HPP\n+#define SHARE_CODE_AOTCODECACHE_HPP\n+\n+#include \"compiler\/compilerDefinitions.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"nmt\/memTag.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/exceptions.hpp\"\n+\n+\/*\n+ * AOT Code Cache collects code from Code Cache and corresponding metadata\n+ * during application training run.\n+ * In following \"production\" runs this code and data can me loaded into\n+ * Code Cache skipping its generation.\n+ * Additionaly special compiled code \"preload\" is generated with class initialization\n+ * barriers which can be called on first Java method invocation.\n+ *\/\n+\n+class AbstractCompiler;\n+class ciConstant;\n+class ciEnv;\n+class ciMethod;\n+class CodeBuffer;\n+class CodeOffsets;\n+class CompileTask;\n+class DebugInformationRecorder;\n+class Dependencies;\n+class ExceptionTable;\n+class ExceptionHandlerTable;\n+template<typename E>\n+class GrowableArray;\n+class ImmutableOopMapSet;\n+class ImplicitExceptionTable;\n+class JavaThread;\n+class Klass;\n+class methodHandle;\n+class Metadata;\n+class Method;\n+class nmethod;\n+class OopMapSet;\n+class OopRecorder;\n+class outputStream;\n+class RelocIterator;\n+class AOTCodeCache;\n+class StubCodeGenerator;\n+\n+enum class vmIntrinsicID : int;\n+\n+#define DO_AOTCODEENTRY_KIND(Fn) \\\n+  Fn(None) \\\n+  Fn(Adapter) \\\n+  Fn(Stub) \\\n+  Fn(Blob) \\\n+  Fn(Code) \\\n+\n+\/\/ Code Cache's entry contain information from CodeBuffer\n+class AOTCodeEntry {\n+public:\n+  enum Kind : s1 {\n+#define DECL_KIND_ENUM(kind) kind,\n+    DO_AOTCODEENTRY_KIND(DECL_KIND_ENUM)\n+#undef DECL_KIND_ENUM\n+    Kind_count\n+  };\n+\n+private:\n+  AOTCodeEntry* _next;\n+  Method*   _method;\n+  Kind   _kind;        \/\/\n+  uint   _id;          \/\/ vmIntrinsic::ID for stub or name's hash for nmethod\n+\n+  uint   _offset;      \/\/ Offset to entry\n+  uint   _size;        \/\/ Entry size\n+  uint   _name_offset; \/\/ Method's or intrinsic name\n+  uint   _name_size;\n+  uint   _code_offset; \/\/ Start of code in cache\n+  uint   _code_size;   \/\/ Total size of all code sections\n+  uint   _reloc_offset;\/\/ Relocations\n+  uint   _reloc_size;  \/\/ Max size of relocations per code section\n+  uint   _num_inlined_bytecodes;\n+\n+  uint   _comp_level;  \/\/ compilation level\n+  uint   _comp_id;     \/\/ compilation id\n+  uint   _decompile;   \/\/ Decompile count for this nmethod\n+  bool   _has_clinit_barriers; \/\/ Generated code has class init checks\n+  bool   _for_preload; \/\/ Code can be used for preload\n+  bool   _loaded;      \/\/ Code was loaded\n+  bool   _not_entrant; \/\/ Deoptimized\n+  bool   _load_fail;   \/\/ Failed to load due to some klass state\n+  bool   _ignore_decompile; \/\/ ignore decompile counter if compilation is done\n+                            \/\/ during \"assembly\" phase without running application\n+  address _dumptime_content_start_addr;\n+public:\n+  AOTCodeEntry(uint offset, uint size, uint name_offset, uint name_size,\n+           uint code_offset, uint code_size,\n+           uint reloc_offset, uint reloc_size,\n+           Kind kind, uint id,\n+           address dumptime_content_start_addr = nullptr,\n+           uint comp_level = 0,\n+           uint comp_id = 0, uint decomp = 0,\n+           bool has_clinit_barriers = false,\n+           bool for_preload = false,\n+           bool ignore_decompile = false) {\n+    _next         = nullptr;\n+    _method       = nullptr;\n+    _kind         = kind;\n+    _id           = id;\n+\n+    _offset       = offset;\n+    _size         = size;\n+    _name_offset  = name_offset;\n+    _name_size    = name_size;\n+    _code_offset  = code_offset;\n+    _code_size    = code_size;\n+    _reloc_offset = reloc_offset;\n+    _reloc_size   = reloc_size;\n+\n+    _dumptime_content_start_addr = dumptime_content_start_addr;\n+\n+    _num_inlined_bytecodes = 0;\n+\n+    _comp_level   = comp_level;\n+    _comp_id      = comp_id;\n+    _decompile    = decomp;\n+    _has_clinit_barriers = has_clinit_barriers;\n+    _for_preload  = for_preload;\n+    _loaded       = false;\n+    _not_entrant  = false;\n+    _load_fail    = false;\n+    _ignore_decompile = ignore_decompile;\n+  }\n+  void* operator new(size_t x, AOTCodeCache* cache);\n+  \/\/ Delete is a NOP\n+  void operator delete( void *ptr ) {}\n+\n+  bool is_adapter() { return _kind == Adapter; }\n+  bool is_stub() { return _kind == Stub; }\n+  bool is_blob() { return _kind == Blob; }\n+  bool is_code() { return _kind == Code; }\n+\n+  AOTCodeEntry* next()    const { return _next; }\n+  void set_next(AOTCodeEntry* next) { _next = next; }\n+\n+  Method*   method()  const { return _method; }\n+  void set_method(Method* method) { _method = method; }\n+  void update_method_for_writing();\n+\n+  Kind kind()         const { return _kind; }\n+  uint id()           const { return _id; }\n+\n+  uint offset()       const { return _offset; }\n+  void set_offset(uint off) { _offset = off; }\n+\n+  uint size()         const { return _size; }\n+  uint name_offset()  const { return _name_offset; }\n+  uint name_size()    const { return _name_size; }\n+  uint code_offset()  const { return _code_offset; }\n+  uint code_size()    const { return _code_size; }\n+  uint reloc_offset() const { return _reloc_offset; }\n+  uint reloc_size()   const { return _reloc_size; }\n+\n+  address dumptime_content_start_addr() const { return _dumptime_content_start_addr; }\n+\n+  uint num_inlined_bytecodes() const { return _num_inlined_bytecodes; }\n+  void set_inlined_bytecodes(int bytes) { _num_inlined_bytecodes = bytes; }\n+\n+  uint comp_level()   const { return _comp_level; }\n+  uint comp_id()      const { return _comp_id; }\n+\n+  uint decompile()    const { return _decompile; }\n+  bool has_clinit_barriers() const { return _has_clinit_barriers; }\n+  bool for_preload()  const { return _for_preload; }\n+  bool is_loaded()    const { return _loaded; }\n+  void set_loaded()         { _loaded = true; }\n+  bool ignore_decompile() const { return _ignore_decompile; }\n+\n+  bool not_entrant()  const { return _not_entrant; }\n+  void set_not_entrant()    { _not_entrant = true; }\n+  void set_entrant()        { _not_entrant = false; }\n+\n+  bool load_fail()  const { return _load_fail; }\n+  void set_load_fail()    { _load_fail = true; }\n+\n+  void print(outputStream* st) const;\n+};\n+\n+\/\/ Addresses of stubs, blobs and runtime finctions called from compiled code.\n+class AOTCodeAddressTable : public CHeapObj<mtCode> {\n+private:\n+  address* _extrs_addr;\n+  address* _stubs_addr;\n+  address* _blobs_addr;\n+  address* _C1_blobs_addr;\n+  address* _C2_blobs_addr;\n+  uint     _extrs_length;\n+  uint     _stubs_length;\n+  uint     _blobs_length;\n+  uint     _C1_blobs_length;\n+  uint     _C2_blobs_length;\n+\n+  bool _extrs_complete;\n+  bool _early_stubs_complete;\n+  bool _shared_blobs_complete;\n+  bool _complete;\n+  bool _opto_complete;\n+  bool _c1_complete;\n+\n+public:\n+  AOTCodeAddressTable() {\n+    _extrs_addr = nullptr;\n+    _stubs_addr = nullptr;\n+    _blobs_addr = nullptr;\n+    _extrs_complete = false;\n+    _early_stubs_complete = false;\n+    _shared_blobs_complete = false;\n+    _complete = false;\n+    _opto_complete = false;\n+    _c1_complete = false;\n+  }\n+  ~AOTCodeAddressTable();\n+  void init_extrs();\n+  void init_early_stubs();\n+  void init_shared_blobs();\n+  void init_stubs();\n+  void init_opto();\n+  void init_c1();\n+  void add_C_string(const char* str);\n+  int  id_for_C_string(address str);\n+  address address_for_C_string(int idx);\n+  int  id_for_address(address addr, RelocIterator iter, CodeBuffer* buffer);\n+  address address_for_id(int id);\n+  bool opto_complete() const { return _opto_complete; }\n+  bool c1_complete() const { return _c1_complete; }\n+};\n+\n+struct AOTCodeSection {\n+public:\n+  address _origin_address;\n+  uint _size;\n+  uint _offset;\n+};\n+\n+enum class DataKind: int {\n+  No_Data   = -1,\n+  Null      = 0,\n+  Klass     = 1,\n+  Method    = 2,\n+  String    = 3,\n+  Primitive = 4, \/\/ primitive Class object\n+  SysLoader = 5, \/\/ java_system_loader\n+  PlaLoader = 6, \/\/ java_platform_loader\n+  MethodCnts= 7,\n+  Klass_Shared  = 8,\n+  Method_Shared = 9,\n+  String_Shared = 10,\n+  MH_Oop_Shared = 11\n+};\n+\n+\/\/ Concurent AOT code reader\n+class AOTCodeReader {\n+private:\n+  const AOTCodeCache* _cache;\n+  const AOTCodeEntry* _entry;\n+  const char*         _load_buffer; \/\/ Loaded cached code buffer\n+  uint  _read_position;             \/\/ Position in _load_buffer\n+  uint  read_position() const { return _read_position; }\n+  void  set_read_position(uint pos);\n+  const char* addr(uint offset) const { return _load_buffer + offset; }\n+\n+  uint _compile_id;\n+  uint _comp_level;\n+  uint compile_id() const { return _compile_id; }\n+  uint comp_level() const { return _comp_level; }\n+\n+  bool _preload;             \/\/ Preloading code before method execution\n+  bool _lookup_failed;       \/\/ Failed to lookup for info (skip only this code load)\n+  void set_lookup_failed()     { _lookup_failed = true; }\n+  void clear_lookup_failed()   { _lookup_failed = false; }\n+  bool lookup_failed()   const { return _lookup_failed; }\n+\n+public:\n+  AOTCodeReader(AOTCodeCache* cache, AOTCodeEntry* entry, CompileTask* task);\n+\n+  AOTCodeEntry* aot_code_entry() { return (AOTCodeEntry*)_entry; }\n+\n+  \/\/ convenience method to convert offset in AOTCodeEntry data to its address\n+  bool compile_nmethod(ciEnv* env, ciMethod* target, AbstractCompiler* compiler);\n+  bool compile_blob(CodeBuffer* buffer, int* pc_offset);\n+\n+  bool compile_adapter(CodeBuffer* buffer, const char* name, uint32_t offsets[4]);\n+\n+  Klass* read_klass(const methodHandle& comp_method, bool shared);\n+  Method* read_method(const methodHandle& comp_method, bool shared);\n+\n+  bool read_code(CodeBuffer* buffer, CodeBuffer* orig_buffer, uint code_offset);\n+  bool read_relocations(CodeBuffer* buffer, CodeBuffer* orig_buffer, OopRecorder* oop_recorder, ciMethod* target);\n+  DebugInformationRecorder* read_debug_info(OopRecorder* oop_recorder);\n+  OopMapSet* read_oop_maps();\n+  bool read_dependencies(Dependencies* dependencies);\n+\n+  oop read_oop(JavaThread* thread, const methodHandle& comp_method);\n+  Metadata* read_metadata(const methodHandle& comp_method);\n+  bool read_oops(OopRecorder* oop_recorder, ciMethod* target);\n+  bool read_metadata(OopRecorder* oop_recorder, ciMethod* target);\n+\n+  bool read_oop_metadata_list(JavaThread* thread, ciMethod* target, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list, OopRecorder* oop_recorder);\n+  void apply_relocations(nmethod* nm, GrowableArray<Handle> &oop_list, GrowableArray<Metadata*> &metadata_list) NOT_CDS_RETURN;\n+\n+  ImmutableOopMapSet* read_oop_map_set();\n+\n+  void print_on(outputStream* st);\n+};\n+\n+class AOTCodeCache : public CHeapObj<mtCode> {\n+\n+\/\/ Classes used to describe AOT code cache.\n+protected:\n+class Config {\n+    uint _compressedOopShift;\n+    uint _compressedKlassShift;\n+    uint _contendedPaddingWidth;\n+    uint _objectAlignment;\n+    uint _gc;\n+    enum Flags {\n+      none                     = 0,\n+      metadataPointers         = 1,\n+      debugVM                  = 2,\n+      compressedOops           = 4,\n+      compressedClassPointers  = 8,\n+      useTLAB                  = 16,\n+      systemClassAssertions    = 32,\n+      userClassAssertions      = 64,\n+      enableContendedPadding   = 128,\n+      restrictContendedPadding = 256,\n+    };\n+    uint _flags;\n+\n+  public:\n+    void record(bool use_meta_ptrs);\n+    bool verify() const;\n+\n+    bool has_meta_ptrs()  const { return (_flags & metadataPointers) != 0; }\n+  };\n+\n+  class Header : public CHeapObj<mtCode> {\n+  private:\n+    \/\/ Here should be version and other verification fields\n+    enum {\n+      AOT_CODE_VERSION = 1\n+    };\n+    uint _version;           \/\/ AOT code version (should match when reading code cache)\n+    uint _cache_size;        \/\/ cache size in bytes\n+    uint _strings_count;     \/\/ number of recorded C strings\n+    uint _strings_offset;    \/\/ offset to recorded C strings\n+    uint _entries_count;     \/\/ number of recorded entries in cache\n+    uint _entries_offset;    \/\/ offset of AOTCodeEntry array describing entries\n+    uint _preload_entries_count; \/\/ entries for pre-loading code\n+    uint _preload_entries_offset;\n+    Config _config;\n+\n+  public:\n+    void init(uint cache_size,\n+              uint strings_count, uint strings_offset,\n+              uint entries_count, uint entries_offset,\n+              uint preload_entries_count, uint preload_entries_offset,\n+              bool use_meta_ptrs) {\n+      _version        = AOT_CODE_VERSION;\n+      _cache_size     = cache_size;\n+      _strings_count  = strings_count;\n+      _strings_offset = strings_offset;\n+      _entries_count  = entries_count;\n+      _entries_offset = entries_offset;\n+      _preload_entries_count  = preload_entries_count;\n+      _preload_entries_offset = preload_entries_offset;\n+\n+      _config.record(use_meta_ptrs);\n+    }\n+\n+    uint cache_size()     const { return _cache_size; }\n+    uint strings_count()  const { return _strings_count; }\n+    uint strings_offset() const { return _strings_offset; }\n+    uint entries_count()  const { return _entries_count; }\n+    uint entries_offset() const { return _entries_offset; }\n+    uint preload_entries_count()  const { return _preload_entries_count; }\n+    uint preload_entries_offset() const { return _preload_entries_offset; }\n+    bool has_meta_ptrs()  const { return _config.has_meta_ptrs(); }\n+\n+    bool verify_config(uint load_size)  const;\n+    bool verify_vm_config() const { \/\/ Called after Universe initialized\n+      return _config.verify();\n+    }\n+  };\n+\n+\/\/ Continue with AOTCodeCache class definition.\n+private:\n+  Header*     _load_header;\n+  char*       _load_buffer;    \/\/ Aligned buffer for loading cached code\n+  char*       _store_buffer;   \/\/ Aligned buffer for storing cached code\n+  char*       _C_store_buffer; \/\/ Original unaligned buffer\n+\n+  uint        _write_position; \/\/ Position in _store_buffer\n+  uint        _load_size;      \/\/ Used when reading cache\n+  uint        _store_size;     \/\/ Used when writing cache\n+  bool _for_read;              \/\/ Open for read\n+  bool _for_write;             \/\/ Open for write\n+  bool _use_meta_ptrs;         \/\/ Store metadata pointers\n+  bool _for_preload;           \/\/ Code for preload\n+  bool _gen_preload_code;      \/\/ Generate pre-loading code\n+  bool _has_clinit_barriers;   \/\/ Code with clinit barriers\n+  bool _closing;               \/\/ Closing cache file\n+  bool _failed;                \/\/ Failed read\/write to\/from cache (cache is broken?)\n+\n+  AOTCodeAddressTable* _table;\n+\n+  AOTCodeEntry* _load_entries;     \/\/ Used when reading cache\n+  uint*     _search_entries;   \/\/ sorted by ID table [id, index]\n+  AOTCodeEntry* _store_entries;    \/\/ Used when writing cache\n+  const char* _C_strings_buf;  \/\/ Loaded buffer for _C_strings[] table\n+  uint      _store_entries_cnt;\n+\n+  uint _compile_id;\n+  uint _comp_level;\n+  uint compile_id() const { return _compile_id; }\n+  uint comp_level() const { return _comp_level; }\n+\n+  static AOTCodeCache* open_for_read();\n+  static AOTCodeCache* open_for_write();\n+\n+  bool set_write_position(uint pos);\n+  bool align_write();\n+  uint write_bytes(const void* buffer, uint nbytes);\n+  const char* addr(uint offset) const { return _load_buffer + offset; }\n+\n+  static AOTCodeAddressTable* addr_table() {\n+    return is_on() && (cache()->_table != nullptr) ? cache()->_table : nullptr;\n+  }\n+\n+  bool _lookup_failed;       \/\/ Failed to lookup for info (skip only this code load)\n+  void set_lookup_failed()     { _lookup_failed = true; }\n+  void clear_lookup_failed()   { _lookup_failed = false; }\n+  bool lookup_failed()   const { return _lookup_failed; }\n+\n+  address reserve_bytes(uint nbytes);\n+\n+  AOTCodeEntry* write_nmethod(nmethod* nm, bool for_preload);\n+\n+  \/\/ States:\n+  \/\/   S >= 0: allow new readers, S readers are currently active\n+  \/\/   S <  0: no new readers are allowed; (-S-1) readers are currently active\n+  \/\/     (special case: S = -1 means no readers are active, and would never be active again)\n+  static volatile int _nmethod_readers;\n+\n+  static void wait_for_no_nmethod_readers();\n+\n+  class ReadingMark {\n+  private:\n+    bool _failed;\n+  public:\n+    ReadingMark();\n+    ~ReadingMark();\n+    bool failed() {\n+      return _failed;\n+    }\n+  };\n+\n+public:\n+  AOTCodeCache();\n+  ~AOTCodeCache();\n+\n+  const char* cache_buffer() const { return _load_buffer; }\n+  bool failed() const { return _failed; }\n+  void set_failed()   { _failed = true; }\n+\n+  static bool is_address_in_aot_cache(address p) NOT_CDS_RETURN_(false);\n+  static uint max_aot_code_size();\n+\n+  uint load_size() const { return _load_size; }\n+  uint write_position() const { return _write_position; }\n+\n+  void load_strings();\n+  int store_strings();\n+\n+  static void init_extrs_table() NOT_CDS_RETURN;\n+  static void init_early_stubs_table() NOT_CDS_RETURN;\n+  static void init_shared_blobs_table() NOT_CDS_RETURN;\n+  static void init_stubs_table() NOT_CDS_RETURN;\n+  static void init_opto_table() NOT_CDS_RETURN;\n+  static void init_c1_table() NOT_CDS_RETURN;\n+  address address_for_id(int id) const { return _table->address_for_id(id); }\n+\n+  bool for_read()  const { return _for_read  && !_failed; }\n+  bool for_write() const { return _for_write && !_failed; }\n+\n+  bool closing()          const { return _closing; }\n+  bool use_meta_ptrs()    const { return _use_meta_ptrs; }\n+  bool gen_preload_code() const { return _gen_preload_code; }\n+\n+  void add_new_C_string(const char* str);\n+\n+  AOTCodeEntry* add_entry() {\n+    _store_entries_cnt++;\n+    _store_entries -= 1;\n+    return _store_entries;\n+  }\n+  void preload_startup_code(TRAPS);\n+\n+  AOTCodeEntry* find_entry(AOTCodeEntry::Kind kind, uint id, uint comp_level = 0, uint decomp = 0);\n+  void invalidate_entry(AOTCodeEntry* entry);\n+\n+  bool finish_write();\n+\n+  void log_stats_on_exit();\n+\n+  static bool load_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) NOT_CDS_RETURN_(false);\n+  static bool store_stub(StubCodeGenerator* cgen, vmIntrinsicID id, const char* name, address start) NOT_CDS_RETURN_(false);\n+\n+  bool write_klass(Klass* klass);\n+  bool write_method(Method* method);\n+\n+  bool write_code(CodeBuffer* buffer, uint& code_size);\n+  bool write_relocations(CodeBuffer* buffer, uint& reloc_size);\n+  bool write_debug_info(DebugInformationRecorder* recorder);\n+  bool write_oop_maps(OopMapSet* oop_maps);\n+\n+  bool write_oop_map_set(nmethod* nm);\n+  bool write_nmethod_reloc_immediates(GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list);\n+  bool write_nmethod_loadtime_relocations(JavaThread* thread, nmethod* nm, GrowableArray<Handle>& oop_list, GrowableArray<Metadata*>& metadata_list);\n+\n+  jobject read_oop(JavaThread* thread, const methodHandle& comp_method);\n+  Metadata* read_metadata(const methodHandle& comp_method);\n+  bool read_oops(OopRecorder* oop_recorder, ciMethod* target);\n+  bool read_metadata(OopRecorder* oop_recorder, ciMethod* target);\n+\n+  bool write_oop(jobject& jo);\n+  bool write_oop(oop obj);\n+  bool write_oops(OopRecorder* oop_recorder);\n+  bool write_metadata(Metadata* m);\n+  bool write_metadata(OopRecorder* oop_recorder);\n+  bool write_oops(nmethod* nm);\n+  bool write_metadata(nmethod* nm);\n+\n+  static bool load_exception_blob(CodeBuffer* buffer, int* pc_offset) NOT_CDS_RETURN_(false);\n+  static bool store_exception_blob(CodeBuffer* buffer, int pc_offset) NOT_CDS_RETURN_(false);\n+\n+  static bool load_adapter(CodeBuffer* buffer, uint32_t id, const char* basic_sig, uint32_t offsets[4]) NOT_CDS_RETURN_(false);\n+  static bool store_adapter(CodeBuffer* buffer, uint32_t id, const char* basic_sig, uint32_t offsets[4]) NOT_CDS_RETURN_(false);\n+\n+  static bool load_nmethod(ciEnv* env, ciMethod* target, int entry_bci, AbstractCompiler* compiler, CompLevel comp_level) NOT_CDS_RETURN_(false);\n+  static AOTCodeEntry* store_nmethod(nmethod* nm, AbstractCompiler* compiler, bool for_preload) NOT_CDS_RETURN_(nullptr);\n+\n+  static uint store_entries_cnt() {\n+    if (is_on_for_write()) {\n+      return cache()->_store_entries_cnt;\n+    }\n+    return -1;\n+  }\n+\n+\/\/ Static access\n+\n+private:\n+  static AOTCodeCache*  _cache;\n+\n+  static bool open_cache();\n+  static bool verify_vm_config() {\n+    if (is_on_for_read()) {\n+      return _cache->_load_header->verify_vm_config();\n+    }\n+    return true;\n+  }\n+public:\n+  static AOTCodeCache* cache() { return _cache; }\n+  static void initialize() NOT_CDS_RETURN;\n+  static void init2() NOT_CDS_RETURN;\n+  static void close() NOT_CDS_RETURN;\n+  static bool is_on() CDS_ONLY({ return _cache != nullptr && !_cache->closing(); }) NOT_CDS_RETURN_(false);\n+  static bool is_C3_on() NOT_CDS_RETURN_(false);\n+  static bool is_code_load_thread_on() NOT_CDS_RETURN_(false);\n+  static bool is_on_for_read()  { return is_on() && _cache->for_read(); }\n+  static bool is_on_for_write() { return is_on() && _cache->for_write(); }\n+  static bool gen_preload_code(ciMethod* m, int entry_bci);\n+  static bool allow_const_field(ciConstant& value) NOT_CDS_RETURN_(false);\n+  static void invalidate(AOTCodeEntry* entry) NOT_CDS_RETURN;\n+  static bool is_loaded(AOTCodeEntry* entry);\n+  static AOTCodeEntry* find_code_entry(const methodHandle& method, uint comp_level);\n+  static void preload_code(JavaThread* thread);\n+\n+  template<typename Function>\n+  static void iterate(Function function) { \/\/ lambda enabled API\n+    AOTCodeCache* cache = open_for_read();\n+    if (cache != nullptr) {\n+      ReadingMark rdmk;\n+      if (rdmk.failed()) {\n+        \/\/ Cache is closed, cannot touch anything.\n+        return;\n+      }\n+\n+      uint count = cache->_load_header->entries_count();\n+      uint* search_entries = (uint*)cache->addr(cache->_load_header->entries_offset()); \/\/ [id, index]\n+      AOTCodeEntry* load_entries = (AOTCodeEntry*)(search_entries + 2 * count);\n+\n+      for (uint i = 0; i < count; i++) {\n+        int index = search_entries[2*i + 1];\n+        AOTCodeEntry* entry = &(load_entries[index]);\n+        function(entry);\n+      }\n+    }\n+  }\n+\n+  static void add_C_string(const char* str) NOT_CDS_RETURN;\n+\n+  static void print_on(outputStream* st) NOT_CDS_RETURN;\n+  static void print_statistics_on(outputStream* st) NOT_CDS_RETURN;\n+  static void print_timers_on(outputStream* st) NOT_CDS_RETURN;\n+  static void print_unused_entries_on(outputStream* st) NOT_CDS_RETURN;\n+};\n+\n+\/\/ +1 for preload code\n+const int AOTCompLevel_count = CompLevel_count + 1; \/\/ 6 levels indexed from 0 to 5\n+\n+struct AOTCodeStats {\n+private:\n+  struct {\n+    uint _kind_cnt[AOTCodeEntry::Kind_count];\n+    uint _nmethod_cnt[AOTCompLevel_count];\n+    uint _clinit_barriers_cnt;\n+  } ccstats; \/\/ ccstats = cached code stats\n+\n+  void check_kind(uint kind) { assert(kind >= AOTCodeEntry::None && kind < AOTCodeEntry::Kind_count, \"Invalid AOTCodeEntry kind %d\", kind); }\n+  void check_complevel(uint lvl) { assert(lvl >= CompLevel_none && lvl < AOTCompLevel_count, \"Invalid compilation level %d\", lvl); }\n+\n+public:\n+  void inc_entry_cnt(uint kind) { check_kind(kind); ccstats._kind_cnt[kind] += 1; }\n+  void inc_nmethod_cnt(uint lvl) { check_complevel(lvl); ccstats._nmethod_cnt[lvl] += 1; }\n+  void inc_preload_cnt() { ccstats._nmethod_cnt[AOTCompLevel_count-1] += 1; }\n+  void inc_clinit_barriers_cnt() { ccstats._clinit_barriers_cnt += 1; }\n+\n+  void collect_entry_stats(AOTCodeEntry* entry) {\n+    inc_entry_cnt(entry->kind());\n+    if (entry->is_code()) {\n+      entry->for_preload() ? inc_nmethod_cnt(AOTCompLevel_count-1)\n+                           : inc_nmethod_cnt(entry->comp_level());\n+      if (entry->has_clinit_barriers()) {\n+        inc_clinit_barriers_cnt();\n+      }\n+    }\n+  }\n+\n+  uint entry_count(uint kind) { check_kind(kind); return ccstats._kind_cnt[kind]; }\n+  uint nmethod_count(uint lvl) { check_complevel(lvl); return ccstats._nmethod_cnt[lvl]; }\n+  uint preload_count() { return ccstats._nmethod_cnt[AOTCompLevel_count-1]; }\n+  uint clinit_barriers_count() { return ccstats._clinit_barriers_cnt; }\n+\n+  uint total_count() {\n+    uint total = 0;\n+    for (int kind = AOTCodeEntry::None; kind < AOTCodeEntry::Kind_count; kind++) {\n+      total += ccstats._kind_cnt[kind];\n+    }\n+    return total;\n+  }\n+\n+  static AOTCodeStats add_cached_code_stats(AOTCodeStats stats1, AOTCodeStats stats2);\n+\n+  \/\/ Runtime stats of the AOT code\n+private:\n+  struct {\n+    struct {\n+      uint _loaded_cnt;\n+      uint _invalidated_cnt;\n+      uint _load_failed_cnt;\n+    } _entry_kinds[AOTCodeEntry::Kind_count],\n+      _nmethods[AOTCompLevel_count];\n+  } rs; \/\/ rs = runtime stats\n+\n+public:\n+  void inc_entry_loaded_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._loaded_cnt += 1; }\n+  void inc_entry_invalidated_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._invalidated_cnt += 1; }\n+  void inc_entry_load_failed_cnt(uint kind) { check_kind(kind); rs._entry_kinds[kind]._load_failed_cnt += 1; }\n+\n+  void inc_nmethod_loaded_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._loaded_cnt += 1; }\n+  void inc_nmethod_invalidated_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._invalidated_cnt += 1; }\n+  void inc_nmethod_load_failed_cnt(uint lvl) { check_complevel(lvl); rs._nmethods[lvl]._load_failed_cnt += 1; }\n+\n+  uint entry_loaded_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._loaded_cnt; }\n+  uint entry_invalidated_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._invalidated_cnt; }\n+  uint entry_load_failed_count(uint kind) { check_kind(kind); return rs._entry_kinds[kind]._load_failed_cnt; }\n+\n+  uint nmethod_loaded_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._loaded_cnt; }\n+  uint nmethod_invalidated_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._invalidated_cnt; }\n+  uint nmethod_load_failed_count(uint lvl) { check_complevel(lvl); return rs._nmethods[lvl]._load_failed_cnt; }\n+\n+  void inc_loaded_cnt(AOTCodeEntry* entry) {\n+    inc_entry_loaded_cnt(entry->kind());\n+    if (entry->is_code()) {\n+      entry->for_preload() ? inc_nmethod_loaded_cnt(AOTCompLevel_count-1)\n+                           : inc_nmethod_loaded_cnt(entry->comp_level());\n+    }\n+  }\n+\n+  void inc_invalidated_cnt(AOTCodeEntry* entry) {\n+    inc_entry_invalidated_cnt(entry->kind());\n+    if (entry->is_code()) {\n+      entry->for_preload() ? inc_nmethod_invalidated_cnt(AOTCompLevel_count-1)\n+                           : inc_nmethod_invalidated_cnt(entry->comp_level());\n+    }\n+  }\n+\n+  void inc_load_failed_cnt(AOTCodeEntry* entry) {\n+    inc_entry_load_failed_cnt(entry->kind());\n+    if (entry->is_code()) {\n+      entry->for_preload() ? inc_nmethod_load_failed_cnt(AOTCompLevel_count-1)\n+                           : inc_nmethod_load_failed_cnt(entry->comp_level());\n+    }\n+  }\n+\n+  void collect_entry_runtime_stats(AOTCodeEntry* entry) {\n+    if (entry->is_loaded()) {\n+      inc_loaded_cnt(entry);\n+    }\n+    if (entry->not_entrant()) {\n+      inc_invalidated_cnt(entry);\n+    }\n+    if (entry->load_fail()) {\n+      inc_load_failed_cnt(entry);\n+    }\n+  }\n+\n+  void collect_all_stats(AOTCodeEntry* entry) {\n+    collect_entry_stats(entry);\n+    collect_entry_runtime_stats(entry);\n+  }\n+\n+  AOTCodeStats() {\n+    memset(this, 0, sizeof(AOTCodeStats));\n+  }\n+};\n+\n+\/\/ code cache internal runtime constants area used by AOT code\n+class AOTRuntimeConstants {\n+ friend class AOTCodeCache;\n+  uint _grain_shift;\n+  uint _card_shift;\n+  static address _field_addresses_list[];\n+  static AOTRuntimeConstants _aot_runtime_constants;\n+  \/\/ private constructor for unique singleton\n+  AOTRuntimeConstants() { }\n+  \/\/ private for use by friend class AOTCodeCache\n+  static void initialize_from_runtime();\n+ public:\n+  static bool contains(address adr) {\n+    address base = (address)&_aot_runtime_constants;\n+    address hi = base + sizeof(AOTRuntimeConstants);\n+    return (base <= adr && adr < hi);\n+  }\n+  static address grain_shift_address() { return (address)&_aot_runtime_constants._grain_shift; }\n+  static address card_shift_address() { return (address)&_aot_runtime_constants._card_shift; }\n+  static address* field_addresses_list() {\n+    return _field_addresses_list;\n+  }\n+};\n+\n+#endif \/\/ SHARE_CODE_AOTCODECACHE_HPP\n","filename":"src\/hotspot\/share\/code\/aotCodeCache.hpp","additions":785,"deletions":0,"binary":false,"changes":785,"status":"added"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -191,1 +190,1 @@\n-  if (_oop_maps != nullptr && !SCCache::is_address_in_aot_cache((address)_oop_maps)) {\n+  if (_oop_maps != nullptr && !AOTCodeCache::is_address_in_aot_cache((address)_oop_maps)) {\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -160,1 +160,1 @@\n-    assert(_oop_maps == nullptr || SCCache::is_address_in_aot_cache((address)_oop_maps), \"Not flushed\");\n+    assert(_oop_maps == nullptr || AOTCodeCache::is_address_in_aot_cache((address)_oop_maps), \"Not flushed\");\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -1560,1 +1559,1 @@\n-    int idx1 = nm->is_scc() ? 1 : 0;\n+    int idx1 = nm->is_aot() ? 1 : 0;\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -87,2 +87,2 @@\n-  friend class SCCache;\n-  friend class SCCReader;\n+  friend class AOTCodeCache;\n+  friend class AOTCodeReader;\n@@ -150,2 +150,2 @@\n-  friend class SCCache;\n-  friend class SCCReader;\n+  friend class AOTCodeCache;\n+  friend class AOTCodeReader;\n","filename":"src\/hotspot\/share\/code\/exceptionHandlerTable.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -32,1 +33,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -1173,1 +1173,1 @@\n-  , SCCEntry* scc_entry\n+  , AOTCodeEntry* aot_code_entry\n@@ -1217,1 +1217,1 @@\n-            handler_table, nul_chk_table, compiler, comp_level, scc_entry\n+            handler_table, nul_chk_table, compiler, comp_level, aot_code_entry\n@@ -1234,1 +1234,1 @@\n-    LogTarget(Debug, scc, nmethod) log;\n+    LogTarget(Debug, aot, codecache, nmethod) log;\n@@ -1265,1 +1265,1 @@\n-                                   SCCReader* scc_reader)\n+                                   AOTCodeReader* aot_code_reader)\n@@ -1285,1 +1285,1 @@\n-  scc_reader->apply_relocations(this, reloc_imm_oop_list, reloc_imm_metadata_list);\n+  aot_code_reader->apply_relocations(this, reloc_imm_oop_list, reloc_imm_metadata_list);\n@@ -1302,1 +1302,1 @@\n-  set_scc_entry(scc_reader->scc_entry());\n+  set_aot_code_entry(aot_code_reader->aot_code_entry());\n@@ -1322,1 +1322,1 @@\n-                              SCCReader* scc_reader)\n+                              AOTCodeReader* aot_code_reader)\n@@ -1343,1 +1343,1 @@\n-                               scc_reader);\n+                               aot_code_reader);\n@@ -1351,1 +1351,1 @@\n-    LogTarget(Debug, scc, nmethod) log;\n+    LogTarget(Debug, aot, codecache, nmethod) log;\n@@ -1462,1 +1462,1 @@\n-    _scc_entry               = nullptr;\n+    _aot_code_entry          = nullptr;\n@@ -1566,1 +1566,1 @@\n-  , SCCEntry* scc_entry\n+  , AOTCodeEntry* aot_code_entry\n@@ -1586,1 +1586,1 @@\n-    _scc_entry      = scc_entry;\n+    _aot_code_entry          = aot_code_entry;\n@@ -2247,1 +2247,1 @@\n-      SCCache::invalidate(_scc_entry);\n+      AOTCodeCache::invalidate(_aot_code_entry);\n@@ -2335,1 +2335,1 @@\n-  if (_immutable_data != data_end() && !SCCache::is_address_in_aot_cache((address)_oop_maps)) {\n+  if (_immutable_data != data_end() && !AOTCodeCache::is_address_in_aot_cache((address)_oop_maps)) {\n@@ -2396,2 +2396,2 @@\n-  \/\/ task->is_scc() is true only for loaded cached code.\n-  \/\/ nmethod::_scc_entry is set for loaded and stored cached code\n+  \/\/ task->is_aot() is true only for loaded cached code.\n+  \/\/ nmethod::_aot_code_entry is set for loaded and stored cached code\n@@ -2400,1 +2400,1 @@\n-  guarantee((_scc_entry != nullptr) || !task->is_scc() || VerifyCachedCode, \"sanity\");\n+  guarantee((_aot_code_entry != nullptr) || !task->is_aot() || VerifyCachedCode, \"sanity\");\n@@ -3133,1 +3133,1 @@\n-  \/\/ Verification can triggered during shutdown after SCCache is closed.\n+  \/\/ Verification can triggered during shutdown after AOTCodeCache is closed.\n@@ -3135,1 +3135,1 @@\n-  if (!is_scc() || SCCache::is_on()) {\n+  if (!is_aot() || AOTCodeCache::is_on()) {\n@@ -3174,1 +3174,1 @@\n-  if (!is_scc() || SCCache::is_on()) {\n+  if (!is_aot() || AOTCodeCache::is_on()) {\n@@ -3345,2 +3345,2 @@\n-  if (SCCache::is_on() && _scc_entry != nullptr) {\n-    _scc_entry->print(st);\n+  if (AOTCodeCache::is_on() && _aot_code_entry != nullptr) {\n+    _aot_code_entry->print(st);\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":23,"deletions":23,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -48,2 +48,2 @@\n-class SCCReader;\n-class SCCEntry;\n+class AOTCodeReader;\n+class AOTCodeEntry;\n@@ -266,1 +266,1 @@\n-  SCCEntry* _scc_entry;\n+  AOTCodeEntry* _aot_code_entry;\n@@ -340,1 +340,1 @@\n-          , SCCEntry* scc_entry\n+          , AOTCodeEntry* aot_code_entry\n@@ -499,1 +499,1 @@\n-                            SCCReader* scc_reader);\n+                            AOTCodeReader* aot_code_reader);\n@@ -518,1 +518,1 @@\n-                              SCCReader* scc_reader);\n+                              AOTCodeReader* aot_code_reader);\n@@ -535,1 +535,1 @@\n-                              , SCCEntry* scc_entry\n+                              , AOTCodeEntry* aot_code_entry\n@@ -963,3 +963,3 @@\n-  SCCEntry* scc_entry() const { return _scc_entry; }\n-  bool is_scc() const { return scc_entry() != nullptr; }\n-  void set_scc_entry(SCCEntry* entry) { _scc_entry = entry; }\n+  AOTCodeEntry* aot_code_entry() const { return _aot_code_entry; }\n+  bool is_aot() const { return aot_code_entry() != nullptr; }\n+  void set_aot_code_entry(AOTCodeEntry* entry) { _aot_code_entry = entry; }\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -479,1 +479,1 @@\n-  \/\/ updating relocations in SCCReader::read_relocations().\n+  \/\/ updating relocations in AOTCodeReader::read_relocations().\n@@ -753,2 +753,2 @@\n-  if (SCCache::is_on()) {\n-    \/\/ SCA needs relocation info for card table base which may point to CodeCache\n+  if (AOTCodeCache::is_on()) {\n+    \/\/ AOTCode needs relocation info for card table base which may point to CodeCache\n","filename":"src\/hotspot\/share\/code\/relocInfo.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -675,1 +675,1 @@\n-  friend class SCCReader;\n+  friend class AOTCodeReader;\n","filename":"src\/hotspot\/share\/code\/relocInfo.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -309,1 +309,1 @@\n-        return !SCCache::is_C3_on();\n+        return !AOTCodeCache::is_C3_on();\n@@ -646,1 +646,1 @@\n-      } else if (SCCache::is_C3_on()) {\n+      } else if (AOTCodeCache::is_C3_on()) {\n@@ -662,1 +662,1 @@\n-    if (SCCache::is_code_load_thread_on()) {\n+    if (AOTCodeCache::is_code_load_thread_on()) {\n@@ -807,2 +807,2 @@\n-    if (task->is_scc()) {\n-      \/\/ SCC tasks are on separate queue, and they should load fast. There is no need to walk\n+    if (task->is_aot()) {\n+      \/\/ AOTCodeCache tasks are on separate queue, and they should load fast. There is no need to walk\n@@ -1094,1 +1094,1 @@\n-  assert(!x->is_scc() && !y->is_scc(), \"SC tasks are not expected here\");\n+  assert(!x->is_aot() && !y->is_aot(), \"SC tasks are not expected here\");\n","filename":"src\/hotspot\/share\/compiler\/compilationPolicy.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -34,1 +35,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -208,2 +208,2 @@\n-CompilerStatistics CompileBroker::_scc_stats;\n-CompilerStatistics CompileBroker::_scc_stats_per_level[CompLevel_full_optimization + 1];\n+CompilerStatistics CompileBroker::_aot_stats;\n+CompilerStatistics CompileBroker::_aot_stats_per_level[CompLevel_full_optimization + 1];\n@@ -635,3 +635,3 @@\n-CompileQueue* CompileBroker::compile_queue(int comp_level, bool is_scc) {\n-  if (is_c2_compile(comp_level)) return ((is_scc  && (_sc_count > 0)) ? _sc2_compile_queue : _c2_compile_queue);\n-  if (is_c1_compile(comp_level)) return ((is_scc && (_sc_count > 0)) ? _sc1_compile_queue : _c1_compile_queue);\n+CompileQueue* CompileBroker::compile_queue(int comp_level, bool is_aot) {\n+  if (is_c2_compile(comp_level)) return ((is_aot  && (_sc_count > 0)) ? _sc2_compile_queue : _c2_compile_queue);\n+  if (is_c1_compile(comp_level)) return ((is_aot && (_sc_count > 0)) ? _sc1_compile_queue : _c1_compile_queue);\n@@ -767,1 +767,1 @@\n-      if (SCCache::is_on() && (_c3_count > 0)) {\n+      if (AOTCodeCache::is_on() && (_c3_count > 0)) {\n@@ -905,1 +905,1 @@\n-  log_info(scc, init)(\"CompileBroker is initialized\");\n+  log_info(aot, codecache, init)(\"CompileBroker is initialized\");\n@@ -1436,2 +1436,2 @@\n-  SCCEntry* scc_entry = find_scc_entry(method, osr_bci, comp_level, compile_reason, requires_online_compilation);\n-  bool is_scc = (scc_entry != nullptr);\n+  AOTCodeEntry* aot_code_entry = find_aot_code_entry(method, osr_bci, comp_level, compile_reason, requires_online_compilation);\n+  bool is_aot = (aot_code_entry != nullptr);\n@@ -1449,1 +1449,1 @@\n-  queue = compile_queue(comp_level, is_scc);\n+  queue = compile_queue(comp_level, is_aot);\n@@ -1555,1 +1555,1 @@\n-                               hot_method, hot_count, scc_entry, compile_reason,\n+                               hot_method, hot_count, aot_code_entry, compile_reason,\n@@ -1558,1 +1558,1 @@\n-    if (task->is_scc() && (_sc_count > 0)) {\n+    if (task->is_aot() && (_sc_count > 0)) {\n@@ -1576,1 +1576,1 @@\n-SCCEntry* CompileBroker::find_scc_entry(const methodHandle& method, int osr_bci, int comp_level,\n+AOTCodeEntry* CompileBroker::find_aot_code_entry(const methodHandle& method, int osr_bci, int comp_level,\n@@ -1579,2 +1579,2 @@\n-  SCCEntry* scc_entry = nullptr;\n-  if (osr_bci == InvocationEntryBci && !requires_online_compilation && SCCache::is_on_for_read()) {\n+  AOTCodeEntry* aot_code_entry = nullptr;\n+  if (osr_bci == InvocationEntryBci && !requires_online_compilation && AOTCodeCache::is_on_for_read()) {\n@@ -1583,2 +1583,2 @@\n-      scc_entry = method->scc_entry();\n-      assert(scc_entry != nullptr && scc_entry->for_preload(), \"sanity\");\n+      aot_code_entry = method->aot_code_entry();\n+      assert(aot_code_entry != nullptr && aot_code_entry->for_preload(), \"sanity\");\n@@ -1586,1 +1586,1 @@\n-      scc_entry = SCCache::find_code_entry(method, comp_level);\n+      aot_code_entry = AOTCodeCache::find_code_entry(method, comp_level);\n@@ -1589,1 +1589,1 @@\n-  return scc_entry;\n+  return aot_code_entry;\n@@ -1778,1 +1778,1 @@\n-      if (online_only && result->is_scc()) {\n+      if (online_only && result->is_aot()) {\n@@ -1900,1 +1900,1 @@\n-                                                SCCEntry*           scc_entry,\n+                                                AOTCodeEntry*       aot_code_entry,\n@@ -1906,1 +1906,1 @@\n-                       hot_method, hot_count, scc_entry, compile_reason, queue,\n+                       hot_method, hot_count, aot_code_entry, compile_reason, queue,\n@@ -2677,1 +2677,1 @@\n-    tty->print(\"%s \", (is_osr ? \"%\" : (task->is_scc() ? \"A\" : \" \")));\n+    tty->print(\"%s \", (is_osr ? \"%\" : (task->is_aot() ? \"A\" : \" \")));\n@@ -2852,1 +2852,1 @@\n-      if (task->is_scc()) {\n+      if (task->is_aot()) {\n@@ -2854,1 +2854,1 @@\n-        stats = &_scc_stats_per_level[level];\n+        stats = &_aot_stats_per_level[level];\n@@ -2871,1 +2871,1 @@\n-      if (task->is_scc()) {\n+      if (task->is_aot()) {\n@@ -2873,1 +2873,1 @@\n-        stats = &_scc_stats_per_level[level];\n+        stats = &_aot_stats_per_level[level];\n@@ -2892,4 +2892,4 @@\n-      if (task->is_scc()) {\n-        _scc_stats._standard.update(time, bytes_compiled);\n-        _scc_stats._nmethods_size += task->nm_total_size();\n-        _scc_stats._nmethods_code_size += task->nm_insts_size();\n+      if (task->is_aot()) {\n+        _aot_stats._standard.update(time, bytes_compiled);\n+        _aot_stats._nmethods_size += task->nm_total_size();\n+        _aot_stats._nmethods_code_size += task->nm_insts_size();\n@@ -2897,1 +2897,1 @@\n-        CompilerStatistics* stats = &_scc_stats_per_level[level];\n+        CompilerStatistics* stats = &_aot_stats_per_level[level];\n@@ -2916,1 +2916,1 @@\n-      if (comp && !task->is_scc()) {\n+      if (comp && !task->is_aot()) {\n@@ -2925,1 +2925,1 @@\n-      } else if (!task->is_scc()) { \/\/ if (!comp)\n+      } else if (!task->is_aot()) { \/\/ if (!comp)\n@@ -2993,1 +2993,1 @@\n-    if (nm->is_scc()) {\n+    if (nm->is_aot()) {\n@@ -2998,1 +2998,1 @@\n-      stats = &_scc_stats_per_level[level - 1];\n+      stats = &_aot_stats_per_level[level - 1];\n@@ -3063,1 +3063,1 @@\n-        if (task->is_scc() && task->preload()) {\n+        if (task->is_aot() && task->preload()) {\n@@ -3109,1 +3109,1 @@\n-        print_tier_helper(st, \"SC T\", tier, &_scc_stats_per_level[tier - 1]);\n+        print_tier_helper(st, \"SC T\", tier, &_aot_stats_per_level[tier - 1]);\n@@ -3136,2 +3136,2 @@\n-    if (_scc_stats._standard._count > 0) {\n-      print_times(\"SC\", &_scc_stats);\n+    if (_aot_stats._standard._count > 0) {\n+      print_times(\"SC\", &_aot_stats);\n@@ -3152,1 +3152,1 @@\n-      CompilerStatistics* stats = &_scc_stats_per_level[tier-1];\n+      CompilerStatistics* stats = &_aot_stats_per_level[tier-1];\n@@ -3201,1 +3201,1 @@\n-    SCCache::print_timers_on(tty);\n+    AOTCodeCache::print_timers_on(tty);\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":43,"deletions":43,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -268,2 +268,2 @@\n-  static CompilerStatistics _scc_stats;\n-  static CompilerStatistics _scc_stats_per_level[];\n+  static CompilerStatistics _aot_stats;\n+  static CompilerStatistics _aot_stats_per_level[];\n@@ -293,1 +293,1 @@\n-                                          SCCEntry*           scc_entry,\n+                                          AOTCodeEntry*       aot_code_entry,\n@@ -325,1 +325,1 @@\n-  static CompileQueue* compile_queue(int comp_level, bool is_scc);\n+  static CompileQueue* compile_queue(int comp_level, bool is_aot);\n@@ -329,3 +329,3 @@\n-  static SCCEntry* find_scc_entry(const methodHandle& method, int osr_bci, int comp_level,\n-                                  CompileTask::CompileReason compile_reason,\n-                                  bool requires_online_compilation);\n+  static AOTCodeEntry* find_aot_code_entry(const methodHandle& method, int osr_bci, int comp_level,\n+                                           CompileTask::CompileReason compile_reason,\n+                                           bool requires_online_compilation);\n@@ -350,2 +350,2 @@\n-  static int queue_size(int comp_level, bool is_scc = false) {\n-    CompileQueue *q = compile_queue(comp_level, is_scc);\n+  static int queue_size(int comp_level, bool is_aot = false) {\n+    CompileQueue *q = compile_queue(comp_level, is_aot);\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -25,1 +25,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -109,1 +108,1 @@\n-                             SCCEntry* scc_entry,\n+                             AOTCodeEntry* aot_code_entry,\n@@ -150,1 +149,1 @@\n-  _scc_entry = scc_entry;\n+  _aot_code_entry = aot_code_entry;\n@@ -266,1 +265,1 @@\n-                             bool is_osr_method, int osr_bci, bool is_blocking, bool is_scc, bool is_preload,\n+                             bool is_osr_method, int osr_bci, bool is_blocking, bool is_aot, bool is_preload,\n@@ -328,1 +327,1 @@\n-  const char scc_char       = is_scc                          ? 'A' : ' ';\n+  const char aot_char       = is_aot                          ? 'A' : ' ';\n@@ -332,1 +331,1 @@\n-  st->print(\"%c%c%c%c%c%c%c \", compile_type, sync_char, exception_char, blocking_char, native_char, scc_char, preload_char);\n+  st->print(\"%c%c%c%c%c%c%c \", compile_type, sync_char, exception_char, blocking_char, native_char, aot_char, preload_char);\n@@ -365,1 +364,1 @@\n-  print_impl(st, is_unloaded() ? nullptr : method(), compile_id(), comp_level(), is_osr_method, osr_bci(), is_blocking(), is_scc(), preload(),\n+  print_impl(st, is_unloaded() ? nullptr : method(), compile_id(), comp_level(), is_osr_method, osr_bci(), is_blocking(), is_aot(), preload(),\n@@ -563,1 +562,1 @@\n-               \/*is_blocking*\/ false, nm->scc_entry() != nullptr,\n+               \/*is_blocking*\/ false, nm->aot_code_entry() != nullptr,\n","filename":"src\/hotspot\/share\/compiler\/compileTask.cpp","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-class SCCEntry;\n+class AOTCodeEntry;\n@@ -113,1 +113,1 @@\n-  SCCEntry*            _scc_entry;\n+  AOTCodeEntry*        _aot_code_entry;\n@@ -150,1 +150,1 @@\n-                  const methodHandle& hot_method, int hot_count, SCCEntry* scc_entry,\n+                  const methodHandle& hot_method, int hot_count, AOTCodeEntry* aot_code_entry,\n@@ -166,3 +166,3 @@\n-  bool         is_scc() const                       { return _scc_entry != nullptr; }\n-  void         clear_scc()                          { _scc_entry = nullptr; }\n-  SCCEntry*    scc_entry()                          { return _scc_entry; }\n+  bool         is_aot() const                       { return _aot_code_entry != nullptr; }\n+  void         clear_aot()                          { _aot_code_entry = nullptr; }\n+  AOTCodeEntry* aot_code_entry()                    { return _aot_code_entry; }\n@@ -275,1 +275,1 @@\n-                                      bool is_scc = false, bool is_preload = false,\n+                                      bool is_aot = false, bool is_preload = false,\n@@ -287,1 +287,1 @@\n-                           nm->scc_entry() != nullptr, nm->preloaded(),\n+                           nm->aot_code_entry() != nullptr, nm->preloaded(),\n","filename":"src\/hotspot\/share\/compiler\/compileTask.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -157,1 +157,1 @@\n-  friend class SCCReader;\n+  friend class AOTCodeReader;\n@@ -221,1 +221,1 @@\n-  friend class SCCReader;\n+  friend class AOTCodeReader;\n","filename":"src\/hotspot\/share\/compiler\/oopMap.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -166,1 +166,1 @@\n-        log.print(\"] [%d] (%s)\", SCCache::store_entries_cnt(), (is_success ? \"success\" : \"FAILED\"));\n+        log.print(\"] [%d] (%s)\", AOTCodeCache::store_entries_cnt(), (is_success ? \"success\" : \"FAILED\"));\n","filename":"src\/hotspot\/share\/compiler\/precompiler.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -83,1 +83,1 @@\n-      if (!AOTForceRecompilation && !(nm->is_scc() && nm->comp_level() == CompLevel_full_optimization)) {\n+      if (!AOTForceRecompilation && !(nm->is_aot() && nm->comp_level() == CompLevel_full_optimization)) {\n","filename":"src\/hotspot\/share\/compiler\/recompilationPolicy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -174,1 +174,1 @@\n-    if (SCCache::is_on_for_write()) {\n+    if (AOTCodeCache::is_on_for_write()) {\n@@ -194,1 +194,1 @@\n-    if (SCCache::is_on_for_write()) {\n+    if (AOTCodeCache::is_on_for_write()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/c1\/g1BarrierSetC1.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -26,3 +26,0 @@\n-#if INCLUDE_CDS\n-#include \"code\/SCCache.hpp\"\n-#endif\n","filename":"src\/hotspot\/share\/gc\/g1\/c2\/g1BarrierSetC2.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -193,1 +193,1 @@\n-class SCAddressTable;\n+class AOTCodeAddressTable;\n@@ -196,1 +196,1 @@\n-  friend class SCAddressTable;\n+  friend class AOTCodeAddressTable;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c1\/shenandoahBarrierSetC1.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -90,1 +90,1 @@\n-class SCAddressTable;\n+class AOTCodeAddressTable;\n@@ -93,1 +93,1 @@\n-  friend SCAddressTable;\n+  friend AOTCodeAddressTable;\n","filename":"src\/hotspot\/share\/gc\/z\/c1\/zBarrierSetC1.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2167,1 +2167,1 @@\n-                                 compiler, comp_level, nullptr \/* SCCEntry *\/,\n+                                 compiler, comp_level, nullptr \/* AOTCodeEntry *\/,\n","filename":"src\/hotspot\/share\/jvmci\/jvmciRuntime.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -184,1 +184,0 @@\n-  LOG_TAG(scc) \\\n","filename":"src\/hotspot\/share\/logging\/logTag.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1329,1 +1329,1 @@\n-    assert(((nmethod*)_preload_code)->scc_entry() == _scc_entry, \"sanity\");\n+    assert(((nmethod*)_preload_code)->aot_code_entry() == _aot_code_entry, \"sanity\");\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-class SCCEntry;\n+class AOTCodeEntry;\n@@ -106,2 +106,2 @@\n-  nmethod*  _preload_code;  \/\/ preloaded SCCache code\n-  SCCEntry* _scc_entry;     \/\/ SCCache entry for pre-loading code\n+  nmethod*  _preload_code;       \/\/ preloaded AOT code\n+  AOTCodeEntry* _aot_code_entry; \/\/ AOT Code Cache entry for pre-loading code\n@@ -398,2 +398,2 @@\n-  void set_scc_entry(SCCEntry* entry) {\n-    _scc_entry = entry;\n+  void set_aot_code_entry(AOTCodeEntry* entry) {\n+    _aot_code_entry = entry;\n@@ -401,2 +401,2 @@\n-  SCCEntry* scc_entry() const {\n-    return _scc_entry;\n+  AOTCodeEntry* aot_code_entry() const {\n+    return _aot_code_entry;\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -105,1 +105,1 @@\n-    SCCache::init_opto_table();\n+    AOTCodeCache::init_opto_table();\n@@ -130,2 +130,2 @@\n-  if (install_code && task->is_scc()) {\n-    bool success = SCCache::load_nmethod(env, target, entry_bci, this, CompLevel_full_optimization);\n+  if (install_code && task->is_aot()) {\n+    bool success = AOTCodeCache::load_nmethod(env, target, entry_bci, this, CompLevel_full_optimization);\n@@ -137,1 +137,1 @@\n-      SCCache::invalidate(task->scc_entry()); \/\/ mark sca_entry as not entrant\n+      AOTCodeCache::invalidate(task->aot_code_entry()); \/\/ mark sca_entry as not entrant\n@@ -139,1 +139,1 @@\n-    if (SCCache::is_code_load_thread_on()) {\n+    if (AOTCodeCache::is_code_load_thread_on()) {\n@@ -144,1 +144,1 @@\n-    task->clear_scc();\n+    task->clear_aot();\n@@ -155,1 +155,1 @@\n-                     SCCache::gen_preload_code(target, entry_bci);\n+                     AOTCodeCache::gen_preload_code(target, entry_bci);\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2145,1 +2145,1 @@\n-    log_debug(scc,deoptimization)(\"Uncommon trap in preload code: reason=%s action=%s method=%s::%s bci=%d, %s\",\n+    log_debug(aot, codecache, deoptimization)(\"Uncommon trap in preload code: reason=%s action=%s method=%s::%s bci=%d, %s\",\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"code\/aotCodeCache.hpp\"\n@@ -29,1 +30,0 @@\n-#include \"code\/SCCache.hpp\"\n@@ -3677,1 +3677,1 @@\n-  if (SCCache::is_on_for_write()) {\n+  if (AOTCodeCache::is_on_for_write()) {\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -185,1 +185,1 @@\n-  \/\/ SCCache::write_nmethod bails when nmethod buffer is expanded.\n+  \/\/ AOTCodeCache::write_nmethod bails when nmethod buffer is expanded.\n@@ -187,3 +187,3 @@\n-  \/\/ ineligible for SCCache stores. In order to minimize this effect,\n-  \/\/ we default to larger default sizes. We do this only when SCC dumping\n-  \/\/ is active, to avoid impact on default configuration.\n+  \/\/ ineligible for AOTCodeCache stores. In order to minimize this effect,\n+  \/\/ we default to larger default sizes. We do this only when AOTCodeCache\n+  \/\/ dumping is active, to avoid impact on default configuration.\n@@ -199,1 +199,1 @@\n-  \/\/ TODO: Revert this back to mainline once SCCache is fixed.\n+  \/\/ TODO: Revert this back to mainline once AOTCodeCache is fixed.\n","filename":"src\/hotspot\/share\/opto\/output.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -74,1 +74,1 @@\n-  SCCache::add_C_string(halt_reason);\n+  AOTCodeCache::add_C_string(halt_reason);\n","filename":"src\/hotspot\/share\/opto\/rootnode.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-  friend class SCAddressTable;\n+  friend class AOTCodeAddressTable;\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3765,1 +3765,1 @@\n-  UseSecondarySupersTable = false; \/\/ FIXME: Disabled for Leyden. Neet to fix SCAddressTable::id_for_address()\n+  UseSecondarySupersTable = false; \/\/ FIXME: Disabled for Leyden. Neet to fix AOTCodeAddressTable::id_for_address()\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2866,1 +2866,1 @@\n-  uint lvl = nm->comp_level() + (nm->is_scc() ? 4 : 0) + (nm->preloaded() ? 1 : 0);\n+  uint lvl = nm->comp_level() + (nm->is_aot() ? 4 : 0) + (nm->preloaded() ? 1 : 0);\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -162,1 +162,1 @@\n-  SCCache::init2();        \/\/ depends on universe_init\n+  AOTCodeCache::init2();        \/\/ depends on universe_init\n@@ -175,2 +175,2 @@\n-  SCCache::init_shared_blobs_table();  \/\/ need this after generate_stubs\n-  SharedRuntime::init_adapter_library(); \/\/ do this after SCCache::init_shared_blobs_table\n+  AOTCodeCache::init_shared_blobs_table();  \/\/ need this after generate_stubs\n+  SharedRuntime::init_adapter_library(); \/\/ do this after AOTCodeCache::init_shared_blobs_table\n@@ -228,1 +228,1 @@\n-  SCCache::init_stubs_table();\n+  AOTCodeCache::init_stubs_table();\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -39,1 +39,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -214,1 +214,1 @@\n-    if (SCCache::is_on_for_read()) {\n+    if (AOTCodeCache::is_on_for_read()) {\n@@ -216,1 +216,1 @@\n-      SCCache::print_statistics_on(&log);\n+      AOTCodeCache::print_statistics_on(&log);\n@@ -218,1 +218,1 @@\n-      SCCache::print_timers_on(&log);\n+      AOTCodeCache::print_timers_on(&log);\n@@ -551,1 +551,1 @@\n-  SCCache::close(); \/\/ Write final data and close archive\n+  AOTCodeCache::close(); \/\/ Write final data and close archive\n","filename":"src\/hotspot\/share\/runtime\/java.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -2848,1 +2848,1 @@\n-  if (SCCache::load_adapter(buffer, id, name, offsets)) {\n+  if (AOTCodeCache::load_adapter(buffer, id, name, offsets)) {\n@@ -2912,1 +2912,1 @@\n-    SCCache::store_adapter(&buffer, id, name, offsets);\n+    AOTCodeCache::store_adapter(&buffer, id, name, offsets);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -205,1 +205,1 @@\n-  friend class SCAddressTable;\n+  friend class AOTCodeAddressTable;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-#include \"code\/SCCache.hpp\"\n+#include \"code\/aotCodeCache.hpp\"\n@@ -865,1 +865,1 @@\n-      SCCache::close();\n+      AOTCodeCache::close();\n@@ -874,1 +874,1 @@\n-  SCCache::preload_code(CHECK_JNI_ERR);\n+  AOTCodeCache::preload_code(CHECK_JNI_ERR);\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-        EXTRA_ARGS=\"$EXTRA_ARGS -Xlog:scc -Xlog:scc,nmethod\"\n+        EXTRA_ARGS=\"$EXTRA_ARGS -Xlog:aot+codecache -Xlog:aot+codecache+nmethod\"\n@@ -431,1 +431,1 @@\n-    CMD=\"$JVM_AND_ARGS $EXTRA_ARGS -Xlog:scc*=warning:file=javac.scc-store.log::filesize=0 \\\n+    CMD=\"$JVM_AND_ARGS $EXTRA_ARGS -Xlog:aot+codecache*=warning:file=javac.aot-store.log::filesize=0 \\\n@@ -442,1 +442,1 @@\n-    CMD=\"$JVM_AND_ARGS $EXTRA_ARGS -Xlog:scc*=warning:file=javac.scc-load.log::filesize=0 \\\n+    CMD=\"$JVM_AND_ARGS $EXTRA_ARGS -Xlog:aot+codecache*=warning:file=javac.aot-load.log::filesize=0 \\\n","filename":"test\/hotspot\/jtreg\/premain\/javac\/javac-test.sh","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-TRAINING_OPTS=\"${TRAINING_OPTS} -Xlog:scc -Xlog:cds=debug::uptime,tags,pid\"\n+TRAINING_OPTS=\"${TRAINING_OPTS} -Xlog:aot+codecache -Xlog:cds=debug::uptime,tags,pid\"\n@@ -70,1 +70,1 @@\n-cmd=\"$launcher $PRODUCTION_OPTS -Xlog:cds -Xlog:scc -XX:CacheDataStore=javac.cds $@ com.sun.tools.javac.Main HelloWorld.java\"\n+cmd=\"$launcher $PRODUCTION_OPTS -Xlog:cds -Xlog:aot+codecache -XX:CacheDataStore=javac.cds $@ com.sun.tools.javac.Main HelloWorld.java\"\n","filename":"test\/hotspot\/jtreg\/premain\/javac_new_workflow\/run.sh","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-        -Xlog:scc*=warning:file=$APP-store-sc.log \\\n+        -Xlog:aot+codecache*=warning:file=$APP-store-sc.log \\\n@@ -99,1 +99,1 @@\n-        -Xlog:scc*=warning:file=$APP-load-sc.log \\\n+        -Xlog:aot+codecache*=warning:file=$APP-load-sc.log \\\n","filename":"test\/hotspot\/jtreg\/premain\/jmh\/run.sh","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-#       e.g. LEYDEN_CALLER_OPTS='-Xlog:scc=error'\n+#       e.g. LEYDEN_CALLER_OPTS='-Xlog:aot+codecache=error'\n","filename":"test\/hotspot\/jtreg\/premain\/lib\/bench-lib-new-workflow.sh","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -236,1 +236,1 @@\n-                       -Xlog:scc*=warning:file=$APPID-store-sc.log::filesize=0 \\\n+                       -Xlog:aot+codecache*=warning:file=$APPID-store-sc.log::filesize=0 \\\n@@ -269,1 +269,1 @@\n-              -XX:CachedCodeFile=$APPID-dynamic.jsa-sc -Xlog:scc=error \\\n+              -XX:CachedCodeFile=$APPID-dynamic.jsa-sc -Xlog:aot+codecache=error \\\n","filename":"test\/hotspot\/jtreg\/premain\/lib\/bench-lib.sh","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -95,1 +95,1 @@\n-        -Xlog:scc*=warning:file=$APP-store-sc.log::filesize=0 \\\n+        -Xlog:aot+codecache*=warning:file=$APP-store-sc.log::filesize=0 \\\n@@ -100,1 +100,1 @@\n-        -Xlog:scc*=warning:file=$APP-load-sc.log::filesize=0 \\\n+        -Xlog:aot+codecache*=warning:file=$APP-load-sc.log::filesize=0 \\\n","filename":"test\/hotspot\/jtreg\/premain\/lib\/premain-run.sh","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -284,1 +284,1 @@\n-\t     -Xlog:scc,cds=debug,cds+class=debug,cds+heap=warning,cds+resolve=debug:file=$@.log \\\n+\t     -Xlog:aot+codecache=debug,cds=debug,cds+class=debug,cds+heap=warning,cds+resolve=debug:file=$@.log \\\n@@ -308,1 +308,1 @@\n-\t       -Xlog:scc,cds=debug,cds+class=debug,cds+heap=warning,cds+resolve=debug:file=$@.log \\\n+\t       -Xlog:aot+codecache=debug,cds=debug,cds+class=debug,cds+heap=warning,cds+resolve=debug:file=$@.log \\\n","filename":"test\/hotspot\/jtreg\/premain\/spring-petclinic\/WarmupMakefile","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-CMDLINE=\"$CMDLINE -XX:CachedCodeFile=spring-petclinic.code.jsa -Xlog:init -Xlog:scc=error -Xmx2g\"\n+CMDLINE=\"$CMDLINE -XX:CachedCodeFile=spring-petclinic.code.jsa -Xlog:init -Xlog:aot+codecache=error -Xmx2g\"\n","filename":"test\/hotspot\/jtreg\/premain\/spring-petclinic\/bench.sh","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -96,1 +96,1 @@\n-            \"-Xlog:scc*\",\n+            \"-Xlog:aot+codecache*\",\n@@ -168,1 +168,1 @@\n-            \"-Xlog:scc*\",\n+            \"-Xlog:aot+codecache*\",\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/AOTFlags.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -133,1 +133,1 @@\n-                cmdLine = StringArrayUtils.concat(\"-Xlog:scc=error\", cmdLine);\n+                cmdLine = StringArrayUtils.concat(\"-Xlog:aot+codecache=error\", cmdLine);\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/applications\/HelidonQuickStartSE.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -132,1 +132,1 @@\n-                cmdLine = StringArrayUtils.concat(\"-Xlog:scc=error\", cmdLine);\n+                cmdLine = StringArrayUtils.concat(\"-Xlog:aot+codecache=error\", cmdLine);\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/applications\/MicronautFirstApp.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -132,1 +132,1 @@\n-                cmdLine = StringArrayUtils.concat(\"-Xlog:scc=error\", cmdLine);\n+                cmdLine = StringArrayUtils.concat(\"-Xlog:aot+codecache=error\", cmdLine);\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/applications\/QuarkusGettingStarted.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-                cmdLine = StringArrayUtils.concat(\"-Xlog:scc=error\", cmdLine);\n+                cmdLine = StringArrayUtils.concat(\"-Xlog:aot+codecache=error\", cmdLine);\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/applications\/SpringPetClinic.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}