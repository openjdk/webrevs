{"files":[{"patch":"@@ -1853,0 +1853,12 @@\n+\n+#ifdef ASSERT\n+void InterpreterMacroAssembler::verify_field_offset(Register reg) {\n+  \/\/ Verify the field offset is not in the header, implicitly checks for 0\n+  Label L;\n+  subs(zr, reg, static_cast<int>(sizeof(markWord) + (UseCompressedClassPointers ? sizeof(narrowKlass) : sizeof(Klass*))));\n+  br(Assembler::GE, L);\n+  stop(\"bad field offset\");\n+  bind(L);\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -295,0 +295,2 @@\n+\n+  void verify_field_offset(Register reg) NOT_DEBUG_RETURN;\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -168,0 +168,1 @@\n+  assert_different_registers(bc_reg, temp_reg);\n@@ -225,2 +226,6 @@\n-  \/\/ patch bytecode\n-  __ strb(bc_reg, at_bcp(0));\n+  \/\/ Patch bytecode with release store to coordinate with ConstantPoolCacheEntry loads\n+  \/\/ in fast bytecode codelets. The fast bytecode codelets have a memory barrier that gains\n+  \/\/ the needed ordering, together with control dependency on entering the fast codelet\n+  \/\/ itself.\n+  __ lea(temp_reg, at_bcp(0));\n+  __ stlrb(bc_reg, temp_reg);\n@@ -2917,0 +2922,1 @@\n+  __ verify_field_offset(r1);\n@@ -3010,0 +3016,2 @@\n+  __ verify_field_offset(r1);\n+\n@@ -3077,0 +3085,4 @@\n+\n+  \/\/ Must prevent reordering of the following cp cache loads with bytecode load\n+  __ membar(MacroAssembler::LoadLoad);\n+\n@@ -3079,0 +3091,1 @@\n+  __ verify_field_offset(r1);\n","filename":"src\/hotspot\/cpu\/aarch64\/templateTable_aarch64.cpp","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"}]}